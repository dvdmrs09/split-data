{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assumption_list_string(assumptions, assumption_dict):\n    '''\nTakes in a list of short forms of assumptions and an assumption\ndictionary, and returns a \"list\" form of the long form of the\nassumptions.\n\nRaises\n------\nValueError\n    if one of the assumptions is not in assumption_dict.\n    '''\n    if isinstance(assumptions, six.string_types):\n        raise TypeError('assumptions must be an iterable of strings, not a '\n                        'string itself')\n    for a in assumptions:\n        if a not in assumption_dict.keys():\n            raise ValueError('{} not present in assumption_dict'.format(a))\n    assumption_strings = [assumption_dict[a] for a in assumptions]\n    return strings_to_list_string(assumption_strings)", "response": "Takes in a list of short forms of assumptions and an assumption_dict and returns a list of long form of the list of assumptions."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef quantity_spec_string(name, quantity_dict):\n    '''\nReturns a quantity specification for docstrings.\n\nExample\n-------\n\n>>> quantity_spec_string('Tv')\n>>> 'Tv : float or ndarray\\n    Data for virtual temperature.'\n    '''\n    if name not in quantity_dict.keys():\n        raise ValueError('{0} not present in quantity_dict'.format(name))\n    s = '{0} : float or ndarray\\n'.format(name)\n    s += doc_paragraph('Data for {0}.'.format(\n        quantity_string(name, quantity_dict)), indent=4)\n    return s", "response": "Returns a quantity specification for docstrings.\nExample\n-------\n\n >>> quantity_spec_string ( Tv ) Tv : float or ndarray\\ n    Data for virtual temperature."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntake in a string without wrapping corresponding to a paragraph and returns a version of that string wrapped to be at most 80 characters in length on each line.", "response": "def doc_paragraph(s, indent=0):\n    '''Takes in a string without wrapping corresponding to a paragraph,\n       and returns a version of that string wrapped to be at most 80\n       characters in length on each line.\n       If indent is given, ensures each line is indented to that number\n       of spaces.\n    '''\n    return '\\n'.join([' '*indent + l for l in wrap(s, width=80-indent)])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_derivative_string(string, quantity_dict):\n    '''\n    Assuming the string is of the form d(var1)d(var2), returns var1, var2.\n    Raises ValueError if the string is not of this form, or if the vars\n    are not keys in the quantity_dict, or if var2 is not a coordinate-like\n    variable.\n    '''\n    match = derivative_prog.match(string)\n    if match is None:\n        raise ValueError('string is not in the form of a derivative')\n    varname = match.group(1)\n    coordname = match.group(2)\n    if (varname not in quantity_dict.keys() or\n            coordname not in quantity_dict.keys()):\n        raise ValueError('variable in string not a valid quantity')\n    return varname, coordname", "response": "Parse a derivative string into a variable name and coordname."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef closest_val(x, L):\n    '''\n    Finds the index value in an iterable closest to a desired value.\n\n    Parameters\n    ----------\n    x : object\n        The desired value.\n    L : iterable\n        The iterable in which to search for the desired value.\n\n    Returns\n    -------\n    index : int\n        The index of the closest value to x in L.\n\n    Notes\n    -----\n    Assumes x and the entries of L are of comparable types.\n\n    Raises\n    ------\n    ValueError:\n        if L is empty\n    '''\n    # Make sure the iterable is nonempty\n    if len(L) == 0:\n        raise ValueError('L must not be empty')\n    if isinstance(L, np.ndarray):\n        # use faster numpy methods if using a numpy array\n        return (np.abs(L-x)).argmin()\n    # for a general iterable (like a list) we need general Python\n    # start by assuming the first item is closest\n    min_index = 0\n    min_diff = abs(L[0] - x)\n    i = 1\n    while i < len(L):\n        # check if each other item is closer than our current closest\n        diff = abs(L[i] - x)\n        if diff < min_diff:\n            # if it is, set it as the new closest\n            min_index = i\n            min_diff = diff\n        i += 1\n    return min_index", "response": "Finds the index value in an iterable closest to a desired value."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the area of an arbitrary polygon on the sphere.", "response": "def area_poly_sphere(lat, lon, r_sphere):\n    '''\nCalculates the area enclosed by an arbitrary polygon on the sphere.\n\nParameters\n----------\n\nlat : iterable\n    The latitudes, in degrees, of the vertex locations of the polygon, in\n    clockwise order.\nlon : iterable\n    The longitudes, in degrees, of the vertex locations of the polygon, in\n    clockwise order.\n\nReturns\n-------\n\narea : float\n    The desired spherical area in the same units as r_sphere.\n\nNotes\n-----\n\nThis function assumes the vertices form a valid polygon (edges do not\nintersect each other).\n\n**References**\n\nComputing the Area of a Spherical Polygon of Arbitrary Shape\nBevis and Cambareri (1987)\nMathematical Geology, vol.19, Issue 4, pp 335-346\n    '''\n    dtr = np.pi/180.\n\n    def _tranlon(plat, plon, qlat, qlon):\n        t = np.sin((qlon-plon)*dtr)*np.cos(qlat*dtr)\n        b = (np.sin(qlat*dtr)*np.cos(plat*dtr) -\n             np.cos(qlat*dtr)*np.sin(plat*dtr)*np.cos((qlon-plon)*dtr))\n        return np.arctan2(t, b)\n\n    if len(lat) < 3:\n        raise ValueError('lat must have at least 3 vertices')\n    if len(lat) != len(lon):\n        raise ValueError('lat and lon must have the same length')\n    total = 0.\n    for i in range(-1, len(lat)-1):\n        fang = _tranlon(lat[i], lon[i], lat[i+1], lon[i+1])\n        bang = _tranlon(lat[i], lon[i], lat[i-1], lon[i-1])\n        fvb = bang - fang\n        if fvb < 0:\n            fvb += 2.*np.pi\n        total += fvb\n    return (total - np.pi*float(len(lat)-2))*r_sphere**2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the second - order centered finite difference derivative of data along the specified axis.", "response": "def ddx(data, axis=0, dx=None, x=None, axis_x=0, boundary='forward-backward'):\n    '''\nCalculates a second-order centered finite difference derivative of data\nalong the specified axis.\n\nParameters\n----------\n\ndata : ndarray\n    Data on which we are taking a derivative.\naxis : int\n    Index of the data array on which to take the derivative.\ndx : float, optional\n    Constant grid spacing value. Will assume constant grid spacing if\n    given. May not be used with argument x. Default value is 1 unless\n    x is given.\nx : ndarray, optional\n    Values of the axis along which we are taking a derivative to allow\n    variable grid spacing. May not be given with argument dx.\naxis_x : int, optional\n    Index of the x array on which to take the derivative. Does nothing if\n    x is not given as an argument.\nboundary : string, optional\n    Boundary condition. If 'periodic', assume periodic boundary condition\n    for centered difference. If 'forward-backward', take first-order\n    forward or backward derivatives at boundary.\n\nReturns\n-------\n\nderivative : ndarray\n    Derivative of the data along the specified axis.\n\nRaises\n------\n\nValueError:\n    If an invalid boundary condition choice is given, if both dx and x are\n    specified, if axis is out of the valid range for the shape of the data,\n    or if x is specified and axis_x is out of the valid range for the shape\n    of x.\n    '''\n    if abs(axis) >= len(data.shape):\n        raise ValueError('axis is out of bounds for the shape of data')\n    if x is not None and abs(axis_x) > len(x.shape):\n        raise ValueError('axis_x is out of bounds for the shape of x')\n    if dx is not None and x is not None:\n        raise ValueError('may not give both x and dx as keyword arguments')\n    if boundary == 'periodic':\n        deriv = (np.roll(data, -1, axis) - np.roll(data, 1, axis)\n                 )/(np.roll(x, -1, axis_x) - np.roll(x, 1, axis_x))\n    elif boundary == 'forward-backward':\n        # We will take forward-backward differencing at edges\n        # need some fancy indexing to handle arbitrary derivative axis\n        # Initialize our index lists\n        front = [slice(s) for s in data.shape]\n        back = [slice(s) for s in data.shape]\n        target = [slice(s) for s in data.shape]\n        # Set our index values for the derivative axis\n        # front is the +1 index for derivative\n        front[axis] = np.array([1, -1])\n        # back is the -1 index for derivative\n        back[axis] = np.array([0, -2])\n        # target is the position where the derivative is being calculated\n        target[axis] = np.array([0, -1])\n        if dx is not None:  # grid spacing is constant\n            deriv = (np.roll(data, -1, axis) - np.roll(data, 1, axis))/(2.*dx)\n            deriv[target] = (data[front]-data[back])/dx\n        else:  # grid spacing is arbitrary\n            # Need to calculate differences for our grid positions, too!\n            # first take care of the centered differences\n            dx = (np.roll(x, -1, axis_x) - np.roll(x, 1, axis_x))\n            # now handle those annoying edge points, like with the data above\n            front_x = [slice(s) for s in x.shape]\n            back_x = [slice(s) for s in x.shape]\n            target_x = [slice(s) for s in x.shape]\n            front_x[axis_x] = np.array([1, -1])\n            back_x[axis_x] = np.array([0, -2])\n            target_x[axis] = np.array([0, -1])\n            dx[target_x] = (x[front_x] - x[back_x])\n            # Here dx spans two grid indices, no need for *2\n            deriv = (np.roll(data, -1, axis) - np.roll(data, 1, axis))/dx\n            deriv[target] = (data[front] - data[back])/dx\n    else:  # invalid boundary condition was given\n        raise ValueError('Invalid option {} for boundary '\n                         'condition.'.format(boundary))\n    return deriv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef d_x(data, axis, boundary='forward-backward'):\n    '''\nCalculates a second-order centered finite difference of data along the\nspecified axis.\n\nParameters\n----------\n\ndata : ndarray\n    Data on which we are taking a derivative.\naxis : int\n    Index of the data array on which to take the difference.\nboundary : string, optional\n    Boundary condition. If 'periodic', assume periodic boundary condition\n    for centered difference. If 'forward-backward', take first-order\n    forward or backward derivatives at boundary.\n\nReturns\n-------\n\nderivative : ndarray\n    Derivative of the data along the specified axis.\n\nRaises\n------\n\nValueError:\n    If an invalid boundary condition choice is given, if both dx and x are\n    specified, if axis is out of the valid range for the shape of the data,\n    or if x is specified and axis_x is out of the valid range for the shape\n    of x.\n    '''\n    if abs(axis) > len(data.shape):\n        raise ValueError('axis is out of bounds for the shape of data')\n    if boundary == 'periodic':\n        diff = np.roll(data, -1, axis) - np.roll(data, 1, axis)\n    elif boundary == 'forward-backward':\n        # We will take forward-backward differencing at edges\n        # need some fancy indexing to handle arbitrary derivative axis\n        # Initialize our index lists\n        front = [slice(s) for s in data.shape]\n        back = [slice(s) for s in data.shape]\n        target = [slice(s) for s in data.shape]\n        # Set our index values for the derivative axis\n        # front is the +1 index for derivative\n        front[axis] = np.array([1, -1])\n        # back is the -1 index for derivative\n        back[axis] = np.array([0, -2])\n        # target is the position where the derivative is being calculated\n        target[axis] = np.array([0, -1])\n        diff = (np.roll(data, -1, axis) - np.roll(data, 1, axis))/(2.)\n        diff[target] = (data[front]-data[back])\n    else:  # invalid boundary condition was given\n        raise ValueError('Invalid option {} for boundary '\n                         'condition.'.format(boundary))\n    return diff", "response": "Calculates a second - order centered finite difference of data along the specified axis."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef semilogy(self, p, T, *args, **kwargs):\n        r'''Plot data.\n\n        Simple wrapper around plot so that pressure is the first (independent)\n        input. This is essentially a wrapper around `semilogy`.\n\n        Parameters\n        ----------\n        p : array_like\n            pressure values\n        T : array_like\n            temperature values, can also be used for things like dew point\n        args\n            Other positional arguments to pass to `semilogy`\n        kwargs\n            Other keyword arguments to pass to `semilogy`\n\n        See Also\n        --------\n        `matplotlib.Axes.semilogy`\n        '''\n        # We need to replace the overridden plot with the original Axis plot\n        # since it is called within Axes.semilogy\n        no_plot = SkewTAxes.plot\n        SkewTAxes.plot = Axes.plot\n        Axes.semilogy(self, T, p, *args, **kwargs)\n        # Be sure to put back the overridden plot method\n        SkewTAxes.plot = no_plot\n        self.yaxis.set_major_formatter(ScalarFormatter())\n        self.yaxis.set_major_locator(MultipleLocator(100))\n        labels = self.xaxis.get_ticklabels()\n        for label in labels:\n            label.set_rotation(45)\n            label.set_horizontalalignment('right')\n            label.set_fontsize(8)\n            label.set_color('#B31515')\n        self.grid(True)\n        self.grid(axis='top', color='#B31515', linestyle='-', linewidth=1,\n                  alpha=0.5, zorder=1.1)\n        self.grid(axis='x', color='#B31515', linestyle='-', linewidth=1,\n                  alpha=0.5, zorder=1.1)\n        self.grid(axis='y', color='k', linestyle='-', linewidth=0.5, alpha=0.5,\n                  zorder=1.1)\n        self.set_xlabel(r'Temperature ($^{\\circ} C$)', color='#B31515')\n        self.set_ylabel('Pressure ($hPa$)')\n        if len(self._mixing_lines) == 0:\n            self.plot_mixing_lines()\n        if len(self._dry_adiabats) == 0:\n            self.plot_dry_adiabats()\n        if len(self._moist_adiabats) == 0:\n            self.plot_moist_adiabats()", "response": "r Plot data.\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plot_moist_adiabats(self, p=None, thetaes=None, **kwargs):\n        r'''Plot moist adiabats.\n\n        Adds saturated pseudo-adiabats (lines of constant equivalent potential\n        temperature) to the plot. The default style of these lines is dashed\n        blue lines with an alpha value of 0.5. These can be overridden using\n        keyword arguments.\n\n        Parameters\n        ----------\n        p : array_like, optional\n            1-dimensional array of pressure values to be included in the moist\n            adiabats. If not specified, they will be linearly distributed\n            across the current plotted pressure range.\n        thetaes : array_like, optional\n            1-dimensional array of saturation equivalent potential temperature\n            values for moist adiabats. By default these will be generated based\n            on the current temperature limits.\n        kwargs\n            Other keyword arguments to pass to\n            `matplotlib.collections.LineCollection`\n\n        See Also\n        --------\n        plot_dry_adiabats\n        `matplotlib.collections.LineCollection`\n        `metpy.calc.moist_lapse`\n        '''\n        for artist in self._moist_adiabats:\n            artist.remove()\n        self._moist_adiabats = []\n\n        def dT_dp(y, p0):\n            return calculate('Gammam', T=y, p=p0, RH=100., p_units='hPa',\n                             T_units='degC')/(\n                g0*calculate('rho', T=y, p=p0, p_units='hPa', T_units='degC',\n                             RH=100.))*100.\n\n        if thetaes is None:\n            xmin, xmax = self.get_xlim()\n            thetaes = np.concatenate((np.arange(xmin, 0, 5),\n                                      np.arange(0, xmax + 51, 5)))\n        # Get pressure levels based on ylims if necessary\n        if p is None:\n            p = np.linspace(self.get_ylim()[0], self.get_ylim()[1])\n\n        cache_dir = user_cache_dir('atmos')\n        if not os.path.isdir(cache_dir):\n            os.mkdir(cache_dir)\n        cache_filename = os.path.join(cache_dir, 'moist_adiabat_data.npz')\n        request_str = 'p:{},\\nthetaes:{}'.format(\n            np.array_str(p), np.array_str(thetaes))\n        t = None\n        cached_data = None\n        if os.path.isfile(cache_filename):\n            cached_data = np.load(cache_filename)\n            if request_str in cached_data.keys():\n                t = cached_data[request_str]\n        if t is None:\n            # did not find cached data\n            # Assemble into data for plotting\n            thetaes_base = odeint(\n                dT_dp, thetaes, np.array([1e3, p[0]], dtype=np.float64))[-1, :]\n            result = odeint(dT_dp, thetaes_base, p)\n            t = result.T\n            data_to_cache = {}\n            if cached_data is not None:\n                data_to_cache.update(cached_data)\n            data_to_cache[request_str] = t\n            np.savez(cache_filename, **data_to_cache)\n        linedata = [np.vstack((ti, p)).T for ti in t]\n\n        # Add to plot\n        kwargs.setdefault('clip_on', True)\n        kwargs.setdefault('colors', '#166916')\n        kwargs.setdefault('linestyles', '-')\n        kwargs.setdefault('alpha', 1)\n        kwargs.setdefault('linewidth', 0.5)\n        kwargs.setdefault('zorder', 1.1)\n        collection = LineCollection(linedata, **kwargs)\n        self._moist_adiabats.append(collection)\n        self.add_collection(collection)\n        label_index = closest_val(240., p)\n        T_label = t[:, label_index].flatten()\n        for i in range(len(thetaes)):\n            text = self.text(\n                T_label[i], p[label_index],\n                '{:.0f}'.format(thetaes[i]),\n                fontsize=8, ha='left', va='center', rotation=-65,\n                color='#166916', bbox={\n                    'facecolor': 'w', 'edgecolor': 'w', 'alpha': 0,\n                    }, zorder=1.2)\n            text.set_clip_on(True)\n            self._moist_adiabats.append(text)", "response": "r Plot moist adiabats."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef plot_mixing_lines(self, p=None, rv=None, **kwargs):\n        r'''Plot lines of constant mixing ratio.\n\n        Adds lines of constant mixing ratio (isohumes) to the\n        plot. The default style of these lines is dashed green lines with an\n        alpha value of 0.8. These can be overridden using keyword arguments.\n\n        Parameters\n        ----------\n        rv : array_like, optional\n            1-dimensional array of unitless mixing ratio values to plot. If\n            none are given, default values are used.\n        p : array_like, optional\n            1-dimensional array of pressure values to be included in the\n            isohumes. If not specified, they will be linearly distributed\n            across the current plotted pressure range.\n        kwargs\n            Other keyword arguments to pass to\n            `matplotlib.collections.LineCollection`\n\n        See Also\n        --------\n        `matplotlib.collections.LineCollection`\n        '''\n        for artist in self._mixing_lines:\n            artist.remove()\n        self._mixing_lines = []\n\n        # Default mixing level values if necessary\n        if rv is None:\n            rv = np.array([\n                0.1e-3, 0.2e-3, 0.5e-3, 1e-3, 1.5e-3, 2e-3, 3e-3, 4e-3, 6e-3,\n                8e-3, 10e-3, 12e-3, 15e-3, 20e-3, 30e-3, 40e-3,\n                50e-3]).reshape(-1, 1)\n        else:\n            rv = np.asarray(rv).reshape(-1, 1)\n\n        # Set pressure range if necessary\n        if p is None:\n            p = np.linspace(min(self.get_ylim()), max(self.get_ylim()))\n        else:\n            p = np.asarray(p)\n\n        # Assemble data for plotting\n        Td = calculate(\n            'Td', p=p, rv=rv, p_units='hPa', rv_units='kg/kg',\n            Td_units='degC')\n        Td_label = calculate('Td', p=550, p_units='hPa', rv=rv,\n                             Td_units='degC')\n        linedata = [np.vstack((t, p)).T for t in Td]\n\n        # Add to plot\n        kwargs.setdefault('clip_on', True)\n        kwargs.setdefault('colors', '#166916')\n        kwargs.setdefault('linestyles', '--')\n        kwargs.setdefault('alpha', 1)\n        kwargs.setdefault('linewidth', 0.5)\n        kwargs.setdefault('zorder', 1.1)\n        collection = LineCollection(linedata, **kwargs)\n        self._mixing_lines.append(collection)\n        self.add_collection(collection)\n        rv = rv.flatten() * 1000\n        for i in range(len(rv)):\n            if rv[i] < 1:\n                format_string = '{:.1f}'\n            else:\n                format_string = '{:.0f}'\n            t = self.text(Td_label[i], 550, format_string.format(rv[i]),\n                          fontsize=8, ha='right', va='center', rotation=60,\n                          color='#166916', bbox={\n                              'facecolor': 'w', 'edgecolor': 'w', 'alpha': 0,\n                              }, zorder=1.2)\n            t.set_clip_on(True)\n            self._mixing_lines.append(t)", "response": "r Plot lines of constant mixing ratio."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving an interable of input quantity names and a methods dictionary returns a list of output quantities that can be calculated.", "response": "def get_calculatable_quantities(inputs, methods):\n    '''\n    Given an interable of input quantity names and a methods dictionary,\n    returns a list of output quantities that can be calculated.\n    '''\n    output_quantities = []\n    updated = True\n    while updated:\n        updated = False\n        for output in methods.keys():\n            if output in output_quantities or output in inputs:\n                # we already know we can calculate this\n                continue\n            for args, func in methods[output].items():\n                if all([arg in inputs or arg in output_quantities\n                        for arg in args]):\n                    output_quantities.append(output)\n                    updated = True\n                    break\n    return tuple(output_quantities) + tuple(inputs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_methods_that_calculate_outputs(inputs, outputs, methods):\n    '''\n    Given iterables of input variable names, output variable names,\n    and a methods dictionary, returns the subset of the methods dictionary\n    that can be calculated, doesn't calculate something we already have,\n    and only contains equations that might help calculate the outputs from\n    the inputs.\n    '''\n    # Get a list of everything that we can possibly calculate\n    # This is useful in figuring out whether we can calculate arguments\n    intermediates = get_calculatable_quantities(inputs, methods)\n    # Initialize our return dictionary\n    return_methods = {}\n    # list so that we can append arguments that need to be output for\n    # some of the paths\n    outputs = list(outputs)\n    # keep track of when to exit the while loop\n    keep_going = True\n    while keep_going:\n        # If there are no updates in a pass, the loop will exit\n        keep_going = False\n        for output in outputs:\n            try:\n                output_dict = return_methods[output]\n            except:\n                output_dict = {}\n            for args, func in methods[output].items():\n                # only check the method if we're not already returning it\n                if args not in output_dict.keys():\n                    # Initialize a list of intermediates needed to use\n                    # this method, to add to outputs if we find we can\n                    # use it.\n                    needed = []\n                    for arg in args:\n                        if arg in inputs:\n                            # we have this argument\n                            pass\n                        elif arg in outputs:\n                            # we may need to calculate one output using\n                            # another output\n                            pass\n                        elif arg in intermediates:\n                            if arg not in outputs:\n                                # don't need to add to needed if it's already\n                                # been put in outputs\n                                needed.append(arg)\n                        else:\n                            # Can't do this func\n                            break\n                    else:  # did not break, can calculate this\n                        output_dict[args] = func\n                        if len(needed) > 0:\n                            # We added an output, so need another loop\n                            outputs.extend(needed)\n                            keep_going = True\n            if len(output_dict) > 0:\n                return_methods[output] = output_dict\n    return return_methods", "response": "Given a list of input variable names output variable names and a methods dictionary returns the subset of the methods dictionary that can be calculated from the inputs and outputs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_calculatable_methods_dict(inputs, methods):\n    '''\n    Given an iterable of input variable names and a methods dictionary,\n    returns the subset of that methods dictionary that can be calculated and\n    which doesn't calculate something we already have. Additionally it may\n    only contain one method for any given output variable, which is the one\n    with the fewest possible arguments.\n    '''\n    # Initialize a return dictionary\n    calculatable_methods = {}\n    # Iterate through each potential method output\n    for var in methods.keys():\n        # See if we already have this output\n        if var in inputs:\n            continue  # if we have it, we don't need to calculate it!\n        else:\n            # Initialize a dict for this output variable\n            var_dict = {}\n            for args, func in methods[var].items():\n                # See if we have what we need to solve this equation\n                if all([arg in inputs for arg in args]):\n                    # If we do, add it to the var_dict\n                    var_dict[args] = func\n            if len(var_dict) == 0:\n                # No methods for this variable, keep going\n                continue\n            elif len(var_dict) == 1:\n                # Exactly one method, perfect.\n                calculatable_methods[var] = var_dict\n            else:\n                # More than one method, find the one with the least arguments\n                min_args = min(var_dict.keys(), key=lambda x: len(x))\n                calculatable_methods[var] = {min_args: var_dict[min_args]}\n    return calculatable_methods", "response": "Given an iterable of input variable names and a methods dictionary returns a subset of that methods dictionary that can be calculated and that may be calculated."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_module_methods(module):\n    '''\n    Returns a methods list corresponding to the equations in the given\n    module. Each entry is a dictionary with keys 'output', 'args', and\n    'func' corresponding to the output, arguments, and function of the\n    method. The entries may optionally include 'assumptions' and\n    'overridden_by_assumptions' as keys, stating which assumptions are\n    required to use the method, and which assumptions mean the method\n    should not be used because it is overridden.\n    '''\n    # Set up the methods dict we will eventually return\n    methods = []\n    funcs = []\n    for item in inspect.getmembers(equations):\n        if (item[0][0] != '_' and '_from_' in item[0]):\n            func = item[1]\n            output = item[0][:item[0].find('_from_')]\n        # avoid returning duplicates\n        if func in funcs:\n            continue\n        else:\n            funcs.append(func)\n        args = tuple(getfullargspec(func).args)\n        try:\n            assumptions = tuple(func.assumptions)\n        except AttributeError:\n            raise NotImplementedError('function {0} in equations module has no'\n                                      ' assumption '\n                                      'definition'.format(func.__name__))\n        try:\n            overridden_by_assumptions = func.overridden_by_assumptions\n        except AttributeError:\n            overridden_by_assumptions = ()\n        methods.append({\n            'func': func,\n            'args': args,\n            'output': output,\n            'assumptions': assumptions,\n            'overridden_by_assumptions': overridden_by_assumptions,\n        })\n    return methods", "response": "Returns a list of methods corresponding to the equations in the given module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_scalar(value):\n    '''If value is a 0-dimensional array, returns the contents of value.\n       Otherwise, returns value.\n    '''\n    if isinstance(value, np.ndarray):\n        if value.ndim == 0:\n            # We have a 0-dimensional array\n            return value[None][0]\n    return value", "response": "Check if value is a 0 - dimensional array returns the contents of value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the requested quantity from the specified arguments and returns a tuple containing the calculated quantity.", "response": "def calculate(*args, **kwargs):\n    '''\nCalculates and returns a requested quantity from quantities passed in as\nkeyword arguments.\n\nParameters\n----------\n\n\\*args : string\n    Names of quantities to be calculated.\nassumptions : tuple, optional\n    Strings specifying which assumptions to enable. Overrides the default\n    assumptions. See below for a list of default assumptions.\nadd_assumptions : tuple, optional\n    Strings specifying assumptions to use in addition to the default\n    assumptions. May not be given in combination with the assumptions kwarg.\nremove_assumptions : tuple, optional\n    Strings specifying assumptions not to use from the default assumptions.\n    May not be given in combination with the assumptions kwarg. May not\n    contain strings that are contained in add_assumptions, if given.\n\\*\\*kwargs : ndarray, optional\n    Keyword arguments used to pass in arrays of data that correspond to\n    quantities used for calculations, or unit specifications for quantities.\n    For a complete list of kwargs that may be used, see the Quantity Parameters\n    section below.\n\nReturns\n-------\n\nquantity : ndarray\n    Calculated quantity.\n    Return type is the same as quantity parameter types.\n    If multiple quantities are requested, returns a tuple containing the\n    quantities.\n\nNotes\n-----\n\nCalculating multiple quantities at once can avoid re-computing intermediate\nquantities, but requires more memory.\n\n**Quantity kwargs**\n\n<quantity parameter list goes here>\n\nIn addition to the quantities above, kwargs of the form <quantity>_unit or\n<quantity>_units can be used with a string specifying a unit for the quantity.\nThis will cause input data for that quantity to be assumed to be in that\nunit, and output data for that quantity to be given in that unit. Note this\nmust be specified separately for *each* quantity. Acceptable units are the\nunits available in the Pint package, with the exception that RH can be in\nunits of \"fraction\" or \"percent\".\n\n**Assumptions**\n\n<default assumptions list goes here>\n\n**Assumption descriptions**\n\n<assumptions list goes here>\n\nExamples\n--------\n\nCalculating pressure from virtual temperature and density:\n\n>>> calculate('p', Tv=273., rho=1.27)\n99519.638400000011\n\nSame calculation, but also returning a list of functions used:\n\n>>> p, funcs = calculate('p', Tv=273., rho=1.27, debug=True)\n>>> funcs\n(<function atmos.equations.p_from_rho_Tv_ideal_gas>,)\n\nSame calculation with temperature instead, ignoring virtual temperature\ncorrection:\n\n>>> calculate('p', T=273., rho=1.27, add_assumptions=('Tv equals T',))\n99519.638400000011\n'''\n    if len(args) == 0:\n        raise ValueError('must specify quantities to calculate')\n    # initialize a solver to do the work\n    solver = FluidSolver(**kwargs)\n    # get the output\n    return solver.calculate(*args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_url(self, data):\n        query_part_one = []\n        query_part_two = []\n        keys_to_be_removed = []\n        for key, value in data.items():\n            if key not in ['version', 'restApi', 'resourcePath']:\n                if key == 'mapArea':\n                    query_part_one.append(','.join(str(val) for val in value))\n                    keys_to_be_removed.append(key)\n                elif key == 'includeLocationCodes':\n                    query_part_one.append(value)\n                    keys_to_be_removed.append(key)\n                else:\n                    if isinstance(value, list):\n                        value = ','.join(str(val) for val in value)\n                    query_part_two.append('{0}={1}'.format(key, value))\n                    keys_to_be_removed.append(key)\n        for k in keys_to_be_removed:\n            del data[k]\n        data['query'] = '{0}?{1}'.format('/'.join(query_part_one),\n                                         '&'.join(query_part_two))\n        return data", "response": "This method occurs after dumping the data into the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_query_string(self, data):\n        query_params = []\n        keys_to_be_removed = []\n        for key, value in data.items():\n            if key not in ['version', 'restApi', 'resourcePath']:\n                if key == 'addressLine':\n                    query_params.append('{0}={1}'.format(key,\n                                                         quote(value)))\n                    keys_to_be_removed.append(key)\n                else:\n                    query_params.append('{0}={1}'.format(key,\n                                                         value))\n                    keys_to_be_removed.append(key)\n        data['query'] = \"&\".join(query_params)\n        for k in keys_to_be_removed:\n            del data[k]\n        return data", "response": "This method occurs after dumping the data into the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_query_string(self, data):\n        queryValues = []\n        keys_to_be_removed = []\n        for key, value in data.items():\n            if key not in ['version', 'restApi', 'resourcePath']:\n                if not key == 'point':\n                    queryValues.append('{0}={1}'.format(key, value))\n                    keys_to_be_removed.append(key)\n                keys_to_be_removed.append(key)\n        queryString = '&'.join(queryValues)\n        data['query'] = '{0}?{1}'.format(data['point'], queryString)\n        for k in list(set(keys_to_be_removed)):\n            del data[k]\n        return data", "response": "This method occurs after dumping the data into the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_url(self):\n        url = '{protocol}/{url}/{rest}/{version}/{restapi}/{rscpath}/' \\\n              '{query}'.format(protocol=self.schema.protocol,\n                               url=self.schema.main_url,\n                               rest=self.schema.rest,\n                               version=self.schema.version,\n                               restapi=self.schema.restApi,\n                               rscpath=self.schema.resourcePath,\n                               query=self.schema.query)\n        return url.replace('/None/', '/')", "response": "Builds the URL for the elevations API services based on the data given\n        by the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting data from the given url", "response": "def get_data(self):\n        \"\"\"Gets data from the given url\"\"\"\n        url = self.build_url()\n        self.elevationdata = requests.get(url)\n        if not self.elevationdata.status_code == 200:\n            raise self.elevationdata.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef elevations(self):\n        resources = self.get_resource()\n        elevations = namedtuple('elevations_data', 'elevations')\n        try:\n            return [elevations(resource['elevations'])\n                    for resource in resources]\n        except KeyError:\n            return [elevations(resource['offsets'])\n                    for resource in resources]\n        except TypeError:\n            try:\n                if isinstance(resources['ElevationData']['Elevations'], dict):\n                    return elevations(resources['ElevationData']['Elevations'])\n            except KeyError:\n                offsets = namedtuple('offsets_data', 'offsets')\n                try:\n                    if isinstance(resources['SeaLevelData']['Offsets'], dict):\n                        return offsets(resources['SeaLevelData']['Offsets'])\n                except KeyError:\n                    print(KeyError)", "response": "Retrieves elevations and offsets from the output response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zoomlevel(self):\n        resources = self.get_resource()\n        zoomlevel = namedtuple('zoomlevel', 'zoomLevel')\n        try:\n            return [zoomlevel(resource['zoomLevel'])\n                    for resource in resources]\n        except TypeError:\n            try:\n                if isinstance(resources['ElevationData'], dict):\n                    return zoomlevel(resources['ElevationData']['ZoomLevel'])\n            except KeyError:\n                try:\n                    if isinstance(resources['SeaLevelData'], dict):\n                        zoom = resources['SeaLevelData']['ZoomLevel']\n                        return zoomlevel(zoom)\n                except KeyError:\n                    print(KeyError)", "response": "Retrieves zoomlevel from the output response\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites output to a JSON file with the given file name", "response": "def to_json_file(self, path, file_name=None):\n        \"\"\"Writes output to a JSON file with the given file name\"\"\"\n        if bool(path) and os.path.isdir(path):\n            self.write_to_json(path, file_name)\n        else:\n            self.write_to_json(os.getcwd(), file_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_data(self):\n        url = self.build_url()\n        self.incidents_data = requests.get(url)\n        if not self.incidents_data.status_code == 200:\n            raise self.incidents_data.raise_for_status()", "response": "Gets data from the given url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef response_to_dict(self):\n        try:\n            return json.loads(self.incidents_data.text)\n        except Exception:\n            return json.loads(json.dumps(xmltodict.parse(\n                self.incidents_data.text)))", "response": "This method helps in returning the output JSON data from the URL\n        and the XML response string to a\n        JSON object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the description of the incident and incidents from the output response", "response": "def description(self):\n        \"\"\"Retrieves the description of the incident/incidents from the output\n        response\n\n        Returns:\n            description(namedtuple): List of named tuples of descriptions of\n            the incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        description = namedtuple('description', 'description')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [description(resource['description'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                try:\n                    return [description(resource['Description'])\n                            for resource in resource_list]\n                except KeyError:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef congestion(self):\n        resource_list = self.traffic_incident()\n        congestion = namedtuple('congestion', 'congestion')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [congestion(resource['congestion'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                try:\n                    return [congestion(resource['CongestionInfo'])\n                            for resource in resource_list]\n                except KeyError:\n                    return None", "response": "Retrieves the congestion information of the incident and incidents from the output response\n        Returns None if there is no congestion information of the incident or incidents."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the detour information of the incident and incidents from the output response", "response": "def detour_info(self):\n        \"\"\"Retrieves the detour information of the incident/incidents from\n        the output response\n\n        Returns:\n            detour_info(namedtuple): List of named tuples of detour info of\n            the incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        detour_info = namedtuple('detour_info', 'detour_info')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [detour_info(resource['detour'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                try:\n                    return [detour_info(resource['detourInfo'])\n                            for resource in resource_list]\n                except KeyError:\n                    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nretrieve the start time of the incident and incidents from the output response", "response": "def start_time(self):\n        \"\"\"Retrieves the start time of the incident/incidents from the output\n        response\n\n        Returns:\n            start_time(namedtuple): List of named tuples of start time of the\n            incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        start_time = namedtuple('start_time', 'start_time')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [start_time(resource['start'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [start_time(resource['StartTimeUTC'])\n                        for resource in resource_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the end time of the incident and incidents from the output response Returns None if there is no end time", "response": "def end_time(self):\n        \"\"\"Retrieves the end time of the incident/incidents from the output\n        response\n\n        Returns:\n            end_time(namedtuple): List of named tuples of end time of the\n            incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        end_time = namedtuple('end_time', 'end_time')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [end_time(resource['end'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [end_time(resource['EndTimeUTC'])\n                        for resource in resource_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef incident_id(self):\n        resource_list = self.traffic_incident()\n        incident_id = namedtuple('incident_id', 'incident_id')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [incident_id(resource['incidentId'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [incident_id(resource['IncidentId'])\n                        for resource in resource_list]", "response": "Retrieves the incident id of the incident from the\n            output response\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lane_info(self):\n        resource_list = self.traffic_incident()\n        lane_info = namedtuple('lane_info', 'lane_info')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [lane_info(resource['lane'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                try:\n                    return [lane_info(resource['LaneInfo'])\n                            for resource in resource_list]\n                except KeyError:\n                    return None", "response": "Retrieves the lane info of the incident and incidents from the\n            output response\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef last_modified(self):\n        resource_list = self.traffic_incident()\n        last_modified = namedtuple('last_modified', 'last_modified')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [last_modified(resource['lastModified'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [last_modified(resource['LastModifiedUTC'])\n                        for resource in resource_list]", "response": "Retrieves the last modified time stamp of the incident or incidents\n            from the output response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef road_closed(self):\n        resource_list = self.traffic_incident()\n        road_closed = namedtuple('road_closed', 'road_closed')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [road_closed(resource['roadClosed'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [road_closed(resource['RoadClosed'])\n                        for resource in resource_list]", "response": "Retrieves the road closed information for the incident and incidents\n        from the output response\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef severity(self):\n        resource_list = self.traffic_incident()\n        severity = namedtuple('severity', 'severity')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [severity(resource['severity'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [severity(resource['Severity'])\n                        for resource in resource_list]", "response": "Retrieves the severity for the incident and incidents from the\n            output response\n        Returns a list of named tuples of severity for the incident and incidents"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the type of the incident and incidents from the output response", "response": "def type(self):\n        \"\"\"Retrieves the type of the incident/incidents from the output\n        response\n\n        Returns:\n            type(namedtuple): List of named tuples of type of the\n            incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        type = namedtuple('type', 'type')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [type(resource['type'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [type(resource['Type'])\n                        for resource in resource_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the verification status of the incident and incidents from the output response Returns None if there is no incident or incidents", "response": "def is_verified(self):\n        \"\"\"Retrieves the verification status of the incident/incidents from the\n        output response\n\n        Returns:\n            verified(namedtuple): List of named tuples of verification status\n            of the incident/incidents\n        \"\"\"\n        resource_list = self.traffic_incident()\n        verified = namedtuple('verified', 'verified')\n        if len(resource_list) == 1 and resource_list[0] is None:\n            return None\n        else:\n            try:\n                return [verified(resource['verified'])\n                        for resource in resource_list]\n            except (KeyError, TypeError):\n                return [verified(resource['Verified'])\n                        for resource in resource_list]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_query_string(self, data):\n        query = []\n        keys_to_be_removed = []\n        for key, value in data.items():\n            if key not in ['version', 'restApi', 'resourcePath']:\n                if not key == 'method':\n                    if key == 'points':\n                        value = ','.join(str(val) for val in value)\n                        keys_to_be_removed.append(key)\n                    query.append('{0}={1}'.format(key, value))\n                    keys_to_be_removed.append(key)\n                keys_to_be_removed.append(key)\n        querystring = '&'.join(query)\n        data['query'] = '{0}?{1}'.format(data['method'], querystring)\n        for k in list(set(keys_to_be_removed)):\n            del data[k]\n        return data", "response": "This method occurs after dumping the data into the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_coordinates(self):\n        resource_list = self.get_resource()\n        coordinates = namedtuple('coordinates', ['latitude', 'longitude'])\n        try:\n            return [coordinates(*resource['point']['coordinates'])\n                    for resource in resource_list]\n        except (KeyError, TypeError):\n            try:\n                if isinstance(resource_list, dict):\n                    resource_list = [resource_list]\n                return [coordinates(resource['Point']['Latitude'],\n                                    resource['Point']['Longitude'])\n                        for resource in resource_list]\n            except (KeyError, ValueError) as exc:\n                print(exc)", "response": "Retrieves coordinates from the output\n            JSON / XML response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_address(self):\n        resource_list = self.get_resource()\n        try:\n            return [resource['address'] for resource in resource_list]\n        except (KeyError, TypeError):\n            try:\n                if isinstance(resource_list, dict):\n                    resource_list = [resource_list]\n                return [resource['Address'] for resource in resource_list]\n            except (KeyError, TypeError) as exc:\n                print(exc)", "response": "Retrieves addresses from the output JSON / XML response\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving the bounding box coordinates from the output JSON / XML response", "response": "def get_bbox(self):\n        \"\"\"Retrieves the bounding box coordinates from the output JSON/XML\n        response\n\n        Returns:\n            boundingbox (namedtuple): List of named tuples of bounding box\n            coordinates\n        \"\"\"\n        resource_list = self.get_resource()\n        bounding_box = namedtuple('boundingbox', ['southlatitude',\n                                                  'westlongitude',\n                                                  'northlatitude',\n                                                  'eastlongitude'])\n        try:\n            return [bounding_box(*resource['bbox'])\n                    for resource in resource_list]\n        except (KeyError, TypeError):\n            try:\n                if isinstance(resource_list, dict):\n                    resource_list = [resource_list]\n                return [bounding_box(resource['BoundingBox']['SouthLatitude'],\n                                     resource['BoundingBox']['WestLongitude'],\n                                     resource['BoundingBox']['NorthLatitude'],\n                                     resource['BoundingBox']['EastLongitude'])\n                        for resource in resource_list]\n            except (KeyError, TypeError) as exc:\n                print(exc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets data from the built url", "response": "def get_data(self):\n        \"\"\"Gets data from the built url\"\"\"\n        url = self.build_url()\n        self.locationApiData = requests.get(url)\n        if not self.locationApiData.status_code == 200:\n            raise self.locationApiData.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_keyspace(name, strategy_class, replication_factor, durable_writes=True, **replication_values):\n    cluster = get_cluster()\n\n    if name not in cluster.metadata.keyspaces:\n        #try the 1.2 method\n        replication_map = {\n            'class': strategy_class,\n            'replication_factor':replication_factor\n        }\n        replication_map.update(replication_values)\n        if strategy_class.lower() != 'simplestrategy':\n            # Although the Cassandra documentation states for `replication_factor`\n            # that it is \"Required if class is SimpleStrategy; otherwise,\n            # not used.\" we get an error if it is present.\n            replication_map.pop('replication_factor', None)\n\n        query = \"\"\"\n        CREATE KEYSPACE {}\n        WITH REPLICATION = {}\n        \"\"\".format(name, json.dumps(replication_map).replace('\"', \"'\"))\n\n        if strategy_class != 'SimpleStrategy':\n            query += \" AND DURABLE_WRITES = {}\".format('true' if durable_writes else 'false')\n\n        execute(query)", "response": "Creates a new keyspace in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates or updates the table with the given model.", "response": "def sync_table(model):\n    \"\"\"\n    Inspects the model and creates / updates the corresponding table and columns.\n\n    Note that the attributes removed from the model are not deleted on the database.\n    They become effectively ignored by (will not show up on) the model.\n    \"\"\"\n\n    if not issubclass(model, Model):\n        raise CQLEngineException(\"Models must be derived from base Model.\")\n\n    if model.__abstract__:\n        raise CQLEngineException(\"cannot create table from abstract model\")\n\n\n    #construct query string\n    cf_name = model.column_family_name()\n    raw_cf_name = model.column_family_name(include_keyspace=False)\n\n    ks_name = model._get_keyspace()\n\n    cluster = get_cluster()\n\n    keyspace = cluster.metadata.keyspaces[ks_name]\n    tables = keyspace.tables\n\n    #check for an existing column family\n    if raw_cf_name not in tables:\n        qs = get_create_table(model)\n\n        try:\n            execute(qs)\n        except CQLEngineException as ex:\n            # 1.2 doesn't return cf names, so we have to examine the exception\n            # and ignore if it says the column family already exists\n            if \"Cannot add already existing column family\" not in unicode(ex):\n                raise\n    else:\n        # see if we're missing any columns\n        fields = get_fields(model)\n        field_names = [x.name for x in fields]\n        for name, col in model._columns.items():\n            if col.primary_key or col.partition_key: continue # we can't mess with the PK\n            if col.db_field_name in field_names: continue # skip columns already defined\n\n            # add missing column using the column def\n            query = \"ALTER TABLE {} add {}\".format(cf_name, col.get_column_def())\n            logger.debug(query)\n            execute(query)\n\n        update_compaction(model)\n\n\n    table = cluster.metadata.keyspaces[ks_name].tables[raw_cf_name]\n\n    indexes = [c for n,c in model._columns.items() if c.index]\n\n    for column in indexes:\n        if table.columns[column.db_field_name].index:\n            continue\n\n        qs = ['CREATE INDEX index_{}_{}'.format(raw_cf_name, column.db_field_name)]\n        qs += ['ON {}'.format(cf_name)]\n        qs += ['(\"{}\")'.format(column.db_field_name)]\n        qs = ' '.join(qs)\n        execute(qs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_compaction_options(model):\n    if not model.__compaction__:\n        return {}\n\n    result = {'class':model.__compaction__}\n\n    def setter(key, limited_to_strategy = None):\n        \"\"\"\n        sets key in result, checking if the key is limited to either SizeTiered or Leveled\n        :param key: one of the compaction options, like \"bucket_high\"\n        :param limited_to_strategy: SizeTieredCompactionStrategy, LeveledCompactionStrategy\n        :return:\n        \"\"\"\n        mkey = \"__compaction_{}__\".format(key)\n        tmp = getattr(model, mkey)\n        if tmp and limited_to_strategy and limited_to_strategy != model.__compaction__:\n            raise CQLEngineException(\"{} is limited to {}\".format(key, limited_to_strategy))\n\n        if tmp:\n            # Explicitly cast the values to strings to be able to compare the\n            # values against introspected values from Cassandra.\n            result[key] = str(tmp)\n\n    setter('tombstone_compaction_interval')\n    setter('tombstone_threshold')\n\n    setter('bucket_high', SizeTieredCompactionStrategy)\n    setter('bucket_low', SizeTieredCompactionStrategy)\n    setter('max_threshold', SizeTieredCompactionStrategy)\n    setter('min_threshold', SizeTieredCompactionStrategy)\n    setter('min_sstable_size', SizeTieredCompactionStrategy)\n\n    setter('sstable_size_in_mb', LeveledCompactionStrategy)\n\n    return result", "response": "Returns a dictionary that can be used to create and altering a tree of tables with compaction strategy."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the compaction options for the given model if necessary.", "response": "def update_compaction(model):\n    \"\"\"Updates the compaction options for the given model if necessary.\n\n    :param model: The model to update.\n\n    :return: `True`, if the compaction options were modified in Cassandra,\n        `False` otherwise.\n    :rtype: bool\n    \"\"\"\n    logger.debug(\"Checking %s for compaction differences\", model)\n    table = get_table_settings(model)\n\n    existing_options = table.options.copy()\n\n    existing_compaction_strategy = existing_options['compaction_strategy_class']\n\n    existing_options = json.loads(existing_options['compaction_strategy_options'])\n\n    desired_options = get_compaction_options(model)\n\n    desired_compact_strategy = desired_options.get('class', SizeTieredCompactionStrategy)\n\n    desired_options.pop('class', None)\n\n    do_update = False\n\n    if desired_compact_strategy not in existing_compaction_strategy:\n        do_update = True\n\n    for k, v in desired_options.items():\n        val = existing_options.pop(k, None)\n        if val != v:\n            do_update = True\n\n    # check compaction_strategy_options\n    if do_update:\n        options = get_compaction_options(model)\n        # jsonify\n        options = json.dumps(options).replace('\"', \"'\")\n        cf_name = model.column_family_name()\n        query = \"ALTER TABLE {} with compaction = {}\".format(cf_name, options)\n        logger.debug(query)\n        execute(query)\n        return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_where_clause(self, clause):\n        if not isinstance(clause, WhereClause):\n            raise StatementException(\"only instances of WhereClause can be added to statements\")\n        clause.set_context_id(self.context_counter)\n        self.context_counter += clause.get_context_size()\n        self.where_clauses.append(clause)", "response": "add a where clause to the list of where clauses"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an assignment clause to the current statement.", "response": "def add_assignment_clause(self, clause):\n        \"\"\"\n        adds an assignment clause to this statement\n        :param clause: the clause to add\n        :type clause: AssignmentClause\n        \"\"\"\n        if not isinstance(clause, AssignmentClause):\n            raise StatementException(\"only instances of AssignmentClause can be added to statements\")\n        clause.set_context_id(self.context_counter)\n        self.context_counter += clause.get_context_size()\n        self.assignments.append(clause)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a TransactionClause to the current statement.", "response": "def add_transaction_clause(self, clause):\n        \"\"\"\n        Adds a iff clause to this statement\n\n        :param clause: The clause that will be added to the iff statement\n        :type clause: TransactionClause\n        \"\"\"\n        if not isinstance(clause, TransactionClause):\n            raise StatementException('only instances of AssignmentClause can be added to statements')\n        clause.set_context_id(self.context_counter)\n        self.context_counter += clause.get_context_size()\n        self.transactions.append(clause)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrecording the hosts and connects to one of them :param hosts: list of hosts, see http://datastax.github.io/python-driver/api/cassandra/cluster.html :type hosts: list :param default_keyspace: The default keyspace to use :type default_keyspace: str :param consistency: The global consistency level :type consistency: int :param lazy_connect: True if should not connect until first use :type lazy_connect: bool :param retry_connect: bool :param retry_connect: True if we should retry to connect even if there was a connection failure initially", "response": "def setup(\n        hosts,\n        default_keyspace,\n        consistency=ConsistencyLevel.ONE,\n        lazy_connect=False,\n        retry_connect=False,\n        **kwargs):\n    \"\"\"\n    Records the hosts and connects to one of them\n\n    :param hosts: list of hosts, see http://datastax.github.io/python-driver/api/cassandra/cluster.html\n    :type hosts: list\n    :param default_keyspace: The default keyspace to use\n    :type default_keyspace: str\n    :param consistency: The global consistency level\n    :type consistency: int\n    :param lazy_connect: True if should not connect until first use\n    :type lazy_connect: bool\n    :param retry_connect: bool\n    :param retry_connect: True if we should retry to connect even if there was a connection failure initially\n    \"\"\"\n    global cluster, session, default_consistency_level, lazy_connect_args\n\n    if 'username' in kwargs or 'password' in kwargs:\n        raise CQLEngineException(\"Username & Password are now handled by using the native driver's auth_provider\")\n\n    if not default_keyspace:\n        raise UndefinedKeyspaceException()\n\n    from cqlengine import models\n    models.DEFAULT_KEYSPACE = default_keyspace\n\n    default_consistency_level = consistency\n    if lazy_connect:\n        kwargs['default_keyspace'] = default_keyspace\n        kwargs['consistency'] = consistency\n        kwargs['lazy_connect'] = False\n        kwargs['retry_connect'] = retry_connect\n        lazy_connect_args = (hosts, kwargs)\n        return\n\n    cluster = Cluster(hosts, **kwargs)\n    try:\n        session = cluster.connect()\n    except NoHostAvailable:\n        if retry_connect:\n            kwargs['default_keyspace'] = default_keyspace\n            kwargs['consistency'] = consistency\n            kwargs['lazy_connect'] = False\n            kwargs['retry_connect'] = retry_connect\n            lazy_connect_args = (hosts, kwargs)\n        raise\n    session.row_factory = dict_factory"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a cleaned and validated value. Raises a ValidationError if there s a problem with the value.", "response": "def validate(self, value):\n        \"\"\"\n        Returns a cleaned and validated value. Raises a ValidationError\n        if there's a problem\n        \"\"\"\n        if value is None:\n            if self.required:\n                raise ValidationError('{} - None values are not allowed'.format(self.column_name or self.db_field))\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_datetime(self, dt):\n        global _last_timestamp\n\n        epoch = datetime(1970, 1, 1, tzinfo=dt.tzinfo)\n        offset = epoch.tzinfo.utcoffset(epoch).total_seconds() if epoch.tzinfo else 0\n        timestamp = (dt  - epoch).total_seconds() - offset\n\n        node = None\n        clock_seq = None\n\n        nanoseconds = int(timestamp * 1e9)\n        timestamp = int(nanoseconds // 100) + 0x01b21dd213814000\n\n        if clock_seq is None:\n            import random\n            clock_seq = random.randrange(1 << 14)  # instead of stable storage\n        time_low = timestamp & 0xffffffff\n        time_mid = (timestamp >> 32) & 0xffff\n        time_hi_version = (timestamp >> 48) & 0x0fff\n        clock_seq_low = clock_seq & 0xff\n        clock_seq_hi_variant = (clock_seq >> 8) & 0x3f\n        if node is None:\n            node = getnode()\n        return pyUUID(fields=(time_low, time_mid, time_hi_version,\n                            clock_seq_hi_variant, clock_seq_low, node), version=1)", "response": "Generates a UUID for a given datetime object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a column definition for CQL table definition", "response": "def get_column_def(self):\n        \"\"\"\n        Returns a column definition for CQL table definition\n        \"\"\"\n        static = \"static\" if self.static else \"\"\n        db_type = self.db_type.format(self.value_type.db_type)\n        return '{} {} {}'.format(self.cql, db_type, static)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconstruct an instance of the class cls from the values dict", "response": "def _construct_instance(cls, values):\n        \"\"\"\n        method used to construct instances from query results\n        this is where polymorphic deserialization occurs\n        \"\"\"\n        # we're going to take the values, which is from the DB as a dict\n        # and translate that into our local fields\n        # the db_map is a db_field -> model field map\n        items = values.items()\n        field_dict = dict([(cls._db_map.get(k, k),v) for k,v in items])\n\n        if cls._is_polymorphic:\n            poly_key = field_dict.get(cls._polymorphic_column_name)\n\n            if poly_key is None:\n                raise PolyMorphicModelException('polymorphic key was not found in values')\n\n            poly_base = cls if cls._is_polymorphic_base else cls._polymorphic_base\n\n            klass = poly_base._get_model_by_polymorphic_key(poly_key)\n            if klass is None:\n                poly_base._discover_polymorphic_submodels()\n                klass = poly_base._get_model_by_polymorphic_key(poly_key)\n                if klass is None:\n                    raise PolyMorphicModelException(\n                        'unrecognized polymorphic key {} for class {}'.format(poly_key, poly_base.__name__)\n                    )\n\n            if not issubclass(klass, cls):\n                raise PolyMorphicModelException(\n                    '{} is not a subclass of {}'.format(klass.__name__, cls.__name__)\n                )\n\n            field_dict = {k: v for k, v in field_dict.items() if k in klass._columns.keys()}\n\n        else:\n            klass = cls\n\n        instance = klass(**field_dict)\n        instance._is_persisted = True\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if this record is persisted with update or insert.", "response": "def _can_update(self):\n        \"\"\"\n        Called by the save function to check if this should be\n        persisted with update or insert\n\n        :return:\n        \"\"\"\n        if not self._is_persisted: return False\n        pks = self._primary_keys.keys()\n        return all([not self._values[k].changed for k in self._primary_keys])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the column family name of the current class.", "response": "def column_family_name(cls, include_keyspace=True):\n        \"\"\"\n        Returns the column family name if it's been defined\n        otherwise, it creates it from the module and class name\n        \"\"\"\n        cf_name = ''\n        if cls.__table_name__:\n            cf_name = cls.__table_name__.lower()\n        else:\n            # get polymorphic base table names if model is polymorphic\n            if cls._is_polymorphic and not cls._is_polymorphic_base:\n                return cls._polymorphic_base.column_family_name(include_keyspace=include_keyspace)\n\n            camelcase = re.compile(r'([a-z])([A-Z])')\n            ccase = lambda s: camelcase.sub(lambda v: '{}_{}'.format(v.group(1), v.group(2).lower()), s)\n\n            cf_name += ccase(cls.__name__)\n            #trim to less than 48 characters or cassandra will complain\n            cf_name = cf_name[-48:]\n            cf_name = cf_name.lower()\n            cf_name = re.sub(r'^_+', '', cf_name)\n        if not include_keyspace: return cf_name\n        return '{}.{}'.format(cls._get_keyspace(), cf_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _select_query(self):\n        if self._where:\n            self._validate_select_where()\n        return SelectStatement(\n            self.column_family_name,\n            fields=self._select_fields(),\n            where=self._where,\n            order_by=self._order,\n            limit=self._limit,\n            allow_filtering=self._allow_filtering\n        )", "response": "Returns a select clause based on the given filter args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_filter_arg(self, arg):\n        statement = arg.rsplit('__', 1)\n        if len(statement) == 1:\n            return arg, None\n        elif len(statement) == 2:\n            return statement[0], statement[1]\n        else:\n            raise QueryException(\"Can't parse '{}'\".format(arg))", "response": "Parses a filter arg in the format:\n        <colname >__<op >\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds IF statements to the queryset.", "response": "def iff(self, *args, **kwargs):\n        \"\"\"Adds IF statements to queryset\"\"\"\n        if len([x for x in kwargs.values() if x is None]):\n            raise CQLEngineException(\"None values on iff are not allowed\")\n\n        clone = copy.deepcopy(self)\n        for operator in args:\n            if not isinstance(operator, TransactionClause):\n                raise QueryException('{} is not a valid query operator'.format(operator))\n            clone._transaction.append(operator)\n\n        for col_name, val in kwargs.items():\n            exists = False\n            try:\n                column = self.model._get_column(col_name)\n            except KeyError:\n                if col_name == 'pk__token':\n                    if not isinstance(val, Token):\n                        raise QueryException(\"Virtual column 'pk__token' may only be compared to Token() values\")\n                    column = columns._PartitionKeysToken(self.model)\n                    quote_field = False\n                else:\n                    raise QueryException(\"Can't resolve column name: '{}'\".format(col_name))\n\n            if isinstance(val, Token):\n                if col_name != 'pk__token':\n                    raise QueryException(\"Token() values may only be compared to the 'pk__token' virtual column\")\n                partition_columns = column.partition_columns\n                if len(partition_columns) != len(val.value):\n                    raise QueryException(\n                        'Token() received {} arguments but model has {} partition keys'.format(\n                            len(val.value), len(partition_columns)))\n                val.set_columns(partition_columns)\n\n            if isinstance(val, BaseQueryFunction) or exists is True:\n                query_val = val\n            else:\n                query_val = column.to_database(val)\n\n            clone._transaction.append(TransactionClause(col_name, query_val))\n\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter(self, *args, **kwargs):\n        #add arguments to the where clause filters\n        if len([x for x in kwargs.values() if x is None]):\n            raise CQLEngineException(\"None values on filter are not allowed\")\n\n        clone = copy.deepcopy(self)\n        for operator in args:\n            if not isinstance(operator, WhereClause):\n                raise QueryException('{} is not a valid query operator'.format(operator))\n            clone._where.append(operator)\n\n        for arg, val in kwargs.items():\n            col_name, col_op = self._parse_filter_arg(arg)\n            quote_field = True\n            #resolve column and operator\n            try:\n                column = self.model._get_column(col_name)\n            except KeyError:\n                if col_name == 'pk__token':\n                    if not isinstance(val, Token):\n                        raise QueryException(\"Virtual column 'pk__token' may only be compared to Token() values\")\n                    column = columns._PartitionKeysToken(self.model)\n                    quote_field = False\n                else:\n                    raise QueryException(\"Can't resolve column name: '{}'\".format(col_name))\n\n            if isinstance(val, Token):\n                if col_name != 'pk__token':\n                    raise QueryException(\"Token() values may only be compared to the 'pk__token' virtual column\")\n                partition_columns = column.partition_columns\n                if len(partition_columns) != len(val.value):\n                    raise QueryException(\n                        'Token() received {} arguments but model has {} partition keys'.format(\n                            len(val.value), len(partition_columns)))\n                val.set_columns(partition_columns)\n\n            #get query operator, or use equals if not supplied\n            operator_class = BaseWhereOperator.get_operator(col_op or 'EQ')\n            operator = operator_class()\n\n            if isinstance(operator, InOperator):\n                if not isinstance(val, (list, tuple)):\n                    raise QueryException('IN queries must use a list/tuple value')\n                query_val = [column.to_database(v) for v in val]\n            elif isinstance(val, BaseQueryFunction):\n                query_val = val\n            else:\n                query_val = column.to_database(val)\n\n            clone._where.append(WhereClause(column.db_field_name, operator, query_val, quote_field=quote_field))\n\n        return clone", "response": "Adds a filter to the queryset returning a new queryset with the same queryset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a single instance matching this query optionally with additional filter kwargs.", "response": "def get(self, *args, **kwargs):\n        \"\"\"\n        Returns a single instance matching this query, optionally with additional filter kwargs.\n\n        A DoesNotExistError will be raised if there are no rows matching the query\n        A MultipleObjectsFoundError will be raised if there is more than one row matching the queyr\n        \"\"\"\n        if args or kwargs:\n            return self.filter(*args, **kwargs).get()\n\n        self._execute_query()\n        if len(self._result_cache) == 0:\n            raise self.model.DoesNotExist\n        elif len(self._result_cache) > 1:\n            raise self.model.MultipleObjectsReturned(\n                    '{} objects found'.format(len(self._result_cache)))\n        else:\n            return self[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef order_by(self, *colnames):\n        if len(colnames) == 0:\n            clone = copy.deepcopy(self)\n            clone._order = []\n            return clone\n\n        conditions = []\n        for colname in colnames:\n            conditions.append('\"{}\" {}'.format(*self._get_ordering_condition(colname)))\n\n        clone = copy.deepcopy(self)\n        clone._order.extend(conditions)\n        return clone", "response": "orders the result set according to the given columns."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the number of rows matched by this query", "response": "def count(self):\n        \"\"\" Returns the number of rows matched by this query \"\"\"\n        if self._batch:\n            raise CQLEngineException(\"Only inserts, updates, and deletes are available in batch mode\")\n\n        if self._result_cache is None:\n            query = self._select_query()\n            query.count = True\n            result = self._execute(query)\n            return result[0]['count']\n        else:\n            return len(self._result_cache)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the limit on the number of results returned", "response": "def limit(self, v):\n        \"\"\"\n        Sets the limit on the number of results returned\n        CQL has a default limit of 10,000\n        \"\"\"\n        if not (v is None or isinstance(v, six.integer_types)):\n            raise TypeError\n        if v == self._limit:\n            return self\n\n        if v < 0:\n            raise QueryException(\"Negative limit is not allowed\")\n\n        clone = copy.deepcopy(self)\n        clone._limit = v\n        return clone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self):\n        #validate where clause\n        partition_key = [x for x in self.model._primary_keys.values()][0]\n        if not any([c.field == partition_key.column_name for c in self._where]):\n            raise QueryException(\"The partition key must be defined on delete queries\")\n\n        dq = DeleteStatement(\n            self.column_family_name,\n            where=self._where,\n            timestamp=self._timestamp\n        )\n        self._execute(dq)", "response": "Deletes the contents of a query\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that a select statement will not create an invalid select statement", "response": "def _validate_select_where(self):\n        \"\"\" Checks that a filterset will not create invalid select statement \"\"\"\n        #check that there's either a = or IN relationship with a primary key or indexed field\n        equal_ops = [self.model._columns.get(w.field) for w in self._where if isinstance(w.operator, EqualsOperator)]\n        token_comparison = any([w for w in self._where if isinstance(w.value, Token)])\n        if not any([w.primary_key or w.index for w in equal_ops]) and not token_comparison and not self._allow_filtering:\n            raise QueryException('Where clauses require either a \"=\" or \"IN\" comparison with either a primary key or indexed field')\n\n        if not self._allow_filtering:\n            #if the query is not on an indexed field\n            if not any([w.index for w in equal_ops]):\n                if not any([w.partition_key for w in equal_ops]) and not token_comparison:\n                    raise QueryException('Filtering on a clustering key without a partition key is not allowed unless allow_filtering() is called on the querset')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a function that will be used to instantiate query results", "response": "def _get_result_constructor(self):\n        \"\"\" Returns a function that will be used to instantiate query results \"\"\"\n        if not self._values_list: # we want models\n            return lambda rows: self.model._construct_instance(rows)\n        elif self._flat_values_list: # the user has requested flattened list (1 value per row)\n            return lambda row: row.popitem()[1]\n        else:\n            return lambda row: self._get_row_value_list(self._only_fields, row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the rows in this queryset with the given values.", "response": "def update(self, **values):\n        \"\"\" Updates the rows in this queryset \"\"\"\n        if not values:\n            return\n\n        nulled_columns = set()\n        us = UpdateStatement(self.column_family_name, where=self._where, ttl=self._ttl,\n                             timestamp=self._timestamp, transactions=self._transaction)\n        for name, val in values.items():\n            col_name, col_op = self._parse_filter_arg(name)\n            col = self.model._columns.get(col_name)\n            # check for nonexistant columns\n            if col is None:\n                raise ValidationError(\"{}.{} has no column named: {}\".format(self.__module__, self.model.__name__, col_name))\n            # check for primary key update attempts\n            if col.is_primary_key:\n                raise ValidationError(\"Cannot apply update to primary key '{}' for {}.{}\".format(col_name, self.__module__, self.model.__name__))\n\n            # we should not provide default values in this use case.\n            val = col.validate(val)\n            \n            if val is None:\n                nulled_columns.add(col_name)\n                continue\n\n            # add the update statements\n            if isinstance(col, Counter):\n                # TODO: implement counter updates\n                raise NotImplementedError\n            elif isinstance(col, (List, Set, Map)):\n                if isinstance(col, List):\n                    klass = ListUpdateClause\n                elif isinstance(col, Set):\n                    klass = SetUpdateClause\n                elif isinstance(col, Map):\n                    klass = MapUpdateClause\n                else:\n                    raise RuntimeError\n                us.add_assignment_clause(klass(col_name, col.to_database(val), operation=col_op))\n            else:\n                us.add_assignment_clause(AssignmentClause(\n                    col_name, col.to_database(val)))\n\n        if us.assignments:\n            self._execute(us)\n\n        if nulled_columns:\n            ds = DeleteStatement(self.column_family_name, fields=nulled_columns, where=self._where)\n            self._execute(ds)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a delete query to remove columns that have changed to null.", "response": "def _delete_null_columns(self):\n        \"\"\"\n        executes a delete query to remove columns that have changed to null\n        \"\"\"\n        ds = DeleteStatement(self.column_family_name)\n        deleted_fields = False\n        for _, v in self.instance._values.items():\n            col = v.column\n            if v.deleted:\n                ds.add_field(col.db_field_name)\n                deleted_fields = True\n            elif isinstance(col, Map):\n                uc = MapDeleteClause(col.db_field_name, v.value, v.previous_value)\n                if uc.get_context_size() > 0:\n                    ds.add_field(uc)\n                    deleted_fields = True\n\n        if deleted_fields:\n            for name, col in self.model._primary_keys.items():\n                ds.add_where_clause(WhereClause(\n                    col.db_field_name,\n                    EqualsOperator(),\n                    col.to_database(getattr(self.instance, name))\n                ))\n            self._execute(ds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self):\n        if self.instance is None:\n            raise CQLEngineException(\"DML Query intance attribute is None\")\n        assert type(self.instance) == self.model\n        null_clustering_key = False if len(self.instance._clustering_keys) == 0 else True\n        static_changed_only = True\n        statement = UpdateStatement(self.column_family_name, ttl=self._ttl,\n                                    timestamp=self._timestamp, transactions=self._transaction)\n        for name, col in self.instance._clustering_keys.items():\n            null_clustering_key = null_clustering_key and col._val_is_null(getattr(self.instance, name, None))\n        #get defined fields and their column names\n        for name, col in self.model._columns.items():\n            # if clustering key is null, don't include non static columns\n            if null_clustering_key and not col.static and not col.partition_key:\n                continue \n            if not col.is_primary_key:\n                val = getattr(self.instance, name, None)\n                val_mgr = self.instance._values[name]\n\n                # don't update something that is null\n                if val is None:\n                    continue\n\n                # don't update something if it hasn't changed\n                if not val_mgr.changed and not isinstance(col, Counter):\n                    continue\n                \n                static_changed_only = static_changed_only and col.static\n                if isinstance(col, (BaseContainerColumn, Counter)):\n                    # get appropriate clause\n                    if isinstance(col, List): klass = ListUpdateClause\n                    elif isinstance(col, Map): klass = MapUpdateClause\n                    elif isinstance(col, Set): klass = SetUpdateClause\n                    elif isinstance(col, Counter): klass = CounterUpdateClause\n                    else: raise RuntimeError\n\n                    # do the stuff\n                    clause = klass(col.db_field_name, val,\n                            previous=val_mgr.previous_value, column=col)\n                    if clause.get_context_size() > 0:\n                        statement.add_assignment_clause(clause)\n                else:\n                    statement.add_assignment_clause(AssignmentClause(\n                        col.db_field_name,\n                        col.to_database(val)\n                    ))\n\n        if statement.get_context_size() > 0 or self.instance._has_counter:\n            for name, col in self.model._primary_keys.items():\n                # only include clustering key if clustering key is not null, and non static columns are changed to avoid cql error\n                if (null_clustering_key or static_changed_only) and (not col.partition_key):\n                    continue\n                statement.add_where_clause(WhereClause(\n                    col.db_field_name,\n                    EqualsOperator(),\n                    col.to_database(getattr(self.instance, name))\n                ))\n            self._execute(statement)\n\n        if not null_clustering_key:\n            self._delete_null_columns()", "response": "Updates a row in the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete one instance from the database.", "response": "def delete(self):\n        \"\"\" Deletes one instance \"\"\"\n        if self.instance is None:\n            raise CQLEngineException(\"DML Query instance attribute is None\")\n\n        ds = DeleteStatement(self.column_family_name, timestamp=self._timestamp)\n        for name, col in self.model._primary_keys.items():\n            if (not col.partition_key) and (getattr(self.instance, name) is None): continue\n            ds.add_where_clause(WhereClause(\n                col.db_field_name,\n                EqualsOperator(),\n                col.to_database(getattr(self.instance, name))\n            ))\n        self._execute(ds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle(client, request):\n    formaters = request.get('formaters', None)\n    if not formaters:\n        formaters = [{'name': 'autopep8'}]\n    logging.debug('formaters: ' + json.dumps(formaters, indent=4))\n    data = request.get('data', None)\n    if not isinstance(data, str):\n        return send(client, 'invalid data', None)\n\n    max_line_length = None\n    for formater in formaters:\n        max_line_length = formater.get('config', {}).get('max_line_length')\n        if max_line_length:\n            break\n\n    for formater in formaters:\n        name = formater.get('name', None)\n        config = formater.get('config', {})\n        if name not in FORMATERS:\n            return send(client, 'formater {} not support'.format(name), None)\n        formater = FORMATERS[name]\n        if formater is None:\n            return send(client, 'formater {} not installed'.format(name), None)\n        if name == 'isort' and max_line_length:\n            config.setdefault('line_length', max_line_length)\n        data = formater(data, **config)\n    return send(client, None, data)", "response": "Handles format request for a single item in the order they are installed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the column family name if it s defined otherwise creates it from the module and class name.", "response": "def column_family_name(self, include_keyspace=True):\n        \"\"\"\n        Returns the column family name if it's been defined\n        otherwise, it creates it from the module and class name\n        \"\"\"\n        if include_keyspace:\n            return '{}.{}'.format(self.keyspace, self.name)\n        else:\n            return self.name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef easeInOutQuad(n):\n    _checkRange(n)\n    if n < 0.5:\n        return 2 * n**2\n    else:\n        n = n * 2 - 1\n        return -0.5 * (n*(n-2) - 1)", "response": "A quadratic tween function that accelerates reaches the midpoint and then decelerates."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef easeInOutCubic(n):\n    _checkRange(n)\n    n = 2 * n\n    if n < 1:\n        return 0.5 * n**3\n    else:\n        n = n - 2\n        return 0.5 * (n**3 + 2)", "response": "A cubic tween function that accelerates reaches the midpoint and then decelerates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef easeInOutQuart(n):\n    _checkRange(n)\n    n = 2 * n\n    if n < 1:\n        return 0.5 * n**4\n    else:\n        n = n - 2\n        return -0.5 * (n**4 - 2)", "response": "A quartic tween function that accelerates reaches the midpoint and then decelerates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef easeInOutCirc(n):\n    _checkRange(n)\n    n = n * 2\n    if n < 1:\n        return -0.5 * (math.sqrt(1 - n**2) - 1)\n    else:\n        n = n - 2\n        return 0.5 * (math.sqrt(1 - n**2) + 1)", "response": "A circular tween function that accelerates reaches the midpoint and then decelerates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef easeInElastic(n, amplitude=1, period=0.3):\n    _checkRange(n)\n    return 1 - easeOutElastic(1-n, amplitude=amplitude, period=period)", "response": "An elastic tween function that begins with an increasing wobble and then snaps into the destination."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef easeOutElastic(n, amplitude=1, period=0.3):\n    _checkRange(n)\n\n    if amplitude < 1:\n        amplitude = 1\n        s = period / 4\n    else:\n        s = period / (2 * math.pi) * math.asin(1 / amplitude)\n\n    return amplitude * 2**(-10*n) * math.sin((n-s)*(2*math.pi / period)) + 1", "response": "An elastic tween function that overshoots the destination and then rubber bands into the destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef easeOutBack(n, s=1.70158):\n    _checkRange(n)\n    n = n - 1\n    return n * n * ((s + 1) * n + s) + 1", "response": "A tween function that overshoots the destination a little and then backs into the destination."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef easeOutBounce(n):\n    _checkRange(n)\n    if n < (1/2.75):\n        return 7.5625 * n * n\n    elif n < (2/2.75):\n        n -= (1.5/2.75)\n        return 7.5625 * n * n + 0.75\n    elif n < (2.5/2.75):\n        n -= (2.25/2.75)\n        return 7.5625 * n * n + 0.9375\n    else:\n        n -= (2.65/2.75)\n        return 7.5625 * n * n + 0.984375", "response": "A bouncing tween function that hits the destination and then bounces to rest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef formfield_for_manytomany(self, db_field, request, **kwargs):\n        '''\n        Not all Admin subclasses use get_field_queryset here, so we will use it explicitly\n        '''\n        db = kwargs.get('using')\n        kwargs['queryset'] = kwargs.get('queryset', self.get_field_queryset(db, db_field, request))\n        return super(AccessControlMixin, self).formfield_for_manytomany(db_field, request, **kwargs)", "response": "Override the default formfield_for_manytomany method to use the queryset directly"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_view(self, request, object_id, extra_context=None):\n        \"The 'delete' admin view for this model.\"\n        queryset = self.model._default_manager.filter(pk=object_id)\n        response = self.delete_selected(request, queryset)\n        if response:\n            return response\n        url = reverse('admin:%s_%s_changelist' % (self.model._meta.app_label, self.model._meta.model_name))\n        return HttpResponseRedirect(url)", "response": "The delete admin view for this model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_selected(self, request, queryset):\n        '''\n        The real delete function always evaluated either from the action, or from the instance delete link\n        '''\n        opts = self.model._meta\n        app_label = opts.app_label\n\n        # Populate deletable_objects, a data structure of all related objects that\n        # will also be deleted.\n        deletable_objects, model_count, perms_needed, protected = self.get_deleted_objects(request, queryset)\n\n        # The user has already confirmed the deletion.\n        # Do the deletion and return a None to display the change list view again.\n        if request.POST.get('post') and not protected:\n            if perms_needed or protected:\n                raise PermissionDenied\n            n = queryset.count()\n            if n:\n                for obj in queryset:\n                    obj_display = force_text(obj)\n                    self.log_deletion(request, obj, obj_display)\n                queryset.delete()\n                self.message_user(request, _(\"Successfully deleted %(count)d %(items)s.\") % {\n                    \"count\": n, \"items\": model_ngettext(self.opts, n)\n                }, messages.SUCCESS)\n            # Return None to display the change list page again.\n            return None\n\n        sz = queryset.count()\n        if sz == 1:\n            objects_name = _('%(verbose_name)s \"%(object)s\"') % {\n                'verbose_name': force_text(opts.verbose_name),\n                'object': queryset[0]\n            }\n        else:\n            objects_name = _('%(count)s %(verbose_name_plural)s') % {\n                'verbose_name_plural': force_text(opts.verbose_name_plural),\n                'count': sz\n            }\n\n        if perms_needed or protected:\n            title = _(\"Cannot delete %(name)s\") % {\"name\": objects_name}\n        else:\n            title = _(\"Are you sure?\")\n\n        context = dict(\n            self.admin_site.each_context(request),\n            title=title,\n            objects_name=objects_name,\n            deletable_objects=[deletable_objects],\n            model_count=dict(model_count).items(),\n            queryset=queryset,\n            perms_lacking=perms_needed,\n            protected=protected,\n            opts=opts,\n            action_checkbox_name=helpers.ACTION_CHECKBOX_NAME,\n            media=self.media,\n        )\n\n        request.current_app = self.admin_site.name\n\n        # Display the confirmation page\n        return TemplateResponse(request, self.delete_selected_confirmation_template or [\n            \"admin/%s/%s/delete_selected_confirmation.html\" % (app_label, opts.model_name),\n            \"admin/%s/delete_selected_confirmation.html\" % app_label,\n            \"admin/delete_selected_confirmation.html\"\n        ], context)", "response": "The real delete function always evaluated from the action or from the instance delete link."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list of objects that should be deleted from the given queryset.", "response": "def get_deleted_objects(self, request, queryset):\n        \"\"\"\n        Find all objects related to instances of ``queryset`` that should also be deleted.\n\n        Returns\n            - to_delete - a nested list of strings suitable for display in the template with the ``unordered_list`` filter.\n            - model_count - statistics for models of all deleted instances\n            - perms_needed - list of names for all instances which can not be deleted because of not enough rights\n            - protected - list of names for all objects protected for deletion because of reference type\n        \"\"\"\n        collector = NestedObjects(using=queryset.db)\n        collector.collect(queryset)\n        model_perms_needed = set()\n        object_perms_needed = set()\n\n        STRONG_DELETION_CONTROL = getattr(settings, 'ACCESS_STRONG_DELETION_CONTROL', False)\n\n        def format_callback(obj):\n            has_admin = obj.__class__ in self.admin_site._registry\n            opts = obj._meta\n\n            no_edit_link = '%s: %s' % (capfirst(opts.verbose_name),\n                                   force_text(obj))\n\n            # Trying to get admin change URL\n            admin_url = None\n            try:\n                admin_url = reverse('%s:%s_%s_change'\n                                % (self.admin_site.name,\n                                   opts.app_label,\n                                   opts.model_name),\n                                None, (quote(obj._get_pk_val()),))\n            except NoReverseMatch:\n                # Change url doesn't exist -- don't display link to edit\n                pass\n\n            # Collecting forbidden subobjects, compatible with Django or forced by the option\n            if STRONG_DELETION_CONTROL or has_admin:\n                if not obj.__class__._meta.auto_created:\n                    manager = AccessManager(obj.__class__)\n                    # filter out forbidden items\n                    if manager.check_deleteable(obj.__class__, request) is False:\n                        model_perms_needed.add(opts.verbose_name)\n                    if not manager.apply_deleteable(obj.__class__._default_manager.filter(pk=obj.pk), request):\n                        object_perms_needed.add(obj)\n\n            if admin_url:\n                # Display a link to the admin page.\n                return format_html('{}: <a href=\"{}\">{}</a>',\n                               capfirst(opts.verbose_name),\n                               admin_url,\n                               obj)\n            else:\n                # Don't display link to edit, because it either has no\n                # admin or is edited inline.\n                return no_edit_link\n\n        to_delete = collector.nested(format_callback)\n\n        protected = [format_callback(obj) for obj in collector.protected]\n        protected = set([format_callback(obj) for obj in object_perms_needed]).union(protected)\n        model_count = {model._meta.verbose_name_plural: len(objs) for model, objs in collector.model_objs.items()}\n\n        return to_delete, model_count, model_perms_needed, protected"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering a plugin for a model.", "response": "def register_plugin(cls, model, plugin):\n        '''\n        Reguster a plugin for the model.\n\n        The only one plugin can be registered. If you want to combine plugins, use CompoundPlugin.\n        '''\n        logger.info(\"Plugin registered for %s: %s\", model, plugin)\n        cls.plugins[model] = plugin"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a default plugin.", "response": "def get_default_plugin(cls):\n        '''\n        Return a default plugin.\n        '''\n        from importlib import import_module\n        from django.conf import settings\n        default_plugin = getattr(settings, 'ACCESS_DEFAULT_PLUGIN', \"access.plugins.DjangoAccessPlugin\")\n        if default_plugin not in cls.default_plugins:\n            logger.info(\"Creating a default plugin: %s\", default_plugin)\n            path = default_plugin.split('.')\n            plugin_path = '.'.join(path[:-1])\n            plugin_name = path[-1]\n            DefaultPlugin = getattr(import_module(plugin_path), plugin_name)\n            cls.default_plugins[default_plugin] = DefaultPlugin()\n        return cls.default_plugins[default_plugin]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef plugin_for(cls, model):\n        '''\n        Find and return a plugin for this model. Uses inheritance to find a model where the plugin is registered.\n        '''\n        logger.debug(\"Getting a plugin for: %s\", model)\n        if not issubclass(model, Model):\n            return\n        if model in cls.plugins:\n            return cls.plugins[model]\n        for b in model.__bases__:\n            p = cls.plugin_for(b)\n            if p:\n                return p", "response": "Find and return a plugin for the given model. Uses inheritance to find and return a plugin for this model. Uses inheritance to find and return a plugin for this model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking both check_visible and apply_visible against the owned model and the owned instance set", "response": "def visible(self, request):\n        '''\n        Checks the both, check_visible and apply_visible, against the owned model and it's instance set\n        '''\n        return self.apply_visible(self.get_queryset(), request) if self.check_visible(self.model, request) is not False else self.get_queryset().none()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks both check_changeable and apply_changeable against the owned model and the owned instance set", "response": "def changeable(self, request):\n        '''\n        Checks the both, check_changeable and apply_changeable, against the owned model and it's instance set\n        '''\n        return self.apply_changeable(self.get_queryset(), request) if self.check_changeable(self.model, request) is not False else self.get_queryset().none()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck both check_deleteable and apply_deleteable against the owned model and the owned instance set", "response": "def deleteable(self, request):\n        '''\n        Checks the both, check_deleteable and apply_deleteable, against the owned model and it's instance set\n        '''\n        return self.apply_deleteable(self.get_queryset(), request) if self.check_deleteable(self.model, request) is not False else self.get_queryset().none()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plugin_from_string(plugin_name):\n    modulename, classname = plugin_name.rsplit('.', 1)\n    module = import_module(modulename)\n    return getattr(module, classname)", "response": "Returns plugin or plugin point class from given plugin name string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nattempts to cast value into an integer returning default if it fails.", "response": "def _parse_int(value, default=None):\n    \"\"\"\n    Attempt to cast *value* into an integer, returning *default* if it fails.\n    \"\"\"\n    if value is None:\n        return default\n    try:\n        return int(value)\n    except ValueError:\n        print \"Couldn't cast value to `int`.\"\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_float(value, default=None):\n    if value is None:\n        return default\n    try:\n        return float(value)\n    except ValueError:\n        print \"Couldn't cast value to `float`.\"\n        return default", "response": "Attempt to cast value into a float returning default if it fails."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_type(value, type_func):\n        default = type_func(0)\n        if value is None:\n            return default\n        try:\n            return type_func(value)\n        except ValueError:\n            return default", "response": "Parse a value into a specific type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef best_fit_distribution(data, bins=200, ax=None):\n    # Get histogram of original data\n    y, x = np.histogram(data, bins=bins, normed=True)\n    x = (x + np.roll(x, -1))[:-1] / 2.0\n\n    # Distributions to check\n    DISTRIBUTIONS = [        \n        st.alpha,st.anglit,st.arcsine,st.beta,st.betaprime,st.bradford,st.burr,st.cauchy,st.chi,st.chi2,st.cosine,\n        st.dgamma,st.dweibull,st.erlang,st.expon,st.exponnorm,st.exponweib,st.exponpow,st.f,st.fatiguelife,st.fisk,\n        st.foldcauchy,st.foldnorm,st.frechet_r,st.frechet_l,st.genlogistic,st.genpareto,st.gennorm,st.genexpon,\n        st.genextreme,st.gausshyper,st.gamma,st.gengamma,st.genhalflogistic,st.gilbrat,st.gompertz,st.gumbel_r,\n        st.gumbel_l,st.halfcauchy,st.halflogistic,st.halfnorm,st.halfgennorm,st.hypsecant,st.invgamma,st.invgauss,\n        st.invweibull,st.johnsonsb,st.johnsonsu,st.ksone,st.kstwobign,st.laplace,st.levy,st.levy_l,st.levy_stable,\n        st.logistic,st.loggamma,st.loglaplace,st.lognorm,st.lomax,st.maxwell,st.mielke,st.nakagami,st.ncx2,st.ncf,\n        st.nct,st.norm,st.pareto,st.pearson3,st.powerlaw,st.powerlognorm,st.powernorm,st.rdist,st.reciprocal,\n        st.rayleigh,st.rice,st.recipinvgauss,st.semicircular,st.t,st.triang,st.truncexpon,st.truncnorm,st.tukeylambda,\n        st.uniform,st.vonmises,st.vonmises_line,st.wald,st.weibull_min,st.weibull_max,st.wrapcauchy\n    ]\n\n    # Best holders\n    best_distribution = st.norm\n    best_params = (0.0, 1.0)\n    best_sse = np.inf\n\n    # Estimate distribution parameters from data\n    for distribution in DISTRIBUTIONS:\n\n        # Try to fit the distribution\n        try:\n            # Ignore warnings from data that can't be fit\n            with warnings.catch_warnings():\n                warnings.filterwarnings('ignore')\n\n                # fit dist to data\n                params = distribution.fit(data)\n\n                # Separate parts of parameters\n                arg = params[:-2]\n                loc = params[-2]\n                scale = params[-1]\n\n                # Calculate fitted PDF and error with fit in distribution\n                pdf = distribution.pdf(x, loc=loc, scale=scale, *arg)\n                sse = np.sum(np.power(y - pdf, 2.0))\n\n                # if axis pass in add to plot\n                try:\n                    if ax:\n                        pd.Series(pdf, x).plot(ax=ax)\n                    end\n                except Exception:\n                    pass\n\n                # identify if this distribution is better\n                if best_sse > sse > 0:\n                    best_distribution = distribution\n                    best_params = params\n                    best_sse = sse\n\n        except Exception:\n            pass\n\n    return (best_distribution.name, best_params)", "response": "Find the best fit distribution to data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_pdf(dist, params, size=10000):\n\n    # Separate parts of parameters\n    arg = params[:-2]\n    loc = params[-2]\n    scale = params[-1]\n\n    # Get sane start and end points of distribution\n    start = dist.ppf(0.01, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.01, loc=loc, scale=scale)\n    end = dist.ppf(0.99, *arg, loc=loc, scale=scale) if arg else dist.ppf(0.99, loc=loc, scale=scale)\n\n    # Build PDF and turn into pandas Series\n    x = np.linspace(start, end, size)\n    y = dist.pdf(x, loc=loc, scale=scale, *arg)\n    pdf = pd.Series(y, x)\n\n    return pdf", "response": "Generate distributions s Propbability Distribution Function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading ISBN from librarything. com", "response": "def download_isbn():\n    with open('raw.json') as input:\n        data = json.load(input)\n    '''\n    print(\"Loading index\")\n    md = readmetadata()\n    for record in data:\n        id = record['metadata']['id']\n        metadata = md[id]\n        pprint(metadata)\n        sys.exit(0)\n        title = record['book']['title']\n        isbn = isbnlib.isbn_from_words(title)\n        metadata = isbnlib.meta(isbn)\n        pprint(metadata)\n        extracted_title = ''\n        print title, extracted_title, isbn\n        time.sleep(1)'''\n    url = 'http://www.librarything.com/api/thingTitle/'\n    for record in data:\n        title = record['book']['title']\n        final_url = url+quote_plus(title)\n        content = requests.get(final_url).content\n        soup = BeautifulSoup(content)\n        extracted_title = soup.idlist.title.string\n        isbn = soup.idlist.find(\"isbn\").string\n        metadata = isbnlib.meta(isbn)\n        pprint(metadata)\n        #print title, extracted_title, min(isbns)\n        time.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_boolean(value, default=False):\n    if value is None:\n        return default\n    try:\n        return bool(value)\n    except ValueError:\n        return default", "response": "Attempt to cast value into a bool returning default if it fails."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a URL into it s response ( a str *.", "response": "def _get(url):\n    \"\"\"\n    Convert a URL into it's response (a *str*).\n    \"\"\"\n    if PYTHON_3:\n        req = request.Request(url, headers=HEADER)\n        response = request.urlopen(req)\n        return response.read().decode('utf-8')\n    else:\n        req = urllib2.Request(url, headers=HEADER)\n        response = urllib2.urlopen(req)\n        return response.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _recursively_convert_unicode_to_str(input):\n    if isinstance(input, dict):\n        return {_recursively_convert_unicode_to_str(key): _recursively_convert_unicode_to_str(value) for key, value in input.items()}\n    elif isinstance(input, list):\n        return [_recursively_convert_unicode_to_str(element) for element in input]\n    elif not PYTHON_3 and isinstance(input, unicode):\n        return input.encode('utf-8')\n    else:\n        return input", "response": "Recursively converts unicode to str"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the cache from the string", "response": "def _load_from_string(data):\n    '''Loads the cache from the string'''\n    global _CACHE\n    if PYTHON_3:\n        data = json.loads(data.decode(\"utf-8\"))\n    else:\n        data = json.loads(data)\n    _CACHE = _recursively_convert_unicode_to_str(data)['data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disconnect(filename=None):\n    global _CONNECTED\n    if filename is not None:\n        try:\n            with open(filename, 'r') as f:\n                _load_from_string(f.read())\n        except FileNotFoundError:\n            raise USGSException(\"\"\"The cache file '{0}' was not found, and I cannot disconnect without one. If you have not been given a cache.json file, then you can create a new one:\n        >>> from earthquakes import earthquakes\n        >>> earthquakes.connect()\n        >>> earthquakes._start_editing()\n        ...\n        >>> earthquakes.get_report()\n        ...\n        >>> earthquakes._save_cache('{0}')\"\"\".format(filename))\n    for key in _CACHE.keys():\n        _CACHE_COUNTER[key] = 0\n    _CONNECTED = False", "response": "Disconnects from the local cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_to_cache(key, value):\n    if key in _CACHE:\n        _CACHE[key].append(value)\n    else:\n        _CACHE[key] = [_PATTERN, value]\n        _CACHE_COUNTER[key] = 0", "response": "Internal method to add a new key - value to the local cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_report_string(time='hour', threshold='significant', online=False):\n    key = _get_report_request(time, threshold)\n    result = _get(key) if _CONNECTED else _lookup(key)\n    if (_CONNECTED or online) and _EDITABLE:\n        _add_to_cache(key, result)\n    return result", "response": "Get a string containing the data for the given time range."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_report(time='hour', threshold='significant', online=False):\n    if threshold not in THRESHOLDS:\n        raise USGSException('Unknown threshold: \"{}\" (must be either \"significant\", \"all\", \"4.5\", \"2.5\", or \"1.0\")'.format(threshold))\n    if time not in TIMES:\n        raise USGSException('Unknown time: \"{}\" (must be either \"hour\", \"day\", \"week\", \"month\")'.format(time))\n    try:\n        result = _get_report_string(time, threshold, online)\n    except HTTPError as e:\n        raise USGSException(\"Internet error ({}): {}\".format(e.code, e.reason))\n    if result == \"\":\n        formatted_threshold = 'Magnitude {}+' if threshold not in ('significant', 'all') else threshold.title()\n        result = Report._from_json({'metadata': {'title': 'USGS {} Earthquakes, Past {}'.format(formatted_threshold, time.title())}})\n        if _USE_CLASSES:\n            return result\n        else:\n            return result._to_dict()\n    elif result:\n        try:\n            json_result = _from_json(result)\n        except ValueError:\n            raise USGSException(\"The response from the server didn't make any sense.\")\n        if _USE_CLASSES:\n            return Report._from_json(json_result)\n        else:\n            return Report._from_json(json_result)._to_dict()\n    else:\n        if _CONNECTED or online:\n            raise USGSException(\"No response from the server.\")\n        else:\n            raise USGSException(\"No data was in the cache for this time and threshold ('{}', '{}').\".format(time, threshold))", "response": "Retrieves a new Report about recent earthquakes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _to_dict(self):\n        ''' Returns a dictionary representation of this object '''\n        return dict(latitude=self.latitude,\n                    longitude=self.longitude,\n                    depth=self.depth)", "response": "Returns a dictionary representation of this object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a Coordinate from json data.", "response": "def _from_json(json_data):\n        \"\"\"\n        Creates a Coordinate from json data.\n        \n        :param json_data: The raw json data to parse\n        :type json_data: dict\n        :returns: Coordinate\n        \"\"\"\n        if len(json_data) >= 3:\n            return Coordinate(_parse_float(json_data[0]),\n                        _parse_float(json_data[1]),\n                        _parse_float(json_data[2]))\n        else:\n            raise USGSException(\"The given coordinate information was incomplete.\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a dictionary representation of this object", "response": "def _to_dict(self):\n        ''' Returns a dictionary representation of this object '''\n        return dict(minimum=self.minimum._to_dict(),\n                    maximum=self.maximum._to_dict())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _from_json(json_data):\n        if len(json_data) >= 6:\n            return BoundingBox(\n                        Coordinate(_parse_float(json_data[0]),\n                                   _parse_float(json_data[1]),\n                                   _parse_float(json_data[2])),\n                        Coordinate(_parse_float(json_data[3]),\n                                   _parse_float(json_data[4]),\n                                   _parse_float(json_data[5])))\n        else:\n            raise USGSException(\"The bounding box information was incomplete.\")", "response": "Creates a BoundingBox from a json string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _from_json(json_data):\n        try:\n            coordinates = json_data['geometry']['coordinates']\n        except KeyError:\n            raise USGSException(\"The geometry information was not returned from the USGS website.\")\n        try:\n            properties = json_data['properties']\n        except KeyError:\n            raise USGSException(\"One of the earthquakes did not have any property information\")\n        return Earthquake(Coordinate._from_json(coordinates),\n                          _parse_float(properties.get('mag', '0'), 0.0),\n                          properties.get('place', ''),\n                          _parse_int(properties.get('time', '0'), 0),\n                          properties.get('url', ''),\n                          _parse_int(properties.get('felt', '0'), 0),\n                          _parse_float(properties.get('cdi', '0'), 0.0),\n                          _parse_float(properties.get('mmi', '0'), 0.0),\n                          properties['alert'] if 'alert' in properties and properties['alert'] else '',\n                          properties.get('status', ''),\n                          _parse_int(properties.get('sig', '0'), 0),\n                          json_data.get('id', ''),\n                          _parse_float(properties.get('dmin', '0'), 0.0),\n                          _parse_float(properties.get('rms', '0'), 0.0),\n                          _parse_float(properties.get('gap', '0'), 0.0))", "response": "Creates a Earthquake object from a json data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary representation of this object", "response": "def _to_dict(self):\n        ''' Returns a dictionary representation of this object '''\n        return dict(area= self.area._to_dict(),\n                    earthquakes = [q._to_dict() for q in self.earthquakes],\n                    title = self.title)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _from_json(json_data):\n        if 'bbox' in json_data:\n            box = BoundingBox._from_json(json_data['bbox'])\n        else:\n            box = BoundingBox(Coordinate(0.,0.,0.), Coordinate(0.,0.,0.))\n        if 'features' in json_data and json_data['features']:\n            quakes = list(map(Earthquake._from_json, json_data['features']))\n        else:\n            quakes = []\n        try:\n            title = json_data['metadata']['title']\n        except KeyError:\n            raise USGSException(\"No report title information returned by server\")\n        return Report(box, quakes, title)", "response": "Creates a Report from json data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforcing the given input to only use str instead of bytes or unicode.", "response": "def _byteify(input):\n    \"\"\"\n    Force the given input to only use `str` instead of `bytes` or `unicode`.\n    This works even if the input is a dict, list,\n    \"\"\"\n    if isinstance(input, dict):\n        return {_byteify(key): _byteify(value) for key, value in input.items()}\n    elif isinstance(input, list):\n        return [_byteify(element) for element in input]\n    elif _PYTHON_3 and isinstance(input, str):\n        return str(input.encode('ascii', 'replace').decode('ascii'))\n    elif not _PYTHON_3 and isinstance(input, unicode):\n        return str(input.encode('ascii', 'replace').decode('ascii'))\n    else:\n        return input"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the table from the given html.", "response": "def extract_table(html):\n    soup = BeautifulSoup(html,'lxml')\n    table = soup.find(\"table\", attrs={\"class\":\"basic_table\"})\n    \n    if table is None:\n        return table\n    return table\n\n    '''# The first tr contains the field names.\n    datasets = []\n    for row in table.find_all(\"tr\"):\n        dataset = list((td.get_text().strip(), \n                        td.attrs.get('colspan', 1),\n                        td.attrs.get('rowspan', 1)) \n                       for td in row.find_all(\"td\"))\n        datasets.append(dataset)'''\n    return datasets"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove outliers from the given list of data.", "response": "def remove_outliers(lodol, actually_keep=True):\n    bad_indexes = set()\n    bad_keys = set()\n    DEVIATIONS = 4\n    MAX_LENGTH = 10000\n    \n    for data in lodol:\n        #print(data['name'])\n        #print([e for e in data['data'] if isinstance(e, (str, unicode))])\n        if isinstance(data['data'][0], (int, float)):\n            mean = statistics.mean(data['data'])\n            std = statistics.stdev(data['data'])\n            evils = 0\n            for index, value in enumerate(data['data']):\n                if mean - DEVIATIONS*std > value or value > mean + DEVIATIONS*std:\n                    bad_keys.add(data['name'])\n                    bad_indexes.add(index)\n                    evils += 1\n            print(data['name'], mean-4*std, mean+4*std, evils)\n            \n    total_indexes = len(lodol[0]['data'])\n    reduced_indexes = total_indexes - len(bad_indexes)\n    print(\"Bad indexes:\", len(bad_indexes), \"/\", total_indexes)\n    '''\n    I have a list of numbers Z from 0 to N\n    I have a list of J numbers (where J < N) randomly distributed throughout Z\n    I wish to remove K numbers from Z, without drawing from any number in J\n    '''\n    if reduced_indexes > MAX_LENGTH:\n        stride = int(total_indexes / MAX_LENGTH)\n        for an_index in range(0, total_indexes, stride):\n            keep_index = random.randint(0, stride-1)\n            for offset in xrange(0, stride):\n                if keep_index != offset:\n                    bad_indexes.add(min(total_indexes, an_index+offset))\n    if actually_keep:\n        bad_indexes = set()\n        bad_keys = set()\n    print(\"Trimmed indexes:\", len(bad_indexes), \"/\", total_indexes)\n    print(\"Contributing keys:\", ', '.join(bad_keys))\n    for data in lodol:\n        data['data'] = [v for i, v in enumerate(data['data']) if i not in bad_indexes]\n        inter = data['name'].split('.', 2)[2]\n        if '.' in inter:\n            category, name = inter.rsplit('.', 1)\n        else:\n            category, name = inter, inter\n        category = category.replace('.', ' ')\n        data['pretty'] = category.title() + \": \"+name.title()\n        if isinstance(data['data'][0], (float, int)):\n            data['type'] = 'number'\n        else:\n            data['type'] = 'text'\n    lodol.sort(key= lambda e: e['pretty'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_outliers(lodol, actually_keep=True):\n    bad_indexes = set()\n    bad_keys = set()\n    DEVIATIONS = 3\n    MAX_LENGTH = 10000\n    \n    for data in lodol:\n        #print(data['name'])\n        #print([e for e in data['data'] if isinstance(e, (str, unicode))])\n        if isinstance(data['data'][0], (int, float)):\n            print(data['name'])\n            mean = statistics.mean(data['data'])\n            std = statistics.stdev(data['data'])\n            evils = 0\n            for index, value in enumerate(data['data']):\n                if mean - DEVIATIONS*std > value or value > mean + DEVIATIONS*std:\n                    bad_keys.add(data['name'])\n                    bad_indexes.add(index)\n                    evils += 1\n            #print(data['name'], mean-4*std, mean+4*std, evils)\n                    \n    total_indexes = len(lodol[0]['data'])\n    reduced_indexes = total_indexes - len(bad_indexes)\n    print(\"Bad indexes:\", len(bad_indexes), \"/\", total_indexes)\n    '''\n    I have a list of numbers Z from 0 to N\n    I have a list of J numbers (where J < N) randomly distributed throughout Z\n    I wish to remove K numbers from Z, without drawing from any number in J\n    '''\n    if reduced_indexes > MAX_LENGTH:\n        stride = total_indexes / MAX_LENGTH\n        for an_index in xrange(0, total_indexes, stride):\n            keep_index = random.randint(0, stride-1)\n            for offset in xrange(0, stride):\n                if keep_index != offset:\n                    bad_indexes.add(min(total_indexes, an_index+offset))\n    if actually_keep:\n        bad_indexes = set()\n        bad_keys = set()\n    print(\"Trimmed indexes:\", len(bad_indexes), \"/\", total_indexes)    \n    #print(\"Contributing keys:\", ', '.join(bad_keys))\n    key_names = [row['name'] for row in lodol]\n    short_key_names = shortest_unique_strings(key_names)\n    key_name_map = dict(zip(key_names, short_key_names))\n    for data in lodol:\n        data['data'] = [v for i, v in enumerate(data['data']) if i not in bad_indexes]\n        #inter = data['name'].split('.', 2)[2]\n        #if '.' in inter:\n        #    category, name = inter.rsplit('.', 1)\n        #else:\n        #    category, name = inter, inter\n        #category = category.replace('.', ' ')\n        #data['pretty'] = category.title() + \": \"+name.title()\n        data['pretty'] = key_name_map[data['name']] \n        print(data['pretty'])\n        if isinstance(data['data'][0], (float, int)):\n            data['type'] = 'number'\n        else:\n            data['type'] = 'text'\n    lodol.sort(key= lambda e: e['pretty'])\n    return key_name_map", "response": "Remove outliers from the given list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_model(cls, name=None, status=ENABLED):\n        ppath = cls.get_pythonpath()\n        if is_plugin_point(cls):\n            if name is not None:\n                kwargs = {}\n                if status is not None:\n                    kwargs['status'] = status\n                return Plugin.objects.get(point__pythonpath=ppath,\n                                          name=name, **kwargs)\n            else:\n                return PluginPointModel.objects.get(pythonpath=ppath)\n        else:\n            return Plugin.objects.get(pythonpath=ppath)", "response": "Returns model instance of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the plugin point model instance. Only used from plugin classes.", "response": "def get_point_model(cls):\n        \"\"\"\n        Returns plugin point model instance. Only used from plugin classes.\n        \"\"\"\n        if is_plugin_point(cls):\n            raise Exception(_('This method is only available to plugin '\n                              'classes.'))\n        else:\n            return PluginPointModel.objects.\\\n                get(plugin__pythonpath=cls.get_pythonpath())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all plugins of the given class.", "response": "def get_plugins(cls):\n        \"\"\"\n        Returns all plugin instances of plugin point, passing all args and\n        kwargs to plugin constructor.\n        \"\"\"\n        # Django >= 1.9 changed something with the migration logic causing\n        # plugins to be executed before the corresponding database tables\n        # exist. This method will only return something if the database\n        # tables have already been created.\n        # XXX: I don't fully understand the issue and there should be\n        # another way but this appears to work fine.\n        if django_version >= (1, 9) and \\\n                not db_table_exists(Plugin._meta.db_table):\n            raise StopIteration\n\n        if is_plugin_point(cls):\n            for plugin_model in cls.get_plugins_qs():\n                yield plugin_model.get_plugin()\n        else:\n            raise Exception(_('This method is only available to plugin point '\n                              'classes.'))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning query set of all plugins belonging to the given plugin point.", "response": "def get_plugins_qs(cls):\n        \"\"\"\n        Returns query set of all plugins belonging to plugin point.\n\n        Example::\n\n            for plugin_instance in MyPluginPoint.get_plugins_qs():\n                print(plugin_instance.get_plugin().name)\n\n        \"\"\"\n        if is_plugin_point(cls):\n            point_pythonpath = cls.get_pythonpath()\n            return Plugin.objects.filter(point__pythonpath=point_pythonpath,\n                                         status=ENABLED).\\\n                order_by('index')\n        else:\n            raise Exception(_('This method is only available to plugin point '\n                              'classes.'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef readmetadata():\n\tif os.path.exists(PICKLEFILE):\n\t\tmetadata = pickle.load(gzip.open(PICKLEFILE, 'rb'))\n\telse:\n\t\tmetadata = {}\n\t\tfor xml in tqdm(getrdfdata()):\n\t\t\tebook = xml.find(r'{%(pg)s}ebook' % NS)\n\t\t\tif ebook is None:\n\t\t\t\tcontinue\n\t\t\tresult = parsemetadata(ebook)\n\t\t\tif result is not None:\n\t\t\t\tmetadata[result['id']] = result\n\t\tpickle.dump(metadata, gzip.open(PICKLEFILE, 'wb'), protocol=-1)\n\treturn metadata", "response": "Read the cached metadata dump of Gutenberg catalog."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getrdfdata():\n\tif not os.path.exists(RDFFILES):\n\t\t_, _ = urllib.urlretrieve(RDFURL, RDFFILES)\n\twith tarfile.open(RDFFILES) as archive:\n\t\tfor tarinfo in archive:\n\t\t\tyield ElementTree.parse(archive.extractfile(tarinfo))", "response": "Downloads Project Gutenberg RDF catalog.\n\tYields : ElementTree. Element"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an etext meta - data definition to extract fields.", "response": "def parsemetadata(ebook):\n\t\"\"\"Parses an etext meta-data definition to extract fields.\n\tArgs:\n\t\tebook (xml.etree.ElementTree.Element): An ebook meta-data definition.\n\t\"\"\"\n\tresult = dict.fromkeys(META_FIELDS)\n\t# get etext no\n\tabout = ebook.get('{%(rdf)s}about' % NS)\n\tresult['id'] = int(os.path.basename(about))\n\t# author\n\tcreator = ebook.find('.//{%(dc)s}creator' % NS)\n\tif creator is not None:\n\t\tname = creator.find('.//{%(pg)s}name' % NS)\n\t\tif name is not None:\n\t\t\tresult['author'] = safeunicode(name.text, encoding='utf-8')\n\t\tbirth = creator.find('.//{%(pg)s}birthdate' % NS)\n\t\tif birth is not None:\n\t\t\tresult['authoryearofbirth'] = int(birth.text)\n\t\tdeath = creator.find('.//{%(pg)s}deathdate' % NS)\n\t\tif death is not None:\n\t\t\tresult['authoryearofdeath'] = int(death.text)\n\t# title\n\ttitle = ebook.find('.//{%(dc)s}title' % NS)\n\tif title is not None:\n\t\tresult['title'] = fixsubtitles(\n\t\t\t\tsafeunicode(title.text, encoding='utf-8'))\n\t# subject lists\n\tresult['subjects'], result['LCC'] = set(), set()\n\tfor subject in ebook.findall('.//{%(dc)s}subject' % NS):\n\t\tres = subject.find('.//{%(dcam)s}memberOf' % NS)\n\t\tif res is None:\n\t\t\tcontinue\n\t\tres = res.get('{%(rdf)s}resource' % NS)\n\t\tvalue = subject.find('.//{%(rdf)s}value' % NS).text\n\t\tif res == ('%(dc)sLCSH' % NS):\n\t\t\tresult['subjects'].add(value)\n\t\telif res == ('%(dc)sLCC' % NS):\n\t\t\tresult['LCC'].add(value)\n\t# formats\n\tresult['formats'] = {file.find('{%(dc)s}format//{%(rdf)s}value' % NS).text:\n\t\t\tfile.get('{%(rdf)s}about' % NS)\n\t\t\tfor file in ebook.findall('.//{%(pg)s}file' % NS)}\n\t# type\n\tbooktype = ebook.find('.//{%(dc)s}type//{%(rdf)s}value' % NS)\n\tif booktype is not None:\n\t\tresult['type'] = booktype.text\n\t# languages\n\tlang = ebook.findall('.//{%(dc)s}language//{%(rdf)s}value' % NS)\n\tresult['language'] = [a.text for a in lang] or None\n\t# download count\n\tdownloads = ebook.find('.//{%(pg)s}downloads' % NS)\n\tif downloads is not None:\n\t\tresult['downloads'] = int(downloads.text)\n\treturn result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef etextno(lines):\n\tfor line in lines:\n\t\tmatch = ETEXTRE.search(line)\n\t\tif match is not None:\n\t\t\tfront_match = match.group('etextid_front')\n\t\t\tback_match = match.group('etextid_back')\n\t\t\tif front_match is not None:\n\t\t\t\treturn int(front_match)\n\t\t\telif back_match is not None:\n\t\t\t\treturn int(back_match)\n\t\t\telse:\n\t\t\t\traise ValueError('no regex match (this should never happen')\n\traise ValueError('no etext-id found')", "response": "Retrieves the id for an etext."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safeunicode(arg, *args, **kwargs):\n\treturn arg if isinstance(arg, unicode) else unicode(arg, *args, **kwargs)", "response": "Coerce argument to unicode if it s not already."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_reports():\n    if False:\n        # If there was a Test version of this method, it would go here. But alas.\n        pass\n    else:\n        rows = _Constants._DATABASE.execute(\"SELECT data FROM energy\".format(\n            hardware=_Constants._HARDWARE))\n        data = [r[0] for r in rows]\n        data = [_Auxiliary._byteify(_json.loads(r)) for r in data]\n        \n        return _Auxiliary._byteify(data)", "response": "Returns the energy data from 1960 to 2014 across various factors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk_interface(self, name, data, in_location):\n        interface = Interface()\n        location = \"{}.{}\".format(in_location, name)\n        if isinstance(data, dict):\n            interface.name = de_identifier(self.require_field(location, \"name\", data, \"\", str))\n            location = \"{}.{}\".format(in_location, clean_identifier(interface.name))\n            interface.returns = de_identifier(self.require_field(location, \"returns\", data, \"\", str))\n            interface.description = self.recommend_field(location, \"description\", data, \"\", str)\n            # Implementations\n            if \"production\" in data:\n                interface.production = self.walk_implementation(\"production\", data[\"production\"], location)\n            else:\n                self.not_found_error(\"{}.{}\".format(location, \"production\"))\n            if \"test\" in data:\n                interface.test = self.walk_implementation(\"test\", data[\"test\"], location)\n            else:\n                interface.test = None\n            # Arguments\n            interface.args = list(self.walk_list(\"{}.args\".format(location), \"args\", data, self.walk_interface_arg))\n            interface.cache = self.typecheck_field(location, \"cache\", data, [], list)\n        else:\n            self.type_error(location, dict, type(data))\n        return interface\n        '''\n            self.require_field(\"url\", \"{}.url\".format(location), data, str)\n            self.require_field(\"verb\", \"{}.verb\".format(location), data, set((\"get\", \"post\", \"delete\", \"put\")))\n            self.recommend_field(\"format\", \"{}.format\".format(location), data, set((\"json\", \"xml\", \"html\", \"csv\", \"text\")), not_found=\"Assuming json.\")\n            self.require_field(\"output\", \"{}.output\".format(location), data, str)\n            self.recommend_field(\n                            \"description\", \n                            \"{}.description\".format(name),\n                            data, str, not_found=\"There will be no documentation for {}!\".format(name))\n            self.typecheck_field(\"comment\", \"{}.comment\".format(location), data, str)\n            if \"inputs\" in data:\n                self.walk_list(\"{}.inputs\".format(location), \"inputs\", data, self.walk_input)\n                # Ensure that every url has the requsite paths!\n                if \"url\" in data:\n                    url_input_names = set(map(str, re.findall(\"<(.*?)>\", data[\"url\"])))\n                    given_input_names = set([input['path'] for input in data[\"inputs\"].values() if 'path' in input])\n                    if not url_input_names.issubset(given_input_names):\n                        self.error(\"Expected full list of url parameters {} for {}, given only {}.\".format(list(url_input_names), location, list(given_input_names)))\n                    \n        else:\n            self.type_error(location, dict, type(data))\n        return interface'''", "response": "Walks the data structure for an interface and returns a new Interface object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\niterate over all registered plugins or plugin points and prepare to add them to database.", "response": "def available(self, src, dst, model):\n        \"\"\"\n        Iterate over all registered plugins or plugin points and prepare to add\n        them to database.\n        \"\"\"\n        for name, point in six.iteritems(src):\n            inst = dst.pop(name, None)\n            if inst is None:\n                self.print_(1, \"Registering %s for %s\" % (model.__name__,\n                                                          name))\n                inst = model(pythonpath=name)\n            if inst.status == REMOVED:\n                self.print_(1, \"Updating %s for %s\" % (model.__name__, name))\n                # re-enable a previously removed plugin point and its plugins\n                inst.status = ENABLED\n            yield point, inst"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmarks all missing plugins that are not registered in database but are not registered.", "response": "def missing(self, dst):\n        \"\"\"\n        Mark all missing plugins, that exists in database, but are not\n        registered.\n        \"\"\"\n        for inst in six.itervalues(dst):\n            if inst.status != REMOVED:\n                inst.status = REMOVED\n                inst.save()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsynchronizing all registered plugins and plugin points to database.", "response": "def all(self):\n        \"\"\"\n        Synchronize all registered plugins and plugin points to database.\n        \"\"\"\n        # Django >= 1.9 changed something with the migration logic causing\n        # plugins to be executed before the corresponding database tables\n        # exist. This method will only return something if the database\n        # tables have already been created.\n        # XXX: I don't fully understand the issue and there should be\n        # another way but this appears to work fine.\n        if django_version >= (1, 9) and (\n                not db_table_exists(Plugin._meta.db_table) or\n                not db_table_exists(PluginPoint._meta.db_table)):\n            return\n        self.points()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn weather reports from the dataset.", "response": "def get_weather(test=False):\n    \"\"\"\n    Returns weather reports from the dataset.\n    \n    \"\"\"\n    if _Constants._TEST or test:\n        rows = _Constants._DATABASE.execute(\"SELECT data FROM weather LIMIT {hardware}\".format(\n            hardware=_Constants._HARDWARE))\n        data = [r[0] for r in rows]\n        data = [_Auxiliary._byteify(_json.loads(r)) for r in data]\n        \n        return _Auxiliary._byteify(data)\n        \n    else:\n        rows = _Constants._DATABASE.execute(\"SELECT data FROM weather\".format(\n            hardware=_Constants._HARDWARE))\n        data = [r[0] for r in rows]\n        data = [_Auxiliary._byteify(_json.loads(r)) for r in data]\n        \n        return _Auxiliary._byteify(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get(self, url, **kw):\n        '''\n        Makes a GET request, setting Authorization\n        header by default\n        '''\n        headers = kw.pop('headers', {})\n        headers.setdefault('Content-Type', 'application/json')\n        headers.setdefault('Accept', 'application/json')\n        headers.setdefault('Authorization', self.AUTHORIZATION_HEADER)\n        kw['headers'] = headers\n        resp = self.session.get(url, **kw)\n        self._raise_for_status(resp)\n        return resp", "response": "Makes a GET request setting Authorization\n        header by default\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _post(self, url, **kw):\n        '''\n        Makes a POST request, setting Authorization\n        header by default\n        '''\n        headers = kw.pop('headers', {})\n        headers.setdefault('Authorization', self.AUTHORIZATION_HEADER)\n        kw['headers'] = headers\n        resp = self.session.post(url, **kw)\n        self._raise_for_status(resp)\n        return resp", "response": "Makes a POST request"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _post_json(self, url, data, **kw):\n        '''\n        Makes a POST request, setting Authorization\n        and Content-Type headers by default\n        '''\n        data = json.dumps(data)\n        headers = kw.pop('headers', {})\n        headers.setdefault('Content-Type', 'application/json')\n        headers.setdefault('Accept', 'application/json')\n\n        kw['headers'] = headers\n        kw['data'] = data\n        return self._post(url, **kw)", "response": "Makes a POST request setting Authorization\n        and Content - Type headers by default\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nauthenticate this client instance.", "response": "def authenticate(self, login=None, password=None):\n        '''\n        Authenticated this client instance.\n\n        ``login`` and ``password`` default to the environment\n        variables ``MS_LOGIN`` and ``MS_PASSWD`` respectively.\n\n\n        :param login: Email address associated with a microsoft account\n        :param password: Matching password\n\n        :raises: :class:`~xbox.exceptions.AuthenticationException`\n\n        :returns: Instance of :class:`~xbox.Client`\n\n        '''\n        if login is None:\n            login = os.environ.get('MS_LOGIN')\n\n        if password is None:\n            password = os.environ.get('MS_PASSWD')\n\n        if not login or not password:\n            msg = (\n                'Authentication credentials required. Please refer to '\n                'http://xbox.readthedocs.org/en/latest/authentication.html'\n            )\n            raise AuthenticationException(msg)\n\n        self.login = login\n\n        # firstly we have to GET the login page and extract\n        # certain data we need to include in our POST request.\n        # sadly the data is locked away in some javascript code\n        base_url = 'https://login.live.com/oauth20_authorize.srf?'\n\n        # if the query string is percent-encoded the server\n        # complains that client_id is missing\n        qs = unquote(urlencode({\n            'client_id': '0000000048093EE3',\n            'redirect_uri': 'https://login.live.com/oauth20_desktop.srf',\n            'response_type': 'token',\n            'display': 'touch',\n            'scope': 'service::user.auth.xboxlive.com::MBI_SSL',\n            'locale': 'en',\n        }))\n        resp = self.session.get(base_url + qs)\n\n        # python 3.x will error if this string is not a\n        # bytes-like object\n        url_re = b'urlPost:\\\\\\'([A-Za-z0-9:\\?_\\-\\.&/=]+)'\n        ppft_re = b'sFTTag:\\\\\\'.*value=\"(.*)\"/>'\n\n        login_post_url = re.search(url_re, resp.content).group(1)\n        post_data = {\n            'login': login,\n            'passwd': password,\n            'PPFT': re.search(ppft_re, resp.content).groups(1)[0],\n            'PPSX': 'Passpor',\n            'SI': 'Sign in',\n            'type': '11',\n            'NewUser': '1',\n            'LoginOptions': '1',\n            'i3': '36728',\n            'm1': '768',\n            'm2': '1184',\n            'm3': '0',\n            'i12': '1',\n            'i17': '0',\n            'i18': '__Login_Host|1',\n        }\n\n        resp = self.session.post(\n            login_post_url, data=post_data, allow_redirects=False,\n        )\n\n        if 'Location' not in resp.headers:\n            # we can only assume the login failed\n            msg = 'Could not log in with supplied credentials'\n            raise AuthenticationException(msg)\n\n        # the access token is included in fragment of the location header\n        location = resp.headers['Location']\n        parsed = urlparse(location)\n        fragment = parse_qs(parsed.fragment)\n        access_token = fragment['access_token'][0]\n\n        url = 'https://user.auth.xboxlive.com/user/authenticate'\n        resp = self.session.post(url, data=json.dumps({\n            \"RelyingParty\": \"http://auth.xboxlive.com\",\n            \"TokenType\": \"JWT\",\n            \"Properties\": {\n                \"AuthMethod\": \"RPS\",\n                \"SiteName\": \"user.auth.xboxlive.com\",\n                \"RpsTicket\": access_token,\n            }\n        }), headers={'Content-Type': 'application/json'})\n\n        json_data = resp.json()\n        user_token = json_data['Token']\n        uhs = json_data['DisplayClaims']['xui'][0]['uhs']\n\n        url = 'https://xsts.auth.xboxlive.com/xsts/authorize'\n        resp = self.session.post(url, data=json.dumps({\n            \"RelyingParty\": \"http://xboxlive.com\",\n            \"TokenType\": \"JWT\",\n            \"Properties\": {\n                \"UserTokens\": [user_token],\n                \"SandboxId\": \"RETAIL\",\n            }\n        }), headers={'Content-Type': 'application/json'})\n\n        response = resp.json()\n        self.AUTHORIZATION_HEADER = 'XBL3.0 x=%s;%s' % (uhs, response['Token'])\n        self.user_xid = response['DisplayClaims']['xui'][0]['xid']\n        self.authenticated = True\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_xuid(cls, xuid):\n        '''\n        Instantiates an instance of ``GamerProfile`` from\n        an xuid\n\n        :param xuid: Xuid to look up\n\n        :raises: :class:`~xbox.exceptions.GamertagNotFound`\n\n        :returns: :class:`~xbox.GamerProfile` instance\n        '''\n\n        url = 'https://profile.xboxlive.com/users/xuid(%s)/profile/settings' % xuid\n        try:\n            return cls._fetch(url)\n        except (GamertagNotFound, InvalidRequest):\n            # this endpoint seems to return 400 when the resource\n            # does not exist\n            raise GamertagNotFound('No such user: %s' % xuid)", "response": "Instantiates an instance of GamerProfile from an Xuid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a specific game clip from the xbox live user.", "response": "def get(cls, xuid, scid, clip_id):\n        '''\n        Gets a specific game clip\n\n        :param xuid: xuid of an xbox live user\n        :param scid: scid of a clip\n        :param clip_id: id of a clip\n        '''\n        url = (\n            'https://gameclipsmetadata.xboxlive.com/users'\n            '/xuid(%(xuid)s)/scids/%(scid)s/clips/%(clip_id)s' % {\n                'xuid': xuid,\n                'scid': scid,\n                'clip_id': clip_id,\n            }\n        )\n        resp = xbox.client._get(url)\n\n        # scid does not seem to matter when fetching clips,\n        # as long as it looks like a uuid it should be fine.\n        # perhaps we'll raise an exception in future\n        if resp.status_code == 404:\n            msg = 'Could not find clip: xuid=%s, scid=%s, clip_id=%s' % (\n                xuid, scid, clip_id,\n            )\n            raise ClipNotFound(msg)\n\n        data = resp.json()\n\n        # as we don't have the user object let's\n        # create a lazily evaluated proxy object\n        # that will fetch it only when required\n        user = UserProxy(xuid)\n        return cls(user, data['gameClip'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all clips saved by a user.", "response": "def saved_from_user(cls, user, include_pending=False):\n        '''\n        Gets all clips 'saved' by a user.\n\n        :param user: :class:`~xbox.GamerProfile` instance\n        :param bool include_pending: whether to ignore clips that are not\n            yet uploaded. These clips will have thumbnails and media_url\n            set to ``None``\n        :returns: Iterator of :class:`~xbox.Clip` instances\n        '''\n\n        url = 'https://gameclipsmetadata.xboxlive.com/users/xuid(%s)/clips/saved'\n        resp = xbox.client._get(url % user.xuid)\n        data = resp.json()\n        for clip in data['gameClips']:\n            if clip['state'] != 'PendingUpload' or include_pending:\n                yield cls(user, clip)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef increment(self, method=None, url=None, response=None, error=None, _pool=None, _stacktrace=None):\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n\n        total = self.total\n        if total is not None:\n            total -= 1\n\n        _observed_errors = self._observed_errors\n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n\n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n            _observed_errors += 1\n\n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n            _observed_errors += 1\n\n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n\n        else:\n            # FIXME: Nothing changed, scenario doesn't make sense.\n            _observed_errors += 1\n\n        new_retry = self.new(\n            total=total,\n            connect=connect, read=read, redirect=redirect,\n            _observed_errors=_observed_errors)\n\n        if new_retry.is_exhausted():\n            raise MaxRetryError(_pool, url, error)\n\n        log.debug(\"Incremented Retry for (url='%s'): %r\" % (url, new_retry))\n\n        return new_retry", "response": "Increment the retry counters for the specified url and response."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, amt=None, decode_content=None, cache_content=False):\n        # Note: content-encoding value should be case-insensitive, per RFC 7230\n        # Section 3.2\n        content_encoding = self.headers.get('content-encoding', '').lower()\n        if self._decoder is None:\n            if content_encoding in self.CONTENT_DECODERS:\n                self._decoder = _get_decoder(content_encoding)\n        if decode_content is None:\n            decode_content = self.decode_content\n\n        if self._fp is None:\n            return\n\n        flush_decoder = False\n\n        try:\n            try:\n                if amt is None:\n                    # cStringIO doesn't like amt=None\n                    data = self._fp.read()\n                    flush_decoder = True\n                else:\n                    cache_content = False\n                    data = self._fp.read(amt)\n                    if amt != 0 and not data:  # Platform-specific: Buggy versions of Python.\n                        # Close the connection when no data is returned\n                        #\n                        # This is redundant to what httplib/http.client _should_\n                        # already do.  However, versions of python released before\n                        # December 15, 2012 (http://bugs.python.org/issue16298) do\n                        # not properly close the connection in all cases. There is\n                        # no harm in redundantly calling close.\n                        self._fp.close()\n                        flush_decoder = True\n\n            except SocketTimeout:\n                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\n                # there is yet no clean way to get at it from this context.\n                raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n\n            except BaseSSLError as e:\n                # FIXME: Is there a better way to differentiate between SSLErrors?\n                if not 'read operation timed out' in str(e):  # Defensive:\n                    # This shouldn't happen but just in case we're missing an edge\n                    # case, let's avoid swallowing SSL errors.\n                    raise\n\n                raise ReadTimeoutError(self._pool, None, 'Read timed out.')\n\n            except HTTPException as e:\n                # This includes IncompleteRead.\n                raise ProtocolError('Connection broken: %r' % e, e)\n\n            self._fp_bytes_read += len(data)\n\n            try:\n                if decode_content and self._decoder:\n                    data = self._decoder.decompress(data)\n            except (IOError, zlib.error) as e:\n                raise DecodeError(\n                    \"Received response with content-encoding: %s, but \"\n                    \"failed to decode it.\" % content_encoding, e)\n\n            if flush_decoder and decode_content and self._decoder:\n                buf = self._decoder.decompress(binary_type())\n                data += buf + self._decoder.flush()\n\n            if cache_content:\n                self._body = data\n\n            return data\n\n        finally:\n            if self._original_response and self._original_response.isclosed():\n                self.release_conn()", "response": "Read the content of the response and return the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an : class : httplib. HTTPResponse instance r return a new instance of ResponseCls with the contents of r.", "response": "def from_httplib(ResponseCls, r, **response_kw):\n        \"\"\"\n        Given an :class:`httplib.HTTPResponse` instance ``r``, return a\n        corresponding :class:`urllib3.response.HTTPResponse` object.\n\n        Remaining parameters are passed to the HTTPResponse constructor, along\n        with ``original_response=r``.\n        \"\"\"\n\n        headers = HTTPHeaderDict()\n        for k, v in r.getheaders():\n            headers.add(k, v)\n\n        # HTTPResponse objects in Python 3 don't have a .strict attribute\n        strict = getattr(r, 'strict', 0)\n        return ResponseCls(body=r,\n                           headers=headers,\n                           status=r.status,\n                           version=r.version,\n                           reason=r.reason,\n                           strict=strict,\n                           original_response=r,\n                           **response_kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add(self, key, value):\n        self._data.setdefault(key.lower(), []).append((key, value))", "response": "Adds a ( name value ) pair to the set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes the given response and tries digest - auth if needed.", "response": "def handle_401(self, r, **kwargs):\n        \"\"\"Takes the given response and tries digest-auth, if needed.\"\"\"\n\n        if self.pos is not None:\n            # Rewind the file position indicator of the body to where\n            # it was to resend the request.\n            r.request.body.seek(self.pos)\n        num_401_calls = getattr(self, 'num_401_calls', 1)\n        s_auth = r.headers.get('www-authenticate', '')\n\n        if 'digest' in s_auth.lower() and num_401_calls < 2:\n\n            setattr(self, 'num_401_calls', num_401_calls + 1)\n            pat = re.compile(r'digest ', flags=re.IGNORECASE)\n            self.chal = parse_dict_header(pat.sub('', s_auth, count=1))\n\n            # Consume content and release the original connection\n            # to allow our new request to reuse the same one.\n            r.content\n            r.raw.release_conn()\n            prep = r.request.copy()\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\n            prep.prepare_cookies(prep._cookies)\n\n            prep.headers['Authorization'] = self.build_digest_header(\n                prep.method, prep.url)\n            _r = r.connection.send(prep, **kwargs)\n            _r.history.append(r)\n            _r.request = prep\n\n            return _r\n\n        setattr(self, 'num_401_calls', 1)\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs a : class : PreparedRequest for transmission and returns it.", "response": "def prepare(self):\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n        p = PreparedRequest()\n        p.prepare(\n            method=self.method,\n            url=self.url,\n            headers=self.headers,\n            files=self.files,\n            data=self.data,\n            params=self.params,\n            auth=self.auth,\n            cookies=self.cookies,\n            hooks=self.hooks,\n        )\n        return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the given HTTP URL.", "response": "def prepare_url(self, url, params):\n        \"\"\"Prepares the given HTTP URL.\"\"\"\n        url = to_native_string(url)\n\n        # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n        # `data` etc to work around exceptions from `url_parse`, which\n        # handles RFC 3986 only.\n        if ':' in url and not url.lower().startswith('http'):\n            self.url = url\n            return\n\n        # Support for unicode domain names and paths.\n        scheme, auth, host, port, path, query, fragment = parse_url(url)\n\n        if not scheme:\n            raise MissingSchema(\"Invalid URL {0!r}: No schema supplied. \"\n                                \"Perhaps you meant http://{0}?\".format(url))\n\n        if not host:\n            raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n\n        # Only want to apply IDNA to the hostname\n        try:\n            host = host.encode('idna').decode('utf-8')\n        except UnicodeError:\n            raise InvalidURL('URL has an invalid label.')\n\n        # Carefully reconstruct the network location\n        netloc = auth or ''\n        if netloc:\n            netloc += '@'\n        netloc += host\n        if port:\n            netloc += ':' + str(port)\n\n        # Bare domains aren't valid URLs.\n        if not path:\n            path = '/'\n\n        if is_py2:\n            if isinstance(scheme, str):\n                scheme = scheme.encode('utf-8')\n            if isinstance(netloc, str):\n                netloc = netloc.encode('utf-8')\n            if isinstance(path, str):\n                path = path.encode('utf-8')\n            if isinstance(query, str):\n                query = query.encode('utf-8')\n            if isinstance(fragment, str):\n                fragment = fragment.encode('utf-8')\n\n        enc_params = self._encode_params(params)\n        if enc_params:\n            if query:\n                query = '%s&%s' % (query, enc_params)\n            else:\n                query = enc_params\n\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n        self.url = url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare the given HTTP body data.", "response": "def prepare_body(self, data, files):\n        \"\"\"Prepares the given HTTP body data.\"\"\"\n\n        # Check if file, fo, generator, iterator.\n        # If not, run through normal process.\n\n        # Nottin' on you.\n        body = None\n        content_type = None\n        length = None\n\n        is_stream = all([\n            hasattr(data, '__iter__'),\n            not isinstance(data, (basestring, list, tuple, dict))\n        ])\n\n        try:\n            length = super_len(data)\n        except (TypeError, AttributeError, UnsupportedOperation):\n            length = None\n\n        if is_stream:\n            body = data\n\n            if files:\n                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n\n            if length is not None:\n                self.headers['Content-Length'] = builtin_str(length)\n            else:\n                self.headers['Transfer-Encoding'] = 'chunked'\n        else:\n            # Multi-part file uploads.\n            if files:\n                (body, content_type) = self._encode_files(files, data)\n            else:\n                if data:\n                    body = self._encode_params(data)\n                    if isinstance(data, basestring) or hasattr(data, 'read'):\n                        content_type = None\n                    else:\n                        content_type = 'application/x-www-form-urlencoded'\n\n            self.prepare_content_length(body)\n\n            # Add content-type if it wasn't explicitly provided.\n            if (content_type) and (not 'content-type' in self.headers):\n                self.headers['Content-Type'] = content_type\n\n        self.body = body"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef request_url(self, request, proxies):\n        proxies = proxies or {}\n        scheme = urlparse(request.url).scheme\n        proxy = proxies.get(scheme)\n\n        if proxy and scheme != 'https':\n            url, _ = urldefrag(request.url)\n        else:\n            url = request.path_url\n\n        return url", "response": "Obtain the url to use when making the final request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending a PreparedRequest object.", "response": "def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n        \"\"\"Sends PreparedRequest object. Returns Response object.\n\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n        :param stream: (optional) Whether to stream the request content.\n        :param timeout: (optional) How long to wait for the server to send\n            data before giving up, as a float, or a (`connect timeout, read\n            timeout <user/advanced.html#timeouts>`_) tuple.\n        :type timeout: float or tuple\n        :param verify: (optional) Whether to verify SSL certificates.\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\n        :param proxies: (optional) The proxies dictionary to apply to the request.\n        \"\"\"\n\n        conn = self.get_connection(request.url, proxies)\n\n        self.cert_verify(conn, request.url, verify, cert)\n        url = self.request_url(request, proxies)\n        self.add_headers(request)\n\n        chunked = not (request.body is None or 'Content-Length' in request.headers)\n\n        if isinstance(timeout, tuple):\n            try:\n                connect, read = timeout\n                timeout = TimeoutSauce(connect=connect, read=read)\n            except ValueError as e:\n                # this may raise a string formatting error.\n                err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n                       \"timeout tuple, or a single float to set \"\n                       \"both timeouts to the same value\".format(timeout))\n                raise ValueError(err)\n        else:\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\n\n        try:\n            if not chunked:\n                resp = conn.urlopen(\n                    method=request.method,\n                    url=url,\n                    body=request.body,\n                    headers=request.headers,\n                    redirect=False,\n                    assert_same_host=False,\n                    preload_content=False,\n                    decode_content=False,\n                    retries=Retry(self.max_retries, read=False),\n                    timeout=timeout\n                )\n\n            # Send the request.\n            else:\n                if hasattr(conn, 'proxy_pool'):\n                    conn = conn.proxy_pool\n\n                low_conn = conn._get_conn(timeout=timeout)\n\n                try:\n                    low_conn.putrequest(request.method,\n                                        url,\n                                        skip_accept_encoding=True)\n\n                    for header, value in request.headers.items():\n                        low_conn.putheader(header, value)\n\n                    low_conn.endheaders()\n\n                    for i in request.body:\n                        low_conn.send(hex(len(i))[2:].encode('utf-8'))\n                        low_conn.send(b'\\r\\n')\n                        low_conn.send(i)\n                        low_conn.send(b'\\r\\n')\n                    low_conn.send(b'0\\r\\n\\r\\n')\n\n                    r = low_conn.getresponse()\n                    resp = HTTPResponse.from_httplib(\n                        r,\n                        pool=conn,\n                        connection=low_conn,\n                        preload_content=False,\n                        decode_content=False\n                    )\n                except:\n                    # If we hit any problems here, clean up the connection.\n                    # Then, reraise so that we can handle the actual exception.\n                    low_conn.close()\n                    raise\n                else:\n                    # All is well, return the connection to the pool.\n                    conn._put_conn(low_conn)\n\n        except (ProtocolError, socket.error) as err:\n            raise ConnectionError(err, request=request)\n\n        except MaxRetryError as e:\n            if isinstance(e.reason, ConnectTimeoutError):\n                raise ConnectTimeout(e, request=request)\n\n            raise ConnectionError(e, request=request)\n\n        except _ProxyError as e:\n            raise ProxyError(e)\n\n        except (_SSLError, _HTTPError) as e:\n            if isinstance(e, _SSLError):\n                raise SSLError(e, request=request)\n            elif isinstance(e, ReadTimeoutError):\n                raise ReadTimeout(e, request=request)\n            else:\n                raise\n\n        return self.build_response(request, resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_encodings_from_content(content):\n\n    charset_re = re.compile(r'<meta.*?charset=[\"\\']*(.+?)[\"\\'>]', flags=re.I)\n    pragma_re = re.compile(r'<meta.*?content=[\"\\']*;?charset=(.+?)[\"\\'>]', flags=re.I)\n    xml_re = re.compile(r'^<\\?xml.*?encoding=[\"\\']*(.+?)[\"\\'>]')\n\n    return (charset_re.findall(content) +\n            pragma_re.findall(content) +\n            xml_re.findall(content))", "response": "Returns a list of encodings from given content string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprepares the connection for ssl_wrap_socket.", "response": "def _prepare_conn(self, conn):\n        \"\"\"\n        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`\n        and establish the tunnel if proxy is used.\n        \"\"\"\n\n        if isinstance(conn, VerifiedHTTPSConnection):\n            conn.set_cert(key_file=self.key_file,\n                          cert_file=self.cert_file,\n                          cert_reqs=self.cert_reqs,\n                          ca_certs=self.ca_certs,\n                          assert_hostname=self.assert_hostname,\n                          assert_fingerprint=self.assert_fingerprint)\n            conn.ssl_version = self.ssl_version\n\n        if self.proxy is not None:\n            # Python 2.7+\n            try:\n                set_tunnel = conn.set_tunnel\n            except AttributeError:  # Platform-specific: Python 2.6\n                set_tunnel = conn._set_tunnel\n\n            if sys.version_info <= (2, 6, 4) and not self.proxy_headers:   # Python 2.6.4 and older\n                set_tunnel(self.host, self.port)\n            else:\n                set_tunnel(self.host, self.port, self.proxy_headers)\n\n            # Establish tunnel connection early, because otherwise httplib\n            # would improperly set Host: header to proxy's IP:port.\n            conn.connect()\n\n        return conn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a string describing the probable encoding of a file.", "response": "def description_of(file, name='stdin'):\n    \"\"\"Return a string describing the probable encoding of a file.\"\"\"\n    u = UniversalDetector()\n    for line in file:\n        u.feed(line)\n    u.close()\n    result = u.result\n    if result['encoding']:\n        return '%s: %s with confidence %s' % (name,\n                                              result['encoding'],\n                                              result['confidence'])\n    else:\n        return '%s: no result' % name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dumps(obj, **kwargs):\n    ''' Serialize `obj` to a JSON formatted `str`. Accepts the same arguments\n    as `json` module in stdlib.\n\n    :param obj: a JSON serializable Python object.\n    :param kwargs: all the arguments that `json.dumps <http://docs.python.org/\n                   2/library/json.html#json.dumps>`_ accepts.\n    :raises: commentjson.JSONLibraryException\n    :returns str: serialized string.\n    '''\n\n    try:\n        return json.dumps(obj, **kwargs)\n    except Exception as e:\n        raise JSONLibraryException(e)", "response": "Serialize obj to a JSON formatted string. Accepts the same arguments\n                   as json module in stdlib."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nserialize obj as a JSON formatted stream to fp.", "response": "def dump(obj, fp, **kwargs):\n    ''' Serialize `obj` as a JSON formatted stream to `fp` (a\n    `.write()`-supporting file-like object). Accepts the same arguments as\n    `json` module in stdlib.\n\n    :param obj: a JSON serializable Python object.\n    :param fp: a `.read()`-supporting file-like object containing a JSON\n               document with or without comments.\n    :param kwargs: all the arguments that `json.dump <http://docs.python.org/\n                   2/library/json.html#json.dump>`_ accepts.\n    :raises: commentjson.JSONLibraryException\n    '''\n\n    try:\n        json.dump(obj, fp, **kwargs)\n    except Exception as e:\n        raise JSONLibraryException(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the appropriate piece of chalk for the logging level", "response": "def get_chalk(level):\n    \"\"\"Gets the appropriate piece of chalk for the logging level\n    \"\"\"\n    if level >= logging.ERROR:\n        _chalk = chalk.red\n    elif level >= logging.WARNING:\n        _chalk = chalk.yellow\n    elif level >= logging.INFO:\n        _chalk = chalk.blue\n    elif level >= logging.DEBUG:\n        _chalk = chalk.green\n    else:\n        _chalk = chalk.white\n    return _chalk"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_str(obj):\n    if not isinstance(obj, str) and PY3 and isinstance(obj, bytes):\n        obj = obj.decode('utf-8')\n    return obj if isinstance(obj, string_types) else str(obj)", "response": "Attempts to convert given object to a string object\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the unicode value of the color.", "response": "def get_color(self, value):\n        \"\"\"Helper method to validate and map values used in the instantiation of\n            of the Color object to the correct unicode value.\n        \"\"\"\n        if value in COLOR_SET:\n            value = COLOR_MAP[value]\n        else:\n            try:\n                value = int(value)\n                if value >= 8:\n                    raise ValueError()\n            except ValueError as exc:\n                raise ValueError(\n                    'Colors should either a member of: {} or a positive '\n                    'integer below 8'.format(', '.join(COLOR_NAMES))\n                )\n        return '{}{}'.format(self.PREFIX, value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an infinite iterator that yields each number of the nonce with function f.", "response": "def ctr_counter(nonce, f, start = 0):\n  \"\"\"\n  Return an infinite iterator that starts at `start` and iterates by 1 over\n  integers between 0 and 2^64 - 1 cyclically, returning on each iteration the\n  result of combining each number with `nonce` using function `f`.\n  \n  `nonce` should be an random 64-bit integer that is used to make the counter\n  unique.\n  \n  `f` should be a function that takes two 64-bit integers, the first being the\n  `nonce`, and combines the two in a lossless manner (i.e. xor, addition, etc.)\n  The returned value should be a 64-bit integer.\n  \n  `start` should be a number less than 2^64.\n  \"\"\"\n  for n in range(start, 2**64):\n    yield f(nonce, n)\n  while True:\n    for n in range(0, 2**64):\n      yield f(nonce, n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt_block(self, block):\n    S0, S1, S2, S3 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    \n    try:\n      L, R = self._u4_2_unpack(block)\n    except struct_error:\n      raise ValueError(\"block is not 8 bytes in length\")\n    \n    for p1, p2 in P[:-1]:\n      L ^= p1\n      a, b, c, d = u1_4_unpack(u4_1_pack(L))\n      R ^= (S0[a] + S1[b] ^ S2[c]) + S3[d] & 0xffffffff\n      R ^= p2\n      a, b, c, d = u1_4_unpack(u4_1_pack(R))\n      L ^= (S0[a] + S1[b] ^ S2[c]) + S3[d] & 0xffffffff\n    p_penultimate, p_last = P[-1]\n    return self._u4_2_pack(R ^ p_last, L ^ p_penultimate)", "response": "Encrypts a block of bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt_ecb(self, data):\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    encrypt = self._encrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    try:\n      LR_iter = self._u4_2_iter_unpack(data)\n    except struct_error:\n      raise ValueError(\"data is not a multiple of the block-size in length\")\n    \n    for plain_L, plain_R in LR_iter:\n      yield u4_2_pack(\n        *encrypt(plain_L, plain_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n      )", "response": "Encrypts data using the Electronic Codebook."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt_ecb(self, data):\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    decrypt = self._decrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    try:\n      LR_iter = self._u4_2_iter_unpack(data)\n    except struct_error:\n      raise ValueError(\"data is not a multiple of the block-size in length\")\n    \n    for cipher_L, cipher_R in LR_iter:\n      yield u4_2_pack(\n        *decrypt(cipher_L, cipher_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n      )", "response": "Decrypt the given data using the Electronic Codebook mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencrypts data using the Electronic Codebook with the ECB - CTS mode.", "response": "def encrypt_ecb_cts(self, data):\n    \"\"\"\n    Return an iterator that encrypts `data` using the Electronic Codebook with\n    Ciphertext Stealing (ECB-CTS) mode of operation.\n    \n    ECB-CTS mode can only operate on `data` that is greater than 8 bytes in\n    length.\n    \n    Each iteration, except the last, always returns a block-sized :obj:`bytes`\n    object (i.e. 8 bytes). The last iteration may return a :obj:`bytes` object\n    with a length less than the block-size, if `data` is not a multiple of the\n    block-size in length.\n    \n    `data` should be a :obj:`bytes`-like object that is greater than 8 bytes in\n    length.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \"\"\"\n    data_len = len(data)\n    if data_len <= 8:\n      raise ValueError(\"data is not greater than 8 bytes in length\")\n      \n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    u4_2_pack = self._u4_2_pack\n    u4_2_unpack = self._u4_2_unpack\n    encrypt = self._encrypt\n    \n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n    \n    plain_L, plain_R = u4_2_unpack(data[0:8])\n    cipher_block = u4_2_pack(\n      *encrypt(plain_L, plain_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n    )\n    \n    for plain_L, plain_R in self._u4_2_iter_unpack(data[8:last_block_stop_i]):\n      yield cipher_block\n      cipher_block = u4_2_pack(\n        *encrypt(plain_L, plain_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n      )\n    \n    plain_L, plain_R = u4_2_unpack(\n      data[last_block_stop_i:] + cipher_block[extra_bytes:]\n    )\n    \n    yield u4_2_pack(\n      *encrypt(plain_L, plain_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n    )\n    yield cipher_block[:extra_bytes]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator that decrypts `data` using the Electronic Codebook with Ciphertext Stealing (ECB-CTS) mode of operation. ECB-CTS mode can only operate on `data` that is greater than 8 bytes in length. Each iteration, except the last, always returns a block-sized :obj:`bytes` object (i.e. 8 bytes). The last iteration may return a :obj:`bytes` object with a length less than the block-size, if `data` is not a multiple of the block-size in length. `data` should be a :obj:`bytes`-like object that is greater than 8 bytes in length. If it is not, a :exc:`ValueError` exception is raised.", "response": "def decrypt_ecb_cts(self, data):\n    \"\"\"\n    Return an iterator that decrypts `data` using the Electronic Codebook with\n    Ciphertext Stealing (ECB-CTS) mode of operation.\n    \n    ECB-CTS mode can only operate on `data` that is greater than 8 bytes in\n    length.\n    \n    Each iteration, except the last, always returns a block-sized :obj:`bytes`\n    object (i.e. 8 bytes). The last iteration may return a :obj:`bytes` object\n    with a length less than the block-size, if `data` is not a multiple of the\n    block-size in length.\n    \n    `data` should be a :obj:`bytes`-like object that is greater than 8 bytes in\n    length.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \"\"\"\n    data_len = len(data)\n    if data_len <= 8:\n      raise ValueError(\"data is not greater than 8 bytes in length\")\n      \n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    u4_2_pack = self._u4_2_pack\n    u4_2_unpack = self._u4_2_unpack\n    decrypt = self._decrypt\n    \n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n        \n    cipher_L, cipher_R = u4_2_unpack(data[0:8])\n    plain_block = u4_2_pack(\n      *decrypt(cipher_L, cipher_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n    )\n    \n    for cipher_L, cipher_R in self._u4_2_iter_unpack(data[8:last_block_stop_i]):\n      yield plain_block\n      plain_block = u4_2_pack(\n        *decrypt(cipher_L, cipher_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n      )\n    \n    cipher_L, cipher_R = u4_2_unpack(\n      data[last_block_stop_i:] + plain_block[extra_bytes:]\n    )\n    \n    yield u4_2_pack(\n      *decrypt(cipher_L, cipher_R, P, S1, S2, S3, S4, u4_1_pack, u1_4_unpack)\n    )\n    yield plain_block[:extra_bytes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef encrypt_cbc(self, data, init_vector):\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    encrypt = self._encrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    try:\n      prev_cipher_L, prev_cipher_R = self._u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n    \n    try:\n      LR_iter = self._u4_2_iter_unpack(data)\n    except struct_error:\n      raise ValueError(\"data is not a multiple of the block-size in length\")\n    \n    for plain_L, plain_R in LR_iter:\n      prev_cipher_L, prev_cipher_R = encrypt(\n        prev_cipher_L ^ plain_L,\n        prev_cipher_R ^ plain_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield u4_2_pack(prev_cipher_L, prev_cipher_R)", "response": "Encrypts data using the Cipher - Block Chaining Random Order"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an iterator that decrypts `data` using the Cipher-Block Chaining (CBC) mode of operation. CBC mode can only operate on `data` that is a multiple of the block-size in length. Each iteration returns a block-sized :obj:`bytes` object (i.e. 8 bytes) containing the decrypted bytes of the corresponding block in `data`. `init_vector` is the initialization vector and should be a :obj:`bytes`-like object with exactly 8 bytes. If it is not, a :exc:`ValueError` exception is raised. `data` should be a :obj:`bytes`-like object that is a multiple of the block-size in length (i.e. 8, 16, 32, etc.). If it is not, a :exc:`ValueError` exception is raised.", "response": "def decrypt_cbc(self, data, init_vector):\n    \"\"\"\n    Return an iterator that decrypts `data` using the Cipher-Block Chaining\n    (CBC) mode of operation.\n    \n    CBC mode can only operate on `data` that is a multiple of the block-size\n    in length.\n    \n    Each iteration returns a block-sized :obj:`bytes` object (i.e. 8 bytes)\n    containing the decrypted bytes of the corresponding block in `data`.\n    \n    `init_vector` is the initialization vector and should be a\n    :obj:`bytes`-like object with exactly 8 bytes.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \n    `data` should be a :obj:`bytes`-like object that is a multiple of the\n    block-size in length (i.e. 8, 16, 32, etc.).\n    If it is not, a :exc:`ValueError` exception is raised.\n    \"\"\"\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    decrypt = self._decrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    try:\n      prev_cipher_L, prev_cipher_R = self._u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n    \n    try:\n      LR_iter = self._u4_2_iter_unpack(data)\n    except struct_error:\n      raise ValueError(\"data is not a multiple of the block-size in length\")\n    \n    for cipher_L, cipher_R in LR_iter:\n      L, R = decrypt(\n        cipher_L, cipher_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield u4_2_pack(prev_cipher_L ^ L, prev_cipher_R ^ R)\n      prev_cipher_L = cipher_L\n      prev_cipher_R = cipher_R"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencrypts data using the CBC - CTS mode.", "response": "def encrypt_cbc_cts(self, data, init_vector):\n    \"\"\"\n    Return an iterator that encrypts `data` using the Cipher-Block Chaining\n    with Ciphertext Stealing (CBC-CTS) mode of operation.\n    \n    CBC-CTS mode can only operate on `data` that is greater than 8 bytes in\n    length.\n    \n    Each iteration, except the last, always returns a block-sized :obj:`bytes`\n    object (i.e. 8 bytes). The last iteration may return a :obj:`bytes` object\n    with a length less than the block-size, if `data` is not a multiple of the\n    block-size in length.\n    \n    `data` should be a :obj:`bytes`-like object that is greater than 8 bytes in\n    length.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \n    `init_vector` is the initialization vector and should be a\n    :obj:`bytes`-like object with exactly 8 bytes.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \"\"\"\n    data_len = len(data)\n    if data_len <= 8:\n      raise ValueError(\"data is not greater than 8 bytes in length\")\n    \n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    u4_2_pack = self._u4_2_pack\n    u4_2_unpack = self._u4_2_unpack\n    encrypt = self._encrypt\n    \n    try:\n      prev_cipher_L, prev_cipher_R = u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n      \n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n    \n    plain_L, plain_R = u4_2_unpack(data[0:8])\n    prev_cipher_L, prev_cipher_R = encrypt(\n      plain_L ^ prev_cipher_L,\n      plain_R ^ prev_cipher_R,\n      P, S1, S2, S3, S4,\n      u4_1_pack, u1_4_unpack\n    )\n    cipher_block = u4_2_pack(prev_cipher_L, prev_cipher_R)\n    \n    for plain_L, plain_R in self._u4_2_iter_unpack(data[8:last_block_stop_i]):\n      yield cipher_block\n      prev_cipher_L, prev_cipher_R = encrypt(\n        plain_L ^ prev_cipher_L,\n        plain_R ^ prev_cipher_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      cipher_block = u4_2_pack(prev_cipher_L, prev_cipher_R)\n    \n    P_L, P_R = u4_2_unpack(data[last_block_stop_i:] + bytes(8 - extra_bytes))\n    \n    yield u4_2_pack(\n      *encrypt(\n        prev_cipher_L ^ P_L,\n        prev_cipher_R ^ P_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n    )\n    \n    yield cipher_block[:extra_bytes]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decrypt_cbc_cts(self, data, init_vector):\n    data_len = len(data)\n    if data_len <= 8:\n      raise ValueError(\"data is not greater than 8 bytes in length\")\n    \n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    u4_2_pack = self._u4_2_pack\n    u4_2_unpack = self._u4_2_unpack\n    decrypt = self._decrypt\n    \n    try:\n      prev_cipher_L, prev_cipher_R = u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n      \n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n    last_block_start_i = last_block_stop_i - 8\n    \n    for cipher_L, cipher_R in self._u4_2_iter_unpack(\n      data[0:last_block_start_i]\n    ):\n      L, R = decrypt(\n        cipher_L, cipher_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield u4_2_pack(L ^ prev_cipher_L, R ^ prev_cipher_R)\n      prev_cipher_L = cipher_L\n      prev_cipher_R = cipher_R\n    \n    cipher_L, cipher_R = u4_2_unpack(data[last_block_start_i:last_block_stop_i])\n    L, R = decrypt(\n      cipher_L, cipher_R,\n      P, S1, S2, S3, S4,\n      u4_1_pack, u1_4_unpack\n    )\n    \n    C_L, C_R = u4_2_unpack(data[last_block_stop_i:] + bytes(8 - extra_bytes))\n    \n    Xn = u4_2_pack(L ^ C_L, R ^ C_R)\n    \n    E_L, E_R = u4_2_unpack(data[last_block_stop_i:] + Xn[extra_bytes:])\n    L, R = decrypt(\n      E_L, E_R,\n      P, S1, S2, S3, S4,\n      u4_1_pack, u1_4_unpack\n    )\n    yield u4_2_pack(L ^ prev_cipher_L, R ^ prev_cipher_R)\n     \n    yield Xn[:extra_bytes]", "response": "Decrypt a block of data using the CBC - CTS mode."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nencrypt data using the Propagating Cipher - Block algorithm.", "response": "def encrypt_pcbc(self, data, init_vector):\n    \"\"\"\n    Return an iterator that encrypts `data` using the Propagating Cipher-Block\n    Chaining (PCBC) mode of operation.\n    \n    PCBC mode can only operate on `data` that is a multiple of the block-size\n    in length.\n    \n    Each iteration returns a block-sized :obj:`bytes` object (i.e. 8 bytes)\n    containing the encrypted bytes of the corresponding block in `data`.\n    \n    `init_vector` is the initialization vector and should be a\n    :obj:`bytes`-like object with exactly 8 bytes.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \n    `data` should be a :obj:`bytes`-like object that is a multiple of the\n    block-size in length (i.e. 8, 16, 32, etc.).\n    If it is not, a :exc:`ValueError` exception is raised.\n    \"\"\"\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    encrypt = self._encrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    try:\n      init_L, init_R = self._u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n    \n    try:\n      LR_iter = self._u4_2_iter_unpack(data)\n    except struct_error:\n      raise ValueError(\"data is not a multiple of the block-size in length\")\n    \n    for plain_L, plain_R in LR_iter:\n      cipher_L, cipher_R = encrypt(\n        init_L ^ plain_L, init_R ^ plain_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield u4_2_pack(cipher_L, cipher_R)\n      init_L = plain_L ^ cipher_L\n      init_R = plain_R ^ cipher_R"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nencrypts data using the Cipher Feedback CFB mode.", "response": "def encrypt_cfb(self, data, init_vector):\n    \"\"\"\n    Return an iterator that encrypts `data` using the Cipher Feedback (CFB)\n    mode of operation.\n    \n    CFB mode can operate on `data` of any length.\n    \n    Each iteration, except the last, always returns a block-sized :obj:`bytes`\n    object (i.e. 8 bytes). The last iteration may return a :obj:`bytes` object\n    with a length less than the block-size, if `data` is not a multiple of the\n    block-size in length.\n    \n    `init_vector` is the initialization vector and should be a\n    :obj:`bytes`-like object with exactly 8 bytes.\n    If it is not, a :exc:`ValueError` exception is raised.\n    \n    `data` should be a :obj:`bytes`-like object (of any length).\n    \"\"\"\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    encrypt = self._encrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    data_len = len(data)\n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n    \n    try:\n      prev_cipher_L, prev_cipher_R = self._u4_2_unpack(init_vector)\n    except struct_error:\n      raise ValueError(\"initialization vector is not 8 bytes in length\")\n    \n    for plain_L, plain_R in self._u4_2_iter_unpack(\n      data[0:last_block_stop_i]\n    ):\n      prev_cipher_L, prev_cipher_R = encrypt(\n        prev_cipher_L, prev_cipher_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )      \n      prev_cipher_L ^= plain_L\n      prev_cipher_R ^= plain_R\n      yield u4_2_pack(prev_cipher_L, prev_cipher_R)\n      \n    if extra_bytes:\n      yield bytes(\n        b ^ n for b, n in zip(\n          data[last_block_stop_i:],\n          u4_2_pack(\n            *encrypt(\n              prev_cipher_L, prev_cipher_R,\n              P, S1, S2, S3, S4,\n              u4_1_pack, u1_4_unpack\n            )\n          )\n        )\n      )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encrypt_ctr(self, data, counter):\n    S1, S2, S3, S4 = self.S\n    P = self.P\n    \n    u4_1_pack = self._u4_1_pack\n    u1_4_unpack = self._u1_4_unpack\n    encrypt = self._encrypt\n    \n    u4_2_pack = self._u4_2_pack\n    \n    u4_2_unpack = self._u4_2_unpack\n    u8_1_pack = self._u8_1_pack\n    \n    data_len = len(data)\n    extra_bytes = data_len % 8\n    last_block_stop_i = data_len - extra_bytes\n    \n    for (plain_L, plain_R), counter_n in zip(\n      self._u4_2_iter_unpack(data[0:last_block_stop_i]),\n      counter\n    ):\n      try:\n        counter_L, counter_R = u4_2_unpack(u8_1_pack(counter_n))\n      except struct_error:\n        raise ValueError(\"integer in counter is not less than 2^64\")\n      \n      counter_L, counter_R = encrypt(\n        counter_L, counter_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield u4_2_pack(plain_L ^ counter_L, plain_R ^ counter_R)\n      \n    if extra_bytes:\n      try:\n        counter_L, counter_R = u4_2_unpack(u8_1_pack(next(counter)))\n      except struct_error:\n        raise ValueError(\"integer in counter is not less than 2^64\")\n      \n      counter_L, counter_R = encrypt(\n        counter_L, counter_R,\n        P, S1, S2, S3, S4,\n        u4_1_pack, u1_4_unpack\n      )\n      yield bytes(\n        b ^ n for b, n in zip(\n          data[last_block_stop_i:],\n          u4_2_pack(counter_L, counter_R)\n        )\n      )", "response": "Encrypts data using the Counter mode of the encryption algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert(self, im):\n        _im = im\n        if self.image_property:\n            _im = self.image_property.convert(im)\n\n        return _im", "response": "Convert the image into a new image object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shuffle(self, overwrite=False):\n\n        if overwrite:\n            shuffled = self.path\n        else:\n            shuffled = FileAPI.add_ext_name(self.path, \"_shuffled\")\n\n        lines = open(self.path).readlines()\n        random.shuffle(lines)\n        open(shuffled, \"w\").writelines(lines)\n        self.path = shuffled", "response": "This method creates a new shuffled file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef multiple_files_count_reads_in_windows(bed_files, args):\n    # type: (Iterable[str], Namespace) -> OrderedDict[str, List[pd.DataFrame]]\n    \"\"\"Use count_reads on multiple files and store result in dict.\n\n    Untested since does the same thing as count reads.\"\"\"\n\n    bed_windows = OrderedDict() # type: OrderedDict[str, List[pd.DataFrame]]\n    for bed_file in bed_files:\n        logging.info(\"Binning \" + bed_file)\n        if \".bedpe\" in bed_file:\n            chromosome_dfs = count_reads_in_windows_paired_end(bed_file, args)\n        else:\n            chromosome_dfs = count_reads_in_windows(bed_file, args)\n        bed_windows[bed_file] = chromosome_dfs\n\n    return bed_windows", "response": "Use count_reads on multiple files and store result in dict.\n    Untested since does the same thing as count reads."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmerging files in a list of windows into a single count .", "response": "def _merge_files(windows, nb_cpu):\n    # type: (Iterable[pd.DataFrame], int) -> pd.DataFrame\n    \"\"\"Merge lists of chromosome bin df chromosome-wise.\n\n    windows is an OrderedDict where the keys are files, the values are lists of\n    dfs, one per chromosome.\n\n    Returns a list of dataframes, one per chromosome, with the collective count\n    per bin for all files.\n\n    TODO: is it faster to merge all in one command?\n    \"\"\"\n\n    # windows is a list of chromosome dfs per file\n    windows = iter(windows)  # can iterate over because it is odict_values\n    merged = next(windows)\n\n    # if there is only one file, the merging is skipped since the windows is used up\n    for chromosome_dfs in windows:\n        # merge_same_files merges the chromosome files in parallel\n        merged = merge_same_files(merged, chromosome_dfs, nb_cpu)\n\n    return merged"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a cumulative distribution of the island expectations.", "response": "def generate_cumulative_dist(island_expectations_d, total_length):\n    # type: (Dict[int, float], int) -> float\n    \"\"\"\n    Generate cumulative distribution: a list of tuples (bins, hist).\n    \"\"\"\n\n    cumulative = [0.0] * (total_length + 1)\n    partial_sum = 0.0\n\n    island_expectations = []\n    for i in range(len(cumulative)):\n        if i in island_expectations_d:\n            island_expectations.append(island_expectations_d[i])\n        else:\n            island_expectations.append(0)\n\n    for index in range(1, len(island_expectations) + 1):\n        complimentary = len(island_expectations) - index\n        partial_sum += island_expectations[complimentary]\n        cumulative[complimentary] = partial_sum\n\n    # move to function call\n    for index in range(len(cumulative)):\n        if cumulative[index] <= E_VALUE:\n            score_threshold = index * BIN_SIZE\n            break\n\n    return score_threshold"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef py2round(value):\n    if value > 0:\n        return float(floor(float(value)+0.5))\n    else:\n        return float(ceil(float(value)-0.5))", "response": "Round values as in Python 2 for Python 3 compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting equivalent discrete intervals to different representations.", "response": "def canonicalize(interval, lower_inc=True, upper_inc=False):\n    \"\"\"\n    Convert equivalent discrete intervals to different representations.\n    \"\"\"\n    if not interval.discrete:\n        raise TypeError('Only discrete ranges can be canonicalized')\n\n    if interval.empty:\n        return interval\n\n    lower, lower_inc = canonicalize_lower(interval, lower_inc)\n    upper, upper_inc = canonicalize_upper(interval, upper_inc)\n\n    return interval.__class__(\n        [lower, upper],\n        lower_inc=lower_inc,\n        upper_inc=upper_inc,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef glb(self, other):\n        return self.__class__(\n            [\n                min(self.lower, other.lower),\n                min(self.upper, other.upper)\n            ],\n            lower_inc=self.lower_inc if self < other else other.lower_inc,\n            upper_inc=self.upper_inc if self > other else other.upper_inc,\n        )", "response": "Return the greatest lower bound for given intervals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the least upper bound for given intervals.", "response": "def lub(self, other):\n        \"\"\"\n        Return the least upper bound for given intervals.\n\n        :param other: AbstractInterval instance\n        \"\"\"\n        return self.__class__(\n            [\n                max(self.lower, other.lower),\n                max(self.upper, other.upper),\n            ],\n            lower_inc=self.lower_inc if self < other else other.lower_inc,\n            upper_inc=self.upper_inc if self > other else other.upper_inc,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_connected(self, other):\n        return self.upper > other.lower and other.upper > self.lower or (\n            self.upper == other.lower and (self.upper_inc or other.lower_inc)\n        ) or (\n            self.lower == other.upper and (self.lower_inc or other.upper_inc)\n        )", "response": "Returns True if the two sets of species are connected to the other."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_enriched_threshold(average_window_readcount):\n    # type: (float) -> int\n    \"\"\"\n    Computes the minimum number of tags required in window for an island to be enriched.\n    \"\"\"\n\n    current_threshold, survival_function = 0, 1\n    for current_threshold in count(start=0, step=1):\n        survival_function -= poisson.pmf(current_threshold,\n                                         average_window_readcount)\n        if survival_function <= WINDOW_P_VALUE:\n            break\n\n    island_enriched_threshold = current_threshold + 1\n\n    return island_enriched_threshold", "response": "Computes the minimum number of tags required in a window for an island to be enriched."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _factln(num):\n    # type: (int) -> float\n    \"\"\"\n    Computes logfactorial regularly for tractable numbers, uses Ramanujans approximation otherwise.\n    \"\"\"\n\n    if num < 20:\n        log_factorial = log(factorial(num))\n    else:\n        log_factorial = num * log(num) - num + log(num * (1 + 4 * num * (\n            1 + 2 * num))) / 6.0 + log(pi) / 2\n\n    return log_factorial", "response": "Returns the logfactorial of the given tractable number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_new_enriched_bins_matrixes(region_files, dfs, bin_size):\n\n    \"\"\"Add enriched bins based on bed files.\n\n    There is no way to find the correspondence between region file and matrix\n    file, but it does not matter.\"\"\"\n\n    dfs = _remove_epic_enriched(dfs)\n\n    names = [\"Enriched_\" + os.path.basename(r) for r in region_files]\n\n    regions = region_files_to_bins(region_files, names, bin_size)\n\n    new_dfs = OrderedDict()\n\n    assert len(regions.columns) == len(dfs)\n    for region, (n, df) in zip(regions, dfs.items()):\n\n        region_col = regions[region]\n\n        df = df.join(region_col, how=\"outer\").fillna(0)\n\n        new_dfs[n] = df\n\n    return new_dfs", "response": "Add enriched bins based on bed files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges data from two strands into strand - agnostic counts.", "response": "def merge_chromosome_dfs(df_tuple):\n    # type: (Tuple[pd.DataFrame, pd.DataFrame]) -> pd.DataFrame\n    \"\"\"Merges data from the two strands into strand-agnostic counts.\"\"\"\n\n    plus_df, minus_df = df_tuple\n    index_cols = \"Chromosome Bin\".split()\n    count_column = plus_df.columns[0]\n\n    if plus_df.empty:\n        return return_other(minus_df, count_column, index_cols)\n    if minus_df.empty:\n        return return_other(plus_df, count_column, index_cols)\n\n    # sum duplicate bins\n    # TODO: why are there duplicate bins here in the first place?\n    plus_df = plus_df.groupby(index_cols).sum()\n    minus_df = minus_df.groupby(index_cols).sum()\n\n    # first sum the two bins from each strand\n    df = pd.concat([plus_df, minus_df], axis=1).fillna(0).sum(axis=1)\n    df = df.reset_index().sort_values(by=\"Bin\")\n\n    df.columns = [\"Chromosome\", \"Bin\", count_column]\n\n    df = df.sort_values([\"Chromosome\", \"Bin\"])\n    df[[\"Bin\", count_column]] = df[[\"Bin\", count_column]].astype(int32)\n    df = df[[count_column, \"Chromosome\", \"Bin\"]]\n    return df.reset_index(drop=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all reads that were shifted outside of the genome endpoints.", "response": "def remove_out_of_bounds_bins(df, chromosome_size):\n    # type: (pd.DataFrame, int) -> pd.DataFrame\n    \"\"\"Remove all reads that were shifted outside of the genome endpoints.\"\"\"\n\n    # The dataframe is empty and contains no bins out of bounds\n    if \"Bin\" not in df:\n        return df\n\n    df = df.drop(df[df.Bin > chromosome_size].index)\n\n    return df.drop(df[df.Bin < 0].index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all reads that were shifted outside of the genome endpoints.", "response": "def remove_bins_with_ends_out_of_bounds(df, chromosome_size,\n                                        window_size):\n    # type: (pd.DataFrame, int, int) -> pd.DataFrame\n    \"\"\"Remove all reads that were shifted outside of the genome endpoints.\"\"\"\n\n    # The dataframe is empty and contains no bins out of bounds\n\n    # print(df.head(2))\n    # print(chromosome_size)\n    # print(window_size)\n    out_of_bounds = df[df.index.get_level_values(\"Bin\") + window_size >\n                       chromosome_size].index\n    # print(len(out_of_bounds))\n    df = df.drop(out_of_bounds)\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate bigwigs from matrix.", "response": "def create_log2fc_bigwigs(matrix, outdir, args):\n    # type: (pd.DataFrame, str, Namespace) -> None\n    \"\"\"Create bigwigs from matrix.\"\"\"\n\n    call(\"mkdir -p {}\".format(outdir), shell=True)\n    genome_size_dict = args.chromosome_sizes\n\n    outpaths = []\n    for bed_file in matrix[args.treatment]:\n        outpath = join(outdir, splitext(basename(bed_file))[0] + \"_log2fc.bw\")\n        outpaths.append(outpath)\n\n    data = create_log2fc_data(matrix, args)\n\n    Parallel(n_jobs=args.number_cores)(delayed(_create_bigwig)(bed_column, outpath, genome_size_dict) for outpath, bed_column in zip(outpaths, data))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd the island expectations to the island_expectations dictionary.", "response": "def add_to_island_expectations_dict(average_window_readcount,\n                                    current_max_scaled_score,\n                                    island_eligibility_threshold,\n                                    island_expectations, gap_contribution):\n    # type: ( float, int, float, Dict[int, float], float) -> Dict[int, float]\n    \"\"\"Can probably be heavily optimized.\n    Time required to run can be seen from logging info.\"\"\"\n\n    scaled_score = current_max_scaled_score + E_VALUE\n    for index in range(current_max_scaled_score + 1, scaled_score + 1):\n        island_expectation = 0.0\n        i = island_eligibility_threshold  #i is the number of tags in the added window\n\n        current_island = int(round(index - compute_window_score(\n            i, average_window_readcount) / BIN_SIZE))\n\n        while (current_island >= 0):\n\n            if current_island in island_expectations:\n                island_expectation += _poisson(\n                    i, average_window_readcount) * island_expectations[\n                        current_island]\n            i += 1\n            current_island = int(round(index - compute_window_score(\n                i, average_window_readcount) / BIN_SIZE))\n        island_expectation *= gap_contribution\n        if island_expectation:\n            island_expectations[index] = island_expectation\n\n    return island_expectations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute the effective genome size for a single file.", "response": "def effective_genome_size(fasta, read_length, nb_cores, tmpdir=\"/tmp\"):\n    # type: (str, int, int, str) -> None\n    \"\"\"Compute effective genome size for genome.\"\"\"\n\n    idx = Fasta(fasta)\n\n    genome_length = sum([len(c) for c in idx])\n\n    logging.info(\"Temporary directory: \" + tmpdir)\n    logging.info(\"File analyzed: \" + fasta)\n    logging.info(\"Genome length: \" + str(genome_length))\n    print(\"File analyzed: \", fasta)\n    print(\"Genome length: \", genome_length)\n\n    chromosomes = \", \".join([c.name for c in idx])\n\n    if \"_\" in chromosomes:\n        print(\"Warning. The following chromosomes are part of your genome:\\n\",\n              chromosomes.replace(\">\", \"\") + \"\\n\",\n              file=sys.stderr)\n        print(\n            \"You probably want to remove all chromosomes in your fasta containing '_' for the effective genome size computation to be accurate.\",\n            file=sys.stderr)\n\n    # if tmpdir is None:\n    #     try:\n    #         tmpdir = os.environ['TMPDIR']\n    #     except KeyError:\n    #         tmpdir = '/tmp'\n    output_file = os.path.join(tmpdir, '{1}.jf'.format(read_length,\n                                                       basename(fasta)))\n    atexit.register(\n        lambda: call(\"rm {output_file}\".format(output_file=output_file), shell=True))\n\n    call(\n        \"jellyfish count -t {nb_cores} -m {read_length} -s {genome_length} -L 1 -U 1 --out-counter-len 1 --counter-len 1 {fasta} -o {output_file}\".format(\n            **vars()),\n        shell=True)\n\n    stats = check_output(\"jellyfish stats {output_file}\".format(\n        output_file=output_file),\n                         shell=True)\n\n    unique_kmers = int(stats.split()[1])\n\n    effective_genome_size = unique_kmers / genome_length\n\n    logging.info(\"Number unique {read_length}-mers: \".format(\n        read_length=read_length) + str(unique_kmers))\n    logging.info(\"Effective genome size: \" + str(effective_genome_size))\n    print(\"Number unique {read_length}-mers: \".format(read_length=read_length),\n          unique_kmers)\n    print(\"Effective genome size: \", effective_genome_size)\n    assert effective_genome_size < 1, \"Something wrong happened, effective genome size over 1!\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_matrixes(chip, input, df, args):\n    # type: (Iterable[pd.DataFrame], Iterable[pd.DataFrame], pd.DataFrame, Namespace) -> List[pd.DataFrame]\n    \"Creates matrixes which can be written to file as is (matrix) or as bedGraph.\"\n\n    genome = args.chromosome_sizes\n\n    chip = put_dfs_in_chromosome_dict(chip)\n    input = put_dfs_in_chromosome_dict(input)\n    all_chromosomes = natsorted(set(list(chip.keys()) + list(input.keys())))\n\n    # print(\"df1\\n\", df, file=sys.stderr)\n    islands = enriched_bins(df, args)\n    # print(\"islands1\\n\", islands, file=sys.stderr)\n\n\n    logging.info(\"Creating matrixes from count data.\")\n    dfms = Parallel(n_jobs=args.number_cores)(delayed(_create_matrixes)(\n        chromosome, chip, input, islands, genome[chromosome],\n        args.window_size) for chromosome in all_chromosomes)\n\n    return dfms", "response": "Creates matrixes which can be written to file as is ( matrix ) or as bedGraph."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds the enriched bins in a df.", "response": "def get_island_bins(df, window_size, genome, args):\n    # type: (pd.DataFrame, int, str, Namespace) -> Dict[str, Set[int]]\n    \"\"\"Finds the enriched bins in a df.\"\"\"\n\n    # need these chromos because the df might not have islands in all chromos\n    chromosomes = natsorted(list(args.chromosome_sizes))\n\n    chromosome_island_bins = {} # type: Dict[str, Set[int]]\n    df_copy = df.reset_index(drop=False)\n    for chromosome in chromosomes:\n        cdf = df_copy.loc[df_copy.Chromosome == chromosome]\n        if cdf.empty:\n            chromosome_island_bins[chromosome] = set()\n        else:\n            island_starts_ends = zip(cdf.Start.values.tolist(),\n                                     cdf.End.values.tolist())\n            island_bins = chain(*[range(\n                int(start), int(end), window_size)\n                                  for start, end in island_starts_ends])\n            chromosome_island_bins[chromosome] = set(island_bins)\n\n    return chromosome_island_bins"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates genome size dict from string containing data.", "response": "def create_genome_size_dict(genome):\n    # type: (str) -> Dict[str,int]\n    \"\"\"Creates genome size dict from string containing data.\"\"\"\n\n    size_file = get_genome_size_file(genome)\n    size_lines = open(size_file).readlines()\n\n    size_dict = {}\n    for line in size_lines:\n        genome, length = line.split()\n        size_dict[genome] = int(length)\n\n    return size_dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_score_threshold(average_window_readcount,\n                            island_enriched_threshold,\n                            gap_contribution, boundary_contribution,\n                            genome_length_in_bins):\n    # type: (float, int, float, float, float) -> float\n    \"\"\"\n    What does island_expectations do?\n    \"\"\"\n\n    required_p_value = poisson.pmf(island_enriched_threshold,\n                                   average_window_readcount)\n\n    prob = boundary_contribution * required_p_value\n\n    score = -log(required_p_value)\n\n    current_scaled_score = int(round(score / BIN_SIZE))\n\n    island_expectations_d = {}  # type: Dict[int, float]\n    island_expectations_d[current_scaled_score] = prob * genome_length_in_bins\n    island_expectations_d[\n        0] = boundary_contribution * genome_length_in_bins / gap_contribution\n\n    current_max_scaled_score = current_scaled_score\n\n    interval = int(1 / BIN_SIZE)\n    partial_cumu = 0.0\n    logging.info(\"Finding the score required to consider an island enriched.\")\n    while (partial_cumu > E_VALUE_THRESHOLD or partial_cumu < 1e-100):\n\n        current_scaled_score += interval\n        current_max_scaled_score = current_scaled_score - interval\n        # logging.debug(island_expectations_d)\n\n        if current_scaled_score > current_max_scaled_score:\n\n            # logging.debug(island_expectations_d)\n            island_expectations_d = add_to_island_expectations_dict(\n                average_window_readcount, current_max_scaled_score,\n                island_enriched_threshold, island_expectations_d,\n                gap_contribution)\n            partial_cumu = 0.0001\n            current_max_scaled_score += 1000\n\n            if max(island_expectations_d) > interval:\n                partial_cumu = sum(\n                    [val\n                     for idx, val in island_expectations_d.items()\n                     if idx > current_max_scaled_score - interval])\n            else:\n                partial_cumu = sum(island_expectations_d.values())\n\n    logging.debug(\"Computing cumulative distribution.\")\n    score_threshold = generate_cumulative_dist(island_expectations_d,\n                                               current_max_scaled_score + 1)\n    logging.info(\"Enriched score threshold for islands: \" + str(\n        score_threshold))\n    return score_threshold", "response": "Compute the score of an island enriched by the average_window_readcount."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nestimate length of reads based on 10000 first.", "response": "def find_readlength(args):\n    # type: (Namespace) -> int\n    \"\"\"Estimate length of reads based on 10000 first.\"\"\"\n\n    try:\n        bed_file = args.treatment[0]\n    except AttributeError:\n        bed_file = args.infiles[0]\n\n    filereader = \"cat \"\n    if bed_file.endswith(\".gz\") and search(\"linux\", platform, IGNORECASE):\n        filereader = \"zcat \"\n    elif bed_file.endswith(\".gz\") and search(\"darwin\", platform, IGNORECASE):\n        filereader = \"gzcat \"\n    elif bed_file.endswith(\".bz2\"):\n        filereader = \"bzgrep \"\n\n    command = filereader + \"{} | head -10000\".format(bed_file)\n    output = check_output(command, shell=True)\n\n    df = pd.read_table(\n        BytesIO(output),\n        header=None,\n        usecols=[1, 2],\n        sep=\"\\t\",\n        names=[\"Start\", \"End\"])\n\n    readlengths = df.End - df.Start\n    mean_readlength = readlengths.mean()\n    median_readlength = readlengths.median()\n    max_readlength = readlengths.max()\n    min_readlength = readlengths.min()\n\n    logging.info((\n        \"Used first 10000 reads of {} to estimate a median read length of {}\\n\"\n        \"Mean readlength: {}, max readlength: {}, min readlength: {}.\").format(\n            bed_file, median_readlength, mean_readlength, max_readlength,\n            min_readlength))\n\n    return median_readlength"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_closest_readlength(estimated_readlength):\n    # type: (int) -> int\n    \"\"\"Find the predefined readlength closest to the estimated readlength.\n\n    In the case of a tie, choose the shortest readlength.\"\"\"\n\n    readlengths = [36, 50, 75, 100]\n    differences = [abs(r - estimated_readlength) for r in readlengths]\n    min_difference = min(differences)\n    index_of_min_difference = [i\n                               for i, d in enumerate(differences)\n                               if d == min_difference][0]\n\n    return readlengths[index_of_min_difference]", "response": "Find the predefined readlength closest to the estimated readlength."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse hyphen ranges such as: 2 - 5, -2 - -1, -3 - 5", "response": "def parse_hyphen_range(self, value):\n        \"\"\"\n        Parse hyphen ranges such as: 2 - 5, -2 - -1, -3 - 5\n        \"\"\"\n        values = value.strip().split('-')\n        values = list(map(strip, values))\n        if len(values) == 1:\n            lower = upper = value.strip()\n        elif len(values) == 2:\n            lower, upper = values\n            if lower == '':\n                # Parse range such as '-3'\n                upper = '-' + upper\n                lower = upper\n        else:\n            if len(values) > 4:\n                raise IntervalException(\n                    'Unknown interval format given.'\n                )\n            values_copy = []\n            for key, value in enumerate(values):\n                if value != '':\n                    try:\n                        if values[key - 1] == '':\n                            value = '-' + value\n                    except IndexError:\n                        pass\n                    values_copy.append(value)\n            lower, upper = values_copy\n\n        return [lower, upper], True, True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_version(output):\n    for x in output.splitlines():\n        match = VERSION_PATTERN.match(x)\n        if match:\n            return match.group('version').strip()\n    return None", "response": "Parses the output of the snort run and returns the version string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the output of the snort alert command and yields any alerts that are found in the output.", "response": "def parse_alert(output):\n    \"\"\"\n    Parses the supplied output and yields any alerts.\n\n    Example alert format:\n    01/28/14-22:26:04.885446  [**] [1:1917:11] INDICATOR-SCAN UPnP service discover attempt [**] [Classification: Detection of a Network Scan] [Priority: 3] {UDP} 10.1.1.132:58650 -> 239.255.255.250:1900\n\n    :param output: A string containing the output of running snort\n    :returns: Generator of snort alert dicts\n    \"\"\"\n    for x in output.splitlines():\n        match = ALERT_PATTERN.match(x)\n        if match:\n            rec = {'timestamp': datetime.strptime(match.group('timestamp'),\n                                                  '%m/%d/%y-%H:%M:%S.%f'),\n                   'sid': int(match.group('sid')),\n                   'revision': int(match.group('revision')),\n                   'priority': int(match.group('priority')),\n                   'message': match.group('message'),\n                   'source': match.group('src'),\n                   'destination': match.group('dest'),\n                   'protocol': match.group('protocol'),\n                   }\n            if match.group('classtype'):\n                rec['classtype'] = match.group('classtype')\n            yield rec"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the commandline to run snort on the given pcap file", "response": "def _snort_cmd(self, pcap):\n        \"\"\"\n        Given a pcap filename, get the commandline to run.\n\n        :param pcap: Pcap filename to scan\n        :returns: list of snort command args to scan supplied pcap file\n        \"\"\"\n        cmdline = \"'{0}' -A console -N -y -c '{1}' {2} -r '{3}'\" \\\n            .format(self.conf['path'], self.conf['config'],\n                    self.conf['extra_args'] or '', pcap)\n        # can't seem to capture stderr from snort on windows\n        # unless launched via cmd shell\n        if 'nt' in os.name:\n            cmdline = \"cmd.exe /c \" + cmdline\n        return shlex.split(cmdline)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(self, pcap):\n        proc = Popen(self._snort_cmd(pcap), stdout=PIPE,\n                     stderr=PIPE, universal_newlines=True)\n        stdout, stderr = proc.communicate()\n        if proc.returncode != 0:\n            raise Exception(\"\\n\".join([\"Execution failed return code: {0}\" \\\n                                .format(proc.returncode), stderr or \"\"]))\n\n        return (parse_version(stderr),\n                [ x for x in parse_alert(stdout) ])", "response": "Runs snort against the supplied pcap file and returns a tuple of version and list of alerts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the commandline to run for a specific pcap file.", "response": "def _suri_cmd(self, pcap, logs):\n        \"\"\"\n        Given a pcap filename, get the commandline to run.\n\n        :param pcap: Pcap filename to scan\n        :param logs: Output directory for logs\n        :returns: list of command args to scan supplied pcap file\n        \"\"\"\n        cmdline = \"'{0}' -c '{1}' -l '{2}' {3} -r '{4}'\" \\\n            .format(self.conf['path'], self.conf['config'],\n                    logs, self.conf['extra_args'] or '', pcap)\n        # can't seem to capture stderr on windows\n        # unless launched via cmd shell\n        if 'nt' in os.name:\n            cmdline = \"cmd.exe /c \" + cmdline\n        return shlex.split(cmdline)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns suricata against the supplied pcap file and returns a tuple of version and list of alerts that were found.", "response": "def run(self, pcap):\n        \"\"\"\n        Runs suricata against the supplied pcap.\n\n        :param pcap: Filepath to pcap file to scan\n        :returns: tuple of version, list of alerts\n        \"\"\"\n        tmpdir = None\n        try:\n            tmpdir = tempfile.mkdtemp(prefix='tmpsuri')\n            proc = Popen(self._suri_cmd(pcap, tmpdir), stdout=PIPE,\n                     stderr=PIPE, universal_newlines=True)\n            stdout, stderr = proc.communicate()\n            if proc.returncode != 0:\n                raise Exception(\"\\n\".join([\"Execution failed return code: {0}\" \\\n                                .format(proc.returncode), stderr or \"\"]))\n\n            with open(os.path.join(tmpdir, 'fast.log')) as tmp:\n                return (parse_version(stdout),\n                    [ x for x in parse_alert(tmp.read()) ])\n        finally:\n            if tmpdir:\n                shutil.rmtree(tmpdir)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef analyse_pcap(infile, filename):\n    tmp = tempfile.NamedTemporaryFile(suffix=\".pcap\", delete=False)\n    m = hashlib.md5()\n    results = {'filename': filename,\n               'status': 'Failed',\n               'apiversion': __version__,\n               }\n    try:\n        size = 0\n        while True:\n            buf = infile.read(16384)\n            if not buf: break\n            tmp.write(buf)\n            size += len(buf)\n            m.update(buf)\n        tmp.close()\n        results['md5'] = m.hexdigest()\n        results['filesize'] = size\n        results.update(runner.run(tmp.name))\n    except OSError as ex:\n        results['stderr'] = str(ex)\n    finally:\n        os.remove(tmp.name)\n    return results", "response": "Run IDS across the supplied file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef submit_and_render():\n    data = request.files.file\n    template = env.get_template(\"results.html\")\n    if not data:\n        pass\n    results = analyse_pcap(data.file, data.filename)\n    results.update(base)\n    return template.render(results)", "response": "Blocking POST handler for file submission and returns rendered html."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nblock POST handler for file submission.", "response": "def api_submit():\n    \"\"\"\n    Blocking POST handler for file submission.\n    Runs snort on supplied file and returns results as json text.\n    \"\"\"\n    data = request.files.file\n    response.content_type = 'application/json'\n    if not data or not hasattr(data, 'file'):\n        return json.dumps({\"status\": \"Failed\", \"stderr\": \"Missing form params\"})\n    return json.dumps(analyse_pcap(data.file, data.filename), default=jsondate, indent=4)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the duration in seconds since start or end.", "response": "def duration(start, end=None):\n    \"\"\"\n    Returns duration in seconds since supplied time.\n    Note: time_delta.total_seconds() only available in python 2.7+\n\n    :param start: datetime object\n    :param end: Optional end datetime, None = now\n    :returns: Seconds as decimal since start\n    \"\"\"\n    if not end:\n        end = datetime.now()\n    td = end - start\n    return (td.microseconds + (td.seconds + td.days * 24 * 3600) * 1000000) \\\n        / 1000000.0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_pcap(pcap):\n    with open(pcap, 'rb') as tmp:\n        header = tmp.read(4)\n        # check for both big/little endian\n        if header == b\"\\xa1\\xb2\\xc3\\xd4\" or \\\n           header == b\"\\xd4\\xc3\\xb2\\xa1\":\n            return True\n        return False", "response": "Simple test for magic bytes in supplied file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the specified IDS runner.", "response": "def _run_ids(runner, pcap):\n    \"\"\"\n    Runs the specified IDS runner.\n\n    :param runner: Runner instance to use\n    :param pcap: File path to pcap for analysis\n    :returns: dict of run metadata/alerts\n    \"\"\"\n    run = {'name': runner.conf.get('name'),\n           'module': runner.conf.get('module'),\n           'ruleset': runner.conf.get('ruleset', 'default'),\n           'status': STATUS_FAILED,\n           }\n    try:\n        run_start = datetime.now()\n        version, alerts = runner.run(pcap)\n        run['version'] = version or 'Unknown'\n        run['status'] = STATUS_SUCCESS\n        run['alerts'] = alerts\n    except Exception as ex:\n        run['error'] = str(ex)\n    finally:\n        run['duration'] = duration(run_start)\n    return run"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(pcap):\n    start = datetime.now()\n    errors = []\n    status = STATUS_FAILED\n    analyses = []\n    pool = ThreadPool(MAX_THREADS)\n    try:\n        if not is_pcap(pcap):\n            raise Exception(\"Not a valid pcap file\")\n\n        runners = []\n        for conf in Config().modules.values():\n            runner = registry.get(conf['module'])\n            if not runner:\n                raise Exception(\"No module named: '{0}' found registered\"\n                                .format(conf['module']))\n            runners.append(runner(conf))\n        # launch via worker pool\n        analyses = [ pool.apply_async(_run_ids, (runner, pcap)) for runner in runners ]\n        analyses = [ x.get() for x in analyses ]\n        # were all runs successful?\n        if all([ x['status'] == STATUS_SUCCESS for x in analyses ]):\n            status = STATUS_SUCCESS\n        # propagate any errors to the main list\n        for run in [ x for x in analyses if x['status'] != STATUS_SUCCESS ]:\n            errors.append(\"Failed to run {0}: {1}\".format(run['name'], run['error']))\n    except Exception as ex:\n        errors.append(str(ex))\n\n    return {'start': start,\n            'duration': duration(start),\n            'status': status,\n            'analyses': analyses,\n            'errors': errors,\n            }", "response": "Runs all configured IDS instances against the supplied pcap file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_up_pool_config(self):\n    '''\n    Helper to configure pool options during DatabaseWrapper initialization.\n    '''\n    self._max_conns = self.settings_dict['OPTIONS'].get('MAX_CONNS', pool_config_defaults['MAX_CONNS'])\n    self._min_conns = self.settings_dict['OPTIONS'].get('MIN_CONNS', self._max_conns)\n                \n    self._test_on_borrow = self.settings_dict[\"OPTIONS\"].get('TEST_ON_BORROW', \n                                                             pool_config_defaults['TEST_ON_BORROW'])\n    if self._test_on_borrow:\n        self._test_on_borrow_query = self.settings_dict[\"OPTIONS\"].get('TEST_ON_BORROW_QUERY', \n                                                                       pool_config_defaults['TEST_ON_BORROW_QUERY'])\n    else: \n        self._test_on_borrow_query = None", "response": "Helper to configure pool options during DatabaseWrapper initialization."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride to return the connection to the pool rather than closing it.", "response": "def close(self):\n        '''\n        Override to return the connection to the pool rather than closing it.\n        '''\n        if self._wrapped_connection and self._pool:\n            logger.debug(\"Returning connection %s to pool %s\" % (self._wrapped_connection, self._pool))\n            self._pool.putconn(self._wrapped_connection)\n            self._wrapped_connection = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _cursor(self):\n        '''\n        Override _cursor to plug in our connection pool code.  We'll return a wrapped Connection\n        which can handle returning itself to the pool when its .close() method is called.\n        '''\n        from django.db.backends.postgresql.version import get_version\n\n        new_connection = False\n        set_tz = False\n        settings_dict = self.settings_dict\n\n        if self.connection is None or connection_pools[self.alias]['settings'] != settings_dict:\n            new_connection = True\n            set_tz = settings_dict.get('TIME_ZONE')\n\n            # Is this the initial use of the global connection_pools dictionary for \n            # this python interpreter? Build a ThreadedConnectionPool instance and \n            # add it to the dictionary if so.\n            if self.alias not in connection_pools or connection_pools[self.alias]['settings'] != settings_dict:\n                if settings_dict['NAME'] == '':\n                    from django.core.exceptions import ImproperlyConfigured\n                    raise ImproperlyConfigured(\"You need to specify NAME in your Django settings file.\")\n                conn_params = {\n                    'database': settings_dict['NAME'],\n                }\n                conn_params.update(settings_dict['OPTIONS'])\n                for extra in ['autocommit'] + pool_config_defaults.keys():\n                    if extra in conn_params:\n                        del conn_params[extra]\n                if settings_dict['USER']:\n                    conn_params['user'] = settings_dict['USER']\n                if settings_dict['PASSWORD']:\n                    conn_params['password'] = settings_dict['PASSWORD']\n                if settings_dict['HOST']:\n                    conn_params['host'] = settings_dict['HOST']\n                if settings_dict['PORT']:\n                    conn_params['port'] = settings_dict['PORT']\n\n                self.create_connection_pool(conn_params)\n\n            self.connection = PooledConnection(connection_pools[self.alias]['pool'], \n                                               test_query=self._test_on_borrow_query)\n            self.connection.set_client_encoding('UTF8')\n            self.connection.set_isolation_level(self.isolation_level)\n            # We'll continue to emulate the old signal frequency in case any code depends upon it\n            connection_created.send(sender=self.__class__, connection=self)\n        cursor = self.connection.cursor()\n        cursor.tzinfo_factory = None\n        if new_connection:\n            if set_tz:\n                cursor.execute(\"SET TIME ZONE %s\", [settings_dict['TIME_ZONE']])\n            if not hasattr(self, '_version'):\n                self.__class__._version = get_version(cursor)\n            if self._version[0:2] < (8, 0):\n                # No savepoint support for earlier version of PostgreSQL.\n                self.features.uses_savepoints = False\n            if self.features.uses_autocommit:\n                if self._version[0:2] < (8, 2):\n                    # FIXME: Needs extra code to do reliable model insert\n                    # handling, so we forbid it for now.\n                    from django.core.exceptions import ImproperlyConfigured\n                    raise ImproperlyConfigured(\"You cannot use autocommit=True with PostgreSQL prior to 8.2 at the moment.\")\n                else:\n                    # FIXME: Eventually we're enable this by default for\n                    # versions that support it, but, right now, that's hard to\n                    # do without breaking other things (#10509).\n                    self.features.can_return_id_from_insert = True\n        return CursorWrapper(cursor)", "response": "Override _cursor to plug in our connection pool code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencoding an integer using Base58", "response": "def b58encode_int(i, default_one=True):\n    '''Encode an integer using Base58'''\n    if not i and default_one:\n        return alphabet[0]\n    string = \"\"\n    while i:\n        i, idx = divmod(i, 58)\n        string = alphabet[idx] + string\n    return string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef b58encode(v):\n    '''Encode a string using Base58'''\n    if not isinstance(v, bytes):\n        raise TypeError(\"a bytes-like object is required, not '%s'\" %\n                        type(v).__name__)\n\n    origlen = len(v)\n    v = v.lstrip(b'\\0')\n    newlen = len(v)\n\n    p, acc = 1, 0\n    for c in iseq(reversed(v)):\n        acc += p * c\n        p = p << 8\n\n    result = b58encode_int(acc, default_one=False)\n\n    return (alphabet[0] * (origlen - newlen) + result)", "response": "Encode a string using Base58"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode a Base58 encoded string as an integer", "response": "def b58decode_int(v):\n    '''Decode a Base58 encoded string as an integer'''\n\n    if not isinstance(v, str):\n        v = v.decode('ascii')\n\n    decimal = 0\n    for char in v:\n        decimal = decimal * 58 + alphabet.index(char)\n    return decimal"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecodes a Base58 encoded string", "response": "def b58decode(v):\n    '''Decode a Base58 encoded string'''\n\n    if not isinstance(v, str):\n        v = v.decode('ascii')\n\n    origlen = len(v)\n    v = v.lstrip(alphabet[0])\n    newlen = len(v)\n\n    acc = b58decode_int(v)\n\n    result = []\n    while acc > 0:\n        acc, mod = divmod(acc, 256)\n        result.append(mod)\n\n    return (b'\\0' * (origlen - newlen) + bseq(reversed(result)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef breadcrumb(context, label, viewname, *args, **kwargs):\n    append_breadcrumb(context, _(escape(label)), viewname, args, kwargs)\n    return ''", "response": "Add a breadcrumb to the list of breadcrumbs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef breadcrumb_raw(context, label, viewname, *args, **kwargs):\n    append_breadcrumb(context, escape(label), viewname, args, kwargs)\n    return ''", "response": "A simple breadcrumb that is a raw string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef breadcrumb_raw_safe(context, label, viewname, *args, **kwargs):\n    append_breadcrumb(context, label, viewname, args, kwargs)\n    return ''", "response": "Same as breadcrumb but with label escaped and translated."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_breadcrumbs(context, *args):\n\n    try:\n        template_path = args[0]\n    except IndexError:\n        template_path = getattr(settings, 'BREADCRUMBS_TEMPLATE',\n                                'django_bootstrap_breadcrumbs/bootstrap2.html')\n\n    links = []\n    for (label, viewname, view_args, view_kwargs) in context[\n            'request'].META.get(CONTEXT_KEY, []):\n        if isinstance(viewname, Model) and hasattr(\n                viewname, 'get_absolute_url') and ismethod(\n                viewname.get_absolute_url):\n            url = viewname.get_absolute_url(*view_args, **view_kwargs)\n        else:\n            try:\n                try:\n                    # 'resolver_match' introduced in Django 1.5\n                    current_app = context['request'].resolver_match.namespace\n                except AttributeError:\n                    try:\n                        resolver_match = resolve(context['request'].path)\n                        current_app = resolver_match.namespace\n                    except Resolver404:\n                        current_app = None\n                url = reverse(viewname=viewname, args=view_args,\n                              kwargs=view_kwargs, current_app=current_app)\n            except NoReverseMatch:\n                url = viewname\n        links.append((url, smart_text(label) if label else label))\n\n    if not links:\n        return ''\n\n    if VERSION > (1, 8):  # pragma: nocover\n        # RequestContext is deprecated in recent django\n        # https://docs.djangoproject.com/en/1.10/ref/templates/upgrading/\n        context = context.flatten()\n\n    context['breadcrumbs'] = links\n    context['breadcrumbs_total'] = len(links)\n\n    return mark_safe(template.loader.render_to_string(template_path, context))", "response": "Render breadcrumbs html using bootstrap css classes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_symbol(self, module, name, fallback=None):\n        if not hasattr(module, name) and fallback:\n            return self._find_symbol(module, fallback, None)\n        return getattr(module, name)", "response": "Find the symbol of the specified name inside the specified module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, work):\n        assert threading.current_thread() == threading.main_thread()\n        assert not self.state.running\n        self.state.running = True\n        self.thread = threading.Thread(target=work, args=(self.state,))\n        self.thread.start()\n        while self.state.running:\n            try:\n                before = time.time()\n                self.update()\n                duration = time.time() - before\n                plt.pause(max(0.001, self.refresh - duration))\n            except KeyboardInterrupt:\n                self.state.running = False\n                self.thread.join()\n                return", "response": "Start the provided work in the main thread and continue the main thread."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self):\n        assert threading.current_thread() == self.thread\n        assert self.state.running\n        self.state.running = False", "response": "Stop the thread that will have the next command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nredrawing the figure to show changed data.", "response": "def update(self):\n        \"\"\"\n        Redraw the figure to show changed data. This is automatically called\n        after `start()` was run.\n        \"\"\"\n        assert threading.current_thread() == threading.main_thread()\n        for axis, line, interface in self.interfaces:\n            line.set_xdata(interface.xdata)\n            line.set_ydata(interface.ydata)\n            axis.set_xlim(0, interface.width or 1, emit=False)\n            axis.set_ylim(0, interface.height or 1, emit=False)\n        self.figure.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apply(self, incoming):\n        assert len(incoming) == self.size\n        self.incoming = incoming\n        outgoing = self.activation(self.incoming)\n        assert len(outgoing) == self.size\n        self.outgoing = outgoing", "response": "Store the incoming activation and apply the activation function and store the result as outgoing activation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delta(self, above):\n        return self.activation.delta(self.incoming, self.outgoing, above)", "response": "Returns the derivative of the activation function at the current state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nevaluate the network with alternative weights on the input data and return the output activation.", "response": "def feed(self, weights, data):\n        \"\"\"\n        Evaluate the network with alternative weights on the input data and\n        return the output activation.\n        \"\"\"\n        assert len(data) == self.layers[0].size\n        self.layers[0].apply(data)\n        # Propagate trough the remaining layers.\n        connections = zip(self.layers[:-1], weights, self.layers[1:])\n        for previous, weight, current in connections:\n            incoming = self.forward(weight, previous.outgoing)\n            current.apply(incoming)\n        # Return the activations of the output layer.\n        return self.layers[-1].outgoing"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_network(self):\n        self.network = Network(self.problem.layers)\n        self.weights = Matrices(self.network.shapes)\n        if self.load:\n            loaded = np.load(self.load)\n            assert loaded.shape == self.weights.shape, (\n                'weights to load must match problem definition')\n            self.weights.flat = loaded\n        else:\n            self.weights.flat = np.random.normal(\n                self.problem.weight_mean, self.problem.weight_scale,\n                len(self.weights.flat))", "response": "Define model and initialize weights."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the class - based training.", "response": "def _init_training(self):\n        # pylint: disable=redefined-variable-type\n        \"\"\"Classes needed during training.\"\"\"\n        if self.check:\n            self.backprop = CheckedBackprop(self.network, self.problem.cost)\n        else:\n            self.backprop = BatchBackprop(self.network, self.problem.cost)\n        self.momentum = Momentum()\n        self.decent = GradientDecent()\n        self.decay = WeightDecay()\n        self.tying = WeightTying(*self.problem.weight_tying)\n        self.weights = self.tying(self.weights)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a loop over batches of an iterable and an operation that should be performed every few elements. Determine whether the operation should should be called for the current index.", "response": "def _every(times, step_size, index):\n        \"\"\"\n        Given a loop over batches of an iterable and an operation that should\n        be performed every few elements. Determine whether the operation should\n        be called for the current index.\n        \"\"\"\n        current = index * step_size\n        step = current // times * times\n        reached = current >= step\n        overshot = current >= step + step_size\n        return current and reached and not overshot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tax_fmt(tax_lvl, end):\n    if \"S\" in tax_lvl:\n        if \"G\" in tax_lvl and tax_lvl[\"S\"].startswith(tax_lvl[\"G\"]):\n            tax_lvl[\"S\"] = tax_lvl[\"S\"][len(tax_lvl[\"G\"])+1:]\n    if \"SS\" in tax_lvl:\n        if \"S\" in tax_lvl and tax_lvl[\"SS\"].startswith(tax_lvl[\"S\"]):\n            tax_lvl[\"SS\"] = tax_lvl[\"SS\"][len(tax_lvl[\"S\"])+1:]\n    \n    # print(ranks[:end])\n    tax = [\"{}__{}\".format(r.lower(), tax_lvl[r] if r in tax_lvl else '') \n             for r in ranks[:end+1]]\n    # add empty identifiers for ranks beyond end\n    #TODO: remove the :-1 when SS support is added\n    tax.extend([\"{}__\".format(r.lower()) for r in ranks[end+1:-1]])\n\n    # even though Bacteria, Archea are now technically Domains/superkingdoms\n    # GreenGenes and other databases still list the traditional \n    # kingdom/phylum/class/etc. So this is a hack to shoehorn the kraken-report\n    # data into that format.\n    if tax[0].startswith('d'):\n        tax[0] = \"k\"+tax[0][1:]\n\n    # print(tax)\n    return tax", "response": "Returns a string representation of a taxonomic hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a single kraken - report entry and return a dictionary of taxa for its rank and name.", "response": "def parse_tax_lvl(entry, tax_lvl_depth=[]):\n    \"\"\"\n    Parse a single kraken-report entry and return a dictionary of taxa for its\n    named ranks.\n\n    :type entry: dict\n    :param entry: attributes of a single kraken-report row.\n    :type tax_lvl_depth: list\n    :param tax_lvl_depth: running record of taxon levels encountered in\n    previous calls.\n    \"\"\"\n    # How deep in the hierarchy are we currently?  Each two spaces of\n    # indentation is one level deeper.  Also parse the scientific name at this\n    # level.\n    depth_and_name = re.match('^( *)(.*)', entry['sci_name'])\n    depth = len(depth_and_name.group(1))//2\n    name = depth_and_name.group(2)\n    # Remove the previous levels so we're one higher than the level of the new\n    # taxon.  (This also works if we're just starting out or are going deeper.)\n    del tax_lvl_depth[depth:]\n    # Append the new taxon.\n    tax_lvl_depth.append((entry['rank'], name))\n    # Create a tax_lvl dict for the named ranks.\n    tax_lvl = {x[0]: x[1] for x in tax_lvl_depth if x[0] in ranks}\n    return(tax_lvl)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a kraken - report file and return a list of with the counts at each of the acceptable taxonomic levels and a formatted string representing their taxonomic hierarchies.", "response": "def parse_kraken_report(kdata, max_rank, min_rank):\n    \"\"\"\n    Parse a single output file from the kraken-report tool. Return a list\n    of counts at each of the acceptable taxonomic levels, and a list of \n    NCBI IDs and a formatted string representing their taxonomic hierarchies.\n\n    :type kdata: str\n    :param kdata: Contents of the kraken report file.\n    \"\"\"\n    # map between NCBI taxonomy IDs and the string rep. of the hierarchy\n    taxa = OrderedDict()\n    # the master collection of read counts (keyed on NCBI ID)\n    counts = OrderedDict()\n    # current rank\n    r = 0\n    max_rank_idx = ranks.index(max_rank)\n    min_rank_idx = ranks.index(min_rank)\n\n    for entry in kdata:\n        erank = entry['rank'].strip()\n        # print(\"erank: \"+erank)\n\n        if erank in ranks:\n            r = ranks.index(erank)\n        \n        # update running tally of ranks\n        tax_lvl = parse_tax_lvl(entry)\n\n        # record the reads assigned to this taxon level, and record the taxonomy string with the NCBI ID\n        if erank in ranks and min_rank_idx >= ranks.index(entry['rank']) >= max_rank_idx:\n            taxon_reads = int(entry[\"taxon_reads\"])\n            clade_reads = int(entry[\"clade_reads\"])\n            if taxon_reads > 0 or (clade_reads > 0 and entry['rank'] == min_rank):\n                taxa[entry['ncbi_tax']] = tax_fmt(tax_lvl, r)\n                if entry['rank'] == min_rank:\n                    counts[entry['ncbi_tax']] = clade_reads\n                else:\n                    counts[entry['ncbi_tax']] = taxon_reads\n                # print(\"  Counting {} reads at {}\".format(counts[entry['ncbi_tax']], '; '.join(taxa[entry['ncbi_tax']])))\n        \n\n        #TODO: handle subspecies\n        #if erank == '-' and min_rank == \"SS\" and last_entry_indent < curr_indent:\n        #    pass\n    return counts, taxa"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_samples(kraken_reports_fp, max_rank, min_rank):\n    taxa = OrderedDict()\n    sample_counts = OrderedDict()\n    for krep_fp in kraken_reports_fp:\n        if not osp.isfile(krep_fp):\n            raise RuntimeError(\"ERROR: File '{}' not found.\".format(krep_fp))\n\n        # use the kraken report filename as the sample ID\n        sample_id = osp.splitext(osp.split(krep_fp)[1])[0]\n\n        with open(krep_fp, \"rt\") as kf:\n            try:\n                kdr = csv.DictReader(kf, fieldnames=field_names, \n                                     delimiter=\"\\t\")\n                kdata = [entry for entry in kdr][1:]\n            except OSError as oe:\n                raise RuntimeError(\"ERROR: {}\".format(oe))\n\n        scounts, staxa = parse_kraken_report(kdata, max_rank=max_rank, \n                                             min_rank=min_rank)\n\n        # update master records\n        taxa.update(staxa)\n        sample_counts[sample_id] = scounts\n\n    return sample_counts, taxa", "response": "Parse all kraken - report data files into sample counts dict\n    store global taxon id -> taxonomy data\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_biom_table(sample_counts, taxa):\n    data = [[0 if taxid not in sample_counts[sid] else sample_counts[sid][taxid] \n              for sid in sample_counts] \n                for taxid in taxa]\n    data = np.array(data, dtype=int)\n    tax_meta = [{'taxonomy': taxa[taxid]} for taxid in taxa]\n    \n    gen_str = \"kraken-biom v{} ({})\".format(__version__, __url__)\n\n    return Table(data, list(taxa), list(sample_counts), tax_meta, \n                 type=\"OTU table\", create_date=str(dt.now().isoformat()),\n                 generated_by=gen_str, input_is_dense=True)", "response": "Create a BIOM table from sample counts and taxonomy identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the BIOM table to a file.", "response": "def write_biom(biomT, output_fp, fmt=\"hdf5\", gzip=False):\n    \"\"\"\n    Write the BIOM table to a file.\n\n    :type biomT: biom.table.Table\n    :param biomT: A BIOM table containing the per-sample OTU counts and metadata\n                  to be written out to file.\n    :type output_fp str\n    :param output_fp: Path to the BIOM-format file that will be written.\n    :type fmt: str\n    :param fmt: One of: hdf5, json, tsv. The BIOM version the table will be\n                output (2.x, 1.0, 'classic').\n    \"\"\"\n    opener = open\n    mode = 'w'\n    if gzip and fmt != \"hdf5\":\n        if not output_fp.endswith(\".gz\"):\n            output_fp += \".gz\"\n        opener = gzip_open\n        mode = 'wt'\n\n    # HDF5 BIOM files are gzipped by default\n    if fmt == \"hdf5\":\n        opener = h5py.File\n\n    with opener(output_fp, mode) as biom_f:\n        if fmt == \"json\":\n            biomT.to_json(biomT.generated_by, direct_io=biom_f)\n        elif fmt == \"tsv\":\n            biom_f.write(biomT.to_tsv())\n        else:\n            biomT.to_hdf5(biom_f, biomT.generated_by)\n\n    return output_fp"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite out a file containing only the OTU IDs from the kraken data.", "response": "def write_otu_file(otu_ids, fp):\n    \"\"\"\n    Write out a file containing only the list of OTU IDs from the kraken data.\n    One line per ID.\n\n    :type otu_ids: list or iterable\n    :param otu_ids: The OTU identifiers that will be written to file.\n    :type fp: str\n    :param fp: The path to the output file.\n    \"\"\"\n    fpdir = osp.split(fp)[0]\n\n    if not fpdir == \"\" and not osp.isdir(fpdir):\n        raise RuntimeError(\"Specified path does not exist: {}\".format(fpdir))\n\n    with open(fp, 'wt') as outf:\n        outf.write('\\n'.join(otu_ids))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, X):\n        if self.fill_missing:\n            X = self.filler.complete(X)\n        return {'X': X}", "response": "Transform a DataFrame with NaN s into a dictionary with one key - X corresponding to given DataFrame but without nan s."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits the categorical encoder on the given data X.", "response": "def fit(self, X):\n        \"\"\"\n        Args:\n            X: DataFrame of categorical features to encode\n        \"\"\"\n        self.categorical_encoder = self.encoder_class(cols=list(X))\n        self.categorical_encoder.fit(X)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms a list of features into a single dictionary.", "response": "def transform(self, numerical_feature_list, categorical_feature_list):\n        \"\"\"\n        Args:\n            numerical_feature_list: list of numerical features\n            categorical_feature_list: list of categorical features\n\n        Returns:\n            Dictionary with following keys:\n                features: DataFrame with concatenated features\n                feature_names: list of features names\n                categorical_features: list of categorical feature names\n        \"\"\"\n        features = numerical_feature_list + categorical_feature_list\n        for feature in features:\n            feature = self._format_target(feature)\n            feature.set_index(self.id_column, drop=True, inplace=True)\n        features = pd.concat(features, axis=1).astype(np.float32).reset_index()\n\n        outputs = dict()\n        outputs['features'] = features\n        outputs['feature_names'] = list(features.columns)\n        outputs['categorical_features'] = self._get_feature_names(categorical_feature_list)\n        return outputs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fit(self, X, y, step_size=0.1, init_weights=None, warm_start: bool=False):\n        assert len(np.shape(X)) == 2, 'X must be 2-dimensional, got {}-D instead.'.format(len(np.shape(X)))\n        assert np.shape(X)[0] > 1, 'X must contain predictions from at least two models. ' \\\n                                   'Got {} instead'.format(np.shape(X)[0])\n\n        assert np.shape(X)[1] == len(y), (\n            'BlendingOptimizer: Length of predictions and labels does not match: '\n            'preds_len={}, y_len={}'.format(np.shape(X)[1], len(y)))\n\n        if warm_start:\n            assert self._weights is not None, 'Optimizer has to be fitted before `warm_start` can be used.'\n            weights = self._weights\n        elif init_weights is None:\n            weights = np.array([1.0] * len(X))\n        else:\n            assert (len(init_weights) == np.shape(X)[0]), (\n                'BlendingOptimizer: Number of models to blend its predictions and weights does not match: '\n                'n_models={}, weights_len={}'.format(np.shape(X)[0], len(init_weights)))\n            weights = init_weights\n\n        def __is_better_score(score_to_test, score):\n            return score_to_test > score if self.maximize else not score_to_test > score\n\n        score = 0\n        best_score = self.maximize - 0.5\n\n        while __is_better_score(best_score, score):\n            best_score = self.metric(y, np.average(np.power(X, self._power), weights=weights, axis=0) ** (\n                    1.0 / self._power))\n            score = best_score\n            best_index, best_step = -1, 0.0\n            for j in range(len(X)):\n                delta = np.array([(0 if k != j else step_size) for k in range(len(X))])\n                s = self.metric(y, np.average(np.power(X, self._power), weights=weights + delta, axis=0) ** (\n                        1.0 / self._power))\n                if __is_better_score(s, best_score):\n                    best_index, best_score, best_step = j, s, step_size\n                    continue\n                if weights[j] - step_size >= 0:\n                    s = self.metric(y, np.average(np.power(X, self._power), weights=weights - delta, axis=0) ** (\n                            1.0 / self._power))\n                    if s > best_score:\n                        best_index, best_score, best_step = j, s, -step_size\n            if __is_better_score(best_score, score):\n                weights[best_index] += best_step\n\n        self._weights = weights\n        self._score = best_score\n\n        return self", "response": "Fit the optimizer on the given predictions and labels."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transform(self, X):\n        assert np.shape(X)[0] == len(self._weights), (\n            'BlendingOptimizer: Number of models to blend its predictions and weights does not match: '\n            'n_models={}, weights_len={}'.format(np.shape(X)[0], len(self._weights)))\n        blended_predictions = np.average(np.power(X, self._power),\n                                         weights=self._weights,\n                                         axis=0) ** (1.0 / self._power)\n\n        return {'y_pred': blended_predictions}", "response": "Performs predictions blending using the trained weights."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fit_transform(self, X, y, step_size=0.1, init_weights=None, warm_start=False):\n        self.fit(X=X, y=y, step_size=step_size, init_weights=init_weights, warm_start=warm_start)\n\n        return self.transform(X=X)", "response": "Fit optimizer to X then transforms X."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnoting Implementation of http://ai.tencent.com/ailab/media/publications/ACL3-Brady.pdf post activation is used instead of pre-activation, could be worth exploring", "response": "def dpcnn(embedding_matrix, embedding_size, trainable_embedding, maxlen, max_features,\n          filter_nr, kernel_size, repeat_block, dense_size, repeat_dense, output_size, output_activation,\n          max_pooling, mean_pooling, weighted_average_attention, concat_mode,\n          dropout_embedding, conv_dropout, dense_dropout, dropout_mode,\n          conv_kernel_reg_l2, conv_bias_reg_l2,\n          dense_kernel_reg_l2, dense_bias_reg_l2,\n          use_prelu, use_batch_norm, batch_norm_first):\n    \"\"\"\n    Note:\n        Implementation of http://ai.tencent.com/ailab/media/publications/ACL3-Brady.pdf\n        post activation is used instead of pre-activation, could be worth exploring\n    \"\"\"\n\n    input_text = Input(shape=(maxlen,))\n    if embedding_matrix is not None:\n        embedding = Embedding(max_features, embedding_size,\n                              weights=[embedding_matrix], trainable=trainable_embedding)(input_text)\n    else:\n        embedding = Embedding(max_features, embedding_size)(input_text)\n\n    embedding = dropout_block(dropout_embedding, dropout_mode)(embedding)\n\n    x = convolutional_block(filter_nr, kernel_size, use_batch_norm, use_prelu, conv_dropout, dropout_mode,\n                            conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first)(embedding)\n    x = convolutional_block(filter_nr, kernel_size, conv_bias_reg_l2, use_prelu, conv_dropout, dropout_mode,\n                            conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first)(x)\n    if embedding_size == filter_nr:\n        x = add([embedding, x])\n    else:\n        embedding_resized = shape_matching_layer(filter_nr, use_prelu, conv_kernel_reg_l2, conv_bias_reg_l2)(embedding)\n        x = add([embedding_resized, x])\n    for _ in range(repeat_block):\n        x = dpcnn_block(filter_nr, kernel_size, use_batch_norm, use_prelu, conv_dropout, dropout_mode,\n                        conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first)(x)\n\n    predictions = classification_block(dense_size=dense_size, repeat_dense=repeat_dense,\n                                       output_size=output_size, output_activation=output_activation,\n                                       max_pooling=max_pooling,\n                                       mean_pooling=mean_pooling,\n                                       weighted_average_attention=weighted_average_attention,\n                                       concat_mode=concat_mode,\n                                       dropout=dense_dropout,\n                                       kernel_reg_l2=dense_kernel_reg_l2, bias_reg_l2=dense_bias_reg_l2,\n                                       use_prelu=use_prelu, use_batch_norm=use_batch_norm,\n                                       batch_norm_first=batch_norm_first)(x)\n    model = Model(inputs=input_text, outputs=predictions)\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnoting Implementation of http://www.aclweb.org/anthology/E17-1104 We didn't use k-max pooling but GlobalMaxPool1D at the end and didn't explore it in the intermediate layers.", "response": "def vdcnn(embedding_size, maxlen, max_features,\n          filter_nr, kernel_size, repeat_block, dense_size, repeat_dense, output_size, output_activation,\n          max_pooling, mean_pooling, weighted_average_attention, concat_mode,\n          dropout_embedding, conv_dropout, dense_dropout, dropout_mode,\n          conv_kernel_reg_l2, conv_bias_reg_l2,\n          dense_kernel_reg_l2, dense_bias_reg_l2,\n          use_prelu, use_batch_norm, batch_norm_first):\n    \"\"\"\n    Note:\n        Implementation of http://www.aclweb.org/anthology/E17-1104\n        We didn't use k-max pooling but GlobalMaxPool1D at the end and didn't explore it in the\n        intermediate layers.\n    \"\"\"\n\n    input_text = Input(shape=(maxlen,))\n    x = Embedding(input_dim=max_features, output_dim=embedding_size)(input_text)\n\n    x = dropout_block(dropout_embedding, dropout_mode)(x)\n\n    x = convolutional_block(filter_nr, kernel_size, use_batch_norm, use_prelu, conv_dropout, dropout_mode,\n                            conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first)(x)\n\n    for i in range(repeat_block):\n        if i + 1 != repeat_block:\n            x = vdcnn_block(filter_nr, kernel_size, use_batch_norm, use_prelu, conv_dropout, dropout_mode,\n                            conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first, last_block=False)(x)\n        else:\n            x = vdcnn_block(filter_nr, kernel_size, use_batch_norm, use_prelu, conv_dropout, dropout_mode,\n                            conv_kernel_reg_l2, conv_bias_reg_l2, batch_norm_first, last_block=True)(x)\n\n    predictions = classification_block(dense_size=dense_size, repeat_dense=repeat_dense,\n                                       output_size=output_size, output_activation=output_activation,\n                                       max_pooling=max_pooling,\n                                       mean_pooling=mean_pooling,\n                                       weighted_average_attention=weighted_average_attention,\n                                       concat_mode=concat_mode,\n                                       dropout=dense_dropout,\n                                       kernel_reg_l2=dense_kernel_reg_l2, bias_reg_l2=dense_bias_reg_l2,\n                                       use_prelu=use_prelu, use_batch_norm=use_batch_norm,\n                                       batch_norm_first=batch_norm_first)(x)\n    model = Model(inputs=input_text, outputs=predictions)\n    return model"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nescape the given html string with the given list of valid tags.", "response": "def escape_tags(value, valid_tags):\n    \"\"\"\n    Strips text from the given html string, leaving only tags.\n    This functionality requires BeautifulSoup, nothing will be\n    done otherwise.\n\n    This isn't perfect. Someone could put javascript in here:\n        <a onClick=\"alert('hi');\">test</a>\n\n        So if you use valid_tags, you still need to trust your data entry.\n        Or we could try:\n          - only escape the non matching bits\n          - use BeautifulSoup to understand the elements, escape everything\n            else and remove potentially harmful attributes (onClick).\n          - Remove this feature entirely. Half-escaping things securely is\n            very difficult, developers should not be lured into a false\n            sense of security.\n    \"\"\"\n    # 1. escape everything\n    value = conditional_escape(value)\n\n    # 2. Reenable certain tags\n    if valid_tags:\n        # TODO: precompile somewhere once?\n        tag_re = re.compile(r'&lt;(\\s*/?\\s*(%s))(.*?\\s*)&gt;' %\n                            '|'.join(re.escape(tag) for tag in valid_tags))\n        value = tag_re.sub(_replace_quot, value)\n\n    # Allow comments to be hidden\n    value = value.replace(\"&lt;!--\", \"<!--\").replace(\"--&gt;\", \"-->\")\n\n    return mark_safe(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of content types from the models defined in settings.", "response": "def _get_seo_content_types(seo_models):\n    \"\"\"Returns a list of content types from the models defined in settings.\"\"\"\n    try:\n        return [ContentType.objects.get_for_model(m).id for m in seo_models]\n    except Exception:  # previously caught DatabaseError\n        # Return an empty list if this is called too early\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_seo_admin(admin_site, metadata_class):\n\n    if metadata_class._meta.use_sites:\n        path_admin = SitePathMetadataAdmin\n        model_instance_admin = SiteModelInstanceMetadataAdmin\n        model_admin = SiteModelMetadataAdmin\n        view_admin = SiteViewMetadataAdmin\n    else:\n        path_admin = PathMetadataAdmin\n        model_instance_admin = ModelInstanceMetadataAdmin\n        model_admin = ModelMetadataAdmin\n        view_admin = ViewMetadataAdmin\n\n    def get_list_display():\n        return tuple(\n            name for name, obj in metadata_class._meta.elements.items()\n            if obj.editable)\n\n    backends = metadata_class._meta.backends\n\n    if 'model' in backends:\n        class ModelAdmin(model_admin):\n            form = get_model_form(metadata_class)\n            list_display = model_admin.list_display + get_list_display()\n\n        _register_admin(admin_site, metadata_class._meta.get_model('model'),\n                        ModelAdmin)\n\n    if 'view' in backends:\n        class ViewAdmin(view_admin):\n            form = get_view_form(metadata_class)\n            list_display = view_admin.list_display + get_list_display()\n\n        _register_admin(admin_site, metadata_class._meta.get_model('view'),\n                        ViewAdmin)\n\n    if 'path' in backends:\n        class PathAdmin(path_admin):\n            form = get_path_form(metadata_class)\n            list_display = path_admin.list_display + get_list_display()\n\n        _register_admin(admin_site, metadata_class._meta.get_model('path'),\n                        PathAdmin)\n\n    if 'modelinstance' in backends:\n        class ModelInstanceAdmin(model_instance_admin):\n            form = get_modelinstance_form(metadata_class)\n            list_display = (model_instance_admin.list_display +\n                            get_list_display())\n\n        _register_admin(admin_site,\n                        metadata_class._meta.get_model('modelinstance'),\n                        ModelInstanceAdmin)", "response": "Register the backends specified in Meta. backends with the admin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _construct_form(self, i, **kwargs):\n        form = super(MetadataFormset, self)._construct_form(i, **kwargs)\n        # Monkey patch the form to always force a save.\n        # It's unfortunate, but necessary because we always want an instance\n        # Affect on performance shouldn't be too great, because ther is only\n        # ever one metadata attached\n        form.empty_permitted = False\n        form.has_changed = lambda: True\n\n        # Set a marker on this object to prevent automatic metadata creation\n        # This is seen by the post_save handler, which then skips this\n        # instance.\n        if self.instance:\n            self.instance.__seo_metadata_handled = True\n\n        return form", "response": "Override the method to change the form attribute empty_permitted."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a metadata object from the given token.", "response": "def do_get_metadata(parser, token):\n    \"\"\"\n    Retrieve an object which can produce (and format) metadata.\n\n    {% get_metadata [for my_path] [in my_language] [on my_site]\n    [as my_variable] %}\n\n    or if you have multiple metadata classes:\n\n    {% get_metadata MyClass [for my_path] [in my_language] [on my_site]\n    [as my_variable] %}\n    \"\"\"\n    bits = list(token.split_contents())\n    tag_name = bits[0]\n    bits = bits[1:]\n    metadata_name = None\n    args = {'as': None, 'for': None, 'in': None, 'on': None}\n\n    # If there are an even number of bits,\n    # a metadata name has been provided.\n    if len(bits) % 2:\n        metadata_name = bits[0]\n        bits = bits[1:]\n\n    # Each bits are in the form \"key value key value ...\"\n    # Valid keys are given in the 'args' dict above.\n    while len(bits):\n        if len(bits) < 2 or bits[0] not in args:\n            raise template.TemplateSyntaxError(\n                \"expected format is '%r [as <variable_name>]'\" % tag_name)\n        key, value, bits = bits[0], bits[1], bits[2:]\n        args[key] = value\n\n    return MetadataNode(\n        metadata_name,\n        variable_name=args['as'],\n        target=args['for'],\n        site=args['on'],\n        language=args['in'],\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_exception(self, exception):\n        try:\n            return super(WebSocketRpcRequest, self)._handle_exception(exception)\n        except Exception:\n            if not isinstance(exception, (odoo.exceptions.Warning, odoo.http.SessionExpiredException, odoo.exceptions.except_orm)):\n                _logger.exception(\"Exception during JSON request handling.\")\n            error = {\n                    'code': 200,\n                    'message': \"Odoo Server Error\",\n                    'data': odoo.http.serialize_exception(exception)\n            }\n            if isinstance(exception, odoo.http.AuthenticationError):\n                error['code'] = 100\n                error['message'] = \"Odoo Session Invalid\"\n            if isinstance(exception, odoo.http.SessionExpiredException):\n                error['code'] = 100\n                error['message'] = \"Odoo Session Expired\"\n            return self._json_response(error=error)", "response": "Handles exceptions raised by the client."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_metadata_model(name=None):\n    if name is not None:\n        try:\n            return registry[name]\n        except KeyError:\n            if len(registry) == 1:\n                valid_names = 'Try using the name \"%s\" or simply leaving it '\\\n                              'out altogether.' % list(registry)[0]\n            else:\n                valid_names = \"Valid names are \" + \", \".join(\n                    '\"%s\"' % k for k in list(registry))\n            raise Exception(\n                \"Metadata definition with name \\\"%s\\\" does not exist.\\n%s\" % (\n                    name, valid_names))\n    else:\n        assert len(registry) == 1, \\\n            \"You must have exactly one Metadata class, if using \" \\\n            \"get_metadata() without a 'name' parameter.\"\n        return list(registry.values())[0]", "response": "Find registered Metadata object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef populate_metadata(model, MetadataClass):\n    for instance in model.objects.all():\n        create_metadata_instance(MetadataClass, instance)", "response": "Populates the metadata for a given model and MetadataClass."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the actual models to be used.", "response": "def _set_seo_models(self, value):\n        \"\"\"Gets the actual models to be used.\"\"\"\n        seo_models = []\n        for model_name in value:\n            if \".\" in model_name:\n                app_label, model_name = model_name.split(\".\", 1)\n                model = apps.get_model(app_label, model_name)\n                if model:\n                    seo_models.append(model)\n            else:\n                app = apps.get_app_config(model_name)\n                if app:\n                    seo_models.extend(app.get_models())\n\n        self.seo_models = seo_models"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nresolve the value for the given name.", "response": "def _resolve_value(self, name):\n        \"\"\" Returns an appropriate value for the given name. \"\"\"\n        name = str(name)\n        if name in self._metadata._meta.elements:\n            element = self._metadata._meta.elements[name]\n\n            # Look in instances for an explicit value\n            if element.editable:\n                value = getattr(self, name)\n                if value:\n                    return value\n\n            # Otherwise, return an appropriate default value (populate_from)\n            populate_from = element.populate_from\n            if isinstance(populate_from, collections.Callable):\n                return populate_from(self, **self._populate_from_kwargs())\n            elif isinstance(populate_from, Literal):\n                return populate_from.value\n            elif populate_from is not NotSet:\n                return self._resolve_value(populate_from)\n\n        # If this is not an element, look for an attribute on metadata\n        try:\n            value = getattr(self._metadata, name)\n        except AttributeError:\n            pass\n        else:\n            if isinstance(value, collections.Callable):\n                if getattr(value, '__self__', None):\n                    return value(self)\n                else:\n                    return value(self._metadata, obj=self)\n            return value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _resolve_template(value, model_instance=None, context=None):\n        if isinstance(value, string_types) and \"{\" in value:\n            if context is None:\n                context = Context()\n            if model_instance is not None:\n                context[model_instance._meta.model_name] = model_instance\n            value = Template(value).render(context)\n        return value", "response": "Resolves any template references in the given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn templated URLs prepared for javascript.", "response": "def _urls_for_js(urls=None):\n    \"\"\"\n    Return templated URLs prepared for javascript.\n    \"\"\"\n    if urls is None:\n        # prevent circular import\n        from .urls import urlpatterns\n        urls = [url.name for url in urlpatterns if getattr(url, 'name', None)]\n    urls = dict(zip(urls, [get_uri_template(url) for url in urls]))\n    urls.update(getattr(settings, 'LEAFLET_STORAGE_EXTRA_URLS', {}))\n    return urls"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef can_edit(self, user=None, request=None):\n        can = False\n        if request and not self.owner:\n            if (getattr(settings, \"LEAFLET_STORAGE_ALLOW_ANONYMOUS\", False)\n                    and self.is_anonymous_owner(request)):\n                can = True\n                if user and user.is_authenticated():\n                    # if user is authenticated, attach as owner\n                    self.owner = user\n                    self.save()\n                    msg = _(\"Your anonymous map has been attached to your account %s\" % user)\n                    messages.info(request, msg)\n        if self.edit_status == self.ANONYMOUS:\n            can = True\n        elif not user.is_authenticated():\n            pass\n        elif user == self.owner:\n            can = True\n        elif self.edit_status == self.EDITORS and user in self.editors.all():\n            can = True\n        return can", "response": "Returns True if a user can edit the instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of custom fields for this model", "response": "def get_custom_fields(self):\n        \"\"\" Return a list of custom fields for this model \"\"\"\n        return CustomField.objects.filter(\n            content_type=ContentType.objects.get_for_model(self))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_model_custom_fields(self):\n        return CustomField.objects.filter(\n            content_type=ContentType.objects.get_for_model(self))", "response": "Return a list of custom fields for this model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_custom_field(self, field_name):\n        content_type = ContentType.objects.get_for_model(self)\n        return CustomField.objects.get(\n            content_type=content_type, name=field_name)", "response": "Get a custom field object for this model."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a value for a specified custom field.", "response": "def get_custom_value(self, field_name):\n        \"\"\" Get a value for a specified custom field\n        field_name - Name of the custom field you want.\n        \"\"\"\n        custom_field = self.get_custom_field(field_name)\n        return CustomFieldValue.objects.get_or_create(\n            field=custom_field, object_id=self.id)[0].value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_custom_value(self, field_name, value):\n        custom_field = self.get_custom_field(field_name)\n        custom_value = CustomFieldValue.objects.get_or_create(\n            field=custom_field, object_id=self.id)[0]\n        custom_value.value = value\n        custom_value.save()", "response": "Set a value for a specific custom field"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the input file is outdated.", "response": "def is_outdated(self, infile, outfile):\n        \"\"\"Check if the input file is outdated.\n        \n        The difficulty with the default implementation is that any file that is\n        `require`d from the entry-point file will not trigger a recompile if it\n        is modified. This overloaded version of the method corrects this by generating\n        a list of all required files that are also a part of the storage manifest\n        and checking if they've been modified since the last compile.\n        \n        The command used to generate the list of dependencies is the same as the compile\n        command but uses the `--list` option instead of `--outfile`.\n        \n        WARNING: It seems to me that just generating the dependencies may take just\n        as long as actually compiling, which would mean we would be better off just\n        forcing a compile every time.\n        \"\"\"\n        \n        # Preliminary check for simply missing file or modified entry-point file.\n        if super(BrowserifyCompiler, self).is_outdated(infile, outfile):\n            return True\n        \n        # Otherwise we need to see what dependencies there are now, and if they're modified.\n        tool, args, env = self._get_cmd_parts()\n        cmd = [tool] + args + ['--list', infile]\n        if self.verbose:\n            print(\"is_outdated command:\", cmd, env)\n        dep_list = self.simple_execute_command(cmd, env=env)\n        if self.verbose:\n            print(\"dep_list is:\", dep_list)\n        for dep_file in dep_list.strip().split('\\n'):\n            if super(BrowserifyCompiler, self).is_outdated(dep_file, outfile):\n                if self.verbose:\n                    print(\"Found dep_file \\\"%s\\\" updated.\" % dep_file)\n                return True\n        \n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getclusters(self, count):\n\n        # only proceed if we got sensible input\n        if count <= 1:\n            raise ClusteringError(\"When clustering, you need to ask for at \"\n                                  \"least two clusters! \"\n                                  \"You asked for %d\" % count)\n\n        # return the data straight away if there is nothing to cluster\n        if (self.__data == [] or len(self.__data) == 1 or\n                count == self.__initial_length):\n            return self.__data\n\n        # It makes no sense to ask for more clusters than data-items available\n        if count > self.__initial_length:\n            raise ClusteringError(\n                \"Unable to generate more clusters than \"\n                \"items available. You supplied %d items, and asked for \"\n                \"%d clusters.\" % (self.__initial_length, count))\n\n        self.initialise_clusters(self.__data, count)\n\n        items_moved = True  # tells us if any item moved between the clusters,\n                            # as we initialised the clusters, we assume that\n                            # is the case\n\n        while items_moved is True:\n            items_moved = False\n            for cluster in self.__clusters:\n                for item in cluster:\n                    res = self.assign_item(item, cluster)\n                    if items_moved is False:\n                        items_moved = res\n        return self.__clusters", "response": "Generates a set of items from the data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef assign_item(self, item, origin):\n        closest_cluster = origin\n        for cluster in self.__clusters:\n            if self.distance(item, centroid(cluster)) < self.distance(\n                    item, centroid(closest_cluster)):\n                closest_cluster = cluster\n\n        if id(closest_cluster) != id(origin):\n            self.move_item(item, origin, closest_cluster)\n            return True\n        else:\n            return False", "response": "Assign an item to a given cluster to the closest located cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_item(self, item, origin, destination):\n        if self.equality:\n            item_index = 0\n            for i, element in enumerate(origin):\n                if self.equality(element, item):\n                    item_index = i\n                    break\n        else:\n            item_index = origin.index(item)\n\n        destination.append(origin.pop(item_index))", "response": "Moves an item from one cluster to another cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialise_clusters(self, input_, clustercount):\n        # initialise the clusters with empty lists\n        self.__clusters = []\n        for _ in range(clustercount):\n            self.__clusters.append([])\n\n        # distribute the items into the clusters\n        count = 0\n        for item in input_:\n            self.__clusters[count % clustercount].append(item)\n            count += 1", "response": "Initialises the clusters by distributing the items from the data set into the n - th cluster."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npublish the current number of elements and total number of elements and remaining number of elements.", "response": "def publish_progress(self, total, current):\n        \"\"\"\n        If a progress function was supplied, this will call that function with\n        the total number of elements, and the remaining number of elements.\n\n        :param total: The total number of elements.\n        :param remaining: The remaining number of elements.\n        \"\"\"\n        if self.progress_callback:\n            self.progress_callback(total, current)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_linkage_method(self, method):\n        if method == 'single':\n            self.linkage = single\n        elif method == 'complete':\n            self.linkage = complete\n        elif method == 'average':\n            self.linkage = average\n        elif method == 'uclus':\n            self.linkage = uclus\n        elif hasattr(method, '__call__'):\n            self.linkage = method\n        else:\n            raise ValueError('distance method must be one of single, '\n                             'complete, average of uclus')", "response": "Sets the method to determine the distance between two clusters."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms hierarchical clustering of items in the specified matrix.", "response": "def cluster(self, matrix=None, level=None, sequence=None):\n        \"\"\"\n        Perform hierarchical clustering.\n\n        :param matrix: The 2D list that is currently under processing. The\n            matrix contains the distances of each item with each other\n        :param level: The current level of clustering\n        :param sequence: The sequence number of the clustering\n        \"\"\"\n        logger.info(\"Performing cluster()\")\n\n        if matrix is None:\n            # create level 0, first iteration (sequence)\n            level = 0\n            sequence = 0\n            matrix = []\n\n        # if the matrix only has two rows left, we are done\n        linkage = partial(self.linkage, distance_function=self.distance)\n        initial_element_count = len(self._data)\n        while len(matrix) > 2 or matrix == []:\n\n            item_item_matrix = Matrix(self._data,\n                                      linkage,\n                                      True,\n                                      0)\n            item_item_matrix.genmatrix(self.num_processes)\n            matrix = item_item_matrix.matrix\n\n            smallestpair = None\n            mindistance = None\n            rowindex = 0  # keep track of where we are in the matrix\n            # find the minimum distance\n            for row in matrix:\n                cellindex = 0  # keep track of where we are in the matrix\n                for cell in row:\n                    # if we are not on the diagonal (which is always 0)\n                    # and if this cell represents a new minimum...\n                    cell_lt_mdist = cell < mindistance if mindistance else False\n                    if ((rowindex != cellindex) and\n                            (cell_lt_mdist or smallestpair is None)):\n                        smallestpair = (rowindex, cellindex)\n                        mindistance = cell\n                    cellindex += 1\n                rowindex += 1\n\n            sequence += 1\n            level = matrix[smallestpair[1]][smallestpair[0]]\n            cluster = Cluster(level, self._data[smallestpair[0]],\n                              self._data[smallestpair[1]])\n\n            # maintain the data, by combining the the two most similar items\n            # in the list we use the min and max functions to ensure the\n            # integrity of the data.  imagine: if we first remove the item\n            # with the smaller index, all the rest of the items shift down by\n            # one. So the next index will be wrong. We could simply adjust the\n            # value of the second \"remove\" call, but we don't know the order\n            # in which they come. The max and min approach clarifies that\n            self._data.remove(self._data[max(smallestpair[0],\n                                             smallestpair[1])])  # remove item 1\n            self._data.remove(self._data[min(smallestpair[0],\n                                             smallestpair[1])])  # remove item 2\n            self._data.append(cluster)  # append item 1 and 2 combined\n\n            self.publish_progress(initial_element_count, len(self._data))\n\n        # all the data is in one single cluster. We return that and stop\n        self.__cluster_created = True\n        logger.info(\"Call to cluster() is complete\")\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getlevel(self, threshold):\n\n        # if it's not worth clustering, just return the data\n        if len(self._input) <= 1:\n            return self._input\n\n        # initialize the cluster if not yet done\n        if not self.__cluster_created:\n            self.cluster()\n\n        return self._data[0].getlevel(threshold)", "response": "Returns all clusters with a maximum distance of threshold in between\n        each other."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flatten(L):\n    if not isinstance(L, list):\n        return [L]\n\n    if L == []:\n        return L\n\n    return flatten(L[0]) + flatten(L[1:])", "response": "Flattens a list.\n\n    Example:\n\n    >>> flatten([a,b,[c,d,[e,f]]])\n    [a,b,c,d,e,f]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the median of the list of numbers.", "response": "def median(numbers):\n    \"\"\"\n    Return the median of the list of numbers.\n    see: http://mail.python.org/pipermail/python-list/2004-December/294990.html\n    \"\"\"\n\n    # Sort the list and take the middle element.\n    n = len(numbers)\n    copy = sorted(numbers)\n    if n & 1:  # There is an odd number of elements\n        return copy[n // 2]\n    else:\n        return (copy[n // 2 - 1] + copy[n // 2]) / 2.0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the minkowski distance between two points.", "response": "def minkowski_distance(x, y, p=2):\n    \"\"\"\n    Calculates the minkowski distance between two points.\n\n    :param x: the first point\n    :param y: the second point\n    :param p: the order of the minkowski algorithm. If *p=1* it is equal\n        to the manhatten distance, if *p=2* it is equal to the euclidian\n        distance. The higher the order, the closer it converges to the\n        Chebyshev distance, which has *p=infinity*.\n    \"\"\"\n    from math import pow\n    assert len(y) == len(x)\n    assert len(x) >= 1\n    sum = 0\n    for i in range(len(x)):\n        sum += abs(x[i] - y[i]) ** p\n    return pow(sum, 1.0 / float(p))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the magnitude of a vecor", "response": "def magnitude(a):\n    \"calculates the magnitude of a vecor\"\n    from math import sqrt\n    sum = 0\n    for coord in a:\n        sum += coord ** 2\n    return sqrt(sum)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the dotproduct between two vecors", "response": "def dotproduct(a, b):\n    \"Calculates the dotproduct between two vecors\"\n    assert(len(a) == len(b))\n    out = 0\n    for i in range(len(a)):\n        out += a[i] * b[i]\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the central vector of a list of vectors", "response": "def centroid(data, method=median):\n    \"returns the central vector of a list of vectors\"\n    out = []\n    for i in range(len(data[0])):\n        out.append(method([x[i] for x in data]))\n    return tuple(out)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef display(self, depth=0):\n        print(depth * \"    \" + \"[level %s]\" % self.level)\n        for item in self.items:\n            if isinstance(item, Cluster):\n                item.display(depth + 1)\n            else:\n                print(depth * \"    \" + \"%s\" % item)", "response": "Pretty - prints this cluster. Useful for debugging."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the structure of the cluster as tuples.", "response": "def topology(self):\n        \"\"\"\n        Returns the structure (topology) of the cluster as tuples.\n\n        Output from cl.data::\n\n                [<Cluster@0.833333333333(['CVS',\n                 <Cluster@0.818181818182(['34.xls',\n                 <Cluster@0.789473684211([<Cluster@0.555555555556(['0.txt',\n                 <Cluster@0.181818181818(['ChangeLog', 'ChangeLog.txt'])>])>,\n                 <Cluster@0.684210526316(['20060730.py',\n                 <Cluster@0.684210526316(['.cvsignore',\n                 <Cluster@0.647058823529(['About.py', <Cluster@0.625(['.idlerc',\n                 '.pylint.d'])>])>])>])>])>])>])>]\n\n        Corresponding output from cl.topo()::\n\n                ('CVS', ('34.xls', (('0.txt', ('ChangeLog', 'ChangeLog.txt')),\n                ('20060730.py', ('.cvsignore', ('About.py',\n                ('.idlerc', '.pylint.d')))))))\n        \"\"\"\n\n        left = self.items[0]\n        right = self.items[1]\n\n        if isinstance(left, Cluster):\n            first = left.topology()\n        else:\n            first = left\n\n        if isinstance(right, Cluster):\n            second = right.topology()\n        else:\n            second = right\n\n        return first, second"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getlevel(self, threshold):\n\n        left = self.items[0]\n        right = self.items[1]\n\n        # if this object itself is below the threshold value we only need to\n        # return it's contents as a list\n        if self.level <= threshold:\n            return [fullyflatten(self.items)]\n\n        # if this cluster's level is higher than the threshold we will\n        # investgate it's left and right part. Their level could be below the\n        # threshold\n        if isinstance(left, Cluster) and left.level <= threshold:\n            if isinstance(right, Cluster):\n                return [fullyflatten(left.items)] + right.getlevel(threshold)\n            else:\n                return [fullyflatten(left.items)] + [[right]]\n        elif isinstance(right, Cluster) and right.level <= threshold:\n            if isinstance(left, Cluster):\n                return left.getlevel(threshold) + [fullyflatten(right.items)]\n            else:\n                return [[left]] + [fullyflatten(right.items)]\n\n        # Alright. We covered the cases where one of the clusters was below\n        # the threshold value. Now we'll deal with the clusters that are above\n        # by recursively applying the previous cases.\n        if isinstance(left, Cluster) and isinstance(right, Cluster):\n            return left.getlevel(threshold) + right.getlevel(threshold)\n        elif isinstance(left, Cluster):\n            return left.getlevel(threshold) + [[right]]\n        elif isinstance(right, Cluster):\n            return [[left]] + right.getlevel(threshold)\n        else:\n            return [[left], [right]]", "response": "This method returns all clusters up to a specific level threshold."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a minified version of the javascript string js", "response": "def jsmin(js, **kwargs):\n    \"\"\"\n    returns a minified version of the javascript string\n    \"\"\"\n    if not is_3:        \n        if cStringIO and not isinstance(js, unicode):\n            # strings can use cStringIO for a 3x performance\n            # improvement, but unicode (in python2) cannot\n            klass = cStringIO.StringIO\n        else:\n            klass = StringIO.StringIO\n    else:\n        klass = io.StringIO\n    ins = klass(js)\n    outs = klass()\n    JavascriptMinify(ins, outs, **kwargs).minify()\n    return outs.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cached(fun):\n\n    _cache = {}\n\n    @wraps(fun)\n    def newfun(a, b, distance_function):\n        frozen_a = frozenset(a)\n        frozen_b = frozenset(b)\n        if (frozen_a, frozen_b) not in _cache:\n            result = fun(a, b, distance_function)\n            _cache[(frozen_a, frozen_b)] = result\n        return _cache[(frozen_a, frozen_b)]\n    return newfun", "response": "Memoizing decorator for linkage functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef single(a, b, distance_function):\n    left_a, right_a = min(a), max(a)\n    left_b, right_b = min(b), max(b)\n    result = min(distance_function(left_a, right_b),\n                 distance_function(left_b, right_a))\n    return result", "response": "Given two collections a and b this will return the distance of the points which are closest together."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive two collections a and b this will return the mean of all the all the items in the all - item tree.", "response": "def average(a, b, distance_function):\n    \"\"\"\n    Given two collections ``a`` and ``b``, this will return the mean of all\n    distances. ``distance_function`` is used to determine the distance between\n    two elements.\n\n    Example::\n\n        >>> single([1, 2], [3, 100], lambda x, y: abs(x-y))\n        26\n    \"\"\"\n    distances = [distance_function(x, y)\n                 for x in a for y in b]\n    return sum(distances) / len(distances)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive two collections a and b this will return the median of all the all the time - to - live distances between the two collections b.", "response": "def uclus(a, b, distance_function):\n    \"\"\"\n    Given two collections ``a`` and ``b``, this will return the *median* of all\n    distances. ``distance_function`` is used to determine the distance between\n    two elements.\n\n    Example::\n\n        >>> single([1, 2], [3, 100], lambda x, y: abs(x-y))\n        2.5\n    \"\"\"\n    distances = sorted([distance_function(x, y)\n                        for x in a for y in b])\n    midpoint, rest = len(distances) // 2, len(distances) % 2\n    if not rest:\n        return sum(distances[midpoint-1:midpoint+1]) / 2\n    else:\n        return distances[midpoint]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nencapsulating the given item into a list of dicts", "response": "def _encapsulate_item_for_combinfunc(item):\n    \"\"\"\n    This function has been extracted in order to \n    make Github issue #28 easier to investigate.\n    It replaces the following two lines of code, \n    which occur twice in method genmatrix, just\n    before the invocation of combinfunc.\n        if not hasattr(item, '__iter__') or isinstance(item, tuple):\n            item = [item]\n    Logging was added to the original two lines\n    and shows that the outcome of this snippet\n    has changed between Python2.7 and Python3.5.\n    This logging showed that the difference in \n    outcome consisted of the handling of the builtin\n    str class, which was encapsulated into a list in\n    Python2.7 but returned naked in Python3.5.\n    Adding a test for this specific class to the \n    set of conditions appears to give correct behaviour\n    under both versions.\n    \"\"\"\n    encapsulated_item = None\n    if  (\n        not hasattr(item, '__iter__') or\n        isinstance(item, tuple) or\n        isinstance(item, str)\n    ):\n        encapsulated_item = [item]\n    else:\n        encapsulated_item = item\n    logging.debug(\n        \"item class:%s encapsulated as:%s \",\n        item.__class__.__name__, \n        encapsulated_item.__class__.__name__\n    )\n    return encapsulated_item"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef worker(self):\n        tasks_completed = 0\n        for task in iter(self.task_queue.get, 'STOP'):\n            col_index, item, item2 = task\n            if not hasattr(item, '__iter__') or isinstance(item, tuple):\n                item = [item]\n            if not hasattr(item2, '__iter__') or isinstance(item2, tuple):\n                item2 = [item2]\n            result = (col_index, self.combinfunc(item, item2))\n            self.done_queue.put(result)\n            tasks_completed += 1\n        logger.info(\"Worker %s performed %s tasks\",\n                    current_process().name,\n                    tasks_completed)", "response": "This function runs the task function in a separate thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the matrix for the items in the data.", "response": "def genmatrix(self, num_processes=1):\n        \"\"\"\n        Actually generate the matrix\n\n        :param num_processes: If you want to use multiprocessing to split up the\n            work and run ``combinfunc()`` in parallel, specify\n            ``num_processes > 1`` and this number of workers will be spun up,\n            the work is split up amongst them evenly.\n        \"\"\"\n        use_multiprocessing = num_processes > 1\n        if use_multiprocessing:\n            self.task_queue = Queue()\n            self.done_queue = Queue()\n\n        self.matrix = []\n        logger.info(\"Generating matrix for %s items - O(n^2)\", len(self.data))\n        if use_multiprocessing:\n            logger.info(\"Using multiprocessing on %s processes!\", num_processes)\n\n        if use_multiprocessing:\n            logger.info(\"Spinning up %s workers\", num_processes)\n            processes = [Process(target=self.worker) for i in range(num_processes)]\n            [process.start() for process in processes]\n\n        for row_index, item in enumerate(self.data):\n            logger.debug(\"Generating row %s/%s (%0.2f%%)\",\n                         row_index,\n                         len(self.data),\n                         100.0 * row_index / len(self.data))\n            row = {}\n            if use_multiprocessing:\n                num_tasks_queued = num_tasks_completed = 0\n            for col_index, item2 in enumerate(self.data):\n                if self.diagonal is not None and col_index == row_index:\n                    # This is a cell on the diagonal\n                    row[col_index] = self.diagonal\n                elif self.symmetric and col_index < row_index:\n                    # The matrix is symmetric and we are \"in the lower left\n                    # triangle\" - fill this in after (in case of multiprocessing)\n                    pass\n                # Otherwise, this cell is not on the diagonal and we do indeed\n                # need to call combinfunc()\n                elif use_multiprocessing:\n                    # Add that thing to the task queue!\n                    self.task_queue.put((col_index, item, item2))\n                    num_tasks_queued += 1\n                    # Start grabbing the results as we go, so as not to stuff all of\n                    # the worker args into memory at once (as Queue.get() is a\n                    # blocking operation)\n                    if num_tasks_queued > num_processes:\n                        col_index, result = self.done_queue.get()\n                        row[col_index] = result\n                        num_tasks_completed += 1\n                else:\n                    # Otherwise do it here, in line\n                    \"\"\"\n                    if not hasattr(item, '__iter__') or isinstance(item, tuple):\n                        item = [item]\n                    if not hasattr(item2, '__iter__') or isinstance(item2, tuple):\n                        item2 = [item2]\n                    \"\"\"\n                    # See the comment in function _encapsulate_item_for_combinfunc\n                    # for details of why the lines above have been replaced\n                    # by function invocations\n                    item = _encapsulate_item_for_combinfunc(item)\n                    item2 = _encapsulate_item_for_combinfunc(item2)\n                    row[col_index] = self.combinfunc(item, item2)\n\n            if self.symmetric:\n                # One more iteration to get symmetric lower left triangle\n                for col_index, item2 in enumerate(self.data):\n                    if col_index >= row_index:\n                        break\n                    # post-process symmetric \"lower left triangle\"\n                    row[col_index] = self.matrix[col_index][row_index]\n\n            if use_multiprocessing:\n                # Grab the remaining worker task results\n                while num_tasks_completed < num_tasks_queued:\n                    col_index, result = self.done_queue.get()\n                    row[col_index] = result\n                    num_tasks_completed += 1\n\n            row_indexed = [row[index] for index in range(len(self.data))]\n            self.matrix.append(row_indexed)\n\n        if use_multiprocessing:\n            logger.info(\"Stopping/joining %s workers\", num_processes)\n            [self.task_queue.put('STOP') for i in range(num_processes)]\n            [process.join() for process in processes]\n\n        logger.info(\"Matrix generated\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(fname):\n    validation = {\n        \"errors\": [],\n        \"warnings\": []\n    }\n    for line in _process(fname):\n        kind, message = _determine(line)\n        if kind in validation:\n            validation[kind].append(message)\n    return validation", "response": "This function uses dciodvfy to generate a list of warnings and errors discovered within the DICOM file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef numpy(self):\n        # load GDCM's image reading functionality\n        image_reader = gdcm.ImageReader()\n        image_reader.SetFileName(self.fname)\n        if not image_reader.Read():\n            raise IOError(\"Could not read DICOM image\")\n        pixel_array = self._gdcm_to_numpy(image_reader.GetImage())\n        return pixel_array", "response": "Grabs image data and converts it to a numpy array"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a GDCM image to a numpy array.", "response": "def _gdcm_to_numpy(self, image):\n        \"\"\" Converts a GDCM image to a numpy array.\n\n        :param image: GDCM.ImageReader.GetImage()\n        \"\"\"\n        gdcm_typemap = {\n            gdcm.PixelFormat.INT8:     numpy.int8,\n            gdcm.PixelFormat.UINT8:    numpy.uint8,\n            gdcm.PixelFormat.UINT16:   numpy.uint16,\n            gdcm.PixelFormat.INT16:    numpy.int16,\n            gdcm.PixelFormat.UINT32:   numpy.uint32,\n            gdcm.PixelFormat.INT32:    numpy.int32,\n            gdcm.PixelFormat.FLOAT32:  numpy.float32,\n            gdcm.PixelFormat.FLOAT64:  numpy.float64\n        }\n        pixel_format = image.GetPixelFormat().GetScalarType()\n        if pixel_format in gdcm_typemap:\n            self.data_type = gdcm_typemap[pixel_format]\n        else:\n            raise KeyError(''.join(pixel_format, \\\n                \" is not a supported pixel format\"))\n\n        #dimension = image.GetDimension(0), image.GetDimension(1)\n        self.dimensions = image.GetDimension(1), image.GetDimension(0)\n        gdcm_array = image.GetBuffer()\n\n        # GDCM returns char* as type str. This converts it to type bytes\n        if sys.version_info >= (3, 0):\n            gdcm_array = gdcm_array.encode(sys.getfilesystemencoding(), \"surrogateescape\")\n\n        # use float for accurate scaling\n        dimensions = image.GetDimensions()\n        result = numpy.frombuffer(gdcm_array, dtype=self.data_type).astype(float)\n        if len(dimensions) == 3:\n            # for cine (animations) there are 3 dims: x, y, number of frames\n            result.shape = dimensions[2], dimensions[0], dimensions[1]\n        else:\n            result.shape = dimensions\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_as_plt(self, fname, pixel_array=None, vmin=None, vmax=None,\n        cmap=None, format=None, origin=None):\n        \"\"\" This method saves the image from a numpy array using matplotlib\n\n        :param fname: Location and name of the image file to be saved.\n        :param pixel_array: Numpy pixel array, i.e. ``numpy()`` return value\n        :param vmin: matplotlib vmin\n        :param vmax: matplotlib vmax\n        :param cmap: matplotlib color map\n        :param format: matplotlib format\n        :param origin: matplotlib origin\n\n        This method will return True if successful\n        \"\"\"\n        from matplotlib.backends.backend_agg \\\n        import FigureCanvasAgg as FigureCanvas\n        from matplotlib.figure import Figure\n        from pylab import cm\n\n        if pixel_array is None:\n            pixel_array = self.numpy\n\n        if cmap is None:\n            cmap = cm.bone\n        fig = Figure(figsize=pixel_array.shape[::-1], dpi=1, frameon=False)\n        canvas = FigureCanvas(fig)\n        fig.figimage(pixel_array, cmap=cmap, vmin=vmin,\n            vmax=vmax, origin=origin)\n        fig.savefig(fname, dpi=1, format=format)\n        return True", "response": "This method saves the image from a numpy array using matplotlib."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_as_pil(self, fname, pixel_array=None):\n        if pixel_array is None:\n            pixel_array = self.numpy\n\n        from PIL import Image as pillow\n        pil_image = pillow.fromarray(pixel_array.astype('uint8'))\n        pil_image.save(fname)\n        return True", "response": "This method saves the image from a numpy array using PILlow."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning an array of dictionaries containing all the data elements in the DICOM file.", "response": "def read(self):\n        \"\"\" Returns array of dictionaries containing all the data elements in\n        the DICOM file.\n        \"\"\"\n        def ds(data_element):\n            value = self._str_filter.ToStringPair(data_element.GetTag())\n            if value[1]:\n                return DataElement(data_element, value[0].strip(), value[1].strip())\n\n        results = [data for data in self.walk(ds) if data is not None]\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwalking through all data elements and allows a function to interact with each data element.", "response": "def walk(self, fn):\n        \"\"\" Loops through all data elements and allows a function to interact\n        with each data element.  Uses a generator to improve iteration.\n\n        :param fn: Function that interacts with each DICOM element \"\"\"\n        if not hasattr(fn, \"__call__\"):\n            raise TypeError(\"\"\"walk_dataset requires a\n                function as its parameter\"\"\")\n\n        dataset = self._dataset\n        iterator = dataset.GetDES().begin()\n        while (not iterator.equal(dataset.GetDES().end())):\n            data_element = iterator.next()\n            yield fn(data_element)\n\n        header = self._header\n        iterator = header.GetDES().begin()\n        while (not iterator.equal(header.GetDES().end())):\n            data_element = iterator.next()\n            yield fn(data_element)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch the DICOM file for data elements given the filters supplied to this method.", "response": "def find(self, group=None, element=None, name=None, VR=None):\n        \"\"\" Searches for data elements in the DICOM file given the filters\n        supplied to this method.\n\n        :param group: Hex decimal for the group of a DICOM element e.g. 0x002\n        :param element: Hex decimal for the element value of a DICOM element e.g. 0x0010\n        :param name: Name of the DICOM element, e.g. \"Modality\"\n        :param VR: Value Representation of the DICOM element, e.g. \"PN\"\n        \"\"\"\n        results = self.read()\n\n        if name is not None:\n            def find_name(data_element):\n                return data_element.name.lower() == name.lower()\n            return filter(find_name, results)\n\n        if group is not None:\n            def find_group(data_element):\n                return (data_element.tag['group'] == group\n                        or int(data_element.tag['group'], 16) == group)\n            results = filter(find_group, results)\n\n        if element is not None:\n            def find_element(data_element):\n                return (data_element.tag['element'] == element\n                        or int(data_element.tag['element'], 16) == element)\n            results = filter(find_element, results)\n\n        if VR is not None:\n            def find_VR(data_element):\n                return data_element.VR.lower() == VR.lower()\n            results = filter(find_VR, results)\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef anonymize(self):\n        self._anon_obj = gdcm.Anonymizer()\n        self._anon_obj.SetFile(self._file)\n        self._anon_obj.RemoveGroupLength()\n\n        if self._anon_tags is None:\n            self._anon_tags = get_anon_tags()\n\n        for tag in self._anon_tags:\n            cur_tag = tag['Tag'].replace(\"(\", \"\")\n            cur_tag = cur_tag.replace(\")\", \"\")\n            name = tag[\"Attribute Name\"].replace(\" \", \"\").encode(\"utf8\")\n            group, element = cur_tag.split(\",\", 1)\n\n            # TODO expand this 50xx, 60xx, gggg, eeee\n            if (\"xx\" not in group\n                and \"gggg\" not in group\n                and \"eeee\" not in group):\n                    group = int(group, 16)\n                    element = int(element, 16)\n                    if self.find(group=group, element=element):\n                        self._anon_obj.Replace(\n                            gdcm.Tag(group, element), \"Anon\" + name)\n\n        return self._anon_obj", "response": "A basic application level anonymization of a DICOM file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave a DICOM file given a GDCM DICOM object.", "response": "def save_as(self, fname, obj=None):\n        \"\"\" Save DICOM file given a GDCM DICOM object.\n        Examples of a GDCM DICOM object:\n        * gdcm.Writer()\n        * gdcm.Reader()\n        * gdcm.Anonymizer()\n\n        :param fname: DICOM file name to be saved\n        :param obj: DICOM object to be saved, if None, Anonymizer() is used\n        \"\"\"\n        writer = gdcm.Writer()\n        writer.SetFileName(fname)\n        if obj is None and self._anon_obj:\n            obj = self._anon_obj\n        else:\n            raise ValueError(\"Need DICOM object, e.g. obj=gdcm.Anonymizer()\")\n        writer.SetFile(obj.GetFile())\n        if not writer.Write():\n            raise IOError(\"Could not save DICOM file\")\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image(self):\n        if self._image is None:\n            self._image = Image(self.fname)\n        return self._image", "response": "Read the DICOM image data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef VR(VR=None, description=None):\n    value_repr = {\n        \"AE\": \"Application Entity\",\n        \"AS\": \"Age String\",\n        \"AT\": \"Attribute Tag\",\n        \"CS\": \"Code String\",\n        \"DA\": \"Date\",\n        \"DS\": \"Decimal String\",\n        \"DT\": \"Date/Time\",\n        \"FL\": \"Floating Point Single (4 bytes)\",\n        \"FD\": \"Floating Point Double (8 bytes)\",\n        \"IS\": \"Integer String\",\n        \"LO\": \"Long String\",\n        \"LT\": \"Long Text\",\n        \"OB\": \"Other Byte\",\n        \"OF\": \"Other Float\",\n        \"OW\": \"Other Word\",\n        \"PN\": \"Person Name\",\n        \"SH\": \"Short String\",\n        \"SL\": \"Signed Long\",\n        \"SQ\": \"Sequence of Items\",\n        \"SS\": \"Signed Short\",\n        \"ST\": \"Short Text\",\n        \"TM\": \"Time\",\n        \"UI\": \"Unique Identifier\",\n        \"UL\": \"Unsigned Long\",\n        \"UN\": \"Unknown\",\n        \"US\": \"Unsigned Short\",\n        \"UT\": \"Unlimited Text\"\n    }\n    assert VR or description, \"Either VR or description required to map VR\"\n\n    if VR is not None:\n        VR = VR.upper()\n        if VR in value_repr:\n            return value_repr[VR]\n\n    for key, value in value_repr.iteritems():\n        if description == value:\n            return key\n\n    return None", "response": "Value Representation ( VR ) < > Description"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the UID of the Transfer Syntax.", "response": "def transfer_syntax(UID=None, description=None):\n    \"\"\" Transfer Syntax UID <-> Description lookup.\n\n    :param UID: Transfer Syntax UID, returns description\n    :param description: Take the description of a transfer syntax and return its UID\n    \"\"\"\n    transfer_syntax = {\n        \"1.2.840.10008.1.2\": \"Implicit VR Endian: Default Transfer Syntax for DICOM\",\n        \"1.2.840.10008.1.2.1\": \"Explicit VR Little Endian\",\n        \"1.2.840.10008.1.2.1.99\": \"Deflated Explicit VR Big Endian\",\n        \"1.2.840.10008.1.2.2\": \"Explicit VR Big Endian\",\n        \"1.2.840.10008.1.2.4.50\": \"JPEG Baseline (Process 1): Default Transfer Syntax for Lossy JPEG 8-bit Image Compression\",\n        \"1.2.840.10008.1.2.4.51\": \"JPEG Baseline (Processes 2 & 4): Default Transfer Syntax for Lossy JPEG 12-bit Image Compression (Process 4 only)\",\n        \"1.2.840.10008.1.2.4.57\": \"JPEG Lossless, Nonhierarchical (Processes 14)\",\n        \"1.2.840.10008.1.2.4.70\": \"JPEG Lossless, Nonhierarchical, First-Order Prediction (Processes 14 [Selection Value 1])\",\n        \"1.2.840.10008.1.2.4.80\": \"JPEG-LS Lossless Image Compression\",\n        \"1.2.840.10008.1.2.4.81\": \"JPEG-LS Lossy (Near- Lossless) Image Compression\",\n        \"1.2.840.10008.1.2.4.90\": \"JPEG 2000 Image Compression (Lossless Only)\",\n        \"1.2.840.10008.1.2.4.91\": \"JPEG 2000 Image Compression\",\n        \"1.2.840.10008.1.2.4.92\": \"JPEG 2000 Part 2 Multicomponent Image Compression (Lossless Only)\",\n        \"1.2.840.10008.1.2.4.93\": \"JPEG 2000 Part 2 Multicomponent Image Compression\",\n        \"1.2.840.10008.1.2.4.94\": \"JPIP Referenced\",\n        \"1.2.840.10008.1.2.4.95\": \"JPIP Referenced Deflate\",\n        \"1.2.840.10008.1.2.5\": \"RLE Lossless\",\n        \"1.2.840.10008.1.2.6.1\": \"RFC 2557 MIME Encapsulation\",\n        \"1.2.840.10008.1.2.4.100\": \"MPEG2 Main Profile Main Level\",\n        \"1.2.840.10008.1.2.4.102\": \"MPEG-4 AVC/H.264 High Profile / Level 4.1\",\n        \"1.2.840.10008.1.2.4.103\": \"MPEG-4 AVC/H.264 BD-compatible High Profile / Level 4.1\"\n    }\n    assert UID or description, \"Either Transfer syntax UID or description required\"\n\n    if UID in transfer_syntax:\n        return transfer_syntax[UID]\n\n    for key, value in transfer_syntax.iteritems():\n        if description == value:\n            return key\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef repo_name(self):\n\n        ds = [[x.repo_name] for x in self.repos]\n        df = pd.DataFrame(ds, columns=['repository'])\n        return df", "response": "Returns a DataFrame of the repo names present in this project directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef coverage(self):\n\n        df = pd.DataFrame(columns=['filename', 'lines_covered', 'total_lines', 'coverage', 'repository'])\n\n        for repo in self.repos:\n            try:\n                cov = repo.coverage()\n                cov['repository'] = repo.repo_name\n                df = df.append(cov)\n            except GitCommandError:\n                print('Warning! Repo: %s seems to not have coverage' % (repo, ))\n\n        df.reset_index()\n\n        return df", "response": "Returns a DataFrame with coverage information for each repo in the project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef file_change_rates(self, branch='master', limit=None, coverage=False, days=None, ignore_globs=None, include_globs=None):\n\n        columns = ['unique_committers', 'abs_rate_of_change', 'net_rate_of_change', 'net_change', 'abs_change', 'edit_rate', 'repository']\n        if coverage:\n            columns += ['lines_covered', 'total_lines', 'coverage']\n        df = pd.DataFrame(columns=columns)\n\n        for repo in self.repos:\n            try:\n                fcr = repo.file_change_rates(\n                    branch=branch,\n                    limit=limit,\n                    coverage=coverage,\n                    days=days,\n                    ignore_globs=ignore_globs,\n                    include_globs=include_globs\n                )\n                fcr['repository'] = repo.repo_name\n                df = df.append(fcr)\n            except GitCommandError:\n                print('Warning! Repo: %s seems to not have the branch: %s' % (repo, branch))\n\n        df.reset_index()\n\n        return df", "response": "This function returns a DataFrame containing some basic aggregations of the file change rates for the current branch and optionally test coverage data."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nestimating the number of hours of each author or committer.", "response": "def hours_estimate(self, branch='master', grouping_window=0.5, single_commit_hours=0.5, limit=None, days=None, committer=True, by=None, ignore_globs=None, include_globs=None):\n        \"\"\"\n        inspired by: https://github.com/kimmobrunfeldt/git-hours/blob/8aaeee237cb9d9028e7a2592a25ad8468b1f45e4/index.js#L114-L143\n\n        Iterates through the commit history of repo to estimate the time commitement of each author or committer over\n        the course of time indicated by limit/extensions/days/etc.\n\n        :param branch: the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param grouping_window: (optional, default=0.5 hours) the threhold for how close two commits need to be to consider them part of one coding session\n        :param single_commit_hours: (optional, default 0.5 hours) the time range to associate with one single commit\n        :param days: (optional, default=None) number of days to return, if limit is None\n        :param committer: (optional, default=True) whether to use committer vs. author\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        if limit is not None:\n            limit = int(limit / len(self.repo_dirs))\n\n        if committer:\n            com = 'committer'\n        else:\n            com = 'author'\n\n        df = pd.DataFrame(columns=[com, 'hours', 'repository'])\n\n        for repo in self.repos:\n            try:\n                ch = repo.hours_estimate(\n                    branch,\n                    grouping_window=grouping_window,\n                    single_commit_hours=single_commit_hours,\n                    limit=limit,\n                    days=days,\n                    committer=committer,\n                    ignore_globs=ignore_globs,\n                    include_globs=include_globs\n                )\n                ch['repository'] = repo.repo_name\n                df = df.append(ch)\n            except GitCommandError:\n                print('Warning! Repo: %s seems to not have the branch: %s' % (repo, branch))\n\n        df.reset_index()\n\n        if by == 'committer' or by == 'author':\n            df = df.groupby(com).agg({'hours': sum})\n            df = df.reset_index()\n        elif by == 'repository':\n            df = df.groupby('repository').agg({'hours': sum})\n            df = df.reset_index()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commit_history(self, branch, limit=None, days=None, ignore_globs=None, include_globs=None):\n\n        if limit is not None:\n            limit = int(limit / len(self.repo_dirs))\n\n        df = pd.DataFrame(columns=['author', 'committer', 'message', 'lines', 'insertions', 'deletions', 'net'])\n\n        for repo in self.repos:\n            try:\n                ch = repo.commit_history(branch, limit=limit, days=days, ignore_globs=ignore_globs, include_globs=include_globs)\n                ch['repository'] = repo.repo_name\n                df = df.append(ch)\n            except GitCommandError:\n                print('Warning! Repo: %s seems to not have the branch: %s' % (repo, branch))\n\n        df.reset_index()\n\n        return df", "response": "Returns a pandas DataFrame containing all of the commits for a given branch."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blame(self, committer=True, by='repository', ignore_globs=None, include_globs=None):\n\n        df = None\n\n        for repo in self.repos:\n            try:\n                if df is None:\n                    df = repo.blame(committer=committer, by=by, ignore_globs=ignore_globs, include_globs=include_globs)\n                else:\n                    df = df.append(repo.blame(committer=committer, by=by, ignore_globs=ignore_globs, include_globs=include_globs))\n            except GitCommandError as err:\n                print('Warning! Repo: %s couldnt be blamed' % (repo, ))\n                pass\n\n        df = df.reset_index(level=1)\n        df = df.reset_index(level=1)\n        if committer:\n            if by == 'repository':\n                df = df.groupby('committer').agg({'loc': np.sum})\n            elif by == 'file':\n                df = df.groupby(['committer', 'file']).agg({'loc': np.sum})\n        else:\n            if by == 'repository':\n                df = df.groupby('author').agg({'loc': np.sum})\n            elif by == 'file':\n                df = df.groupby(['author', 'file']).agg({'loc': np.sum})\n\n        df = df.sort_values(by=['loc'], ascending=False)\n\n        return df", "response": "Returns the blame of the current HEAD of the repositories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef file_detail(self, rev='HEAD', committer=True, ignore_globs=None, include_globs=None):\n\n        df = None\n\n        for repo in self.repos:\n            try:\n                if df is None:\n                    df = repo.file_detail(ignore_globs=ignore_globs, include_globs=include_globs, committer=committer, rev=rev)\n                    df['repository'] = repo.repo_name\n                else:\n                    chunk = repo.file_detail(ignore_globs=ignore_globs, include_globs=include_globs, committer=committer, rev=rev)\n                    chunk['repository'] = repo.repo_name\n                    df = df.append(chunk)\n            except GitCommandError:\n                print('Warning! Repo: %s couldnt be inspected' % (repo, ))\n\n        df = df.reset_index(level=1)\n        df = df.set_index(['file', 'repository'])\n        return df", "response": "Returns a table of all current files in the repos with some high level information about each file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame containing all branches in origin.", "response": "def branches(self):\n        \"\"\"\n        Returns a data frame of all branches in origin.  The DataFrame will have the columns:\n\n         * repository\n         * local\n         * branch\n\n        :returns: DataFrame\n        \"\"\"\n\n        df = pd.DataFrame(columns=['repository', 'local', 'branch'])\n\n        if _has_joblib:\n            ds = Parallel(n_jobs=-1, backend='threading', verbose=0)(\n                delayed(_branches_func)\n                (x) for x in self.repos\n            )\n            for d in ds:\n                df = df.append(d)\n        else:\n            for repo in self.repos:\n                try:\n                    df = df.append(_branches_func(repo))\n                except GitCommandError:\n                    print('Warning! Repo: %s couldn\\'t be inspected' % (repo, ))\n\n        df.reset_index()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revs(self, branch='master', limit=None, skip=None, num_datapoints=None):\n\n        if limit is not None:\n            limit = math.floor(float(limit) / len(self.repos))\n\n        if num_datapoints is not None:\n            num_datapoints = math.floor(float(num_datapoints) / len(self.repos))\n\n        df = pd.DataFrame(columns=['repository', 'rev'])\n\n        if _has_joblib:\n            ds = Parallel(n_jobs=-1, backend='threading', verbose=0)(\n                delayed(_revs_func)\n                (x, branch, limit, skip, num_datapoints) for x in self.repos\n            )\n            for d in ds:\n                df = df.append(d)\n        else:\n            for repo in self.repos:\n                try:\n                    revs = repo.revs(branch=branch, limit=limit, skip=skip, num_datapoints=num_datapoints)\n                    revs['repository'] = repo.repo_name\n                    df = df.append(revs)\n                except GitCommandError:\n                    print('Warning! Repo: %s couldn\\'t be inspected' % (repo, ))\n\n        df.reset_index()\n\n        return df", "response": "Returns a dataframe of all revision tags and their timestamps for each project."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cumulative_blame(self, branch='master', by='committer', limit=None, skip=None, num_datapoints=None, committer=True, ignore_globs=None, include_globs=None):\n\n        blames = []\n        for repo in self.repos:\n            try:\n                blame = repo.cumulative_blame(\n                    branch=branch,\n                    limit=limit,\n                    skip=skip,\n                    num_datapoints=num_datapoints,\n                    committer=committer,\n                    ignore_globs=ignore_globs,\n                    include_globs=include_globs\n                )\n                blames.append((repo.repo_name, blame))\n            except GitCommandError:\n                print('Warning! Repo: %s couldn\\'t be inspected' % (repo, ))\n                pass\n\n        global_blame = blames[0][1]\n        global_blame.columns = [x + '__' + str(blames[0][0]) for x in global_blame.columns.values]\n        blames = blames[1:]\n        for reponame, blame in blames:\n            blame.columns = [x + '__' + reponame for x in blame.columns.values]\n            global_blame = pd.merge(global_blame, blame, left_index=True, right_index=True, how='outer')\n\n        global_blame.fillna(method='pad', inplace=True)\n        global_blame.fillna(0.0, inplace=True)\n\n        if by == 'committer':\n            committers = [(str(x).split('__')[0].lower().strip(), x) for x in global_blame.columns.values]\n\n            if sys.version_info.major == 2:\n                committer_mapping = dict([(c, [x[1] for x in committers if x[0] == c]) for c in set([x[0] for x in committers])])\n            else:\n                committer_mapping = {c: [x[1] for x in committers if x[0] == c] for c in {x[0] for x in committers}}\n\n            for committer in committer_mapping.keys():\n                global_blame[committer] = 0\n                for col in committer_mapping.get(committer, []):\n                    global_blame[committer] += global_blame[col]\n\n            global_blame = global_blame.reindex(columns=list(committer_mapping.keys()))\n        elif by == 'project':\n            projects = [(str(x).split('__')[1].lower().strip(), x) for x in global_blame.columns.values]\n\n            if sys.version_info.major == 2:\n                project_mapping = dict([(c, [x[1] for x in projects if x[0] == c]) for c in set([x[0] for x in projects])])\n            else:\n                project_mapping = {c: [x[1] for x in projects if x[0] == c] for c in {x[0] for x in projects}}\n\n            for project in project_mapping.keys():\n                global_blame[project] = 0\n                for col in project_mapping.get(project, []):\n                    global_blame[project] += global_blame[col]\n\n            global_blame = global_blame.reindex(columns=list(project_mapping.keys()))\n\n        global_blame = global_blame[~global_blame.index.duplicated()]\n\n        return global_blame", "response": "Returns a dataframe of cumulative blame for a collection of projects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a DataFrame with the properties of all repositories in the project directory.", "response": "def repo_information(self):\n        \"\"\"\n        Returns a DataFrame with the properties of all repositories in the project directory. The returned DataFrame\n        will have the columns:\n\n         * local_directory\n         * branches\n         * bare\n         * remotes\n         * description\n         * references\n         * heads\n         * submodules\n         * tags\n         * active_branch\n\n        :return: DataFrame\n        \"\"\"\n\n        data = [[repo.git_dir,\n                 repo.repo.branches,\n                 repo.repo.bare,\n                 repo.repo.remotes,\n                 repo.repo.description,\n                 repo.repo.references,\n                 repo.repo.heads,\n                 repo.repo.submodules,\n                 repo.repo.tags,\n                 repo.repo.active_branch] for repo in self.repos]\n\n        df = pd.DataFrame(data, columns=[\n            'local_directory',\n            'branches',\n            'bare',\n            'remotes',\n            'description',\n            'references',\n            'heads',\n            'submodules',\n            'tags',\n            'active_branch'\n        ])\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the bus factor of a repository in a specific language.", "response": "def bus_factor(self, ignore_globs=None, include_globs=None, by='projectd'):\n        \"\"\"\n        An experimental heuristic for truck factor of a repository calculated by the current distribution of blame in\n        the repository's primary branch.  The factor is the fewest number of contributors whose contributions make up at\n        least 50% of the codebase's LOC\n\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n\n        :return:\n        \"\"\"\n\n        if by == 'file':\n            raise NotImplementedError('File-wise bus factor')\n        elif by == 'projectd':\n            blame = self.blame(ignore_globs=ignore_globs, include_globs=include_globs, by='repository')\n            blame = blame.sort_values(by=['loc'], ascending=False)\n\n            total = blame['loc'].sum()\n            cumulative = 0\n            tc = 0\n            for idx in range(blame.shape[0]):\n                cumulative += blame.ix[idx, 'loc']\n                tc += 1\n                if cumulative >= total / 2:\n                    break\n\n            return pd.DataFrame([['projectd', tc]], columns=['projectd', 'bus factor'])\n        elif by == 'repository':\n            df = pd.DataFrame(columns=['repository', 'bus factor'])\n            for repo in self.repos:\n                try:\n                    df = df.append(repo.bus_factor(ignore_globs=include_globs, include_globs=include_globs, by=by))\n                except GitCommandError:\n                    print('Warning! Repo: %s couldn\\'t be inspected' % (repo, ))\n\n            df.reset_index()\n            return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a pandas DataFrame containing all of the data for a punchcard.", "response": "def punchcard(self, branch='master', limit=None, days=None, by=None, normalize=None, ignore_globs=None, include_globs=None):\n        \"\"\"\n        Returns a pandas DataFrame containing all of the data for a punchcard.\n\n         * day_of_week\n         * hour_of_day\n         * author / committer\n         * lines\n         * insertions\n         * deletions\n         * net\n\n        :param branch: the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param days: (optional, default=None) number of days to return, if limit is None\n        :param by: (optional, default=None) agg by options, None for no aggregation (just a high level punchcard), or 'committer', 'author', 'repository'\n        :param normalize: (optional, default=None) if an integer, returns the data normalized to max value of that (for plotting)\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        df = pd.DataFrame()\n\n        if by == 'repository':\n            repo_by = None\n        else:\n            repo_by = by\n\n        for repo in self.repos:\n            try:\n                chunk = repo.punchcard(\n                    branch=branch,\n                    limit=limit,\n                    days=days,\n                    by=repo_by,\n                    normalize=None,\n                    ignore_globs=ignore_globs,\n                    include_globs=include_globs\n                )\n                chunk['repository'] = repo.repo_name\n                df = df.append(chunk)\n            except GitCommandError:\n                print('Warning! Repo: %s couldn\\'t be inspected' % (repo, ))\n\n        df.reset_index()\n\n        aggs = ['hour_of_day', 'day_of_week']\n        if by is not None:\n            aggs.append(by)\n\n        punch_card = df.groupby(aggs).agg({\n            'lines': np.sum,\n            'insertions': np.sum,\n            'deletions': np.sum,\n            'net': np.sum\n        })\n        punch_card.reset_index(inplace=True)\n\n        # normalize all cols\n        if normalize is not None:\n            for col in ['lines', 'insertions', 'deletions', 'net']:\n                punch_card[col] = (punch_card[col] / punch_card[col].sum()) * normalize\n\n        return punch_card"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nestablishes a default - setting listener.", "response": "def default_listener(col_attr, default):\n    \"\"\"Establish a default-setting listener.\"\"\"\n\n    @event.listens_for(col_attr, \"init_scalar\", retval=True, propagate=True)\n    def init_scalar(target, value, dict_):\n\n        if default.is_callable:\n            # the callable of ColumnDefault always accepts a context argument\n            value = default.arg(None)\n        elif default.is_scalar:\n            value = default.arg\n        else:\n            raise NotImplementedError(\n                \"Can't invoke pre-default for a SQL-level column default\")\n\n        dict_[col_attr.key] = value\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_coverage(self):\n\n        if os.path.exists(self.git_dir + os.sep + '.coverage'):\n            try:\n                with open(self.git_dir + os.sep + '.coverage', 'r') as f:\n                    blob = f.read()\n                    blob = blob.split('!')[2]\n                    json.loads(blob)\n                return True\n            except Exception:\n                return False\n        else:\n            return False", "response": "Returns a boolean for is a parseable. coverage file can be found in the repository"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nestimating the time commitement of each author or author in a single coding session.", "response": "def hours_estimate(self, branch='master', grouping_window=0.5, single_commit_hours=0.5, limit=None, days=None,\n                       committer=True, ignore_globs=None, include_globs=None):\n        \"\"\"\n        inspired by: https://github.com/kimmobrunfeldt/git-hours/blob/8aaeee237cb9d9028e7a2592a25ad8468b1f45e4/index.js#L114-L143\n\n        Iterates through the commit history of repo to estimate the time commitement of each author or committer over\n        the course of time indicated by limit/extensions/days/etc.\n\n        :param branch: the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param grouping_window: (optional, default=0.5 hours) the threhold for how close two commits need to be to consider them part of one coding session\n        :param single_commit_hours: (optional, default 0.5 hours) the time range to associate with one single commit\n        :param days: (optional, default=None) number of days to return, if limit is None\n        :param committer: (optional, default=True) whether to use committer vs. author\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        max_diff_in_minutes = grouping_window * 60.0\n        first_commit_addition_in_minutes = single_commit_hours * 60.0\n\n        # First get the commit history\n        ch = self.commit_history(branch=branch, limit=limit, days=days, ignore_globs=ignore_globs,\n                                 include_globs=include_globs)\n\n        # split by committer|author\n        if committer:\n            by = 'committer'\n        else:\n            by = 'author'\n        people = set(ch[by].values)\n\n        ds = []\n        for person in people:\n            commits = ch[ch[by] == person]\n            commits_ts = [x * 10e-10 for x in sorted(commits.index.values.tolist())]\n\n            if len(commits_ts) < 2:\n                ds.append([person, 0])\n                continue\n\n            def estimate(index, date):\n                next_ts = commits_ts[index + 1]\n                diff_in_minutes = next_ts - date\n                diff_in_minutes /= 60.0\n                if diff_in_minutes < max_diff_in_minutes:\n                    return diff_in_minutes / 60.0\n                return first_commit_addition_in_minutes / 60.0\n\n            hours = [estimate(a, b) for a, b in enumerate(commits_ts[:-1])]\n            hours = sum(hours)\n            ds.append([person, hours])\n\n        df = DataFrame(ds, columns=[by, 'hours'])\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a DataFrame of all file changes for the specified branch.", "response": "def file_change_history(self, branch='master', limit=None, days=None, ignore_globs=None, include_globs=None):\n        \"\"\"\n        Returns a DataFrame of all file changes (via the commit history) for the specified branch.  This is similar to\n        the commit history DataFrame, but is one row per file edit rather than one row per commit (which may encapsulate\n        many file changes). Included in the DataFrame will be the columns:\n\n         * date (index)\n         * author\n         * committer\n         * message\n         * filename\n         * insertions\n         * deletions\n\n        :param branch: the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param days: (optional, default=None) number of days to return if limit is None\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        # setup the dataset of commits\n        if limit is None:\n            if days is None:\n                ds = [[\n                          x.author.name,\n                          x.committer.name,\n                          x.committed_date,\n                          x.message,\n                          x.name_rev.split()[0],\n                          self.__check_extension(x.stats.files, ignore_globs=ignore_globs, include_globs=include_globs)\n                      ] for x in self.repo.iter_commits(branch, max_count=sys.maxsize)]\n            else:\n                ds = []\n                c_date = time.time()\n                commits = self.repo.iter_commits(branch, max_count=sys.maxsize)\n                dlim = time.time() - days * 24 * 3600\n                while c_date > dlim:\n                    try:\n                        if sys.version_info.major == 2:\n                            x = commits.next()\n                        else:\n                            x = commits.__next__()\n                    except StopIteration:\n                        break\n\n                    c_date = x.committed_date\n                    if c_date > dlim:\n                        ds.append([\n                            x.author.name,\n                            x.committer.name,\n                            x.committed_date,\n                            x.message,\n                            x.name_rev.split()[0],\n                            self.__check_extension(x.stats.files, ignore_globs=ignore_globs,\n                                                   include_globs=include_globs)\n                        ])\n\n        else:\n            ds = [[\n                      x.author.name,\n                      x.committer.name,\n                      x.committed_date,\n                      x.message,\n                      x.name_rev.split()[0],\n                      self.__check_extension(x.stats.files, ignore_globs=ignore_globs, include_globs=include_globs)\n                  ] for x in self.repo.iter_commits(branch, max_count=limit)]\n\n        ds = [x[:-1] + [fn, x[-1][fn]['insertions'], x[-1][fn]['deletions']] for x in ds for fn in x[-1].keys() if\n              len(x[-1].keys()) > 0]\n\n        # make it a pandas dataframe\n        df = DataFrame(ds,\n                       columns=['author', 'committer', 'date', 'message', 'rev', 'filename', 'insertions', 'deletions'])\n\n        # format the date col and make it the index\n        df['date'] = to_datetime(df['date'].map(datetime.datetime.fromtimestamp))\n        df.set_index(keys=['date'], drop=True, inplace=True)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_change_rates(self, branch='master', limit=None, coverage=False, days=None, ignore_globs=None,\n                          include_globs=None):\n        \"\"\"\n        This function will return a DataFrame containing some basic aggregations of the file change history data, and\n        optionally test coverage data from a coverage_data.py .coverage file.  The aim here is to identify files in the\n        project which have abnormal edit rates, or the rate of changes without growing the files size.  If a file has\n        a high change rate and poor test coverage, then it is a great candidate for writing more tests.\n\n        :param branch: (optional, default=master) the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param coverage: (optional, default=False) a bool for whether or not to attempt to join in coverage data.\n        :param days: (optional, default=None) number of days to return if limit is None\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        fch = self.file_change_history(\n            branch=branch,\n            limit=limit,\n            days=days,\n            ignore_globs=ignore_globs,\n            include_globs=include_globs\n        )\n        fch.reset_index(level=0, inplace=True)\n\n        if fch.shape[0] > 0:\n            file_history = fch.groupby('filename').agg(\n                {\n                    'insertions': [np.sum, np.max, np.mean],\n                    'deletions': [np.sum, np.max, np.mean],\n                    'message': lambda x: ','.join(['\"' + str(y) + '\"' for y in x]),\n                    'committer': lambda x: ','.join(['\"' + str(y) + '\"' for y in x]),\n                    'author': lambda x: ','.join(['\"' + str(y) + '\"' for y in x]),\n                    'date': [np.max, np.min]\n                }\n            )\n\n            file_history.columns = [' '.join(col).strip() for col in file_history.columns.values]\n\n            file_history = file_history.rename(columns={\n                'message <lambda>': 'messages',\n                'committer <lambda>': 'committers',\n                'insertions sum': 'total_insertions',\n                'insertions amax': 'max_insertions',\n                'insertions mean': 'mean_insertions',\n                'author <lambda>': 'authors',\n                'date amax': 'max_date',\n                'date amin': 'min_date',\n                'deletions sum': 'total_deletions',\n                'deletions amax': 'max_deletions',\n                'deletions mean': 'mean_deletions'\n            })\n\n            # get some building block values for later use\n            file_history['net_change'] = file_history['total_insertions'] - file_history['total_deletions']\n            file_history['abs_change'] = file_history['total_insertions'] + file_history['total_deletions']\n            file_history['delta_time'] = file_history['max_date'] - file_history['min_date']\n\n            try:\n                file_history['delta_days'] = file_history['delta_time'].map(\n                    lambda x: np.ceil(x.seconds / (24 * 3600) + 0.01))\n            except AttributeError as e:\n                file_history['delta_days'] = file_history['delta_time'].map(\n                    lambda x: np.ceil((float(x.total_seconds()) * 10e-6) / (24 * 3600) + 0.01))\n\n            # calculate metrics\n            file_history['net_rate_of_change'] = file_history['net_change'] / file_history['delta_days']\n            file_history['abs_rate_of_change'] = file_history['abs_change'] / file_history['delta_days']\n            file_history['edit_rate'] = file_history['abs_rate_of_change'] - file_history['net_rate_of_change']\n            file_history['unique_committers'] = file_history['committers'].map(lambda x: len(set(x.split(','))))\n\n            # reindex\n            file_history = file_history.reindex(\n                columns=['unique_committers', 'abs_rate_of_change', 'net_rate_of_change', 'net_change', 'abs_change',\n                         'edit_rate'])\n            file_history.sort_values(by=['edit_rate'], inplace=True)\n\n            if coverage and self.has_coverage():\n                file_history = file_history.merge(self.coverage(), left_index=True, right_on='filename', how='outer')\n                file_history.set_index(keys=['filename'], drop=True, inplace=True)\n        else:\n            file_history = DataFrame(\n                columns=['unique_committers', 'abs_rate_of_change', 'net_rate_of_change', 'net_change', 'abs_change',\n                         'edit_rate'])\n\n        return file_history", "response": "This function returns a DataFrame containing some basic aggregations of the file change history data and a coverage data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __check_extension(files, ignore_globs=None, include_globs=None):\n\n        if include_globs is None or include_globs == []:\n            include_globs = ['*']\n\n        out = {}\n        for key in files.keys():\n            # count up the number of patterns in the ignore globs list that match\n            if ignore_globs is not None:\n                count_exclude = sum([1 if fnmatch.fnmatch(key, g) else 0 for g in ignore_globs])\n            else:\n                count_exclude = 0\n\n            # count up the number of patterns in the include globs list that match\n            count_include = sum([1 if fnmatch.fnmatch(key, g) else 0 for g in include_globs])\n\n            # if we have one vote or more to include and none to exclude, then we use the file.\n            if count_include > 0 and count_exclude == 0:\n                out[key] = files[key]\n\n        return out", "response": "Internal method to filter a list of file changes by extension and ignore_dirs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef blame(self, rev='HEAD', committer=True, by='repository', ignore_globs=None, include_globs=None):\n\n        blames = []\n        file_names = [x for x in self.repo.git.log(pretty='format:', name_only=True, diff_filter='A').split('\\n') if\n                      x.strip() != '']\n        for file in self.__check_extension({x: x for x in file_names}, ignore_globs=ignore_globs,\n                                           include_globs=include_globs).keys():\n            try:\n                blames.append(\n                    [x + [str(file).replace(self.git_dir + '/', '')] for x in\n                     self.repo.blame(rev, str(file).replace(self.git_dir + '/', ''))]\n                )\n            except GitCommandError:\n                pass\n\n        blames = [item for sublist in blames for item in sublist]\n        if committer:\n            if by == 'repository':\n                blames = DataFrame(\n                    [[x[0].committer.name, len(x[1])] for x in blames],\n                    columns=['committer', 'loc']\n                ).groupby('committer').agg({'loc': np.sum})\n            elif by == 'file':\n                blames = DataFrame(\n                    [[x[0].committer.name, len(x[1]), x[2]] for x in blames],\n                    columns=['committer', 'loc', 'file']\n                ).groupby(['committer', 'file']).agg({'loc': np.sum})\n        else:\n            if by == 'repository':\n                blames = DataFrame(\n                    [[x[0].author.name, len(x[1])] for x in blames],\n                    columns=['author', 'loc']\n                ).groupby('author').agg({'loc': np.sum})\n            elif by == 'file':\n                blames = DataFrame(\n                    [[x[0].author.name, len(x[1]), x[2]] for x in blames],\n                    columns=['author', 'loc', 'file']\n                ).groupby(['author', 'file']).agg({'loc': np.sum})\n\n        return blames", "response": "Returns the blame of the current HEAD of the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef revs(self, branch='master', limit=None, skip=None, num_datapoints=None):\n\n        if limit is None and skip is None and num_datapoints is not None:\n            limit = sum(1 for _ in self.repo.iter_commits())\n            skip = int(float(limit) / num_datapoints)\n        else:\n            if limit is None:\n                limit = sys.maxsize\n            elif skip is not None:\n                limit = limit * skip\n\n        ds = [[x.committed_date, x.name_rev.split(' ')[0]] for x in self.repo.iter_commits(branch, max_count=limit)]\n        df = DataFrame(ds, columns=['date', 'rev'])\n\n        if skip is not None:\n            if skip == 0:\n                skip = 1\n\n            if df.shape[0] >= skip:\n                df = df.ix[range(0, df.shape[0], skip)]\n                df.reset_index()\n            else:\n                df = df.ix[[0]]\n                df.reset_index()\n\n        return df", "response": "Returns a dataframe of all revision tags and their timestamps."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the cumulative blame at every revision of interest.", "response": "def cumulative_blame(self, branch='master', limit=None, skip=None, num_datapoints=None, committer=True,\n                         ignore_globs=None, include_globs=None):\n        \"\"\"\n        Returns the blame at every revision of interest. Index is a datetime, column per committer, with number of lines\n        blamed to each committer at each timestamp as data.\n\n        :param branch: (optional, default 'master') the branch to work in\n        :param limit: (optional, default None), the maximum number of revisions to return, None for no limit\n        :param skip: (optional, default None), the number of revisions to skip. Ex: skip=2 returns every other revision, None for no skipping.\n        :param num_datapoints: (optional, default=None) if limit and skip are none, and this isn't, then num_datapoints evenly spaced revs will be used\n        :param committer: (optional, defualt=True) true if committer should be reported, false if author\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n\n        \"\"\"\n\n        revs = self.revs(branch=branch, limit=limit, skip=skip, num_datapoints=num_datapoints)\n\n        # get the commit history to stub out committers (hacky and slow)\n        if sys.version_info.major == 2:\n            committers = set([x.committer.name for x in self.repo.iter_commits(branch, max_count=sys.maxsize)])\n        else:\n            committers = {x.committer.name for x in self.repo.iter_commits(branch, max_count=sys.maxsize)}\n\n        for y in committers:\n            revs[y] = 0\n\n        if self.verbose:\n            print('Beginning processing for cumulative blame:')\n\n        # now populate that table with some actual values\n        for idx, row in revs.iterrows():\n            if self.verbose:\n                print('%s. [%s] getting blame for rev: %s' % (\n                str(idx), datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'), row.rev,))\n\n            blame = self.blame(rev=row.rev, committer=committer, ignore_globs=ignore_globs, include_globs=include_globs)\n            for y in committers:\n                try:\n                    loc = blame.loc[y, 'loc']\n                    revs.set_value(idx, y, loc)\n                except KeyError:\n                    pass\n\n        del revs['rev']\n\n        revs['date'] = to_datetime(revs['date'].map(datetime.datetime.fromtimestamp))\n        revs.set_index(keys=['date'], drop=True, inplace=True)\n        revs = revs.fillna(0.0)\n\n        # drop 0 cols\n        for col in revs.columns.values:\n            if col != 'col':\n                if revs[col].sum() == 0:\n                    del revs[col]\n\n        # drop 0 rows\n        keep_idx = []\n        committers = [x for x in revs.columns.values if x != 'date']\n        for idx, row in revs.iterrows():\n            if sum([row[x] for x in committers]) > 0:\n                keep_idx.append(idx)\n\n        revs = revs.ix[keep_idx]\n\n        return revs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parallel_cumulative_blame(self, branch='master', limit=None, skip=None, num_datapoints=None, committer=True,\n                                  workers=1, ignore_globs=None, include_globs=None):\n        \"\"\"\n        Returns the blame at every revision of interest. Index is a datetime, column per committer, with number of lines\n        blamed to each committer at each timestamp as data.\n\n        :param branch: (optional, default 'master') the branch to work in\n        :param limit: (optional, default None), the maximum number of revisions to return, None for no limit\n        :param skip: (optional, default None), the number of revisions to skip. Ex: skip=2 returns every other revision, None for no skipping.\n        :param num_datapoints: (optional, default=None) if limit and skip are none, and this isn't, then num_datapoints evenly spaced revs will be used\n        :param committer: (optional, defualt=True) true if committer should be reported, false if author\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :param workers: (optional, default=1) integer, the number of workers to use in the threadpool, -1 for one per core.\n        :return: DataFrame\n\n        \"\"\"\n\n        if not _has_joblib:\n            raise ImportError('''Must have joblib installed to use parallel_cumulative_blame(), please use\n            cumulative_blame() instead.''')\n\n        revs = self.revs(branch=branch, limit=limit, skip=skip, num_datapoints=num_datapoints)\n\n        if self.verbose:\n            print('Beginning processing for cumulative blame:')\n\n        revisions = json.loads(revs.to_json(orient='index'))\n        revisions = [revisions[key] for key in revisions]\n\n        ds = Parallel(n_jobs=workers, backend='threading', verbose=5)(\n            delayed(_parallel_cumulative_blame_func)\n            (self, x, committer, ignore_globs, include_globs) for x in revisions\n        )\n\n        revs = DataFrame(ds)\n        del revs['rev']\n\n        revs['date'] = to_datetime(revs['date'].map(datetime.datetime.fromtimestamp))\n        revs.set_index(keys=['date'], drop=True, inplace=True)\n        revs = revs.fillna(0.0)\n\n        # drop 0 cols\n        for col in revs.columns.values:\n            if col != 'col':\n                if revs[col].sum() == 0:\n                    del revs[col]\n\n        # drop 0 rows\n        keep_idx = []\n        committers = [x for x in revs.columns.values if x != 'date']\n        for idx, row in revs.iterrows():\n            if sum([row[x] for x in committers]) > 0:\n                keep_idx.append(idx)\n\n        revs = revs.ix[keep_idx]\n        revs.sort_index(ascending=False, inplace=True)\n\n        return revs", "response": "Returns the cumulative blame of the revision of interest at every timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a DataFrame of all branches in origin.", "response": "def branches(self):\n        \"\"\"\n        Returns a data frame of all branches in origin.  The DataFrame will have the columns:\n\n         * repository\n         * branch\n         * local\n\n        :returns: DataFrame\n        \"\"\"\n\n        # first pull the local branches\n        local_branches = self.repo.branches\n        data = [[x.name, True] for x in list(local_branches)]\n\n        # then the remotes\n        remote_branches = self.repo.git.branch(all=True).split('\\n')\n        if sys.version_info.major == 2:\n            remote_branches = set([x.split('/')[-1] for x in remote_branches if 'remotes' in x])\n        else:\n            remote_branches = {x.split('/')[-1] for x in remote_branches if 'remotes' in x}\n\n        data += [[x, False] for x in remote_branches]\n\n        df = DataFrame(data, columns=['branch', 'local'])\n        df['repository'] = self._repo_name()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a DataFrame of all tags in origin.", "response": "def tags(self):\n        \"\"\"\n        Returns a data frame of all tags in origin.  The DataFrame will have the columns:\n\n         * repository\n         * tag\n\n        :returns: DataFrame\n        \"\"\"\n\n        tags = self.repo.tags\n        df = DataFrame([x.name for x in list(tags)], columns=['tag'])\n        df['repository'] = self._repo_name()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _repo_name(self):\n\n        if self._git_repo_name is not None:\n            return self._git_repo_name\n        else:\n            reponame = self.repo.git_dir.split(os.sep)[-2]\n            if reponame.strip() == '':\n                return 'unknown_repo'\n            return reponame", "response": "Returns the name of the repository using the local directory name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bus_factor(self, by='repository', ignore_globs=None, include_globs=None):\n\n        if by == 'file':\n            raise NotImplementedError('File-wise bus factor')\n\n        blame = self.blame(include_globs=include_globs, ignore_globs=ignore_globs, by=by)\n        blame = blame.sort_values(by=['loc'], ascending=False)\n\n        total = blame['loc'].sum()\n        cumulative = 0\n        tc = 0\n        for idx in range(blame.shape[0]):\n            cumulative += blame.ix[idx, 'loc']\n            tc += 1\n            if cumulative >= total / 2:\n                break\n\n        return DataFrame([[self._repo_name(), tc]], columns=['repository', 'bus factor'])", "response": "Calculates the bus factor of a repository"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the owner of a given file in a given revision. Returns None if the file is not in a given revision.", "response": "def file_owner(self, rev, filename, committer=True):\n        \"\"\"\n        Returns the owner (by majority blame) of a given file in a given rev. Returns the committers' name.\n\n        :param rev:\n        :param filename:\n        :param committer:\n        \"\"\"\n        try:\n            if committer:\n                cm = 'committer'\n            else:\n                cm = 'author'\n\n            blame = self.repo.blame(rev, os.path.join(self.git_dir, filename))\n            blame = DataFrame([[x[0].committer.name, len(x[1])] for x in blame], columns=[cm, 'loc']).groupby(cm).agg(\n                {'loc': np.sum})\n            if blame.shape[0] > 0:\n                return blame['loc'].idxmax()\n            else:\n                return None\n        except (GitCommandError, KeyError):\n            if self.verbose:\n                print('Couldn\\'t Calcualte File Owner for %s' % (rev,))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a table of all current files in the repos with some high level information about each file.", "response": "def file_detail(self, include_globs=None, ignore_globs=None, rev='HEAD', committer=True):\n        \"\"\"\n        Returns a table of all current files in the repos, with some high level information about each file (total LOC,\n        file owner, extension, most recent edit date, etc.).\n\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :param committer: (optional, default=True) true if committer should be reported, false if author\n        :return:\n        \"\"\"\n\n        # first get the blame\n        blame = self.blame(\n            include_globs=include_globs,\n            ignore_globs=ignore_globs,\n            rev=rev,\n            committer=committer,\n            by='file'\n        )\n        blame = blame.reset_index(level=1)\n        blame = blame.reset_index(level=1)\n\n        # reduce it to files and total LOC\n        df = blame.reindex(columns=['file', 'loc'])\n        df = df.groupby('file').agg({'loc': np.sum})\n        df = df.reset_index(level=1)\n\n        # map in file owners\n        df['file_owner'] = df['file'].map(lambda x: self.file_owner(rev, x, committer=committer))\n\n        # add extension (something like the language)\n        df['ext'] = df['file'].map(lambda x: x.split('.')[-1])\n\n        # add in last edit date for the file\n        df['last_edit_date'] = df['file'].map(self._file_last_edit)\n        df['last_edit_date'] = to_datetime(df['last_edit_date'])\n\n        df = df.set_index('file')\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pandas DataFrame containing all of the data for a punchcard.", "response": "def punchcard(self, branch='master', limit=None, days=None, by=None, normalize=None, ignore_globs=None,\n                  include_globs=None):\n        \"\"\"\n        Returns a pandas DataFrame containing all of the data for a punchcard.\n\n         * day_of_week\n         * hour_of_day\n         * author / committer\n         * lines\n         * insertions\n         * deletions\n         * net\n\n        :param branch: the branch to return commits for\n        :param limit: (optional, default=None) a maximum number of commits to return, None for no limit\n        :param days: (optional, default=None) number of days to return, if limit is None\n        :param by: (optional, default=None) agg by options, None for no aggregation (just a high level punchcard), or 'committer', 'author'\n        :param normalize: (optional, default=None) if an integer, returns the data normalized to max value of that (for plotting)\n        :param ignore_globs: (optional, default=None) a list of globs to ignore, default none excludes nothing\n        :param include_globs: (optinal, default=None) a list of globs to include, default of None includes everything.\n        :return: DataFrame\n        \"\"\"\n\n        ch = self.commit_history(\n            branch=branch,\n            limit=limit,\n            days=days,\n            ignore_globs=ignore_globs,\n            include_globs=include_globs\n        )\n\n        # add in the date fields\n        ch['day_of_week'] = ch.index.map(lambda x: x.weekday())\n        ch['hour_of_day'] = ch.index.map(lambda x: x.hour)\n\n        aggs = ['hour_of_day', 'day_of_week']\n        if by is not None:\n            aggs.append(by)\n\n        punch_card = ch.groupby(aggs).agg({\n            'lines': np.sum,\n            'insertions': np.sum,\n            'deletions': np.sum,\n            'net': np.sum\n        })\n        punch_card.reset_index(inplace=True)\n\n        # normalize all cols\n        if normalize is not None:\n            for col in ['lines', 'insertions', 'deletions', 'net']:\n                punch_card[col] = (punch_card[col] / punch_card[col].sum()) * normalize\n\n        return punch_card"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_punchcard(df, metric='lines', title='punchcard', by=None):\n\n    if not HAS_MPL:\n        raise ImportError('Must have matplotlib installed to use the plotting functions')\n\n    # find how many plots we are making\n    if by is not None:\n        unique_vals = set(df[by].values.tolist())\n    else:\n        unique_vals = ['foo']\n    for idx, val in enumerate(unique_vals):\n        if by is not None:\n            sub_df = df[df[by] == val]\n        else:\n            sub_df = df\n        fig = plt.figure(figsize=(8, title and 3 or 2.5), facecolor='#ffffff')\n        ax = fig.add_subplot('111', axisbg='#ffffff')\n        fig.subplots_adjust(left=0.06, bottom=0.04, right=0.98, top=0.95)\n        if by is not None:\n            ax.set_title(title + ' (%s)' % (str(val), ), y=0.96).set_color('#333333')\n        else:\n            ax.set_title(title, y=0.96).set_color('#333333')\n        ax.set_frame_on(False)\n        ax.scatter(sub_df['hour_of_day'], sub_df['day_of_week'], s=sub_df[metric], c='#333333', edgecolor='#333333')\n        for line in ax.get_xticklines() + ax.get_yticklines():\n            line.set_alpha(0.0)\n        dist = -0.8\n        ax.plot([dist, 23.5], [dist, dist], c='#555555')\n        ax.plot([dist, dist], [dist, 6.4], c='#555555')\n        ax.set_xlim(-1, 24)\n        ax.set_ylim(-0.9, 6.9)\n        ax.set_yticks(range(7))\n        for tx in ax.set_yticklabels(['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun']):\n            tx.set_color('#555555')\n            tx.set_size('x-small')\n        ax.set_xticks(range(24))\n        for tx in ax.set_xticklabels(['%02d' % x for x in range(24)]):\n            tx.set_color('#555555')\n            tx.set_size('x-small')\n        ax.set_aspect('equal')\n        if idx + 1 == len(unique_vals):\n            plt.show(block=True)\n        else:\n            plt.show(block=False)", "response": "Plots the punchcard of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _decode(self, obj, context):\n        return b''.join(map(int2byte, [c + 0x60 for c in bytearray(obj)])).decode(\"utf8\")", "response": "Decode the object into a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a standard non - relational field.", "response": "def build_standard_field(self, field_name, model_field):\n        \"\"\"\n        Creates a default instance of a basic non-relational field.\n        \"\"\"\n        kwargs = {}\n\n        if model_field.null or model_field.blank:\n            kwargs['required'] = False\n\n            if model_field.null:\n                kwargs['allow_null'] = True\n            if model_field.blank and (issubclass(model_field.__class__, models.CharField) or\n                                      (issubclass(model_field.__class__, models.TextField))):\n                kwargs['allow_blank'] = True\n\n        if isinstance(model_field, models.AutoField) or not model_field.editable:\n            kwargs['read_only'] = True\n\n        if model_field.has_default():\n            kwargs['default'] = model_field.get_default()\n\n        if issubclass(model_field.__class__, models.TextField):\n            kwargs['style'] = {'base_template': 'textarea.html'}\n\n        if model_field.verbose_name is not None:\n            kwargs['label'] = model_field.verbose_name\n\n        if model_field.help_text is not None:\n            kwargs['help_text'] = model_field.help_text\n\n        # TODO: TypedChoiceField?\n        if model_field.flatchoices:  # This ModelField contains choices\n            kwargs['choices'] = model_field.flatchoices\n            if model_field.null:\n                kwargs['empty'] = None\n            return (ChoiceField, kwargs)\n\n        # put this below the ChoiceField because min_value isn't a valid initializer\n        if issubclass(model_field.__class__, models.PositiveIntegerField) or\\\n                issubclass(model_field.__class__, models.PositiveSmallIntegerField):\n            kwargs['min_value'] = 0\n\n        attribute_dict = {\n            models.CharField: ['max_length'],\n            models.CommaSeparatedIntegerField: ['max_length'],\n            models.DecimalField: ['max_digits', 'decimal_places'],\n            models.EmailField: ['max_length'],\n            models.FileField: ['max_length'],\n            models.ImageField: ['max_length'],\n            models.SlugField: ['max_length'],\n            models.URLField: ['max_length'],\n        }\n\n        # === django-rest-framework-hstore specific ====\n        # if available, use __basefield__ attribute instead of __class__\n        # this will cause DRF to pick the correct DRF-field\n        key = getattr(model_field, '__basefield__', model_field.__class__)\n\n        if key in attribute_dict:\n            attributes = attribute_dict[key]\n            for attribute in attributes:\n                kwargs.update({attribute: getattr(model_field, attribute)})\n\n        if model_field.__class__ == DictionaryField and model_field.schema:\n            kwargs['schema'] = True\n\n        try:\n            return (self.serializer_field_mapping[key], kwargs)\n        except KeyError:\n            pass\n\n        try:\n            return (self.serializer_field_mapping[model_field.__class__.__name__], kwargs)\n        except KeyError:\n            # return ModelField(model_field=model_field, **kwargs)\n            return super(HStoreSerializer, self).build_standard_field(field_name, model_field)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the object with the new data.", "response": "def update(self, instance, validated_data):\n        \"\"\"\n        temporarily remove hstore virtual fields otherwise DRF considers them many2many\n        \"\"\"\n        model = self.Meta.model\n        meta = self.Meta.model._meta\n        original_virtual_fields = list(meta.virtual_fields)  # copy\n\n        if hasattr(model, '_hstore_virtual_fields'):\n            # remove hstore virtual fields from meta\n            for field in model._hstore_virtual_fields.values():\n                meta.virtual_fields.remove(field)\n\n        instance = super(HStoreSerializer, self).update(instance, validated_data)\n\n        if hasattr(model, '_hstore_virtual_fields'):\n            # restore original virtual fields\n            meta.virtual_fields = original_virtual_fields\n\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef display(self, data, x=None, y=None, xlabel=None, ylabel=None,\n                style=None, nlevels=None, levels=None, contour_labels=None,\n                store_data=True, col=0, unzoom=True, auto_contrast=False,\n                contrast_level=0, **kws):\n        \"\"\"\n        generic display, using imshow (default) or contour\n        \"\"\"\n        if style is not None:\n            self.conf.style = style\n        self.axes.cla()\n        conf = self.conf\n        conf.log_scale = False\n        conf.rot, conf.flip_ud, conf.flip_lr = False, False, False\n        conf.highlight_areas = []\n        if 1 in data.shape:\n            data = data.squeeze()\n        self.data_shape = data.shape\n        self.data_range = [0, data.shape[1], 0, data.shape[0]]\n        conf.contrast_level = contrast_level\n        if auto_contrast:\n            conf.contrast_level = 1\n        if x is not None:\n            self.xdata = np.array(x)\n            if self.xdata.shape[0] != data.shape[1]:\n                self.xdata = None\n        if y is not None:\n            self.ydata = np.array(y)\n            if self.ydata.shape[0] != data.shape[0]:\n                self.ydata = None\n\n        if xlabel is not None:\n            self.xlab = xlabel\n        if ylabel is not None:\n            self.ylab = ylabel\n        if store_data:\n            self.conf.data = data\n\n        cmap = self.conf.cmap[col]\n        if self.conf.style == 'contour':\n            if levels is None:\n                levels = self.conf.ncontour_levels\n            else:\n                self.conf.ncontour_levels = levels\n            if nlevels is None:\n                nlevels = self.conf.ncontour_levels = 9\n            nlevels = max(2, nlevels)\n            clevels  = np.linspace(data.min(), data.max(), nlevels+1)\n            self.conf.contour_levels = clevels\n            self.conf.image = self.axes.contourf(data, cmap=self.conf.cmap[col],\n                                                 levels=clevels)\n\n            self.conf.contour = self.axes.contour(data, cmap=self.conf.cmap[col],\n                                                  levels=clevels)\n            cmap_name = self.conf.cmap[col].name\n            xname = 'gray'\n            try:\n                if cmap_name == 'gray_r':\n                    xname = 'Reds_r'\n                elif cmap_name == 'gray':\n                    xname = 'Reds'\n                elif cmap_name.endswith('_r'):\n                    xname = 'gray_r'\n            except:\n                pass\n            self.conf.contour.set_cmap(getattr(colormap, xname))\n\n            if contour_labels is None:\n                contour_labels = self.conf.contour_labels\n            if contour_labels:\n                self.axes.clabel(self.conf.contour, fontsize=10, inline=1)\n            if hasattr(self.contour_callback , '__call__'):\n                self.contour_callback(levels=clevels)\n        else:\n            if data.max() == data.min():\n                img = data\n            else:\n                img = (data - data.min()) /(1.0*data.max() - data.min())\n            self.conf.image = self.axes.imshow(img, cmap=self.conf.cmap[col],\n                                               interpolation=self.conf.interp)\n\n        self.axes.set_axis_off()\n        if unzoom:\n            self.unzoom_all()\n        if hasattr(self.data_callback, '__call__'):\n            self.data_callback(data, x=x, y=y, **kws)\n\n        self.conf.indices = None\n        self.indices_thread = Thread(target=self.calc_indices, args=(data.shape, ))\n        self.indices_thread.start()", "response": "displays the data in the current image"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating image on panel as quickly as possible", "response": "def update_image(self, data):\n        \"\"\"\n        update image on panel, as quickly as possible\n        \"\"\"\n        if 1 in data.shape:\n            data = data.squeeze()\n        if self.conf.contrast_level is not None:\n            clevels = [self.conf.contrast_level, 100.0-self.conf.contrast_level]\n            imin, imax = np.percentile(data, clevels)\n            data = np.clip((data - imin)/(imax - imin + 1.e-8), 0, 1)\n        self.axes.images[0].set_data(data)\n        self.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_highlight_area(self, mask, label=None, col=0):\n        patch = mask * np.ones(mask.shape) * 0.9\n        cmap = self.conf.cmap[col]\n        area = self.axes.contour(patch, cmap=cmap, levels=[0, 1])\n        self.conf.highlight_areas.append(area)\n        col = None\n        if hasattr(cmap, '_lut'):\n            rgb  = [int(i*240)^255 for i in cmap._lut[0][:3]]\n            col  = '#%02x%02x%02x' % (rgb[0], rgb[1], rgb[2])\n\n        if label is not None:\n            def fmt(*args, **kws): return label\n            self.axes.clabel(area, fontsize=9, fmt=fmt,\n                             colors=col, rightside_up=True)\n\n        if col is not None:\n            for l in area.collections:\n                l.set_color(col)\n\n        self.canvas.draw()", "response": "add a highlighted area"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate xy limits of a plot", "response": "def set_viewlimits(self, axes=None):\n        \"\"\" update xy limits of a plot\"\"\"\n        if axes is None:\n            axes = self.axes\n\n        xmin, xmax, ymin, ymax = self.data_range\n        if len(self.conf.zoom_lims) >1:\n            zlims = self.conf.zoom_lims[-1]\n            if axes in zlims:\n                xmin, xmax, ymin, ymax = zlims[axes]\n\n        xmin = max(self.data_range[0], xmin)\n        xmax = min(self.data_range[1], xmax)\n        ymin = max(self.data_range[2], ymin)\n        ymax = min(self.data_range[3], ymax)\n        if (xmax < self.data_range[0] or\n            xmin > self.data_range[1] or\n            ymax < self.data_range[2] or\n            ymin > self.data_range[3] ):\n            self.conf.zoom_lims.pop()\n            return\n\n        if abs(xmax-xmin) < 2:\n            xmin = int(0.5*(xmax+xmin) - 1)\n            xmax = xmin + 2\n\n        if abs(ymax-ymin) < 2:\n            ymin = int(0.5*(ymax+xmin) - 1)\n            ymax = ymin + 2\n\n        self.axes.set_xlim((xmin, xmax),emit=True)\n        self.axes.set_ylim((ymin, ymax),emit=True)\n        self.axes.update_datalim(((xmin, ymin), (xmax, ymax)))\n\n        self.conf.datalimits = [xmin, xmax, ymin, ymax]\n        self.redraw()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef BuildPanel(self):\n        figsize = (1.0*self.size[0]/self.dpi, 1.0*self.size[1]/self.dpi)\n        self.fig   = Figure(figsize, dpi=self.dpi)\n        self.axes  = self.fig.add_axes([0.0, 0.0, 1.0, 1.0])\n\n        self.canvas = FigureCanvasWxAgg(self, -1, self.fig)\n        self.fig.set_facecolor('#FFFFFD')\n\n        self.conf.axes  = self.axes\n        self.conf.fig   = self.fig\n        self.conf.canvas= self.canvas\n\n        # self.canvas.SetCursor(wx.StockCursor(wx.CURSOR_ARROW))\n        # This way of adding to sizer allows resizing\n        sizer = wx.BoxSizer(wx.HORIZONTAL)\n        sizer.Add(self.canvas, 1, wx.ALL|wx.GROW)\n        self.SetSizer(sizer)\n        self.Fit()\n        self.addCanvasEvents()", "response": "builds basic GUI panel and popup menu"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_indices(self, shape):\n        if len(shape) == 2:\n            ny, nx = shape\n        elif len(shape) == 3:\n            ny, nx, nchan = shape\n\n        inds = []\n        for iy in range(ny):\n            inds.extend([(ix, iy) for ix in range(nx)])\n        self.conf.indices = np.array(inds)", "response": "calculates and stores the set of indices for the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nzoom out 1 level, or to full data range", "response": "def unzoom(self, event=None, set_bounds=True):\n        \"\"\" zoom out 1 level, or to full data range \"\"\"\n        lims = None\n        if len(self.conf.zoom_lims) > 1:\n            lims = self.conf.zoom_lims.pop()\n        ax = self.axes\n        if lims is None: # auto scale\n            self.conf.zoom_lims = [None]\n            xmin, xmax, ymin, ymax = self.data_range\n            lims = {self.axes: [xmin, xmax, ymin, ymax]}\n        self.set_viewlimits()\n        self.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef zoom_leftup(self, event=None):\n        if self.zoom_ini is None:\n            return\n\n        ini_x, ini_y, ini_xd, ini_yd = self.zoom_ini\n        try:\n            dx = abs(ini_x - event.x)\n            dy = abs(ini_y - event.y)\n        except:\n            dx, dy = 0, 0\n        t0 = time.time()\n        self.rbbox = None\n        self.zoom_ini = None\n        if (dx > 3) and (dy > 3) and (t0-self.mouse_uptime)>0.1:\n            self.mouse_uptime = t0\n            zlims, tlims = {}, {}\n            ax =  self.axes\n            xmin, xmax = ax.get_xlim()\n            ymin, ymax = ax.get_ylim()\n\n            zlims[ax] = [xmin, xmax, ymin, ymax]\n\n            if len(self.conf.zoom_lims) == 0:\n                self.conf.zoom_lims.append(zlims)\n\n\n            ax_inv = ax.transData.inverted\n            try:\n                x1, y1 = ax_inv().transform((event.x, event.y))\n            except:\n                x1, y1 = self.x_lastmove, self.y_lastmove\n            try:\n                x0, y0 = ax_inv().transform((ini_x, ini_y))\n            except:\n                x0, y0 = ini_xd, ini_yd\n\n            tlims[ax] = [int(round(min(x0, x1))), int(round(max(x0, x1))),\n                         int(round(min(y0, y1))), int(round(max(y0, y1)))]\n            self.conf.zoom_lims.append(tlims)\n            # now apply limits:\n            self.set_viewlimits()\n            if callable(self.zoom_callback):\n                self.zoom_callback(wid=self.GetId(), limits=tlims[ax])", "response": "leftup event handler for zoom mode in images"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef redraw(self, col=0):\n        conf = self.conf\n        # note: rotation re-calls display(), to reset the image\n        # other transformations will just do .set_data() on image\n        if conf.rot:\n            if self.xdata is not None:\n                self.xdata = self.xdata[::-1]\n            if self.ydata is not None:\n                self.ydata = self.ydata[:]\n\n            self.display(np.rot90(conf.data),\n                         x=self.ydata, xlabel=self.ylab,\n                         y=self.xdata, ylabel=self.xlab)\n        # flips, log scales\n        img = conf.data\n        if img is None: return\n        if len(img.shape) == 2:\n            col = 0\n        if self.conf.style == 'image':\n            if conf.flip_ud:   img = np.flipud(img)\n            if conf.flip_lr:   img = np.fliplr(img)\n            if conf.log_scale:\n                img = np.log10(1 + 9.0*img)\n\n        # apply intensity scale for current limited (zoomed) image\n        if len(img.shape) == 2:\n            # apply clipped color scale, as from sliders\n\n            imin = float(conf.int_lo[col])\n            imax = float(conf.int_hi[col])\n            if conf.log_scale:\n                imin = np.log10(1 + 9.0*imin)\n                imax = np.log10(1 + 9.0*imax)\n\n            (xmin, xmax, ymin, ymax) = self.conf.datalimits\n            if xmin is None:  xmin = 0\n            if xmax is None:  xmax = img.shape[1]\n            if ymin is None:  ymin = 0\n            if ymax is None:  ymax = img.shape[0]\n\n\n            img = (img - imin)/(imax - imin + 1.e-8)\n            mlo = conf.cmap_lo[0]/(1.0*conf.cmap_range)\n            mhi = conf.cmap_hi[0]/(1.0*conf.cmap_range)\n            if self.conf.style == 'image':\n                conf.image.set_data(np.clip((img - mlo)/(mhi - mlo + 1.e-8), 0, 1))\n                conf.image.set_interpolation(conf.interp)\n        else:\n            r, g, b = img[:,:,0], img[:,:,1], img[:,:,2]\n\n            rmin = float(conf.int_lo[0])\n            rmax = float(conf.int_hi[0])\n            gmin = float(conf.int_lo[1])\n            gmax = float(conf.int_hi[1])\n            bmin = float(conf.int_lo[2])\n            bmax = float(conf.int_hi[2])\n            if conf.log_scale:\n                rmin = np.log10(1 + 9.0*rmin)\n                rmax = np.log10(1 + 9.0*rmax)\n                gmin = np.log10(1 + 9.0*gmin)\n                gmax = np.log10(1 + 9.0*gmax)\n                bmin = np.log10(1 + 9.0*bmin)\n                bmax = np.log10(1 + 9.0*bmax)\n\n            rlo = conf.cmap_lo[0]/(1.0*conf.cmap_range)\n            rhi = conf.cmap_hi[0]/(1.0*conf.cmap_range)\n            glo = conf.cmap_lo[1]/(1.0*conf.cmap_range)\n            ghi = conf.cmap_hi[1]/(1.0*conf.cmap_range)\n            blo = conf.cmap_lo[2]/(1.0*conf.cmap_range)\n            bhi = conf.cmap_hi[2]/(1.0*conf.cmap_range)\n            r = (r - rmin)/(rmax - rmin + 1.e-8)\n            g = (g - gmin)/(gmax - gmin + 1.e-8)\n            b = (b - bmin)/(bmax - bmin + 1.e-8)\n\n            inew = img*1.0\n            inew[:,:,0] = np.clip((r - rlo)/(rhi - rlo + 1.e-8), 0, 1)\n            inew[:,:,1] = np.clip((g - glo)/(ghi - glo + 1.e-8), 0, 1)\n            inew[:,:,2] = np.clip((b - blo)/(bhi - blo + 1.e-8), 0, 1)\n\n            whitebg = conf.tricolor_bg.startswith('wh')\n\n            if whitebg:\n                inew = conf.tricolor_white_bg(inew)\n\n            if self.conf.style == 'image':\n                conf.image.set_data(inew)\n                conf.image.set_interpolation(conf.interp)\n        self.canvas.draw()\n        if callable(self.redraw_callback):\n            self.redraw_callback(wid=self.GetId())", "response": "redraw image with the specified color map and interpolation"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collect_directories(self, directories):\n        directories = util.to_absolute_paths(directories)\n\n        if not self.recursive:\n            return self._remove_blacklisted(directories)\n\n        recursive_dirs = set()\n        for dir_ in directories:\n            walk_iter = os.walk(dir_, followlinks=True)\n            walk_iter = [w[0] for w in walk_iter]\n            walk_iter = util.to_absolute_paths(walk_iter)\n            walk_iter = self._remove_blacklisted(walk_iter)\n            recursive_dirs.update(walk_iter)\n        return recursive_dirs", "response": "Collect all the directories into a set object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_directories(self, directories, except_blacklisted=True):\n        directories = util.to_absolute_paths(directories)\n        if except_blacklisted:\n            directories = self._remove_blacklisted(directories)\n\n        self.plugin_directories.update(directories)", "response": "Adds directories to the set of plugin directories."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the plugin directories to directories.", "response": "def set_directories(self, directories, except_blacklisted=True):\n        \"\"\"\n        Sets the plugin directories to `directories`. This will delete\n        the previous state stored in `self.plugin_directories` in favor\n        of the `directories` passed in.\n\n        `directories` may be either a single object or an iterable.\n\n        `directories` can contain relative paths but will be\n        converted into absolute paths based on the current working\n        directory.\n\n        if `except_blacklisted` is `True` all `directories` in\n        `self.blacklisted_directories` will be removed\n        \"\"\"\n        directories = util.to_absolute_paths(directories)\n        if except_blacklisted:\n            directories = self._remove_blacklisted(directories)\n\n        self.plugin_directories = directories"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves any directories from the set of plugin directories.", "response": "def remove_directories(self, directories):\n        \"\"\"\n        Removes any `directories` from the set of plugin directories.\n\n        `directories` may be a single object or an iterable.\n\n        Recommend passing in all paths as absolute, but the method will\n        attemmpt to convert all paths to absolute if they are not already\n        based on the current working directory.\n        \"\"\"\n        directories = util.to_absolute_paths(directories)\n        self.plugin_directories = util.remove_from_set(self.plugin_directories,\n                                                       directories)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_blacklisted_directories(self,\n                                    directories,\n                                    remove_from_stored_directories=True):\n\n        \"\"\"\n        Adds `directories` to be blacklisted. Blacklisted directories will not\n        be returned or searched recursively when calling the\n        `collect_directories` method.\n\n        `directories` may be a single instance or an iterable. Recommend\n        passing in absolute paths, but method will try to convert to absolute\n        paths based on the current working directory.\n\n        If `remove_from_stored_directories` is true, all `directories`\n        will be removed from `self.plugin_directories`\n        \"\"\"\n        absolute_paths = util.to_absolute_paths(directories)\n        self.blacklisted_directories.update(absolute_paths)\n        if remove_from_stored_directories:\n            plug_dirs = self.plugin_directories\n            plug_dirs = util.remove_from_set(plug_dirs,\n                                             directories)", "response": "Adds directories to blacklisted directories."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the directories to be blacklisted.", "response": "def set_blacklisted_directories(self,\n                                    directories,\n                                    remove_from_stored_directories=True):\n        \"\"\"\n        Sets the `directories` to be blacklisted. Blacklisted directories will\n        not be returned or searched recursively when calling\n        `collect_directories`.\n\n        This will replace the previously stored set of blacklisted\n        paths.\n\n        `directories` may be a single instance or an iterable. Recommend\n        passing in absolute paths. Method will try to convert to absolute path\n        based on current working directory.\n        \"\"\"\n        absolute_paths = util.to_absolute_paths(directories)\n        self.blacklisted_directories = absolute_paths\n        if remove_from_stored_directories:\n            plug_dirs = self.plugin_directories\n            plug_dirs = util.remove_from_set(plug_dirs,\n                                             directories)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the directories from the set of blacklisted directories.", "response": "def remove_blacklisted_directories(self, directories):\n        \"\"\"\n        Attempts to remove the `directories` from the set of blacklisted\n        directories. If a particular directory is not found in the set of\n        blacklisted, method will continue on silently.\n\n        `directories` may be a single instance or an iterable. Recommend\n        passing in absolute paths. Method will try to convert to an absolute\n        path if it is not already using the current working directory.\n        \"\"\"\n        directories = util.to_absolute_paths(directories)\n        black_dirs = self.blacklisted_directories\n        black_dirs = util.remove_from_set(black_dirs, directories)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves blacklisted directories from directories and returns whatever is left in the set.", "response": "def _remove_blacklisted(self, directories):\n        \"\"\"\n        Attempts to remove the blacklisted directories from `directories`\n        and then returns whatever is left in the set.\n\n        Called from the `collect_directories` method.\n        \"\"\"\n        directories = util.to_absolute_paths(directories)\n        directories = util.remove_from_set(directories,\n                                           self.blacklisted_directories)\n\n        return directories"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot(self, x, y, **kw):\n        return self.frame.plot(x,y,**kw)", "response": "plot x y values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imsave(filename, data, photometric=None, planarconfig=None,\n           resolution=None, description=None, software='tifffile.py',\n           byteorder=None, bigtiff=False):\n    \"\"\"Write image data to TIFF file.\n\n    Image data are written uncompressed in one stripe per plane.\n    Dimensions larger than 2 or 3 (depending on photometric mode and\n    planar configuration) are flattened and saved as separate pages.\n\n    Parameters\n    ----------\n    filename : str\n        Name of file to write.\n    data : array_like\n        Input image. The last dimensions are assumed to be image height,\n        width, and samples.\n    photometric : {'minisblack', 'miniswhite', 'rgb'}\n        The color space of the image data.\n        By default this setting is inferred from the data shape.\n    planarconfig : {'contig', 'planar'}\n        Specifies if samples are stored contiguous or in separate planes.\n        By default this setting is inferred from the data shape.\n        'contig': last dimension contains samples.\n        'planar': third last dimension contains samples.\n    resolution : ((int, int), (int, int))\n        X and Y resolution in dots per inch as rational numbers.\n    description : str\n        The subject of the image. Saved with the first page only.\n    software : str\n        Name of the software used to create the image.\n        Saved with the first page only.\n    byteorder : {'<', '>'}\n        The endianness of the data in the file.\n        By default this is the system's native byte order.\n    bigtiff : bool\n        If True the BigTIFF format is used.\n        By default the standard TIFF format is used for data less than 2040 MB.\n\n    Examples\n    --------\n    >>> data = numpy.random.rand(10, 3, 301, 219)\n    >>> imsave('temp.tif', data)\n\n    \"\"\"\n    assert(photometric in (None, 'minisblack', 'miniswhite', 'rgb'))\n    assert(planarconfig in (None, 'contig', 'planar'))\n    assert(byteorder in (None, '<', '>'))\n\n    if byteorder is None:\n        byteorder = '<' if sys.byteorder == 'little' else '>'\n\n    data = numpy.asarray(data, dtype=byteorder+data.dtype.char, order='C')\n    data_shape = shape = data.shape\n    data = numpy.atleast_2d(data)\n\n    if not bigtiff and data.size * data.dtype.itemsize < 2040*2**20:\n        bigtiff = False\n        offset_size = 4\n        tag_size = 12\n        numtag_format = 'H'\n        offset_format = 'I'\n        val_format = '4s'\n    else:\n        bigtiff = True\n        offset_size = 8\n        tag_size = 20\n        numtag_format = 'Q'\n        offset_format = 'Q'\n        val_format = '8s'\n\n    # unify shape of data\n    samplesperpixel = 1\n    extrasamples = 0\n    if photometric is None:\n        if data.ndim > 2 and (shape[-3] in (3, 4) or shape[-1] in (3, 4)):\n            photometric = 'rgb'\n        else:\n            photometric = 'minisblack'\n    if photometric == 'rgb':\n        if len(shape) < 3:\n            raise ValueError(\"not a RGB(A) image\")\n        if planarconfig is None:\n            planarconfig = 'planar' if shape[-3] in (3, 4) else 'contig'\n        if planarconfig == 'contig':\n            if shape[-1] not in (3, 4):\n                raise ValueError(\"not a contiguous RGB(A) image\")\n            data = data.reshape((-1, 1) + shape[-3:])\n            samplesperpixel = shape[-1]\n        else:\n            if shape[-3] not in (3, 4):\n                raise ValueError(\"not a planar RGB(A) image\")\n            data = data.reshape((-1, ) + shape[-3:] + (1, ))\n            samplesperpixel = shape[-3]\n        if samplesperpixel == 4:\n            extrasamples = 1\n    elif planarconfig and len(shape) > 2:\n        if planarconfig == 'contig':\n            data = data.reshape((-1, 1) + shape[-3:])\n            samplesperpixel = shape[-1]\n        else:\n            data = data.reshape((-1, ) + shape[-3:] + (1, ))\n            samplesperpixel = shape[-3]\n        extrasamples = samplesperpixel - 1\n    else:\n        planarconfig = None\n        data = data.reshape((-1, 1) + shape[-2:] + (1, ))\n\n    shape = data.shape  # (pages, planes, height, width, contig samples)\n\n    bytestr = bytes if sys.version[0] == '2' else lambda x: bytes(x, 'ascii')\n    tifftypes = {'B': 1, 's': 2, 'H': 3, 'I': 4, '2I': 5, 'b': 6,\n                 'h': 8, 'i': 9, 'f': 11, 'd': 12, 'Q': 16, 'q': 17}\n    tifftags = {'new_subfile_type': 254, 'subfile_type': 255,\n        'image_width': 256, 'image_length': 257, 'bits_per_sample': 258,\n        'compression': 259, 'photometric': 262, 'fill_order': 266,\n        'document_name': 269, 'image_description': 270, 'strip_offsets': 273,\n        'orientation': 274, 'samples_per_pixel': 277, 'rows_per_strip': 278,\n        'strip_byte_counts': 279, 'x_resolution': 282, 'y_resolution': 283,\n        'planar_configuration': 284, 'page_name': 285, 'resolution_unit': 296,\n        'software': 305, 'datetime': 306, 'predictor': 317, 'color_map': 320,\n        'extra_samples': 338, 'sample_format': 339}\n\n    tags = []\n    tag_data = []\n\n    def pack(fmt, *val):\n        return struct.pack(byteorder+fmt, *val)\n\n    def tag(name, dtype, number, value, offset=[0]):\n        # append tag binary string to tags list\n        # append (offset, value as binary string) to tag_data list\n        # increment offset by tag_size\n        if dtype == 's':\n            value = bytestr(value) + b'\\0'\n            number = len(value)\n            value = (value, )\n        t = [pack('HH', tifftags[name], tifftypes[dtype]),\n             pack(offset_format, number)]\n        if len(dtype) > 1:\n            number *= int(dtype[:-1])\n            dtype = dtype[-1]\n        if number == 1:\n            if isinstance(value, (tuple, list)):\n                value = value[0]\n            t.append(pack(val_format, pack(dtype, value)))\n        elif struct.calcsize(dtype) * number <= offset_size:\n            t.append(pack(val_format, pack(str(number)+dtype, *value)))\n        else:\n            t.append(pack(offset_format, 0))\n            tag_data.append((offset[0] + offset_size + 4,\n                             pack(str(number)+dtype, *value)))\n        tags.append(b''.join(t))\n        offset[0] += tag_size\n\n    if software:\n        tag('software', 's', 0, software)\n    if description:\n        tag('image_description', 's', 0, description)\n    elif shape != data_shape:\n        tag('image_description', 's', 0,\n            \"shape=(%s)\" % (\",\".join('%i' % i for i in data_shape)))\n    tag('datetime', 's', 0,\n        datetime.datetime.now().strftime(\"%Y:%m:%d %H:%M:%S\"))\n    # write previous tags only once\n    writeonce = (len(tags), len(tag_data)) if shape[0] > 1 else None\n    tag('compression', 'H', 1, 1)\n    tag('orientation', 'H', 1, 1)\n    tag('image_width', 'I', 1, shape[-2])\n    tag('image_length', 'I', 1, shape[-3])\n    tag('new_subfile_type', 'I', 1, 0 if shape[0] == 1 else 2)\n    tag('sample_format', 'H', 1,\n        {'u': 1, 'i': 2, 'f': 3, 'c': 6}[data.dtype.kind])\n    tag('photometric', 'H', 1,\n        {'miniswhite': 0, 'minisblack': 1, 'rgb': 2}[photometric])\n    tag('samples_per_pixel', 'H', 1, samplesperpixel)\n    if planarconfig:\n        tag('planar_configuration', 'H', 1, 1 if planarconfig=='contig' else 2)\n        tag('bits_per_sample', 'H', samplesperpixel,\n            (data.dtype.itemsize * 8, ) * samplesperpixel)\n    else:\n        tag('bits_per_sample', 'H', 1, data.dtype.itemsize * 8)\n    if extrasamples:\n        if photometric == 'rgb':\n            tag('extra_samples', 'H', 1, 1)  # alpha channel\n        else:\n            tag('extra_samples', 'H', extrasamples, (0, ) * extrasamples)\n    if resolution:\n        tag('x_resolution', '2I', 1, resolution[0])\n        tag('y_resolution', '2I', 1, resolution[1])\n        tag('resolution_unit', 'H', 1, 2)\n    tag('rows_per_strip', 'I', 1, shape[-3])\n    # use one strip per plane\n    strip_byte_counts = (data[0, 0].size * data.dtype.itemsize, ) * shape[1]\n    tag('strip_byte_counts', offset_format, shape[1], strip_byte_counts)\n    # strip_offsets must be the last tag; will be updated later\n    tag('strip_offsets', offset_format, shape[1], (0, ) * shape[1])\n\n    fd = open(filename, 'wb')\n    seek = fd.seek\n    tell = fd.tell\n\n    def write(arg, *args):\n        fd.write(pack(arg, *args) if args else arg)\n\n    write({'<': b'II', '>': b'MM'}[byteorder])\n    if bigtiff:\n        write('HHH', 43, 8, 0)\n    else:\n        write('H', 42)\n    ifd_offset = tell()\n    write(offset_format, 0)  # first IFD\n    for i in range(shape[0]):\n        # update pointer at ifd_offset\n        pos = tell()\n        seek(ifd_offset)\n        write(offset_format, pos)\n        seek(pos)\n        # write tags\n        write(numtag_format, len(tags))\n        tag_offset = tell()\n        write(b''.join(tags))\n        ifd_offset = tell()\n        write(offset_format, 0)  # offset to next ifd\n        # write extra tag data and update pointers\n        for off, dat in tag_data:\n            pos = tell()\n            seek(tag_offset + off)\n            write(offset_format, pos)\n            seek(pos)\n            write(dat)\n        # update strip_offsets\n        pos = tell()\n        if len(strip_byte_counts) == 1:\n            seek(ifd_offset - offset_size)\n            write(offset_format, pos)\n        else:\n            seek(pos - offset_size*shape[1])\n            strip_offset = pos\n            for size in strip_byte_counts:\n                write(offset_format, strip_offset)\n                strip_offset += size\n        seek(pos)\n        # write data\n        data[i].tofile(fd)  # if this fails, try update Python and numpy\n        fd.flush()\n        # remove tags that should be written only once\n        if writeonce:\n            tags = tags[writeonce[0]:]\n            d = writeonce[0] * tag_size\n            tag_data = [(o-d, v) for (o, v) in tag_data[writeonce[1]:]]\n            writeonce = None\n    fd.close()", "response": "Write image data to TIFF file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef imread(filename, *args, **kwargs):\n    with TIFFfile(filename) as tif:\n        return tif.asarray(*args, **kwargs)", "response": "Return image data from TIFF file as numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads tag data from file and return as byte string.", "response": "def read_bytes(fd, byte_order, dtype, count):\n    \"\"\"Read tag data from file and return as byte string.\"\"\"\n    return numpy.fromfile(fd, byte_order+dtype[-1], count).tostring()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_numpy(fd, byte_order, dtype, count):\n    return numpy.fromfile(fd, byte_order+dtype[-1], count)", "response": "Read tag data from file and return as numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading NIH_IMAGE_HEADER tag from file and return as dictionary.", "response": "def read_nih_image_header(fd, byte_order, dtype, count):\n    \"\"\"Read NIH_IMAGE_HEADER tag from file and return as dictionary.\"\"\"\n    fd.seek(12, 1)\n    return {'version': struct.unpack(byte_order+'H', fd.read(2))[0]}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_mm_header(fd, byte_order, dtype, count):\n    return numpy.rec.fromfile(fd, MM_HEADER, 1, byteorder=byte_order)[0]", "response": "Read MM_HEADER tag from file and return as numpy. rec. array."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_mm_uic1(fd, byte_order, dtype, count):\n    t = fd.read(8*count)\n    t = struct.unpack('%s%iI' % (byte_order, 2*count), t)\n    return dict((MM_TAG_IDS[k], v) for k, v in zip(t[::2], t[1::2])\n                if k in MM_TAG_IDS)", "response": "Read MM_UIC1 tag from file and return as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_mm_uic2(fd, byte_order, dtype, count):\n    result = {'number_planes': count}\n    values = numpy.fromfile(fd, byte_order+'I', 6*count)\n    result['z_distance'] = values[0::6] // values[1::6]\n    #result['date_created'] = tuple(values[2::6])\n    #result['time_created'] = tuple(values[3::6])\n    #result['date_modified'] = tuple(values[4::6])\n    #result['time_modified'] = tuple(values[5::6])\n    return result", "response": "Read MM_UIC2 tag from file and return as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_mm_uic3(fd, byte_order, dtype, count):\n    t = numpy.fromfile(fd, byte_order+'I', 2*count)\n    return {'wavelengths': t[0::2] // t[1::2]}", "response": "Read MM_UIC3 tag from file and return as dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_cz_lsm_info(fd, byte_order, dtype, count):\n    result = numpy.rec.fromfile(fd, CZ_LSM_INFO, 1,\n                                byteorder=byte_order)[0]\n    {50350412: '1.3', 67127628: '2.0'}[result.magic_number]  # validation\n    return result", "response": "Read CS_LSM_INFO tag from file and return as numpy. rec. array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading LSM time stamps from file and return as list.", "response": "def read_cz_lsm_time_stamps(fd, byte_order):\n    \"\"\"Read LSM time stamps from file and return as list.\"\"\"\n    size, count = struct.unpack(byte_order+'II', fd.read(8))\n    if size != (8 + 8 * count):\n        raise ValueError(\"lsm_time_stamps block is too short\")\n    return struct.unpack(('%s%dd' % (byte_order, count)),\n                         fd.read(8*count))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef read_cz_lsm_event_list(fd, byte_order):\n    count = struct.unpack(byte_order+'II', fd.read(8))[1]\n    events = []\n    while count > 0:\n        esize, etime, etype = struct.unpack(byte_order+'IdI', fd.read(16))\n        etext = stripnull(fd.read(esize - 16))\n        events.append((etime, etype, etext))\n        count -= 1\n    return events", "response": "Read LSM events from file and return as list of ( time type text )."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_cz_lsm_scan_info(fd, byte_order):\n    block = Record()\n    blocks = [block]\n    unpack = struct.unpack\n    if 0x10000000 != struct.unpack(byte_order+\"I\", fd.read(4))[0]:\n        raise ValueError(\"not a lsm_scan_info structure\")\n    fd.read(8)\n    while True:\n        entry, dtype, size = unpack(byte_order+\"III\", fd.read(12))\n        if dtype == 2:\n            value = stripnull(fd.read(size))\n        elif dtype == 4:\n            value = unpack(byte_order+\"i\", fd.read(4))[0]\n        elif dtype == 5:\n            value = unpack(byte_order+\"d\", fd.read(8))[0]\n        else:\n            value = 0\n        if entry in CZ_LSM_SCAN_INFO_ARRAYS:\n            blocks.append(block)\n            name = CZ_LSM_SCAN_INFO_ARRAYS[entry]\n            newobj = []\n            setattr(block, name, newobj)\n            block = newobj\n        elif entry in CZ_LSM_SCAN_INFO_STRUCTS:\n            blocks.append(block)\n            newobj = Record()\n            block.append(newobj)\n            block = newobj\n        elif entry in CZ_LSM_SCAN_INFO_ATTRIBUTES:\n            name = CZ_LSM_SCAN_INFO_ATTRIBUTES[entry]\n            setattr(block, name, value)\n        elif entry == 0xffffffff:\n            block = blocks.pop()\n        else:\n            setattr(block, \"unknown_%x\" % entry, value)\n        if not blocks:\n            break\n    return block", "response": "Read LSM scan information from file and return as Record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_by(module_function, warn=False):\n    def decorate(func, module_function=module_function, warn=warn):\n        sys.path.append(os.path.dirname(__file__))\n        try:\n            module, function = module_function.split('.')\n            func, oldfunc = getattr(__import__(module), function), func\n            globals()['__old_' + func.__name__] = oldfunc\n        except Exception:\n            if warn:\n                warnings.warn(\"failed to import %s\" % module_function)\n        sys.path.pop()\n        return func\n\n    return decorate", "response": "Try replace decorated function by module. function."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecompresses PackBits encoded byte string.", "response": "def decodepackbits(encoded):\n    \"\"\"Decompress PackBits encoded byte string.\n\n    PackBits is a simple byte-oriented run-length compression scheme.\n\n    \"\"\"\n    func = ord if sys.version[0] == '2' else lambda x: x\n    result = []\n    i = 0\n    try:\n        while True:\n            n = func(encoded[i]) + 1\n            i += 1\n            if n < 129:\n                result.extend(encoded[i:i+n])\n                i += n\n            elif n > 129:\n                result.extend(encoded[i:i+1] * (258-n))\n                i += 1\n    except IndexError:\n        pass\n    return b''.join(result) if sys.version[0] == '2' else bytes(result)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decodelzw(encoded):\n    unpack = struct.unpack\n\n    if sys.version[0] == '2':\n        newtable = [chr(i) for i in range(256)]\n    else:\n        newtable = [bytes([i]) for i in range(256)]\n    newtable.extend((0, 0))\n\n    def next_code():\n        \"\"\"Return integer of `bitw` bits at `bitcount` position in encoded.\"\"\"\n        start = bitcount // 8\n        s = encoded[start:start+4]\n        try:\n            code = unpack('>I', s)[0]\n        except Exception:\n            code = unpack('>I', s + b'\\x00'*(4-len(s)))[0]\n        code = code << (bitcount % 8)\n        code = code & mask\n        return code >> shr\n\n    switchbitch = {  # code: bit-width, shr-bits, bit-mask\n        255: (9, 23, int(9*'1'+'0'*23, 2)),\n        511: (10, 22, int(10*'1'+'0'*22, 2)),\n        1023: (11, 21, int(11*'1'+'0'*21, 2)),\n        2047: (12, 20, int(12*'1'+'0'*20, 2)), }\n    bitw, shr, mask = switchbitch[255]\n    bitcount = 0\n\n    if len(encoded) < 4:\n        raise ValueError(\"strip must be at least 4 characters long\")\n\n    if next_code() != 256:\n        raise ValueError(\"strip must begin with CLEAR code\")\n\n    code = oldcode = 0\n    result = []\n    while True:\n        code = next_code()  # ~5% faster when inlining this function\n        bitcount += bitw\n        if code == 257:  # EOI\n            break\n        if code == 256:  # CLEAR\n            table = newtable[:]\n            lentable = 258\n            bitw, shr, mask = switchbitch[255]\n            code = next_code()\n            bitcount += bitw\n            if code == 257:  # EOI\n                break\n            result.append(table[code])\n        else:\n            if code < lentable:\n                decoded = table[code]\n                newcode = table[oldcode] + decoded[:1]\n            else:\n                newcode = table[oldcode]\n                newcode += newcode[:1]\n                decoded = newcode\n            result.append(decoded)\n            table.append(newcode)\n            lentable += 1\n        oldcode = code\n        if lentable in switchbitch:\n            bitw, shr, mask = switchbitch[lentable]\n\n    if code != 257:\n        raise ValueError(\"unexpected end of stream (code %i)\" % code)\n\n    return b''.join(result)", "response": "Decompress an encoded LZW compressed TIFF strip."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unpackints(data, dtype, itemsize, runlen=0):\n    if itemsize == 1:  # bitarray\n        data = numpy.fromstring(data, '|B')\n        data = numpy.unpackbits(data)\n        if runlen % 8:\n            data = data.reshape(-1, runlen+(8-runlen%8))\n            data = data[:, :runlen].reshape(-1)\n        return data.astype(dtype)\n\n    dtype = numpy.dtype(dtype)\n    if itemsize in (8, 16, 32, 64):\n        return numpy.fromstring(data, dtype)\n    if itemsize < 1 or itemsize > 32:\n        raise ValueError(\"itemsize out of range: %i\" % itemsize)\n    if dtype.kind not in \"biu\":\n        raise ValueError(\"invalid dtype\")\n\n    itembytes = next(i for i in (1, 2, 4, 8) if 8 * i >= itemsize)\n    if itembytes != dtype.itemsize:\n        raise ValueError(\"dtype.itemsize too small\")\n    if runlen == 0:\n        runlen = len(data) // itembytes\n    skipbits = runlen*itemsize % 8\n    if skipbits:\n        skipbits = 8 - skipbits\n    shrbits = itembytes*8 - itemsize\n    bitmask = int(itemsize*'1'+'0'*shrbits, 2)\n    dtypestr = '>' + dtype.char  # dtype always big endian?\n\n    unpack = struct.unpack\n    l = runlen * (len(data)*8 // (runlen*itemsize + skipbits))\n    result = numpy.empty((l, ), dtype)\n    bitcount = 0\n    for i in range(len(result)):\n        start = bitcount // 8\n        s = data[start:start+itembytes]\n        try:\n            code = unpack(dtypestr, s)[0]\n        except Exception:\n            code = unpack(dtypestr, s + b'\\x00'*(itembytes-len(s)))[0]\n        code = code << (bitcount % 8)\n        code = code & bitmask\n        result[i] = code >> shrbits\n        bitcount += itemsize\n        if (i+1) % runlen == 0:\n            bitcount += skipbits\n    return result", "response": "Decompress byte string to array of integers of any bit size <= 32."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns reoriented view of image array. Parameters ---------- image : numpy array Non-squeezed output of asarray() functions. Axes -3 and -2 must be image length and width respectively. orientation : int or str One of TIFF_ORIENTATIONS keys or values.", "response": "def reorient(image, orientation):\n    \"\"\"Return reoriented view of image array.\n\n    Parameters\n    ----------\n    image : numpy array\n        Non-squeezed output of asarray() functions.\n        Axes -3 and -2 must be image length and width respectively.\n    orientation : int or str\n        One of TIFF_ORIENTATIONS keys or values.\n\n    \"\"\"\n    o = TIFF_ORIENTATIONS.get(orientation, orientation)\n    if o == 'top_left':\n        return image\n    elif o == 'top_right':\n        return image[..., ::-1, :]\n    elif o == 'bottom_left':\n        return image[..., ::-1, :, :]\n    elif o == 'bottom_right':\n        return image[..., ::-1, ::-1, :]\n    elif o == 'left_top':\n        return numpy.swapaxes(image, -3, -2)\n    elif o == 'right_top':\n        return numpy.swapaxes(image, -3, -2)[..., ::-1, :]\n    elif o == 'left_bottom':\n        return numpy.swapaxes(image, -3, -2)[..., ::-1, :, :]\n    elif o == 'right_bottom':\n        return numpy.swapaxes(image, -3, -2)[..., ::-1, ::-1, :]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns string truncated at first null character.", "response": "def stripnull(string):\n    \"\"\"Return string truncated at first null character.\"\"\"\n    i = string.find(b'\\x00')\n    return string if (i < 0) else string[:i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns datetime object from timestamp in Excel serial format.", "response": "def datetime_from_timestamp(n, epoch=datetime.datetime.fromordinal(693594)):\n    \"\"\"Return datetime object from timestamp in Excel serial format.\n\n    Examples\n    --------\n    >>> datetime_from_timestamp(40237.029999999795)\n    datetime.datetime(2010, 2, 28, 0, 43, 11, 999982)\n\n    \"\"\"\n    return epoch + datetime.timedelta(n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef imshow(data, title=None, vmin=0, vmax=None, cmap=None,\n           bitspersample=None, photometric='rgb', interpolation='nearest',\n           dpi=96, figure=None, subplot=111, maxdim=4096, **kwargs):\n    \"\"\"Plot n-dimensional images using matplotlib.pyplot.\n\n    Return figure, subplot and plot axis.\n    Requires pyplot already imported ``from matplotlib import pyplot``.\n\n    Parameters\n    ----------\n    bitspersample : int or None\n        Number of bits per channel in integer RGB images.\n    photometric : {'miniswhite', 'minisblack', 'rgb', or 'palette'}\n        The color space of the image data.\n    title : str\n        Window and subplot title.\n    figure : matplotlib.figure.Figure (optional).\n        Matplotlib to use for plotting.\n    subplot : int\n        A matplotlib.pyplot.subplot axis.\n    maxdim : int\n        maximum image size in any dimension.\n    kwargs : optional\n        Arguments for matplotlib.pyplot.imshow.\n\n    \"\"\"\n    #if photometric not in ('miniswhite', 'minisblack', 'rgb', 'palette'):\n    #    raise ValueError(\"Can't handle %s photometrics\" % photometric)\n    isrgb = photometric in ('rgb', 'palette')\n    data = numpy.atleast_2d(data.squeeze())\n    data = data[(slice(0, maxdim), ) * len(data.shape)]\n\n    dims = data.ndim\n    if dims < 2:\n        raise ValueError(\"not an image\")\n    elif dims == 2:\n        dims = 0\n        isrgb = False\n    else:\n        if (isrgb and data.shape[-3] in (3, 4)):\n            data = numpy.swapaxes(data, -3, -2)\n            data = numpy.swapaxes(data, -2, -1)\n        elif (not isrgb and data.shape[-1] in (3, 4)):\n            data = numpy.swapaxes(data, -3, -1)\n            data = numpy.swapaxes(data, -2, -1)\n        isrgb = isrgb and data.shape[-1] in (3, 4)\n        dims -= 3 if isrgb else 2\n\n    if photometric == 'palette':\n        datamax = data.max()\n        if datamax > 255:\n            data >>= 8  # possible precision loss\n        data = data.astype('B')\n    elif data.dtype.kind in 'ui':\n        if not isrgb or bitspersample is None:\n            bitspersample = int(math.ceil(math.log(data.max(), 2)))\n        elif not isinstance(bitspersample, int):\n            # bitspersample can be tuple, e.g. (5, 6, 5)\n            bitspersample = data.dtype.itemsize * 8\n        datamax = 2**bitspersample\n        if isrgb:\n            if bitspersample < 8:\n                data <<= 8 - bitspersample\n            elif bitspersample > 8:\n                data >>= bitspersample - 8  # precision loss\n            data = data.astype('B')\n    elif data.dtype.kind == 'f':\n        datamax = data.max()\n        if isrgb and datamax > 1.0:\n            if data.dtype.char == 'd':\n                data = data.astype('f')\n            data /= datamax\n    elif data.dtype.kind == 'b':\n        datamax = 1\n\n    if vmax is None:\n        vmax = datamax\n    if vmin is None:\n        if data.dtype.kind != 'f':\n            vmin = 0\n\n    pyplot = sys.modules['matplotlib.pyplot']\n\n    if figure is None:\n        pyplot.rc('font', family='sans-serif', weight='normal', size=8)\n        figure = pyplot.figure(dpi=dpi, figsize=(10.3, 6.3), frameon=True,\n                               facecolor='1.0', edgecolor='w')\n        try:\n            figure.canvas.manager.window.title(title)\n        except Exception:\n            pass\n        pyplot.subplots_adjust(bottom=0.03*(dims+2), top=0.9,\n                               left=0.1, right=0.95, hspace=0.05, wspace=0.0)\n    subplot = pyplot.subplot(subplot)\n\n    if title:\n        pyplot.title(title, size=11)\n\n    if cmap is None:\n        if photometric == 'miniswhite':\n            cmap = 'gray_r' if vmin == 0 else 'coolwarm_r'\n        else:\n            cmap = 'gray' if vmin == 0 else 'coolwarm'\n\n    image = pyplot.imshow(data[(0, ) * dims].squeeze(), vmin=vmin, vmax=vmax,\n                          cmap=cmap, interpolation=interpolation, **kwargs)\n\n    if not isrgb:\n        pyplot.colorbar()  # panchor=(0.55, 0.5), fraction=0.05\n\n    def format_coord(x, y):\n        # callback function to format coordinate display in toolbar\n        x = int(x + 0.5)\n        y = int(y + 0.5)\n        try:\n            if dims:\n                return \"%s @ %s [%4i, %4i]\" % (cur_ax_dat[1][y, x],\n                                               current, x, y)\n            else:\n                return \"%s @ [%4i, %4i]\" % (data[y, x], x, y)\n        except IndexError:\n            return \"\"\n\n    pyplot.gca().format_coord = format_coord\n\n    if dims:\n        current = list((0, ) * dims)\n        cur_ax_dat = [0, data[tuple(current)].squeeze()]\n        sliders = [pyplot.Slider(\n            pyplot.axes([0.125, 0.03*(axis+1), 0.725, 0.025]),\n            'Dimension %i' % axis, 0, data.shape[axis]-1, 0, facecolor='0.5',\n            valfmt='%%.0f [%i]' % data.shape[axis]) for axis in range(dims)]\n        for slider in sliders:\n            slider.drawon = False\n\n        def set_image(current, sliders=sliders, data=data):\n            # change image and redraw canvas\n            cur_ax_dat[1] = data[tuple(current)].squeeze()\n            image.set_data(cur_ax_dat[1])\n            for ctrl, index in zip(sliders, current):\n                ctrl.eventson = False\n                ctrl.set_val(index)\n                ctrl.eventson = True\n            figure.canvas.draw()\n\n        def on_changed(index, axis, data=data, current=current):\n            # callback function for slider change event\n            index = int(round(index))\n            cur_ax_dat[0] = axis\n            if index == current[axis]:\n                return\n            if index >= data.shape[axis]:\n                index = 0\n            elif index < 0:\n                index = data.shape[axis] - 1\n            current[axis] = index\n            set_image(current)\n\n        def on_keypressed(event, data=data, current=current):\n            # callback function for key press event\n            key = event.key\n            axis = cur_ax_dat[0]\n            if str(key) in '0123456789':\n                on_changed(key, axis)\n            elif key == 'right':\n                on_changed(current[axis] + 1, axis)\n            elif key == 'left':\n                on_changed(current[axis] - 1, axis)\n            elif key == 'up':\n                cur_ax_dat[0] = 0 if axis == len(data.shape)-1 else axis + 1\n            elif key == 'down':\n                cur_ax_dat[0] = len(data.shape)-1 if axis == 0 else axis - 1\n            elif key == 'end':\n                on_changed(data.shape[axis] - 1, axis)\n            elif key == 'home':\n                on_changed(0, axis)\n\n        figure.canvas.mpl_connect('key_press_event', on_keypressed)\n        for axis, ctrl in enumerate(sliders):\n            ctrl.on_changed(lambda k, a=axis: on_changed(k, a))\n\n    return figure, subplot, image", "response": "Plot an image using matplotlib. pyplot. imshow."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main(argv=None):\n    if float(sys.version[0:3]) < 2.6:\n        print(\"This script requires Python version 2.6 or better.\")\n        print(\"This is Python version %s\" % sys.version)\n        return 0\n    if argv is None:\n        argv = sys.argv\n\n    import re\n    import optparse\n\n    search_doc = lambda r, d: re.search(r, __doc__).group(1) if __doc__ else d\n    parser = optparse.OptionParser(\n        usage=\"usage: %prog [options] path\",\n        description=search_doc(\"\\n\\n([^|]*?)\\n\\n\", ''),\n        version=\"%%prog %s\" % search_doc(\":Version: (.*)\", \"Unknown\"))\n    opt = parser.add_option\n    opt('-p', '--page', dest='page', type='int', default=-1,\n        help=\"display single page\")\n    opt('-s', '--series', dest='series', type='int', default=-1,\n        help=\"display series of pages of same shape\")\n    opt('--noplot', dest='noplot', action='store_true', default=False,\n        help=\"don't display images\")\n    opt('--interpol', dest='interpol', metavar='INTERPOL', default='bilinear',\n        help=\"image interpolation method\")\n    opt('--dpi', dest='dpi', type='int', default=96,\n        help=\"set plot resolution\")\n    opt('--debug', dest='debug', action='store_true', default=False,\n        help=\"raise exception on failures\")\n    opt('--test', dest='test', action='store_true', default=False,\n        help=\"try read all images in path\")\n    opt('--doctest', dest='doctest', action='store_true', default=False,\n        help=\"runs the internal tests\")\n    opt('-v', '--verbose', dest='verbose', action='store_true', default=True)\n    opt('-q', '--quiet', dest='verbose', action='store_false')\n\n    settings, path = parser.parse_args()\n    path = ' '.join(path)\n\n    if settings.doctest:\n        import doctest\n        doctest.testmod()\n        return 0\n    if not path:\n        parser.error(\"No file specified\")\n    if settings.test:\n        test_tifffile(path, settings.verbose)\n        return 0\n\n    print(\"Reading file structure...\", end=' ')\n    start = time.time()\n    try:\n        tif = TIFFfile(path)\n    except Exception as e:\n        if settings.debug:\n            raise\n        else:\n            print(\"\\n\", e)\n            sys.exit(0)\n    print(\"%.3f ms\" % ((time.time()-start) * 1e3))\n\n    if tif.is_ome:\n        settings.norgb = True\n\n    images = [(None, tif[0 if settings.page < 0 else settings.page])]\n    if not settings.noplot:\n        print(\"Reading image data... \", end=' ')\n        notnone = lambda x: next(i for i in x if i is not None)\n        start = time.time()\n        try:\n            if settings.page >= 0:\n                images = [(tif.asarray(key=settings.page),\n                           tif[settings.page])]\n            elif settings.series >= 0:\n                images = [(tif.asarray(series=settings.series),\n                           notnone(tif.series[settings.series].pages))]\n            else:\n                images = []\n                for i, s in enumerate(tif.series):\n                    try:\n                        images.append(\n                            (tif.asarray(series=i), notnone(s.pages)))\n                    except ValueError as e:\n                        images.append((None, notnone(s.pages)))\n                        if settings.debug:\n                            raise\n                        else:\n                            print(\"\\n* series %i failed: %s... \" % (i, e),\n                                  end='')\n            print(\"%.3f ms\" % ((time.time()-start) * 1e3))\n        except Exception as e:\n            if settings.debug:\n                raise\n            else:\n                print(e)\n    tif.close()\n\n    print(\"\\nTIFF file:\", tif)\n    print()\n    for i, s in enumerate(tif.series):\n        print (\"Series %i\" % i)\n        print(s)\n        print()\n    for i, page in images:\n        print(page)\n        print(page.tags)\n        if page.is_palette:\n            print(\"\\nColor Map:\", page.color_map.shape, page.color_map.dtype)\n        for attr in ('cz_lsm_info', 'cz_lsm_scan_information',\n                     'mm_uic_tags', 'mm_header', 'nih_image_header'):\n            if hasattr(page, attr):\n                print(\"\", attr.upper(), Record(getattr(page, attr)), sep=\"\\n\")\n        print()\n\n    if images and not settings.noplot:\n        try:\n            import matplotlib\n            matplotlib.use('TkAgg')\n            from matplotlib import pyplot\n        except ImportError as e:\n            warnings.warn(\"failed to import matplotlib.\\n%s\" % e)\n        else:\n            for img, page in images:\n                if img is None:\n                    continue\n                vmin, vmax = None, None\n                if page.is_stk:\n                    try:\n                        vmin = page.mm_uic_tags['min_scale']\n                        vmax = page.mm_uic_tags['max_scale']\n                    except KeyError:\n                        pass\n                    else:\n                        if vmax <= vmin:\n                            vmin, vmax = None, None\n                title = \"%s\\n %s\" % (str(tif), str(page))\n                imshow(img, title=title, vmin=vmin, vmax=vmax,\n                       bitspersample=page.bits_per_sample,\n                       photometric=page.photometric,\n                       interpolation=settings.interpol,\n                       dpi=settings.dpi)\n            pyplot.show()", "response": "Command line usage main function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        if not hasattr(self, 'tiffs'):\n            return\n        for tif in self._tiffs.values():\n            if tif._fd:\n                tif._fd.close()\n                tif._fd = None", "response": "Close open file handle s."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fromfile(self):\n        self._fd.seek(0)\n        try:\n            self.byte_order = {b'II': '<', b'MM': '>'}[self._fd.read(2)]\n        except KeyError:\n            raise ValueError(\"not a valid TIFF file\")\n        version = struct.unpack(self.byte_order+'H', self._fd.read(2))[0]\n        if version == 43:  # BigTiff\n            self.offset_size, zero = struct.unpack(self.byte_order+'HH',\n                                                   self._fd.read(4))\n            if zero or self.offset_size != 8:\n                raise ValueError(\"not a valid BigTIFF file\")\n        elif version == 42:\n            self.offset_size = 4\n        else:\n            raise ValueError(\"not a TIFF file\")\n        self.pages = []\n        while True:\n            try:\n                page = TIFFpage(self)\n                self.pages.append(page)\n            except StopIteration:\n                break\n        if not self.pages:\n            raise ValueError(\"empty TIFF file\")", "response": "Read TIFF header and all page records from file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns series of TIFFpage with compatible shape and properties.", "response": "def series(self):\n        \"\"\"Return series of TIFFpage with compatible shape and properties.\"\"\"\n        if self.is_ome:\n            series = self._omeseries()\n        elif self.is_fluoview:\n            dims = {b'X': 'X', b'Y': 'Y', b'Z': 'Z', b'T': 'T',\n                    b'WAVELENGTH': 'C', b'TIME': 'T', b'XY': 'R',\n                    b'EVENT': 'V', b'EXPOSURE': 'L'}\n            mmhd = list(reversed(self.pages[0].mm_header.dimensions))\n            series = [Record(\n                axes=''.join(dims.get(i[0].strip().upper(), 'O')\n                             for i in mmhd if i[1] > 1),\n                shape=tuple(int(i[1]) for i in mmhd if i[1] > 1),\n                pages=self.pages, dtype=numpy.dtype(self.pages[0].dtype))]\n        elif self.is_lsm:\n            lsmi = self.pages[0].cz_lsm_info\n            axes = CZ_SCAN_TYPES[lsmi.scan_type]\n            if self.pages[0].is_rgb:\n                axes = axes.replace('C', '').replace('XY', 'XYC')\n            axes = axes[::-1]\n            shape = [getattr(lsmi, CZ_DIMENSIONS[i]) for i in axes]\n            pages = [p for p in self.pages if not p.is_reduced]\n            series = [Record(axes=axes, shape=shape, pages=pages,\n                             dtype=numpy.dtype(pages[0].dtype))]\n            if len(pages) != len(self.pages):  # reduced RGB pages\n                pages = [p for p in self.pages if p.is_reduced]\n                cp = 1\n                i = 0\n                while cp < len(pages) and i < len(shape)-2:\n                    cp *= shape[i]\n                    i += 1\n                shape = shape[:i] + list(pages[0].shape)\n                axes = axes[:i] + 'CYX'\n                series.append(Record(axes=axes, shape=shape, pages=pages,\n                                     dtype=numpy.dtype(pages[0].dtype)))\n        elif self.is_nih:\n            series = [Record(pages=self.pages,\n                             shape=(len(self.pages),) + self.pages[0].shape,\n                             axes='I' + self.pages[0].axes,\n                             dtype=numpy.dtype(self.pages[0].dtype))]\n        elif self.pages[0].is_shaped:\n            shape = self.pages[0].tags['image_description'].value[7:-1]\n            shape = tuple(int(i) for i in shape.split(b','))\n            series = [Record(pages=self.pages, shape=shape,\n                             axes='O' * len(shape),\n                             dtype=numpy.dtype(self.pages[0].dtype))]\n        else:\n            shapes = []\n            pages = {}\n            for page in self.pages:\n                shape = page.shape + (page.axes,\n                                      page.compression in TIFF_DECOMPESSORS)\n                if not shape in pages:\n                    shapes.append(shape)\n                    pages[shape] = [page]\n                else:\n                    pages[shape].append(page)\n            series = [Record(pages=pages[s],\n                             axes=(('I' + s[-2])\n                                   if len(pages[s]) > 1 else s[-2]),\n                             dtype=numpy.dtype(pages[s][0].dtype),\n                             shape=((len(pages[s]), ) + s[:-2]\n                                    if len(pages[s]) > 1 else s[:-2]))\n                      for s in shapes]\n        return series"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns image data of multiple TIFF pages as numpy array.", "response": "def asarray(self, key=None, series=None):\n        \"\"\"Return image data of multiple TIFF pages as numpy array.\n\n        By default the first image series is returned.\n\n        Parameters\n        ----------\n        key : int, slice, or sequence of page indices\n            Defines which pages to return as array.\n        series : int\n            Defines which series of pages to return as array.\n\n        \"\"\"\n        if key is None and series is None:\n            series = 0\n        if series is not None:\n            pages = self.series[series].pages\n        else:\n            pages = self.pages\n\n        if key is None:\n            pass\n        elif isinstance(key, int):\n            pages = [pages[key]]\n        elif isinstance(key, slice):\n            pages = pages[key]\n        elif isinstance(key, collections.Iterable):\n            pages = [pages[k] for k in key]\n        else:\n            raise TypeError('key must be an int, slice, or sequence')\n\n        if len(pages) == 1:\n            return pages[0].asarray()\n        elif self.is_nih:\n            result = numpy.vstack(p.asarray(colormapped=False,\n                                            squeeze=False) for p in pages)\n            if pages[0].is_palette:\n                result = numpy.take(pages[0].color_map, result, axis=1)\n                result = numpy.swapaxes(result, 0, 1)\n        else:\n            if self.is_ome and any(p is None for p in pages):\n                firstpage = next(p for p in pages if p)\n                nopage = numpy.zeros_like(\n                    firstpage.asarray())\n            result = numpy.vstack((p.asarray() if p else nopage)\n                                  for p in pages)\n        if key is None:\n            try:\n                result.shape = self.series[series].shape\n            except ValueError:\n                warnings.warn(\"failed to reshape %s to %s\" % (\n                              result.shape, self.series[series].shape))\n                result.shape = (-1,) + pages[0].shape\n        else:\n            result.shape = (-1,) + pages[0].shape\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning image series in OME - TIFF files.", "response": "def _omeseries(self):\n        \"\"\"Return image series in OME-TIFF files.\"\"\"\n        root = ElementTree.XML(self.pages[0].tags['image_description'].value)\n        uuid = root.attrib.get('UUID', None)\n        self._tiffs = {uuid: self}\n        modulo = {}\n        result = []\n        for element in root:\n            if element.tag.endswith('BinaryOnly'):\n                warnings.warn(\"not an OME-TIFF master file\")\n                break\n            if element.tag.endswith('StructuredAnnotations'):\n                for annot in element:\n                    if not annot.attrib.get('Namespace',\n                                            '').endswith('modulo'):\n                        continue\n                    for value in annot:\n                        for modul in value:\n                            for along in modul:\n                                if not along.tag[:-1].endswith('Along'):\n                                    continue\n                                axis = along.tag[-1]\n                                newaxis = along.attrib.get('Type', 'other')\n                                newaxis = AXES_LABELS[newaxis]\n                                if 'Start' in along.attrib:\n                                    labels = range(\n                                        int(along.attrib['Start']),\n                                        int(along.attrib['End']) + 1,\n                                        int(along.attrib.get('Step', 1)))\n                                else:\n                                    labels = [label.text for label in along\n                                              if label.tag.endswith('Label')]\n                                modulo[axis] = (newaxis, labels)\n            if not element.tag.endswith('Image'):\n                continue\n            for pixels in element:\n                if not pixels.tag.endswith('Pixels'):\n                    continue\n                atr = pixels.attrib\n                axes = \"\".join(reversed(atr['DimensionOrder']))\n                shape = list(int(atr['Size'+ax]) for ax in axes)\n                size = numpy.prod(shape[:-2])\n                ifds = [None] * size\n                for data in pixels:\n                    if not data.tag.endswith('TiffData'):\n                        continue\n                    atr = data.attrib\n                    ifd = int(atr.get('IFD', 0))\n                    num = int(atr.get('NumPlanes', 1 if 'IFD' in atr else 0))\n                    num = int(atr.get('PlaneCount', num))\n                    idx = [int(atr.get('First'+ax, 0)) for ax in axes[:-2]]\n                    idx = numpy.ravel_multi_index(idx, shape[:-2])\n                    for uuid in data:\n                        if uuid.tag.endswith('UUID'):\n                            if uuid.text not in self._tiffs:\n                                fn = uuid.attrib['FileName']\n                                try:\n                                    tf = TIFFfile(os.path.join(self.fpath, fn))\n                                except (IOError, ValueError):\n                                    warnings.warn(\"failed to read %s\" % fn)\n                                    break\n                                self._tiffs[uuid.text] = tf\n                            pages = self._tiffs[uuid.text].pages\n                            try:\n                                for i in range(num if num else len(pages)):\n                                    ifds[idx + i] = pages[ifd + i]\n                            except IndexError:\n                                warnings.warn(\"ome-xml: index out of range\")\n                            break\n                    else:\n                        pages = self.pages\n                        try:\n                            for i in range(num if num else len(pages)):\n                                ifds[idx + i] = pages[ifd + i]\n                        except IndexError:\n                            warnings.warn(\"ome-xml: index out of range\")\n                result.append(Record(axes=axes, shape=shape, pages=ifds,\n                                     dtype=numpy.dtype(ifds[0].dtype)))\n\n        for record in result:\n            for axis, (newaxis, labels) in modulo.items():\n                i = record.axes.index(axis)\n                size = len(labels)\n                if record.shape[i] == size:\n                    record.axes = record.axes.replace(axis, newaxis, 1)\n                else:\n                    record.shape[i] //= size\n                    record.shape.insert(i+1, size)\n                    record.axes = record.axes.replace(axis, axis+newaxis, 1)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the TIFF IFD structure and its tags from file.", "response": "def _fromfile(self):\n        \"\"\"Read TIFF IFD structure and its tags from file.\n\n        File cursor must be at storage position of IFD offset and is left at\n        offset to next IFD.\n\n        Raises StopIteration if offset (first bytes read) is 0.\n\n        \"\"\"\n        fd = self.parent._fd\n        byte_order = self.parent.byte_order\n        offset_size = self.parent.offset_size\n\n        fmt = {4: 'I', 8: 'Q'}[offset_size]\n        offset = struct.unpack(byte_order + fmt, fd.read(offset_size))[0]\n        if not offset:\n            raise StopIteration()\n\n        # read standard tags\n        tags = self.tags\n        fd.seek(offset)\n        fmt, size = {4: ('H', 2), 8: ('Q', 8)}[offset_size]\n        try:\n            numtags = struct.unpack(byte_order + fmt, fd.read(size))[0]\n        except Exception:\n            warnings.warn(\"corrupted page list\")\n            raise StopIteration()\n\n        for _ in range(numtags):\n            tag = TIFFtag(self.parent)\n            tags[tag.name] = tag\n\n        # read LSM info subrecords\n        if self.is_lsm:\n            pos = fd.tell()\n            for name, reader in CZ_LSM_INFO_READERS.items():\n                try:\n                    offset = self.cz_lsm_info[\"offset_\"+name]\n                except KeyError:\n                    continue\n                if not offset:\n                    continue\n                fd.seek(offset)\n                try:\n                    setattr(self, \"cz_lsm_\"+name, reader(fd, byte_order))\n                except ValueError:\n                    pass\n            fd.seek(pos)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates standard tags and initialize attributes.", "response": "def _process_tags(self):\n        \"\"\"Validate standard tags and initialize attributes.\n\n        Raise ValueError if tag values are not supported.\n\n        \"\"\"\n        tags = self.tags\n        for code, (name, default, dtype, count, validate) in TIFF_TAGS.items():\n            if not (name in tags or default is None):\n                tags[name] = TIFFtag(code, dtype=dtype, count=count,\n                                     value=default, name=name)\n            if name in tags and validate:\n                try:\n                    if tags[name].count == 1:\n                        setattr(self, name, validate[tags[name].value])\n                    else:\n                        setattr(self, name, tuple(validate[value]\n                                            for value in tags[name].value))\n                except KeyError:\n                    raise ValueError(\"%s.value (%s) not supported\" %\n                                     (name, tags[name].value))\n\n        tag = tags['bits_per_sample']\n        if tag.count == 1:\n            self.bits_per_sample = tag.value\n        else:\n            value = tag.value[:self.samples_per_pixel]\n            if any((v-value[0] for v in value)):\n                self.bits_per_sample = value\n            else:\n                self.bits_per_sample = value[0]\n\n        tag = tags['sample_format']\n        if tag.count == 1:\n            self.sample_format = TIFF_SAMPLE_FORMATS[tag.value]\n        else:\n            value = tag.value[:self.samples_per_pixel]\n            if any((v-value[0] for v in value)):\n                self.sample_format = [TIFF_SAMPLE_FORMATS[v] for v in value]\n            else:\n                self.sample_format = TIFF_SAMPLE_FORMATS[value[0]]\n\n        self.strips_per_image = int(math.floor(float(self.image_length +\n                            self.rows_per_strip - 1) / self.rows_per_strip))\n\n        key = (self.sample_format, self.bits_per_sample)\n        self.dtype = self._dtype = TIFF_SAMPLE_DTYPES.get(key, None)\n\n        if self.is_stk:\n            planes = tags['mm_uic2'].count\n            # consolidate mm_uci tags\n            self.mm_uic_tags = Record(tags['mm_uic2'].value)\n            for key in ('mm_uic3', 'mm_uic4', 'mm_uic1'):\n                if key in tags:\n                    self.mm_uic_tags.update(tags[key].value)\n            if self.planar_configuration == 'contig':\n                self._shape = (planes, 1, self.image_length,\n                               self.image_width, self.samples_per_pixel)\n                self.shape = tuple(self._shape[i] for i in (0, 2, 3, 4))\n                self.axes = \"PYXS\"\n            else:\n                self._shape = (planes, self.samples_per_pixel,\n                               self.image_length, self.image_width, 1)\n                self.shape = self._shape[:4]\n                self.axes = \"PSYX\"\n        elif self.is_palette:\n            self.dtype = self.tags['color_map'].dtype[1]\n            self.color_map = numpy.array(self.color_map, self.dtype)\n            dmax = self.color_map.max()\n            if dmax < 256:\n                self.dtype = numpy.uint8\n                self.color_map = self.color_map.astype(self.dtype)\n            #else:\n            #    self.dtype = numpy.uint8\n            #    self.color_map >>= 8\n            #    self.color_map = self.color_map.astype(self.dtype)\n            self.color_map.shape = (3, -1)\n            self._shape = (1, 1, self.image_length, self.image_width, 1)\n            if self.color_map.shape[1] >= 2**self.bits_per_sample:\n                self.shape = (3, self.image_length, self.image_width)\n                self.axes = \"SYX\"\n            else:\n                # LSM and FluoView\n                self.shape = (self.image_length, self.image_width)\n                self.axes = \"YX\"\n        elif self.is_rgb or self.samples_per_pixel > 1:\n            if self.planar_configuration == 'contig':\n                self._shape = (1, 1, self.image_length, self.image_width,\n                               self.samples_per_pixel)\n                self.shape = (self.image_length, self.image_width,\n                              self.samples_per_pixel)\n                self.axes = \"YXS\"\n            else:\n                self._shape = (1, self.samples_per_pixel, self.image_length,\n                               self.image_width, 1)\n                self.shape = self._shape[1:-1]\n                self.axes = \"SYX\"\n            if self.is_rgb and 'extra_samples' in self.tags:\n                extra_samples = self.extra_samples\n                if self.tags['extra_samples'].count == 1:\n                    extra_samples = (extra_samples, )\n                for exs in extra_samples:\n                    if exs in ('unassalpha', 'assocalpha'):\n                        if self.planar_configuration == 'contig':\n                            self.shape = self.shape[:2] + (4,)\n                        else:\n                            self.shape = (4,) + self.shape[1:]\n                        break\n        else:\n            self._shape = (1, 1, self.image_length, self.image_width, 1)\n            self.shape = self._shape[2:4]\n            self.axes = \"YX\"\n\n        if not self.compression and not 'strip_byte_counts' in tags:\n            self.strip_byte_counts = numpy.prod(self.shape) * (\n                self.bits_per_sample // 8)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef asarray(self, squeeze=True, colormapped=True, rgbonly=True):\n        fd = self.parent._fd\n        if not fd:\n            raise IOError(\"TIFF file is not open\")\n        if self.dtype is None:\n            raise ValueError(\"data type not supported: %s%i\" % (\n                self.sample_format, self.bits_per_sample))\n        if self.compression not in TIFF_DECOMPESSORS:\n            raise ValueError(\"cannot decompress %s\" % self.compression)\n        if ('ycbcr_subsampling' in self.tags and\n            self.tags['ycbcr_subsampling'].value not in (1, (1, 1))):\n            raise ValueError(\"YCbCr subsampling not supported\")\n        tag = self.tags['sample_format']\n        if tag.count != 1 and any((i-tag.value[0] for i in tag.value)):\n            raise ValueError(\"sample formats don't match %s\" % str(tag.value))\n\n        dtype = self._dtype\n        shape = self._shape\n        image_width = self.image_width\n        image_length = self.image_length\n        typecode = self.parent.byte_order + dtype\n        bits_per_sample = self.bits_per_sample\n\n        if self.is_tiled:\n            if 'tile_offsets' in self.tags:\n                byte_counts = self.tile_byte_counts\n                offsets = self.tile_offsets\n            else:\n                byte_counts = self.strip_byte_counts\n                offsets = self.strip_offsets\n            tile_width = self.tile_width\n            tile_length = self.tile_length\n            tw = (image_width + tile_width - 1) // tile_width\n            tl = (image_length + tile_length - 1) // tile_length\n            shape = shape[:-3] + (tl*tile_length, tw*tile_width, shape[-1])\n            tile_shape = (tile_length, tile_width, shape[-1])\n            runlen = tile_width\n        else:\n            byte_counts = self.strip_byte_counts\n            offsets = self.strip_offsets\n            runlen = image_width\n\n        try:\n            offsets[0]\n        except TypeError:\n            offsets = (offsets, )\n            byte_counts = (byte_counts, )\n        if any(o < 2 for o in offsets):\n            raise ValueError(\"corrupted file\")\n\n        if (not self.is_tiled and (self.is_stk or (not self.compression\n            and bits_per_sample in (8, 16, 32, 64)\n            and all(offsets[i] == offsets[i+1] - byte_counts[i]\n                    for i in range(len(offsets)-1))))):\n            # contiguous data\n            fd.seek(offsets[0])\n            result = numpy.fromfile(fd, typecode, numpy.prod(shape))\n            result = result.astype('=' + dtype)\n        else:\n            if self.planar_configuration == 'contig':\n                runlen *= self.samples_per_pixel\n            if bits_per_sample in (8, 16, 32, 64, 128):\n                if (bits_per_sample * runlen) % 8:\n                    raise ValueError(\"data and sample size mismatch\")\n                unpack = lambda x: numpy.fromstring(x, typecode)\n            elif isinstance(bits_per_sample, tuple):\n                unpack = lambda x: unpackrgb(x, typecode, bits_per_sample)\n            else:\n                unpack = lambda x: unpackints(x, typecode, bits_per_sample,\n                                              runlen)\n            decompress = TIFF_DECOMPESSORS[self.compression]\n            if self.is_tiled:\n                result = numpy.empty(shape, dtype)\n                tw, tl, pl = 0, 0, 0\n                for offset, bytecount in zip(offsets, byte_counts):\n                    fd.seek(offset)\n                    tile = unpack(decompress(fd.read(bytecount)))\n                    tile.shape = tile_shape\n                    result[0, pl, tl:tl+tile_length,\n                           tw:tw+tile_width, :] = tile\n                    del tile\n                    tw += tile_width\n                    if tw >= shape[-2]:\n                        tw, tl = 0, tl + tile_length\n                        if tl >= shape[-3]:\n                            tl, pl = 0, pl + 1\n                result = result[..., :image_length, :image_width, :]\n            else:\n                result = numpy.empty(shape, dtype).reshape(-1)\n                index = 0\n                for offset, bytecount in zip(offsets, byte_counts):\n                    fd.seek(offset)\n                    stripe = unpack(decompress(fd.read(bytecount)))\n                    size = min(result.size, stripe.size)\n                    result[index:index+size] = stripe[:size]\n                    del stripe\n                    index += size\n\n        result.shape = self._shape\n\n        if self.predictor == 'horizontal':\n            # workaround bug in LSM510 software\n            if not (self.parent.is_lsm and not self.compression):\n                numpy.cumsum(result, axis=3, dtype=dtype, out=result)\n\n        if colormapped and self.is_palette:\n            if self.color_map.shape[1] >= 2**bits_per_sample:\n                # FluoView and LSM might fail here\n                result = numpy.take(self.color_map, result, axis=1)\n        elif rgbonly and self.is_rgb and 'extra_samples' in self.tags:\n            # return only RGB and first alpha channel if exists\n            extra_samples = self.extra_samples\n            if self.tags['extra_samples'].count == 1:\n                extra_samples = (extra_samples, )\n            for i, exs in enumerate(extra_samples):\n                if exs in ('unassalpha', 'assocalpha'):\n                    if self.planar_configuration == 'contig':\n                        result = result[..., [0, 1, 2, 3+i]]\n                    else:\n                        result = result[:, [0, 1, 2, 3+i]]\n                    break\n            else:\n                if self.planar_configuration == 'contig':\n                    result = result[..., :3]\n                else:\n                    result = result[:, :3]\n\n        if squeeze:\n            try:\n                result.shape = self.shape\n            except ValueError:\n                pass\n\n        return result", "response": "Read image data from file and return as numpy array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize instance from data.", "response": "def _fromdata(self, code, dtype, count, value, name=None):\n        \"\"\"Initialize instance from arguments.\"\"\"\n        self.code = int(code)\n        self.name = name if name else str(code)\n        self.dtype = TIFF_DATA_TYPES[dtype]\n        self.count = int(count)\n        self.value = value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _fromfile(self, parent):\n        fd = parent._fd\n        byte_order = parent.byte_order\n\n        self._offset = fd.tell()\n        self.value_offset = self._offset + parent.offset_size + 4\n\n        fmt, size = {4: ('HHI4s', 12), 8: ('HHQ8s', 20)}[parent.offset_size]\n        data = fd.read(size)\n        code, dtype = struct.unpack(byte_order + fmt[:2], data[:4])\n        count, value = struct.unpack(byte_order + fmt[2:], data[4:])\n\n        if code in TIFF_TAGS:\n            name = TIFF_TAGS[code][0]\n        elif code in CUSTOM_TAGS:\n            name = CUSTOM_TAGS[code][0]\n        else:\n            name = str(code)\n\n        try:\n            dtype = TIFF_DATA_TYPES[dtype]\n        except KeyError:\n            raise ValueError(\"unknown TIFF tag data type %i\" % dtype)\n\n        fmt = '%s%i%s' % (byte_order, count*int(dtype[0]), dtype[1])\n        size = struct.calcsize(fmt)\n        if size > parent.offset_size or code in CUSTOM_TAGS:\n            pos = fd.tell()\n            tof = {4: 'I', 8: 'Q'}[parent.offset_size]\n            self.value_offset = struct.unpack(byte_order+tof, value)[0]\n            fd.seek(self.value_offset)\n            if code in CUSTOM_TAGS:\n                readfunc = CUSTOM_TAGS[code][1]\n                value = readfunc(fd, byte_order, dtype, count)\n                fd.seek(0, 2)  # bug in numpy/Python 3.x ?\n                if isinstance(value, dict):  # numpy.core.records.record\n                    value = Record(value)\n            elif code in TIFF_TAGS or dtype[-1] == 's':\n                value = struct.unpack(fmt, fd.read(size))\n            else:\n                value = read_numpy(fd, byte_order, dtype, count)\n                fd.seek(0, 2)  # bug in numpy/Python 3.x ?\n            fd.seek(pos)\n        else:\n            value = struct.unpack(fmt, value[:size])\n\n        if not code in CUSTOM_TAGS:\n            if len(value) == 1:\n                value = value[0]\n\n        if dtype.endswith('s'):\n            value = stripnull(value)\n\n        self.code = code\n        self.name = name\n        self.dtype = dtype\n        self.count = count\n        self.value = value", "response": "Read tag structure from open file. Advance file cursor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverwriting data for trace t", "response": "def set_xylims(self, limits, axes=None):\n        \"\"\"overwrite data for trace t \"\"\"\n        if self.panel is not None:\n            self.panel.set_xylims(limits, axes=axes)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nzoom out full data range", "response": "def unzoom_all(self,event=None):\n        \"\"\"zoom out full data range \"\"\"\n        if self.panel is not None:\n            self.panel.unzoom_all(event=event)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unzoom(self,event=None):\n        if self.panel is not None: self.panel.unzoom(event=event)", "response": "zoom out 1 level or to full data range"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_figure(self,event=None, transparent=False, dpi=600):\n        if self.panel is not None:\n            self.panel.save_figure(event=event,\n                                   transparent=transparent, dpi=dpi)", "response": "save figure image to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots after clearing current plot", "response": "def plot(self, x, y, panel='top', xlabel=None, **kws):\n        \"\"\"plot after clearing current plot \"\"\"\n        panel = self.get_panel(panel)\n        panel.plot(x, y, **kws)\n        if xlabel is not None:\n            self.xlabel = xlabel\n        if self.xlabel is not None:\n            self.panel_bot.set_xlabel(self.xlabel)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nzooms out full data range", "response": "def unzoom_all(self, event=None):\n        \"\"\" zoom out full data range \"\"\"\n        for p in (self.panel, self.panel_bot):\n            p.conf.zoom_lims = []\n            p.conf.unzoom(full=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nzooming out 1 level, or to full data range", "response": "def unzoom(self, event=None, panel='top'):\n        \"\"\"zoom out 1 level, or to full data range \"\"\"\n        panel = self.get_panel(panel)\n        panel.conf.unzoom(event=event)\n        self.panel.set_viewlimits()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_line(self, t, x, y, panel='top', **kws):\n        panel = self.get_panel(panel)\n        panel.update_line(t, x, y, **kws)", "response": "overwrite data for trace t"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting xy limits for this log entry", "response": "def set_xylims(self, lims, axes=None, panel='top', **kws):\n        \"\"\"set xy limits\"\"\"\n        panel = self.get_panel(panel)\n        # print(\"Stacked set_xylims \", panel, self.panel)\n        panel.set_xylims(lims, axes=axes, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_figure(self, event=None, panel='top'):\n        panel = self.get_panel(panel)\n        panel.save_figure(event=event)", "response": "save figure image to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef toggle_grid(self, event=None, show=None):\n        \"toggle grid on top/bottom panels\"\n        if show is None:\n            show = not self.panel.conf.show_grid\n        for p in (self.panel, self.panel_bot):\n            p.conf.enable_grid(show)", "response": "toggle grid on top / bottom panels"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npasses theme colors to bottom panel", "response": "def onThemeColor(self, color, item):\n        \"\"\"pass theme colors to bottom panel\"\"\"\n        bconf = self.panel_bot.conf\n        if item == 'grid':\n            bconf.set_gridcolor(color)\n        elif item == 'bg':\n            bconf.set_bgcolor(color)\n        elif item == 'frame':\n            bconf.set_framecolor(color)\n        elif item == 'text':\n            bconf.set_textcolor(color)\n        bconf.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npasses left / right margins on to bottom panel", "response": "def onMargins(self, left=0.1, top=0.1, right=0.1, bottom=0.1):\n        \"\"\" pass left/right margins on to bottom panel\"\"\"\n        bconf = self.panel_bot.conf\n        l, t, r, b = bconf.margins\n        bconf.set_margins(left=left, top=t, right=right, bottom=b)\n        bconf.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating xy limits of a plot", "response": "def set_viewlimits(self, panel='top'):\n        \"\"\"update xy limits of a plot, as used with .update_line() \"\"\"\n        this_panel = self.get_panel(panel)\n\n        xmin, xmax, ymin, ymax = this_panel.conf.set_viewlimits()[0]\n        # print(\"Set ViewLimits \", xmin, xmax, ymin, ymax)\n        # make top/bottom panel follow xlimits\n        if this_panel == self.panel:\n            other = self.panel_bot\n            for _ax in other.fig.get_axes():\n                _ax.set_xlim((xmin, xmax), emit=True)\n            other.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding names to the internal collection of entry points to track .", "response": "def add_entry_points(self, names):\n        \"\"\"\n        adds `names` to the internal collection of entry points to track\n\n        `names` can be a single object or an iterable but\n        must be a string or iterable of strings.\n        \"\"\"\n        names = util.return_set(names)\n        self.entry_point_names.update(names)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the internal collection of entry points to be equal to names.", "response": "def set_entry_points(self, names):\n        \"\"\"\n        sets the internal collection of entry points to be\n        equal to `names`\n\n        `names` can be a single object or an iterable but\n        must be a string or iterable of strings.\n        \"\"\"\n        names = util.return_set(names)\n        self.entry_point_names = names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove names from the set of entry points to track.", "response": "def remove_entry_points(self, names):\n        \"\"\"\n        removes `names` from the set of entry points to track.\n\n        `names` can be a single object or an iterable.\n        \"\"\"\n        names = util.return_set(names)\n        util.remove_from_set(self.entry_point_names,\n                             names)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncollect the plugins from the entry_points.", "response": "def collect_plugins(self,\n                        entry_points=None,\n                        verify_requirements=False,\n                        return_dict=False):\n\n        \"\"\"\n        collects the plugins from the `entry_points`. If `entry_points` is not\n        explicitly defined, this method will pull from the internal state\n        defined using the add/set entry points methods.\n\n        `entry_points` can be a single object or an iterable, but must be\n        either a string or an iterable of strings.\n\n        returns a list of plugins or an empty list.\n        \"\"\"\n\n        if entry_points is None:\n            entry_points = self.entry_point_names\n        else:\n            entry_points = util.return_set(entry_points)\n\n        plugins = []\n        plugin_names = []\n        for name in entry_points:\n            for entry_point in pkg_resources.iter_entry_points(name):\n                if (hasattr(entry_point, 'resolve') and\n                        hasattr(entry_point, 'require')):\n\n                    if verify_requirements:\n                        entry_point.require()\n\n                    plugin = entry_point.resolve()\n                else:\n                    plugin = entry_point.load()\n\n                plugins.append(plugin)\n                plugin_names.append(entry_point.name)\n\n        if return_dict:\n            return {n: v for n, v in zip(plugin_names, plugins)}\n\n        return plugins, plugin_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_texmath(txt):\n    s = \"%s \" % txt\n    out = []\n    i = 0\n    while i < len(s)-1:\n        if s[i] == '\\\\' and s[i+1] in ('n', 't'):\n            if s[i+1] == 'n':\n                out.append('\\n')\n            elif s[i+1] == 't':\n                out.append('\\t')\n            i += 1\n        elif s[i] == '$':\n            j = s[i+1:].find('$')\n            if j < 0:\n                j = len(s)\n            out.append(s[i:j+2])\n            i += j+2\n        else:\n            out.append(s[i])\n        i += 1\n        if i > 5000:\n            break\n    return ''.join(out).strip()", "response": "clean tex math string preserving control sequences\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a linerace panel", "response": "def make_linetrace_panel(self, parent, font=None):\n        \"\"\"colours and line properties\"\"\"\n\n        panel = scrolled.ScrolledPanel(parent, size=(900, 250),\n                                       style=wx.GROW|wx.TAB_TRAVERSAL, name='p1')\n\n        if font is None:\n            font = wx.Font(12, wx.SWISS, wx.NORMAL, wx.NORMAL, False)\n\n        sizer = wx.GridBagSizer(2, 2)\n        i = 0\n\n        ax = self.axes[0]\n        if matplotlib.__version__ < '2.0':\n            axis_bgcol = ax.get_axis_bgcolor()\n        else:\n            axis_bgcol = ax.get_facecolor()\n\n        labstyle= wx.ALIGN_LEFT|wx.ALIGN_CENTER_VERTICAL\n\n        opts = dict(size=(40, 30), style=labstyle)\n\n        ctitle = wx.StaticText(panel, -1, ' Colors:  ')\n        ltheme = wx.StaticText(panel, -1, ' Color Theme: ')\n\n        themes = list(self.conf.color_themes.keys())\n\n        coltheme = wx.Choice(panel, choices=themes)\n        coltheme.SetStringSelection(self.conf.color_theme)\n        coltheme.Bind(wx.EVT_CHOICE, self.onColorThemeStyle)\n\n        textcol = csel.ColourSelect(panel, label=\" Text \",\n                                    colour=mpl_color(self.conf.textcolor),\n                                    size=(50, 30), style=labstyle)\n\n        gridcol = csel.ColourSelect(panel, label=\" Grid \",\n                                    colour=mpl_color(self.conf.gridcolor),\n                                    size=(50, 30), style=labstyle)\n\n        bgcol = csel.ColourSelect(panel, label=\" Background \",\n                                  colour=mpl_color(axis_bgcol),\n                                  size=(120, 30), style=labstyle)\n\n        fbgcol = csel.ColourSelect(panel,  label=\" Outer Frame \",\n                                   colour=mpl_color(self.canvas.figure.get_facecolor()),\n                                   size=(120, 30), style=labstyle)\n\n\n        self.colwids = {'text': textcol, 'bg': bgcol,\n                        'grid': gridcol, 'frame': fbgcol}\n\n        bgcol.Bind(csel.EVT_COLOURSELECT,   partial(self.onColor, item='bg'))\n        fbgcol.Bind(csel.EVT_COLOURSELECT,  partial(self.onColor, item='frame'))\n        gridcol.Bind(csel.EVT_COLOURSELECT, partial(self.onColor, item='grid'))\n        textcol.Bind(csel.EVT_COLOURSELECT, partial(self.onColor, item='text'))\n\n        show_grid  = wx.CheckBox(panel,-1, ' Show Grid ', (-1, -1), (-1, -1))\n        show_grid.Bind(wx.EVT_CHECKBOX,self.onShowGrid)\n        show_grid.SetValue(self.conf.show_grid)\n\n        show_box  = wx.CheckBox(panel,-1, ' Show Top/Right Axes ', (-1, -1), (-1, -1))\n        show_box.Bind(wx.EVT_CHECKBOX, self.onShowBox)\n        show_box.SetValue(self.conf.axes_style == 'box')\n\n        show_leg = wx.CheckBox(panel,-1, 'Show Legend', (-1, -1), (-1, -1))\n        show_leg.Bind(wx.EVT_CHECKBOX,partial(self.onShowLegend, item='legend'))\n        show_leg.SetValue(self.conf.show_legend)\n        if show_leg not in self.show_legend_cbs:\n            self.show_legend_cbs.append(show_leg)\n\n        reset_btn = wx.Button(panel, label='Reset Line Colors', size=(175, -1))\n        reset_btn.Bind(wx.EVT_BUTTON, self.onResetLines)\n\n        csizer = wx.BoxSizer(wx.HORIZONTAL)\n\n        csizer.Add(ctitle,    0, labstyle, 3)\n        csizer.Add(textcol,   0, labstyle, 3)\n        csizer.Add(gridcol,   0, labstyle, 3)\n        csizer.Add(bgcol,     0, labstyle, 3)\n        csizer.Add(fbgcol ,   0, labstyle, 3)\n        csizer.Add(ltheme,    1, labstyle, 3)\n        csizer.Add(coltheme,  1, labstyle, 3)\n        csizer.Add(reset_btn, 0, labstyle, 3)\n\n        sizer.Add(csizer,    (1, 0), (1, 9), labstyle, 2)\n\n\n        # csizer.Add(show_grid, 0, labstyle, 3)\n        # csizer.Add(show_box,  0, labstyle, 3)\n        sizer.Add(show_grid, (2, 1), (1, 1))\n        sizer.Add(show_box,  (2, 2), (1, 3))\n        sizer.Add(show_leg,  (2, 5), (1, 2))\n\n        irow = 3\n        for t in ('#','Label','Color', 'Style',\n                  'Thickness','Symbol',' Size', 'Z Order', 'Join Style'):\n            x = wx.StaticText(panel, -1, t)\n            x.SetFont(font)\n            sizer.Add(x,(irow,i),(1,1),wx.ALIGN_LEFT|wx.ALL, 3)\n            i = i+1\n        self.trace_labels = []\n        ntrace_display = min(self.conf.ntrace+2, len(self.conf.traces))\n        for i in range(ntrace_display):\n            irow += 1\n            label  = \"trace %i\" % i\n            lin  = self.conf.traces[i]\n            dlab = lin.label\n            dcol = hexcolor(lin.color)\n            dthk = lin.linewidth\n            dmsz = lin.markersize\n            dsty = lin.style\n            djsty = lin.drawstyle\n            dzord = lin.zorder\n            dsym = lin.marker\n            lab = LabelEntry(panel, dlab, size=125,labeltext=\"%i\" % (i+1),\n                               action = partial(self.onText, item='trace', trace=i))\n            self.trace_labels.append(lab)\n\n            col = csel.ColourSelect(panel,  -1, \"\", dcol, size=(25, 25))\n            col.Bind(csel.EVT_COLOURSELECT, partial(self.onColor, trace=i))\n\n            self.colwids[i] = col\n\n            thk = FloatSpin(panel, -1,  pos=(-1,-1), size=(FSPINSIZE, 25), value=dthk,\n                            min_val=0, max_val=10, increment=0.5, digits=1)\n            thk.Bind(EVT_FLOATSPIN, partial(self.onThickness, trace=i))\n\n            sty = wx.Choice(panel, choices=self.conf.styles, size=(100,-1))\n            sty.Bind(wx.EVT_CHOICE,partial(self.onStyle,trace=i))\n            sty.SetStringSelection(dsty)\n\n            msz = FloatSpin(panel, -1,  pos=(-1,-1), size=(FSPINSIZE, 25), value=dmsz,\n                            min_val=0, max_val=30, increment=1, digits=0)\n            msz.Bind(EVT_FLOATSPIN, partial(self.onMarkerSize, trace=i))\n\n            zor = FloatSpin(panel, -1,  pos=(-1,-1), size=(FSPINSIZE, 25),\n                            value=dzord,\n                            min_val=-500, max_val=500, increment=1, digits=0)\n            zor.Bind(EVT_FLOATSPIN, partial(self.onZorder, trace=i))\n\n            sym = wx.Choice(panel, -1, choices=self.conf.symbols, size=(120,-1))\n            sym.Bind(wx.EVT_CHOICE,partial(self.onSymbol,trace=i))\n\n            sym.SetStringSelection(dsym)\n\n            jsty = wx.Choice(panel, -1, choices=self.conf.drawstyles, size=(100,-1))\n            jsty.Bind(wx.EVT_CHOICE, partial(self.onJoinStyle, trace=i))\n            jsty.SetStringSelection(djsty)\n\n            sizer.Add(lab.label,(irow,0),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(lab, (irow,1),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(col, (irow,2),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(sty, (irow,3),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(thk, (irow,4),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(sym, (irow,5),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(msz, (irow,6),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(zor, (irow,7),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n            sizer.Add(jsty, (irow,8),(1,1),wx.ALIGN_LEFT|wx.ALL, 5)\n\n        autopack(panel,sizer)\n        panel.SetupScrolling()\n        return panel"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, line=None):\n        if line:\n            markercolor = self.markercolor\n            if markercolor is None: markercolor=self.color\n            # self.set_markeredgecolor(markercolor, line=line)\n            # self.set_markerfacecolor(markercolor, line=line)\n\n            self.set_label(self.label, line=line)\n            self.set_color(self.color, line=line)\n            self.set_style(self.style, line=line)\n            self.set_drawstyle(self.drawstyle, line=line)\n            self.set_marker(self.marker,line=line)\n            self.set_markersize(self.markersize, line=line)\n            self.set_linewidth(self.linewidth, line=line)", "response": "update the matplotlib Line2D to have the current properties"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _init_trace(self, n,  color, style,\n                    linewidth=2.5, zorder=None, marker=None, markersize=6):\n        \"\"\" used for building set of traces\"\"\"\n        while n >= len(self.traces):\n            self.traces.append(LineProperties())\n        line = self.traces[n]\n        label = \"trace %i\" % (n+1)\n        line.label = label\n        line.drawstyle = 'default'\n        if zorder     is None:\n            zorder = 5 * (n+1)\n        line.zorder = zorder\n        if color      is not None: line.color = color\n        if style      is not None: line.style = style\n        if linewidth  is not None: line.linewidth = linewidth\n        if marker     is not None: line.marker = marker\n        if markersize is not None: line.markersize = markersize\n        self.traces[n] = line", "response": "initialize the trace n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_gridcolor(self, color):\n        self.gridcolor = color\n        for ax in self.canvas.figure.get_axes():\n            for i in ax.get_xgridlines()+ax.get_ygridlines():\n                i.set_color(color)\n                i.set_zorder(-1)\n        if callable(self.theme_color_callback):\n            self.theme_color_callback(color, 'grid')", "response": "set color for grid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting color for background of plot", "response": "def set_bgcolor(self, color):\n        \"\"\"set color for background of plot\"\"\"\n        self.bgcolor = color\n        for ax in self.canvas.figure.get_axes():\n            if matplotlib.__version__ < '2.0':\n                ax.set_axis_bgcolor(color)\n            else:\n                ax.set_facecolor(color)\n        if callable(self.theme_color_callback):\n            self.theme_color_callback(color, 'bg')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting color for outer frame", "response": "def set_framecolor(self, color):\n        \"\"\"set color for outer frame\"\"\"\n        self.framecolor = color\n        self.canvas.figure.set_facecolor(color)\n        if callable(self.theme_color_callback):\n            self.theme_color_callback(color, 'frame')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets color for labels and axis text", "response": "def set_textcolor(self, color):\n        \"\"\"set color for labels and axis text\"\"\"\n        self.textcolor = color\n        self.relabel()\n        if callable(self.theme_color_callback):\n            self.theme_color_callback(color, 'text')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables or disable grid display", "response": "def enable_grid(self, show=None, delay_draw=False):\n        \"enable/disable grid display\"\n        if show is not None:\n            self.show_grid = show\n        axes = self.canvas.figure.get_axes()\n        ax0 = axes[0]\n        for i in ax0.get_xgridlines() + ax0.get_ygridlines():\n            i.set_color(self.gridcolor)\n            i.set_zorder(-1)\n        axes[0].grid(self.show_grid)\n        for ax in axes[1:]:\n            ax.grid(False)\n        if not delay_draw:\n            self.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting axes style: one of 'box' / 'fullbox' : show all four axes borders 'open' / 'leftbot' : show left and bottom axes 'bottom' : show bottom axes only", "response": "def set_axes_style(self, style=None, delay_draw=False):\n        \"\"\"set axes style: one of\n           'box' / 'fullbox'  : show all four axes borders\n           'open' / 'leftbot' : show left and bottom axes\n           'bottom'           : show bottom axes only\n        \"\"\"\n        if style is not None:\n            self.axes_style = style\n        axes0 = self.canvas.figure.get_axes()[0]\n        _sty = self.axes_style.lower()\n        if  _sty in ('fullbox', 'full'):\n            _sty = 'box'\n        if  _sty == 'leftbot':\n            _sty = 'open'\n\n        if _sty == 'box':\n            axes0.xaxis.set_ticks_position('both')\n            axes0.yaxis.set_ticks_position('both')\n            axes0.spines['top'].set_visible(True)\n            axes0.spines['right'].set_visible(True)\n        elif _sty == 'open':\n            axes0.xaxis.set_ticks_position('bottom')\n            axes0.yaxis.set_ticks_position('left')\n            axes0.spines['top'].set_visible(False)\n            axes0.spines['right'].set_visible(False)\n        elif _sty == 'bottom':\n            axes0.xaxis.set_ticks_position('bottom')\n            axes0.spines['top'].set_visible(False)\n            axes0.spines['left'].set_visible(False)\n            axes0.spines['right'].set_visible(False)\n        if not delay_draw:\n            self.canvas.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unzoom(self, full=False, delay_draw=False):\n        if full:\n            self.zoom_lims = self.zoom_lims[:1]\n            self.zoom_lims = []\n        elif len(self.zoom_lims) > 0:\n            self.zoom_lims.pop()\n        self.set_viewlimits()\n        if not delay_draw:\n            self.canvas.draw()", "response": "unzoom display 1 level or all the way"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_logscale(self, xscale='linear', yscale='linear',\n                     delay_draw=False):\n        \"set log or linear scale for x, y axis\"\n        self.xscale = xscale\n        self.yscale = yscale\n        for axes in self.canvas.figure.get_axes():\n            try:\n                axes.set_yscale(yscale, basey=10)\n            except:\n                axes.set_yscale('linear')\n            try:\n                axes.set_xscale(xscale, basex=10)\n            except:\n                axes.set_xscale('linear')\n        if not delay_draw:\n            self.process_data()", "response": "set log or linear scale for x y axis"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds text to plot", "response": "def add_text(self, text, x, y, **kws):\n        \"\"\"add text to plot\"\"\"\n        self.panel.add_text(text, x, y, **kws)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_arrow(self, x1, y1, x2, y2, **kws):\n        self.panel.add_arrow(x1, y1, x2, y2, **kws)", "response": "add arrow to plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(self, x, y, **kw):\n        self.panel.plot(x, y, **kw)", "response": "plot the current plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef oplot(self, x, y, **kw):\n        self.panel.oplot(x, y, **kw)", "response": "generic plotting method overplotting any existing plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef scatterplot(self, x, y, **kw):\n        self.panel.scatterplot(x, y, **kw)", "response": "scatterplot after clearing current plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nover-writes data for trace t", "response": "def update_line(self, t, x, y, **kw):\n        \"\"\"overwrite data for trace t \"\"\"\n        self.panel.update_line(t, x, y, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ExportTextFile(self, fname, title='unknown plot'):\n        \"save plot data to external file\"\n\n        buff = [\"# Plot Data for %s\" % title,\n                \"#---------------------------------\"]\n\n        out = []\n        labels = []\n        itrace = 0\n        for ax in self.panel.fig.get_axes():\n            for line in ax.lines:\n                itrace += 1\n                x = line.get_xdata()\n                y = line.get_ydata()\n                ylab = line.get_label()\n\n                if len(ylab) < 1:\n                    ylab = 'Y%i' % itrace\n                for c in ' .:\";|/\\\\(){}[]\\'&^%*$+=-?!@#':\n                    ylab = ylab.replace(c, '_')\n                xlab = (' X%d' % itrace + ' '*3)[:4]\n                ylab = ' '*(18-len(ylab)) + ylab + '  '\n                out.extend([x, y])\n                labels.extend([xlab, ylab])\n\n        if itrace == 0:\n            return\n\n        buff.append('# %s' % (' '.join(labels)))\n\n        npts = [len(a) for a in out]\n        for i in range(max(npts)):\n            oline = []\n            for a in out:\n                d = np.nan\n                if i < len(a):\n                    d = a[i]\n                oline.append(gformat(d, 12))\n            buff.append(' '.join(oline))\n\n        buff.append('')\n        with open(fname, 'w') as fout:\n            fout.write(\"\\n\".join(buff))\n        fout.close()\n        self.write_message(\"Exported data to '%s'\" % fname, panel=0)", "response": "save plot data to external file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding directories to the set of plugin directories.", "response": "def add_plugin_directories(self, paths, except_blacklisted=True):\n        \"\"\"\n        Adds `directories` to the set of plugin directories.\n\n        `directories` may be either a single object or a iterable.\n\n        `directories` can be relative paths, but will be converted into\n        absolute paths based on the current working directory.\n\n        if `except_blacklisted` is `True` all `directories` in\n        that are blacklisted will be removed\n        \"\"\"\n        self.directory_manager.add_directories(paths, except_blacklisted)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_plugin_directories(self, paths, except_blacklisted=True):\n        self.directory_manager.set_directories(paths, except_blacklisted)", "response": "Sets the plugin directories to paths."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_plugin_filepaths(self, filepaths, except_blacklisted=True):\n        self.file_manager.add_plugin_filepaths(filepaths,\n                                               except_blacklisted)", "response": "Adds filepaths to internal state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset internal state to filepaths. Recommend passing filepaths in absolute filepaths.", "response": "def set_plugin_filepaths(self, filepaths, except_blacklisted=True):\n        \"\"\"\n        Sets internal state to `filepaths`. Recommend passing\n        in absolute filepaths. Method will attempt to convert to\n        absolute paths if they are not already.\n\n        `filepaths` can be a single object or an iterable.\n\n        If `except_blacklisted` is `True`, all `filepaths` that\n        have been blacklisted will not be set.\n        \"\"\"\n        self.file_manager.set_plugin_filepaths(filepaths,\n                                               except_blacklisted)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_blacklisted_directories(self,\n                                    directories,\n                                    rm_black_dirs_from_stored_dirs=True):\n        \"\"\"\n        Adds `directories` to be blacklisted. Blacklisted directories will not\n        be returned or searched recursively when calling the\n        `collect_directories` method.\n\n        `directories` may be a single instance or an iterable. Recommend\n        passing in absolute paths, but method will try to convert to absolute\n        paths based on the current working directory.\n\n        If `remove_from_stored_directories` is true, all `directories`\n        will be removed from internal state.\n        \"\"\"\n        add_black_dirs = self.directory_manager.add_blacklisted_directories\n        add_black_dirs(directories, rm_black_dirs_from_stored_dirs)", "response": "Adds directories to be blacklisted."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the directories to be blacklisted.", "response": "def set_blacklisted_directories(self,\n                                    directories,\n                                    rm_black_dirs_from_stored_dirs=True):\n        \"\"\"\n        Sets the `directories` to be blacklisted. Blacklisted directories will\n        not be returned or searched recursively when calling\n        `collect_directories`.\n\n        This will replace the previously stored set of blacklisted\n        paths.\n\n        `directories` may be a single instance or an iterable. Recommend\n        passing in absolute paths. Method will try to convert to absolute path\n        based on current working directory.\n        \"\"\"\n        set_black_dirs = self.directory_manager.set_blacklisted_directories\n        set_black_dirs(directories, rm_black_dirs_from_stored_dirs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd filepaths to blacklisted filepaths.", "response": "def add_blacklisted_filepaths(self, filepaths, remove_from_stored=True):\n        \"\"\"\n        Add `filepaths` to blacklisted filepaths.\n        If `remove_from_stored` is `True`, any `filepaths` in\n        internal state will be automatically removed.\n        \"\"\"\n        self.file_manager.add_blacklisted_filepaths(filepaths,\n                                                    remove_from_stored)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef collect_filepaths(self, directories):\n        plugin_filepaths = set()\n        directories = util.to_absolute_paths(directories)\n        for directory in directories:\n            filepaths = util.get_filepaths_from_dir(directory)\n            filepaths = self._filter_filepaths(filepaths)\n            plugin_filepaths.update(set(filepaths))\n\n        plugin_filepaths = self._remove_blacklisted(plugin_filepaths)\n\n        return plugin_filepaths", "response": "Collects and returns every filepath from each directory in directories that is filtered through file_filters."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds filepaths to the internal filepaths list.", "response": "def add_plugin_filepaths(self, filepaths, except_blacklisted=True):\n        \"\"\"\n        Adds `filepaths` to the `self.plugin_filepaths`. Recommend passing\n        in absolute filepaths. Method will attempt to convert to\n        absolute paths if they are not already.\n\n        `filepaths` can be a single object or an iterable\n\n        If `except_blacklisted` is `True`, all `filepaths` that\n        have been blacklisted will not be added.\n        \"\"\"\n        filepaths = util.to_absolute_paths(filepaths)\n        if except_blacklisted:\n            filepaths = util.remove_from_set(filepaths,\n                                             self.blacklisted_filepaths)\n\n        self.plugin_filepaths.update(filepaths)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_plugin_filepaths(self, filepaths, except_blacklisted=True):\n        filepaths = util.to_absolute_paths(filepaths)\n        if except_blacklisted:\n            filepaths = util.remove_from_set(filepaths,\n                                             self.blacklisted_filepaths)\n\n        self.plugin_filepaths = filepaths", "response": "Sets filepaths to the plugin_filepaths attribute."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_plugin_filepaths(self, filepaths):\n        filepaths = util.to_absolute_paths(filepaths)\n        self.plugin_filepaths = util.remove_from_set(self.plugin_filepaths,\n                                                     filepaths)", "response": "Removes filepaths from self. plugin_filepaths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset internal file filters to file_filters by tossing old state.", "response": "def set_file_filters(self, file_filters):\n        \"\"\"\n        Sets internal file filters to `file_filters` by tossing old state.\n        `file_filters` can be single object or iterable.\n        \"\"\"\n        file_filters = util.return_list(file_filters)\n        self.file_filters = file_filters"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_file_filters(self, file_filters):\n        file_filters = util.return_list(file_filters)\n        self.file_filters.extend(file_filters)", "response": "Adds file_filters to the internal file filters list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_file_filters(self, file_filters):\n        self.file_filters = util.remove_from_list(self.file_filters,\n                                                  file_filters)", "response": "Removes the file_filters from the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding filepaths to blacklisted filepaths.", "response": "def add_blacklisted_filepaths(self, filepaths, remove_from_stored=True):\n        \"\"\"\n        Add `filepaths` to blacklisted filepaths.\n        If `remove_from_stored` is `True`, any `filepaths` in\n        `plugin_filepaths` will be automatically removed.\n\n        Recommend passing in absolute filepaths but method will attempt\n        to convert to absolute filepaths based on current working directory.\n        \"\"\"\n        filepaths = util.to_absolute_paths(filepaths)\n        self.blacklisted_filepaths.update(filepaths)\n        if remove_from_stored:\n            self.plugin_filepaths = util.remove_from_set(self.plugin_filepaths,\n                                                         filepaths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_blacklisted_filepaths(self, filepaths, remove_from_stored=True):\n        filepaths = util.to_absolute_paths(filepaths)\n        self.blacklisted_filepaths = filepaths\n        if remove_from_stored:\n            self.plugin_filepaths = util.remove_from_set(self.plugin_filepaths,\n                                                         filepaths)", "response": "Sets internal blacklisted filepaths to filepaths."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_blacklisted_filepaths(self, filepaths):\n        filepaths = util.to_absolute_paths(filepaths)\n        black_paths = self.blacklisted_filepaths\n        black_paths = util.remove_from_set(black_paths, filepaths)", "response": "Removes filepaths from blacklisted filepaths"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _remove_blacklisted(self, filepaths):\n        filepaths = util.remove_from_set(filepaths, self.blacklisted_filepaths)\n        return filepaths", "response": "Internal helper method to remove the blacklisted filepaths from filepaths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhelping iterate through all the file parsers each filter is applied individually to the same set of `filepaths`", "response": "def _filter_filepaths(self, filepaths):\n        \"\"\"\n        helps iterate through all the file parsers\n        each filter is applied individually to the\n        same set of `filepaths`\n        \"\"\"\n        if self.file_filters:\n            plugin_filepaths = set()\n            for file_filter in self.file_filters:\n                plugin_paths = file_filter(filepaths)\n                plugin_filepaths.update(plugin_paths)\n        else:\n            plugin_filepaths = filepaths\n\n        return plugin_filepaths"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nplots after clearing current plot", "response": "def plot(self,x,y,panel=None,**kws):\n        \"\"\"plot after clearing current plot \"\"\"\n        if panel is None:\n            panel = self.current_panel\n        opts = {}\n        opts.update(self.default_panelopts)\n        opts.update(kws)\n        self.panels[panel].plot(x ,y, **opts)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_line(self, t, x, y, panel=None, **kw):\n        if panel is None:\n            panel = self.current_panel\n        self.panels[panel].update_line(t, x, y, **kw)", "response": "overwrite data for trace t"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\noverwriting data for trace t", "response": "def set_xylims(self, lims, axes=None, panel=None):\n        \"\"\"overwrite data for trace t \"\"\"\n        if panel is None: panel = self.current_panel\n        self.panels[panel].set_xylims(lims, axes=axes, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unzoom_all(self,event=None,panel=None):\n        if panel is None: panel = self.current_panel\n        self.panels[panel].unzoom_all(event=event)", "response": "zoom out full data range"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nzoom out 1 level or to full data range", "response": "def unzoom(self,event=None,panel=None):\n        \"\"\"zoom out 1 level, or to full data range \"\"\"\n        if panel is None: panel = self.current_panel\n        self.panels[panel].unzoom(event=event)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave figure image to file", "response": "def save_figure(self,event=None,panel=None):\n        \"\"\" save figure image to file\"\"\"\n        if panel is None: panel = self.current_panel\n        self.panels[panel].save_figure(event=event)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn rgb tuple for named color in rgb. txt or hex color", "response": "def rgb(color,default=(0,0,0)):\n    \"\"\" return rgb tuple for named color in rgb.txt or a hex color \"\"\"\n    c = color.lower()\n    if c[0:1] == '#' and len(c)==7:\n        r,g,b = c[1:3], c[3:5], c[5:]\n        r,g,b = [int(n, 16) for n in (r, g, b)]\n        return (r,g,b)\n\n    if c.find(' ')>-1:    c = c.replace(' ','')\n    if c.find('gray')>-1: c = c.replace('gray','grey')\n    if c in x11_colors.keys():  return x11_colors[c]\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning hex color given a tuple wx. Color or X11 named color", "response": "def hexcolor(color):\n    \" returns hex color given a tuple, wx.Color, or X11 named color\"\n    # first, if this is a hex color already, return!\n    # Python 3: needs rewrite for str/unicode change\n    if isinstance(color, six.string_types):\n        if color[0] == '#' and len(color)==7:\n            return color.lower()\n\n    # now, get color to an rgb tuple\n    rgb = (0,0,0)\n    if isinstance(color, tuple):\n        rgb = color\n    elif isinstance(color, list):\n        rgb = tuple(color)\n    elif isinstance(color, six.string_types):\n        c = color.lower()\n        if c.find(' ')>-1:    c = c.replace(' ','')\n        if c.find('gray')>-1: c = c.replace('gray','grey')\n        if c in x11_colors:\n            rgb = x11_colors[c]\n    else:\n        try:\n            rgb = color.Red(), color.Green(), color.Blue()\n        except:\n            pass\n\n    # convert rgb to hex color\n    col = '#%02x%02x%02x' % (rgb)\n    return col.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef register_custom_colormaps():\n    if not HAS_MPL:\n        return ()\n    makemap = LinearSegmentedColormap.from_list\n    for name, val in custom_colormap_data.items():\n        cm1 = np.array(val).transpose().astype('f8')/256.0\n        cm2 = cm1[::-1]\n        nam1 = name\n        nam2 = '%s_r' % name\n        register_cmap(name=nam1, cmap=makemap(nam1, cm1, 256), lut=256)\n        register_cmap(name=nam2, cmap=makemap(nam2, cm2, 256), lut=256)\n\n    return ('stdgamma', 'red', 'green', 'blue', 'red_heat', 'green_heat',\n            'blue_heat', 'magenta', 'yellow', 'cyan')", "response": "Registers custom color maps for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplot after clearing current plot", "response": "def plot_residual(self, x, y1, y2, label1='Raw data', label2='Fit/theory', \n             xlabel=None, ylabel=None, show_legend=True,\n             **kws):\n        \"\"\"plot after clearing current plot \"\"\"\n\n        panel = self.get_panel('top')\n        panel.plot(x, y1, label=label1, **kws)\n        panel = self.get_panel('top')\n        panel.oplot(x, y2, label=label2, ylabel=ylabel, show_legend=show_legend, **kws)\n        panel = self.get_panel('bottom')\n        panel.plot(x, (y2-y1), ylabel='residual', show_legend=False, **kws)\n        \n        if xlabel is not None:\n            self.xlabel = xlabel\n        if self.xlabel is not None:\n            self.panel_bot.set_xlabel(self.xlabel)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display(self, img, title=None, colormap=None, style='image',\n                subtitles=None, auto_contrast=False, contrast_level=None, **kws):\n        \"\"\"display image\"\"\"\n        if title is not None:\n            self.SetTitle(title)\n        if subtitles is not None:\n            self.subtitles = subtitles\n        cmode = self.config_mode.lower()[:3]\n        img = np.array(img)\n\n        if len(img.shape) == 3:\n            ishape = img.shape\n            # make sure 3d image is shaped (NY, NX, 3)\n            if ishape[2] != 3:\n                if ishape[0] == 3:\n                    img = img.swapaxes(0, 1).swapaxes(1, 2)\n                elif ishape[1] == 3:\n                    img = img.swapaxes(1, 2)\n\n            if cmode != 'rgb':\n                for comp in self.config_panel.Children:\n                    comp.Destroy()\n                self.config_mode = 'rgb'\n                self.panel.conf.tricolor_mode = 'rgb'\n                self.Build_ConfigPanel()\n        else:\n            if cmode != 'int':\n                for comp in self.config_panel.Children:\n                    comp.Destroy()\n                self.config_mode = 'int'\n                self.Build_ConfigPanel()\n\n        if contrast_level is None:\n            if auto_contrast:\n                cl_str = '1.0'\n            else:\n                cl_str = self.contrast_panel.choice.GetStringSelection()\n        else:\n            cl_int = max(np.where(Contrast_NDArray<=contrast_level)[0])\n            cl_str = Contrast_List[cl_int]\n\n        if cl_str == 'None':\n            contrast_level = 0\n        else:\n            contrast_level = float(cl_str)\n\n        self.contrast_panel.choice.SetStringSelection(cl_str)\n        self.panel.conf.contrast_level = contrast_level\n\n        self.panel.display(img, style=style, contrast_level=contrast_level,\n                           **kws)\n\n        self.set_contrast_levels(contrast_level=contrast_level)\n\n        self.panel.conf.title = title\n        if colormap is not None and self.config_mode == 'int':\n            self.cmap_panels[0].set_colormap(name=colormap)\n\n        if subtitles is not None:\n            if isinstance(subtitles, dict):\n                self.set_subtitles(**subtitles)\n            elif self.config_mode == 'int':\n                self.set_subtitles(red=subtitles)\n\n        self.panel.conf.style = 'image'\n        self.contrast_panel.Enable()\n        self.interp_panel.Enable()\n        if style == 'contour':\n            self.panel.conf.style = 'contour'\n            self.contrast_panel.Disable()\n            self.interp_panel.Disable()\n\n        self.config_panel.Refresh()\n        self.SendSizeEvent()\n        wx.CallAfter(self.EnableMenus)", "response": "display image in the current color panel"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Build_ConfigPanel(self):\n        panel = self.config_panel\n        sizer = wx.BoxSizer(wx.VERTICAL)\n\n        lsty = wx.ALIGN_LEFT|wx.LEFT|wx.TOP|wx.EXPAND\n\n        if self.config_mode == 'rgb':\n            for icol, col in enumerate(RGB_COLORS):\n                self.cmap_panels[icol] =  ColorMapPanel(self.config_panel,\n                                                       self.panel,\n                                                       title='%s: ' % col.title(),\n                                                       color=icol,\n                                                       default=col,\n                                                       colormap_list=None)\n\n                sizer.Add(self.cmap_panels[icol], 0, lsty, 2)\n\n                sizer.Add(wx.StaticLine(self.config_panel, size=(100, 2),\n                                        style=wx.LI_HORIZONTAL), 0, lsty, 2)\n\n            self.interp_panel = InterpPanel(self.config_panel,\n                                            callback=self.onInterp)\n            self.contrast_panel = ContrastPanel(self.config_panel,\n                                            callback=self.set_contrast_levels)\n\n            sizer.Add(self.interp_panel, 0, lsty, 2)\n            sizer.Add(self.contrast_panel, 0, lsty, 2)\n\n\n        else:\n            self.cmap_panels[0] =  ColorMapPanel(self.config_panel,\n                                                 self.panel,\n                                                 default='gray',\n                                                 colormap_list=ColorMap_List)\n            self.interp_panel = InterpPanel(self.config_panel,\n                                            callback=self.onInterp)\n            self.contrast_panel = ContrastPanel(self.config_panel,\n                                            callback=self.set_contrast_levels)\n\n            sizer.Add(self.cmap_panels[0],  0, lsty, 1)\n            sizer.Add(wx.StaticLine(self.config_panel, size=(100, 2),\n                                    style=wx.LI_HORIZONTAL), 0, lsty, 2)\n            sizer.Add(self.interp_panel, 0, lsty, 2)\n            sizer.Add(self.contrast_panel, 0, lsty, 2)\n\n        cust = self.CustomConfig(self.config_panel, None, 0)\n        if cust is not None:\n            sizer.Add(cust, 0, lsty, 1)\n        pack(self.config_panel, sizer)", "response": "Builds the config panel for left - hand - side of frame RGB Maps"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nenhance contrast levels or use full data range", "response": "def set_contrast_levels(self, contrast_level=None):\n        \"\"\"enhance contrast levels, or use full data range\n        according to value of self.panel.conf.contrast_level\n        \"\"\"\n        if contrast_level is None:\n            clevel = self.contrast_panel.choice.GetStringSelection()\n            if clevel == 'None':\n                contrast_level = 0\n            else:\n                contrast_level = float(clevel)\n\n        conf = self.panel.conf\n        img  = self.panel.conf.data\n        if contrast_level is None:\n            contrast_level = 0\n        conf.contrast_level = contrast_level\n        clevels = [contrast_level, 100.0-contrast_level]\n\n        if len(img.shape) == 2: # intensity map\n            col = 0\n            jmin = imin = img.min()\n            jmax = imax = img.max()\n            self.cmap_panels[col].imin_val.SetValue('%.4g' % imin)\n            self.cmap_panels[col].imax_val.SetValue('%.4g' % imax)\n\n            jmin, jmax = np.percentile(img, clevels)\n            if imax == imin:\n                imax = imin + 0.5\n            conf.cmap_lo[col] = xlo = (jmin-imin)*conf.cmap_range/(imax-imin)\n            conf.cmap_hi[col] = xhi = (jmax-imin)*conf.cmap_range/(imax-imin)\n\n\n            self.cmap_panels[col].cmap_hi.SetValue(xhi)\n            self.cmap_panels[col].cmap_lo.SetValue(xlo)\n            self.cmap_panels[col].islider_range.SetLabel('Shown: [ %.4g :  %.4g ]' % (jmin, jmax))\n            self.cmap_panels[col].redraw_cmap()\n\n        if len(img.shape) == 3: # rgb map\n            for ix in range(3):\n                jmin = imin = img[:,:,ix].min()\n                jmax = imax = img[:,:,ix].max()\n                self.cmap_panels[ix].imin_val.SetValue('%.4g' % imin)\n                self.cmap_panels[ix].imax_val.SetValue('%.4g' % imax)\n\n                jmin, jmax = np.percentile(img[:,:,ix], clevels)\n                if imax == imin:\n                    imax = imin + 0.5\n                conf.cmap_lo[ix] = xlo = (jmin-imin)*conf.cmap_range/(imax-imin)\n                conf.cmap_hi[ix] = xhi = (jmax-imin)*conf.cmap_range/(imax-imin)\n                self.cmap_panels[ix].cmap_hi.SetValue(xhi)\n                self.cmap_panels[ix].cmap_lo.SetValue(xlo)\n\n                self.cmap_panels[ix].islider_range.SetLabel('Shown: [ %.4g :  %.4g ]' % (jmin, jmax))\n                self.cmap_panels[ix].redraw_cmap()\n        self.panel.redraw()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef onCMapSave(self, event=None, col='int'):\n        file_choices = 'PNG (*.png)|*.png'\n        ofile = 'Colormap.png'\n        dlg = wx.FileDialog(self, message='Save Colormap as...',\n                            defaultDir=os.getcwd(),\n                            defaultFile=ofile,\n                            wildcard=file_choices,\n                            style=wx.FD_SAVE|wx.FD_CHANGE_DIR)\n\n        if dlg.ShowModal() == wx.ID_OK:\n            self.cmap_panels[0].cmap_canvas.print_figure(dlg.GetPath(), dpi=600)", "response": "save color table image"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef save_figure(self,event=None, transparent=True, dpi=600):\n        if self.panel is not None:\n            self.panel.save_figure(event=event,\n                                   transparent=transparent, dpi=dpi)", "response": "save figure image to file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the given filename is a valid plugin for this Strategy", "response": "def plugin_valid(self, filename):\n        \"\"\"\n        Checks if the given filename is a valid plugin for this Strategy\n        \"\"\"\n        filename = os.path.basename(filename)\n        for regex in self.regex_expressions:\n            if regex.match(filename):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auto_reply_message(self):\n        if self._auto_reply is None:\n            r = requests.get('https://outlook.office.com/api/v2.0/me/MailboxSettings/AutomaticRepliesSetting',\n                             headers=self._headers)\n            check_response(r)\n            self._auto_reply = r.json().get('InternalReplyMessage')\n\n        return self._auto_reply", "response": "The account s Internal Auto Reply Message"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_auto_reply(self, message, status=AutoReplyStatus.ALWAYS_ENABLED, start=None, end=None,\n                       external_message=None, audience=AutoReplyAudience.ALL):\n        # type: (str, OutlookAccount.AutoReplyStatus, datetime, datetime, str, OutlookAccount.AutoReplyAudience) -> None\n        \"\"\" Set an automatic reply for the account.\n        Args:\n            message (str): The message to be sent in replies. If external_message is provided this is the message sent\n            to internal recipients\n            status (OutlookAccount.AutoReplyStatus): Whether the auto-reply should be always enabled, scheduled, or\n            disabled. You can use :class:`AutoReplyStatus <pyOutlook.core.main.OutlookAccount.AutoReplyStatus>` to\n            provide the value. Defaults to ALWAYS_ENABLED.\n            start (datetime): If status is set to SCHEDULED, this is when the replies will start being sent.\n            end (datetime): If status is set to SCHEDULED, this is when the replies will stop being sent.\n            external_message (str): If provided, this message will be sent to external recipients.\n            audience (OutlookAccount.AutoReplyAudience): Whether replies should be sent to everyone, contacts only,\n            or internal recipients only. You can use\n            :class:`AutoReplyAudience <pyOutlook.core.main.OutlookAccount.AutoReplyAudience>` to provide the value.\n\n        \"\"\"\n\n        start_is_none = start is None\n        end_is_none = end is None\n\n        if (not start_is_none and end_is_none) or (start_is_none and not end_is_none):\n            raise ValueError('Start and End not must both either be None or datetimes')\n\n        start_is_datetime = isinstance(start, datetime)\n        end_is_datetime = isinstance(end, datetime)\n\n        if not start_is_datetime and not start_is_none or not end_is_datetime and not end_is_none:\n            raise ValueError('Start and End must both either be None or datetimes')\n\n        request_data = dict(Status=status, ExternalAudience=audience)\n\n        # Outlook requires both an internal and external message. For convenience, pyOutlook allows only one message\n        # and uses that as the external message if none is provided\n        if external_message is None:\n            external_message = message\n\n        request_data.update(InternalReplyMessage=message, ExternalReplyMessage=external_message)\n\n        if not start_is_none and not end_is_none:\n            request_data.update(ScheduledStartDateTime=dict(DateTime=str(start)))\n            request_data.update(ScheduledEndDateTime=dict(DateTime=str(end)))\n\n        data = {\n            \"@odata.context\": \"https://outlook.office.com/api/v2.0/$metadata#Me/MailboxSettings\",\n            \"AutomaticRepliesSetting\": request_data\n        }\n\n        requests.patch('https://outlook.office.com/api/v2.0/me/MailboxSettings',\n                       headers=self._headers, data=json.dumps(data))\n\n        self._auto_reply = message", "response": "Sets the automatic reply for the account."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_message(self, message_id):\n        r = requests.get('https://outlook.office.com/api/v2.0/me/messages/' + message_id, headers=self._headers)\n        check_response(r)\n        return Message._json_to_message(self, r.json())", "response": "Gets the message matching the provided id."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting first 10 messages in account across all folders.", "response": "def get_messages(self, page=0):\n        \"\"\"Get first 10 messages in account, across all folders.\n\n        Keyword Args:\n            page (int): Integer representing the 'page' of results to fetch\n\n        Returns:\n            List[:class:`Message <pyOutlook.core.message.Message>`]\n\n        \"\"\"\n        endpoint = 'https://outlook.office.com/api/v2.0/me/messages'\n        if page > 0:\n            endpoint = endpoint + '/?%24skip=' + str(page) + '0'\n\n        log.debug('Getting messages from endpoint: {} with Headers: {}'.format(endpoint, self._headers))\n\n        r = requests.get(endpoint, headers=self._headers)\n\n        check_response(r)\n\n        return Message._json_to_messages(self, r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new email object.", "response": "def new_email(self, body='', subject='', to=list):\n        \"\"\"Creates a :class:`Message <pyOutlook.core.message.Message>` object.\n\n        Keyword Args:\n            body (str): The body of the email\n            subject (str): The subject of the email\n            to (List[Contact]): A list of recipients to email\n\n        Returns:\n            :class:`Message <pyOutlook.core.message.Message>`\n\n        \"\"\"\n        return Message(self.access_token, body, subject, to)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending an email in one method", "response": "def send_email(self, body=None, subject=None, to=list, cc=None, bcc=None,\n                   send_as=None, attachments=None):\n        \"\"\"Sends an email in one method, a shortcut for creating an instance of\n        :class:`Message <pyOutlook.core.message.Message>` .\n\n        Args:\n            body (str): The body of the email\n            subject (str): The subject of the email\n            to (list): A list of :class:`Contacts <pyOutlook.core.contact.Contact>`\n            cc (list): A list of :class:`Contacts <pyOutlook.core.contact.Contact>` which will be added to the\n                'Carbon Copy' line\n            bcc (list): A list of :class:`Contacts <pyOutlook.core.contact.Contact>` while be blindly added to the email\n            send_as (Contact): A :class:`Contact <pyOutlook.core.contact.Contact>` whose email the OutlookAccount\n                has access to\n            attachments (list): A list of dictionaries with two parts\n                [1] 'name' - a string which will become the file's name\n                [2] 'bytes' - the bytes of the file.\n\n        \"\"\"\n        email = Message(self.access_token, body, subject, to, cc=cc, bcc=bcc, sender=send_as)\n\n        if attachments is not None:\n            for attachment in attachments:\n                email.attach(attachment.get('bytes'), attachment.get('name'))\n\n        email.send()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all folders for this account", "response": "def get_folders(self):\n        \"\"\" Returns a list of all folders for this account\n\n            Returns:\n                List[:class:`Folder <pyOutlook.core.folder.Folder>`]\n        \"\"\"\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/'\n\n        r = requests.get(endpoint, headers=self._headers)\n\n        if check_response(r):\n            return Folder._json_to_folders(self, r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_folder_by_id(self, folder_id):\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + folder_id\n\n        r = requests.get(endpoint, headers=self._headers)\n\n        check_response(r)\n        return_folder = r.json()\n        return Folder._json_to_folder(self, return_folder)", "response": "Retrieve a Folder by its Outlook ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_messages_from_folder_name(self, folder_name):\n        r = requests.get('https://outlook.office.com/api/v2.0/me/MailFolders/' + folder_name + '/messages',\n                         headers=self._headers)\n        check_response(r)\n        return Message._json_to_messages(self, r.json())", "response": "Retrieves all messages from a folder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parent_folder(self):\n        # type: () -> Folder\n        \"\"\" Returns the :class:`Folder <pyOutlook.core.folder.Folder>` this message is in\n\n            >>> account = OutlookAccount('')\n            >>> message = account.get_messages()[0]\n            >>> message.parent_folder\n            Inbox\n            >>> message.parent_folder.unread_count\n            19\n\n        Returns: :class:`Folder <pyOutlook.core.folder.Folder>`\n\n        \"\"\"\n        if self.__parent_folder is None:\n            self.__parent_folder = self.account.get_folder_by_id(self.__parent_folder_id)\n\n        return self.__parent_folder", "response": "Returns the parent folder of the current message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef api_representation(self, content_type):\n        payload = dict(Subject=self.subject, Body=dict(ContentType=content_type, Content=self.body))\n\n        if self.sender is not None:\n            payload.update(From=self.sender.api_representation())\n\n        # A list of strings can also be provided for convenience. If provided, convert them into Contacts\n        if any(isinstance(item, str) for item in self.to):\n            self.to = [Contact(email=email) for email in self.to]\n\n        # Turn each contact into the JSON needed for the Outlook API\n\n        recipients = [contact.api_representation() for contact in self.to]\n\n        payload.update(ToRecipients=recipients)\n\n        # Conduct the same process for CC and BCC if needed\n        if self.cc:\n            if any(isinstance(email, str) for email in self.cc):\n                self.cc = [Contact(email) for email in self.cc]\n\n            cc_recipients = [contact.api_representation() for contact in self.cc]\n            payload.update(CcRecipients=cc_recipients)\n\n        if self.bcc:\n            if any(isinstance(email, str) for email in self.bcc):\n                self.bcc = [Contact(email) for email in self.bcc]\n\n            bcc_recipients = [contact.api_representation() for contact in self.bcc]\n            payload.update(BccRecipients=bcc_recipients)\n\n        if self._attachments:\n            payload.update(Attachments=[attachment.api_representation() for attachment in self._attachments])\n\n        payload.update(Importance=str(self.importance))\n\n        return dict(Message=payload)", "response": "Returns the JSON representation of this message."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _make_api_call(self, http_type, endpoint, extra_headers = None, data=None):\n        # type: (str, str, dict, Any) -> None\n        \"\"\"\n        Internal method to handle making calls to the Outlook API and logging both the request and response\n        Args:\n            http_type: (str) 'post' or 'delete'\n            endpoint: (str) The endpoint the request will be made to\n            headers: A dict of headers to send to the requests module in addition to Authorization and Content-Type\n            data: The data to provide to the requests module\n\n        Raises:\n            MiscError: For errors that aren't a 401\n            AuthError: For 401 errors\n\n        \"\"\"\n\n        headers = {\"Authorization\": \"Bearer \" + self.account.access_token, \"Content-Type\": \"application/json\"}\n\n        if extra_headers is not None:\n            headers.update(extra_headers)\n\n        log.debug('Making Outlook API request for message (ID: {}) with Headers: {} Data: {}'\n                  .format(self.message_id, headers, data))\n\n        if http_type == 'post':\n            r = requests.post(endpoint, headers=headers, data=data)\n        elif http_type == 'delete':\n            r = requests.delete(endpoint, headers=headers)\n        elif http_type == 'patch':\n            r = requests.patch(endpoint, headers=headers, data=data)\n        else:\n            raise NotImplemented\n\n        check_response(r)", "response": "Internal method to handle making API calls to the Outlook API."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, content_type='HTML'):\n\n        payload = self.api_representation(content_type)\n\n        endpoint = 'https://outlook.office.com/api/v1.0/me/sendmail'\n        self._make_api_call('post', endpoint=endpoint, data=json.dumps(payload))", "response": "Sends the message to the recipients body and attachments of the Message and returns None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nforward the message to the specified recipients.", "response": "def forward(self, to_recipients, forward_comment=None):\n        # type: (Union[List[Contact], List[str]], str) -> None\n        \"\"\"Forward Message to recipients with an optional comment.\n\n        Args:\n            to_recipients: A list of :class:`Contacts <pyOutlook.core.contact.Contact>` to send the email to.\n            forward_comment: String comment to append to forwarded email.\n\n        Examples:\n            >>> john = Contact('john.doe@domain.com')\n            >>> betsy = Contact('betsy.donalds@domain.com')\n            >>> email = Message()\n            >>> email.forward([john, betsy])\n            >>> email.forward([john], 'Hey John')\n        \"\"\"\n        payload = dict()\n\n        if forward_comment is not None:\n            payload.update(Comment=forward_comment)\n\n        # A list of strings can also be provided for convenience. If provided, convert them into Contacts\n        if any(isinstance(recipient, str) for recipient in to_recipients):\n            to_recipients = [Contact(email=email) for email in to_recipients]\n\n        # Contact() will handle turning itself into the proper JSON format for the API\n        to_recipients = [contact.api_representation() for contact in to_recipients]\n\n        payload.update(ToRecipients=to_recipients)\n\n        endpoint = 'https://outlook.office.com/api/v2.0/me/messages/{}/forward'.format(self.message_id)\n\n        self._make_api_call('post', endpoint=endpoint, data=json.dumps(payload))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplying to the Message.", "response": "def reply(self, reply_comment):\n        \"\"\"Reply to the Message.\n\n        Notes:\n            HTML can be inserted in the string and will be interpreted properly by Outlook.\n\n        Args:\n            reply_comment: String message to send with email.\n\n        \"\"\"\n        payload = '{ \"Comment\": \"' + reply_comment + '\"}'\n        endpoint = 'https://outlook.office.com/api/v2.0/me/messages/' + self.message_id + '/reply'\n\n        self._make_api_call('post', endpoint, data=payload)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplies to everyone on the email including those on the CC line.", "response": "def reply_all(self, reply_comment):\n        \"\"\"Replies to everyone on the email, including those on the CC line.\n\n        With great power, comes great responsibility.\n\n        Args:\n            reply_comment: The string comment to send to everyone on the email.\n\n        \"\"\"\n        payload = '{ \"Comment\": \"' + reply_comment + '\"}'\n        endpoint = 'https://outlook.office.com/api/v2.0/me/messages/{}/replyall'.format(self.message_id)\n\n        self._make_api_call('post', endpoint, data=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_to(self, folder):\n        if isinstance(folder, Folder):\n            self.move_to(folder.id)\n        else:\n            self._move_to(folder)", "response": "Moves the email to the specified folder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attach(self, file_bytes, file_name):\n        try:\n            file_bytes = base64.b64encode(file_bytes)\n        except TypeError:\n            file_bytes = base64.b64encode(bytes(file_bytes, 'utf-8'))\n\n        self._attachments.append(\n            Attachment(get_valid_filename(file_name), file_bytes.decode('utf-8'))\n        )", "response": "Adds an attachment to the email."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform image from RGB with 0 0", "response": "def tricolor_white_bg(self, img):\n        \"\"\"transforms image from RGB with (0,0,0)\n        showing black to  RGB with 0,0,0 showing white\n\n        takes the Red intensity and sets\n        the new intensity to go\n        from (0, 0.5, 0.5) (for Red=0)  to (0, 0, 0) (for Red=1)\n        and so on for the Green and Blue maps.\n\n        Thus the image will be transformed from\n          old intensity                new intensity\n          (0.0, 0.0, 0.0) (black)   (1.0, 1.0, 1.0) (white)\n          (1.0, 1.0, 1.0) (white)   (0.0, 0.0, 0.0) (black)\n          (1.0, 0.0, 0.0) (red)     (1.0, 0.5, 0.5) (red)\n          (0.0, 1.0, 0.0) (green)   (0.5, 1.0, 0.5) (green)\n          (0.0, 0.0, 1.0) (blue)    (0.5, 0.5, 1.0) (blue)\n\n        \"\"\"\n        tmp = 0.5*(1.0 - (img - img.min())/(img.max() - img.min()))\n        out = tmp*0.0\n        out[:,:,0] = tmp[:,:,1] + tmp[:,:,2]\n        out[:,:,1] = tmp[:,:,0] + tmp[:,:,2]\n        out[:,:,2] = tmp[:,:,0] + tmp[:,:,1]\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rgb2cmy(self, img, whitebg=False):\n        tmp = img*1.0\n        if whitebg:\n            tmp = (1.0 - (img - img.min())/(img.max() - img.min()))\n        out = tmp*0.0\n        out[:,:,0] = (tmp[:,:,1] + tmp[:,:,2])/2.0\n        out[:,:,1] = (tmp[:,:,0] + tmp[:,:,2])/2.0\n        out[:,:,2] = (tmp[:,:,0] + tmp[:,:,1])/2.0\n        return out", "response": "transforms image from RGB to CMY"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck to see if the given filepath is a valid entry point for the current user", "response": "def plugin_valid(self, filepath):\n        \"\"\"\n        checks to see if plugin ends with one of the\n        approved extensions\n        \"\"\"\n        plugin_valid = False\n        for extension in self.extensions:\n            if filepath.endswith(\".{}\".format(extension)):\n                plugin_valid = True\n                break\n        return plugin_valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef api_representation(self):\n        return dict(EmailAddress=dict(Name=self.name, Address=self.email))", "response": "Returns the JSON representation required by Outlook s API for contacts"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the focused flag for this entry in the Inference Classification endpoint.", "response": "def set_focused(self, account, is_focused):\n        # type: (OutlookAccount, bool) -> bool\n        \"\"\" Emails from this contact will either always be put in the Focused inbox, or always put in Other, based on\n        the value of is_focused.\n\n        Args:\n            account (OutlookAccount): The :class:`OutlookAccount <pyOutlook.core.main.OutlookAccount>`\n                the override should be set for\n            is_focused (bool): Whether this contact should be set to Focused, or Other.\n\n        Returns:\n            True if the request was successful\n        \"\"\"\n        endpoint = 'https://outlook.office.com/api/v2.0/me/InferenceClassification/Overrides'\n\n        if is_focused:\n            classification = 'Focused'\n        else:\n            classification = 'Other'\n\n        data = dict(ClassifyAs=classification, SenderEmailAddress=dict(Address=self.email))\n\n        r = requests.post(endpoint, headers=account._headers, data=json.dumps(data))\n\n        # Will raise an error if necessary, otherwise returns True\n        result = check_response(r)\n\n        self.focused = is_focused\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef image2wxbitmap(img):\n    \"PIL image 2 wx bitmap\"\n    if is_wxPhoenix:\n        wximg = wx.Image(*img.size)\n    else:\n        wximg = wx.EmptyImage(*img.size)\n    wximg.SetData(img.tobytes())\n    return wximg.ConvertToBitmap()", "response": "PIL image 2 wx bitmap"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_contrast_levels(self, contrast_level=0):\n        for cmap_panel, img_panel in zip((self.cmap_panels[0], self.cmap_panels[1]),\n                                         (self.img1_panel, self.img2_panel)):\n            conf = img_panel.conf\n            img  = img_panel.conf.data\n            if contrast_level is None:\n                contrast_level = 0\n            conf.contrast_level = contrast_level\n            clevels = [contrast_level, 100.0-contrast_level]\n\n            jmin = imin = img.min()\n            jmax = imax = img.max()\n            cmap_panel.imin_val.SetValue('%.4g' % imin)\n            cmap_panel.imax_val.SetValue('%.4g' % imax)\n            jmin, jmax = np.percentile(img, clevels)\n\n            conf.int_lo[0]  = imin\n            conf.int_hi[0]  = imax\n            conf.cmap_lo[0] = xlo = (jmin-imin)*conf.cmap_range/(imax-imin)\n            conf.cmap_hi[0] = xhi = (jmax-imin)*conf.cmap_range/(imax-imin)\n\n            cmap_panel.cmap_hi.SetValue(xhi)\n            cmap_panel.cmap_lo.SetValue(xlo)\n            cmap_panel.islider_range.SetLabel('Shown: [ %.4g :  %.4g ]' % (jmin, jmax))\n            cmap_panel.redraw_cmap()\n            img_panel.redraw()", "response": "enhance contrast levels or use full data range according to value of self. panel. conf. contrast_level\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_valid_filename(s):\n    s = str(s).strip().replace(' ', '_')\n    return re.sub(r'(?u)[^-\\w.]', '', s)", "response": "Returns a string that can be used for a clean\n    filename."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_response(response):\n    status_code = response.status_code\n\n    if 100 < status_code < 299:\n        return True\n\n    elif status_code == 401 or status_code == 403:\n        message = get_response_data(response)\n        raise AuthError('Access Token Error, Received ' + str(status_code) +\n                        ' from Outlook REST Endpoint with the message: {}'.format(message))\n\n    elif status_code == 400:\n        message = get_response_data(response)\n        raise RequestError('The request made to the Outlook API was invalid. Received the following message: {}'.\n                           format(message))\n    else:\n        message = get_response_data(response)\n        raise APIError('Encountered an unknown error from the Outlook API: {}'.format(message))", "response": "Checks that a response is successful raising the appropriate Exceptions otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plugins(self, filter_function=None):\n        plugins = self.plugins\n        if filter_function is not None:\n            plugins = filter_function(plugins)\n        return plugins", "response": "Gets out the plugins from the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting instances out of the internal state using the specified filter function.", "response": "def get_instances(self, filter_function=IPlugin):\n        \"\"\"\n        Gets instances out of the internal state using\n        the default filter supplied in filter_function.\n        By default, it is the class IPlugin.\n\n        Can optionally pass in a list or tuple of classes\n        in for `filter_function` which will accomplish\n        the same goal.\n\n        lastly, a callable can be passed in, however\n        it is up to the user to determine if the\n        objects are instances or not.\n        \"\"\"\n        if isinstance(filter_function, (list, tuple)):\n            return self._get_instance(filter_function)\n        elif inspect.isclass(filter_function):\n            return self._get_instance(filter_function)\n        elif filter_function is None:\n            return self.plugins\n        else:\n            return filter_function(self.plugins)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters classes as plugins that are not subclassed from . classes may be a single object or an iterable.", "response": "def register_classes(self, classes):\n        \"\"\"\n        Register classes as plugins that are not subclassed from\n        IPlugin.\n        `classes` may be a single object or an iterable.\n        \"\"\"\n        classes = util.return_list(classes)\n        for klass in classes:\n            IPlugin.register(klass)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_class_instance(self, klass):\n        if (klass in self.blacklisted_plugins or not\n                self.instantiate_classes or\n                klass == IPlugin):\n            return\n        elif self.unique_instances and self._unique_class(klass):\n            self.plugins.append(klass())\n        elif not self.unique_instances:\n            self.plugins.append(klass())", "response": "handles class instances. If a class is blacklisted, returns.\n        If uniuqe_instances is True and the class is unique, instantiates\n        the class and adds the new object to plugins.\n\n        If not unique_instances, creates and adds new instance to plugin\n        state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_blacklisted_plugins(self, plugins):\n        plugins = util.return_list(plugins)\n        self.blacklisted_plugins.extend(plugins)", "response": "add blacklisted plugins. plugins may be a single object or iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets blacklisted plugins. `plugins` may be a single object or iterable.", "response": "def set_blacklisted_plugins(self, plugins):\n        \"\"\"\n        sets blacklisted plugins.\n        `plugins` may be a single object or iterable.\n        \"\"\"\n        plugins = util.return_list(plugins)\n        self.blacklisted_plugins = plugins"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_modules(self, filepaths):\n        # removes filepaths from processed if they are not in sys.modules\n        self._update_loaded_modules()\n        filepaths = util.return_set(filepaths)\n\n        modules = []\n        for filepath in filepaths:\n            filepath = self._clean_filepath(filepath)\n            # check to see if already processed and move onto next if so\n            if self._processed_filepath(filepath):\n                continue\n\n            module_name = util.get_module_name(filepath)\n            plugin_module_name = util.create_unique_module_name(module_name)\n\n            try:\n                module = load_source(plugin_module_name, filepath)\n            # Catch all exceptions b/c loader will return errors\n            # within the code itself, such as Syntax, NameErrors, etc.\n            except Exception:\n                exc_info = sys.exc_info()\n                self._log.error(msg=self._error_string.format(filepath),\n                                exc_info=exc_info)\n                continue\n\n            self.loaded_modules.add(module.__name__)\n            modules.append(module)\n            self.processed_filepaths[module.__name__] = filepath\n\n        return modules", "response": "Loads the modules from their filepaths."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collect_plugins(self, modules=None):\n        if modules is None:\n            modules = self.get_loaded_modules()\n        else:\n            modules = util.return_list(modules)\n\n        plugins = []\n        for module in modules:\n            module_plugins = [(item[1], item[0])\n                              for item\n                              in inspect.getmembers(module)\n                              if item[1] and item[0] != '__builtins__']\n            module_plugins, names = zip(*module_plugins)\n\n            module_plugins = self._filter_modules(module_plugins, names)\n            plugins.extend(module_plugins)\n        return plugins", "response": "Collects all the plugins from modules."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_module_plugin_filters(self, module_plugin_filters):\n        module_plugin_filters = util.return_list(module_plugin_filters)\n        self.module_plugin_filters = module_plugin_filters", "response": "Sets the internal module filters to module_plugin_filters"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd module_plugin_filters to the internal module filters list.", "response": "def add_module_plugin_filters(self, module_plugin_filters):\n        \"\"\"\n        Adds `module_plugin_filters` to the internal module filters.\n        May be a single object or an iterable.\n\n        Every module filters must be a callable and take in\n        a list of plugins and their associated names.\n        \"\"\"\n        module_plugin_filters = util.return_list(module_plugin_filters)\n        self.module_plugin_filters.extend(module_plugin_filters)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_modules(self, names):\n        loaded_modules = []\n        for name in names:\n            loaded_modules.append(sys.modules[name])\n        return loaded_modules", "response": "An internal method that gets the names from sys. modules and returns\n            as a list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd in modules to the loaded_modules list.", "response": "def add_to_loaded_modules(self, modules):\n        \"\"\"\n        Manually add in `modules` to be tracked by the module manager.\n\n        `modules` may be a single object or an iterable.\n        \"\"\"\n        modules = util.return_set(modules)\n        for module in modules:\n            if not isinstance(module, str):\n                module = module.__name__\n            self.loaded_modules.add(module)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the. py file from the filepath if it is a directory or not present.", "response": "def _clean_filepath(self, filepath):\n        \"\"\"\n        processes the filepath by checking if it is a directory or not\n        and adding `.py` if not present.\n        \"\"\"\n        if (os.path.isdir(filepath) and\n                os.path.isfile(os.path.join(filepath, '__init__.py'))):\n\n            filepath = os.path.join(filepath, '__init__.py')\n\n        if (not filepath.endswith('.py') and\n                os.path.isfile(filepath + '.py')):\n            filepath += '.py'\n        return filepath"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking to see if the filepath has already been processed", "response": "def _processed_filepath(self, filepath):\n        \"\"\"\n        checks to see if the filepath has already been processed\n        \"\"\"\n        processed = False\n        if filepath in self.processed_filepaths.values():\n            processed = True\n\n        return processed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _update_loaded_modules(self):\n        system_modules = sys.modules.keys()\n        for module in list(self.loaded_modules):\n            if module not in system_modules:\n                self.processed_filepaths.pop(module)\n                self.loaded_modules.remove(module)", "response": "Updates the loaded modules by checking if they are still in sys. modules and removing them from self. processed_filepaths."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nzooms out full data range", "response": "def unzoom_all(self, event=None):\n        \"\"\" zoom out full data range \"\"\"\n        if len(self.conf.zoom_lims) > 0:\n            self.conf.zoom_lims = [self.conf.zoom_lims[0]]\n        self.unzoom(event)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef unzoom(self, event=None, set_bounds=True):\n        lims = None\n        if len(self.conf.zoom_lims) > 1:\n            lims = self.conf.zoom_lims.pop()\n        ax = self.axes\n        # print 'base unzoom ', lims, set_bounds\n        if lims is None: # auto scale\n            self.conf.zoom_lims = [None]\n            xmin, xmax, ymin, ymax = self.data_range\n            ax.set_xlim((xmin, xmax), emit=True)\n            ax.set_ylim((ymin, ymax), emit=True)\n            if set_bounds:\n                ax.update_datalim(((xmin, ymin), (xmax, ymax)))\n                ax.set_xbound(ax.xaxis.get_major_locator(\n                    ).view_limits(xmin, xmax))\n                ax.set_ybound(ax.yaxis.get_major_locator(\n                    ).view_limits(ymin, ymax))\n        else:\n            self.set_viewlimits()\n\n        self.canvas.draw()", "response": "unzoom out 1 level or to full data range"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_right_axes(self):\n        \"create, if needed, and return right-hand y axes\"\n        if len(self.fig.get_axes()) < 2:\n            ax = self.axes.twinx()\n\n        return self.fig.get_axes()[1]", "response": "create if needed and return right - hand y axes"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving figure image to file", "response": "def save_figure(self, event=None, transparent=False, dpi=600):\n        \"\"\" save figure image to file\"\"\"\n        file_choices = \"PNG (*.png)|*.png|SVG (*.svg)|*.svg|PDF (*.pdf)|*.pdf\"\n        try:\n            ofile = self.conf.title.strip()\n        except:\n            ofile = 'Image'\n        if len(ofile) > 64:\n            ofile = ofile[:63].strip()\n        if len(ofile) < 1:\n            ofile = 'plot'\n\n        for c in ' :\";|/\\\\': # \"\n            ofile = ofile.replace(c, '_')\n\n        ofile = ofile + '.png'\n        orig_dir = os.path.abspath(os.curdir)\n        dlg = wx.FileDialog(self, message='Save Plot Figure as...',\n                            defaultDir = os.getcwd(),\n                            defaultFile=ofile,\n                            wildcard=file_choices,\n                            style=wx.FD_SAVE|wx.FD_CHANGE_DIR)\n\n        if dlg.ShowModal() == wx.ID_OK:\n            path = dlg.GetPath()\n            if hasattr(self, 'fig'):\n                self.fig.savefig(path, transparent=transparent, dpi=dpi)\n            else:\n                self.canvas.print_figure(path, transparent=transparent, dpi=dpi)\n            if (path.find(self.launch_dir) ==  0):\n                path = path[len(self.launch_dir)+1:]\n            self.write_message('Saved plot to %s' % path)\n        os.chdir(orig_dir)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nleaving button down: report x,y coords, start zooming mode", "response": "def onLeftDown(self, event=None):\n        \"\"\" left button down: report x,y coords, start zooming mode\"\"\"\n        if event is None:\n            return\n        self.cursor_mode_action('leftdown', event=event)\n        self.ForwardEvent(event=event.guiEvent)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinishing wx event forward it to other wx objects", "response": "def ForwardEvent(self, event=None):\n        \"\"\"finish wx event, forward it to other wx objects\"\"\"\n        if event is not None:\n            event.Skip()\n            if self.HasCapture():\n                try:\n                    self.ReleaseMouse()\n                except:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrights button down show pop - up", "response": "def onRightDown(self, event=None):\n        \"\"\" right button down: show pop-up\"\"\"\n        if event is None:\n            return\n        # note that the matplotlib event location have to be converted\n        if event.inaxes is not None and self.popup_menu is not None:\n            pos = event.guiEvent.GetPosition()\n            wx.CallAfter(self.PopupMenu, self.popup_menu, pos)\n        self.cursor_mode_action('rightdown', event=event)\n        self.ForwardEvent(event=event.guiEvent)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef onRightUp(self, event=None):\n        if event is None:\n            return\n        self.cursor_mode_action('rightup', event=event)\n        self.ForwardEvent(event=event.guiEvent)", "response": "right button up: put back to cursor mode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nformat the date x - data. primitive and probably needs need improvement following matplotlib s date methods. improvement", "response": "def __date_format(self, x):\n        \"\"\" formatter for date x-data. primitive, and probably needs\n        improvement, following matplotlib's date methods.\n        \"\"\"\n\n        if x < 1: x = 1\n\n        span = self.axes.xaxis.get_view_interval()\n        tmin = max(1.0, span[0])\n        tmax = max(2.0, span[1])\n        tmin = time.mktime(dates.num2date(tmin).timetuple())\n        tmax = time.mktime(dates.num2date(tmax).timetuple())\n        nhours = (tmax - tmin)/3600.0\n        fmt = \"%m/%d\"\n        if nhours < 0.1:\n            fmt = \"%H:%M\\n%Ssec\"\n        elif nhours < 4:\n            fmt = \"%m/%d\\n%H:%M\"\n        elif nhours < 24*8:\n            fmt = \"%m/%d\\n%H:%M\"\n        try:\n            return time.strftime(fmt, dates.num2date(x).timetuple())\n        except:\n            return \"?\""}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __format(self, x, type='x'):\n        fmt, v = '%1.5g','%1.5g'\n        if type == 'y':\n            ax = self.axes.yaxis\n        elif type == 'y2' and len(self.fig.get_axes()) > 1:\n            ax =  self.fig.get_axes()[1].yaxis\n        else:\n            ax = self.axes.xaxis\n\n        try:\n            dtick = 0.1 * ax.get_view_interval().span()\n        except:\n            dtick = 0.2\n        try:\n            ticks = ax.get_major_locator()()\n            dtick = abs(ticks[1] - ticks[0])\n        except:\n            pass\n        if dtick > 89999:\n            fmt, v = ('%.1e',  '%1.6g')\n        elif dtick > 1.99:\n            fmt, v = ('%1.0f', '%1.2f')\n        elif dtick > 0.099:\n            fmt, v = ('%1.1f', '%1.3f')\n        elif dtick > 0.0099:\n            fmt, v = ('%1.2f', '%1.4f')\n        elif dtick > 0.00099:\n            fmt, v = ('%1.3f', '%1.5f')\n        elif dtick > 0.000099:\n            fmt, v = ('%1.4f', '%1.6e')\n        elif dtick > 0.0000099:\n            fmt, v = ('%1.5f', '%1.6e')\n\n        s =  fmt % x\n        s.strip()\n        s = s.replace('+', '')\n        while s.find('e0')>0:\n            s = s.replace('e0','e')\n        while s.find('-0')>0:\n            s = s.replace('-0','-')\n        if type == 'y':\n            self._yfmt = v\n        if type == 'y2':\n            self._y2fmt = v\n        if type == 'x':\n            self._xfmt = v\n        return s", "response": "format the current value of the current color"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nhandle key events on canvas", "response": "def __onKeyEvent(self, event=None):\n        \"\"\" handles key events on canvas\n        \"\"\"\n        if event is None:\n            return\n        key = event.guiEvent.GetKeyCode()\n        if (key < wx.WXK_SPACE or  key > 255):\n            return\n        ckey = chr(key)\n        mod  = event.guiEvent.ControlDown()\n        if self.is_macosx:\n            mod = event.guiEvent.MetaDown()\n        if mod:\n            if ckey == 'C':\n                self.canvas.Copy_to_Clipboard(event)\n            elif ckey == 'S':\n                self.save_figure(event)\n            elif ckey == 'K':\n                self.configure(event)\n            elif ckey == 'Z':\n                self.unzoom(event)\n            elif ckey == 'P':\n                self.canvas.printer.Print(event)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zoom_motion(self, event=None):\n        try:\n            x, y  = event.x, event.y\n        except:\n            return\n        self.report_motion(event=event)\n        if self.zoom_ini is None:\n            return\n        ini_x, ini_y, ini_xd, ini_yd = self.zoom_ini\n        if event.xdata is not None:\n            self.x_lastmove = event.xdata\n        if event.ydata is not None:\n            self.y_lastmove = event.ydata\n        x0     = min(x, ini_x)\n        ymax   = max(y, ini_y)\n        width  = abs(x-ini_x)\n        height = abs(y-ini_y)\n        y0     = self.canvas.figure.bbox.height - ymax\n\n        zdc = wx.ClientDC(self.canvas)\n        zdc.SetLogicalFunction(wx.XOR)\n        zdc.SetBrush(wx.TRANSPARENT_BRUSH)\n        zdc.SetPen(wx.Pen('White', 2, wx.SOLID))\n        zdc.ResetBoundingBox()\n        if not is_wxPhoenix:\n            zdc.BeginDrawing()\n\n        # erase previous box\n        if self.rbbox is not None:\n            zdc.DrawRectangle(*self.rbbox)\n        self.rbbox = (x0, y0, width, height)\n        zdc.DrawRectangle(*self.rbbox)\n        if not is_wxPhoenix:\n            zdc.EndDrawing()", "response": "motion event handler for zoom mode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef zoom_leftdown(self, event=None):\n        self.x_lastmove, self.y_lastmove = None, None\n        self.zoom_ini = (event.x, event.y, event.xdata, event.ydata)\n        self.report_leftdown(event=event)", "response": "leftdown event handler for zoom mode"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lasso_leftdown(self, event=None):\n        try:\n            self.report_leftdown(event=event)\n        except:\n            return\n\n        if event.inaxes:\n            # set lasso color\n            color='goldenrod'\n            cmap = getattr(self.conf, 'cmap', None)\n            if isinstance(cmap, dict):\n                cmap = cmap['int']\n            try:\n                if cmap is not None:\n                    rgb = (int(i*255)^255 for i in cmap._lut[0][:3])\n                    color = '#%02x%02x%02x' % tuple(rgb)\n            except:\n                pass\n            self.lasso = Lasso(event.inaxes, (event.xdata, event.ydata),\n                               self.lassoHandler)\n            self.lasso.line.set_color(color)", "response": "leftdown event handler for lasso mode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rename(self, new_folder_name):\n        headers = self.headers\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id\n        payload = '{ \"DisplayName\": \"' + new_folder_name + '\"}'\n\n        r = requests.patch(endpoint, headers=headers, data=payload)\n\n        if check_response(r):\n            return_folder = r.json()\n            return self._json_to_folder(self.account, return_folder)", "response": "Renames the Folder to the provided name."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves all child Folders inside of this Folder.", "response": "def get_subfolders(self):\n        \"\"\"Retrieve all child Folders inside of this Folder.\n\n        Raises:\n            AuthError: Raised if Outlook returns a 401, generally caused by an invalid or expired access token.\n\n        Returns:\n            List[:class:`Folder <pyOutlook.core.folder.Folder>`]\n        \"\"\"\n        headers = self.headers\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id + '/childfolders'\n\n        r = requests.get(endpoint, headers=headers)\n\n        if check_response(r):\n            return self._json_to_folders(self.account, r.json())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete(self):\n        headers = self.headers\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id\n\n        r = requests.delete(endpoint, headers=headers)\n\n        check_response(r)", "response": "Deletes this Folder.\n\n        Raises:\n            AuthError: Raised if Outlook returns a 401, generally caused by an invalid or expired access token."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef move_into(self, destination_folder):\n        # type: (Folder) -> None\n        \"\"\"Move the Folder into a different folder.\n\n        This makes the Folder provided a child folder of the destination_folder.\n\n        Raises:\n            AuthError: Raised if Outlook returns a 401, generally caused by an invalid or expired access token.\n\n        Args:\n            destination_folder: A :class:`Folder <pyOutlook.core.folder.Folder>` that should become the parent\n\n        Returns:\n            A new :class:`Folder <pyOutlook.core.folder.Folder>` that is now\n            inside of the destination_folder.\n\n        \"\"\"\n        headers = self.headers\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id + '/move'\n        payload = '{ \"DestinationId\": \"' + destination_folder.id + '\"}'\n\n        r = requests.post(endpoint, headers=headers, data=payload)\n\n        if check_response(r):\n            return_folder = r.json()\n            return self._json_to_folder(self.account, return_folder)", "response": "Move the Folder into a different folder."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a child folder within the Folder it is called from and returns the new Folder object.", "response": "def create_child_folder(self, folder_name):\n        \"\"\"Creates a child folder within the Folder it is called from and returns the new Folder object.\n\n        Args:\n            folder_name: The name of the folder to create\n\n        Returns: :class:`Folder <pyOutlook.core.folder.Folder>`\n        \"\"\"\n        headers = self.headers\n        endpoint = 'https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id + '/childfolders'\n        payload = '{ \"DisplayName\": \"' + folder_name + '\"}'\n\n        r = requests.post(endpoint, headers=headers, data=payload)\n\n        if check_response(r):\n            return_folder = r.json()\n            return self._json_to_folder(self.account, return_folder)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef messages(self):\n        headers = self.headers\n        r = requests.get('https://outlook.office.com/api/v2.0/me/MailFolders/' + self.id + '/messages', headers=headers)\n        check_response(r)\n        return Message._json_to_messages(self.account, r.json())", "response": "Retrieves the messages in this Folder and \n        returning a list of : class : Messages <pyOutlook. core. message. Message >"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nformats a number with '%g - like format except that we assume that the number is a number of digits.", "response": "def gformat(val, length=11):\n    \"\"\"Format a number with '%g'-like format, except that\n\n        a) the length of the output string will be the requested length.\n        b) positive numbers will have a leading blank.\n        b) the precision will be as high as possible.\n        c) trailing zeros will not be trimmed.\n\n    The precision will typically be length-7.\n\n    Arguments\n    ---------\n    val       value to be formatted\n    length    length of output string\n\n    Returns\n    -------\n    string of specified length.\n\n    Notes\n    ------\n     Positive values will have leading blank.\n\n    \"\"\"\n    try:\n        expon = int(log10(abs(val)))\n    except (OverflowError, ValueError):\n        expon = 0\n    length = max(length, 7)\n    form = 'e'\n    prec = length - 7\n    if abs(expon) > 99:\n        prec -= 1\n    elif ((expon > 0 and expon < (prec+4)) or\n          (expon <= 0 and -expon < (prec-1))):\n        form = 'f'\n        prec += 4\n        if expon > 0:\n            prec -= expon\n    fmt = '{0: %i.%i%s}' % (length, prec, form)\n    return fmt.format(val)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef MenuItem(parent, menu, label='', longtext='', action=None, default=True,\n             **kws):\n    \"\"\"Add Item to a Menu, with action\n    m = Menu(parent, menu, label, longtext, action=None)\n    \"\"\"\n    item = menu.Append(-1, label, longtext, **kws)\n    kind = item.GetKind()\n    if kind == wx.ITEM_CHECK:\n        item.Check(default)\n    if callable(action):\n        parent.Bind(wx.EVT_MENU, action, item)\n    return item", "response": "Add a MenuItem to a Menu"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Setup(self, event=None):\n\n        if hasattr(self, 'printerData'):\n            data = wx.PageSetupDialogData()\n            data.SetPrintData(self.printerData)\n        else:\n            data = wx.PageSetupDialogData()\n        data.SetMarginTopLeft( (15, 15) )\n        data.SetMarginBottomRight( (15, 15) )\n\n        dlg = wx.PageSetupDialog(None, data)\n\n        if dlg.ShowModal() == wx.ID_OK:\n            data = dlg.GetPageSetupData()\n            tl = data.GetMarginTopLeft()\n            br = data.GetMarginBottomRight()\n        self.printerData = wx.PrintData(data.GetPrintData())\n        dlg.Destroy()", "response": "Setup figure for printing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Preview(self, title=None, event=None):\n        if title is None:\n            title = self.title\n        if self.canvas is None:\n            self.canvas = self.parent.canvas\n\n        po1  = PrintoutWx(self.parent.canvas, title=title,\n                          width=self.pwidth,   margin=self.pmargin)\n        po2  = PrintoutWx(self.parent.canvas, title=title,\n                          width=self.pwidth,   margin=self.pmargin)\n        self.preview = wx.PrintPreview(po1, po2, self.printerData)\n\n        if ((is_wxPhoenix and self.preview.IsOk()) or\n            (not is_wxPhoenix and self.preview.Ok())):\n            self.preview.SetZoom(85)\n            frameInst= self.parent\n            while not isinstance(frameInst, wx.Frame):\n                frameInst= frameInst.GetParent()\n            frame = wx.PreviewFrame(self.preview, frameInst, \"Preview\")\n            frame.Initialize()\n            frame.SetSize((850, 650))\n            frame.Centre(wx.BOTH)\n            frame.Show(True)", "response": "generate Print Preview with wx Print mechanism"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting figure using wx Print mechanism", "response": "def Print(self, title=None, event=None):\n        \"\"\" Print figure using wx Print mechanism\"\"\"\n        pdd = wx.PrintDialogData()\n        pdd.SetPrintData(self.printerData)\n        pdd.SetToPage(1)\n        printer  = wx.Printer(pdd)\n        if title is None:\n            title = self.title\n\n        printout = PrintoutWx(self.parent.canvas, title=title,\n                              width=self.pwidth, margin=self.pmargin)\n        print_ok = printer.Print(self.parent, printout, True)\n\n        if not print_ok and not printer.GetLastError() == wx.PRINTER_CANCELLED:\n            wx.MessageBox(\"\"\"There was a problem printing.\n            Perhaps your current printer is not set correctly?\"\"\",\n                          \"Printing\", wx.OK)\n        printout.Destroy()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_float(val):\n    out = None\n    if not val in (None, ''):\n        try:\n            out = float(val)\n        except ValueError:\n            return None\n        if numpy.isnan(out):\n            out = default\n    return out", "response": "helper function to set a floating value in a node s node list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __GetMark(self):\n        \" keep track of cursor position within text\"\n        try:\n            self.__mark = min(wx.TextCtrl.GetSelection(self)[0],\n                              len(wx.TextCtrl.GetValue(self).strip()))\n        except:\n            self.__mark = 0", "response": "keep track of cursor position within text"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting mark for later", "response": "def __SetMark(self, mark=None):\n        \"set mark for later\"\n        if mark is None:\n            mark = self.__mark\n        self.SetSelection(mark, mark)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnChar(self, event):\n        key   = event.GetKeyCode()\n        entry = wx.TextCtrl.GetValue(self).strip()\n        pos   = wx.TextCtrl.GetSelection(self)\n        # really, the order here is important:\n        # 1. return sends to ValidateEntry\n        if key == wx.WXK_RETURN:\n            if not self.is_valid:\n                wx.TextCtrl.SetValue(self, self.format % set_float(self.__bound_val))\n            else:\n                self.SetValue(entry)\n            return\n\n        # 2. other non-text characters are passed without change\n        if (key < wx.WXK_SPACE or key == wx.WXK_DELETE or key > 255):\n            event.Skip()\n            return\n\n        # 3. check for multiple '.' and out of place '-' signs and ignore these\n        #    note that chr(key) will now work due to return at #2\n\n        has_minus = '-' in entry\n        ckey = chr(key)\n        if ((ckey == '.' and (self.__prec == 0 or '.' in entry) ) or\n            (ckey == '-' and (has_minus or  pos[0] != 0)) or\n            (ckey != '-' and  has_minus and pos[0] == 0)):\n            return\n        # 4. allow digits, but not other characters\n        if chr(key) in self.__digits:\n            event.Skip()", "response": "event handler for character events"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks for validity of value", "response": "def __CheckValid(self, value):\n        \"check for validity of value\"\n        val = self.__val\n        self.is_valid = True\n        try:\n            val = set_float(value)\n            if self.__min is not None and (val < self.__min):\n                self.is_valid = False\n                val = self.__min\n            if self.__max is not None and (val > self.__max):\n                self.is_valid = False\n                val = self.__max\n        except:\n            self.is_valid = False\n        self.__bound_val = self.__val = val\n        fgcol, bgcol = self.fgcol_valid, self.bgcol_valid\n        if not self.is_valid:\n            fgcol, bgcol = self.fgcol_invalid, self.bgcol_invalid\n\n        self.SetForegroundColour(fgcol)\n        self.SetBackgroundColour(bgcol)\n        self.Refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef plot(self, xdata, ydata, side='left', title=None,\n             xlabel=None, ylabel=None, y2label=None,\n             use_dates=False, **kws):\n        \"\"\"\n        plot (that is, create a new plot: clear, then oplot)\n        \"\"\"\n        allaxes = self.fig.get_axes()\n        if len(allaxes) > 1:\n            for ax in allaxes[1:]:\n                if ax in self.data_range:\n                    self.data_range.pop(ax)\n                self.fig.delaxes(ax)\n\n        self.data_range = {}\n        self.conf.zoom_lims = []\n        self.conf.axes_traces = {}\n        self.clear()\n        axes = self.axes\n        if side == 'right':\n            axes = self.get_right_axes()\n        self.conf.ntrace  = 0\n        self.conf.yscale = 'linear'\n        self.conf.user_limits[axes] = [None, None, None, None]\n\n        if xlabel is not None:\n            self.set_xlabel(xlabel, delay_draw=True)\n        if ylabel is not None:\n            self.set_ylabel(ylabel, delay_draw=True)\n        if y2label is not None:\n            self.set_y2label(y2label, delay_draw=True)\n        if title is not None:\n            self.set_title(title, delay_draw=True)\n        if use_dates is not None:\n            self.use_dates  = use_dates\n        return self.oplot(xdata, ydata, side=side, **kws)", "response": "plot (that is, create a new plot: clear, then oplot)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef oplot(self, xdata, ydata, side='left', label=None,\n              xlabel=None, ylabel=None, y2label=None, title=None,\n              dy=None, ylog_scale=None, xlog_scale=None, grid=None,\n              xmin=None, xmax=None, ymin=None, ymax=None,\n              color=None, style=None, drawstyle=None,\n              linewidth=2, marker=None, markersize=None,\n              refresh=True, show_legend=None,\n              legend_loc='best', legend_on=True, delay_draw=False,\n              bgcolor=None, framecolor=None, gridcolor=None,\n              labelfontsize=None, legendfontsize=None,\n              fullbox=None, axes_style=None, zorder=None, viewpad=None, **kws):\n        \"\"\" basic plot method, overplotting any existing plot \"\"\"\n        self.cursor_mode = 'zoom'\n        conf = self.conf\n        conf.plot_type = 'lineplot'\n        axes = self.axes\n        if side == 'right':\n            axes = self.get_right_axes()\n        # set y scale to log/linear\n        if ylog_scale is not None:\n            conf.yscale = {False:'linear', True:'log'}[ylog_scale]\n\n        if xlog_scale is not None:\n            conf.xscale = {False:'linear', True:'log'}[xlog_scale]\n\n        axes.xaxis.set_major_formatter(FuncFormatter(self.xformatter))\n        if self.use_dates:\n            xdata = [datetime.fromtimestamp(i) for i in xdata]\n            xdata = dates.date2num(xdata)\n            # axes.xaxis.set_major_locator(dates.AutoDateLocator())\n\n        if linewidth is None:\n            linewidth = 2\n\n        if viewpad is not None:\n            conf.viewpad = viewpad\n\n        if xlabel is not None:\n            self.set_xlabel(xlabel, delay_draw=delay_draw)\n        if ylabel is not None:\n            self.set_ylabel(ylabel, delay_draw=delay_draw)\n        if y2label is not None:\n            self.set_y2label(y2label, delay_draw=delay_draw)\n        if title  is not None:\n            self.set_title(title, delay_draw=delay_draw)\n        if show_legend is not None:\n            conf.set_legend_location(legend_loc, legend_on)\n            conf.show_legend = show_legend\n\n        if grid is not None:\n            conf.show_grid = grid\n\n        # set data range for this trace\n        datarange = [min(xdata), max(xdata), min(ydata), max(ydata)]\n\n        if axes not in conf.user_limits:\n            conf.user_limits[axes] = [None, None, None, None]\n\n        if xmin is not None:\n            conf.user_limits[axes][0] = xmin\n        if xmax is not None:\n            conf.user_limits[axes][1] = xmax\n        if ymin is not None:\n            conf.user_limits[axes][2] = ymin\n        if ymax is not None:\n            conf.user_limits[axes][3] = ymax\n\n        if axes == self.axes:\n            axes.yaxis.set_major_formatter(FuncFormatter(self.yformatter))\n        else:\n            axes.yaxis.set_major_formatter(FuncFormatter(self.y2formatter))\n\n        n = conf.ntrace\n        if zorder is None:\n            zorder = 5*(n+1)\n        if axes not in conf.axes_traces:\n            conf.axes_traces[axes] = []\n        conf.axes_traces[axes].append(n)\n\n        if bgcolor is not None:\n            conf.bgcolor = bgcolor\n            axes.set_axis_bgcolor(bgcolor)\n        if framecolor is not None:\n            self.canvas.figure.set_facecolor(framecolor)\n\n        conf.set_trace_zorder(zorder, delay_draw=True)\n        if color:\n            conf.set_trace_color(color, delay_draw=True)\n        if style:\n            conf.set_trace_style(style, delay_draw=True)\n        if marker:\n            conf.set_trace_marker(marker, delay_draw=True)\n        if linewidth is not None:\n            conf.set_trace_linewidth(linewidth, delay_draw=True)\n        if markersize is not None:\n            conf.set_trace_markersize(markersize, delay_draw=True)\n        if drawstyle is not None:\n            conf.set_trace_drawstyle(drawstyle, delay_draw=True)\n        if gridcolor is not None:\n            conf.gridcolor = gridcolor\n        if dy is None:\n            _lines = axes.plot(xdata, ydata, drawstyle=drawstyle, zorder=zorder)\n        else:\n            _lines = axes.errorbar(xdata, ydata, yerr=dy, zorder=zorder)\n\n        if axes not in conf.data_save:\n            conf.data_save[axes] = []\n        conf.data_save[axes].append((xdata, ydata))\n\n        if conf.show_grid and axes == self.axes:\n            # I'm sure there's a better way...\n            for i in axes.get_xgridlines() + axes.get_ygridlines():\n                i.set_color(conf.gridcolor)\n                i.set_zorder(-100)\n            axes.grid(True)\n        else:\n            axes.grid(False)\n\n        if (self.conf.xscale == 'log' or self.conf.yscale == 'log'):\n            self.set_logscale(xscale=self.conf.xscale,\n                              yscale=self.conf.yscale,\n                              delay_draw=delay_draw)\n\n        if label is None:\n            label = 'trace %i' % (conf.ntrace+1)\n        conf.set_trace_label(label, delay_draw=True)\n        conf.set_trace_datarange(datarange)\n        needs_relabel = False\n        if labelfontsize is not None:\n            conf.labelfont.set_size(labelfontsize)\n            needs_relabel = True\n\n        if legendfontsize is not None:\n            conf.legendfont.set_size(legendfontsize)\n            needs_relabel = True\n\n        if n < len(conf.lines):\n            conf.lines[n] = _lines\n        else:\n            conf._init_trace(n, 'black', 'solid')\n            conf.lines.append(_lines)\n\n        # now set plot limits:\n        if not delay_draw:\n            self.set_viewlimits()\n        if refresh:\n            conf.refresh_trace(conf.ntrace)\n            needs_relabel = True\n\n        if conf.show_legend and not delay_draw:\n            conf.draw_legend()\n\n        if needs_relabel and not delay_draw:\n            conf.relabel()\n\n        # axes style ('box' or 'open')\n        conf.axes_style = 'box'\n        if fullbox is not None and not fullbox:\n            conf.axes_style = 'open'\n        if axes_style in ('open', 'box', 'bottom'):\n            conf.axes_style = axes_style\n        conf.set_axes_style(delay_draw=delay_draw)\n        if not delay_draw:\n            self.draw()\n            self.canvas.Refresh()\n        conf.ntrace = conf.ntrace + 1\n        return _lines", "response": "basic plot method overplotting any existing plot"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nplotting many traces at once taking a list of data and plotting them at once", "response": "def plot_many(self, datalist, side='left', title=None,\n                  xlabel=None, ylabel=None, **kws):\n        \"\"\"\n        plot many traces at once, taking a list of (x, y) pairs\n        \"\"\"\n        def unpack_tracedata(tdat, **kws):\n            if (isinstance(tdat, dict) and\n                'xdata' in tdat and 'ydata' in tdat):\n                xdata = tdat.pop('xdata')\n                ydata = tdat.pop('ydata')\n                out = kws\n                out.update(tdat)\n            elif isinstance(tdat, (list, tuple)):\n                out = kws\n                xdata = tdat[0]\n                ydata = tdat[1]\n            return (xdata, ydata, out)\n\n        opts = dict(side=side, title=title, xlabel=xlabel, ylabel=ylabel,\n                    delay_draw=True)\n        opts.update(kws)\n        x0, y0, opts = unpack_tracedata(datalist[0], **opts)\n\n        self.plot(x0, y0, **opts)\n\n        for dat in datalist[1:]:\n            x, y, opts = unpack_tracedata(dat, delay_draw=True)\n            self.oplot(x, y, **opts)\n\n        conf = self.conf\n        if conf.show_legend:\n            conf.draw_legend()\n        conf.relabel()\n        self.draw()\n        self.canvas.Refresh()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_text(self, text, x, y, side='left', size=None,\n                 rotation=None, ha='left', va='center',\n                 family=None, **kws):\n        \"\"\"add text at supplied x, y position\"\"\"\n        axes = self.axes\n        if side == 'right':\n            axes = self.get_right_axes()\n        dynamic_size = False\n        if size is None:\n            size = self.conf.legendfont.get_size()\n            dynamic_size = True\n        t = axes.text(x, y, text, ha=ha, va=va, size=size,\n                      rotation=rotation, family=family, **kws)\n        self.conf.added_texts.append((dynamic_size, t))\n        self.draw()", "response": "add text at supplied x y position"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd arrow supplied x y position", "response": "def add_arrow(self, x1, y1, x2, y2,  side='left',\n                  shape='full', color='black',\n                  width=0.01, head_width=0.03, overhang=0, **kws):\n        \"\"\"add arrow supplied x, y position\"\"\"\n        dx, dy = x2-x1, y2-y1\n\n        axes = self.axes\n        if side == 'right':\n            axes = self.get_right_axes()\n        axes.arrow(x1, y1, dx, dy, shape=shape,\n                   length_includes_head=True,\n                   fc=color, edgecolor=color,\n                   width=width, head_width=head_width,\n                   overhang=overhang, **kws)\n        self.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets user - defined limits and apply them", "response": "def set_xylims(self, limits, axes=None, side='left'):\n        \"set user-defined limits and apply them\"\n        if axes is None:\n            axes = self.axes\n            if side == 'right':\n                axes = self.get_right_axes()\n        self.conf.user_limits[axes] = limits\n        self.unzoom_all()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntoggles derivative of data", "response": "def toggle_deriv(self, evt=None, value=None):\n        \"toggle derivative of data\"\n        if value is None:\n            self.conf.data_deriv = not self.conf.data_deriv\n\n            expr = self.conf.data_expr or ''\n            if self.conf.data_deriv:\n                expr = \"deriv(%s)\" % expr\n            self.write_message(\"plotting %s\" % expr, panel=0)\n\n            self.conf.process_data()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset log or linear scale for x y axis", "response": "def set_logscale(self, event=None, xscale='linear', yscale='linear',\n                     delay_draw=False):\n        \"set log or linear scale for x, y axis\"\n        self.conf.set_logscale(xscale=xscale, yscale=yscale,\n                               delay_draw=delay_draw)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef BuildPanel(self):\n        self.fig   = Figure(self.figsize, dpi=self.dpi)\n        # 1 axes for now\n        self.gridspec = GridSpec(1,1)\n        kwargs = {'facecolor': self.conf.bgcolor}\n        if matplotlib.__version__ < \"2.0\":\n            kwargs = {'axisbg': self.conf.bgcolor}\n\n        self.axes  = self.fig.add_subplot(self.gridspec[0], **kwargs)\n\n        self.canvas = FigureCanvas(self, -1, self.fig)\n\n        self.printer.canvas = self.canvas\n        self.set_bg(self.conf.framecolor)\n        self.conf.canvas = self.canvas\n        self.canvas.SetCursor(wxCursor(wx.CURSOR_CROSS))\n        self.canvas.mpl_connect(\"pick_event\", self.__onPickEvent)\n\n        # overwrite ScalarFormatter from ticker.py here:\n        self.axes.xaxis.set_major_formatter(FuncFormatter(self.xformatter))\n        self.axes.yaxis.set_major_formatter(FuncFormatter(self.yformatter))\n\n        # This way of adding to sizer allows resizing\n        sizer = wx.BoxSizer(wx.VERTICAL)\n        sizer.Add(self.canvas, 2, wx.LEFT|wx.TOP|wx.BOTTOM|wx.EXPAND, 0)\n        self.SetAutoLayout(True)\n        self.autoset_margins()\n        self.SetSizer(sizer)\n        self.Fit()\n\n        canvas_draw = self.canvas.draw\n        def draw(*args, **kws):\n            self.autoset_margins()\n            canvas_draw(*args, **kws)\n        self.canvas.draw = draw\n        self.addCanvasEvents()", "response": "builds basic GUI panel and popup menu"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _updateCanvasDraw(self):\n        fn = self.canvas.draw\n        def draw2(*a,**k):\n            self._updateGridSpec()\n            return fn(*a,**k)\n        self.canvas.draw = draw2", "response": "Overload of the draw function that updates the axes position before each draw"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_default_margins(self):\n        trans = self.fig.transFigure.inverted().transform\n\n        # Static margins\n        l, t, r, b = self.axesmargins\n        (l, b), (r, t) = trans(((l, b), (r, t)))\n\n        # Extent\n        dl, dt, dr, db = 0, 0, 0, 0\n        for i, ax in enumerate(self.fig.get_axes()):\n            (x0, y0),(x1, y1) = ax.get_position().get_points()\n            try:\n                (ox0, oy0), (ox1, oy1) = ax.get_tightbbox(self.canvas.get_renderer()).get_points()\n                (ox0, oy0), (ox1, oy1) = trans(((ox0 ,oy0),(ox1 ,oy1)))\n                dl = min(0.2, max(dl, (x0 - ox0)))\n                dt = min(0.2, max(dt, (oy1 - y1)))\n                dr = min(0.2, max(dr, (ox1 - x1)))\n                db = min(0.2, max(db, (y0 - oy0)))\n            except:\n                pass\n\n        return (l + dl, t + dt, r + dr, b + db)", "response": "get default margins for all axes"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a single trace", "response": "def update_line(self, trace, xdata, ydata, side='left', draw=False,\n                    update_limits=True):\n        \"\"\" update a single trace, for faster redraw \"\"\"\n\n        x = self.conf.get_mpl_line(trace)\n        x.set_data(xdata, ydata)\n        datarange = [xdata.min(), xdata.max(), ydata.min(), ydata.max()]\n        self.conf.set_trace_datarange(datarange, trace=trace)\n        axes = self.axes\n        if side == 'right':\n            axes = self.get_right_axes()\n\n        if update_limits:\n            self.set_viewlimits()\n        if draw:\n            self.draw()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __onPickEvent(self, event=None):\n        legline = event.artist\n        trace = self.conf.legend_map.get(legline, None)\n        visible = True\n        if trace is not None and self.conf.hidewith_legend:\n            line, legline, legtext = trace\n            visible = not line.get_visible()\n            line.set_visible(visible)\n            if visible:\n                legline.set_zorder(10.00)\n                legline.set_alpha(1.00)\n                legtext.set_zorder(10.00)\n                legtext.set_alpha(1.00)\n            else:\n                legline.set_alpha(0.50)\n                legtext.set_alpha(0.50)", "response": "set the color of the pick event"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget userid by email", "response": "def get_userid_by_email(self, email):\n        ''' get userid by email '''\n        response, status_code = self.__pod__.Users.get_v2_user(\n            sessionToken=self.__session__,\n            email=email\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_id_by_user(self, username):\n        ''' get user id by username '''\n        response, status_code = self.__pod__.Users.get_v2_user(\n            sessionToken=self.__session__,\n            username=username\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "get user id by username"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_user_by_userid(self, userid):\n        ''' get user by user id '''\n        response, status_code = self.__pod__.Users.get_v2_user(\n            sessionToken=self.__session__,\n            uid=userid\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "get user by user id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking on presence of a user", "response": "def get_user_presence(self, userid):\n        ''' check on presence of a user '''\n        response, status_code = self.__pod__.Presence.get_v2_user_uid_presence(\n            sessionToken=self.__session__,\n            uid=userid\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_user_presence(self, userid, presence):\n        ''' set presence of user '''\n        response, status_code = self.__pod__.Presence.post_v2_user_uid_presence(\n            sessionToken=self.__session__,\n            uid=userid,\n            presence=presence\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "set presence of user"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a user to a stream", "response": "def search_user(self, search_str, search_filter, local):\n        ''' add a user to a stream '''\n        response, status_code = self.__pod__.Users.post_v1_user_search(\n            sessionToken=self.__session__,\n            searchRequest={'query': search_str,\n                           'filters': search_filter}\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef p12parse(self):\n        ''' parse p12 cert and get the cert / priv key for requests module '''\n        # open it, using password. Supply/read your own from stdin.\n        p12 = crypto.load_pkcs12(open(self.p12, 'rb').read(), self.pwd)\n        # grab the certs / keys\n        p12cert = p12.get_certificate()     # (signed) certificate object\n        p12private = p12.get_privatekey()      # private key.\n        # dump private key and cert\n        symphony_key = crypto.dump_privatekey(crypto.FILETYPE_PEM, p12private)\n        symphony_crt = crypto.dump_certificate(crypto.FILETYPE_PEM, p12cert)\n        # write tmpfiles\n        crtpath = self.write_tmpfile(symphony_crt)\n        keypath = self.write_tmpfile(symphony_key)\n        # return cert and privkey\n        return crtpath, keypath", "response": "parse p12 cert and get the cert and privkey for requests module"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    # Check python version\n    if sys.version_info < (3, 0, 0):\n        sys.stderr.write(\n            'You need python 3.0 or later to run this script!' + os.linesep\n        )\n        exit(1)\n    # Generate requires\n    if platform.system() == 'Windows':\n        requirements_file = 'windows.txt'\n    else:\n        requirements_file = 'base.txt'\n    requirements_file = os.path.join('requirements', requirements_file)\n    with open(requirements_file) as requirements_reader:\n        requires = requirements_reader.read().splitlines()\n    # Get package description\n    with open('README.rst') as readme_reader:\n        long_description = readme_reader.read()\n    # Describe installer\n    settings = {\n        'name': 'pyspectator',\n        'version': '1.2.1',\n        'author': 'Maxim Grischuk',\n        'author_email': 'uzumaxy@gmail.com',\n        'maintainer': 'Maxim Grischuk',\n        'maintainer_email': 'uzumaxy@gmail.com',\n        'packages': ['pyspectator'],\n        'url': 'https://github.com/it-geeks-club/pyspectator',\n        'download_url': 'https://github.com/it-geeks-club/pyspectator/releases',\n        'license': 'BSD',\n        'description': 'pyspectator is a Python cross-platform tool for '\n                       'monitoring OS resources.',\n        'long_description': long_description,\n        'install_requires': requires,\n        'keywords': [\n            'pyspectator', 'spectator',\n            'monitoring', 'tool',\n            'statistic', 'stats',\n            'computer', 'pc', 'server',\n            'mem', 'memory',\n            'network', 'net', 'io',\n            'processor', 'cpu',\n            'hdd', 'hard', 'disk', 'drive'\n        ],\n        'platforms': 'Platform Independent',\n        'package_data': {\n            'pyspectator': ['LICENSE', 'README.rst']\n        },\n        'scripts': ['console.py'],\n        'tests_require': ['pytest>=2.6.2'],\n        'cmdclass': {'test': PyTest},\n        'classifiers': [\n            'Development Status :: 5 - Production/Stable',\n            'Environment :: Console',\n            'Environment :: MacOS X',\n            'Environment :: Win32 (MS Windows)',\n            'Intended Audience :: Developers',\n            'Intended Audience :: Information Technology',\n            'Intended Audience :: System Administrators',\n            'License :: OSI Approved :: BSD License',\n            'Natural Language :: English',\n            'Operating System :: MacOS :: MacOS X',\n            'Operating System :: Microsoft :: Windows :: Windows 7',\n            'Operating System :: Microsoft :: Windows :: Windows NT/2000',\n            'Operating System :: Microsoft :: Windows :: Windows Server 2003',\n            'Operating System :: Microsoft :: Windows :: Windows Server 2008',\n            'Operating System :: Microsoft :: Windows :: Windows Vista',\n            'Operating System :: Microsoft :: Windows :: Windows XP',\n            'Operating System :: Microsoft',\n            'Operating System :: OS Independent',\n            'Operating System :: POSIX :: BSD :: FreeBSD',\n            'Operating System :: POSIX :: Linux',\n            'Operating System :: POSIX :: SunOS/Solaris',\n            'Operating System :: POSIX',\n            'Programming Language :: C',\n            'Programming Language :: Python :: 3',\n            'Programming Language :: Python :: 3.0',\n            'Programming Language :: Python :: 3.1',\n            'Programming Language :: Python :: 3.2',\n            'Programming Language :: Python :: 3.3',\n            'Programming Language :: Python :: 3.4',\n            'Programming Language :: Python :: 3.5',\n            'Programming Language :: Python :: Implementation :: CPython',\n            'Programming Language :: Python',\n            'Topic :: Software Development :: Libraries :: Python Modules',\n            'Topic :: Software Development :: Libraries',\n            'Topic :: System :: Benchmark',\n            'Topic :: System :: Hardware',\n            'Topic :: System :: Monitoring',\n            'Topic :: System :: Networking :: Monitoring',\n            'Topic :: System :: Networking',\n            'Topic :: System :: Systems Administration',\n            'Topic :: Utilities',\n        ],\n    }\n    setup(**settings)", "response": "Main function for the main function of the module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist features the pod supports", "response": "def list_features(self):\n        ''' list features the pod supports '''\n        response, status_code = self.__pod__.System.get_v1_admin_system_features_list(\n            sessionToken=self.__session__\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating features by user id", "response": "def user_feature_update(self, userid, payload):\n        ''' update features by user id '''\n        response, status_code = self.__pod__.User.post_v1_admin_user_uid_features_update(\n            sessionToken=self.__session__,\n            uid=userid,\n            payload=payload\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_user_avatar(self, userid):\n        ''' get avatar by user id '''\n        response, status_code = self.__pod__.User.get_v1_admin_user_uid_avatar(\n            sessionToken=self.__session,\n            uid=userid\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "get user avatar by user id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates avatar by userid", "response": "def user_avatar_update(self, userid, payload):\n        ''' updated avatar by userid '''\n        response, status_code = self.__pod__.User.post_v1_admin_user_uid_avatar_update(\n            sessionToken=self.__session,\n            uid=userid,\n            payload=payload\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef PKCS_GET_query(self, req_hook, req_args):\n        ''' Generic GET query method '''\n        # GET request methods only require sessionTokens\n        headers = {'content-type': 'application/json',\n                   'sessionToken': self.__session__}\n\n        # HTTP GET query method using requests module\n        try:\n            if req_args is None:\n                response = requests.get(self.__url__ + req_hook,\n                                        headers=headers,\n                                        cert=(self.__crt__, self.__key__),\n                                        verify=True)\n            else:\n                response = requests.get(self.__url__ + req_hook + str(req_args),\n                                        headers=headers,\n                                        cert=(self.__crt__, self.__key__),\n                                        verify=True)\n        except requests.exceptions.RequestException as err:\n            self.logger.error(err)\n            return '500', 'Internal Error in PKCS_RESTful.GET_query()'\n        # return the token\n        self.logger.debug('%s: %s' % (response.status_code, response.text))\n        return response.status_code, response.text", "response": "Generic GET query method"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PKCS_POST_query(self, req_hook, req_args):\n        ''' Generic POST query method '''\n        # HTTP POST queries require keyManagerTokens and sessionTokens\n        headers = {'Content-Type': 'application/json',\n                   'sessionToken': self.__session__,\n                   'keyManagerToken': self.__keymngr__}\n\n        # HTTP POST query to keymanager authenticate API\n        try:\n            if req_args is None:\n                response = requests.post(self.__url__ + req_hook,\n                                         headers=headers,\n                                         cert=(self.__crt__, self.__key__),\n                                         verify=True)\n            else:\n                response = requests.post(self.__url__ + req_hook,\n                                         headers=headers,\n                                         data=req_args,\n                                         cert=(self.__crt__, self.__key__),\n                                         verify=True)\n        except requests.exceptions.RequestException as err:\n            self.logger.error(err)\n            return '500', 'Internal Error in PKCS_RESTful.POST_query()'\n        # return the token\n        self.logger.debug('%s: %s' % (response.status_code, response.text))\n        return response.status_code, response.text", "response": "Generic POST query method"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ib_group_member_list(self, group_id):\n        ''' ib group member list '''\n        req_hook = 'pod/v1/admin/group/' + group_id + '/membership/list'\n        req_args = None\n        status_code, response = self.__rest__.GET_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "ib group member list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ib_group_policy_list(self):\n        ''' ib group policy list '''\n        req_hook = 'pod/v1/admin/policy/list'\n        req_args = None\n        status_code, response = self.__rest__.GET_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "ib group policy list"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GET_query(self, req_hook, req_args):\n        ''' Generic GET query method '''\n        # GET request methods only require sessionTokens\n        headers = {'content-type': 'application/json',\n                   'sessionToken': self.__session__}\n\n        # HTTP GET query method using requests module\n        try:\n            if req_args is None:\n                response = requests.get(self.__url__ + req_hook,\n                                        headers=headers,\n                                        verify=True)\n            else:\n                response = requests.get(self.__url__ + req_hook + str(req_args),\n                                        headers=headers,\n                                        verify=True)\n        except requests.exceptions.RequestException as err:\n            self.logger.error(err)\n            return '500', 'Internal Error in RESTful.GET_query()'\n        # return the token\n        return response.status_code, response.text", "response": "Generic GET query method"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef POST_query(self, req_hook, req_args):\n        ''' Generic POST query method '''\n        # HTTP POST queries require keyManagerTokens and sessionTokens\n        headers = {'Content-Type': 'application/json',\n                   'sessionToken': self.__session__,\n                   'keyManagerToken': self.__keymngr__}\n\n        # HTTP POST query to keymanager authenticate API\n        try:\n            if req_args is None:\n                response = requests.post(self.__url__ + req_hook,\n                                         headers=headers,\n                                         verify=True)\n            else:\n                response = requests.post(self.__url__ + req_hook,\n                                         headers=headers,\n                                         data=req_args,\n                                         verify=True)\n        except requests.exceptions.RequestException as err:\n            self.logger.error(err)\n            return '500', 'Internal Error in RESTful.POST_query()'\n        # return the token\n        return response.status_code, response.text", "response": "Generic POST query method"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to the Symphony instance.", "response": "def connect(self):\n        ''' instantiate objects / parse config file '''\n        # open config file for parsing\n        try:\n            settings = configparser.ConfigParser()\n            settings._interpolation = configparser.ExtendedInterpolation()\n        except Exception as err:\n            self.logger.error(\"Failed to instantiate config parser exception: %s\" % err)\n            raise\n        try:\n            settings.read(self.__config__)\n        except Exception as err:\n            self.logger.error(\"Failed to read config file exception: %s\" % err)\n            raise\n\n        # Connect to Symphony\n        symphony_p12 = settings.get('symphony', 'symphony_p12')\n        symphony_pwd = settings.get('symphony', 'symphony_pwd')\n        symphony_pod_uri = settings.get('symphony', 'symphony_pod_uri')\n        symphony_keymanager_uri = settings.get('symphony', 'symphony_keymanager_uri')\n        symphony_agent_uri = settings.get('symphony', 'symphony_agent_uri')\n        symphony_sessionauth_uri = settings.get('symphony', 'symphony_sessionauth_uri')\n        symphony_sid = settings.get('symphony', 'symphony_sid')\n        crypt = symphony.Crypt(symphony_p12, symphony_pwd)\n        symphony_crt, symphony_key = crypt.p12parse()\n\n        try:\n            # instantiate auth methods\n            auth = symphony.Auth(symphony_sessionauth_uri, symphony_keymanager_uri, symphony_crt, symphony_key)\n            # get session token\n            session_token = auth.get_session_token()\n            self.logger.info(\"AUTH ( session token ): %s\" % session_token)\n            # get keymanager token\n            keymngr_token = auth.get_keymanager_token()\n            self.logger.info(\"AUTH ( key manager token ): %s\" % keymngr_token)\n            # instantiate agent methods\n            agent = symphony.Agent(symphony_agent_uri, session_token, keymngr_token)\n            # instantiate pod methods\n            pod = symphony.Pod(symphony_pod_uri, session_token, keymngr_token)\n\n            self.logger.info(\"INSTANTIATION ( all objects successful)\")\n        except Exception as err:\n            self.logger.error(\"Failed to authenticate and initialize: %s\" % err)\n            raise\n        # return references and such\n        return agent, pod, symphony_sid"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_MML(self, mml):\n        ''' parse the MML structure '''\n        hashes_c = []\n        mentions_c = []\n        soup = BeautifulSoup(mml, \"lxml\")\n        hashes = soup.find_all('hash', {\"tag\": True})\n        for hashe in hashes:\n            hashes_c.append(hashe['tag'])\n        mentions = soup.find_all('mention', {\"uid\": True})\n        for mention in mentions:\n            mentions_c.append(mention['uid'])\n        msg_string = soup.messageml.text.strip()\n        self.logger.debug('%s : %s : %s' % (hashes_c, mentions_c, msg_string))\n        return hashes_c, mentions_c, msg_string", "response": "parse the MML structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing messages from a datafeed", "response": "def parse_msg(self, datafeed):\n        ''' parse messages '''\n        message_parsed = []\n        for message in datafeed:\n            mid = message['id']\n            streamId = message['streamId']\n            mstring = message['message']\n            fromuser = message['fromUserId']\n            timestamp = message['timestamp']\n            timestamp_c = date.fromtimestamp(int(timestamp) / 1000.0)\n            hashes, mentions, msg_string = self.parse_MML(mstring)\n            message_broke = {'messageId': mid,\n                             'streamId': streamId,\n                             'fromUser': fromuser,\n                             'timestamp': timestamp,\n                             'timestamp_c': timestamp_c,\n                             'hashes': hashes,\n                             'mentions': mentions,\n                             'messageStr': msg_string}\n            message_parsed.append(message_broke)\n        self.logger.debug(message_parsed)\n        return message_parsed"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a user to a stream", "response": "def member_add(self, stream_id, user_id):\n        ''' add a user to a stream '''\n        req_hook = 'pod/v1/room/' + str(stream_id) + '/membership/add'\n        req_args = '{ \"id\": %s }' % user_id\n        status_code, response = self.__rest__.POST_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_room(self, payload):\n        ''' create a stream in a non-inclusive manner '''\n        response, status_code = self.__pod__.Streams.post_v2_room_create(\n            # V2RoomAttributes\n            payload=payload\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "create a stream in a non - inclusive manner"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_room(self, stream_id, room_definition):\n        ''' update a room definition '''\n        req_hook = 'pod/v2/room/' + str(stream_id) + '/update'\n        req_args = json.dumps(room_definition)\n        status_code, response = self.__rest__.POST_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "update a room definition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting list of room members", "response": "def room_members(self, stream_id):\n        ''' get list of room members '''\n        req_hook = 'pod/v2/room/' + str(stream_id) + '/membership/list'\n        req_args = None\n        status_code, response = self.__rest__.GET_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef promote_owner(self, stream_id, user_id):\n        ''' promote user to owner in stream '''\n        req_hook = 'pod/v1/room/' + stream_id + '/membership/promoteOwner'\n        req_args = '{ \"id\": %s }' % user_id\n        status_code, response = self.__rest__.POST_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "promote user to owner in stream"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsearching rooms by name", "response": "def search_rooms(self, query, labels=None, active=True, creator=None, skip=0, limit=25):\n        ''' search rooms '''\n        req_hook = 'pod/v2/room/search?skip=' + str(skip) + '&limit=' + str(limit)\n        json_query = {\n                       \"query\": query,\n                       \"labels\": labels,\n                       \"active\": active,\n                       \"creator\": creator\n                     }\n        req_args = json.dumps(json_query)\n        status_code, response = self.__rest__.POST_query(req_hook, req_args)\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the decoded claims without verification of any kind.", "response": "def get_unverified_claims(token):\n    \"\"\"Returns the decoded claims without verification of any kind.\n\n    Args:\n        token (str): A signed JWT to decode the headers from.\n\n    Returns:\n        dict: The dict representation of the token claims.\n\n    Raises:\n        JWTError: If there is an exception decoding the token.\n    \"\"\"\n    try:\n        claims = jws.get_unverified_claims(token)\n    except:\n        raise JWTError('Error decoding token claims.')\n\n    try:\n        claims = json.loads(claims.decode('utf-8'))\n    except ValueError as e:\n        raise JWTError('Invalid claims string: %s' % e)\n\n    if not isinstance(claims, Mapping):\n        raise JWTError('Invalid claims string: must be a json object')\n\n    return claims"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating that the at_hash claim included in the claims matches the access_token returned by the OpenID Provider.", "response": "def _validate_at_hash(claims, access_token, algorithm):\n    \"\"\"\n    Validates that the 'at_hash' parameter included in the claims matches\n    with the access_token returned alongside the id token as part of\n    the authorization_code flow.\n\n    Args:\n        claims (dict): The claims dictionary to validate.\n        access_token (str): The access token returned by the OpenID Provider.\n        algorithm (str): The algorithm used to sign the JWT, as specified by\n            the token headers.\n    \"\"\"\n    if 'at_hash' not in claims and not access_token:\n        return\n    elif 'at_hash' in claims and not access_token:\n        msg = 'No access_token provided to compare against at_hash claim.'\n        raise JWTClaimsError(msg)\n    elif access_token and 'at_hash' not in claims:\n        msg = 'at_hash claim missing from token.'\n        raise JWTClaimsError(msg)\n\n    try:\n        expected_hash = calculate_at_hash(access_token,\n                                          ALGORITHMS.HASHES[algorithm])\n    except (TypeError, ValueError):\n        msg = 'Unable to calculate at_hash to verify against token claims.'\n        raise JWTClaimsError(msg)\n        \n    if claims['at_hash'] != expected_hash:\n        raise JWTClaimsError('at_hash claim does not match access_token.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read_datafeed(self, datafeed_id):\n        ''' get datafeed '''\n        response, status_code = self.__agent__.Datafeed.get_v4_datafeed_id_read(\n            sessionToken=self.__session__,\n            keyManagerToken=self.__keymngr__,\n            id=datafeed_id\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "get datafeed with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_message(self, threadid, msgFormat, message):\n        ''' send message to threadid/stream '''\n        # using deprecated v3 message create because of bug in codegen of v4 ( multipart/form-data )\n        response, status_code = self.__agent__.Messages.post_v3_stream_sid_message_create(\n            sessionToken=self.__session__,\n            keyManagerToken=self.__keymngr__,\n            sid=threadid,\n            message={\"format\": msgFormat,\n                     \"message\": message}\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response", "response": "send message to threadid"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting datafeed from a specific stream", "response": "def read_stream(self, stream_id, since_epoch):\n        ''' get datafeed '''\n        response, status_code = self.__agent__.Messages.get_v4_stream_sid_message(\n            sessionToken=self.__session__,\n            keyManagerToken=self.__keymngr__,\n            sid=stream_id,\n            since=since_epoch\n        ).result()\n        self.logger.debug('%s: %s' % (status_code, response))\n        return status_code, response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef blackbody_spectral_radiance(T, wavelength):\n    r'''Returns the spectral radiance, in units of W/m^2/sr/\u00b5m.\n\n    .. math::\n        I_{\\lambda,blackbody,e}(\\lambda,T)=\\frac{2hc_o^2}\n        {\\lambda^5[\\exp(hc_o/\\lambda k T)-1]}\n\n    Parameters\n    ----------\n    T : float\n        Temperature of the surface, [K]\n    wavelength : float\n        Length of the wave to be considered, [m]\n\n    Returns\n    -------\n    I : float\n        Spectral radiance [W/(m^2*sr*m)]\n\n    Notes\n    -----\n    Can be used to derive the Stefan-Boltzman law, or determine the maximum\n    radiant frequency for a given temperature.\n    \n    Examples\n    --------\n    Checked with Spectral-calc.com, at [2]_.\n\n    >>> blackbody_spectral_radiance(800., 4E-6)\n    1311692056.2430143\n    \n    Calculation of power from the sun (earth occupies 6.8E-5 steradian of the\n    sun):\n        \n    >>> from scipy.integrate import quad\n    >>> rad = lambda l: blackbody_spectral_radiance(5778., l)*6.8E-5\n    >>> quad(rad, 1E-10, 1E-4)[0]\n    1367.9808043781559\n\n    References\n    ----------\n    .. [1] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    .. [2] Spectral-calc.com. Blackbody Calculator, 2015.\n       http://www.spectralcalc.com/blackbody_calculator/blackbody.php\n    '''\n    try:\n        return 2.*h*c**2/wavelength**5/(exp(h*c/(wavelength*T*k)) - 1.)\n    except OverflowError:\n        return 0.0", "response": "r Returns the spectral radiance of a given temperature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grey_transmittance(extinction_coefficient, molar_density, length, base=e):\n    r'''Calculates the transmittance of a grey body, given the extinction\n    coefficient of the material, its molar density, and the path length of the \n    radiation.\n    \n    .. math::\n        \\tau = base^{(-\\epsilon \\cdot l\\cdot \\rho_m )}\n\n    Parameters\n    ----------\n    extinction_coefficient : float\n        The extinction coefficient of the material the radiation is passing at\n        the modeled frequency, [m^2/mol]\n    molar_density : float\n        The molar density of the material the radiation is passing through,\n        [mol/m^3]\n    length : float\n        The length of the body the radiation is transmitted through, [m]\n    base : float, optional\n        The exponent used in calculations; `e` is more theoretically sound but\n        10 is often used as a base by chemists, [-]\n\n    Returns\n    -------\n    transmittance : float\n        The fraction of spectral radiance which is transmitted through a grey \n        body (can be liquid, gas, or even solid ex. in the case of glasses) [-]\n\n    Notes\n    -----\n    For extinction coefficients, see the HITRAN database. They are temperature\n    and pressure dependent for each chemical and phase.\n\n    Examples\n    --------\n    Overall transmission loss through 1 cm of precipitable water equivalent\n    atmospheric water vapor at a frequency of 1.3 um [2]_:\n    \n    >>> grey_transmittance(3.8e-4, molar_density=55300, length=1e-2)\n    0.8104707721191062\n\n    References\n    ----------\n    .. [1] Modest, Michael F. Radiative Heat Transfer, Third Edition. 3rd\n       edition. New York: Academic Press, 2013.\n    .. [2] Eldridge, Ralph G. \"Water Vapor Absorption of Visible and Near \n       Infrared Radiation.\" Applied Optics 6, no. 4 (April 1, 1967): 709-13.\n       https://doi.org/10.1364/AO.6.000709.\n    '''\n    transmittance = molar_density*extinction_coefficient*length\n    return base**(-transmittance)", "response": "r Calculates the transmittance of a single Grey body."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solar_spectrum(model='SOLAR-ISS'):\n    r'''Returns the solar spectrum of the sun according to the specified model.\n    Only the 'SOLAR-ISS' model is supported.\n\n    Parameters\n    ----------\n    model : str, optional\n        The model to use; 'SOLAR-ISS' is the only model available, [-]\n\n    Returns\n    -------\n    wavelengths : ndarray\n        The wavelengths of the solar spectra, [m]\n    SSI : ndarray\n        The solar spectral irradiance of the sun, [W/(m^2*m)]\n    uncertainties : ndarray\n        The estimated absolute uncertainty of the measured spectral irradiance  \n        of the sun, [W/(m^2*m)]\n\n    Notes\n    -----\n    The power of the sun changes as the earth gets closer or further away.\n    \n    In [1]_, the UV and VIS data come from observations in 2008; the IR comes\n    from measurements made from 2010-2016. There is a further 28 W/m^2 for the\n    3 micrometer to 160 micrometer range, not included in this model. All data\n    was corrected to a standard distance of one astronomical unit from the Sun,\n    as is the resultant spectrum. \n    \n    The variation of the spectrum as a function of distance from the sun should\n    alter only the absolute magnitudes.\n    \n    [2]_ contains another dataset.\n    \n    Examples\n    --------\n    >>> wavelengths, SSI, uncertainties = solar_spectrum()\n    \n    Calculate the minimum and maximum values of the wavelengths (0.5 nm/3000nm)\n    and SSI:\n        \n    >>> min(wavelengths), max(wavelengths), min(SSI), max(SSI)\n    (5e-10, 2.9999000000000003e-06, 1330.0, 2256817820.0)\n    \n    Integration - calculate the solar constant, in untis of W/m^2 hitting\n    earth's atmosphere.\n    \n    >>> np.trapz(SSI, wavelengths)\n    1344.802978238\n\n    References\n    ----------\n    .. [1] Meftah, M., L. Dam\u00e9, D. Bols\u00e9e, A. Hauchecorne, N. Pereira, D. \n       Sluse, G. Cessateur, et al. \"SOLAR-ISS: A New Reference Spectrum Based \n       on SOLAR/SOLSPEC Observations.\" Astronomy & Astrophysics 611 (March 1, \n       2018): A1. https://doi.org/10.1051/0004-6361/201731316.\n    .. [2] Woods Thomas N., Chamberlin Phillip C., Harder Jerald W., Hock \n       Rachel A., Snow Martin, Eparvier Francis G., Fontenla Juan, McClintock\n       William E., and Richard Erik C. \"Solar Irradiance Reference Spectra \n       (SIRS) for the 2008 Whole Heliosphere Interval (WHI).\" Geophysical\n       Research Letters 36, no. 1 (January 1, 2009).\n       https://doi.org/10.1029/2008GL036373.\n    '''\n    if model == 'SOLAR-ISS':\n        pth = os.path.join(folder, 'solar_iss_2018_spectrum.dat')\n        data = np.loadtxt(pth)\n        wavelengths, SSI, uncertainties = data[:, 0], data[:, 1], data[:, 2]\n        \n        wavelengths = wavelengths*1E-9\n        SSI = SSI*1E9\n        \n        # Convert -1 uncertainties to nans\n        uncertainties[uncertainties == -1] = np.nan\n        \n        uncertainties = uncertainties*1E9\n    return wavelengths, SSI, uncertainties", "response": "r Returns the solar spectrum of the sun in the specified model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Rohsenow(rhol, rhog, mul, kl, Cpl, Hvap, sigma, Te=None, q=None, Csf=0.013,\n             n=1.7):\n    r'''Calculates heat transfer coefficient for a evaporator operating\n    in the nucleate boiling regime according to [2]_ as presented in [1]_.\n    \n    Either heat flux or excess temperature is required.\n\n    With `Te` specified:\n    \n    .. math::\n        h = {{\\mu }_{L}} \\Delta H_{vap} \\left[ \\frac{g( \\rho_L-\\rho_v)}\n        {\\sigma } \\right]^{0.5}\\left[\\frac{C_{p,L}\\Delta T_e^{2/3}}{C_{sf}\n        \\Delta H_{vap} Pr_L^n}\\right]^3\n    \n    With `q` specified:\n    \n    .. math::\n        h = \\left({{\\mu }_{L}} \\Delta H_{vap} \\left[ \\frac{g( \\rho_L-\\rho_v)}\n        {\\sigma } \\right]^{0.5}\\left[\\frac{C_{p,L}\\Delta T_e^{2/3}}{C_{sf}\n        \\Delta H_{vap} Pr_L^n}\\right]^3\\right)^{1/3}q^{2/3}\n\n    Parameters\n    ----------\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n    Csf : float\n        Rohsenow coefficient specific to fluid and metal [-]\n    n : float\n        Constant, 1 for water, 1.7 (default) for other fluids usually [-]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    No further work is required on this correlation. Multiple sources confirm\n    its form and rearrangement.\n\n    Examples\n    --------\n    h for water at atmospheric pressure on oxidized aluminum.\n\n    >>> Rohsenow(rhol=957.854, rhog=0.595593, mul=2.79E-4, kl=0.680, Cpl=4217,\n    ... Hvap=2.257E6, sigma=0.0589, Te=4.9, Csf=0.011, n=1.26)\n    3723.655267067467\n\n    References\n    ----------\n    .. [1] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [2] Rohsenow, Warren M. \"A Method of Correlating Heat Transfer Data for\n       Surface Boiling of Liquids.\" Technical Report. Cambridge, Mass.\u202f: M.I.T.\n       Division of Industrial Cooporation, 1951\n    '''\n    if Te:\n        return mul*Hvap*(g*(rhol-rhog)/sigma)**0.5*(Cpl*Te**(2/3.)/Csf/Hvap/(Cpl*mul/kl)**n)**3\n    elif q:\n        A = mul*Hvap*(g*(rhol-rhog)/sigma)**0.5*(Cpl/Csf/Hvap/(Cpl*mul/kl)**n)**3\n        return A**(1/3.)*q**(2/3.)\n    else:\n        raise Exception('Either q or Te is needed for this correlation')", "response": "r Calculates the Rohsenow heat transfer coefficient for a given liquid and gas."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef McNelly(rhol, rhog, kl, Cpl, Hvap, sigma, P, Te=None, q=None):\n    r'''Calculates heat transfer coefficient for a evaporator operating\n    in the nucleate boiling regime according to [2]_ as presented in [1]_.\n\n    Either heat flux or excess temperature is required.\n\n    With `Te` specified:\n    \n    .. math::\n        h = \\left(0.225\\left(\\frac{\\Delta T_e C_{p,l}}{H_{vap}}\\right)^{0.69}\n        \\left(\\frac{P k_L}{\\sigma}\\right)^{0.31}\n        \\left(\\frac{\\rho_L}{\\rho_V}-1\\right)^{0.33}\\right)^{1/0.31}\n\n    With `q` specified:\n    \n    .. math::\n        h = 0.225\\left(\\frac{q C_{p,l}}{H_{vap}}\\right)^{0.69} \\left(\\frac{P \n        k_L}{\\sigma}\\right)^{0.31}\\left(\\frac{\\rho_L}{\\rho_V}-1\\right)^{0.33}\n\n    Parameters\n    ----------\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    P : float\n        Saturation pressure of fluid, [Pa]\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n    \n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Further examples for this function are desired.\n\n    Examples\n    --------\n    Water boiling, with excess temperature of 4.3 K.\n\n    >>> McNelly(Te=4.3, P=101325, Cpl=4180., kl=0.688, sigma=0.0588,\n    ... Hvap=2.25E6, rhol=958., rhog=0.597)\n    533.8056972951352\n\n    References\n    ----------\n    .. [1] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [2] McNelly M. J.: \"A correlation of the rates of heat transfer to n\n       ucleate boiling liquids,\" J. Imp Coll. Chem Eng Soc 7:18, 1953.\n    '''\n    if Te:\n        return (0.225*(Te*Cpl/Hvap)**0.69*(P*kl/sigma)**0.31*(rhol/rhog-1.)**0.33\n            )**(1./0.31)\n    elif q:\n        return 0.225*(q*Cpl/Hvap)**0.69*(P*kl/sigma)**0.31*(rhol/rhog-1.)**0.33\n    else:\n        raise Exception('Either q or Te is needed for this correlation')", "response": "r Returns a new nucleate boiling regime with the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Montinsky(P, Pc, Te=None, q=None):\n    r'''Calculates heat transfer coefficient for a evaporator operating\n    in the nucleate boiling regime according to [2]_ as presented in [1]_.\n\n    Either heat flux or excess temperature is required.\n\n    With `Te` specified:\n    \n    .. math::\n        h = \\left(0.00417P_c^{0.69} \\Delta Te^{0.7}\\left[1.8(P/P_c)^{0.17} + \n        4(P/P_c)^{1.2} + 10(P/P_c)^{10}\\right]\\right)^{1/0.3}\n\n    With `q` specified:\n    \n    .. math::\n        h = 0.00417P_c^{0.69} q^{0.7}\\left[1.8(P/P_c)^{0.17} + 4(P/P_c)^{1.2} \n        + 10(P/P_c)^{10}\\right]\n\n    Parameters\n    ----------\n    P : float\n        Saturation pressure of fluid, [Pa]\n    Pc : float\n        Critical pressure of fluid, [Pa]\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Formulas has been found consistent in all cited sources. Examples have\n    been found in [1]_ and [3]_.\n\n    The equation for this function is sometimes given with a constant of 3.7E-5\n    instead of 0.00417 if critical pressure is not internally\n    converted to kPa. [3]_ lists a constant of 3.596E-5.\n\n    Examples\n    --------\n    Water boiling at 1 atm, with excess temperature of 4.3K from [1]_.\n\n    >>> Montinsky(P=101325, Pc=22048321, Te=4.3)\n    1185.0509770292663\n\n    References\n    ----------\n    .. [1] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [2] Mostinsky I. L.: \"Application of the rule of corresponding states\n       for the calculation of heat transfer and critical heat flux,\"\n       Teploenergetika 4:66, 1963 English Abstr. Br Chem Eng 8(8):586, 1963\n    .. [3] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [4] Serth, R. W., Process Heat Transfer: Principles,\n       Applications and Rules of Thumb. 2E. Amsterdam: Academic Press, 2014.\n    '''\n    if Te:\n        return (0.00417*(Pc/1000.)**0.69*Te**0.7*(1.8*(P/Pc)**0.17 + 4*(P/Pc)**1.2\n        +10*(P/Pc)**10))**(1/0.3)\n    elif q:\n        return (0.00417*(Pc/1000.)**0.69*q**0.7*(1.8*(P/Pc)**0.17 + 4*(P/Pc)**1.2\n        +10*(P/Pc)**10))\n    else:\n        raise Exception('Either q or Te is needed for this correlation')", "response": "r Montinsky is a simple function that calculates the heat transfer coefficient for a evaporator operating\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Stephan_Abdelsalam(rhol, rhog, mul, kl, Cpl, Hvap, sigma, Tsat, Te=None, \n                       q=None, kw=401, rhow=8.96, Cpw=384, angle=None, \n                       correlation='general'):\n    r'''Calculates heat transfer coefficient for a evaporator operating\n    in the nucleate boiling regime according to [2]_ as presented in [1]_.\n    Five variants are possible.\n\n    Either heat flux or excess temperature is required. The forms for `Te` are\n    not shown here, but are similar to those of the other functions.\n\n    .. math::\n        h = 0.23X_1^{0.674} X_2^{0.35} X_3^{0.371} X_5^{0.297} X_8^{-1.73} k_L/d_B\n\n        X1 = \\frac{q D_d}{K_L T_{sat}}\n\n        X2 = \\frac{\\alpha^2 \\rho_L}{\\sigma D_d}\n\n        X3 = \\frac{C_{p,L} T_{sat} D_d^2}{\\alpha^2}\n\n        X4 = \\frac{H_{vap} D_d^2}{\\alpha^2}\n\n        X5 = \\frac{\\rho_V}{\\rho_L}\n\n        X6 = \\frac{C_{p,l} \\mu_L}{k_L}\n\n        X7 = \\frac{\\rho_W C_{p,W} k_W}{\\rho_L C_{p,L} k_L}\n\n        X8 = \\frac{\\rho_L-\\rho_V}{\\rho_L}\n\n        D_b = 0.0146\\theta\\sqrt{\\frac{2\\sigma}{g(\\rho_L-\\rho_g)}}\n\n    Respectively, the following four correlations are for water, hydrocarbons,\n    cryogenic fluids, and refrigerants.\n\n    .. math::\n        h = 0.246\\times 10^7 X1^{0.673} X4^{-1.58} X3^{1.26}X8^{5.22}k_L/d_B\n\n        h = 0.0546 X5^{0.335} X1^{0.67} X8^{-4.33} X4^{0.248}k_L/d_B\n\n        h = 4.82 X1^{0.624} X7^{0.117} X3^{0.374} X4^{-0.329}X5^{0.257} k_L/d_B\n\n        h = 207 X1^{0.745} X5^{0.581} X6^{0.533} k_L/d_B\n\n    Parameters\n    ----------\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    Tsat : float\n        Saturation temperature at operating pressure [Pa]\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n    kw : float, optional\n        Thermal conductivity of wall (only for cryogenics) [W/m/K]\n    rhow : float, optional\n        Density of the wall (only for cryogenics) [kg/m^3]\n    Cpw : float, optional\n        Heat capacity of wall (only for cryogenics) [J/kg/K]\n    angle : float, optional\n        Contact angle of bubble with wall [degrees]\n    correlation : str, optional\n        Any of 'general', 'water', 'hydrocarbon', 'cryogenic', or 'refrigerant'\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    If cryogenic correlation is selected, metal properties are used. Default\n    values are the properties of copper at STP.\n\n    The angle is selected automatically if a correlation is selected; if angle\n    is provided anyway, the automatic selection is ignored. A IndexError\n    exception is raised if the correlation is not in the dictionary\n    _angles_Stephan_Abdelsalam.\n\n    Examples\n    --------\n    Example is from [3]_ and matches.\n\n    >>> Stephan_Abdelsalam(Te=16.2, Tsat=437.5, Cpl=2730., kl=0.086, mul=156E-6,\n    ... sigma=0.0082, Hvap=272E3, rhol=567, rhog=18.09, angle=35)\n    26722.441071108373\n\n    References\n    ----------\n    .. [1] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [2] Stephan, K., and M. Abdelsalam. \"Heat-Transfer Correlations for\n       Natural Convection Boiling.\" International Journal of Heat and Mass\n       Transfer 23, no. 1 (January 1980): 73-87.\n       doi:10.1016/0017-9310(80)90140-4.\n    .. [3] Serth, R. W., Process Heat Transfer: Principles,\n       Applications and Rules of Thumb. 2E. Amsterdam: Academic Press, 2014.\n    '''\n    if Te is None and q is None:\n        raise Exception('Either q or Te is needed for this correlation')\n    angle = _angles_Stephan_Abdelsalam[correlation]\n\n    db = 0.0146*angle*(2*sigma/g/(rhol-rhog))**0.5\n    diffusivity_L = kl/rhol/Cpl\n\n    if Te:\n        X1 = db/kl/Tsat*Te\n    else:\n        X1 = db/kl/Tsat*q\n    X2 = diffusivity_L**2*rhol/sigma/db\n    X3 = Hvap*db**2/diffusivity_L**2\n    X4 = Hvap*db**2/diffusivity_L**2\n    X5 = rhog/rhol\n    X6 = Cpl*mul/kl\n    X7 = rhow*Cpw*kw/(rhol*Cpl*kl)\n    X8 = (rhol-rhog)/rhol\n\n    if correlation == 'general':\n        if Te:\n            h = (0.23*X1**0.674*X2**0.35*X3**0.371*X5**0.297*X8**-1.73*kl/db)**(1/0.326)\n        else:\n            h = (0.23*X1**0.674*X2**0.35*X3**0.371*X5**0.297*X8**-1.73*kl/db)\n    elif correlation == 'water':\n        if Te:\n            h = (0.246E7*X1**0.673*X4**-1.58*X3**1.26*X8**5.22*kl/db)**(1/0.327)\n        else:\n            h = (0.246E7*X1**0.673*X4**-1.58*X3**1.26*X8**5.22*kl/db)\n    elif correlation == 'hydrocarbon':\n        if Te:\n            h = (0.0546*X5**0.335*X1**0.67*X8**-4.33*X4**0.248*kl/db)**(1/0.33)\n        else:\n            h = (0.0546*X5**0.335*X1**0.67*X8**-4.33*X4**0.248*kl/db)\n    elif correlation == 'cryogenic':\n        if Te:\n            h = (4.82*X1**0.624*X7**0.117*X3**0.374*X4**-0.329*X5**0.257*kl/db)**(1/0.376)\n        else:\n            h = (4.82*X1**0.624*X7**0.117*X3**0.374*X4**-0.329*X5**0.257*kl/db)\n    else:\n        if Te:\n            h = (207*X1**0.745*X5**0.581*X6**0.533*kl/db)**(1/0.255)\n        else:\n            h = (207*X1**0.745*X5**0.581*X6**0.533*kl/db)\n    return h", "response": "r'''Calculates heat transfer coefficient for a evaporator operating\n    in the nucleate boiling regime according to [2]_ as presented in [1]_.\n    Five variants are possible.\n\n    Either heat flux or excess temperature is required. The forms for `Te` are\n    not shown here, but are similar to those of the other functions.\n\n    .. math::\n        h = 0.23X_1^{0.674} X_2^{0.35} X_3^{0.371} X_5^{0.297} X_8^{-1.73} k_L/d_B\n\n        X1 = \\frac{q D_d}{K_L T_{sat}}\n\n        X2 = \\frac{\\alpha^2 \\rho_L}{\\sigma D_d}\n\n        X3 = \\frac{C_{p,L} T_{sat} D_d^2}{\\alpha^2}\n\n        X4 = \\frac{H_{vap} D_d^2}{\\alpha^2}\n\n        X5 = \\frac{\\rho_V}{\\rho_L}\n\n        X6 = \\frac{C_{p,l} \\mu_L}{k_L}\n\n        X7 = \\frac{\\rho_W C_{p,W} k_W}{\\rho_L C_{p,L} k_L}\n\n        X8 = \\frac{\\rho_L-\\rho_V}{\\rho_L}\n\n        D_b = 0.0146\\theta\\sqrt{\\frac{2\\sigma}{g(\\rho_L-\\rho_g)}}\n\n    Respectively, the following four correlations are for water, hydrocarbons,\n    cryogenic fluids, and refrigerants.\n\n    .. math::\n        h = 0.246\\times 10^7 X1^{0.673} X4^{-1.58} X3^{1.26}X8^{5.22}k_L/d_B\n\n        h = 0.0546 X5^{0.335} X1^{0.67} X8^{-4.33} X4^{0.248}k_L/d_B\n\n        h = 4.82 X1^{0.624} X7^{0.117} X3^{0.374} X4^{-0.329}X5^{0.257} k_L/d_B\n\n        h = 207 X1^{0.745} X5^{0.581} X6^{0.533} k_L/d_B\n\n    Parameters\n    ----------\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    Tsat : float\n        Saturation temperature at operating pressure [Pa]\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n    kw : float, optional\n        Thermal conductivity of wall (only for cryogenics) [W/m/K]\n    rhow : float, optional\n        Density of the wall (only for cryogenics) [kg/m^3]\n    Cpw : float, optional\n        Heat capacity of wall (only for cryogenics) [J/kg/K]\n    angle : float, optional\n        Contact angle of bubble with wall [degrees]\n    correlation : str, optional\n        Any of 'general', 'water', 'hydrocarbon', 'cryogenic', or 'refrigerant'\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    If cryogenic correlation is selected, metal properties are used. Default\n    values are the properties of copper at STP.\n\n    The angle is selected automatically if a correlation is selected; if angle\n    is provided anyway, the automatic selection is ignored. A IndexError\n    exception is raised if the correlation is not in the dictionary\n    _angles_Stephan_Abdelsalam.\n\n    Examples\n    --------\n    Example is from [3]_ and matches.\n\n    >>> Stephan_Abdelsalam(Te=16.2, Tsat=437.5, Cpl=2730., kl=0.086, mul=156E-6,\n    ... sigma=0.0082, Hvap=272E3, rhol=567, rhog=18.09, angle=35)\n    26722.441071108373\n\n    References\n    ----------\n    .. [1] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [2] Stephan, K., and M. Abdelsalam. \"Heat-Transfer Correlations for\n       Natural Convection Boiling.\" International Journal of Heat and Mass\n       Transfer 23, no. 1 (January 1980): 73-87.\n       doi:10.1016/0017-9310(80)90140-4.\n    .. [3] Serth, R. W., Process Heat Transfer: Principles,\n       Applications and Rules of Thumb. 2E. Amsterdam: Academic Press, 2014."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Gorenflo(P, Pc, q=None, Te=None, CASRN=None, h0=None, Ra=4E-7):\n    r'''Calculates heat transfer coefficient for a pool boiling according to \n    [1]_ and also presented in [2]_. Calculation is based on the corresponding\n    states law, with a single regression constant per fluid. P and Pc are \n    always required.\n    \n    Either `q` or `Te` may be specified. Either `CASRN` or `h0` may be \n    specified as well. If `CASRN` is specified and the fluid is not in the\n    list of those studied, an error is raises.\n\n    .. math::\n        \\frac{h}{h_0} = C_W F(p^*) \\left(\\frac{q}{q_0}\\right)^n\n        \n        C_W = \\left(\\frac{R_a}{R_{ao}}\\right)^{0.133}\n\n        q_0 = 20 \\;000 \\frac{\\text{W}}{\\text{m}^{2}}\n        \n        R_{ao} = 0.4 \\mu\\text{m}\n        \n    For fluids other than water:\n    \n    .. math::\n        n = 0.9 - 0.3 p^{*0.3}\n        \n        f(p^*) = 1.2p^{*0.27} + \\left(2.5 + \\frac{1}{1-p^*}\\right)p^*\n    \n    For water:\n    \n    .. math::\n        n = 0.9 - 0.3 p^{*0.15}\n        \n        f(p^*) = 1.73p^{*0.27} + \\left(6.1 + \\frac{0.68}{1-p^*}\\right)p^2\n\n    Parameters\n    ----------\n    P : float\n        Saturation pressure of fluid, [Pa]\n    Pc : float\n        Critical pressure of fluid, [Pa]\n    q : float, optional\n        Heat flux, [W/m^2]\n    Te : float, optional\n        Excess wall temperature, [K]\n    CASRN : str, optional\n        CASRN of fluid\n    h0 : float\n        Reference heat transfer coefficient, [W/m^2/K]\n    Ra : float, optional\n        Roughness parameter of the surface (0.4 micrometer default), [m]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    A more recent set of reference heat fluxes is available. Where a range of\n    values was listed for reference heat fluxes in [1]_, values from the\n    second edition of [1]_ were used instead. 44 values are available, all\n    listed in the dictionary `h0_Gorenflow_1993`. Values range from 2000\n    to 24000 W/m^2/K.\n\n    Examples\n    --------\n    Water boiling at 3 bar and a heat flux of 2E4 W/m^2/K.\n\n    >>> Gorenflo(3E5, 22048320., q=2E4, CASRN='7732-18-5')\n    3043.344595525422\n\n    References\n    ----------\n    .. [1] Schlunder, Ernst U, VDI. VDI Heat Atlas. Dusseldorf: V.D.I. Verlag, \n       1993. http://digital.ub.uni-paderborn.de/hs/download/pdf/41898?originalFilename=true\n    .. [2] Bertsch, Stefan S., Eckhard A. Groll, and Suresh V. Garimella. \n       \"Review and Comparative Analysis of Studies on Saturated Flow Boiling in\n       Small Channels.\" Nanoscale and Microscale Thermophysical Engineering 12,\n       no. 3 (September 4, 2008): 187-227. doi:10.1080/15567260802317357.\n    '''\n    Pr = P/Pc\n    Ra0 = 0.4E-6\n    q0 = 2E4\n    if CASRN not in h0_Gorenflow_1993 and h0 is None:\n        raise Exception('Reference heat transfer coefficient not known')\n    if not h0:\n        h0 = h0_Gorenflow_1993[CASRN]\n    if CASRN != '7732-18-5':\n        # Case for not dealing with water\n        n = 0.9 - 0.3*Pr**0.3\n        Fp = 1.2*Pr**0.27 + (2.5 + 1/(1-Pr))*Pr\n    else:\n        # Case for water\n        n = 0.9 - 0.3*Pr**0.15\n        Fp = 1.73*Pr**0.27 + (6.1 + 0.68/(1-Pr))*Pr**2\n    CW = (Ra/Ra0)**0.133\n    if q:\n        return h0*CW*Fp*(q/q0)**n\n    elif Te:\n        A = h0*CW*Fp*(Te/q0)**n\n        return A**(-1./(n - 1.))\n    else:\n        raise Exception('Either q or Te is needed for this correlation')", "response": "r Gorenflo is a simple formula for calculating the heat transfer coefficient for a pool of studied fluids."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef h_nucleic(Te=None, q=None, Tsat=None, P=None, dPsat=None, Cpl=None, \n              kl=None, mul=None, rhol=None, sigma=None, Hvap=None, rhog=None, \n              MW=None, Pc=None, CAS=None, Method=None, AvailableMethods=False, \n              **kwargs):\n    r'''This function handles the calculation of nucleate boiling\n    heat flux and chooses the best method for performing the calculation\n    based on the provided information.\n\n    One of `Te` and `q` are always required.\n\n    Parameters\n    ----------\n    Te : float, optional\n        Excess wall temperature, [K]\n    q : float, optional\n        Heat flux, [W/m^2]\n    Tsat : float, optional\n        Saturation temperature at operating pressure [Pa]\n    P : float, optional\n        Saturation pressure of fluid, [Pa]\n    dPsat : float, optional\n        Difference in saturation pressure of the fluid at Te and T, [Pa]\n    Cpl : float, optional\n        Heat capacity of liquid [J/kg/K]\n    kl : float, optional\n        Thermal conductivity of liquid [W/m/K]\n    mul : float, optional\n        Viscosity of liquid [Pa*s]\n    rhol : float, optional\n        Density of the liquid [kg/m^3]\n    sigma : float, optional\n        Surface tension of liquid [N/m]\n    Hvap : float, optional\n        Heat of vaporization of the fluid at P, [J/kg]\n    rhog : float, optional\n        Density of the produced gas [kg/m^3]\n    MW : float, optional\n        Molecular weight of fluid, [g/mol]\n    Pc : float, optional\n        Critical pressure of fluid, [Pa]\n    CAS : str, optional\n        CAS of fluid\n\n    Returns\n    -------\n    h : float\n        Nucleate boiling heat flux [W/m^2]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate `h` with the given inputs\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        The name of the method to use; one of ['Gorenflo (1993)', \n        'Stephan-Abdelsalam water', 'Stephan-Abdelsalam cryogenic', \n        'Stephan-Abdelsalam', 'HEDH-Taborek', 'Forster-Zuber', 'Rohsenow', \n        'Cooper', 'Bier', 'Montinsky', 'McNelly']\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate `h` with the given inputs\n        \n    Notes\n    -----\n    The methods Stephan-Abdelsalam, Cooper, and Gorenflo all take other \n    arguments as well such as surface roughness or the thermal properties of\n    the wall material. See them for their documentation. These parameters\n    can also be passed as keyword arguments.\n    \n    >>> h_nucleic(P=3E5, Pc=22048320., q=2E4, CAS='7732-18-5', Ra=1E-6)\n    3437.7726419934147\n    \n    Examples\n    --------\n    Water boiling at 3 bar and a heat flux of 2E4 W/m^2/K.\n\n    >>> h_nucleic(P=3E5, Pc=22048320., q=2E4, CAS='7732-18-5')\n    3043.344595525422\n    \n    Water, known excess temperature of 4.9 K, Rohsenow method\n\n    >>> h_nucleic(rhol=957.854, rhog=0.595593, mul=2.79E-4, kl=0.680, Cpl=4217,\n    ... Hvap=2.257E6, sigma=0.0589, Te=4.9, Csf=0.011, n=1.26, \n    ... Method='Rohsenow')\n    3723.655267067467\n    '''\n    def list_methods():\n        methods = []\n        if all((P, Pc)):\n            if CAS and CAS in h0_Gorenflow_1993:\n                methods.append('Gorenflo (1993)')\n        if all((Te, Tsat, Cpl, kl, mul, sigma, Hvap, rhol, rhog)):\n            if CAS and CAS == '7732-18-5':\n                methods.append('Stephan-Abdelsalam water')\n            if CAS and CAS in cryogenics:\n                methods.append('Stephan-Abdelsalam cryogenic')\n            methods.append('Stephan-Abdelsalam')\n        if all((Te, P, Pc)):\n            methods.append('HEDH-Taborek')\n        if all((Te, dPsat, Cpl, kl, mul, sigma, Hvap, rhol, rhog)):\n            methods.append('Forster-Zuber')\n        if all((Te, Cpl, kl, mul, sigma, Hvap, rhol, rhog)):\n            methods.append('Rohsenow')\n        if all((Te, P, Pc, MW)):\n            methods.append('Cooper')\n        if all((Te, P, Pc)):\n            methods.append('Bier')\n        if all((Te, P, Pc)):\n            methods.append('Montinsky')\n        if all((Te, P, Cpl, kl, sigma, Hvap, rhol, rhog)):\n            methods.append('McNelly')\n        return methods\n\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        methods = list_methods()\n        if methods == []:\n            raise Exception('Insufficient property data for any method.')\n        Method = methods[0]\n\n    if Method == 'Stephan-Abdelsalam':\n        return Stephan_Abdelsalam(Te=Te, q=q, Tsat=Tsat, Cpl=Cpl, kl=kl, mul=mul,\n                               sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog,\n                               correlation='general', **kwargs)\n    elif Method == 'Stephan-Abdelsalam water':\n        return Stephan_Abdelsalam(Te=Te, q=q, Tsat=Tsat, Cpl=Cpl, kl=kl, mul=mul,\n                               sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog,\n                               correlation='water', **kwargs)\n    elif Method == 'Stephan-Abdelsalam cryogenic':\n        return Stephan_Abdelsalam(Te=Te, q=q, Tsat=Tsat, Cpl=Cpl, kl=kl, mul=mul,\n                               sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog,\n                               correlation='cryogenic', **kwargs)\n    elif Method == 'HEDH-Taborek':\n        return HEDH_Taborek(Te=Te, q=q, P=P, Pc=Pc)\n    elif Method == 'Forster-Zuber':\n        return Forster_Zuber(Te=Te, q=q, dPsat=dPsat, Cpl=Cpl, kl=kl, mul=mul,\n                          sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog, **kwargs)\n    elif Method == 'Rohsenow':\n        return Rohsenow(Te=Te, q=q, Cpl=Cpl, kl=kl, mul=mul, sigma=sigma, Hvap=Hvap,\n                     rhol=rhol, rhog=rhog, **kwargs)\n    elif Method == 'Cooper':\n        return Cooper(Te=Te, q=q, P=P, Pc=Pc, MW=MW, **kwargs)\n    elif Method == 'Bier':\n        return Bier(Te=Te, q=q, P=P, Pc=Pc, **kwargs)\n    elif Method == 'Montinsky':\n        return Montinsky(Te=Te, q=q, P=P, Pc=Pc, **kwargs)\n    elif Method == 'McNelly':\n        return McNelly(Te=Te, q=q, P=P, Cpl=Cpl, kl=kl, sigma=sigma, Hvap=Hvap,\n                    rhol=rhol, rhog=rhog, **kwargs)\n    elif Method == 'Gorenflo (1993)':\n        return Gorenflo(P=P, q=q, Pc=Pc, Te=Te, CASRN=CAS, **kwargs)\n    else:\n        raise Exception(\"Correlation name not recognized; see the \"\n                        \"documentation for the available options.\")", "response": "r This function handles the calculation of nucleate boiling heat flux based on the provided information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Zuber(sigma, Hvap, rhol, rhog, K=0.18):\n    r'''Calculates critical heat flux for nucleic boiling of a flat plate\n    or other shape as presented in various sources.\n    K = pi/24 is believed to be the original [1]_ value for K, but 0.149 is\n    now more widely used, a value claimed to be from [2]_ according to [5]_.\n    Cao [4]_ lists a value of 0.18 for K. The Wolverine Tube data book also\n    lists a value of 0.18, and so it is the default.\n\n    .. math::\n        q_c = 0.149H_{vap} \\rho_g^{0.5}\\left[\\sigma g (\\rho_L-\\rho_g)\\right]^{0.25}\n\n    Parameters\n    ----------\n    sigma : float\n        Surface tension of liquid [N/m]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n    K : float\n        Constant []\n\n    Returns\n    -------\n    q: float\n        Critical heat flux [W/m^2]\n\n    Notes\n    -----\n    No further work is required on this correlation. Multiple sources confirm\n    its form.\n\n    Examples\n    --------\n    Example from [3]_\n\n    >>> Zuber(sigma=8.2E-3, Hvap=272E3, rhol=567, rhog=18.09, K=0.149)\n    444307.22304342285\n    >>> Zuber(sigma=8.2E-3, Hvap=272E3, rhol=567, rhog=18.09, K=0.18)\n    536746.9808578263\n\n    References\n    ----------\n    .. [1] Zuber N. \"On the stability of boiling heat transfer\". Trans ASME 1958\n        80:711-20.\n    .. [2] Lienhard, J.H., and Dhir, V.K., 1973, Extended Hydrodynamic Theory\n       of the Peak and Minimum Heat Fluxes, NASA CR-2270.\n    .. [3] Serth, R. W., Process Heat Transfer: Principles,\n       Applications and Rules of Thumb. 2E. Amsterdam: Academic Press, 2014.\n    .. [4] Cao, Eduardo. Heat Transfer in Process Engineering.\n       McGraw Hill Professional, 2009.\n    .. [5] Kreith, Frank, Raj Manglik, and Mark Bohn. Principles of Heat\n       Transfer, 7E.Mason, OH: Cengage Learning, 2010.\n    '''\n    return K*Hvap*rhog**0.5*(g*sigma*(rhol-rhog))**0.25", "response": "r Zuber function for the base class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Serth_HEDH(D, sigma, Hvap, rhol, rhog):\n    r'''Calculates critical heat flux for nucleic boiling of a tube bundle\n    according to [2]_, citing [3]_, and using [1]_ as the original form.\n\n    .. math::\n        q_c = KH_{vap} \\rho_g^{0.5}\\left[\\sigma g (\\rho_L-\\rho_g)\\right]^{0.25}\n\n        K = 0.123 (R^*)^{-0.25} \\text{ for 0.12 < R* < 1.17}\n\n        K = 0.118\n\n        R^* = \\frac{D}{2} \\left[\\frac{g(\\rho_L-\\rho_G)}{\\sigma}\\right]^{0.5}\n\n    Parameters\n    ----------\n    D : float\n        Diameter of tubes [m]\n    sigma : float\n        Surface tension of liquid [N/m]\n    Hvap : float\n        Heat of vaporization of the fluid at T, [J/kg]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the produced gas [kg/m^3]\n\n    Returns\n    -------\n    q: float\n        Critical heat flux [W/m^2]\n\n    Notes\n    -----\n    A further source for this would be nice.\n\n    Examples\n    --------\n    >>> Serth_HEDH(D=0.0127, sigma=8.2E-3, Hvap=272E3, rhol=567, rhog=18.09)\n    351867.46522901946\n\n    References\n    ----------\n    .. [1] Zuber N. \"On the stability of boiling heat transfer\". Trans ASME\n       1958 80:711-20.\n    .. [2] Serth, R. W., Process Heat Transfer: Principles,\n       Applications and Rules of Thumb. 2E. Amsterdam: Academic Press, 2014.\n    .. [3] Schl\u00fcnder, Ernst U, and International Center for Heat and Mass\n       Transfer. Heat Exchanger Design Handbook. Washington:\n       Hemisphere Pub. Corp., 1987.\n    '''\n    R = D/2*(g*(rhol-rhog)/sigma)**0.5\n    if 0.12 <= R  <= 1.17:\n        K = 0.125*R**-0.25\n    else:\n        K = 0.118\n    return K*Hvap*rhog**0.5*(g*sigma*(rhol-rhog))**0.25", "response": "r Serth_HEDH returns a sequence of critical heat flux for a single liquid bundle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef qmax_boiling(rhol=None, rhog=None, sigma=None, Hvap=None, D=None, P=None, \n                 Pc=None, Method=None, AvailableMethods=False):\n    r'''This function handles the calculation of nucleate boiling critical\n    heat flux and chooses the best method for performing the calculation.\n    \n    Preferred methods are 'Serth-HEDH' when a tube diameter is specified,\n    and 'Zuber' otherwise.\n\n    Parameters\n    ----------\n    rhol : float, optional\n        Density of the liquid [kg/m^3]\n    rhog : float, optional\n        Density of the produced gas [kg/m^3]\n    sigma : float, optional\n        Surface tension of liquid [N/m]\n    Hvap : float, optional\n        Heat of vaporization of the fluid at T, [J/kg]\n    D : float, optional\n        Diameter of tubes [m]\n    P : float, optional\n        Saturation pressure of fluid, [Pa]\n    Pc : float, optional\n        Critical pressure of fluid, [Pa]\n\n    Returns\n    -------\n    q : float\n        Nucleate boiling critical heat flux [W/m^2]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate qmax with the given inputs\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        A string of the function name to use; one of ('Serth-HEDH', 'Zuber', \n        or 'HEDH-Montinsky')\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate `qmax` with the given inputs\n        \n    Examples\n    --------\n    >>> qmax_boiling(D=0.0127, sigma=8.2E-3, Hvap=272E3, rhol=567, rhog=18.09)\n    351867.46522901946\n    '''\n    def list_methods():\n        methods = []\n        if all((sigma, Hvap, rhol, rhog, D)):\n            methods.append('Serth-HEDH')\n        if all((sigma, Hvap, rhol, rhog)):\n            methods.append('Zuber')\n        if all((P, Pc)):\n            methods.append('HEDH-Montinsky')\n        return methods\n\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        methods = list_methods()\n        if methods == []:\n            raise Exception('Insufficient property or geometry data for any '\n                            'method.')\n        Method = methods[0]\n\n    if Method == 'Serth-HEDH':\n        return Serth_HEDH(D=D, sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog)\n    elif Method == 'Zuber':\n        return Zuber(sigma=sigma, Hvap=Hvap, rhol=rhol, rhog=rhog)\n    elif Method == 'HEDH-Montinsky':\n        return HEDH_Montinsky(P=P, Pc=Pc)\n    else:\n        raise Exception(\"Correlation name not recognized; options are \"\n                        \"'Serth-HEDH', 'Zuber' and 'HEDH-Montinsky'\")", "response": "r This function calculates the maximum of the nucleate boiling critical heat flux of a given liquid and mass."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Nu_vertical_plate_Churchill(Pr, Gr):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    plate according to the Churchill-Chu [1]_ correlation, also presented in\n    [2]_. Plate must be isothermal; an alternate expression exists for constant\n    heat flux.\n\n    .. math::\n        Nu_{L}=\\left[0.825+\\frac{0.387Ra_{L}^{1/6}}\n        {[1+(0.492/Pr)^{9/16}]^{8/27}}\\right]^2\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Although transition from laminar to turbulent is discrete in reality, this\n    equation provides a smooth transition in value from laminar to turbulent.\n    Checked with the original source.\n\n    Can be applied to vertical cylinders as well, subject to the criteria below:\n\n    .. math::\n        \\frac{D}{L}\\ge \\frac{35}{Gr_L^{1/4}}\n\n    Examples\n    --------\n    From [2]_, Example 9.2, matches:\n\n    >>> Nu_vertical_plate_Churchill(0.69, 2.63E9)\n    147.16185223770603\n\n    References\n    ----------\n    .. [1] Churchill, Stuart W., and Humbert H. S. Chu. \"Correlating Equations\n       for Laminar and Turbulent Free Convection from a Vertical Plate.\"\n       International Journal of Heat and Mass Transfer 18, no. 11\n       (November 1, 1975): 1323-29. doi:10.1016/0017-9310(75)90243-4.\n    .. [2] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    Ra = Pr * Gr\n    Nu = (0.825 + (0.387*Ra**(1/6.)/(1 + (0.492/Pr)**(9/16.))**(8/27.)))**2\n    return Nu", "response": "r Returns a string that represents the natural convection around a vertical cylinder with the given correlation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Nu_vertical_cylinder_Griffiths_Davis_Morgan(Pr, Gr, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to the results of [1]_ correlated by [2]_, as\n    presented in [3]_ and [4]_.\n\n    .. math::\n        Nu_H = 0.67 Ra_H^{0.25},\\; 10^{7} < Ra < 10^{9}\n\n        Nu_H = 0.0782 Ra_H^{0.357}, \\; 10^{9} < Ra < 10^{11}\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Cylinder of diameter 17.43 cm, length from 4.65 to 263.5 cm. Air as fluid.\n    Transition between ranges is not smooth.\n    If outside of range, no warning is given.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Griffiths_Davis_Morgan(.7, 2E10)\n    327.6230596100138\n\n    References\n    ----------\n    .. [1] Griffiths, Ezer, A. H. Davis, and Great Britain. The Transmission of\n       Heat by Radiation and Convection. London: H. M. Stationery off., 1922.\n    .. [2] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [3] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [4] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if turbulent or (Ra > 1E9 and turbulent is None):\n        Nu = 0.0782*Ra**0.357\n    else:\n        Nu = 0.67*Ra**0.25\n    return Nu", "response": "r Returns the number of natural convection around a vertical cylinder."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Nu_vertical_cylinder_Jakob_Linke_Morgan(Pr, Gr, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to the results of [1]_ correlated by [2]_, as\n    presented in [3]_ and [4]_.\n\n    .. math::\n        Nu_H = 0.555 Ra_H^{0.25},\\; 10^{4} < Ra < 10^{8}\n\n        Nu_H = 0.129 Ra_H^{1/3},\\; 10^{8} < Ra < 10^{12}\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Cylinder of diameter 3.5 cm, length from L/D = 4.3. Air as fluid.\n    Transition between ranges is not smooth.\n    If outside of range, no warning is given. Results are presented rounded in\n    [4]_, and the second range is not shown in [3]_.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Jakob_Linke_Morgan(.7, 2E10)\n    310.90835207860454\n\n    References\n    ----------\n    .. [1] Jakob, M., and Linke, W., Warmeubergang beim Verdampfen von\n       Flussigkeiten an senkrechten und waagerechten Flaschen, Phys. Z.,\n       vol. 36, pp. 267-280, 1935.\n    .. [2] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [3] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [4] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if turbulent or (Ra > 1E8 and turbulent is None):\n        Nu = 0.129*Ra**(1/3.)\n    else:\n        Nu = 0.555*Ra**0.25\n    return Nu", "response": "r Returns the number of natural convection around a vertical cylinder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Nu_vertical_cylinder_Carne_Morgan(Pr, Gr, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to the results of [1]_ correlated by [2]_, as\n    presented in [3]_ and [4]_.\n\n    .. math::\n        Nu_H = 1.07 Ra_H^{0.28},\\; 2\\times 10^{6} < Ra < 2\\times 10^{8}\n\n        Nu_H = 0.152 Ra_H^{0.38},\\; 2\\times 10^{8} < Ra < 2\\times 10^{11}\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Cylinder of diameters 0.475 cm to 7.62 cm, L/D from 8 to 127. Isothermal\n    boundary condition was assumed, but not verified. Transition between ranges\n    is not smooth. If outside of range, no warning is given. The higher range\n    of [1]_ is not shown in [3]_, and the formula for the first is actually for\n    the second in [3]_.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Carne_Morgan(.7, 2E8)\n    204.31470629065677\n\n    References\n    ----------\n    .. [1] J. B. Carne. \"LIX. Heat Loss by Natural Convection from Vertical\n       Cylinders.\" The London, Edinburgh, and Dublin Philosophical Magazine and\n       Journal of Science 24, no. 162 (October 1, 1937): 634-53.\n       doi:10.1080/14786443708565140.\n    .. [2] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [3] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [4] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if turbulent or (Ra > 2E8 and turbulent is None):\n        return 0.152*Ra**0.38\n    else:\n        return 1.07*Ra**0.28", "response": "r Returns the number of natural convection around a vertical isothermal cylinder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the number of natural convection around a vertical isothermal cylinder.", "response": "def Nu_vertical_cylinder_Eigenson_Morgan(Pr, Gr, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to the results of [1]_ correlated by [2]_,\n    presented in [3]_ and in more detail in [4]_.\n\n    .. math::\n        Nu_H = 0.48 Ra_H^{0.25},\\; 10^{9} < Ra\n\n        Nu_H = 51.5 + 0.0000726 Ra_H^{0.63},\\; 10^{9} < Ra < 1.69 \\times 10^{10}\n\n        Nu_H = 0.148 Ra_H^{1/3} - 127.6 ,\\; 1.69 \\times 10^{10} < Ra\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Author presents results as appropriate for both flat plates and cylinders.\n    Height of 2.5 m with diameters of 2.4, 7.55, 15, 35, and 50 mm. Another\n    experiment of diameter 58 mm and length of 6.5 m was considered.\n    Cylinder of diameters 0.475 cm to 7.62 cm, L/D from 8 to 127.Transition\n    between ranges is not smooth. If outside of range, no warning is given.\n    Formulas are presented similarly in [3]_ and [4]_, but only [4]_ shows\n    the transition formula.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Eigenson_Morgan(0.7, 2E10)\n    230.55946525499715\n\n    References\n    ----------\n    .. [1] Eigenson L (1940). Les lois gouvernant la transmission de la chaleur\n       aux gaz biatomiques par les parois des cylindres verticaux dans le cas\n       de convection naturelle. Dokl Akad Nauk SSSR 26:440-444\n    .. [2] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [3] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [4] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if turbulent or (Ra > 1.69E10 and turbulent is None):\n        return 0.148*Ra**(1/3.) - 127.6\n    elif 1E9 < Ra < 1.69E10 and turbulent is not False:\n        return 51.5 + 0.0000726*Ra**0.63\n    else:\n        return 0.48*Ra**0.25"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Nu_vertical_cylinder_McAdams_Weiss_Saunders(Pr, Gr, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to the results of [1]_ and [2]_ correlated by\n    [3]_, as presented in [4]_, [5]_, and [6]_.\n\n    .. math::\n        Nu_H = 0.59 Ra_H^{0.25},\\; 10^{4} < Ra < 10^{9}\n\n        Nu_H = 0.13 Ra_H^{1/3.},\\; 10^{9} < Ra < 10^{12}\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Transition between ranges is not smooth. If outside of range, no warning is\n    given. For ranges under 10^4, a graph is provided, not included here.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_McAdams_Weiss_Saunders(.7, 2E10)\n    313.31849434277973\n\n    References\n    ----------\n    .. [1] Weise, Rudolf. \"Warmeubergang durch freie Konvektion an\n       quadratischen Platten.\" Forschung auf dem Gebiet des Ingenieurwesens\n       A 6, no. 6 (November 1935): 281-92. doi:10.1007/BF02592565.\n    .. [2] Saunders, O. A. \"The Effect of Pressure Upon Natural Convection in\n       Air.\" Proceedings of the Royal Society of London A: Mathematical,\n       Physical and Engineering Sciences 157, no. 891 (November 2, 1936):\n       278-91. doi:10.1098/rspa.1936.0194.\n    .. [3] McAdams, William Henry. Heat Transmission. 3E. Malabar, Fla:\n       Krieger Pub Co, 1985.\n    .. [4] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [5] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [6] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if turbulent or (Ra > 1E9 and turbulent is None):\n        return 0.13*Ra**(1/3.)\n    else:\n        return 0.59*Ra**0.25", "response": "r A function that calculates the number of natural convection around a vertical cylinder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Nu_vertical_cylinder_Al_Arabi_Khamis(Pr, Gr, L, D, turbulent=None):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to [1]_, also as presented in [2]_ and [3]_.\n\n    .. math::\n        Nu_H = 2.9Ra_H^{0.25}/Gr_D^{1/12},\\; 9.88 \\times 10^7 \\le Ra_H \\le 2.7\\times10^{9}\n\n        Nu_H = 0.47 Ra_H^{0.333}/Gr_D^{1/12},\\; 2.7 \\times 10^9 \\le Ra_H \\le 2.95\\times10^{10}\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number with respect to cylinder height [-]\n    L : float\n        Length of vertical cylinder, [m]\n    D : float\n        Diameter of cylinder, [m]\n    turbulent : bool or None, optional\n        Whether or not to force the correlation to return the turbulent\n\t\t result; will return the laminar regime if False; leave as None for\n        automatic selection\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    For air. Local Nusselt number results also given in [1]_. D from 12.75 to\n    51 mm; H from 300 to 2000 mm. Temperature kept constant by steam condensing.\n\n    If outside of range, no warning is given. Applies for range of:\n\n    .. math::\n        1.08 \\times 10^4 \\le Gr_D \\le 6.9 \\times 10^5\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Al_Arabi_Khamis(.71, 2E10, 10, 1)\n    280.39793209114765\n\n    References\n    ----------\n    .. [1] Al-Arabi, M., and M. Khamis. \"Natural Convection Heat Transfer from\n       Inclined Cylinders.\" International Journal of Heat and Mass Transfer 25,\n       no. 1 (January 1982): 3-15. doi:10.1016/0017-9310(82)90229-0.\n    .. [2] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [3] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Gr_D = Gr/L**3*D**3\n    Ra = Pr*Gr\n    if turbulent or (Ra > 2.6E9 and turbulent is None):\n        return 0.47*Ra**(1/3.)*Gr_D**(-1/12.)\n    else:\n        return 2.9*Ra**0.25*Gr_D**(-1/12.)", "response": "Calculates the Nusselt number for natural convection around a vertical cylinder."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the number of natural convection around a isothermal cylinder in a Popiel - Churchill system.", "response": "def Nu_vertical_cylinder_Popiel_Churchill(Pr, Gr, L, D,\n                     Nu_vertical_plate_correlation=Nu_vertical_plate_Churchill):\n    r'''Calculates Nusselt number for natural convection around a vertical\n    isothermal cylinder according to [1]_, also  presented in [2]_.\n\n    .. math::\n        \\frac{Nu}{Nu_{L,fp}} = 1 + B\\left[32^{0.5}Gr_L^{-0.25}\\frac{L}{D}\\right]^C\n\n        B = 0.0571322 + 0.20305 Pr^{-0.43}\n\n        C = 0.9165 - 0.0043Pr^{0.5} + 0.01333\\ln Pr + 0.0004809/Pr\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number with respect to cylinder height [-]\n    L : float\n        Length of vertical cylinder, [m]\n    D : float\n        Diameter of cylinder, [m]\n    Nu_vertical_plate_correlation : function, optional\n        Correlation for vertical plate heat transfer\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    For 0.01 < Pr < 100. Requires a vertical flat plate correlation.\n    Both [2], [3] present a power of 2 instead of 0.5 on the 32 in the equation,\n    but the original has the correct form.\n\n    Examples\n    --------\n    >>> Nu_vertical_cylinder_Popiel_Churchill(0.7, 1E10, 2.5, 1)\n    228.8979005514989\n\n    References\n    ----------\n    .. [1] Popiel, C. O., J. Wojtkowiak, and K. Bober. \"Laminar Free Convective\n       Heat Transfer from Isothermal Vertical Slender Cylinder.\" Experimental\n       Thermal and Fluid Science 32, no. 2 (November 2007): 607-613.\n       doi:10.1016/j.expthermflusci.2007.07.003.\n    .. [2] Popiel, Czeslaw O. \"Free Convection Heat Transfer from Vertical\n       Slender Cylinders: A Review.\" Heat Transfer Engineering 29, no. 6\n       (June 1, 2008): 521-36. doi:10.1080/01457630801891557.\n    .. [3] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    B = 0.0571322 + 0.20305*Pr**-0.43\n    C = 0.9165 - 0.0043*Pr**0.5 + 0.01333*log(Pr) + 0.0004809/Pr\n    Nu_fp = Nu_vertical_plate_correlation(Pr, Gr)\n    return Nu_fp*(1 + B*(32**0.5*Gr**-0.25*L/D)**C)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Nu_horizontal_cylinder_Kuehn_Goldstein(Pr, Gr):\n    r'''Calculates Nusselt number for natural convection around a horizontal\n    cylinder according to the Kuehn-Goldstein [1]_ correlation, also shown in\n    [2]_. Cylinder must be isothermal.\n\n    .. math::\n        \\frac{2}{Nu_D} = \\ln\\left[1 + \\frac{2}{\\left[\\left\\{0.518Ra_D^{0.25}\n        \\left[1 + \\left(\\frac{0.559}{Pr}\\right)^{3/5}\\right]^{-5/12}\n        \\right\\}^{15} + (0.1Ra_D^{1/3})^{15}\\right]^{1/15}}\\right]\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    [1]_ suggests this expression is valid for all cases except low-Pr fluids.\n    [2]_ suggests no restrictions.\n\n    Examples\n    --------\n    >>> Nu_horizontal_cylinder_Kuehn_Goldstein(0.69, 2.63E9)\n    122.99323525628186\n\n    References\n    ----------\n    .. [1] Kuehn, T. H., and R. J. Goldstein. \"Correlating Equations for\n       Natural Convection Heat Transfer between Horizontal Circular Cylinders.\"\n       International Journal of Heat and Mass Transfer 19, no. 10\n       (October 1976): 1127-34. doi:10.1016/0017-9310(76)90145-9\n    .. [2] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    return 2./log(1 + 2./((0.518*Ra**0.25*(1. + (0.559/Pr)**0.6)**(-5/12.))**15\n                  + (0.1*Ra**(1/3.))**15)**(1/15.))", "response": "r A function that calculates the Nusselt number for natural convection around a horizontal cylinder according to the Kuehn - Goldstein correlation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the Nusselt number for natural convection around a horizontal cylinder according to the Morgan.", "response": "def Nu_horizontal_cylinder_Morgan(Pr, Gr):\n    r'''Calculates Nusselt number for natural convection around a horizontal\n    cylinder according to the Morgan [1]_ correlations, a product of a very\n    large review of the literature. Sufficiently common as to be shown in [2]_.\n    Cylinder must be isothermal.\n\n    .. math::\n        Nu_D = C Ra_D^n\n\n    +----------+----------+-------+-------+\n    |  Gr min  |  Gr max  |  C    |  n    |\n    +==========+==========+=======+=======+\n    | 10E-10   |  10E-2   | 0.675 | 0.058 |\n    +----------+----------+-------+-------+\n    | 10E-2    |  10E2    | 1.02  | 0.148 |\n    +----------+----------+-------+-------+\n    | 10E2     |  10E4    | 0.850 | 0.188 |\n    +----------+----------+-------+-------+\n    | 10E4     |  10E7    | 0.480 | 0.250 |\n    +----------+----------+-------+-------+\n    | 10E7     |  10E12   | 0.125 | 0.333 |\n    +----------+----------+-------+-------+\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Most comprehensive review with a new proposed equation to date.\n    Discontinuous among the jumps in range. Blindly runs outside if upper and\n    lower limits without warning.\n\n    Examples\n    --------\n    >>> Nu_horizontal_cylinder_Morgan(0.69, 2.63E9)\n    151.3881997228419\n\n    References\n    ----------\n    .. [1] Morgan, V.T., The Overall Convective Heat Transfer from Smooth\n       Circular Cylinders, in Advances in Heat Transfer, eds. T.F. Irvin and\n       J.P. Hartnett, V 11, 199-264, 1975.\n    .. [2] Boetcher, Sandra K. S. \"Natural Convection Heat Transfer From\n       Vertical Cylinders.\" In Natural Convection from Circular Cylinders,\n       23-42. Springer, 2014.\n    '''\n    Ra = Pr*Gr\n    if Ra < 1E-2:\n        C, n = 0.675, 0.058\n    elif Ra < 1E2:\n        C, n = 1.02, 0.148\n    elif Ra < 1E4:\n        C, n = 0.850, 0.188\n    elif Ra < 1E7:\n        C, n = 0.480, 0.250\n    else:\n        # up to 1E12\n        C, n = 0.125, 0.333\n    return C*Ra**n"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Nu_horizontal_cylinder(Pr, Gr, Method=None, AvailableMethods=False):\n    r'''This function handles choosing which horizontal cylinder free convection\n    correlation is used. Generally this is used by a helper class, but can be\n    used directly. Will automatically select the correlation to use if none is\n    provided; returns None if insufficient information is provided.\n\n    Prefered functions are 'Morgan' when discontinuous results are acceptable\n    and 'Churchill-Chu' otherwise.\n\n    Parameters\n    ----------\n    Pr : float\n        Prandtl number [-]\n    Gr : float\n        Grashof number [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate Nu with the given inputs\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        A string of the function name to use, as in the dictionary\n        horizontal_cylinder_correlations\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate Nu with the given inputs\n\n    Examples\n    --------\n    >>> Nu_horizontal_cylinder(0.72, 1E7)\n    24.864192615468973\n    '''\n    def list_methods():\n        methods = []\n        for key, values in horizontal_cylinder_correlations.items():\n                methods.append(key)\n        if 'Morgan' in methods:\n            methods.remove('Morgan')\n            methods.insert(0, 'Morgan')\n        return methods\n\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        Method = list_methods()[0]\n\n    if Method in horizontal_cylinder_correlations:\n        return horizontal_cylinder_correlations[Method](Pr=Pr, Gr=Gr)\n    else:\n        raise Exception(\"Correlation name not recognized; see the \"\n                        \"documentation for the available options.\")", "response": "r Returns the number of non - discontinuous horizontal cylinder free convections for a given number Pr and Gr."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Nu_plate_Martin(Re, Pr, plate_enlargement_factor, variant='1999'):\n    r'''Calculates Nusselt number for single-phase flow in a \n    Chevron-style plate heat exchanger according to [1]_, also shown in [2]_\n    and [3]_. \n    \n    .. math::\n        Nu = 0.122 Pr^{1/3} \\left[f_d Re^2 \\sin (2\\phi)\\right]^{0.374}\n        \n    The Darcy friction factor should be calculated with the Martin (1999) \n    friction factor correlation, as that is what the power of 0.374 was \n    regressed with. It can be altered to a later formulation by Martin in the\n    VDI Heat Atlas 2E, which increases the calculated heat transfer friction \n    slightly.\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to the hydraulic diameter of the channels,\n        [-]\n    Pr : float\n        Prandtl number calculated with bulk fluid properties, [-]\n    plate_enlargement_factor : float\n        The extra surface area multiplier as compared to a flat plate\n        caused the corrugations, [-]\n    variant : str\n        One of '1999' or 'VDI'; chooses between the two Martin friction\n        factor correlations, [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to `Dh`, [-]\n\n    Notes\n    -----\n    Based on experimental data from Re from 200 - 10000 and enhancement \n    factors calculated with chevron angles of 0 to 80 degrees. See \n    `PlateExchanger` for further clarification on the definitions.\n        \n    Note there is a discontinuity at Re = 2000 for the transition from\n    laminar to turbulent flow, arising from the friction factor correlation's\n    transition ONLY, although the literature suggests the transition\n    is actually smooth.\n    \n    A viscosity correction power for liquid flows of (1/6) is suggested, and\n    for gases, no correction factor.\n\n    Examples\n    --------\n    >>> Nu_plate_Martin(Re=2000, Pr=.7, plate_enlargement_factor=1.18)\n    43.5794551998615\n    \n    References\n    ----------\n    .. [1] Martin, Holger. \"A Theoretical Approach to Predict the Performance \n       of Chevron-Type Plate Heat Exchangers.\" Chemical Engineering and \n       Processing: Process Intensification 35, no. 4 (January 1, 1996): 301-10. \n       https://doi.org/10.1016/0255-2701(95)04129-X.\n    .. [2] Martin, Holger. \"Economic optimization of compact heat exchangers.\"\n       EF-Conference on Compact Heat Exchangers and Enhancement Technology for \n       the Process Industries, Banff, Canada, July 18-23, 1999, 1999. \n       https://publikationen.bibliothek.kit.edu/1000034866.\n    .. [3] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    try:\n        fd_correlation = _Nu_plate_Martin_correlations[variant]\n    except KeyError:\n        raise Exception(\"Supported friction factor correlations are Martin's\"\n                        \" '1999' correlation or his 'VDI' correlation only\")\n    fd = fd_correlation(Re, plate_enlargement_factor)\n    # VDI, original, and Bj\u00f6rn Palm and Joachim Claesson recommend 0.122 leading coeff\n    # The 0.205 in some publications is what happens when the friction factor\n    # is in a fanning basis; = 4^0.374*1.22 = 2.048944\n    Nu = 0.122*Pr**(1/3.)*(fd*Re*Re*sin(2.0*plate_enlargement_factor))**0.374\n    return Nu", "response": "r Returns the Nusselt number for a single - phase flow in a given Martin plate."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Nu_plate_Muley_Manglik(Re, Pr, chevron_angle, plate_enlargement_factor):\n    r'''Calculates Nusselt number for single-phase flow in a \n    Chevron-style plate heat exchanger according to [1]_, also shown in [2]_\n    and [3]_. \n    \n    .. math::\n        Nu = [0.2668 - 0.006967(\\beta) + 7.244\\times 10^{-5}(\\beta)^2]\n        \\times[20.7803 - 50.9372\\phi + 41.1585\\phi^2 - 10.1507\\phi^3]\n        \\times Re^{[0.728 + 0.0543\\sin[(2\\pi\\beta/90) + 3.7]]} Pr^{1/3}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to the hydraulic diameter of the channels,\n        [-]\n    Pr : float\n        Prandtl number calculated with bulk fluid properties, [-]\n    chevron_angle : float\n        Angle of the plate corrugations with respect to the vertical axis\n        (the direction of flow if the plates were straight), between 0 and\n        90. Many plate exchangers use two alternating patterns; use their\n        average angle for that situation [degrees]\n    plate_enlargement_factor : float\n        The extra surface area multiplier as compared to a flat plate\n        caused the corrugations, [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to `Dh`, [-]\n\n    Notes\n    -----\n    The correlation as presented in [1]_ suffers from a typo, with a \n    coefficient of 10.51 instead of 10.15. Several more decimal places were\n    published along with the corrected typo in [2]_. This has a *very large*\n    difference if not implemented.\n    \n    The viscosity correction power is recommended to be the blanket\n    Sieder and Tate (1936) value of 0.14.\n    \n    The correlation is recommended in the range of Reynolds numbers above\n    1000, chevron angles between 30 and 60 degrees, and enlargement factors\n    from 1 to 1.5. Due to its cubic nature it is not likely to give good \n    results if the chevron angle or enlargement factors are out of those\n    ranges.\n\n    Examples\n    --------\n    >>> Nu_plate_Muley_Manglik(Re=2000, Pr=.7, chevron_angle=45,\n    ... plate_enlargement_factor=1.18)\n    36.49087100602062\n\n    References\n    ----------\n    .. [1] Muley, A., and R. M. Manglik. \"Experimental Study of Turbulent Flow\n       Heat Transfer and Pressure Drop in a Plate Heat Exchanger With Chevron \n       Plates.\" Journal of Heat Transfer 121, no. 1 (February 1, 1999): 110-17. \n       doi:10.1115/1.2825923.\n    .. [2] Palm, Bj\u00f6rn, and Joachim Claesson. \"Plate Heat Exchangers: \n       Calculation Methods for Single- and Two-Phase Flow (Keynote),\" January \n       1, 2005, 103-13. https://doi.org/10.1115/ICMM2005-75092.\n    '''\n    beta, phi = chevron_angle, plate_enlargement_factor\n    t1 = (0.2668 - 0.006967*beta + 7.244E-5*beta**2)\n    #t2 = (20.78 - 50.94*phi + 41.16*phi**2 - 10.51*phi**3)\n    # It was the extra decimals which were needed\n    t2 = (20.7803 - 50.9372*phi + 41.1585*phi**2 - 10.1507*phi**3)\n    t3 = (0.728 + 0.0543*sin((2*pi*beta/90) + 3.7))\n    return t1*t2*Re**t3*Pr**(1/3.)", "response": "Calculates the Nusselt number for a single - phase flow in a Chevron - style plate exchanger according to [ 1 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Nu_plate_Khan_Khan(Re, Pr, chevron_angle):\n    r'''Calculates Nusselt number for single-phase flow in a \n    Chevron-style plate heat exchanger according to [1]_.\n    \n    .. math::\n        Nu = \\left(0.0161\\frac{\\beta}{\\beta_{max}} + 0.1298\\right)\n        Re^{\\left(0.198 \\frac{\\beta}{\\beta_{max}} + 0.6398\\right)} \n        Pr^{0.35} \n                \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to the hydraulic diameter of the channels,\n        [-]\n    Pr : float\n        Prandtl number calculated with bulk fluid properties, [-]\n    chevron_angle : float\n        Angle of the plate corrugations with respect to the vertical axis\n        (the direction of flow if the plates were straight), between 0 and\n        90. Many plate exchangers use two alternating patterns; use their\n        average angle for that situation [degrees]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to `Dh`, [-]\n\n    Notes\n    -----\n    The viscosity correction power is recommended to be the blanket\n    Sieder and Tate (1936) value of 0.14.\n    \n    The correlation is recommended in the range of Reynolds numbers from\n    500 to 2500, chevron angles between 30 and 60 degrees, and Prandtl\n    numbers between 3.5 and 6.\n\n    Examples\n    --------\n    >>> Nu_plate_Khan_Khan(Re=1000, Pr=4.5, chevron_angle=30)\n    38.40883639103741\n    \n    References\n    ----------\n    .. [1] Khan, T. S., M. S. Khan, Ming-C. Chyu, and Z. H. Ayub. \"Experimental\n       Investigation of Single Phase Convective Heat Transfer Coefficient in a \n       Corrugated Plate Heat Exchanger for Multiple Plate Configurations.\" \n       Applied Thermal Engineering 30, no. 8 (June 1, 2010): 1058-65.\n       https://doi.org/10.1016/j.applthermaleng.2010.01.021. \n    '''\n    beta_max = 60.\n    beta_ratio = chevron_angle/beta_max\n    Nu = (0.0161*beta_ratio + 0.1298)*Re**(0.198*beta_ratio + 0.6398)*Pr**0.35\n    return Nu", "response": "Calculates the Nusselt number for a single - phase flow in a \n addFile."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef calc_Cmax(mh, mc, Cph, Cpc):\n    r'''Returns the heat capacity rate for the maximum stream\n    having flows `mh` and `mc`, with averaged heat capacities `Cph` and `Cpc`.\n\n    .. math::\n        C_c = m_cC_{p,c}\n\n        C_h = m_h C_{p,h}\n\n        C_{max} = \\max(C_c, C_h)\n\n    Parameters\n    ----------\n    mh : float\n        Mass flow rate of hot stream, [kg/s]\n    mc : float\n        Mass flow rate of cold stream, [kg/s]\n    Cph : float\n        Averaged heat capacity of hot stream, [J/kg/K]\n    Cpc : float\n        Averaged heat capacity of cold stream, [J/kg/K]\n\n    Returns\n    -------\n    Cmax : float\n        The heat capacity rate of the larger fluid, [W/K]\n\n    Notes\n    -----\n    Used with the effectiveness method for heat exchanger design.\n    Technically, it doesn't matter if the hot and cold streams are in the right\n    order for the input, but it is easiest to use this function when the order\n    is specified.\n\n    Examples\n    --------\n    >>> calc_Cmax(mh=22., mc=5.5, Cph=2200, Cpc=4400.)\n    48400.0\n\n    References\n    ----------\n    .. [1] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    Ch = mh*Cph\n    Cc = mc*Cpc\n    return max(Ch, Cc)", "response": "r Returns the heat capacity rate for the maximum stream\n    with flows mh and mc with averaged heat capacities Cph and Cpc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef temperature_effectiveness_air_cooler(R1, NTU1, rows, passes):\n    r'''Returns temperature effectiveness `P1` of an air cooler with \n    a specified heat capacity ratio, number of transfer units `NTU1`,\n    number of rows `rows`, and number of passes `passes`. The supported cases\n    are as follows:\n        \n    * N rows 1 pass\n    * N row N pass (up to N = 5)\n    * 4 rows 2 passes\n    \n    For N rows 1 passes ([2]_, shown in [1]_ and [3]_):\n        \n    .. math::\n        P = \\frac{1}{R} \\left\\{1 - \\left[\\frac{N\\exp(NKR)}\n        {1 + \\sum_{i=1}^{N-1}\\sum_{j=0}^i  {{i}\\choose{j}}K^j \\exp(-(i-j)NTU/N)\n        \\sum_{k=0}^j \\frac{(NKR)^k}{k!}}\\right]^{-1}\\right\\}\n        \n    For 2 rows 2 passes (cited as from [4]_ in [1]_):\n        \n    .. math::\n        P_1 = \\frac{1}{R}\\left(1 -\\frac{1}{\\xi}\\right)\n        \n        \\xi = \\frac{K}{2} + \\left(1 - \\frac{K}{2}\\right)\\exp(2KR)\n        \n        K = 1 - \\exp\\left(\\frac{-NTU}{2}\\right)\n        \n    For 3 rows / 3 passes (cited as from [4]_ in [1]_):\n        \n    .. math::\n        \\xi = K\\left[1 - \\frac{K}{4} - RK\\left(1 - \\frac{K}{2}\\right)\\right]\n        \\exp(KR) + \\exp(3KR)\\left(1 - \\frac{K}{2}\\right)^2\n        \n        K = 1 - \\exp\\left(\\frac{-NTU}{3}\\right)\n        \n    For 4 rows / 4 passes (cited as from [4]_ in [1]_):\n        \n    .. math::\n        \\xi = \\frac{K}{2}\\left(1 - \\frac{K}{2} + \\frac{K^2}{4}\\right)\n        + K\\left(1 - \\frac{K}{2}\\right)\n        \\left[1 - \\frac{R}{8}K\\left(1 - \\frac{K}{2}\\right)\\exp(2KR)\\right]\n        + \\exp(4KR)\\left(1 - \\frac{K}{2}\\right)^3\n        \n        K = 1 - \\exp\\left(\\frac{-NTU}{4}\\right)\n        \n    For 5 rows / 5 passes (cited as from [4]_ in [1]_):\n        \n    .. math::\n        \\xi = \\left\\{K \\left(1 - \\frac{3}{4}K + \\frac{K^2}{2}- \\frac{K^3}{8}\n        \\right) - RK^2\\left[1 -K + \\frac{3}{4}K^2 - \\frac{1}{4}K^3\n        - \\frac{R}{2}K^2\\left(1 - \\frac{K}{2}\\right)^2\\right]\\right\\}\\exp(KR)\n        + \\left[K\\left(1 - \\frac{3}{4}K + \\frac{1}{16}K^3\\right) - 3RK^2\\left(1\n        - \\frac{K}{2}\\right)^3\\right]\\exp(3KR)+ \\left(1 - \\frac{K}{2}\\right)^4\n        \\exp(5KR)\n\n    For 4 rows / 2 passes (cited as from [4]_ in [1]_):\n        \n    .. math::\n        P_1 = \\frac{1}{R}\\left(1 -\\frac{1}{\\xi}\\right)\n        \n        \\xi = \\left\\{\\frac{R}{2}K^3[4 - K + 2RK^2] + \\exp(4KR)\n        + K\\left[1 - \\frac{K}{2} + \\frac{K^2}{8}\\right]\n        \\left[1 - \\exp(4KR)\\right]\n        \\right\\}\\frac{1}{(1+RK^2)^2}\n        \n        K = 1 - \\exp\\left(\\frac{-NTU}{4}\\right)\n        \n    Parameters\n    ----------\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (process fluid side) [-]\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (process fluid side) [-]\n    rows : int\n        Number of rows of tubes in the air cooler [-]\n    passes : int\n        Number of passes the process fluid undergoes [-]\n        \n    Returns\n    -------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (process fluid side) [-]\n\n    Notes\n    -----\n\n    Examples\n    --------\n\n    References\n    ----------\n    .. [1] Thulukkanam, Kuppan. Heat Exchanger Design Handbook, Second Edition. \n       CRC Press, 2013.\n    .. [2] Schedwill, H., \"Thermische Auslegung von Kreuzstromwarmeaustauschern, \n       Fortschr-Ber.\" VDI Reihe 6 19, VDI, Germany, 1968.\n    .. [3] Schlunder, Ernst U, and International Center for Heat and Mass\n       Transfer. Heat Exchanger Design Handbook. Washington:\n       Hemisphere Pub. Corp., 1983.\n    .. [4]  Nicole, F. J. L.. \"Mean temperature difference for heat exchanger\n       design.\" Council for Scientific and Industrial Research, Special Report\n       Chem. 223, Pretoria, South Africa (1972).\n    '''\n    if passes == 1:\n        N = rows\n        K = 1. - exp(-NTU1/N)\n        NKR1 = N*K*R1\n        NTU1_N = NTU1/N\n        top = N*exp(N*K*R1)\n        # Precalculate integer factorials up to N\n        factorials = [factorial(i) for i in range(N)]\n        K_powers = [K**j for j in range(0, N+1)]\n        NKR1_powers = [NKR1**k for k in range(0, N+1)]\n        exp_terms = [exp(i*NTU1_N) for i in range(-N+1, 1)]\n        NKR1_powers_over_factorials = [NKR1_powers[k]/factorials[k] \n                                       for k in range(N)]\n        \n        # Precompute even more...\n        NKR1_pows_div_factorials = [0]\n        for k in NKR1_powers_over_factorials:\n            NKR1_pows_div_factorials.append(NKR1_pows_div_factorials[-1]+k)\n        NKR1_pows_div_factorials.pop(0)\n        \n        final_speed = [i*j for i, j in zip(K_powers, NKR1_pows_div_factorials)]\n        \n        tot = 0.\n        for i in range(1, N):\n            for j in range(0, i+1):\n                # can't optimize the factorial\n                prod = factorials[i]/(factorials[i-j]*factorials[j])\n                tot1 = prod*exp_terms[j-i-1]\n                tot += tot1*final_speed[j]\n    \n        return 1./R1*(1. - 1./(top/(1.+tot)))\n    elif rows == passes == 2:\n        K = 1. - exp(-0.5*NTU1)\n        xi = 0.5*K + (1. - 0.5*K)*exp(2.*K*R1)\n        return 1./R1*(1. - 1./xi)\n    elif rows == passes == 3:\n        K = 1. - exp(-NTU1/3.)\n        xi = (K*(1. - 0.25*K - R1*K*(1. - 0.5*K))*exp(K*R1)\n              + exp(3.*K*R1)*(1. - 0.5*K)**2)\n        return 1./R1*(1. - 1./xi)\n    elif rows == passes == 4:\n        K = 1. - exp(-0.25*NTU1)\n        xi = (0.5*K*(1. - 0.5*K + 0.25*K**2)\n              + K*(1. - 0.5*K)*(1. - 0.125*R1*K*(1. - 0.5*K)*exp(2.*K*R1))\n              + exp(4.*K*R1)*(1. - 0.5*K)**3)\n        return 1./R1*(1. - 1./xi)\n    elif rows == passes == 5:\n        K = 1. - exp(-0.2*NTU1)\n        xi = (K*(1. - .75*K + .5*K**2 - .125*K**3) \n              - R1*K**2*(1. - K + .75*K**2 - .25*K**3 \n              - .5*R1*K**2*(1. - .5*K)**2))*exp(K*R1)\n        xi += ((K*(1. - .75*K + 1/16.*K**3) - 3*R1*K**2*(1. - .5*K)**3)\n              *exp(3*K*R1) + (1. - .5*K)**4*exp(5*K*R1))\n        return 1./R1*(1. - 1./xi)\n    elif rows == 4 and passes == 2:\n        K = 1. - exp(-0.25*NTU1)\n        xi = (0.5*R1*K**3*(4. - K + 2.*R1*K**2) + exp(4.*K*R1) + K*(1. - 0.5*K \n              + 0.125*K**2)*(1 - exp(4.*K*R1)))*(1. + R1*K**2)**-2\n        return 1./R1*(1. - 1./xi)\n    else:\n        raise Exception('Number of passes and rows not supported.')", "response": "r Returns a string that represents the temperature effectiveness P1 of an air cooler with \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef temperature_effectiveness_TEMA_J(R1, NTU1, Ntp):\n    r'''Returns temperature effectiveness `P1` of a TEMA J type heat exchanger  \n    with a specified heat capacity ratio, number of transfer units `NTU1`,\n    and of number of tube passes `Ntp`. The supported cases are as follows:\n        \n    * One tube pass (shell fluid mixed)\n    * Two tube passes (shell fluid mixed, tube pass mixed between passes)\n    * Four tube passes (shell fluid mixed, tube pass mixed between passes)\n    \n    For 1-1 TEMA J shell and tube exchangers, shell and tube fluids mixed:\n\n    .. math::\n        P_1 = \\frac{1}{R_1}\\left[1- \\frac{(2-R_1)(2E + R_1 B)}{(2+R_1)\n        (2E - R_1/B)}\\right]\n        \n    For 1-2 TEMA J, shell and tube fluids mixed. There are two possible \n    arrangements for the flow and the number of tube passes, but the equation\n    is the same in both:\n        \n    .. math::\n        P_1 = \\left[1 + \\frac{R_1}{2} + \\lambda B - 2\\lambda C D\\right]^{-1}\n        \n        B = \\frac{(A^\\lambda +1)}{A^\\lambda -1}\n        \n        C = \\frac{A^{(1 + \\lambda)/2}}{\\lambda - 1 + (1 + \\lambda)A^\\lambda}\n        \n        D = 1 + \\frac{\\lambda A^{(\\lambda-1)/2}}{A^\\lambda -1}\n        \n        A = \\exp(NTU_1)\n        \n        \\lambda = (1 + R_1^2/4)^{0.5}\n        \n    For 1-4 TEMA J, shell and tube exchanger with both sides mixed:\n        \n    .. math::\n        P_1 = \\left[1 + \\frac{R_1}{4}\\left(\\frac{1+3E}{1+E}\\right) + \\lambda B \n        - 2 \\lambda C D\\right]^{-1}\n        \n        B = \\frac{A^\\lambda +1}{A^\\lambda -1}\n        \n        C = \\frac{A^{(1+\\lambda)/2}}{\\lambda - 1 + (1 + \\lambda)A^\\lambda}\n        \n        D = 1 + \\frac{\\lambda A^{(\\lambda-1)/2}}{A^\\lambda -1}\n        \n        A = \\exp(NTU_1)\n        \n        E = \\exp(R_1 NTU_1/2)\n        \n        \\lambda = (1 + R_1^2/16)^{0.5}\n        \n    Parameters\n    ----------\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (shell side = 1, tube side = 2) [-]\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (shell side = 1, tube side\n        = 2) [-]\n    Ntp : int\n        Number of tube passes, 1, 2, or 4, [-]\n        \n    Returns\n    -------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n\n    Notes\n    -----\n    For numbers of tube passes that are not 1, 2, or 4, an exception is raised.\n    The convention for the formulas in [1]_ and [3]_ are with the shell side\n    as side 1, and the tube side as side 2. [2]_ has formulas with the \n    opposite convention.\n\n    Examples\n    --------\n    >>> temperature_effectiveness_TEMA_J(R1=1/3., NTU1=1., Ntp=1)\n    0.5699085193651295\n\n    References\n    ----------\n    .. [1] Shah, Ramesh K., and Dusan P. Sekulic. Fundamentals of Heat \n       Exchanger Design. 1st edition. Hoboken, NJ: Wiley, 2002.\n    .. [2] Thulukkanam, Kuppan. Heat Exchanger Design Handbook, Second Edition. \n       CRC Press, 2013.\n    .. [3] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    '''\n    if Ntp == 1:\n        A = exp(NTU1)\n        B = exp(-NTU1*R1/2.)\n        if R1 != 2:\n            P1 = 1./R1*(1. - (2. - R1)*(2.*A + R1*B)/(2. + R1)/(2.*A - R1/B))\n        else:\n            P1 = 0.5*(1. - (1. + A**-2)/2./(1. + NTU1))\n    elif Ntp == 2:\n        lambda1 = (1. + R1*R1/4.)**0.5\n        A = exp(NTU1)\n        D = 1. + lambda1*A**((lambda1 - 1.)/2.)/(A**lambda1 - 1.)\n        C = A**((1+lambda1)/2.)/(lambda1 - 1. + (1. + lambda1)*A**lambda1)\n        B = (A**lambda1 + 1.)/(A**lambda1 - 1.)\n        P1 = 1./(1. + R1/2. + lambda1*B - 2.*lambda1*C*D)\n    elif Ntp == 4:\n        lambda1 = (1. + R1**2/16.)**0.5\n        E = exp(R1*NTU1/2.)\n        A = exp(NTU1)\n        D = 1. + lambda1*A**((lambda1-1)/2.)/(A**lambda1-1.)\n        C = A**((1+lambda1)/2.)/(lambda1 - 1. + (1. + lambda1)*A**lambda1)\n        B = (A**lambda1 + 1.)/(A**lambda1-1)\n        P1 = 1./(1. + R1/4.*(1. + 3.*E)/(1. + E) + lambda1*B - 2.*lambda1*C*D)\n    else:\n        raise Exception('Supported numbers of tube passes are 1, 2, and 4.')\n    return P1", "response": "r Returns a temperature effectiveness P1 for a TEMA J type heat exchanger with a specified heat capacity ratio NTU1 and number of transfer units Ntp."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef temperature_effectiveness_TEMA_H(R1, NTU1, Ntp, optimal=True):\n    r'''Returns temperature effectiveness `P1` of a TEMA H type heat exchanger  \n    with a specified heat capacity ratio, number of transfer units `NTU1`,\n    and of number of tube passes `Ntp`. For the two tube pass case, there are\n    two possible orientations, one inefficient and one efficient controlled\n    by the `optimal` option. The supported cases are as follows:\n        \n    * One tube pass (tube fluid split into two streams individually mixed,  \n      shell fluid mixed)\n    * Two tube passes (shell fluid mixed, tube pass mixed between passes)\n    * Two tube passes (shell fluid mixed, tube pass mixed between passes, inlet\n      tube side next to inlet shell-side)\n    \n    1-1 TEMA H, tube fluid split into two streams individually mixed, shell \n    fluid mixed:\n\n    .. math::\n        P_1 = E[1 + (1 - BR_1/2)(1 - A R_1/2 + ABR_1)] - AB(1 - BR_1/2)\n        \n        A = \\frac{1}{1 + R_1/2}\\{1 - \\exp[-NTU_1(1 + R_1/2)/2]\\}\n        \n        B = \\frac{1-D}{1-R_1 D/2}\n        \n        D = \\exp[-NTU_1(1-R_1/2)/2]\n        \n        E = (A + B - ABR_1/2)/2\n        \n    1-2 TEMA H, shell and tube fluids mixed in each pass at the cross section:\n        \n    .. math::\n        P_1 = \\frac{1}{R_1}\\left[1 - \\frac{(1-D)^4}{B - 4G/R_1}\\right]\n        \n        B = (1+H)(1+E)^2\n        \n        G = (1-D)^2(D^2 + E^2) + D^2(1 + E)^2\n        \n        H = [1 - \\exp(-2\\beta)]/(4/R_1 -1)\n        \n        E = [1 - \\exp(-\\beta)]/(4/R_1 - 1)\n        \n        D = [1 - \\exp(-\\alpha)]/(4/R_1 + 1)\n        \n        \\alpha = NTU_1(4 + R_1)/8\n        \n        \\beta = NTU_1(4-R_1)/8\n        \n    1-2 TEMA H, shell and tube fluids mixed in each pass at the cross section\n    but with the inlet tube stream coming in next to the shell fluid inlet\n    in an inefficient way (this is only shown in [2]_, and the stream 1/2 \n    convention in it is different but converted here; P1 is still returned):\n        \n    .. math::\n        P_2 = \\left[1 - \\frac{B + 4GR_2}{(1-D)^4}\\right]\n    \n        B = (1 + H)(1 + E)^2\n        \n        G = (1-D)^2(D^2 + E^2) + D^2(1 + E)^2\n        \n        D = \\frac{1 - \\exp(-\\alpha)}{1 - 4R_2}\n        \n        E = \\frac{\\exp(-\\beta) - 1}{4R_2 +1}\n        \n        H = \\frac{\\exp(-2\\beta) - 1}{4R_2 +1}\n        \n        \\alpha = \\frac{NTU_2}{8}(4R_2 -1)\n        \n        \\beta = \\frac{NTU_2}{8}(4R_2 +1)\n                \n    Parameters\n    ----------\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (shell side = 1, tube side = 2) [-]\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (shell side = 1, tube side\n        = 2) [-]\n    Ntp : int\n        Number of tube passes, 1, or 2, [-]\n    optimal : bool, optional\n        Whether or not the arrangement is configured to give more of a\n        countercurrent and efficient (True) case or an inefficient parallel\n        case, [-]\n        \n    Returns\n    -------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n\n    Notes\n    -----\n    For numbers of tube passes greater than 1 or 2, an exception is raised.\n    The convention for the formulas in [1]_ and [3]_ are with the shell side\n    as side 1, and the tube side as side 2. [2]_ has formulas with the \n    opposite convention.\n\n    Examples\n    --------\n    >>> temperature_effectiveness_TEMA_H(R1=1/3., NTU1=1., Ntp=1)\n    0.5730728284905833\n\n    References\n    ----------\n    .. [1] Shah, Ramesh K., and Dusan P. Sekulic. Fundamentals of Heat \n       Exchanger Design. 1st edition. Hoboken, NJ: Wiley, 2002.\n    .. [2] Thulukkanam, Kuppan. Heat Exchanger Design Handbook, Second Edition. \n       CRC Press, 2013.\n    .. [3] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    '''\n    if Ntp == 1:\n        A = 1./(1 + R1/2.)*(1. - exp(-NTU1*(1. + R1/2.)/2.))\n        D = exp(-NTU1*(1. - R1/2.)/2.)\n        if R1 != 2:\n            B = (1. - D)/(1. - R1*D/2.)\n        else:\n            B = NTU1/(2. + NTU1)\n        E = (A + B - A*B*R1/2.)/2.\n        P1 = E*(1. + (1. - B*R1/2.)*(1. - A*R1/2. + A*B*R1)) - A*B*(1. - B*R1/2.)\n    elif Ntp == 2 and optimal:\n        alpha = NTU1*(4. + R1)/8.\n        beta = NTU1*(4. - R1)/8.\n        D = (1. - exp(-alpha))/(4./R1 + 1)\n        if R1 != 4:\n            E = (1. - exp(-beta))/(4./R1 - 1.)\n            H = (1. - exp(-2.*beta))/(4./R1 - 1.)\n        else:\n            E = NTU1/2.\n            H = NTU1\n        G = (1-D)**2*(D**2 + E**2) + D**2*(1+E)**2\n        B = (1. + H)*(1. + E)**2\n        P1 = 1./R1*(1. - (1. - D)**4/(B - 4.*G/R1))\n    elif Ntp == 2 and not optimal:\n        R1_orig = R1\n        #NTU2 = NTU1*R1_orig but we want to treat it as NTU1 in this case\n        NTU1 = NTU1*R1_orig # switch 1\n        # R2 = 1/R1 but we want to treat it as R1 in this case\n        R1 = 1./R1_orig # switch 2\n        \n        beta = NTU1*(4.*R1 + 1)/8.\n        alpha = NTU1/8.*(4.*R1 - 1.)\n        H = (exp(-2.*beta) - 1.)/(4.*R1 + 1.)\n        E = (exp(-beta) - 1.)/(4.*R1 + 1.)\n        B = (1. + H)*(1. + E)**2\n        if R1 != 0.25:\n            D = (1. - exp(-alpha))/(1. - 4.*R1)\n            G = (1. - D)**2*(D**2 + E**2) + D**2*(1. + E)**2\n            P1 = (1. - (B + 4.*G*R1)/(1. - D)**4)\n        else:\n            D = -NTU1/8.\n            G = (1. - D)**2*(D**2 + E**2) + D**2*(1. + E)**2\n            P1 = (1. - (B + 4.*G*R1)/(1. - D)**4)\n        P1 = P1/R1_orig # switch 3, confirmed\n    else:\n        raise Exception('Supported numbers of tube passes are 1 and 2.')\n    return P1", "response": "r Returns a temperature effectiveness P1 of a TEMA H type heat exchanger  \n    with a specified heat capacity ratio NTU1 and number of transfer units Ntp."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef temperature_effectiveness_plate(R1, NTU1, Np1, Np2, counterflow=True, \n                                    passes_counterflow=True, reverse=False):\n    r'''Returns the temperature effectiveness `P1` of side 1 of a plate heat \n    exchanger with a specified side 1 heat capacity ratio `R1`, side 1 number\n    of transfer units `NTU1`, number of passes on sides 1 and 2 (respectively\n    `Np1` and `Np2`). \n        \n    For all cases, the function also takes as arguments whether the exchanger \n    is setup in an overall counter or parallel orientation `counterflow`, and \n    whether or not individual stream passes are themselves counterflow or\n    parallel. \n    \n    The 20 supported cases are as follows. (the first number of sides listed\n    refers to side 1, and the second number refers to side 2):\n        \n    * 1 pass/1 pass parallelflow\n    * 1 pass/1 pass counterflow\n    * 1 pass/2 pass\n    * 1 pass/3 pass or 3 pass/1 pass (with the two end passes in parallel)\n    * 1 pass/3 pass or 3 pass/1 pass (with the two end passes in counterflow)\n    * 1 pass/4 pass \n    * 2 pass/2 pass, overall parallelflow, individual passes in parallel \n    * 2 pass/2 pass, overall parallelflow, individual passes counterflow\n    * 2 pass/2 pass, overall counterflow, individual passes parallelflow \n    * 2 pass/2 pass, overall counterflow, individual passes counterflow \n    * 2 pass/3 pass or 3 pass/2 pass, overall parallelflow \n    * 2 pass/3 pass or 3 pass/2 pass, overall counterflow\n    * 2 pass/4 pass or 4 pass/2 pass, overall parallel flow\n    * 2 pass/4 pass or 4 pass/2 pass, overall counterflow flow\n    \n    For all plate heat exchangers, there are two common formulas used by most\n    of the expressions.\n    \n    .. math::\n        P_p(x, y) = \\frac{1 - \\exp[-x(1 + y)]}{1 + y}\n        \n        P_c(x, y) = \\frac{1 - \\exp[-x(1 - y)]}{1 - y\\exp[-x(1 - y)]}\n        \n    The main formulas used are as follows. Note that for some cases such as\n    4 pass/2 pass, the formula is not shown because it is that of 2 pass/4 \n    pass, but with R1, NTU1, and P1 conversions.\n        \n    For 1 pass/1 pass paralleflow (streams symmetric):\n        \n    .. math::\n        P_1 = P_p(NTU_1, R_1)\n        \n    For 1 pass/1 pass counterflow (streams symmetric):\n    \n    .. math::\n        P_1 = P_c(NTU_1, R_1)\n            \n    For 1 pass/2 pass (any of the four possible configurations):\n        \n    .. math::\n        P_1 = 0.5(A + B - 0.5ABR_1)\n        \n        A = P_p(NTU_1, 0.5R_1)\n        \n        B = P_c(NTU_1, 0.5R_1)\n        \n    For 1 pass/3 pass (with the two end passes in parallel):\n        \n    .. math::\n        P_1 = \\frac{1}{3}\\left[B + A\\left(1 - \\frac{R_1 B}{3}\\right)\\left(2 \n        - \\frac{R_1 A}{3}\\right)\\right]\n        \n        A = P_p\\left(NTU_1, \\frac{R_1}{3}\\right)\n        \n        B = P_c\\left(NTU_1, \\frac{R_1}{3}\\right)\n        \n    For 1 pass/3 pass (with the two end passes in counterflow):\n        \n    .. math::\n        P_1 = \\frac{1}{3}\\left[A + B\\left(1 - \\frac{R_1 A}{3}\\right)\\left(2\n        - \\frac{R_1 B}{3}\\right)\\right]\n            \n        A = P_p\\left(NTU_1, \\frac{R_1}{3}\\right)\n        \n        B = P_c\\left(NTU_1, \\frac{R_1}{3}\\right)\n        \n    For 1 pass/4 pass (any of the four possible configurations):\n    \n    .. math::\n        P_1 = \\frac{1-Q}{R_1}\n        \n        Q = \\left(1 - \\frac{AR_1}{4}\\right)^2\\left(1 - \\frac{BR_1}{4}\\right)^2\n        \n        A = P_p\\left(NTU_1, \\frac{R_1}{4}\\right)\n        \n        B = P_c\\left(NTU_1, \\frac{R_1}{4}\\right)\n        \n    For 2 pass/2 pass, overall parallelflow, individual passes in parallel \n    (stream symmetric):\n        \n    .. math::\n        P_1 = P_p(NTU_1, R_1)\n        \n    For 2 pass/2 pass, overall parallelflow, individual passes counterflow\n    (stream symmetric):\n        \n    .. math::\n        P_1 = B[2 - B(1 + R_1)]\n        \n        B = P_c\\left(\\frac{NTU_1}{2}, R_1\\right)\n        \n    For 2 pass/2 pass, overall counterflow, individual passes parallelflow \n    (stream symmetric):\n        \n    .. math::\n        P_1 = \\frac{2A - A^2(1 + R_1)}{1 - R_1 A^2}\n        \n        A = P_p\\left(\\frac{NTU_1}{2}, R_1\\right)\n        \n    For 2 pass/2 pass, overall counterflow and individual passes counterflow \n    (stream symmetric):\n        \n    .. math::\n        P_1 = P_c(NTU_1, R_1)\n        \n    For 2 pass/3 pass, overall parallelflow:\n        \n    .. math::\n        P_1 = A + B - \\left(\\frac{2}{9} + \\frac{D}{3}\\right)\n        (A^2 + B^2) - \\left(\\frac{5}{9} + \\frac{4D}{3}\\right)AB\n        + \\frac{D(1+D)AB(A+B)}{3} - \\frac{D^2A^2B^2}{9}\n        \n        A = P_p\\left(\\frac{NTU_1}{2}, D\\right)\n        \n        B = P_c\\left(\\frac{NTU_1}{2}, D\\right)\n        \n        D = \\frac{2R_1}{3}\n        \n    For 2 pass/3 pass, overall counterflow:\n        \n    .. math::\n        P_1 = \\frac{A + 0.5B + 0.5C + D}{R_1}\n        \n        A = \\frac{2R_1 EF^2 - 2EF + F - F^2}\n        {2R_1 E^2 F^2 - E^2 - F^2 - 2EF + E + F}\n        \n        B = \\frac{A(E-1)}{F}\n        \n        C = \\frac{1 - A}{E}\n        \n        D = R_1 E^2 C - R_1 E + R_1 - \\frac{C}{2}\n        \n        E = \\frac{3}{2R_1 G}\n        \n        F = \\frac{3}{2R_1 H}\n        \n        G = P_c\\left(\\frac{NTU_1}{2}, \\frac{2R_1}{3}\\right)\n        \n        H = P_p\\left(\\frac{NTU_1}{2}, \\frac{2R_1}{3}\\right)\n        \n    For 2 pass/4 pass, overall parallel flow:\n        \n    .. math::\n        P_1 = 2D - (1 + R_1)D^2\n        \n        D = \\frac{A + B - 0.5ABR_1}{2}\n        \n        A = P_p\\left(\\frac{NTU_1}{2}, \\frac{R_1}{2}\\right)\n        \n        B = P_c\\left(\\frac{NTU_1}{2}, \\frac{R_1}{2}\\right)\n        \n    For 2 pass/4 pass, overall counterflow flow:\n        \n    .. math::\n        P_1 = \\frac{2D - (1+R_1)D^2}{1 - D^2 R_1}\n        \n        D = \\frac{A + B - 0.5ABR_1}{2}\n        \n        A = P_p\\left(\\frac{NTU_1}{2}, \\frac{R_1}{2}\\right)\n        \n        B = P_c\\left(\\frac{NTU_1}{2}, \\frac{R_1}{2}\\right)\n                \n    Parameters\n    ----------\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 [-]\n    Np1 : int\n        Number of passes on side 1 [-]\n    Np2 : int\n        Number of passes on side 2 [-]\n    counterflow : bool\n        Whether or not the overall flow through the heat exchanger is in\n        counterflow or parallel flow, [-]\n    passes_counterflow : bool\n        In addition to the overall flow direction, in some cases individual \n        passes may be in counter or parallel flow; this controlls that [-]\n    reverse : bool\n        Used **internally only** to allow cases like the 1-4 formula to work  \n        for the 4-1 flow case, without having to duplicate the code [-]\n\n    Returns\n    -------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n\n    Notes\n    -----\n    For diagrams of these heat exchangers, see [3]_.\n    In all cases, each pass is assumed to be made up of an infinite number\n    of plates. The fluid velocities must be uniform across the plate channels,\n    and the flow must be uniformly distributed between the channels. The heat\n    transfer coefficient is also assumed constant.\n    \n    The defaults of counterflow=True and passes_counterflow=True will always\n    result in the most efficient heat exchanger option, normally what is\n    desired.\n    \n    If a number of passes which is not supported is provided, an exception is\n    raised.\n\n    Examples\n    --------\n    Three passes on side 1; one pass on side 2; two end passes in counterflow\n    orientation.\n    \n    >>> temperature_effectiveness_plate(R1=1/3., NTU1=1., Np1=3, Np2=1)\n    0.5743514352720835\n    \n    If the same heat exchanger (in terms of NTU1 and R1) were operating with\n    sides 1 and 2 switched, a slightly less efficient design results.\n    \n    >>> temperature_effectiveness_plate(R1=1/3., NTU1=1., Np1=1, Np2=3)\n    0.5718726757657066\n    \n    References\n    ----------\n    .. [1] Shah, Ramesh K., and Dusan P. Sekulic. Fundamentals of Heat \n       Exchanger Design. 1st edition. Hoboken, NJ: Wiley, 2002.\n    .. [2] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [3] Kandlikar, S. G., and R. K. Shah. \"Asymptotic Effectiveness-NTU \n       Formulas for Multipass Plate Heat Exchangers.\" Journal of Heat Transfer \n       111, no. 2 (May 1, 1989): 314-21. doi:10.1115/1.3250679.\n    .. [4] Kandlikar, S. G., and R. K. Shah. \"Multipass Plate Heat Exchangers\n       Effectiveness-NTU Results and Guidelines for Selecting Pass \n       Arrangements.\" Journal of Heat Transfer 111, no. 2 (May 1, 1989): \n       300-313. doi:10.1115/1.3250678.   \n    '''\n    if Np1 == 1 and Np2 == 1 and counterflow:\n        return Pc(NTU1, R1)\n    elif Np1 == 1 and Np2 == 1 and not counterflow:\n        return Pp(NTU1, R1)\n    elif Np1 == 1 and Np2 == 2:\n        # There are four configurations but all have the same formula\n        # They do behave different depending on the number of available plates\n        # but this model assues infinity\n        # There are four more arrangements that are equivalent as well\n        A = Pp(NTU1, 0.5*R1)\n        B = Pc(NTU1, 0.5*R1)\n        return 0.5*(A + B - 0.5*A*B*R1)\n    elif Np1 == 1 and Np2 == 3 and counterflow:\n        # There are six configurations, two formulas\n        # Each behaves differently though as a function of number of plates\n        A = Pp(NTU1, R1/3.)\n        B = Pc(NTU1, R1/3.)\n        return 1/3.*(A + B*(1. - R1*A/3.)*(2. - R1*B/3.))\n    elif Np1 == 1 and Np2 == 3 and not counterflow:\n        A = Pp(NTU1, R1/3.)\n        B = Pc(NTU1, R1/3.)\n        return 1/3.*(B + A*(1. - R1*B/3.)*(2. - R1*A/3.))\n    elif Np1 == 1 and Np2 == 4:\n        # four configurations\n        # Again a function of number of plates, but because expressions assume\n        # infinity it gets ignored and they're the same\n        A = Pp(NTU1, 0.25*R1)\n        B = Pc(NTU1, 0.25*R1)\n        t1 = (1. - 0.25*A*R1)\n        t2 = (1. - 0.25*B*R1)\n        t3 = t1*t2 # minor optimization\n        return (1. - t3*t3)/R1\n    elif Np1 == 2 and Np2 == 2:\n        if counterflow and passes_counterflow:\n            return Pc(NTU1, R1)\n        elif counterflow and not passes_counterflow:\n            A = Pp(0.5*NTU1, R1)\n            return (2.*A - A*A*(1. + R1))/(1. - R1*A*A)\n        elif not counterflow and passes_counterflow:\n            B = Pc(0.5*NTU1, R1)\n            return B*(2. - B*(1. + R1))\n        elif not counterflow and not passes_counterflow:\n            return temperature_effectiveness_plate(R1, NTU1, Np1=1, Np2=1, \n                                                   counterflow=False)\n    elif Np1 == 2 and Np2 == 3:\n        # One place says there are four configurations; no other discussion is\n        # presented\n        if counterflow:\n            H = Pp(0.5*NTU1, 2./3.*R1)\n            G = Pc(0.5*NTU1, 2./3.*R1)\n            E = 1./(2./3.*R1*G)\n            F = 1./(2./3.*R1*H)\n            E2 = E*E\n            F2 = F*F\n            A = (2.*R1*E*F2 - 2.*E*F + F - F2)/(2.*R1*E2*F2 - E2 - F2 - 2.*E*F + E + F)\n            C = (1. - A)/E\n            D = R1*E*E*C - R1*E + R1 - 0.5*C\n            B = A*(E - 1.)/F\n            return (A + 0.5*B + 0.5*C + D)/R1\n        elif not counterflow:\n            D = 2*R1/3.\n            A = Pp(NTU1/2, D)\n            B = Pc(NTU1/2, D)\n            return (A + B - (2/9. + D/3.)*(A*A + B*B)\n                    -(5./9. + 4./3.*D)*A*B\n                    + D*(1. + D)*A*B*(A + B)/3.\n                    - D*D*A*A*B*B/9.)\n    elif Np1 == 2 and Np2 == 4:\n        # Both cases are correct for passes_counterflow=True or False\n        if counterflow:\n            A = Pp(0.5*NTU1, 0.5*R1)\n            B = Pc(0.5*NTU1, 0.5*R1)\n            D = 0.5*(A + B - 0.5*A*B*R1)\n            return (2.*D - (1. + R1)*D*D)/(1. - D*D*R1)\n        elif not counterflow:\n            A = Pp(0.5*NTU1, 0.5*R1)\n            B = Pc(0.5*NTU1, 0.5*R1)\n            D = 0.5*(A + B - 0.5*A*B*R1)\n            return 2.*D - ((1. + R1)*D*D)\n    if not reverse:\n        # only the assymetric cases will be able to solve by flipping things\n        # Note that asymmetric performs differently depending on the arguments\n        # The user still needs to input R1, NTU1 for side 1\n        # so if they want to do a 3-1 instead of a 1-3 as is implemented here\n        # They give R1 and NTU1 for \"3 pass\" side instead of the \"1 pass\" side \n        # and will get back P1 for the \"3 pass\" side.\n        R2 = 1./R1\n        NTU2 = NTU1*R1\n        P2 = temperature_effectiveness_plate(R1=R2, NTU1=NTU2, Np1=Np2, Np2=Np1,\n                                             counterflow=counterflow, \n                                             passes_counterflow=passes_counterflow, \n                                             reverse=True)\n        P1 = P2*R2\n        return P1\n    \n    raise Exception('Supported number of passes does not have a formula available')", "response": "r Returns the temperature effectiveness P1 of a given number of transfer units NTU1 and Np1 and Np2 of a plate heat exchanger."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, **kwargs):\n    '''Private function to solve the P-NTU method backwards, given the\n    function to use, the upper and lower NTU bounds for consideration,\n    and the desired P1 and R1 values.\n    '''\n    P1_max = _NTU_from_P_objective(NTU_max, R1, 0, function, **kwargs)\n    P1_min = _NTU_from_P_objective(NTU_min, R1, 0, function, **kwargs)\n    if P1 > P1_max:\n        raise ValueError('No solution possible gives such a high P1; maximum P1=%f at NTU1=%f' %(P1_max, NTU_max))\n    if P1 < P1_min:\n        raise ValueError('No solution possible gives such a low P1; minimum P1=%f at NTU1=%f' %(P1_min, NTU_min))\n    # Construct the function as a lambda expression as solvers don't support kwargs\n    to_solve = lambda NTU1: _NTU_from_P_objective(NTU1, R1, P1, function, **kwargs)\n    return ridder(to_solve, NTU_min, NTU_max)", "response": "Private function to solve the P - NTU method backwards given the upper and lower NTU bounds for consideration P1 and R1 values."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _NTU_max_for_P_solver(data, R1):\n    '''Private function to calculate the upper bound on the NTU1 value in the\n    P-NTU method. This value is calculated via a pade approximation obtained\n    on the result of a global minimizer which calculated the maximum P1\n    at a given R1 from ~1E-7 to approximately 100. This should suffice for \n    engineering applications. This value is needed to bound the solver.\n    '''\n    offset_max = data['offset'][-1]\n    for offset, p, q in zip(data['offset'], data['p'], data['q']):\n        if R1 < offset or offset == offset_max:\n            x = R1 - offset\n            return _horner(p, x)/_horner(q, x)", "response": "Private function to calculate the upper bound on the NTU1 value in the P - NTU method."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef NTU_from_P_basic(P1, R1, subtype='crossflow'):\n    r'''Returns the number of transfer units of a basic heat exchanger type\n    with a specified (for side 1) thermal effectiveness `P1`, and heat capacity \n    ratio `R1`. The supported cases are as follows:\n        \n    * Counterflow (ex. double-pipe) [analytical]\n    * Parallel (ex. double pipe inefficient configuration) [analytical]\n    * Crossflow, single pass, fluids unmixed [numerical]\n    * Crossflow, single pass, fluid 1 mixed, fluid 2 unmixed [analytical]\n    * Crossflow, single pass, fluid 2 mixed, fluid 1 unmixed [analytical]\n    * Crossflow, single pass, both fluids mixed [numerical]\n    \n    The analytical solutions, for those cases they are available, are as \n    follows:\n        \n    Counterflow:\n        \n    .. math::\n        NTU_1 = - \\frac{1}{R_{1} - 1} \\log{\\left (\\frac{P_{1} R_{1} - 1}{P_{1} \n        - 1} \\right )}\n    \n    Parallel:\n    \n    .. math::\n        NTU_1 = \\frac{1}{R_{1} + 1} \\log{\\left (- \\frac{1}{P_{1} \\left(R_{1} \n        + 1\\right) - 1} \\right )}\n    \n    Crossflow, single pass, fluid 1 mixed, fluid 2 unmixed:\n        \n    .. math::\n        NTU_1 = - \\frac{1}{R_{1}} \\log{\\left (R_{1} \\log{\\left (- \\left(P_{1}\n        - 1\\right) e^{\\frac{1}{R_{1}}} \\right )} \\right )}\n    \n    Crossflow, single pass, fluid 2 mixed, fluid 1 unmixed\n    \n    .. math::\n        NTU_1 = - \\log{\\left (\\frac{1}{R_{1}} \\log{\\left (- \\left(P_{1} R_{1}\n        - 1\\right) e^{R_{1}} \\right )} \\right )}\n    \n    Parameters\n    ----------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    subtype : float\n        The type of heat exchanger; one of 'counterflow', 'parallel', \n        'crossflow', 'crossflow approximate', 'crossflow, mixed 1', \n        'crossflow, mixed 2', 'crossflow, mixed 1&2'.\n        \n    Returns\n    -------\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 [-]\n\n    Notes\n    -----\n    Although this function allows the thermal effectiveness desired to be\n    specified, it does not mean such a high value can be obtained. An exception\n    is raised when this occurs, although not always a helpful one.\n    \n    >>> NTU_from_P_basic(P1=.99, R1=.1, subtype='parallel')\n    Traceback (most recent call last):\n    ValueError: math domain error\n            \n    For the 'crossflow approximate' solution the function is monotonic, and a\n    bounded solver is used within the range of NTU1 from 1E-11 to 1E5. \n    \n    For the full correct 'crossflow' solution, the initial guess for newton's\n    method is obtained by the 'crossflow approximate' solution; the function\n    may not converge because of inaccuracy performing the numerical integral \n    involved.\n\n    For the 'crossflow, mixed 1&2' solution, a bounded solver is first use, but\n    the upper bound on P1 and the upper NTU1 limit is calculated from a pade\n    approximation performed with mpmath. \n\n    Examples\n    --------\n    >>> NTU_from_P_basic(P1=.975, R1=.1, subtype='counterflow')\n    3.984769850376482\n    '''\n    NTU_min = 1E-11\n    function = temperature_effectiveness_basic\n    if subtype == 'counterflow':\n        return -log((P1*R1 - 1.)/(P1 - 1.))/(R1 - 1.)\n    elif subtype == 'parallel':\n        return log(-1./(P1*(R1 + 1.) - 1.))/(R1 + 1.)\n    elif subtype == 'crossflow, mixed 1':\n        return -log(R1*log(-(P1 - 1.)*exp(1./R1)))/R1\n    elif subtype == 'crossflow, mixed 2':\n        return -log(log(-(P1*R1 - 1.)*exp(R1))/R1)\n    elif subtype == 'crossflow, mixed 1&2':\n        NTU_max = _NTU_max_for_P_solver(NTU_from_P_basic_crossflow_mixed_12, R1)        \n    elif subtype == 'crossflow approximate':\n        # These are tricky but also easy because P1 can always be 1\n        NTU_max = 1E5\n    elif subtype == 'crossflow':\n        guess = NTU_from_P_basic(P1, R1, subtype='crossflow approximate')\n        to_solve = lambda NTU1 : _NTU_from_P_objective(NTU1, R1, P1, function, subtype='crossflow')\n        return newton(to_solve, guess)\n    else:\n        raise Exception('Subtype not recognized.')\n    return _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, subtype=subtype)", "response": "r Returns the number of transfer units of a basic heat exchanger type with a specified thermal effectiveness P1 and heat capacity \n    ratio R1."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef NTU_from_P_G(P1, R1, Ntp, optimal=True):\n    r'''Returns the number of transfer units of a TEMA G type heat exchanger\n    with a specified (for side 1) thermal effectiveness `P1`, heat capacity \n    ratio `R1`, the number of tube passes `Ntp`, and for the two-pass case\n    whether or not the inlets are arranged optimally. The supported cases are \n    as follows:\n        \n    * One tube pass (tube fluid split into two streams individually mixed,  \n      shell fluid mixed)\n    * Two tube passes (shell and tube exchanger with shell and tube fluids  \n      mixed in each pass at the cross section), counterflow arrangement\n    * Two tube passes (shell and tube exchanger with shell and tube fluids  \n      mixed in each pass at the cross section), parallelflow arrangement\n                \n    Parameters\n    ----------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (shell side = 1, tube side = 2) [-]\n    Ntp : int\n        Number of tube passes, 1 or 2 [-]\n    optimal : bool, optional\n        Whether or not the arrangement is configured to give more of a\n        countercurrent and efficient (True) case or an inefficient parallel\n        case (only applies for two passes), [-]\n\n    Returns\n    -------\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (shell side = 1, tube side\n        = 2) [-]\n\n    Notes\n    -----\n    For numbers of tube passes greater than 1 or 2, an exception is raised.\n    \n    Although this function allows the thermal effectiveness desired to be\n    specified, it does not mean such a high value can be obtained. An exception\n    is raised which shows the maximum possible effectiveness obtainable at the\n    specified `R1` and configuration.\n    \n    >>> NTU_from_P_G(P1=1, R1=1/3., Ntp=2)\n    Traceback (most recent call last):\n    ValueError: No solution possible gives such a high P1; maximum P1=0.954545 at NTU1=10000.000000\n    \n    Of the three configurations, 1 pass and the optimal 2 pass have monotonic \n    functions which allow for a bounded solver to work smoothly. In both cases\n    a solution is searched for between NTU1 values of 1E-11 and 1E-4.\n    \n    For the 2 pass unoptimal solution, a bounded solver is first use, but\n    the upper bound on P1 and the upper NTU1 limit is calculated from a pade\n    approximation performed with mpmath. \n\n    Examples\n    --------\n    >>> NTU_from_P_G(P1=.573, R1=1/3., Ntp=1)\n    0.9999513707769526\n    '''\n    NTU_min = 1E-11\n    function = temperature_effectiveness_TEMA_G\n    if Ntp == 1 or (Ntp == 2 and optimal):\n        NTU_max = 1E4\n        # We could fit a curve to determine the NTU where the floating point\n        # does not allow NTU to increase though, but that would be another\n        # binary bisection process, different from the current pipeline\n    elif Ntp == 2 and not optimal:\n        NTU_max = _NTU_max_for_P_solver(NTU_from_G_2_unoptimal, R1)\n    else:\n        raise Exception('Supported numbers of tube passes are 1 or 2.')\n    return _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, Ntp=Ntp, optimal=optimal)", "response": "r Returns the number of transfer units of a TEMA G type heat exchanger with a specified thermal effectiveness P1 heat capacity ratio R1 and number of tube passes Ntp."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef NTU_from_P_J(P1, R1, Ntp):\n    r'''Returns the number of transfer units of a TEMA J type heat exchanger\n    with a specified (for side 1) thermal effectiveness `P1`, heat capacity \n    ratio `R1`, and the number of tube passes `Ntp`. The supported cases are \n    as follows:\n        \n    * One tube pass (shell fluid mixed)\n    * Two tube passes (shell fluid mixed, tube pass mixed between passes)\n    * Four tube passes (shell fluid mixed, tube pass mixed between passes)\n    \n    Parameters\n    ----------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (shell side = 1, tube side = 2) [-]\n    Ntp : int\n        Number of tube passes, 1, 2, or 4, [-]\n        \n    Returns\n    -------\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (shell side = 1, tube side\n        = 2) [-]\n\n    Notes\n    -----\n    For numbers of tube passes that are not 1, 2, or 4, an exception is raised.\n    \n    For the 1 tube pass case, a bounded solver is used to solve the equation\n    numerically, with NTU1 ranging from 1E-11 to 1E3. NTU1 grows extremely\n    quickly near its upper limit (NTU1 diverges to infinity at this maximum, \n    but because the solver is bounded it will only increase up to 1000 before\n    an exception is raised).\n        \n    >>> NTU_from_P_J(P1=.995024, R1=.01, Ntp=1)\n    13.940758760696617\n    >>> NTU_from_P_J(P1=.99502487562188, R1=.01, Ntp=1)\n    536.4817955951684\n    >>> NTU_from_P_J(P1=.99502487562189, R1=.01, Ntp=1)\n    Traceback (most recent call last):\n    ValueError: No solution possible gives such a high P1; maximum P1=0.995025 at NTU1=1000.000000\n    \n    For the 2 pass and 4 pass solution, a bounded solver is first use, but\n    the upper bound on P1 and the upper NTU1 limit is calculated from a pade\n    approximation performed with mpmath. These normally do not allow NTU1 to \n    rise above 100.\n\n    Examples\n    --------\n    >>> NTU_from_P_J(P1=.57, R1=1/3., Ntp=1)\n    1.0003070138879648\n    '''\n    NTU_min = 1E-11\n    function = temperature_effectiveness_TEMA_J\n    if Ntp == 1:\n        # Very often failes because at NTU=1000, there is no variation in P1\n        # for instance at NTU=40, P1 already peaked and does not decline with\n        # higher NTU\n        NTU_max = 1E3\n        # We could fit a curve to determine the NTU where the floating point\n        # does not allow NTU to increase though, but that would be another\n        # binary bisection process, different from the current pipeline\n    elif Ntp == 2:\n        NTU_max = _NTU_max_for_P_solver(NTU_from_P_J_2, R1)\n    elif Ntp == 4:\n        NTU_max = _NTU_max_for_P_solver(NTU_from_P_J_4, R1)\n    else:\n        raise Exception('Supported numbers of tube passes are 1, 2, and 4.')\n    return _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, Ntp=Ntp)", "response": "r Returns the number of transfer units of a TEMA J type heat exchanger with a specified thermal effectiveness P1 heat capacity ratio R1 and number of tube passes Ntp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef NTU_from_P_E(P1, R1, Ntp, optimal=True):\n    r'''Returns the number of transfer units of a TEMA E type heat exchanger\n    with a specified (for side 1) thermal effectiveness `P1`, heat capacity \n    ratio `R1`, the number of tube passes `Ntp`, and for the two-pass case\n    whether or not the inlets are arranged optimally. The supported cases are \n    as follows:\n        \n    * 1-1 TEMA E, shell fluid mixed\n    * 1-2 TEMA E, shell fluid mixed (this configuration is symmetric)\n    * 1-2 TEMA E, shell fluid split into two steams individually mixed\n    * 1-3 TEMA E, shell and tube fluids mixed, one parallel pass and two \n      counterflow passes (efficient)\n    * 1-3 TEMA E, shell and tube fluids mixed, two parallel passes and one \n      counteflow pass (inefficient)\n    * 1-N TEMA E, shall and tube fluids mixed, efficient counterflow \n      orientation, N an even number\n      \n    Two of these cases have analytical solutions; the rest use numerical \n    solvers of varying quality.\n    \n    The analytical solution to 1-1 TEMA E, shell fluid mixed (the same as pure\n    counterflow):\n        \n    .. math::\n        NTU_1 = - \\frac{1}{R_{1} - 1} \\log{\\left (\\frac{P_{1} R_{1} - 1}{P_{1} \n        - 1} \\right )}\n    \n    1-2 TEMA E, shell fluid mixed:\n        \n    .. math::\n        NTU_1 = \\frac{2}{\\sqrt{R_{1}^{2} + 1}} \\log{\\left (\\sqrt{\\frac{P_{1} \n        R_{1} - P_{1} \\sqrt{R_{1}^{2} + 1} + P_{1} - 2}{P_{1} R_{1} + P_{1} \n        \\sqrt{R_{1}^{2} + 1} + P_{1} - 2}} \\right )}\n        \n    Parameters\n    ----------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 (shell side = 1, tube side = 2) [-]\n    Ntp : int\n        Number of tube passes, 1, 2, 3, 4, or an even number [-]\n    optimal : bool, optional\n        Whether or not the arrangement is configured to give more of a\n        countercurrent and efficient (True) case or an inefficient parallel\n        case, [-]\n\n    Returns\n    -------\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 (shell side = 1, tube side\n        = 2) [-]\n\n    Notes\n    -----\n    For odd numbers of tube passes greater than 3, an exception is raised. \n    \n    For the 2 pass, unoptimal case, a bounded solver is used with NTU1 between\n    1E-11 and 100; the solution to any feasible P1 was found to lie in there.\n    For the 4 or a higher even number of pass case, the upper limit on NTU1\n    is 1000; this solver works pretty well, but as NTU1 reaches its limit the\n    change in P1 is so small a smaller but also correct solution is often \n    returned.\n    \n    For both the optimal and unoptimal 3 tube pass case, a solution is only\n    returned if NTU1 is between 1E-11 and 10. These functions are extremely\n    mathematically frustrating, and as NTU1 rises above 10 catastrophic \n    cancellation quickly results in this expression finding a ZeroDivisionError.\n    The use of arbitrary prevision helps little - quickly 1000 digits are needed,\n    and then 1000000 digits, and so one. Using SymPy's rational number support\n    works better but is extremely slow for these complicated solutions.\n    Nevertheless, so long as a solution is between 1E-11 and 10, the solver is\n    quite robust.\n\n    Examples\n    --------\n    >>> NTU_from_P_E(P1=.58, R1=1/3., Ntp=2)\n    1.0381979240816719\n\n    '''\n    NTU_min = 1E-11\n    function = temperature_effectiveness_TEMA_E\n    if Ntp == 1:\n        return NTU_from_P_basic(P1, R1, subtype='counterflow')\n    elif Ntp == 2 and optimal:\n        # Nice analytical solution is available\n        # There are actualy two roots but one of them is complex\n        x1 = R1*R1 + 1.\n        return 2.*log(((P1*R1 - P1*x1**0.5 + P1 - 2.)/(P1*R1 + P1*x1**0.5 + P1 - 2.))**0.5)*(x1)**-.5\n    elif Ntp == 2 and not optimal:\n        NTU_max = 1E2 \n        # Can't find anywhere it needs to go above 70 to reach the maximum\n    elif Ntp == 3 and optimal:\n        # no pade could be found, just about the worst-conditioned problem\n        # I've ever found\n        # Higher starting values result in errors\n        NTU_max = 10\n    elif Ntp == 3 and not optimal:\n        # no pade could be found, just about the worst-conditioned problem\n        # I've ever found\n        NTU_max = 10\n    elif Ntp == 4 or Ntp %2 == 0:\n        NTU_max = 1E3\n    else:\n        raise Exception('For TEMA E shells with an odd number of tube passes more than 3, no solution is implemented.')\n    return _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, Ntp=Ntp, optimal=optimal)", "response": "r Returns the number of transfer units of a given thermal effectiveness P1 heat capacity ratio R1 and number of tube passes Ntp."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef NTU_from_P_plate(P1, R1, Np1, Np2, counterflow=True, \n                     passes_counterflow=True, reverse=False):\n    r'''Returns the number of transfer units of a plate heat exchanger\n    with a specified side 1 heat capacity ratio `R1`, side 1 number\n    of transfer units `NTU1`, number of passes on sides 1 and 2 (respectively\n    `Np1` and `Np2`). \n            \n    For all cases, the function also takes as arguments whether the exchanger \n    is setup in an overall counter or parallel orientation `counterflow`, and \n    whether or not individual stream passes are themselves counterflow or\n    parallel. \n    \n    The 20 supported cases are as follows. (the first number of sides listed\n    refers to side 1, and the second number refers to side 2):\n        \n    * 1 pass/1 pass parallelflow\n    * 1 pass/1 pass counterflow\n    * 1 pass/2 pass\n    * 1 pass/3 pass or 3 pass/1 pass (with the two end passes in parallel)\n    * 1 pass/3 pass or 3 pass/1 pass (with the two end passes in counterflow)\n    * 1 pass/4 pass \n    * 2 pass/2 pass, overall parallelflow, individual passes in parallel \n    * 2 pass/2 pass, overall parallelflow, individual passes counterflow\n    * 2 pass/2 pass, overall counterflow, individual passes parallelflow \n    * 2 pass/2 pass, overall counterflow, individual passes counterflow \n    * 2 pass/3 pass or 3 pass/2 pass, overall parallelflow \n    * 2 pass/3 pass or 3 pass/2 pass, overall counterflow\n    * 2 pass/4 pass or 4 pass/2 pass, overall parallel flow\n    * 2 pass/4 pass or 4 pass/2 pass, overall counterflow flow\n    \n    For all except the simplest cases numerical solutions are used.\n    \n    1 pass/1 pass counterflow (also 2/2 fully counterflow):\n    \n    .. math::\n        NTU_1 = - \\frac{1}{R_{1} - 1} \\log{\\left (\\frac{P_{1} R_{1} - 1}{P_{1} \n        - 1} \\right )}\n    \n    1 pass/1 pass parallel flow (also 2/2 fully parallelflow):\n    \n    .. math::\n        NTU_1 = \\frac{1}{R_{1} + 1} \\log{\\left (- \\frac{1}{P_{1} \\left(R_{1} \n        + 1\\right) - 1} \\right )}\n                \n    Parameters\n    ----------\n    P1 : float\n        Thermal effectiveness of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    R1 : float\n        Heat capacity ratio of the heat exchanger in the P-NTU method,\n        calculated with respect to stream 1 [-]\n    Np1 : int\n        Number of passes on side 1 [-]\n    Np2 : int\n        Number of passes on side 2 [-]\n    counterflow : bool\n        Whether or not the overall flow through the heat exchanger is in\n        counterflow or parallel flow, [-]\n    passes_counterflow : bool\n        In addition to the overall flow direction, in some cases individual \n        passes may be in counter or parallel flow; this controlls that [-]\n    reverse : bool\n        Used **internally only** to allow cases like the 1-4 formula to work  \n        for the 4-1 flow case, without having to duplicate the code [-]\n\n    Returns\n    -------\n    NTU1 : float\n        Thermal number of transfer units of the heat exchanger in the P-NTU \n        method, calculated with respect to stream 1 [-]\n\n    Notes\n    -----\n    The defaults of counterflow=True and passes_counterflow=True will always\n    result in the most efficient heat exchanger option, normally what is\n    desired.\n    \n    If a number of passes which is not supported is provided, an exception is\n    raised.\n    \n    For more details, see :obj:`temperature_effectiveness_plate`.\n\n    Examples\n    --------\n    Three passes on side 1; one pass on side 2; two end passes in counterflow\n    orientation.\n    \n    >>> NTU_from_P_plate(P1=0.5743, R1=1/3., Np1=3, Np2=1)\n    0.9998336056060733\n    '''\n    NTU_min = 1E-11\n    function = temperature_effectiveness_plate\n    if Np1 == 1 and Np2 == 1 and counterflow:\n        try:\n            return -log((P1*R1 - 1.)/(P1 - 1.))/(R1 - 1.)\n        except ValueError:\n            raise ValueError('The maximum P1 obtainable at the specified R1 is %f at the limit of NTU1=inf.' %(1./R1))\n        \n    elif Np1 == 1 and Np2 == 1 and not counterflow:\n        try:\n            return log(-1./(P1*(R1 + 1.) - 1.))/(R1 + 1.)\n        except ValueError:\n            raise ValueError('The maximum P1 obtainable at the specified R1 is %f at the limit of NTU1=inf.' %Pp(1E10, R1))\n    elif Np1 == 1 and Np2 == 2:\n        NTU_max = 100.\n    elif Np1 == 1 and Np2 == 3 and counterflow:\n        NTU_max = 100.\n    elif Np1 == 1 and Np2 == 3 and not counterflow:\n        NTU_max = 100.\n    elif Np1 == 1 and Np2 == 4:\n        NTU_max = 100.\n    elif Np1 == 2 and Np2 == 2:\n        if counterflow and passes_counterflow:\n            return NTU_from_P_plate(P1, R1, Np1=1, Np2=1, counterflow=True, \n                                    passes_counterflow=True)\n        elif counterflow and not passes_counterflow:\n            NTU_max = 100\n        elif not counterflow and passes_counterflow:\n            NTU_max = _NTU_max_for_P_solver(NTU_from_plate_2_2_parallel_counterflow, R1)\n        elif not counterflow and not passes_counterflow:\n            return NTU_from_P_plate(P1, R1, Np1=1, Np2=1, counterflow=False, \n                                    passes_counterflow=False)\n    elif Np1 == 2 and Np2 == 3:\n        if counterflow:\n            NTU_max = 100\n        elif not counterflow:\n            NTU_max = _NTU_max_for_P_solver(NTU_from_plate_2_3_parallel, R1)\n    elif Np1 == 2 and Np2 == 4:\n        if counterflow:\n            NTU_max = 100\n        elif not counterflow:\n            NTU_max = _NTU_max_for_P_solver(NTU_from_plate_2_4_parallel, R1)\n    elif not reverse:\n        # Proved to work by example\n        P2 = P1*R1\n        R2 = 1./R1\n        NTU2 = NTU_from_P_plate(R1=R2, P1=P2, Np1=Np2, Np2=Np1,\n                                counterflow=counterflow, \n                                passes_counterflow=passes_counterflow, \n                                reverse=True)\n        NTU1 = NTU2/R1\n        return NTU1\n    else:\n        raise Exception('Supported number of passes does not have a formula available')\n    return _NTU_from_P_solver(P1, R1, NTU_min, NTU_max, function, Np1=Np1, \n                              Np2=Np2, counterflow=counterflow, \n                              passes_counterflow=passes_counterflow)", "response": "r Returns the number of transfer units of a given plate with a specified number of heat capacity ratio R1 and number of passes Np1 and Np2."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef F_LMTD_Fakheri(Thi, Tho, Tci, Tco, shells=1):\n    r'''Calculates the log-mean temperature difference correction factor `Ft` \n    for a shell-and-tube heat exchanger with one or an even number of tube \n    passes, and a given number of shell passes, with the expression given in \n    [1]_ and also shown in [2]_.\n    \n    .. math::\n        F_t=\\frac{S\\ln W}{\\ln \\frac{1+W-S+SW}{1+W+S-SW}}\n\n        S = \\frac{\\sqrt{R^2+1}}{R-1}\n        \n        W = \\left(\\frac{1-PR}{1-P}\\right)^{1/N}\n        \n        R = \\frac{T_{in}-T_{out}}{t_{out}-t_{in}}\n        \n        P = \\frac{t_{out}-t_{in}}{T_{in}-t_{in}}\n        \n    If R = 1 and logarithms cannot be evaluated:\n        \n    .. math::\n        W' = \\frac{N-NP}{N-NP+P}\n        \n        F_t = \\frac{\\sqrt{2}\\frac{1-W'}{W'}}{\\ln\\frac{\\frac{W'}{1-W'}+\\frac{1}\n        {\\sqrt{2}}}{\\frac{W'}{1-W'}-\\frac{1}{\\sqrt{2}}}}\n        \n    Parameters\n    ----------\n    Thi : float\n        Inlet temperature of hot fluid, [K]\n    Tho : float\n        Outlet temperature of hot fluid, [K]\n    Tci : float\n        Inlet temperature of cold fluid, [K]\n    Tco : float\n        Outlet temperature of cold fluid, [K]        \n    shells : int, optional\n        Number of shell-side passes, [-]\n\n    Returns\n    -------\n    Ft : float\n        Log-mean temperature difference correction factor, [-]\n\n    Notes\n    -----\n    This expression is symmetric - the same result is calculated if the cold\n    side values are swapped with the hot side values. It also does not \n    depend on the units of the temperature given.\n\n    Examples\n    --------\n    >>> F_LMTD_Fakheri(Tci=15, Tco=85, Thi=130, Tho=110, shells=1)\n    0.9438358829645933\n\n    References\n    ----------\n    .. [1] Fakheri, Ahmad. \"A General Expression for the Determination of the \n       Log Mean Temperature Correction Factor for Shell and Tube Heat \n       Exchangers.\" Journal of Heat Transfer 125, no. 3 (May 20, 2003): 527-30.\n       doi:10.1115/1.1571078.\n    .. [2] Hall, Stephen. Rules of Thumb for Chemical Engineers, Fifth Edition.\n       Oxford; Waltham, MA: Butterworth-Heinemann, 2012.\n    '''\n    R = (Thi - Tho)/(Tco - Tci)\n    P = (Tco - Tci)/(Thi - Tci)\n    if R == 1.0:\n        W2 = (shells - shells*P)/(shells - shells*P + P)\n        return (2**0.5*(1. - W2)/W2)/log(((W2/(1. - W2) + 2**-0.5)/(W2/(1. - W2) - 2**-0.5)))\n    else:\n        W = ((1. - P*R)/(1. - P))**(1./shells)\n        S = (R*R + 1.)**0.5/(R - 1.)\n        return S*log(W)/log((1. + W - S + S*W)/(1. + W + S - S*W))", "response": "r Returns the log - mean temperature difference correction factor Ft for a given hot fluid and tube and shell - and - tube."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a Tubing element is in TEMA format.", "response": "def check_tubing_TEMA(NPS=None, BWG=None):\n    '''\n    >>> check_tubing_TEMA(2, 22)\n    False\n    >>> check_tubing_TEMA(0.375, 22)\n    True\n    '''\n    if NPS in TEMA_tubing:\n        if BWG in TEMA_tubing[NPS]:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef shell_clearance(DBundle=None, DShell=None):\n    r'''Looks up the recommended clearance between a shell and tube bundle in \n    a TEMA HX [1]. Either the bundle diameter or the shell diameter are needed \n    provided.\n\n    Parameters\n    ----------\n    DBundle : float, optional\n        Outer diameter of tube bundle, [m]\n    DShell : float, optional\n        Shell inner diameter, [m]\n\n    Returns\n    -------\n    c : float\n        Shell-tube bundle clearance, [m]\n\n    Notes\n    -----\n    Lower limits are extended up to the next limit where intermediate limits\n    are not provided. \n    \n    Examples\n    --------\n    >>> shell_clearance(DBundle=1.245)\n    0.0064\n\n    References\n    ----------\n    .. [1] Standards of the Tubular Exchanger Manufacturers Association,\n       Ninth edition, 2007, TEMA, New York.\n    '''\n    DShell_data = [(0.457, 0.0032), (1.016, 0.0048), (1.397, 0.0064),\n                   (1.778, 0.0079), (2.159, 0.0095)]\n    DBundle_data = [(0.457 - 0.0048, 0.0032), (1.016 - 0.0064, 0.0048),\n                    (1.397 - 0.0079, 0.0064), (1.778 - 0.0095, 0.0079),\n                    (2.159 - 0.011, 0.0095)]\n    if DShell:\n        for DShell_tabulated, c in DShell_data:\n            if DShell < DShell_tabulated:\n                return c\n        return 0.011\n    elif DBundle:\n        for DBundle_tabulated, c in DBundle_data:\n            if DBundle < DBundle_tabulated:\n                return c\n        return 0.011\n    else:\n        raise Exception('Either DShell or DBundle must be specified')", "response": "r Returns the recommended clearance between two shells and tube bundles in a single object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef L_unsupported_max(Do, material='CS'):\n    r'''Determines the maximum length of a heat exchanger tube can go without\n    a support, acording to TEMA [1]_. The limits provided apply for the \n    worst-case temperature allowed for the material to be used at.\n\n    Parameters\n    ----------\n    Do : float\n        Outer tube diameter, [m]\n    material : str\n        Material type, either 'CS' or 'aluminium', [-]\n\n    Returns\n    -------\n    L_unsupported : float\n        Maximum length of unsupported tube, [m]\n\n    Notes\n    -----\n    The 'CS' results is also listed as representing high alloy steel, low \n    alloy steel, nickel-copper, nickel, and nickel-chromium-iron alloys.\n    The 'aluminium' results are those of copper and copper alloys and\n    also titanium alloys.\n    \n    The maximum and minimum tube outer diameter tabulated are 3 inch and 1/4  \n    inch respectively. The result is returned for the nearest tube diameter\n    equal or smaller than the provided diameter, which helps ensures the \n    returned tube length will not be optimistic. However, if the diameter is \n    under 0.25 inches, the result will be optimistic!\n    \n    \n    Examples\n    --------\n    >>> L_unsupported_max(Do=.0254, material='CS')\n    1.88\n\n    References\n    ----------\n    .. [1] Standards of the Tubular Exchanger Manufacturers Association,\n       Ninth edition, 2007, TEMA, New York, p 5.4-5.\n    '''\n    Do = Do/inch # convert diameter to inches\n    i = bisect(_L_unsupported_Do, Do)-1\n    i = i if i < 11 else 11 # bisect returns 1+ if above the index\n    i = 0 if i == -1 else i\n    if material == 'CS':\n        return _L_unsupported_steel[i]\n    elif material == 'aluminium':\n        return _L_unsupported_aluminium[i]\n    else:\n        raise Exception('Material argument should be one of \"CS\" or \"aluminium\"')", "response": "r Returns the maximum length of a tube that can be used at a given temperature."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Ntubes_Phadkeb(DBundle, Do, pitch, Ntp, angle=30):\n    r'''Using tabulated values and correction factors for number of passes,\n    the highly accurate method of [1]_ is used to obtain the tube count\n    of a given tube bundle outer diameter for a given tube size and pitch.\n\n    Parameters\n    ----------\n    DBundle : float\n        Outer diameter of tube bundle, [m]\n    Do : float\n        Tube outer diameter, [m]\n    pitch : float\n        Pitch; distance between two orthogonal tube centers, [m]\n    Ntp : int\n        Number of tube passes, [-]\n    angle : float, optional\n        The angle the tubes are positioned; 30, 45, 60 or 90, [degrees]\n\n    Returns\n    -------\n    Nt : int\n        Total number of tubes that fit in the heat exchanger, [-]\n\n    Notes\n    -----\n    For single-pass cases, the result is exact, and no tubes need to be removed\n    for any reason. For 4, 6, 8 pass arrangements, a number of tubes must be \n    removed to accomodate pass partition plates. The following assumptions\n    are involved with that:\n        * The pass partition plate is where a row of tubes would have been. \n          Only one or two rows are assumed affected.\n        * The thickness of partition plate is < 70% of the tube outer diameter.\n        * The distance between the centerline of the partition plate and the \n          centerline of the nearest row of tubes is equal to the pitch.    \n    \n    This function will fail when there are more than 100,000 tubes.\n    [1]_ tabulated values up to approximately 3,000 tubes derived with \n    number theory. The sequesnces of integers were identified in the\n    On-Line Encyclopedia of Integer Sequences (OEIS), and formulas listed in\n    it were used to generate more coefficient to allow up to 100,000 tubes.\n    The integer sequences are A003136, A038590, A001481, and A057961. The \n    generation of coefficients for A038590 is very slow, but the rest are\n    reasonably fast.\n    \n    The number of tubes that fit generally does not increase one-by-one, but by\n    several.\n    \n    >>> Ntubes_Phadkeb(DBundle=1.007, Do=.028, pitch=.036, Ntp=2, angle=45.)\n    558\n    >>> Ntubes_Phadkeb(DBundle=1.008, Do=.028, pitch=.036, Ntp=2, angle=45.)\n    574\n    \n    Because a pass partition needs to be installed in multiple tube pass\n    shells, more tubes fit in an exchanger the fewer passes are used.\n    \n    >>> Ntubes_Phadkeb(DBundle=1.008, Do=.028, pitch=.036, Ntp=1, angle=45.)\n    593\n\n    Examples\n    --------\n    >>> Ntubes_Phadkeb(DBundle=1.200-.008*2, Do=.028, pitch=.036, Ntp=2, angle=45.)\n    782\n\n    References\n    ----------\n    .. [1] Phadke, P. S., Determining tube counts for shell and tube\n       exchangers, Chem. Eng., September, 91, 65-68 (1984).\n    '''\n    if DBundle <= Do*Ntp:\n        return 0\n    \n    if Ntp == 6:\n        e = 0.265\n    elif Ntp == 8:\n        e = 0.404\n    else:\n        e = 0.\n\n    r = 0.5*(DBundle - Do)/pitch\n    s = r*r\n    Ns, Nr = floor(s), floor(r)\n    # If Ns is between two numbers, take the smaller one\n    # C1 is the number of tubes for a single pass arrangement.\n    if angle == 30 or angle == 60:\n        i = np.searchsorted(triangular_Ns, Ns, side='right')\n        C1 = int(triangular_C1s[i-1])\n    elif angle == 45 or angle == 90:\n        i = np.searchsorted(square_Ns, Ns, side='right')\n        C1 = int(square_C1s[i-1])\n\n    Cx = 2*Nr + 1.\n\n    # triangular and rotated triangular\n    if (angle == 30 or angle == 60):\n        w = 2*r/3**0.5\n        Nw = floor(w)\n        if Nw % 2 == 0:\n            Cy = 3*Nw\n        else:\n            Cy = 3*Nw + 1\n        if Ntp == 2:\n            if angle == 30 :\n                C2 = C1 - Cx\n            else:\n                C2 = C1 - Cy - 1\n        else: # 4 passes, or 8; this value is needed\n            C4 = C1 - Cx - Cy\n\n    if (angle == 30 or angle == 60) and (Ntp == 6 or Ntp == 8):\n        if angle == 30: # triangular\n            v = 2*e*r/3**0.5 + 0.5\n            Nv = floor(v)\n            u = 3**0.5*Nv/2.\n            if Nv % 2 == 0:\n                z = (s-u*u)**0.5\n            else:\n                z = (s-u*u)**0.5 - 0.5\n            Nz = floor(z)\n            if Ntp == 6:\n                C6 = C1 - Cy - 4*Nz - 1\n            else:\n                C8 = C4 - 4*Nz\n        else: # rotated triangular\n            v = 2.*e*r\n            Nv = floor(v)\n            u1 = 0.5*Nv\n            z = (s - u1*u1)**0.5\n            w1 = 2*z/2**0.5\n#            w1 = 2**2**0.5 # WRONG\n            u2 = 0.5*(Nv + 1)\n            zs = (s-u2*u2)**0.5\n            w2 = 2.*zs/3**0.5\n            if Nv%2 == 0:\n                z1 = 0.5*w1\n                z2 = 0.5*(w2+1)\n            else:\n                z1 = 0.5*(w1+1)\n                z2 = 0.5*w2\n            Nz1 = floor(z1)\n            Nz2 = floor(z2)\n            if Ntp == 6:\n                C6 = C1 - Cx - 4.*(Nz1 + Nz2)\n            else: # 8\n                C8 = C4 - 4.*(Nz1 + Nz2)\n\n    if (angle == 45 or angle == 90):\n        if angle == 90:\n            Cy = Cx - 1.\n            # eq 6 or 8 for c2 or c4\n            if Ntp == 2:\n                C2 = C1 - Cx\n            else: # 4 passes, or 8; this value is needed\n                C4 = C1 - Cx - Cy\n        else: # rotated square\n            w = r/2**0.5\n            Nw = floor(w)\n            Cx = 2.*Nw + 1\n            Cy = Cx - 1\n            if Ntp == 2:\n                C2 = C1 - Cx\n            else: # 4 passes, or 8; this value is needed\n                C4 = C1 - Cx - Cy\n\n    if (angle == 45 or angle == 90) and (Ntp == 6 or Ntp == 8):\n        if angle == 90:\n            v = e*r + 0.5\n            Nv = floor(v)\n            z = (s - Nv*Nv)**0.5\n            Nz = floor(z)\n            if Ntp == 6:\n                C6 = C1 - Cy - 4*Nz - 1\n            else:\n                C8 = C4 - 4*Nz\n        else:\n            w = r/2**0.5\n            Nw = floor(w)\n            Cx = 2*Nw + 1\n\n            v = 2**0.5*e*r\n            Nv = floor(v)\n            u1 = Nv/2**0.5\n            z = (s-u1*u1)**0.5\n            w1 = 2**0.5*z\n            u2 = (Nv + 1)/2**0.5\n            zs = (s-u2*u2)**0.5\n            w2 = 2**0.5*zs\n            # if Nv is odd, 21a and 22a. If even, 21b and 22b. Nz1, Nz2\n            if Nv %2 == 0:\n                z1 = 0.5*w1\n                z2 = 0.5*(w2 + 1)\n            else:\n                z1 = 0.5*(w1 + 1)\n                z2 = 0.5*w2\n            Nz1 = floor(z1)\n            Nz2 = floor(z2)\n            if Ntp == 6:\n                C6 = C1 - Cx - 4*(Nz1 + Nz2)\n            else: # 8\n                C8 = C4 - 4*(Nz1 + Nz2)\n\n    if Ntp == 1:\n        ans = C1\n    elif Ntp == 2:\n        ans = C2\n    elif Ntp == 4:\n        ans = C4\n    elif Ntp == 6:\n        ans = C6\n    elif Ntp == 8:\n        ans = C8\n    else:\n        raise Exception('Only 1, 2, 4, 6, or 8 tube passes are supported')\n    ans = int(ans)\n    # In some cases, a negative number would be returned by these formulas\n    if ans < 0:\n        ans = 0 # pragma: no cover\n    return ans", "response": "r Returns a count of tubes that fit in a given tube bundle with given outer diameter pitch and number of tubes Ntp and angle."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Ntubes_HEDH(DBundle=None, Do=None, pitch=None, angle=30):\n    r'''A rough equation presented in the HEDH for estimating\n    the number of tubes in a tube bundle of differing geometries and tube\n    sizes. No accuracy estimation given. Only 1 pass is supported.\n\n    .. math::\n        N = \\frac{0.78(D_{bundle} - D_o)^2}{C_1(\\text{pitch})^2}\n        \n    C1 = 0.866 for 30\u00b0 and 60\u00b0 layouts, and 1 for 45 and 90\u00b0 layouts.\n        \n    Parameters\n    ----------\n    DBundle : float\n        Outer diameter of tube bundle, [m]\n    Do : float\n        Tube outer diameter, [m]\n    pitch : float\n        Pitch; distance between two orthogonal tube centers, [m]\n    angle : float\n        The angle the tubes are positioned; 30, 45, 60 or 90, [degrees]\n\n    Returns\n    -------\n    N : float\n        Number of tubes, [-]\n\n    Notes\n    -----\n    Seems reasonably accurate.\n\n    Examples\n    --------\n    >>> Ntubes_HEDH(DBundle=1.184, Do=.028, pitch=.036, angle=30)\n    928\n\n    References\n    ----------\n    .. [1] Schlunder, Ernst U, and International Center for Heat and Mass\n       Transfer. Heat Exchanger Design Handbook. Washington:\n       Hemisphere Pub. Corp., 1983.\n    '''\n    if angle == 30 or angle == 60:\n        C1 = 13/15.\n    elif angle == 45 or angle == 90:\n        C1 = 1.\n    else:\n        raise Exception('Only 30, 60, 45 and 90 degree layouts are supported')\n    Dctl = DBundle - Do\n    N = 0.78*Dctl**2/C1/pitch**2\n    return int(N)", "response": "r A rough equation presented in the HEDH for estimating\n    the number of tubes in a tube bundle of differing geometries and tube sizes and tube sizes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DBundle_for_Ntubes_HEDH(N, Do, pitch, angle=30):\n    r'''A rough equation presented in the HEDH for estimating the tube bundle\n    diameter necessary to fit a given number of tubes. \n    No accuracy estimation given. Only 1 pass is supported.\n\n    .. math::\n        D_{bundle} = (D_o + (\\text{pitch})\\sqrt{\\frac{1}{0.78}}\\cdot\n        \\sqrt{C_1\\cdot N})\n\n\n    C1 = 0.866 for 30\u00b0 and 60\u00b0 layouts, and 1 for 45 and 90\u00b0 layouts.\n\n    Parameters\n    ----------\n    N : float\n        Number of tubes, [-]\n    Do : float\n        Tube outer diameter, [m]\n    pitch : float\n        Pitch; distance between two orthogonal tube centers, [m]\n    angle : float\n        The angle the tubes are positioned; 30, 45, 60 or 90, [degrees]\n\n    Returns\n    -------\n    DBundle : float\n        Outer diameter of tube bundle, [m]\n\n    Notes\n    -----\n    Easily reversed from the main formulation.\n\n    Examples\n    --------\n    >>> DBundle_for_Ntubes_HEDH(N=928, Do=.028, pitch=.036, angle=30)\n    1.1839930795640605\n\n    References\n    ----------\n    .. [1] Schlunder, Ernst U, and International Center for Heat and Mass\n       Transfer. Heat Exchanger Design Handbook. Washington:\n       Hemisphere Pub. Corp., 1983.\n    '''\n    if angle == 30 or angle == 60:\n        C1 = 13/15.\n    elif angle == 45 or angle == 90:\n        C1 = 1.\n    else:\n        raise Exception('Only 30, 60, 45 and 90 degree layouts are supported')\n    return (Do + (1./.78)**0.5*pitch*(C1*N)**0.5)", "response": "r A rough equation presented in the HEDH for estimating the tube bundle for a given number of tubes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ASHRAE_k(ID):\n    r'''Returns thermal conductivity of a building or insulating material\n    from a table in [1]_. Thermal conductivity is independent of temperature\n    here. Many entries in the table are listed for varying densities, but the\n    appropriate ID from the table must be selected to account for that.\n\n    Parameters\n    ----------\n    ID : str\n        ID corresponding to a material in the dictionary `ASHRAE`\n\n    Returns\n    -------\n    k : float\n        Thermal conductivity of the material, [W/m/K]\n\n    Examples\n    --------\n    >>> ASHRAE_k(ID='Mineral fiber')\n    0.036\n\n    References\n    ----------\n    .. [1] ASHRAE Handbook: Fundamentals. American Society of Heating,\n       Refrigerating and Air-Conditioning Engineers, Incorporated, 2013.\n    '''\n    values = ASHRAE[ID]\n    if values[2]:\n        return values[2]\n    else:\n        R = values[3]\n        t = values[4]/1000. # mm to m\n        return R_to_k(R, t)", "response": "A function to get the thermal conductivity of a material in ASHRAE."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nearest_material(name, complete=False):\n    r'''Returns the nearest hit to a given name from from dictionaries of\n    building, insulating, or refractory material from tables in [1]_, [2]_,\n    and [3]_. Function will pick the closest match based on a fuzzy search.\n    if `complete` is True, will only return hits with all three of density,\n    heat capacity, and thermal conductivity available.\n\n    Parameters\n    ----------\n    name : str\n        Search keywords to be used by difflib function\n    complete : bool, optional\n        If True, returns only hits with all parameters available\n\n    Returns\n    -------\n    ID : str\n        A key to one of the dictionaries mentioned above\n\n    Examples\n    --------\n    >>> nearest_material('stainless steel')\n    'Metals, stainless steel'\n\n    References\n    ----------\n    .. [1] ASHRAE Handbook: Fundamentals. American Society of Heating,\n       Refrigerating and Air-Conditioning Engineers, Incorporated, 2013.\n    .. [2] DIN EN 12524 (2000-07) Building Materials and Products\n       Hygrothermal Properties - Tabulated Design Values; English Version of\n       DIN EN 12524.\n    .. [3] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    if complete:\n        hits = difflib.get_close_matches(name, materials_dict.keys(), n=1000, cutoff=0)\n        for hit in hits:\n            if materials_dict[hit] == 1 or materials_dict[hit]==3 or (ASHRAE[hit][0] and ASHRAE[hit][1]):\n                return hit\n    else:\n        ID = difflib.get_close_matches(name, materials_dict.keys(), n=1, cutoff=0.6)\n        if not ID:\n            ID = difflib.get_close_matches(name, materials_dict.keys(), n=1, cutoff=0.3)\n        if not ID:\n            ID = difflib.get_close_matches(name, materials_dict.keys(), n=1, cutoff=0)\n        return ID[0]", "response": "r Returns the nearest hit to a given name from the given dictionary of ASHRAE building insulating or refractory material."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef k_material(ID, T=298.15):\n    r'''Returns thermal conductivity of a building, insulating, or refractory\n    material from tables  in [1]_, [2]_, and [3]_. Thermal conductivity may or\n    may not be dependent on temperature depending on the source used. Function\n    must be provided with either a key to one of the dictionaries\n    `refractories`, `ASHRAE`, or `building_materials` - or a search term which\n    will pick the closest match based on a fuzzy search. To determine which\n    source the fuzzy search will pick, use the function `nearest_material`.\n    Fuzzy searches are slow; it is preferable to call this function with a\n    material key directly.\n\n    Parameters\n    ----------\n    ID : str\n        String as described above\n    T : float, optional\n        Temperature of the material, [K]\n\n    Returns\n    -------\n    k : float\n        Thermal conductivity of the material, [W/m/K]\n\n    Examples\n    --------\n    >>> k_material('Mineral fiber')\n    0.036\n\n    References\n    ----------\n    .. [1] ASHRAE Handbook: Fundamentals. American Society of Heating,\n       Refrigerating and Air-Conditioning Engineers, Incorporated, 2013.\n    .. [2] DIN EN 12524 (2000-07) Building Materials and Products\n       Hygrothermal Properties - Tabulated Design Values; English Version of\n       DIN EN 12524.\n    .. [3] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    if ID not in materials_dict:\n        ID = nearest_material(ID)\n    if ID in refractories:\n        return refractory_VDI_k(ID, T)\n    elif ID in ASHRAE:\n        return ASHRAE_k(ID)\n    else:\n        return float(building_materials[ID][1])", "response": "r Returns thermal conductivity of a single material in the system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rho_material(ID):\n    r'''Returns the density of a building, insulating, or refractory\n    material from tables  in [1]_, [2]_, and [3]_. No temperature dependence is\n    available. Function must be provided with either a key to one of the\n    dictionaries `refractories`, `ASHRAE`, or `building_materials` - or a\n    search term which will pick the closest match based on a fuzzy search. To\n    determine which source the fuzzy search will pick, use the function\n    `nearest_material`. Fuzzy searches are slow; it is preferable to call this\n    function with a material key directly.\n\n    Parameters\n    ----------\n    ID : str\n        String as described above\n\n    Returns\n    -------\n    rho : float\n        Density of the material, [kg/m^3]\n\n    Examples\n    --------\n    >>> rho_material('Board, Asbestos/cement')\n    1900.0\n\n    References\n    ----------\n    .. [1] ASHRAE Handbook: Fundamentals. American Society of Heating,\n       Refrigerating and Air-Conditioning Engineers, Incorporated, 2013.\n    .. [2] DIN EN 12524 (2000-07) Building Materials and Products\n       Hygrothermal Properties - Tabulated Design Values; English Version of\n       DIN EN 12524.\n    .. [3] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    if ID not in materials_dict:\n        ID = nearest_material(ID)\n    if ID in refractories:\n        rho = float(refractories[ID][0]) # Density available for all hits\n    elif ID in building_materials:\n        rho = float(building_materials[ID][0]) # Density available for all hits\n    else:\n        rho = ASHRAE[ID][0]\n        if rho is None:\n            raise Exception('Density is not available for this material')\n        else:\n            rho = float(rho)\n    return rho", "response": "r Returns the density of a single material in the ASHRAE or ASHRAE tables in ASHRAE tables in ASHRAE and ASHRAE tables in ASHRAE and ASHRAE tables in ASHRAE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Cp_material(ID, T=298.15):\n    r'''Returns heat capacity of a building, insulating, or refractory\n    material from tables  in [1]_, [2]_, and [3]_. Heat capacity may or\n    may not be dependent on temperature depending on the source used. Function\n    must be provided with either a key to one of the dictionaries\n    `refractories`, `ASHRAE`, or `building_materials` - or a search term which\n    will pick the closest match based on a fuzzy search. To determine which\n    source the fuzzy search will pick, use the function `nearest_material`.\n    Fuzzy searches are slow; it is preferable to call this function with a\n    material key directly.\n\n    Parameters\n    ----------\n    ID : str\n        String as described above\n    T : float, optional\n        Temperature of the material, [K]\n\n    Returns\n    -------\n    Cp : float\n        Heat capacity of the material, [W/m/K]\n\n    Examples\n    --------\n    >>> Cp_material('Mineral fiber')\n    840.0\n\n    References\n    ----------\n    .. [1] ASHRAE Handbook: Fundamentals. American Society of Heating,\n       Refrigerating and Air-Conditioning Engineers, Incorporated, 2013.\n    .. [2] DIN EN 12524 (2000-07) Building Materials and Products\n       Hygrothermal Properties - Tabulated Design Values; English Version of\n       DIN EN 12524.\n    .. [3] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    if ID not in materials_dict:\n        ID = nearest_material(ID)\n    if ID in refractories:\n        Cp = refractory_VDI_Cp(ID, T)\n    elif ID in building_materials:\n        Cp = float(building_materials[ID][2]) # Density available for all hits\n    else:\n        Cp = ASHRAE[ID][1]\n        if Cp is None:\n            raise Exception('Heat capacity is not available for this material')\n        else:\n            Cp = float(Cp)\n    return Cp", "response": "r Returns the heat capacity of a single material in the system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Sun_Mishima(m, D, rhol, rhog, mul, kl, Hvap, sigma, q=None, Te=None):\n    r'''Calculates heat transfer coefficient for film boiling of saturated\n    fluid in any orientation of flow. Correlation\n    is as shown in [1]_, and also reviewed in [2]_ and [3]_.\n    \n    Either the heat flux or excess temperature is required for the calculation\n    of heat transfer coefficient. Uses liquid-only Reynolds number, Weber\n    number, and Boiling number. Weber number is defined in terms of the velocity\n    if all fluid were liquid.\n\n    .. math::\n        h_{tp} = \\frac{ 6 Re_{lo}^{1.05} Bg^{0.54}}\n        {We_l^{0.191}(\\rho_l/\\rho_g)^{0.142}}\\frac{k_l}{D}\n        \n        Re_{lo} = \\frac{G_{tp}D}{\\mu_l}\n    \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Hvap : float\n        Heat of vaporization of liquid [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    q : float, optional\n        Heat flux to wall [W/m^2]\n    Te : float, optional\n        Excess temperature of wall, [K]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    [1]_ has been reviewed. \n    \n    [1]_ used 2501 data points to derive the results, covering \n    hydraulic diameters from 0.21 to 6.05 mm and 11 different fluids.\n    \n\n    Examples\n    --------\n    >>> Sun_Mishima(m=1, D=0.3, rhol=567., rhog=18.09, kl=0.086, mul=156E-6, sigma=0.02, Hvap=9E5, Te=10)\n    507.6709168372167\n\n    References\n    ----------\n    .. [1] Sun, Licheng, and Kaichiro Mishima. \"An Evaluation of Prediction \n       Methods for Saturated Flow Boiling Heat Transfer in Mini-Channels.\" \n       International Journal of Heat and Mass Transfer 52, no. 23-24 (November \n       2009): 5323-29. doi:10.1016/j.ijheatmasstransfer.2009.06.041.\n    .. [2] Fang, Xiande, Zhanru Zhou, and Dingkun Li. \"Review of Correlations \n       of Flow Boiling Heat Transfer Coefficients for Carbon Dioxide.\"\n       International Journal of Refrigeration 36, no. 8 (December 2013): \n       2017-39. doi:10.1016/j.ijrefrig.2013.05.015.\n    '''\n    G = m/(pi/4*D**2)\n    V = G/rhol\n    Relo = G*D/mul\n    We = Weber(V=V, L=D, rho=rhol, sigma=sigma)\n    if q:\n        Bg = Boiling(G=G, q=q, Hvap=Hvap)\n        return 6*Relo**1.05*Bg**0.54/(We**0.191*(rhol/rhog)**0.142)*kl/D\n    elif Te:\n        A = 6*Relo**1.05/(We**0.191*(rhol/rhog)**0.142)*kl/D\n        return A**(50/23.)*Te**(27/23.)/(G**(27/23.)*Hvap**(27/23.))\n    else:\n        raise Exception('Either q or Te is needed for this correlation')", "response": "r Calculates the Sun Mishima of the given fluid in any orientation of flow."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Thome(m, x, D, rhol, rhog, mul, mug, kl, kg, Cpl, Cpg, Hvap, sigma, Psat, \n          Pc, q=None, Te=None):\n    r'''Calculates heat transfer coefficient for film boiling of saturated\n    fluid in any orientation of flow. Correlation\n    is as developed in [1]_ and [2]_, and also reviewed [3]_. This is a \n    complicated model, but expected to have more accuracy as a result.\n    \n    Either the heat flux or excess temperature is required for the calculation\n    of heat transfer coefficient. The solution for a specified excess \n    temperature is solved numerically, making it slow.\n    \n    .. math::\n        h(z) = \\frac{t_l}{\\tau} h_l(z) +\\frac{t_{film}}{\\tau} h_{film}(z) \n        +  \\frac{t_{dry}}{\\tau} h_{g}(z) \n    \n        h_{l/g}(z) = (Nu_{lam}^4 + Nu_{trans}^4)^{1/4} k/D\n        \n        Nu_{laminar} = 0.91 {Pr}^{1/3} \\sqrt{ReD/L(z)}\n        \n        Nu_{trans} = \\frac{ (f/8) (Re-1000)Pr}{1+12.7 (f/8)^{1/2} (Pr^{2/3}-1)}\n        \\left[ 1 + \\left( \\frac{D}{L(z)}\\right)^{2/3}\\right]\n        \n        f = (1.82 \\log_{10} Re - 1.64 )^{-2}\n        \n        L_l = \\frac{\\tau G_{tp}}{\\rho_l}(1-x)\n        \n        L_{dry} = v_p t_{dry}\n        \n        t_l = \\frac{\\tau}{1 + \\frac{\\rho_l}{\\rho_g}\\frac{x}{1-x}}\n        \n        t_v = \\frac{\\tau}{1 + \\frac{\\rho_g}{\\rho_l}\\frac{1-x}{x}}\n        \n        \\tau = \\frac{1}{f_{opt}}\n        \n        f_{opt} = \\left(\\frac{q}{q_{ref}}\\right)^{n_f}\n        \n        q_{ref} = 3328\\left(\\frac{P_{sat}}{P_c}\\right)^{-0.5}\n        \n        t_{dry,film} = \\frac{\\rho_l \\Delta H_{vap}}{q}[\\delta_0(z) - \n        \\delta_{min}]\n        \n        \\frac{\\delta_0}{D} = C_{\\delta 0}\\left(3\\sqrt{\\frac{\\nu_l}{v_p D}}\n        \\right)^{0.84}\\left[(0.07Bo^{0.41})^{-8} + 0.1^{-8}\\right]^{-1/8}\n        \n        Bo = \\frac{\\rho_l D}{\\sigma} v_p^2\n        \n        v_p = G_{tp} \\left[\\frac{x}{\\rho_g} + \\frac{1-x}{\\rho_l}\\right]\n        \n        h_{film}(z) = \\frac{2 k_l}{\\delta_0(z) + \\delta_{min}(z)}\n        \n        \\delta_{min} = 0.3\\cdot 10^{-6} \\text{m}\n        \n        C_{\\delta,0} = 0.29\n        \n        n_f = 1.74\n        \n    if t dry film > tv:\n    \n    .. math::\n        \\delta_{end}(x) = \\delta(z, t_v)\n        \n        t_{film} = t_v\n        \n        t_{dry} = 0\n    \n    Otherwise:\n    \n    .. math::\n        \\delta_{end}(z) = \\delta_{min}\n        \n        t_{film} = t_{dry,film}\n        \n        t_{dry} = t_v - t_{film}\n    \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific tube interval []\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    kg : float\n        Thermal conductivity of gas [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    Cpg : float\n        Heat capacity of gas [J/kg/K]\n    Hvap : float\n        Heat of vaporization of liquid [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    Psat : float\n        Vapor pressure of fluid, [Pa]\n    Pc : float\n        Critical pressure of fluid, [Pa]\n    q : float, optional\n        Heat flux to wall [W/m^2]\n    Te : float, optional\n        Excess temperature of wall, [K]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    [1]_ and [2]_ have been reviewed, and are accurately reproduced in [3]_.\n    \n    [1]_ used data from 7 studies, covering 7 fluids and Dh from 0.7-3.1 mm, \n    heat flux from 0.5-17.8 W/cm^2, x from 0.01-0.99, and G from 50-564 \n    kg/m^2/s.\n    \n    Liquid and/or gas slugs are both considered, and are hydrodynamically\n    developing. `Ll` is the calculated length of liquid slugs, and `L_dry` \n    is the same for vapor slugs.\n    \n    Because of the complexity of the model and that there is some logic in this\n    function, `Te` as an input may lead to a different solution that the\n    calculated `q` will in return.\n    \n    Examples\n    --------\n    >>> Thome(m=1, x=0.4, D=0.3, rhol=567., rhog=18.09, kl=0.086, kg=0.2,\n    ... mul=156E-6, mug=1E-5, Cpl=2300, Cpg=1400, sigma=0.02, Hvap=9E5, \n    ... Psat=1E5, Pc=22E6, q=1E5)\n    1633.008836502032\n\n    References\n    ----------\n    .. [1] Thome, J. R., V. Dupont, and A. M. Jacobi. \"Heat Transfer Model for \n       Evaporation in Microchannels. Part I: Presentation of the Model.\" \n       International Journal of Heat and Mass Transfer 47, no. 14-16 (July \n       2004): 3375-85. doi:10.1016/j.ijheatmasstransfer.2004.01.006.\n    .. [2] Dupont, V., J. R. Thome, and A. M. Jacobi. \"Heat Transfer Model for \n       Evaporation in Microchannels. Part II: Comparison with the Database.\" \n       International Journal of Heat and Mass Transfer 47, no. 14-16 (July \n       2004): 3387-3401. doi:10.1016/j.ijheatmasstransfer.2004.01.007.\n    .. [3] Bertsch, Stefan S., Eckhard A. Groll, and Suresh V. Garimella. \n       \"Review and Comparative Analysis of Studies on Saturated Flow Boiling in\n       Small Channels.\" Nanoscale and Microscale Thermophysical Engineering 12,\n       no. 3 (September 4, 2008): 187-227. doi:10.1080/15567260802317357.\n    '''\n    if q is None and Te:\n        to_solve = lambda q : q/Thome(m=m, x=x, D=D, rhol=rhol, rhog=rhog, kl=kl, kg=kg, mul=mul, mug=mug, Cpl=Cpl, Cpg=Cpg, sigma=sigma, Hvap=Hvap, Psat=Psat, Pc=Pc, q=q) - Te\n        q = newton(to_solve, 1E4)\n        return Thome(m=m, x=x, D=D, rhol=rhol, rhog=rhog, kl=kl, kg=kg, mul=mul, mug=mug, Cpl=Cpl, Cpg=Cpg, sigma=sigma, Hvap=Hvap, Psat=Psat, Pc=Pc, q=q)\n    elif q is None and Te is None:\n        raise Exception('Either q or Te is needed for this correlation')\n    C_delta0 = 0.3E-6\n    G = m/(pi/4*D**2)\n    Rel = G*D*(1-x)/mul\n    Reg = G*D*x/mug\n    qref = 3328*(Psat/Pc)**-0.5\n    fopt = (q/qref)**1.74\n    tau = 1./fopt\n    \n    vp = G*(x/rhog + (1-x)/rhol)\n    Bo = rhol*D/sigma*vp**2 # Not standard definition\n    nul = nu_mu_converter(rho=rhol, mu=mul)\n    delta0 = D*0.29*(3*(nul/vp/D)**0.5)**0.84*((0.07*Bo**0.41)**-8 + 0.1**-8)**(-1/8.)\n    \n    tl = tau/(1 + rhol/rhog*(x/(1.-x)))\n    tv = tau/(1 ++ rhog/rhol*((1.-x)/x))\n\n    t_dry_film = rhol*Hvap/q*(delta0 - C_delta0)\n    if t_dry_film > tv:\n        t_film = tv\n        delta_end = delta0 - q/rhol/Hvap*tv # what could time possibly be?\n        t_dry = 0\n    else:\n        t_film = t_dry_film\n        delta_end = C_delta0\n        t_dry = tv-t_film\n    Ll = tau*G/rhol*(1-x)\n    Ldry = t_dry*vp\n\n\n    Prg = Prandtl(Cp=Cpg, k=kg, mu=mug)\n    Prl = Prandtl(Cp=Cpl, k=kl, mu=mul)\n    fg = (1.82*log10(Reg) - 1.64)**-2\n    fl = (1.82*log10(Rel) - 1.64)**-2\n    \n    Nu_lam_Zl = 2*0.455*(Prl)**(1/3.)*(D*Rel/Ll)**0.5\n    Nu_trans_Zl = turbulent_Gnielinski(Re=Rel, Pr=Prl, fd=fl)*(1 + (D/Ll)**(2/3.))\n    if Ldry == 0:\n        Nu_lam_Zg, Nu_trans_Zg = 0, 0\n    else:\n        Nu_lam_Zg = 2*0.455*(Prg)**(1/3.)*(D*Reg/Ldry)**0.5\n        Nu_trans_Zg = turbulent_Gnielinski(Re=Reg, Pr=Prg, fd=fg)*(1 + (D/Ldry)**(2/3.))\n        \n    h_Zg = kg/D*(Nu_lam_Zg**4 + Nu_trans_Zg**4)**0.25\n    h_Zl = kl/D*(Nu_lam_Zl**4 + Nu_trans_Zl**4)**0.25\n        \n    h_film = 2*kl/(delta0 + C_delta0)\n    return tl/tau*h_Zl + t_film/tau*h_film + t_dry/tau*h_Zg", "response": "r A simple Thome model that calculates the heat transfer coefficient for a given fluid in any orientation of flow."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Liu_Winterton(m, x, D, rhol, rhog, mul, kl, Cpl, MW, P,  Pc, Te):\n    r'''Calculates heat transfer coefficient for film boiling of saturated\n    fluid in any orientation of flow. Correlation\n    is as developed in [1]_, also reviewed in [2]_ and [3]_.\n    \n    Excess wall temperature is required to use this correlation.\n    \n    .. math::\n        h_{tp} = \\sqrt{ (F\\cdot h_l)^2 + (S\\cdot h_{nb})^2} \n        \n        S = \\left( 1+0.055F^{0.1} Re_{L}^{0.16}\\right)^{-1}\n        \n        h_{l} = 0.023 Re_L^{0.8} Pr_l^{0.4} k_l/D\n\n        Re_L = \\frac{GD}{\\mu_l}\n        \n        F = \\left[ 1+ xPr_{l}(\\rho_l/\\rho_g-1)\\right]^{0.35}\n        \n        h_{nb} = \\left(55\\Delta Te^{0.67} \\frac{P}{P_c}^{(0.12 - 0.2\\log_{10}\n         R_p)}(-\\log_{10} \\frac{P}{P_c})^{-0.55} MW^{-0.5}\\right)^{1/0.33}\n    \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific tube interval []\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    MW : float\n        Molecular weight of the fluid, [g/mol]\n    P : float\n        Pressure of fluid, [Pa]\n    Pc : float\n        Critical pressure of fluid, [Pa]\n    Te : float, optional\n        Excess temperature of wall, [K]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    [1]_ has been reviewed, and is accurately reproduced in [3]_.\n    \n    Uses the `Cooper` and `turbulent_Dittus_Boelter` correlations.\n    \n    A correction for horizontal flow at low Froude numbers is available in \n    [1]_ but has not been implemented and is not recommended in several \n    sources.\n    \n    Examples\n    --------\n    >>> Liu_Winterton(m=1, x=0.4, D=0.3, rhol=567., rhog=18.09, kl=0.086, \n    ... mul=156E-6, Cpl=2300, P=1E6, Pc=22E6, MW=44.02, Te=7)\n    4747.749477190532\n\n    References\n    ----------\n    .. [1] Liu, Z., and R. H. S. Winterton. \"A General Correlation for \n       Saturated and Subcooled Flow Boiling in Tubes and Annuli, Based on a \n       Nucleate Pool Boiling Equation.\" International Journal of Heat and Mass \n       Transfer 34, no. 11 (November 1991): 2759-66. \n       doi:10.1016/0017-9310(91)90234-6. \n    .. [2] Fang, Xiande, Zhanru Zhou, and Dingkun Li. \"Review of Correlations \n       of Flow Boiling Heat Transfer Coefficients for Carbon Dioxide.\" \n       International Journal of Refrigeration 36, no. 8 (December 2013): \n       2017-39. doi:10.1016/j.ijrefrig.2013.05.015.\n    .. [3] Bertsch, Stefan S., Eckhard A. Groll, and Suresh V. Garimella. \n       \"Review and Comparative Analysis of Studies on Saturated Flow Boiling in\n       Small Channels.\" Nanoscale and Microscale Thermophysical Engineering 12,\n       no. 3 (September 4, 2008): 187-227. doi:10.1080/15567260802317357.\n    '''\n    G = m/(pi/4*D**2)\n    ReL = D*G/mul\n    Prl = Prandtl(Cp=Cpl, mu=mul, k=kl)\n    hl = turbulent_Dittus_Boelter(Re=ReL, Pr=Prl)*kl/D\n    F = (1 + x*Prl*(rhol/rhog - 1))**0.35\n    S = (1 + 0.055*F**0.1*ReL**0.16)**-1\n#    if horizontal:\n#        Fr = Froude(V=G/rhol, L=D, squared=True)\n#        if Fr < 0.05:\n#            ef = Fr**(0.1 - 2*Fr)\n#            es = Fr**0.5\n#            F *= ef\n#            S *= es\n    h_nb = Cooper(Te=Te, P=P, Pc=Pc, MW=MW)\n    return ((F*hl)**2 + (S*h_nb)**2)**0.5", "response": "r Calculates the heat transfer coefficient for a given liquid in any orientation of flow."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef h_boiling_Amalfi(m, x, Dh, rhol, rhog, mul, mug, kl, Hvap, sigma, q, \n                     A_channel_flow, chevron_angle=45):\n    r'''Calculates the two-phase boiling heat transfer coefficient of a \n    liquid and gas flowing inside a plate and frame heat exchanger, as\n    developed in [1]_ from a wide range of existing correlations and data sets. \n    Expected to be the most accurate correlation currently available.\n\n    For Bond number < 4 (tiny channel case):\n        \n    .. math::\n        h= 982 \\left(\\frac{k_l}{D_h}\\right)\\left(\\frac{\\beta}{\\beta_{max}}\\right)^{1.101}\n        \\left(\\frac{G^2 D_h}{\\rho_m \\sigma}\\right)^{0.315}\n        \\left(\\frac{\\rho_l}{\\rho_g}\\right)^{-0.224} Bo^{0.320}\n        \n    For Bond number >= 4:\n        \n    .. math::\n        h = 18.495 \\left(\\frac{k_l}{D_h}\\right) \\left(\\frac{\\beta}{\\beta_{max}}\n        \\right)^{0.248}\\left(Re_g\\right)^{0.135}\\left(Re_{lo}\\right)^{0.351}\n        \\left(\\frac{\\rho_l}{\\rho_g}\\right)^{-0.223} Bd^{0.235} Bo^{0.198}\n        \n    In the above equations, beta max is 45 degrees; Bo is Boiling number;\n    and Bd is Bond number.\n    \n    Note that this model depends on the specific heat flux involved.\n            \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific point in the plate exchanger []\n    Dh : float\n        Hydraulic diameter of the plate, :math:`D_h = \\frac{4\\lambda}{\\phi}` [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of the liquid [Pa*s]\n    mug : float\n        Viscosity of the gas [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Hvap : float\n        Heat of vaporization of the fluid at the system pressure, [J/kg]\n    sigma : float\n        Surface tension of liquid [N/m]\n    q : float\n        Heat flux, [W/m^2]\n    A_channel_flow : float\n        The flow area for the fluid, calculated as \n        :math:`A_{ch} = 2\\cdot \\text{width} \\cdot \\text{amplitude}` [m]\n    chevron_angle : float, optional\n        Angle of the plate corrugations with respect to the vertical axis\n        (the direction of flow if the plates were straight), between 0 and\n        90. For exchangers with two angles, use the average value. [degrees]\n\n    Returns\n    -------\n    h : float\n        Boiling heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Heat transfer correlation developed from 1903 datum. Fluids included R134a, \n    ammonia, R236fa, R600a, R290, R1270, R1234yf, R410A, R507A, ammonia/water, \n    and air/water mixtures. Wide range of operating conditions, plate geometries.\n        \n    Examples\n    --------\n    >>> h_boiling_Amalfi(m=3E-5, x=.4, Dh=0.00172, rhol=567., rhog=18.09, \n    ... kl=0.086, mul=156E-6, mug=7.11E-6, sigma=0.02, Hvap=9E5, q=1E5, \n    ... A_channel_flow=0.0003)\n    776.0781179096225\n\n    References\n    ----------\n    .. [1] Amalfi, Raffaele L., Farzad Vakili-Farahani, and John R. Thome. \n       \"Flow Boiling and Frictional Pressure Gradients in Plate Heat Exchangers.\n       Part 2: Comparison of Literature Methods to Database and New Prediction \n       Methods.\" International Journal of Refrigeration 61 (January 2016):\n       185-203. doi:10.1016/j.ijrefrig.2015.07.009.\n    '''    \n    chevron_angle_max = 45.\n    beta_s = chevron_angle/chevron_angle_max\n    \n    rho_s = (rhol/rhog) # rho start in model\n    \n    G = m/A_channel_flow # Calculating the area of the channel is normally specified well\n    Bd = Bond(rhol=rhol, rhog=rhog, sigma=sigma, L=Dh)\n    \n    rho_h = 1./(x/rhog + (1-x)/rhol) # homogeneous holdup - mixture density calculation\n    We_m = G*G*Dh/sigma/rho_h\n    \n    Bo = q/(G*Hvap) # Boiling number\n\n    if Bd < 4:\n        # Should occur normally for \"microscale\" conditions\n        Nu_tp = 982*beta_s**1.101*We_m**0.315*Bo**0.320*rho_s**-0.224\n    else:\n        Re_lo = G*Dh/mul\n        Re_g = G*x*Dh/mug\n        Nu_tp = 18.495*beta_s**0.135*Re_g**0.135*Re_lo**0.351*Bd**0.235*Bo**0.198*rho_s**-0.223\n    return kl/Dh*Nu_tp", "response": "r Returns the two - phase boiling heat transfer coefficient of a given liquid and gas flowing inside a given plate and frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef h_boiling_Han_Lee_Kim(m, x, Dh, rhol, rhog, mul, kl, Hvap, Cpl, q, \n                          A_channel_flow, wavelength, chevron_angle=45):\n    r'''Calculates the two-phase boiling heat transfer coefficient of a \n    liquid and gas flowing inside a plate and frame heat exchanger, as\n    developed in [1]_ from experiments with three plate exchangers and the\n    working fluids R410A and R22. A well-documented and tested correlation,\n    reviewed in [2]_, [3]_, [4]_, [5]_, and [6]_.\n    \n    .. math::\n        h = Ge_1\\left(\\frac{k_l}{D_h}\\right)Re_{eq}^{Ge_2} Pr^{0.4} Bo_{eq}^{0.3}\n        \n        Ge_1 = 2.81\\left(\\frac{\\lambda}{D_h}\\right)^{-0.041}\\left(\\frac{\\pi}{2}\n        -\\beta\\right)^{-2.83}\n        \n        Ge_2 = 0.746\\left(\\frac{\\lambda}{D_h}\\right)^{-0.082}\\left(\\frac{\\pi}\n        {2}-\\beta\\right)^{0.61}\n        \n        Re_{eq} = \\frac{G_{eq} D_h}{\\mu_l}\n        \n        Bo_{eq} = \\frac{q}{G_{eq} H_{vap}}\n        \n        G_{eq} = \\frac{m}{A_{flow}}\\left[1 - x + x\\left(\\frac{\\rho_l}{\\rho_g}\n        \\right)^{1/2}\\right]\n\n    In the above equations, lambda is the wavelength of the corrugations, and\n    the flow area is specified to be (twice the corrugation amplitude times the\n    width of the plate. The mass flow is that per channel. Radians is used in\n    degrees, and the formulas are for the  inclination angle not the\n    chevron angle (it is converted internally).\n    Note that this model depends on the specific heat flux involved.\n            \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific point in the plate exchanger []\n    Dh : float\n        Hydraulic diameter of the plate, :math:`D_h = \\frac{4\\lambda}{\\phi}` [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of the liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Hvap : float\n        Heat of vaporization of the fluid at the system pressure, [J/kg]\n    Cpl : float\n        Heat capacity of liquid [J/kg/K]\n    q : float\n        Heat flux, [W/m^2]\n    A_channel_flow : float\n        The flow area for the fluid, calculated as \n        :math:`A_{ch} = 2\\cdot \\text{width} \\cdot \\text{amplitude}` [m]\n    wavelength : float\n        Distance between the bottoms of two of the ridges (sometimes called \n        pitch), [m]\n    chevron_angle : float, optional\n        Angle of the plate corrugations with respect to the vertical axis\n        (the direction of flow if the plates were straight), between 0 and\n        90. For exchangers with two angles, use the average value. [degrees]\n\n    Returns\n    -------\n    h : float\n        Boiling heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Date regression was with the log mean temperature difference, uncorrected\n    for geometry. Developed with three plate heat exchangers with angles of 45, \n    35, and 20 degrees. Mass fluxes ranged from 13 to 34 kg/m^2/s; evaporating \n    temperatures of 5, 10, and 15 degrees, vapor quality 0.9 to 0.15, heat \n    fluxes of 2.5-8.5 kW/m^2.\n        \n    Examples\n    --------\n    >>> h_boiling_Han_Lee_Kim(m=3E-5, x=.4, Dh=0.002, rhol=567., rhog=18.09, \n    ... kl=0.086, mul=156E-6,  Hvap=9E5, Cpl=2200, q=1E5, A_channel_flow=0.0003,\n    ... wavelength=3.7E-3, chevron_angle=45)\n    675.7322255419421\n\n    References\n    ----------\n    .. [1] Han, Dong-Hyouck, Kyu-Jung Lee, and Yoon-Ho Kim. \"Experiments on the\n       Characteristics of Evaporation of R410A in Brazed Plate Heat Exchangers \n       with Different Geometric Configurations.\" Applied Thermal Engineering 23,\n       no. 10 (July 2003): 1209-25. doi:10.1016/S1359-4311(03)00061-9.\n    .. [2] Amalfi, Raffaele L., Farzad Vakili-Farahani, and John R. Thome. \n       \"Flow Boiling and Frictional Pressure Gradients in Plate Heat Exchangers.\n       Part 1: Review and Experimental Database.\" International Journal of \n       Refrigeration 61 (January 2016): 166-84.\n       doi:10.1016/j.ijrefrig.2015.07.010.\n    .. [3] Eldeeb, Radia, Vikrant Aute, and Reinhard Radermacher. \"A Survey of\n       Correlations for Heat Transfer and Pressure Drop for Evaporation and \n       Condensation in Plate Heat Exchangers.\" International Journal of \n       Refrigeration 65 (May 2016): 12-26. doi:10.1016/j.ijrefrig.2015.11.013.\n    .. [4] Solotych, Valentin, Donghyeon Lee, Jungho Kim, Raffaele L. Amalfi, \n       and John R. Thome. \"Boiling Heat Transfer and Two-Phase Pressure Drops\n       within Compact Plate Heat Exchangers: Experiments and Flow \n       Visualizations.\" International Journal of Heat and Mass Transfer 94 \n       (March 2016): 239-253. doi:10.1016/j.ijheatmasstransfer.2015.11.037.\n    .. [5] Garc\u00eda-Cascales, J. R., F. Vera-Garc\u00eda, J. M. Corber\u00e1n-Salvador, and\n       J. Gonz\u00e1lvez-Maci\u00e1. \"Assessment of Boiling and Condensation Heat \n       Transfer Correlations in the Modelling of Plate Heat Exchangers.\" \n       International Journal of Refrigeration 30, no. 6 (September 2007): \n       1029-41. doi:10.1016/j.ijrefrig.2007.01.004. \n    .. [6] Huang, Jianchang. \"Performance Analysis of Plate Heat Exchangers \n       Used as Refrigerant Evaporators,\" 2011. Thesis.\n       http://wiredspace.wits.ac.za/handle/10539/9779\n    '''\n    chevron_angle = radians(chevron_angle)\n    G = m/A_channel_flow # For once, clearly defined in the publication\n    G_eq = G*((1. - x) + x*(rhol/rhog)**0.5)\n    Re_eq = G_eq*Dh/mul\n    Bo_eq = q/(G_eq*Hvap)\n    Pr = Prandtl(Cp=Cpl, k=kl, mu=mul)\n    Ge1 = 2.81*(wavelength/Dh)**-0.041*chevron_angle**-2.83\n    Ge2 = 0.746*(wavelength/Dh)**-0.082*chevron_angle**0.61\n    return Ge1*kl/Dh*Re_eq**Ge2*Bo_eq**0.3*Pr**0.4", "response": "r Returns a two - phase boiling heat transfer coefficient of a given liquid and gas flowing inside a given channel."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef laminar_entry_thermal_Hausen(Re=None, Pr=None, L=None, Di=None):\n    r'''Calculates average internal convection Nusselt number for laminar flows\n    in pipe during the thermal entry region according to [1]_ as shown in\n    [2]_ and cited by [3]_.\n\n    .. math::\n        Nu_D=3.66+\\frac{0.0668\\frac{D}{L}Re_{D}Pr}{1+0.04{(\\frac{D}{L}\n        Re_{D}Pr)}^{2/3}}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    L : float\n        Length of pipe [m]\n    Di : float\n        Diameter of pipe [m]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    If Pr >> 1, (5 is a common requirement) this equation also applies to flows\n    with developing velocity profile.\n    As L gets larger, this equation  becomes the constant-temperature Nusselt\n    number.\n\n    Examples\n    --------\n    >>> laminar_entry_thermal_Hausen(Re=100000, Pr=1.1, L=5, Di=.5)\n    39.01352358988535\n\n    References\n    ----------\n    .. [1] Hausen, H. Darstellung des Warmeuberganges in Rohren durch\n       verallgeminerte Potenzbeziehungen, Z. Ver deutsch. Ing Beih.\n       Verfahrenstech., 4, 91-98, 1943\n    .. [2] W. M. Kays. 1953. Numerical Solutions for Laminar Flow Heat Transfer\n       in Circular Tubes.\n    .. [3] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E.\n       Hoboken, NJ: Wiley, 2011.\n    '''\n    Gz = Di/L*Re*Pr\n    return 3.66 + (0.0668*Gz)/(1+0.04*(Gz)**(2/3.))", "response": "r Returns the average internal convection Nusselt number for a given resource in a given pipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef turbulent_Dittus_Boelter(Re, Pr, heating=True, revised=True):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [1]_, and [2]_, a reprint of [3]_.\n\n    .. math::\n        Nu = m*Re_D^{4/5}Pr^n\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    heating : bool\n        Indicates if the process is heating or cooling, optional\n    revised : bool\n        Indicates if revised coefficients should be used or not\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    The revised coefficient is m = 0.023.\n    The original form of Dittus-Boelter has a linear coefficient of 0.0243\n    for heating and 0.0265 for cooling. These are sometimes rounded to 0.024\n    and 0.026 respectively.\n    The default, heating, provides n = 0.4. Cooling makes n 0.3.\n\n    0.6 \u2264 Pr \u2264  160\n    Re_{D} \u2265 10000\n    L/D \u2265 10\n\n    Examples\n    --------\n    >>> turbulent_Dittus_Boelter(Re=1E5, Pr=1.2)\n    247.40036409449127\n    >>> turbulent_Dittus_Boelter(Re=1E5, Pr=1.2, heating=False)\n    242.9305927410295\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Dittus, F. W., and L. M. K. Boelter. \"Heat Transfer in Automobile\n       Radiators of the Tubular Type.\" International Communications in Heat\n       and Mass Transfer 12, no. 1 (January 1985): 3-22.\n       doi:10.1016/0735-1933(85)90003-X\n    .. [3] Dittus, F. W., and L. M. K. Boelter, University of California\n       Publications in Engineering, Vol. 2, No. 13, pp. 443-461, October 17,\n       1930.\n    '''\n    m = 0.023\n    if heating:\n        power = 0.4\n    else:\n        power = 0.3\n\n    if heating and not revised:\n        m = 0.0243\n    elif not heating and not revised:\n        m = 0.0265\n    else:\n        m = 0.023\n    return m*Re**0.8*Pr**power", "response": "r Returns a string that represents the internal convection Nusselt number for a given process and process number."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef turbulent_Sieder_Tate(Re, Pr, mu=None, mu_w=None):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [1]_ and supposedly [2]_.\n\n    .. math::\n        Nu = 0.027Re^{4/5}Pr^{1/3}\\left(\\frac{\\mu}{\\mu_s}\\right)^{0.14}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    mu : float\n        Viscosity of fluid, [Pa*s]\n    mu_w : float\n        Viscosity of fluid at wall temperature, [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    A linear coefficient of 0.023 is often listed with this equation. The\n    source of the discrepancy is not known. The equation is not present in the\n    original paper, but is nevertheless the source usually cited for it.\n\n    Examples\n    --------\n    >>> turbulent_Sieder_Tate(Re=1E5, Pr=1.2)\n    286.9178136793052\n    >>> turbulent_Sieder_Tate(Re=1E5, Pr=1.2, mu=0.01, mu_w=0.067)\n    219.84016455766044\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Sieder, E. N., and G. E. Tate. \"Heat Transfer and Pressure Drop of\n       Liquids in Tubes.\" Industrial & Engineering Chemistry 28, no. 12\n       (December 1, 1936): 1429-35. doi:10.1021/ie50324a027.\n    '''\n    Nu = 0.027*Re**0.8*Pr**(1/3.)\n    if mu_w and mu:\n        Nu *= (mu/mu_w)**0.14\n    return Nu", "response": "r Calculates internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ] _ and supposedly [ 2 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating internal convection Nusselt number for turbulent flows in pipe according to [ 1 ] T. von Karman.", "response": "def turbulent_von_Karman(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as in [1]_.\n\n    .. math::\n        Nu = \\frac{(f/8)Re Pr}{1 + 5(f/8)^{0.5}\\left[Pr-1+\\ln\\left(\\frac{5Pr+1}\n        {6}\\right)\\right]}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Range according to [1]_ is 0.5 \u2264 Pr \u2264 3  and 10^4 \u2264 Re \u2264 10^5.\n\n    Examples\n    --------\n    >>> turbulent_von_Karman(Re=1E5, Pr=1.2, fd=0.0185)\n    255.7243541243272\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] T. von Karman, \"The Analogy Between Fluid Friction and Heat\n       Transfer,\" Trans. ASME, (61):705-710,1939.\n    '''\n    return fd/8.*Re*Pr/(1 + 5*(fd/8.)**0.5*(Pr - 1 + log((5*Pr + 1)/6.)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ].", "response": "def turbulent_Friend_Metzner(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as in [1]_.\n\n    .. math::\n        Nu = \\frac{(f/8)RePr}{1.2 + 11.8(f/8)^{0.5}(Pr-1)Pr^{-1/3}}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Range according to [1]_ 50 < Pr \u2264 600  and 5*10^4 \u2264 Re \u2264 5*10^6.\n    The extreme limits on range should be considered!\n\n    Examples\n    --------\n    >>> turbulent_Friend_Metzner(Re=1E5, Pr=100., fd=0.0185)\n    1738.3356262055322\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Friend, W. L., and A. B. Metzner. \u201cTurbulent Heat Transfer inside\n       Tubes and the Analogy among Heat, Mass, and Momentum Transfer.\u201d AIChE\n       Journal 4, no. 4 (December 1, 1958): 393-402. doi:10.1002/aic.690040404.\n    '''\n    return (fd/8.)*Re*Pr/(1.2 + 11.8*(fd/8.)**0.5*(Pr - 1.)*Pr**(-1/3.))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef turbulent_Webb(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as in [1]_.\n\n    .. math::\n        Nu = \\frac{(f/8)RePr}{1.07 + 9(f/8)^{0.5}(Pr-1)Pr^{1/4}}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Range according to [1]_ is 0.5 < Pr \u2264 100  and 10^4 \u2264 Re \u2264 5*10^6\n\n    Examples\n    --------\n    >>> turbulent_Webb(Re=1E5, Pr=1.2, fd=0.0185)\n    239.10130376815872\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Webb, Dr R. L. \u201cA Critical Evaluation of Analytical Solutions and\n       Reynolds Analogy Equations for Turbulent Heat and Mass Transfer in\n       Smooth Tubes.\u201d W\u00e4rme - Und Stoff\u00fcbertragung 4, no. 4\n       (December 1, 1971): 197\u2013204. doi:10.1007/BF01002474.\n    '''\n    return (fd/8.)*Re*Pr/(1.07 + 9.*(fd/8.)**0.5*(Pr - 1.)*Pr**0.25)", "response": "Calculates internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ]."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef turbulent_Sandall(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as in [1]_.\n\n    .. math::\n        Nu = \\frac{(f/8)RePr}{12.48Pr^{2/3} - 7.853Pr^{1/3} + 3.613\\ln Pr + 5.8 + C}\\\\\n        C = 2.78\\ln((f/8)^{0.5} Re/45)\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    Range according to [1]_ is 0.5< Pr \u2264 2000  and 10^4 \u2264 Re \u2264 5*10^6.\n\n    Examples\n    --------\n    >>> turbulent_Sandall(Re=1E5, Pr=1.2, fd=0.0185)\n    229.0514352970239\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Sandall, O. C., O. T. Hanna, and P. R. Mazet. \u201cA New Theoretical\n       Formula for Turbulent Heat and Mass Transfer with Gases or Liquids in\n       Tube Flow.\u201d The Canadian Journal of Chemical Engineering 58, no. 4\n       (August 1, 1980): 443\u201347. doi:10.1002/cjce.5450580404.\n    '''\n    C = 2.78*log((fd/8.)**0.5*Re/45.)\n    return (fd/8.)**0.5*Re*Pr/(12.48*Pr**(2/3.) - 7.853*Pr**(1/3.) \n                               + 3.613*log(Pr) + 5.8 + C)", "response": "Calculates internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ]."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef turbulent_Martinelli(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as shown in [1]_.\n\n    .. math::\n        Nu  = \\frac{RePr(f/8)^{0.5}}{5[Pr + \\ln(1+5Pr) + 0.5\\ln(Re(f/8)^{0.5}/60)]}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    No range is given for this equation. Liquid metals are probably its only\n    applicability.\n\n    Examples\n    --------\n    >>> turbulent_Martinelli(Re=1E5, Pr=100., fd=0.0185)\n    887.1710686396347\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Martinelli, R. C. (1947). \"Heat transfer to molten metals\".\n       Trans. ASME, 69, 947-959.\n    '''\n    return Re*Pr*(fd/8.)**0.5/5/(Pr + log(1. + 5.*Pr) + 0.5*log(Re*(fd/8.)**0.5/60.))", "response": "Calculates internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ] _."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating internal convection Nusselt number for turbulent flows in a single file system.", "response": "def turbulent_Dipprey_Sabersky(Re, Pr, fd, eD):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as shown in [1]_.\n\n    .. math::\n        Nu = \\frac{RePr(f/8)}{1 + (f/8)^{0.5}[5.19Re_\\epsilon^{0.2} Pr^{0.44} - 8.48]}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n    eD : float\n        Relative roughness, [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    According to [1]_, the limits are:\n    1.2 \u2264 Pr \u2264 5.94 and 1.4*10^4 \u2264 Re \u2264 5E5 and 0.0024 \u2264 eD \u2264 0.049.\n\n    Examples\n    --------\n    >>> turbulent_Dipprey_Sabersky(Re=1E5, Pr=1.2, fd=0.0185, eD=1E-3)\n    288.33365198566656\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Dipprey, D. F., and R. H. Sabersky. \u201cHeat and Momentum Transfer in\n       Smooth and Rough Tubes at Various Prandtl Numbers.\u201d International\n       Journal of Heat and Mass Transfer 6, no. 5 (May 1963): 329\u201353.\n       doi:10.1016/0017-9310(63)90097-8\n    '''\n    Re_e = Re*eD*(fd/8.)**0.5\n    return Re*Pr*fd/8./(1 + (fd/8.)**0.5*(5.19*Re_e**0.2*Pr**0.44 - 8.48))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate internal convection Nusselt number for turbulent flows in a pipe according to [ 1 ] Gowen and James Hartnett and Young Cho.", "response": "def turbulent_Gowen_Smith(Re, Pr, fd):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as shown in [1]_.\n\n    .. math::\n        Nu = \\frac{Re Pr (f/8)^{0.5}} {4.5 + [0.155(Re(f/8)^{0.5})^{0.54}\n        + (8/f)^{0.5}]Pr^{0.5}}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    0.7 \u2264 Pr \u2264 14.3 and 10^4 \u2264 Re \u2264 5E4 and 0.0021 \u2264 eD \u2264 0.095\n\n    Examples\n    --------\n    >>> turbulent_Gowen_Smith(Re=1E5, Pr=1.2, fd=0.0185)\n    131.72530453824106\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] Gowen, R. A., and J. W. Smith. \u201cTurbulent Heat Transfer from Smooth\n       and Rough Surfaces.\u201d International Journal of Heat and Mass Transfer 11,\n       no. 11 (November 1968): 1657\u201374. doi:10.1016/0017-9310(68)90046-X.\n    '''\n    return Re*Pr*(fd/8.)**0.5/(4.5 + (0.155*(Re*(fd/8.)**0.5)**0.54 + (8./fd)**0.5)*Pr**0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate internal convection Nusselt number for turbulent flows in a pipe.", "response": "def turbulent_Bhatti_Shah(Re, Pr, fd, eD):\n    r'''Calculates internal convection Nusselt number for turbulent flows\n    in pipe according to [2]_ as shown in [1]_. The most widely used rough\n    pipe turbulent correlation.\n\n    .. math::\n        Nu_D = \\frac{(f/8)Re_DPr}{1+\\sqrt{f/8}(4.5Re_{\\epsilon}^{0.2}Pr^{0.5}-8.48)}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    fd : float\n        Darcy friction factor [-]\n    eD : float\n        Relative roughness, [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n\n    Notes\n    -----\n    According to [1]_, the limits are:\n    0.5 \u2264 Pr \u2264  10\n    0.002 \u2264 \u03b5/D \u2264  0.05\n    10,000 \u2264 Re_{D}\n    Another correlation is listed in this equation, with a wider variety\n    of validity.\n\n    Examples\n    --------\n    >>> turbulent_Bhatti_Shah(Re=1E5, Pr=1.2, fd=0.0185, eD=1E-3)\n    302.7037617414273\n\n    References\n    ----------\n    .. [1] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    .. [2] M. S. Bhatti and R. K. Shah. Turbulent and transition flow\n       convective heat transfer in ducts. In S. Kaka\u00e7, R. K. Shah, and W.\n       Aung, editors, Handbook of Single-Phase Convective Heat Transfer,\n       chapter 4. Wiley-Interscience, New York, 1987.\n    '''\n    Re_e = Re*eD*(fd/8.)**0.5\n    return Re*Pr*fd/8./(1 + (fd/8.)**0.5*(4.5*Re_e**0.2*Pr**0.5 - 8.48))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Nu_conv_internal(Re, Pr, eD=0, Di=None, x=None, fd=None, Method=None, \n                     AvailableMethods=False):\n    r'''This function calculates the heat transfer coefficient for internal\n    convection inside a circular pipe. \n    \n    Requires at a minimum a flow's Reynolds and Prandtl numbers `Re` and `Pr`. \n    Relative roughness `eD` can be specified to include the enhancement of heat \n    transfer from the added turbulence. \n    \n    For laminar flow, thermally and hydraulically developing flow is supported\n    with the pipe diameter `Di` and distance `x` is provided.\n    \n    If no correlation's name is provided as `Method`, the most accurate \n    applicable correlation is selected.\n    \n    * If laminar, `x` and `Di` provided:  'Baehr-Stephan laminar thermal/velocity entry'\n    * Otherwise if laminar, no entry information provided: 'Laminar - constant T' (Nu = 3.66)\n    * If turbulent and `Pr` < 0.03: 'Martinelli'\n    * If turbulent, `x` and `Di` provided: 'Hausen'\n    * Otherwise if turbulent: 'Churchill-Zajic'\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    Pr : float\n        Prandtl number, [-]\n    eD : float, optional\n        Relative roughness, [-]\n    Di : float, optional\n        Inside diameter of pipe, [m]\n    x : float, optional\n        Length inside of pipe for calculation, [m]\n    fd : float, optoinal\n        Darcy friction factor [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number, [-]\n    methods : list, only returned if AvailableMethods == True\n        List of methods which can be used to calculate `Nu` with the given inputs\n\n    Other Parameters\n    ----------------\n    Method : string, optional\n        A string of the function name to use, as in the dictionary\n        vertical_cylinder_correlations\n    AvailableMethods : bool, optional\n        If True, function will consider which methods which can be used to\n        calculate Nu with the given inputs\n        \n    Examples\n    --------\n    Turbulent example\n    \n    >>> Nu_conv_internal(Re=1E5, Pr=.7)\n    183.71057902604906\n\n    Entry length - laminar example\n    \n    >>> Nu_conv_internal(Re=1E2, Pr=.7, x=.01, Di=.1)\n    14.91799128769779\n    '''\n    def list_methods():\n        methods = []\n        if Re < LAMINAR_TRANSITION_PIPE:\n            # Laminar!\n            if all((Re, Pr, x, Di)):\n                methods.append('Baehr-Stephan laminar thermal/velocity entry')\n                methods.append('Hausen laminar thermal entry')\n                methods.append('Seider-Tate laminar thermal entry')\n\n            methods.append('Laminar - constant T')\n            methods.append('Laminar - constant Q')\n        else:\n            if all((Re, Pr)) and Pr < 0.03:\n                # Liquid metals\n                methods.append('Martinelli')\n            if all((Re, Pr, Di, x)):\n                methods.append('Hausen')\n            if Re and Pr and (eD is not None or fd is not None):\n                # handle correlations with roughness\n                methods.append('Churchill-Zajic')\n                methods.append('Petukhov-Kirillov-Popov')\n                methods.append('Gnielinski')\n                methods.append('Bhatti-Shah')\n                methods.append('Dipprey-Sabersky')\n                methods.append('Sandall')\n                methods.append('Webb')\n                methods.append('Friend-Metzner')\n                methods.append('Prandtl')\n                methods.append('von-Karman')\n                methods.append('Gowen-Smith')\n                methods.append('Kawase-Ulbrecht')\n                methods.append('Kawase-De')\n                methods.append('Nunner')\n            if Re and Pr:\n                methods.append('Dittus-Boelter')\n                methods.append('Sieder-Tate')\n                methods.append('Drexel-McAdams')\n                methods.append('Colburn')\n                methods.append('ESDU')\n                methods.append('Gnielinski smooth low Pr') # 1\n                methods.append('Gnielinski smooth high Pr') # 2\n        return methods\n\n    if AvailableMethods:\n        return list_methods()\n    if not Method:\n        Method = list_methods()[0]\n        \n    if eD is not None and fd is None:\n        fd = friction_factor(Re=Re, eD=eD)\n\n    if Method == 'Laminar - constant T':\n        Nu = laminar_T_const()\n    elif Method == 'Laminar - constant Q':\n        Nu = laminar_Q_const()\n    elif Method == 'Baehr-Stephan laminar thermal/velocity entry':\n        Nu = laminar_entry_thermal_Hausen(Re=Re, Pr=Pr, L=x, Di=Di)\n    elif Method == 'Hausen laminar thermal entry':\n        Nu = laminar_entry_Seider_Tate(Re=Re, Pr=Pr, L=x, Di=Di)\n    elif Method == 'Seider-Tate laminar thermal entry':\n        Nu = laminar_entry_Baehr_Stephan(Re=Re, Pr=Pr, L=x, Di=Di)\n    elif Method == 'Churchill-Zajic':\n        Nu = turbulent_Churchill_Zajic(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Petukhov-Kirillov-Popov':\n        Nu = turbulent_Petukhov_Kirillov_Popov(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Gnielinski':\n        Nu = turbulent_Gnielinski(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Sandall':\n        Nu = turbulent_Sandall(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Webb':\n        Nu = turbulent_Webb(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Friend-Metzner':\n        Nu = turbulent_Friend_Metzner(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Prandtl':\n        Nu = turbulent_Prandtl(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'von-Karman':\n        Nu = turbulent_von_Karman(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Martinelli':\n        Nu = turbulent_Martinelli(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Gowen-Smith':\n        Nu = turbulent_Gowen_Smith(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Kawase-Ulbrecht':\n        Nu = turbulent_Kawase_Ulbrecht(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Kawase-De':\n        Nu = turbulent_Kawase_De(Re=Re, Pr=Pr, fd=fd)\n    elif Method == 'Dittus-Boelter':\n        Nu = turbulent_Dittus_Boelter(Re=Re, Pr=Pr)\n    elif Method == 'Sieder-Tate':\n        Nu = turbulent_Sieder_Tate(Re=Re, Pr=Pr)\n    elif Method == 'Drexel-McAdams':\n        Nu = turbulent_Drexel_McAdams(Re=Re, Pr=Pr)\n    elif Method == 'Colburn':\n        Nu = turbulent_Colburn(Re=Re, Pr=Pr)\n    elif Method == 'ESDU':\n        Nu = turbulent_ESDU(Re=Re, Pr=Pr)\n    elif Method == 'Gnielinski smooth low Pr':\n        Nu = turbulent_Gnielinski_smooth_1(Re=Re, Pr=Pr)\n    elif Method == 'Gnielinski smooth high Pr':\n        Nu = turbulent_Gnielinski_smooth_2(Re=Re, Pr=Pr)\n    elif Method == 'Hausen':\n        Nu = turbulent_entry_Hausen(Re=Re, Pr=Pr, Di=Di, x=x)\n    elif Method == 'Bhatti-Shah':\n        Nu = turbulent_Bhatti_Shah(Re=Re, Pr=Pr, fd=fd, eD=eD)\n    elif Method == 'Dipprey-Sabersky':\n        Nu = turbulent_Dipprey_Sabersky(Re=Re, Pr=Pr, fd=fd, eD=eD)\n    elif Method == 'Nunner':\n        fd_smooth = friction_factor(Re, eD=0)\n        Nu = turbulent_Nunner(Re=Re, Pr=Pr, fd=fd, fd_smooth=fd_smooth)\n    else:\n        raise Exception(\"Correlation name not recognized; see the \"\n                        \"documentation for the available options.\")\n    return Nu", "response": "r Returns the internal Nu value for a given Reynolds Prandtl number x and Di."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef helical_turbulent_Nu_Mori_Nakayama(Re, Pr, Di, Dc):\n    r'''Calculates Nusselt number for a fluid flowing inside a curved \n    pipe such as a helical coil under turbulent conditions, using the method of \n    Mori and Nakayama [1]_, also shown in [2]_ and [3]_.\n            \n    For :math:`Pr < 1`:\n        \n    .. math::\n        Nu = \\frac{Pr}{26.2(Pr^{2/3}-0.074)}Re^{0.8}\\left(\\frac{D_i}{D_c}\n        \\right)^{0.1}\\left[1 + \\frac{0.098}{\\left[Re\\left(\\frac{D_i}{D_c}\n        \\right)^2\\right]^{0.2}}\\right]\n            \n    For :math:`Pr \\ge 1`:\n        \n    .. math::\n        Nu = \\frac{Pr^{0.4}}{41}Re^{5/6}\\left(\\frac{D_i}{D_c}\\right)^{1/12}\n        \\left[1 + \\frac{0.061}{\\left[Re\\left(\\frac{D_i}{D_c}\\right)^{2.5}\n        \\right]^{1/6}}\\right]\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with `D=Di`, [-]\n    Pr : float\n        Prandtl number with bulk properties [-]\n    Di : float\n        Inner diameter of the coil, [m]\n    Dc : float\n        Diameter of the helix/coil measured from the center of the tube on one\n        side to the center of the tube on the other side, [m]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to `Di`, [-]\n\n    Notes\n    -----    \n    At very low curvatures, the predicted heat transfer coefficient\n    grows unbounded.\n    \n    Applicable for :math:`Re\\left(\\frac{D_i}{D_c}\\right)^2 > 0.1`\n\n    Examples\n    --------\n    >>> helical_turbulent_Nu_Mori_Nakayama(2E5, 0.7, 0.01, .2)\n    496.2522480663327\n\n    References\n    ----------\n    .. [1] Mori, Yasuo, and Wataru Nakayama. \"Study on Forced Convective Heat \n       Transfer in Curved Pipes.\" International Journal of Heat and Mass \n       Transfer 10, no. 5 (May 1, 1967): 681-95. \n       doi:10.1016/0017-9310(67)90113-5. \n    .. [2] El-Genk, Mohamed S., and Timothy M. Schriener. \"A Review and \n       Correlations for Convection Heat Transfer and Pressure Losses in \n       Toroidal and Helically Coiled Tubes.\" Heat Transfer Engineering 0, no. 0\n       (June 7, 2016): 1-28. doi:10.1080/01457632.2016.1194693.\n    .. [3] Hardik, B. K., P. K. Baburajan, and S. V. Prabhu. \"Local Heat \n       Transfer Coefficient in Helical Coils with Single Phase Flow.\" \n       International Journal of Heat and Mass Transfer 89 (October 2015): \n       522-38. doi:10.1016/j.ijheatmasstransfer.2015.05.069.\n    '''\n    D_ratio = Di/Dc\n    if Pr < 1:\n        term1 = Pr/(26.2*(Pr**(2/3.) - 0.074))*Re**0.8*D_ratio**0.1\n        term2 = 1. + 0.098*(Re*D_ratio*D_ratio)**-0.2\n    else:\n        term1 = Pr**0.4/41.*Re**(5/6.)*(Di/Dc)**(1/12.)\n        term2 = 1. + 0.061/(Re*(Di/Dc)**2.5)**(1/6.)\n    return term1*term2", "response": "r Returns a string that is used to calculate the Nusselt number for a curved \n   ."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef helical_turbulent_Nu_Schmidt(Re, Pr, Di, Dc):\n    r'''Calculates Nusselt number for a fluid flowing inside a curved \n    pipe such as a helical coil under turbulent conditions, using the method of \n    Schmidt [1]_, also shown in [2]_, [3]_, and [4]_.\n            \n    For :math:`Re_{crit} < Re < 2.2\\times 10 ^4`:\n        \n    .. math::\n        Nu = 0.023\\left[1 + 14.8\\left(1 + \\frac{D_i}{D_c}\\right)\\left(\n        \\frac{D_i}{D_c}\\right)^{1/3}\\right]Re^{0.8-0.22\\left(\\frac{D_i}{D_c}\n        \\right)^{0.1}}Pr^{1/3}\n            \n    For :math:`2.2\\times 10^4 < Re < 1.5\\times 10^5`:\n        \n    .. math::\n        Nu = 0.023\\left[1 + 3.6\\left(1 - \\frac{D_i}{D_c}\\right)\\left(\\frac{D_i}\n        {D_c}\\right)^{0.8}\\right]Re^{0.8}Pr^{1/3}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with `D=Di`, [-]\n    Pr : float\n        Prandtl number with bulk properties [-]\n    Di : float\n        Inner diameter of the coil, [m]\n    Dc : float\n        Diameter of the helix/coil measured from the center of the tube on one\n        side to the center of the tube on the other side, [m]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to `Di`, [-]\n        \n    Notes\n    -----\n    For very low curvatures, reasonable results are returned by both cases\n    of Reynolds numbers.\n\n    Examples\n    --------\n    >>> helical_turbulent_Nu_Schmidt(2E5, 0.7, 0.01, .2)\n    466.2569996832083\n\n    References\n    ----------\n    .. [1] Schmidt, Eckehard F. \"W\u00e4rme\u00fcbergang Und Druckverlust in \n       Rohrschlangen.\" Chemie Ingenieur Technik 39, no. 13 (July 10, 1967): \n       781-89. doi:10.1002/cite.330391302. \n    .. [2] El-Genk, Mohamed S., and Timothy M. Schriener. \"A Review and \n       Correlations for Convection Heat Transfer and Pressure Losses in \n       Toroidal and Helically Coiled Tubes.\" Heat Transfer Engineering 0, no. 0\n       (June 7, 2016): 1-28. doi:10.1080/01457632.2016.1194693.\n    .. [3] Hardik, B. K., P. K. Baburajan, and S. V. Prabhu. \"Local Heat \n       Transfer Coefficient in Helical Coils with Single Phase Flow.\" \n       International Journal of Heat and Mass Transfer 89 (October 2015): \n       522-38. doi:10.1016/j.ijheatmasstransfer.2015.05.069.\n    .. [4] Rohsenow, Warren and James Hartnett and Young Cho. Handbook of Heat\n       Transfer, 3E. New York: McGraw-Hill, 1998.\n    '''\n    D_ratio = Di/Dc\n    if Re <= 2.2E4:\n        term = Re**(0.8 - 0.22*D_ratio**0.1)*Pr**(1/3.)\n        return 0.023*(1. + 14.8*(1. + D_ratio)*D_ratio**(1/3.))*term\n    else:\n        return 0.023*(1. + 3.6*(1. - D_ratio)*D_ratio**0.8)*Re**0.8*Pr**(1/3.)", "response": "r Returns a base class that calculates the Nusselt number for a curved \n    with respect to D Di and Dc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Nu_packed_bed_Gnielinski(dp, voidage, vs, rho, mu, Pr, fa=None):\n    r'''Calculates Nusselt number of a fluid passing over a bed of particles\n    using a correlation shown in [3]_ and cited as from [1]_ and [2]_. Likely\n    the best available model as the author of [1]_ is the same as [2]_ and\n    [3]_.\n\n    .. math::\n        Nu = f_a Nu_{sphere}\n\n        Nu_{sphere} = 2 + \\sqrt{Nu_{m,lam}^2 + Nu_{m,turb}^2}\n\n        Nu_{m,lam} = 0.664Re^{0.5} Pr^{1/3}\n\n        Nu_{m,turb} = \\frac{0.037Re^{0.8} Pr}{1 + 2.443Re^{-0.1}(Pr^{2/3} -1)}\n\n        Re = \\frac{\\rho v_s d_p}{\\mu \\epsilon}\n\n    Parameters\n    ----------\n    dp : float\n        Equivalent spherical particle diameter of packing [m]\n    voidage : float\n        Void fraction of bed packing [-]\n    vs : float\n        Superficial velocity of the fluid [m/s]\n    rho : float\n        Density of the fluid [kg/m^3]\n    mu : float\n        Viscosity of the fluid, [Pa*s]\n    Pr : float\n        Prandtl number of the fluid []\n    fa : float, optional\n        Fator increasing heat transfer []\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number for heat transfer to the packed bed [-]\n\n    Notes\n    -----\n    `fa` is a factor relating how much more heat transfer happens than would\n    normally, around one sphere. For spheres of the same size,\n    :math:`f_a = 1 + 1.5(1-\\epsilon)`. For cylinders with l/d ratio of\n    0.24 < l/d < 1.2 use fa = 1.6. For cubes, use fa = 1.6 For Raschig rings,\n    use `fa` = 2.1 For Berl saddles, use `fa` = 2.3. fa is calculated with\n    the relationship for spheres if not provided.\n\n    Confirmed with experimental data for a range of :math:`1E-1 < Re <1,000`\n    and :math:`0.4 < Pr < 1000` for spheres. Limits are smaller for other\n    shapes.\n\n    Examples\n    --------\n    >>> Nu_packed_bed_Gnielinski(dp=8E-4, voidage=0.4, vs=1, rho=1E3, mu=1E-3, Pr=0.7)\n    61.37823202546954\n\n    References\n    ----------\n    .. [1] Gnielinski, V. (1981) \"Equations for the calculation of heat and\n       mass transfer during flow through stationary spherical packings at\n       moderate and high Peclet numbers\". International Chemical Engineering\n       21 (3): 378-383\n    .. [2] Gnielinski, V. (1982) \"Berechnung des Warmeund Stoffaustauschs in\n       durchstomten ruhenden Schuttungen\". Verfahrenstechnik 16(1): 36-39\n    .. [3] Gnielinski, V. in G esellschaft, V. D. I., ed. VDI Heat Atlas.\n       2nd ed. 2010 edition. Berlin; New York: Springer, 2010.\n    '''\n    Re = rho*vs*dp/mu/voidage\n    Nu_lam = 0.664*Re**0.5*Pr**(1/3.)\n    Nu_turb = 0.037*Re**0.8*Pr/(1 + 2.443*Re**-0.1*(Pr**(2/3.)-1))\n    Nu_sphere = 2 + (Nu_lam**2 + Nu_turb**2)**0.5\n    if not fa:\n        fa = 1 + 1.5*(1-voidage)\n    return fa*Nu_sphere", "response": "r Calculates the Nusselt number of a packed bed of particles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the Nusselt number of a fluid passing over a bed of particles and packs it into a new one.", "response": "def Nu_KTA(Re, Pr, voidage):\n    r'''Calculates Nusselt number of a fluid passing over a bed of particles\n    using a correlation shown in [1]_ and also cited in the review of [2]_.\n    \n    .. math::\n        Nu = 1.27\\frac{Pr^{1/3}}{\\epsilon^{1.18}}Re^{0.36}\n        + 0.033\\frac{Pr^{0.5}}{\\epsilon^{1.07}}Re^{0.86}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with pebble diameter as characteristic dimension, [-]\n    Pr : float\n        Prandtl number of the fluid [-]\n    voidage : float\n        Void fraction of bed packing [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number for heat transfer to the packed bed [-]\n\n    Notes\n    -----\n    100 < Re < 1E5;\n    0.36 < \u03b5 < 0.42;\n    D/d > 20 with D as bed diameter, d as particle diameter;\n    H > 4d with H as bed height.\n    \n    Examples\n    --------\n    >>> Nu_KTA(2000, 0.7, 0.4)\n    102.08516480718129\n\n    References\n    ----------\n    .. [1] Reactor Core Design of High-Temperature Gas-Cooled Reactors Part 2: \n       Heat Transfer in Spherical Fuel Elements (June 1983).\n       http://www.kta-gs.de/e/standards/3100/3102_2_engl_1983_06.pdf\n    .. [2] Abdulmohsin, Rahman S., and Muthanna H. Al-Dahhan. \"Characteristics \n       of Convective Heat Transport in a Packed Pebble-Bed Reactor.\" Nuclear\n       Engineering and Design 284 (April 1, 2015): 143-52. \n       doi:10.1016/j.nucengdes.2014.11.041.\n    '''\n    return (1.27*Pr**(1/3.)*Re**0.36/voidage**1.18 \n            + 0.033*Pr**0.5/voidage**1.07*Re**0.86)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Nu_Gupta(Re, Pr, rho_w=None, rho_b=None, mu_w=None, mu_b=None):\n    r'''Calculates internal convection Nusselt number for turbulent vertical\n    upward flow in a pipe under supercritical conditions according to [1]_.\n        \n    .. math::\n        Nu_w = 0.004 Re_w^{0.923} \\bar{Pr}_w^{0.773}\n        \\left(\\frac{\\rho_w}{\\rho_b}\\right)^{0.186}\n        \\left(\\frac{\\mu_w}{\\mu_b}\\right)^{0.366}\n        \n        \\bar{Cp} = \\frac{H_w-H_b}{T_w-T_b}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with wall fluid properties, [-]\n    Pr : float\n        Prandtl number with wall fluid properties and an average heat capacity\n        between the wall and bulk temperatures [-]\n    rho_w : float, optional\n        Density at the wall temperature, [kg/m^3]\n    rho_b : float, optional\n        Density at the bulk temperature, [kg/m^3]\n    mu_w : float, optional\n        Viscosity at the wall temperature, [Pa*s]\n    mu_b : float, optional\n        Viscosity at the bulk temperature, [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with wall fluid properties, [-]\n\n    Notes\n    -----\n    For the data used to develop the correlation, P was set at 24 MPa, and D \n    was 10 mm. G varied from 200-1500 kg/m^2/s and q varied from 0 to 1250 \n    kW/m^2.\n    \n    Cp used in the calculation of Prandtl number should be the average value\n    of those at the wall and the bulk temperatures.\n\n    For deteriorated heat transfer, this was the most accurate correlation in \n    [2]_ with a MAD of 18.1%.\n    \n    If the extra density and viscosity information is not provided, it will \n    not be used.\n\n    Examples\n    --------\n    >>> Nu_Gupta(1E5, 1.2, 330, 290., 8e-4, 9e-4)\n    186.20135477175126\n\n    References\n    ----------\n    .. [1] Gupta, Sahil, Amjad Farah, Krysten King, Sarah Mokry, and Igor \n       Pioro. \"Developing New Heat-Transfer Correlation for SuperCritical-Water\n       Flow in Vertical Bare Tubes,\" January 1, 2010, 809-17. \n       doi:10.1115/ICONE18-30024.\n    .. [2] Chen, Weiwei, Xiande Fang, Yu Xu, and Xianghui Su. \"An Assessment of\n       Correlations of Forced Convection Heat Transfer to Water at \n       Supercritical Pressure.\" Annals of Nuclear Energy 76 (February 2015): \n       451-60. doi:10.1016/j.anucene.2014.10.027.\n    '''\n    Nu = 0.004*Re**0.923*Pr**0.773\n    if rho_w and rho_b:\n        Nu *= (rho_w/rho_b)**0.186\n    if mu_w and mu_b:\n        Nu *= (mu_w/mu_b)**0.366\n    return Nu", "response": "r Returns the internal convection Nusselt number for turbulent vertical flow in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Nu_Swenson(Re, Pr, rho_w=None, rho_b=None):\n    r'''Calculates internal convection Nusselt number for turbulent vertical\n    upward flow in a pipe under supercritical conditions according to [1]_.\n        \n    .. math::\n        Nu_w = 0.00459 Re_w^{0.923} Pr_w^{0.613}\n        \\left(\\frac{\\rho_w}{\\rho_b}\\right)^{0.231}\n\n        \\bar{Cp} = \\frac{H_w-H_b}{T_w-T_b}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with wall fluid properties, [-]\n    Pr : float\n        Prandtl number with wall fluid properties and an average heat capacity\n        between the wall and bulk temperatures [-]\n    rho_w : float, optional\n        Density at the wall temperature, [kg/m^3]\n    rho_b : float, optional\n        Density at the bulk temperature, [kg/m^3]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with wall fluid properties, [-]\n\n    Notes\n    -----\n    The range of examined parameters is as follows: \n    P from 22.8 to 27.6 MPa; G from 542-2150 kg/m^2/s; \n    Re from 7.5E4 to 3.16E6; T_b from 75 to 576 degrees Celsius and T_w from\n    93 to 649 degrees Celsius.\n    \n    Cp used in the calculation of Prandtl number should be the average value\n    of those at the wall and the bulk temperatures.\n\n    For deteriorated heat transfer, this was the most accurate correlation in \n    [2]_ with a MAD of 18.4%. On the overall database in [3]_, it was the \n    9th most accurate correlation.\n    \n    If the extra density information is not provided, it will not be used.\n\n    Examples\n    --------\n    >>> Nu_Swenson(1E5, 1.2, 330, 290.)\n    217.92827034803668\n\n    References\n    ----------\n    .. [1] Swenson, H. S., J. R. Carver, and C. R. Kakarala. \"Heat Transfer to \n       Supercritical Water in Smooth-Bore Tubes.\" Journal of Heat Transfer 87, \n       no. 4 (November 1, 1965): 477-83. doi:10.1115/1.3689139.\n    .. [2] Chen, Weiwei, Xiande Fang, Yu Xu, and Xianghui Su. \"An Assessment of\n       Correlations of Forced Convection Heat Transfer to Water at \n       Supercritical Pressure.\" Annals of Nuclear Energy 76 (February 2015): \n       451-60. doi:10.1016/j.anucene.2014.10.027.\n    .. [3] Yu, Jiyang, Baoshan Jia, Dan Wu, and Daling Wang. \"Optimization of \n       Heat Transfer Coefficient Correlation at Supercritical Pressure Using \n       Genetic Algorithms.\" Heat and Mass Transfer 45, no. 6 (January 8, 2009): \n       757-66. doi:10.1007/s00231-008-0475-4.\n    .. [4] J\u00e4ger, Wadim, Victor Hugo S\u00e1nchez Espinoza, and Antonio Hurtado. \n       \"Review and Proposal for Heat Transfer Predictions at Supercritical \n       Water Conditions Using Existing Correlations and Experiments.\" Nuclear \n       Engineering and Design, (W3MDM) University of Leeds International \n       Symposium: What Where When? Multi-dimensional Advances for Industrial \n       Process Monitoring, 241, no. 6 (June 2011): 2184-2203. \n       doi:10.1016/j.nucengdes.2011.03.022. \n    '''\n    Nu = 0.00459*Re**0.923*Pr**0.613\n    if rho_w and rho_b:\n        Nu *= (rho_w/rho_b)**0.231\n    return Nu", "response": "r Returns the internal convection Nusselt number for turbulent vertical flow in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Nu_Xu(Re, Pr, rho_w=None, rho_b=None, mu_w=None, mu_b=None):\n    r'''Calculates internal convection Nusselt number for turbulent vertical\n    upward flow in a pipe under supercritical conditions according to [1]_.\n        \n    .. math::\n        Nu_b = 0.02269 Re_b^{0.8079} \\bar{Pr}_b^{0.9213}\n        \\left(\\frac{\\rho_w}{\\rho_b}\\right)^{0.6638}\n        \\left(\\frac{\\mu_w}{\\mu_b}\\right)^{0.8687}\n        \n        \\bar{Cp} = \\frac{H_w-H_b}{T_w-T_b}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with bulk fluid properties, [-]\n    Pr : float\n        Prandtl number with bulk fluid properties and an average heat capacity\n        between the wall and bulk temperatures [-]\n    rho_w : float, optional\n        Density at the wall temperature, [kg/m^3]\n    rho_b : float, optional\n        Density at the bulk temperature, [kg/m^3]\n    mu_w : float, optional\n        Viscosity at the wall temperature, [Pa*s]\n    mu_b : float, optional\n        Viscosity at the bulk temperature, [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with bulk fluid properties, [-]\n\n    Notes\n    -----\n    For the data used to develop the correlation, P varied from 23 to 30 MPa,\n    and D was 12 mm. G varied from 600-1200 kg/m^2/s and q varied from 100 to \n    600 kW/m^2.\n    \n    Cp used in the calculation of Prandtl number should be the average value\n    of those at the wall and the bulk temperatures.\n\n    For deteriorated heat transfer, this was the third most accurate  \n    correlation in [2]_ with a MAD of 20.5%.\n    \n    If the extra density and viscosity information is not provided, it will \n    not be used.\n\n    Examples\n    --------\n    >>> Nu_Xu(1E5, 1.2, 330, 290., 8e-4, 9e-4)\n    289.133054256742\n\n    References\n    ----------\n    .. [1] Xu, F., Guo, L.J., Mao, Y.F., Jiang, X.E., 2005. \"Experimental \n       investigation to the heat transfer characteristics of water in vertical \n       pipes under supercritical pressure\". J. Xi'an Jiaotong University 39, \n       468-471.\n    .. [2] Chen, Weiwei, Xiande Fang, Yu Xu, and Xianghui Su. \"An Assessment of\n       Correlations of Forced Convection Heat Transfer to Water at \n       Supercritical Pressure.\" Annals of Nuclear Energy 76 (February 2015): \n       451-60. doi:10.1016/j.anucene.2014.10.027.\n    '''\n    Nu = 0.02269*Re**0.8079*Pr**0.9213\n    if rho_w and rho_b:\n        Nu *= (rho_w/rho_b)**0.6638\n    if mu_w and mu_b:\n        Nu *= (mu_w/mu_b)**0.8687\n    return Nu", "response": "r Returns the internal convection Nusselt number for turbulent vertical base flow in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Nu_Mokry(Re, Pr, rho_w=None, rho_b=None):\n    r'''Calculates internal convection Nusselt number for turbulent vertical\n    upward flow in a pipe under supercritical conditions according to [1]_,\n    and reviewed in [2]_.\n        \n    .. math::\n        Nu_b = 0.0061 Re_b^{0.904} \\bar{Pr}_b^{0.684}\n        \\left(\\frac{\\rho_w}{\\rho_b}\\right)^{0.564}\n        \n        \\bar{Cp} = \\frac{H_w-H_b}{T_w-T_b}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with bulk fluid properties, [-]\n    Pr : float\n        Prandtl number with bulk fluid properties and an average heat capacity\n        between the wall and bulk temperatures [-]\n    rho_w : float, optional\n        Density at the wall temperature, [kg/m^3]\n    rho_b : float, optional\n        Density at the bulk temperature, [kg/m^3]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with bulk fluid properties, [-]\n\n    Notes\n    -----\n    For the data used to develop the correlation, P was set at 20 MPa, and D \n    was 10 mm. G varied from 200-1500 kg/m^2/s and q varied from 0 to 1250\n    kW/m^2.\n    \n    Cp used in the calculation of Prandtl number should be the average value\n    of those at the wall and the bulk temperatures.\n\n    For deteriorated heat transfer, this was the four most accurate correlation  \n    in [2]_ with a MAD of 24.0%. It was also the 7th most accurate against\n    enhanced heat transfer, with a MAD of 14.7%, and the most accurate for the\n    normal heat transfer database as well as the top correlation in all \n    categories combined.\n    \n    If the extra density information is not provided, it will not be used.\n\n    Examples\n    --------\n    >>> Nu_Mokry(1E5, 1.2, 330, 290.)\n    246.1156319156992\n\n    References\n    ----------\n    .. [1] Mokry, Sarah, Igor Pioro, Amjad Farah, Krysten King, Sahil Gupta, \n       Wargha Peiman, and Pavel Kirillov. \"Development of Supercritical Water \n       Heat-Transfer Correlation for Vertical Bare Tubes.\" Nuclear Engineering\n       and Design, International Conference on Nuclear Energy for New Europe \n       2009, 241, no. 4 (April 2011): 1126-36. \n       doi:10.1016/j.nucengdes.2010.06.012.\n    .. [2] Chen, Weiwei, Xiande Fang, Yu Xu, and Xianghui Su. \"An Assessment of\n       Correlations of Forced Convection Heat Transfer to Water at \n       Supercritical Pressure.\" Annals of Nuclear Energy 76 (February 2015): \n       451-60. doi:10.1016/j.anucene.2014.10.027.\n    '''\n    Nu = 0.0061*Re**0.904*Pr**0.684\n    if rho_w and rho_b:\n        Nu *= (rho_w/rho_b)**0.564\n    return Nu", "response": "r Returns the internal convection Nusselt number for turbulent vertical flow in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Nu_Zhu(Re, Pr, rho_w=None, rho_b=None, k_w=None, k_b=None):\n    r'''Calculates internal convection Nusselt number for turbulent vertical\n    upward flow in a pipe under supercritical conditions according to [1]_.\n        \n    .. math::\n        Nu_b = 0.0068 Re_b^{0.9} \\bar{Pr}_b^{0.63}\n        \\left(\\frac{\\rho_w}{\\rho_b}\\right)^{0.17}\n        \\left(\\frac{k_w}{k_b}\\right)^{0.29}\n\n        \\bar{Cp} = \\frac{H_w-H_b}{T_w-T_b}\n        \n    Parameters\n    ----------\n    Re : float\n        Reynolds number with bulk fluid properties, [-]\n    Pr : float\n        Prandtl number with bulk fluid properties and an average heat capacity\n        between the wall and bulk temperatures [-]\n    rho_w : float, optional\n        Density at the wall temperature, [kg/m^3]\n    rho_b : float, optional\n        Density at the bulk temperature, [kg/m^3]\n    k_w : float, optional\n        Thermal conductivity at the wall temperature, [W/m/K]\n    k_b : float, optional\n        Thermal conductivity at the bulk temperature, [W/m/K]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with bulk fluid properties, [-]\n\n    Notes\n    -----\n    For the data used to develop the correlation, P varied from 22 to 30 MPa,\n    and D was 26 mm. G varied from 600-1200 kg/m^2/s and q varied from 200 to \n    600 kW/m^2.    \n    \n    Cp used in the calculation of Prandtl number should be the average value\n    of those at the wall and the bulk temperatures.\n\n    On the overall database in [2]_, this was the 8th most accurate \n    correlation,and ninth most accurate against normal heat transfer.\n    \n    If the extra density and thermal conductivity information is not provided, \n    it will not be used.\n\n    Examples\n    --------\n    >>> Nu_Zhu(1E5, 1.2, 330, 290., 0.63, 0.69)\n    240.1459854494706\n\n    References\n    ----------\n    .. [1] Zhu, Xiaojing, Qincheng Bi, Dong Yang, and Tingkuan Chen. \"An \n       Investigation on Heat Transfer Characteristics of Different Pressure \n       Steam-Water in Vertical Upward Tube.\" Nuclear Engineering and Design \n       239, no. 2 (February 2009): 381-88. doi:10.1016/j.nucengdes.2008.10.026.\n    .. [2] Chen, Weiwei, Xiande Fang, Yu Xu, and Xianghui Su. \"An Assessment of\n       Correlations of Forced Convection Heat Transfer to Water at \n       Supercritical Pressure.\" Annals of Nuclear Energy 76 (February 2015): \n       451-60. doi:10.1016/j.anucene.2014.10.027.\n    '''\n    Nu = 0.0068*Re**0.9*Pr**0.63\n    if rho_w and rho_b:\n        Nu *= (rho_w/rho_b)**0.17\n    if k_w and k_b:\n        Nu *= (k_w/k_b)**0.29\n    return Nu", "response": "r Returns the internal convection Nusselt number for turbulent vertical flow in a pipe."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Nusselt_laminar(Tsat, Tw, rhog, rhol, kl, mul, Hvap, L, angle=90.):\n    r'''Calculates heat transfer coefficient for laminar film condensation\n    of a pure chemical on a flat plate, as presented in [1]_ according to an\n    analysis performed by Nusselt in 1916.\n\n    .. math::\n        h=0.943\\left[\\frac{g\\sin(\\theta)\\rho_{liq}(\\rho_l-\\rho_v)k_{l}^3\n        \\Delta H_{vap}}{\\mu_l(T_{sat}-T_w)L}\\right]^{0.25}\n\n    Parameters\n    ----------\n    Tsat : float\n        Saturation temperature at operating pressure [Pa]\n    Tw : float\n        Wall temperature, [K]\n    rhog : float\n        Density of the gas [kg/m^3]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    Hvap : float\n        Heat of vaporization of the fluid at P, [J/kg]\n    L : float\n        Length of the plate [m]\n    angle : float, optional\n        Angle of inclination of the plate [degrees]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Optionally, the plate may be inclined.\n    The constant 0.943 is actually:\n    \n    .. math::\n        2\\sqrt{2}/3\n\n    Examples\n    --------\n    p. 578 in [1]_, matches exactly.\n\n    >>> Nusselt_laminar(Tsat=370, Tw=350, rhog=7.0, rhol=585., kl=0.091,\n    ... mul=158.9E-6, Hvap=776900, L=0.1)\n    1482.206403453679\n\n    References\n    ----------\n    .. [1] Hewitt, G. L. Shires T. Reg Bott G. F., George L. Shires, and\n       T. R. Bott. Process Heat Transfer. 1E. Boca Raton: CRC Press, 1994.\n    '''\n    return 2.*2.**0.5/3.*(kl**3*rhol*(rhol - rhog)*g*sin(angle/180.*pi)\n                          *Hvap/(mul*(Tsat - Tw)*L))**0.25", "response": "r Returns a base class for the Nusselt laminar film condensation tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef Cavallini_Smith_Zecchin(m, x, D, rhol, rhog, mul, mug, kl, Cpl):\n    r'''Calculates heat transfer coefficient for condensation\n    of a fluid inside a tube, as presented in\n    [1]_, also given in [2]_ and [3]_.\n\n    .. math::\n        Nu = \\frac{hD_i}{k_l} = 0.05 Re_e^{0.8} Pr_l^{0.33}\n        \n        Re_{eq} = Re_g(\\mu_g/\\mu_l)(\\rho_l/\\rho_g)^{0.5} + Re_l\n\n        v_{gs} = \\frac{mx}{\\rho_g \\frac{\\pi}{4}D^2}\n\n        v_{ls} = \\frac{m(1-x)}{\\rho_l \\frac{\\pi}{4}D^2}\n\n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific interval [-]\n    D : float\n        Diameter of the channel [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    mug : float\n        Viscosity of gas [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Constant-pressure heat capacity of liquid [J/kg/K]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n\n    Examples\n    --------\n    >>> Cavallini_Smith_Zecchin(m=1, x=0.4, D=.3, rhol=800, rhog=2.5, mul=1E-5, mug=1E-3, kl=0.6, Cpl=2300)\n    5578.218369177804\n    \n    References\n    ----------\n    .. [1] A. Cavallini, J. R. Smith and R. Zecchin, A dimensionless correlation\n       for heat transfer in forced convection condensation, 6th International \n       Heat Transfer Conference., Tokyo, Japan (1974) 309-313. \n    .. [2] Kaka\u00e7, Sadik, ed. Boilers, Evaporators, and Condensers. 1st. \n       Wiley-Interscience, 1991.\n    .. [3] Balc\u0131lar, Muhammet, Ahmet Selim Dalk\u0131l\u0131\u00e7, Berna Bolat, and Somchai \n       Wongwises. \"Investigation of Empirical Correlations on the Determination\n       of Condensation Heat Transfer Characteristics during Downward Annular \n       Flow of R134a inside a Vertical Smooth Tube Using Artificial \n       Intelligence Algorithms.\" Journal of Mechanical Science and Technology \n       25, no. 10 (October 12, 2011): 2683-2701. doi:10.1007/s12206-011-0618-2.\n    '''\n    Prl = Prandtl(Cp=Cpl, mu=mul, k=kl)\n    Vl = m*(1-x)/(rhol*pi/4*D**2)\n    Vg = m*x/(rhog*pi/4*D**2)\n    Rel = Reynolds(V=Vl, D=D, rho=rhol, mu=mul)    \n    Reg = Reynolds(V=Vg, D=D, rho=rhog, mu=mug)\n    '''The following was coded, and may be used instead of the above lines,\n    to check that the definitions of parameters here provide the same results\n    as those defined in [1]_.\n    G = m/(pi/4*D**2)\n    Re = G*D/mul\n    Rel = Re*(1-x)\n    Reg = Re*x/(mug/mul)'''\n    Reeq = Reg*(mug/mul)*(rhol/rhog)**0.5 + Rel\n    Nul = 0.05*Reeq**0.8*Prl**0.33\n    return Nul*kl/D", "response": "r Calculates the condensation of a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a single resource in a tube."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Shah(m, x, D, rhol, mul, kl, Cpl, P, Pc):\n    r'''Calculates heat transfer coefficient for condensation\n    of a fluid inside a tube, as presented in [1]_ and again by the same \n    author in [2]_; also given in [3]_. Requires no properties of the gas.\n    Uses the Dittus-Boelter correlation for single phase heat transfer \n    coefficient, with a Reynolds number assuming all the flow is liquid.\n\n    .. math::\n        h_{TP} = h_L\\left[(1-x)^{0.8} +\\frac{3.8x^{0.76}(1-x)^{0.04}}\n        {P_r^{0.38}}\\right]\n    \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific interval [-]\n    D : float\n        Diameter of the channel [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    mul : float\n        Viscosity of liquid [Pa*s]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    Cpl : float\n        Constant-pressure heat capacity of liquid [J/kg/K]\n    P : float\n        Pressure of the fluid, [Pa]\n    Pc : float\n        Critical pressure of the fluid, [Pa]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    [1]_ is well written an unambiguous as to how to apply this equation.\n\n    Examples\n    --------\n    >>> Shah(m=1, x=0.4, D=.3, rhol=800, mul=1E-5, kl=0.6, Cpl=2300, P=1E6, Pc=2E7)\n    2561.2593415479214\n\n    References\n    ----------\n    .. [1] Shah, M. M. \"A General Correlation for Heat Transfer during Film \n       Condensation inside Pipes.\" International Journal of Heat and Mass \n       Transfer 22, no. 4 (April 1, 1979): 547-56. \n       doi:10.1016/0017-9310(79)90058-9. \n    .. [2] Shah, M. M., Heat Transfer During Film Condensation in Tubes and \n       Annuli: A Review of the Literature, ASHRAE Transactions, vol. 87, no. \n       3, pp. 1086-1100, 1981.\n    .. [3] Kaka\u00e7, Sadik, ed. Boilers, Evaporators, and Condensers. 1st. \n       Wiley-Interscience, 1991.\n    '''\n    VL = m/(rhol*pi/4*D**2)\n    ReL = Reynolds(V=VL, D=D, rho=rhol, mu=mul)\n    Prl = Prandtl(Cp=Cpl, k=kl, mu=mul)\n    hL = turbulent_Dittus_Boelter(ReL, Prl)*kl/D\n    Pr = P/Pc\n    return hL*((1-x)**0.8 + 3.8*x**0.76*(1-x)**0.04/Pr**0.38)", "response": "r Calculates the heat transfer coefficient of a single phase flow in a tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Davis_David(m, x, D, rhol, rhog, Cpl, kl, mul):\n    r'''Calculates the two-phase non-boiling heat transfer coefficient of a \n    liquid and gas flowing inside a tube of any inclination, as in [1]_ and \n    reviewed in [2]_.\n\n    .. math::\n        \\frac{h_{TP} D}{k_l} = 0.060\\left(\\frac{\\rho_L}{\\rho_G}\\right)^{0.28}\n        \\left(\\frac{DG_{TP} x}{\\mu_L}\\right)^{0.87}\n        \\left(\\frac{C_{p,L} \\mu_L}{k_L}\\right)^{0.4}\n        \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific tube interval [-]\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    Cpl : float\n        Constant-pressure heat capacity of liquid [J/kg/K]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    mul : float\n        Viscosity of liquid [Pa*s]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    Developed for both vertical and horizontal flow, and flow patters of \n    annular or mist annular flow. Steam-water and air-water were the only \n    considered fluid combinations. Quality ranged from 0.1 to 1 in their data.\n    [1]_ claimed an AAE of 17%.\n\n    Examples\n    --------\n    >>> Davis_David(m=1, x=.9, D=.3, rhol=1000, rhog=2.5, Cpl=2300, kl=.6, \n    ... mul=1E-3)\n    1437.3282869955121\n\n    References\n    ----------\n    .. [1] Davis, E. J., and M. M. David. \"Two-Phase Gas-Liquid Convection Heat\n       Transfer. A Correlation.\" Industrial & Engineering Chemistry \n       Fundamentals 3, no. 2 (May 1, 1964): 111-18. doi:10.1021/i160010a005.\n    .. [2] Dongwoo Kim, Venkata K. Ryali, Afshin J. Ghajar, Ronald L. \n       Dougherty. \"Comparison of 20 Two-Phase Heat Transfer Correlations with \n       Seven Sets of Experimental Data, Including Flow Pattern and Tube \n       Inclination Effects.\" Heat Transfer Engineering 20, no. 1 (February 1, \n       1999): 15-40. doi:10.1080/014576399271691.\n    '''\n    G = m/(pi/4*D**2)\n    Prl = Prandtl(Cp=Cpl, mu=mul, k=kl)\n    Nu_TP = 0.060*(rhol/rhog)**0.28*(D*G*x/mul)**0.87*Prl**0.4\n    return Nu_TP*kl/D", "response": "r Calculates the two - phase non - boiling heat transfer coefficient of a given liquid and gas flowing inside a specific tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Elamvaluthi_Srinivas(m, x, D, rhol, rhog, Cpl, kl, mug, mu_b, mu_w=None):\n    r'''Calculates the two-phase non-boiling heat transfer coefficient of a \n    liquid and gas flowing inside a tube of any inclination, as in [1]_ and \n    reviewed in [2]_.\n\n    .. math::\n        \\frac{h_{TP} D}{k_L} = 0.5\\left(\\frac{\\mu_G}{\\mu_L}\\right)^{0.25} \n        Re_M^{0.7} Pr^{1/3}_L (\\mu_b/\\mu_w)^{0.14}\n        \n        Re_M = \\frac{D V_L \\rho_L}{\\mu_L} + \\frac{D V_g \\rho_g}{\\mu_g}\n        \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific tube interval [-]\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    Cpl : float\n        Constant-pressure heat capacity of liquid [J/kg/K]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    mug : float\n        Viscosity of gas [Pa*s]\n    mu_b : float\n        Viscosity of liquid at bulk conditions (average of inlet/outlet \n        temperature) [Pa*s]\n    mu_w : float, optional\n        Viscosity of liquid at wall temperature [Pa*s]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    If the viscosity at the wall temperature is not given, the liquid viscosity\n    correction is not applied.\n    \n    Developed for vertical flow, and flow patters of bubbly and slug.\n    Gas/liquid superficial velocity ratios from 0.3 to 4.6, liquid mass fluxes \n    from 200 to 1600 kg/m^2/s, and the fluids tested were air-water and \n    air-aqueous glycerine solutions. The tube inner diameter was 1 cm, and the\n    L/D ratio was 86.\n    \n    Examples\n    --------\n    >>> Elamvaluthi_Srinivas(m=1, x=.9, D=.3, rhol=1000, rhog=2.5, Cpl=2300, \n    ... kl=.6, mug=1E-5, mu_b=1E-3, mu_w=1.2E-3)\n    3901.2134471578584\n    \n    References\n    ----------\n    .. [1] Elamvaluthi, G., and N. S. Srinivas. \"Two-Phase Heat Transfer in Two\n       Component Vertical Flows.\" International Journal of Multiphase Flow 10, \n       no. 2 (April 1, 1984): 237-42. doi:10.1016/0301-9322(84)90021-1.\n    .. [2] Dongwoo Kim, Venkata K. Ryali, Afshin J. Ghajar, Ronald L. \n       Dougherty. \"Comparison of 20 Two-Phase Heat Transfer Correlations with \n       Seven Sets of Experimental Data, Including Flow Pattern and Tube \n       Inclination Effects.\" Heat Transfer Engineering 20, no. 1 (February 1, \n       1999): 15-40. doi:10.1080/014576399271691.\n    '''\n    Vg = m*x/(rhog*pi/4*D**2)\n    Vl = m*(1-x)/(rhol*pi/4*D**2)\n\n    Prl = Prandtl(Cp=Cpl, mu=mu_b, k=kl)\n    ReM = D*Vl*rhol/mu_b + D*Vg*rhog/mug\n    Nu_TP = 0.5*(mug/mu_b)**0.25*ReM**0.7*Prl**(1/3.)\n    if mu_w:\n        Nu_TP *= (mu_b/mu_w)**0.14\n    return Nu_TP*kl/D", "response": "r Returns the two - phase non - boiling non - boiling heat transfer coefficient of a given liquid and gas flowing inside a specific tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Ravipudi_Godbold(m, x, D, rhol, rhog, Cpl, kl, mug, mu_b, mu_w=None):\n    r'''Calculates the two-phase non-boiling heat transfer coefficient of a \n    liquid and gas flowing inside a tube of any inclination, as in [1]_ and \n    reviewed in [2]_.\n\n    .. math::\n        Nu = \\frac{h_{TP} D}{k_l} = 0.56 \\left(\\frac{V_{gs}}{V_{ls}}\n        \\right)^{0.3}\\left(\\frac{\\mu_g}{\\mu_l}\\right)^{0.2} Re_{ls}^{0.6} \n        Pr_l^{1/3}\\left(\\frac{\\mu_b}{\\mu_w}\\right)^{0.14}\n    \n    Parameters\n    ----------\n    m : float\n        Mass flow rate [kg/s]\n    x : float\n        Quality at the specific tube interval [-]\n    D : float\n        Diameter of the tube [m]\n    rhol : float\n        Density of the liquid [kg/m^3]\n    rhog : float\n        Density of the gas [kg/m^3]\n    Cpl : float\n        Constant-pressure heat capacity of liquid [J/kg/K]\n    kl : float\n        Thermal conductivity of liquid [W/m/K]\n    mug : float\n        Viscosity of gas [Pa*s]\n    mu_b : float\n        Viscosity of liquid at bulk conditions (average of inlet/outlet \n        temperature) [Pa*s]\n    mu_w : float, optional\n        Viscosity of liquid at wall temperature [Pa*s]\n\n    Returns\n    -------\n    h : float\n        Heat transfer coefficient [W/m^2/K]\n\n    Notes\n    -----\n    If the viscosity at the wall temperature is not given, the liquid viscosity\n    correction is not applied.\n    \n    Developed with a vertical pipe, superficial gas/liquid velocity ratios of \n    1-90, in the froth regime, and for fluid mixtures of air and water, \n    toluene, benzene, and methanol.\n    \n    Examples\n    --------\n    >>> Ravipudi_Godbold(m=1, x=.9, D=.3, rhol=1000, rhog=2.5, Cpl=2300, kl=.6, mug=1E-5, mu_b=1E-3, mu_w=1.2E-3)\n    299.3796286459285\n\n    References\n    ----------\n    .. [1] Ravipudi, S., and Godbold, T., The Effect of Mass Transfer on Heat\n       Transfer Rates for Two-Phase Flow in a Vertical Pipe, Proceedings 6th \n       International Heat Transfer Conference, Toronto, V. 1, p. 505-510, 1978.\n    .. [2] Dongwoo Kim, Venkata K. Ryali, Afshin J. Ghajar, Ronald L. \n       Dougherty. \"Comparison of 20 Two-Phase Heat Transfer Correlations with \n       Seven Sets of Experimental Data, Including Flow Pattern and Tube \n       Inclination Effects.\" Heat Transfer Engineering 20, no. 1 (February 1, \n       1999): 15-40. doi:10.1080/014576399271691.\n    '''\n    Vgs = m*x/(rhog*pi/4*D**2)\n    Vls = m*(1-x)/(rhol*pi/4*D**2)\n    Prl = Prandtl(Cp=Cpl, mu=mu_b, k=kl)\n    Rels = D*Vls*rhol/mu_b\n    Nu = 0.56*(Vgs/Vls)**0.3*(mug/mu_b)**0.2*Rels**0.6*Prl**(1/3.)\n    if mu_w:\n        Nu *= (mu_b/mu_w)**0.14\n    return Nu*kl/D", "response": "r Calculates the two - phase non - boiling heat transfer coefficient of a single liquid and gas flowing inside a single tube."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef R_value_to_k(R_value, SI=True):\n    r'''Returns the thermal conductivity of a substance given its R-value,\n    which can be in either SI units of m^2 K/(W*inch) or the Imperial units\n    of ft^2 deg F*h/(BTU*inch).\n\n    Parameters\n    ----------\n    R_value : float\n        R-value of a substance [m^2 K/(W*inch) or ft^2 deg F*h/(BTU*inch)]\n    SI : bool, optional\n        Whether to use the SI conversion or not\n\n    Returns\n    -------\n    k : float\n        Thermal conductivity of a substance [W/m/K]\n\n    Notes\n    -----\n    If given input is SI, it is divided by 0.0254 (multiplied by 39.37) and\n    then inversed. Otherwise, it is multiplied by 6.93347 and then inversed.\n\n    Examples\n    --------\n    >>> R_value_to_k(0.12), R_value_to_k(0.71, SI=False)\n    (0.2116666666666667, 0.20313787163983468)\n\n    >>> R_value_to_k(1., SI=False)/R_value_to_k(1.)\n    5.678263341113488\n\n    References\n    ----------\n    .. [1] Gesellschaft, V. D. I., ed. VDI Heat Atlas. 2nd edition.\n       Berlin; New York:: Springer, 2010.\n    '''\n    if SI:\n        r = R_value/inch\n    else:\n        r = R_value*foot**2*degree_Fahrenheit*hour/Btu/inch\n    return thermal_resistivity_to_k(r)", "response": "r Returns the thermal conductivity of a substance given its R - value and SI = True if the substance is in SI units of m^2 K or BTU units of m^2 K or BTU units of m^2 K or BTU units of m^2 K."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef S_isothermal_pipe_to_isothermal_pipe(D1, D2, W, L=1.):\n    r'''Returns the Shape factor `S` of a pipe of constant outer temperature\n    and of outer diameter `D1` which is `w` distance from another infinite\n    pipe of outer diameter`D2`. Length `L` must be provided, but can be set to\n    1 to obtain a dimensionless shape factor used in some sources.\n\n    .. math::\n        S = \\frac{2\\pi L}{\\cosh^{-1}\\left(\\frac{4w^2-D_1^2-D_2^2}{2D_1D_2}\\right)}\n\n    Parameters\n    ----------\n    D1 : float\n        Diameter of one pipe, [m]\n    D2 : float\n        Diameter of the other pipe, [m]\n    W : float\n        Distance from the middle of one pipe to the middle of the other, [m]\n    L : float, optional\n        Length of the pipe, [m]\n\n    Returns\n    -------\n    S : float\n        Shape factor [m]\n\n    Examples\n    --------\n    >>> S_isothermal_pipe_to_isothermal_pipe(.1, .2, 1, 1)\n    1.188711034982268\n\n    Notes\n    -----\n    L should be much larger than both diameters. L should be larger than W.\n\n    .. math::\n        Q = Sk(T_1 - T_2) \\\\ R_{\\text{shape}}=\\frac{1}{Sk}\n\n    References\n    ----------\n    .. [1] Kreith, Frank, Raj Manglik, and Mark Bohn. Principles of Heat\n       Transfer. Cengage, 2010.\n    .. [2] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    return 2.*pi*L/acosh((4*W**2 - D1**2 - D2**2)/(2.*D1*D2))", "response": "r Returns the Shape factor S of a pipe of constant outer temperature D1 and of outer diameter D2 which is w distance from another infinite base pipe of outer diameter D2."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef S_isothermal_pipe_to_two_planes(D, Z, L=1.):\n    r'''Returns the Shape factor `S` of a pipe of constant outer temperature\n    and of outer diameter `D` which is `Z` distance from two infinite\n    isothermal planes of equal temperatures, parallel to each other and\n    enclosing the pipe. Length `L` must be provided, but can be set to\n    1 to obtain a dimensionless shape factor used in some sources.\n\n    .. math::\n        S = \\frac{2\\pi L}{\\ln\\frac{8z}{\\pi D}}\n\n    Parameters\n    ----------\n    D : float\n        Diameter of the pipe, [m]\n    Z : float\n        Distance from the middle of the pipe to either of the planes, [m]\n    L : float, optional\n        Length of the pipe, [m]\n\n    Returns\n    -------\n    S : float\n        Shape factor [m]\n\n    Examples\n    --------\n    >>> S_isothermal_pipe_to_two_planes(.1, 5, 1)\n    1.2963749299921428\n\n    Notes\n    -----\n    L should be much larger than both diameters. L should be larger than W.\n\n    .. math::\n        Q = Sk(T_1 - T_2) \\\\ R_{\\text{shape}}=\\frac{1}{Sk}\n\n    References\n    ----------\n    .. [1] Shape Factors for Heat Conduction Through Bodies with Isothermal or\n       Convective Boundary Conditions, J. E. Sunderland, K. R. Johnson, ASHRAE\n       Transactions, Vol. 70, 1964.\n    .. [2] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    return 2.*pi*L/log(8.*Z/(pi*D))", "response": "r Returns the Shape factor S of a pipe of constant outer temperature D and of outer diameter Z which is a distance from two infinite isothermal planes of equal temperatures parallel to each other and the length L."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wall_factor_fd(mu, mu_wall, turbulent=True, liquid=False):\n    r'''Computes the wall correction factor for pressure drop due to friction\n    between a fluid and a wall. These coefficients were derived for internal \n    flow inside a pipe, but can be used elsewhere where appropriate data is \n    missing. \n    \n    .. math::\n        \\frac{f_d}{f_{d,\\text{constant properties}}} \n        = \\left(\\frac{\\mu}{\\mu_{wall}}\\right)^n\n\n    Parameters\n    ----------\n    mu : float\n        Viscosity (or Prandtl number) of flowing fluid away from the wall,\n        [Pa*s]\n    mu_wall : float\n        Viscosity (or Prandtl number) of the fluid at the wall, [Pa*s]\n    turbulent : bool\n        Whether or not to use the turbulent coefficient, [-]\n    liquid : bool\n        Whether or not to use the liquid phase coefficient; otherwise the gas\n        coefficient is used, [-]\n        \n    Returns\n    -------\n    factor : float\n        Correction factor for pressure loss; to be multiplied by the friction\n        factor, or pressure drop to obtain the actual result, [-]\n\n    Notes\n    -----\n    The exponents are determined as follows:\n        \n    +-----------+--------+---------+---------+\n    | Regime    | Phase  | Heating | Cooling |\n    +===========+========+=========+=========+\n    | Turbulent | Liquid | -0.25   | -0.25   |\n    +-----------+--------+---------+---------+\n    | Turbulent | Gas    | 0.1     | 0.1     |\n    +-----------+--------+---------+---------+\n    | Laminar   | Liquid | -0.58   | -0.5    |\n    +-----------+--------+---------+---------+\n    | Laminar   | Gas    | -1      | -1      |\n    +-----------+--------+---------+---------+\n    \n    Examples\n    --------\n    >>> wall_factor_fd(mu=8E-4, mu_wall=3E-4, turbulent=True, liquid=True)\n    0.7825422900366437\n\n    References\n    ----------\n    .. [1] Kays, William M., and Michael E. Crawford. Convective Heat and Mass \n       Transfer. 3rd edition. New York: McGraw-Hill Science/Engineering/Math,\n       1993.\n    '''\n    params = wall_factor_fd_defaults[(turbulent, liquid)]\n    return wall_factor(mu=mu, mu_wall=mu_wall, **params)", "response": "r Returns the correction factor for pressure drop due to friction between a fluid and a wall."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wall_factor_Nu(mu, mu_wall, turbulent=True, liquid=False):\n    r'''Computes the wall correction factor for heat transfer between a fluid\n    and a wall. These coefficients were derived for internal flow inside a \n    pipe, but can be used elsewhere where appropriate data is missing. It is\n    also useful to compare these results with the coefficients used in various\n    heat transfer coefficients.\n    \n    .. math::\n        \\frac{Nu}{Nu_{\\text{constant properties}}} \n        = \\left(\\frac{\\mu}{\\mu_{wall}}\\right)^n\n\n    Parameters\n    ----------\n    mu : float\n        Viscosity (or Prandtl number) of flowing fluid away from the heat\n        transfer surface, [Pa*s]\n    mu_wall : float\n        Viscosity (or Prandtl number) of the fluid at the wall, [Pa*s]\n    turbulent : bool\n        Whether or not to use the turbulent coefficient, [-]\n    liquid : bool\n        Whether or not to use the liquid phase coefficient; otherwise the gas\n        coefficient is used, [-]\n        \n    Returns\n    -------\n    factor : float\n        Correction factor for heat transfer; to be multiplied by the Nusselt\n        number, or heat transfer coefficient to obtain the actual result, [-]\n\n    Notes\n    -----\n    The exponents are determined as follows:\n        \n    +-----------+--------+---------+---------+\n    | Regime    | Phase  | Heating | Cooling |\n    +===========+========+=========+=========+\n    | Turbulent | Liquid | 0.11    | 0.25    |\n    +-----------+--------+---------+---------+\n    | Turbulent | Gas    | 0.5     | 0       |\n    +-----------+--------+---------+---------+\n    | Laminar   | Liquid | 0.14    | 0.14    |\n    +-----------+--------+---------+---------+\n    | Laminar   | Gas    | 0       | 0       |\n    +-----------+--------+---------+---------+    \n    \n    Examples\n    --------\n    >>> wall_factor_Nu(mu=8E-4, mu_wall=3E-4, turbulent=True, liquid=True)\n    1.1139265634480144\n    \n    >>> wall_factor_Nu(mu=8E-4, mu_wall=3E-4, turbulent=False, liquid=True)\n    1.147190712947014\n    \n    >>> wall_factor_Nu(mu=1.5E-5, mu_wall=1.3E-5, turbulent=True, liquid=False)\n    1.0741723110591495\n    \n    >>> wall_factor_Nu(mu=1.5E-5, mu_wall=1.3E-5, turbulent=False, liquid=False)\n    1.0\n\n    References\n    ----------\n    .. [1] Kays, William M., and Michael E. Crawford. Convective Heat and Mass \n       Transfer. 3rd edition. New York: McGraw-Hill Science/Engineering/Math,\n       1993.\n    '''\n    params = wall_factor_Nu_defaults[(turbulent, liquid)]\n    return wall_factor(mu=mu, mu_wall=mu_wall, **params)", "response": "r Returns the correction factor for a fluid that is used for the Nusselt - based flow between a fluid and a wall."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wall_factor(mu=None, mu_wall=None, Pr=None, Pr_wall=None, T=None, \n                T_wall=None, mu_heating_coeff=0.11, mu_cooling_coeff=0.25, \n                Pr_heating_coeff=0.11, Pr_cooling_coeff=0.25, \n                T_heating_coeff=0.11, T_cooling_coeff=0.25,\n                property_option=WALL_FACTOR_PRANDTL):\n    r'''Computes the wall correction factor for heat transfer, mass transfer,\n    or momentum transfer between a fluid and a wall. Utility function; the\n    coefficients for the phenomenon must be provided to this method. The\n    default coefficients are for heat transfer of a turbulent liquid.\n    \n    The general formula is as follows; substitute the property desired and\n    the phenomenon desired into the equation for things other than heat\n    transfer.\n    \n    .. math::\n        \\frac{Nu}{Nu_{\\text{constant properties}}} \n        = \\left(\\frac{\\mu}{\\mu_{wall}}\\right)^n\n\n    Parameters\n    ----------\n    mu : float, optional\n        Viscosity of flowing fluid away from the surface, [Pa*s]\n    mu_wall : float, optional\n        Viscosity of the fluid at the wall, [Pa*s]\n    Pr : float, optional\n        Prandtl number of flowing fluid away from the surface, [-]\n    Pr_wall : float, optional\n        Prandtl number of the fluid at the wall, [-]\n    T : float, optional\n        Temperature of flowing fluid away from the surface, [K]\n    T_wall : float, optional\n        Temperature of the fluid at the wall, [K]\n    mu_heating_coeff : float, optional\n        Coefficient for viscosity - surface providing heating, [-]\n    mu_cooling_coeff : float, optional\n        Coefficient for viscosity - surface providing cooling, [-]\n    Pr_heating_coeff : float, optional\n        Coefficient for Prandtl number - surface providing heating, [-]\n    Pr_cooling_coeff : float, optional\n        Coefficient for Prandtl number - surface providing cooling, [-]\n    T_heating_coeff : float, optional\n        Coefficient for temperature - surface providing heating, [-]\n    T_cooling_coeff : float, optional\n        Coefficient for temperature - surface providing cooling, [-]\n    property_option : str, optional\n        Which property to use for computing the correction factor; one of\n        'Viscosity', 'Prandtl', or 'Temperature'.\n        \n    Returns\n    -------\n    factor : float\n        Correction factor for heat transfer; to be multiplied by the Nusselt\n        number or heat transfer coefficient or friction factor or pressure drop\n        to obtain the actual result, [-]\n    \n    Examples\n    --------\n    >>> wall_factor(mu=8E-4, mu_wall=3E-4, Pr=1.2, Pr_wall=1.1, T=300,\n    ... T_wall=350, property_option='Prandtl')\n    1.0096172023817749\n    '''\n    if property_option == WALL_FACTOR_DEFAULT:\n        property_option = WALL_FACTOR_PRANDTL\n    if property_option == WALL_FACTOR_VISCOSITY:\n        if mu is None or mu_wall is None:\n            raise TypeError('Viscosity wall correction specified but both '\n                            'viscosity values are not available.')\n        heating = is_heating_property(mu, mu_wall)\n        if heating:\n            return (mu/mu_wall)**mu_heating_coeff\n        else:\n            return (mu/mu_wall)**mu_cooling_coeff\n    elif property_option == WALL_FACTOR_TEMPERATURE: \n        if T is None or T_wall is None:\n            raise TypeError('Temperature wall correction specified but both '\n                            'temperature values are not available.')\n        heating = is_heating_temperature(T, T_wall)\n        if heating:\n            return (T/T_wall)**T_heating_coeff\n        else:\n            return (T/T_wall)**T_cooling_coeff\n    elif property_option == WALL_FACTOR_PRANDTL: \n        if Pr is None or Pr_wall is None:\n            raise TypeError('Prandtl number wall correction specified but both'\n                            ' Prandtl number values are not available.') \n        heating = is_heating_property(Pr, Pr_wall)\n        if heating:\n            return (Pr/Pr_wall)**Pr_heating_coeff\n        else:\n            return (Pr/Pr_wall)**Pr_cooling_coeff\n    else:\n        raise Exception('Supported options are %s' %([WALL_FACTOR_VISCOSITY, \n                                                      WALL_FACTOR_PRANDTL, \n                                                      WALL_FACTOR_TEMPERATURE,\n                                                      WALL_FACTOR_DEFAULT]))", "response": "r Returns the wall correction factor for heat transfer mass transfer and momentum transfer between a fluid and a wall."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Ft_aircooler(Thi, Tho, Tci, Tco, Ntp=1, rows=1):\n    r'''Calculates log-mean temperature difference correction factor for\n    a crossflow heat exchanger, as in an Air Cooler. Method presented in [1]_,\n    fit to other's nonexplicit work. Error is < 0.1%. Requires number of rows\n    and tube passes as well as stream temperatures.\n\n    .. math::\n        F_T = 1 - \\sum_{i=1}^m \\sum_{k=1}^n a_{i,k}(1-r_{1,m})^k\\sin(2i\\arctan R)\n\n        R = \\frac{T_{hi} - T_{ho}}{T_{co}-T_{ci}}\n\n        r_{1,m} = \\frac{\\Delta T_{lm}}{T_{hi} - T_{ci}}\n\n    Parameters\n    ----------\n    Thi : float\n        Temperature of hot fluid in [K]\n    Tho : float\n        Temperature of hot fluid out [K]\n    Tci : float\n        Temperature of cold fluid in [K]\n    Tco : float\n        Temperature of cold fluid out [K]\n    Ntp : int\n        Number of passes the tubeside fluid will flow through [-]\n    rows : int\n        Number of rows of tubes [-]\n\n    Returns\n    -------\n    Ft : float\n        Log-mean temperature difference correction factor [-]\n\n    Notes\n    -----\n    This equation assumes that the hot fluid is tubeside, as in the case of air\n    coolers. The model is not symmetric, so ensure to switch around the inputs\n    if using this function for other purposes.\n\n    This equation appears in [1]_. It has been verified.\n    For some cases, approximations are made to match coefficients with the\n    number of tube passes and rows provided.\n    16 coefficients are used for each case; 8 cases are considered:\n\n    * 1 row 1 pass\n    * 2 rows 1 pass\n    * 2 rows 2 passes\n    * 3 rows 1 pass\n    * 3 rows 3 passes\n    * 4 rows 1 pass\n    * 4 rows 2 passes\n    * 4 rows 4 passes\n\n    Examples\n    --------\n    >>> Ft_aircooler(Thi=125., Tho=45., Tci=25., Tco=95., Ntp=1, rows=4)\n    0.5505093604092708\n\n    References\n    ----------\n    .. [1] Roetzel, W., and F. J. L. Nicole. \"Mean Temperature Difference for\n       Heat Exchanger Design-A General Approximate Explicit Equation.\" Journal\n       of Heat Transfer 97, no. 1 (February 1, 1975): 5-8.\n       doi:10.1115/1.3450288\n    '''\n    dTlm = LMTD(Thi=Thi, Tho=Tho, Tci=Tci, Tco=Tco)\n    rlm = dTlm/(Thi-Tci)\n    R = (Thi-Tho)/(Tco-Tci)\n#    P = (Tco-Tci)/(Thi-Tci)\n\n    if Ntp == 1 and rows == 1:\n        coefs = _crossflow_1_row_1_pass\n    elif Ntp == 1 and rows == 2:\n        coefs = _crossflow_2_rows_1_pass\n    elif Ntp == 1 and rows == 3:\n        coefs = _crossflow_3_rows_1_pass\n    elif Ntp == 1 and rows == 4:\n        coefs = _crossflow_4_rows_1_pass\n    elif Ntp == 1 and rows > 4:\n        # A reasonable assumption\n        coefs = _crossflow_4_rows_1_pass\n    elif Ntp == 2 and rows == 2:\n        coefs = _crossflow_2_rows_2_pass\n    elif Ntp == 3 and rows == 3:\n        coefs = _crossflow_3_rows_3_pass\n    elif Ntp == 4 and rows == 4:\n        coefs = _crossflow_4_rows_4_pass\n    elif Ntp > 4 and rows > 4 and Ntp == rows:\n        # A reasonable assumption\n        coefs = _crossflow_4_rows_4_pass\n    elif Ntp  == 2 and rows == 4:\n        coefs = _crossflow_4_rows_2_pass\n    else:\n        # A bad assumption, but hey, gotta pick something.\n        coefs = _crossflow_4_rows_2_pass\n    tot = 0\n    atanR = atan(R)\n    cmps = range(len(coefs))\n    for k in cmps:\n        x0 = (1. - rlm)**(k + 1.)\n        for i in cmps:\n            tot += coefs[k][i]*x0*sin(2.*(i + 1.)*atanR)\n    return 1. - tot", "response": "r Calculates the log - mean temperature difference correction factor for a crossflow heat exchanger."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dP_Zukauskas(Re, n, ST, SL, D, rho, Vmax):\n    r'''Calculates pressure drop for crossflow across a tube bank\n    of tube number n at a specified Re. Method presented in [1]_.\n    Also presented in [2]_.\n\n    .. math::\n        \\Delta P = N_L \\chi \\left(\\frac{\\rho V_{max}^2}{2}\\right)f\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number, [-]\n    n : float\n        Number of tube rows, [-]\n    ST : float\n        Transverse pitch, used only by some conditions, [m]\n    SL : float\n        Longitudal pitch, used only by some conditions, [m]\n    D : float\n        Tube outer diameter, [m]\n    rho : float\n        Fluid density, [kg/m^3]\n    Vmax : float\n        Maximum velocity, [m/s]\n\n    Returns\n    -------\n    dP : float\n        Pressure drop, [Pa]\n\n    Notes\n    -----\n    Does not account for effects in a heat exchanger.\n    Example 2 is from [2]_. Matches to 0.3%; figures are very approximate.\n    Interpolation used with 4 graphs to obtain friction factor and a\n    correction factor.\n\n    Examples\n    --------\n    >>> dP_Zukauskas(Re=13943., n=7, ST=0.0313, SL=0.0343, D=0.0164, rho=1.217, Vmax=12.6)\n    235.22916169118335\n    >>> dP_Zukauskas(Re=13943., n=7, ST=0.0313, SL=0.0313, D=0.0164, rho=1.217, Vmax=12.6)\n    217.0750033117563\n\n    References\n    ----------\n    .. [1] Zukauskas, A. Heat transfer from tubes in crossflow. In T.F. Irvine,\n       Jr. and J. P. Hartnett, editors, Advances in Heat Transfer, volume 8,\n       pages 93-160. Academic Press, Inc., New York, 1972.\n    .. [2] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    a = ST/D\n    b = SL/D\n    if a == b:\n        parameter = (a-1.)/(b-1.)\n        f = float(dP_inline_f(Re, b))\n        x = float(dP_inline_correction(parameter, Re))\n    else:\n        parameter = a/b\n        f = float(dP_staggered_f(Re, a))\n        x = float(dP_staggered_correction(parameter, Re))\n\n    return n*x*f*rho/2*Vmax**2", "response": "r Calculates pressure drop for crossflow across a tube bank and a tube number n."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef Nu_cylinder_Zukauskas(Re, Pr, Prw=None):\n    r'''Calculates Nusselt number for crossflow across a single tube at a\n    specified Re. Method from [1]_, also shown without modification in [2]_.\n\n    .. math::\n        Nu_{D}=CRe^{m}Pr^{n}\\left(\\frac{Pr}{Pr_s}\\right)^{1/4}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to cylinder diameter, [-]\n    Pr : float\n        Prandtl number at free stream temperature [-]\n    Prw : float, optional\n        Prandtl number at wall temperature, [-]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to cylinder diameter, [-]\n\n    Notes\n    -----\n    If Prandtl number at wall are not provided, the Prandtl number correction\n    is not used and left to an outside function.\n\n    n is 0.37 if Pr <= 10; otherwise n is 0.36.\n\n    C and m are from the following table. If Re is outside of the ranges shown,\n    the nearest range is used blindly.\n\n    +---------+-------+-----+\n    | Re      | C     | m   |\n    +=========+=======+=====+\n    | 1-40    | 0.75  | 0.4 |\n    +---------+-------+-----+\n    | 40-1E3  | 0.51  | 0.5 |\n    +---------+-------+-----+\n    | 1E3-2E5 | 0.26  | 0.6 |\n    +---------+-------+-----+\n    | 2E5-1E6 | 0.076 | 0.7 |\n    +---------+-------+-----+\n\n    Examples\n    --------\n    Example 7.3 in [2]_, matches.\n\n    >>> Nu_cylinder_Zukauskas(7992, 0.707, 0.69)\n    50.523612661934386\n\n    References\n    ----------\n    .. [1] Zukauskas, A. Heat transfer from tubes in crossflow. In T.F. Irvine,\n       Jr. and J. P. Hartnett, editors, Advances in Heat Transfer, volume 8,\n       pages 93-160. Academic Press, Inc., New York, 1972.\n    .. [2] Bergman, Theodore L., Adrienne S. Lavine, Frank P. Incropera, and\n       David P. DeWitt. Introduction to Heat Transfer. 6E. Hoboken, NJ:\n       Wiley, 2011.\n    '''\n    if Re <= 40:\n        c, m = 0.75, 0.4\n    elif Re < 1E3:\n        c, m = 0.51, 0.5\n    elif Re < 2E5:\n        c, m = 0.26, 0.6\n    else:\n        c, m = 0.076, 0.7\n    if Pr <= 10:\n        n = 0.37\n    else:\n        n = 0.36\n    Nu = c*Re**m*Pr**n\n    if Prw:\n        Nu = Nu*(Pr/Prw)**0.25\n    return Nu", "response": "r Returns the number of crossflow across a single tube at a\n    specified Re and Pr and Prw."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Nu_cylinder_Whitaker(Re, Pr, mu=None, muw=None):\n    r'''Calculates Nusselt number for crossflow across a single tube as shown\n    in [1]_ at a specified `Re` and `Pr`, both evaluated at the free stream\n    temperature. Recommends a viscosity exponent correction of 0.25, which is\n    applied only if provided. Also shown in [2]_.\n\n    .. math::\n        Nu_D = (0.4 Re_D^{0.5} + 0.06Re_D^{2/3})Pr^{0.4}\n        \\left(\\frac{\\mu}{\\mu_w}\\right)^{0.25}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to cylinder diameter, [-]\n    Pr : float\n        Prandtl number at free stream temperature, [-]\n    mu : float, optional\n        Viscosity of fluid at the free stream temperature [Pa*s]\n    muw : float, optional\n        Viscosity of fluid at the wall temperature [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to cylinder diameter, [-]\n\n    Notes\n    -----\n    Developed considering data from 1 to 1E5 Re, 0.67 to 300 Pr, and range of\n    viscosity ratios from 0.25 to 5.2. Found experimental data to generally\n    agree with it within 25%.\n\n    Examples\n    --------\n    >>> Nu_cylinder_Whitaker(6071, 0.7)\n    45.94527461589126\n\n    References\n    ----------\n    .. [1] Whitaker, Stephen. \"Forced Convection Heat Transfer Correlations for\n       Flow in Pipes, Past Flat Plates, Single Cylinders, Single Spheres, and\n       for Flow in Packed Beds and Tube Bundles.\" AIChE Journal 18, no. 2\n       (March 1, 1972): 361-371. doi:10.1002/aic.690180219.\n    .. [2] Sanitjai, S., and R. J. Goldstein. \"Forced Convection Heat Transfer\n       from a Circular Cylinder in Crossflow to Air and Liquids.\" International\n       Journal of Heat and Mass Transfer 47, no. 22 (October 2004): 4795-4805.\n       doi:10.1016/j.ijheatmasstransfer.2004.05.012.\n    '''\n    Nu = (0.4*Re**0.5 + 0.06*Re**(2/3.))*Pr**0.3\n    if mu and muw:\n        Nu *= (mu/muw)**0.25\n    return Nu", "response": "r Returns a string that represents the number of crossflow across a single tube."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Nu_cylinder_Perkins_Leppert_1962(Re, Pr, mu=None, muw=None):\n    r'''Calculates Nusselt number for crossflow across a single tube as shown\n    in [1]_ at a specified `Re` and `Pr`, both evaluated at the free stream\n    temperature. Recommends a viscosity exponent correction of 0.25, which is\n    applied only if provided. Also shown in [2]_.\n\n    .. math::\n        Nu = \\left[0.30Re^{0.5} + 0.10Re^{0.67}\\right]Pr^{0.4}\n        \\left(\\frac{\\mu}{\\mu_w}\\right)^{0.25}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to cylinder diameter, [-]\n    Pr : float\n        Prandtl number at free stream temperature, [-]\n    mu : float, optional\n        Viscosity of fluid at the free stream temperature [Pa*s]\n    muw : float, optional\n        Viscosity of fluid at the wall temperature [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to cylinder diameter, [-]\n\n    Notes\n    -----\n    Considered results with Re from 40 to 1E5, Pr from 1 to 300; and viscosity\n    ratios of 0.25 to 4.\n\n    Examples\n    --------\n    >>> Nu_cylinder_Perkins_Leppert_1962(6071, 0.7)\n    49.97164291175499\n\n    References\n    ----------\n    .. [1] Perkins, Jr., H. C., and G. Leppert. \"Forced Convection Heat\n       Transfer From a Uniformly Heated Cylinder.\" Journal of Heat Transfer 84,\n       no. 3 (August 1, 1962): 257-261. doi:10.1115/1.3684359.\n    .. [2] Sanitjai, S., and R. J. Goldstein. \"Forced Convection Heat Transfer\n       from a Circular Cylinder in Crossflow to Air and Liquids.\" International\n       Journal of Heat and Mass Transfer 47, no. 22 (October 2004): 4795-4805.\n       doi:10.1016/j.ijheatmasstransfer.2004.05.012.\n    '''\n    Nu = (0.30*Re**0.5 + 0.10*Re**0.67)*Pr**0.4\n    if mu and muw:\n        Nu *= (mu/muw)**0.25\n    return Nu", "response": "r A function that calculates the Nusselt number for crossflow across a single tube at a specified free stream temperature and temperature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef Nu_cylinder_Perkins_Leppert_1964(Re, Pr, mu=None, muw=None):\n    r'''Calculates Nusselt number for crossflow across a single tube as shown\n    in [1]_ at a specified `Re` and `Pr`, both evaluated at the free stream\n    temperature. Recommends a viscosity exponent correction of 0.25, which is\n    applied only if provided. Also shown in [2]_.\n\n    .. math::\n        Nu = \\left[0.31Re^{0.5} + 0.11Re^{0.67}\\right]Pr^{0.4}\n        \\left(\\frac{\\mu}{\\mu_w}\\right)^{0.25}\n\n    Parameters\n    ----------\n    Re : float\n        Reynolds number with respect to cylinder diameter, [-]\n    Pr : float\n        Prandtl number at free stream temperature, [-]\n    mu : float, optional\n        Viscosity of fluid at the free stream temperature [Pa*s]\n    muw : float, optional\n        Viscosity of fluid at the wall temperature [Pa*s]\n\n    Returns\n    -------\n    Nu : float\n        Nusselt number with respect to cylinder diameter, [-]\n\n    Notes\n    -----\n    Considers new data since `Nu_cylinder_Perkins_Leppert_1962`, Re from 2E3 to\n    1.2E5, Pr from 1 to 7, and surface to bulk temperature differences of\n    11 to 66.\n\n    Examples\n    --------\n    >>> Nu_cylinder_Perkins_Leppert_1964(6071, 0.7)\n    53.61767038619986\n\n    References\n    ----------\n    .. [1] Perkins Jr., H. C., and G. Leppert. \"Local Heat-Transfer\n       Coefficients on a Uniformly Heated Cylinder.\" International Journal of\n       Heat and Mass Transfer 7, no. 2 (February 1964): 143-158.\n       doi:10.1016/0017-9310(64)90079-1.\n    .. [2] Sanitjai, S., and R. J. Goldstein. \"Forced Convection Heat Transfer\n       from a Circular Cylinder in Crossflow to Air and Liquids.\" International\n       Journal of Heat and Mass Transfer 47, no. 22 (October 2004): 4795-4805.\n       doi:10.1016/j.ijheatmasstransfer.2004.05.012.\n    '''\n    Nu = (0.31*Re**0.5 + 0.11*Re**0.67)*Pr**0.4\n    if mu and muw:\n        Nu *= (mu/muw)**0.25\n    return Nu", "response": "r Returns a Nu_cylinder_Perkins_Leppert_1964 object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef k2g(kml_path, output_dir, separate_folders, style_type, \n  style_filename):\n    \"\"\"\n    Given a path to a KML file, convert it to a a GeoJSON FeatureCollection file and save it to the given output directory.\n\n    If ``--separate_folders``, then create several GeoJSON files, one for each folder in the KML file that contains geodata or that has a descendant node that contains geodata.\n    Warning: this can produce GeoJSON files with the same geodata in case the KML file has nested folders with geodata.\n\n    If ``--style_type`` is specified, then also build a JSON style file of the given style type and save it to the output directory under the file name given by ``--style_filename``.\n    \"\"\"\n    m.convert(kml_path, output_dir, separate_folders, style_type, style_filename)", "response": "Converts a KML file to GeoJSON FeatureCollection files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rm_paths(*paths):\n    for p in paths:\n        p = Path(p)\n        if p.exists():\n            if p.is_file():\n                p.unlink()\n            else:\n                shutil.rmtree(str(p))", "response": "Delete the given file paths and directories."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a KML DOM node grab its coordinates and times and convert them into a dictionary with the keys and values.", "response": "def gx_coords(node):\n    \"\"\"\n    Given a KML DOM node, grab its <gx:coord> and <gx:timestamp><when>subnodes, and convert them into a dictionary with the keys and values\n\n    - ``'coordinates'``: list of lists of float coordinates\n    - ``'times'``: list of timestamps corresponding to the coordinates\n\n    \"\"\"\n    els = get(node, 'gx:coord')\n    coordinates = []\n    times = []\n    coordinates = [gx_coords1(val(el)) for el in els]\n    time_els = get(node, 'when')\n    times = [val(t) for t in time_els]\n    return {\n      'coordinates': coordinates,\n      'times': times,\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef disambiguate(names, mark='1'):\n    names_seen = set()\n    new_names = []\n    for name in names:\n        new_name = name\n        while new_name in names_seen:\n            new_name += mark\n        new_names.append(new_name)\n        names_seen.add(new_name)\n\n    return new_names", "response": "Given a list of strings names return a new list of names where repeated names have been disambiguated by repeatedly appending the given mark."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a string that can be used for a clean filename.", "response": "def to_filename(s):\n    \"\"\"\n    Based on `django/utils/text.py <https://github.com/django/django/blob/master/django/utils/text.py>`_.\n    Return the given string converted to a string that can be used for a clean filename.\n    Specifically, leading and trailing spaces are removed; other spaces are converted to underscores, and anything that is not a unicode alphanumeric, dash, underscore, or dot, is removed.\n\n    EXAMPLE::\n\n        >>> to_filename(\"%  A d\\sbla'{-+\\)(\u00e7? \")\n        'A_dsbla-\u00e7'\n\n    \"\"\"\n    s = re.sub(r'(?u)[^-\\w. ]', '', s)\n    s = s.strip().replace(' ', '_')\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_rgb_and_opacity(s):\n    # Set defaults\n    color = '000000'\n    opacity = 1\n\n    if s.startswith('#'):\n        s = s[1:]\n    if len(s) == 8:\n        color = s[6:8] + s[4:6] + s[2:4]\n        opacity = round(int(s[0:2], 16)/256, 2)\n    elif len(s) == 6:\n        color = s[4:6] + s[2:4] + s[0:2]\n    elif len(s) == 3:\n        color = s[::-1]\n\n    return '#' + color, opacity", "response": "Given a KML color string return an equivalent RGB hex color string and an opacity float rounded to 2 decimal places."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build_svg_style(node):\n    d = {}\n    for item in get(node, 'Style'):\n        style_id = '#' + attr(item, 'id')\n        # Create style properties\n        props = {}\n        for x in get(item, 'PolyStyle'):\n            color = val(get1(x, 'color'))\n            if color:\n                rgb, opacity = build_rgb_and_opacity(color)\n                props['fill'] = rgb\n                props['fill-opacity'] = opacity\n                # Set default border style\n                props['stroke'] = rgb\n                props['stroke-opacity'] = opacity\n                props['stroke-width'] = 1\n            fill = valf(get1(x, 'fill'))\n            if fill == 0:\n                props['fill-opacity'] = fill\n            elif fill == 1 and 'fill-opacity' not in props:\n                props['fill-opacity'] = fill\n            outline = valf(get1(x, 'outline'))\n            if outline == 0:\n                props['stroke-opacity'] = outline\n            elif outline == 1 and 'stroke-opacity' not in props:\n                props['stroke-opacity'] = outline\n        for x in get(item, 'LineStyle'):\n            color = val(get1(x, 'color'))\n            if color:\n                rgb, opacity = build_rgb_and_opacity(color)\n                props['stroke'] = rgb\n                props['stroke-opacity'] = opacity\n            width = valf(get1(x, 'width'))\n            if width is not None:\n                props['stroke-width'] = width\n        for x in get(item, 'IconStyle'):\n            icon = get1(x, 'Icon')\n            if not icon:\n                continue\n            # Clear previous style properties\n            props = {}\n            props['iconUrl'] = val(get1(icon, 'href'))\n\n        d[style_id] = props\n\n    return d", "response": "Given a DOM node grab its top - level Style nodes convert them into a master dictionary of the form\n    and return the resulting SVG style dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_geometry(node):\n    geoms = []\n    times = []\n    if get1(node, 'MultiGeometry'):\n        return build_geometry(get1(node, 'MultiGeometry'))\n    if get1(node, 'MultiTrack'):\n        return build_geometry(get1(node, 'MultiTrack'))\n    if get1(node, 'gx:MultiTrack'):\n        return build_geometry(get1(node, 'gx:MultiTrack'))\n    for geotype in GEOTYPES:\n        geonodes = get(node, geotype)\n        if not geonodes:\n            continue\n        for geonode in geonodes:\n            if geotype == 'Point':\n                geoms.append({\n                  'type': 'Point',\n                  'coordinates': coords1(val(get1(\n                    geonode, 'coordinates')))\n                })\n            elif geotype == 'LineString':\n                geoms.append({\n                  'type': 'LineString',\n                  'coordinates': coords(val(get1(\n                    geonode, 'coordinates')))\n                })\n            elif geotype == 'Polygon':\n                rings = get(geonode, 'LinearRing')\n                coordinates = [coords(val(get1(ring, 'coordinates')))\n                  for ring in rings]\n                geoms.append({\n                  'type': 'Polygon',\n                  'coordinates': coordinates,\n                })\n            elif geotype in ['Track', 'gx:Track']:\n                track = gx_coords(geonode)\n                geoms.append({\n                  'type': 'LineString',\n                  'coordinates': track['coordinates'],\n                })\n                if track['times']:\n                    times.append(track['times'])\n\n    return {'geoms': geoms, 'times': times}", "response": "Builds a GeoJSON geometry dictionary corresponding to the given KML node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_feature(node):\n    geoms_and_times = build_geometry(node)\n    if not geoms_and_times['geoms']:\n        return None\n\n    props = {}\n    for x in get(node, 'name')[:1]:\n        name = val(x)\n        if name:\n            props['name'] = val(x)\n    for x in get(node, 'description')[:1]:\n        desc = val(x)\n        if desc:\n            props['description'] = desc\n    for x in get(node, 'styleUrl')[:1]:\n        style_url = val(x)\n        if style_url[0] != '#':\n            style_url = '#' + style_url\n        props['styleUrl'] = style_url\n    for x in get(node, 'PolyStyle')[:1]:\n        color = val(get1(x, 'color'))\n        if color:\n            rgb, opacity = build_rgb_and_opacity(color)\n            props['fill'] = rgb\n            props['fill-opacity'] = opacity\n            # Set default border style\n            props['stroke'] = rgb\n            props['stroke-opacity'] = opacity\n            props['stroke-width'] = 1\n        fill = valf(get1(x, 'fill'))\n        if fill == 0:\n            props['fill-opacity'] = fill\n        elif fill == 1 and 'fill-opacity' not in props:\n            props['fill-opacity'] = fill\n        outline = valf(get1(x, 'outline'))\n        if outline == 0:\n            props['stroke-opacity'] = outline\n        elif outline == 1 and 'stroke-opacity' not in props:\n            props['stroke-opacity'] = outline\n    for x in get(node, 'LineStyle')[:1]:\n        color = val(get1(x, 'color'))\n        if color:\n            rgb, opacity = build_rgb_and_opacity(color)\n            props['stroke'] = rgb\n            props['stroke-opacity'] = opacity\n        width = valf(get1(x, 'width'))\n        if width:\n            props['stroke-width'] = width\n    for x in get(node, 'ExtendedData')[:1]:\n        datas = get(x, 'Data')\n        for data in datas:\n            props[attr(data, 'name')] = val(get1(data, 'value'))\n        simple_datas = get(x, 'SimpleData')\n        for simple_data in simple_datas:\n            props[attr(simple_data, 'name')] = val(simple_data)\n    for x in get(node, 'TimeSpan')[:1]:\n        begin = val(get1(x, 'begin'))\n        end = val(get1(x, 'end'))\n        props['timeSpan'] = {'begin': begin, 'end': end}\n    if geoms_and_times['times']:\n        times = geoms_and_times['times']\n        if len(times) == 1:\n            props['times'] = times[0]\n        else:\n            props['times'] = times\n\n    feature = {\n      'type': 'Feature',\n      'properties': props,\n    }\n\n    geoms = geoms_and_times['geoms']\n    if len(geoms) == 1:\n        feature['geometry'] = geoms[0]\n    else:\n        feature['geometry'] = {\n          'type': 'GeometryCollection',\n          'geometries': geoms,\n        }\n\n    if attr(node, 'id'):\n        feature['id'] = attr(node, 'id')\n\n    return feature", "response": "Builds and returns a ( decoded ) GeoJSON Feature corresponding to this KML node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild and returns a ( decoded ) GeoJSON FeatureCollection corresponding to this KML DOM node.", "response": "def build_feature_collection(node, name=None):\n    \"\"\"\n    Build and return a (decoded) GeoJSON FeatureCollection corresponding to this KML DOM node (typically a KML Folder).\n    If a name is given, store it in the FeatureCollection's ``'name'`` attribute.\n    \"\"\"\n    # Initialize\n    geojson = {\n      'type': 'FeatureCollection',\n      'features': [],\n    }\n\n    # Build features\n    for placemark in get(node, 'Placemark'):\n        feature = build_feature(placemark)\n        if feature is not None:\n            geojson['features'].append(feature)\n\n    # Give the collection a name if requested\n    if name is not None:\n        geojson['name'] = name\n\n    return geojson"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_layers(node, disambiguate_names=True):\n    layers = []\n    names = []\n    for i, folder in enumerate(get(node, 'Folder')):\n        name = val(get1(folder, 'name'))\n        geojson = build_feature_collection(folder, name)\n        if geojson['features']:\n            layers.append(geojson)\n            names.append(name)\n\n    if not layers:\n        # No folders, so use the root node\n        name = val(get1(node, 'name'))\n        geojson = build_feature_collection(node, name)\n        if geojson['features']:\n            layers.append(geojson)\n            names.append(name)\n\n    if disambiguate_names:\n        new_names = disambiguate(names)\n        new_layers = []\n        for i, layer in enumerate(layers):\n            layer['name'] = new_names[i]\n            new_layers.append(layer)\n        layers = new_layers\n\n    return layers", "response": "Builds a list of GeoJSON FeatureCollections for each KML node that contains geodata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting a KML file to one or several GeoJSON FeatureCollection files and saves the result to the given output directory.", "response": "def convert(kml_path, output_dir, separate_folders=False,\n  style_type=None, style_filename='style.json'):\n    \"\"\"\n    Given a path to a KML file, convert it to one or several GeoJSON FeatureCollection files and save the result(s) to the given output directory.\n\n    If not ``separate_folders`` (the default), then create one GeoJSON file.\n    Otherwise, create several GeoJSON files, one for each folder in the KML file that contains geodata or that has a descendant node that contains geodata.\n    Warning: this can produce GeoJSON files with the same geodata in case the KML file has nested folders with geodata.\n\n    If a ``style_type`` is given, then also build a JSON style file of the given style type and save it to the output directory under the name given by ``style_filename``.\n    \"\"\"\n    # Create absolute paths\n    kml_path = Path(kml_path).resolve()\n    output_dir = Path(output_dir)\n    if not output_dir.exists():\n        output_dir.mkdir()\n    output_dir = output_dir.resolve()\n\n    # Parse KML\n    with kml_path.open(encoding='utf-8', errors='ignore') as src:\n        kml_str = src.read()\n    root = md.parseString(kml_str)\n\n    # Build GeoJSON layers\n    if separate_folders:\n        layers = build_layers(root)\n    else:\n        layers = [build_feature_collection(root, name=kml_path.stem)]\n\n    # Create filenames for layers\n    filenames = disambiguate(\n      [to_filename(layer['name'])\n      for layer in layers])\n    filenames = [name + '.geojson' for name in filenames]\n\n    # Write layers to files\n    for i in range(len(layers)):\n        path = output_dir/filenames[i]\n        with path.open('w') as tgt:\n            json.dump(layers[i], tgt)\n\n    # Build and export style file if desired\n    if style_type is not None:\n        if style_type not in STYLE_TYPES:\n            raise ValueError('style type must be one of {!s}'.format(\n              STYLE_TYPES))\n        builder_name = 'build_{!s}_style'.format(style_type)\n        style_dict = globals()[builder_name](root)\n        path = output_dir/style_filename\n        with path.open('w') as tgt:\n            json.dump(style_dict, tgt)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of codename name for all tools.", "response": "def _get_all_permissions(opts, tools):\n    \"\"\"Returns (codename, name) for all tools.\"\"\"\n    perms = []\n    for tool in tools:\n        perms.append((_get_permission_codename(tool, opts), 'Can %s %s' % \\\n                (tool.name, opts.verbose_name_plural)))\n    return perms"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_permissions(**kwargs):\n    from django.contrib.contenttypes.models import ContentType\n\n    object_tools.autodiscover()\n    tools = object_tools.tools._registry\n\n    # This will hold the permissions we're looking for as\n    # (content_type, (codename, name))\n    searched_perms = list()\n    # The codenames and ctypes that should exist.\n    ctypes = set()\n    for model, tools in tools.items():\n        ctype = ContentType.objects.get_for_model(model)\n        ctypes.add(ctype)\n        for perm in _get_all_permissions(model._meta, tools):\n            searched_perms.append((ctype, perm))\n\n    # Find all the Permissions that have a context_type for a model we're\n    # looking for.  We don't need to check for codenames since we already have\n    # a list of the ones we're going to create.\n    all_perms = set(auth_app.Permission.objects.filter(\n        content_type__in=ctypes,\n    ).values_list(\n        \"content_type\", \"codename\"\n    ))\n\n    for ctype, (codename, name) in searched_perms:\n        # If the permissions exists, move on.\n        if (ctype.pk, codename) in all_perms:\n            continue\n        p = auth_app.Permission.objects.create(\n            codename=codename,\n            name=name,\n            content_type=ctype\n        )\n        if kwargs.get(\"verbosity\", 2) >= 2:\n            print(\"Adding permission '%s'\" % p)", "response": "Create all permissions for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_random_user(self):\n        c = self.db.cursor()\n        c.execute('''SELECT username, password, fullname FROM users\n                     WHERE rowid >= (abs(random()) % (SELECT max(rowid) FROM users))\n                     LIMIT 1''')\n        r = c.fetchone()\n        return {\"username\": r[0], \"password\": r[1], \"fullname\": r[2]}", "response": "Gets a random user from the provider\n\n        table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the element with the given locator is available.", "response": "def is_element_available(self, locator):\n        \"\"\"\n        Synchronization method for making sure the element we're looking for is not only on the page,\n        but also visible -- since Se will happily deal with things that aren't visible.\n\n        Use this instead of is_element_present most of the time.\n        \"\"\"\n        if self.driver.is_element_present(locator):\n            if self.driver.is_visible(locator):\n                return True\n            else:\n                return False\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwait until an element is available for the given locator.", "response": "def wait_for_available(self, locator):\n        \"\"\"\n        Synchronization to deal with elements that are present, and are visible\n\n        :raises: ElementVisiblityTimeout\n        \"\"\"\n        for i in range(timeout_seconds):\n            try:\n                if self.is_element_available(locator):\n                    break\n            except:\n                pass\n            time.sleep(1)\n        else:\n            raise ElementVisiblityTimeout(\"%s availability timed out\" % locator)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwait until the element identified by locator is visible.", "response": "def wait_for_visible(self, locator):\n        \"\"\"\n        Synchronization to deal with elements that are present, but are disabled until some action\n        triggers their visibility.\n\n        :raises: ElementVisiblityTimeout\n        \"\"\"\n        for i in range(timeout_seconds):\n            try:\n                if self.driver.is_visible(locator):\n                    break\n            except:\n                pass\n            time.sleep(1)\n        else:\n            raise ElementVisiblityTimeout(\"%s visibility timed out\" % locator)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wait_for_text(self, locator, text):\n        for i in range(timeout_seconds):\n            try:\n                e = self.driver.find_element_by_locator(locator)\n                if e.text == text:\n                    break\n            except:\n                pass\n            time.sleep(1)\n        else:\n            raise ElementTextTimeout(\"%s value timed out\" % locator)\n        return True", "response": "Synchronization on some text being displayed in a particular element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef validate(tool_class, model_class):\n    if not hasattr(tool_class, 'name'):\n        raise ImproperlyConfigured(\"No 'name' attribute found for tool %s.\" % (\n            tool_class.__name__\n        ))\n\n    if not hasattr(tool_class, 'label'):\n        raise ImproperlyConfigured(\"No 'label' attribute found for tool %s.\" % (\n            tool_class.__name__\n        ))\n\n    if not hasattr(tool_class, 'view'):\n        raise NotImplementedError(\"No 'view' method found for tool %s.\" % (\n            tool_class.__name__\n        ))", "response": "Validates that the given tool_class is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, object_tool_class, model_class=None):\n        if not object_tool_class:\n            return None\n\n        # Don't validate unless required.\n        if object_tool_class and settings.DEBUG:\n            from object_tools.validation import validate\n            validate(object_tool_class, model_class)\n            # = lambda model, adminclass: None\n\n        if not model_class:\n            models = get_models()\n        else:\n            models = [model_class, ]\n\n        for model in models:\n            if model._meta.abstract:\n                raise ImproperlyConfigured(\n                    'The model %s is abstract, so it \\\n                    cannot be registered with object tools.' % model.__name__)\n\n            # Instantiate the object_tools class to save in the registry\n            if model in self._registry:\n                self._registry[model].append(object_tool_class(model))\n            else:\n                self._registry[model] = [object_tool_class(model), ]", "response": "Registers the given object tool class with the given model class."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconstructs a form from the request.", "response": "def construct_form(self, request):\n        \"\"\"\n        Constructs form from POST method using self.form_class.\n        \"\"\"\n        if not hasattr(self, 'form_class'):\n            return None\n\n        if request.method == 'POST':\n            form = self.form_class(self.model, request.POST, request.FILES)\n        else:\n            form = self.form_class(self.model)\n        return form"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef has_permission(self, user):\n        return user.has_perm(\n            self.model._meta.app_label + '.' + self.get_permission()\n        )", "response": "Returns True if the given user has permission to use the tool."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef media(self, form):\n        js = ['admin/js/core.js', 'admin/js/admin/RelatedObjectLookups.js',\n              'admin/js/jquery.min.js', 'admin/js/jquery.init.js']\n\n        media = forms.Media(\n            js=['%s%s' % (settings.STATIC_URL, u) for u in js],\n        )\n\n        if form:\n            for name, field in form.fields.items():\n                media = media + field.widget.media\n\n        return media", "response": "Returns a new Media instance for the given form."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of URL patterns for the current object.", "response": "def _urls(self):\n        \"\"\"\n        URL patterns for tool linked to _view method.\n        \"\"\"\n        info = (\n            self.model._meta.app_label, self.model._meta.model_name,\n            self.name,\n        )\n        urlpatterns = [\n            url(r'^%s/$' % self.name, self._view, name='%s_%s_%s' % info)\n        ]\n        return urlpatterns"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconstructs the context for the admin.", "response": "def construct_context(self, request):\n        \"\"\"\n        Builds context with various required variables.\n        \"\"\"\n        opts = self.model._meta\n        app_label = opts.app_label\n        object_name = opts.object_name.lower()\n        form = self.construct_form(request)\n\n        media = self.media(form)\n        context = {\n            'user': request.user,\n            'title': '%s %s' % (self.label, opts.verbose_name_plural.lower()),\n            'tool': self,\n            'opts': opts,\n            'app_label': app_label,\n            'media': media,\n            'form': form,\n            'changelist_url': reverse('admin:%s_%s_changelist' % (\n                app_label, object_name\n            ))\n        }\n\n        # Pass along fieldset if sepcififed.\n        if hasattr(form, 'fieldsets'):\n            admin_form = helpers.AdminForm(form, form.fieldsets, {})\n            context['adminform'] = admin_form\n\n        return context"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nviews wrapper taking care of houskeeping for painless form rendering.", "response": "def _view(self, request, extra_context=None):\n        \"\"\"\n        View wrapper taking care of houskeeping for painless form rendering.\n        \"\"\"\n        if not self.has_permission(request.user):\n            raise PermissionDenied\n\n        return self.view(request, self.construct_context(request))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a random row from the provider", "response": "def randomRow(self):\n        \"\"\"\n        Gets a random row from the provider\n\n        :returns: List\n        \"\"\"\n        l = []\n        for row in self.data:\n            l.append(row)\n        return random.choice(l)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_random_user(self):\n        from provider.models import User\n        u = User.objects.order_by('?')[0]\n        return {\"username\": u.username, \"password\": u.password, \"fullname\": u.fullname}", "response": "Gets a random user from the provider\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_false(self, expr, msg=None):\n        try:\n            self.assert_false(expr, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether the condition is false\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_is_none(self, expr, msg=None):\n        try:\n            self.assert_is_none(expr, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether the expr is None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify_in(self, first, second, msg=\"\"):\n        try:\n            self.assert_in(first, second, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether the first is in second\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_is_instance(self, obj, cls, msg=\"\"):\n        try:\n            self.assert_is_instance(obj, cls, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether the object is an instance of cls\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify_is_not_instance(self, obj, cls, msg=\"\"):\n        try:\n            self.assert_is_not_instance(obj, cls, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether the object is not an instance of cls\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify_element_present(self, locator, msg=None):\n        try:\n            self.asset_element_present(locator, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether and element is present in the current window"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef verify_visible(self, locator, msg=None):\n        try:\n            self.assert_visible(locator, msg)\n        except AssertionError, e:\n            if msg:\n                m = \"%s:\\n%s\" % (msg, str(e))\n            else:\n                m = str(e)\n            self.verification_erorrs.append(m)", "response": "Soft assert for whether and element is present and visible in the current window"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns passed object but if chain method is used returns the last processed object.", "response": "def obj(self):\n        \"\"\"\n        Returns passed object but if chain method is used\n        returns the last processed result\n        \"\"\"\n        if self._wrapped is not self.Null:\n            return self._wrapped\n        else:\n            return self.object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _wrap(self, ret):\n        if self.chained:\n            self._wrapped = ret\n            return self\n        else:\n            return ret", "response": "Wrap the result of the method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a value into a real object.", "response": "def _toOriginal(self, val):\n        \"\"\" Pitty attempt to convert itertools result into a real object\n        \"\"\"\n        if self._clean.isTuple():\n            return tuple(val)\n        elif self._clean.isList():\n            return list(val)\n        elif self._clean.isDict():\n            return dict(val)\n        else:\n            return val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating through each item of an object", "response": "def each(self, func):\n        \"\"\"\n        iterates through each item of an object\n        :Param: func iterator function\n        \"\"\"\n        if self._clean.isTuple() or self._clean.isList():\n            for index, value in enumerate(self.obj):\n                r = func(value, index, self.obj)\n                if r is \"breaker\":\n                    break\n        else:\n            for index, key in enumerate(self.obj):\n                r = func(self.obj[key], key, self.obj, index)\n                if r is \"breaker\":\n                    break\n        return self._wrap(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map(self, func):\n        ns = self.Namespace()\n        ns.results = []\n\n        def by(value, index, list, *args):\n            ns.results.append(func(value, index, list))\n\n        _(self.obj).each(by)\n        return self._wrap(ns.results)", "response": "Return the results of applying the iterator to each element."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild up a single result from a list of values aka inject or foldl aka foldl aka inject or foldl aka foldl aka inject or foldl aka foldl aka inject", "response": "def reduce(self, func, memo=None):\n        \"\"\"\n        **Reduce** builds up a single result from a list of values,\n        aka `inject`, or foldl\n        \"\"\"\n        if memo is None:\n            memo = []\n        ns = self.Namespace()\n        ns.initial = True  # arguments.length > 2\n        ns.memo = memo\n        obj = self.obj\n\n        def by(value, index, *args):\n            if not ns.initial:\n                ns.memo = value\n                ns.initial = True\n            else:\n                ns.memo = func(ns.memo, value, index)\n\n        _(obj).each(by)\n        return self._wrap(ns.memo)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(self, func):\n        self.ftmp = None\n\n        def test(value, index, list):\n            if func(value, index, list) is True:\n                self.ftmp = value\n                return True\n        self._clean.any(test)\n        return self._wrap(self.ftmp)", "response": "Return the first value which passes a truth test. Aliased as detect."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all the elements that pass a truth test.", "response": "def filter(self, func):\n        \"\"\" Return all the elements that pass a truth test.\n        \"\"\"\n        return self._wrap(list(filter(func, self.obj)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reject(self, func):\n        return self._wrap(list(filter(lambda val: not func(val), self.obj)))", "response": "Return all the elements for which a truth test fails."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new Sequence of all the elements in the sequence that match a truth test.", "response": "def all(self, func=None):\n        \"\"\" Determine whether all of the elements match a truth test.\n        \"\"\"\n        if func is None:\n            func = lambda x, *args: x\n        self.altmp = True\n\n        def testEach(value, index, *args):\n            if func(value, index, *args) is False:\n                self.altmp = False\n\n        self._clean.each(testEach)\n        return self._wrap(self.altmp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if at least one element in the object contains a truth test.", "response": "def any(self, func=None):\n        \"\"\"\n        Determine if at least one element in the object\n        matches a truth test.\n        \"\"\"\n        if func is None:\n            func = lambda x, *args: x\n        self.antmp = False\n\n        def testEach(value, index, *args):\n            if func(value, index, *args) is True:\n                self.antmp = True\n                return \"breaker\"\n\n        self._clean.each(testEach)\n        return self._wrap(self.antmp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines if a given value is included in the array or object using is.", "response": "def include(self, target):\n        \"\"\"\n        Determine if a given value is included in the\n        array or object using `is`.\n        \"\"\"\n        if self._clean.isDict():\n            return self._wrap(target in self.obj.values())\n        else:\n            return self._wrap(target in self.obj)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninvoke a method on every item in a collection.", "response": "def invoke(self, method, *args):\n        \"\"\" Invoke a method (with arguments) on every item in a collection.\n        \"\"\"\n        def inv(value, *ar):\n            if (\n                _(method).isFunction() or\n                _(method).isLambda() or\n                _(method).isMethod()\n            ):\n                return method(value, *args)\n            else:\n                return getattr(value, method)(*args)\n        return self._wrap(self._clean.map(inv))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pluck(self, key):\n        return self._wrap([x.get(key) for x in self.obj])", "response": "Returns a list of the values of the given key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new object containing only the objects with specific key value pairs.", "response": "def where(self, attrs=None, first=False):\n        \"\"\"\n        Convenience version of a common use case of `filter`:\n        selecting only objects\n        containing specific `key:value` pairs.\n        \"\"\"\n        if attrs is None:\n            return None if first is True else []\n\n        method = _.find if first else _.filter\n\n        def by(val, *args):\n            for key, value in attrs.items():\n                try:\n                    if attrs[key] != val[key]:\n                        return False\n                except KeyError:\n                    return False\n                return True\n\n        return self._wrap(method(self.obj, by))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef findWhere(self, attrs=None):\n        return self._wrap(self._clean.where(attrs, True))", "response": "Returns the first object containing specific key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef max(self):\n        if(self._clean.isDict()):\n            return self._wrap(list())\n        return self._wrap(max(self.obj))", "response": "Return the maximum element or a list of elements."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the minimum element of the array or element - based computation.", "response": "def min(self):\n        \"\"\" Return the minimum element (or element-based computation).\n        \"\"\"\n        if(self._clean.isDict()):\n            return self._wrap(list())\n        return self._wrap(min(self.obj))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsorting the object s values by a criterion produced by an iterator.", "response": "def sortBy(self, val=None):\n        \"\"\" Sort the object's values by a criterion produced by an iterator.\n        \"\"\"\n        if val is not None:\n            if _(val).isString():\n                return self._wrap(sorted(self.obj, key=lambda x,\n                                  *args: x.get(val)))\n            else:\n                return self._wrap(sorted(self.obj, key=val))\n        else:\n            return self._wrap(sorted(self.obj))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngroup the object s entries by a criterion.", "response": "def groupBy(self, val):\n        \"\"\"\n        Groups the object's values by a criterion. Pass either a string\n        attribute to group by, or a function that returns the criterion.\n        \"\"\"\n\n        def by(result, key, value):\n            if key not in result:\n                result[key] = []\n            result[key].append(value)\n\n        res = self._group(self.obj, val, by)\n\n        return self._wrap(res)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef indexBy(self, val=None):\n        if val is None:\n            val = lambda *args: args[0]\n\n        def by(result, key, value):\n            result[key] = value\n\n        res = self._group(self.obj, val, by)\n\n        return self._wrap(res)", "response": "Returns a new table with the entries grouped by a criterion."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncounts the number of instances of an object that match a certain criterion.", "response": "def countBy(self, val):\n        \"\"\"\n        Counts instances of an object that group by a certain criterion. Pass\n        either a string attribute to count by, or a function that returns the\n        criterion.\n        \"\"\"\n\n        def by(result, key, value):\n            if key not in result:\n                result[key] = 0\n            result[key] += 1\n\n        res = self._group(self.obj, val, by)\n\n        return self._wrap(res)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index of the object in the cache sorted by the object s entry key.", "response": "def sortedIndex(self, obj, iterator=lambda x: x):\n        \"\"\"\n        Use a comparator function to figure out the smallest index at which\n        an object should be inserted so as to maintain order.\n        Uses binary search.\n        \"\"\"\n        array = self.obj\n        value = iterator(obj)\n        low = 0\n        high = len(array)\n        while low < high:\n            mid = (low + high) >> 1\n            if iterator(array[mid]) < value:\n                low = mid + 1\n            else:\n                high = mid\n        return self._wrap(low)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the first element of an array.", "response": "def first(self, n=1):\n        \"\"\"\n        Get the first element of an array. Passing **n** will return the\n        first N values in the array. Aliased as `head` and `take`.\n        The **guard** check allows it to work with `_.map`.\n        \"\"\"\n        res = self.obj[0:n]\n        if len(res) is 1:\n            res = res[0]\n        return self._wrap(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef last(self, n=1):\n        res = self.obj[-n:]\n        if len(res) is 1:\n            res = res[0]\n        return self._wrap(res)", "response": "Get the last n elements in an array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flatten(self, shallow=None):\n        return self._wrap(self._flatten(self.obj, shallow))", "response": "Return a completely flattened version of an array."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef without(self, *values):\n        if self._clean.isDict():\n            newlist = {}\n            for i, k in enumerate(self.obj):\n                # if k not in values:  # use indexof to check identity\n                if _(values).indexOf(k) is -1:\n                    newlist.set(k, self.obj[k])\n        else:\n            newlist = []\n            for i, v in enumerate(self.obj):\n                # if v not in values:  # use indexof to check identity\n                if _(values).indexOf(v) is -1:\n                    newlist.append(v)\n\n        return self._wrap(newlist)", "response": "Return a copy of the array that does not contain the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef partition(self, predicate=None):\n        predicate = self._lookupIterator(predicate)\n        pass_list = []\n        fail_list = []\n\n        def by(elem, index, *args):\n            (pass_list if predicate(elem) else fail_list).append(elem)\n\n        _.each(self.obj, by)\n\n        return self._wrap([pass_list, fail_list])", "response": "Split an array into two arrays where the elements all satisfy the given predicate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nproducing a duplicate - free version of the array.", "response": "def uniq(self, isSorted=False, iterator=None):\n        \"\"\"\n        Produce a duplicate-free version of the array. If the array has already\n        been sorted, you have the option of using a faster algorithm.\n        Aliased as `unique`.\n        \"\"\"\n        ns = self.Namespace()\n        ns.results = []\n        ns.array = self.obj\n        initial = self.obj\n        if iterator is not None:\n            initial = _(ns.array).map(iterator)\n\n        def by(memo, value, index):\n            if ((_.last(memo) != value or\n                 not len(memo)) if isSorted else not _.include(memo, value)):\n                memo.append(value)\n                ns.results.append(ns.array[index])\n\n            return memo\n\n        ret = _.reduce(initial, by)\n        return self._wrap(ret)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef union(self, *args):\n        # setobj = set(self.obj)\n        # for i, v in enumerate(args):\n        #     setobj = setobj + set(args[i])\n        # return self._wrap(self._clean._toOriginal(setobj))\n        args = list(args)\n        args.insert(0, self.obj)\n        return self._wrap(_.uniq(self._flatten(args, True, [])))", "response": "Produce an array that contains the union of the elements in self and all of the passed - in arrays."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nproducing an array that contains every item shared between all the passed - in arrays.", "response": "def intersection(self, *args):\n        \"\"\"\n        Produce an array that contains every item shared between all the\n        passed-in arrays.\n        \"\"\"\n        if type(self.obj[0]) is int:\n            a = self.obj\n        else:\n            a = tuple(self.obj[0])\n        setobj = set(a)\n        for i, v in enumerate(args):\n            setobj = setobj & set(args[i])\n        return self._wrap(list(setobj))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef difference(self, *args):\n        setobj = set(self.obj)\n        for i, v in enumerate(args):\n            setobj = setobj - set(args[i])\n        return self._wrap(self._clean._toOriginal(setobj))", "response": "Take the difference between one array and a number of other arrays."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nzip together multiple lists into a single array -- elements that share an index go together.", "response": "def zip(self, *args):\n        \"\"\"\n        Zip together multiple lists into a single array -- elements that share\n        an index go together.\n        \"\"\"\n        args = list(args)\n        args.insert(0, self.obj)\n        maxLen = _(args).chain().collect(lambda x, *args: len(x)).max().value()\n        for i, v in enumerate(args):\n            l = len(args[i])\n            if l < maxLen:\n                args[i]\n            for x in range(maxLen - l):\n                args[i].append(None)\n        return self._wrap(zip(*args))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef zipObject(self, values):\n        result = {}\n        keys = self.obj\n        i = 0\n        l = len(keys)\n        while i < l:\n            result[keys[i]] = values[i]\n            l = len(keys)\n            i += 1\n\n        return self._wrap(result)", "response": "Zip together two arrays of keys and array of values into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef indexOf(self, item, isSorted=False):\n        array = self.obj\n        ret = -1\n\n        if not (self._clean.isList() or self._clean.isTuple()):\n            return self._wrap(-1)\n\n        if isSorted:\n            i = _.sortedIndex(array, item)\n            ret = i if array[i] is item else -1\n        else:\n            i = 0\n            l = len(array)\n            while i < l:\n                if array[i] is item:\n                    return self._wrap(i)\n                i += 1\n        return self._wrap(ret)", "response": "Return the index of the first occurrence of an item in an array."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the position of the last occurrence of an item in an array or - 1 if the item is not included in the array.", "response": "def lastIndexOf(self, item):\n        \"\"\"\n        Return the position of the last occurrence of an\n        item in an array, or -1 if the item is not included in the array.\n        \"\"\"\n        array = self.obj\n        i = len(array) - 1\n        if not (self._clean.isList() or self._clean.isTuple()):\n            return self._wrap(-1)\n\n        while i > -1:\n            if array[i] is item:\n                return self._wrap(i)\n            i -= 1\n        return self._wrap(-1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate an integer Array containing an arithmetic progression.", "response": "def range(self, *args):\n        \"\"\" Generate an integer Array containing an arithmetic progression.\n        \"\"\"\n        args = list(args)\n        args.insert(0, self.obj)\n        return self._wrap(range(*args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef memoize(self, hasher=None):\n        ns = self.Namespace()\n        ns.memo = {}\n        if hasher is None:\n            hasher = lambda x: x\n\n        def memoized(*args, **kwargs):\n            key = hasher(*args)\n            if key not in ns.memo:\n                ns.memo[key] = self.obj(*args, **kwargs)\n            return ns.memo[key]\n\n        return self._wrap(memoized)", "response": "Memoize an expensive function by storing its results."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndelaying a function for the given number of milliseconds and then calls it with the arguments supplied.", "response": "def delay(self, wait, *args):\n        \"\"\"\n        Delays a function for the given number of milliseconds, and then calls\n        it with the arguments supplied.\n        \"\"\"\n\n        def call_it():\n            self.obj(*args)\n\n        t = Timer((float(wait) / float(1000)), call_it)\n        t.start()\n        return self._wrap(self.obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a function that will only be triggered at most once during a given window of time.", "response": "def throttle(self, wait):\n        \"\"\"\n        Returns a function, that, when invoked, will only be triggered\n        at most once during a given window of time.\n        \"\"\"\n        ns = self.Namespace()\n        ns.timeout = None\n        ns.throttling = None\n        ns.more = None\n        ns.result = None\n\n        def done():\n            ns.more = ns.throttling = False\n\n        whenDone = _.debounce(done, wait)\n        wait = (float(wait) / float(1000))\n\n        def throttled(*args, **kwargs):\n            def later():\n                ns.timeout = None\n                if ns.more:\n                    self.obj(*args, **kwargs)\n                whenDone()\n\n            if not ns.timeout:\n                ns.timeout = Timer(wait, later)\n                ns.timeout.start()\n\n            if ns.throttling:\n                ns.more = True\n            else:\n                ns.throttling = True\n                ns.result = self.obj(*args, **kwargs)\n            whenDone()\n            return ns.result\n        return self._wrap(throttled)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a function that will be called after it stops to be invoked for N milliseconds.", "response": "def debounce(self, wait, immediate=None):\n        \"\"\"\n        Returns a function, that, as long as it continues to be invoked,\n        will not be triggered. The function will be called after it stops\n        being called for N milliseconds. If `immediate` is passed, trigger\n        the function on the leading edge, instead of the trailing.\n        \"\"\"\n        wait = (float(wait) / float(1000))\n\n        def debounced(*args, **kwargs):\n            def call_it():\n                self.obj(*args, **kwargs)\n            try:\n                debounced.t.cancel()\n            except(AttributeError):\n                pass\n            debounced.t = Timer(wait, call_it)\n            debounced.t.start()\n        return self._wrap(debounced)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a function that will be executed at most one time. Useful for lazy initialization.", "response": "def once(self):\n        \"\"\"\n        Returns a function that will be executed at most one time,\n        no matter how often you call it. Useful for lazy initialization.\n        \"\"\"\n        ns = self.Namespace()\n        ns.memo = None\n        ns.run = False\n\n        def work_once(*args, **kwargs):\n            if ns.run is False:\n                ns.memo = self.obj(*args, **kwargs)\n            ns.run = True\n            return ns.memo\n\n        return self._wrap(work_once)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrap a function to return the first function passed as an argument to the second function allowing you to adjust arguments before and after.", "response": "def wrap(self, wrapper):\n        \"\"\"\n        Returns the first function passed as an argument to the second,\n        allowing you to adjust arguments, run code before and after, and\n        conditionally execute the original function.\n        \"\"\"\n        def wrapped(*args, **kwargs):\n\n            if kwargs:\n                kwargs[\"object\"] = self.obj\n            else:\n                args = list(args)\n                args.insert(0, self.obj)\n\n            return wrapper(*args, **kwargs)\n\n        return self._wrap(wrapped)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef after(self, func):\n        ns = self.Namespace()\n        ns.times = self.obj\n\n        if ns.times <= 0:\n            return func()\n\n        def work_after(*args):\n            if ns.times <= 1:\n                return func(*args)\n            ns.times -= 1\n\n        return self._wrap(work_after)", "response": "Returns a function that will only be executed after being\n        called N times."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pairs(self):\n        keys = self._clean.keys()\n        pairs = []\n        for key in keys:\n            pairs.append([key, self.obj[key]])\n\n        return self._wrap(pairs)", "response": "Convert an object into a list of [ key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninverting the keys and values of an object.", "response": "def invert(self):\n        \"\"\"\n        Invert the keys and values of an object.\n        The values must be serializable.\n        \"\"\"\n        keys = self._clean.keys()\n        inverted = {}\n        for key in keys:\n            inverted[self.obj[key]] = key\n\n        return self._wrap(inverted)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef functions(self):\n        names = []\n\n        for i, k in enumerate(self.obj):\n            if _(self.obj[k]).isCallable():\n                names.append(k)\n\n        return self._wrap(sorted(names))", "response": "Return a sorted list of the function names available on the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extend(self, *args):\n        args = list(args)\n        for i in args:\n            self.obj.update(i)\n\n        return self._wrap(self.obj)", "response": "Extend a given object with all the properties in\n            passed - in object s."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pick(self, *args):\n        ns = self.Namespace()\n        ns.result = {}\n\n        def by(key, *args):\n            if key in self.obj:\n                ns.result[key] = self.obj[key]\n\n        _.each(self._flatten(args, True, []), by)\n        return self._wrap(ns.result)", "response": "Return a copy of the object only containing the\n        whitelisted properties."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling in a given object with default properties.", "response": "def defaults(self, *args):\n        \"\"\" Fill in a given object with default properties.\n        \"\"\"\n        ns = self.Namespace\n        ns.obj = self.obj\n\n        def by(source, *ar):\n            for i, prop in enumerate(source):\n                if prop not in ns.obj:\n                    ns.obj[prop] = source[prop]\n\n        _.each(args, by)\n\n        return self._wrap(ns.obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalls the interceptor with the obj and then returns obj.", "response": "def tap(self, interceptor):\n        \"\"\"\n        Invokes interceptor with the obj, and then returns obj.\n        The primary purpose of this method is to \"tap into\" a method chain, in\n        order to perform operations on intermediate results within the chain.\n        \"\"\"\n        interceptor(self.obj)\n        return self._wrap(self.obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the object is empty.", "response": "def isEmpty(self):\n        \"\"\"\n        Is a given array, string, or object empty?\n        An \"empty\" object has no enumerable own-properties.\n        \"\"\"\n        if self.obj is None:\n            return True\n        if self._clean.isString():\n            ret = self.obj.strip() is \"\"\n        elif self._clean.isDict():\n            ret = len(self.obj.keys()) == 0\n        else:\n            ret = len(self.obj) == 0\n        return self._wrap(ret)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef isFile(self):\n        try:\n            filetype = file\n        except NameError:\n            filetype = io.IOBase\n\n        return self._wrap(type(self.obj) is filetype)", "response": "Check if the given object is a file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef join(self, glue=\" \"):\n        j = glue.join([str(x) for x in self.obj])\n        return self._wrap(j)", "response": "Javascript s join implementation"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef matches(self):\n        def ret(obj, *args):\n            if self.obj is obj:\n                return True  # avoid comparing an object to itself.\n\n            for key in self.obj:\n                if self.obj[key] != obj[key]:\n                    return False\n\n            return True\n\n        return self._wrap(ret)", "response": "Returns a predicate for checking whether an object has a given set of key value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrunning a function n times.", "response": "def times(self, func, *args):\n        \"\"\" Run a function **n** times.\n        \"\"\"\n        n = self.obj\n        i = 0\n        while n is not 0:\n            n -= 1\n            func(i)\n            i += 1\n\n        return self._wrap(func)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a random integer between min and max.", "response": "def random(self, max_number=None):\n        \"\"\" Return a random integer between min and max (inclusive).\n        \"\"\"\n        min_number = self.obj\n        if max_number is None:\n            min_number = 0\n            max_number = self.obj\n        return random.randrange(min_number, max_number)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef result(self, property, *args):\n        if self.obj is None:\n            return self._wrap(self.obj)\n\n        if(hasattr(self.obj, property)):\n            value = getattr(self.obj, property)\n        else:\n            value = self.obj.get(property)\n        if _.isCallable(value):\n            return self._wrap(value(*args))\n        return self._wrap(value)", "response": "Returns the value of the named property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mixin(self):\n        methods = self.obj\n        for i, k in enumerate(methods):\n            setattr(underscore, k, methods[k])\n\n        self.makeStatic()\n        return self._wrap(self.obj)", "response": "Add your own custom functions to the Underscore object ensuring that they re correctly added to the OOP wrapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uniqueId(self, prefix=\"\"):\n        _IdCounter.count += 1\n        id = _IdCounter.count\n        if prefix:\n            return self._wrap(prefix + str(id))\n        else:\n            return self._wrap(id)", "response": "Generate a unique integer id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nescapes a string for HTML interpolation.", "response": "def escape(self):\n        \"\"\" Escape a string for HTML interpolation.\n        \"\"\"\n        # & must be handled first\n        self.obj = self.obj.replace(\"&\", self._html_escape_table[\"&\"])\n\n        for i, k in enumerate(self._html_escape_table):\n            v = self._html_escape_table[k]\n            if k is not \"&\":\n                self.obj = self.obj.replace(k, v)\n\n        return self._wrap(self.obj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a string that can be used to render a micro - template for the current object.", "response": "def template(self, data=None, settings=None):\n        \"\"\"\n        Python micro-templating, similar to John Resig's implementation.\n        Underscore templating handles arbitrary delimiters, preserves\n        whitespace, and correctly escapes quotes within interpolated code.\n        \"\"\"\n        if settings is None:\n            settings = {}\n        ts = _.templateSettings\n        _.defaults(ts, self.templateSettings)\n        _.extend(settings, ts)\n\n        # settings = {\n        #     \"interpolate\": self.templateSettings.get('interpolate'),\n        #     \"evaluate\": self.templateSettings.get('evaluate'),\n        #     \"escape\": self.templateSettings.get('escape')\n        # }\n\n        _.extend(settings, {\n            \"escaper\": r\"\\\\|'|\\r|\\n|\\t|\\u2028|\\u2029\",\n            \"unescaper\": r\"\\\\(\\\\|'|r|n|t|u2028|u2029)\"\n        })\n\n        src = self.obj\n        #src = re.sub('\"', r'\\\"', src)\n        #src = re.sub(r'\\\\', r\"\\\\\", src)\n        ns = self.Namespace()\n        ns.indent_level = 1\n\n        def unescape(code):\n            def unescapes(matchobj):\n                a = re.sub(\"^[\\'\\\"]|[\\'\\\"]$\", \"\", (\"%r\" % matchobj.group(1)))\n                # Python doesn't accept \\n as a key\n                if a == '\\n':\n                    a = \"bn\"\n                if a == '\\r':\n                    a = \"br\"\n                if a == '\\t':\n                    a = \"bt\"\n                if a == '\\u2028':\n                    a = 'bu2028'\n                if a == '\\u2029':\n                    a = 'bu2029'\n                return self.escapes[a]\n            return re.sub(settings.get('unescaper'), unescapes, code)\n\n        def escapes(matchobj):\n            a = matchobj.group(0)\n            # Python doesn't accept \\n as a key\n            if a == '\\n':\n                a = \"bn\"\n            if a == '\\r':\n                a = \"br\"\n            if a == '\\t':\n                a = \"bt\"\n            if a == '\\u2028':\n                a = 'bu2028'\n            if a == '\\u2029':\n                a = 'bu2029'\n            return '\\\\' + self.escapes[a]\n\n        def indent(n=None):\n            if n is not None:\n                ns.indent_level += n\n            return \"  \" * ns.indent_level\n\n        def interpolate(matchobj):\n            if getattr(str, 'decode', False):\n                key = (matchobj.group(1).decode('string-escape')).strip()\n            else:\n                key = (bytes(matchobj.group(1), \"utf-8\").decode()).strip()\n            return \"' + str(\" + unescape(key) + \" or '') + '\"\n\n        def evaluate(matchobj):\n            if getattr(str, 'decode', False):\n                code = (matchobj.group(1).decode('string-escape')).strip()\n            else:\n                code = (bytes(matchobj.group(1), \"utf-8\").decode()).strip()\n            if code.startswith(\"end\"):\n                return \"')\\n\" + indent(-1) + \"ns.__p += ('\"\n            elif code.endswith(':'):\n                return \"')\\n\" + indent() + unescape(code) + \\\n                       \"\\n\" + indent(+1) + \"ns.__p += ('\"\n            else:\n                return \"')\\n\" + indent() + unescape(code) + \\\n                       \"\\n\" + indent() + \"ns.__p += ('\"\n\n        def escape(matchobj):\n            if getattr(str, 'decode', False):\n                key = (matchobj.group(1).decode('string-escape')).strip()\n            else:\n                key = (bytes(matchobj.group(1), \"utf-8\").decode()).strip()\n            return \"' + _.escape(str(\" + unescape(key) + \" or '')) + '\"\n\n        source = indent() + 'class closure(object):\\n    pass' + \\\n                            ' # for full closure support\\n'\n        source += indent() + 'ns = closure()\\n'\n        source += indent() + \"ns.__p = ''\\n\"\n        #src = re.sub(\"^[\\'\\\"]|[\\'\\\"]$\", \"\", (\"%r\" % src))\n        src = re.sub(settings.get(\"escaper\"), escapes, src)\n        source += indent() + \"ns.__p += ('\" + \\\n            re.sub(settings.get('escape'), escape, src) + \"')\\n\"\n        source = re.sub(settings.get('interpolate'), interpolate, source)\n        source = re.sub(settings.get('evaluate'), evaluate, source)\n\n        if getattr(str, 'decode', False):\n            source += indent() + 'return ns.__p.decode(\"string_escape\")\\n'\n        else:\n            source += indent() + 'return bytes(ns.__p, \"utf-8\").decode()\\n'\n\n        f = self.create_function(settings.get(\"variable\")\n                                 or \"obj=None\", source)\n\n        if data is not None:\n            return f(data)\n        return f"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef value(self):\n        if self._wrapped is not self.Null:\n            return self._wrapped\n        else:\n            return self.obj", "response": "returns the object instead of instance\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprovide static access to underscore class", "response": "def makeStatic():\n        \"\"\" Provide static access to underscore class\n        \"\"\"\n        p = lambda value: inspect.ismethod(value) or inspect.isfunction(value)\n        for eachMethod in inspect.getmembers(underscore,\n                                             predicate=p):\n            m = eachMethod[0]\n            if not hasattr(_, m):\n                def caller(a):\n                    def execute(*args):\n                        if len(args) == 1:\n                            r = getattr(underscore(args[0]), a)()\n                        elif len(args) > 1:\n                            rargs = args[1:]\n                            r = getattr(underscore(args[0]), a)(*rargs)\n                        else:\n                            r = getattr(underscore([]), a)()\n                        return r\n                    return execute\n                _.__setattr__(m, caller(m))\n        # put the class itself as a parameter so that we can use it on outside\n        _.__setattr__(\"underscore\", underscore)\n        _.templateSettings = {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init():\n    global _users, _names\n    _configure_app(app)\n    _users, _names = _init_login_manager(app)\n    _configure_logger()\n    init_scheduler(app.config.get('SQLALCHEMY_DATABASE_URI'))\n    db.init(app.config.get('SQLALCHEMY_DATABASE_URI'))", "response": "Initialise and configure the application database scheduler etc."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the Flask WSGI app.", "response": "def _configure_app(app_):\n    \"\"\"Configure the Flask WSGI app.\"\"\"\n    app_.url_map.strict_slashes = False\n    app_.config.from_object(default_settings)\n    app_.config.from_envvar('JOB_CONFIG', silent=True)\n    db_url = app_.config.get('SQLALCHEMY_DATABASE_URI')\n    if not db_url:\n        raise Exception('No db_url in config')\n    app_.wsgi_app = ProxyFix(app_.wsgi_app)\n\n    global SSL_VERIFY\n    if app_.config.get('SSL_VERIFY') in ['False', 'FALSE', '0', False, 0]:\n        SSL_VERIFY = False\n    else:\n        SSL_VERIFY = True\n\n    return app_"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialise and configure the login manager.", "response": "def _init_login_manager(app_):\n    \"\"\"Initialise and configure the login manager.\"\"\"\n    login_manager = flogin.LoginManager()\n    login_manager.setup_app(app_)\n    login_manager.anonymous_user = Anonymous\n    login_manager.login_view = \"login\"\n\n    users = {app_.config['USERNAME']: User('Admin', 0)}\n    names = dict((int(v.get_id()), k) for k, v in users.items())\n\n    @login_manager.user_loader\n    def load_user(userid):\n        userid = int(userid)\n        name = names.get(userid)\n        return users.get(name)\n\n    return users, names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the given logger for production deployment.", "response": "def _configure_logger_for_production(logger):\n    \"\"\"Configure the given logger for production deployment.\n\n    Logs to stderr and file, and emails errors to admins.\n\n    \"\"\"\n    stderr_handler = logging.StreamHandler(sys.stderr)\n    stderr_handler.setLevel(logging.INFO)\n    if 'STDERR' in app.config:\n        logger.addHandler(stderr_handler)\n\n    file_handler = logging.handlers.RotatingFileHandler(\n        app.config.get('LOG_FILE'), maxBytes=67108864, backupCount=5)\n    file_handler.setLevel(logging.INFO)\n    if 'LOG_FILE' in app.config:\n        logger.addHandler(file_handler)\n\n    mail_handler = logging.handlers.SMTPHandler(\n        '127.0.0.1',\n        app.config.get('FROM_EMAIL'),\n        app.config.get('ADMINS', []),\n        'CKAN Service Error')\n    mail_handler.setLevel(logging.ERROR)\n    if 'FROM_EMAIL' in app.config:\n        logger.addHandler(mail_handler)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures the logging module.", "response": "def _configure_logger():\n    \"\"\"Configure the logging module.\"\"\"\n    if not app.debug:\n        _configure_logger_for_production(logging.getLogger())\n    elif not app.testing:\n        _configure_logger_for_debugging(logging.getLogger())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitialising and configure the scheduler.", "response": "def init_scheduler(db_uri):\n    \"\"\"Initialise and configure the scheduler.\"\"\"\n    global scheduler\n    scheduler = apscheduler.Scheduler()\n    scheduler.misfire_grace_time = 3600\n    scheduler.add_jobstore(\n        sqlalchemy_store.SQLAlchemyJobStore(url=db_uri), 'default')\n    scheduler.add_listener(\n        job_listener,\n        events.EVENT_JOB_EXECUTED | events.EVENT_JOB_MISSED\n        | events.EVENT_JOB_ERROR)\n    return scheduler"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlisten to completed job", "response": "def job_listener(event):\n    '''Listens to completed job'''\n    job_id = event.job.args[0]\n\n    if event.code == events.EVENT_JOB_MISSED:\n        db.mark_job_as_missed(job_id)\n    elif event.exception:\n        if isinstance(event.exception, util.JobError):\n            error_object = event.exception.as_dict()\n        else:\n            error_object = \"\\n\".join(traceback.format_tb(event.traceback) +\n                    [repr(event.exception)])\n        db.mark_job_as_errored(job_id, error_object)\n    else:\n        db.mark_job_as_completed(job_id, event.retval)\n\n    api_key = db.get_job(job_id)[\"api_key\"]\n    result_ok = send_result(job_id, api_key)\n\n    if not result_ok:\n        db.mark_job_as_failed_to_post_result(job_id)\n\n    # Optionally notify tests that job_listener() has finished.\n    if \"_TEST_CALLBACK_URL\" in app.config:\n        requests.get(app.config[\"_TEST_CALLBACK_URL\"])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshowing version available job types and name of service.", "response": "def status():\n    '''Show version, available job types and name of service.\n\n    **Results:**\n\n    :rtype: A dictionary with the following keys\n    :param version: Version of the service provider\n    :type version: float\n    :param job_types: Available job types\n    :type job_types: list of strings\n    :param name: Name of the service\n    :type name: string\n    :param stats: Shows stats for jobs in queue\n    :type stats: dictionary\n    '''\n    job_types = async_types.keys() + sync_types.keys()\n\n    counts = {}\n    for job_status in job_statuses:\n        counts[job_status] = db.ENGINE.execute(\n            db.JOBS_TABLE.count()\n            .where(db.JOBS_TABLE.c.status == job_status)\n        ).first()[0]\n\n    return flask.jsonify(\n        version=0.1,\n        job_types=job_types,\n        name=app.config.get('NAME', 'example'),\n        stats=counts\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login():\n    '''Log in as administrator\n\n    You can use wither basic auth or form based login (via POST).\n\n    :param username: The administrator's username\n    :type username: string\n    :param password: The administrator's password\n    :type password: string\n    '''\n    username = None\n    password = None\n    next = flask.request.args.get('next')\n    auth = flask.request.authorization\n\n    if flask.request.method == 'POST':\n        username = flask.request.form['username']\n        password = flask.request.form['password']\n\n    if auth and auth.type == 'basic':\n        username = auth.username\n        password = auth.password\n\n    if not flogin.current_user.is_active:\n        error = 'You have to login with proper credentials'\n        if username and password:\n            if check_auth(username, password):\n                user = _users.get(username)\n                if user:\n                    if flogin.login_user(user):\n                        return flask.redirect(next or flask.url_for(\"user\"))\n                    error = 'Could not log in user.'\n                else:\n                    error = 'User not found.'\n            else:\n                error = 'Wrong username or password.'\n        else:\n            error = 'No username or password.'\n        return flask.Response(\n            'Could not verify your access level for that URL.\\n {}'.format(error),\n            401,\n            {str('WWW-Authenticate'): str('Basic realm=\"Login Required\"')})\n    return flask.redirect(next or flask.url_for(\"user\"))", "response": "Log in as administrator\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nshows information about the current user", "response": "def user():\n    '''Show information about the current user\n\n    :rtype: A dictionary with the following keys\n    :param id: User id\n    :type id: int\n    :param name: User name\n    :type name: string\n    :param is_active: Whether the user is currently active\n    :type is_active: bool\n    :param is_anonymous: The anonymous user is the default user if you\n        are not logged in\n    :type is_anonymous: bool\n    '''\n    user = flogin.current_user\n    return flask.jsonify({\n        'id': user.get_id(),\n        'name': user.name,\n        'is_active': user.is_active(),\n        'is_anonymous': user.is_anonymous\n    })"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlog out the active user", "response": "def logout():\n    \"\"\" Log out the active user\n    \"\"\"\n    flogin.logout_user()\n    next = flask.request.args.get('next')\n    return flask.redirect(next or flask.url_for(\"user\"))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef job_list():\n    '''List all jobs.\n\n    :param _limit: maximum number of jobs to show (default 100)\n    :type _limit: int\n    :param _offset: how many jobs to skip before showin the first one (default 0)\n    :type _offset: int\n    :param _status: filter jobs by status (complete, error)\n    :type _status: string\n\n    Also, you can filter the jobs by their metadata. Use the metadata key\n    as parameter key and the value as value.\n\n    :rtype: A list of job ids\n    '''\n    args = dict((key, value) for key, value in flask.request.args.items())\n    limit = args.pop('_limit', 100)\n    offset = args.pop('_offset', 0)\n\n    select = sql.select(\n        [db.JOBS_TABLE.c.job_id],\n        from_obj=[db.JOBS_TABLE.outerjoin(\n            db.METADATA_TABLE,\n            db.JOBS_TABLE.c.job_id == db.METADATA_TABLE.c.job_id)\n        ]).\\\n        group_by(db.JOBS_TABLE.c.job_id).\\\n        order_by(db.JOBS_TABLE.c.requested_timestamp.desc()).\\\n        limit(limit).offset(offset)\n\n    status = args.pop('_status', None)\n    if status:\n        select = select.where(db.JOBS_TABLE.c.status == status)\n\n    ors = []\n    for key, value in args.iteritems():\n        # Turn strings into unicode to stop SQLAlchemy\n        # \"Unicode type received non-unicode bind param value\" warnings.\n        key = unicode(key)\n\n        ors.append(sql.and_(db.METADATA_TABLE.c.key == key,\n                   db.METADATA_TABLE.c.value == value))\n\n    if ors:\n        select = select.where(sql.or_(*ors))\n        select = select.having(\n            sql.func.count(db.JOBS_TABLE.c.job_id) == len(ors)\n        )\n\n    result = db.ENGINE.execute(select)\n    listing = []\n    for (job_id,) in result:\n        listing.append(flask.url_for('job_status', job_id=job_id))\n\n    return flask.jsonify(list=listing)", "response": "List all jobs in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef job_status(job_id, show_job_key=False, ignore_auth=False):\n    '''Show a specific job.\n\n    **Results:**\n\n    :rtype: A dictionary with the following keys\n    :param status: Status of job (complete, error)\n    :type status: string\n    :param sent_data: Input data for job\n    :type sent_data: json encodable data\n    :param job_id: An identifier for the job\n    :type job_id: string\n    :param result_url: Callback url\n    :type result_url: url string\n    :param data: Results from job.\n    :type data: json encodable data\n    :param error: Error raised during job execution\n    :type error: string\n    :param metadata: Metadata provided when submitting job.\n    :type metadata: list of key - value pairs\n    :param requested_timestamp: Time the job started\n    :type requested_timestamp: timestamp\n    :param finished_timestamp: Time the job finished\n    :type finished_timestamp: timestamp\n\n    :statuscode 200: no error\n    :statuscode 403: not authorized to view the job's data\n    :statuscode 404: job id not found\n    :statuscode 409: an error occurred\n    '''\n    job_dict = db.get_job(job_id)\n    if not job_dict:\n        return json.dumps({'error': 'job_id not found'}), 404, headers\n    if not ignore_auth and not is_authorized(job_dict):\n        return json.dumps({'error': 'not authorized'}), 403, headers\n    job_dict.pop('api_key', None)\n    if not show_job_key:\n        job_dict.pop('job_key', None)\n    return flask.Response(json.dumps(job_dict, cls=DatetimeJsonEncoder),\n                          mimetype='application/json')", "response": "Show a specific job."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef job_delete(job_id):\n    '''Deletes the job together with its logs and metadata.\n\n    :param job_id: An identifier for the job\n    :type job_id: string\n\n    :statuscode 200: no error\n    :statuscode 403: not authorized to delete the job\n    :statuscode 404: the job could not be found\n    :statuscode 409: an error occurred\n    '''\n    conn = db.ENGINE.connect()\n    job = db.get_job(job_id)\n    if not job:\n        return json.dumps({'error': 'job_id not found'}), 404, headers\n    if not is_authorized(job):\n        return json.dumps({'error': 'not authorized'}), 403, headers\n    trans = conn.begin()\n    try:\n        conn.execute(db.JOBS_TABLE.delete().where(\n                     db.JOBS_TABLE.c.job_id == job_id))\n        trans.commit()\n        return json.dumps({'success': True}), 200, headers\n    except Exception, e:\n        trans.rollback()\n        return json.dumps({'error': str(e)}), 409, headers\n    finally:\n        conn.close()", "response": "Deletes the job together with its logs and metadata."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nclearing old jobs for days", "response": "def clear_jobs():\n    '''Clear old jobs\n\n    :param days: Jobs for how many days should be kept (default: 10)\n    :type days: integer\n\n    :statuscode 200: no error\n    :statuscode 403: not authorized to delete jobs\n    :statuscode 409: an error occurred\n    '''\n    if not is_authorized():\n        return json.dumps({'error': 'not authorized'}), 403, headers\n\n    days = flask.request.args.get('days', None)\n    return _clear_jobs(days)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef job_data(job_id):\n    '''Get the raw data that the job returned. The mimetype\n    will be the value provided in the metdata for the key ``mimetype``.\n\n    **Results:**\n\n    :rtype: string\n\n    :statuscode 200: no error\n    :statuscode 403: not authorized to view the job's data\n    :statuscode 404: job id not found\n    :statuscode 409: an error occurred\n    '''\n    job_dict = db.get_job(job_id)\n    if not job_dict:\n        return json.dumps({'error': 'job_id not found'}), 404, headers\n    if not is_authorized(job_dict):\n        return json.dumps({'error': 'not authorized'}), 403, headers\n    if job_dict['error']:\n        return json.dumps({'error': job_dict['error']}), 409, headers\n    content_type = job_dict['metadata'].get('mimetype')\n    return flask.Response(job_dict['data'], mimetype=content_type)", "response": "Get the raw data that the job returned."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubmits a job. If no id is provided, a random id will be generated. :param job_type: Which kind of job should be run. Has to be one of the available job types. :type job_type: string :param api_key: An API key that is needed to execute the job. This could be a CKAN API key that is needed to write any data. The key will also be used to administer jobs. If you don't want to use a real API key, you can provide a random string that you keep secure. :type api_key: string :param data: Data that is send to the job as input. (Optional) :type data: json encodable data :param result_url: Callback url that is called once the job has finished. (Optional) :type result_url: url string :param metadata: Data needed for the execution of the job which is not the input data. (Optional) :type metadata: list of key - value pairs **Results:** :rtype: A dictionary with the following keys :param job_id: An identifier for the job :type job_id: string :param job_key: A key that is required to view and administer the job :type job_key: string :statuscode 200: no error :statuscode 409: an error occurred", "response": "def job(job_id=None):\n    '''Submit a job. If no id is provided, a random id will be generated.\n\n    :param job_type: Which kind of job should be run. Has to be one of the\n        available job types.\n    :type job_type: string\n    :param api_key: An API key that is needed to execute the job. This could\n        be a CKAN API key that is needed to write any data. The key will also be\n        used to administer jobs. If you don't want to use a real API key, you can\n        provide a random string that you keep secure.\n    :type api_key: string\n    :param data: Data that is send to the job as input. (Optional)\n    :type data: json encodable data\n    :param result_url: Callback url that is called once the job has finished.\n        (Optional)\n    :type result_url: url string\n    :param metadata: Data needed for the execution of the job which is not\n        the input data. (Optional)\n    :type metadata: list of key - value pairs\n\n    **Results:**\n\n    :rtype: A dictionary with the following keys\n    :param job_id: An identifier for the job\n    :type job_id: string\n    :param job_key: A key that is required to view and administer the job\n    :type job_key: string\n\n    :statuscode 200: no error\n    :statuscode 409: an error occurred\n\n    '''\n    if not job_id:\n        job_id = str(uuid.uuid4())\n\n    # key required for job administration\n    job_key = str(uuid.uuid4())\n\n    ############# ERROR CHECKING ################\n    try:\n        input = flask.request.json\n    except werkzeug.exceptions.BadRequest:\n        return json.dumps({\"error\": \"Malformed json\"}), 409, headers\n\n    # Idk why but this is needed for some libraries that\n    # send malformed content types\n    if (not input and\n            'application/json' in flask.request.content_type.lower()):\n        try:\n            input = json.loads(flask.request.data)\n        except ValueError:\n            pass\n    if not input:\n        return json.dumps({\"error\": ('Not recognised as json, make '\n                                     'sure content type is application/'\n                                     'json')}), 409, headers\n\n    ACCEPTED_ARGUMENTS = set(['job_type', 'data', 'metadata',\n                              'result_url', 'api_key', 'metadata'])\n    extra_keys = set(input.keys()) - ACCEPTED_ARGUMENTS\n    if extra_keys:\n        return json.dumps({\"error\": (\n            'Too many arguments. Extra keys are {}'.format(\n                ', '.join(extra_keys)))}), 409, headers\n\n    #check result_url here as good to give warning early.\n    result_url = input.get('result_url')\n    if result_url and not result_url.startswith('http'):\n        return json.dumps({\"error\": \"result_url has to start with http\"}), \\\n            409, headers\n\n    job_type = input.get('job_type')\n    if not job_type:\n        return json.dumps({\"error\": \"Please specify a job type\"}), 409, headers\n\n    job_types = async_types.keys() + sync_types.keys()\n\n    if job_type not in job_types:\n        error_string = (\n            'Job type {} not available. Available job types are {}'\n        ).format(job_type, ', '.join(job_types))\n        return json.dumps({\"error\": error_string}), 409, headers\n\n    api_key = input.get('api_key')\n    if not api_key:\n        return json.dumps({\"error\": \"Please provide your API key.\"}), 409, headers\n\n    metadata = input.get('metadata', {})\n    if not isinstance(metadata, dict):\n        return json.dumps({\"error\": \"metadata has to be a json object\"}), \\\n            409, headers\n    ############# END CHECKING ################\n\n    synchronous_job = sync_types.get(job_type)\n    if synchronous_job:\n        return run_synchronous_job(synchronous_job, job_id, job_key, input)\n    else:\n        asynchronous_job = async_types.get(job_type)\n        return run_asynchronous_job(asynchronous_job, job_id, job_key, input)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning true if the request is authorized for the job .", "response": "def is_authorized(job=None):\n    '''Returns true if the request is authorized for the job\n    if provided. If no job is provided, the user has to be admin\n    to be authorized.\n    '''\n    if flogin.current_user.is_authenticated:\n        return True\n    if job:\n        job_key = flask.request.headers.get('Authorization')\n        if job_key == app.config.get('SECRET_KEY'):\n            return True\n        return job['job_key'] == job_key\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_result(job_id, api_key=None):\n    ''' Send results to where requested.\n\n    If api_key is provided, it is used, otherwiese\n    the key from the job will be used.\n    '''\n    job_dict = db.get_job(job_id)\n    result_url = job_dict.get('result_url')\n\n    if not result_url:\n\n        # A job with an API key (for using when posting to the callback URL)\n        # but no callback URL is weird, but it can happen.\n        db.delete_api_key(job_id)\n\n        return True\n\n    api_key_from_job = job_dict.pop('api_key', None)\n    if not api_key:\n        api_key = api_key_from_job\n    headers = {'Content-Type': 'application/json'}\n    if api_key:\n        if ':' in api_key:\n            header, key = api_key.split(':')\n        else:\n            header, key = 'Authorization', api_key\n        headers[header] = key\n\n    try:\n        result = requests.post(\n            result_url,\n            data=json.dumps(job_dict, cls=DatetimeJsonEncoder),\n            headers=headers, verify=SSL_VERIFY)\n\n        db.delete_api_key(job_id)\n\n    except requests.ConnectionError:\n        return False\n\n    return result.status_code == requests.codes.ok", "response": "Send results to where requested."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(uri, echo=False):\n    global ENGINE, _METADATA, JOBS_TABLE, METADATA_TABLE, LOGS_TABLE\n    ENGINE = sqlalchemy.create_engine(uri, echo=echo, convert_unicode=True)\n    _METADATA = sqlalchemy.MetaData(ENGINE)\n    JOBS_TABLE = _init_jobs_table()\n    METADATA_TABLE = _init_metadata_table()\n    LOGS_TABLE = _init_logs_table()\n    _METADATA.create_all(ENGINE)", "response": "Initialise the sqlalchemy engine metadata and table objects that we use to store the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the job with the given job_id as a dict.", "response": "def get_job(job_id):\n    \"\"\"Return the job with the given job_id as a dict.\n\n    The dict also includes any metadata or logs associated with the job.\n\n    Returns None instead of a dict if there's no job with the given job_id.\n\n    The keys of a job dict are:\n\n    \"job_id\": The unique identifier for the job (unicode)\n\n    \"job_type\": The name of the job function that will be executed for this\n        job (unicode)\n\n    \"status\": The current status of the job, e.g. \"pending\", \"complete\", or\n        \"error\" (unicode)\n\n    \"data\": Any output data returned by the job if it has completed\n        successfully. This may be any JSON-serializable type, e.g. None, a\n        string, a dict, etc.\n\n    \"error\": If the job failed with an error this will be a dict with a\n        \"message\" key whose value is a string error message. The dict may also\n        have other keys specific to the particular type of error. If the job\n        did not fail with an error then \"error\" will be None.\n\n    \"requested_timestamp\": The time at which the job was requested (string)\n\n    \"finished_timestamp\": The time at which the job finished (string)\n\n    \"sent_data\": The input data for the job, provided by the client site.\n        This may be any JSON-serializable type, e.g. None, a string, a dict,\n        etc.\n\n    \"result_url\": The callback URL that CKAN Service Provider will post the\n        result to when the job finishes (unicode)\n\n    \"api_key\": The API key that CKAN Service Provider will use when posting\n        the job result to the result_url (unicode or None). A None here doesn't\n        mean that there was no API key: CKAN Service Provider deletes the API\n        key from the database after it has posted the result to the result_url.\n\n    \"job_key\": The key that users must provide (in the Authorization header of\n        the HTTP request) to be authorized to modify the job (unicode).\n        For example requests to the CKAN Service Provider API need this to get\n        the status or output data of a job or to delete a job.\n        If you login to CKAN Service Provider as an administrator then you can\n        administer any job without providing its job_key.\n\n    \"metadata\": Any custom metadata associated with the job (dict)\n\n    \"logs\": Any logs associated with the job (list)\n\n    \"\"\"\n    # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n    # warnings.\n    if job_id:\n        job_id = unicode(job_id)\n\n    result = ENGINE.execute(\n        JOBS_TABLE.select().where(JOBS_TABLE.c.job_id == job_id)).first()\n\n    if not result:\n        return None\n\n    # Turn the result into a dictionary representation of the job.\n    result_dict = {}\n    for field in result.keys():\n        value = getattr(result, field)\n        if value is None:\n            result_dict[field] = value\n        elif field in ('sent_data', 'data', 'error'):\n            result_dict[field] = json.loads(value)\n        elif isinstance(value, datetime.datetime):\n            result_dict[field] = value.isoformat()\n        else:\n            result_dict[field] = unicode(value)\n\n    result_dict['metadata'] = _get_metadata(job_id)\n    result_dict['logs'] = _get_logs(job_id)\n\n    return result_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_pending_job(job_id, job_key, job_type, api_key,\n                    data=None, metadata=None, result_url=None):\n    \"\"\"Add a new job with status \"pending\" to the jobs table.\n\n    All code that adds jobs to the jobs table should go through this function.\n    Code that adds to the jobs table manually should be refactored to use this\n    function.\n\n    May raise unspecified exceptions from Python core, SQLAlchemy or JSON!\n    TODO: Document and unit test these!\n\n    :param job_id: a unique identifier for the job, used as the primary key in\n        ckanserviceprovider's \"jobs\" database table\n    :type job_id: unicode\n\n    :param job_key: the key required to administer the job via the API\n    :type job_key: unicode\n\n    :param job_type: the name of the job function that will be executed for\n        this job\n    :type job_key: unicode\n\n    :param api_key: the client site API key that ckanserviceprovider will use\n        when posting the job result to the result_url\n    :type api_key: unicode\n\n    :param data: The input data for the job (called sent_data elsewhere)\n    :type data: Any JSON-serializable type\n\n    :param metadata: A dict of arbitrary (key, value) metadata pairs to be\n        stored along with the job. The keys should be strings, the values can\n        be strings or any JSON-encodable type.\n    :type metadata: dict\n\n    :param result_url: the callback URL that ckanserviceprovider will post the\n        job result to when the job has finished\n    :type result_url: unicode\n\n    \"\"\"\n    if not data:\n        data = {}\n    data = json.dumps(data)\n\n    # Turn strings into unicode to stop SQLAlchemy\n    # \"Unicode type received non-unicode bind param value\" warnings.\n    if job_id:\n        job_id = unicode(job_id)\n    if job_type:\n        job_type = unicode(job_type)\n    if result_url:\n        result_url = unicode(result_url)\n    if api_key:\n        api_key = unicode(api_key)\n    if job_key:\n        job_key = unicode(job_key)\n    data = unicode(data)\n\n    if not metadata:\n        metadata = {}\n\n    conn = ENGINE.connect()\n    trans = conn.begin()\n    try:\n        conn.execute(JOBS_TABLE.insert().values(\n            job_id=job_id,\n            job_type=job_type,\n            status='pending',\n            requested_timestamp=datetime.datetime.now(),\n            sent_data=data,\n            result_url=result_url,\n            api_key=api_key,\n            job_key=job_key))\n\n        # Insert any (key, value) metadata pairs that the job has into the\n        # metadata table.\n        inserts = []\n        for key, value in metadata.items():\n            type_ = 'string'\n            if not isinstance(value, basestring):\n                value = json.dumps(value)\n                type_ = 'json'\n\n            # Turn strings into unicode to stop SQLAlchemy\n            # \"Unicode type received non-unicode bind param value\" warnings.\n            key = unicode(key)\n            value = unicode(value)\n\n            inserts.append(\n                {\"job_id\": job_id,\n                 \"key\": key,\n                 \"value\": value,\n                 \"type\": type_}\n            )\n        if inserts:\n            conn.execute(METADATA_TABLE.insert(), inserts)\n        trans.commit()\n    except Exception:\n        trans.rollback()\n        raise\n    finally:\n        conn.close()", "response": "Add a new pending job to the jobs table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _validate_error(error):\n    if error is None:\n        return None\n    elif isinstance(error, basestring):\n        return {\"message\": error}\n    else:\n        try:\n            message = error[\"message\"]\n            if isinstance(message, basestring):\n                return error\n            else:\n                raise InvalidErrorObjectError(\n                    \"error['message'] must be a string\")\n        except (TypeError, KeyError):\n            raise InvalidErrorObjectError(\n                \"error must be either a string or a dict with a message key\")", "response": "Validate and return the given error object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _update_job(job_id, job_dict):\n    # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n    # warnings.\n    if job_id:\n        job_id = unicode(job_id)\n\n    if \"error\" in job_dict:\n        job_dict[\"error\"] = _validate_error(job_dict[\"error\"])\n        job_dict[\"error\"] = json.dumps(job_dict[\"error\"])\n        # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n        # warnings.\n        job_dict[\"error\"] = unicode(job_dict[\"error\"])\n\n    # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n    # warnings.\n    if \"data\" in job_dict:\n        job_dict[\"data\"] = unicode(job_dict[\"data\"])\n\n    ENGINE.execute(\n        JOBS_TABLE.update()\n        .where(JOBS_TABLE.c.job_id == job_id)\n        .values(**job_dict))", "response": "Update the database row for the given job_id with the given job_dict."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmarks a job as completed successfully.", "response": "def mark_job_as_completed(job_id, data=None):\n    \"\"\"Mark a job as completed successfully.\n\n    :param job_id: the job_id of the job to be updated\n    :type job_id: unicode\n\n    :param data: the output data returned by the job\n    :type data: any JSON-serializable type (including None)\n\n    \"\"\"\n    update_dict = {\n        \"status\": \"complete\",\n        \"data\": json.dumps(data),\n        \"finished_timestamp\": datetime.datetime.now(),\n    }\n    _update_job(job_id, update_dict)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mark_job_as_errored(job_id, error_object):\n    update_dict = {\n        \"status\": \"error\",\n        \"error\": error_object,\n        \"finished_timestamp\": datetime.datetime.now(),\n    }\n    _update_job(job_id, update_dict)", "response": "Mark a job as failed with an error."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init_jobs_table():\n    _jobs_table = sqlalchemy.Table(\n        'jobs', _METADATA,\n        sqlalchemy.Column('job_id', sqlalchemy.UnicodeText, primary_key=True),\n        sqlalchemy.Column('job_type', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('status', sqlalchemy.UnicodeText, index=True),\n        sqlalchemy.Column('data', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('error', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('requested_timestamp', sqlalchemy.DateTime),\n        sqlalchemy.Column('finished_timestamp', sqlalchemy.DateTime),\n        sqlalchemy.Column('sent_data', sqlalchemy.UnicodeText),\n        # Callback URL:\n        sqlalchemy.Column('result_url', sqlalchemy.UnicodeText),\n        # CKAN API key:\n        sqlalchemy.Column('api_key', sqlalchemy.UnicodeText),\n        # Key to administer job:\n        sqlalchemy.Column('job_key', sqlalchemy.UnicodeText),\n        )\n    return _jobs_table", "response": "Initialise the jobs table in the db."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitialising the metadata table in the db.", "response": "def _init_metadata_table():\n    \"\"\"Initialise the \"metadata\" table in the db.\"\"\"\n    _metadata_table = sqlalchemy.Table(\n        'metadata', _METADATA,\n        sqlalchemy.Column(\n            'job_id', sqlalchemy.ForeignKey(\"jobs.job_id\", ondelete=\"CASCADE\"),\n            nullable=False, primary_key=True),\n        sqlalchemy.Column('key', sqlalchemy.UnicodeText, primary_key=True),\n        sqlalchemy.Column('value', sqlalchemy.UnicodeText, index=True),\n        sqlalchemy.Column('type', sqlalchemy.UnicodeText),\n        )\n    return _metadata_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitialises the logs table in the db.", "response": "def _init_logs_table():\n    \"\"\"Initialise the \"logs\" table in the db.\"\"\"\n    _logs_table = sqlalchemy.Table(\n        'logs', _METADATA,\n        sqlalchemy.Column(\n            'job_id', sqlalchemy.ForeignKey(\"jobs.job_id\", ondelete=\"CASCADE\"),\n            nullable=False),\n        sqlalchemy.Column('timestamp', sqlalchemy.DateTime),\n        sqlalchemy.Column('message', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('level', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('module', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('funcName', sqlalchemy.UnicodeText),\n        sqlalchemy.Column('lineno', sqlalchemy.Integer)\n        )\n    return _logs_table"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns any metadata for the given job_id from the metadata table.", "response": "def _get_metadata(job_id):\n    \"\"\"Return any metadata for the given job_id from the metadata table.\"\"\"\n    # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n    # warnings.\n    job_id = unicode(job_id)\n\n    results = ENGINE.execute(\n        METADATA_TABLE.select().where(\n            METADATA_TABLE.c.job_id == job_id)).fetchall()\n    metadata = {}\n    for row in results:\n        value = row['value']\n        if row['type'] == 'json':\n            value = json.loads(value)\n        metadata[row['key']] = value\n    return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning any logs for the given job_id from the logs table.", "response": "def _get_logs(job_id):\n    \"\"\"Return any logs for the given job_id from the logs table.\"\"\"\n    # Avoid SQLAlchemy \"Unicode type received non-unicode bind param value\"\n    # warnings.\n    job_id = unicode(job_id)\n\n    results = ENGINE.execute(\n        LOGS_TABLE.select().where(LOGS_TABLE.c.job_id == job_id)).fetchall()\n\n    results = [dict(result) for result in results]\n\n    for result in results:\n        result.pop(\"job_id\")\n\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_node_attributes(pattern, node, *attributes):\n    for attribute_name in attributes:\n        attribute = node.get(attribute_name)\n        if attribute is not None and pattern.search(attribute):\n            return True\n\n    return False", "response": "Checks if a node matches any of the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_hash_id(node):\n    try:\n        content = tostring(node)\n    except Exception:\n        logger.exception(\"Generating of hash failed\")\n        content = to_bytes(repr(node))\n\n    hash_id = md5(content).hexdigest()\n    return hash_id[:8]", "response": "Generates a hash_id for the node in question."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the density of text in given node and text in links contained in the node.", "response": "def get_link_density(node, node_text=None):\n    \"\"\"\n    Computes the ratio for text in given node and text in links\n    contained in the node. It is computed from number of\n    characters in the texts.\n\n    :parameter Element node:\n        HTML element in which links density is computed.\n    :parameter string node_text:\n        Text content of given node if it was obtained before.\n    :returns float:\n        Returns value of computed 0 <= density <= 1, where 0 means\n        no links and 1 means that node contains only links.\n    \"\"\"\n    if node_text is None:\n        node_text = node.text_content()\n    node_text = normalize_whitespace(node_text.strip())\n\n    text_length = len(node_text)\n    if text_length == 0:\n        return 0.0\n\n    links_length = sum(map(_get_normalized_text_length, node.findall(\".//a\")))\n    # Give 50 bonus chars worth of length for each img.\n    # Tweaking this 50 down a notch should help if we hit false positives.\n    img_bonuses = 50 * len(node.findall(\".//img\"))\n    links_length = max(0, links_length - img_bonuses)\n\n    return links_length / text_length"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_class_weight(node):\n    weight = 0\n\n    if check_node_attributes(CLS_WEIGHT_NEGATIVE, node, \"class\"):\n        weight -= 25\n    if check_node_attributes(CLS_WEIGHT_POSITIVE, node, \"class\"):\n        weight += 25\n\n    if check_node_attributes(CLS_WEIGHT_NEGATIVE, node, \"id\"):\n        weight -= 25\n    if check_node_attributes(CLS_WEIGHT_POSITIVE, node, \"id\"):\n        weight += 25\n\n    return weight", "response": "Compute the weight of the element according to its class and id."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a node is likely to be in the unlikely list.", "response": "def is_unlikely_node(node):\n    \"\"\"\n    Short helper for checking unlikely status.\n\n    If the class or id are in the unlikely list, and there's not also a\n    class/id in the likely list then it might need to be removed.\n    \"\"\"\n    unlikely = check_node_attributes(CLS_UNLIKELY, node, \"class\", \"id\")\n    maybe = check_node_attributes(CLS_MAYBE, node, \"class\", \"id\")\n\n    return bool(unlikely and not maybe and node.tag != \"body\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef score_candidates(nodes):\n    MIN_HIT_LENTH = 25\n    candidates = {}\n\n    for node in nodes:\n        logger.debug(\"* Scoring candidate %s %r\", node.tag, node.attrib)\n\n        # if the node has no parent it knows of then it ends up creating a\n        # body & html tag to parent the html fragment\n        parent = node.getparent()\n        if parent is None:\n            logger.debug(\"Skipping candidate - parent node is 'None'.\")\n            continue\n\n        grand = parent.getparent()\n        if grand is None:\n            logger.debug(\"Skipping candidate - grand parent node is 'None'.\")\n            continue\n\n        # if paragraph is < `MIN_HIT_LENTH` characters don't even count it\n        inner_text = node.text_content().strip()\n        if len(inner_text) < MIN_HIT_LENTH:\n            logger.debug(\n                \"Skipping candidate - inner text < %d characters.\",\n                MIN_HIT_LENTH)\n            continue\n\n        # initialize readability data for the parent\n        # add parent node if it isn't in the candidate list\n        if parent not in candidates:\n            candidates[parent] = ScoredNode(parent)\n\n        if grand not in candidates:\n            candidates[grand] = ScoredNode(grand)\n\n        # add a point for the paragraph itself as a base\n        content_score = 1\n\n        if inner_text:\n            # add 0.25 points for any commas within this paragraph\n            commas_count = inner_text.count(\",\")\n            content_score += commas_count * 0.25\n            logger.debug(\"Bonus points for %d commas.\", commas_count)\n\n            # subtract 0.5 points for each double quote within this paragraph\n            double_quotes_count = inner_text.count('\"')\n            content_score += double_quotes_count * -0.5\n            logger.debug(\n                \"Penalty points for %d double-quotes.\", double_quotes_count)\n\n            # for every 100 characters in this paragraph, add another point\n            # up to 3 points\n            length_points = len(inner_text) / 100\n            content_score += min(length_points, 3.0)\n            logger.debug(\"Bonus points for length of text: %f\", length_points)\n\n        # add the score to the parent\n        logger.debug(\n            \"Bonus points for parent %s %r with score %f: %f\",\n            parent.tag, parent.attrib, candidates[parent].content_score,\n            content_score)\n        candidates[parent].content_score += content_score\n        # the grand node gets half\n        logger.debug(\n            \"Bonus points for grand %s %r with score %f: %f\",\n            grand.tag, grand.attrib, candidates[grand].content_score,\n            content_score / 2.0)\n        candidates[grand].content_score += content_score / 2.0\n\n        if node not in candidates:\n            candidates[node] = ScoredNode(node)\n        candidates[node].content_score += content_score\n\n    for candidate in candidates.values():\n        adjustment = 1.0 - get_link_density(candidate.node)\n        candidate.content_score *= adjustment\n        logger.debug(\n            \"Link density adjustment for %s %r: %f\",\n            candidate.node.tag, candidate.node.attrib, adjustment)\n\n    return candidates", "response": "Given a list of potential nodes find some initial scores to start"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear(self):\n        self.filename = ''\n        self.filehandler = 0\n        # Station name, identification and revision year:\n        self.station_name = ''\n        self.rec_dev_id = ''\n        self.rev_year = 0000\n        # Number and type of channels:\n        self.TT = 0\n        self.A = 0 # Number of analog channels.\n        self.D = 0 # Number of digital channels.\n        # Analog channel information:\n        self.An = []\n        self.Ach_id = []\n        self.Aph = []\n        self.Accbm = []\n        self.uu = []\n        self.a = []\n        self.b = []\n        self.skew = []\n        self.min = []\n        self.max = []\n        self.primary = []\n        self.secondary = []\n        self.PS = []\n        # Digital channel information:\n        self.Dn = []\n        self.Dch_id = []\n        self.Dph = []\n        self.Dccbm = []\n        self.y = []\n        # Line frequency:\n        self.lf = 0\n        # Sampling rate information:\n        self.nrates = 0\n        self.samp = []\n        self.endsamp = []\n        # Date/time stamps:\n        #    defined by: [dd,mm,yyyy,hh,mm,ss.ssssss]\n        self.start = [00,00,0000,00,00,0.0]\n        self.trigger = [00,00,0000,00,00,0.0]\n        # Data file type:\n        self.ft = ''\n        # Time stamp multiplication factor:\n        self.timemult = 0.0\n        \n        self.DatFileContent = ''", "response": "Clear the internal ( private ) variables of the class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ReadCFG(self):\n            \n        self.filehandler = open(self.filename,'r')\n        # Processing first line:\n        line = self.filehandler.readline()\n        templist = line.split(',')\n        self.station_name = templist[0]\n        self.rec_dev_id = templist[1]\n        # Odd cfg file may not contain all first line fields\n        # checking vector length to avoid IndexError\n        if len(templist) > 2:\n            self.rev_year = int(templist[2])\n\n        # Processing second line:\n        line = self.filehandler.readline().rstrip() # Read line and remove spaces and new line characters.\n        templist = line.split(',')\n        self.TT = int(templist[0])\n        self.A = int(templist[1].strip('A'))\n        self.D = int(templist[2].strip('D'))\n\n        # Processing analog channel lines:\n        for i in range(self.A): #@UnusedVariable\n            line = self.filehandler.readline()\n            templist = line.split(',')\n            self.An.append(int(templist[0]))\n            self.Ach_id.append(templist[1])\n            self.Aph.append(templist[2])\n            self.Accbm.append(templist[3])\n            self.uu.append(templist[4])\n            self.a.append(float(templist[5]))\n            self.b.append(float(templist[6]))\n            self.skew.append(float(templist[7]))\n            self.min.append(int(templist[8]))\n            self.max.append(int(templist[9]))\n            # Odd cfg file may not contain all analog channel fields\n            # checking vector length to avoid IndexError\n            if len(templist) > 10:\n                self.primary.append(float(templist[10]))\n            if len(templist) > 11:\n                self.secondary.append(float(templist[11]))\n            if len(templist) > 12:\n                self.PS.append(templist[12])\n\n        # Processing digital channel lines:\n        for i in range(self.D): #@UnusedVariable\n            line = self.filehandler.readline()\n            templist = line.split(',')\n            self.Dn.append(int(templist[0]))\n            self.Dch_id.append(templist[1])\n            self.Dph.append(templist[2])\n            # Odd cfg file may not contain all digital channel fields\n            # checking vector length to avoid IndexError\n            if len(templist) > 3:\n                self.Dccbm.append(templist[3])\n            if len(templist) > 4:\n                self.y.append(int(templist[4]))\n\n        # Read line frequency:\n        self.lf = int(float(self.filehandler.readline()))\n\n        # Read sampling rates:\n        self.nrates = int(self.filehandler.readline()) # nrates.\n        for i in range(self.nrates): #@UnusedVariable\n            line = self.filehandler.readline()\n            templist = line.split(',')\n            self.samp.append(int(float(templist[0])))\n            self.endsamp.append(int(float(templist[1])))\n\n        # Read start date and time ([dd,mm,yyyy,hh,mm,ss.ssssss]):\n        line = self.filehandler.readline()\n        templist = line.split('/')\n        self.start[0] = int(templist[0]) # day.\n        self.start[1] = int(templist[1]) # month.\n        templist = templist[2].split(',')\n        self.start[2] = int(templist[0]) # year.\n        templist = templist[1].split(':')\n        self.start[3] = int(templist[0]) # hours.\n        self.start[4] = int(templist[1]) # minutes.\n        self.start[5] = float(templist[2]) # seconds.\n\n        # Read trigger date and time ([dd,mm,yyyy,hh,mm,ss.ssssss]):\n        line = self.filehandler.readline()\n        templist = line.split('/')\n        self.trigger[0] = int(templist[0]) # day.\n        self.trigger[1] = int(templist[1]) # month.\n        templist = templist[2].split(',')\n        self.trigger[2] = int(templist[0]) # year.\n        templist = templist[1].split(':')\n        self.trigger[3] = int(templist[0]) # hours.\n        self.trigger[4] = int(templist[1]) # minutes.\n        self.trigger[5] = float(templist[2]) # seconds.\n\n        # Read file type:\n        self.ft = self.filehandler.readline()\n        \n        # Read time multiplication factor:\n        # Odd cfg file may not have multiplication field, so checking\n        # its existance before reading is a safe measure\n        # If the multiplication field is not available, it will be considered as 1\n        self.timemul = self.filehandler.readline()\n        if self.timemul != '':\n            self.timemul = float(self.timemul)\n        else:\n            self.timemul = 1\n\n        # END READING .CFG FILE.\n        self.filehandler.close()", "response": "Reads the Comtrade cfg file and populates the internal attributes."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a time stamp vector based on the number of samples and sample rate.", "response": "def getTime(self):\n        \"\"\"\n        Actually, this function creates a time stamp vector \n        based on the number of samples and sample rate.\n        \"\"\"\n        T = 1/float(self.samp[self.nrates-1])\n        endtime = self.endsamp[self.nrates-1] * T\n\n        t = numpy.linspace(0,endtime,self.endsamp[self.nrates-1])\n\n        return t"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAnalogID(self,num):\n        listidx = self.An.index(num) # Get the position of the channel number.\n        return self.Ach_id[listidx]", "response": "Returns the COMTRADE ID of a given channel number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread the COMTRADE ID of a given channel number.", "response": "def getDigitalID(self,num):\n        \"\"\"\n        Reads the COMTRADE ID of a given channel number.\n        The number to be given is the same of the COMTRADE header.\n        \"\"\"\n        listidx = self.Dn.index(num) # Get the position of the channel number.\n        return self.Dch_id[listidx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getAnalogType(self,num):\n        listidx = self.An.index(num)\n        unit = self.uu[listidx]\n\n        if unit == 'kV' or unit == 'V':\n            return 'V'\n        elif unit == 'A' or unit == 'kA':\n            return 'I'\n        else:\n            print 'Unknown channel type'\n            return 0", "response": "Returns the type of the channel num based \n        on its unit stored in the Comtrade header file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getAnalogUnit(self,num):\n        listidx = self.An.index(num) # Get the position of the channel number.\n        return self.uu[listidx]", "response": "Returns the COMTRADE channel unit for a given channel number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the contents of the Comtrade. dat file and stores them in a private variable.", "response": "def ReadDataFile(self):\n        \"\"\"\n        Reads the contents of the Comtrade .dat file and store them in a\n        private variable.\n        \n        For accessing a specific channel data, see methods getAnalogData and\n        getDigitalData.\n        \"\"\"\n        if os.path.isfile(self.filename[0:-4] + '.dat'):\n            filename = self.filename[0:-4] + '.dat'\n    \n        elif os.path.isfile(self.filename[0:-4] + '.DAT'):\n            filename = self.filename[0:-4] + '.DAT'\n        \n        else:\n            print \"Data file File not found.\"\n            return 0\n        \n        self.filehandler = open(filename,'rb')\n        self.DatFileContent = self.filehandler.read()\n    \n        # END READING .dat FILE.\n        self.filehandler.close() # Close file.        \n        \n        return 1"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAnalogChannelData(self,ChNumber):\n\n        if not self.DatFileContent:\n            print \"No data file content. Use the method ReadDataFile first\"\n            return 0\n        \n        if (ChNumber > self.A):\n            print \"Channel number greater than the total number of channels.\"\n            return 0\n            \n        # Fomating string for struct module:\n        str_struct = \"ii%dh\" %(self.A + int(numpy.ceil((float(self.D)/float(16)))))\n        # Number of bytes per sample:\n        NB = 4 + 4 + self.A*2 + int(numpy.ceil((float(self.D)/float(16))))*2        \n        # Number of samples:\n        N = self.getNumberOfSamples()\n        \n        # Empty column vector:\n        values = numpy.empty((N,1))\n\n        ch_index = self.An.index(ChNumber)\n\n        # Reading the values from DatFileContent string:\n        for i in range(N):\n            data = struct.unpack(str_struct,self.DatFileContent[i*NB:(i*NB)+NB])\n            values[i] = data[ChNumber+1] # The first two number ar the sample index and timestamp\n\n        values = values * self.a[ch_index] # a factor\n        values = values + self.b[ch_index] # b factor\n        \n        return values", "response": "Returns an array of numbers containing the data values of the channel with the specified number."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an array of numbers containing the values of the digital channel status.", "response": "def getDigitalChannelData(self,ChNumber):\n        \"\"\"\n        Returns an array of numbers (0 or 1) containing the values of the \n        digital channel status.\n        \n        ChNumber: digital channel number.\n        \"\"\"\n\n        if not self.DatFileContent:\n            print \"No data file content. Use the method ReadDataFile first\"\n            return 0\n            \n        if (ChNumber > self.D):\n            print \"Digital channel number greater than the total number of channels.\"\n            return 0\n        \n        # Fomating string for struct module:\n        str_struct = \"ii%dh%dH\" %(self.A, int(numpy.ceil((float(self.D)/float(16)))))\n        # Number of bytes per sample:\n        NB = 4 + 4 + self.A*2 + int(numpy.ceil((float(self.D)/float(16))))*2        \n        # Number of samples:\n        N = self.getNumberOfSamples()\n\n        # Empty column vector:\n        values = numpy.empty((N,1))\n        # Number of the 16 word where digital channal is. Every word contains\n        # 16 digital channels:\n        byte_number = int(numpy.ceil((ChNumber-1)/16)+1)\n        # Value of the digital channel. Ex. channal 1 has value 2^0=1, channel\n        # 2 has value 2^1 = 2, channel 3 => 2^2=4 and so on.\n        digital_ch_value = (1<<(ChNumber-1-(byte_number-1)*16))\n\n        # Reading the values from DatFileContent string:\n        for i in range(N):\n            data = struct.unpack(str_struct,self.DatFileContent[i*NB:(i*NB)+NB])\n            # The first two number ar the sample index and timestamp.\n            # And logic to extract only one channel from the 16 bit.\n            # Normalize the output to 0 or 1 \n            values[i] = (digital_ch_value & data[self.A+1+byte_number]) * 1/digital_ch_value \n        \n        # Return the array.\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(self):\n        \"Connect to a host on a given (SSL) port.\"\n\n        #\n        # source_address \u00e9 atributo inclu\u00eddo na vers\u00e3o 2.7 do Python\n        # Verificando a exist\u00eancia para funcionar em vers\u00f5es anteriores \u00e0 2.7\n        #\n        if hasattr(self, 'source_address'):\n            sock = socket.create_connection((self.host, self.port), self.timeout, self.source_address)\n        else:\n            sock = socket.create_connection((self.host, self.port), self.timeout)\n\n        if self._tunnel_host:\n            self.sock = sock\n            self._tunnel()\n\n        if sys.version_info >= (2,7,13):\n            self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_TLS, do_handshake_on_connect=False)\n        else:\n            self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file, ssl_version=ssl.PROTOCOL_SSLv23, do_handshake_on_connect=False)", "response": "Connect to a host on a given ( SSL ) port."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initLogger():\n    '''\n    This code taken from Matt's Suspenders for initializing a logger\n    '''\n    global logger\n    logger = logging.getLogger('root')\n    logger.setLevel(logging.DEBUG)\n    ch = logging.StreamHandler(sys.stdout)\n    ch.setLevel(logging.INFO)\n    formatter = logging.Formatter(\"[%(asctime)s] %(levelname)s: %(message)s\", \"%Y-%m-%d %H:%M:%S\")\n    ch.setFormatter(formatter)\n    logger.addHandler(ch)", "response": "This code taken from Matt s Suspenders for initializing a logger\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mainRun():\n    '''\n    This is the primary function for external typical users to run when the Command Line Interface is used\n    '''\n    #start up the logger\n    initLogger()\n    \n    #attempt to parse the arguments\n    p = ap.ArgumentParser(description=util.DESC, formatter_class=ap.RawTextHelpFormatter)\n    \n    #version data\n    p.add_argument('-V', '--version', action='version', version='%(prog)s' + \\\n                   ' %s in MSBWT %s' % (util.VERSION, util.PKG_VERSION))\n    \n    #TODO: do we want subparsers groups by type or sorted by name? it's type currently\n    \n    sp = p.add_subparsers(dest='subparserID')\n    p2 = sp.add_parser('cffq', help='create a MSBWT from FASTQ files (pp + cfpp)')\n    p2.add_argument('-p', metavar='numProcesses', dest='numProcesses', type=int, default=1, help='number of processes to run (default: 1)')\n    p2.add_argument('-u', '--uniform', dest='areUniform', action='store_true', help='the input sequences have uniform length', default=False)\n    p2.add_argument('-c', '--compressed', dest='buildCompressed', action='store_true', help='build the RLE BWT (faster, less disk I/O)', default=False)\n    p2.add_argument('outBwtDir', type=util.newDirectory, help='the output MSBWT directory')\n    p2.add_argument('inputFastqs', nargs='+', type=util.readableFastqFile, help='the input FASTQ files')\n    \n    p7 = sp.add_parser('pp', help='pre-process FASTQ files before BWT creation')\n    p7.add_argument('-u', '--uniform', dest='areUniform', action='store_true', help='the input sequences have uniform length', default=False)\n    p7.add_argument('outBwtDir', type=util.newDirectory, help='the output MSBWT directory')\n    p7.add_argument('inputFastqs', nargs='+', type=util.readableFastqFile, help='the input FASTQ files')\n    \n    p3 = sp.add_parser('cfpp', help='create a MSBWT from pre-processed sequences and offsets')\n    p3.add_argument('-p', metavar='numProcesses', dest='numProcesses', type=int, default=1, help='number of processes to run (default: 1)')\n    p3.add_argument('-u', '--uniform', dest='areUniform', action='store_true', help='the input sequences have uniform length', default=False)\n    p3.add_argument('-c', '--compressed', dest='buildCompressed', action='store_true', help='build the RLE BWT (faster, less disk I/O)', default=False)\n    p3.add_argument('bwtDir', type=util.existingDirectory, help='the MSBWT directory to process')\n    \n    p4 = sp.add_parser('merge', help='merge many MSBWTs into a single MSBWT')\n    p4.add_argument('-p', metavar='numProcesses', dest='numProcesses', type=int, default=1, help='number of processes to run (default: 1)')\n    p4.add_argument('outBwtDir', type=util.newDirectory, help='the output MSBWT directory')\n    p4.add_argument('inputBwtDirs', nargs='+', type=util.existingDirectory, help='input BWT directories to merge')\n    \n    p5 = sp.add_parser('query', help='search for a sequence in an MSBWT, prints sequence and seqID')\n    p5.add_argument('inputBwtDir', type=util.existingDirectory, help='the BWT to query')\n    p5.add_argument('kmer', type=util.validKmer, help='the input k-mer to search for')\n    p5.add_argument('-d', '--dump-seqs', dest='dumpSeqs', action='store_true', help='print all sequences with the given kmer (default=False)', default=False)\n    \n    p6 = sp.add_parser('massquery', help='search for many sequences in an MSBWT')\n    p6.add_argument('inputBwtDir', type=util.existingDirectory, help='the BWT to query')\n    p6.add_argument('kmerFile', help='a file with one k-mer per line')\n    p6.add_argument('outputFile', help='output file with counts per line')\n    p6.add_argument('-r', '--rev-comp', dest='reverseComplement', action='store_true', help='also search for each kmer\\'s reverse complement', default=False)\n    \n    p8 = sp.add_parser('compress', help='compress a MSBWT from byte/base to RLE')\n    p8.add_argument('-p', metavar='numProcesses', dest='numProcesses', type=int, default=1, help='number of processes to run (default: 1)')\n    p8.add_argument('srcDir', type=util.existingDirectory, help='the source directory for the BWT to compress')\n    p8.add_argument('dstDir', type=util.newDirectory, help='the destination directory')\n    \n    p9 = sp.add_parser('decompress', help='decompress a MSBWT from RLE to byte/base')\n    p9.add_argument('-p', metavar='numProcesses', dest='numProcesses', type=int, default=1, help='number of processes to run (default: 1)')\n    p9.add_argument('srcDir', type=util.existingDirectory, help='the source directory for the BWT to compress')\n    p9.add_argument('dstDir', type=util.newDirectory, help='the destination directory')\n    \n    p10 = sp.add_parser('convert', help='convert from a raw text input to RLE')\n    p10.add_argument('-i', metavar='inputTextFN', dest='inputTextFN', default=None, help='input text filename (default: stdin)')\n    p10.add_argument('dstDir', type=util.newDirectory, help='the destination directory')\n    \n    args = p.parse_args()\n    \n    if args.subparserID == 'cffq':\n        logger.info('Inputs:\\t'+str(args.inputFastqs))\n        logger.info('Uniform:\\t'+str(args.areUniform))\n        logger.info('Output:\\t'+args.outBwtDir)\n        logger.info('Output Compressed:\\t'+str(args.buildCompressed))\n        logger.info('Processes:\\t'+str(args.numProcesses))\n        if args.numProcesses > 1:\n            logger.warning('Using multi-processing with slow disk accesses can lead to slower build times.')\n        print\n        if args.areUniform:\n            #if they are uniform, use the method developed by Bauer et al., it's likely short Illumina seq\n            if args.buildCompressed:\n                MultiStringBWT.createMSBWTCompFromFastq(args.inputFastqs, args.outBwtDir, args.numProcesses, args.areUniform, logger)\n            else:\n                MultiStringBWT.createMSBWTFromFastq(args.inputFastqs, args.outBwtDir, args.numProcesses, args.areUniform, logger)\n        else:\n            #if they aren't uniform, use the merge method by Holt et al., it's likely longer PacBio seq\n            if args.buildCompressed:\n                logger.error('No compressed builder for non-uniform datasets, compress after creation.')\n            else:\n                Multimerge.createMSBWTFromFastq(args.inputFastqs, args.outBwtDir, args.numProcesses, args.areUniform, logger)\n        \n    elif args.subparserID == 'pp':\n        logger.info('Inputs:\\t'+str(args.inputFastqs))\n        logger.info('Uniform:\\t'+str(args.areUniform))\n        logger.info('Output:\\t'+args.outBwtDir)\n        if args.areUniform:\n            #preprocess for Bauer et al. method\n            MultiStringBWT.preprocessFastqs(args.inputFastqs, args.outBwtDir, args.areUniform, logger)\n        else:\n            #preprocess for Holt et al. method\n            numProcs = 1\n            Multimerge.preprocessFastqs(args.inputFastqs, args.outBwtDir, numProcs, args.areUniform, logger)\n        \n    elif args.subparserID == 'cfpp':\n        logger.info('BWT dir:\\t'+args.bwtDir)\n        logger.info('Uniform:\\t'+str(args.areUniform))\n        logger.info('Output Compressed:\\t'+str(args.buildCompressed))\n        logger.info('Processes:\\t'+str(args.numProcesses))\n        if args.numProcesses > 1:\n            logger.warning('Using multi-processing with slow disk accesses can lead to slower build times.')\n        print\n        seqFN = args.bwtDir+'/seqs.npy'\n        offsetFN = args.bwtDir+'/offsets.npy'\n        bwtFN = args.bwtDir+'/msbwt.npy'\n        \n        if args.areUniform:\n            #process it using the column-wise Bauer et al. method\n            if args.buildCompressed:\n                MSBWTCompGenCython.createMsbwtFromSeqs(args.bwtDir, args.numProcesses, logger)\n            else:\n                MSBWTGenCython.createMsbwtFromSeqs(args.bwtDir, args.numProcesses, logger)\n        else:\n            #process it using the Holt et al. merge method\n            if args.buildCompressed:\n                logger.error('No compressed builder for non-uniform datasets, compress after creation.')\n            else:\n                Multimerge.interleaveLevelMerge(args.bwtDir, args.numProcesses, args.areUniform, logger)\n        \n    elif args.subparserID == 'compress':\n        logger.info('Source Directory:'+args.srcDir)\n        logger.info('Dest Directory:'+args.dstDir)\n        logger.info('Processes:'+str(args.numProcesses))\n        if args.srcDir == args.dstDir:\n            raise Exception('Source and destination directories cannot be the same directory.')\n        print\n        MSBWTGen.compressBWT(args.srcDir+'/msbwt.npy', args.dstDir+'/comp_msbwt.npy', args.numProcesses, logger)\n        \n    elif args.subparserID == 'decompress':\n        logger.info('Source Directory: '+args.srcDir)\n        logger.info('Dest Directory: '+args.dstDir)\n        logger.info('Processes: '+str(args.numProcesses))\n        print\n        MSBWTGen.decompressBWT(args.srcDir, args.dstDir, args.numProcesses, logger)\n        #TODO: remove if srcdir and dstdir are the same?\n        \n    elif args.subparserID == 'merge':\n        logger.info('Inputs:\\t'+str(args.inputBwtDirs))\n        logger.info('Output:\\t'+args.outBwtDir)\n        logger.info('Processes:\\t'+str(args.numProcesses))\n        if args.numProcesses > 1:\n            logger.warning('Multi-processing is not supported at this time, but will be included in a future release.')\n            numProcs = 1\n            #logger.warning('Using multi-processing with slow disk accesses can lead to slower build times.')\n        print\n        #MSBWTGen.mergeNewMSBWT(args.outBwtDir, args.inputBwtDirs, args.numProcesses, logger)\n        if len(args.inputBwtDirs) > 2:\n            #this is a deprecated method, it may still work if you feel daring\n            #MSBWTGenCython.mergeMsbwts(args.inputBwtDirs, args.outBwtDir, 1, logger)\n            logger.error('Merging more than two MSBWTs at once is not currently supported.')\n        else:\n            GenericMerge.mergeTwoMSBWTs(args.inputBwtDirs[0], args.inputBwtDirs[1], args.outBwtDir, numProcs, logger)\n        \n    elif args.subparserID == 'query':\n        #this is the easiest thing we can do, don't dump the standard info, just do it\n        msbwt = MultiStringBWT.loadBWT(args.inputBwtDir, logger=logger)\n        \n        #always print how many are found, users can parse it out if they want\n        r = msbwt.findIndicesOfStr(args.kmer)\n        print r[1]-r[0]\n        \n        #dump the seqs if request\n        if args.dumpSeqs:\n            for x in xrange(r[0], r[1]):\n                dInd = msbwt.getSequenceDollarID(x)\n                print msbwt.recoverString(dInd)[1:]+','+str(dInd)\n    \n    elif args.subparserID == 'massquery':\n        logger.info('Input:\\t'+str(args.inputBwtDir))\n        logger.info('Queries:\\t'+str(args.kmerFile))\n        logger.info('Output:\\t'+args.outputFile)\n        logger.info('Rev-comp:\\t'+str(args.reverseComplement))\n        print\n        msbwt = MultiStringBWT.loadBWT(args.inputBwtDir, logger=logger)\n        \n        output = open(args.outputFile, 'w+')\n        output.write('k-mer,counts')\n        if args.reverseComplement:\n            output.write(',revCompCounts\\n')\n        else:\n            output.write('\\n')\n        \n        logger.info('Beginning queries...')\n        for line in open(args.kmerFile, 'r'):\n            kmer = line.strip('\\n')\n            c = msbwt.countOccurrencesOfSeq(kmer)\n            if args.reverseComplement:\n                rc = msbwt.countOccurrencesOfSeq(MultiStringBWT.reverseComplement(kmer))\n                output.write(kmer+','+str(c)+','+str(rc)+'\\n')\n            else:\n                output.write(kmer+','+str(c)+'\\n')\n        logger.info('Queries complete.')\n    \n    elif args.subparserID == 'convert':\n        if args.inputTextFN == None:\n            logger.info('Input: stdin')\n        else:\n            logger.info('Input: '+args.inputTextFN)\n        logger.info('Output: '+args.dstDir)\n        logger.info('Beginning conversion...')\n        CompressToRLE.compressInput(args.inputTextFN, args.dstDir)\n        logger.info('Finished conversion.')\n        \n    else:\n        print args.subparserID+\" is currently not implemented, please wait for a future release.\"", "response": "This is the primary function for external users to run when the Command Line Interface is used\n "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bwtPartialInsertPoolCall(tup):\n    '''\n    This is a function typically called by a multiprocess pool to do the partial insertions\n    @param tup - the tuple of inputs, see below for breakdown\n    '''\n    #load these values from the tuple\n    (procLabel, seqFNPrefix, offsetFN, finalOutFN, prevIterFN, columnStart, fmIndex, insertionFNs, cOffset, areUniform) = tup\n    \n    #mark the start time\n    sTime = time.time()\n    debug = False\n    \n    #TODO: param is hardcoded, bad?\n    vcLen = 6\n    \n    #load the sequences and the offsets\n    if areUniform:\n        #figure out the length of uniformity\n        offsets = np.load(offsetFN, 'r')\n        uniformLength = int(offsets[0])\n        \n        mmapSeqs = np.load(seqFNPrefix+'.'+str(columnStart % uniformLength)+'.npy')\n    else:\n        offsetData = np.load(offsetFN, 'r')\n        mmapSeqs = np.load(seqFNPrefix+'.npy', 'r')\n    fnToLoad = prevIterFN\n    \n    #if there's nothing to insert, we can just rename the file\n    if len(insertionFNs) == 0:\n        #TODO: is this screwing up our save points? note that we're renaming so we'd lose the old before guaranteed safe\n        #nothing to do in this iteration\n        oldFN = fnToLoad\n        newFN = finalOutFN+'.'+procLabel+'.'+str(columnStart)+'.npy'\n        os.rename(oldFN, newFN)\n        \n        #vcLen*vcLen matrix for fmDeltas\n        fmDeltas = [[0]*vcLen]*vcLen\n        nextInsertFNs = [None]*vcLen\n        \n        #return None as last to let it know not to update\n        return (fmDeltas, nextInsertFNs, None)\n        \n    debugDump('Running.', procLabel, sTime, debug)\n    \n    #load the previous iteration and mark the column we're in\n    column = columnStart\n    prevIter = np.load(fnToLoad, 'r')\n    \n    #reset everything\n    nextInserts = [None]*vcLen\n    insertionArrays = []\n    \n    #this is a normal task\n    #but first, clear the dump task\n    newInsertSize = 0\n    insertCounts = [0]*vcLen\n    debugDump('Loading inserts...', procLabel, sTime, debug)\n    for i, fn in enumerate(insertionFNs):\n        #fully load these into memory for fastest results\n        insertionArrays.append(np.load(fn))\n        newInsertSize += insertionArrays[i].shape[0]\n        insertCounts = np.add(insertCounts, np.bincount(insertionArrays[i]['f1'], minlength=vcLen))\n        try:\n            os.remove(fn)\n        except:\n            pass\n        \n    debugDump('Loaded inserts.', procLabel, sTime, debug)\n    \n    #create the file for the next iteration by pre-allocating for the new insertion size\n    nextIter = np.zeros(shape=(prevIter.shape[0]+newInsertSize,), dtype='<u1')\n    nextIter[:] = vcLen\n    \n    #mark the counts\n    fmDeltas = [None]*vcLen\n    nextInsertFNs = [None]*vcLen\n    \n    #insert everything that needs inserting\n    for arr in insertionArrays:\n        nextIter[arr['f0']-cOffset] = arr['f1'][:]\n    \n    #copy the other\n    if prevIter.shape[0] > 0:\n        nextIter[nextIter == vcLen] = prevIter[:]\n    \n    #save the next iteration\n    debugDump('Saving...', procLabel, sTime, debug)\n    np.save(finalOutFN+'.'+procLabel+'.'+str(column)+'.npy', nextIter)\n    debugDump('Finished saving.', procLabel, sTime, debug)\n    \n    #no longer need this\n    del prevIter\n    try:\n        os.remove(prevIterFN)\n    except:\n        pass\n        \n    for c in xrange(0, vcLen):\n        #create this array\n        nextInserts[c] = np.zeros(shape=(insertCounts[c],), dtype='<u8,<u1,<u4')\n        \n        #clear the fmDeltas\n        fmDeltas[c] = [0]*vcLen\n        \n    bc = np.array(fmIndex)\n    newInsertFilePos = [0]*vcLen\n    p = 0\n    for arr in insertionArrays:\n        nz = np.nonzero(arr['f1'])[0]\n        seqIds = arr['f2'][nz]\n        \n        if areUniform:\n            nextC = mmapSeqs[seqIds]\n        else:\n            indices = np.subtract(offsetData[seqIds+1], (column+1))\n            if seqIds.shape[0] > 0 and seqIds[0] == 0 and offsetData[1] < (column+1):\n                indices[0] = offsetData[1]-1\n            nextC = mmapSeqs[indices]\n        \n        pos = np.zeros(dtype='<u8', shape=(seqIds.shape[0], ))\n        \n        for i in xrange(0, seqIds.shape[0]):\n            e = arr['f0'][nz[i]]-cOffset\n            if p == e:\n                pass\n            else:\n                bc = np.add(bc, np.bincount(nextIter[p:e], minlength=vcLen))\n            pos[i] = bc[arr['f1'][nz[i]]]\n            p = e\n        \n        for c in xrange(1, vcLen):\n            counters = np.where(arr['f1'][nz] == c)[0]\n            nextInserts[c]['f0'][newInsertFilePos[c]:newInsertFilePos[c]+counters.shape[0]] = pos[counters]\n            nextInserts[c]['f1'][newInsertFilePos[c]:newInsertFilePos[c]+counters.shape[0]] = nextC[counters]\n            nextInserts[c]['f2'][newInsertFilePos[c]:newInsertFilePos[c]+counters.shape[0]] = seqIds[counters]\n            newInsertFilePos[c] += counters.shape[0]\n            \n            if counters.shape[0] == 0:\n                pass\n            else:\n                fmDeltas[c] = np.add(fmDeltas[c], np.bincount(nextC[counters], minlength=6))\n    \n    nextShape = nextIter.shape[0]\n    \n    nextInsertFNs = [None]*vcLen\n    for c in xrange(1, vcLen):\n        if insertCounts[c] > 0:\n            nextInsertFN = finalOutFN+'.'+str(c)+procLabel+'.'+str(column)+'.temp.npy'\n            nextInsertFNs[c] = nextInsertFN\n            np.save(nextInsertFN, nextInserts[c])\n            \n    #cleanup \n    del nz\n    del seqIds\n    if not areUniform:\n        del indices\n    del nextC\n    del counters\n    del pos\n    del nextIter\n    del insertionArrays\n    del nextInserts\n    gc.collect()\n    \n    debugDump('Finished.', procLabel, sTime, debug)\n    \n    return (fmDeltas, nextInsertFNs, nextShape)", "response": "This is a function typically called by a multiprocess pool to do the partial insertions\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iterateCreateFromSeqs(startingColumn, fmStarts, fmDeltas, allFirstCounts, allBwtCounts, cOffset, totalCounts, numValidChars,\n                          mergedFN, seqFNPrefix, offsetFN, insertFNs, numProcs, areUniform, depth, logger):\n    '''\n    This function is the actual series of iterations that a BWT creation will perform.  It's separate so we can build a function\n    for resuming construction if we fail for some reason.\n    TODO: build a recovery function to start midway through BWT construction.\n    TODO: @param values need explanation\n    '''\n    bwt = np.load(mergedFN, 'r+')\n    \n    column = startingColumn\n    newInserts = True\n    while newInserts:\n        st = time.time()\n        \n        #iterate through the sorted keys\n        keySort = sorted(fmStarts.keys())\n        for i, key in enumerate(keySort):\n            #all deltas get copied\n            for c2 in xrange(0, numValidChars):\n                #copy only to the ones after key\n                allFirstCounts[int(key[0])] += fmDeltas[key][c2]\n                allBwtCounts[c2] += fmDeltas[key][c2]\n                for key2 in keySort[i+1:]:\n                    fmStarts[key2][c2] += fmDeltas[key][c2]\n                    \n                    if key[0] == key2[0]:\n                        cOffset[key2] += fmDeltas[key][c2]\n                    \n                fmDeltas[key][c2] = 0\n        \n        #blank out the next insertions and make sure we set up the keys we already know about\n        nextInsertFNs = {}\n        for key in keySort:\n            nextInsertFNs[key] = []\n        \n        #default to having no new insertions\n        newInserts = False\n        \n        #generate tuples of data packets for processing\n        tups = []\n        for key in keySort:\n            prevIterFN = mergedFN+'.'+key+'.'+str(column-1)+'.npy'\n            cOff = cOffset[key]\n            tup = (key, seqFNPrefix, offsetFN, mergedFN, prevIterFN, column, copy.deepcopy(fmStarts[key]), insertFNs[key], cOff, areUniform)\n            tups.append(tup)\n        \n        if numProcs > 1:\n            #TODO: chunksize?\n            #create a pool of processes based on the input\n            myPool = multiprocessing.Pool(numProcs)\n            rets = myPool.imap(bwtPartialInsertPoolCall, tups, 1)\n        else:\n            rets = []\n            for tup in tups:\n                rets.append(bwtPartialInsertPoolCall(tup))\n        \n        for i, ret in enumerate(rets):\n            (retFmDelta, retInsertFNs, retShape) = ret\n            key = keySort[i]\n            \n            for c in xrange(1, numValidChars):\n                if retInsertFNs[c] == None:\n                    continue\n                \n                nextKey = (str(c)+key)[0:depth]\n                if not fmStarts.has_key(nextKey):\n                    fmDeltas[nextKey] = [0]*numValidChars\n                        \n                    keyInd = bisect.bisect(keySort, nextKey)\n                    if keyInd < len(keySort):\n                        fmStarts[nextKey] = copy.deepcopy(fmStarts[keySort[keyInd]])\n                    else:\n                        fmStarts[nextKey] = copy.deepcopy(allBwtCounts)\n                    \n                    if keyInd == len(keySort) or keySort[keyInd][0] != nextKey[0]:\n                        cOffset[nextKey] = allFirstCounts[int(nextKey[0])]\n                    else:\n                        cOffset[nextKey] = cOffset[keySort[keyInd]]\n                    \n                    np.lib.format.open_memmap(mergedFN+'.'+nextKey+'.'+str(column)+'.npy', 'w+', '<u8,<u1,<u4', (0,))\n                \n                for c2 in xrange(0, numValidChars):\n                    fmDeltas[nextKey][c2] += retFmDelta[c][c2]\n                \n                if not nextInsertFNs.has_key(nextKey):\n                    nextInsertFNs[nextKey] = []\n                \n                if retInsertFNs[c] != None:\n                    nextInsertFNs[nextKey].append(retInsertFNs[c])\n                    newInserts = True\n            \n            #None means we didn't change anything\n            if retShape != None:\n                totalCounts[key] = retShape\n        \n        if numProcs > 1:\n            myPool.terminate()\n            myPool.join()\n            myPool = None\n        \n        #at this point, we know everything is over, so we can clean up the previous step\n        for key in keySort:\n            prevIterFN = mergedFN+'.'+key+'.'+str(column-1)+'.npy'\n            try:\n                os.remove(prevIterFN)\n            except:\n                pass\n            for fn in insertFNs[key]:\n                try:\n                    os.remove(fn)\n                except:\n                    pass\n        \n        insertFNs = nextInsertFNs\n            \n        #copy inserts and move to the next column\n        column += 1\n        \n        et = time.time()\n        logger.info('Finished iteration '+str(column-2)+' in '+str(et-st)+' seconds...')\n            \n    \n    logger.info('Creating final output...')\n    \n    ei = 0\n    sortedKeys = sorted(totalCounts.keys())\n    for key in sortedKeys:\n        copyArr = np.load(mergedFN+'.'+key+'.'+str(column-1)+'.npy', 'r')\n        si = ei\n        ei += totalCounts[key]\n        bwt[si:ei] = copyArr[:]\n        \n    for key in sortedKeys:\n        os.remove(mergedFN+'.'+key+'.'+str(column-1)+'.npy')", "response": "This function is used to iterate through the sequence of files in the BWT and create a new BWT."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compressBWT(inputFN, outputFN, numProcs, logger):\n    '''\n    Current encoding scheme uses 3 LSB for the letter and 5 MSB for a count, note that consecutive ones of the same character\n    combine to create one large count.  So to represent 34A, you would have 00010|001 followed by 00001|001 which can be though of\n    as 2*1 + 32*1 = 34\n    @param inputFN - the filename of the BWT to compress\n    @param outputFN - the destination filename for the compressed BWT, .npy format\n    @param numProcs - number of processes to use during compressing\n    @param logger - logger from initLogger()\n    '''\n    #create bit spacings\n    letterBits = 3\n    numberBits = 8-letterBits\n    numPower = 2**numberBits\n    mask = 255 >> letterBits\n    \n    #load the thing to compress\n    logger.info('Loading src file...')\n    bwt = np.load(inputFN, 'r')\n    logger.info('Original size:'+str(bwt.shape[0])+'B')\n    numProcs = min(numProcs, bwt.shape[0])\n    \n    #first locate boundaries\n    tups = []\n    binSize = 1000000\n    numBins = max(numProcs, bwt.shape[0]/binSize)\n    \n    for i in xrange(0, numBins):\n        startIndex = i*bwt.shape[0]/numBins\n        endIndex = (i+1)*bwt.shape[0]/numBins\n        tempFN = outputFN+'.temp.'+str(i)+'.npy'\n        tups.append((inputFN, startIndex, endIndex, tempFN))\n    \n    logger.info('Compressing bwt...')\n    \n    #run our multi-processed builder\n    if numProcs > 1:\n        myPool = multiprocessing.Pool(numProcs)\n        rets = myPool.map(compressBWTPoolProcess, tups)\n    else:\n        rets = []\n        for tup in tups:\n            rets.append(compressBWTPoolProcess(tup))\n    \n    #calculate how big it will be after combining the separate chunk\n    totalSize = 0\n    prevChar = -1\n    prevTotal = 0\n    for ret in rets:\n        #start by just adding the raw size\n        totalSize += ret[0]\n        \n        #check if we need to compensate for a break point like AAA|A\n        if prevChar == ret[1]:\n            totalSize -= int(math.floor(math.log(prevTotal, numPower)+1)+math.floor(math.log(ret[2], numPower)+1))\n            prevTotal += ret[2]\n            totalSize += int(math.floor(math.log(prevTotal, numPower)+1))\n            if ret[0] == 1:\n                #don't clear prev total\n                pass\n            else:\n                prevTotal = ret[4]\n        else:\n            prevTotal = ret[4]\n        prevChar = ret[3]\n    \n    #make the real output by joining all of the partial compressions into a single file\n    finalBWT = np.lib.format.open_memmap(outputFN, 'w+', '<u1', (totalSize,))\n    logger.info('Calculated compressed size:'+str(totalSize)+'B')\n    logger.info('Joining sub-compressions...')\n    \n    #iterate a second time, this time storing things\n    prevChar = -1\n    prevTotal = 0\n    offset = 0\n    for ret in rets:\n        copyArr = np.load(ret[5], 'r')\n        if prevChar == ret[1]:\n            #calculate byte usage of combining\n            prevBytes = int(math.floor(math.log(prevTotal, numPower)+1))\n            nextBytes = int(math.floor(math.log(ret[2], numPower)+1))\n            prevTotal += ret[2]\n            \n            #actually combine them\n            offset -= prevBytes\n            power = 0\n            while prevTotal >= numPower**power:\n                finalBWT[offset] = (((prevTotal / (numPower**power)) & mask) << letterBits)+prevChar\n                power += 1\n                offset += 1\n            \n            #copy over the extra stuff and calculate the new offset\n            finalBWT[offset:offset+(copyArr.shape[0]-nextBytes)] = copyArr[nextBytes:]\n            offset += (copyArr.shape[0] - nextBytes)\n            \n            if ret[0] == 1:\n                pass\n            else:\n                prevTotal = ret[4]\n            \n        else:\n            #nothing shared, just copy the easy way\n            finalBWT[offset:offset+copyArr.shape[0]] = copyArr\n            offset += copyArr.shape[0]\n            prevTotal = ret[4]\n            \n        prevChar = ret[3]\n        \n    #clear all intermediate files\n    for ret in rets:\n        os.remove(ret[5])\n    \n    logger.info('Compression finished.')\n    \n    #return this i guess\n    return finalBWT", "response": "This function compresses a BWT file into a new file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compressBWTPoolProcess(tup):\n    '''\n    During compression, each available process will calculate a subportion of the BWT independently using this \n    function.  This process takes the chunk and rewrites it into a given filename using the technique described\n    in the compressBWT(...) function header\n    '''\n    #pull the tuple info\n    inputFN = tup[0]\n    startIndex = tup[1]\n    endIndex = tup[2]\n    tempFN = tup[3]\n    \n    #this shouldn't happen\n    if startIndex == endIndex:\n        print 'ERROR: EQUAL INDICES'\n        return None\n    \n    #load the file\n    bwt = np.load(inputFN, 'r')\n    \n    #create bit spacings\n    letterBits = 3\n    numberBits = 8-letterBits\n    numPower = 2**numberBits\n    mask = 255 >> letterBits\n    \n    #search for the places they're different\n    whereSol = np.add(startIndex+1, np.where(bwt[startIndex:endIndex-1] != bwt[startIndex+1:endIndex])[0])\n    \n    #this is the difference between two adjacent ones\n    deltas = np.zeros(dtype='<u4', shape=(whereSol.shape[0]+1,))\n    if whereSol.shape[0] == 0:\n        deltas[0] = endIndex-startIndex\n    else:\n        deltas[0] = whereSol[0]-startIndex\n        deltas[1:-1] = np.subtract(whereSol[1:], whereSol[0:-1])\n        deltas[-1] = endIndex - whereSol[-1]\n    \n    #calculate the number of bytes we need to store this information\n    size = 0\n    byteCount = 0\n    lastCount = 1\n    while lastCount > 0:\n        lastCount = np.where(deltas >= 2**(numberBits*byteCount))[0].shape[0]\n        size += lastCount\n        byteCount += 1\n    \n    #create the file\n    ret = np.lib.format.open_memmap(tempFN, 'w+', '<u1', (size,))\n    retIndex = 0\n    c = bwt[startIndex]\n    startChar = c\n    delta = deltas[0]\n    while delta > 0:\n        ret[retIndex] = ((delta & mask) << letterBits)+c\n        delta /= numPower\n        retIndex += 1\n    \n    #fill in the values based on the bit functions\n    for i in xrange(0, whereSol.shape[0]):\n        c = bwt[whereSol[i]]\n        delta = deltas[i+1]\n        while delta > 0:\n            ret[retIndex] = ((delta & mask) << letterBits)+c\n            delta /= numPower\n            retIndex += 1\n    endChar = c\n    \n    #return a lot of information so we can easily combine the results\n    return (size, startChar, deltas[0], endChar, deltas[-1], tempFN)", "response": "This function takes a tuple of input filename and returns a tuple of the size of the file and the size of the file that is used to store the subportion of the BWT independently using this \n    function."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if this embed is an ok one to count.", "response": "def ok_embedded_video(node):\n    \"\"\"Check if this embed/video is an ok one to count.\"\"\"\n    good_keywords = ('youtube', 'blip.tv', 'vimeo')\n\n    node_str = tounicode(node)\n    for key in good_keywords:\n        if key in node_str:\n            return True\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef build_base_document(dom, return_fragment=True):\n    body_element = dom.find(\".//body\")\n\n    if body_element is None:\n        fragment = fragment_fromstring('<div id=\"readabilityBody\"/>')\n        fragment.append(dom)\n    else:\n        body_element.tag = \"div\"\n        body_element.set(\"id\", \"readabilityBody\")\n        fragment = body_element\n\n    return document_from_fragment(fragment, return_fragment)", "response": "Builds a base document with the body as root."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if a node is a common block level element and adds siblings to the candidate list.", "response": "def check_siblings(candidate_node, candidate_list):\n    \"\"\"\n    Looks through siblings for content that might also be related.\n    Things like preambles, content split by ads that we removed, etc.\n    \"\"\"\n    candidate_css = candidate_node.node.get(\"class\")\n    potential_target = candidate_node.content_score * 0.2\n    sibling_target_score = potential_target if potential_target > 10 else 10\n    parent = candidate_node.node.getparent()\n    siblings = parent.getchildren() if parent is not None else []\n\n    for sibling in siblings:\n        append = False\n        content_bonus = 0\n\n        if sibling is candidate_node.node:\n            append = True\n\n        # Give a bonus if sibling nodes and top candidates have the example\n        # same class name\n        if candidate_css and sibling.get(\"class\") == candidate_css:\n            content_bonus += candidate_node.content_score * 0.2\n\n        if sibling in candidate_list:\n            adjusted_score = \\\n                candidate_list[sibling].content_score + content_bonus\n\n            if adjusted_score >= sibling_target_score:\n                append = True\n\n        if sibling.tag == \"p\":\n            link_density = get_link_density(sibling)\n            content = sibling.text_content()\n            content_length = len(content)\n\n            if content_length > 80 and link_density < 0.25:\n                append = True\n            elif content_length < 80 and link_density == 0:\n                if \". \" in content:\n                    append = True\n\n        if append:\n            logger.debug(\n                \"Sibling appended: %s %r\", sibling.tag, sibling.attrib)\n            if sibling.tag not in (\"div\", \"p\"):\n                # We have a node that isn't a common block level element, like\n                # a form or td tag. Turn it into a div so it doesn't get\n                # filtered out later by accident.\n                sibling.tag = \"div\"\n\n            if candidate_node.node != sibling:\n                candidate_node.node.append(sibling)\n\n    return candidate_node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean_document(node):\n    if node is None or len(node) == 0:\n        return None\n\n    logger.debug(\"\\n\\n-------------- CLEANING DOCUMENT -----------------\")\n    to_drop = []\n\n    for n in node.iter():\n        # clean out any in-line style properties\n        if \"style\" in n.attrib:\n            n.set(\"style\", \"\")\n\n        # remove embended objects unless it's wanted video\n        if n.tag in (\"object\", \"embed\") and not ok_embedded_video(n):\n            logger.debug(\"Dropping node %s %r\", n.tag, n.attrib)\n            to_drop.append(n)\n\n        # clean headings with bad css or high link density\n        if n.tag in (\"h1\", \"h2\", \"h3\", \"h4\") and get_class_weight(n) < 0:\n            logger.debug(\"Dropping <%s>, it's insignificant\", n.tag)\n            to_drop.append(n)\n\n        if n.tag in (\"h3\", \"h4\") and get_link_density(n) > 0.33:\n            logger.debug(\"Dropping <%s>, it's insignificant\", n.tag)\n            to_drop.append(n)\n\n        # drop block element without content and children\n        if n.tag in (\"div\", \"p\"):\n            text_content = shrink_text(n.text_content())\n            if len(text_content) < 5 and not n.getchildren():\n                logger.debug(\n                    \"Dropping %s %r without content.\", n.tag, n.attrib)\n                to_drop.append(n)\n\n        # finally try out the conditional cleaning of the target node\n        if clean_conditionally(n):\n            to_drop.append(n)\n\n    drop_nodes_with_parents(to_drop)\n\n    return node", "response": "Cleans up the final document we return as the readable article."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the clean_el if it looks like bad content based on rules.", "response": "def clean_conditionally(node):\n    \"\"\"Remove the clean_el if it looks like bad content based on rules.\"\"\"\n    if node.tag not in ('form', 'table', 'ul', 'div', 'p'):\n        return  # this is not the tag we are looking for\n\n    weight = get_class_weight(node)\n    # content_score = LOOK up the content score for this node we found\n    # before else default to 0\n    content_score = 0\n\n    if weight + content_score < 0:\n        logger.debug('Dropping conditional node')\n        logger.debug('Weight + score < 0')\n        return True\n\n    commas_count = node.text_content().count(',')\n    if commas_count < 10:\n        logger.debug(\n            \"There are %d commas so we're processing more.\", commas_count)\n\n        # If there are not very many commas, and the number of\n        # non-paragraph elements is more than paragraphs or other ominous\n        # signs, remove the element.\n        p = len(node.findall('.//p'))\n        img = len(node.findall('.//img'))\n        li = len(node.findall('.//li')) - 100\n        inputs = len(node.findall('.//input'))\n\n        embed = 0\n        embeds = node.findall('.//embed')\n        for e in embeds:\n            if ok_embedded_video(e):\n                embed += 1\n        link_density = get_link_density(node)\n        content_length = len(node.text_content())\n\n        remove_node = False\n\n        if li > p and node.tag != 'ul' and node.tag != 'ol':\n            logger.debug('Conditional drop: li > p and not ul/ol')\n            remove_node = True\n        elif inputs > p / 3.0:\n            logger.debug('Conditional drop: inputs > p/3.0')\n            remove_node = True\n        elif content_length < 25 and (img == 0 or img > 2):\n            logger.debug('Conditional drop: len < 25 and 0/>2 images')\n            remove_node = True\n        elif weight < 25 and link_density > 0.2:\n            logger.debug('Conditional drop: weight small (%f) and link is dense (%f)', weight, link_density)\n            remove_node = True\n        elif weight >= 25 and link_density > 0.5:\n            logger.debug('Conditional drop: weight big but link heavy')\n            remove_node = True\n        elif (embed == 1 and content_length < 75) or embed > 1:\n            logger.debug(\n                'Conditional drop: embed w/o much content or many embed')\n            remove_node = True\n\n        if remove_node:\n            logger.debug('Node will be removed: %s %r %s', node.tag, node.attrib, node.text_content()[:30])\n\n        return remove_node\n\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds cadidate nodes for the readable version of the article.", "response": "def find_candidates(document):\n    \"\"\"\n    Finds cadidate nodes for the readable version of the article.\n\n    Here's we're going to remove unlikely nodes, find scores on the rest,\n    clean up and return the final best match.\n    \"\"\"\n    nodes_to_score = set()\n    should_remove = set()\n\n    for node in document.iter():\n        if is_unlikely_node(node):\n            logger.debug(\n                \"We should drop unlikely: %s %r\", node.tag, node.attrib)\n            should_remove.add(node)\n        elif is_bad_link(node):\n            logger.debug(\n                \"We should drop bad link: %s %r\", node.tag, node.attrib)\n            should_remove.add(node)\n        elif node.tag in SCORABLE_TAGS:\n            nodes_to_score.add(node)\n\n    return score_candidates(nodes_to_score), should_remove"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_bad_link(node):\n    if node.tag != \"a\":\n        return False\n\n    name = node.get(\"name\")\n    href = node.get(\"href\")\n    if name and not href:\n        return True\n\n    if href:\n        href_parts = href.split(\"#\")\n        if len(href_parts) == 2 and len(href_parts[1]) > 25:\n            return True\n\n    return False", "response": "Helper to determine if the node is a bad link."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef leaf_div_elements_into_paragraphs(document):\n    for element in document.iter(tag=\"div\"):\n        child_tags = tuple(n.tag for n in element.getchildren())\n        if \"div\" not in child_tags and \"p\" not in child_tags:\n            logger.debug(\n                \"Changing leaf block element <%s> into <p>\", element.tag)\n            element.tag = \"p\"\n\n    return document", "response": "Turn some block elements that don t have children block level\n    elements into paragraphs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the lxml tree of the given html and returns the dom element.", "response": "def dom(self):\n        \"\"\"Parsed lxml tree (Document Object Model) of the given html.\"\"\"\n        try:\n            dom = self._original_document.dom\n            # cleaning doesn't return, just wipes in place\n            html_cleaner(dom)\n            return leaf_div_elements_into_paragraphs(dom)\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates list of candidates from the DOM.", "response": "def candidates(self):\n        \"\"\"Generates list of candidates from the DOM.\"\"\"\n        dom = self.dom\n        if dom is None or len(dom) == 0:\n            return None\n\n        candidates, unlikely_candidates = find_candidates(dom)\n        drop_nodes_with_parents(unlikely_candidates)\n\n        return candidates"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _readable(self):\n        if not self.candidates:\n            logger.info(\"No candidates found in document.\")\n            return self._handle_no_candidates()\n\n        # right now we return the highest scoring candidate content\n        best_candidates = sorted(\n            (c for c in self.candidates.values()),\n            key=attrgetter(\"content_score\"), reverse=True)\n\n        printer = PrettyPrinter(indent=2)\n        logger.debug(printer.pformat(best_candidates))\n\n        # since we have several candidates, check the winner's siblings\n        # for extra content\n        winner = best_candidates[0]\n        updated_winner = check_siblings(winner, self.candidates)\n        updated_winner.node = prep_article(updated_winner.node)\n        if updated_winner.node is not None:\n            dom = build_base_document(\n                updated_winner.node, self._return_fragment)\n        else:\n            logger.info(\n                'Had candidates but failed to find a cleaned winning DOM.')\n            dom = self._handle_no_candidates()\n\n        return self._remove_orphans(dom.get_element_by_id(\"readabilityBody\"))", "response": "The readable parsed article."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_no_candidates(self):\n        # since we've not found a good candidate we're should help this\n        if self.dom is not None and len(self.dom):\n            dom = prep_article(self.dom)\n            dom = build_base_document(dom, self._return_fragment)\n            return self._remove_orphans(\n                dom.get_element_by_id(\"readabilityBody\"))\n        else:\n            logger.info(\"No document to use.\")\n            return build_error_document(self._return_fragment)", "response": "If we fail to find a good candidate we need to find something else."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert DOM into paragraphs.", "response": "def parse(cls, dom):\n        \"\"\"Converts DOM into paragraphs.\"\"\"\n        handler = cls()\n        saxify(dom, handler)\n        return handler.content"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef createMSBWTFromSeqs(seqArray, mergedDir, numProcs, areUniform, logger):\n    '''\n    This function takes a series of sequences and creates the BWT using the technique from Cox and Bauer\n    @param seqArray - a list of '$'-terminated sequences to be in the MSBWT\n    @param mergedFN - the final destination filename for the BWT\n    @param numProcs - the number of processes it's allowed to use\n    '''\n    #wipe the auxiliary data stored here\n    MSBWTGen.clearAuxiliaryData(mergedDir)\n    \n    #TODO: do we want a special case for N=1? there was one in early code, but we could just assume users aren't dumb\n    seqFN = mergedDir+'/seqs.npy'\n    offsetFN = mergedDir+'/offsets.npy'\n    \n    #sort the sequences\n    seqCopy = sorted(seqArray)\n    if areUniform:\n        uniformLength = len(seqArray[0])\n    else:\n        uniformLength = 0\n        \n    #join into one massive string\n    seqCopy = ''.join(seqCopy)\n    \n    #convert the sequences into uint8s and then save it\n    seqCopy = np.fromstring(seqCopy, dtype='<u1')\n    \n    MSBWTGen.writeSeqsToFiles(seqCopy, seqFN, offsetFN, uniformLength)\n    MSBWTGen.createFromSeqs(seqFN, offsetFN, mergedDir+'/msbwt.npy', numProcs, areUniform, logger)", "response": "This function takes a series of sequences and creates the MSBWT from it."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createMSBWTFromFastq(fastqFNs, outputDir, numProcs, areUniform, logger):\n    '''\n    This function takes fasta filenames and creates the BWT using the technique from Cox and Bauer by simply loading\n    all string prior to computation\n    @param fastqFNs - a list of fastq filenames to extract sequences from\n    @param outputDir - the directory for all of the bwt related data\n    @param numProcs - the number of processes it's allowed to use\n    @areUniform - true if all the sequences passed into the function are of equal length\n    '''\n    #generate the files we will reference and clear out the in memory array before making the BWT\n    logger.info('Saving sorted sequences...')\n    seqFN = outputDir+'/seqs.npy'\n    offsetFN = outputDir+'/offsets.npy'\n    abtFN = outputDir+'/about.npy'\n    bwtFN = outputDir+'/msbwt.npy'\n    \n    MSBWTGen.clearAuxiliaryData(outputDir)\n    preprocessFastqs(fastqFNs, seqFN, offsetFN, abtFN, areUniform, logger)\n    MSBWTGen.createFromSeqs(seqFN, offsetFN, bwtFN, numProcs, areUniform, logger)", "response": "This function takes a list of fastq filenames and creates a BWT from it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createMSBWTFromBam(bamFNs, outputDir, numProcs, areUniform, logger):\n    '''\n    This function takes a fasta filename and creates the BWT using the technique from Cox and Bauer\n    @param bamFNs - a list of BAM filenames to extract sequences from, READS MUST BE SORTED BY NAME\n    @param outputDir - the directory for all of the bwt related data\n    @param numProcs - the number of processes it's allowed to use\n    @areUniform - true if all the sequences passed into the function are of equal length\n    '''\n    #generate the files we will reference and clear out the in memory array before making the BWT\n    logger.info('Saving sorted sequences...')\n    seqFN = outputDir+'/seqs.npy'\n    offsetFN = outputDir+'/offsets.npy'\n    abtFN = outputDir+'/about.npy'\n    bwtFN = outputDir+'/msbwt.npy'\n    \n    MSBWTGen.clearAuxiliaryData(outputDir)\n    preprocessBams(bamFNs, seqFN, offsetFN, abtFN, areUniform, logger)\n    MSBWTGen.createFromSeqs(seqFN, offsetFN, bwtFN, numProcs, areUniform, logger)", "response": "This function takes a fasta filename and creates the BWT using the technique from Cox and Bauer\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef preprocessFastqs(fastqFNs, seqFNPrefix, offsetFN, abtFN, areUniform, logger):\n    '''\n    This function does the grunt work behind string extraction for fastq files\n    @param fastqFNs - a list of .fq filenames for parsing\n    @param seqFNPrefix - this is always of the form '<DIR>/seqs.npy'\n    @param offsetFN - this is always of the form '<DIR>/offsets.npy'\n    @param abtFN - this is always of the form '<DIR>/about.npy'\n    @param areUniform - True if all sequences are of uniform length\n    @param logger - logger object for output \n    '''\n    #create a seqArray\n    seqArray = []\n    \n    tempFileId = 0\n    seqsPerFile = 1000000\n    maxSeqLen = -1\n    numSeqs = 0\n    \n    subSortFNs = []\n    \n    for fnID, fn in enumerate(fastqFNs):\n        #open the file and read in starting form the second, every 4th line\n        logger.info('Loading \\''+fn+'\\'...')\n        if fn.endswith('.gz'):\n            fp = gzip.open(fn, 'r')\n        else:\n            fp = open(fn, 'r')\n        i = -1\n        \n        #go through each line\n        for line in fp:\n            if i % 4 == 0:\n                seqArray.append((line.strip('\\n')+'$', fnID, i/4))\n                if len(seqArray) == seqsPerFile:\n                    if not areUniform or maxSeqLen == -1:\n                        maxSeqLen = 0\n                        for seq, fID, seqID in seqArray:\n                            if len(seq) > maxSeqLen:\n                                maxSeqLen = len(seq)\n                    \n                    tempFN = seqFNPrefix+'.sortTemp.'+str(tempFileId)+'.npy'\n                    subSortFNs.append(tempFN)\n                    \n                    tempArray = np.lib.format.open_memmap(tempFN, 'w+', 'a'+str(maxSeqLen)+',<u1,<u8', (len(seqArray),))\n                    tempArray[:] = sorted(seqArray)\n                    numSeqs += len(seqArray)\n                    del tempArray\n                    tempFileId += 1\n                    seqArray = []\n            i += 1\n                \n        fp.close()\n    \n    if len(seqArray) > 0:\n        if not areUniform or maxSeqLen == -1:\n            maxSeqLen = 0\n            for seq, fID, seqID in seqArray:\n                if len(seq) > maxSeqLen:\n                    maxSeqLen = len(seq)\n        \n        tempFN = seqFNPrefix+'.sortTemp.'+str(tempFileId)+'.npy'\n        subSortFNs.append(tempFN)\n        \n        tempArray = np.lib.format.open_memmap(tempFN, 'w+', 'a'+str(maxSeqLen)+',<u1,<u8', (len(seqArray),))\n        tempArray[:] = sorted(seqArray)\n        numSeqs += len(seqArray)\n        del tempArray\n        tempFileId += 1\n        seqArray = []\n    \n    logger.info('Pre-sorting '+str(numSeqs)+' sequences...')\n    iters = []\n    for fn in subSortFNs:\n        iters.append(customiter(np.load(fn, 'r')))\n    \n    #save it\n    tempFN = seqFNPrefix+'.temp.npy'\n    fp = open(tempFN, 'w+')\n    \n    aboutFile = np.lib.format.open_memmap(abtFN, 'w+', '<u1,<u8', (numSeqs,))\n    ind = 0\n    \n    for tup in heapq.merge(*iters):\n        (seq, fID, seqID) = tup\n        aboutFile[ind] = (fID, seqID)\n        fp.write(seq)\n        ind += 1\n        \n    fp.close()\n    \n    #clean up disk space\n    for fn in subSortFNs:\n        os.remove(fn)\n    \n    #convert the sequences into uint8s and then save it\n    del seqArray\n    seqArray = np.memmap(tempFN)\n    \n    if areUniform:\n        uniformLength = maxSeqLen\n    else:\n        uniformLength = 0\n    \n    logger.info('Saving sorted sequences for BWT construction...')\n    MSBWTGen.writeSeqsToFiles(seqArray, seqFNPrefix, offsetFN, uniformLength)\n    \n    #wipe this\n    del seqArray\n    os.remove(tempFN)", "response": "This function does the grunt work behind string extraction for fastq files\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mergeNewSeqs(seqArray, mergedDir, numProcs, areUniform, logger):\n    '''\n    This function takes a series of sequences and creates a big BWT by merging the smaller ones \n    Mostly a test function, no real purpose to the tool as of now\n    @param seqArray - a list of '$'-terminated strings to be placed into the array\n    @param mergedFN - the final destination filename for the merged BWT\n    @param numProcs - the number of processors the merge is allowed to create\n    '''\n    #first wipe away any traces of old information for the case of overwriting a BWT at mergedFN\n    MSBWTGen.clearAuxiliaryData(mergedDir)\n    \n    #create two smaller ones\n    midPoint = len(seqArray)/3\n    mergedDir1 = mergedDir+'0'\n    mergedDir2 = mergedDir+'1'\n    mergedDir3 = mergedDir+'2'\n    \n    try:\n        shutil.rmtree(mergedDir1)\n    except:\n        pass\n    try:\n        shutil.rmtree(mergedDir2)\n    except:\n        pass\n    try:\n        shutil.rmtree(mergedDir3)\n    except:\n        pass\n    os.makedirs(mergedDir1)\n    os.makedirs(mergedDir2)\n    os.makedirs(mergedDir3)\n    \n    createMSBWTFromSeqs(seqArray[0:midPoint], mergedDir1, numProcs, areUniform, logger)\n    createMSBWTFromSeqs(seqArray[midPoint:2*midPoint], mergedDir2, numProcs, areUniform, logger)\n    createMSBWTFromSeqs(seqArray[2*midPoint:], mergedDir3, numProcs, areUniform, logger)\n    \n    #now do the actual merging\n    MSBWTGen.mergeNewMSBWT(mergedDir, [mergedDir1, mergedDir2, mergedDir3], numProcs, logger)", "response": "This function takes a series of sequences and creates a big BWT by merging them into one smaller ones. This function takes a series of sequences and creates a big BWT at mergedDir and then creates a new one at mergedDir."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef compareKmerProfiles(profileFN1, profileFN2):\n    '''\n    This function takes two kmer profiles and compare them for similarity.\n    @param profileFN1 - the first kmer-profile to compare to\n    @param profileFN2 - the second kmer-profile to compare to\n    @return - a tuple of the form (1-norm, 2-norm, sum of differences, normalized Dot product)\n    '''\n    fp1 = open(profileFN1, 'r')\n    fp2 = open(profileFN2, 'r')\n    \n    oneNorm = 0\n    twoNorm = 0\n    sumDeltas = 0\n    dotProduct = 0\n    \n    tot1 = float(fp1.readline().strip('\\n').split(',')[1])\n    tot2 = float(fp2.readline().strip('\\n').split(',')[1])\n    \n    (seq1, count1) = parseProfileLine(fp1)\n    (seq2, count2) = parseProfileLine(fp2)\n    \n    while seq1 != None or seq2 != None:\n        if seq1 == seq2:\n            delta = abs(count1/tot1-count2/tot2)\n            dotProduct += (count1/tot1)*(count2/tot2)\n            (seq1, count1) = parseProfileLine(fp1)\n            (seq2, count2) = parseProfileLine(fp2)\n        elif seq2 == None or (seq1 != None and seq1 < seq2):\n            delta = count1/tot1\n            (seq1, count1) = parseProfileLine(fp1)\n        else:\n            delta = count2/tot2\n            (seq2, count2) = parseProfileLine(fp2)\n        \n        if delta > oneNorm:\n            oneNorm = delta\n        \n        twoNorm += delta*delta\n        sumDeltas += delta\n    \n    fp1.close()\n    fp2.close()\n    \n    twoNorm = math.sqrt(twoNorm)\n    #print '1-norm:\\t\\t'+str(oneNorm)\n    #print '2-norm:\\t\\t'+str(twoNorm)\n    #print 'Delta sum:\\t'+str(sumDeltas)\n    return (oneNorm, twoNorm, sumDeltas, dotProduct)", "response": "This function takes two kmer profiles and compares them for similarity."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parseProfileLine(fp):\n    '''\n    Helper function for profile parsing\n    @param fp - the file pointer to get the next line from\n    @return - (kmer, kmerCount) as (string, int)\n    '''\n    nextLine = fp.readline()\n    if nextLine == None or nextLine == '':\n        return (None, None)\n    else:\n        pieces = nextLine.strip('\\n').split(',')\n        return (pieces[0], int(pieces[1]))", "response": "Helper function for profile parsing\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interactiveTranscriptConstruction(bwtDir, seedKmer, endSeeds, threshold, numNodes, direction, logger):\n    '''\n    This function is intended to be an interactive technique for constructing transcripts, probably to be released\n    in a future version of msbwt\n    @param bwtFN - the filename of the BWT to load\n    @param seedKmer - the seed sequence to use for construction\n    @param threshold - minimum number for a path to be considered a path\n    @param direction - True is forward, False is backward\n    @param logger - the logger\n    @param \n    '''\n    kmerLen = len(seedKmer)\n    validChars = ['$', 'A', 'C', 'G', 'N', 'T']\n    \n    pileups = []\n    \n    logger.info('Loading '+bwtDir+'...')\n    msbwt = loadBWT(bwtDir)\n    if os.path.exists(bwtDir+'/origins.npy'):\n        raise Exception(\"You haven\\'t reimplemented the handling of origin files\")\n        origins = np.load(bwtDir+'/origins.npy', 'r')\n    else:\n        origins = None\n    \n    logger.info('Beginning with seed \\''+seedKmer+'\\', len='+str(kmerLen))\n    \n    kmer = seedKmer\n    pos = kmerLen\n    ret = ''+kmer\n    \n    #these variable are for counting the average pileup\n    totalPileup = 0\n    numCovered = 0\n    \n    discoveredBlocks = []\n    discoveredEdges = []\n    pathTups = []\n    parentID = -1\n    blockID = 0\n    \n    #TODO: make it an input\n    #we're stating that 5 reads indicates a path here\n    pathThreshold = threshold\n    \n    foundKmers = {}\n    movingAverage = 0\n    \n    for es in endSeeds:\n        foundKmers[es] = 'END_SEED'\n    \n    terminate = False\n    while not terminate and len(discoveredBlocks) < numNodes:\n        \n        if len(kmer) != kmerLen:\n            print 'ERROR: DIFFERENT SIZED K-MER '+str(len(kmer))\n            raise Exception('ERROR')\n        \n        #First, perform all the counts of paths going both forwards and backwards\n        counts = {}\n        revCounts = {}\n        \n        maxV = 0\n        maxC = ''\n        total = 0\n        \n        numPaths = 0\n        numRevPaths = 0\n        \n        for c in validChars:\n            #forward counts\n            fr1 = msbwt.findIndicesOfStr(kmer+c)\n            fr2 = msbwt.findIndicesOfStr(reverseComplement(kmer+c))\n            \n            #backward counts\n            br1 = msbwt.findIndicesOfStr(c+kmer)\n            br2 = msbwt.findIndicesOfStr(reverseComplement(c+kmer))\n            \n            counts[c] = (fr1[1]-fr1[0])+(fr2[1]-fr2[0])\n            revCounts[c] = (br1[1]-br1[0])+(br2[1]-br2[0])\n            \n            if c != '$':\n                total += counts[c]\n                if counts[c] > maxV:\n                    maxV = counts[c]\n                    maxC = c\n                \n                if counts[c] > pathThreshold:\n                    numPaths += 1\n                    \n                if revCounts[c] > pathThreshold:\n                    numRevPaths += 1\n            \n            if origins != None:\n                pass\n        \n        totalPileup += total\n        numCovered += 1\n        \n        if numRevPaths > 1:\n            discoveredBlocks.append((parentID, ret, pileups, 'MERGE_'+str(blockID+1)))\n            discoveredEdges.append((blockID, blockID+1, revCounts))\n            \n            print 'INCOMING MERGE FOUND: '+str(discoveredBlocks[blockID])\n            parentID = blockID\n            blockID += 1\n            \n            ret = ''+kmer\n            pileups = []\n            \n        if total == 0:\n            print 'No strings found.'\n            discoveredBlocks.append((parentID, ret, pileups, 'TERMINAL'))\n            \n            pileups = []\n            \n            print pathTups\n            print discoveredBlocks\n            \n            if len(pathTups) == 0:\n                terminate = True\n            else:\n                nextPathTup = pathTups.pop(0)\n                print 'Handling1: '+str(nextPathTup)\n                parentID = nextPathTup[1]\n                direction = nextPathTup[2]\n                kmer = nextPathTup[3]\n                ret = ''+kmer\n                    \n                discoveredEdges.append((parentID, blockID+1, nextPathTup[0]))\n            \n            blockID += 1\n            continue\n        \n        \n        #now we identify this kmer as being part of the block\n        foundKmers[kmer] = blockID\n        r1 = msbwt.findIndicesOfStr(kmer)\n        r2 = msbwt.findIndicesOfStr(reverseComplement(kmer))\n        kmerCount = (r1[1]-r1[0])+(r2[1]-r2[0])\n        pileups.append(kmerCount)\n        \n        if total == 0:\n            perc = 0\n        else:\n            perc = float(maxV)/total\n            \n        if numPaths > 1:\n            #TODO: reverse ret if direction is reversed\n            discoveredBlocks.append((parentID, ret, pileups, 'SPLIT'))\n            \n            for c in validChars[1:]:\n                if counts[c] > pathThreshold:\n                    #counts, parent block, direction, starting seed\n                    if direction:\n                        pathSeed = kmer[1:]+c\n                    else:\n                        pathSeed = c+kmer[0:-1]\n                    \n                    pathTup = (counts[c], blockID, direction, pathSeed)\n                    pathTups.append(pathTup)\n            \n            print pathTups\n            print discoveredBlocks\n            \n            if len(pathTups) == 0:\n                terminate = True\n            else:\n                nextPathTup = pathTups.pop(0)\n                print 'Handling2: '+str(nextPathTup)\n                parentID = nextPathTup[1]\n                direction = nextPathTup[2]\n                kmer = nextPathTup[3]\n                \n                ret = ''+kmer    \n                pileups = []\n                                \n                discoveredEdges.append((parentID, blockID+1, nextPathTup[0]))\n            \n            blockID += 1\n            \n        else:\n            if direction:\n                kmer = kmer[1:]+maxC\n                ret += maxC\n            else:\n                kmer = maxC+kmer[0:-1]\n                ret = maxC+ret\n            pos += 1\n            \n            movingAverage = .9*movingAverage+.1*maxV\n            print str(pos)+':\\t'+kmer+'\\t'+str(perc)+'\\t'+str(maxV)+'/'+str(total)+'\\t'+str(total-maxV)+'\\t'+str(movingAverage)\n            \n        while foundKmers.has_key(kmer) and not terminate:\n            #TODO: reverse ret if direction is reversed\n            discoveredBlocks.append((parentID, ret, pileups, 'MERGE_'+str(foundKmers[kmer])))\n            discoveredEdges.append((blockID, foundKmers[kmer], ''))\n            \n            print pathTups\n            print discoveredBlocks\n            \n            if len(pathTups) == 0:\n                terminate = True\n            else:\n                nextPathTup = pathTups.pop(0)\n                print 'Handling3: '+str(nextPathTup)\n                #pileups.append(nextPathTup[0])\n                parentID = nextPathTup[1]\n                direction = nextPathTup[2]\n                kmer = nextPathTup[3]\n                \n                ret = ''+kmer\n                pileups = []\n                    \n                discoveredEdges.append((parentID, blockID+1, nextPathTup[0]))\n            blockID += 1\n    \n    return (discoveredBlocks, discoveredEdges)", "response": "This function is intended to be used by interactiveTranscriptConstruction in a future version of msbwt."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef reverseComplement(seq):\n    '''\n    Helper function for generating reverse-complements\n    '''\n    revComp = ''\n    complement = {'A':'T', 'C':'G', 'G':'C', 'T':'A', 'N':'N', '$':'$'}\n    for c in reversed(seq):\n        revComp += complement[c]\n    return revComp", "response": "Helper function for generating reverse - complements\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef countOccurrencesOfSeq(self, seq, givenRange=None):\n        '''\n        This function counts the number of occurrences of the given sequence\n        @param seq - the sequence to search for\n        @param givenRange - the range to start from (if a partial search has already been run), default=whole range\n        @return - an integer count of the number of times seq occurred in this BWT\n        '''\n        #init the current range\n        if givenRange == None:\n            if not self.searchCache.has_key(seq[-self.cacheDepth:]):\n                res = self.findIndicesOfStr(seq[-self.cacheDepth:])\n                self.searchCache[seq[-self.cacheDepth:]] = (int(res[0]), int(res[1]))\n            \n            l, h = self.searchCache[seq[-self.cacheDepth:]]\n            seq = seq[0:-self.cacheDepth]\n            \n        else:\n            l = givenRange[0]\n            h = givenRange[1]\n            \n        #reverse sequence and convert to ints so we can iterate through it\n        revSeq = [self.charToNum[c] for c in reversed(seq)]\n        \n        for c in revSeq:\n            #get the start and end offsets\n            l = self.getOccurrenceOfCharAtIndex(c, l)\n            h = self.getOccurrenceOfCharAtIndex(c, h)\n            \n            #early exit for counts\n            if l == h:\n                return 0\n        \n        #return the difference\n        return h - l", "response": "This function counts the number of occurrences of the given sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef constructFMIndex(self, logger):\n        '''\n        This function iterates through the BWT and counts the letters as it goes to create the FM index.  For example, the string 'ACC$' would have BWT\n        'C$CA'.  The FM index would iterate over this and count the occurence of the letter it found so you'd end up with this:\n        BWT    FM-index\n        C    0    0    0\n        $    0    0    1\n        C    1    0    1\n        A    1    0    2\n             1    1    2\n        This is necessary for finding the occurrence of a letter using the getOccurrenceOfCharAtIndex(...) function.\n        In reality, this function creates a sampled FM-index so only one index every 2048 bases is filled in.\n        This file is always stored in '<DIR>/fmIndex.npy'\n        '''\n        #sampling method\n        self.searchCache = {}\n        self.bitPower = 11\n        self.binSize = 2**self.bitPower\n        self.fmIndexFN = self.dirName+'/fmIndex.npy'\n        \n        if os.path.exists(self.fmIndexFN):\n            self.partialFM = np.load(self.fmIndexFN, 'r')\n        else:\n            if logger != None:\n                logger.info('First time calculation of \\'%s\\'' % self.fmIndexFN)\n            \n            #pre-allocate space\n            self.partialFM = np.lib.format.open_memmap(self.fmIndexFN, 'w+', '<u8', (self.bwt.shape[0]/self.binSize+1, self.vcLen))\n            \n            #now perform each count and store it to disk\n            counts = np.zeros(dtype='<u8', shape=(self.vcLen,))\n            counts[:] = self.startIndex\n            self.partialFM[0] = self.startIndex\n            for j in xrange(1, self.partialFM.shape[0]):\n                counts += np.bincount(self.bwt[self.binSize*(j-1):self.binSize*j], minlength=self.vcLen)\n                self.partialFM[j] = counts", "response": "This function creates a FM index for the given set of letters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getOccurrenceOfCharAtIndex(self, sym, index):\n        '''\n        This functions gets the FM-index value of a character at the specified position\n        @param sym - the character to find the occurrence level\n        @param index - the index we want to find the occurrence level at\n        @return - the number of occurrences of char before the specified index\n        '''\n        #sampling method\n        #get the bin we occupy\n        binID = index >> self.bitPower\n        \n        #these two methods seem to have the same approximate run time\n        if (binID << self.bitPower) == index:\n            ret = self.partialFM[binID][sym]\n        else:\n            ret = self.partialFM[binID][sym] + np.bincount(self.bwt[binID << self.bitPower:index], minlength=6)[sym]\n        return int(ret)", "response": "This functions gets the FM - index value of a character at the specified index"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getFullFMAtIndex(self, index):\n        '''\n        This function creates a complete FM-index for a specific position in the BWT.  Example using the above example:\n        BWT    Full FM-index\n                 $ A C G T\n        C        0 1 2 4 4\n        $        0 1 3 4 4\n        C        1 1 3 4 4\n        A        1 1 4 4 4\n                 1 2 4 4 4\n        @return - the above information in the form of an array that already incorporates the offset value into the counts\n        '''\n        #get the bin we occupy\n        binID = index >> self.bitPower\n        if binID << self.bitPower == index:\n            ret = self.partialFM[binID]\n        else:\n            ret = self.partialFM[binID] + np.bincount(self.bwt[binID << self.bitPower:index], minlength=6)\n        return ret", "response": "This function creates a complete FM - index for a specific position in the BWT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef loadMsbwt(self, dirName, logger):\n        '''\n        This functions loads a BWT file and constructs total counts, indexes start positions, and constructs an FM index in memory\n        @param dirName - the directory to load, inside should be '<DIR>/comp_msbwt.npy' or it will fail\n        '''\n        #open the file with our BWT in it\n        self.dirName = dirName\n        self.bwt = np.load(self.dirName+'/comp_msbwt.npy', 'r')\n        \n        #build auxiliary structures\n        self.constructTotalCounts(logger)\n        self.constructIndexing()\n        self.constructFMIndex(logger)", "response": "This function loads a BWT file and creates auxiliary structures with the same attributes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef constructFMIndex(self, logger):\n        '''\n        This function iterates through the BWT and counts the letters as it goes to create the FM index.  For example, the string 'ACC$' would have BWT\n        'C$CA'.  The FM index would iterate over this and count the occurence of the letter it found so you'd end up with this:\n        BWT    FM-index\n        C    0    0    0\n        $    0    0    1\n        C    1    0    1\n        A    1    0    2\n             1    1    2\n        This is necessary for finding the occurrence of a letter using the getOccurrenceOfCharAtIndex(...) function.\n        In reality, this function creates a sampled FM-index more complicated than the uncompressed counter-part.  This is \n        because the 2048 size bins don't fall evenly all the time.  A second data structure is used to tell you where to start\n        a particular FM-index count.  The two files necessary are '<DIR>/comp_fmIndex.npy' and '<DIR>/comp_refIndex.npy'\n        '''\n        #sampling method\n        self.searchCache = {}\n        self.bitPower = 11\n        self.binSize = 2**self.bitPower\n        \n        self.fmIndexFN = self.dirName+'/comp_fmIndex.npy'\n        self.fmRefFN = self.dirName+'/comp_refIndex.npy'\n        \n        if os.path.exists(self.fmIndexFN) and os.path.exists(self.fmRefFN):\n            #both exist, just memmap them\n            self.partialFM = np.load(self.fmIndexFN, 'r')\n            self.refFM = np.load(self.fmRefFN, 'r')\n        else:\n            if logger != None:\n                logger.info('First time calculation of \\'%s\\'' % self.fmIndexFN)\n            \n            #pre-allocate space\n            samplingSize = int(math.ceil(float(self.totalSize)/self.binSize))\n            self.partialFM = np.lib.format.open_memmap(self.fmIndexFN, 'w+', '<u8', (samplingSize, self.vcLen))\n            self.refFM = np.lib.format.open_memmap(self.fmRefFN, 'w+', '<u8', (samplingSize,))\n            \n            countsSoFar = np.cumsum(self.totalCounts)-self.totalCounts\n            totalCounts = 0\n            \n            prevStart = 0\n            bwtIndex = 0\n            chunkSize = 10000\n            \n            samplingID = 0\n            \n            #iterate through the whole file creating dynamically sized bins\n            while bwtIndex < self.bwt.shape[0] and samplingID < samplingSize:\n                #extract letters and counts so we can do sums\n                letters = np.bitwise_and(self.bwt[bwtIndex:bwtIndex+chunkSize], self.mask)\n                counts = np.right_shift(self.bwt[bwtIndex:bwtIndex+chunkSize], self.letterBits, dtype='<u8')\n                \n                #numpy methods for find the powers\n                i = 1\n                same = (letters[0:-1] == letters[1:])\n                while np.count_nonzero(same) > 0:\n                    (counts[i:])[same] *= self.numPower\n                    i += 1\n                    same = np.bitwise_and(same[0:-1], same[1:])\n                \n                offsets = np.cumsum(counts)\n                \n                #this is basically looking for a clean breakpoint for our bin to end\n                moreToUpdate = True\n                while moreToUpdate:\n                    prevStart = np.searchsorted(offsets, samplingID*self.binSize-totalCounts, 'right')\n                    if prevStart == letters.shape[0]:\n                        prevStart -= 1\n                        while prevStart > 0 and letters[prevStart] == letters[prevStart-1]:\n                            prevStart -= 1\n                        moreToUpdate = False\n                    else:\n                        while prevStart > 0 and letters[prevStart] == letters[prevStart-1]:\n                            prevStart -= 1\n                        \n                        self.refFM[samplingID] = bwtIndex+prevStart\n                        if prevStart > 0:\n                            self.partialFM[samplingID][:] = np.add(countsSoFar, np.bincount(letters[0:prevStart], counts[0:prevStart], self.vcLen))\n                        else:\n                            self.partialFM[samplingID][:] = countsSoFar\n                        samplingID += 1\n                        \n                        \n                bwtIndex += prevStart\n                if prevStart > 0:\n                    countsSoFar += np.bincount(letters[0:prevStart], counts[0:prevStart], self.vcLen)\n                    totalCounts += np.sum(np.bincount(letters[0:prevStart], counts[0:prevStart], self.vcLen))\n            \n        #we'll use this later when we do lookups\n        self.offsetSum = np.sum(self.partialFM[0])", "response": "This function creates the FM index for the given set of unique names."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse for searching, this function masks the complexity behind retrieving a specific character at a specific index in our compressed BWT. @param index - the index to retrieve the character from @param return - return the character in our BWT that's at a particular index (integer format)", "response": "def getCharAtIndex(self, index):\n        '''\n        Used for searching, this function masks the complexity behind retrieving a specific character at a specific index\n        in our compressed BWT.\n        @param index - the index to retrieve the character from\n        @param return - return the character in our BWT that's at a particular index (integer format)\n        '''\n        #get the bin we should start from\n        binID = index >> self.bitPower\n        bwtIndex = self.refFM[binID]\n        \n        #these are the values that indicate how far in we really are\n        trueIndex = np.sum(self.partialFM[binID])-self.offsetSum\n        dist = index-trueIndex\n        \n        #calculate how big of a region we actually need to 'decompress'\n        if binID == self.refFM.shape[0]-1:\n            endRange = self.bwt.shape[0]\n        else:\n            endRange = self.refFM[binID+1]+1\n            while endRange < self.bwt.shape[0] and (self.bwt[endRange] & self.mask) == (self.bwt[endRange-1] & self.mask):\n                endRange += 1\n        \n        #extract the symbols and counts associated with each byte\n        letters = np.bitwise_and(self.bwt[bwtIndex:endRange], self.mask)\n        counts = np.right_shift(self.bwt[bwtIndex:endRange], self.letterBits, dtype='<u8')\n        \n        #numpy methods for find the powers\n        i = 1\n        same = (letters[0:-1] == letters[1:])\n        while np.count_nonzero(same) > 0:\n            (counts[i:])[same] *= self.numPower\n            i += 1\n            same = np.bitwise_and(same[0:-1], same[1:])\n        \n        #these are the true counts after raising to the appropriate power\n        cs = np.cumsum(counts)\n        x = np.searchsorted(cs, dist, 'right')\n        return letters[x]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decompressBlocks(self, startBlock, endBlock):\n        '''\n        This is mostly a helper function to get BWT range, but I wanted it to be a separate thing for use possibly in \n        decompression\n        @param startBlock - the index of the start block we will decode\n        @param endBlock - the index of the final block we will decode, if they are the same, we decode one block\n        @return - an array of size blockSize*(endBlock-startBlock+1), interpreting that block is up to getBWTRange(...)\n        '''\n        expectedIndex = startBlock*self.binSize\n        trueIndex = np.sum(self.partialFM[startBlock])-self.offsetSum\n        dist = expectedIndex - trueIndex\n        \n        #find the end of the region of interest\n        startRange = self.refFM[startBlock]\n        if endBlock >= self.refFM.shape[0]-1:\n            endRange = self.bwt.shape[0]\n            returnSize = self.binSize*(endBlock-startBlock)+(self.totalSize % self.binSize)\n        else:\n            endRange = self.refFM[endBlock+1]+1\n            returnSize = self.binSize*(endBlock-startBlock+1)\n            while endRange < self.bwt.shape[0] and (self.bwt[endRange] & self.mask) == (self.bwt[endRange-1] & self.mask):\n                endRange += 1\n        \n        ret = np.zeros(dtype='<u1', shape=(returnSize,))\n        \n        #split the letters and numbers in the compressed bwt\n        letters = np.bitwise_and(self.bwt[startRange:endRange], self.mask)\n        counts = np.right_shift(self.bwt[startRange:endRange], self.letterBits, dtype='<u8')\n        \n        #multiply counts where needed\n        i = 1\n        same = (letters[0:-1] == letters[1:])\n        while np.count_nonzero(same) > 0:\n            (counts[i:])[same] *= self.numPower\n            i += 1\n            same = np.bitwise_and(same[0:-1], same[1:])\n        \n        #now I have letters and counts, time to fill in the array\n        s = 0\n        lInd = 0\n        while dist > 0:\n            if counts[lInd] < dist:\n                dist -= counts[lInd]\n                lInd += 1\n            else:\n                counts[lInd] -= dist\n                dist = 0\n        \n        #we're at the correct letter index now\n        while s < ret.shape[0]:\n            if lInd >= letters.shape[0]:\n                pass\n            ret[s:s+counts[lInd]] = letters[lInd]\n            s += counts[lInd]\n            lInd += 1\n        \n        return ret", "response": "This function is used to get the compressed version of the BWT from the start and end indices of the BWT."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef decode_html(html):\n    if isinstance(html, unicode):\n        return html\n\n    match = CHARSET_META_TAG_PATTERN.search(html)\n    if match:\n        declared_encoding = match.group(1).decode(\"ASCII\")\n        # proceed unknown encoding as if it wasn't found at all\n        with ignored(LookupError):\n            return html.decode(declared_encoding, \"ignore\")\n\n    # try to enforce UTF-8 firstly\n    with ignored(UnicodeDecodeError):\n        return html.decode(\"utf8\")\n\n    text = TAG_MARK_PATTERN.sub(to_bytes(\" \"), html)\n    diff = text.decode(\"utf8\", \"ignore\").encode(\"utf8\")\n    sizes = len(diff), len(text)\n\n    # 99% of text is UTF-8\n    if abs(len(text) - len(diff)) < max(sizes) * 0.01:\n        return html.decode(\"utf8\", \"ignore\")\n\n    # try detect encoding\n    encoding = \"utf8\"\n    encoding_detector = chardet.detect(text)\n    if encoding_detector[\"encoding\"]:\n        encoding = encoding_detector[\"encoding\"]\n\n    return html.decode(encoding, \"ignore\")", "response": "Decodes an HTML page into Unicode."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_document(html_content, base_href=None):\n    assert html_content is not None\n\n    if isinstance(html_content, unicode):\n        html_content = html_content.encode(\"utf8\", \"xmlcharrefreplace\")\n\n    try:\n        document = document_fromstring(html_content, parser=UTF8_PARSER)\n    except (ParserError, XMLSyntaxError):\n        raise ValueError(\"Failed to parse document contents.\")\n\n    if base_href:\n        document.make_links_absolute(base_href, resolve_base_href=True)\n    else:\n        document.resolve_base_href()\n\n    return document", "response": "Builds a document from a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_properties(self):\n        props_dict = self.data.get('properties', {})\n        for prop_name in self.KNOWN_PROPERTIES:\n            if prop_name in props_dict:\n                setattr(self, prop_name, props_dict.get(prop_name))\n            else:\n                setattr(self, prop_name, None)", "response": "Parse the properties of the node and set them as attributes on this company so that they can make calls."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_relationship(self):\n        rs_dict = self.data.get('relationships', {})\n        for rs_name in self.KNOWN_RELATIONSHIPS:\n            if rs_name in rs_dict:\n                setattr(\n                    self, rs_name, Relationship(rs_name, rs_dict.get(rs_name)))\n            else:\n                # fill in other relationships with None values\n                setattr(self, rs_name, NoneRelationshipSingleton)", "response": "Parse the Relationships and properties of the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self):\n        self.startTime = datetime.datetime.now()\n        self.offset = 0\n        return self", "response": "Reset time and counts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, sent):\n        self.offset = sent\n\n        now = datetime.datetime.now()\n\n        elapsed = (now - self.startTime).total_seconds()\n        if elapsed > 0:\n            mbps = (sent * 8 / (10 ** 6)) / elapsed\n        else:\n            mbps = None\n\n        self._display(sent, now, self.name, mbps)", "response": "Update self and parent with intermediate progress."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstop overwriting display or update parent.", "response": "def close(self):\n        \"\"\" Stop overwriting display, or update parent. \"\"\"\n        if self.parent:\n            self.parent.update(self.parent.offset + self.offset)\n            return\n        self.output.write(\"\\n\")\n        self.output.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransfers large data from sender to receiver.", "response": "def transfer(sendContext, receiveContext, chunkSize):\n    \"\"\" Transfer (large) data from sender to receiver. \"\"\"\n    try:\n        chunkSize = receiveContext.chunkSize\n    except AttributeError:\n        pass\n\n    if sendContext is not None and receiveContext is not None:\n        with receiveContext as writer:\n            # Open reader after writer,\n            # so any raised errors will abort write before writer closes.\n            with sendContext as reader:\n                checkBefore = None\n                if hasattr(writer, 'skipChunk'):\n                    checkBefore = hasattr(reader, 'checkSum')\n\n                while True:\n                    if checkBefore is True:\n                        (size, checkSum) = reader.checkSum(chunkSize)\n\n                        if writer.skipChunk(size, checkSum):\n                            reader.seek(size, io.SEEK_CUR)\n                            continue\n\n                    data = reader.read(chunkSize)\n                    if len(data) == 0:\n                        break\n\n                    if checkBefore is False:\n                        checkSum = hashlib.md5(data).hexdigest()\n\n                        if writer.skipChunk(len(data), checkSum, data):\n                            continue\n\n                    writer.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndisplay the object in a nice string.", "response": "def display(obj, detail='phrase'):\n    \"\"\" Friendly string for volume, using sink paths. \"\"\"\n    try:\n        return obj.display(detail=detail)\n    except AttributeError:\n        return str(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _printUUID(uuid, detail='word'):\n    if not isinstance(detail, int):\n        detail = detailNum[detail]\n\n    if detail > detailNum['word']:\n        return uuid\n\n    if uuid is None:\n        return None\n\n    return \"%s...%s\" % (uuid[:4], uuid[-4:])", "response": "Return friendly abbreviated string for uuid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns logging function that will return True if action should be skipped because of dry run.", "response": "def skipDryRun(logger, dryRun, level=logging.DEBUG):\n    \"\"\" Return logging function.\n\n    When logging function called, will return True if action should be skipped.\n    Log will indicate if skipped because of dry run.\n    \"\"\"\n    # This is an undocumented \"feature\" of logging module:\n    # logging.log() requires a numeric level\n    # logging.getLevelName() maps names to numbers\n    if not isinstance(level, int):\n        level = logging.getLevelName(level)\n    return (\n        functools.partial(_logDryRun, logger, level) if dryRun\n        else functools.partial(logger.log, level)\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn list of volumes or diffs in this Store s selected directory.", "response": "def listContents(self):\n        \"\"\" Return list of volumes or diffs in this Store's selected directory. \"\"\"\n        vols = list(self.listVolumes())\n        vols.sort(key=lambda v: self.getSendPath(v))\n        return [vol.display(self, detail=\"line\") for vol in vols]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning list of all volumes in this Store s selected directory.", "response": "def listVolumes(self):\n        \"\"\" Return list of all volumes in this Store's selected directory. \"\"\"\n        for (vol, paths) in self.paths.items():\n            for path in paths:\n                if path.startswith('/'):\n                    continue\n                if path == '.':\n                    continue\n                if self.userVolume is not None and os.path.basename(path) != self.userVolume:\n                    continue\n                yield vol\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getSendPath(self, volume):\n        try:\n            return self._fullPath(next(iter(self.getPaths(volume))))\n        except StopIteration:\n            return None", "response": "Get the path appropriate for sending the volume from this Store."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef selectReceivePath(self, paths):\n        logger.debug(\"%s\", paths)\n\n        if not paths:\n            path = os.path.basename(self.userPath) + '/Anon'\n\n        try:\n            # Relative paths are preferred\n            path = [p for p in paths if not p.startswith(\"/\")][0]\n        except IndexError:\n            # If no relative path, just use the first path\n            path = os.path.relpath(list(paths)[0], self.userPath)\n\n        return self._fullPath(path)", "response": "Select the receive path based on the source and destination paths."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns fullPath relative to Store directory.", "response": "def _relativePath(self, fullPath):\n        \"\"\" Return fullPath relative to Store directory.\n\n        Return fullPath if fullPath is not inside directory.\n\n        Return None if fullPath is outside our scope.\n        \"\"\"\n        if fullPath is None:\n            return None\n\n        assert fullPath.startswith(\"/\"), fullPath\n\n        path = os.path.relpath(fullPath, self.userPath)\n\n        if not path.startswith(\"../\"):\n            return path\n        elif self.ignoreExtraVolumes:\n            return None\n        else:\n            return fullPath"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sendTo(self, dest, chunkSize):\n        vol = self.toVol\n        paths = self.sink.getPaths(vol)\n\n        if self.sink == dest:\n            logger.info(\"Keep: %s\", self)\n            self.sink.keep(self)\n        else:\n            # Log, but don't skip yet, so we can log more detailed skipped actions later\n            skipDryRun(logger, dest.dryrun, 'INFO')(\"Xfer: %s\", self)\n\n            receiveContext = dest.receive(self, paths)\n\n            sendContext = self.sink.send(self)\n\n            # try:\n            #     receiveContext.metadata['btrfsVersion'] = self.btrfsVersion\n            # except AttributeError:\n            #     pass\n\n            transfer(sendContext, receiveContext, chunkSize)\n\n        if vol.hasInfo():\n            infoContext = dest.receiveVolumeInfo(paths)\n\n            if infoContext is None:\n                # vol.writeInfo(sys.stdout)\n                pass\n            else:\n                with infoContext as stream:\n                    vol.writeInfo(stream)", "response": "Send this difference to the destination Store."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite one line of diff information.", "response": "def writeInfoLine(self, stream, fromUUID, size):\n        \"\"\" Write one line of diff information. \"\"\"\n        if size is None or fromUUID is None:\n            return\n        if not isinstance(size, int):\n            logger.warning(\"Bad size: %s\", size)\n            return\n        stream.write(str(\"%s\\t%s\\t%d\\n\" % (\n            self.uuid,\n            fromUUID,\n            size,\n        )))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite information about the diffs into a file stream for use later.", "response": "def writeInfo(self, stream):\n        \"\"\" Write information about diffs into a file stream for use later. \"\"\"\n        for (fromUUID, size) in Diff.theKnownSizes[self.uuid].iteritems():\n            self.writeInfoLine(stream, fromUUID, size)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the diff has information to write.", "response": "def hasInfo(self):\n        \"\"\" Will have information to write. \"\"\"\n        count = len([None\n                     for (fromUUID, size)\n                     in Diff.theKnownSizes[self.uuid].iteritems()\n                     if size is not None and fromUUID is not None\n                     ])\n        return count > 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef readInfo(stream):\n        try:\n            for line in stream:\n                (toUUID, fromUUID, size) = line.split()\n                try:\n                    size = int(size)\n                except Exception:\n                    logger.warning(\"Bad size: %s\", size)\n                    continue\n                logger.debug(\"diff info: %s %s %d\", toUUID, fromUUID, size)\n                Diff.theKnownSizes[toUUID][fromUUID] = size\n        except Exception as error:\n            logger.warn(\"Can't read .bs info file (%s)\", error)", "response": "Read previously - written information about diffs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef display(self, sink=None, detail='phrase'):\n        if not isinstance(detail, int):\n            detail = detailNum[detail]\n\n        if detail >= detailNum['line'] and self.size is not None:\n            size = \" (%s%s)\" % (\n                humanize(self.size),\n                \"\" if self.exclusiveSize is None else (\n                    \" %s exclusive\" % (humanize(self.exclusiveSize))\n                )\n            )\n        else:\n            size = \"\"\n\n        vol = \"%s %s\" % (\n            _printUUID(self._uuid, detail - 1),\n            sink.getSendPath(self) if sink else \"\",\n        )\n\n        return vol + size", "response": "Display the current object in a friendly string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make(cls, vol):\n        if isinstance(vol, cls):\n            return vol\n        elif vol is None:\n            return None\n        else:\n            return cls(vol, None)", "response": "Convert uuid to Volume"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfilling in volumes and paths.", "response": "def _fillVolumesAndPaths(self, paths):\n        \"\"\" Fill in paths.\n\n        :arg paths: = { Store.Volume: [\"linux path\",]}\n        \"\"\"\n        self.diffs = collections.defaultdict((lambda: []))\n        self.extraKeys = {}\n\n        for key in self.bucket.list():\n            if key.name.startswith(theTrashPrefix):\n                continue\n\n            keyInfo = self._parseKeyName(key.name)\n\n            if keyInfo is None:\n                if key.name[-1:] != '/':\n                    logger.warning(\"Ignoring '%s' in S3\", key.name)\n                continue\n\n            if keyInfo['type'] == 'info':\n                stream = io.BytesIO()\n                key.get_contents_to_file(stream)\n                Store.Volume.readInfo(stream)\n                continue\n\n            if keyInfo['from'] == 'None':\n                keyInfo['from'] = None\n\n            path = self._relativePath(\"/\" + keyInfo['fullpath'])\n\n            if path is None:\n                continue\n\n            diff = Store.Diff(self, keyInfo['to'], keyInfo['from'], key.size)\n\n            logger.debug(\"Adding %s in %s\", diff, path)\n\n            self.diffs[diff.fromVol].append(diff)\n            paths[diff.toVol].append(path)\n\n            self.extraKeys[diff] = path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of volumes or diffs in this Store s selected directory.", "response": "def listContents(self):\n        \"\"\" Return list of volumes or diffs in this Store's selected directory. \"\"\"\n        items = list(self.extraKeys.items())\n        items.sort(key=lambda t: t[1])\n\n        (count, size) = (0, 0)\n\n        for (diff, path) in items:\n            if path.startswith(\"/\"):\n                continue\n            yield str(diff)\n            count += 1\n            size += diff.size\n\n        yield \"TOTAL: %d diffs %s\" % (count, humanize(size))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hasEdge(self, diff):\n        return diff.toVol in [d.toVol for d in self.diffs[diff.fromVol]]", "response": "Test whether an edge is in this sink."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef receive(self, diff, paths):\n        path = self.selectReceivePath(paths)\n        keyName = self._keyName(diff.toUUID, diff.fromUUID, path)\n\n        if self._skipDryRun(logger)(\"receive %s in %s\", keyName, self):\n            return None\n\n        progress = _BotoProgress(diff.size) if self.showProgress is True else None\n        return _Uploader(self.bucket, keyName, progress)", "response": "Return a Context Manager for a file - like object to store a diff."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a context manager for a file - like object to store volume info.", "response": "def receiveVolumeInfo(self, paths):\n        \"\"\" Return Context Manager for a file-like (stream) object to store volume info. \"\"\"\n        path = self.selectReceivePath(paths)\n        path = path + Store.theInfoExtension\n\n        if self._skipDryRun(logger)(\"receive info in '%s'\", path):\n            return None\n\n        return _Uploader(self.bucket, path, bufferSize=theInfoBufferSize)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a key name.", "response": "def _parseKeyName(self, name):\n        \"\"\" Returns dict with fullpath, to, from. \"\"\"\n        if name.endswith(Store.theInfoExtension):\n            return {'type': 'info'}\n\n        match = self.keyPattern.match(name)\n        if not match:\n            return None\n\n        match = match.groupdict()\n        match.update(type='diff')\n\n        return match"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the diff to the stream context manager.", "response": "def send(self, diff):\n        \"\"\" Write the diff (toVol from fromVol) to the stream context manager. \"\"\"\n        path = self._fullPath(self.extraKeys[diff])\n        keyName = self._keyName(diff.toUUID, diff.fromUUID, path)\n        key = self.bucket.get_key(keyName)\n\n        if self._skipDryRun(logger)(\"send %s in %s\", keyName, self):\n            return None\n\n        progress = _BotoProgress(diff.size) if self.showProgress is True else None\n        return _Downloader(key, progress)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef keep(self, diff):\n        path = self.extraKeys[diff]\n\n        if not path.startswith(\"/\"):\n            logger.debug(\"Keeping %s\", path)\n            del self.extraKeys[diff]\n            return\n\n        # Copy into self.userPath, if not there already\n\n        keyName = self._keyName(diff.toUUID, diff.fromUUID, path)\n        newPath = os.path.join(self.userPath, os.path.basename(path))\n        newName = self._keyName(diff.toUUID, diff.fromUUID, newPath)\n\n        if not self._skipDryRun(logger)(\"Copy %s to %s\", keyName, newName):\n            self.bucket.copy_key(newName, self.bucket.name, keyName)", "response": "Keep the entry in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef deleteUnused(self):\n        (count, size) = (0, 0)\n\n        for (diff, path) in self.extraKeys.items():\n            if path.startswith(\"/\"):\n                continue\n\n            keyName = self._keyName(diff.toUUID, diff.fromUUID, path)\n\n            count += 1\n            size += diff.size\n\n            if self._skipDryRun(logger, 'INFO')(\"Trash: %s\", diff):\n                continue\n\n            try:\n                self.bucket.copy_key(theTrashPrefix + keyName, self.bucket.name, keyName)\n                self.bucket.delete_key(keyName)\n            except boto.exception.S3ResponseError as error:\n                logger.error(\"%s: %s\", error.code, error.message)\n\n            try:\n                keyName = os.path.dirname(keyName) + Store.theInfoExtension\n                self.bucket.copy_key(theTrashPrefix + keyName, self.bucket.name, keyName)\n                self.bucket.delete_key(keyName)\n            except boto.exception.S3ResponseError as error:\n                logger.debug(\"%s: %s\", error.code, error.message)\n\n        logger.info(\"Trashed %d diffs (%s)\", count, humanize(size))", "response": "Delete any old snapshots in path if not kept."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    args = command.parse_args()\n\n    with btrfs.FileSystem(args.dir) as mount:\n        # mount.rescanSizes()\n\n        fInfo = mount.FS_INFO()\n        pprint.pprint(fInfo)\n\n        vols = mount.subvolumes\n\n        # for dev in mount.devices:\n        #     pprint.pprint(dev)\n\n        for vol in vols:\n            print(vol)\n\n    return 0", "response": "Print the current state of the current node."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef humanize(number):\n    # units = ('bytes', 'KB', 'MB', 'GB', 'TB')\n    # base = 1000\n    units = ('bytes', 'KiB', 'MiB', 'GiB', 'TiB')\n    base = 1024\n    if number is None:\n        return None\n    pow = int(math.log(number, base)) if number > 0 else 0\n    pow = min(pow, len(units) - 1)\n    mantissa = number / (base ** pow)\n    return \"%.4g %s\" % (mantissa, units[pow])", "response": "Return a human - readable string for number."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a context manager that will store a diff.", "response": "def receive(self, path, diff, showProgress=True):\n        \"\"\" Return a context manager for stream that will store a diff. \"\"\"\n        directory = os.path.dirname(path)\n\n        cmd = [\"btrfs\", \"receive\", \"-e\", directory]\n\n        if Store.skipDryRun(logger, self.dryrun)(\"Command: %s\", cmd):\n            return None\n\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            stdout=DEVNULL,\n        )\n        _makeNice(process)\n\n        return _Writer(process, process.stdin, path, diff, showProgress)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, targetPath, parent, diff, showProgress=True, allowDryRun=True):\n        if parent is not None:\n            cmd = [\"btrfs\", \"send\", \"-p\", parent, targetPath]\n        else:\n            cmd = [\"btrfs\", \"send\", targetPath]\n\n        if Store.skipDryRun(logger, self.dryrun and allowDryRun)(\"Command: %s\", cmd):\n            return None\n\n        process = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, stdin=DEVNULL)\n        _makeNice(process)\n\n        return _Reader(process, process.stdout, targetPath, diff, showProgress)", "response": "Send a snapshot to the target path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef analyze(self, chunkSize, *sinks):\n        measureSize = False\n        if self.measureSize:\n            for sink in sinks:\n                if sink.isRemote:\n                    measureSize = True\n\n        # Use destination (already uploaded) edges first\n        sinks = list(sinks)\n        sinks.reverse()\n        self.dest = sinks[0]\n\n        def currentSize():\n            return sum([\n                n.diffSize\n                for n in self.nodes.values()\n                if n.diff is not None and n.diff.sink != self.dest\n            ])\n\n        while True:\n            self._analyzeDontMeasure(chunkSize, measureSize, *sinks)\n\n            if not measureSize:\n                return\n\n            estimatedSize = currentSize()\n\n            # logger.info(\"Measuring any estimated diffs\")\n\n            for node in self.nodes.values():\n                edge = node.diff\n                if edge is not None and edge.sink != self.dest and edge.sizeIsEstimated:\n                    edge.sink.measureSize(edge, chunkSize)\n\n            actualSize = currentSize()\n\n            logger.info(\n                \"measured size (%s), estimated size (%s)\",\n                humanize(actualSize), humanize(estimatedSize),\n            )\n\n            if actualSize <= 1.2 * estimatedSize:\n                return", "response": "Analyze the size of the source and destination edges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _analyzeDontMeasure(self, chunkSize, willMeasureLater, *sinks):\n        nodes = [None]\n        height = 1\n\n        def sortKey(node):\n            if node is None:\n                return None\n            return (node.intermediate, self._totalSize(node))\n\n        while len(nodes) > 0:\n            logger.debug(\"Analyzing %d nodes for height %d...\", len(nodes), height)\n\n            nodes.sort(key=sortKey)\n\n            for fromNode in nodes:\n                if self._height(fromNode) >= height:\n                    continue\n\n                if fromNode is not None and fromNode.diffSize is None:\n                    continue\n\n                fromVol = fromNode.volume if fromNode else None\n\n                logger.debug(\"Following edges from %s\", fromVol)\n\n                for sink in sinks:\n                    # logger.debug(\n                    #     \"Listing edges in %s\",\n                    #     sink\n                    # )\n\n                    for edge in sink.getEdges(fromVol):\n                        toVol = edge.toVol\n\n                        # logger.debug(\"Edge: %s\", edge)\n\n                        # Skip any edges already in the destination\n                        if sink != self.dest and self.dest.hasEdge(edge):\n                            continue\n\n                        if toVol in self.nodes:\n                            toNode = self.nodes[toVol]\n                        # Don't transfer any edges we won't need in the destination\n                        # elif sink != self.dest:\n                        #     logger.debug(\"Won't transfer unnecessary %s\", edge)\n                        #     continue\n                        else:\n                            toNode = _Node(toVol, True)\n                            self.nodes[toVol] = toNode\n\n                        logger.debug(\"Considering %s\", edge)\n\n                        edgeSize = edge.size\n                        if edge.sizeIsEstimated:\n                            if willMeasureLater:\n                                # Slight preference for accurate sizes\n                                edgeSize *= 1.2\n                            else:\n                                # Large preference for accurate sizes\n                                edgeSize *= 2\n\n                        newCost = self._cost(sink, edgeSize, fromNode, height)\n\n                        if toNode.diff is None:\n                            oldCost = None\n                        else:\n                            oldCost = self._cost(\n                                toNode.sink,\n                                toNode.diffSize,\n                                self._getNode(toNode.previous),\n                                self._height(toNode)\n                            )\n\n                        # Don't use a more-expensive path\n                        if oldCost is not None and oldCost <= newCost:\n                            continue\n\n                        # Don't create circular paths\n                        if self._wouldLoop(fromVol, toVol):\n                            # logger.debug(\"Ignoring looping edge: %s\", toVol.display(sink))\n                            continue\n\n                        # if measureSize and sink != self.dest and edge.sizeIsEstimated:\n                        #     sink.measureSize(edge, chunkSize)\n                        #     newCost = self._cost(sink, edge.size, fromSize, height)\n                        #     if oldCost is not None and oldCost <= newCost:\n                        #         continue\n\n                        logger.debug(\n                            \"Replacing edge (%s -> %s cost)\\n%s\",\n                            humanize(oldCost),\n                            humanize(newCost),\n                            toNode.display(sink)\n                        )\n                        # logger.debug(\"Cost elements: %s\", dict(\n                        #     sink=str(sink),\n                        #     edgeSize=humanize(edgeSize),\n                        #     fromSize=humanize(fromSize),\n                        #     height=height,\n                        # ))\n\n                        toNode.diff = edge\n\n            nodes = [node for node in self.nodes.values() if self._height(node) == height]\n            height += 1\n\n        self._prune()\n\n        for node in self.nodes.values():\n            node.height = self._height(node)\n            if node.diff is None:\n                logger.error(\n                    \"No source diffs for %s\",\n                    node.volume.display(sinks[-1], detail=\"line\"),\n                )", "response": "Analyze the diff between two volumes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning all diffs used in optimal network.", "response": "def iterDiffs(self):\n        \"\"\" Return all diffs used in optimal network. \"\"\"\n        nodes = self.nodes.values()\n        nodes.sort(key=lambda node: self._height(node))\n        for node in nodes:\n            yield node.diff"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving all intermediate nodes that aren t needed.", "response": "def _prune(self):\n        \"\"\" Get rid of all intermediate nodes that aren't needed. \"\"\"\n        done = False\n        while not done:\n            done = True\n            for node in [node for node in self.nodes.values() if node.intermediate]:\n                if not [dep for dep in self.nodes.values() if dep.previous == node.volume]:\n                    # logger.debug(\"Removing unnecessary node %s\", node)\n                    del self.nodes[node.volume]\n                    done = False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _fillVolumesAndPaths(self, paths):\n        with self.btrfs as mount:\n            for bv in mount.subvolumes:\n                if not bv.readOnly:\n                    continue\n\n                vol = self._btrfsVol2StoreVol(bv)\n                if vol is None:\n                    continue\n\n                path = bv.fullPath\n\n                if path is None:\n                    logger.info(\"Skipping deleted volume %s\", bv.uuid)\n                    continue\n\n                relPath = None\n\n                for path in bv.linuxPaths:\n                    path = self._relativePath(path)\n\n                    if path is None:\n                        continue  # path is outside store scope\n\n                    paths[vol].append(path)\n\n                    infoPath = self._fullPath(path + Store.theInfoExtension)\n                    if os.path.exists(infoPath):\n                        logger.debug(\"Reading %s\", infoPath)\n                        with open(infoPath) as info:\n                            Store.Volume.readInfo(info)\n\n                    if not path.startswith(\"/\"):\n                        relPath = path\n\n                if vol not in paths:\n                    continue\n\n                logger.debug(\"%s\", vol.display(sink=self, detail='phrase'))\n\n                if vol.uuid in self.butterVolumes:\n                    logger.warn(\n                        \"Duplicate effective uuid %s in '%s' and '%s'\",\n                        vol.uuid, path, self.butterVolumes[vol.uuid].fullPath\n                    )\n\n                self.butterVolumes[vol.uuid] = bv\n\n                if relPath is not None:\n                    # vol is inside Store directory\n                    self.extraVolumes[vol] = relPath", "response": "Fill in volumes and paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getEdges(self, fromVol):\n        if fromVol is None:\n            for toVol in self.paths:\n                yield Store.Diff(self, toVol, fromVol, toVol.size)\n            return\n\n        if fromVol not in self.paths:\n            return\n\n        fromBVol = self.butterVolumes[fromVol.uuid]\n        parentUUID = fromBVol.parent_uuid\n        butterDir = os.path.dirname(fromBVol.fullPath)\n\n        vols = [vol for vol in self.butterVolumes.values()\n                if vol.parent_uuid == parentUUID or\n                os.path.dirname(vol.fullPath) == butterDir\n                ]\n\n        changeRate = self._calcChangeRate(vols)\n\n        for toBVol in vols:\n            if toBVol == fromBVol:\n                continue\n\n            # This gives a conservative estimate of the size of the diff\n\n            estimatedSize = self._estimateSize(toBVol, fromBVol, changeRate)\n\n            toVol = self._btrfsVol2StoreVol(toBVol)\n\n            yield Store.Diff(self, toVol, fromVol, estimatedSize, sizeIsEstimated=True)", "response": "Return the edges available from fromVol."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receive(self, diff, paths):\n        if not self.dryrun:\n            self._fileSystemSync()\n\n        path = self.selectReceivePath(paths)\n\n        if os.path.exists(path):\n            raise Exception(\n                \"Path %s exists, can't receive %s\" % (path, diff.toUUID)\n            )\n\n        return self.butter.receive(path, diff, self.showProgress is True)", "response": "Return a Context Manager object for a file - like object to store a diff."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef receiveVolumeInfo(self, paths):\n        path = self.selectReceivePath(paths)\n        path = path + Store.theInfoExtension\n\n        if Store.skipDryRun(logger, self.dryrun)(\"receive info to %s\", path):\n            return None\n\n        return open(path, \"w\")", "response": "Return a file - like object to store volume info."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measureSize(self, diff, chunkSize):\n        self._fileSystemSync()\n\n        sendContext = self.butter.send(\n            self.getSendPath(diff.toVol),\n            self.getSendPath(diff.fromVol),\n            diff,\n            showProgress=self.showProgress is not False,\n            allowDryRun=False,\n        )\n\n        class _Measure(io.RawIOBase):\n\n            def __init__(self, estimatedSize, showProgress):\n                self.totalSize = None\n                self.progress = progress.DisplayProgress(estimatedSize) if showProgress else None\n\n            def __enter__(self):\n                self.totalSize = 0\n                if self.progress:\n                    self.progress.__enter__()\n                return self\n\n            def __exit__(self, exceptionType, exceptionValue, traceback):\n                if self.progress:\n                    self.progress.__exit__(exceptionType, exceptionValue, traceback)\n                return False  # Don't supress exception\n\n            def writable(self):\n                return True\n\n            def write(self, bytes):\n                self.totalSize += len(bytes)\n                if self.progress:\n                    self.progress.update(self.totalSize)\n\n        logger.info(\"Measuring %s\", diff)\n\n        measure = _Measure(diff.size, self.showProgress is not False)\n        Store.transfer(sendContext, measure, chunkSize)\n\n        diff.setSize(measure.totalSize, False)\n\n        for path in self.getPaths(diff.toVol):\n            path = self._fullPath(path) + Store.theInfoExtension\n\n            with open(path, \"a\") as infoFile:\n                diff.toVol.writeInfoLine(infoFile, diff.fromUUID, measure.totalSize)", "response": "Measure the size of a specific entry in the file system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef send(self, diff):\n        if not self.dryrun:\n            self._fileSystemSync()\n\n        return self.butter.send(\n            self.getSendPath(diff.toVol),\n            self.getSendPath(diff.fromVol),\n            diff,\n            self.showProgress is True,\n        )", "response": "Write the diff to the stream context manager."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef keep(self, diff):\n        self._keepVol(diff.toVol)\n        self._keepVol(diff.fromVol)", "response": "Mark this diff or volume as kept in path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _keepVol(self, vol):\n        if vol is None:\n            return\n\n        if vol in self.extraVolumes:\n            del self.extraVolumes[vol]\n            return\n\n        if vol not in self.paths:\n            raise Exception(\"%s not in %s\" % (vol, self))\n\n        paths = [os.path.basename(path) for path in self.paths[vol]]\n        newPath = self.selectReceivePath(paths)\n\n        if self._skipDryRun(logger, 'INFO')(\"Copy %s to %s\", vol, newPath):\n            return\n\n        self.butterVolumes[vol.uuid].copy(newPath)", "response": "Mark this volume to be kept in path."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deletePartials(self, dryrun=False):\n        for (vol, path) in self.extraVolumes.items():\n            if not path.endswith(\".part\"):\n                continue\n            if self._skipDryRun(logger, 'INFO', dryrun=dryrun)(\"Delete subvolume %s\", path):\n                continue\n            self.butterVolumes[vol.uuid].destroy()", "response": "Delete any old partial uploads and downloads in path."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a type definition.", "response": "def _parseDefinition(typeDef, name, len=1, reader=None, writer=None):\n        \"\"\" Return (name, format, type) for field.\n\n        type.popValue() and type.yieldArgs() must be implemented.\n\n        \"\"\"\n        if isinstance(typeDef, Structure):\n            return (name, typeDef.fmt, typeDef)\n\n        if len != 1:\n            size = struct.calcsize(typeDef)\n            if typeDef not in \"xspP\":\n                typeDef = 's'\n            typeDef = str(len * size) + typeDef\n\n        fmtChar = typeDef[-1:]\n\n        if fmtChar == 'x':\n            typeObj = Structure.skipType\n        else:\n            typeObj = _TypeWriter(Structure.defaults[fmtChar], reader, writer)\n\n        return (name, typeDef, typeObj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield all the args that are set in the keyArgs.", "response": "def yieldArgs(self, keyArgs):\n        try:\n            keyArgs = keyArgs._asdict() if keyArgs else {}\n        except AttributeError:\n            pass\n        logger.debug('Args: %s', keyArgs)\n        \"\"\" Take (nested) dict(s) of args to set, and return flat list of args. \"\"\"\n        for (name, typeObj) in self._types.items():\n            logger.debug('Yielding %s: %s', name, typeObj)\n            for arg in typeObj.yieldArgs(keyArgs.get(name, None)):\n                yield arg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting specified key arguments into data structure.", "response": "def write(self, keyArgs):\n        \"\"\" Write specified key arguments into data structure. \"\"\"\n        # bytearray doesn't work with fcntl\n        args = array.array('B', (0,) * self.size)\n        self._struct.pack_into(args, 0, *list(self.yieldArgs(keyArgs)))\n        return args"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a flat arglist and pop relevent values and return as a value or tuple.", "response": "def popValue(self, argList):\n        \"\"\" Take a flat arglist, and pop relevent values and return as a value or tuple. \"\"\"\n        # return self._Tuple(*[name for (name, typeObj) in self._types.items()])\n        return self._Tuple(*[typeObj.popValue(argList) for (name, typeObj) in self._types.items()])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads data structure and return named tuple.", "response": "def read(self, data, offset=0):\n        \"\"\" Read data structure and return (nested) named tuple(s). \"\"\"\n        if isinstance(data, Buffer):\n            return data.read(self)\n\n        try:\n            args = list(self._struct.unpack_from(data, offset))\n        except TypeError as error:\n            # Working around struct.unpack_from issue #10212\n            logger.debug(\"error: %s\", error)\n            args = list(self._struct.unpack_from(str(bytearray(data)), offset))\n        args.reverse()\n        return self.popValue(args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a view of the next newLength bytes and skip it.", "response": "def readView(self, newLength=None):\n        \"\"\" Return a view of the next newLength bytes, and skip it. \"\"\"\n        if newLength is None:\n            newLength = self.len\n        result = self.peekView(newLength)\n        self.skip(newLength)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a view of the next newLength bytes.", "response": "def peekView(self, newLength):\n        \"\"\" Return a view of the next newLength bytes. \"\"\"\n        # Note: In Python 2.7, memoryviews can't be written to\n        # by the struct module. (BUG)\n        return memoryview(self.buf)[self.offset:self.offset + newLength]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef readBuffer(self, newLength):\n        result = Buffer(self.buf, self.offset, newLength)\n        self.skip(newLength)\n        return result", "response": "Read next chunk as another buffer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _IOC(cls, dir, op, structure=None):\n        control = cls(dir, op, structure)\n\n        def do(dev, **args):\n            return control(dev, **args)\n        return do", "response": "Encode an ioctl id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef IOWR(cls, op, structure):\n        return cls._IOC(READ | WRITE, op, structure)", "response": "Returns an ioctl Device method with READ and WRITE arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn standard human - friendly UUID.", "response": "def bytes2uuid(b):\n    \"\"\" Return standard human-friendly UUID. \"\"\"\n    if b.strip(chr(0)) == '':\n        return None\n\n    s = b.encode('hex')\n    return \"%s-%s-%s-%s-%s\" % (s[0:8], s[8:12], s[12:16], s[16:20], s[20:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a hardlink to the tree.", "response": "def _addLink(self, dirTree, dirID, dirSeq, dirPath, name):\n        \"\"\" Add tree reference and name. (Hardlink). \"\"\"\n        logger.debug(\"Link  %d-%d-%d '%s%s'\", dirTree, dirID, dirSeq, dirPath, name)\n        # assert dirTree != 0, (dirTree, dirID, dirSeq, dirPath, name)\n        assert (dirTree, dirID, dirSeq) not in self.links, (dirTree, dirID, dirSeq)\n        self.links[(dirTree, dirID, dirSeq)] = (dirPath, name)\n        assert len(self.links) == 1, self.links  # Cannot have multiple hardlinks to a directory\n        logger.debug(\"%s\", self)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning full path of the butter root.", "response": "def fullPath(self):\n        \"\"\" Return full butter path from butter root. \"\"\"\n        for ((dirTree, dirID, dirSeq), (dirPath, name)) in self.links.items():\n            try:\n                path = self.fileSystem.volumes[dirTree].fullPath\n                if path is not None:\n                    return path + (\"/\" if path[-1] != \"/\" else \"\") + dirPath + name\n            except Exception:\n                logging.debug(\"Haven't imported %d yet\", dirTree)\n\n        if self.id == BTRFS_FS_TREE_OBJECTID:\n            return \"/\"\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning full paths from linux root.", "response": "def linuxPaths(self):\n        \"\"\" Return full paths from linux root.\n\n        The first path returned will be the path through the top-most mount.\n        (Usually the root).\n        \"\"\"\n        for ((dirTree, dirID, dirSeq), (dirPath, name)) in self.links.items():\n            for path in self.fileSystem.volumes[dirTree].linuxPaths:\n                yield path + \"/\" + dirPath + name\n        if self.fullPath in self.fileSystem.mounts:\n            yield self.fileSystem.mounts[self.fullPath]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete this subvolume from the filesystem.", "response": "def destroy(self):\n        \"\"\" Delete this subvolume from the filesystem. \"\"\"\n        path = next(iter(self.linuxPaths))\n        directory = _Directory(os.path.dirname(path))\n        with directory as device:\n            device.SNAP_DESTROY(name=str(os.path.basename(path)), )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a copy of this object into a new object.", "response": "def copy(self, path):\n        \"\"\" Make another snapshot of this into dirName. \"\"\"\n        directoryPath = os.path.dirname(path)\n        if not os.path.exists(directoryPath):\n            os.makedirs(directoryPath)\n\n        logger.debug('Create copy of %s in %s', os.path.basename(path), directoryPath)\n\n        with self._snapshot() as source, _Directory(directoryPath) as dest:\n            dest.SNAP_CREATE_V2(\n                flags=BTRFS_SUBVOL_RDONLY,\n                name=str(os.path.basename(path)),\n                fd=source.fd,\n            )\n\n        with SnapShot(path) as destShot:\n            flags = destShot.SUBVOL_GETFLAGS()\n            destShot.SUBVOL_SETFLAGS(flags=flags.flags & ~BTRFS_SUBVOL_RDONLY)\n\n            destShot.SET_RECEIVED_SUBVOL(\n                uuid=self.received_uuid or self.uuid,\n                stransid=self.sent_gen or self.current_gen,\n                stime=timeOrNone(self.info.stime) or timeOrNone(self.info.ctime) or 0,\n                flags=0,\n            )\n\n            destShot.SUBVOL_SETFLAGS(flags=flags.flags)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef subvolumes(self):\n        self.SYNC()\n        self._getDevices()\n        self._getRoots()\n        self._getMounts()\n        self._getUsage()\n\n        volumes = self.volumes.values()\n        volumes.sort(key=(lambda v: v.fullPath))\n        return volumes", "response": "Return a list of all subvolumes contained in this mount."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _rescanSizes(self, force=True):\n        status = self.QUOTA_CTL(cmd=BTRFS_QUOTA_CTL_ENABLE).status\n        logger.debug(\"CTL Status: %s\", hex(status))\n\n        status = self.QUOTA_RESCAN_STATUS()\n        logger.debug(\"RESCAN Status: %s\", status)\n\n        if not status.flags:\n            if not force:\n                return\n            self.QUOTA_RESCAN()\n\n        logger.warn(\"Waiting for btrfs quota usage scan...\")\n        self.QUOTA_RESCAN_WAIT()", "response": "Zero and recalculate quota sizes to subvolume sizes will be correct."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef TLV_GET(attrs, attrNum, format):\n    attrView = attrs[attrNum]\n    if format == 's':\n        format = str(attrView.len) + format\n    try:\n        (result,) = struct.unpack_from(format, attrView.buf, attrView.offset)\n    except TypeError:\n        # Working around struct.unpack_from issue #10212\n        (result,) = struct.unpack_from(format, str(bytearray(attrView.buf)), attrView.offset)\n    return result", "response": "Get a tag - length - value encoded attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef TLV_PUT(attrs, attrNum, format, value):\n    attrView = attrs[attrNum]\n    if format == 's':\n        format = str(attrView.len) + format\n    struct.pack_into(format, attrView.buf, attrView.offset, value)", "response": "Put a tag - length - value encoded attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replaceIDs(data, receivedUUID, receivedGen, parentUUID, parentGen):\n    if len(data) < 20:\n        return data\n\n    logger.debug(\n        \"Setting received %s/%d and parent %s/%d\",\n        receivedUUID, receivedGen or 0, parentUUID, parentGen or 0.\n        )\n    data = bytearray(data)  # Make data writable\n\n    buf = ioctl.Buffer(data)\n    header = buf.read(btrfs_stream_header)\n\n    if header.magic != BTRFS_SEND_STREAM_MAGIC:\n        raise ParseException(\"Didn't find '%s'\" % (BTRFS_SEND_STREAM_MAGIC))\n\n    logger.debug(\"Version: %d\", header.version)\n\n    if header.version > BTRFS_SEND_STREAM_VERSION:\n        logger.warn(\"Unknown stream version: %d\", header.version)\n\n    cmdHeaderView = buf.peekView(btrfs_cmd_header.size)\n    cmdHeader = buf.read(btrfs_cmd_header)\n\n    logger.debug(\"Command: %d\", cmdHeader.cmd)\n\n    # Read the attributes\n\n    attrs = {}\n    attrDataView = buf.peekView(cmdHeader.len)\n    attrData = buf.readBuffer(cmdHeader.len)\n\n    while attrData.len > 0:\n        attrHeader = attrData.read(btrfs_tlv_header)\n        attrs[attrHeader.tlv_type] = attrData.readBuffer(attrHeader.tlv_len)\n\n    def calcCRC():\n        header = cmdHeader._asdict()\n        header['crc'] = 0\n\n        # This works, but is slow\n        # crc = crc32c.CRC_INIT ^ crc32c._MASK\n        # crc = crc32c.crc_update(crc, btrfs_cmd_header.write(header))\n        # crc = crc32c.crc_update(crc, attrDataView)\n        # crc = crc32c.crc_finalize(crc)\n        # crc = crc ^ crc32c._MASK\n\n        # This works, and can be fast, when it used compiled extension\n        crc = 0 ^ 0xffffffff\n        crc = crc32c(btrfs_cmd_header.write(header).tostring(), crc)\n        crc = crc32c(attrDataView.tobytes(), crc)\n        crc &= 0xffffffff\n        crc = crc ^ 0xffffffff\n\n        # This does *not* work\n        # crc = 0 ^ 0xffffffff\n        # crc = binascii.crc32(btrfs_cmd_header.write(header), crc)\n        # crc = binascii.crc32(attrDataView, crc)\n        # crc &= 0xffffffff\n        # crc ^= 0xffffffff\n\n        return crc\n\n    crc = calcCRC()\n    if cmdHeader.crc != crc:\n        logger.warn(\n            \"Stored crc (%d) doesn't match calculated crc (%d)\",\n            cmdHeader.crc, crc,\n            )\n\n    # Dispatch based on cmd and attributes\n\n    s = attrs\n\n    def correct(attr, format, name, old, new, encode=None):\n        if new is not None and new != old:\n            logger.debug(\"Correcting %s from %s to %s\", name, str(old), str(new))\n            if encode is not None:\n                new = encode(new)\n            TLV_PUT(attrs, attr, format, new)\n\n    def correctCRC():\n        crc = calcCRC()\n        if cmdHeader.crc != crc:\n            logger.debug(\"Correcting CRC from %d to %d\", cmdHeader.crc, crc)\n            header = cmdHeader._asdict()\n            header['crc'] = crc\n            cmdHeaderView[:] = btrfs_cmd_header.write(header).tostring()\n\n    if cmdHeader.cmd == BTRFS_SEND_C_SUBVOL:\n        path = TLV_GET_STRING(s, BTRFS_SEND_A_PATH, )\n        uuid = TLV_GET_UUID(s, BTRFS_SEND_A_UUID, )\n        ctransid = TLV_GET_U64(s, BTRFS_SEND_A_CTRANSID, )\n\n        logger.debug('Subvol: %s/%d %s', uuid, ctransid, path)\n\n        correct(\n            BTRFS_SEND_A_UUID,\n            's',\n            'received UUID',\n            uuid,\n            receivedUUID,\n            btrfs.uuid2bytes\n        )\n        correct(\n            BTRFS_SEND_A_CTRANSID,\n            t.u64,\n            'received gen',\n            ctransid,\n            receivedGen\n        )\n\n    elif cmdHeader.cmd == BTRFS_SEND_C_SNAPSHOT:\n        path = TLV_GET_STRING(s, BTRFS_SEND_A_PATH, )\n        uuid = TLV_GET_UUID(s, BTRFS_SEND_A_UUID, )\n        ctransid = TLV_GET_U64(s, BTRFS_SEND_A_CTRANSID, )\n        clone_uuid = TLV_GET_UUID(s, BTRFS_SEND_A_CLONE_UUID, )\n        clone_ctransid = TLV_GET_U64(s, BTRFS_SEND_A_CLONE_CTRANSID, )\n\n        logger.debug(\n            'Snapshot: %s/%d -> %s/%d %s',\n            clone_uuid, clone_ctransid, uuid, ctransid, path\n        )\n\n        correct(\n            BTRFS_SEND_A_UUID,\n            's',\n            'received UUID',\n            uuid,\n            receivedUUID,\n            btrfs.uuid2bytes\n        )\n        correct(\n            BTRFS_SEND_A_CTRANSID,\n            t.u64,\n            'received gen',\n            ctransid,\n            receivedGen\n        )\n\n        correct(\n            BTRFS_SEND_A_CLONE_UUID,\n            's',\n            'parent UUID',\n            clone_uuid,\n            parentUUID,\n            btrfs.uuid2bytes\n        )\n        correct(\n            BTRFS_SEND_A_CLONE_CTRANSID,\n            t.u64,\n            'parent gen',\n            clone_ctransid,\n            parentGen\n        )\n    else:\n        logger.warn(\"Didn't find volume UUID command\")\n\n    correctCRC()\n\n    return data", "response": "Parse and replace UUID and transid info in data stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef command(name, mode):\n    def decorator(fn):\n        commands[name] = fn.__name__\n        _Client._addMethod(fn.__name__, name, mode)\n        return fn\n    return decorator", "response": "Decorator to label a method as a command with name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef diff(self, diff):\n        if diff is None:\n            return None\n        return dict(\n            toVol=diff.toUUID,\n            fromVol=diff.fromUUID,\n            size=diff.size,\n            sizeIsEstimated=diff.sizeIsEstimated,\n        )", "response": "Serialize to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fillVolumesAndPaths(self, paths):\n        for (volDict, volPaths) in self._client.fillVolumesAndPaths():\n            vol = Store.Volume(**volDict)\n            paths[vol] = volPaths", "response": "Fill in paths.\n\n        :arg paths: = { Store.Volume: [\"linux path\",]}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the edges available from fromVol.", "response": "def getEdges(self, fromVol):\n        \"\"\" Return the edges available from fromVol. \"\"\"\n        return [\n            self.toObj.diff(diff)\n            for diff in self._client.getEdges(self.toArg.vol(fromVol))\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef measureSize(self, diff, chunkSize):\n        (toUUID, fromUUID) = self.toArg.diff(diff)\n        isInteractive = sys.stderr.isatty()\n        return self.toObj.diff(self._client.measureSize(\n            toUUID,\n            fromUUID,\n            diff.size,\n            chunkSize,\n            isInteractive,\n        ))", "response": "Measure the size of a new entry."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, diff):\n        if Store.skipDryRun(logger, self.dryrun)(\"send %s\", diff):\n            return None\n\n        (diffTo, diffFrom) = self.toArg.diff(diff)\n        self._client.send(diffTo, diffFrom)\n\n        progress = DisplayProgress(diff.size) if self.showProgress is True else None\n        return _SSHStream(self._client, progress)", "response": "Send a diff to the remote host."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreceive a diff from a file - like object.", "response": "def receive(self, diff, paths):\n        \"\"\" Return Context Manager for a file-like (stream) object to store a diff. \"\"\"\n        path = self.selectReceivePath(paths)\n        path = self._relativePath(path)\n\n        if Store.skipDryRun(logger, self.dryrun)(\"receive to %s\", path):\n            return None\n\n        (diffTo, diffFrom) = self.toArg.diff(diff)\n        self._client.receive(path, diffTo, diffFrom)\n\n        progress = DisplayProgress(diff.size) if self.showProgress is True else None\n        return _SSHStream(self._client, progress)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a SSHStream object to store volume info.", "response": "def receiveVolumeInfo(self, paths):\n        \"\"\" Return Context Manager for a file-like (stream) object to store volume info. \"\"\"\n        path = self.selectReceivePath(paths)\n        path = path + Store.theInfoExtension\n\n        if Store.skipDryRun(logger, self.dryrun)(\"receive info to %s\", path):\n            return None\n\n        self._client.receiveInfo(path)\n\n        return _SSHStream(self._client)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmarking this diff or volume as kept in path.", "response": "def keep(self, diff):\n        \"\"\" Mark this diff (or volume) to be kept in path. \"\"\"\n        (toUUID, fromUUID) = self.toArg.diff(diff)\n        self._client.keep(toUUID, fromUUID)\n        logger.debug(\"Kept %s\", diff)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef deleteUnused(self):\n        if self.dryrun:\n            self._client.listUnused()\n        else:\n            self._client.deleteUnused()", "response": "Delete any old snapshots in path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete any old partial uploads and downloads in path.", "response": "def deletePartials(self):\n        \"\"\" Delete any old partial uploads/downloads in path. \"\"\"\n        if self.dryrun:\n            self._client.listPartials()\n        else:\n            self._client.deletePartials()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nopening connection to the remote host.", "response": "def _open(self):\n        \"\"\" Open connection to remote host. \"\"\"\n        if self._process is not None:\n            return\n\n        cmd = [\n            'ssh',\n            self._host,\n            'sudo',\n            'buttersink',\n            '--server',\n            '--mode',\n            self._mode,\n            self._directory\n        ]\n        logger.debug(\"Connecting with: %s\", cmd)\n        self._process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.PIPE,\n            stderr=sys.stderr,\n            # stdout=sys.stdout,\n            stdout=subprocess.PIPE,\n        )\n\n        version = self.version()\n        logger.info(\"Remote version: %s\", version)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _close(self):\n        if self._process is None:\n            return\n\n        self.quit()\n\n        self._process.stdin.close()\n\n        logger.debug(\"Waiting for ssh process to finish...\")\n        self._process.wait()  # Wait for ssh session to finish.\n\n        # self._process.terminate()\n        # self._process.kill()\n\n        self._process = None", "response": "Close connection to remote host."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        normalized = os.path.normpath(self.path) + (\"/\" if self.path.endswith(\"/\") else \"\")\n        if self.path != normalized:\n            sys.stderr.write(\"Please use full path '%s'\" % (normalized,))\n            return -1\n\n        self.butterStore = ButterStore.ButterStore(None, self.path, self.mode, dryrun=False)\n        # self.butterStore.ignoreExtraVolumes = True\n\n        self.toObj = _Arg2Obj(self.butterStore)\n        self.toDict = _Obj2Dict()\n\n        self.running = True\n\n        with self.butterStore:\n            with self:\n                while self.running:\n                    self._processCommand()\n\n        return 0", "response": "Runs the server. Returns with system error code."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend parseable json result of command.", "response": "def _sendResult(self, result):\n        \"\"\" Send parseable json result of command. \"\"\"\n        # logger.debug(\"Result: %s\", result)\n\n        try:\n            result = json.dumps(result)\n        except Exception as error:\n            result = json.dumps(self._errorInfo(command, error))\n\n        sys.stdout.write(result)\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns kernel and btrfs version.", "response": "def version(self):\n        \"\"\" Return kernel and btrfs version. \"\"\"\n        return dict(\n            buttersink=theVersion,\n            btrfs=self.butterStore.butter.btrfsVersion,\n            linux=platform.platform(),\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, diffTo, diffFrom):\n        diff = self.toObj.diff(diffTo, diffFrom)\n        self._open(self.butterStore.send(diff))", "response": "Do a btrfs send."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receive(self, path, diffTo, diffFrom):\n        diff = self.toObj.diff(diffTo, diffFrom)\n        self._open(self.butterStore.receive(diff, [path, ]))", "response": "Receive a btrfs diff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend or receive a chunk of data.", "response": "def streamWrite(self, size):\n        \"\"\" Send or receive a chunk of data.\n\n        :arg size:  Amount of data.  0 indicates EOT.\n        \"\"\"\n        size = int(size)\n        if size == 0:\n            self._close()\n            return\n\n        self._sendResult(dict(message=\"writing...\", stream=True, size=size))\n        data = sys.stdin.read(size)\n        self.stream.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend or receive a chunk of data.", "response": "def streamRead(self, size):\n        \"\"\" Send or receive a chunk of data.\n\n        :arg size:  Amount of data requested.\n        \"\"\"\n        size = int(size)\n        data = self.stream.read(size)\n        size = len(data)\n        if size == 0:\n            self._close()\n            return dict(message=\"Finished\", size=0)\n\n        self._sendResult(dict(message=\"reading...\", stream=True, size=size))\n        sys.stdout.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fillVolumesAndPaths(self):\n        return [\n            (self.toDict.vol(vol), paths)\n            for vol, paths in self.butterStore.paths.items()\n        ]", "response": "Get all volumes and paths for initialization."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the edges available from fromVol.", "response": "def getEdges(self, fromVol):\n        \"\"\" Return the edges available from fromVol. \"\"\"\n        return [self.toDict.diff(d) for d in self.butterStore.getEdges(self.toObj.vol(fromVol))]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef measureSize(self, diffTo, diffFrom, estimatedSize, chunkSize, isInteractive):\n        diff = self.toObj.diff(diffTo, diffFrom, estimatedSize)\n        isInteractive = self.toObj.bool(isInteractive)\n        self.butterStore.showProgress = None if isInteractive else False\n        self.butterStore.measureSize(diff, int(chunkSize))\n        return self.toDict.diff(diff)", "response": "Measure the size of the data in the butter store."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef keep(self, diffTo, diffFrom):\n        diff = self.toObj.diff(diffTo, diffFrom)\n        self.butterStore.keep(diff)", "response": "Mark this diff ( or volume to be kept in path."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_lists(keys=[], values=[], name='NT'):\n    mapping = dict(zip(keys, values))\n    return mapper(mapping, _nt_name=name)", "response": "Map namedtuples given a pair of key value lists."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_json(data=None, path=None, name='NT'):\n    if data and not path:\n        return mapper(json.loads(data), _nt_name=name)\n    if path and not data:\n        return mapper(json.load(path), _nt_name=name)\n    if data and path:\n        raise ValueError('expected one source and received two')", "response": "Load namedtuples with json data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload namedtuples with yaml data.", "response": "def load_yaml(data=None, path=None, name='NT'):\n    \"\"\" Map namedtuples with yaml data. \"\"\"\n    if data and not path:\n        return mapper(yaml.load(data), _nt_name=name)\n    if path and not data:\n        with open(path, 'r') as f:\n            data = yaml.load(f)\n        return mapper(data, _nt_name=name)\n    if data and path:\n        raise ValueError('expected one source and received two')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a namedtuple from a list of environment variables. If not found in shell gets input with getpass. getpass or input.", "response": "def load_env(keys=[], name='NT', use_getpass=False):\n    \"\"\" Returns a namedtuple from a list of environment variables.\n    If not found in shell, gets input with *input* or *getpass*. \"\"\"\n    NT = namedtuple(name, keys)\n    if use_getpass:\n        values = [os.getenv(x) or getpass.getpass(x) for x in keys]\n    else:\n        values = [os.getenv(x) or input(x) for x in keys]\n    return NT(*values)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a mapping to namedtuples recursively.", "response": "def mapper(mapping, _nt_name='NT'):\n    \"\"\" Convert mappings to namedtuples recursively. \"\"\"\n    if isinstance(mapping, Mapping) and not isinstance(mapping, AsDict):\n        for key, value in list(mapping.items()):\n            mapping[key] = mapper(value)\n        return namedtuple_wrapper(_nt_name, **mapping)\n    elif isinstance(mapping, list):\n        return [mapper(item) for item in mapping]\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nusing ignore to prevent mapping from being mapped to a namedtuple.", "response": "def ignore(mapping):\n    \"\"\" Use ignore to prevent a mapping from being mapped to a namedtuple. \"\"\"\n    if isinstance(mapping, Mapping):\n        return AsDict(mapping)\n    elif isinstance(mapping, list):\n        return [ignore(item) for item in mapping]\n    return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nensures that the directory at DIR_PATH exists.", "response": "def ensure_dir(dir_path):\n    \"\"\"\n    If DIR_PATH does not exist, makes it. Failing that, raises Exception.\n    Returns True if dir already existed; False if it had to be made.\n    \"\"\"\n    exists = dir_exists(dir_path)\n    if not exists:\n        try:\n            os.makedirs(dir_path)\n        except(Exception,RuntimeError), e:\n            raise Exception(\"Unable to create directory %s. Cause %s\" %\n                            (dir_path, e))\n    return exists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn true if host1 and host2 are mapped to the same host.", "response": "def is_same_host(host1, host2):\n\n    \"\"\"\n    Returns true if host1 == host2 OR map to the same host (using DNS)\n    \"\"\"\n    try:\n\n        if host1 == host2:\n            return True\n        else:\n            ips1 = get_host_ips(host1)\n            ips2 = get_host_ips(host2)\n            return len(set(ips1) & set(ips2)) > 0\n    except Exception, ex:\n        log_exception(ex)\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_same_address(addr1, addr2):\n    hostport1 = addr1.split(\":\")\n    hostport2 = addr2.split(\":\")\n\n    return (is_same_host(hostport1[0], hostport2[0]) and\n            hostport1[1] == hostport2[1])", "response": "Returns true if the two addresses are in the host : port pair and the host is the same"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_openssl():\n    try:\n        open_ssl_exe = which(\"openssl\")\n        if not open_ssl_exe:\n            raise Exception(\"No openssl exe found in path\")\n\n        try:\n            # execute a an invalid command to get output with available options\n            # since openssl does not have a --help option unfortunately\n            execute_command([open_ssl_exe, \"s_client\", \"invalidDummyCommand\"])\n        except subprocess.CalledProcessError as e:\n            if \"fallback_scsv\" not in e.output:\n                raise Exception(\"openssl does not support TLS_FALLBACK_SCSV\")\n    except Exception as e:\n        raise MongoctlException(\"Unsupported OpenSSL. %s\" % e)", "response": "Validates OpenSSL to ensure it has TLS_FALLBACK_SCSV supported."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the member document against the current rs config", "response": "def validate_against_current_config(self, current_rs_conf):\n        \"\"\"\n        Validates the member document against current rs conf\n            1- If there is a member in current config with _id equals to my id\n                then ensure hosts addresses resolve to the same host\n\n            2- If there is a member in current config with host resolving to my\n               host then ensure that if my id is et then it\n               must equal member._id\n\n        \"\"\"\n\n        # if rs is not configured yet then there is nothing to validate\n        if not current_rs_conf:\n            return\n\n        my_host = self.get_host()\n        current_member_confs = current_rs_conf['members']\n        err = None\n        for curr_mem_conf in current_member_confs:\n            if (self.id and\n                        self.id == curr_mem_conf['_id'] and\n                    not is_same_address(my_host, curr_mem_conf['host'])):\n                err = (\"Member config is not consistent with current rs \"\n                       \"config. \\n%s\\n. Both have the sam _id but addresses\"\n                       \" '%s' and '%s' do not resolve to the same host.\" %\n                       (document_pretty_string(curr_mem_conf),\n                        my_host, curr_mem_conf['host'] ))\n\n            elif (is_same_address(my_host, curr_mem_conf['host']) and\n                      self.id and\n                          self.id != curr_mem_conf['_id']):\n                err = (\"Member config is not consistent with current rs \"\n                       \"config. \\n%s\\n. Both addresses\"\n                       \" '%s' and '%s' resolve to the same host but _ids '%s'\"\n                       \" and '%s' are not equal.\" %\n                       (document_pretty_string(curr_mem_conf),\n                        my_host, curr_mem_conf['host'],\n                        self.id, curr_mem_conf['_id']))\n\n        if err:\n            raise MongoctlException(\"Invalid member configuration:\\n%s \\n%s\" %\n                                    (self, err))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the best secondary member to be used for dumping.", "response": "def get_dump_best_secondary(self, max_repl_lag=None):\n        \"\"\"\n        Returns the best secondary member to be used for dumping\n        best = passives with least lags, if no passives then least lag\n        \"\"\"\n        secondary_lag_tuples = []\n\n        primary_member = self.get_primary_member()\n        if not primary_member:\n            raise MongoctlException(\"Unable to determine primary member for\"\n                                    \" cluster '%s'\" % self.id)\n\n        master_status = primary_member.get_server().get_member_rs_status()\n\n        if not master_status:\n            raise MongoctlException(\"Unable to determine replicaset status for\"\n                                    \" primary member '%s'\" %\n                                    primary_member.get_server().id)\n\n        for member in self.get_members():\n            if member.get_server().is_secondary():\n                repl_lag = member.get_server().get_repl_lag(master_status)\n                if max_repl_lag and  repl_lag > max_repl_lag:\n                    log_info(\"Excluding member '%s' because it's repl lag \"\n                             \"(in seconds)%s is more than max %s. \" %\n                             (member.get_server().id,\n                              repl_lag, max_repl_lag))\n                    continue\n                secondary_lag_tuples.append((member,repl_lag))\n\n        def best_secondary_comp(x, y):\n            x_mem, x_lag = x\n            y_mem, y_lag = y\n            if x_mem.is_passive():\n                if y_mem.is_passive():\n                    return x_lag - y_lag\n                else:\n                    return -1\n            elif y_mem.is_passive():\n                return 1\n            else:\n                return x_lag - y_lag\n\n        if secondary_lag_tuples:\n            secondary_lag_tuples.sort(best_secondary_comp)\n            return secondary_lag_tuples[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_replicaset_initialized(self):\n\n        # it's possible isMaster returns an \"incomplete\" result if we\n        # query a replica set member while it's loading the replica set config\n        # https://jira.mongodb.org/browse/SERVER-13458\n        # let's try to detect this state before proceeding\n        # seems like if the \"secondary\" field is present, but \"setName\" isn't,\n        # it's a good indicator that we just need to wait a bit\n        # add an uptime check in for good measure\n\n        for member in self.get_members():\n            server = member.get_server()\n\n            if server.has_joined_replica():\n                return True\n\n        return False", "response": "check if the replica set is initialized"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind an id for a member_conf where fom current members confs exists and returns the element s _id if it exists.", "response": "def match_member_id(self, member_conf, current_member_confs):\n        \"\"\"\n        Attempts to find an id for member_conf where fom current members confs\n        there exists a element.\n        Returns the id of an element of current confs\n        WHERE member_conf.host and element.host are EQUAL or map to same host\n        \"\"\"\n        if current_member_confs is None:\n            return None\n\n        for curr_mem_conf in current_member_confs:\n            if is_same_address(member_conf['host'], curr_mem_conf['host']):\n                return curr_mem_conf['_id']\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nseeds all users returned by get_seed_users() IF there are no users seed yet i.e. system.users collection is empty", "response": "def setup_server_users(server):\n    \"\"\"\n    Seeds all users returned by get_seed_users() IF there are no users seed yet\n    i.e. system.users collection is empty\n    \"\"\"\n    \"\"\"if not should_seed_users(server):\n        log_verbose(\"Not seeding users for server '%s'\" % server.id)\n        return\"\"\"\n\n    log_info(\"Checking if there are any users that need to be added for \"\n             \"server '%s'...\" % server.id)\n\n    seed_users = server.get_seed_users()\n\n    count_new_users = 0\n\n    # Note: If server member of a replica then don't setup admin\n    # users because primary server will do that at replinit\n\n    # Now create admin ones\n    if not server.is_slave():\n        count_new_users += setup_server_admin_users(server)\n\n    for dbname, db_seed_users in seed_users.items():\n        # create the admin ones last so we won't have an auth issue\n        if dbname in [\"admin\", \"local\"]:\n            continue\n        count_new_users += setup_server_db_users(server, dbname, db_seed_users)\n\n\n    if count_new_users > 0:\n        log_info(\"Added %s users.\" % count_new_users)\n    else:\n        log_verbose(\"Did not add any new users.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepend_global_admin_user(other_users, server):\n    cred0 = get_global_login_user(server, \"admin\")\n    if cred0 and cred0[\"username\"] and cred0[\"password\"]:\n        log_verbose(\"Seeding : CRED0 to the front of the line!\")\n        return [cred0] + other_users if other_users else [cred0]\n    else:\n        return other_users", "response": "Prepends the admin user to the front of the list of users"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_os_dist_info():\n\n    distribution = platform.dist()\n    dist_name = distribution[0].lower()\n    dist_version_str = distribution[1]\n    if dist_name and dist_version_str:\n        return dist_name, dist_version_str\n    else:\n        return None, None", "response": "Returns the distribution info and the version string of the current OS distribution"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverride command options with configdb address", "response": "def export_cmd_options(self, options_override=None, standalone=False):\n        \"\"\"\n            Override!\n        :return:\n        \"\"\"\n        cmd_options = super(MongosServer, self).export_cmd_options(\n            options_override=options_override)\n\n        # Add configServers arg\n        cluster = self.get_validate_cluster()\n\n        cmd_options[\"configdb\"] = cluster.get_config_db_address()\n\n        return cmd_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_mongo_version(self):\n        if self._mongo_version:\n            return self._mongo_version\n\n        mongo_version = self.read_current_mongo_version()\n\n        if not mongo_version:\n            mongo_version = self.get_configured_mongo_version()\n\n        self._mongo_version = mongo_version\n\n        return self._mongo_version", "response": "Gets the mongo version of the server if it is running otherwise returns the configured version"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nissuing a buildinfo command on the server", "response": "def get_server_build_info(self):\n        \"\"\"\n        issues a buildinfo command\n        \"\"\"\n        if self.is_online():\n            try:\n                return self.get_mongo_client().server_info()\n            except OperationFailure, ofe:\n                log_exception(ofe)\n                if \"there are no users authenticated\" in str(ofe):\n                    # this is a pymongo 3.6.1 regression where the buildinfo command fails on non authenticated client\n                    # fall-back to an authenticated client\n                    admin_db = self.get_db(\"admin\", no_auth=False)\n                    return admin_db.command(\"buildinfo\")\n            except Exception, e:\n                log_exception(e)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticate_db(self, db, dbname, retry=True):\n        log_verbose(\"Server '%s' attempting to authenticate to db '%s'\" % (self.id, dbname))\n        login_user = self.get_login_user(dbname)\n        username = None\n        password = None\n\n\n        auth_success = False\n\n        if login_user:\n            username = login_user[\"username\"]\n            if \"password\" in login_user:\n                password = login_user[\"password\"]\n\n        # have three attempts to authenticate\n        no_tries = 0\n\n        while not auth_success and no_tries < 3:\n            if not username:\n                username = read_username(dbname)\n            if not password:\n                password = self.lookup_password(dbname, username)\n                if not password:\n                    password = read_password(\"Enter password for user '%s\\%s'\"%\n                                             (dbname, username))\n\n            # if auth success then exit loop and memoize login\n            try:\n                auth_success = db.authenticate(username, password)\n                log_verbose(\"Authentication attempt #%s to db '%s' result: %s\" % (no_tries, dbname, auth_success))\n            except OperationFailure, ofe:\n                if \"auth fails\" in str(ofe):\n                    auth_success = False\n\n            if auth_success or not retry:\n                break\n            else:\n                log_error(\"Invalid login!\")\n                username = None\n                password = None\n\n            no_tries += 1\n\n        if auth_success:\n            self.set_login_user(dbname, username, password)\n            log_verbose(\"Authentication Succeeded!\")\n        else:\n            log_verbose(\"Authentication failed\")\n\n        return auth_success", "response": "Authenticate to the given database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the working login for a database", "response": "def get_working_login(self, database, username=None, password=None):\n        \"\"\"\n            authenticate to the specified database starting with specified\n            username/password (if present), try to return a successful login\n            within 3 attempts\n        \"\"\"\n        login_user = None\n\n\n        #  this will authenticate and update login user\n        self.get_db(database, username=username, password=password,\n                    never_auth_with_admin=True)\n\n        login_user = self.get_login_user(database)\n\n        if login_user:\n            username = login_user[\"username\"]\n            password = (login_user[\"password\"] if \"password\" in login_user\n                        else None)\n        return username, password"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef needs_to_auth(self, dbname):\n        log_debug(\"Checking if server '%s' needs to auth on  db '%s'....\" %\n                  (self.id, dbname))\n        try:\n            client = self.get_mongo_client()\n            db = client.get_database(dbname)\n            db.collection_names()\n            result = False\n        except (RuntimeError,Exception), e:\n            log_exception(e)\n            # updated for to handle auth failures from mongodb 3.6\n            result = \"authorized\" in str(e) or \"there are no users authenticated\" in str(e)\n\n        log_debug(\"needs_to_auth check for server '%s'  on db '%s' : %s\" %\n                  (self.id, dbname, result))\n        return result", "response": "Determines if the server needs to authenticate to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef needs_repl_key(self):\n        cluster = self.get_cluster()\n        return (self.supports_repl_key() and\n                cluster is not None and cluster.get_repl_key() is not None)", "response": "Check if we need a repl key for this user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef exact_or_minor_exe_version_match(executable_name,\n                                     exe_version_tuples,\n                                     version):\n    \"\"\"\n    IF there is an exact match then use it\n     OTHERWISE try to find a minor version match\n    \"\"\"\n    exe = exact_exe_version_match(executable_name,\n                                  exe_version_tuples,\n                                  version)\n\n    if not exe:\n        exe = minor_exe_version_match(executable_name,\n                                      exe_version_tuples,\n                                      version)\n    return exe", "response": "Try to find an exact match for the executable name and version tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the specified value is a server or cluster database address.", "response": "def is_server_or_cluster_db_address(value):\n    \"\"\"\n    checks if the specified value is in the form of\n    [server or cluster id][/database]\n    \"\"\"\n    # check if value is an id string\n    id_path = value.split(\"/\")\n    id = id_path[0]\n    return len(id_path) <= 2 and (repository.lookup_server(id) or\n                                  repository.lookup_cluster(id))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npause your program until a specific end time.", "response": "def until(time):\n    \"\"\"\n    Pause your program until a specific end time.\n    'time' is either a valid datetime object or unix timestamp in seconds (i.e. seconds since Unix epoch)\n    \"\"\"\n    end = time\n\n    # Convert datetime to unix timestamp and adjust for locality\n    if isinstance(time, datetime):\n        zoneDiff = pytime.time() - (datetime.now()- datetime(1970, 1, 1)).total_seconds()\n        end = (time - datetime(1970, 1, 1)).total_seconds() + zoneDiff\n\n    # Type check\n    if not isinstance(end, (int, float)):\n        raise Exception('The time parameter is not a number or datetime object')\n\n    # Now we wait\n    while True:\n        now = pytime.time()\n        diff = end - now\n\n        #\n        # Time is up!\n        #\n        if diff <= 0:\n            break\n        else:\n            # 'logarithmic' sleeping to minimize loop iterations\n            sleep(diff / 2)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef seconds(num):\n    now = pytime.time()\n    end = now + num\n    until(end)", "response": "Pause for this many seconds\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _pre_mongod_server_start(server, options_override=None):\n\n    lock_file_path = server.get_lock_file_path()\n\n    no_journal = (server.get_cmd_option(\"nojournal\") or\n                  (options_override and \"nojournal\" in options_override))\n    if (os.path.exists(lock_file_path) and\n            server.is_arbiter_server() and\n            no_journal):\n\n        log_warning(\"WARNING: Detected a lock file ('%s') for your server '%s'\"\n                    \" ; since this server is an arbiter, there is no need for\"\n                    \" repair or other action. Deleting mongod.lock and\"\n                    \" proceeding...\" % (lock_file_path, server.id))\n        try:\n            os.remove(lock_file_path)\n        except Exception, e:\n            log_exception(e)\n            raise MongoctlException(\"Error while trying to delete '%s'. \"\n                                    \"Cause: %s\" % (lock_file_path, e))", "response": "This function is called before the server starts."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprepares the server for use as configured.", "response": "def prepare_mongod_server(server):\n    \"\"\"\n     Contains post start server operations\n    \"\"\"\n    log_info(\"Preparing server '%s' for use as configured...\" %\n             server.id)\n\n    cluster = server.get_cluster()\n    # setup the local users if server supports that\n    if server.supports_local_users():\n        users.setup_server_local_users(server)\n\n    if not server.is_cluster_member() or server.is_standalone_config_server():\n        users.setup_server_users(server)\n\n    if cluster and server.is_primary():\n        users.setup_cluster_users(cluster, server)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the less stringent rlimit value.", "response": "def _rlimit_min(one_val, nother_val):\n    \"\"\"Returns the more stringent rlimit value.  -1 means no limit.\"\"\"\n    if one_val < 0 or nother_val < 0 :\n        return max(one_val, nother_val)\n    else:\n        return min(one_val, nother_val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef generate_start_command(server, options_override=None, standalone=False):\n    command = []\n\n    if mongod_needs_numactl():\n        log_info(\"Running on a NUMA machine...\")\n        command = apply_numactl(command)\n\n    # append the mongod executable\n    command.append(get_server_executable(server))\n\n    # create the command args\n    cmd_options = server.export_cmd_options(options_override=options_override,\n                                            standalone=standalone)\n\n    command.extend(options_to_command_args(cmd_options))\n    return command", "response": "Generate the command to start the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\noverride Get server home directory.", "response": "def get_server_home(self):\n        \"\"\"\n            Override!\n        :return:\n        \"\"\"\n        home_dir = super(MongodServer, self).get_server_home()\n        if not home_dir:\n            home_dir = self.get_db_path()\n\n        return home_dir"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef export_cmd_options(self, options_override=None, standalone=False):\n        cmd_options = super(MongodServer, self).export_cmd_options(\n            options_override=options_override)\n\n        # reset some props to exporting vals\n        cmd_options['dbpath'] = self.get_db_path()\n\n        if 'repairpath' in cmd_options:\n            cmd_options['repairpath'] = resolve_path(cmd_options['repairpath'])\n\n        # Add ReplicaSet args if a cluster is configured\n\n        repl_cluster = self.get_replicaset_cluster()\n        if repl_cluster is not None:\n            if \"replSet\" not in cmd_options:\n                cmd_options[\"replSet\"] = repl_cluster.id\n\n        # apply standalone if specified\n        if standalone:\n            if \"replSet\" in cmd_options:\n                del cmd_options[\"replSet\"]\n            if \"keyFile\" in cmd_options:\n                del cmd_options[\"keyFile\"]\n\n        # add configsvr as needed\n        if self.is_config_server():\n            cmd_options[\"configsvr\"] = True\n\n        # add shardsvr as needed\n        if self.is_shard_server():\n            cmd_options[\"shardsvr\"] = True\n\n        # remove wiredTigerCacheSizeGB if its not an int since we set it in runtime parameter\n        #  wiredTigerEngineRuntimeConfig in this case\n        if \"wiredTigerCacheSizeGB\" in cmd_options and not isinstance(self.get_cmd_option(\"wiredTigerCacheSizeGB\"), int):\n            del cmd_options[\"wiredTigerCacheSizeGB\"]\n\n        return cmd_options", "response": "Override the default command options for MongodServer."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_seed_users(self):\n        seed_users = super(MongodServer, self).get_seed_users()\n        # exempt database users for config servers\n        if seed_users and self.is_config_server():\n            for dbname in seed_users.keys():\n                if dbname not in [\"admin\", \"local\", \"config\"]:\n                    del seed_users[dbname]\n\n        return seed_users", "response": "Override! Get seed users."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_repl_lag(self, master_status):\n        member_status = self.get_member_rs_status()\n\n        if not member_status:\n            raise MongoctlException(\"Unable to determine replicaset status for\"\n                                    \" member '%s'\" %\n                                    self.id)\n\n        return get_member_repl_lag(member_status, master_status)", "response": "Returns the lag between two members from rs. status and master_status."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mongo_client(*args, **kwargs):\n\n    kwargs = kwargs or {}\n    connection_timeout_ms = kwargs.get(\"connectTimeoutMS\") or CONN_TIMEOUT_MS\n\n    kwargs.update({\n        \"socketTimeoutMS\": connection_timeout_ms,\n        \"connectTimeoutMS\": connection_timeout_ms,\n        \"maxPoolSize\": 1\n    })\n\n    if pymongo.get_version_string().startswith(\"3.2\"):\n        if kwargs and kwargs.get(\"serverSelectionTimeoutMS\") is None:\n            kwargs[\"connect\"] = True\n            kwargs[\"serverSelectionTimeoutMS\"] = connection_timeout_ms\n\n    return _mongo_client(*args, **kwargs)", "response": "wrapper around mongo client\n    :param args:\n    :param kwargs:\n    :return:"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a NetJSON NetworkGraph object to a NetworkX Graph object which is then returned.", "response": "def parse(self, data):\n        \"\"\"\n        Converts a NetJSON 'NetworkGraph' object\n        to a NetworkX Graph object,which is then returned.\n        Additionally checks for protocol version, revision and metric.\n        \"\"\"\n        graph = self._init_graph()\n        # ensure is NetJSON NetworkGraph object\n        if 'type' not in data or data['type'] != 'NetworkGraph':\n            raise ParserError('Parse error, not a NetworkGraph object')\n        # ensure required keys are present\n        required_keys = ['protocol', 'version', 'metric', 'nodes', 'links']\n        for key in required_keys:\n            if key not in data:\n                raise ParserError('Parse error, \"{0}\" key not found'.format(key))\n\n        # store metadata\n        self.protocol = data['protocol']\n        self.version = data['version']\n        self.revision = data.get('revision')  # optional\n        self.metric = data['metric']\n\n        # create graph\n        for node in data['nodes']:\n            graph.add_node(node['id'],\n                           label=node['label'] if 'label' in node else None,\n                           local_addresses=node.get('local_addresses', []),\n                           **node.get('properties', {}))\n        for link in data['links']:\n            try:\n                source = link[\"source\"]\n                dest = link[\"target\"]\n                cost = link[\"cost\"]\n            except KeyError as e:\n                raise ParserError('Parse error, \"%s\" key not found' % e)\n            properties = link.get('properties', {})\n            graph.add_edge(source, dest, weight=cost, **properties)\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a OpenVPN JSON object to a NetworkX Graph object which is then returned.", "response": "def parse(self, data):\n        \"\"\"\n        Converts a OpenVPN JSON to a NetworkX Graph object\n        which is then returned.\n        \"\"\"\n        # initialize graph and list of aggregated nodes\n        graph = self._init_graph()\n        server = self._server_common_name\n        # add server (central node) to graph\n        graph.add_node(server)\n        # data may be empty\n        if data is None:\n            clients = []\n            links = []\n        else:\n            clients = data.client_list.values()\n            links = data.routing_table.values()\n        # add clients in graph as nodes\n        for client in clients:\n            if client.common_name == 'UNDEF':\n                continue\n            client_properties = {\n                'label': client.common_name,\n                'real_address': str(client.real_address.host),\n                'port': int(client.real_address.port),\n                'connected_since': client.connected_since.strftime('%Y-%m-%dT%H:%M:%SZ'),\n                'bytes_received': int(client.bytes_received),\n                'bytes_sent': int(client.bytes_sent)\n            }\n            local_addresses = [\n                str(route.virtual_address)\n                for route in data.routing_table.values()\n                if route.real_address == client.real_address\n            ]\n            if local_addresses:\n                client_properties['local_addresses'] = local_addresses\n            graph.add_node(str(client.real_address.host), **client_properties)\n        # add links in routing table to graph\n        for link in links:\n            if link.common_name == 'UNDEF':\n                continue\n            graph.add_edge(server, str(link.real_address.host), weight=1)\n        return graph"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_python(self, data):\n        try:\n            return super(BatmanParser, self).to_python(data)\n        except ConversionException as e:\n            return self._txtinfo_to_python(e.data)", "response": "Converts the data into a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts txtinfo format to python list of items", "response": "def _txtinfo_to_python(self, data):\n        \"\"\"\n        Converts txtinfo format to python\n        \"\"\"\n        self._format = 'txtinfo'\n        # find interesting section\n        lines = data.split('\\n')\n        try:\n            start = lines.index('Table: Topology') + 2\n        except ValueError:\n            raise ParserError('Unrecognized format')\n        topology_lines = [line for line in lines[start:] if line]\n        # convert to python list\n        parsed_lines = []\n        for line in topology_lines:\n            values = line.split(' ')\n            parsed_lines.append({\n                'source': values[0],\n                'target': values[1],\n                'cost': float(values[4])\n            })\n        return parsed_lines"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_primary_address(self, mac_address, node_list):\n        for local_addresses in node_list:\n            if mac_address in local_addresses:\n                return local_addresses[0]\n        return mac_address", "response": "Returns the primary mac address associated with a secondary one."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of main mac addresses.", "response": "def _get_aggregated_node_list(self, data):\n        \"\"\"\n        Returns list of main and secondary mac addresses.\n        \"\"\"\n        node_list = []\n        for node in data:\n            local_addresses = [node['primary']]\n            if 'secondary' in node:\n                local_addresses += node['secondary']\n            node_list.append(local_addresses)\n        return node_list"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the data into a dict.", "response": "def parse(self, data):\n        \"\"\"\n        Calls the right method depending on the format,\n        which can be one of the wollowing:\n            * alfred_vis\n            * txtinfo\n        \"\"\"\n        method = getattr(self, '_parse_{0}'.format(self._format))\n        return method(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_alfred_vis(self, data):\n        # initialize graph and list of aggregated nodes\n        graph = self._init_graph()\n        if 'source_version' in data:\n            self.version = data['source_version']\n        if 'vis' not in data:\n            raise ParserError('Parse error, \"vis\" key not found')\n        node_list = self._get_aggregated_node_list(data['vis'])\n\n        # loop over topology section and create networkx graph\n        for node in data[\"vis\"]:\n            for neigh in node[\"neighbors\"]:\n                graph.add_node(node['primary'], **{\n                    'local_addresses': node.get('secondary', []),\n                    'clients': node.get('clients', [])\n                })\n                primary_neigh = self._get_primary_address(neigh['neighbor'],\n                                                          node_list)\n                # networkx automatically ignores duplicated edges\n                graph.add_edge(node['primary'],\n                               primary_neigh,\n                               weight=float(neigh['metric']))\n        return graph", "response": "Converts a alfred - vis JSON object to a NetworkX Graph object which is then returned."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_txtinfo(self, data):\n        graph = self._init_graph()\n        for link in data:\n            graph.add_edge(link['source'],\n                           link['target'],\n                           weight=link['cost'])\n        return graph", "response": "Converts the python list returned by self. _txtinfo_to_python to a NetworkX Graph object which is then returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the input data and converts it into a Python data structure.", "response": "def to_python(self, data):\n        \"\"\"\n        Parses the input data and converts it into a Python data structure\n        Input data might be:\n            * a path which points to a JSON file\n            * a URL which points to a JSON file\n              (supported schemes: http, https, telnet)\n            * a JSON formatted string\n            * a dict representing a JSON structure\n        \"\"\"\n        if isinstance(data, dict):\n            return data\n        elif isinstance(data, six.string_types):\n            # assuming is JSON\n            try:\n                return json.loads(data)\n            except ValueError:\n                pass\n        raise ConversionException('Could not recognize format', data=data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef json(self, dict=False, **kwargs):\n        try:\n            graph = self.graph\n        except AttributeError:\n            raise NotImplementedError()\n        return _netjson_networkgraph(self.protocol,\n                                     self.version,\n                                     self.revision,\n                                     self.metric,\n                                     graph.nodes(data=True),\n                                     graph.edges(data=True),\n                                     dict,\n                                     **kwargs)", "response": "Outputs NetJSON format for this object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diff(old, new):\n    protocol = new.protocol\n    version = new.version\n    revision = new.revision\n    metric = new.metric\n    # calculate differences\n    in_both = _find_unchanged(old.graph, new.graph)\n    added_nodes, added_edges = _make_diff(old.graph, new.graph, in_both)\n    removed_nodes, removed_edges = _make_diff(new.graph, old.graph, in_both)\n    changed_edges = _find_changed(old.graph, new.graph, in_both)\n    # create netjson objects\n    # or assign None if no changes\n    if added_nodes.nodes() or added_edges.edges():\n        added = _netjson_networkgraph(protocol, version, revision, metric,\n                                      added_nodes.nodes(data=True),\n                                      added_edges.edges(data=True),\n                                      dict=True)\n    else:\n        added = None\n    if removed_nodes.nodes() or removed_edges.edges():\n        removed = _netjson_networkgraph(protocol, version, revision, metric,\n                                        removed_nodes.nodes(data=True),\n                                        removed_edges.edges(data=True),\n                                        dict=True)\n    else:\n        removed = None\n    if changed_edges:\n        changed = _netjson_networkgraph(protocol, version, revision, metric,\n                                        [],\n                                        changed_edges,\n                                        dict=True)\n    else:\n        changed = None\n    return OrderedDict((\n        ('added', added),\n        ('removed', removed),\n        ('changed', changed)\n    ))", "response": "Returns a dictionary of differences between two NetworkGraph compatible format"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_diff(old, new, both):\n    # make a copy of old topology to avoid tampering with it\n    diff_edges = new.copy()\n    not_different = [tuple(edge) for edge in both]\n    diff_edges.remove_edges_from(not_different)\n    # repeat operation with nodes\n    diff_nodes = new.copy()\n    not_different = []\n    for new_node in new.nodes():\n        if new_node in old.nodes():\n            not_different.append(new_node)\n    diff_nodes.remove_nodes_from(not_different)\n    # return tuple with modified graphs\n    # one for nodes and one for links\n    return diff_nodes, diff_edges", "response": "Calculates differences between two topologies old and new"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _find_unchanged(old, new):\n    edges = []\n    old_edges = [set(edge) for edge in old.edges()]\n    new_edges = [set(edge) for edge in new.edges()]\n    for old_edge in old_edges:\n        if old_edge in new_edges:\n            edges.append(set(old_edge))\n    return edges", "response": "Find the edges that are in both old and new."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_changed(old, new, both):\n    # create two list of sets of old and new edges including cost\n    old_edges = []\n    for edge in old.edges(data=True):\n        # skip links that are not in both\n        if set((edge[0], edge[1])) not in both:\n            continue\n        # wrap cost in tuple so it will be recognizable\n        cost = (edge[2]['weight'],)\n        old_edges.append(set((edge[0], edge[1], cost)))\n    new_edges = []\n    for edge in new.edges(data=True):\n        # skip links that are not in both\n        if set((edge[0], edge[1])) not in both:\n            continue\n        # wrap cost in tuple so it will be recognizable\n        cost = (edge[2]['weight'],)\n        new_edges.append(set((edge[0], edge[1], cost)))\n    # find out which edge changed\n    changed = []\n    for new_edge in new_edges:\n        if new_edge not in old_edges:\n            # new_edge is a set, convert it to list\n            new_edge = list(new_edge)\n            for item in new_edge:\n                if isinstance(item, tuple):\n                    # unwrap cost from tuple and put it in a dict\n                    cost = {'weight': item[0]}\n                    new_edge.remove(item)\n            changed.append((new_edge[0], new_edge[1], cost))\n    return changed", "response": "finds links that have changed cost\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, data):\n        # initialize graph and list of aggregated nodes\n        graph = self._init_graph()\n        if len(data) != 0:\n            if \"links\" not in data[0]:\n                raise ParserError('Parse error, \"links\" key not found')\n        # loop over topology section and create networkx graph\n        # this data structure does not contain cost information, so we set it as 1\n        for node in data:\n            for link in node['links']:\n                cost = (link['txRate'] + link['rxRate']) / 2.0\n                graph.add_edge(node['name'],\n                               link['name'],\n                               weight=cost,\n                               tx_rate=link['txRate'],\n                               rx_rate=link['rxRate'])\n        return graph", "response": "Converts a BMX6 b6m JSON to a NetworkX Graph object which is then returned."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, data):\n        graph = self._init_graph()\n        # loop over links and create networkx graph\n        # Add only working nodes with working links\n        for link in data.get_inner_links():\n            if link.status != libcnml.libcnml.Status.WORKING:\n                continue\n            interface_a, interface_b = link.getLinkedInterfaces()\n            source = interface_a.ipv4\n            dest = interface_b.ipv4\n            # add link to Graph\n            graph.add_edge(source, dest, weight=1)\n        return graph", "response": "Converts a CNML structure to a NetworkX Graph object which is then returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_python(self, data):\n        try:\n            return super(OlsrParser, self).to_python(data)\n        except ConversionException as e:\n            return self._txtinfo_to_jsoninfo(e.data)", "response": "Converts the data to a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, data):\n        graph = self._init_graph()\n        if 'topology' not in data:\n            raise ParserError('Parse error, \"topology\" key not found')\n        elif 'mid' not in data:\n            raise ParserError('Parse error, \"mid\" key not found')\n\n        # determine version and revision\n        if 'config' in data:\n            version_info = data['config']['olsrdVersion'].replace(' ', '').split('-')\n            self.version = version_info[1]\n            # try to get only the git hash\n            if 'hash_' in version_info[-1]:\n                version_info[-1] = version_info[-1].split('hash_')[-1]\n            self.revision = version_info[-1]\n\n        # process alias list\n        alias_dict = {}\n        for node in data['mid']:\n            local_addresses = [alias['ipAddress'] for alias in node['aliases']]\n            alias_dict[node['ipAddress']] = local_addresses\n\n        # loop over topology section and create networkx graph\n        for link in data['topology']:\n            try:\n                source = link['lastHopIP']\n                target = link['destinationIP']\n                cost = link['tcEdgeCost']\n                properties = {\n                    'link_quality': link['linkQuality'],\n                    'neighbor_link_quality': link['neighborLinkQuality']\n                }\n            except KeyError as e:\n                raise ParserError('Parse error, \"%s\" key not found' % e)\n            # add nodes with their local_addresses\n            for node in [source, target]:\n                if node not in alias_dict:\n                    continue\n                graph.add_node(node, local_addresses=alias_dict[node])\n            # skip links with infinite cost\n            if cost == float('inf'):\n                continue\n            # original olsrd cost (jsoninfo multiplies by 1024)\n            cost = float(cost) / 1024.0\n            # add link to Graph\n            graph.add_edge(source, target, weight=cost, **properties)\n        return graph", "response": "Parses a dict representing an OLSR 0. 6. x topology into a NetworkX Graph object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _txtinfo_to_jsoninfo(self, data):\n        # replace INFINITE with inf, which is convertible to float\n        data = data.replace('INFINITE', 'inf')\n        # find interesting section\n        lines = data.split('\\n')\n\n        # process links in topology section\n        try:\n            start = lines.index('Table: Topology') + 2\n            end = lines[start:].index('') + start\n        except ValueError:\n            raise ParserError('Unrecognized format')\n        topology_lines = lines[start:end]\n        # convert topology section to jsoninfo format\n        topology = []\n        for line in topology_lines:\n            values = line.split('\\t')\n            topology.append({\n                'destinationIP': values[0],\n                'lastHopIP': values[1],\n                'linkQuality': float(values[2]),\n                'neighborLinkQuality': float(values[3]),\n                'tcEdgeCost': float(values[4]) * 1024.0\n            })\n\n        # process alias (MID) section\n        try:\n            start = lines.index('Table: MID') + 2\n            end = lines[start:].index('') + start\n        except ValueError:\n            raise ParserError('Unrecognized format')\n        mid_lines = lines[start:end]\n        # convert mid section to jsoninfo format\n        mid = []\n        for line in mid_lines:\n            values = line.split('\\t')\n            node = values[0]\n            aliases = values[1].split(';')\n            mid.append({\n                'ipAddress': node,\n                'aliases': [{'ipAddress': alias} for alias in aliases]\n            })\n\n        return {\n            'topology': topology,\n            'mid': mid\n        }", "response": "converts olsr 1 txtinfo format to jsoninfo format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to a JIRA server.", "response": "def connect_to_jira(self, JIRAUsername=None,\r\n                        JIRAPassword=None, options=None):\r\n        \"\"\"\r\n        Connect to a JIRA server.\r\n\r\n            Arguments:\r\n                |  JIRAUsername (string)  \t|  (Optional) A JIRA Username you wish to authenticate with, will authorise with anonymous account if left empty      \t\t\t\t|\r\n                |  JIRAPassword (string)  \t|  (Optional) If a username was specified and a password is not the user will be prompted for password at runtime \t\t\t\t\t|\r\n                |  options (dictionary) \t|  (Optional) A dictionary of options that the JIRA connection will be initialied with \t                                            |\r\n\r\n            This must be called first to be able to do most JIRA actions such as creating a new issue and assigning users.\r\n            When connecting to JIRA you may need to authenticate a user. This can be done by passing in Username and Password as parameters. However, should you wish to not have a sensitive password saved in a file,  an option is available to not pass in a Password and a prompt will appear asking for the JIRA password at runtime.\r\n\r\n\r\n            'connect to jira' can be called on its own and will default options to:\r\n                '{'rest_api_version': '2', 'verify': True,\r\n                'server': 'http://localhost:2990/jira', 'headers': {'X-Atlassian-Token': 'nocheck'},\r\n                'rest_path': 'api', 'resilient': False, 'async': False}'\r\n            These can all be customised as needed.\r\n\r\n            Examples:\r\n                |  *Keyword*        |  *Parameters* | \t\t\t\t\t\t\t\t\t| \t\t\t\t\t\t\t\t\t|\r\n                |  connect to jira  |  \t\t\t\t|           \t\t\t\t\t\t|                          \t\t\t|\r\n                |  connect to jira  |  asimmons\t    | options= {'http://devjira01'} \t|    \t\t\t\t\t\t\t\t|\r\n                |  connect to jira  |  asimmond \t| MyP@ssword \t\t\t\t\t\t| {'server': http://devjira01'} \t|\r\n        \"\"\"\r\n\r\n        if JIRAUsername is not None and (JIRAPassword is \"\" or JIRAPassword is None):\r\n            JIRAPassword = getpass.getpass(\"\\nJIRA Password: \")\r\n\t\t\r\n        print JIRAUsername\r\n\r\n        JIRAOptions = eval(options)\r\n        if JIRAUsername is None:\r\n            try:\r\n                self.jira = JIRA(JIRAOptions)\r\n            except:\r\n                sys.__stdout__.write(\"\\nAuthentication to JIRA unsuccessful. Ensure the user used has sufficient access and that Username and Password were correct\\n\\n\")\r\n                sys.exit(1)\r\n\r\n        else:\r\n            try:\r\n                self.jira = JIRA(options=JIRAOptions, basic_auth=(str(JIRAUsername),\r\n                                 str(JIRAPassword)))\r\n            except:\r\n                sys.__stdout__.write(\"\\nAuthentication to JIRA unsuccessful. Ensure the user used has sufficient access and that Username and Password were correct\\n\\n\")\r\n                sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new JIRA issue.", "response": "def create_issue(self, issue_field_dict, assign_current_user=False):\r\n        \"\"\"\r\n        Creates a new JIRA issue.\r\n\r\n            Arguments:\r\n                |  issue_field_dict (string)  \t\t\t| A dictionary in the form of a string that the user can specify the issues fields and field values \t\t\t|\r\n                |  assign_current_user (string/bool)  \t| (Optional) A flag to assign the current user to the issue once it is successfully created, defaults to False\t|\r\n\r\n            Will create a new issue and returns an Issue Key.\r\n            The user will use the issue_field_dict variable to specify the issues field and their respective values. This must be in the form of a string written as a dictionary\r\n                e.g. {'FieldName':'FieldValue'}\r\n\r\n            The field value can also be another dictionary (in some field cases this is needed)\r\n                e.g. {'FieldName1':{'key':'value'}, 'FieldName2':FieldValue, 'FieldName3':{'name':'value'}}\r\n\r\n            This Create Issue Example page (https://developer.atlassian.com/display/JIRADEV/JIRA+REST+API+Example+-+Create+Issue) is full of useful information in what is required for creating issues, including customfields and issue field value types, it is very important to get the value type right or an error will be thrown.\r\n\r\n\r\n            Examples:\r\n                |  *Keyword*        \t|  *Parameters*   \t| \t\t\t\t\t\t\t\t\t\t\t\t\t\t| \t\t|\r\n                |  ${issue_field_dict} \t|  {'project':{'key': 'PROJ'}, 'summary':'Create New Issue', 'description':'Creating a new issue', 'issuetype':{'name': 'Bug'}} |    |\r\n                |  connect to jira      |  asimmons         | options= {'http://devjira01'}                         |       |\r\n                |  ${issue}\t\t\t\t|  create issue \t|  ${issue_field_dict}\t\t\t\t\t\t\t\t\t|      \t|\r\n\r\n                |  connect to jira      |  asimmons         | options= {'http://devjira01'}                         |  \t\t|\r\n                |  ${issue}\t\t\t\t|  create issue \t|  ${issue_field_dict}\t\t\t\t\t\t\t\t\t|  True |\r\n        \"\"\"\r\n        issue_field_dict = eval(str(issue_field_dict))\r\n        print issue_field_dict\r\n\r\n        new_issue = self.jira.create_issue(issue_field_dict)\r\n        if assign_current_user is True:\r\n            self.assign_user_to_issue(new_issue, self.jira.current_user())\r\n        return new_issue"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a link between two issues.", "response": "def create_issue_link(self, link_type, inwardissue,\r\n                          outwardissue, comment=None):\r\n        \"\"\"\r\n        Create a link between two issues.\r\n\r\n            Arguments:\r\n                |  link_type (string)  \t| The type of link\t\t\t\t\t\t\t\t\t|\r\n                |  inwardissue (string)  \t| The issue to link from  \t\t\t\t\t\t\t|\r\n                |  outwardissue (string)  \t| The issue to link to \t\t\t\t\t\t\t\t|\r\n                |  comment (string)  \t\t| (Optional) A comment to add when joining issues\t|\r\n\r\n            Example:\r\n                |  *Keyword*        \t|  *Parameters* | \t\t\t\t\t\t\t\t\t| \t\t\t|\r\n                |  connect to jira      |  asimmons     | options= {'http://devjira01'}     |  \t\t\t|\r\n                |  ${issue}\t\t\t\t|  create issue |  ${issue_field_dict}\t\t\t\t|  True \t|\r\n                |  create issue link\t|  relates to   |  ${issue} \t\t\t\t\t\t|  PROJ-385\t|\r\n        \"\"\"\r\n        self.jira.create_issue_link(type=link_type,\r\n                                    inwardIssue=str(inwardissue),\r\n                                    outwardIssue=str(outwardissue))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a user to an existing issue", "response": "def assign_user_to_issue(self, issue, JIRAUsername):\r\n    # TODO: Review docs\r\n        \"\"\"\r\n        Adds a user to a specified issue's watcher list\r\n\r\n        Arguments:\r\n            |  issue (string)  \t\t| A JIRA Issue that a user needs to be assigned to, can be an issue ID or Key\t\t|\r\n            |  JIRAUsername (string)  \t| A JIRA Username to assign a user to an issue   \t\t\t\t\t\t\t\t\t|\r\n\r\n        Example:\r\n           |  *Keyword*        \t\t|  *Parameters* | \t\t\t\t\t\t\t\t\t|\r\n           |  connect to jira       |  asimmons     | options= {'http://devjira01'}     |\r\n           |  ${issue}\t\t\t\t|  create issue |  ${issue_field_dict}\t\t\t\t|\r\n           |  assign user to issue\t|  ${issue}\t\t|  aSample \t\t\t\t\t\t\t|\r\n        \"\"\"\r\n        self.jira.assign_issue(issue=issue, assignee=JIRAUsername)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a user to a specified issue s watcher list", "response": "def add_watcher_to_issue(self, issue, JIRAUsername):\r\n        \"\"\"\r\n        Adds a user to a specified issue's watcher list.\r\n\r\n        Arguments:\r\n            |  issue (string)  \t\t| A JIRA Issue that a watcher needs added to, can be an issue ID or Key\t\t|\r\n            |  JIRAUsername (string)  \t| A JIRA Username to add as a watcher to an issue   \t\t\t\t\t|\r\n\r\n        Example:\r\n            |  *Keyword*        \t|  *Parameters* | \t\t\t\t\t\t\t\t|\t\t|\r\n            |  connect to jira  |  asimmons     | options= {'http://devjira01'}     | \t\t|\r\n            |  ${issue}\t\t\t\t|  create issue |  ${issue_field_dict}\t\t\t|  True |\r\n            |  add watcher to issue\t|  ${issue}\t\t|  aSample \t\t\t\t\t\t| \t\t|\r\n\r\n        \"\"\"\r\n        self.jira.add_watcher(issue=issue, watcher=JIRAUsername)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_comment_to_issue(self, issue, comment, visibility=None):\r\n        self.jira.add_comment(issue=issue, body=comment)", "response": "Adds a comment to an existing issue"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_attachment_to_issue(self, issue, attachment, filename=None):\r\n        self.jira.add_attachment(issue=issue, attachment=attachment,\r\n                                 filename=filename)", "response": "Uploads and attaches a file to an existing JIRA issue."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nformatting the log record.", "response": "def format(self, record):\n        \"\"\"\n        :param logging.LogRecord record:\n        \"\"\"\n        super(HtmlFormatter, self).format(record)\n\n        if record.funcName:\n            record.funcName = escape_html(str(record.funcName))\n        if record.name:\n            record.name = escape_html(str(record.name))\n        if record.msg:\n            record.msg = escape_html(record.getMessage())\n        if self.use_emoji:\n            if record.levelno == logging.DEBUG:\n                record.levelname += ' ' + EMOJI.WHITE_CIRCLE\n            elif record.levelno == logging.INFO:\n                record.levelname += ' ' + EMOJI.BLUE_CIRCLE\n            else:\n                record.levelname += ' ' + EMOJI.RED_CIRCLE\n\n        if hasattr(self, '_style'):\n            return self._style.format(record)\n        else:\n            # py2.7 branch\n            return self._fmt % record.__dict__"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_releases(data, **kwargs):\n    if \"versions\" in data:\n        return sorted(data[\"versions\"].keys(), key=lambda v: parse(v), reverse=True)\n    return []", "response": "Get all releases from pypi meta data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urls(session, name, data, find_changelogs_fn, **kwargs):\n    # if this package has valid meta data, build up a list of URL candidates we can possibly\n    # search for changelogs on\n    if \"versions\" in data:\n        candidates = set()\n        for version, item in data[\"versions\"].items():\n            if \"homepage\" in item and item[\"homepage\"] is not None:\n                if isinstance(item[\"homepage\"], list):\n                    candidates.add(*item[\"homepage\"])\n                else:\n                    candidates.add(item[\"homepage\"])\n            if \"repository\" in item and item[\"repository\"] is not None:\n                if \"url\" in item[\"repository\"]:\n                    repo = item[\"repository\"][\"url\"]\n                elif \"path\" in item[\"repository\"]:\n                    repo = item[\"repository\"][\"path\"]\n                else:\n                    continue\n                repo = repo.replace(\"git://\", \"https://\").replace(\".git\", \"\")\n                candidates.add(repo)\n        return find_changelogs_fn(session=session, name=name, candidates=candidates)\n    return set(), set()", "response": "Gets URLs to changelogs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(name, content, releases, get_head_fn):\n    changelog = {}\n    releases = frozenset(releases)\n    head = False\n    for line in content.splitlines():\n        new_head = get_head_fn(name=name, line=line, releases=releases)\n        if new_head:\n            head = new_head\n            changelog[head] = \"\"\n            continue\n        if not head:\n            continue\n        line = line.replace(\"@\", \"\")\n        line = line.replace(\"#\", \"\")\n        changelog[head] += line + \"\\n\"\n    return changelog", "response": "Parses the given content for a valid changelog\n   ."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if line is a head of the package name and returns the version of the release.", "response": "def get_head(name, line, releases):\n    \"\"\"\n    Checks if `line` is a head\n    :param name: str, package name\n    :param line: str, line\n    :param releases: list, releases\n    :return: str, version if this is a valid head, False otherwise\n    \"\"\"\n    if not line:\n        return False\n    # if this line begins with an invalid starting character, return early.\n    # invalid characters are those used by various markup languages to introduce a new\n    # new list item\n    for char in INVALID_LINE_START:\n        # markdown uses ** for bold text, we also want to make sure to not exclude lines\n        # that contain a release\n        if line.startswith(char) and not line.startswith(\"**\") and not \"release\" in line.lower():\n            return False\n    # if this line ends with a \".\" this isn't a valid head, return early.\n    for char in INVALID_LINE_ENDS:\n        if line.endswith(char):\n            return False\n\n    # if the line contains \"python\", it is not a valid head. It's more likely that the mantainers\n    # are talking about a Python release in general.\n    # Note the leading ' ' to not exclude lines like python-foolibrary\n    if 'python ' in line.lower():\n        return False\n\n    # Our goal is to find a somewhat parseable line. For this to work, we need to remove all\n    # parts that are not needed so that:\n    # release (12/12/2016) v2.0.3\n    # becomes something like\n    # 12 12 2016 v2.0.3\n\n    # remove all needless clutter from the line, but preserve characters that are used as\n    # seperators like \"/\" and \"\\\".\n    line = line.replace(\"/\", \" \").replace(\"\\\\\", \" \")\n    uncluttered = re.sub(\"[^0123456789. a-zA-Z]\", \"\", line).strip().lower()\n\n    # we are looking for a valid head here. If the head contains \"release\" or \"version\" we are\n    # pretty close but don't want them included when we try to parse the version. Remove them.\n    for intro in COMMON_RELEASE_INTRODUCTION:\n        if uncluttered.startswith(intro):\n            uncluttered = uncluttered.replace(intro, \"\")\n    # some projects use the project name as a prefix, remove it\n    uncluttered_name = re.sub(\"[^0123456789. a-zA-Z]\", \"\", name).strip().lower()\n    uncluttered = uncluttered.replace(uncluttered_name, \"\").strip()\n    # now that all the clutter is removed, the line should be relatively short. If this is a valid\n    # head the only thing left should be the version and possibly some datestamp. We are going\n    # to count the length and assume a length of 8 for the version part, 8 for the datestamp and\n    # 2 as a safety. Leaving us with a max line length of 18\n    #if len(uncluttered) > 40:\n    #    return False\n\n    # split the line in parts and sort these parts by \".\" count in reversed order. This turns a\n    # line like \"12 12 2016 v2.0.3 into ['v2.0.3', \"12\", \"12\", \"2016\"]\n    parts = uncluttered.split(\" \")\n\n    # if a line contains more than 6 parts, it's unlikely that this is a valid head\n    if len(parts) >= 8:\n        # nevertheless: if there's a '.' in one of the first three items, we might be able to\n        # find a valid head here.\n        if not (\".\" in parts[0] or \".\" in parts[1] or \".\" in parts[2]):\n            return False\n\n    if len(parts) > 1:\n        parts = parts[::len(parts)-1]\n        parts.sort(key=lambda s: \".\" in s, reverse=True)\n    # loop over all our parts an find a parseable version\n    for part in parts:\n        # remove the \"v\" prefix as it is not parseable\n        if part.startswith(\"v\"):\n            part = part[1:]\n        # if there is no \".\" in this part, continue with the next one\n        if \".\" not in part:\n            continue\n        # looking good so far, return the version if it is parseable\n        try:\n            Version(part)\n            return part\n        except InvalidVersion as e:\n            pass\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the given commit log into a dict.", "response": "def parse_commit_log(name, content, releases, get_head_fn):\n    \"\"\"\n    Parses the given commit log\n    :param name: str, package name\n    :param content: list, directory paths\n    :param releases: list, releases\n    :param get_head_fn: function\n    :return: dict, changelog\n    \"\"\"\n    log = \"\"\n    raw_log = \"\"\n    for path, _ in content:\n        log += \"\\n\".join(changelog(repository=GitRepos(path), tag_filter_regexp=r\"v?\\d+\\.\\d+(\\.\\d+)?\"))\n        raw_log += \"\\n\" + subprocess.check_output(\n            [\"git\", \"-C\", path, \"--no-pager\", \"log\", \"--decorate\"]).decode(\"utf-8\")\n        shutil.rmtree(path)\n    log = parse(name, log, releases, get_head_fn)\n\n    return log, raw_log"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading custom functions from custom. py.", "response": "def _load_custom_functions(vendor, name):\n    \"\"\"\n    Loads custom functions from custom/{vendor}/{name}.py. This allows to quickly override any\n    function that is used to retrieve and parse the changelog.\n    :param name: str, package name\n    :param vendor: str, vendor\n    :return: dict, functions\n    \"\"\"\n    functions = {}\n    # Some packages have dash in their name, replace them with underscore\n    # E.g. python-ldap to python_ldap\n    filename = \"{}.py\".format(name.replace(\"-\", \"_\").lower())\n    path = os.path.join(\n        os.path.dirname(os.path.realpath(__file__)),  # current working dir\n        \"custom\",  # /dir/parser\n        vendor,  # /dir/parser/pypi\n        filename  # /dir/parser/pypi/django.py\n    )\n    if os.path.isfile(path):\n        module_name = \"parser.{vendor}.{name}\".format(vendor=vendor, name=name)\n        module = imp.load_source(module_name, path)\n        functions = dict(\n            (function, getattr(module, function, None)) for function in ALLOWED_CUSTOM_FUNCTIONS\n            if hasattr(module, function)\n        )\n    return functions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all functions and custom functions for the given package and vendor.", "response": "def _bootstrap_functions(name, vendor, functions):\n    \"\"\"\n    Loads all functions, including custom functions, for the given package/vendor and updates it\n    with the functions passed to this function. [:)]\n    It loads the default functions first, then the custom functions and lastly the functions passed\n    to this function (if any). [:)]\n    :param name: str, package name\n    :param vendor: str, vendor\n    :param functions: dict, custom functions\n    :return: dict, functions\n    \"\"\"\n    # load default functions\n    from . import parser\n    from . import finder\n    fns = {\n        \"get_content\": get_content,\n        \"parse\": parser.parse,\n        \"get_head\": parser.get_head,\n        \"find_changelogs\": finder.find_changelogs\n    }\n\n    # load vendor functions\n    if vendor == \"pypi\":\n        from . import pypi\n        fns.update({\n            \"get_metadata\": pypi.get_metadata,\n            \"get_releases\": pypi.get_releases,\n            \"get_urls\": pypi.get_urls,\n        })\n    elif vendor == \"npm\":\n        from . import npm\n        fns.update({\n            \"get_metadata\": npm.get_metadata,\n            \"get_releases\": npm.get_releases,\n            \"get_urls\": npm.get_urls,\n        })\n    elif vendor == \"gem\":\n        from . import rubygems\n        fns.update({\n            \"get_metadata\": rubygems.get_metadata,\n            \"get_releases\": rubygems.get_releases,\n            \"get_urls\": rubygems.get_urls,\n        })\n    elif vendor == \"launchpad\":\n        from . import launchpad\n        fns.update({\n            \"get_metadata\": launchpad.get_metadata,\n            \"get_releases\": launchpad.get_releases,\n            \"get_urls\": launchpad.get_urls,\n            \"find_changelogs\": launchpad.find_changelogs,\n            \"get_content\": launchpad.get_content,\n            \"parse\": launchpad.parse\n        })\n\n    # load custom functions for special packages lying in custom/{vendor}/{package}.py\n    custom_fns = _load_custom_functions(vendor=vendor, name=name)\n    fns.update(custom_fns)\n\n    # update custom functions with those passed in here. This allows\n    fns.update(functions)\n    return fns"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if the project is hosted on launchpad.", "response": "def check_for_launchpad(old_vendor, name, urls):\n    \"\"\"Check if the project is hosted on launchpad.\n\n    :param name: str, name of the project\n    :param urls: set, urls to check.\n    :return: the name of the project on launchpad, or an empty string.\n    \"\"\"\n    if old_vendor != \"pypi\":\n        # XXX This might work for other starting vendors\n        # XXX but I didn't check. For now only allow\n        # XXX pypi -> launchpad.\n        return ''\n\n    for url in urls:\n        try:\n            return re.match(r\"https?://launchpad.net/([\\w.\\-]+)\",\n                            url).groups()[0]\n        except AttributeError:\n            continue\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_switch_vendor(old_vendor, name, urls, _depth=0):\n    if _depth > 3:\n        # Protect against recursive things vendors here.\n        return \"\"\n    new_name = check_for_launchpad(old_vendor, name, urls)\n    if new_name:\n        return \"launchpad\", new_name\n    return \"\", \"\"", "response": "Check if the project should switch vendors."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to find a changelog for the given package.", "response": "def get(name, vendor=\"pypi\", functions={}, _depth=0):\n    \"\"\"\n    Tries to find a changelog for the given package.\n    :param name: str, package name\n    :param vendor: str, vendor\n    :param functions: dict, custom functions\n    :return: dict, changelog\n    \"\"\"\n    fns = _bootstrap_functions(name=name, vendor=vendor, functions=functions)\n    session = Session()\n    # get meta data for the given package and use this metadata to\n    # find urls pointing to a possible changelog\n    data = fns[\"get_metadata\"](session=session, name=name)\n    releases = fns[\"get_releases\"](name=name, data=data)\n    urls, repos = fns[\"get_urls\"](\n        session=session,\n        name=name,\n        data=data,\n        releases=releases,\n        find_changelogs_fn=fns[\"find_changelogs\"]\n    )\n\n    # load the content from the given urls and parse the changelog\n    content = fns[\"get_content\"](session=session, urls=urls)\n    changelog = fns[\"parse\"](\n        name=name,\n        content=content,\n        releases=releases,\n        get_head_fn=fns[\"get_head\"]\n    )\n    del fns\n    if changelog:\n        return changelog\n\n    # We could not find any changelogs.\n    # Check to see if we can switch vendors.\n    new_vendor, new_name = check_switch_vendor(vendor, name, repos,\n                                               _depth=_depth)\n    if new_vendor and new_vendor != vendor:\n        return get(new_name, vendor=new_vendor, functions=functions,\n                   _depth=_depth+1)\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to parse a changelog from the raw commit log.", "response": "def get_commit_log(name, vendor='pypi', functions={}, _depth=0):\n    \"\"\"\n    Tries to parse a changelog from the raw commit log.\n    :param name: str, package name\n    :param vendor: str, vendor\n    :param functions: dict, custom functions\n    :return: tuple, (dict -> commit log, str -> raw git log)\n    \"\"\"\n    if \"find_changelogs\" not in functions:\n        from .finder import find_git_repo\n        functions[\"find_changelogs\"] = find_git_repo\n    if \"get_content\" not in functions:\n        functions[\"get_content\"] = clone_repo\n    if \"parse\" not in functions:\n        from .parser import parse_commit_log\n        functions[\"parse\"] = parse_commit_log\n    return get(\n        name=name,\n        vendor=vendor,\n        functions=functions\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads the content from a list of URLs.", "response": "def get_content(session, urls):\n    \"\"\"\n    Loads the content from URLs, ignoring connection errors.\n    :param session: requests Session instance\n    :param urls: list, str URLs\n    :return: str, content\n    \"\"\"\n\n    content = \"\"\n    for url in urls:\n        try:\n            logger.debug(\"GET changelog from {url}\".format(url=url))\n            if \"https://api.github.com\" in url and url.endswith(\"releases\"):\n                # this is a github API release page, fetch it if token is set\n                if not GITHUB_API_TOKEN:\n                    logger.warning(\"Fetching release pages requires CHANGELOGS_GITHUB_API_TOKEN \"\n                                   \"to be set\")\n                    continue\n                resp = session.get(url, headers={\n                    \"Authorization\": \"token {}\".format(GITHUB_API_TOKEN)\n                })\n                if resp.status_code == 200:\n                    for item in resp.json():\n                        content += \"\\n\\n{}\\n{}\".format(item['tag_name'], item[\"body\"])\n            else:\n                resp = session.get(url)\n                if resp.status_code == 200:\n                    content += \"\\n\\n\" + resp.text\n        except requests.ConnectionError:\n            pass\n    return content"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clone_repo(session, urls):\n    repos = []\n    for url in urls:\n        dir = mkdtemp()\n        call = [\"git\", \"clone\", url, dir]\n        subprocess.call(call)\n        repos.append((dir, url))\n    return repos", "response": "Clones the given repos in temp directories and returns a list of the cloned repos and the URL of the cloned repos"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unknown(*args, **kwargs):\n    name = kwargs.get('name', '')\n    return \"%s(%s)\" % (name, ', '.join(str(a) for a in args))", "response": "Unknow scss function handler.\n        Simple"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _rgba(r, g, b, a, **kwargs):\n    return ColorValue((float(r), float(g), float(b), float(a)))", "response": "Converts an rgba quadruplet into a color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmixing two colors together.", "response": "def _mix(color1, color2, weight=0.5, **kwargs):\n    \"\"\" Mixes two colors together.\n    \"\"\"\n    weight = float(weight)\n    c1 = color1.value\n    c2 = color2.value\n    p = 0.0 if weight < 0 else 1.0 if weight > 1 else weight\n    w = p * 2 - 1\n    a = c1[3] - c2[3]\n\n    w1 = ((w if (w * a == -1) else (w + a) / (1 + w * a)) + 1) / 2.0\n    w2 = 1 - w1\n    q = [w1, w1, w1, p]\n    r = [w2, w2, w2, 1 - p]\n    return ColorValue([c1[i] * q[i] + c2[i] * r[i] for i in range(4)])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _hsla(h, s, l, a, **kwargs):\n    res = colorsys.hls_to_rgb(float(h), float(l), float(s))\n    return ColorValue([x * 255.0 for x in res] + [float(a)])", "response": "HSL with alpha channel color value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting hue value of HSL color.", "response": "def _hue(color, **kwargs):\n    \"\"\" Get hue value of HSL color.\n    \"\"\"\n    h = colorsys.rgb_to_hls(*[x / 255.0 for x in color.value[:3]])[0]\n    return NumberValue(h * 360.0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget lightness value of HSL color.", "response": "def _lightness(color, **kwargs):\n    \"\"\" Get lightness value of HSL color.\n    \"\"\"\n    l = colorsys.rgb_to_hls(*[x / 255.0 for x in color.value[:3]])[1]\n    return NumberValue((l * 100, '%'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _saturation(color, **kwargs):\n    s = colorsys.rgb_to_hls(*[x / 255.0 for x in color.value[:3]])[2]\n    return NumberValue((s * 100, '%'))", "response": "Get saturation value of HSL color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the inverse of a color.", "response": "def _invert(color, **kwargs):\n    \"\"\" Returns the inverse (negative) of a color.\n        The red, green, and blue values are inverted, while the opacity is left alone.\n    \"\"\"\n    col = ColorValue(color)\n    args = [\n        255.0 - col.value[0],\n        255.0 - col.value[1],\n        255.0 - col.value[2],\n        col.value[3],\n    ]\n    inverted = ColorValue(args)\n    return inverted"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a single XML file into a sequence of objects.", "response": "def load(path, cache=None, precache=False):\n    \"\"\" Parse from file.\n    \"\"\"\n    parser = Stylesheet(cache)\n    return parser.load(path, precache=precache)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing nested rulesets and save it in cache.", "response": "def parse(self, target):\n        \"\"\" Parse nested rulesets\n            and save it in cache.\n        \"\"\"\n        if isinstance(target, ContentNode):\n            if target.name:\n                self.parent = target\n                self.name.parse(self)\n                self.name += target.name\n            target.ruleset.append(self)\n        self.root.cache['rset'][str(self.name).split()[0]].add(self)\n        super(Ruleset, self).parse(target)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the root and parent context.", "response": "def parse(self, target):\n        \"\"\" Update root and parent context.\n        \"\"\"\n        super(VarDefinition, self).parse(target)\n        if isinstance(self.parent, ParseNode):\n            self.parent.ctx.update({self.name: self.expression.value})\n        self.root.set_var(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets variable to global stylesheet context.", "response": "def set_var(self, vardef):\n        \"\"\" Set variable to global stylesheet context.\n        \"\"\"\n        if not(vardef.default and self.cache['ctx'].get(vardef.name)):\n            self.cache['ctx'][vardef.name] = vardef.expression.value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update(self, cache):\n        self.cache['delims'] = cache.get('delims')\n        self.cache['opts'].update(cache.get('opts'))\n        self.cache['rset'].update(cache.get('rset'))\n        self.cache['mix'].update(cache.get('mix'))\n        map(self.set_var, cache['ctx'].values())", "response": "Update self. cache from other."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning scss from string and return nodes.", "response": "def scan(src):\n        \"\"\" Scan scss from string and return nodes.\n        \"\"\"\n        assert isinstance(src, (unicode_, bytes_))\n        try:\n            nodes = STYLESHEET.parseString(src, parseAll=True)\n            return nodes\n        except ParseBaseException:\n            err = sys.exc_info()[1]\n            print(err.line, file=sys.stderr)\n            print(\" \" * (err.column - 1) + \"^\", file=sys.stderr)\n            print(err, file=sys.stderr)\n            sys.exit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncompiling css from scss string.", "response": "def loads(self, src):\n        \"\"\" Compile css from scss string.\n        \"\"\"\n        assert isinstance(src, (unicode_, bytes_))\n        nodes = self.scan(src.strip())\n        self.parse(nodes)\n        return ''.join(map(str, nodes))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncompiling scss from file.", "response": "def load(self, f, precache=None):\n        \"\"\" Compile scss from file.\n            File is string path of file object.\n        \"\"\"\n        precache = precache or self.get_opt('cache') or False\n        nodes = None\n        if isinstance(f, file_):\n            path = os.path.abspath(f.name)\n\n        else:\n            path = os.path.abspath(f)\n            f = open(f)\n\n        cache_path = os.path.splitext(path)[0] + '.ccss'\n\n        if precache and os.path.exists(cache_path):\n            ptime = os.path.getmtime(cache_path)\n            ttime = os.path.getmtime(path)\n            if ptime > ttime:\n                dump = open(cache_path, 'rb').read()\n                nodes = pickle.loads(dump)\n\n        if not nodes:\n            src = f.read()\n            nodes = self.scan(src.strip())\n\n        if precache:\n            f = open(cache_path, 'wb')\n            pickle.dump(nodes, f, protocol=1)\n\n        self.parse(nodes)\n        return ''.join(map(str, nodes))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload config file into memory", "response": "def load_config(filename, filepath=''):\n    \"\"\"\n    Loads config file\n\n    Parameters\n    ----------\n    filename: str\n        Filename of config file (incl. file extension\n    filepath: str\n        Absolute path to directory of desired config file\n    \"\"\"\n\n    FILE = path.join(filepath, filename)\n\n    try:\n        cfg.read(FILE)\n        global _loaded\n        _loaded = True\n    except:\n        print(\"configfile not found.\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_metadata(session, name):\n    resp = session.get(\n        \"https://api.launchpad.net/1.0/{}/releases\".format(name))\n    if resp.status_code == 200:\n        return resp.json()\n    return {}", "response": "Gets meta data for the given package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_content(session, urls):\n    for url in urls:\n        resp = session.get(url)\n        if resp.ok:\n            return resp.json()\n    return {}", "response": "Loads the content from a list of URLs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the given content for a valid changelog", "response": "def parse(name, content, releases, get_head_fn):\n    \"\"\"\n    Parses the given content for a valid changelog\n    :param name: str, package name\n    :param content: str, content\n    :param releases: list, releases\n    :param get_head_fn: function\n    :return: dict, changelog\n    \"\"\"\n    try:\n        return {e[\"version\"]: e[\"changelog\"] for e in content[\"entries\"]\n                if e[\"changelog\"]}\n    except KeyError:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetecting emoticons from text", "response": "def emoticons(string):\n    '''emot.emoticons is use to detect emoticons from text\n\n        >>> text = \"I love python \ud83d\udc68 :-)\"\n        >>> emot.emoticons(text)\n        >>> {'value': [':-)'], 'location': [[16, 19]], 'mean': ['Happy face smiley'], 'flag': True}\n    '''\n    __entities = []\n    flag = True\n    try:\n        pattern = u'(' + u'|'.join(k for k in emo_unicode.EMOTICONS) + u')'\n        __entities = []\n        __value = []\n        __location = []\n        matches = re.finditer(r\"%s\"%pattern,str(string))\n        for et in matches:\n            __value.append(et.group().strip())\n            __location.append([et.start(),et.end()])\n            \n        __mean = []\n        for each in __value:\n            __mean.append(emo_unicode.EMOTICONS_EMO[each])\n        \n        if len(__value) < 1:\n            flag = False\n        __entities = {\n        'value' : __value,\n        'location' : __location,\n        'mean' : __mean,\n        'flag' : flag\n        }\n    except Exception as e:\n        __entities = [{'flag' : False}]\n        #print(\"No emoiticons found\")\n        return __entities\n\n    return __entities"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninitialize with app configuration", "response": "def init_app(self, app, add_context_processor=True):\n        \"\"\"\n        Initialize with app configuration\n        \"\"\"\n\n        # Check if login manager has been initialized\n        if not hasattr(app, 'login_manager'):\n            self.login_manager.init_app(\n                app,\n                add_context_processor=add_context_processor)\n\n        # Clear flashed messages since we redirect to auth immediately\n        self.login_manager.login_message = None\n        self.login_manager.needs_refresh_message = None\n\n        # Set default unauthorized callback\n        self.login_manager.unauthorized_handler(self.unauthorized_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning login url with params encoded in state", "response": "def login_url(self, params=None, **kwargs):\n        \"\"\"\n        Return login url with params encoded in state\n\n        Available Google auth server params:\n        response_type: code, token\n        prompt: none, select_account, consent\n        approval_prompt: force, auto\n        access_type: online, offline\n        scopes: string (separated with commas) or list\n        redirect_uri: string\n        login_hint: string\n        \"\"\"\n        kwargs.setdefault('response_type', 'code')\n        kwargs.setdefault('access_type', 'online')\n\n        if 'prompt' not in kwargs:\n            kwargs.setdefault('approval_prompt', 'auto')\n\n        scopes = kwargs.pop('scopes', self.scopes.split(','))\n        if USERINFO_PROFILE_SCOPE not in scopes:\n            scopes.append(USERINFO_PROFILE_SCOPE)\n\n        redirect_uri = kwargs.pop('redirect_uri', self.redirect_uri)\n        state = self.sign_params(params or {})\n\n        return GOOGLE_OAUTH2_AUTH_URL + '?' + urlencode(\n            dict(client_id=self.client_id,\n                 scope=' '.join(scopes),\n                 redirect_uri=redirect_uri,\n                 state=state,\n                 **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unauthorized_callback(self):\n        return redirect(self.login_url(params=dict(next=request.url)))", "response": "Redirect to login url with next param set as request. url\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexchanges code for token", "response": "def exchange_code(self, code, redirect_uri):\n        \"\"\"\n        Exchanges code for token/s\n        \"\"\"\n\n        token = requests.post(GOOGLE_OAUTH2_TOKEN_URL, data=dict(\n            code=code,\n            redirect_uri=redirect_uri,\n            grant_type='authorization_code',\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n        )).json()\n        if not token or token.get('error'):\n            abort(400)\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_access_token(self, refresh_token):\n\n        token = requests.post(GOOGLE_OAUTH2_TOKEN_URL, data=dict(\n            refresh_token=refresh_token,\n            grant_type='refresh_token',\n            client_id=self.client_id,\n            client_secret=self.client_secret,\n        )).json()\n\n        if not token or token.get('error'):\n            return\n\n        return token", "response": "Get a new access token using a refresh token to obtain a new access token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the given content for a valid changelog .", "response": "def parse(name, content, releases, get_head_fn):\n    \"\"\"\n    Parses the given content for a valid changelog\n    :param name: str, package name\n    :param content: str, content\n    :param releases: list, releases\n    :param get_head_fn: function\n    :return: dict, changelog\n    \"\"\"\n    changelog = {}\n    releases = frozenset(releases)\n    head = False\n    date_line = None\n    for line in content.splitlines():\n        if DATE_RE.match(line):\n            date_line = line\n            continue\n        if line.strip().startswith(\"PyAudio\"):\n            try:\n                head = line.strip().split()[1]\n            except:\n                continue\n            changelog[head] = date_line + \"\\n\"\n            continue\n        if not head:\n            continue\n        line = line.replace(\"@\", \"\")\n        line = line.replace(\"#\", \"\")\n        changelog[head] += line + \"\\n\"\n    return changelog"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nvalidate the URL :param url: :return:", "response": "def validate_url(url):\n    \"\"\"\n    Validates the URL\n    :param url:\n    :return:\n    \"\"\"\n    if validators.url(url):\n        return url\n    elif validators.domain(url):\n        return \"http://{}\".format(url)\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvalidate and formats a URL pointing to a repo on github. com or sourceforge. net.", "response": "def validate_repo_url(url):\n    \"\"\"\n    Validates and formats `url` to be valid URL pointing to a repo on bitbucket.org or github.com\n    :param url: str, URL\n    :return: str, valid URL if valid repo, emptry string otherwise\n    \"\"\"\n    try:\n        if \"github.com\" in url:\n            return re.findall(r\"https?://w?w?w?.?github.com/[\\w\\-]+/[\\w.-]+\", url)[0]\n        elif \"bitbucket.org\" in url:\n            return re.findall(r\"https?://bitbucket.org/[\\w.-]+/[\\w.-]+\", url)[0] + \"/src/\"\n        elif \"launchpad.net\" in url:\n            return re.findall(r\"https?://launchpad.net/[\\w.-]+\", url)[0]\n        elif \"sourceforge.net\" in url:\n            mo = re.match(r\"https?://sourceforge.net/projects/\"\n                          r\"([\\w.-]+)/\", url, re.I)\n            template = \"https://sourceforge.net/p/{}/code/HEAD/tree/trunk/src/\"\n            return template.format(mo.groups()[0])\n    except (IndexError, AttributeError):\n        pass\n    return \"\""}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the given name contains the project name.", "response": "def contains_project_name(name, link):\n    \"\"\"\n    Checks if the given link `somewhat` contains the project name.\n    :param name: str, project name\n    :param link: str, link\n    :return: bool, True if the link contains the project name\n    \"\"\"\n    def unclutter(string):\n        # strip out all python references and remove all excessive characters\n        string = string.lower().replace(\"_\", \"-\").replace(\".\", \"-\")\n        for replace in [\"python-\", \"py-\", \"-py\", \"-python\"]:\n            string = string.replace(replace, \"\")\n        return re.sub(\"[^0123456789 a-zA-Z]\", \"\", string).strip()\n    return unclutter(name) in unclutter(link)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_repo_urls(session, name, candidates):\n    for _url in candidates:\n        if validate_url(_url):\n            try:\n                resp = session.get(_url)\n                if resp.status_code == 200:\n                    tree = etree.HTML(resp.content)\n                    if tree:\n                        for link in frozenset([str(l) for l in tree.xpath(\"//a/@href\")]):\n                            # check if the link 1) is to github.com / bitbucket.org AND 2) somewhat\n                            # contains the project name\n                            if (\"github.com\" in link or \"bitbucket.org\" in link or\n                                    \"sourceforge.net\" in link) \\\n                                    and contains_project_name(name, link):\n                                link = validate_url(validate_repo_url(url=link))\n                                if link:\n                                    logger.debug(\"Found repo URL {}\".format(link))\n                                    yield link\n            except ConnectionError:\n                # we really don't care about connection errors here. a lot of project pages are simply\n                # down because the project is no longer maintained\n                pass\n            except etree.XMLSyntaxError:\n                # unable to parse HTML\n                pass\n            except UnicodeEncodeError:\n                pass", "response": "Searches the given URL candidates and returns the URL to a repository."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to find changelogs on the given repo_url.", "response": "def find_changelog(session, repo_url, deep=True):\n    \"\"\"\n    Tries to find changelogs on the given `repo_url`.\n    :param session: requests Session instance\n    :param repo_url: str, URL to the repo\n    :param deep: bool, deep search\n    :return: str, URL to the raw changelog content\n    \"\"\"\n    logger.debug(\"Trying to find changelog on repo {}\".format(repo_url))\n    resp = session.get(repo_url)\n    if resp.status_code == 200:\n        # build up a list of URLs on this repo. xpath() isn't returning raw strings, so we have to\n        # convert them first. We also need to strip out all GET parameters if any.\n        tree = etree.HTML(resp.content)\n        try:\n            links = frozenset([str(l).split(\"?\")[0] for l in tree.xpath(\"//a/@href\")])\n        except UnicodeEncodeError:\n            links = []\n        match, found = False, False\n        for link in links:\n            # we are going to check for valid changelog links on the root first. We do that by\n            # checking if the link ends with one of out changelog filename candidates.\n            for candidate in CHANGELOG_FILENAME_CANDIDATES:\n                if link.endswith(candidate):\n                    if \"github.com\" in repo_url and \"blob\" in link:\n                        link = link.replace(repo_url, \"\")\n                        match = validate_url(\"https://raw.githubusercontent.com\" + link.replace(\"/blob/\", \"/\"))\n                    elif \"bitbucket.org\" in repo_url and \"src\" in link:\n                        match = validate_url(\"https://bitbucket.org\" + link.replace(\"/src/\", \"/raw/\"))\n                    elif \"sourceforge.net\" in repo_url:\n                        match = validate_url(repo_url + link + \"?format=raw\")\n                    if match:\n                        yield match\n                        match, found = False, True\n\n        # if this is a deep search and we haven't found any changelogs on the repo root, we are\n        # going to check every potential doc page.\n        if deep and not found:\n            for link in links:\n                sublink = False\n                for doc_candidate in DOCS_CANDIDATES:\n                    if link.endswith(doc_candidate):\n                        if \"github.com\" in repo_url and \"tree\" in link:\n                            if link.startswith(\"https://github.com\"):\n                                sublink = link\n                            else:\n                                sublink = \"https://github.com\" + link\n                        elif \"bitbucket.org\" in repo_url and \"src\" in link:\n                            sublink = \"https://bitbucket.org\" + link\n                        # if we find a valid link to a doc subdirectory on the repo call this\n                        # function again and yield all possible changelog hits\n                        if sublink:\n                            for _url in find_changelog(session, sublink, deep=False):\n                                yield _url\n                                sublink = False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_repo_urls(candidates):\n    # first, we are going to filter down the URL candidates to be all valid urls\n    candidates = set(url for url in [validate_url(_url) for _url in candidates] if url)\n    logger.info(\"Got repo candidates {}\".format(candidates))\n    repos = set(url for url in [validate_repo_url(_url) for _url in candidates] if url)\n    logger.info(\"Filtered initial candidates down to {}\".format(repos))\n\n    return repos", "response": "Filter out all repos that are not valid urls"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_changelogs(session, name, candidates):\n    repos = filter_repo_urls(candidates=candidates)\n    # if we are lucky and there isn't a valid repo URL in our URL candidates, we need to go deeper\n    # and check the URLs if they contain a link to a repo\n    if not repos:\n        logger.info(\"No repo found, trying to find one on related sites {}\".format(candidates))\n        repos = set(find_repo_urls(session, name, candidates))\n\n    urls = []\n    for repo in repos:\n        for url in find_changelog(session, repo):\n            if not contains_project_name(name, url):\n                logger.debug(\"Found changelog on {url}, but it does not contain the project name \"\n                             \"{name}, \"\"aborting\".format(name=name, url=url))\n                continue\n            urls.append(url)\n\n    if not urls:\n        # at this point we failed to fetch a changelog from plain files. we might find one on the\n        # github release page.\n        logger.debug(\"No plain changelog urls found, trying release page\")\n        for repo in repos:\n            # make sure the link to the release page contains the project name\n            if contains_project_name(name, repo):\n                for url in find_release_page(session, repo):\n                    urls.append(url)\n    return set(urls), repos", "response": "Tries to find changelogs on the given list of candidates and returns a tuple of the set of urls and repos that are linked to the given project name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to find git repos on the given list of candidates and returns a set of git urls and repo urls", "response": "def find_git_repo(session, name, candidates):\n    \"\"\"\n    Tries to find git repos on the given URL candidates\n    :param session: requests Session instance\n    :param name: str, project name\n    :param candidates: list, URL candidates\n    :return: tuple, (set(git URLs), set(repo URLs))\n    \"\"\"\n\n    repos = filter_repo_urls(candidates=candidates)\n\n    # if we are lucky and there isn't a valid repo URL in our URL candidates, we need to go deeper\n    # and check the URLs if they contain a link to a repo\n    if not repos:\n        logger.info(\"No repo found, trying to find one on related sites {}\".format(candidates))\n        repos = set(find_repo_urls(session, name, candidates))\n\n    urls = []\n    for repo in repos:\n        username, reponame = repo.split(\"/\")[3:5]\n        if \"github.com\" in repo:\n            urls.append(\n                \"https://github.com/{username}/{reponame}.git\".format(\n                    username=username, reponame=reponame\n                )\n            )\n        elif \"bitbucket.org\" in repo:\n            urls.append(\n                \"https://bitbucket.org/{username}/{reponame}\".format(\n                    username=username, reponame=reponame\n                )\n            )\n    return set(urls), repos"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_urls(session, name, data, find_changelogs_fn, **kwargs):\n    # if this package has valid meta data, build up a list of URL candidates we can possibly\n    # search for changelogs on\n    candidates = [\n        url for url in\n        [data.get(attr) for attr in (\n            \"project_uri\", \"homepage_uri\", \"wiki_uri\", \"documentation_uri\", \"mailing_list_uri\",\n            \"source_code_uri\", \"bug_tracker_uri\"\n        )]\n        if url\n    ]\n    return find_changelogs_fn(session=session, name=name, candidates=candidates)", "response": "Gets URLs to changelogs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the configuration file and returns a ConfigParser object.", "response": "def readcfg(filepath, section):\n    \"\"\" \n    Reads the configuration file. If section is not available, calls\n    create_oedb_config_file to add the new section to an existing config.ini.\n    \n    Parameters\n    ----------\n    filepath : str\n        Absolute path of config file including the filename itself\n    section : str\n        Section in config file which contains connection details\n    Returns\n    -------\n    cfg : configparser.ConfigParser\n        Used for configuration file parser language.\n    \"\"\"\n\n    cfg = cp.ConfigParser()\n    cfg.read(filepath)\n    \n    if not cfg.has_section(section):\n        print('The section \"{sec}\" is not in the config file {file}.'\n              .format(sec=section,\n                      file=filepath))\n        cfg = create_oedb_config_file(filepath, section)   \n\n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasking the user for the database connection details and returns them as a ConfigParser - object.", "response": "def get_connection_details(section):\n    \"\"\"\n    Asks the user for the database connection details and returns them as a\n    ConfigParser-object.\n    \n    Parameters\n    ----------\n    None\n    \n    Returns\n    -------\n    cfg : configparser.ConfigParser\n        Used for configuration file parser language.\n    \"\"\"\n    print('Please enter your connection details:')\n    dialect = input('Enter input value for `dialect` (default: psycopg2): ') or 'psycopg2'\n    username = input('Enter value for `username`: ')\n    database = input('Enter value for `database`: ')\n    host = input('Enter value for `host`: ')\n    port = input('Enter value for `port` (default: 5432): ') or '5432'\n\n    cfg = cp.ConfigParser()\n    cfg.add_section(section)\n    cfg.set(section, 'dialect', dialect)\n    cfg.set(section, 'username', username)\n    cfg.set(section, 'host', host)\n    cfg.set(section, 'port', port)\n    cfg.set(section, 'database', database)\n    pw = getpass.getpass(prompt=\"Enter your password/token to \" \\\n                                        \"store it in \"\n                                        \"keyring: \".format(database=section))\n    keyring.set_password(section, cfg.get(section, \"username\"), pw)\n    \n    return cfg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connection(filepath=None, section='oep'):\n\n    # define default filepath if not provided\n    if filepath is None:\n        filepath = os.path.join(os.path.expanduser(\"~\"), '.egoio', 'config.ini')\n\n    # does the file exist?\n    if not os.path.isfile(filepath):\n        print('DB config file {file} not found. '\n          'This might be the first run of the tool. '\n          .format(file=filepath))\n        cfg = create_oedb_config_file(filepath, section=section)\n    else:\n        cfg = readcfg(filepath, section)\n    \n    try:\n        pw = cfg.get(section, \"password\")\n    except:\n        pw = keyring.get_password(section,\n                                  cfg.get(section, \"username\"))\n        if pw is None:\n            pw = getpass.getpass(prompt='No password found for database \"{db}\". '\n                                        'Enter your password to '\n                                        'store it in keyring: '\n                                 .format(db=cfg.get(section, 'database')))\n            keyring.set_password(section, cfg.get(section, \"username\"), pw)\n        \n    # establish connection and return it\n    conn = create_engine(\n        \"postgresql+{dialect}://{user}:{password}@{host}:{port}/{db}\".format(\n            dialect=cfg.get(section, 'dialect', fallback='psycopg2'),\n            user=cfg.get(section, 'username'),\n            password=pw,\n            host=cfg.get(section, 'host'),\n            port=cfg.get(section, 'port'),\n            db=cfg.get(section, 'database')))\n\n    return conn", "response": "Instantiate a SQLAlchemy connection object for use with SQLAlchemy."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading custom. pypi. map. txt and builds a dict where map[package_name] = url", "response": "def get_url_map():\n    \"\"\"\n    Loads custom/pypi/map.txt and builds a dict where map[package_name] = url\n    :return: dict, urls\n    \"\"\"\n    map = {}\n    path = os.path.join(\n        os.path.dirname(os.path.realpath(__file__)),  # current working dir ../\n        \"custom\",  # ../custom/\n        \"pypi\",  # ../custom/pypi/\n        \"map.txt\"  # ../custom/pypi/map.txt\n    )\n    with open(path) as f:\n        for line in f.readlines():\n            package, url = line.strip().split(\": \")\n            map[package] = url\n    return map"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_urls(session, name, data, find_changelogs_fn, **kwargs):\n    # check if there's a changelog in ../custom/pypi/map.txt\n    map = get_url_map()\n    if name.lower().replace(\"_\", \"-\") in map:\n        logger.info(\"Package {name}'s URL is in pypi/map.txt, returning\".format(name=name))\n        return [map[name.lower().replace(\"_\", \"-\")]], set()\n    # if this package has valid meta data, build up a list of URL candidates we can possibly\n    # search for changelogs on\n    if \"info\" in data:\n        # add all URLs in pypi's meta data:\n        # {\n        #   \"info\": {\n        #       \"home_page\":\n        #       \"docs_url\":\n        #       \"bugtrack_url\":\n        #   }\n        # }\n        candidates = [\n            url for url in\n            [data[\"info\"].get(attr) for attr in (\"home_page\", \"docs_url\", \"bugtrack_url\")]\n            if url\n        ]\n        # the latest release page on pypi might also contain links, add it\n        candidates.append(\"https://pypi.python.org/pypi/{name}/{latest_release}\".format(\n            name=name,\n            latest_release=next(iter(get_releases(data)))\n        ))\n        # Check the download URL as well.\n        if \"download_url\" in data:\n            candidates.append(data[\"download_url\"])\n        if data['info']['description']:\n            candidates.extend(changelogs.url_re.findall(data[\"info\"][\"description\"]))\n        return find_changelogs_fn(session=session, name=name, candidates=candidates)\n    return set(), set()", "response": "Gets URLs to the changelogs of a given package."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of all translation instances in the linguist.", "response": "def translation_instances(self):\n        \"\"\"\n        Returns translation instances.\n        \"\"\"\n        return [\n            instance\n            for k, v in six.iteritems(self.instance._linguist_translations)\n            for instance in v.values()\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a translation from the cache.", "response": "def get_cache(\n        self,\n        instance,\n        translation=None,\n        language=None,\n        field_name=None,\n        field_value=None,\n    ):\n        \"\"\"\n        Returns translation from cache.\n        \"\"\"\n        is_new = bool(instance.pk is None)\n\n        try:\n            cached_obj = instance._linguist_translations[field_name][language]\n            if not cached_obj.field_name:\n                cached_obj.field_name = field_name\n            if not cached_obj.language:\n                cached_obj.language = language\n            if not cached_obj.identifier:\n                cached_obj.identifier = self.instance.linguist_identifier\n        except KeyError:\n            cached_obj = None\n\n            if not is_new:\n                if translation is None:\n                    try:\n                        translation = self.decider.objects.get(\n                            identifier=self.instance.linguist_identifier,\n                            object_id=self.instance.pk,\n                            language=language,\n                            field_name=field_name,\n                        )\n                    except self.decider.DoesNotExist:\n                        pass\n\n            if cached_obj is None:\n                if translation is not None:\n                    cached_obj = CachedTranslation.from_object(translation)\n                else:\n                    cached_obj = CachedTranslation(\n                        instance=instance,\n                        language=language,\n                        field_name=field_name,\n                        field_value=field_value,\n                    )\n\n            instance._linguist_translations[cached_obj.field_name][\n                cached_obj.language\n            ] = cached_obj\n\n        return cached_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the cache for the current language of the entry.", "response": "def set_cache(\n        self,\n        instance=None,\n        translation=None,\n        language=None,\n        field_name=None,\n        field_value=None,\n    ):\n        \"\"\"\n        Add a new translation into the cache.\n        \"\"\"\n        if instance is not None and translation is not None:\n            cached_obj = CachedTranslation.from_object(translation)\n            instance._linguist_translations[translation.field_name][\n                translation.language\n            ] = cached_obj\n            return cached_obj\n\n        if instance is None:\n            instance = self.instance\n\n        cached_obj = self.get_cache(\n            instance,\n            translation=translation,\n            field_value=field_value,\n            language=language,\n            field_name=field_name,\n        )\n\n        if field_value is None and cached_obj.field_value:\n            cached_obj.deleted = True\n\n        if field_value != cached_obj.field_value:\n            cached_obj.has_changed = True\n            cached_obj.field_value = field_value\n\n        return cached_obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride default behavior to handle linguist fields.", "response": "def _filter_or_exclude(self, negate, *args, **kwargs):\n        \"\"\"\n        Overrides default behavior to handle linguist fields.\n        \"\"\"\n        from .models import Translation\n\n        new_args = self.get_cleaned_args(args)\n        new_kwargs = self.get_cleaned_kwargs(kwargs)\n\n        translation_args = self.get_translation_args(args)\n        translation_kwargs = self.get_translation_kwargs(kwargs)\n\n        has_linguist_args = self.has_linguist_args(args)\n        has_linguist_kwargs = self.has_linguist_kwargs(kwargs)\n\n        if translation_args or translation_kwargs:\n            ids = list(\n                set(\n                    Translation.objects.filter(\n                        *translation_args, **translation_kwargs\n                    ).values_list(\"object_id\", flat=True)\n                )\n            )\n            if ids:\n                new_kwargs[\"id__in\"] = ids\n\n        has_kwargs = has_linguist_kwargs and not (new_kwargs or new_args)\n        has_args = has_linguist_args and not (new_args or new_kwargs)\n\n        # No translations but we looked for translations?\n        # Returns empty queryset.\n        if has_kwargs or has_args:\n            return self._clone().none()\n\n        return super(QuerySetMixin, self)._filter_or_exclude(\n            negate, *new_args, **new_kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_concrete_fields_with_model(self):\n        return [\n            (f, f.model if f.model != self.model else None)\n            for f in self.model._meta.get_fields()\n            if f.concrete\n            and (\n                not f.is_relation or f.one_to_one or (f.many_to_one and f.related_model)\n            )\n        ]", "response": "For compatibility with Django < = 1. 10. Replace old\nMimeType. _meta. get_concrete_fields_with_model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all field names that are available in the linguist.", "response": "def linguist_field_names(self):\n        \"\"\"\n        Returns linguist field names (example: \"title\" and \"title_fr\").\n        \"\"\"\n        return list(self.model._linguist.fields) + list(\n            utils.get_language_fields(self.model._linguist.fields)\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_linguist_kwargs(self, kwargs):\n        for k in kwargs:\n            if self.is_linguist_lookup(k):\n                return True\n        return False", "response": "Returns True if the given kwargs contain a linguist lookup."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the given list of arguments and returns True if they contain any linguist lookups.", "response": "def has_linguist_args(self, args):\n        \"\"\"\n        Parses the given args and returns True if they contain\n        linguist lookups.\n        \"\"\"\n        linguist_args = []\n        for arg in args:\n            condition = self._get_linguist_condition(arg)\n            if condition:\n                linguist_args.append(condition)\n        return bool(linguist_args)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn linguist args from model args.", "response": "def get_translation_args(self, args):\n        \"\"\"\n        Returns linguist args from model args.\n        \"\"\"\n        translation_args = []\n        for arg in args:\n            condition = self._get_linguist_condition(arg, transform=True)\n            if condition:\n                translation_args.append(condition)\n        return translation_args"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_translation_kwargs(self, kwargs):\n        lks = []\n        for k, v in six.iteritems(kwargs):\n            if self.is_linguist_lookup(k):\n                lks.append(\n                    utils.get_translation_lookup(self.model._linguist.identifier, k, v)\n                )\n\n        translation_kwargs = {}\n        for lk in lks:\n            for k, v in six.iteritems(lk):\n                if k not in translation_kwargs:\n                    translation_kwargs[k] = v\n\n        return translation_kwargs", "response": "Returns kwargs related to Translation model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn true if the given lookup is a valid linguist lookup.", "response": "def is_linguist_lookup(self, lookup):\n        \"\"\"\n        Returns true if the given lookup is a valid linguist lookup.\n        \"\"\"\n        field = utils.get_field_name_from_lookup(lookup)\n\n        # To keep default behavior with \"FieldError: Cannot resolve keyword\".\n        if (\n            field not in self.concrete_field_names\n            and field in self.linguist_field_names\n        ):\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a tree and returns a linguist lookups or model lookups", "response": "def _get_linguist_condition(self, condition, reverse=False, transform=False):\n        \"\"\"\n        Parses Q tree and returns linguist lookups or model lookups\n        if reverse is True.\n        \"\"\"\n        # We deal with a node\n        if isinstance(condition, Q):\n            children = []\n            for child in condition.children:\n                parsed = self._get_linguist_condition(\n                    condition=child, reverse=reverse, transform=transform\n                )\n                if parsed is not None:\n                    if (isinstance(parsed, Q) and parsed.children) or isinstance(\n                        parsed, tuple\n                    ):\n                        children.append(parsed)\n\n            new_condition = copy.deepcopy(condition)\n            new_condition.children = children\n\n            return new_condition\n\n        # We are dealing with a lookup ('field', 'value').\n        lookup, value = condition\n        is_linguist = self.is_linguist_lookup(lookup)\n\n        if transform and is_linguist:\n            return Q(\n                **utils.get_translation_lookup(\n                    self.model._linguist.identifier, lookup, value\n                )\n            )\n\n        if (reverse and not is_linguist) or (not reverse and is_linguist):\n            return condition"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning positional arguments for related model query.", "response": "def get_cleaned_args(self, args):\n        \"\"\"\n        Returns positional arguments for related model query.\n        \"\"\"\n        if not args:\n            return args\n\n        cleaned_args = []\n        for arg in args:\n            condition = self._get_linguist_condition(arg, True)\n            if condition:\n                cleaned_args.append(condition)\n\n        return cleaned_args"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_cleaned_kwargs(self, kwargs):\n        cleaned_kwargs = kwargs.copy()\n\n        if kwargs is not None:\n            for k in kwargs:\n                if self.is_linguist_lookup(k):\n                    del cleaned_kwargs[k]\n\n        return cleaned_kwargs", "response": "Returns concrete field lookups."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a new instance with the translations of the specified fields.", "response": "def with_translations(self, **kwargs):\n        \"\"\"\n        Prefetches translations.\n\n        Takes three optional keyword arguments:\n\n        * ``field_names``: ``field_name`` values for SELECT IN\n        * ``languages``: ``language`` values for SELECT IN\n        * ``chunks_length``: fetches IDs by chunk\n        \"\"\"\n\n        force = kwargs.pop(\"force\", False)\n\n        if self._prefetch_translations_done and force is False:\n            return self\n\n        self._prefetched_translations_cache = utils.get_grouped_translations(\n            self, **kwargs\n        )\n        self._prefetch_translations_done = True\n\n        return self._clone()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef available_languages(self):\n        from .models import Translation\n\n        return (\n            Translation.objects.filter(\n                identifier=self.linguist_identifier, object_id=self.pk\n            )\n            .values_list(\"language\", flat=True)\n            .distinct()\n            .order_by(\"language\")\n        )", "response": "Returns a list of all available languages for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_translations(self, language=None):\n        from .models import Translation\n\n        if not self.pk:\n            return Translation.objects.none()\n\n        return Translation.objects.get_translations(obj=self, language=language)", "response": "Returns available translations for this instance."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef override_language(self, language):\n        previous_language = self._linguist.language\n        self._linguist.language = language\n        yield\n        self._linguist.language = previous_language", "response": "Context manager to override the instance language."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _save_table(\n        self,\n        raw=False,\n        cls=None,\n        force_insert=False,\n        force_update=False,\n        using=None,\n        update_fields=None,\n    ):\n        \"\"\"\n        Overwrites model's ``_save_table`` method to save translations after instance\n        has been saved (required to retrieve the object ID for ``Translation``\n        model).\n\n        Preferred over overriding the object's ``save`` method\n        to ensure that `pre_save` and ``post_save`` signals happen\n        respectively before and after the translations have been saved to the database.\n\n        Thus ``pre_save`` signals have access to the ``has_changed`` attribute on translated fields\n        before the translations are saved and the attribute is reset.\n        And `post_save`` signals always have access to the updated translations.\n        \"\"\"\n        updated = super(ModelMixin, self)._save_table(\n            raw=raw,\n            cls=cls,\n            force_insert=force_insert,\n            force_update=force_update,\n            using=using,\n            update_fields=update_fields,\n        )\n        self._linguist.decider.objects.save_translations([self])\n        return updated", "response": "Save the object s translations to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates Linguist Meta attribute.", "response": "def validate_meta(meta):\n    \"\"\"\n    Validates Linguist Meta attribute.\n    \"\"\"\n    if not isinstance(meta, (dict,)):\n        raise TypeError('Model Meta \"linguist\" must be a dict')\n\n    required_keys = (\"identifier\", \"fields\")\n\n    for key in required_keys:\n        if key not in meta:\n            raise KeyError('Model Meta \"linguist\" dict requires %s to be defined', key)\n\n    if not isinstance(meta[\"fields\"], (list, tuple)):\n        raise ImproperlyConfigured(\n            \"Linguist Meta's fields attribute must be a list or tuple\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default_value_getter(field):\n\n    def default_value_func_getter(self):\n        localized_field = utils.build_localized_field_name(\n            field, self._linguist.active_language\n        )\n        value = getattr(self, localized_field)\n        if value:\n            return value\n\n        default_field = utils.build_localized_field_name(field, self.default_language)\n        return getattr(self, default_field)\n\n    return default_value_func_getter", "response": "Returns a function that returns the value of the specified field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a function that will set the value of the specified field in the current language.", "response": "def default_value_setter(field):\n    \"\"\"\n    When setting to the name of the field itself, the value\n    in the current language will be set.\n    \"\"\"\n\n    def default_value_func_setter(self, value):\n        localized_field = utils.build_localized_field_name(\n            field, self._linguist.active_language\n        )\n\n        setattr(self, localized_field, value)\n\n    return default_value_func_setter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new class that wraps it with a TranslationField class.", "response": "def field_factory(base_class):\n    \"\"\"\n    Takes a field base class and wrap it with ``TranslationField`` class.\n    \"\"\"\n    from .fields import TranslationField\n\n    class TranslationFieldField(TranslationField, base_class):\n        pass\n\n    TranslationFieldField.__name__ = \"Translation%s\" % base_class.__name__\n\n    return TranslationFieldField"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a translation field for the given field.", "response": "def create_translation_field(translated_field, language):\n    \"\"\"\n    Takes the original field, a given language, a decider model and return a\n    Field class for model.\n    \"\"\"\n    cls_name = translated_field.__class__.__name__\n\n    if not isinstance(translated_field, tuple(SUPPORTED_FIELDS.keys())):\n        raise ImproperlyConfigured(\"%s is not supported by Linguist.\" % cls_name)\n\n    translation_class = field_factory(translated_field.__class__)\n    kwargs = get_translation_class_kwargs(translated_field.__class__)\n\n    return translation_class(\n        translated_field=translated_field, language=language, **kwargs\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect(self):\n        '''\n        Connect to the drone.\n\n        :raises RuntimeError: if the drone is connected or closed already.\n        '''\n        if self.connected:\n            raise RuntimeError(\n                '{} is connected already'.format(self.__class__.__name__))\n        if self.closed:\n            raise RuntimeError(\n                '{} is closed already'.format(self.__class__.__name__))\n        self.connected = True\n        self._connect()", "response": "Connect to the drone."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncloses the drone and disconnect all threads.", "response": "def close(self):\n        '''\n        Exit all threads and disconnect the drone.\n\n        This method has no effect if the drone is closed already or not\n        connected yet.\n        '''\n        if not self.connected:\n            return\n        if self.closed:\n            return\n        self.closed = True\n        self._close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _set_flags(self, **flags):\n        '''\n        Set the flags of this argument.\n\n        Example: ``int_param._set_flags(a=1, b=2, c=4, d=8)``\n        '''\n        self._flags = enum.IntEnum('_flags', flags)\n        self.__dict__.update(self._flags.__members__)\n        self._patch_flag_doc()", "response": "Sets the flags of this parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_translations(sender, instance, **kwargs):\n    if issubclass(sender, (ModelMixin,)):\n        instance._linguist.decider.objects.filter(\n            identifier=instance.linguist_identifier, object_id=instance.pk\n        ).delete()", "response": "Delete related instance s translations when instance is deleted."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndraws a tree from a node.", "response": "def draw_tree(node,\n              child_iter=lambda n: n.children,\n              text_str=str):\n    \"\"\"Support asciitree 0.2 API.\n\n    This function solely exist to not break old code (using asciitree 0.2).\n    Its use is deprecated.\"\"\"\n    return LeftAligned(traverse=Traversal(get_text=text_str,\n                                          get_children=child_iter),\n                       draw=LegacyStyle())(node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef render(self, node):\n        lines = []\n\n        children = self.traverse.get_children(node)\n        lines.append(self.draw.node_label(self.traverse.get_text(node)))\n\n        for n, child in enumerate(children):\n            child_tree = self.render(child)\n\n            if n == len(children) - 1:\n                # last child does not get the line drawn\n                lines.append(self.draw.last_child_head(child_tree.pop(0)))\n                lines.extend(self.draw.last_child_tail(l)\n                             for l in child_tree)\n            else:\n                lines.append(self.draw.child_head(child_tree.pop(0)))\n                lines.extend(self.draw.child_tail(l)\n                             for l in child_tree)\n\n        return lines", "response": "Renders a node. This function returns internally as it returns\n        a list of lines. Use : func:`~asciitree. LeftAligned. __call__ instead."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_language():\n    lang = _get_language()\n\n    if not lang:\n        return get_fallback_language()\n\n    langs = [l[0] for l in settings.SUPPORTED_LANGUAGES]\n    if lang not in langs and \"-\" in lang:\n        lang = lang.split(\"-\")[0]\n\n    if lang in langs:\n        return lang\n\n    return settings.DEFAULT_LANGUAGE", "response": "Returns an active language code that is guaranteed to be in\n    settings. SUPPORTED_LANGUAGES."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activate_language(instances, language):\n    language = (\n        language if language in get_supported_languages() else get_fallback_language()\n    )\n    for instance in instances:\n        instance.activate_language(language)", "response": "Activates the given language for the given list of instances."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a class given a class_path.", "response": "def load_class(class_path, setting_name=None):\n    \"\"\"\n    Loads a class given a class_path. The setting value may be a string or a\n    tuple. The setting_name parameter is only there for pretty error output, and\n    therefore is optional.\n    \"\"\"\n    if not isinstance(class_path, six.string_types):\n        try:\n            class_path, app_label = class_path\n        except:\n            if setting_name:\n                raise exceptions.ImproperlyConfigured(\n                    CLASS_PATH_ERROR % (setting_name, setting_name)\n                )\n            else:\n                raise exceptions.ImproperlyConfigured(\n                    CLASS_PATH_ERROR % (\"this setting\", \"It\")\n                )\n\n    try:\n        class_module, class_name = class_path.rsplit(\".\", 1)\n    except ValueError:\n        if setting_name:\n            txt = \"%s isn't a valid module. Check your %s setting\" % (\n                class_path,\n                setting_name,\n            )\n        else:\n            txt = \"%s isn't a valid module.\" % class_path\n        raise exceptions.ImproperlyConfigured(txt)\n\n    try:\n        mod = import_module(class_module)\n    except ImportError as e:\n        if setting_name:\n            txt = 'Error importing backend %s: \"%s\". Check your %s setting' % (\n                class_module,\n                e,\n                setting_name,\n            )\n        else:\n            txt = 'Error importing backend %s: \"%s\".' % (class_module, e)\n        raise exceptions.ImproperlyConfigured(txt)\n\n    try:\n        clazz = getattr(mod, class_name)\n    except AttributeError:\n        if setting_name:\n            txt = (\n                'Backend module \"%s\" does not define a \"%s\" class. Check'\n                \" your %s setting\" % (class_module, class_name, setting_name)\n            )\n        else:\n            txt = 'Backend module \"%s\" does not define a \"%s\" class.' % (\n                class_module,\n                class_name,\n            )\n        raise exceptions.ImproperlyConfigured(txt)\n    return clazz"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the model string notation Django uses for lazily loaded ForeignKeys", "response": "def get_model_string(model_name):\n    \"\"\"\n    Returns the model string notation Django uses for lazily loaded ForeignKeys\n    (eg 'auth.User') to prevent circular imports.\n    This is needed to allow our crazy custom model usage.\n    \"\"\"\n    setting_name = \"LINGUIST_%s_MODEL\" % model_name.upper().replace(\"_\", \"\")\n    class_path = getattr(settings, setting_name, None)\n    if not class_path:\n        return \"linguist.%s\" % model_name\n    elif isinstance(class_path, basestring):\n        parts = class_path.split(\".\")\n        try:\n            index = parts.index(\"models\") - 1\n        except ValueError:\n            raise exceptions.ImproperlyConfigured(\n                CLASS_PATH_ERROR % (setting_name, setting_name)\n            )\n        app_label, model_name = parts[index], parts[-1]\n    else:\n        try:\n            class_path, app_label = class_path\n            model_name = class_path.split(\".\")[-1]\n        except:\n            raise exceptions.ImproperlyConfigured(\n                CLASS_PATH_ERROR % (setting_name, setting_name)\n            )\n    return \"%s.%s\" % (app_label, model_name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a translation lookup for a language field and its value.", "response": "def get_translation_lookup(identifier, field, value):\n    \"\"\"\n    Mapper that takes a language field, its value and returns the\n    related lookup for Translation model.\n    \"\"\"\n    # Split by transformers\n    parts = field.split(\"__\")\n\n    # Store transformers\n    transformers = parts[1:] if len(parts) > 1 else None\n\n    # defaults to \"title\" and default language\n    field_name = parts[0]\n    language = get_fallback_language()\n\n    name_parts = parts[0].split(\"_\")\n    if len(name_parts) > 1:\n        supported_languages = get_supported_languages()\n        last_part = name_parts[-1]\n        if last_part in supported_languages:\n            # title_with_underscore_fr?\n            field_name = \"_\".join(name_parts[:-1])\n            language = last_part\n        else:\n            # title_with_underscore?\n            # Let's use default language\n            field_name = \"_\".join(name_parts)\n\n    value_lookup = (\n        \"field_value\"\n        if transformers is None\n        else \"field_value__%s\" % \"__\".join(transformers)\n    )\n\n    lookup = {\"field_name\": field_name, \"identifier\": identifier, \"language\": language}\n\n    lookup[value_lookup] = value\n\n    return lookup"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_grouped_translations(instances, **kwargs):\n    grouped_translations = collections.defaultdict(list)\n\n    if not instances:\n        return grouped_translations\n\n    if not isinstance(instances, collections.Iterable):\n        instances = [instances]\n\n    if isinstance(instances, QuerySet):\n        model = instances.model\n    else:\n        model = instances[0]._meta.model\n\n    instances_ids = []\n\n    for instance in instances:\n        instances_ids.append(instance.pk)\n\n        if instance._meta.model != model:\n            raise Exception(\n                \"You cannot use different model instances, only one authorized.\"\n            )\n\n    from .models import Translation\n    from .mixins import ModelMixin\n\n    decider = model._meta.linguist.get(\"decider\", Translation)\n    identifier = model._meta.linguist.get(\"identifier\", None)\n    chunks_length = kwargs.get(\"chunks_length\", None)\n    populate_missing = kwargs.get(\"populate_missing\", True)\n\n    if identifier is None:\n        raise Exception('You must define Linguist \"identifier\" meta option')\n\n    lookup = dict(identifier=identifier)\n    for kwarg in (\"field_names\", \"languages\"):\n        value = kwargs.get(kwarg, None)\n        if value is not None:\n            if not isinstance(value, (list, tuple)):\n                value = [value]\n            lookup[\"%s__in\" % kwarg[:-1]] = value\n\n    if chunks_length is not None:\n        translations_qs = []\n        for ids in utils.chunks(instances_ids, chunks_length):\n            ids_lookup = copy.copy(lookup)\n            ids_lookup[\"object_id__in\"] = ids\n            translations_qs.append(decider.objects.filter(**ids_lookup))\n        translations = itertools.chain.from_iterable(translations_qs)\n    else:\n        lookup[\"object_id__in\"] = instances_ids\n        translations = decider.objects.filter(**lookup)\n\n    for translation in translations:\n        grouped_translations[translation.object_id].append(translation)\n\n    return grouped_translations", "response": "Takes instances and returns grouped translations ready to be set in cache."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef every(secs):\n    '''\n    Generator that yields for every *secs* seconds.\n\n    Example:\n\n        >>> for _ in every(0.1):\n        ...     print('Hello')\n\n    You get ``Hello`` output every 0.1 seconds.\n    '''\n    time_stated = time.monotonic()\n    while True:\n        time_yielded = time.monotonic()\n        yield time_yielded - time_stated\n        time.sleep(max(0, secs + time_yielded - time.monotonic()))", "response": "Generator that yields every secs seconds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_free_udp_port():\n    '''\n    Get a free UDP port.\n\n    Note this is vlunerable to race conditions.\n    '''\n    import socket\n    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n    sock.bind(('localhost', 0))\n    addr = sock.getsockname()\n    sock.close()\n    return addr[1]", "response": "Get a free UDP port."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_available_languages(self, obj):\n        return obj.available_languages if obj is not None else self.model.objects.none()", "response": "Returns a list of available languages for the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_translations(self, obj, language=None):\n        lookup = {\"identifier\": obj.linguist_identifier, \"object_id\": obj.pk}\n\n        if language is not None:\n            lookup[\"language\"] = language\n\n        return self.get_queryset().filter(**lookup)", "response": "Get all translations for a given object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_translations(self, instances):\n        if not isinstance(instances, (list, tuple)):\n            instances = [instances]\n\n        for instance in instances:\n\n            translations = []\n\n            for obj in instance._linguist.translation_instances:\n                if obj.field_name:\n                    obj.object_id = instance.pk\n                    if (obj.is_new and obj.field_value) or (\n                        obj.has_changed and not obj.is_new\n                    ):\n                        field = instance.get_field_object(obj.field_name, obj.language)\n                        if hasattr(field, \"pre_save\") and callable(field.pre_save):\n                            obj.field_value = field.pre_save(instance, True)\n\n                    translations.append(obj)\n\n            to_create = [\n                (obj, self.model(**obj.attrs))\n                for obj in translations\n                if obj.is_new and obj.field_value\n            ]\n            to_update = [\n                obj for obj in translations if obj.has_changed and not obj.is_new\n            ]\n            to_delete = [obj for obj in translations if obj.deleted]\n\n            created = True\n\n            if to_create:\n                objects = [obj for cached, obj in to_create]\n                try:\n                    with transaction.atomic():\n                        self.bulk_create(objects)\n                except IntegrityError:\n                    created = False\n\n            if to_update:\n                for obj in to_update:\n                    self.filter(**obj.lookup).update(field_value=obj.field_value)\n                    obj.has_changed = False\n\n            if created:\n                for cached, obj in to_create:\n                    cached.is_new = False\n                    cached.has_changed = False\n\n            if to_delete:\n                for obj in to_delete:\n                    self.filter(**obj.lookup).delete()\n                    obj.has_changed = False", "response": "Save cached translations in model instances as dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npack the command into bytes*", "response": "def _pack(self, seq='SEQUNSET'):\n        '''\n        Packs the command into *bytes*\n\n        :param seq: sequence number\n        :rtype: bytes\n        '''\n\n        return 'AT*{clsname}={seq}{argl_wc}\\r'.format(\n            clsname=type(self).__name__,\n            seq=seq,\n            argl_wc=b''.join(self._iter_packed_with_comma()).decode()\n        ).encode()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend the takeoff command.", "response": "def takeoff(self):\n        '''\n        Sends the takeoff command.\n        '''\n        self.send(at.REF(at.REF.input.start))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef emergency(self):\n        '''\n        Sends the emergency command.\n        '''\n        self.send(at.REF(at.REF.input.select))", "response": "Sends the emergency command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the current thread s current thread s current thread s current thread.", "response": "def _move(self, roll=0, pitch=0, gaz=0, yaw=0):\n        '''\n        Same as sending :py:class:`~pyardrone.at.PCMD` command with progressive\n        flag.\n        '''\n        self.send(at.PCMD(at.PCMD.flag.progressive, roll, pitch, gaz, yaw))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef move(\n            self, *,\n            forward=0, backward=0,\n            left=0, right=0,\n            up=0, down=0,\n            cw=0, ccw=0):\n        '''\n        Moves the drone.\n\n        To move the drone forward at 0.8x speed:\n\n        >>> drone.move(forward=0.8)\n\n        To move the drone right at 0.5x speed and upward at full speed:\n\n        >>> drone.move(right=0.5, up=1)\n\n        To rotate clockwise at 0.7x speed:\n\n        >>> drone.move(cw=0.7)\n\n        :param forward:  speed for moving forward\n        :param backward: speed for moving backward\n        :param left:     speed for moving left\n        :param right:    speed for moving right\n        :param up:       speed for moving up\n        :param down:     speed for moving down\n        :param cw:       speed for rotating clockwise\n        :param ccw:      speed for rotating counter-clockwise\n        '''\n        self._move(\n            roll=right-left,\n            pitch=backward-forward,\n            gaz=up-down,\n            yaw=cw-ccw\n        )", "response": "Moves the drone.\n\n        To move the drone forward at 0.8x speed:\n\n        >>> drone.move(forward=0.8)\n\n        To move the drone right at 0.5x speed and upward at full speed:\n\n        >>> drone.move(right=0.5, up=1)\n\n        To rotate clockwise at 0.7x speed:\n\n        >>> drone.move(cw=0.7)\n\n        :param forward:  speed for moving forward\n        :param backward: speed for moving backward\n        :param left:     speed for moving left\n        :param right:    speed for moving right\n        :param up:       speed for moving up\n        :param down:     speed for moving down\n        :param cw:       speed for rotating clockwise\n        :param ccw:      speed for rotating counter-clockwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nencodes an integer into a symbol string.", "response": "def encode(number, checksum=False, split=0):\n    \"\"\"Encode an integer into a symbol string.\n\n    A ValueError is raised on invalid input.\n\n    If checksum is set to True, a check symbol will be\n    calculated and appended to the string.\n\n    If split is specified, the string will be divided into\n    clusters of that size separated by hyphens.\n\n    The encoded string is returned.\n    \"\"\"\n    number = int(number)\n    if number < 0:\n        raise ValueError(\"number '%d' is not a positive integer\" % number)\n\n    split = int(split)\n    if split < 0:\n        raise ValueError(\"split '%d' is not a positive integer\" % split)\n\n    check_symbol = ''\n    if checksum:\n        check_symbol = encode_symbols[number % check_base]\n\n    if number == 0:\n        return '0' + check_symbol\n\n    symbol_string = ''\n    while number > 0:\n        remainder = number % base\n        number //= base\n        symbol_string = encode_symbols[remainder] + symbol_string\n    symbol_string = symbol_string + check_symbol\n\n    if split:\n        chunks = []\n        for pos in range(0, len(symbol_string), split):\n            chunks.append(symbol_string[pos:pos + split])\n        symbol_string = '-'.join(chunks)\n\n    return symbol_string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndecoding an encoded string.", "response": "def decode(symbol_string, checksum=False, strict=False):\n    \"\"\"Decode an encoded symbol string.\n\n    If checksum is set to True, the string is assumed to have a\n    trailing check symbol which will be validated. If the\n    checksum validation fails, a ValueError is raised.\n\n    If strict is set to True, a ValueError is raised if the\n    normalization step requires changes to the string.\n\n    The decoded string is returned.\n    \"\"\"\n    symbol_string = normalize(symbol_string, strict=strict)\n    if checksum:\n        symbol_string, check_symbol = symbol_string[:-1], symbol_string[-1]\n\n    number = 0\n    for symbol in symbol_string:\n        number = number * base + decode_symbols[symbol]\n\n    if checksum:\n        check_value = decode_symbols[check_symbol]\n        modulo = number % check_base\n        if check_value != modulo:\n            raise ValueError(\"invalid check symbol '%s' for string '%s'\" %\n                             (check_symbol, symbol_string))\n\n    return number"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize an encoded symbol string.", "response": "def normalize(symbol_string, strict=False):\n    \"\"\"Normalize an encoded symbol string.\n\n    Normalization provides error correction and prepares the\n    string for decoding. These transformations are applied:\n\n       1. Hyphens are removed\n       2. 'I', 'i', 'L' or 'l' are converted to '1'\n       3. 'O' or 'o' are converted to '0'\n       4. All characters are converted to uppercase\n\n    A TypeError is raised if an invalid string type is provided.\n\n    A ValueError is raised if the normalized string contains\n    invalid characters.\n\n    If the strict parameter is set to True, a ValueError is raised\n    if any of the above transformations are applied.\n\n    The normalized string is returned.\n    \"\"\"\n    if isinstance(symbol_string, string_types):\n        if not PY3:\n            try:\n                symbol_string = symbol_string.encode('ascii')\n            except UnicodeEncodeError:\n                raise ValueError(\"string should only contain ASCII characters\")\n    else:\n        raise TypeError(\"string is of invalid type %s\" %\n                        symbol_string.__class__.__name__)\n\n    norm_string = symbol_string.replace('-', '').translate(normalize_symbols).upper()\n\n    if not valid_symbols.match(norm_string):\n        raise ValueError(\"string '%s' contains invalid characters\" % norm_string)\n\n    if strict and norm_string != symbol_string:\n        raise ValueError(\"string '%s' requires normalization\" % symbol_string)\n\n    return norm_string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_translation_field_names():\n    from .models import Translation\n\n    fields = [f.name for f in Translation._meta.get_fields()]\n    fields.remove(\"id\")\n\n    return fields", "response": "Returns a list of all translation field names except the id field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send(self, command, *, log=True):\n        '''\n        :param pyardrone.at.base.ATCommand command: command to send\n\n        Sends the command to the drone,\n        with an internal increasing sequence number.\n        this method is thread-safe.\n        '''\n        with self.sequence_number_mutex:\n            self.sequence_number += 1\n            packed = command._pack(self.sequence_number)\n            self.send_bytes(packed, log=log)", "response": "Sends the specified command to the drone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning required packages Plus any version tests and warnings", "response": "def setup_requires():\n    \"\"\"\n    Return required packages\n\n    Plus any version tests and warnings\n    \"\"\"\n    from pkg_resources import parse_version\n    required = ['cython>=0.24.0']\n    numpy_requirement = 'numpy>=1.7.1'\n\n    try:\n        import numpy\n    except Exception:\n        required.append(numpy_requirement)\n    else:\n        if parse_version(numpy.__version__) < parse_version('1.7.1'):\n            required.append(numpy_requirement)\n\n    return required"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_block_context(template, context):\n\n    # Ensure there's a BlockContext before rendering. This allows blocks in\n    # ExtendsNodes to be found by sub-templates (allowing {{ block.super }} and\n    # overriding sub-blocks to work).\n    if BLOCK_CONTEXT_KEY not in context.render_context:\n        context.render_context[BLOCK_CONTEXT_KEY] = BlockContext()\n    block_context = context.render_context[BLOCK_CONTEXT_KEY]\n\n    for node in template.nodelist:\n        if isinstance(node, ExtendsNode):\n            compiled_parent = node.get_parent(context)\n\n            # Add the parent node's blocks to the context. (This ends up being\n            # similar logic to ExtendsNode.render(), where we're adding the\n            # parent's blocks to the context so a child can find them.)\n            block_context.add_blocks(\n                {n.name: n for n in compiled_parent.nodelist.get_nodes_by_type(BlockNode)})\n\n            _build_block_context(compiled_parent, context)\n            return compiled_parent\n\n        # The ExtendsNode has to be the first non-text node.\n        if not isinstance(node, TextNode):\n            break", "response": "Populate the block context with BlockNodes from parent templates."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _render_template_block_nodelist(nodelist, block_name, context):\n\n    # Attempt to find the wanted block in the current template.\n    for node in nodelist:\n        # If the wanted block was found, return it.\n        if isinstance(node, BlockNode):\n            # No matter what, add this block to the rendering context.\n            context.render_context[BLOCK_CONTEXT_KEY].push(node.name, node)\n\n            # If the name matches, you're all set and we found the block!\n            if node.name == block_name:\n                return node.render(context)\n\n        # If a node has children, recurse into them. Based on\n        # django.template.base.Node.get_nodes_by_type.\n        for attr in node.child_nodelists:\n            try:\n                new_nodelist = getattr(node, attr)\n            except AttributeError:\n                continue\n\n            # Try to find the block recursively.\n            try:\n                return _render_template_block_nodelist(new_nodelist, block_name, context)\n            except BlockNotFound:\n                continue\n\n    # The wanted block_name was not found.\n    raise BlockNotFound(\"block with name '%s' does not exist\" % block_name)", "response": "Recursively iterate over a node to find the wanted block."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload the given template_name and renders the given block with the given context dictionary as context. Returns a string.", "response": "def render_block_to_string(template_name, block_name, context=None):\n    \"\"\"\n    Loads the given template_name and renders the given block with the given\n    dictionary as context. Returns a string.\n\n        template_name\n            The name of the template to load and render. If it's a list of\n            template names, Django uses select_template() instead of\n            get_template() to find the template.\n    \"\"\"\n\n    # Like render_to_string, template_name can be a string or a list/tuple.\n    if isinstance(template_name, (tuple, list)):\n        t = loader.select_template(template_name)\n    else:\n        t = loader.get_template(template_name)\n\n    # Create the context instance.\n    context = context or {}\n\n    # The Django backend.\n    if isinstance(t, DjangoTemplate):\n        return django_render_block(t, block_name, context)\n\n    elif isinstance(t, Jinja2Template):\n        from render_block.jinja2 import jinja2_render_block\n        return jinja2_render_block(t, block_name, context)\n\n    else:\n        raise UnsupportedEngine(\n            'Can only render blocks from the Django template backend.')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of actions on the client map and configurations.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        For attached volumes, missing containers are created and initial containers are started and prepared with\n        permissions. Outdated containers or containers with errors are recreated. The latter also applies to instance\n        containers. Similarly, instance containers are created if missing and started unless not initial and marked as\n        persistent.\n        On running instance containers missing exec commands are run; if the container needs to be started, all exec\n        commands are launched.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        config_id = state.config_id\n        config_type = config_id.config_type\n        if config_type == ItemType.NETWORK:\n            if state.base_state == State.ABSENT:\n                log.debug(\"Not found - creating network %s.\", config_id)\n                return [ItemAction(state, Action.CREATE)]\n            elif state.state_flags & StateFlags.NEEDS_RESET:\n                log.debug(\"Found to be outdated - resetting %s.\", config_id)\n                connected_containers = state.extra_data.get('containers')\n                if connected_containers:\n                    cc_names = [c_info.get('Name', c_id) for c_id, c_info in six.iteritems(connected_containers)]\n                    log.debug(\"Disconnecting containers from %s: %s.\", config_id, cc_names)\n                    actions = [ItemAction(state, NetworkUtilAction.DISCONNECT_ALL, containers=cc_names)]\n                else:\n                    actions = []\n                actions.append(ItemAction(state, DerivedAction.RESET_NETWORK))\n                return actions\n        elif config_type == ItemType.IMAGE:\n            if state.base_state == State.ABSENT or self.pull_before_update:\n                return [ItemAction(state, ImageAction.PULL,\n                                   insecure_registry=self.pull_insecure_registry)]\n        elif config_type == ItemType.VOLUME:\n            if state.base_state == State.ABSENT:\n                log.debug(\"Not found - creating attached volume %s.\", config_id)\n                action_type = Action.CREATE\n            elif state.state_flags & StateFlags.NEEDS_RESET:\n                log.debug(\"Found to be outdated or non-recoverable - resetting %s.\", config_id)\n                action_type = DerivedAction.RESET_VOLUME\n            elif state.state_flags & StateFlags.INITIAL:\n                log.debug(\"Container for attached volume found but initial, starting %s.\", config_id)\n                action_type = Action.START\n            else:\n                return None\n            return [\n                ItemAction(state, action_type),\n                ItemAction(state, VolumeUtilAction.PREPARE),\n            ]\n        elif config_type == ItemType.CONTAINER:\n            ci_initial = state.state_flags & StateFlags.INITIAL\n            if state.base_state == State.ABSENT:\n                log.debug(\"Not found - creating and starting instance container %s.\", config_id)\n                action_type = DerivedAction.STARTUP_CONTAINER\n            elif state.state_flags & StateFlags.NEEDS_RESET:\n                if state.base_state == State.RUNNING or state.state_flags & StateFlags.RESTARTING:\n                    log.debug(\"Found to be outdated or non-recoverable - resetting %s.\", config_id)\n                    action_type = DerivedAction.RESET_CONTAINER\n                else:\n                    log.debug(\"Found to be outdated or non-recoverable - relaunching %s.\", config_id)\n                    action_type = DerivedAction.RELAUNCH_CONTAINER\n            else:\n                actions = []\n                if state.state_flags & StateFlags.NETWORK_DISCONNECTED:\n                    dn = state.extra_data['disconnected']\n                    log.debug(\"Container is connecting to the following networks: %s.\", dn)\n                    actions.append(ItemAction(state, Action.CONNECT, endpoints=dn))\n                if state.state_flags & StateFlags.NETWORK_MISMATCH:\n                    rn = state.extra_data['reconnect']\n                    n_names, n_ep = zip(*rn)\n                    log.debug(\"Container is reconnecting to the following networks: %s.\", n_names)\n                    actions.extend([\n                        ItemAction(state, Action.DISCONNECT, networks=n_names),\n                        ItemAction(state, Action.CONNECT, endpoints=n_ep),\n                    ])\n                if state.state_flags & StateFlags.NETWORK_LEFT:\n                    ln = state.extra_data['left']\n                    log.debug(\"Container is disconnecting from the following networks: %s.\", ln)\n                    actions.append(ItemAction(state, Action.DISCONNECT, networks=ln))\n                if (state.base_state != State.RUNNING and\n                        (ci_initial or not state.state_flags & StateFlags.PERSISTENT)):\n                    log.debug(\"Container found but not running, starting %s.\", config_id)\n                    actions.extend([\n                        ItemAction(state, Action.START),\n                        ItemAction(state, ContainerUtilAction.EXEC_ALL),\n                    ])\n                else:\n                    if state.state_flags & StateFlags.HOST_CONFIG_UPDATE:\n                        update_args = state.extra_data['update_container']\n                        if update_args:\n                            log.debug(\"Container %s with updated host config: %s.\", config_id, update_args)\n                            actions.append(ItemAction(state, Action.UPDATE, update_values=update_args))\n                    if state.state_flags & StateFlags.EXEC_COMMANDS:\n                        run_cmds = state.extra_data['exec_commands']\n                        if run_cmds:\n                            log.debug(\"Container %s up-to-date, but with missing commands %s.\", config_id, run_cmds)\n                            actions.append(ItemAction(state, ContainerUtilAction.EXEC_COMMANDS, run_cmds=run_cmds))\n                return actions\n            return [\n                ItemAction(state, action_type),\n                ItemAction(state, ContainerUtilAction.EXEC_ALL),\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the host path for a container volume.", "response": "def get_host_path(root, path, instance=None):\n    \"\"\"\n    Generates the host path for a container volume. If the given path is a dictionary, uses the entry of the instance\n    name.\n\n    :param root: Root path to prepend, if ``path`` does not already describe an absolute path.\n    :type root: unicode | str | AbstractLazyObject\n    :param path: Path string or dictionary of per-instance paths.\n    :type path: unicode | str | dict | AbstractLazyObject\n    :param instance: Optional instance name.\n    :type instance: unicode | str\n    :return: Path on the host that is mapped to the container volume.\n    :rtype: unicode | str\n    \"\"\"\n    r_val = resolve_value(path)\n    if isinstance(r_val, dict):\n        r_instance = instance or 'default'\n        r_path = resolve_value(r_val.get(r_instance))\n        if not r_path:\n            raise ValueError(\"No path defined for instance {0}.\".format(r_instance))\n    else:\n        r_path = r_val\n    r_root = resolve_value(root)\n    if r_path and r_root and (r_path[0] != posixpath.sep):\n        return posixpath.join(r_root, r_path)\n    return r_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_actions(self, actions):\n        policy = self._policy\n        for action in actions:\n            config_id = action.config_id\n            config_type = config_id.config_type\n            client_config = policy.clients[action.client_name]\n            client = client_config.get_client()\n            c_map = policy.container_maps[config_id.map_name]\n\n            if config_type == ItemType.CONTAINER:\n                config = c_map.get_existing(config_id.config_name)\n                item_name = policy.cname(config_id.map_name, config_id.config_name, config_id.instance_name)\n            elif config_type == ItemType.VOLUME:\n                a_parent_name = config_id.config_name if c_map.use_attached_parent_name else None\n                item_name = policy.aname(config_id.map_name, config_id.instance_name, parent_name=a_parent_name)\n                if client_config.features['volumes']:\n                    config = c_map.get_existing_volume(config_id.config_name)\n                else:\n                    config = c_map.get_existing(config_id.config_name)\n            elif config_type == ItemType.NETWORK:\n                config = c_map.get_existing_network(config_id.config_name)\n                item_name = policy.nname(config_id.map_name, config_id.config_name)\n            elif config_type == ItemType.IMAGE:\n                config = None\n                item_name = format_image_tag(config_id.config_name, config_id.instance_name)\n            else:\n                raise ValueError(\"Invalid configuration type.\", config_id.config_type)\n\n            for action_type in action.action_types:\n                try:\n                    a_method = self.action_methods[(config_type, action_type)]\n                except KeyError:\n                    raise ActionTypeException(config_id, action_type)\n                action_config = ActionConfig(action.client_name, action.config_id, client_config, client,\n                                             c_map, config)\n                try:\n                    res = a_method(action_config, item_name, **action.extra_data)\n                except Exception:\n                    exc_info = sys.exc_info()\n                    raise ActionException(exc_info, action.client_name, config_id, action_type)\n                if res is not None:\n                    yield ActionOutput(action.client_name, config_id, action_type, res)", "response": "Runs the given lists of attached actions and instance actions on the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_client(cls, client):\n        if hasattr(client, 'client_configuration'):\n            return client.client_configuration\n        kwargs = {'client': client}\n        for attr in cls.init_kwargs:\n            if hasattr(client, attr):\n                kwargs[attr] = getattr(client, attr)\n        if hasattr(client, 'api_version'):\n            kwargs['version'] = client.api_version\n        return cls(**kwargs)", "response": "Constructs a new instance of the class from an existing client instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_init_kwargs(self):\n        init_kwargs = {}\n        for k in self.init_kwargs:\n            if k in self.core_property_set:\n                init_kwargs[k] = getattr(self, k)\n            elif k in self:\n                init_kwargs[k] = self[k]\n        return init_kwargs", "response": "Generates keyword arguments for creating a new Docker client instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_client(self):\n        client = self._client\n        if not client:\n            self._client = client = self.client_constructor(**self.get_init_kwargs())\n            client.client_configuration = self\n            # Client might update the version number after construction.\n            updated_version = getattr(client, 'api_version', None)\n            if updated_version:\n                self.version = updated_version\n        return client", "response": "Retrieves or creates a client instance from this configuration object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exec_commands(self, action, c_name, run_cmds, **kwargs):\n        client = action.client\n        exec_results = []\n        for run_cmd in run_cmds:\n            cmd = run_cmd.cmd\n            cmd_user = run_cmd.user\n            log.debug(\"Creating exec command in container %s with user %s: %s.\", c_name, cmd_user, cmd)\n            ec_kwargs = self.get_exec_create_kwargs(action, c_name, cmd, cmd_user)\n            create_result = client.exec_create(**ec_kwargs)\n            if create_result:\n                e_id = create_result['Id']\n                log.debug(\"Starting exec command with id %s.\", e_id)\n                es_kwargs = self.get_exec_start_kwargs(action, c_name, e_id)\n                client.exec_start(**es_kwargs)\n                exec_results.append(create_result)\n            else:\n                log.debug(\"Exec command was created, but did not return an id. Assuming that it has been started.\")\n        if exec_results:\n            return exec_results\n        return None", "response": "Runs a single command inside a container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exec_container_commands(self, action, c_name, **kwargs):\n        config_cmds = action.config.exec_commands\n        if not config_cmds:\n            return None\n        return self.exec_commands(action, c_name, run_cmds=config_cmds)", "response": "Executes all configured commands of a container instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares a path string for replacement operations on a node.", "response": "def prepare_path(path, replace_space, replace_sep, expandvars, expanduser):\n    \"\"\"\n    Performs `os.path` replacement operations on a path string.\n\n    :param path: Path string\n    :type path: unicode | str\n    :param replace_space: Mask spaces with backslash.\n    :param replace_sep: Replace potentially different path separators with POSIX path notation (use :const:`posixpath.sep`).\n    :type replace_sep: bool\n    :param expandvars: Expand environment variables (:func:`~os.path.expandvars`).\n    :type expandvars: bool\n    :param expanduser: Expand user variables (:func:`~os.path.expanduser`).\n    :type expanduser: bool\n    :return: Path string from `path` with aforementioned replacements.\n    :rtype: unicode | str\n    \"\"\"\n    r_path = path\n    if expandvars:\n        r_path = os.path.expandvars(r_path)\n    if expanduser:\n        r_path = os.path.expanduser(r_path)\n    if replace_sep and os.sep != posixpath.sep:\n        r_path = r_path.replace(os.path.sep, posixpath.sep)\n    if replace_space:\n        r_path = r_path.replace(' ', '\\\\ ')\n    return r_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a command line to the notation as used in a Dockerfile CMD and ENTRYPOINT command.", "response": "def format_command(cmd, shell=False):\n    \"\"\"\n    Converts a command line to the notation as used in a Dockerfile ``CMD`` and ``ENTRYPOINT`` command. In shell\n    notation, this returns a simple string, whereas by default it returns a JSON-list format with the command and\n    arguments.\n\n    :param cmd: Command line as a string or tuple.\n    :type cmd: unicode | str | tuple | list\n    :param shell: Use the notation so that Docker runs the command in a shell. Default is ``False``.\n    :type shell: bool\n    :return: The command string.\n    :rtype: unicode | str\n    \"\"\"\n\n    def _split_cmd():\n        line = None\n        for part in cmd.split(' '):\n            line = part if line is None else '{0} {1}'.format(line, part)\n            if part[-1] != '\\\\':\n                yield line\n                line = None\n        if line is not None:\n            yield line\n\n    if cmd in ([], ''):\n        return '[]'\n    if shell:\n        if isinstance(cmd, (list, tuple)):\n            return ' '.join(cmd)\n        elif isinstance(cmd, six.string_types):\n            return cmd\n    else:\n        if isinstance(cmd, (list, tuple)):\n            return json.dumps(map(six.text_type, cmd))\n        elif isinstance(cmd, six.string_types):\n            return json.dumps(list(_split_cmd()))\n    raise ValueError(\"Invalid type of command string or sequence: {0}\".format(cmd))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a port number or multiple port numbers as used in the Dockerfile EXPOSE command to a tuple.", "response": "def format_expose(expose):\n    \"\"\"\n    Converts a port number or multiple port numbers, as used in the Dockerfile ``EXPOSE`` command, to a tuple.\n\n    :param: Port numbers, can be as integer, string, or a list/tuple of those.\n    :type expose: int | unicode | str | list | tuple\n    :return: A tuple, to be separated by spaces before inserting in a Dockerfile.\n    :rtype: tuple\n    \"\"\"\n    if isinstance(expose, six.string_types):\n        return expose,\n    elif isinstance(expose, collections.Iterable):\n        return map(six.text_type, expose)\n    return six.text_type(expose),"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprefix one or multiple arguments with a Dockerfile command.", "response": "def prefix(self, prefix='#', *args):\n        \"\"\"\n        Prefix one or multiple arguments with a Dockerfile command. The default is ``#``, for comments. Multiple args will\n        be separated by a space.\n\n        :param prefix: Dockerfile command to use, e.g. ``ENV`` or ``RUN``.\n        :type prefix: unicode | str\n        :param args: Arguments to be prefixed.\n        \"\"\"\n        self.write(prefix)\n        if args:\n            self.write(' ')\n            self.writeline(' '.join(map(six.text_type, args)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prefix_all(self, prefix='#', *lines):\n        for line in lines:\n            if isinstance(line, (tuple, list)):\n                self.prefix(prefix, *line)\n            elif line:\n                self.prefix(prefix, line)\n            else:\n                self.blank()", "response": "Prefix all the lines in the log with the given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a file to the Dockerfile context tarball.", "response": "def add_file(self, src_path, dst_path=None, ctx_path=None, replace_space=True, expandvars=False, expanduser=False,\n                 remove_final=False):\n        \"\"\"\n        Adds a file to the Docker build. An ``ADD`` command is inserted, and the path is stored for later packaging of\n        the context tarball.\n\n        :param src_path: Path to the file or directory.\n        :type src_path: unicode | str\n        :param dst_path: Destination path during the Docker build. By default uses the last element of `src_path`.\n        :type dst_path: unicode | str\n        :param ctx_path: Path inside the context tarball. Can be set in order to avoid name clashes. By default\n         identical to the destination path.\n        :type ctx_path: unicode | str\n        :param replace_space: Mask spaces in path names with a backslash. Default is ``True``.\n        :type replace_space: bool\n        :param expandvars: Expand local environment variables. Default is ``False``.\n        :type expandvars: bool\n        :param expanduser: Expand local user variables. Default is ``False``.\n        :type expanduser: bool\n        :param remove_final: Remove the file after the build operation has completed. Can be useful e.g. for source code\n         archives, which are no longer needed after building the binaries. Note that this will not reduce the size of\n         the resulting image (actually may increase instead) unless the image is squashed.\n        :type remove_final: bool\n        :return: The path of the file in the Dockerfile context.\n        :rtype: unicode | str\n        \"\"\"\n        if dst_path is None:\n            head, tail = os.path.split(src_path)\n            if not tail:\n                # On trailing backslashes.\n                tail = os.path.split(head)[1]\n                if not tail:\n                    ValueError(\"Could not generate target path from input '{0}'; needs to be specified explicitly.\")\n            target_path = tail\n        else:\n            target_path = dst_path\n\n        source_path = prepare_path(src_path, False, False, expandvars, expanduser)\n        target_path = prepare_path(target_path, replace_space, True, expandvars, expanduser)\n        if ctx_path:\n            context_path = prepare_path(ctx_path, replace_space, True, expandvars, expanduser)\n        else:\n            context_path = target_path\n        self.prefix('ADD', context_path, target_path)\n        self._files.append((source_path, context_path))\n        if remove_final:\n            self._remove_files.add(target_path)\n        return context_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds the contents of another tar archive to the build.", "response": "def add_archive(self, src_file, remove_final=False):\n        \"\"\"\n        Adds the contents of another tarfile to the build. It will be repackaged during context generation, and added\n        to the root level of the file system. Therefore, it is not required that tar (or compression utilities) is\n        present in the base image.\n\n        :param src_file: Tar archive to add.\n        :type src_file: unicode | str\n        :param remove_final: Remove the contents after the build operation has completed. Note that this will remove all\n         top-level components of the tar archive recursively. Therefore, you should not use this on standard unix\n         folders. This will also not reduce the size of the resulting image (actually may increase instead) unless the\n         image is squashed.\n        :type remove_final: bool\n        :return: Name of the root files / directories added to the Dockerfile.\n        :rtype: list[unicode | str]\n        \"\"\"\n        with tarfile.open(src_file, 'r') as tf:\n            member_names = [member.name\n                            for member in tf.getmembers()\n                            if posixpath.sep not in member.name]\n        self.prefix_all('ADD', *zip(member_names, member_names))\n        if remove_final:\n            self._remove_files.update(member_names)\n        self._archives.append(src_file)\n        return member_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a shared volume. Not actually written until finalized.", "response": "def add_volume(self, path):\n        \"\"\"\n        Add a shared volume (i.e. with the ``VOLUME`` command). Not actually written until finalized.\n\n        :param path: Path to the shared volume.\n        \"\"\"\n        self.check_not_finalized()\n        if self.volumes is None:\n            self.volumes = [path]\n        else:\n            self.volumes.append(path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the given string to the Dockerfile.", "response": "def write(self, input_str):\n        \"\"\"\n        Adds content to the Dockerfile.\n\n        :param input_str: Content.\n        :type input_str: unicode | str\n        \"\"\"\n        self.check_not_finalized()\n        if isinstance(input_str, six.binary_type):\n            self.fileobj.write(input_str)\n        else:\n            self.fileobj.write(input_str.encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfinalize the Dockerfile. Before the buffer is practically marked as read-only, the following Dockerfile commands are written: * ``RUN rm -R`` on each files marked for automatic removal; * ``VOLUME`` for shared volumes; * ``USER`` as the default user for following commands; * ``WORKDIR`` as the working directory for following commands; * ``SHELL`` if the default shell is to be changed; * ``ENTRYPOINT`` and ``CMD``, each formatted as a shell or exec command according to :attr:`command_shell`; * ``EXPOSE`` for exposed ports; * ``LABEL``, ``STOPSIGNAL``, and ``HEALTHCHECK`` instructions for the image; An attempt to finalize an already-finalized instance has no effect.", "response": "def finalize(self):\n        \"\"\"\n        Finalizes the Dockerfile. Before the buffer is practically marked as read-only, the following Dockerfile\n        commands are written:\n\n        * ``RUN rm -R`` on each files marked for automatic removal;\n        * ``VOLUME`` for shared volumes;\n        * ``USER`` as the default user for following commands;\n        * ``WORKDIR`` as the working directory for following commands;\n        * ``SHELL`` if the default shell is to be changed;\n        * ``ENTRYPOINT`` and ``CMD``, each formatted as a shell or exec command according to :attr:`command_shell`;\n        * ``EXPOSE`` for exposed ports;\n        * ``LABEL``, ``STOPSIGNAL``, and ``HEALTHCHECK`` instructions for the image;\n\n        An attempt to finalize an already-finalized instance has no effect.\n        \"\"\"\n        if self._finalized:\n            return\n        if self._remove_files:\n            for filename in self._remove_files:\n                self.prefix('RUN', 'rm -Rf', filename)\n            self.blank()\n        if self._volumes is not None:\n            self.prefix('VOLUME', json.dumps(self._volumes))\n        if self._cmd_user:\n            self.prefix('USER', self._cmd_user)\n        if self._cmd_workdir:\n            self.prefix('WORKDIR', self._cmd_workdir)\n        if self._shell:\n            self.prefix('SHELL', self._shell)\n        if self._entrypoint is not None:\n            self.prefix('ENTRYPOINT', format_command(self._entrypoint, self._command_shell))\n        if self._command is not None:\n            self.prefix('CMD', format_command(self._command, self._command_shell))\n        if self._expose is not None:\n            self.prefix('EXPOSE', *format_expose(self._expose))\n        if self._labels:\n            self.prefix('LABEL', *format_labels(self._labels))\n        if self._stopsignal:\n            self.prefix('STOPSIGNAL', self._stopsignal)\n        if self._healthcheck:\n            self.prefix('HEALTHCHECK', self._healthcheck)\n        super(DockerFile, self).finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_dependency(self, item, resolve_parent, parents):\n        dep = []\n        for parent_key in parents:\n            if item == parent_key:\n                raise CircularDependency(item, True)\n            if parent_key.config_type == ItemType.CONTAINER:\n                parent_dep = resolve_parent(parent_key)\n                if item in parent_dep:\n                    raise CircularDependency(item)\n                merge_list(dep, parent_dep)\n        merge_list(dep, parents)\n        return dep", "response": "Merge dependencies of current configuration item with further dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexpand paths on a YAML document node.", "response": "def expand_node(loader, node, expand_method):\n    \"\"\"\n    Expands paths on a YAML document node. If it is a sequence node (list) items on the first level are expanded. For\n    a mapping node (dict), values are expanded.\n\n    :param loader: YAML loader.\n    :type loader: yaml.loader.SafeLoader\n    :param node: Document node.\n    :type node: ScalarNode, MappingNode, or SequenceNode\n    :param expand_method: Callable to expand the path with.\n    :type expand_method: callable\n    :return: Expanded value.\n    :rtype: unicode | str | list | dict\n    \"\"\"\n    if isinstance(node, yaml.nodes.ScalarNode):\n        val = loader.construct_scalar(node)\n        return expand_method(val)\n    elif isinstance(node, yaml.nodes.MappingNode):\n        val = loader.construct_mapping(node)\n        for d_key, d_val in six.iteritems(val):\n            val[d_key] = expand_method(d_val)\n        return val\n    elif isinstance(node, yaml.nodes.SequenceNode):\n        val = loader.construct_sequence(node)\n        return [expand_method(l_val) for l_val in val]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload a ContainerMap from a YAML stream.", "response": "def load_map(stream, name=None, check_integrity=True, check_duplicates=True):\n    \"\"\"\n    Loads a ContainerMap configuration from a YAML document stream.\n\n    :param stream: YAML stream.\n    :type stream: file\n    :param name: Name of the ContainerMap. If not provided, will be attempted to read from a ``name`` attribute on the\n      document root level.\n    :type name: unicode | str\n    :param check_integrity: Performs a brief integrity check; default is ``True``.\n    :type check_integrity: bool\n    :param check_duplicates: Check for duplicate attached volumes during integrity check.\n    :type check_duplicates: bool\n    :return: A ContainerMap object.\n    :rtype: ContainerMap\n    \"\"\"\n    map_dict = yaml.safe_load(stream)\n    if isinstance(map_dict, dict):\n        map_name = name or map_dict.pop('name', None)\n        if not map_name:\n            raise ValueError(\"No map name provided, and none found in YAML stream.\")\n        return ContainerMap(map_name, map_dict, check_integrity=check_integrity, check_duplicates=check_duplicates)\n    raise ValueError(\"Valid map could not be decoded.\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_clients(stream, configuration_class=ClientConfiguration):\n    client_dict = yaml.safe_load(stream)\n    if isinstance(client_dict, dict):\n        return {client_name: configuration_class(**client_config)\n                for client_name, client_config in six.iteritems(client_dict)}\n    raise ValueError(\"Valid configuration could not be decoded.\")", "response": "Loads client configurations from a YAML document stream."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_map_file(filename, name=None, check_integrity=True):\n    if name == '':\n        base_name = os.path.basename(filename)\n        map_name, __, __ = os.path.basename(base_name).rpartition(os.path.extsep)\n    else:\n        map_name = name\n    with open(filename, 'r') as f:\n        return load_map(f, name=map_name, check_integrity=check_integrity)", "response": "Loads a ContainerMap from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_clients_file(filename, configuration_class=ClientConfiguration):\n    with open(filename, 'r') as f:\n        return load_clients(f, configuration_class=configuration_class)", "response": "Loads client configurations from a YAML file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an instance of the current policy class.", "response": "def get_policy(self):\n        \"\"\"\n        Returns an instance of :attr:`~policy_class`.\n\n        :return: An instance of the current policy class.\n        :rtype: dockermap.map.policy.base.BasePolicy\n        \"\"\"\n        if not self._policy:\n            self._policy = self.policy_class(self._maps, self._clients)\n        return self._policy"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the state generator object to be used for the given action.", "response": "def get_state_generator(self, action_name, policy, kwargs):\n        \"\"\"\n        Returns the state generator to be used for the given action.\n\n        :param action_name: Action identifier name.\n        :type action_name: unicode | str\n        :param policy: An instance of the current policy class.\n        :type policy: dockermap.map.policy.base.BasePolicy\n        :param kwargs: Keyword arguments. Can be modified by the initialization of the state generator.\n        :type kwargs: dict\n        :return: State generator object.\n        :rtype: dockermap.map.state.base.AbstractStateGenerator\n        \"\"\"\n        state_generator_cls = self.generators[action_name][0]\n        state_generator = state_generator_cls(policy, kwargs)\n        return state_generator"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the action generator object to be used for the given action.", "response": "def get_action_generator(self, action_name, policy, kwargs):\n        \"\"\"\n        Returns the action generator to be used for the given action.\n\n        :param action_name: Action identifier name.\n        :type action_name: unicode | str\n        :param policy: An instance of the current policy class.\n        :type policy: dockermap.map.policy.base.BasePolicy\n        :param kwargs: Keyword arguments. Can be modified by the initialization of the action generator.\n        :type kwargs: dict\n        :return: Action generator object.\n        :rtype: dockermap.map.action.base.AbstractActionGenerator\n        \"\"\"\n        action_generator_cls = self.generators[action_name][1]\n        action_generator = action_generator_cls(policy, kwargs)\n        return action_generator"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_states(self, action_name, config_name, instances=None, map_name=None, **kwargs):\n        policy = self.get_policy()\n        _set_forced_update_ids(kwargs, policy.container_maps, map_name or self._default_map, instances)\n        state_generator = self.get_state_generator(action_name, policy, kwargs)\n        log.debug(\"Remaining kwargs passed to client actions: %s\", kwargs)\n        config_ids = get_map_config_ids(config_name, policy.container_maps, map_name or self._default_map,\n                                        instances)\n        log.debug(\"Generating states for configurations: %s\", config_ids)\n        return state_generator.get_states(config_ids)", "response": "Returns a generator of states in relation to the indicated action."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_actions(self, action_name, config_name, instances=None, map_name=None, **kwargs):\n        policy = self.get_policy()\n        action_generator = self.get_action_generator(action_name, policy, kwargs)\n        for state in self.get_states(action_name, config_name, instances=instances, map_name=map_name, **kwargs):\n            log.debug(\"Evaluating state: %s.\", state)\n            actions = action_generator.get_state_actions(state, **kwargs)\n            if actions:\n                log.debug(\"Running actions: %s\", actions)\n                yield actions\n            else:\n                log.debug(\"No actions returned.\")", "response": "Returns the entire set of actions performed for the indicated action name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run_actions(self, action_name, config_name, instances=None, map_name=None, **kwargs):\n        policy = self.get_policy()\n        results = []\n        runner = self.get_runner(policy, kwargs)\n        for action_list in self.get_actions(action_name, config_name, instances, map_name, **kwargs):\n            try:\n                for res in runner.run_actions(action_list):\n                    results.append(res)\n            except ActionException as ae:\n                raise ActionRunnerException.from_action_exception(ae, results)\n            except:\n                exc_info = sys.exc_info()\n                raise PartialResultsError(exc_info, results)\n        return results", "response": "Runs all actions performed for the specified action name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating container instances for a container configuration.", "response": "def create(self, container, instances=None, map_name=None, **kwargs):\n        \"\"\"\n        Creates container instances for a container configuration.\n\n        :param container: Container name.\n        :type container: unicode | str\n        :param instances: Instance name to create. If not specified, will create all instances as specified in the\n         configuration (or just one default instance).\n        :type instances: tuple | list\n        :param map_name: Container map name. Optional - if not provided the default map is used.\n        :type map_name: unicode | str\n        :param kwargs: Additional kwargs. If multiple actions are resulting from this, they will only be applied to\n          the main container creation.\n        :return: Return values of created containers.\n        :rtype: list[dockermap.map.runner.ActionOutput]\n        \"\"\"\n        return self.run_actions('create', container, instances=instances, map_name=map_name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef start(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('start', container, instances=instances, map_name=map_name, **kwargs)", "response": "Starts instances for a container configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef restart(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('restart', container, instances=instances, map_name=map_name, **kwargs)", "response": "Restarts the specified instances for a container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nstopping instances for a container configuration. :param container: Container name. :type container: unicode | str :param instances: Instance names to stop. If not specified, will stop all instances as specified in the configuration (or just one default instance). :type instances: collections.Iterable[unicode | str | NoneType] :param map_name: Container map name. Optional - if not provided the default map is used. :type map_name: unicode | str :param raise_on_error: Errors on stop and removal may result from Docker volume problems, that do not further affect further actions. Such errors are always logged, but do not raise an exception unless this is set to ``True``. Please note that 404 errors (on non-existing containers) are always ignored on stop and removal. :type raise_on_error: bool :param kwargs: Additional kwargs. If multiple actions are resulting from this, they will only be applied to the main container stop. :return: Return values of stopped containers. :rtype: list[dockermap.map.runner.ActionOutput]", "response": "def stop(self, container, instances=None, map_name=None, **kwargs):\n        \"\"\"\n        Stops instances for a container configuration.\n\n        :param container: Container name.\n        :type container: unicode | str\n        :param instances: Instance names to stop. If not specified, will stop all instances as specified in the\n         configuration (or just one default instance).\n        :type instances: collections.Iterable[unicode | str | NoneType]\n        :param map_name: Container map name. Optional - if not provided the default map is used.\n        :type map_name: unicode | str\n        :param raise_on_error: Errors on stop and removal may result from Docker volume problems, that do not further\n          affect further actions. Such errors are always logged, but do not raise an exception unless this is set to\n          ``True``. Please note that 404 errors (on non-existing containers) are always ignored on stop and removal.\n        :type raise_on_error: bool\n        :param kwargs: Additional kwargs. If multiple actions are resulting from this, they will only be applied to\n          the main container stop.\n        :return: Return values of stopped containers.\n        :rtype: list[dockermap.map.runner.ActionOutput]\n        \"\"\"\n        return self.run_actions('stop', container, instances=instances, map_name=map_name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('remove', container, instances=instances, map_name=map_name, **kwargs)", "response": "Removes instances from a container configuration."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef startup(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('startup', container, instances=instances, map_name=map_name, **kwargs)", "response": "Start up container instances from a container configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nshutting down a container instance from a container configuration.", "response": "def shutdown(self, container, instances=None, map_name=None, **kwargs):\n        \"\"\"\n        Shut down container instances from a container configuration. Typically this means stopping and removing\n        containers. Note that not all policy classes necessarily implement this method.\n\n        :param container: Container name.\n        :type container: unicode | str\n        :param instances: Instance names to remove. If not specified, will remove all instances as specified in the\n         configuration (or just one default instance).\n        :type instances: collections.Iterable[unicode | str | NoneType]\n        :param map_name: Container map name. Optional - if not provided the default map is used.\n        :type map_name: unicode | str\n        :param kwargs: Additional kwargs. Only options controlling policy behavior are considered.\n        :return: Return values of removed containers.\n        :rtype: list[dockermap.map.runner.ActionOutput]\n        \"\"\"\n        return self.run_actions('shutdown', container, instances=instances, map_name=map_name, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('update', container, instances=instances, map_name=map_name, **kwargs)", "response": "Updates the container s instance names and map names based on detected changes in the container configuration or environment."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run_script(self, container, instance=None, map_name=None, **kwargs):\n        return self.run_actions('script', container, instances=instance, map_name=map_name, **kwargs)", "response": "Runs a script or single command in the context of a container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef signal(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('signal', container, instances=instances, map_name=map_name, **kwargs)", "response": "Sends a signal to a single running container configuration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pull_images(self, container, instances=None, map_name=None, **kwargs):\n        return self.run_actions('pull_images', container, map_name=map_name, **kwargs)", "response": "Pulls images for container configurations along their dependency path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_persistent_containers(self, map_name=None):\n        if map_name:\n            maps = [self._maps[map_name].get_extended_map()]\n        else:\n            maps = [m.get_extended_map() for m in self._maps.values()]\n        cname_func = self.policy_class.cname\n        aname_func = self.policy_class.aname\n        c_names = []\n        for c_map in maps:\n            m_name = c_map.name\n            attached, persistent = c_map.get_persistent_items()\n            if c_map.use_attached_parent_name:\n                c_names.extend([aname_func(m_name, ca, c_name)\n                                for c_name, ca in attached])\n            else:\n                c_names.extend([aname_func(m_name, ca[1])\n                                for ca in attached])\n            c_names.extend([cname_func(m_name, c_name, ci)\n                            for c_name, ci in persistent])\n        return c_names", "response": "Lists the names of all persistent containers on the specified map or all maps."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login(self, action, registry, **kwargs):\n        log.info(\"Logging into registry %s.\", registry)\n        login_kwargs = {'registry': registry}\n        auth_config = action.client_config.auth_configs.get(registry)\n        if auth_config:\n            log.debug(\"Registry auth config for %s found.\", registry)\n            login_kwargs.update(auth_config)\n            insecure_registry = kwargs.get('insecure_registry')\n            if insecure_registry is not None:\n                login_kwargs['insecure_registry'] = insecure_registry\n        else:\n            raise KeyError(\"No login information found for registry.\", registry)\n        update_kwargs(login_kwargs, kwargs)\n        res = action.client.login(**login_kwargs)\n        if res:\n            log.debug(\"User %(username)s logged into %(registry)s.\", login_kwargs)\n            self._login_registries.add(registry)\n        return res", "response": "Logs in to a Docker registry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pull(self, action, image_name, **kwargs):\n        config_id = action.config_id\n        registry, __, image = config_id.config_name.rpartition('/')\n        if registry and '.' in registry and registry not in self._login_registries:\n            self.login(action, registry, insecure_registry=kwargs.get('insecure_registry'))\n        log.info(\"Pulling image %s:%s.\", config_id.config_name, config_id.instance_name)\n        res = action.client.pull(repository=config_id.config_name, tag=config_id.instance_name, **kwargs)\n        log.debug(\"Done pulling image %s:%s.\", config_id.config_name, config_id.instance_name)\n        self._policy.images[action.client_name].refresh_repo(config_id.config_name)\n        log.debug(\"Refreshed image cache for repo %s.\", config_id.config_name)\n        return res", "response": "Pull an image for a container configuration."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the output of the Docker CLI docker network ls and returns it in the format similar to the Docker API.", "response": "def parse_networks_output(out):\n    \"\"\"\n    Parses the output of the Docker CLI 'docker network ls' and returns it in the format similar to the Docker API.\n\n    :param out: CLI output.\n    :type out: unicode | str\n    :return: Parsed result.\n    :rtype: list[dict]\n    \"\"\"\n    if not out:\n        return []\n    line_iter = islice(out.splitlines(), 1, None)  # Skip header\n    return list(map(_network_info, line_iter))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the output of the Docker CLI docker volume ls and returns it in the format similar to the Docker API.", "response": "def parse_volumes_output(out):\n    \"\"\"\n    Parses the output of the Docker CLI 'docker volume ls' and returns it in the format similar to the Docker API.\n\n    :param out: CLI output.\n    :type out: unicode | str\n    :return: Parsed result.\n    :rtype: list[dict]\n    \"\"\"\n    if not out:\n        return []\n    line_iter = islice(out.splitlines(), 1, None)  # Skip header\n    return list(map(_volume_info, line_iter))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_inspect_output(out, item_type):\n    parsed = json.loads(out, encoding='utf-8')\n    if parsed:\n        return parsed[0]\n    raise NotFound(\"{0} not found.\".format(item_type.title()), None)", "response": "Parses the output of the Docker CLI inspect <container or docker network inspect <network > and returns the parsed JSON string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_images_output(out):\n    line_iter = islice(out.splitlines(), 1, None)  # Skip header\n    split_lines = (line.split() for line in line_iter)\n    return [\n        _summarize_tags(image_id, image_lines)\n        for image_id, image_lines in groupby(sorted(split_lines, key=_get_image_id), key=_get_image_id)\n    ]", "response": "Parses the output of the Docker CLI docker images."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the output of docker version", "response": "def parse_version_output(out):\n    \"\"\"\n    Parses the output of 'docker version --format=\"{{json .}}\"'. Essentially just returns the parsed JSON string,\n    like the Docker API does. Fields are slightly different however.\n\n    :param out: CLI output.\n    :type out: unicode | str\n    :return: Parsed result.\n    :rtype: dict\n    \"\"\"\n    parsed = json.loads(out, encoding='utf-8')\n    if parsed:\n        return parsed.get('Client', {})\n    return {}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the output of the Docker top <container > command.", "response": "def parse_top_output(out):\n    \"\"\"\n    Parses the output of the Docker CLI 'docker top <container>'. Note that if 'ps' output columns are modified and\n    'args' (for the command) is anywhere but in the last column, this will not parse correctly. However, the Docker API\n    produces wrong output in this case as well.\n    Returns a dictionary with entries 'Titles' and 'Processes' just like the Docker API would.\n\n    :param out: CLI output.\n    :type out: unicode | str\n    :return: Parsed result.\n    :rtype: dict\n    \"\"\"\n    lines = out.splitlines()\n    line_iter = iter(lines)\n    header_line = next(line_iter)\n    titles = header_line.split()\n    max_split = len(titles) - 1\n    return {\n        'Titles': titles,\n        'Processes': [line.split(None, max_split) for line in line_iter],\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrefreshes the internal cache with the current image ids.", "response": "def refresh(self):\n        \"\"\"\n        Fetches image and their ids from the client.\n        \"\"\"\n        if not self._client:\n            return\n        current_images = self._client.images()\n        self.clear()\n        self._update(current_images)\n        for image in current_images:\n            tags = image.get('RepoTags')\n            if tags:\n                self.update({tag: image['Id'] for tag in tags})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef refresh(self):\n        if not self._client:\n            return\n        current_containers = self._client.containers(all=True)\n        self.clear()\n        for container in current_containers:\n            container_names = container.get('Names')\n            if container_names:\n                c_id = container['Id']\n                self.update((name[1:], c_id)\n                            for name in container_names)", "response": "Refreshes the cache with all current container names from the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self):\n        if not self._client:\n            return\n        current_networks = self._client.networks()\n        self.clear()\n        self.update((net['Name'], net['Id'])\n                    for net in current_networks)", "response": "Refreshes the cache with all current network names and id."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef refresh(self):\n        if not self._client:\n            return\n        current_volumes = self._client.volumes()['Volumes']\n        self.clear()\n        if current_volumes:\n            self.update(vol['Name'] for vol in current_volumes)", "response": "Refreshes the internal cache of all current network names."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nforcing a refresh of a cached item.", "response": "def refresh(self, item):\n        \"\"\"\n        Forces a refresh of a cached item.\n\n        :param item: Client name.\n        :type item: unicode | str\n        :return: Items in the cache.\n        :rtype: DockerHostItemCache.item_class\n        \"\"\"\n        client = self._clients[item].get_client()\n        self[item] = val = self.item_class(client)\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run_script(self, action, c_name, script_path=None, entrypoint=None, command_format=None,\n                   wait_timeout=None, container_script_dir='/tmp/script_run', timestamps=None, tail='all'):\n        \"\"\"\n        Creates a container from its configuration to run a script or single command. The container is specifically\n        created for this action. If it exists prior to the script run, it fails; optionally it can be removed by setting\n        :attr:`remove_existing_before` to ``True``. The script is run by setting entrypoint and command and\n        mounting the directory containing the script to the new container. After the script run, the container is\n        destroyed (excluding its dependencies), unless :attr:`remove_created_after` is set to ``False``.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param c_name: Container name.\n        :type c_name: unicode | str\n        :param script_path: Path to the script on the Docker host. Note that this needs to have the executable bit\n         set, if the script runtime (e.g. bash) requires it. If no script is to be used, (e.g. for a single command),\n         this can point to a directory for writing back results to.\n        :param entrypoint: Entrypoint of the container. Typically this should be the scripting executable, such as\n         ``/bin/bash``.\n        :type entrypoint: unicode | str\n        :param command_format: Command to pass to the container. This should be any arguments to the entrypoint, and\n         can include a formatting string variable ``{script_path}`` which is substituted with the path inside the\n         container. The command_format can be provided as a single string or a list of strings. Of no command is set,\n         ``['-c', '{script_path}']`` is assumed, which are the arguments to ``/bin/bash`` for running a single script.\n        :type command_format: unicode | str | list[unicode | str] | tuple[unicode | str]\n        :param wait_timeout: How long to wait for the container to finish. If not set, will be read from the client\n         configuration parameter ``wait_timeout``.\n        :type wait_timeout: int\n        :param container_script_dir: Directory to use for the script inside the container. This is also the path where\n         other files in the same directory as the script will be located.\n        :type container_script_dir: unicode | str\n        :param timestamps:\n        :type timestamps: bool\n        :param tail:\n        :type tail: unicode | str\n        :return: A dictionary with the container ``id``, the client alias ``client``, the stdout output ``log``, and\n         the exit code ``exit_code``. In case a wait timeout occurred, instead of ``log`` and ``exit_code`` returns a\n         key ``error``.\n        :rtype: dict[unicode | str, dict]\n        \"\"\"\n        client = action.client\n        client_config = action.client_config\n        if script_path:\n            if os.path.isdir(script_path):\n                script_dir = script_path\n                c_script_path = container_script_dir\n            else:\n                script_dir, script_name = os.path.split(script_path)\n                c_script_path = posixpath.join(container_script_dir, script_name)\n            if command_format:\n                if isinstance(command_format, (tuple, list)):\n                    command = [six.text_type(cmd_item).format(script_path=c_script_path) for cmd_item in command_format]\n                elif isinstance(command_format, six.string_types):\n                    command = command_format.format(script_path=c_script_path)\n                else:\n                    raise ValueError(\"Only strings and lists of strings are allowed as a command.\")\n            else:\n                command = None\n            volumes = [container_script_dir]\n            binds = ['{0}:{1}:rw'.format(script_dir, container_script_dir)]\n        else:\n            volumes = None\n            binds = None\n            command = command_format\n\n        if client_config.features['host_config']:\n            create_extra_kwargs = {'host_config': dict(binds=binds)}\n            start_extra_kwargs = {}\n        else:\n            create_extra_kwargs = {}\n            start_extra_kwargs = {'binds': binds}\n        created = self.create_container(action, c_name, entrypoint=entrypoint, command=command,\n                                        volumes=volumes, **create_extra_kwargs)\n        if not created:\n            raise ScriptRunException(\"No new containers were created.\")\n        result = {'id': created['Id'], 'client': action.client_name}\n        stopped = True\n        try:\n            self.start_container(action, c_name, **start_extra_kwargs)\n            stopped = False\n            timeout = wait_timeout or action.config.stop_timeout or client_config.get('timeout')\n            container_id = created['Id']\n            try:\n                self.wait(action, c_name, timeout=timeout)\n            except Timeout:\n                result['error'] = \"Timed out while waiting for the container to finish.\"\n            else:\n                stopped = True\n                c_info = client.inspect_container(container_id)\n                result['exit_code'] = c_info['State']['ExitCode']\n                result['log'] = client.logs(c_name, timestamps=timestamps, tail=tail)\n        finally:\n            if self.remove_created_after:\n                if not stopped:\n                    self.stop(action, c_name, timeout=3)\n                self.remove_container(action, c_name)\n        return result", "response": "Creates a new container from its configuration to run a script or single command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_state_actions(self, state, **kwargs):\n        if state.config_flags & ConfigFlags.DEPENDENT or state.config_id.config_type != ItemType.CONTAINER:\n            return super(ScriptActionGenerator, self).get_state_actions(state, **kwargs)\n\n        if state.base_state == State.ABSENT:\n            actions = []\n        else:\n            log.debug(\"Found existing script containers: %s\", state.config_id)\n            if not self.remove_existing_before:\n                config_id = state.config_id\n                c_name = self._policy.cname(config_id.map_name, config_id.config_name, config_id.instance_name)\n                if state.client_name == self._policy.default_client_name:\n                    error_msg = \"Container {0} existed prior to running the script.\".format(c_name)\n                else:\n                    error_msg = (\"Container {0} existed on client {1} prior to running the \"\n                                 \"script.\").format(c_name, state.client_name)\n                raise ScriptActionException(error_msg)\n\n            if state.base_state == State.RUNNING or state.state_flags & StateFlags.RESTARTING:\n                log.debug(\"Preparing shutdown of existing container: %s\", state.config_id)\n                actions = [ItemAction(state, DerivedAction.SHUTDOWN_CONTAINER)]\n            else:\n                log.debug(\"Preparing removal existing container: %s\", state.config_id)\n                actions = [ItemAction(state, Action.REMOVE)]\n\n        actions.append(ItemAction(state, ContainerUtilAction.SCRIPT, extra_data=kwargs))\n        return actions", "response": "Returns a list of actions on the client map and configurations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of items that are marked as persistent. Each returned item is in the format ( config name instance or attached name ) where the instance name can also be None.", "response": "def get_persistent_items(self):\n        \"\"\"\n        Returns attached container items and container configurations that are marked as persistent. Each returned\n        item is in the format ``(config name, instance/attached name)``, where the instance name can also be ``None``.\n\n        :return: Lists of attached items.\n        :rtype: (list[(unicode | str, unicode | str)], list[unicode | str, unicode | str | NoneType])\n        \"\"\"\n        attached_items = [(container, ac)\n                          for container, config in self\n                          for ac in config.attaches]\n        persistent_containers = [(container, ci)\n                                 for container, config in self if config.persistent\n                                 for ci in config.instances or [None]]\n        return attached_items, persistent_containers"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_image(self, image):\n        name, __, tag = image.rpartition(':')\n        if not name:\n            name, tag = tag, name\n        if '/' in name:\n            if name[0] == '/':\n                repo_name = name[1:]\n            else:\n                repo_name = name\n        else:\n            default_prefix = resolve_value(self.repository)\n            if default_prefix:\n                repo_name = '{0}/{1}'.format(default_prefix, name)\n            else:\n                repo_name = name\n        if tag:\n            return repo_name, tag\n        default_tag = resolve_value(self.default_tag)\n        return repo_name, default_tag or 'latest'", "response": "This method returns the full image name and tag that should be used when creating a new container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dependency_items(self):\n        def _get_used_items_np(u):\n            volume_config_name, __, volume_instance = u.name.partition('.')\n            attaching_config_name = attaching.get(volume_config_name)\n            if attaching_config_name:\n                used_c_name = attaching_config_name\n                used_instances = instances.get(attaching_config_name)\n            else:\n                used_c_name = volume_config_name\n                if volume_instance:\n                    used_instances = (volume_instance, )\n                else:\n                    used_instances = instances.get(volume_config_name)\n            return [MapConfigId(ItemType.CONTAINER, self._name, used_c_name, ai)\n                    for ai in used_instances or (None, )]\n\n        def _get_used_items_ap(u):\n            volume_config_name, __, volume_instance = u.name.partition('.')\n            attaching_config = ext_map.get_existing(volume_config_name)\n            attaching_instances = instances.get(volume_config_name)\n            config_volumes = {a.name for a in attaching_config.attaches}\n            if not volume_instance or volume_instance in config_volumes:\n                used_instances = attaching_instances\n            else:\n                used_instances = (volume_instance, )\n            return [MapConfigId(ItemType.CONTAINER, self._name, volume_config_name, ai)\n                    for ai in used_instances or (None, )]\n\n        def _get_linked_items(lc):\n            linked_config_name, __, linked_instance = lc.partition('.')\n            if linked_instance:\n                linked_instances = (linked_instance, )\n            else:\n                linked_instances = instances.get(linked_config_name)\n            return [MapConfigId(ItemType.CONTAINER, self._name, linked_config_name, li)\n                    for li in linked_instances or (None, )]\n\n        def _get_network_mode_items(n):\n            net_config_name, net_instance = n\n            network_ref_config = ext_map.get_existing(net_config_name)\n            if network_ref_config:\n                if net_instance and net_instance in network_ref_config.instances:\n                    network_instances = (net_instance, )\n                else:\n                    network_instances = network_ref_config.instances or (None, )\n                return [MapConfigId(ItemType.CONTAINER, self._name, net_config_name, ni)\n                        for ni in network_instances]\n            return []\n\n        def _get_network_items(n):\n            if n.network_name in DEFAULT_PRESET_NETWORKS:\n                return []\n            net_items = [MapConfigId(ItemType.NETWORK, self._name, n.network_name)]\n            if n.links:\n                net_items.extend(itertools.chain.from_iterable(_get_linked_items(l.container) for l in n.links))\n            return net_items\n\n        if self._extended:\n            ext_map = self\n        else:\n            ext_map = self.get_extended_map()\n\n        instances = {c_name: c_config.instances\n                     for c_name, c_config in ext_map}\n        if not self.use_attached_parent_name:\n            attaching = {attaches.name: c_name\n                         for c_name, c_config in ext_map\n                         for attaches in c_config.attaches}\n            used_func = _get_used_items_np\n        else:\n            used_func = _get_used_items_ap\n\n        def _get_dep_list(name, config):\n            image, tag = self.get_image(config.image or name)\n            d = []\n            nw = config.network_mode\n            if isinstance(nw, tuple):\n                merge_list(d, _get_network_mode_items(nw))\n            merge_list(d, itertools.chain.from_iterable(map(_get_network_items, config.networks)))\n            merge_list(d, itertools.chain.from_iterable(map(used_func, config.uses)))\n            merge_list(d, itertools.chain.from_iterable(_get_linked_items(l.container) for l in config.links))\n            d.extend(MapConfigId(ItemType.VOLUME, self._name, name, a.name)\n                     for a in config.attaches)\n            d.append(MapConfigId(ItemType.IMAGE, self._name, image, tag))\n            return d\n\n        for c_name, c_config in ext_map:\n            dep_list = _get_dep_list(c_name, c_config)\n            for c_instance in c_config.instances or (None, ):\n                yield MapConfigId(ItemType.CONTAINER, self._name, c_name, c_instance), dep_list", "response": "Generates all containers' dependencies i. e. an iterator on tuples in the format\n       . container_name used_containers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a merged copy of the given configuration with all inherited values merged with the container configuration.", "response": "def get_extended(self, config):\n        \"\"\"\n        Generates a configuration that includes all inherited values.\n\n        :param config: Container configuration.\n        :type config: ContainerConfiguration\n        :return: A merged (shallow) copy of all inherited configurations merged with the container configuration.\n        :rtype: ContainerConfiguration\n        \"\"\"\n        if not config.extends or self._extended:\n            return config\n        extended_config = ContainerConfiguration()\n        for ext_name in config.extends:\n            ext_cfg_base = self._containers.get(ext_name)\n            if not ext_cfg_base:\n                raise KeyError(ext_name)\n            ext_cfg = self.get_extended(ext_cfg_base)\n            extended_config.merge_from_obj(ext_cfg)\n        extended_config.merge_from_obj(config)\n        return extended_config"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of this map which includes all non - abstract configurations in their extended form.", "response": "def get_extended_map(self):\n        \"\"\"\n        Creates a copy of this map which includes all non-abstract configurations in their extended form.\n\n        :return: Copy of this map.\n        :rtype: ContainerMap\n        \"\"\"\n        map_copy = self.__class__(self.name)\n        map_copy.update_from_obj(self, copy=True, update_containers=False)\n        for c_name, c_config in self:\n            map_copy._containers[c_name] = self.get_extended(c_config)\n        map_copy._extended = True\n        return map_copy"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef check_integrity(self, check_duplicates=True):\n        def _get_instance_names(c_name, instances):\n            if instances:\n                return ['{0}.{1}'.format(c_name, instance) for instance in instances]\n            return [c_name]\n\n        def _get_container_items(c_name, c_config):\n            instance_names = _get_instance_names(c_name, c_config.instances)\n            group_ref_names = instance_names[:]\n            if c_config.instances:\n                group_ref_names.append(c_name)\n            shared = instance_names[:] if c_config.shares or c_config.binds or c_config.uses else []\n            bind = [b.name for b in c_config.binds if isinstance(b, SharedVolume)]\n            link = [l.container for l in c_config.links]\n            uses = [u.name for u in c_config.uses]\n            networks = [n.network_name for n in c_config.networks if n.network_name not in DEFAULT_PRESET_NETWORKS]\n            network_mode = c_config.network_mode\n            if isinstance(network_mode, tuple):\n                if network_mode[1]:\n                    net_containers = ['{0[0]}.{0[1]}'.format(network_mode)]\n                else:\n                    net_containers = [network_mode[0]]\n            else:\n                net_containers = []\n            if self.use_attached_parent_name:\n                attaches = [(c_name, a.name) for a in c_config.attaches]\n            else:\n                attaches = [a.name for a in c_config.attaches]\n            attaches_with_path = [a.name for a in c_config.attaches\n                                  if isinstance(a, UsedVolume)]\n            return (instance_names, group_ref_names, uses, attaches, attaches_with_path, shared, bind, link, networks,\n                    net_containers)\n\n        self.clean()\n        (all_instances, all_grouprefs, all_used, all_attached, all_attached_default, all_shared, all_binds, all_links,\n         all_networks, all_net_containers) = zip(*[\n            _get_container_items(k, v) for k, v in self.get_extended_map()\n         ])\n        if self.use_attached_parent_name:\n            all_attached_names = tuple('{0}.{1}'.format(c_name, a)\n                                       for c_name, a in itertools.chain.from_iterable(all_attached))\n        else:\n            all_attached_names = tuple(itertools.chain.from_iterable(all_attached))\n\n        ref_set = set(itertools.chain.from_iterable(all_grouprefs))\n        group_set = set(self.groups.keys())\n        ambiguous_names = group_set & ref_set\n        if ambiguous_names:\n            ambiguous_str = ', '.join(ambiguous_names)\n            raise MapIntegrityError(\"Names are used both for container configurations (or instances) and for container \"\n                                    \"groups: {0}.\".format(ambiguous_str))\n        group_referenced = set(itertools.chain.from_iterable(self.groups.values()))\n        missing_refs = group_referenced - ref_set\n        if missing_refs:\n            missing_ref_str = ', '.join(missing_refs)\n            raise MapIntegrityError(\"Container configurations or certain instances are referenced by groups, but are \"\n                                    \"not defined: {0}.\".format(missing_ref_str))\n        volume_shared = tuple(itertools.chain.from_iterable(all_shared)) + all_attached_names\n        if check_duplicates:\n            duplicated = [name for name, count in six.iteritems(Counter(volume_shared)) if count > 1]\n            if duplicated:\n                dup_str = ', '.join(duplicated)\n                raise MapIntegrityError(\"Duplicated attached volumes found with name(s): {0}.\".format(dup_str))\n        used_set = set(itertools.chain.from_iterable(all_used))\n        shared_set = set(volume_shared)\n        missing_shares = used_set - shared_set\n        if missing_shares:\n            missing_share_str = ', '.join(missing_shares)\n            raise MapIntegrityError(\"No shared or attached volumes found for used volume(s): \"\n                                    \"{0}.\".format(missing_share_str))\n        binds_set = set(itertools.chain.from_iterable(all_binds))\n        host_set = set(self.host.keys())\n        missing_binds = binds_set - host_set\n        if missing_binds:\n            missing_mapped_str = ', '.join(missing_binds)\n            raise MapIntegrityError(\"No host share found for mapped volume(s): {0}.\".format(missing_mapped_str))\n        if self.use_attached_parent_name:\n            volume_set = binds_set.union(a[1] for a in itertools.chain.from_iterable(all_attached))\n        else:\n            volume_set = binds_set.union(all_attached_names)\n        named_set = set(self.volumes.keys()).union(itertools.chain.from_iterable(all_attached_default))\n        missing_names = volume_set - named_set\n        if missing_names:\n            missing_names_str = ', '.join(missing_names)\n            raise MapIntegrityError(\"No volume name-path-assignments found for volume(s): \"\n                                    \"{0}.\".format(missing_names_str))\n        instance_set = set(itertools.chain.from_iterable(all_instances))\n        linked_set = set(itertools.chain.from_iterable(all_links))\n        missing_links = linked_set - instance_set\n        if missing_links:\n            missing_links_str = ', '.join(missing_links)\n            raise MapIntegrityError(\"No container instance found for link(s): {0}.\".format(missing_links_str))\n        used_network_set = set(itertools.chain.from_iterable(all_networks))\n        used_net_container_set = set(itertools.chain.from_iterable(all_net_containers))\n        available_network_set = set(self.networks.keys())\n        missing_networks = used_network_set - available_network_set\n        if missing_networks:\n            missing_networks_str = ', '.join(missing_networks)\n            raise MapIntegrityError(\"No network configuration found for the following network reference(s): \"\n                                    \"{0}\".format(missing_networks_str))\n        missing_net_containers = used_net_container_set - instance_set\n        if missing_net_containers:\n            missing_net_cnt_str = ', '.join(missing_net_containers)\n            raise MapIntegrityError(\"No container instance found for the following network mode reference(s): \"\n                                    \"{0}\".format(missing_net_cnt_str))", "response": "Checks the integrity of the container map."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_state_actions(self, state, **kwargs):\n        if state.base_state == State.ABSENT:\n            if state.config_id.config_type == ItemType.IMAGE:\n                return [ItemAction(state, ImageAction.PULL)]\n            actions = [ItemAction(state, Action.CREATE, extra_data=kwargs)]\n            if state.config_id.config_type == ItemType.CONTAINER:\n                actions.append(ItemAction(state, ContainerUtilAction.CONNECT_ALL))\n            return actions", "response": "Returns a list of actions on the client map and configurations."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates actions on the client map and configurations.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        Generally starts containers that are not running. Attached containers are skipped unless they are initial.\n        Attached containers are also prepared with permissions. Where applicable, exec commands are run in started\n        instance containers.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        config_type = state.config_id.config_type\n        if (config_type == ItemType.VOLUME and state.base_state == State.PRESENT and\n                state.state_flags & StateFlags.INITIAL):\n            return [\n                ItemAction(state, Action.START),\n                ItemAction(state, VolumeUtilAction.PREPARE),\n            ]\n        elif config_type == ItemType.CONTAINER and state.base_state == State.PRESENT:\n            return [\n                ItemAction(state, Action.START, extra_data=kwargs),\n                ItemAction(state, ContainerUtilAction.EXEC_ALL),\n            ]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the list of actions on the client map and configurations.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        Restarts instance containers.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        if (state.config_id.config_type == ItemType.CONTAINER and state.base_state != State.ABSENT and\n                not state.state_flags & StateFlags.INITIAL):\n            actions = [ItemAction(state, DerivedAction.RESTART_CONTAINER, extra_data=kwargs)]\n            if self.restart_exec_commands:\n                actions.append(ItemAction(state, ContainerUtilAction.EXEC_ALL, extra_data=kwargs))\n            return actions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the list of actions that can be performed on the client map and configurations.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        Stops containers that are running. Does not check attached containers. Considers using the pre-configured\n        ``stop_signal``.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        if (state.config_id.config_type == ItemType.CONTAINER and state.base_state != State.ABSENT and\n                not state.state_flags & StateFlags.INITIAL):\n            return [ItemAction(state, ContainerUtilAction.SIGNAL_STOP, extra_data=kwargs)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_state_actions(self, state, **kwargs):\n        config_type = state.config_id.config_type\n        if config_type == ItemType.CONTAINER:\n            extra_data = kwargs\n        else:\n            extra_data = None\n        if state.base_state == State.PRESENT:\n            if ((config_type == ItemType.VOLUME and self.remove_attached) or\n                    (config_type == ItemType.CONTAINER and\n                     self.remove_persistent or not state.state_flags & StateFlags.PERSISTENT)):\n                return [ItemAction(state, Action.REMOVE, extra_data=extra_data)]\n            elif config_type == ItemType.NETWORK:\n                connected_containers = state.extra_data.get('containers')\n                if connected_containers:\n                    actions = [ItemAction(state, NetworkUtilAction.DISCONNECT_ALL, {'containers': connected_containers})]\n                else:\n                    actions = []\n                actions.append(ItemAction(state, Action.REMOVE, extra_data=kwargs))\n                return actions", "response": "Returns the list of actions on the client map and configurations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_state_actions(self, state, **kwargs):\n        config_type = state.config_id.config_type\n        if config_type == ItemType.VOLUME:\n            if state.base_state == State.ABSENT:\n                return [\n                    ItemAction(state, Action.CREATE),\n                    ItemAction(state, VolumeUtilAction.PREPARE),\n                ]\n            elif state.base_state == State.PRESENT and state.state_flags & StateFlags.INITIAL:\n                return [\n                    ItemAction(state, Action.START),\n                    ItemAction(state, VolumeUtilAction.PREPARE),\n                ]\n        elif config_type == ItemType.CONTAINER:\n            if state.base_state == State.ABSENT:\n                return [\n                    ItemAction(state, DerivedAction.STARTUP_CONTAINER),\n                    ItemAction(state, ContainerUtilAction.EXEC_ALL),\n                ]\n            elif state.base_state == State.PRESENT:\n                return [\n                    ItemAction(state, Action.START),\n                    ItemAction(state, ContainerUtilAction.EXEC_ALL),\n                ]\n        else:\n            if config_type == ItemType.NETWORK:\n                return [ItemAction(state, Action.CREATE)]\n            elif config_type == ItemType.IMAGE:\n                return [ItemAction(state, ImageAction.PULL)]", "response": "Returns the list of actions on the client map and configurations where the base state is in the given state."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of actions on the client map and configurations where the items are removed from the map.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        A combination of StopActionGenerator and RemoveActionGenerator - stops and removes containers where\n        appropriate.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        config_type = state.config_id.config_type\n        if config_type == ItemType.NETWORK:\n            if state.base_state == State.PRESENT:\n                connected_containers = state.extra_data.get('containers')\n                if connected_containers:\n                    cc_names = [c.get('Name', c['Id']) for c in connected_containers]\n                    actions = [ItemAction(state, NetworkUtilAction.DISCONNECT_ALL,\n                                          extra_data={'containers': cc_names})]\n                else:\n                    actions = []\n                actions.append(ItemAction(state, Action.REMOVE, extra_data=kwargs))\n                return actions\n        elif config_type == ItemType.VOLUME and self.remove_attached:\n            return [ItemAction(state, Action.REMOVE)]\n        elif config_type == ItemType.CONTAINER:\n            if self.remove_persistent or not state.state_flags & StateFlags.PERSISTENT:\n                if state.base_state == State.RUNNING or state.state_flags & StateFlags.RESTARTING:\n                    return [ItemAction(state, DerivedAction.SHUTDOWN_CONTAINER)]\n                elif state.base_state == State.PRESENT:\n                    return [ItemAction(state, Action.REMOVE)]\n            elif state.base_state == State.RUNNING or state.state_flags & StateFlags.RESTARTING:\n                return [ItemAction(state, Action.REMOVE)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_state_actions(self, state, **kwargs):\n        if state.config_id.config_type == ItemType.CONTAINER and state.base_state == State.RUNNING:\n            return [ItemAction(state, Action.KILL, extra_data=kwargs)]", "response": "Returns a list of actions on the client map and configurations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_version():\n    finder = VersionFinder()\n    finder.visit(ast.parse(local_file('curdling', 'version.py')))\n    return finder.version", "response": "Read version from curdling version. py without loading any files"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_requirements(path):\n    try:\n        requirements = map(str.strip, local_file(path).splitlines())\n    except IOError:\n        raise RuntimeError(\"Couldn't find the `requirements.txt' file :(\")\n\n    links = []\n    pkgs = []\n    for req in requirements:\n        if not req:\n            continue\n        if 'http:' in req or 'https:' in req:\n            links.append(req)\n            name, version = re.findall(\"\\#egg=([^\\-]+)-(.+$)\", req)[0]\n            pkgs.append('{0}=={1}'.format(name, version))\n        else:\n            pkgs.append(req)\n\n    return pkgs, links", "response": "Rudimentary parser for the requirements. txt file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_distribution_paths(name):\n    pyver = 'python' + sys.version[:3]\n\n    paths = {\n        'prefix' : '{prefix}',\n        'data'   : '{prefix}/lib/{pyver}/site-packages',\n        'purelib': '{prefix}/lib/{pyver}/site-packages',\n        'platlib': '{prefix}/lib/{pyver}/site-packages',\n        'headers': '{prefix}/include/{pyver}/{name}',\n        'scripts': '{prefix}/bin',\n    }\n\n    # pip uses a similar path as an alternative to the system's (read-only)\n    # include directory:\n    if hasattr(sys, 'real_prefix'):  # virtualenv\n        paths['headers'] = os.path.abspath(\n            os.path.join(sys.prefix, 'include', 'site', pyver, name))\n\n    # Replacing vars\n    for key, val in paths.items():\n        paths[key] = val.format(prefix=PREFIX, name=name, pyver=pyver)\n    return paths", "response": "Return the paths where the package content should be installed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_response(response):\n    if isinstance(response, six.binary_type):\n        response = response.decode('utf-8')\n    try:\n        obj = json.loads(response)\n    except ValueError:\n        return {}\n    return obj", "response": "Parses the JSON response into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build(self, tag, add_latest_tag=False, add_tags=None, raise_on_error=True, **kwargs):\n        response = super(DockerClientWrapper, self).build(tag=tag, **kwargs)\n        # It is not the kwargs alone that decide if we get a stream, so we have to check.\n        if isinstance(response, tuple):\n            image_id = response[0]\n        else:\n            last_log = self._docker_log_stream(response, raise_on_error)\n            if last_log and last_log.startswith('Successfully built '):\n                image_id = last_log[19:]  # Remove prefix\n            else:\n                image_id = None\n\n        if not image_id:\n            return None\n\n        self.add_extra_tags(image_id, tag, add_tags, add_latest_tag)\n        return image_id", "response": "Overrides the DockerClientWrapper. build method and filters the output."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef login(self, username, password=None, email=None, registry=None, reauth=False, **kwargs):\n        response = super(DockerClientWrapper, self).login(username, password, email, registry, reauth=reauth, **kwargs)\n        return response.get('Status') == 'Login Succeeded' or response.get('username') == username", "response": "Logs in to a Docker registry server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush an image repository to the registry.", "response": "def push(self, repository, stream=False, raise_on_error=True, **kwargs):\n        \"\"\"\n        Pushes an image repository to the registry.\n\n        :param repository: Name of the repository (can include a tag).\n        :type repository: unicode | str\n        :param stream: Use the stream output format with additional status information.\n        :type stream: bool\n        :param raise_on_error: Raises errors in the status output as a DockerStatusException. Otherwise only logs\n         errors.\n        :type raise_on_error: bool\n        :param kwargs: Additional kwargs for :meth:`docker.client.Client.push`.\n        :return: ``True`` if the image has been pushed successfully.\n        :rtype: bool\n        \"\"\"\n        response = super(DockerClientWrapper, self).push(repository, stream=stream, **kwargs)\n        if stream:\n            result = self._docker_status_stream(response, raise_on_error)\n        else:\n            result = self._docker_status_stream(response.split('\\r\\n') if response else (), raise_on_error)\n        return result and not result.get('error')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef push_container_logs(self, container):\n        logs = self.logs(container).decode('utf-8')\n        log_lines = logs.split('\\n')\n        if log_lines and not log_lines[-1]:\n            log_lines.pop()\n        for line in log_lines:\n            self.push_log(LOG_CONTAINER_FORMAT, logging.INFO, container, line)", "response": "Reads the logs of a container and passes them to the push_log method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_container(self, container, raise_on_error=True, raise_not_found=False, **kwargs):\n        try:\n            super(DockerClientWrapper, self).remove_container(container, **kwargs)\n        except APIError as e:\n            exc_info = sys.exc_info()\n            if e.response.status_code == 404:\n                if raise_not_found:\n                    six.reraise(*exc_info)\n            else:\n                self.push_log(\"Failed to remove container '%s': %s\", logging.ERROR, container, e.explanation)\n                if raise_on_error:\n                    six.reraise(*exc_info)", "response": "Removes a container from the container store."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stop(self, container, raise_on_error=True, **kwargs):\n        try:\n            super(DockerClientWrapper, self).stop(container, **kwargs)\n        except APIError as e:\n            exc_info = sys.exc_info()\n            self.push_log(\"Failed to stop container '%s': %s\", logging.ERROR, container, e.explanation)\n            if raise_on_error:\n                six.reraise(*exc_info)", "response": "Stops a container. For convenience optionally ignores API errors.\n\n        :param container: Container name.\n        :type container: unicode | str\n        :param raise_on_error: Errors on stop and removal may result from Docker volume problems, that may not\n          affect further actions. Such errors are always logged, but do not raise an exception if this is set to\n          ``True``.\n        :type raise_on_error: bool\n        :param kwargs: Additional keyword args for :meth:`docker.client.Client.stop`."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy_resource(self, container, resource, local_filename):\n        raw = self.copy(container, resource)\n        with open(local_filename, 'wb+') as f:\n            for buf in raw:\n                f.write(buf)", "response": "Copy a resource from a Docker container to a local tar file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tag_check_function(tags):\n    suffixes = [':{0}'.format(t) for t in tags]\n\n    def _check_image(image):\n        repo_tags = image['RepoTags']\n        if not repo_tags:\n            return False\n        return any(r_tag.endswith(s) for s in suffixes for r_tag in repo_tags)\n\n    return _check_image", "response": "Generates a function that checks whether the given image has any of the given tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef primary_container_name(names, default=None, strip_trailing_slash=True):\n    if strip_trailing_slash:\n        ex_names = [name[1:] for name in names if name.find('/', 2) == -1]\n    else:\n        ex_names = [name for name in names if name.find('/', 2) == -1]\n    if ex_names:\n        return ex_names[0]\n    return default", "response": "Given a list of names finds the primary container name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_extra_tags(self, image_id, main_tag, extra_tags, add_latest):\n        repo, __, i_tag = main_tag.rpartition(':')\n        tag_set = set(extra_tags or ())\n        if add_latest:\n            tag_set.add('latest')\n        tag_set.discard(i_tag)\n        added_tags = []\n        tag_kwargs = {}\n        if str(self.api_version) < DEPRECATED_FORCE_TAG_VERSION:\n            tag_kwargs['force'] = True\n        if repo and tag_set:\n            for t in tag_set:\n                try:\n                    self.tag(image_id, repo, t, **tag_kwargs)\n                except:\n                    exc_info = sys.exc_info()\n                    raise PartialResultsError(exc_info, added_tags)\n                else:\n                    added_tags.append(t)\n        return added_tags", "response": "Adds extra tags to an image after de - duplicatedating tag names."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a log message to the log file.", "response": "def push_log(self, info, level, *args, **kwargs):\n        \"\"\"\n        Writes logs. To be fully implemented by subclasses.\n\n        :param info: Log message content.\n        :type info: unicode | str\n        :param level: Logging level.\n        :type level: int\n        :param args: Positional arguments to pass to logger.\n        :param kwargs: Keyword arguments to pass to logger.\n        \"\"\"\n        log.log(level, info, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nbuilding a docker image from the given docker context with a Dockerfile file object.", "response": "def build_from_context(self, ctx, tag, **kwargs):\n        \"\"\"\n        Builds a docker image from the given docker context with a `Dockerfile` file object.\n\n        :param ctx: An instance of :class:`~.context.DockerContext`.\n        :type ctx: dockermap.build.context.DockerContext\n        :param tag: New image tag.\n        :type tag: unicode | str\n        :param kwargs: See :meth:`docker.client.Client.build`.\n        :return: New, generated image id or `None`.\n        :rtype: unicode | str\n        \"\"\"\n        return self.build(fileobj=ctx.fileobj, tag=tag, custom_context=True, encoding=ctx.stream_encoding, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a docker image from the given Dockerfile.", "response": "def build_from_file(self, dockerfile, tag, **kwargs):\n        \"\"\"\n        Builds a docker image from the given :class:`~dockermap.build.dockerfile.DockerFile`. Use this as a shortcut to\n        :meth:`build_from_context`, if no extra data is added to the context.\n\n        :param dockerfile: An instance of :class:`~dockermap.build.dockerfile.DockerFile`.\n        :type dockerfile: dockermap.build.dockerfile.DockerFile\n        :param tag: New image tag.\n        :type tag: unicode | str\n        :param kwargs: See :meth:`docker.client.Client.build`.\n        :return: New, generated image id or ``None``.\n        :rtype: unicode | str\n        \"\"\"\n        with DockerContext(dockerfile, finalize=True) as ctx:\n            return self.build_from_context(ctx, tag, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all stopped containers and removes them; by default does not remove containers that have never been started. :param include_initial: Consider containers that have never been started. :type include_initial: bool :param exclude: Container names to exclude from the cleanup process. :type exclude: collections.Iterable[unicode | str] :param raise_on_error: Forward errors raised by the client and cancel the process. By default only logs errors. :type raise_on_error: bool :param list_only: When set to ``True``, only lists containers, but does not actually remove them. :type list_only: bool :return: List of removed containers. :rtype: list[unicode | str]", "response": "def cleanup_containers(self, include_initial=False, exclude=None, raise_on_error=False, list_only=False):\n        \"\"\"\n        Finds all stopped containers and removes them; by default does not remove containers that have never been\n        started.\n\n        :param include_initial: Consider containers that have never been started.\n        :type include_initial: bool\n        :param exclude: Container names to exclude from the cleanup process.\n        :type exclude: collections.Iterable[unicode | str]\n        :param raise_on_error: Forward errors raised by the client and cancel the process. By default only logs errors.\n        :type raise_on_error: bool\n        :param list_only: When set to ``True``, only lists containers, but does not actually remove them.\n        :type list_only: bool\n        :return: List of removed containers.\n        :rtype: list[unicode | str]\n        \"\"\"\n        exclude_names = set(exclude or ())\n\n        def _stopped_containers():\n            for container in self.containers(all=True):\n                c_names = [name[1:] for name in container['Names'] or () if name.find('/', 2)]\n                c_status = container['Status']\n                if (((include_initial and c_status == '') or c_status.startswith('Exited') or c_status == 'Dead') and\n                        exclude_names.isdisjoint(c_names)):\n                    c_id = container['Id']\n                    c_name = primary_container_name(c_names, default=c_id, strip_trailing_slash=False)\n                    yield c_id, c_name\n\n        stopped_containers = list(_stopped_containers())\n        if list_only:\n            return stopped_containers\n        removed_containers = []\n        for cid, cn in stopped_containers:\n            try:\n                self.remove_container(cn)\n            except:\n                exc_info = sys.exc_info()\n                if raise_on_error:\n                    raise PartialResultsError(exc_info, removed_containers)\n            else:\n                removed_containers.append(cn)\n        return removed_containers"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cleanup_images(self, remove_old=False, keep_tags=None, force=False, raise_on_error=False, list_only=False):\n        used_images = set(self.inspect_container(container['Id'])['Image']\n                          for container in self.containers(all=True))\n        all_images = self.images(all=True)\n        image_dependencies = [(image['Id'], image['ParentId'])\n                              for image in all_images\n                              if image['ParentId']]\n        if remove_old:\n            check_tags = {'latest'}\n            if keep_tags:\n                check_tags.update(keep_tags)\n            tag_check = tag_check_function(check_tags)\n        elif remove_old:\n            tag_check = tag_check_function(['latest'])\n        else:\n            tag_check = is_repo_image\n        keep_images = {image['Id']\n                       for image in all_images\n                       if tag_check(image)} | used_images\n        test_images = [image['Id']\n                       for image in all_images\n                       if image['Id'] not in keep_images]\n        resolver = ImageDependentsResolver(image_dependencies)\n        unused_images = [image_id\n                         for image_id in test_images\n                         if keep_images.isdisjoint(resolver.get_dependencies(image_id))]\n        if list_only:\n            return unused_images\n        removed_images = []\n        for iid in unused_images:\n            try:\n                self.remove_image(iid, force=force)\n            except:\n                exc_info = sys.exc_info()\n                if raise_on_error:\n                    raise PartialResultsError(exc_info, removed_images)\n            else:\n                removed_images.append(iid)\n        return removed_images", "response": "Removes all images that are not used by any container or another image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_all_containers(self, stop_timeout=10, list_only=False):\n        containers = [(container['Id'], container['Status'])\n                      for container in self.containers(all=True)]\n        running_containers = [c_id\n                              for c_id, status in containers\n                              if not (status.startswith('Exited') or status == 'Dead')]\n        if list_only:\n            return running_containers, [c[0] for c in containers]\n        stopped_containers = []\n        for c_id in running_containers:\n            try:\n                self.stop(c_id, timeout=stop_timeout)\n            except Timeout:\n                log.warning(\"Container %s did not stop in time - sent SIGKILL.\", c_id)\n                try:\n                    self.wait(c_id, timeout=stop_timeout)\n                except Timeout:\n                    pass\n            except:\n                exc_info = sys.exc_info()\n                raise PartialResultsError(exc_info, (stopped_containers, []))\n            else:\n                stopped_containers.append(c_id)\n        removed_containers = []\n        for c_id, __ in containers:\n            try:\n                self.remove_container(c_id)\n            except:\n                exc_info = sys.exc_info()\n                raise PartialResultsError(exc_info, (stopped_containers, removed_containers))\n            else:\n                removed_containers.append(c_id)\n        return stopped_containers, removed_containers", "response": "Stops all containers and removes them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_container_names(self):\n        current_containers = self.containers(all=True)\n        return set(c_name[1:] for c in current_containers for c_name in c['Names'])", "response": "Fetches names of all present containers from Docker."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_image_tags(self):\n        current_images = self.images()\n        tags = {tag: i['Id'] for i in current_images for tag in i['RepoTags']}\n        return tags", "response": "Fetches image labels from Docker."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resolve_value(value, types=type_registry):\n    if value is None:\n        return None\n    elif isinstance(value, lazy_type):\n        return value.get()\n    elif types:\n        resolve_func = types.get(expand_type_name(type(value)))\n        if resolve_func:\n            return resolve_func(value)\n    return value", "response": "Resolves the given value for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef resolve_deep(values, max_depth=5, types=None):\n    def _resolve_sub(v, level):\n        l1 = level + 1\n        res_val = resolve_value(v, all_types)\n        if l1 < max_depth:\n            if isinstance(res_val, (list, tuple)):\n                return [_resolve_sub(item, l1) for item in res_val]\n            elif isinstance(res_val, dict):\n                return {resolve_value(rk, all_types): _resolve_sub(rv, l1) for rk, rv in iteritems(res_val)}\n        return res_val\n\n    if types:\n        all_types = type_registry.copy()\n        all_types.update(types)\n    else:\n        all_types = type_registry\n    return _resolve_sub(values, -1)", "response": "Resolves all late - resolving types into their current values to a certain depth."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a type for lazy value resolution.", "response": "def register_type(resolve_type, resolve_func):\n    \"\"\"\n    Registers a type for lazy value resolution. Instances of AbstractLazyObject do not have to\n    be registered. The exact type must be provided in ``resolve_type``, not a superclass of it.\n    Types registered will be passed through the given function by :func:`resolve_value`.\n\n    :param resolve_type: Type to consider during late value resolution.\n    :type resolve_type: type\n    :param resolve_func: Function to run for retrieving the original value. It needs to accept\n     exactly one argument - the substitute value to resolve to the actual value.\n    :type resolve_func: function\n    \"\"\"\n    if not isinstance(resolve_type, type):\n        raise ValueError(\"Expected type, got {0}.\".format(type(resolve_type).__name__))\n    if not callable(resolve_func):\n        raise ValueError(\"Function is not callable.\")\n    type_registry[expand_type_name(resolve_type)] = resolve_func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve and returns the object value. Re - uses an existing previous evaluation.", "response": "def get(self):\n        \"\"\"\n        Resolves and returns the object value. Re-uses an existing previous evaluation, if applicable.\n\n        :return: The result of evaluating the object.\n        \"\"\"\n        if not self._evaluated:\n            self._val = self._func(*self._args, **self._kwargs)\n            self._evaluated = True\n        return self._val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_dependency_paths(item_paths):\n    merged_paths = []\n    for item, path in item_paths:\n        sub_path_idx = []\n        path_set = set(path)\n        for index, (merged_item, merged_path, merged_set) in enumerate(merged_paths):\n            if item in merged_set:\n                path = None\n                break\n            elif merged_item in path_set:\n                sub_path_idx.append(index)\n            elif merged_set & path_set:\n                path = [p for p in path if p not in merged_set]\n                path_set = set(path)\n                if not path:\n                    break\n        for spi in reversed(sub_path_idx):\n            merged_paths.pop(spi)\n        if path is not None:\n            merged_paths.append((item, path, path_set))\n    return [(i[0], i[1]) for i in merged_paths]", "response": "Utility function that merges multiple dependency paths into one."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate this configuration object with values from a dictionary.", "response": "def update_from_dict(self, dct):\n        \"\"\"\n        Updates this configuration object from a dictionary.\n\n        See :meth:`ConfigurationObject.update` for details.\n\n        :param dct: Values to update the ConfigurationObject with.\n        :type dct: dict\n        \"\"\"\n        if not dct:\n            return\n        all_props = self.__class__.CONFIG_PROPERTIES\n        for key, value in six.iteritems(dct):\n            attr_config = all_props.get(key)\n            if attr_config:\n                setattr(self, key, value)\n            else:\n                self.update_default_from_dict(key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate this configuration object with values from another.", "response": "def update_from_obj(self, obj, copy=False):\n        \"\"\"\n        Updates this configuration object from another.\n\n        See :meth:`ConfigurationObject.update` for details.\n\n        :param obj: Values to update the ConfigurationObject with.\n        :type obj: ConfigurationObject\n        :param copy: Copies lists and dictionaries.\n        :type copy: bool\n        \"\"\"\n        obj.clean()\n        obj_config = obj._config\n        all_props = self.__class__.CONFIG_PROPERTIES\n        if copy:\n            for key, value in six.iteritems(obj_config):\n                attr_config = all_props.get(key)\n                if attr_config:\n                    attr_type = attr_config.attr_type\n                    if attr_type:\n                        if issubclass(attr_type, list):\n                            self._config[key] = value[:]\n                        elif attr_type is dict:\n                            self._config[key] = value.copy()\n                    else:\n                        self._config[key] = value\n                    self._modified.discard(key)\n        else:\n            filtered_dict = {key: value\n                             for key, value in six.iteritems(obj_config)\n                             if key in all_props}\n            self._config.update(filtered_dict)\n            self._modified.difference_update(filtered_dict.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_from_dict(self, dct, lists_only=False):\n        if not dct:\n            return\n        self.clean()\n        all_props = self.__class__.CONFIG_PROPERTIES\n        for key, value in six.iteritems(dct):\n            attr_config = all_props.get(key)\n            if attr_config:\n                attr_type, default, input_func, merge_func = attr_config[:4]\n                if (merge_func is not False and value != default and\n                        (not lists_only or (attr_type and issubclass(attr_type, list)))):\n                    if input_func:\n                        value = input_func(value)\n                    self._merge_value(attr_type, merge_func, key, value)\n            else:\n                self.merge_default_from_dict(key, value, lists_only=lists_only)", "response": "Merges a dictionary into this ConfigurationObject."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmerging a configuration object into this one.", "response": "def merge_from_obj(self, obj, lists_only=False):\n        \"\"\"\n        Merges a configuration object into this one.\n\n        See :meth:`ConfigurationObject.merge` for details.\n\n        :param obj: Values to update the ConfigurationObject with.\n        :type obj: ConfigurationObject\n        :param lists_only: Ignore single-value attributes and update dictionary options.\n        :type lists_only: bool\n        \"\"\"\n        self.clean()\n        obj.clean()\n        obj_config = obj._config\n        all_props = self.__class__.CONFIG_PROPERTIES\n        for key, value in six.iteritems(obj_config):\n            attr_config = all_props[key]\n            attr_type, default, __, merge_func = attr_config[:4]\n            if (merge_func is not False and value != default and\n                    (not lists_only or (attr_type and issubclass(attr_type, list)))):\n                self._merge_value(attr_type, merge_func, key, value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the configuration with the contents of the given dictionary or ConfigurationObject.", "response": "def update(self, values, copy_instance=False):\n        \"\"\"\n        Updates the configuration with the contents of the given configuration object or dictionary.\n\n        In case of a dictionary, only valid attributes for this class are considered. Existing attributes are replaced\n        with the new values. The object is not cleaned before or after, i.e. may accept invalid input.\n\n        In case of an update by object, that object is cleaned before the update, so that updated values should be\n        validated. However, already-stored values are not cleaned before or after.\n\n        :param values: Dictionary or ConfigurationObject to update this configuration with.\n        :type values: dict | ConfigurationObject\n        :param copy_instance: Copies lists and dictionaries. Only has an effect if ``values`` is a ConfigurationObject.\n        :type copy_instance: bool\n        \"\"\"\n        if isinstance(values, self.__class__):\n            self.update_from_obj(values, copy=copy_instance)\n        elif isinstance(values, dict):\n            self.update_from_dict(values)\n        else:\n            raise ValueError(\"{0} or dictionary expected; found '{1}'.\".format(self.__class__.__name__,\n                                                                               type(values).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge the values into one list including unique elements from both lists.", "response": "def merge(self, values, lists_only=False):\n        \"\"\"\n        Merges list-based attributes into one list including unique elements from both lists. When ``lists_only`` is\n        set to ``False``, updates dictionaries and overwrites single-value attributes. The resulting configuration\n        is 'clean', i.e. input values converted and validated. If the conversion is not possible, a ``ValueError`` is\n        raised.\n\n        :param values: Values to update the ConfigurationObject with.\n        :type values: dict | ConfigurationObject\n        :param lists_only: Ignore single-value attributes and update dictionary options.\n        :type lists_only: bool\n        \"\"\"\n        if isinstance(values, self.__class__):\n            self.merge_from_obj(values, lists_only=lists_only)\n        elif isinstance(values, dict):\n            self.merge_from_dict(values, lists_only=lists_only)\n        else:\n            raise ValueError(\"{0} or dictionary expected; found '{1}'.\".format(self.__class__.__name__,\n                                                                               type(values).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncleaning the input values of this configuration object.", "response": "def clean(self):\n        \"\"\"\n        Cleans the input values of this configuration object.\n\n        Fields that have gotten updated through properties are converted to configuration values that match the\n        format needed by functions using them. For example, for list-like values it means that input of single strings\n        is transformed into a single-entry list. If this conversion fails, a ``ValueError`` is raised.\n        \"\"\"\n        all_props = self.__class__.CONFIG_PROPERTIES\n        for prop_name in self._modified:\n            attr_config = all_props.get(prop_name)\n            if attr_config and attr_config.input_func:\n                self._config[prop_name] = attr_config.input_func(self._config[prop_name])\n        self._modified.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_dict(self):\n        self.clean()\n        d = OrderedDict()\n        all_props = self.__class__.CONFIG_PROPERTIES\n        for attr_name, attr_config in six.iteritems(all_props):\n            value = self._config[attr_name]\n            attr_type = attr_config.attr_type\n            if attr_type:\n                if value:\n                    if issubclass(attr_type, list):\n                        if issubclass(attr_type, NamedTupleList):\n                            d[attr_name] = [i._asdict() for i in value]\n                        else:\n                            d[attr_name] = value[:]\n                    elif attr_type is dict:\n                        d[attr_name] = dict(value)\n            elif value is not NotSet:\n                d[attr_name] = value\n        return d", "response": "Returns a copy of the configuration dictionary. Changes in this should not reflect on the original\n        object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of actions on the client map and configurations.", "response": "def get_state_actions(self, state, **kwargs):\n        \"\"\"\n        Attached containers are created and prepared, if they are missing. They are re-created if they have terminated\n        with errors. Instance containers are created if missing, started if stopped, and re-created / started if an\n        attached container has been missing.\n\n        :param state: Configuration state.\n        :type state: dockermap.map.state.ConfigState\n        :param kwargs: Additional keyword arguments.\n        :return: Actions on the client, map, and configurations.\n        :rtype: list[dockermap.map.action.ItemAction]\n        \"\"\"\n        config_type = state.config_id.config_type\n        config_tuple = (state.client_name, state.config_id.map_name, state.config_id.config_name)\n        if config_type == ItemType.VOLUME:\n            if state.base_state == State.ABSENT:\n                action = Action.CREATE\n                self.recreated_volumes.add(config_tuple)\n            else:\n                if state.state_flags & StateFlags.NONRECOVERABLE:\n                    action = DerivedAction.RESET_VOLUME\n                    self.recreated_volumes.add(config_tuple)\n                elif state.state_flags & StateFlags.INITIAL:\n                    action = Action.START\n                else:\n                    return None\n            return [\n                ItemAction(state, action),\n                ItemAction(state, VolumeUtilAction.PREPARE),\n            ]\n        elif config_type == ItemType.CONTAINER:\n            if config_tuple in self.recreated_volumes:\n                if state.base_state == State.ABSENT:\n                    action = DerivedAction.STARTUP_CONTAINER\n                elif state.base_state == State.RUNNING:\n                    action = DerivedAction.RESET_CONTAINER\n                elif state.base_state == State.PRESENT:\n                    if state.base_state & StateFlags.INITIAL:\n                        action = Action.START\n                    else:\n                        action = DerivedAction.RELAUNCH_CONTAINER\n                else:\n                    return None\n            else:\n                if state.base_state == State.ABSENT:\n                    action = DerivedAction.STARTUP_CONTAINER\n                else:\n                    if state.state_flags & StateFlags.NONRECOVERABLE:\n                        action = DerivedAction.RESET_CONTAINER\n                    elif (state.base_state != State.RUNNING and\n                          (state.state_flags & StateFlags.INITIAL or\n                           not state.state_flags & StateFlags.PERSISTENT)):\n                        action = Action.START\n                    else:\n                        return None\n            return [\n                ItemAction(state, action),\n                ItemAction(state, ContainerUtilAction.EXEC_ALL),\n            ]\n        elif config_type == ItemType.NETWORK and state.base_state == State.ABSENT:\n            return [ItemAction(state, Action.CREATE)]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dependencies(self, item):\n        def _get_sub_dependency(sub_item):\n            e = self._deps.get(sub_item)\n            if e is None:\n                return self.get_default()\n\n            if e.dependencies is NotInitialized:\n                e.dependencies = self.merge_dependency(sub_item, _get_sub_dependency, e.parent)\n            return e.dependencies\n\n        return _get_sub_dependency(item)", "response": "Returns the list of dependencies on the given item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the direct dependencies or dependents of a single item.", "response": "def get(self, item):\n        \"\"\"\n        Returns the direct dependencies or dependents of a single item. Does not follow the entire dependency path.\n\n        :param item: Node to return dependencies for.\n        :return: Immediate dependencies or dependents.\n        \"\"\"\n        e = self._deps.get(item)\n        if e is None:\n            return self.get_default()\n        return e.parent"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef merge_dependency(self, item, resolve_parent, parents):\n        dep = []\n        for parent_key in parents:\n            if item == parent_key:\n                raise CircularDependency(item, True)\n            parent_dep = resolve_parent(parent_key)\n            if item in parent_dep:\n                raise CircularDependency(item)\n            merge_list(dep, parent_dep)\n        merge_list(dep, parents)\n        return dep", "response": "Merge dependencies of the current element with further dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the dependencies of the items in the inverse relationship format i. e. from an iterable or dict that is structured as a tuple.", "response": "def update(self, items):\n        \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. Note that this implementation is only valid for 1:1 relationships, i.e. that each\n        node has also exactly one dependent. For other cases, :class:`~MultiDependencyResolver` should be used.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n        for parent, sub_item in _iterate_dependencies(items):\n            dep = self._deps[sub_item]\n            if parent not in dep.parent:\n                dep.parent.append(parent)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self, items):\n        for item, parents in _iterate_dependencies(items):\n            dep = self._deps[item]\n            merge_list(dep.parent, parents)", "response": "Updates the dependencies with the given items."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the dependencies in the inverse relationship format i. e. from an iterable or dict that is structured as a list of items. The parent element item is added to the dependencies list.", "response": "def update(self, items):\n        \"\"\"\n        Updates the dependencies in the inverse relationship format, i.e. from an iterable or dict that is structured\n        as `(item, dependent_items)`. The parent element `item` may occur multiple times.\n\n        :param items: Iterable or dictionary in the format `(item, dependent_items)`.\n        :type items: collections.Iterable\n        \"\"\"\n        for parent, sub_items in _iterate_dependencies(items):\n            for si in sub_items:\n                dep = self._deps[si]\n                if parent not in dep.parent:\n                    dep.parent.append(parent)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsignal the container to stop.", "response": "def signal_stop(self, action, c_name, **kwargs):\n        \"\"\"\n        Stops a container, either using the default client stop method, or sending a custom signal and waiting\n        for the container to stop.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param c_name: Container name.\n        :type c_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict\n        \"\"\"\n        client = action.client\n        sig = action.config.stop_signal\n        stop_kwargs = self.get_container_stop_kwargs(action, c_name, kwargs=kwargs)\n        if not sig or sig == 'SIGTERM' or sig == signal.SIGTERM:\n            try:\n                client.stop(**stop_kwargs)\n            except Timeout:\n                log.warning(\"Container %s did not stop in time - sent SIGKILL.\", c_name)\n                try:\n                    client.wait(c_name, timeout=stop_kwargs.get('timeout', 10))\n                except Timeout:\n                    pass\n        else:\n            log.debug(\"Sending signal %s to the container %s and waiting for stop.\", sig, c_name)\n            client.kill(c_name, signal=sig)\n            client.wait(c_name, timeout=stop_kwargs.get('timeout', 10))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preprocess_matches(input_items):\n    for i in input_items:\n        s = i.strip()\n        if not s:\n            continue\n        if s[0] == '!':\n            is_negative = True\n            match_str = s[1:]\n            if not match_str:\n                continue\n        else:\n            is_negative = False\n            match_str = s\n        yield re.compile(fnmatch.translate(LITERAL_PATTERN.sub(r'[\\g<1>]', match_str))), is_negative", "response": "Converts filepath. Match patterns into Python regular expression patterns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate exclusion patterns from a. dockerignore file located in the given path. Returns None if the file does not exist.", "response": "def get_exclusions(path):\n    \"\"\"\n    Generates exclusion patterns from a ``.dockerignore`` file located in the given path. Returns ``None`` if the\n    file does not exist.\n\n    :param path: Path to look up the ``.dockerignore`` in.\n    :type path: unicode | str\n    :return: List of patterns, that can be passed into :func:`get_filter_func`.\n    :rtype: list[(__RegEx, bool)]\n    \"\"\"\n    if not os.path.isdir(path):\n        return None\n    dockerignore_file = os.path.join(path, '.dockerignore')\n    if not os.path.isfile(dockerignore_file):\n        return None\n    with open(dockerignore_file, 'rb') as dif:\n        return list(preprocess_matches(dif.readlines()))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_filter_func(patterns, prefix):\n    prefix_len = len(prefix.strip(os.path.sep)) + 1\n    if any(i[1] for i in patterns):\n        def _exclusion_func(tarinfo):\n            name = tarinfo.name[prefix_len:]\n            exclude = False\n            for match_str, is_negative in patterns:\n                if is_negative:\n                    if not exclude:\n                        continue\n                    if match_str.match(name) is not None:\n                        exclude = False\n                elif exclude:\n                    continue\n                elif match_str.match(name) is not None:\n                    exclude = True\n            if exclude:\n                return None\n            return tarinfo\n    else:\n        # Optimized version: If there are no exemptions from matches, not all matches have to be processed.\n        exclusions = [i[0] for i in patterns]\n\n        def _exclusion_func(tarinfo):\n            name = tarinfo.name[prefix_len:]\n            if any(match_str.match(name) is not None for match_str in exclusions):\n                return None\n            return tarinfo\n\n    return _exclusion_func", "response": "Returns a filter function that can be used as filter argument on tarfile. add."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(self, name, arcname=None, **kwargs):\n        if os.path.isdir(name):\n            exclusions = get_exclusions(name)\n            if exclusions:\n                target_prefix = os.path.abspath(arcname or name)\n                kwargs.setdefault('filter', get_filter_func(exclusions, target_prefix))\n        self.tarfile.add(name, arcname=arcname, **kwargs)", "response": "Add a file or directory to the context tarball."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding the contents of another tarball to this one.", "response": "def addarchive(self, name):\n        \"\"\"\n        Add (i.e. copy) the contents of another tarball to this one.\n\n        :param name: File path to the tar archive.\n        :type name: unicode | str\n        \"\"\"\n        with tarfile.open(name, 'r') as st:\n            for member in st.getmembers():\n                self.tarfile.addfile(member, st.extractfile(member.name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_dockerfile(self, dockerfile):\n        if isinstance(dockerfile, DockerFile):\n            dockerfile.finalize()\n            dockerfile_obj = dockerfile.fileobj\n            for path, arcname in dockerfile._files:\n                self.add(path, arcname=arcname)\n            for archive in dockerfile._archives:\n                self.addarchive(archive)\n            tarinfo = tarfile.TarInfo('Dockerfile')\n            tarinfo.size = dockerfile_obj.tell()\n            dockerfile_obj.seek(0)\n            self.tarfile.addfile(tarinfo, dockerfile_obj)\n        else:\n            self.add(dockerfile, arcname='Dockerfile')", "response": "Adds a Dockerfile to the context."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving the entire Docker context tarball to a separate file.", "response": "def save(self, name):\n        \"\"\"\n        Saves the entire Docker context tarball to a separate file.\n\n        :param name: File path to save the tarball into.\n        :type name: unicode | str\n        \"\"\"\n        with open(name, 'wb+') as f:\n            while True:\n                buf = self._fileobj.read()\n                if not buf:\n                    break\n                f.write(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_kwargs(kwargs, *updates):\n    for update in updates:\n        if not update:\n            continue\n        for key, val in six.iteritems(update):\n            u_item = resolve_value(val)\n            if u_item is None:\n                continue\n            if key in ('command' or 'entrypoint'):\n                kwargs[key] = u_item\n            elif isinstance(u_item, (tuple, list)):\n                kw_item = kwargs.get(key)\n                u_list = map(resolve_value, u_item)\n                if isinstance(kw_item, list):\n                    merge_list(kw_item, u_list)\n                elif isinstance(kw_item, tuple):\n                    new_list = list(kw_item)\n                    merge_list(new_list, u_list)\n                    kwargs[key] = new_list\n                else:\n                    kwargs[key] = list(u_list)\n            elif isinstance(u_item, dict):\n                kw_item = kwargs.get(key)\n                u_dict = {u_k: resolve_value(u_v) for u_k, u_v in six.iteritems(u_item)}\n                if isinstance(kw_item, dict):\n                    kw_item.update(u_dict)\n                else:\n                    kwargs[key] = u_dict\n            else:\n                kwargs[key] = u_item", "response": "Utility function for merging multiple keyword arguments with a single object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate the list of volumes for the container.", "response": "def get_volumes(container_map, config, default_volume_paths, include_named):\n    \"\"\"\n    Generates volume paths for the ``volumes`` argument during container creation.\n\n    :param container_map: Container map.\n    :type container_map: dockermap.map.config.main.ContainerMap\n    :param config: Container configuration.\n    :type config: dockermap.map.config.container.ContainerConfiguration\n    :param default_volume_paths: Dictionary with volume aliases and their default paths.\n    :type default_volume_paths: dict[unicode | str, unicode | str]\n    :param include_named: Whether to include attached and their re-used volumes. This should be done if Docker supports\n      named volumes; otherwise volumes are inherited from other containers via ``volumes_from``.\n    :type include_named: bool\n    :return: List of shared volume mount points.\n    :rtype: list[unicode | str]\n    \"\"\"\n    def _bind_volume_path(vol):\n        if isinstance(vol, HostVolume):\n            return resolve_value(vol.path)\n        v_path = resolve_value(default_volume_paths.get(vol.name))\n        if v_path:\n            return v_path\n        raise KeyError(\"No host-volume information found for alias {0}.\".format(vol))\n\n    def _attached_volume_path(vol):\n        if isinstance(vol, UsedVolume):\n            return resolve_value(vol.path)\n        v_path = resolve_value(default_volume_paths.get(vol.name))\n        if v_path:\n            return v_path\n        raise KeyError(\"No volume information found for alias {0}.\".format(vol))\n\n    def _used_volume_path(vol):\n        if isinstance(vol, UsedVolume):\n            return resolve_value(vol.path)\n        if container_map.use_attached_parent_name:\n            return resolve_value(default_volume_paths.get(vol.name.partition('.')[2]))\n        return resolve_value(default_volume_paths.get(vol.name))\n\n    volumes = list(map(resolve_value, config.shares))\n    volumes.extend(map(_bind_volume_path, config.binds))\n    if include_named:\n        volumes.extend(map(_attached_volume_path, config.attaches))\n        volumes.extend(filter(None, map(_used_volume_path, config.uses)))\n    return volumes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate the list of shared volume mount points for the given container configuration.", "response": "def get_volumes_from(container_map, config_name, config, policy, include_volumes):\n    \"\"\"\n    Generates volume paths for the host config ``volumes_from`` argument during container creation.\n\n    :param container_map: Container map.\n    :type container_map: dockermap.map.config.main.ContainerMap\n    :param config_name: Container configuration name.\n    :type config_name: unicode | str\n    :param config: Container configuration.\n    :type config: dockermap.map.config.container.ContainerConfiguration\n    :param policy: Base policy for generating names and determining volumes.\n    :type policy: dockermap.map.policy.base.BasePolicy\n    :param include_volumes: Whether to include attached and their re-used volumes. This should not be done if Docker\n      supports named volumes, because these are included in ``volumes`` with their paths.\n    :type include_volumes: bool\n    :return: List of shared volume mount points.\n    :rtype: list[unicode | str]\n    \"\"\"\n    aname = policy.aname\n    cname = policy.cname\n    map_name = container_map.name\n    volume_names = set(policy.default_volume_paths[map_name].keys())\n\n    def container_name(u_name):\n        uc_name, __, ui_name = u_name.partition('.')\n        return cname(map_name, uc_name, ui_name)\n\n    def volume_or_container_name(u_name):\n        if u_name in volume_names:\n            if container_map.use_attached_parent_name:\n                v_parent_name, __, attached_name = u_name.partition('.')\n                return aname(map_name, attached_name, v_parent_name)\n            return aname(map_name, u_name)\n        return container_name(u_name)\n\n    def volume_str(name, readonly):\n        if readonly:\n            return '{0}:ro'.format(name)\n        return name\n\n    use_attached_parent_name = container_map.use_attached_parent_name\n    if include_volumes:\n        volumes_from = [volume_str(volume_or_container_name(u.name), u.readonly)\n                        for u in config.uses]\n        a_parent_name = config_name if use_attached_parent_name else None\n        volumes_from.extend([aname(map_name, attached.name, a_parent_name)\n                             for attached in config.attaches])\n        return volumes_from\n\n    if use_attached_parent_name:\n        return [volume_str(container_name(u.name), u.readonly)\n                for u in config.uses\n                if u.name.partition('.')[2] not in volume_names]\n    return [volume_str(container_name(u.name), u.readonly)\n            for u in config.uses\n            if u.name not in volume_names]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating the list of host volumes and named volumes for the container creation.", "response": "def get_host_binds(container_map, config_name, config, instance, policy, named_volumes):\n    \"\"\"\n    Generates the list of host volumes and named volumes (where applicable) for the host config ``bind`` argument\n    during container creation.\n\n    :param container_map: Container map.\n    :type container_map: dockermap.map.config.main.ContainerMap\n    :param config: Container configuration.\n    :type config: dockermap.map.config.container.ContainerConfiguration\n    :param instance: Instance name. Pass ``None`` if not applicable.\n    :type instance: unicode | str\n    :return: List of shared volumes with host volumes and the read-only flag.\n    :rtype: list[unicode | str]\n    \"\"\"\n    def volume_str(paths, readonly):\n        return '{0[1]}:{0[0]}:{1}'.format(paths, 'ro' if readonly else 'rw')\n\n    def _attached_volume(vol):\n        parent_name = config_name if use_attached_parent_name else None\n        volume_name = aname(map_name, vol.name, parent_name=parent_name)\n        if isinstance(vol, UsedVolume):\n            path = resolve_value(vol.path)\n        else:\n            path = resolve_value(default_paths.get(vol.name))\n        return volume_str((path, volume_name), vol.readonly)\n\n    def _used_volume(vol):\n        if use_attached_parent_name:\n            parent_name, __, alias = vol.name.partition('.')\n        else:\n            alias = vol.name\n            parent_name = None\n        if alias not in default_paths:\n            return None\n        volume_name = aname(map_name, alias, parent_name=parent_name)\n        if isinstance(vol, UsedVolume):\n            path = resolve_value(vol.path)\n        else:\n            path = resolve_value(default_paths[alias])\n        return volume_str((path, volume_name), vol.readonly)\n\n    aname = policy.aname\n    map_name = container_map.name\n    use_attached_parent_name = container_map.use_attached_parent_name\n    default_paths = policy.default_volume_paths[map_name]\n    bind = [volume_str(get_shared_volume_path(container_map, shared_volume, instance), shared_volume.readonly)\n            for shared_volume in config.binds]\n    if named_volumes:\n        bind.extend(map(_attached_volume, config.attaches))\n        bind.extend(filter(None, map(_used_volume, config.uses)))\n    return bind"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_port_bindings(container_config, client_config):\n    port_bindings = {}\n    if_ipv4 = client_config.interfaces\n    if_ipv6 = client_config.interfaces_ipv6\n    for exposed_port, ex_port_bindings in itertools.groupby(\n            sorted(container_config.exposes, key=_get_ex_port), _get_ex_port):\n        bind_list = list(_get_port_bindings(ex_port_bindings, if_ipv4, if_ipv6))\n        if bind_list:\n            port_bindings[exposed_port] = bind_list\n    return port_bindings", "response": "Generates the input dictionary contents for the port_bindings argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the command lines for adjusting a volume s ownership and permissions.", "response": "def get_preparation_cmd(user, permissions, path):\n    \"\"\"\n    Generates the command lines for adjusting a volume's ownership and permission flags. Returns an empty list if there\n    is nothing to adjust.\n\n    :param user: User to set ownership for on the path via ``chown``.\n    :type user: unicode | str | int | dockermap.functional.AbstractLazyObject\n    :param permissions: Permission flags to set via ``chmod``.\n    :type permissions: unicode | str | dockermap.functional.AbstractLazyObject\n    :param path: Path to adjust permissions on.\n    :type path: unicode | str\n    :return: Iterator over resulting command strings.\n    :rtype: collections.Iterable[unicode | str]\n    \"\"\"\n    r_user = resolve_value(user)\n    r_permissions = resolve_value(permissions)\n    if user:\n        yield chown(r_user, path)\n    if permissions:\n        yield chmod(r_permissions, path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_urlhash(self, url, fmt):\n        with self.open(os.path.basename(url)) as f:\n            return {'url': fmt(url), 'sha256': filehash(f, 'sha256')}", "response": "Returns the hash of the file of an internal url\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists all versions of a package", "response": "def package_releases(self, package, url_fmt=lambda u: u):\n        \"\"\"List all versions of a package\n\n        Along with the version, the caller also receives the file list with all\n        the available formats.\n        \"\"\"\n        return [{\n            'name': package,\n            'version': version,\n            'urls': [self.get_urlhash(f, url_fmt) for f in files]\n        } for version, files in self.storage.get(package, {}).items()]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch information about the container from the client.", "response": "def inspect(self):\n        \"\"\"\n        Fetches information about the container from the client.\n        \"\"\"\n        policy = self.policy\n        config_id = self.config_id\n        if self.config_id.config_type == ItemType.VOLUME:\n            if self.container_map.use_attached_parent_name:\n                container_name = policy.aname(config_id.map_name, config_id.instance_name, config_id.config_name)\n            else:\n                container_name = policy.aname(config_id.map_name, config_id.instance_name)\n        else:\n            container_name = policy.cname(config_id.map_name, config_id.config_name, config_id.instance_name)\n\n        self.container_name = container_name\n        if container_name in policy.container_names[self.client_name]:\n            self.detail = self.client.inspect_container(container_name)\n        else:\n            self.detail = NOT_FOUND"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninspects the network state.", "response": "def inspect(self):\n        \"\"\"\n        Inspects the network state.\n        \"\"\"\n        if not self.client_config.features['networks']:\n            raise ValueError(\"Client does not support network configuration.\", self.client_name)\n        config_id = self.config_id\n        network_name = self.network_name = self.policy.nname(config_id.map_name, config_id.config_name)\n        if network_name in self.policy.network_names[self.client_name]:\n            self.detail = self.client.inspect_network(network_name)\n        else:\n            self.detail = NOT_FOUND"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inspect(self):\n        if not self.client_config.features['volumes']:\n            raise ValueError(\"Client does not support volume configuration.\", self.client_name)\n        config_id = self.config_id\n        parent_name = config_id.config_name if self.container_map.use_attached_parent_name else None\n        volume_name = self.volume_name = self.policy.aname(config_id.map_name, config_id.instance_name,\n                                                           parent_name=parent_name)\n        if volume_name in self.policy.volume_names[self.client_name]:\n            self.detail = self.client.inspect_volume(volume_name)\n        else:\n            self.detail = NOT_FOUND", "response": "Inspects the network state."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inspect(self):\n        policy = self.policy\n        image_name = format_image_tag((self.config_id.config_name, self.config_id.instance_name))\n        image_id = policy.images[self.client_name].get(image_name)\n        if image_id:\n            self.detail = {'Id': image_id}   # Currently there is no need for actually inspecting the image.\n        else:\n            self.detail = NOT_FOUND", "response": "Fetches image information from the client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_config_states(self, config_id, config_flags=ConfigFlags.NONE):\n        c_map = self._policy.container_maps[config_id.map_name]\n        clients = c_map.clients or [self._policy.default_client_name]\n        config_type = config_id.config_type\n\n        for client_name in clients:\n            if config_type == ItemType.CONTAINER:\n                c_state = self.get_container_state(client_name, config_id, config_flags)\n            elif config_type == ItemType.VOLUME:\n                client_config = self._policy.clients[client_name]\n                if client_config.features['volumes']:\n                    c_state = self.get_volume_state(client_name, config_id, config_flags)\n                else:\n                    c_state = self.get_container_state(client_name, config_id, config_flags)\n            elif config_type == ItemType.NETWORK:\n                c_state = self.get_network_state(client_name, config_id, config_flags)\n            elif config_type == ItemType.IMAGE:\n                c_state = self.get_image_state(client_name, config_id, config_flags)\n            else:\n                raise ValueError(\"Invalid configuration type.\", config_type)\n            c_state.inspect()\n            # Extract base state, state flags, and extra info.\n            state_info = ConfigState(client_name, config_id, config_flags, *c_state.get_state())\n            log.debug(\"Configuration state information: %s\", state_info)\n            yield state_info", "response": "Generates the state of a single item in the container state store."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate state information for the selected containers.", "response": "def get_states(self, config_ids):\n        \"\"\"\n        Generates state information for the selected containers.\n\n        :param config_ids: List of MapConfigId tuples.\n        :type config_ids: list[dockermap.map.input.MapConfigId]\n        :return: Iterable of configuration states.\n        :rtype: collections.Iterable[dockermap.map.state.ConfigState]\n        \"\"\"\n        return itertools.chain.from_iterable(self.generate_config_states(config_id)\n                                             for config_id in config_ids)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_states(self, config_ids):\n        input_paths = [\n            (config_id, list(self.get_dependency_path(config_id)))\n            for config_id in config_ids\n        ]\n        log.debug(\"Dependency paths from input: %s\", input_paths)\n        dependency_paths = merge_dependency_paths(input_paths)\n        log.debug(\"Merged dependency paths: %s\", dependency_paths)\n        return itertools.chain.from_iterable(self._get_all_states(config_id, dependency_path)\n                                             for config_id, dependency_path in dependency_paths)", "response": "Generates state information for the selected container and its dependencies."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_attached_preparation_create_kwargs(self, action, volume_container, volume_alias, kwargs=None):\n        client_config = action.client_config\n        config_id = action.config_id\n        policy = self._policy\n        if client_config.features['volumes']:\n            path = PREPARATION_TMP_PATH\n        else:\n            path = resolve_value(policy.default_volume_paths[config_id.map_name][volume_alias])\n        user = policy.volume_users[config_id.map_name][volume_alias]\n        permissions = policy.volume_permissions[config_id.map_name][volume_alias]\n        cmd = ' && '.join(get_preparation_cmd(user, permissions, path))\n        if not cmd:\n            return None\n        c_kwargs = dict(\n            image=policy.core_image,\n            command=cmd,\n            user='root',\n            network_disabled=True,\n        )\n        hc_extra_kwargs = kwargs.pop('host_config', None) if kwargs else None\n        use_host_config = client_config.features['host_config']\n        if use_host_config:\n            if client_config.features['volumes']:\n                c_kwargs['volumes'] = [PREPARATION_TMP_PATH]\n            hc_kwargs = self.get_attached_preparation_host_config_kwargs(action, None, volume_container,\n                                                                         kwargs=hc_extra_kwargs)\n            if hc_kwargs:\n                if use_host_config == USE_HC_MERGE:\n                    c_kwargs.update(hc_kwargs)\n                else:\n                    c_kwargs['host_config'] = HostConfig(version=client_config.version, **hc_kwargs)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to prepare an attached container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_attached_preparation_host_config_kwargs(self, action, container_name, volume_container, kwargs=None):\n        if action.client_config.features['volumes']:\n            c_kwargs = dict(binds=['{0}:{1}'.format(volume_container, PREPARATION_TMP_PATH)])\n        else:\n            c_kwargs = dict(volumes_from=[volume_container])\n        if container_name:\n            c_kwargs['container'] = container_name\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to set up the HostConfig for preparing an attached container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating keyword arguments for the preparation command that will wait for a container when preparing a volume.", "response": "def get_attached_preparation_wait_kwargs(self, action, container_name, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for waiting for a container when preparing a volume. The container name may be\n        the container being prepared, or the id of the container calling preparation commands.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param container_name: Container name or id. Set ``None`` when included in kwargs for ``create_container``.\n        :type container_name: unicode | str | NoneType\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict | NoneType\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        c_kwargs = dict(container=container_name)\n        client_config = action.client_config\n        c_kwargs = dict(container=container_name)\n        wait_timeout = client_config.get('wait_timeout')\n        if wait_timeout is not None:\n            c_kwargs['timeout'] = wait_timeout\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrun a temporary container for preparing an attached volume.", "response": "def _prepare_container(self, client, action, volume_container, volume_alias):\n        \"\"\"\n        Runs a temporary container for preparing an attached volume for a container configuration.\n\n        :param client: Docker client.\n        :type client: docker.Client\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param volume_container: Name of the container that shares the volume.\n        :type volume_container: unicode | str\n        :param volume_alias: Volume alias that is used for map references, for looking up paths.\n        :type volume_alias: unicode | str\n        \"\"\"\n        apc_kwargs = self.get_attached_preparation_create_kwargs(action, volume_container, volume_alias)\n        if not apc_kwargs:\n            return\n        a_wait_kwargs = self.get_attached_preparation_wait_kwargs(action, volume_container)\n        client.wait(volume_container, **a_wait_kwargs)\n        temp_container = client.create_container(**apc_kwargs)\n        temp_id = temp_container['Id']\n        try:\n            if action.client_config.features['host_config']:\n                client.start(temp_id)\n            else:\n                aps_kwargs = self.get_attached_preparation_host_config_kwargs(action, temp_id, volume_container)\n                client.start(**aps_kwargs)\n            temp_wait_kwargs = self.get_attached_preparation_wait_kwargs(action, temp_id)\n            client.wait(temp_id, **temp_wait_kwargs)\n        finally:\n            client.remove_container(temp_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprepare an attached volume for a container configuration.", "response": "def prepare_attached(self, action, a_name, **kwargs):\n        \"\"\"\n        Prepares an attached volume for a container configuration.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param a_name: The full name or id of the container sharing the volume.\n        :type a_name: unicode | str\n        \"\"\"\n        client = action.client\n        config_id = action.config_id\n        policy = self._policy\n        if action.container_map.use_attached_parent_name:\n            v_alias = '{0.config_name}.{0.instance_name}'.format(config_id)\n        else:\n            v_alias = config_id.instance_name\n        user = policy.volume_users[config_id.map_name][v_alias]\n        permissions = policy.volume_permissions[config_id.map_name][v_alias]\n\n        if not (self.prepare_local and hasattr(client, 'run_cmd')):\n            return self._prepare_container(client, action, a_name, v_alias)\n        if action.client_config.features['volumes']:\n            volume_detail = client.inspect_volume(a_name)\n            local_path = volume_detail['Mountpoint']\n        else:\n            instance_detail = client.inspect_container(a_name)\n            volumes = get_instance_volumes(instance_detail, False)\n            path = resolve_value(policy.default_volume_paths[config_id.map_name][v_alias])\n            local_path = volumes.get(path)\n            if not local_path:\n                raise ValueError(\"Could not locate local path of volume alias '{0}' / \"\n                                 \"path '{1}' in container {2}.\".format(action.config_id.instance_name, path, a_name))\n        return [\n            client.run_cmd(cmd)\n            for cmd in get_preparation_cmd(user, permissions, local_path)\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nextracting the user for running a container from the given value.", "response": "def extract_user(user_value):\n    \"\"\"\n    Extract the user for running a container from the following possible input formats:\n\n    * Integer (UID)\n    * User name string\n    * Tuple of ``user, group``\n    * String in the format ``user:group``\n\n    :param user_value: User name, uid, user-group tuple, or user:group string.\n    :type user_value: int | tuple | unicode | str\n    :return: User name or id.\n    :rtype: unicode | str\n    \"\"\"\n    user = resolve_value(user_value)\n    if not user and user != 0 and user != '0':\n        return None\n    if isinstance(user, tuple):\n        return user[0]\n    if isinstance(user, six.integer_types):\n        return six.text_type(user)\n    return user.partition(':')[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_shared_volume_path(container_map, vol, instance=None):\n    if isinstance(vol, HostVolume):\n        c_path = resolve_value(vol.path)\n        if is_path(c_path):\n            return c_path, get_host_path(container_map.host.root, vol.host_path, instance)\n        raise ValueError(\"Host-container-binding must be described by two paths or one alias name.\",\n                         vol)\n    alias = vol.name\n    volume_config = resolve_value(container_map.volumes.get(alias))\n    h_path = container_map.host.get_path(alias, instance)\n    if volume_config and h_path:\n        return volume_config.default_path, h_path\n    raise KeyError(\"No host-volume information found for alias {0}.\".format(alias))", "response": "Resolves a volume alias of a container configuration or a tuple of two paths to the host and container bind paths."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract the mount points mapped directories or names of a Docker container.", "response": "def get_instance_volumes(instance_detail, check_names):\n    \"\"\"\n    Extracts the mount points and mapped directories or names of a Docker container.\n\n    :param instance_detail: Result from a container inspection.\n    :type instance_detail: dict\n    :param check_names: Whether to check for named volumes.\n    :type check_names: bool\n    :return: Dictionary of volumes, with the destination (inside the container) as a key, and the source (external to\n     the container) as values. If ``check_names`` is ``True``, the value contains the mounted volume name instead.\n    :rtype: dict[unicode | str, unicode | str]\n    \"\"\"\n    if 'Mounts' in instance_detail:\n        if check_names:\n            return {m['Destination']: m.get('Name') or m['Source']\n                    for m in instance_detail['Mounts']}\n        return {m['Destination']: m['Source']\n                for m in instance_detail['Mounts']}\n    return instance_detail.get('Volumes') or {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmerges items into a list.", "response": "def merge_list(merged_list, items):\n    \"\"\"\n    Merges items into a list, appends ignoring duplicates but retaining the original order. This modifies the list and\n    does not return anything.\n\n    :param merged_list: List to append de-duplicated items to.\n    :type merged_list: list\n    :param items: Items to merge into the list.\n    :type items: collections.Iterable\n    \"\"\"\n    if not items:\n        return\n    merged_set = set(merged_list)\n    merged_add = merged_set.add\n    merged_list.extend(item\n                       for item in items\n                       if item not in merged_set and not merged_add(item))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisconnect all containers from a network.", "response": "def disconnect_all_containers(self, action, network_name, containers, **kwargs):\n        \"\"\"\n        Disconnects all containers from a network.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param network_name: Network name or id.\n        :type network_name: unicode | str\n        :param containers: Container names or ids.\n        :type containers: collections.Iterable[unicode | str]\n        :param kwargs: Additional keyword arguments.\n        :type kwargs: dict\n        \"\"\"\n        client = action.client\n        for c_name in containers:\n            disconnect_kwargs = self.get_network_disconnect_kwargs(action, network_name, c_name, kwargs=kwargs)\n            client.disconnect_container_from_network(**disconnect_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef connect_networks(self, action, container_name, endpoints, skip_first=False, **kwargs):\n        if not endpoints or (skip_first and len(endpoints) <= 1):\n            return\n        client = action.client\n        map_name = action.config_id.map_name\n        nname = self._policy.nname\n        if skip_first:\n            endpoints = islice(endpoints, 1, None)\n        for network_endpoint in endpoints:\n            network_name = nname(map_name, network_endpoint.network_name)\n            connect_kwargs = self.get_network_connect_kwargs(action, network_name, container_name, network_endpoint,\n                                                             kwargs=kwargs)\n            client.connect_container_to_network(**connect_kwargs)", "response": "Connects a container to a set of configured networks."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disconnect_networks(self, action, container_name, networks, **kwargs):\n        client = action.client\n        for n_name in networks:\n            disconnect_kwargs = self.get_network_disconnect_kwargs(action, n_name, container_name, kwargs=kwargs)\n            client.disconnect_container_from_network(**disconnect_kwargs)", "response": "Disconnects a container from a set of networks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef connect_all_networks(self, action, container_name, **kwargs):\n        kwargs.setdefault('skip_first', True)\n        self.connect_networks(action, container_name, action.config.networks, **kwargs)", "response": "Connects a container to all of its configured networks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the string buffer to a file. Finalizes prior to saving.", "response": "def save(self, name):\n        \"\"\"\n        Save the string buffer to a file. Finalizes prior to saving.\n\n        :param name: File path.\n        :type name: unicode | str\n        \"\"\"\n        self.finalize()\n        with open(name, 'wb+') as f:\n            if six.PY3:\n                f.write(self.fileobj.getbuffer())\n            else:\n                f.write(self.fileobj.getvalue().encode('utf-8'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves the contents of the temporary file somewhere else. Finalizes prior to saving.", "response": "def save(self, name):\n        \"\"\"\n        Copy the contents of the temporary file somewhere else. Finalizes prior to saving.\n\n        :param name: File path.\n        :type name: unicode | str\n        \"\"\"\n        self.finalize()\n        with open(name, 'wb+') as f:\n            buf = self._fileobj.read()\n            while buf:\n                f.write(buf)\n                buf = self._fileobj.read()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_path(value):\n    return value and isinstance(value, six.string_types) and (value[0] == posixpath.sep or value[:2] == CURRENT_DIR)", "response": "Checks whether the given value represents a path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_list(value):\n    if value is None:\n        return []\n    elif value is NotSet:\n        return NotSet\n    elif isinstance(value, (list, tuple)):\n        return list(value)\n    elif isinstance(value, six.string_types + (lazy_type, )) or uses_type_registry(value):\n        return [value]\n    raise ValueError(\"Invalid type; expected a list, tuple, or string type, found {0}.\".format(\n        type(value).__name__))", "response": "Returns the given value as a list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the network mode of a Docker host configuration.", "response": "def get_network_mode(value):\n    \"\"\"\n    Generates input for the ``network_mode`` of a Docker host configuration. If it points at a container, the\n    configuration of the container is returned.\n\n    :param value: Network mode input.\n    :type value: unicode | str | tuple | list | NoneType\n    :return: Network mode or container to re-use the network stack of.\n    :rtype: unicode | str | tuple | NoneType\n    \"\"\"\n    if not value or value == 'disabled':\n        return 'none'\n    if isinstance(value, (tuple, list)):\n        if len(value) == 2:\n            return tuple(value)\n        return ValueError(\"Tuples or lists need to have length 2 for container network references.\")\n    if value in DEFAULT_PRESET_NETWORKS:\n        return value\n    if value.startswith('container:'):\n        return value\n    if value.startswith('/'):\n        return 'container:{0}'.format(value[1:])\n    ref_name, __, ref_instance = value.partition('.')\n    return ref_name, ref_instance or None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert input into a HealthCheck tuple.", "response": "def get_healthcheck(value):\n    \"\"\"\n    Converts input into a :class:`HealthCheck` tuple. Input can be passed as string, tuple, list, or a dictionary. If\n    set to ``None``, the health check will be set to ``NONE``, i.e. override an existing configuration from the image.\n\n    :param value: Health check input.\n    :type value: unicode | str | tuple | list | NoneType\n    :return: HealthCheck tuple\n    :rtype: HealthCheck\n    \"\"\"\n    if isinstance(value, HealthCheck):\n        return value\n    elif isinstance(value, six.string_types + (lazy_type,)) or uses_type_registry(value):\n        return HealthCheck(value)\n    elif isinstance(value, (tuple, list)):\n        return HealthCheck(*value)\n    elif isinstance(value, dict):\n        return HealthCheck(**value)\n    raise ValueError(\n        \"Invalid type; expected a list, tuple, dict, or string type, found {0}.\".format(type(value).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_type_item(self, value):\n        if isinstance(value, (HostVolume, SharedVolume)):\n            return value\n        elif isinstance(value, six.string_types):\n            return SharedVolume(value, False)\n        elif isinstance(value, (list, tuple)):\n            return _shared_host_volume_from_tuple(*value)\n        elif isinstance(value, dict):\n            v_len = len(value)\n            if v_len == 1:\n                k, v = list(value.items())[0]\n                if k == 'name':\n                    return SharedVolume(v)\n                elif isinstance(v, (list, tuple)):\n                    return _shared_host_volume_from_tuple(k, *v)\n                return _shared_host_volume_from_tuple(k, v)\n            elif 'path' in value:\n                return HostVolume(**value)\n            return SharedVolume(**value)\n        raise ValueError(\n            \"Invalid type; expected a list, tuple, dict, or string type, found {0}.\".format(type(value).__name__))", "response": "Converts the input to a SharedVolume or HostVolume tuple for a host bind."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_type_item(self, value):\n        if isinstance(value, (UsedVolume, SharedVolume)):\n            if value.readonly:\n                raise ValueError(\"Attached volumes should not be read-only.\")\n            return value\n        elif isinstance(value, six.string_types):\n            return SharedVolume(value)\n        elif isinstance(value, (list, tuple)):\n            v_len = len(value)\n            if v_len == 2:\n                if value[1]:\n                    return UsedVolume(value[0], value[1])\n                return SharedVolume(value[0])\n            elif v_len == 1:\n                return SharedVolume(value[0])\n            raise ValueError(\"Invalid element length; only tuples and lists of length 1-2 can be converted to a \"\n                             \"UsedVolume or SharedVolume tuple; found length {0}.\".format(v_len))\n        elif isinstance(value, dict):\n            v_len = len(value)\n            if v_len == 1:\n                k, v = list(value.items())[0]\n                if k == 'name':\n                    return SharedVolume(v)\n                return UsedVolume(k, v)\n            elif 'path' in value:\n                return UsedVolume(**value)\n            return SharedVolume(**value)\n        raise ValueError(\n            \"Invalid type; expected a list, tuple, dict, or string type, found {0}.\".format(type(value).__name__))", "response": "Converts the given value to a UsedVolume or SharedVolume tuple."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the input value to a ExecCommand tuple.", "response": "def get_type_item(self, value):\n        \"\"\"\n        Converts the input to a ExecCommand tuple. It can be from a single string, list, or tuple. Single values (also\n        single-element lists or tuples) are considered a command string, whereas two-element items are read as\n        ``(command string, user name)``.\n\n        :param value: Input value for conversion.\n        :return: ExecCommand tuple.\n        :rtype: ExecCommand\n        \"\"\"\n        if isinstance(value, ExecCommand):\n            return value\n        elif isinstance(value, six.string_types + (lazy_type,)):\n            return ExecCommand(value)\n        elif isinstance(value, (list, tuple)):\n            v_len = len(value)\n            if 1 <= v_len <= 3:\n                return ExecCommand(*value)\n            raise ValueError(\"Invalid element length; only tuples and lists of length 1-3 can be converted to a \"\n                             \"ExecCommand tuple. Found length {0}.\".format(v_len))\n        elif isinstance(value, dict):\n            return ExecCommand(**value)\n        raise ValueError(\n            \"Invalid type; expected a list, tuple, dict, or string type, found {0}.\".format(type(value).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_type_item(self, value):\n        sub_types = six.string_types + six.integer_types\n        if isinstance(value, PortBinding):\n            return value\n        elif isinstance(value, sub_types):  # Port only\n            return PortBinding(value)\n        elif isinstance(value, (list, tuple)):  # Exposed port, host port, and possibly interface\n            v_len = len(value)\n            if v_len == 1 and isinstance(value[0], sub_types):\n                return PortBinding(value[0])\n            if v_len == 2:\n                if isinstance(value[1], dict):\n                    return PortBinding(value[0], **value[1])\n                ex_port, host_bind = value\n                if isinstance(host_bind, sub_types + (lazy_type,)) or host_bind is None or uses_type_registry(\n                        host_bind):\n                    # Port, host port\n                    return PortBinding(ex_port, host_bind)\n                elif isinstance(host_bind, (list, tuple)):\n                    s_len = len(host_bind)\n                    if s_len in (2, 3):  # Port, (host port, interface) or (host port, interface, ipv6)\n                        return PortBinding(ex_port, *host_bind)\n                raise ValueError(\"Invalid sub-element type or length. Needs to be a port number or a tuple / list: \"\n                                 \"(port, interface) or (port, interface, ipv6).\")\n            elif v_len in (3, 4):\n                return PortBinding(*value)\n            raise ValueError(\"Invalid element length; only tuples and lists of length 2 to 4 can be converted to a \"\n                             \"PortBinding tuple.\")\n        elif isinstance(value, dict):\n            return PortBinding(**value)\n        raise ValueError(\n            \"Invalid type; expected a dict, list, tuple, int, or string type, found {0}.\".format(type(value).__name__))", "response": "Converts the given value to a tuple."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert the input value to a NetworkEndpoint tuple.", "response": "def get_type_item(self, value):\n        \"\"\"\n        Converts the input to a NetworkEndpoint tuple. It can be from a single-entry dictionary, single string, list, or\n        tuple. Single values (also single-element lists or tuples) are considered a network name. Dictionaries can also\n        contain nested dictionaries with keyword arguments to the NetworkEndpoint. Lists / tuples of length 2 are also\n        checked for such dictionaries.\n\n        :param value: Input value for conversion.\n        :return: NetworkEndpoint tuple.\n        :rtype: NetworkEndpoint\n        \"\"\"\n        if isinstance(value, NetworkEndpoint):\n            return value\n        elif isinstance(value, six.string_types + (lazy_type,)):\n            return NetworkEndpoint(value)\n        elif isinstance(value, (list, tuple)):\n            v_len = len(value)\n            if v_len == 2 and isinstance(value[1], dict):\n                return NetworkEndpoint(value[0], **value[1])\n            elif 1 <= v_len <= 6:\n                return NetworkEndpoint(*value)\n            raise ValueError(\"Invalid element length; only dictionaries, pr tuples and lists of length 1-6 can be \"\n                             \"converted to a NetworkEndpoint tuple. Found length {0}.\".format(v_len))\n        elif isinstance(value, dict):\n            d_len = len(value)\n            if d_len == 1:\n                k, v = list(value.items())[0]\n                if k == 'network_name':\n                    return NetworkEndpoint(v)\n                if not v:\n                    return NetworkEndpoint(k)\n                if isinstance(v, six.string_types):\n                    return NetworkEndpoint(k, v)\n                v_len = len(v)\n                if isinstance(v, dict):\n                    return NetworkEndpoint(k, **v)\n                elif isinstance(v, (list, tuple)):\n                    if 1 <= v_len <= 5:\n                        return NetworkEndpoint(k, *v)\n                    raise ValueError(\"Invalid sub-element length; lists and tuples of length 1-5 can be converted. \"\n                                     \"Found length {0}.\".format(v_len))\n                raise ValueError(\n                    \"Invalid sub-element format; only dicts and tuples of length 1-5 can be converted. Found \"\n                    \"type {0}.\".format(type(value).__name__))\n            return NetworkEndpoint(**value)\n        raise ValueError(\n            \"Invalid type; expected a dict, list, tuple, or string type, found {0}.\".format(type(value).__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_type_item(self, value, map_name=None, instances=None):\n        if isinstance(value, InputConfigId):\n            return value\n        elif isinstance(value, MapConfigId):\n            if value.instance_name:\n                v_instances = value.instance_name,\n            else:\n                v_instances = None\n            return InputConfigId(value.config_type, value.map_name, value.config_name, v_instances or instances)\n        elif isinstance(value, six.string_types):\n            s_map_name, __, s_config_name = value.partition('.')\n            if s_config_name:\n                config_name, __, s_instance = s_config_name.partition('.')\n                if s_instance:\n                    s_instances = s_instance,\n                else:\n                    s_instances = None\n            else:\n                config_name = s_map_name\n                s_map_name = map_name\n                s_instances = None\n            return InputConfigId(ItemType.CONTAINER, s_map_name, config_name, s_instances or instances)\n        elif isinstance(value, (tuple, list)):\n            v_len = len(value)\n            if v_len == 3:\n                v_instances = value[2]\n                if not v_instances:\n                    return InputConfigId(ItemType.CONTAINER, value[0], value[1])\n                if isinstance(v_instances, tuple):\n                    return InputConfigId(ItemType.CONTAINER, *value)\n                elif isinstance(v_instances, list):\n                    return InputConfigId(ItemType.CONTAINER, value[0], value[1], tuple(v_instances))\n                elif isinstance(v_instances, six.string_types):\n                    return InputConfigId(ItemType.CONTAINER, value[0], value[1], (v_instances,))\n                raise ValueError(\n                    \"Invalid type of instance specification in '{0}'; expected a list, tuple, or string type, \"\n                    \"found {1}.\".format(value, type(v_instances).__name__), v_instances)\n            elif v_len == 2:\n                return InputConfigId(ItemType.CONTAINER, value[0] or map_name, value[1], instances)\n            elif v_len == 1:\n                return InputConfigId(ItemType.CONTAINER, map_name, value[0], instances)\n            raise ValueError(\"Invalid element length; only tuples and lists of length 1-3 can be converted to a \"\n                             \"InputConfigId tuple. Found length {0}.\".format(v_len))\n        elif isinstance(value, dict):\n            kwargs = {\n                'config_type': ItemType.CONTAINER,\n                'map_name': map_name,\n                'instance_names': instances,\n            }\n            kwargs.update(value)\n            return InputConfigId(**kwargs)\n        raise ValueError(\n            \"Invalid type; expected a list, tuple, dict, or string type, found {0}.\".format(type(value).__name__))", "response": "Converts the input value to a InputConfigId tuple."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield all the container configurations that are in group order.", "response": "def expand_groups(config_ids, maps):\n    \"\"\"\n    Iterates over a list of container configuration ids, expanding groups of container configurations.\n\n    :param config_ids: List of container configuration ids.\n    :type config_ids: collections.Iterable[dockermap.map.input.InputConfigId | dockermap.map.input.MapConfigId]\n    :param maps: Extended container maps.\n    :type maps: dict[unicode | str, dockermap.map.config.main.ContainerMap]\n    :return: Expanded MapConfigId tuples.\n    :rtype: collections.Iterable[dockermap.map.input.InputConfigId]\n    \"\"\"\n    for config_id in config_ids:\n        if config_id.map_name == '__all__':\n            c_maps = six.iteritems(maps)\n        else:\n            c_maps = (config_id.map_name, maps[config_id.map_name]),\n        if isinstance(config_id, InputConfigId):\n            instance_name = config_id.instance_names\n        elif isinstance(config_id, MapConfigId):\n            instance_name = (config_id.instance_name, )\n        else:\n            raise ValueError(\"Expected InputConfigId or MapConfigId tuple; found {0}.\"\n                             \"\".format(type(config_id).__name__))\n        for map_name, c_map in c_maps:\n            if config_id.config_name == '__all__' and config_id.config_type == ItemType.CONTAINER:\n                for config_name in six.iterkeys(c_map.containers):\n                    yield MapConfigId(config_id.config_type, map_name, config_name, instance_name)\n            else:\n                group = c_map.groups.get(config_id.config_name)\n                if group is not None:\n                    for group_item in group:\n                        if isinstance(group_item, MapConfigId):\n                            yield group_item\n                        elif isinstance(group_item, six.string_types):\n                            config_name, __, instance = group_item.partition('.')\n                            yield MapConfigId(config_id.config_type, map_name, config_name,\n                                              (instance, ) if instance else instance_name)\n                        else:\n                            raise ValueError(\"Invalid group item. Must be string or MapConfigId tuple; \"\n                                             \"found {0}.\".format(type(group_item).__name__))\n                else:\n                    yield MapConfigId(config_id.config_type, map_name, config_id.config_name, instance_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_instances(config_ids, ext_maps):\n    for type_map_config, items in itertools.groupby(sorted(config_ids, key=get_map_config), get_map_config):\n        config_type, map_name, config_name = type_map_config\n        instances = _get_nested_instances(items)\n        c_map = ext_maps[map_name]\n        try:\n            c_instances = _get_config_instances(config_type, c_map, config_name)\n        except KeyError:\n            raise KeyError(\"Configuration not found.\", type_map_config)\n        if c_instances and None in instances:\n            for i in c_instances:\n                yield MapConfigId(config_type, map_name, config_name, i)\n        else:\n            for i in instances:\n                yield MapConfigId(config_type, map_name, config_name, i)", "response": "Iterates over a list of input configuration ids expanding configured instances if None is specified. Otherwise it yields all of the instances in the list."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a list of MapConfigId tuples with expanded groups listing all input or configured instances and sorted by map and configuration.", "response": "def get_map_config_ids(value, maps, default_map_name=None, default_instances=None):\n    \"\"\"\n    From a value, which can be a string, a iterable of strings, or MapConfigId tuple(s), generates a list of MapConfigId\n    tuples with expanded groups, listing all input or configured instances, and sorted by map and configuration.\n\n    :param value: Input value(s).\n    :type value: str | unicode | dockermap.map.input.InputConfigId | collection.Iterable[str | unicode | dockermap.map.input.InputConfigId]\n    :param maps: Dictionary with expanded container maps, for resolving groups, aliases (``'__all__'``), and configured\n      instances in absence of instance specification in the input.\n    :param default_map_name: Default map name that is used, in case it is not part of the input.\n    :param default_instances: Default instance name list that is used, in case it is not specified in the input.\n    :return: List of MapConfigId tuples.\n    :rtype: list[dockermap.map.input.MapConfigId]\n    \"\"\"\n    input_ids = InputConfigIdList(value, map_name=default_map_name, instances=default_instances)\n    return list(expand_instances(expand_groups(input_ids, maps), maps))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_network(self, action, n_name, **kwargs):\n        c_kwargs = self.get_network_create_kwargs(action, n_name, **kwargs)\n        res = action.client.create_network(**c_kwargs)\n        self._policy.network_names[action.client_name][n_name] = res['Id']\n        return res", "response": "Creates a configured network."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves a network from the map.", "response": "def remove_network(self, action, n_name, **kwargs):\n        \"\"\"\n        Removes a network.\n\n        :param action: Action configuration.\n        :type action: dockermap.map.runner.ActionConfig\n        :param n_name: Network name or id.\n        :type n_name: unicode | str\n        :param kwargs: Additional keyword arguments.\n        :type kwargs: dict\n        \"\"\"\n        c_kwargs = self.get_network_remove_kwargs(action, n_name, **kwargs)\n        res = action.client.remove_network(**c_kwargs)\n        del self._policy.network_names[action.client_name][n_name]\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating keyword arguments for the Docker client to create a container.", "response": "def get_container_create_kwargs(self, action, container_name, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to create a container.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param container_name: Container name.\n        :type container_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict | NoneType\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        policy = self._policy\n        client_config = action.client_config\n        container_map = action.container_map\n        container_config = action.config\n        image_tag = container_map.get_image(container_config.image or action.config_id.config_name)\n        default_paths = policy.default_volume_paths[action.config_id.map_name]\n        c_kwargs = dict(\n            name=container_name,\n            image=format_image_tag(image_tag),\n            volumes=get_volumes(container_map, container_config, default_paths,\n                                client_config.features['volumes']),\n            user=extract_user(container_config.user),\n            ports=[resolve_value(port_binding.exposed_port)\n                   for port_binding in container_config.exposes if port_binding.exposed_port],\n            hostname=policy.get_hostname(container_name, action.client_name) if container_map.set_hostname else None,\n            domainname=resolve_value(client_config.get('domainname', container_map.default_domain)) or None,\n        )\n        if container_config.network_mode == 'none':\n            c_kwargs['network_disabled'] = True\n        elif client_config.features['networks'] and container_config.networks:\n            first_network = container_config.networks[0]\n            c_kwargs['networking_config'] = NetworkingConfig({\n                policy.nname(action.config_id.map_name, first_network.network_name): EndpointConfig(\n                    client_config.version, **self.get_network_create_endpoint_kwargs(action, first_network)\n                )\n            })\n        if client_config.features['stop_signal'] and container_config.stop_signal:\n            c_kwargs['stop_signal'] = container_config.stop_signal\n        hc_extra_kwargs = kwargs.pop('host_config', None) if kwargs else None\n        use_host_config = client_config.features['host_config']\n        if use_host_config:\n            hc_kwargs = self.get_container_host_config_kwargs(action, None, kwargs=hc_extra_kwargs)\n            if hc_kwargs:\n                if use_host_config == USE_HC_MERGE:\n                    c_kwargs.update(hc_kwargs)\n                else:\n                    c_kwargs['host_config'] = HostConfig(version=client_config.version, **hc_kwargs)\n        if client_config.features['stop_timeout'] and container_config.stop_timeout:\n            c_kwargs['stop_timeout'] = container_config.stop_timeout\n        if client_config.features['healthcheck'] and container_config.healthcheck:\n            c_kwargs['healthcheck'] = container_config.healthcheck._asdict()\n        update_kwargs(c_kwargs, init_options(container_config.create_options), kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_container_host_config_kwargs(self, action, container_name, kwargs=None):\n        container_map = action.container_map\n        container_config = action.config\n        client_config = action.client_config\n        config_id = action.config_id\n        map_name = config_id.map_name\n        policy = self._policy\n        cname = policy.cname\n        supports_volumes = client_config.features['volumes']\n\n        c_kwargs = dict(\n            links=[(cname(map_name, l_name), alias or policy.get_hostname(l_name))\n                   for l_name, alias in container_config.links],\n            binds=get_host_binds(container_map, config_id.config_name, container_config, config_id.instance_name,\n                                 policy, supports_volumes),\n            volumes_from=get_volumes_from(container_map, config_id.config_name, container_config,\n                                          policy, not supports_volumes),\n            port_bindings=get_port_bindings(container_config, client_config),\n        )\n        network_mode = container_config.network_mode\n        if isinstance(network_mode, tuple):\n            c_kwargs['network_mode'] = 'container:{0}'.format(cname(map_name, *network_mode))\n        elif isinstance(network_mode, string_types):\n            c_kwargs['network_mode'] = network_mode\n        if container_name:\n            c_kwargs['container'] = container_name\n        update_kwargs(c_kwargs, init_options(container_config.host_config), kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to set up the HostConfig or start a container."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_attached_container_create_kwargs(self, action, container_name, kwargs=None):\n        client_config = action.client_config\n        policy = self._policy\n        config_id = action.config_id\n        path = resolve_value(policy.default_volume_paths[config_id.map_name][config_id.instance_name])\n        user = extract_user(action.config.user)\n        c_kwargs = dict(\n            name=container_name,\n            image=self._policy.base_image,\n            volumes=[path],\n            user=user,\n            network_disabled=True,\n        )\n        hc_extra_kwargs = kwargs.pop('host_config', None) if kwargs else None\n        use_host_config = client_config.features['host_config']\n        if use_host_config:\n            hc_kwargs = self.get_attached_container_host_config_kwargs(action, None, kwargs=hc_extra_kwargs)\n            if hc_kwargs:\n                if use_host_config == USE_HC_MERGE:\n                    c_kwargs.update(hc_kwargs)\n                else:\n                    c_kwargs['host_config'] = HostConfig(version=client_config.version, **hc_kwargs)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to create an attached container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attached_container_host_config_kwargs(self, action, container_name, kwargs=None):\n        if container_name:\n            c_kwargs = {'container': container_name}\n        else:\n            c_kwargs = {}\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to set up the HostConfig or start an attached container."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_container_update_kwargs(self, action, container_name, update_values, kwargs=None):\n        c_kwargs = dict(container=container_name)\n        update_kwargs(c_kwargs, update_values, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to update the HostConfig of an existing container."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_container_wait_kwargs(self, action, container_name, kwargs=None):\n        c_kwargs = dict(container=container_name)\n        timeout = action.client_config.get('wait_timeout')\n        if timeout is not None:\n            c_kwargs['timeout'] = timeout\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to wait for a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_container_stop_kwargs(self, action, container_name, kwargs=None):\n        c_kwargs = dict(\n            container=container_name,\n        )\n        stop_timeout = action.config.stop_timeout\n        if stop_timeout is NotSet:\n            timeout = action.client_config.get('stop_timeout')\n            if timeout is not None:\n                c_kwargs['timeout'] = timeout\n        elif stop_timeout is not None:\n            c_kwargs['timeout'] = stop_timeout\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to stop a container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_container_remove_kwargs(self, action, container_name, kwargs=None):\n        c_kwargs = dict(container=container_name)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to remove a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates keyword arguments for the Docker client to create a network.", "response": "def get_network_create_kwargs(self, action, network_name, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to create a network.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param network_name: Network name or id.\n        :type network_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        config = action.config\n        c_kwargs = dict(\n            name=network_name,\n            driver=config.driver,\n            options=config.driver_options,\n        )\n        if config.internal:\n            c_kwargs['internal'] = True\n        driver_opts = init_options(config.driver_options)\n        if driver_opts:\n            c_kwargs['options'] = {option_name: resolve_value(option_value)\n                                   for option_name, option_value in iteritems(driver_opts)}\n        update_kwargs(c_kwargs, init_options(config.create_options), kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating keyword arguments for the Docker client to remove a network.", "response": "def get_network_remove_kwargs(self, action, network_name, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to remove a network.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param network_name: Network name or id.\n        :type network_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        c_kwargs = dict(net_id=network_name)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_network_create_endpoint_kwargs(self, action, endpoint_config, kwargs=None):\n        map_name = action.config_id.map_name\n        policy = self._policy\n        c_kwargs = dict(\n            ipv4_address=resolve_value(endpoint_config.ipv4_address),\n            ipv6_address=resolve_value(endpoint_config.ipv6_address),\n        )\n        if endpoint_config.aliases:\n            c_kwargs['aliases'] = list(map(resolve_value, endpoint_config.aliases))\n        if endpoint_config.links:\n            c_kwargs['links'] = [(policy.cname(map_name, l_name), alias or policy.get_hostname(l_name))\n                                 for l_name, alias in endpoint_config.links]\n        if endpoint_config.link_local_ips:\n            c_kwargs['link_local_ips'] = list(map(resolve_value, endpoint_config.link_local_ips))\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for Docker s create_endpoint_config utility / EndpointConfig type as well as kwargs for connect_container_to_network."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating keyword arguments for the Docker client to add a container to a network.", "response": "def get_network_connect_kwargs(self, action, network_name, container_name, endpoint_config=None, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to add a container to a network.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param network_name: Network name or id.\n        :type network_name: unicode | str\n        :param container_name: Container name or id.\n        :type container_name: unicode | str\n        :param endpoint_config: Network endpoint configuration.\n        :type endpoint_config: dockermap.map.input.NetworkEndpoint\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        c_kwargs = dict(\n            container=container_name,\n            net_id=network_name,\n        )\n        if endpoint_config:\n            c_kwargs.update(self.get_network_create_endpoint_kwargs(action, endpoint_config))\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating keyword arguments for the Docker client to remove a container from a network.", "response": "def get_network_disconnect_kwargs(self, action, network_name, container_name, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to remove a container from a network.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param container_name: Container name or id.\n        :type container_name: unicode | str\n        :param network_name: Network name or id.\n        :type network_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        c_kwargs = dict(\n            container=container_name,\n            net_id=network_name,\n        )\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_exec_create_kwargs(self, action, container_name, exec_cmd, exec_user, kwargs=None):\n        c_kwargs = dict(\n            container=container_name,\n            cmd=resolve_value(exec_cmd),\n        )\n        if exec_user is not None:\n            c_kwargs['user'] = text_type(resolve_value(exec_user))\n        elif action.config.user is not NotSet:\n            c_kwargs['user'] = extract_user(action.config.user)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to create a container."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate keyword arguments for the Docker client to set up or start a container.", "response": "def get_exec_start_kwargs(self, action, container_name, exec_id, kwargs=None):\n        \"\"\"\n        Generates keyword arguments for the Docker client to set up the HostConfig or start a container.\n\n        :param action: Action configuration.\n        :type action: ActionConfig\n        :param container_name: Container name or id.\n        :type container_name: unicode | str\n        :param kwargs: Additional keyword arguments to complement or override the configuration-based values.\n        :type kwargs: dict | NoneType\n        :param exec_id: Id of the exec instance.\n        :type exec_id: long\n        :return: Resulting keyword arguments.\n        :rtype: dict\n        \"\"\"\n        c_kwargs = dict(exec_id=exec_id)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_volume_create_kwargs(self, action, volume_name, kwargs=None):\n        config = action.config\n        c_kwargs = dict(name=volume_name)\n        if config:\n            c_kwargs['driver'] = config.driver\n            driver_opts = init_options(config.driver_options)\n            if driver_opts:\n                c_kwargs['driver_opts'] = {option_name: resolve_value(option_value)\n                                           for option_name, option_value in iteritems(driver_opts)}\n            update_kwargs(c_kwargs, init_options(config.create_options), kwargs)\n        else:\n            update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to create a volume."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_volume_remove_kwargs(self, action, volume_name, kwargs=None):\n        c_kwargs = dict(name=volume_name)\n        update_kwargs(c_kwargs, kwargs)\n        return c_kwargs", "response": "Generates keyword arguments for the Docker client to remove a volume."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cname(cls, map_name, container, instance=None):\n        if instance:\n            return '{0}.{1}.{2}'.format(map_name, container, instance)\n        return '{0}.{1}'.format(map_name, container)", "response": "Generates a container name that should be used for creating new containers and checking the status of existing containers."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a container name that should be used for creating new attached volume containers and checking the status of existing containers.", "response": "def aname(cls, map_name, attached_name, parent_name=None):\n        \"\"\"\n        Generates a container name that should be used for creating new attached volume containers and checking the\n        status of existing containers.\n\n        In this implementation, the format will be ``<map name>.<attached>``, or ``<map name>.<parent name>.<attached>``\n        if the parent container configuration name is provided.\n\n        :param map_name: Container map name.\n        :type map_name: unicode | str\n        :param attached_name: Attached container alias.\n        :type attached_name: unicode | str\n        :param parent_name: Container configuration name that has contains attached container.\n        :type parent_name: unicode | str\n        :return: Container name.\n        :rtype: unicode | str\n        \"\"\"\n        if parent_name:\n            return '{0}.{1}.{2}'.format(map_name, parent_name, attached_name)\n        return '{0}.{1}'.format(map_name, attached_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nname(cls, map_name, network_name):\n        if network_name in DEFAULT_PRESET_NETWORKS:\n            return network_name\n        return '{0}.{1}'.format(map_name, network_name)", "response": "Generates a network name that should be used for creating new networks and checking the status of existing networks on the client."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_hostname(cls, container_name, client_name=None):\n        base_name = container_name\n        for old, new in cls.hostname_replace:\n            base_name = base_name.replace(old, new)\n        if not client_name or client_name == cls.default_client_name:\n            return base_name\n        client_suffix = client_name\n        for old, new in cls.hostname_replace:\n            client_suffix = client_suffix.replace(old, new)\n        return '{0}-{1}'.format(base_name, client_suffix)", "response": "Determines the host name of a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adduser(username, uid=None, system=False, no_login=True, no_password=False, group=False, gecos=None, **kwargs):\n    return _format_cmd('adduser', username, __system=bool(system), __uid=uid, __group=bool(group), __gid=uid,\n                       no_login=(no_login, _NO_CREATE_HOME, _NO_LOGIN),\n                       __disabled_password=no_login or bool(no_password),\n                       __gecos=gecos, **kwargs)", "response": "Formats an adduser command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting a user and group as needed for chown.", "response": "def get_user_group(user_group):\n    \"\"\"\n    Formats a user and group in the format ``user:group``, as needed for `chown`. If user_group is a tuple, this is used\n    for the fomatting. If a string or integer is given, it will be formatted as ``user:user``. Otherwise the input is\n    returned - this method does not perform any more checks.\n\n    :param user_group: User name, user id, user and group in format ``user:group``, ``user_id:group_id``, or tuple of\n      ``(user, group)``.\n    :type user_group: unicode | str | int | tuple\n    :return: Formatted string with in the format ``user:group``.\n    :rtype: unicode | str\n    \"\"\"\n    if isinstance(user_group, tuple):\n        return '{0}:{1}'.format(*user_group)\n    elif isinstance(user_group, six.integer_types) or ':' not in user_group:\n        return '{0}:{0}'.format(user_group)\n    return user_group"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addgroupuser(username, uid, groupnames=None, system=False, no_login=True, no_password=False, gecos=None, sudo=False,\n                 **kwargs):\n    \"\"\"\n    Generates a unix command line for creating user and group with the same name, assigning the user to the group.\n    Has the same effect as combining :func:`~addgroup`, :func:`~adduser`, and :func:`~assignuser`.\n\n    :param username: User name to create.\n    :type username: unicode | str\n    :param uid: User id to use.\n    :type uid: int\n    :param groupnames: Iterable with additional group names to assign the user to.\n    :type groupnames: collections.Iterable[unicode | str]\n    :param system: Create a system user and group. Default is ``False``.\n    :type system: bool\n    :param no_login: Disallow login of this user and group, and skip creating the home directory. Default is ``True``.\n    :type no_login: bool\n    :param no_password: Do not set a password for the new user.\n    :type: no_password: bool\n    :param gecos: Provide GECOS info and suppress prompt.\n    :type gecos: unicode | str\n    :param sudo: Prepend `sudo` to the command. Default is ``False``. When using Fabric, use its `sudo` command instead.\n    :type sudo: bool\n    :param kwargs: Additional keyword arguments for command line arguments.\n    :return: Unix shell command line.\n    :rtype: unicode | str\n    \"\"\"\n    group = addgroup(username, uid, system)\n    user = adduser(username, uid, system, no_login, no_password, False, gecos, **kwargs)\n    prefix = 'sudo ' if sudo else ''\n    if groupnames:\n        usermod = assignuser(username, groupnames)\n        return '{0}{1} && {0}{2} && {0}{3}'.format(prefix, group, user, usermod)\n    return '{0}{1} && {0}{2}'.format(prefix, group, user)", "response": "Creates a user and group with the same name and assign the user to the group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mkdir(path, create_parent=True, check_if_exists=False):\n    cmd = _format_cmd('mkdir', path, _p=create_parent)\n    if check_if_exists:\n        return 'if [[ ! -d {0} ]]; then {1}; fi'.format(path, cmd)\n    return cmd", "response": "Creates a directory in the NICs base directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mkdir_chown(paths, user_group=None, permissions='ug=rwX,o=rX', create_parent=True, check_if_exists=False, recursive=False):\n\n    def _generate_str(path):\n        mkdir_str = mkdir(path, create_parent, check_if_exists)\n        chown_str = chown(user_group, path, recursive) if user_group else None\n        chmod_str = chmod(permissions, path, recursive) if permissions else None\n        return ' && '.join(n for n in (mkdir_str, chown_str, chmod_str) if n)\n\n    if isinstance(paths, (tuple, list)):\n        return '; '.join((_generate_str(path) for path in paths))\n    return _generate_str(paths)", "response": "Generates a unix command line for creating a directory and assigning permissions to it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding the field to a parent serializer.", "response": "def bind(self, field_name, parent):\n        \"\"\"\n        Create translation serializer dynamically.\n\n        Takes translatable model class (shared_model) from parent serializer and it\n        may create a serializer class on the fly if no custom class was specified.\n        \"\"\"\n        super(TranslatedFieldsField, self).bind(field_name, parent)\n\n        # Expect 1-on-1 for now. Allow using source as alias,\n        # but it should not be a dotted path for now\n        related_name = self.source or field_name\n\n        # This could all be done in __init__(), but by moving the code here,\n        # it's possible to auto-detect the parent model.\n        if self.shared_model is not None and self.serializer_class is not None:\n            return\n\n        # Fill in the blanks\n        if self.serializer_class is None:\n            if self.shared_model is None:\n                # Auto detect parent model\n                from .serializers import TranslatableModelSerializer\n                if not isinstance(parent, TranslatableModelSerializer):\n                    raise TypeError(\"Expected 'TranslatableModelSerializer' as serializer base class\")\n                if not issubclass(parent.Meta.model, TranslatableModel):\n                    raise TypeError(\"Expected 'TranslatableModel' for the parent model\")\n\n                self.shared_model = parent.Meta.model\n\n            # Create serializer based on shared model.\n            translated_model = self.shared_model._parler_meta[related_name]\n            self.serializer_class = create_translated_fields_serializer(\n                self.shared_model, related_name=related_name,\n                meta={'fields': translated_model.get_translated_fields()}\n            )\n        else:\n            if not issubclass(self.serializer_class.Meta.model, TranslatedFieldsModel):\n                raise TypeError(\"Expected 'TranslatedFieldsModel' for the serializer model\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserialize translated fields. Simply iterate over available translations and, for each language, delegate serialization logic to the translation model serializer. Output languages can be selected by passing a list of language codes, `languages`, within the serialization context.", "response": "def to_representation(self, value):\n        \"\"\"\n        Serialize translated fields.\n\n        Simply iterate over available translations and, for each language,\n        delegate serialization logic to the translation model serializer.\n\n        Output languages can be selected by passing a list of language codes,\n        `languages`, within the serialization context.\n        \"\"\"\n        if value is None:\n            return\n\n        # Only need one serializer to create the native objects\n        serializer = self.serializer_class(\n            instance=self.parent.instance,  # Typically None\n            context=self.context,\n            partial=self.parent.partial\n        )\n\n        # Don't need to have a 'language_code', it will be split up already,\n        # so this should avoid redundant output.\n        if 'language_code' in serializer.fields:\n            raise ImproperlyConfigured(\"Serializer may not have a 'language_code' field\")\n\n        translations = value.all()  # value = translations related manager\n        languages = self.context.get('languages')\n        if languages:\n            translations = translations.filter(language_code__in=languages)\n\n        # Split into a dictionary per language\n        result = OrderedDict()\n        for translation in translations:\n            result[translation.language_code] = serializer.to_representation(translation)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_internal_value(self, data):\n        if data is None:\n            return\n\n        if not isinstance(data, dict):\n            self.fail('invalid')\n        if not self.allow_empty and len(data) == 0:\n            self.fail('empty')\n\n        result, errors = {}, {}\n        for lang_code, model_fields in data.items():\n            serializer = self.serializer_class(data=model_fields)\n            if serializer.is_valid():\n                result[lang_code] = serializer.validated_data\n            else:\n                errors[lang_code] = serializer.errors\n\n        if errors:\n            raise serializers.ValidationError(errors)\n        return result", "response": "Deserialize data from translations fields."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(self, text, layers=None):\n        params = {\n            \"text\": text,\n            \"key\": self.key,\n        }\n\n        if layers is not None:\n            # if it's string\n            if isinstance(layers, six.string_types):\n                params[\"layers\"] = layers\n\n            # if it's another iterable object\n            elif isinstance(layers, collections.Iterable):\n                params[\"layers\"] = \",\".join(layers)\n\n        req = requests.get(self.NLU_URL, params=params)\n        return req.json()", "response": "Parses passed text into json object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to get the generated file.", "response": "def generate(self, text):\n        \"\"\"Try to get the generated file.\n\n        Args:\n            text: The text that you want to generate.\n        \"\"\"\n        if not text:\n            raise Exception(\"No text to speak\")\n\n        if len(text) >= self.MAX_CHARS:\n            raise Exception(\"Number of characters must be less than 2000\")\n\n        params = self.__params.copy()\n        params[\"text\"] = text\n        self._data = requests.get(self.TTS_URL, params=params,\n                                  stream=False).iter_content()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self, path=\"speech\"):\n        if self._data is None:\n            raise Exception(\"There's nothing to save\")\n\n        extension = \".\" + self.__params[\"format\"]\n        if os.path.splitext(path)[1] != extension:\n            path += extension\n\n        with open(path, \"wb\") as f:\n            for d in self._data:\n                f.write(d)\n\n        return path", "response": "Save the data in file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_translated_fields_serializer(shared_model, meta=None, related_name=None, **fields):\n    if not related_name:\n        translated_model = shared_model._parler_meta.root_model\n    else:\n        translated_model = shared_model._parler_meta[related_name].model\n\n    # Define inner Meta class\n    if not meta:\n        meta = {}\n    meta['model'] = translated_model\n    meta.setdefault('fields', ['language_code'] + translated_model.get_translated_fields())\n\n    # Define serialize class attributes\n    attrs = {}\n    attrs.update(fields)\n    attrs['Meta'] = type('Meta', (), meta)\n\n    # Dynamically create the serializer class\n    return type('{0}Serializer'.format(translated_model.__name__), (serializers.ModelSerializer,), attrs)", "response": "Create a Rest Framework serializer class for a translated fields model."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsaves the current object and extract the translations and save them after main object save.", "response": "def save(self, **kwargs):\n        \"\"\"\n        Extract the translations and save them after main object save.\n\n        By default all translations will be saved no matter if creating\n        or updating an object. Users with more complex needs might define\n        their own save and handle translation saving themselves.\n        \"\"\"\n        translated_data = self._pop_translated_data()\n        instance = super(TranslatableModelSerializer, self).save(**kwargs)\n        self.save_translations(instance, translated_data)\n        return instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pop_translated_data(self):\n        translated_data = {}\n        for meta in self.Meta.model._parler_meta:\n            translations = self.validated_data.pop(meta.rel_name, {})\n            if translations:\n                translated_data[meta.rel_name] = translations\n        return translated_data", "response": "Return a dict of translated fields from other data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving the translations into the translation objects.", "response": "def save_translations(self, instance, translated_data):\n        \"\"\"\n        Save translation data into translation objects.\n        \"\"\"\n        for meta in self.Meta.model._parler_meta:\n            translations = translated_data.get(meta.rel_name, {})\n            for lang_code, model_fields in translations.items():\n                translation = instance._get_translated_model(lang_code, auto_create=True, meta=meta)\n                for field, value in model_fields.items():\n                    setattr(translation, field, value)\n\n        # Go through the same hooks as the regular model,\n        # instead of calling translation.save() directly.\n        instance.save_translations()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to load the given conf file and return the config object.", "response": "def load_conf(cfg_path):\n    \"\"\"\n    Try to load the given conf file.\n    \"\"\"\n    global config\n    try:\n        cfg = open(cfg_path, 'r')\n    except Exception as ex:\n        if verbose:\n            print(\"Unable to open {0}\".format(cfg_path))\n            print(str(ex))\n        return False\n\n    # Read the entire contents of the conf file\n    cfg_json = cfg.read()\n    cfg.close()\n    # print(cfg_json)\n\n    # Try to parse the conf file into a Python structure\n    try:\n        config = json.loads(cfg_json)\n    except Exception as ex:\n        print(\"Unable to parse configuration file as JSON\")\n        print(str(ex))\n        return False\n\n    # This config was successfully loaded\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_values(name, values):\n    int_values = map(int, values)\n    cv_dict[values_key][name] = int_values", "response": "Adds an alias with list of values to the channel dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndetermine if a list of values are valid DMX values.", "response": "def are_valid_values(values):\n    \"\"\"\n    Determines if a list of values are valid DMX values (0-255).\n    \"\"\"\n    try:\n        int_values = map(int, values)\n        for v in int_values:\n            if (v >= 0) and (v <= 255):\n                continue\n            else:\n                return False\n    except Exception as ex:\n        # print(ex)\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_rc_file():\n    # If an rc file is named in the config, use it.\n    # Otherwise, fall back to looking in the HOME directory.\n    # The fall back won't work under RPi because HOME will be root.\n    if \"uDMXrc\" in config:\n        rcfile = config[\"uDMXrc\"]\n    else:\n        if os.name == \"nt\":\n            # Windows\n            rcfile = os.path.join(os.environ[\"USERPROFILE\"], \".uDMXrc\")\n        else:\n            # Mostly *nix type systems\n            rcfile = os.path.join(os.environ[\"HOME\"], \".uDMXrc\")\n    try:\n        cf = open(rcfile, 'r')\n        for line in cf:\n            tokens = line.split()\n\n            # Blank line\n            if len(tokens) == 0:\n                continue\n\n            # A comment\n            if tokens[0] == '#':\n                continue\n            # A channel alias\n            elif tokens[0] == 'channel':\n                # channel alias value\n                if len(tokens) >= 3:\n                    if is_valid_channel(tokens[2]):\n                        add_channel(tokens[1], tokens[2])\n                    else:\n                        print(line)\n                        print(\"Invalid channel value\")\n                else:\n                    print(line)\n                    print(\"Invalid channel statement\")\n            # A DMX value or values\n            elif tokens[0] in ['value', 'values']:\n                # value alias value\n                if len(tokens) >= 3:\n                    if are_valid_values(tokens[2:]):\n                        add_values(tokens[1], tokens[2:])\n                    else:\n                        print(line)\n                        print(\"Invalid value(s)\")\n                else:\n                    print(line)\n                    print(\"Invalid value statement\")\n            # Something we don't recognize\n            else:\n                print(line)\n                print(tokens[0], \"is not a recognized resource file statement\")\n        cf.close()\n    except:\n        print(\"Unable to open resource file\", rcfile)", "response": "Load the contents of the rc file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef translate_message_tokens(message_tokens):\n    trans_tokens = []\n    if message_tokens[0] in cv_dict[channels_key]:\n        trans_tokens.append(cv_dict[channels_key][message_tokens[0]])\n    else:\n        trans_tokens.append(int(message_tokens[0]))\n\n    for token in message_tokens[1:]:\n        if token in cv_dict[values_key]:\n            trans_tokens.extend(cv_dict[values_key][token])\n        else:\n            trans_tokens.append(int(token))\n\n    return trans_tokens", "response": "Translate a list of tokens into a list of tokens."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend a message to the uDMX USB device.", "response": "def send_dmx_message(message_tokens):\n    \"\"\"\n    Send the DMX message defined by the command line arguments (message tokens).\n    The first argument/token is the DMX channel.\n    The remaining argument(s).token(s) are DMX values.\n    \"\"\"\n\n    # Open the uDMX USB device\n    dev = pyudmx.uDMXDevice()\n    if not dev.open():\n        print(\"Unable to find and open uDMX interface\")\n        return False\n\n    # Translate the tokens into integers.\n    # trans_tokens[0] will be the one-based channel number (1-512) as an integer.\n    # The remaining tokens will be zero-based values (0-255) as integers.\n    trans_tokens = translate_message_tokens(message_tokens)\n\n    if len(trans_tokens) == 2:\n        # Single value message\n        if verbose:\n            print(\"Sending single value message channel:\", trans_tokens[0], \"value:\", trans_tokens[1])\n        n = dev.send_single_value(trans_tokens[0], trans_tokens[1])\n        if verbose:\n            print(\"Sent\", n, \"value\")\n    else:\n        # Multi-value message\n        if verbose:\n            print(\"Sending multi-value message channel:\", trans_tokens[0], \"values:\", trans_tokens[1:])\n        n = dev.send_multi_value(trans_tokens[0], trans_tokens[1:])\n        if verbose:\n            print(\"Sent\", n, \"values\")\n\n    # This may not be absolutely necessary, but it is safe.\n    # It's the closest thing to a close() method.\n    dev.close()\n\n    # Returns True if something was sent\n    return n > 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_headers(cls, msg):\n        return list(email.parser.Parser().parsestr(msg).items())", "response": "Parse HTTP headers.\n\n        Args:\n            msg (str): HTTP message.\n\n        Returns:\n            (List[Tuple[str, str]): List of header tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a string to response object.", "response": "def parse(cls, msg):\n        \"\"\"Parse message string to response object.\"\"\"\n        lines = msg.splitlines()\n        version, status_code, reason = lines[0].split()\n        headers = cls.parse_headers('\\r\\n'.join(lines[1:]))\n        return cls(version=version, status_code=status_code,\n                   reason=reason, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a string to request object.", "response": "def parse(cls, msg):\n        \"\"\"Parse message string to request object.\"\"\"\n        lines = msg.splitlines()\n        method, uri, version = lines[0].split()\n        headers = cls.parse_headers('\\r\\n'.join(lines[1:]))\n        return cls(version=version, uri=uri, method=method, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sendto(self, transport, addr):\n        msg = bytes(self) + b'\\r\\n'\n        logger.debug(\"%s:%s < %s\", *(addr + (self,)))\n        transport.sendto(msg, addr)", "response": "Send a message to a given address via given transport."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef open(self, vendor_id: int = 0x16c0, product_id: int = 0x5dc, bus: int = None, address: int = None) -> bool:\n        kwargs = {}\n        if vendor_id:\n            kwargs[\"idVendor\"] = vendor_id\n        if product_id:\n            kwargs[\"idProduct\"] = product_id\n        if bus:\n            kwargs[\"bus\"] = bus\n        if address:\n            kwargs[\"address\"] = address\n        # Find the uDMX interface\n        self._dev = usb.core.find(**kwargs)\n        return self._dev is not None", "response": "Open the first USB device that matches the search criteria."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n        # This may not be absolutely necessary, but it is safe.\n        # It's the closest thing to a close() method.\n        if self._dev is not None:\n            usb.util.dispose_resources(self._dev)\n            self._dev = None", "response": "Close and release the current usb device."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsends a control message to the current device.", "response": "def _send_control_message(self, cmd: int, value_or_length: int = 1, channel: int = 1,\n                              data_or_length: Union[int, bytearray] = 1) -> int:\n        \"\"\"\n        Sends a control transfer to the current device.\n        :param cmd: 1 for single value transfer, 2 for multi-value transfer\n        :param value_or_length: for single value transfer, the value. For multi-value transfer,\n            the length of the data bytearray.\n        :param channel: DMX channel number, 1- 512\n        :param data_or_length: for a single value transfer it should be 1.\n            For a multi-value transfer, a bytearray containing the values.\n        :return: number of bytes sent.\n        \"\"\"\n\n        if self._dev is None:\n            raise ValueError(\"No usb device opened\")\n\n        # All data transfers use this request type. This is more for\n        # the PyUSB package than for the uDMX as the uDMX does not\n        # use it..\n        bmRequestType = usb.util.CTRL_TYPE_VENDOR | usb.util.CTRL_RECIPIENT_DEVICE | usb.util.CTRL_OUT\n\n        \"\"\"\n        usb request for SetSingleChannel:\n            Request Type:   ignored by device, should be USB_TYPE_VENDOR | USB_RECIP_DEVICE | USB_ENDPOINT_OUT\n            Request:        1\n            Value:          value to set [0 .. 255]\n            Index:          channel index to set [0 .. 511], not the human known value of 1-512\n            Length:         ignored, but returned as the number of byte values transfered\n        usb request for SetMultiChannel:\n            Request Type:   ignored by device, should be USB_TYPE_VENDOR | USB_RECIP_DEVICE | USB_ENDPOINT_OUT\n            Request:        2\n            Value:          number of channels to set [1 .. 512-wIndex]\n            Index:          index of first channel to set [0 .. 511], not the human known value of 1-512\n            Data:           iterable object containing values (we use a bytearray)\n        \"\"\"\n\n        n = self._dev.ctrl_transfer(bmRequestType, cmd, wValue=value_or_length, wIndex=channel - 1,\n                                    data_or_wLength=data_or_length)\n\n        # For a single value transfer the return value is the data_or_length value.\n        # For a multi-value transfer the return value is the number of values transfer\n        # which should be the number of values in the data_or_length bytearray.\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a single value to the uDMX.", "response": "def send_single_value(self, channel: int, value: int) -> int:\n        \"\"\"\n        Send a single value to the uDMX\n        :param channel: DMX channel number, 1-512\n        :param value: Value to be sent to channel, 0-255\n        :return: number of bytes actually sent\n        \"\"\"\n        SetSingleChannel = 1\n        n = self._send_control_message(SetSingleChannel, value_or_length=value, channel=channel, data_or_length=1)\n        return n"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_multi_value(self, channel: int, values: Union[List[int], bytearray]) -> int:\n        SetMultiChannel = 2\n        if isinstance(values, bytearray):\n            ba = values\n        else:\n            ba = bytearray(values)\n        n = self._send_control_message(SetMultiChannel, value_or_length=len(ba),\n                                       channel=channel, data_or_length=ba)\n        return n", "response": "Send multiple consecutive bytes to the uDMX\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a boolean argument to an ArgumentParser instance.", "response": "def add_boolean_argument(parser, name, default=False):\n    \"\"\"Add a boolean argument to an ArgumentParser instance.\"\"\"\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--set',  action='store_true', dest=name,\n                       default=default)\n    group.add_argument('--unset', action='store_false', dest=name,\n                       default=default)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_rgb(dev, red, green, blue, dimmer):\n    cv = [0 for v in range(0, 512)]\n    cv[0] = red\n    cv[1] = green\n    cv[2] = blue\n    cv[6] = dimmer\n    sent = dev.send_multi_value(1, cv)\n    return sent", "response": "Send a set of RGB values to the light\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n\n    # Channel value list for channels 1-512\n    cv = [0 for v in range(0, 512)]\n\n    # Create an instance of the DMX controller and open it    \n    print(\"Opening DMX controller...\")\n    dev = pyudmx.uDMXDevice()\n    # This will automagically find a single Anyma-type USB DMX controller\n    dev.open()\n    # For informational purpose, display what we know about the DMX controller\n    print(dev.Device)\n\n    # Send messages to the light changing it to red, then green, then blue\n    # This is the \"hard way\" to do it, but illustrates how it's done\n\n    print(\"Setting to red...\")\n    cv[0] = 255  # red\n    cv[6] = 128  # dimmer to half value\n    sent = dev.send_multi_value(1, cv)\n    print(\"Set to red\")\n    sleep(3.0)\n\n    print(\"Setting to green...\")\n    cv[0] = 0  # red\n    cv[1] = 255  # green\n    cv[6] = 128  # dimmer to half value\n    sent = dev.send_multi_value(1, cv)\n    print(\"Set to green\")\n    sleep(3.0)\n\n    print(\"Setting to blue...\")\n    cv[0] = 0  # red\n    cv[1] = 0  # green\n    cv[2] = 255  # blue\n    cv[6] = 128  # dimmer to half value\n    sent = dev.send_multi_value(1, cv)\n    print(\"Set to blue\")\n    sleep(3.0)\n\n    # Here's an easier way to do it\n\n    print(\"And, again the easier way\")\n    send_rgb(dev, 255, 0, 0, 128)\n    sleep(3.0)\n    send_rgb(dev, 0, 255, 0, 128)\n    sleep(3.0)\n    send_rgb(dev, 0, 0, 255, 128)\n    sleep(3.0)\n\n    print(\"Reset all channels and close..\")\n    # Turns the light off\n    cv = [0 for v in range(0, 512)]\n    dev.send_multi_value(1, cv)\n    dev.close()", "response": "This function is used to control a DMX light through an Anyma USB controller and a DMX controller"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconnect to vCenter server", "response": "def connect(self):\n        \"\"\"Connect to vCenter server\"\"\"\n        try:\n            context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)\n            if self.config['no_ssl_verify']:\n                requests.packages.urllib3.disable_warnings()\n                context.verify_mode = ssl.CERT_NONE\n                self.si = SmartConnectNoSSL(\n                    host=self.config['server'],\n                    user=self.config['username'],\n                    pwd=self.config['password'],\n                    port=int(self.config['port']),\n                    certFile=None,\n                    keyFile=None,\n                )\n            else:\n                self.si = SmartConnect(\n                    host=self.config['server'],\n                    user=self.config['username'],\n                    pwd=self.config['password'],\n                    port=int(self.config['port']),\n                    sslContext=context,\n                    certFile=None,\n                    keyFile=None,\n                )\n        except Exception as e:\n            print('Unable to connect to vsphere server.')\n            print(e)\n            sys.exit(1)\n\n        # add a clean up routine\n        atexit.register(Disconnect, self.si)\n\n        self.content = self.si.RetrieveContent()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncommanding Section: list VMware objects", "response": "def list_objects(self):\n        \"\"\"\n        Command Section: list\n        List available VMware objects\n        \"\"\"\n        vimtype = self.config['type']\n        vim_obj = \"vim.%s\" % vimtype\n\n        try:\n            container = self.content.viewManager.CreateContainerView(\n                self.content.rootFolder, [eval(vim_obj)], True)\n        except AttributeError:\n            print(\"%s is not a Managed Object Type.  See the vSphere API \"\n                  \"docs for possible options.\" % vimtype)\n            sys.exit(1)\n\n        # print header line\n        print(\"%s list\" % vimtype)\n\n        if vimtype == \"VirtualMachine\":\n            rows = [['MOID', 'Name', 'Status']]\n        else:\n            rows = [['MOID', 'Name']]\n\n        for c in container.view:\n            if vimtype == \"VirtualMachine\":\n                rows.append([c._moId, c.name, c.runtime.powerState])\n            else:\n                rows.append([c._moId, c.name])\n\n        self.print_as_table(rows)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncommand Section: clone Clone a VM from a template", "response": "def clone(self):\n        \"\"\"\n        Command Section: clone\n        Clone a VM from a template\n        \"\"\"\n        self.config['hostname'] = self.config['hostname'].lower()\n        self.config['mem'] = int(self.config['mem'] * 1024)  # convert GB to MB\n\n        print(\"Cloning %s to new host %s with %sMB RAM...\" % (\n            self.config['template'],\n            self.config['hostname'],\n            self.config['mem']\n        ))\n\n        # initialize a list to hold our network settings\n        ip_settings = list()\n\n        # Get network settings for each IP\n        for key, ip_string in enumerate(self.config['ips']):\n\n            # convert ip from string to the 'IPAddress' type\n            ip = IPAddress(ip_string)\n\n            # determine network this IP is in\n            for network in self.config['networks']:\n                if ip in IPNetwork(network):\n                    self.config['networks'][network]['ip'] = ip\n                    ipnet = IPNetwork(network)\n                    self.config['networks'][network]['subnet_mask'] = str(\n                        ipnet.netmask\n                    )\n                    ip_settings.append(self.config['networks'][network])\n\n            # throw an error if we couldn't find a network for this ip\n            if not any(d['ip'] == ip for d in ip_settings):\n                print(\"I don't know what network %s is in.  You can supply \"\n                      \"settings for this network in config.yml.\" % ip_string)\n                sys.exit(1)\n\n        # network to place new VM in\n        self.get_obj([vim.Network], ip_settings[0]['network'])\n        datacenter = self.get_obj([vim.Datacenter],\n                                  ip_settings[0]['datacenter']\n                                  )\n\n        # get the folder where VMs are kept for this datacenter\n        if self.config['destination_folder']:\n            destfolder = self.content.searchIndex.FindByInventoryPath(\n                self.config['destination_folder']\n            )\n        else:\n            destfolder = datacenter.vmFolder\n\n        cluster = self.get_obj([vim.ClusterComputeResource],\n                               ip_settings[0]['cluster']\n                               )\n\n        resource_pool_str = self.config['resource_pool']\n        # resource_pool setting in config file takes priority over the\n        # default 'Resources' pool\n        if resource_pool_str == 'Resources' \\\n                and ('resource_pool' in ip_settings[key]):\n            resource_pool_str = ip_settings[key]['resource_pool']\n\n        resource_pool = self.get_resource_pool(cluster, resource_pool_str)\n\n        host_system = self.config['host']\n        if host_system != \"\":\n            host_system = self.get_obj([vim.HostSystem],\n                                       self.config['host']\n                                       )\n\n        if self.debug:\n            self.print_debug(\n                \"Destination cluster\",\n                cluster\n            )\n            self.print_debug(\n                \"Resource pool\",\n                resource_pool\n            )\n\n        if resource_pool is None:\n            # use default resource pool of target cluster\n            resource_pool = cluster.resourcePool\n\n        datastore = None\n\n        if self.config['datastore']:\n            datastore = self.get_obj(\n                [vim.Datastore], self.config['datastore'])\n        elif 'datastore' in ip_settings[0]:\n            datastore = self.get_obj(\n                [vim.Datastore],\n                ip_settings[0]['datastore'])\n        if datastore is None:\n            print(\"Error: Unable to find Datastore '%s'\"\n                  % ip_settings[0]['datastore'])\n            sys.exit(1)\n\n        if self.config['template_folder']:\n            template_vm = self.get_vm_failfast(\n                self.config['template'],\n                False,\n                'Template VM',\n                path=self.config['template_folder']\n            )\n        else:\n            template_vm = self.get_vm_failfast(\n                self.config['template'],\n                False,\n                'Template VM'\n            )\n\n        # Relocation spec\n        relospec = vim.vm.RelocateSpec()\n        relospec.datastore = datastore\n        if host_system:\n            relospec.host = host_system\n\n        if resource_pool:\n            relospec.pool = resource_pool\n\n        # Networking self.config for VM and guest OS\n        devices = []\n        adaptermaps = []\n\n        # add existing NIC devices from template to our list of NICs\n        # to be created\n        try:\n            for device in template_vm.config.hardware.device:\n\n                if hasattr(device, 'addressType'):\n                    # this is a VirtualEthernetCard, so we'll delete it\n                    nic = vim.vm.device.VirtualDeviceSpec()\n                    nic.operation = \\\n                        vim.vm.device.VirtualDeviceSpec.Operation.remove\n                    nic.device = device\n                    devices.append(nic)\n        except:\n            # not the most graceful handling, but unable to reproduce\n            # user's issues in #57 at this time.\n            pass\n\n        # create a Network device for each static IP\n        for key, ip in enumerate(ip_settings):\n            # VM device\n            nic = vim.vm.device.VirtualDeviceSpec()\n            # or edit if a device exists\n            nic.operation = vim.vm.device.VirtualDeviceSpec.Operation.add\n            nic.device = vim.vm.device.VirtualVmxnet3()\n            nic.device.wakeOnLanEnabled = True\n            nic.device.addressType = 'assigned'\n            # 4000 seems to be the value to use for a vmxnet3 device\n            nic.device.key = 4000\n            nic.device.deviceInfo = vim.Description()\n            nic.device.deviceInfo.label = 'Network Adapter %s' % (key + 1)\n            if 'dvportgroup' in ip_settings[key]:\n                dvpg = ip_settings[key]['dvportgroup']\n                nic.device.deviceInfo.summary = dvpg\n                pg_obj = self.get_obj([vim.dvs.DistributedVirtualPortgroup], dvpg)  # noqa\n                dvs_port_connection = vim.dvs.PortConnection()\n                dvs_port_connection.portgroupKey = pg_obj.key\n                dvs_port_connection.switchUuid = (\n                    pg_obj.config.distributedVirtualSwitch.uuid\n                )\n                # did it to get pep8\n                e_nic = vim.vm.device.VirtualEthernetCard\n                nic.device.backing = (\n                    e_nic.DistributedVirtualPortBackingInfo()\n                )\n\n                nic.device.backing.port = dvs_port_connection\n            else:\n                nic.device.deviceInfo.summary = ip_settings[key]['network']\n                nic.device.backing = (\n                    vim.vm.device.VirtualEthernetCard.NetworkBackingInfo()\n                )\n                nic.device.backing.network = (\n                    self.get_obj([vim.Network], ip_settings[key]['network'])\n                )\n                nic.device.backing.deviceName = ip_settings[key]['network']\n                nic.device.backing.useAutoDetect = False\n\n            nic.device.connectable = vim.vm.device.VirtualDevice.ConnectInfo()\n            nic.device.connectable.startConnected = True\n            nic.device.connectable.allowGuestControl = True\n            devices.append(nic)\n\n            if 'customspecname' in ip_settings[key]:\n                custom_spec_name = ip_settings[key]['customspecname']\n                customspec = (\n                    self.get_customization_settings(custom_spec_name)\n                )\n                guest_map = customspec.nicSettingMap[0]\n            else:\n                customspec = vim.vm.customization.Specification()\n                # guest NIC settings, i.e. 'adapter map'\n                guest_map = vim.vm.customization.AdapterMapping()\n                guest_map.adapter = vim.vm.customization.IPSettings()\n            guest_map.adapter.ip = vim.vm.customization.FixedIp()\n            guest_map.adapter.ip.ipAddress = str(ip_settings[key]['ip'])\n\n            if 'subnet_mask' in ip_settings[key]:\n                guest_map.adapter.subnetMask = (\n                    str(ip_settings[key]['subnet_mask'])\n                )\n\n            if 'gateway' in ip_settings[key]:\n                guest_map.adapter.gateway = ip_settings[key]['gateway']\n\n            if self.config['domain']:\n                guest_map.adapter.dnsDomain = self.config['domain']\n\n            adaptermaps.append(guest_map)\n\n        # DNS settings\n        if 'dns_servers' in self.config:\n            globalip = vim.vm.customization.GlobalIPSettings()\n            globalip.dnsServerList = self.config['dns_servers']\n            globalip.dnsSuffixList = self.config['domain']\n            customspec.globalIPSettings = globalip\n\n        # Hostname settings\n        ident = vim.vm.customization.LinuxPrep()\n        ident.domain = self.config['domain']\n        ident.hostName = vim.vm.customization.FixedName()\n        ident.hostName.name = self.config['hostname']\n\n        customspec.nicSettingMap = adaptermaps\n        customspec.identity = ident\n\n        # VM config spec\n        vmconf = vim.vm.ConfigSpec()\n        vmconf.numCPUs = self.config['cpus']\n        vmconf.memoryMB = self.config['mem']\n        vmconf.cpuHotAddEnabled = True\n        vmconf.memoryHotAddEnabled = True\n        vmconf.deviceChange = devices\n\n        # Clone spec\n        clonespec = vim.vm.CloneSpec()\n        clonespec.location = relospec\n        clonespec.config = vmconf\n        clonespec.customization = customspec\n        clonespec.powerOn = True\n        clonespec.template = False\n\n        self.addDisks(template_vm, clonespec)\n\n        if self.debug:\n            self.print_debug(\"CloneSpec\", clonespec)\n\n        # fire the clone task\n        tasks = [template_vm.Clone(folder=destfolder,\n                                   name=self.config['hostname'],\n                                   spec=clonespec\n                                   )]\n        result = self.WaitForTasks(tasks)\n\n        if self.config['post_clone_cmd']:\n            try:\n                # helper env variables\n                os.environ['EZMOMI_CLONE_HOSTNAME'] = self.config['hostname']\n                print(\"Running --post-clone-cmd %s\"\n                      % self.config['post_clone_cmd'])\n                os.system(self.config['post_clone_cmd'])\n\n            except Exception as e:\n                print(\"Error running post-clone command. Exception: %s\" % e)\n                pass\n\n        # send notification email\n        if self.config['mail']:\n            self.send_email()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef status(self):\n        vm = self.get_vm_failfast(self.config['name'])\n        extra = self.config['extra']\n        parserFriendly = self.config['parserFriendly']\n\n        status_to_print = []\n        if extra:\n            status_to_print = \\\n                [[\"vmname\", \"powerstate\", \"ipaddress\", \"hostname\", \"memory\",\n                  \"cpunum\", \"uuid\", \"guestid\", \"uptime\"]] + \\\n                [[vm.name, vm.runtime.powerState,\n                  vm.summary.guest.ipAddress or '',\n                  vm.summary.guest.hostName or '',\n                  str(vm.summary.config.memorySizeMB),\n                  str(vm.summary.config.numCpu),\n                  vm.summary.config.uuid, vm.summary.guest.guestId,\n                  str(vm.summary.quickStats.uptimeSeconds) or '0']]\n        else:\n            status_to_print = [[vm.name, vm.runtime.powerState]]\n\n        if parserFriendly:\n            self.print_as_lines(status_to_print)\n        else:\n            self.print_as_table(status_to_print)", "response": "Check power status of the virtual machine"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shutdown(self):\n        vm = self.get_vm_failfast(self.config['name'])\n\n        if vm.runtime.powerState == vim.VirtualMachinePowerState.poweredOff:\n            print(\"%s already poweredOff\" % vm.name)\n        else:\n            if self.guestToolsRunning(vm):\n                timeout_minutes = 10\n                print(\"waiting for %s to shutdown \"\n                      \"(%s minutes before forced powerOff)\" % (\n                          vm.name,\n                          str(timeout_minutes)\n                      ))\n                vm.ShutdownGuest()\n                if self.WaitForVirtualMachineShutdown(vm,\n                                                      timeout_minutes * 60):\n                    print(\"shutdown complete\")\n                    print(\"%s poweredOff\" % vm.name)\n                else:\n                    print(\"%s has not shutdown after %s minutes:\"\n                          \"will powerOff\" % (vm.name, str(timeout_minutes)))\n                    self.powerOff()\n\n            else:\n                print(\"GuestTools not running or not installed: will powerOff\")\n                self.powerOff()", "response": "Shutdown guests and power off the virtual machine"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind a resource pool given a pool name for desired cluster", "response": "def get_resource_pool(self, cluster, pool_name):\n        \"\"\"\n        Find a resource pool given a pool name for desired cluster\n        \"\"\"\n        pool_obj = None\n\n        # get a list of all resource pools in this cluster\n        cluster_pools_list = cluster.resourcePool.resourcePool\n\n        # get list of all resource pools with a given text name\n        pool_selections = self.get_obj(\n            [vim.ResourcePool],\n            pool_name,\n            return_all=True\n        )\n\n        # get the first pool that exists in a given cluster\n        if pool_selections:\n            for p in pool_selections:\n                if p in cluster_pools_list:\n                    pool_obj = p\n                    break\n\n        return pool_obj"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the vsphere object associated with a given text name or MOID", "response": "def get_obj(self, vimtype, name, return_all=False, path=\"\"):\n        \"\"\"Get the vsphere object associated with a given text name or MOID\"\"\"\n        obj = list()\n        if path:\n            obj_folder = self.content.searchIndex.FindByInventoryPath(path)\n            container = self.content.viewManager.CreateContainerView(\n                obj_folder, vimtype, True\n            )\n        else:\n            container = self.content.viewManager.CreateContainerView(\n                self.content.rootFolder, vimtype, True)\n\n        for c in container.view:\n            if name in [c.name, c._GetMoId()]:\n                if return_all is False:\n                    return c\n                    break\n                else:\n                    obj.append(c)\n\n        if len(obj) > 0:\n            return obj\n        else:\n            # for backwards-compat\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_host_system_failfast(\n            self,\n            name,\n            verbose=False,\n            host_system_term='HS'\n    ):\n        \"\"\"\n        Get a HostSystem object\n        fail fast if the object isn't a valid reference\n        \"\"\"\n        if verbose:\n            print(\"Finding HostSystem named %s...\" % name)\n\n        hs = self.get_host_system(name)\n\n        if hs is None:\n            print(\"Error: %s '%s' does not exist\" % (host_system_term, name))\n            sys.exit(1)\n\n        if verbose:\n            print(\"Found HostSystem: {0} Name: {1}\" % (hs, hs.name))\n\n        return hs", "response": "Get a HostSystem object fail fast if the object isn t a valid reference"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a VirtualMachine object", "response": "def get_vm(self, name, path=\"\"):\n        \"\"\"Get a VirtualMachine object\"\"\"\n        if path:\n            return self.get_obj([vim.VirtualMachine], name, path=path)\n        else:\n            return self.get_obj([vim.VirtualMachine], name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a VirtualMachine object fail fast if the object isn t a valid reference", "response": "def get_vm_failfast(self, name, verbose=False, vm_term='VM', path=\"\"):\n        \"\"\"\n        Get a VirtualMachine object\n        fail fast if the object isn't a valid reference\n        \"\"\"\n        if verbose:\n            print(\"Finding VirtualMachine named %s...\" % name)\n        if path:\n            vm = self.get_vm(name, path=path)\n        else:\n            vm = self.get_vm(name)\n        if vm is None:\n            print(\"Error: %s '%s' does not exist\" % (vm_term, name))\n            sys.exit(1)\n\n        if verbose:\n            print(\"Found VirtualMachine: %s Name: %s\" % (vm, vm.name))\n\n        return vm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef WaitForVirtualMachineShutdown(\n            self,\n            vm_to_poll,\n            timeout_seconds,\n            sleep_period=5\n    ):\n        \"\"\"\n        Guest shutdown requests do not run a task we can wait for.\n        So, we must poll and wait for status to be poweredOff.\n\n        Returns True if shutdown, False if poll expired.\n        \"\"\"\n        seconds_waited = 0  # wait counter\n        while seconds_waited < timeout_seconds:\n            # sleep first, since nothing shuts down instantly\n            seconds_waited += sleep_period\n            time.sleep(sleep_period)\n\n            vm = self.get_vm(vm_to_poll.name)\n            if vm.runtime.powerState == \\\n                    vim.VirtualMachinePowerState.poweredOff:\n                return True\n\n        return False", "response": "Waits until the VM is poweredOff."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaintains the existing api for Session. request. Used by all of the higher level methods e. g. Session. get.", "response": "def request_patch(self, *args, **kwargs):\n    \"\"\"Maintains the existing api for Session.request.\n    Used by all of the higher level methods, e.g. Session.get.\n    The background_callback param allows you to do some processing on the\n    response in the background, e.g. call resp.json() so that json parsing\n    happens in the background thread.\n    \"\"\"\n    func = sup = super(FuturesSession, self).request\n\n    background_callback = kwargs.pop('background_callback', None)\n    if background_callback:\n        def wrap(*args_, **kwargs_):\n            resp = sup(*args_, **kwargs_)\n            # Patch the closure to return the callback.\n            return background_callback(self, resp)\n\n        func = wrap\n    return self.executor.submit(func, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _start_http_session(self):\n        api_logger.debug(\"Starting new HTTP session...\")\n        self.session = FuturesSession(executor=self.executor, max_workers=self.max_workers)\n        self.session.headers.update({\"User-Agent\": self.user_agent})\n        if self.username and self.password:\n            api_logger.debug(\"Requests will use authorization.\")\n            self.session.auth = HTTPBasicAuth(self.username, self.password)", "response": "Start a new HTTP session."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbases method for handling HTTP requests via the current requests session. :param request_type: The request type as a string (e.g. \"POST\", \"GET\", \"PUT\", etc.) :param sub_uri: The REST end point (sub-uri) to communicate with. :param params: (Optional) HTTP Request parameters. Default: none :param callback: (Optional) A callback function to be excuted on the resulting requests response. This synchronous implementation will return the results of the callback. Default: None. This method returns either the decoded JSON or the raw request content. :param raise_for_status: (Optional) When set True, we raise requests.HTTPError on 4xx or 5xx status. When set False, non-2xx/3xx status code is ignored. Default: True :param raw: (Optional) If no callback is set, return the raw content from the request if this is set True. If False, the method attempts to parse the request as JSON data and return the resutls. Default: False :param kwargs: Additional parameters to pass to the session request call. :return: The concurrent.futures object that holds the future for the API method call.", "response": "def _service_request(self, request_type, sub_uri, params=None, callback=None,\n                         raise_for_status=True, raw=False, **kwargs):\n        \"\"\"\n        Base method for handling HTTP requests via the current requests session.\n        :param request_type: The request type as a string (e.g. \"POST\", \"GET\", \"PUT\", etc.)\n        :param sub_uri: The REST end point (sub-uri) to communicate with.\n        :param params: (Optional) HTTP Request parameters. Default: none\n        :param callback: (Optional) A callback function to be excuted on the resulting requests response.\n                         This synchronous implementation will return the results of the callback.\n                         Default: None. This method returns either the decoded JSON or the raw request content.\n        :param raise_for_status: (Optional) When set True, we raise requests.HTTPError on 4xx or 5xx status. When\n                                 set False, non-2xx/3xx status code is ignored. Default: True\n        :param raw: (Optional) If no callback is set, return the raw content from the request if this is set True.\n                    If False, the method attempts to parse the request as JSON data and return the resutls.\n                    Default: False\n        :param kwargs: Additional parameters to pass to the session request call.\n        :return: The concurrent.futures object that holds the future for the API method call.\n        \"\"\"\n        api_logger.debug(\"Sending request: {} ({})\".format(sub_uri, request_type))\n        if not self.session:\n            self._start_http_session()\n        uri = urljoin(self.uri_base, sub_uri)\n        if params:\n            kwargs.update(params=params)\n        if callback:\n            def base_callback(_, response):\n                if raise_for_status:\n                    response.raise_for_status()\n                response.encoding = 'utf-8'\n                return callback(response)\n        else:\n            def base_callback(_, response):\n                if raise_for_status:\n                    response.raise_for_status()\n                response.encoding = 'utf-8'\n                return response.content if raw else json.loads(response.text)\n        response_future = self.session.request(request_type, uri, background_callback=base_callback, **kwargs)\n        return response_future"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets geolocation data for a given IP address.", "response": "def location(ip=None, key=None, field=None):\n    ''' Get geolocation data for a given IP address\n        If field is specified, get specific field as text \n        Else get complete location data as JSON \n    '''\n\n    if field and (field not in field_list):\n        return 'Invalid field'\n\n    if field:\n        if ip:\n            url = 'https://ipapi.co/{}/{}/'.format(ip, field)\n        else:\n            url = 'https://ipapi.co/{}/'.format(field)\n    else:\n        if ip:\n            url = 'https://ipapi.co/{}/json/'.format(ip)\n        else:\n            url = 'https://ipapi.co/json/'\n\n    if key or API_KEY:\n        url = '{}?key={}'.format(url, (key or API_KEY))\n\n    response = get(url, headers=headers)\n\n    if field:\n        return response.text\n    else:\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def main_loop(loop, password, user, ip):  # pylint: disable=invalid-name\n    async with aiohttp.ClientSession(loop=loop) as session:\n        VAR['sma'] = pysma.SMA(session, ip, password=password, group=user)\n        await VAR['sma'].new_session()\n        if VAR['sma'].sma_sid is None:\n            _LOGGER.info(\"No session ID\")\n            return\n\n        _LOGGER.info(\"NEW SID: %s\", VAR['sma'].sma_sid)\n\n        VAR['running'] = True\n        cnt = 5\n        sensors = pysma.Sensors()\n        while VAR.get('running'):\n            await VAR['sma'].read(sensors)\n            print_table(sensors)\n            cnt -= 1\n            if cnt == 0:\n                break\n            await asyncio.sleep(2)\n\n        await VAR['sma'].close_session()", "response": "Main loop for the main loop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the cache with the current result from GitHub.", "response": "def update(self):\n        \"\"\"\n        Connect to GitHub API endpoint specified by `_apicall_parameters()`,\n        postprocess the result using `_apiresult_postprocess()` and trigger\n        a cache update if the API call was successful.\n\n        If an error occurs, cache the empty result generated by\n        `_apiresult_error()`. Additionally, set up retrying after a certain\n        time.\n\n        Return `True` if the API call was successful, `False` otherwise.\n\n        Call this method directly if you want to invalidate the current cache.\n        Otherwise, just call `data()`, which will automatically call `update()`\n        if required.\n        \"\"\"\n        result = self.api.github_api(*self._apicall_parameters())\n        if result is None:\n            # an error occurred, try again after BACKOFF\n            self._next_update = datetime.now() + timedelta(seconds=self.BACKOFF)\n            # assume an empty result until the error disappears\n            self._cached_result = self._apiresult_error()\n        else:\n            # request successful, cache does not expire\n            self._next_update = None\n            # Write the new result into self._cached_result to be picked up by\n            # _data on `del self._data`.\n            self._cached_result = self._apiresult_postprocess(result)\n\n        # Don't `del self._data` if it has never been cached, that would create\n        # ugly database entries in the cache table.\n        if not self._first_lookup:\n            del self._data\n        else:\n            self._first_lookup = False\n\n        # signal success or error\n        return result is not None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the data from Trac cache.", "response": "def data(self):\n        \"\"\"\n        Get a cached post-processed result of a GitHub API call. Uses Trac cache\n        to avoid constant querying of the remote API. If a previous API call did\n        not succeed, automatically retries after a timeout.\n        \"\"\"\n        if self._next_update and datetime.now() > self._next_update:\n            self.update()\n        return self._data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef teams(self):\n        teams = self._teamlist.teams()\n\n        # find out which teams have been added or removed since the last sync\n        current_teams = set(self._teamobjects.keys())\n        new_teams = set(teams.keys()) # pylint: disable=no-member\n        added = new_teams - current_teams\n        removed = current_teams - new_teams\n\n        for team in removed:\n            del self._teamobjects[team]\n        for team in added:\n            self._teamobjects[team] = GitHubTeam(\n                self._api, self._env, self._org, teams[team], team) # pylint: disable=unsubscriptable-object\n        return self._teamobjects.values()", "response": "Return a sequence of GitHubTeam objects one for each team in this\n        org.\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef members(self):\n        allmembers = set()\n        for team in self.teams():\n            allmembers.update(team.members())\n        return sorted(allmembers)", "response": "Return a list of all users in this organization. Users are identified by their login name. Users are identified by their teams in this organization. Users are identified by their login name. Users are identified by their login name. Users are identified by their teams in this organization."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntriggers an update and cache invalidation for the team identified by the given slug. Returns True on success False otherwise.", "response": "def update_team(self, slug):\n        \"\"\"\n        Trigger an update and cache invalidation for the team identified by the\n        given `slug`. Returns `True` on success, `False` otherwise.\n\n        :param slug: The GitHub 'slug' that identifies the team in URLs\n        \"\"\"\n        if slug not in self._teamobjects:\n            # This case is checked and handled further up, but better be safe\n            # than sorry.\n            return False # pragma: no cover\n        return self._teamobjects[slug].update()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef github_api(self, url, *args):\n        import requests\n        import urllib\n\n        github_api_url = os.environ.get(\"TRAC_GITHUB_API_URL\", \"https://api.github.com/\")\n        formatted_url = github_api_url + url.format(*(urllib.quote(str(x)) for x in args))\n        access_token = _config_secret(self.access_token)\n        self.log.debug(\"Hitting GitHub API endpoint %s with user %s\", formatted_url, self.username) # pylint: disable=no-member\n        results = []\n        try:\n            has_next = True\n            while has_next:\n                req = requests.get(formatted_url, auth=(self.username, access_token))\n                if req.status_code != 200:\n                    try:\n                        message = req.json()['message']\n                    except Exception: # pylint: disable=broad-except\n                        message = req.text\n                    self.log.error(\"Error communicating with GitHub API at {}: {}\".format( # pylint: disable=no-member\n                        formatted_url, message))\n                    return None\n                results.extend(req.json())\n                has_next = 'next' in req.links\n                if has_next:\n                    formatted_url = req.links['next']['url']\n        except requests.exceptions.ConnectionError as rce:\n            self.log.error(\"Exception while communicating with GitHub API at {}: {}\".format( # pylint: disable=no-member\n                formatted_url, rce))\n            return None\n        return results", "response": "Connect to the given GitHub API URL and return the decoded JSON\n        result on success Return None on error"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_team(self, slug):\n        if self._org:\n            if not self._org.has_team(slug):\n                return self._org.update()\n            return self._org.update_team(slug)\n        # self._org is created during Trac startup, so there should never\n        # be a case where we try to update an org before it's created; this\n        # is a sanity check only.\n        return False", "response": "Trigger update and cache invalidation for the given team identified by the\n        given slug. Returns True if the update was successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of names of the groups that the user with the specified username is a member of. Implements an IPermissionGroupProvider API.", "response": "def get_permission_groups(self, username):\n        \"\"\"\n        Return a list of names of the groups that the user with the specified\n        name is a member of. Implements an `IPermissionGroupProvider` API.\n\n        This specific implementation connects to GitHub with a dedicated user,\n        fetches and caches the teams and their users configured at GitHub and\n        converts the data into a format usable for easy access by username.\n        \"\"\"\n        if not self.organization or not self.username or not self.access_token:\n            return []\n        elif (self.username_prefix and\n                not username.startswith(self.username_prefix)):\n            return []\n\n        data = self._fetch_groups()\n        if not data:\n            self.log.error(\"No cached groups from GitHub available\") # pylint: disable=no-member\n            return []\n        else:\n            return data.get(username[len(self.username_prefix):], [])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning whether the handler wants to process the given request.", "response": "def match_request(self, req):\n        \"\"\"\n        Return whether the handler wants to process the given request.\n        Implements an `IRequestHandler` API.\n        \"\"\"\n        match = self._request_re.match(req.path_info)\n        if match:\n            return True\n        if os.environ.get('TRAC_GITHUB_ENABLE_DEBUGGING', None) is not None:\n            debug_match = self._debug_request_re.match(req.path_info)\n            if debug_match:\n                return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nprocess the given request and return a tuple of the contents of the response.", "response": "def process_request(self, req):\n        \"\"\"\n        Process the given request `req`, implements an `IRequestHandler` API.\n\n        Normally, `process_request` would return a tuple, but since none of\n        these requests will return an HTML page, they will all terminate\n        without a return value and directly send a response.\n        \"\"\"\n        if os.environ.get('TRAC_GITHUB_ENABLE_DEBUGGING', None) is not None:\n            debug_match = self._debug_request_re.match(req.path_info)\n            if debug_match:\n                self.process_debug_request(req)\n\n        if req.method != 'POST':\n            msg = u'Endpoint is ready to accept GitHub Organization membership notifications.\\n'\n            self.log.warning(u'Method not allowed (%s)', req.method) # pylint: disable=no-member\n            req.send(msg.encode('utf-8'), 'text/plain', 405)\n\n        event = req.get_header('X-GitHub-Event')\n        supported_events = {\n            'ping': self._handle_ping_ev,\n            'membership': self._handle_membership_ev\n        }\n\n        # Check whether this event is supported\n        if event not in supported_events:\n            msg = u'Event type %s is not supported\\n' % event\n            self.log.warning(msg.rstrip('\\n')) # pylint: disable=no-member\n            req.send(msg.encode('utf-8'), 'text/plain', 400)\n\n        # Verify the event's signature\n        reqdata = req.read()\n        signature = req.get_header('X-Hub-Signature')\n        if not self._verify_webhook_signature(signature, reqdata):\n            msg = u'Webhook signature verification failed\\n'\n            self.log.warning(msg.rstrip('\\n')) # pylint: disable=no-member\n            req.send(msg.encode('utf-8'), 'text/plain', 403)\n\n        # Decode JSON and handle errors\n        try:\n            payload = json.loads(reqdata)\n        except (ValueError, KeyError):\n            msg = u'Invalid payload\\n'\n            self.log.warning(msg.rstrip('\\n')) # pylint: disable=no-member\n            req.send(msg.encode('utf-8'), 'text/plain', 400)\n\n        # Handle the event\n        try:\n            supported_events[event](req, payload)\n        except RequestDone:\n            # Normal termination, bubble up\n            raise\n        except Exception: # pylint: disable=broad-except\n            msg = (u'Exception occurred while handling payload, '\n                   'possible invalid payload\\n%s' % traceback.format_exc())\n            self.log.warning(msg.rstrip('\\n')) # pylint: disable=no-member\n            req.send(msg.encode('utf-8'), 'text/plain', 500)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef all_of(api_call, *args, **kwargs):\n    kwargs = kwargs.copy()\n    pos, outer_limit = 0, kwargs.get('limit', 0) or sys.maxsize\n    while True:\n        response = api_call(*args, **kwargs)\n        for item in response.get('results', []):\n            pos += 1\n            if pos > outer_limit:\n                return\n            yield item\n        ##print((pos, response['start'], response['limit']))\n        if response.get('_links', {}).get('next', None):\n            kwargs['start'] = response['start'] + response['size']\n            kwargs['limit'] = response['limit']\n        else:\n            return", "response": "Generator that iterates over all results of an API call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _start_http_session(self):\n        api_logger.debug(\"Starting new HTTP session...\")\n        self.session = requests.Session()\n        self.session.headers.update({\"User-Agent\": self.user_agent})\n        if self.username and self.password:\n            api_logger.debug(\"Requests will use authorization.\")\n            self.session.auth = HTTPBasicAuth(self.username, self.password)", "response": "Start a new requests HTTP session."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_content(self, content_type=None, space_key=None, title=None, status=None, posting_day=None,\n                    expand=None, start=None, limit=None, callback=None):\n        \"\"\"\n        Returns a paginated list of Content.\n        :param content_type (string): OPTIONAL: The content type to return. Default value: \"page\".\n                                      Valid values: \"page\",\"blogpost\".\n        :param space_key (string): OPTIONAL: The space key to find content under.\n        :param title (string): OPTIONAL: The title of the page to find. Required for page type.\n        :param status (string): OPTIONAL: List of statuses the content to be found is in. Defaults to current\n                                is not specified. If set to 'any', content in 'current' and 'trashed' status\n                                will be fetched. Does not support 'historical' status for now.\n        :param posting_day (string): OPTIONAL: The posting day of the blog post. Required for blogpost type.\n                                     Format: yyyy-mm-dd. Example: 2013-02-13\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the content.\n                                Default value: history,space,version\n        :param start (int): OPTIONAL: The start point of the collection to return.\n        :param limit (int): OPTIONAL: The limit of the number of items to return,\n                            this may be restricted by fixed system limits.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content endpoint, or the results of the callback.\n                 Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if content_type:\n            params[\"type\"] = content_type\n        if space_key:\n            params[\"spaceKey\"] = space_key\n        if title:\n            params[\"title\"] = title\n        if status:\n            params[\"status\"] = status\n        if posting_day:\n            params[\"postingDay\"] = posting_day\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content\", params=params, callback=callback)", "response": "Returns a paginated list of Content."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a piece of Content.", "response": "def get_content_by_id(self, content_id, status=None, version=None, expand=None, callback=None):\n        \"\"\"\n        Returns a piece of Content.\n        :param content_id (string): The id of the content.\n        :param status (string): OPTIONAL: List of Content statuses to filter results on. Default value: [current]\n        :param version (int): OPTIONAL: The content version to retrieve. Default: Latest.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the content.\n                                Default value: history,space,version We can also specify some extensions such as\n                                extensions.inlineProperties (for getting inline comment-specific properties) or\n                                extensions.resolution for the resolution status of each comment in the results.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id} endpoint, or the results of the callback.\n                 Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if status:\n            params[\"status\"] = status\n        if version is not None:\n            params[\"version\"] = int(version)\n        if expand:\n            params[\"expand\"] = expand\n        return self._service_get_request(\"rest/api/content/{id}\".format(id=content_id), params=params,\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a specific content s macro by its hash.", "response": "def get_content_macro_by_hash(self, content_id, version, macro_hash, callback=None):\n        \"\"\"\n        Returns the body of a macro (in storage format) with the given hash.\n        This resource is primarily used by connect applications that require the body of macro to perform their work.\n\n        The hash is generated by connect during render time of the local macro holder and\n        is usually only relevant during the scope of one request. For optimisation purposes, this hash will usually\n        live for multiple requests.\n\n        Collecting a macro by its hash should now be considered deprecated and will be replaced,\n        transparently with macroIds. This resource is currently only called from connect addons\n        which will eventually all use the\n        {@link #getContentById(com.atlassian.confluence.api.model.content.id.ContentId,\n        java.util.List, Integer, String)} resource.\n\n        To make the migration as seamless as possible, this resource will match macros against a generated hash or a\n        stored macroId. This will allow add ons to work during the migration period.\n        :param content_id (string): A string containing the id of the content.\n        :param version (int): The version of the content which the hash belongs.\n        :param macro_hash (string): The macroId to find the correct macro\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the endpoint, or the results of the callback.\n                 Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        return self._service_get_request(\"rest/api/content/{id}/history/{version}/macro/hash/{hash}\"\n                                         \"\".format(id=content_id, version=version, hash=macro_hash), callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the body of a content with the given id and version.", "response": "def get_content_macro_by_macro_id(self, content_id, version, macro_id, callback=None):\n        \"\"\"\n        Returns the body of a macro (in storage format) with the given id.\n        This resource is primarily used by connect applications that require the body of macro to perform their work.\n\n        When content is created, if no macroId is specified, then Confluence will generate a random id.\n        The id is persisted as the content is saved and only modified by Confluence if there are conflicting IDs.\n\n        To preserve backwards compatibility this resource will also match on the hash of the macro body, even if a\n        macroId is found. This check will become redundant as pages get macroId's generated for them and transparently\n        propagate out to all instances.\n        :param content_id (string): A string containing the id of the content.\n        :param version (int): The version of the content to search.\n        :param macro_id (string): The macroID to find the corresponding macro.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the endpoint, or the results of the callback.\n                 Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        return self._service_get_request(\"rest/api/content/{id}/history/{version}/macro/id/{macro_id}\"\n                                         \"\".format(id=content_id, version=int(version), macro_id=macro_id),\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_content(self, cql_str=None, cql_context=None, expand=None, start=0, limit=None, callback=None):\n        params = {}\n        if cql_str:\n            params[\"cql\"] = cql_str\n        if cql_context:\n            params[\"cqlcontext\"] = json.dumps(cql_context)\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content/search\", params=params, callback=callback)", "response": "Search for content using the CQL query string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a map of direct children of a piece of Content.", "response": "def get_content_children(self, content_id, expand=None, parent_version=None, callback=None):\n        \"\"\"\n        Returns a map of the direct children of a piece of Content. Content can have multiple types of children -\n        for example a Page can have children that are also Pages, but it can also have Comments and Attachments.\n\n        The {@link ContentType}(s) of the children returned is specified by the \"expand\" query parameter in the request\n        - this parameter can include expands for multiple child types.\n        If no types are included in the expand parameter, the map returned will just list the child types that\n        are available to be expanded for the {@link Content} referenced by the \"content_id\" parameter.\n        :param content_id (string): A string containing the id of the content to retrieve children for.\n        :param expand (string): OPTIONAL :A comma separated list of properties to expand on the children.\n                                Default: None.\n        :param parent_version (int): OPTIONAL: An integer representing the version of the content to retrieve\n                                     children for. Default: 0 (Latest)\n\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/child endpoint, or the results of the callback.\n                 Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if parent_version:\n            params[\"parentVersion\"] = parent_version\n        return self._service_get_request(\"rest/api/content/{id}/child\".format(id=content_id), params=params,\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_content_descendants(self, content_id, expand=None, callback=None):\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        return self._service_get_request(\"rest/api/content/{id}/descendant\".format(id=content_id), params=params,\n                                         callback=callback)", "response": "Get the descendants of a piece of Content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_content_descendants_by_type(self, content_id, child_type, expand=None, start=None, limit=None,\n                                        callback=None):\n        \"\"\"\n        Returns the direct descendants of a piece of Content, limited to a single descendant type.\n\n        The {@link ContentType}(s) of the descendants returned is specified by the \"type\" path parameter in the request.\n\n        Currently the only supported descendants are comment descendants of non-comment Content.\n        :param content_id (string): A string containing the id of the content to retrieve descendants for\n        :param child_type (string): A {@link ContentType} to filter descendants on.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the descendants.\n                                Default: Empty\n        :param start (int): OPTIONAL: The index of the first item within the result set that should be returned.\n                            Default: 0.\n        :param limit (int): OPTIONAL: How many items should be returned after the start index.\n                            Default: 25 or site limit.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/descendant/{type} endpoint, or the results of the\n                 callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content/{id}/descendant/{type}\"\n                                         \"\".format(id=content_id, type=child_type), params=params, callback=callback)", "response": "Get the direct descendants of a piece of Content limited to a single descendant type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the list of labels on a piece of Content.", "response": "def get_content_labels(self, content_id, prefix=None, start=None, limit=None, callback=None):\n        \"\"\"\n        Returns the list of labels on a piece of Content.\n        :param content_id (string): A string containing the id of the labels content container.\n        :param prefix (string): OPTIONAL: The prefixes to filter the labels with {@see Label.Prefix}.\n                                Default: None.\n        :param start (int): OPTIONAL: The start point of the collection to return. Default: None (0).\n        :param limit (int): OPTIONAL: The limit of the number of labels to return, this may be restricted by\n                            fixed system limits. Default: 200.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/label endpoint, or the results of the\n                 callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if prefix:\n            params[\"prefix\"] = prefix\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content/{id}/label\".format(id=content_id), params=params,\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_content_comments(self, content_id, expand=None, parent_version=None, start=None, limit=None,\n                             location=None, depth=None, callback=None):\n        \"\"\"\n        Returns the comments associated with a piece of content.\n        :param content_id (string): A string containing the id of the content to retrieve children for.\n        :param expand (string): OPTIONAL: a comma separated list of properties to expand on the children.\n                                We can also specify some extensions such as extensions.inlineProperties (for getting\n                                inline comment-specific properties) or extensions.resolution for the resolution status\n                                of each comment in the results. Default: Empty\n        :param parent_version (int): OPTIONAL: An int representing the version of the content to retrieve children for.\n                                     Default: 0\n        :param start (int): OPTIONAL: The index of the first item within the result set that should be returned.\n                            Default: 0.\n        :param limit (int): OPTIONAL: How many items should be returned after the start index. Default: Site limit.\n        :param location (string): OPTIONAL: The location of the comments. Possible values are: \"inline\", \"footer\",\n                                  \"resolved\". You can define multiple location params. The results will be the comments\n                                  matched by any location. Default: \"\" (all).\n        :param depth: The depth of the comments. Possible values are: \"\" (ROOT only), \"all\". Default: \"\".\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/child/comment endpoint, or the results of the\n                 callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if parent_version:\n            params[\"parentVersion\"] = parent_version\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        if location:\n            params[\"location\"] = location\n        if depth:\n            assert depth in {\"\", \"all\"}\n            params[\"depth\"] = depth\n        return self._service_get_request(\"rest/api/content/{id}/child/comment\".format(id=content_id),\n                                         params=params, callback=callback)", "response": "Returns the comments associated with a piece of content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_content_attachments(self, content_id, expand=None, start=None, limit=None, filename=None, media_type=None,\n                                callback=None):\n        \"\"\"\n        Returns a paginated list of attachment Content entities within a single container.\n        :param content_id (string): A string containing the id of the attachments content container.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the Attachments returned.\n                                Default: Empty.\n        :param start (int): OPTIONAL: The index of the first item within the result set that should be returned.\n                            Default: None (0).\n        :param limit (int): OPTIONAL: How many items should be returned after the start index. Default: 50\n        :param filename (string): OPTIONAL: A filter parameter to return only the Attachment with the matching file\n                                  name. Default: None.\n        :param media_type: OPTIONAL: A filter parameter to return only Attachments with a matching Media-Type.\n                           Default: None.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/child/attachment endpoint, or the results of the\n                 callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        if filename is not None:\n            params[\"filename\"] = filename\n        if media_type is not None:\n            params[\"mediaType\"] = media_type\n        return self._service_get_request(\"rest/api/content/{id}/child/attachment\".format(id=content_id),\n                                         params=params, callback=callback)", "response": "Returns a paginated list of attachment Content entities within a single container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_content_properties(self, content_id, expand=None, start=None, limit=None, callback=None):\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content/{id}/property\".format(id=content_id),\n                                         params=params, callback=callback)", "response": "Returns a paginated list of content properties attached to a piece of Content."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a content property by its key.", "response": "def get_content_property_by_key(self, content_id, property_key, expand=None, callback=None):\n        \"\"\"\n        Returns a content property.\n        :param content_id (string): A string containing the id of the property content container.\n        :param property_key (string): The key associated with the property requested.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the content properties.\n                                Default value: \"version\"\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/property/{key} endpoint, or the results of the\n                 callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        return self._service_get_request(\"rest/api/content/{id}/property/{key}\".format(id=content_id, key=property_key),\n                                         params=params, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_op_restrictions_by_content_operation(self, content_id, operation_key, expand=None, start=None, limit=None,\n                                                 callback=None):\n        \"\"\"\n        Returns info about all restrictions of given operation.\n        :param content_id (string): The content ID to query on.\n        :param operation_key (string): The operation key to query on.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the content properties.\n                                Default: Again, this is unclear/inconsistent when reading documentation. The REST\n                                    documentation claims that both are default:\n                                        \"group\"\n                                        \"restrictions.user,restrictions.group\"\n        :param start (int): Pagination start count.\n        :param limit (int): Pagination return count limit.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/restriction/byOperation/{operationKey} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/content/{id}/restriction/byOperation/{opkey}\"\n                                         \"\".format(id=content_id, opkey=operation_key),\n                                         params=params, callback=callback)", "response": "Get all restrictions of a given content operation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns information about all tracked long - running tasks.", "response": "def get_long_tasks(self, expand=None, start=None, limit=None, callback=None):\n        \"\"\"\n        Returns information about all tracked long-running tasks.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the tasks.\n        :param start (int): OPTIONAL: The pagination start count.\n        :param limit (int): OPTIONAL: The pagination return count limit.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the longtask endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/longtask\", params=params, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning information about a long - running task.", "response": "def get_long_task_info(self, long_task_id, expand=None, callback=None):\n        \"\"\"\n        Returns information about a long-running task.\n        :param long_task_id (string): The key of the task to be returned.\n        :param expand (string): A comma separated list of properties to expand on the task. Default: Empty\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the longtask/{id} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        return self._service_get_request(\"rest/api/longtask/{id}\".format(id=long_task_id), params=params,\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_spaces(self, space_key=None, expand=None, start=None, limit=None, callback=None):\n        params = {}\n        if space_key:\n            params[\"spaceKey\"] = space_key\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/space\", params=params, callback=callback)", "response": "Returns information about the spaces present in the Confluence instance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning information about a specific resource in a space.", "response": "def get_space_information(self, space_key, expand=None, callback=None):\n        \"\"\"\n        Returns information about a space.\n        :param space_key (string): A string containing the key of the space.\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on the space. Default: Empty.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the space/{spaceKey} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if expand:\n            params[\"expand\"] = expand\n        return self._service_get_request(\"rest/api/space/{key}\".format(key=space_key),\n                                         params=params, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the content in this given space.", "response": "def get_space_content(self, space_key, depth=None, expand=None, start=None, limit=None, callback=None):\n        \"\"\"\n        Returns the content in this given space.\n        :param space_key (string): A string containing the key of the space.\n        :param depth (string): OPTIONAL: A string indicating if all content, or just the root content of the space is\n                               returned. Default: \"all\". Valid values: \"all\", \"root\".\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on each piece of content\n                                retrieved. Default: Empty.\n        :param start (int): OPTIONAL: The start point of the collection to return. Default: 0.\n        :param limit (int): OPTIONAL: The limit of the number of labels to return, this may be restricted by fixed\n                            system limits. Default: 25.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the space/{spaceKey}/content endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if depth:\n            assert depth in {\"all\", \"root\"}\n            params[\"depth\"] = depth\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/space/{key}/content\".format(key=space_key),\n                                         params=params, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the content in this given space with the given type.", "response": "def get_space_content_by_type(self, space_key, content_type, depth=None, expand=None, start=None, limit=None,\n                                  callback=None):\n        \"\"\"\n        Returns the content in this given space with the given type.\n        :param space_key (string): A string containing the key of the space.\n        :param content_type (string): The type of content to return with the space. Valid values: \"page\", \"blogpost\".\n        :param depth (string): OPTIONAL: A string indicating if all content, or just the root content of the space is\n                               returned. Default: \"all\". Valid values: \"all\", \"root\".\n        :param expand (string): OPTIONAL: A comma separated list of properties to expand on each piece of content\n                                retrieved. Default: Empty.\n        :param start (int): OPTIONAL: The start point of the collection to return. Default: 0.\n        :param limit (int): OPTIONAL: The limit of the number of labels to return, this may be restricted by fixed\n                            system limits. Default: 25.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the space/{spaceKey}/content/{type} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        assert content_type in [\"page\", \"blogpost\"]\n        params = {}\n        if depth:\n            assert depth in {\"all\", \"root\"}\n            params[\"depth\"] = depth\n        if expand:\n            params[\"expand\"] = expand\n        if start is not None:\n            params[\"start\"] = int(start)\n        if limit is not None:\n            params[\"limit\"] = int(limit)\n        return self._service_get_request(\"rest/api/space/{key}/content/{type}\".format(key=space_key, type=content_type),\n                                         params=params, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new piece of Content.", "response": "def create_new_content(self, content_data, callback=None):\n        \"\"\"\n        Creates a new piece of Content.\n        :param content_data (dict): A dictionary representing the data for the new content. Must have keys:\n                                    \"type\", \"title\", \"space\", \"body\".\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n\n        Example content_data:\n            {\n                \"type\": \"page\",\n                \"title\": \"Example Content title\",\n                \"space\": {\n                    \"key\": \"TST\"\n                },\n                \"body\": {\n                    \"storage\": {\n                        \"value\": \"<p>This is a new page</p>\",\n                        \"representation\": \"storage\"\n                    }\n                }\n            }\n        \"\"\"\n        assert isinstance(content_data, dict) and set(content_data.keys()) >= self.NEW_CONTENT_REQUIRED_KEYS\n        return self._service_post_request(\"rest/api/content\", data=json.dumps(content_data),\n                                          headers={\"Content-Type\": \"application/json\"}, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd one or more attachments to a Confluence Content entity.", "response": "def create_new_attachment_by_content_id(self, content_id, attachments, callback=None):\n        \"\"\"\n        Add one or more attachments to a Confluence Content entity, with optional comments.\n\n        Comments are optional, but if included there must be as many comments as there are files, and the comments must\n        be in the same order as the files.\n        :param content_id (string): A string containing the id of the attachments content container.\n        :param attachments (list of dicts or dict): This is a list of dictionaries or a dictionary.\n                                                    Each dictionary must have the key\n                                                    \"file\" with a value that is I/O like (file, StringIO, etc.), and\n                                                    may also have a key \"comment\" with a string for file comments.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/child/attachment endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        if isinstance(attachments, list):\n            assert all(isinstance(at, dict) and \"file\" in list(at.keys()) for at in attachments)\n        elif isinstance(attachments, dict):\n            assert \"file\" in list(attachments.keys())\n        else:\n            assert False\n        return self._service_post_request(\"rest/api/content/{id}/child/attachment\".format(id=content_id),\n                                          headers={\"X-Atlassian-Token\": \"nocheck\"}, files=attachments,\n                                          callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a list of labels to the specified content.", "response": "def create_new_label_by_content_id(self, content_id, label_names, callback=None):\n        \"\"\"\n        Adds a list of labels to the specified content.\n        :param content_id (string): A string containing the id of the labels content container.\n        :param label_names (list): A list of labels (strings) to apply to the content.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/label endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        assert isinstance(label_names, list)\n        assert all(isinstance(ln, dict) and set(ln.keys()) == {\"prefix\", \"name\"} for ln in label_names)\n        return self._service_post_request(\"rest/api/content/{id}/label\".format(id=content_id),\n                                         data=json.dumps(label_names), headers={\"Content-Type\": \"application/json\"},\n                                         callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_new_content_property(self, content_id, content_property, callback=None):\n        assert isinstance(content_property, dict)\n        assert {\"key\", \"value\"} <= set(content_property.keys())\n        return self._service_post_request(\"rest/api/content/{id}/property\".format(id=content_id),\n                                          data=json.dumps(content_property),\n                                          headers={\"Content-Type\": \"application/json\"}, callback=callback)", "response": "Create a new content property. Potentially a duplicate at the REST API level of the content_id create_new_property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_new_space(self, space_definition, callback=None):\n        assert isinstance(space_definition, dict) and {\"key\", \"name\", \"description\"} <= set(space_definition.keys())\n        return self._service_post_request(\"rest/api/space\", data=json.dumps(space_definition),\n                                          headers={\"Content-Type\": \"application/json\"}, callback=callback)", "response": "Creates a new space."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_content_by_id(self, content_data, content_id, callback=None):\n        assert isinstance(content_data, dict) and set(content_data.keys()) >= self.UPDATE_CONTENT_REQUIRED_KEYS\n        return self._service_put_request(\"rest/api/content/{id}\".format(id=content_id), data=json.dumps(content_data),\n                                         headers={\"Content-Type\": \"application/json\"}, callback=callback)", "response": "Updates a piece of Content by the id."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_attachment_metadata(self, content_id, attachment_id, new_metadata, callback=None):\n        assert isinstance(new_metadata, dict) and set(new_metadata.keys()) >= self.ATTACHMENT_METADATA_KEYS\n        return self._service_put_request(\"rest/api/content/{id}/child/attachment/{attachment_id}\"\n                                         \"\".format(id=content_id, attachment_id=attachment_id),\n                                         data=json.dumps(new_metadata), headers={\"Content-Type\": \"application/json\"},\n                                         callback=callback)", "response": "Update the metadata for an attachment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_attachment(self, content_id, attachment_id, attachment, callback=None):\n        if isinstance(attachment, dict):\n            assert \"file\" in list(attachment.keys())\n        else:\n            assert False\n        return self._service_post_request(\"rest/api/content/{content_id}/child/attachment/{attachment_id}/data\"\n                                          \"\".format(content_id=content_id, attachment_id=attachment_id),\n                                          headers={\"X-Atlassian-Token\": \"nocheck\"}, files=attachment,\n                                          callback=callback)", "response": "Update the binary data of an attachment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating a content property.", "response": "def update_property(self, content_id, property_key, new_property_data, callback=None):\n        \"\"\"\n        Updates a content property.\n\n        The body contains the representation of the content property. Must include the property id, and the new version\n        number. Attempts to create a new content property if the given version number is 1, just like\n        {@link #create(com.atlassian.confluence.api.model.content.id.ContentId, String,\n            com.atlassian.confluence.api.model.content.JsonContentProperty)}.\n        :param content_id (string): The ID for the content to attach the property to.\n        :param property_key (string): The key for the property to update.\n        :param new_property_data (dict): The updated property data. This requires the keys \"key\", \"value\", and\n                                         \"version\".\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id}/property/{key} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n\n        Example updated property data:\n        {\n            \"key\": \"example-property-key\",\n            \"value\": {\n                \"anything\": \"goes\"\n            },\n            \"version\": {\n                \"number\": 2,\n                \"minorEdit\": false\n            }\n        }\n        \"\"\"\n        assert isinstance(new_property_data, dict) and {\"key\", \"value\", \"version\"} <= set(new_property_data.keys())\n        return self._service_put_request(\"rest/api/content/{id}/property/{key}\".format(id=content_id, key=property_key),\n                                         data=json.dumps(new_property_data),\n                                         headers={\"Content-Type\": \"application/json\"}, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate a Space s metadata.", "response": "def update_space(self, space_key, space_definition, callback=None):\n        \"\"\"\n        Updates a Space.\n\n        Currently only the Space name, description and homepage can be updated.\n        :param space_key (string): The key of the space to update.\n        :param space_definition (dict): The dictionary describing the updated space metadata. This should include\n                                        \"key\", \"name\" and \"description\".\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the space/{key} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n\n        Example updated space definition:\n        {\n            \"key\": \"TST\",\n            \"name\": \"Example space\",\n            \"description\": {\n                \"plain\": {\n                    \"value\": \"This is an example space\",\n                    \"representation\": \"plain\"\n                }\n            }\n        }\n        \"\"\"\n        assert isinstance(space_definition, dict) and {\"key\", \"name\", \"description\"} <= set(space_definition.keys())\n        return self._service_put_request(\"rest/api/space/{key}\".format(key=space_key),\n                                         data=json.dumps(space_definition),\n                                         headers={\"Content-Type\": \"application/json\"}, callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_contentbody_to_new_type(self, content_data, old_representation, new_representation, callback=None):\n        assert {old_representation, new_representation} < {\"storage\", \"editor\", \"view\", \"export_view\"}\n        # TODO: Enforce conversion rules better here.\n        request_data = {\"value\": str(content_data), \"representation\": old_representation}\n        return self._service_post_request(\"rest/api/contentbody/convert/{to}\".format(to=new_representation),\n                                          data=json.dumps(request_data),\n                                          headers={\"Content-Type\": \"application/json\"}, callback=callback)", "response": "Converts the content body to the new type."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a piece of Content based on its ID and status.", "response": "def delete_content_by_id(self, content_id, status=None, callback=None):\n        \"\"\"\n        Trashes or purges a piece of Content, based on its {@link ContentType} and {@link ContentStatus}.\n        :param content_id (string): The ID for the content to remove.\n        :param status (string): OPTIONAL: A status code to query for the location (?) of the content.\n                                The REST API suggests you might use \"trashed\". Default: Empty.\n        :param callback: OPTIONAL: The callback to execute on the resulting data, before the method returns.\n                         Default: None (no callback, raw data returned).\n        :return: The JSON data returned from the content/{id} endpoint,\n                 or the results of the callback. Will raise requests.HTTPError on bad input, potentially.\n        \"\"\"\n        params = {}\n        if status:\n            params[\"status\"] = status\n        return self._service_delete_request(\"rest/api/content/{id}\".format(id=content_id), params=params,\n                                            callback=callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_label_by_id(self, content_id, label_name, callback=None):\n        params = {\"name\": label_name}\n        return self._service_delete_request(\"rest/api/content/{id}/label\".format(id=content_id),\n                                            params=params, callback=callback)", "response": "Delete a label from the specified content."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_property(self, content_id, property_key, callback=None):\n        return self._service_delete_request(\"rest/api/content/{id}/property/{key}\"\n                                            \"\".format(id=content_id, key=property_key), callback=callback)", "response": "Delete a content property."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_space(self, space_key, callback=None):\n        return self._service_delete_request(\"rest/api/space/{key}\".format(key=space_key),\n                                            callback=callback)", "response": "Delete a space in a long running task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a sensor warning if it exists.", "response": "def add(self, sensor):\n        \"\"\"Add a sensor, warning if it exists.\"\"\"\n        if isinstance(sensor, (list, tuple)):\n            for sss in sensor:\n                self.add(sss)\n            return\n\n        if not isinstance(sensor, Sensor):\n            raise TypeError(\"pysma.Sensor expected\")\n\n        if sensor.name in self:\n            old = self[sensor.name]\n            self.__s.remove(old)\n            _LOGGER.warning(\"Replacing sensor %s with %s\", old, sensor)\n\n        if sensor.key in self:\n            _LOGGER.warning(\"Duplicate SMA sensor key %s\", sensor.key)\n\n        self.__s.append(sensor)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch json data for requests.", "response": "def _fetch_json(self, url, payload):\n        \"\"\"Fetch json data for requests.\"\"\"\n        params = {\n            'data': json.dumps(payload),\n            'headers': {'content-type': 'application/json'},\n            'params': {'sid': self.sma_sid} if self.sma_sid else None,\n        }\n        for _ in range(3):\n            try:\n                with async_timeout.timeout(3):\n                    res = yield from self._aio_session.post(\n                        self._url + url, **params)\n                    return (yield from res.json()) or {}\n            except asyncio.TimeoutError:\n                continue\n        return {'err': \"Could not connect to SMA at {} (timeout)\"\n                       .format(self._url)}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nestablish a new session.", "response": "def new_session(self):\n        \"\"\"Establish a new session.\"\"\"\n        body = yield from self._fetch_json(URL_LOGIN, self._new_session_data)\n        self.sma_sid = jmespath.search('result.sid', body)\n        if self.sma_sid:\n            return True\n\n        msg = 'Could not start session, %s, got {}'.format(body)\n\n        if body.get('err'):\n            if body.get('err') == 503:\n                _LOGGER.error(\"Max amount of sessions reached\")\n            else:\n                _LOGGER.error(msg, body.get('err'))\n        else:\n            _LOGGER.error(msg, \"Session ID expected [result.sid]\")\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a set of keys.", "response": "def read(self, sensors):\n        \"\"\"Read a set of keys.\"\"\"\n        payload = {'destDev': [], 'keys': list(set([s.key for s in sensors]))}\n        if self.sma_sid is None:\n            yield from self.new_session()\n            if self.sma_sid is None:\n                return False\n        body = yield from self._fetch_json(URL_VALUES, payload=payload)\n\n        # On the first 401 error we close the session which will re-login\n        if body.get('err') == 401:\n            _LOGGER.warning(\"401 error detected, closing session to force \"\n                            \"another login attempt\")\n            self.close_session()\n            return False\n\n        _LOGGER.debug(json.dumps(body))\n        for sen in sensors:\n            if sen.extract_value(body):\n                _LOGGER.debug(\"%s\\t= %s %s\",\n                              sen.name, sen.value, sen.unit)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\niterating the GLib main loop and process the task queue and media queue.", "response": "def run(self):\n        \"\"\"Run the process.\n\n        Iterate the GLib main loop and process the task queue.\n        \"\"\"\n        loop = GLib.MainLoop()\n        context = loop.get_context()\n        while True:\n            time.sleep(0.1)\n            if context.pending():\n                context.iteration()\n                self._manager[ATTR_POSITION] = self._position()\n            try:\n                method, args = self._task_queue.get(False)\n                getattr(self, method)(**args)\n            except queue.Empty:\n                pass\n            if self.state != STATE_IDLE:\n                continue\n            try:\n                uri = self._media_queue.get(False)\n                self.media(uri)\n            except queue.Empty:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nplay a media file.", "response": "def media(self, uri):\n        \"\"\"Play a media file.\"\"\"\n        try:\n            local_path, _ = urllib.request.urlretrieve(uri)\n            metadata = mutagen.File(local_path, easy=True)\n            if metadata.tags:\n                self._tags = metadata.tags\n            title = self._tags.get(TAG_TITLE, [])\n            self._manager[ATTR_TITLE] = title[0] if len(title) else ''\n            artist = self._tags.get(TAG_ARTIST, [])\n            self._manager[ATTR_ARTIST] = artist[0] if len(artist) else ''\n            album = self._tags.get(TAG_ALBUM, [])\n            self._manager[ATTR_ALBUM] = album[0] if len(album) else ''\n            local_uri = 'file://{}'.format(local_path)\n\n        # urllib.error.HTTPError\n        except Exception:  # pylint: disable=broad-except\n            local_uri = uri\n        self._player.set_state(Gst.State.NULL)\n        self._player.set_property(PROP_URI, local_uri)\n        self._player.set_state(Gst.State.PLAYING)\n        self.state = STATE_PLAYING\n        self._manager[ATTR_URI] = uri\n        self._manager[ATTR_DURATION] = self._duration()\n        self._manager[ATTR_VOLUME] = self._player.get_property(PROP_VOLUME)\n        _LOGGER.info('playing %s (as %s)', uri, local_uri)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef play(self):\n        if self.state == STATE_PAUSED:\n            self._player.set_state(Gst.State.PLAYING)\n            self.state = STATE_PLAYING", "response": "Change state to playing."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pause(self):\n        if self.state == STATE_PLAYING:\n            self._player.set_state(Gst.State.PAUSED)\n            self.state = STATE_PAUSED", "response": "Change state to paused."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the current volume.", "response": "def set_volume(self, volume):\n        \"\"\"Set volume.\"\"\"\n        self._player.set_property(PROP_VOLUME, volume)\n        self._manager[ATTR_VOLUME] = volume\n        _LOGGER.info('volume set to %.2f', volume)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets state of the cache manager.", "response": "def state(self, state):\n        \"\"\"Set state.\"\"\"\n        self._state = state\n        self._manager[ATTR_STATE] = state\n        _LOGGER.info('state changed to %s', state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _on_message(self, bus, message):  # pylint: disable=unused-argument\n        if message.type == Gst.MessageType.EOS:\n            self.stop()\n        elif message.type == Gst.MessageType.ERROR:\n            self.stop()\n            err, _ = message.parse_error()\n            _LOGGER.error('%s', err)", "response": "When a message is received from Gstreamer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the previous node.", "response": "def get_previous_node(node):\n    \"\"\"\n    Return the node before this node.\n    \"\"\"\n    if node.prev_sibling:\n        return node.prev_sibling\n    if node.parent:\n        return get_previous_node(node.parent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef casperjs_command_kwargs():\n    kwargs = {\n        'stdout': subprocess.PIPE,\n        'stderr': subprocess.PIPE,\n        'universal_newlines': True\n    }\n    phantom_js_cmd = app_settings['PHANTOMJS_CMD']\n    if phantom_js_cmd:\n        path = '{0}:{1}'.format(\n            os.getenv('PATH', ''), os.path.dirname(phantom_js_cmd)\n        )\n        kwargs.update({'env': {'PATH': path}})\n    return kwargs", "response": "will construct kwargs for cmd\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the command to use for the capture engine.", "response": "def casperjs_command():\n    \"\"\"\n    Determine which capture engine is specified. Possible options:\n    - casperjs\n    - phantomjs\n    Based on this value, locate the binary of the capture engine.\n\n    If setting <engine>_CMD is not defined, then\n    look up for ``<engine>`` in shell PATH and\n    build the whole capture command.\n    \"\"\"\n    method = app_settings['CAPTURE_METHOD']\n    cmd = app_settings['%s_CMD' % method.upper()]\n    sys_path = os.getenv('PATH', '').split(':')\n    if cmd is None:\n        for binpath in sys_path:\n            cmd = os.path.join(binpath, method)\n            if os.path.exists(cmd):\n                break\n    cmd = [cmd]\n\n    if app_settings['TEST_CAPTURE_SCRIPT']:\n        try:\n            proc = subprocess.Popen(cmd + ['--version'], **casperjs_command_kwargs())\n            proc.communicate()\n            status = proc.returncode\n            assert status == 0\n        except OSError:\n            msg = \"%s binary cannot be found in PATH (%s)\" % (method, sys_path)\n            raise ImproperlyConfigured(msg)\n        except AssertionError:\n            msg = \"%s returned status code %s\" % (method, status)\n            raise ImproperlyConfigured(msg)\n\n    # Add extra CLI arguments\n    cmd += app_settings['CLI_ARGS']\n\n    # Concatenate with capture script\n    app_path = os.path.dirname(__file__)\n\n    capture = app_settings['CAPTURE_SCRIPT']\n    if capture.startswith('./'):\n        capture = os.path.join(app_path, 'scripts', capture)\n\n    assert os.path.exists(capture), 'Cannot find %s' % capture\n    return cmd + [capture]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef casperjs_capture(stream, url, method=None, width=None, height=None,\n                     selector=None, data=None, waitfor=None, size=None,\n                     crop=None, render='png', wait=None):\n    \"\"\"\n    Captures web pages using ``casperjs``\n    \"\"\"\n    if isinstance(stream, six.string_types):\n        output = stream\n    else:\n        with NamedTemporaryFile('wb+', suffix='.%s' % render, delete=False) as f:\n            output = f.name\n    try:\n        cmd = CASPERJS_CMD + [url, output]\n\n        # Extra command-line options\n        cmd += ['--format=%s' % render]\n        if method:\n            cmd += ['--method=%s' % method]\n        if width:\n            cmd += ['--width=%s' % width]\n        if height:\n            cmd += ['--height=%s' % height]\n        if selector:\n            cmd += ['--selector=%s' % selector]\n        if data:\n            cmd += ['--data=\"%s\"' % json.dumps(data)]\n        if waitfor:\n            cmd += ['--waitfor=%s' % waitfor]\n        if wait:\n            cmd += ['--wait=%s' % wait]\n        logger.debug(cmd)\n        # Run CasperJS process\n        proc = subprocess.Popen(cmd, **casperjs_command_kwargs())\n        stdout = proc.communicate()[0]\n        process_casperjs_stdout(stdout)\n\n        size = parse_size(size)\n        render = parse_render(render)\n\n        if size or (render and render != 'png' and render != 'pdf'):\n            # pdf isn't an image, therefore we can't postprocess it.\n            image_postprocess(output, stream, size, crop, render)\n        else:\n            if stream != output:\n                # From file to stream\n                with open(output, 'rb') as out:\n                    stream.write(out.read())\n                stream.flush()\n    finally:\n        if stream != output:\n            os.unlink(output)", "response": "Capture web page using CasperJS."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef process_casperjs_stdout(stdout):\n    for line in stdout.splitlines():\n        bits = line.split(':', 1)\n        if len(bits) < 2:\n            bits = ('INFO', bits)\n        level, msg = bits\n\n        if level == 'FATAL':\n            logger.fatal(msg)\n            raise CaptureError(msg)\n        elif level == 'ERROR':\n            logger.error(msg)\n        else:\n            logger.info(msg)", "response": "Parse and digest capture script output."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses url URL parameter.", "response": "def parse_url(request, url):\n    \"\"\"Parse url URL parameter.\"\"\"\n    try:\n        validate = URLValidator()\n        validate(url)\n    except ValidationError:\n        if url.startswith('/'):\n            host = request.get_host()\n            scheme = 'https' if request.is_secure() else 'http'\n            url = '{scheme}://{host}{uri}'.format(scheme=scheme,\n                                                  host=host,\n                                                  uri=url)\n        else:\n            url = request.build_absolute_uri(reverse(url))\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_render(render):\n    formats = {\n        'jpeg': guess_all_extensions('image/jpeg'),\n        'png': guess_all_extensions('image/png'),\n        'gif': guess_all_extensions('image/gif'),\n        'bmp': guess_all_extensions('image/x-ms-bmp'),\n        'tiff': guess_all_extensions('image/tiff'),\n        'xbm': guess_all_extensions('image/x-xbitmap'),\n        'pdf': guess_all_extensions('application/pdf')\n    }\n    if not render:\n        render = 'png'\n    else:\n        render = render.lower()\n        for k, v in formats.items():\n            if '.%s' % render in v:\n                render = k\n                break\n        else:\n            render = 'png'\n    return render", "response": "Parse render URL parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses size URL parameter. >>> parse_size((100,None)) None >>> parse_size('300x100') (300, 100) >>> parse_size('300x') None >>> parse_size('x100') None >>> parse_size('x') None", "response": "def parse_size(size_raw):\n    \"\"\" Parse size URL parameter.\n\n    >>> parse_size((100,None))\n    None\n    >>> parse_size('300x100')\n    (300, 100)\n    >>> parse_size('300x')\n    None\n    >>> parse_size('x100')\n    None\n    >>> parse_size('x')\n    None\n    \"\"\"\n    try:\n        width_str, height_str = size_raw.lower().split('x')\n    except AttributeError:\n        size = None\n    except ValueError:\n        size = None\n    else:\n        try:\n            width = int(width_str)\n            assert width > 0\n        except (ValueError, AssertionError):\n            width = None\n        try:\n            height = int(height_str)\n            assert height > 0\n        except (ValueError, AssertionError):\n            height = None\n        size = width, height\n        if not all(size):\n            size = None\n    return size"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef build_absolute_uri(request, url):\n    if app_settings.get('CAPTURE_ROOT_URL'):\n        return urljoin(app_settings.get('CAPTURE_ROOT_URL'), url)\n    return request.build_absolute_uri(url)", "response": "Build an absolute URI for the given url."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrendering a template from django project and return the file object of the result.", "response": "def render_template(template_name, context, format='png',\n                    output=None, using=None, **options):\n    \"\"\"\n    Render a template from django project, and return the\n    file object of the result.\n    \"\"\"\n    # output stream, as required by casperjs_capture\n    stream = BytesIO()\n    out_f = None\n    # the suffix=.html is a hack for phantomjs which *will*\n    # complain about not being able to open source file\n    # unless it has a 'html' extension.\n    with NamedTemporaryFile(suffix='.html') as render_file:\n        template_content = render_to_string(\n            template_name,\n            context,\n            using=using,\n        )\n        # now, we need to replace all occurences of STATIC_URL\n        # with the corresponding file://STATIC_ROOT, but only\n        # if STATIC_URL doesn't contain a public URI (like http(s))\n        static_url = getattr(settings, 'STATIC_URL', '')\n        if settings.STATIC_ROOT and\\\n           static_url and not static_url.startswith('http'):\n            template_content = template_content.replace(\n                static_url,\n                'file://%s' % settings.STATIC_ROOT\n            )\n        render_file.write(template_content.encode('utf-8'))\n        # this is so that the temporary file actually gets filled\n        # with the result.\n        render_file.seek(0)\n\n        casperjs_capture(\n            stream,\n            url='file://%s' % render_file.name,\n            **options\n        )\n\n        # if no output was provided, use NamedTemporaryFile\n        # (so it is an actual file) and return it (so that\n        # after function ends, it gets automatically removed)\n        if not output:\n            out_f = NamedTemporaryFile()\n        else:\n            # if output was provided, write the rendered\n            # content to it\n            out_f = open(output, 'wb')\n        out_f.write(stream.getvalue())\n        out_f.seek(0)\n\n        # return the output if NamedTemporaryFile was used\n        if not output:\n            return out_f\n        else:\n            # otherwise, just close the file.\n            out_f.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef go(fn, *args, **kwargs):\n    if not callable(fn):\n        raise TypeError('go() requires a function, not %r' % (fn,))\n    result = [None]\n    error = []\n\n    def target():\n        try:\n            result[0] = fn(*args, **kwargs)\n        except Exception:\n            # Are we in interpreter shutdown?\n            if sys:\n                error.extend(sys.exc_info())\n\n    t = threading.Thread(target=target)\n    t.daemon = True\n    t.start()\n\n    def get_result(timeout=10):\n        t.join(timeout)\n        if t.is_alive():\n            raise AssertionError('timed out waiting for %r' % fn)\n        if error:\n            reraise(*error)\n        return result[0]\n\n    return get_result", "response": "Launch an operation on a thread and get a handle to its future result."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlaunches a thread and wait for its result before exiting the code block. >>> with going(lambda: 'return value') as future: ... pass >>> future() # Won't block, the future is ready by now. 'return value' Or discard the result: >>> with going(lambda: \"don't care\"): ... pass If an exception is raised within the context, the result is lost: >>> with going(lambda: 'return value') as future: ... assert 1 == 0 Traceback (most recent call last): ... AssertionError", "response": "def going(fn, *args, **kwargs):\n    \"\"\"Launch a thread and wait for its result before exiting the code block.\n\n    >>> with going(lambda: 'return value') as future:\n    ...    pass\n    >>> future()  # Won't block, the future is ready by now.\n    'return value'\n\n    Or discard the result:\n\n    >>> with going(lambda: \"don't care\"):\n    ...    pass\n\n\n    If an exception is raised within the context, the result is lost:\n\n    >>> with going(lambda: 'return value') as future:\n    ...    assert 1 == 0\n    Traceback (most recent call last):\n    ...\n    AssertionError\n    \"\"\"\n    future = go(fn, *args, **kwargs)\n    try:\n        yield future\n    except:\n        # We are raising an exception, just try to clean up the future.\n        exc_info = sys.exc_info()\n        try:\n            # Shorter than normal timeout.\n            future(timeout=1)\n        except:\n            log_message = ('\\nerror in %s:\\n'\n                           % format_call(inspect.currentframe()))\n            sys.stderr.write(log_message)\n            traceback.print_exc()\n            # sys.stderr.write('exc in %s' % format_call(inspect.currentframe()))\n        reraise(*exc_info)\n    else:\n        # Raise exception or discard result.\n        future(timeout=10)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwaiting up to timeout seconds for predicate to be true.", "response": "def wait_until(predicate, success_description, timeout=10):\n    \"\"\"Wait up to 10 seconds (by default) for predicate to be true.\n\n    E.g.:\n\n        wait_until(lambda: client.primary == ('a', 1),\n                   'connect to the primary')\n\n    If the lambda-expression isn't true after 10 seconds, we raise\n    AssertionError(\"Didn't ever connect to the primary\").\n\n    Returns the predicate's first true value.\n    \"\"\"\n    start = time.time()\n    while True:\n        retval = predicate()\n        if retval:\n            return retval\n\n        if time.time() - start > timeout:\n            raise AssertionError(\"Didn't ever %s\" % success_description)\n\n        time.sleep(0.1)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndecoding a BSON C string to python unicode string.", "response": "def _get_c_string(data, position):\n    \"\"\"Decode a BSON 'C' string to python unicode string.\"\"\"\n    end = data.index(b\"\\x00\", position)\n    return _utf_8_decode(data[position:end], None, True)[0], end + 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling method while holding a lock.", "response": "def _synchronized(meth):\n    \"\"\"Call method while holding a lock.\"\"\"\n\n    @functools.wraps(meth)\n    def wrapper(self, *args, **kwargs):\n        with self._lock:\n            return meth(self, *args, **kwargs)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbinding a TCP socket to a given address.", "response": "def bind_tcp_socket(address):\n    \"\"\"Takes (host, port) and returns (socket_object, (host, port)).\n\n    If the passed-in port is None, bind an unused port and return it.\n    \"\"\"\n    host, port = address\n    for res in set(socket.getaddrinfo(host, port, socket.AF_INET,\n                                      socket.SOCK_STREAM, 0,\n                                      socket.AI_PASSIVE)):\n\n        family, socktype, proto, _, sock_addr = res\n        sock = socket.socket(family, socktype, proto)\n        if os.name != 'nt':\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n        # Automatic port allocation with port=None.\n        sock.bind(sock_addr)\n        sock.listen(128)\n        bound_port = sock.getsockname()[1]\n        return sock, (host, bound_port)\n\n    raise socket.error('could not bind socket')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind_domain_socket(address):\n    path, _ = address\n    try:\n        os.unlink(path)\n    except OSError:\n        pass\n\n    sock = socket.socket(socket.AF_UNIX)\n    sock.bind(path)\n    sock.listen(128)\n    return sock, (path, 0)", "response": "Takes ( socket path 0 ) and returns ( socket_object 0 )."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntakes a client socket and return a Request.", "response": "def mock_server_receive_request(client, server):\n    \"\"\"Take a client socket and return a Request.\"\"\"\n    header = mock_server_receive(client, 16)\n    length = _UNPACK_INT(header[:4])[0]\n    request_id = _UNPACK_INT(header[4:8])[0]\n    opcode = _UNPACK_INT(header[12:])[0]\n    msg_bytes = mock_server_receive(client, length - 16)\n    if opcode not in OPCODES:\n        raise NotImplementedError(\"Don't know how to unpack opcode %d yet\"\n                                  % opcode)\n    return OPCODES[opcode].unpack(msg_bytes, client, server, request_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreceive length bytes from a socket object.", "response": "def mock_server_receive(sock, length):\n    \"\"\"Receive `length` bytes from a socket object.\"\"\"\n    msg = b''\n    while length:\n        chunk = sock.recv(length)\n        if chunk == b'':\n            raise socket.error(errno.ECONNRESET, 'closed')\n\n        length -= len(chunk)\n        msg += chunk\n\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_docs(*args, **kwargs):\n    err_msg = \"Can't interpret args: \"\n    if not args and not kwargs:\n        return []\n\n    if not args:\n        # OpReply(ok=1, ismaster=True).\n        return [kwargs]\n\n    if isinstance(args[0], (int, float, bool)):\n        # server.receives().ok(0, err='uh oh').\n        if args[1:]:\n            raise_args_err(err_msg, ValueError)\n        doc = OrderedDict({'ok': args[0]})\n        doc.update(kwargs)\n        return [doc]\n\n    if isinstance(args[0], (list, tuple)):\n        # Send a batch: OpReply([{'a': 1}, {'a': 2}]).\n        if not all(isinstance(doc, (OpReply, Mapping))\n                   for doc in args[0]):\n            raise_args_err('each doc must be a dict:')\n        if kwargs:\n            raise_args_err(err_msg, ValueError)\n        return list(args[0])\n\n    if isinstance(args[0], (string_type, text_type)):\n        if args[2:]:\n            raise_args_err(err_msg, ValueError)\n\n        if len(args) == 2:\n            # Command('aggregate', 'collection', {'cursor': {'batchSize': 1}}).\n            doc = OrderedDict({args[0]: args[1]})\n        else:\n            # OpReply('ismaster', me='a.com').\n            doc = OrderedDict({args[0]: 1})\n        doc.update(kwargs)\n        return [doc]\n\n    if kwargs:\n        raise_args_err(err_msg, ValueError)\n\n    # Send a batch as varargs: OpReply({'a': 1}, {'a': 2}).\n    if not all(isinstance(doc, (OpReply, Mapping)) for doc in args):\n        raise_args_err('each doc must be a dict')\n\n    return args", "response": "Make the documents for a Request or Reply."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_matcher(*args, **kwargs):\n    if args and isinstance(args[0], Matcher):\n        if args[1:] or kwargs:\n            raise_args_err(\"can't interpret args\")\n        return args[0]\n\n    return Matcher(*args, **kwargs)", "response": "Make a Matcher from a message spec."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make_prototype_request(*args, **kwargs):\n    if args and inspect.isclass(args[0]) and issubclass(args[0], Request):\n        request_cls, arg_list = args[0], args[1:]\n        return request_cls(*arg_list, **kwargs)\n    if args and isinstance(args[0], Request):\n        if args[1:] or kwargs:\n            raise_args_err(\"can't interpret args\")\n        return args[0]\n\n    # Match any opcode.\n    return Request(*args, **kwargs)", "response": "Make a prototype Request for a Matcher."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntrues if seq0 is a subset of seq1 and their elements are in same order.", "response": "def seq_match(seq0, seq1):\n    \"\"\"True if seq0 is a subset of seq1 and their elements are in same order.\n\n    >>> seq_match([], [])\n    True\n    >>> seq_match([1], [1])\n    True\n    >>> seq_match([1, 1], [1])\n    False\n    >>> seq_match([1], [1, 2])\n    True\n    >>> seq_match([1, 1], [1, 1])\n    True\n    >>> seq_match([3], [1, 2, 3])\n    True\n    >>> seq_match([1, 3], [1, 2, 3])\n    True\n    >>> seq_match([2, 1], [1, 2, 3])\n    False\n    \"\"\"\n    len_seq1 = len(seq1)\n    if len_seq1 < len(seq0):\n        return False\n    seq1_idx = 0\n    for i, elem in enumerate(seq0):\n        while seq1_idx < len_seq1:\n            if seq1[seq1_idx] == elem:\n                break\n            seq1_idx += 1\n        if seq1_idx >= len_seq1 or seq1[seq1_idx] != elem:\n            return False\n        seq1_idx += 1\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nraises an error with standard message displaying function call.", "response": "def raise_args_err(message='bad arguments', error_class=TypeError):\n    \"\"\"Throw an error with standard message, displaying function call.\n\n    >>> def f(a, *args, **kwargs):\n    ...     raise_args_err()\n    ...\n    >>> f(1, 2, x='y')\n    Traceback (most recent call last):\n    ...\n    TypeError: bad arguments: f(1, 2, x='y')\n    \"\"\"\n    frame = inspect.currentframe().f_back\n    raise error_class(message + ': ' + format_call(frame))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interactive_server(port=27017, verbose=True, all_ok=False, name='MockupDB',\n                       ssl=False, uds_path=None):\n    \"\"\"A `MockupDB` that the mongo shell can connect to.\n\n    Call `~.MockupDB.run` on the returned server, and clean it up with\n    `~.MockupDB.stop`.\n\n    If ``all_ok`` is True, replies {ok: 1} to anything unmatched by a specific\n    responder.\n    \"\"\"\n    if uds_path is not None:\n        port = None\n\n    server = MockupDB(port=port,\n                      verbose=verbose,\n                      request_timeout=int(1e6),\n                      ssl=ssl,\n                      auto_ismaster=True,\n                      uds_path=uds_path)\n    if all_ok:\n        server.append_responder({})\n    server.autoresponds('whatsmyuri', you='localhost:12345')\n    server.autoresponds({'getLog': 'startupWarnings'},\n                        log=['hello from %s!' % name])\n    server.autoresponds(OpMsg('buildInfo'), version='MockupDB ' + __version__)\n    server.autoresponds(OpMsg('listCollections'))\n    server.autoresponds('replSetGetStatus', ok=0)\n    server.autoresponds('getFreeMonitoringStatus', ok=0)\n    return server", "response": "A simple mockup server that can be used to connect to a mongo server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nassert this matches a : ref : message spec <message spec.", "response": "def assert_matches(self, *args, **kwargs):\n        \"\"\"Assert this matches a :ref:`message spec <message spec>`.\n\n        Returns self.\n        \"\"\"\n        matcher = make_matcher(*args, **kwargs)\n        if not matcher.matches(self):\n            raise AssertionError('%r does not match %r' % (self, matcher))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplying to a query with the QueryFailure flag and an '$err' key. Returns True so it is suitable as an Autoresponds handler.", "response": "def fail(self, err='MockupDB query failure', *args, **kwargs):\n        \"\"\"Reply to a query with the QueryFailure flag and an '$err' key.\n\n        Returns True so it is suitable as an `~MockupDB.autoresponds` handler.\n        \"\"\"\n        kwargs.setdefault('flags', 0)\n        kwargs['flags'] |= REPLY_FLAGS['QueryFailure']\n        kwargs['$err'] = err\n        self.replies(*args, **kwargs)\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hangup(self):\n        if self._server:\n            self._server._log('\\t%d\\thangup' % self.client_port)\n        self._client.shutdown(socket.SHUT_RDWR)\n        return True", "response": "Close the connection and shutdown the client."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _replies(self, *args, **kwargs):\n        reply_msg = make_reply(*args, **kwargs)\n        if self._server:\n            self._server._log('\\t%d\\t<-- %r' % (self.client_port, reply_msg))\n        reply_bytes = reply_msg.reply_bytes(self)\n        self._client.sendall(reply_bytes)", "response": "Overridable method. Sends a reply to the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unpack(cls, msg, client, server, request_id):\n        payload_document = OrderedDict()\n        flags, = _UNPACK_UINT(msg[:4])\n        pos = 4\n        if flags != 0 and flags != 2:\n            raise ValueError('OP_MSG flag must be 0 or 2 not %r' % (flags,))\n\n        while pos < len(msg):\n            payload_type, = _UNPACK_BYTE(msg[pos:pos + 1])\n            pos += 1\n            payload_size, = _UNPACK_INT(msg[pos:pos + 4])\n            if payload_type == 0:\n                doc = bson.decode_all(msg[pos:pos + payload_size],\n                                      CODEC_OPTIONS)[0]\n                payload_document.update(doc)\n                pos += payload_size\n            elif payload_type == 1:\n                section_size, = _UNPACK_INT(msg[pos:pos + 4])\n                pos += 4\n                identifier, pos = _get_c_string(msg, pos)\n                # Section starts w/ 4-byte size prefix, identifier ends w/ nil.\n                documents_len = section_size - len(identifier) - 1 - 4\n                documents = bson.decode_all(msg[pos:pos + documents_len],\n                                            CODEC_OPTIONS)\n                payload_document[identifier] = documents\n                pos += documents_len\n\n        database = payload_document['$db']\n        return OpMsg(payload_document, namespace=database, flags=flags,\n                     _client=client, request_id=request_id,\n                     _server=server)", "response": "Parse an OP_MSG message and return an OpMsg object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a message and return an OpQuery or Command object.", "response": "def unpack(cls, msg, client, server, request_id):\n        \"\"\"Parse message and return an `OpQuery` or `Command`.\n\n        Takes the client message as bytes, the client and server socket objects,\n        and the client request id.\n        \"\"\"\n        flags, = _UNPACK_INT(msg[:4])\n        namespace, pos = _get_c_string(msg, 4)\n        is_command = namespace.endswith('.$cmd')\n        num_to_skip, = _UNPACK_INT(msg[pos:pos + 4])\n        pos += 4\n        num_to_return, = _UNPACK_INT(msg[pos:pos + 4])\n        pos += 4\n        docs = bson.decode_all(msg[pos:], CODEC_OPTIONS)\n        if is_command:\n            assert len(docs) == 1\n            command_ns = namespace[:-len('.$cmd')]\n            return Command(docs, namespace=command_ns, flags=flags,\n                           _client=client, request_id=request_id,\n                           _server=server)\n        else:\n            if len(docs) == 1:\n                fields = None\n            else:\n                assert len(docs) == 2\n                fields = docs[1]\n            return OpQuery(docs[0], fields=fields, namespace=namespace,\n                           flags=flags, num_to_skip=num_to_skip,\n                           num_to_return=num_to_return, _client=client,\n                           request_id=request_id, _server=server)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a message and return an OpGetMore.", "response": "def unpack(cls, msg, client, server, request_id):\n        \"\"\"Parse message and return an `OpGetMore`.\n\n        Takes the client message as bytes, the client and server socket objects,\n        and the client request id.\n        \"\"\"\n        flags, = _UNPACK_INT(msg[:4])\n        namespace, pos = _get_c_string(msg, 4)\n        num_to_return, = _UNPACK_INT(msg[pos:pos + 4])\n        pos += 4\n        cursor_id, = _UNPACK_LONG(msg[pos:pos + 8])\n        return OpGetMore(namespace=namespace, flags=flags, _client=client,\n                         num_to_return=num_to_return, cursor_id=cursor_id,\n                         request_id=request_id, _server=server)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unpack(cls, msg, client, server, _):\n        # Leading 4 bytes are reserved.\n        num_of_cursor_ids, = _UNPACK_INT(msg[4:8])\n        cursor_ids = []\n        pos = 8\n        for _ in range(num_of_cursor_ids):\n            cursor_ids.append(_UNPACK_INT(msg[pos:pos + 4])[0])\n            pos += 4\n        return OpKillCursors(_client=client, cursor_ids=cursor_ids,\n                             _server=server)", "response": "Parse a message and return an OpKillCursors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a message and return an OpInsert.", "response": "def unpack(cls, msg, client, server, request_id):\n        \"\"\"Parse message and return an `OpInsert`.\n\n        Takes the client message as bytes, the client and server socket objects,\n        and the client request id.\n        \"\"\"\n        flags, = _UNPACK_INT(msg[:4])\n        namespace, pos = _get_c_string(msg, 4)\n        docs = bson.decode_all(msg[pos:], CODEC_OPTIONS)\n        return cls(*docs, namespace=namespace, flags=flags, _client=client,\n                   request_id=request_id, _server=server)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking a Request and return an OP_REPLY message as bytes.", "response": "def reply_bytes(self, request):\n        \"\"\"Take a `Request` and return an OP_REPLY message as bytes.\"\"\"\n        flags = struct.pack(\"<i\", self._flags)\n        cursor_id = struct.pack(\"<q\", self._cursor_id)\n        starting_from = struct.pack(\"<i\", self._starting_from)\n        number_returned = struct.pack(\"<i\", len(self._docs))\n        reply_id = random.randint(0, 1000000)\n        response_to = request.request_id\n\n        data = b''.join([flags, cursor_id, starting_from, number_returned])\n        data += b''.join([bson.BSON.encode(doc) for doc in self._docs])\n\n        message = struct.pack(\"<i\", 16 + len(data))\n        message += struct.pack(\"<i\", reply_id)\n        message += struct.pack(\"<i\", response_to)\n        message += struct.pack(\"<i\", OP_REPLY)\n        return message + data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reply_bytes(self, request):\n        flags = struct.pack(\"<I\", self._flags)\n        payload_type = struct.pack(\"<b\", 0)\n        payload_data = bson.BSON.encode(self.doc)\n        data = b''.join([flags, payload_type, payload_data])\n\n        reply_id = random.randint(0, 1000000)\n        response_to = request.request_id\n\n        header = struct.pack(\n            \"<iiii\", 16 + len(data), reply_id, response_to, OP_MSG)\n        return header + data", "response": "Take a Request and return an OP_MSG message as bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntesting if a request matches a : ref : message spec <message spec.", "response": "def matches(self, *args, **kwargs):\n        \"\"\"Test if a request matches a :ref:`message spec <message spec>`.\n\n        Returns ``True`` or ``False``.\n        \"\"\"\n        request = make_prototype_request(*args, **kwargs)\n        if self._prototype.opcode not in (None, request.opcode):\n            return False\n        if self._prototype.is_command not in (None, request.is_command):\n            return False\n        for name in dir(self._prototype):\n            if name.startswith('_') or name in request._non_matched_attrs:\n                # Ignore privates, and handle documents specially.\n                continue\n            prototype_value = getattr(self._prototype, name, None)\n            if inspect.ismethod(prototype_value):\n                continue\n            actual_value = getattr(request, name, None)\n            if prototype_value not in (None, actual_value):\n                return False\n        if len(self._prototype.docs) not in (0, len(request.docs)):\n            return False\n\n        return self._prototype._matches_docs(self._prototype.docs, request.docs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart serving. Returns the bound port or 0 for domain socket.", "response": "def run(self):\n        \"\"\"Begin serving. Returns the bound port, or 0 for domain socket.\"\"\"\n        self._listening_sock, self._address = (\n            bind_domain_socket(self._address)\n            if self._uds_path\n            else bind_tcp_socket(self._address))\n\n        if self._ssl:\n            certfile = os.path.join(os.path.dirname(__file__), 'server.pem')\n            self._listening_sock = _ssl.wrap_socket(\n                self._listening_sock,\n                certfile=certfile,\n                server_side=True)\n        self._accept_thread = threading.Thread(target=self._accept_loop)\n        self._accept_thread.daemon = True\n        self._accept_thread.start()\n        return self.port"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstops serving. Always call this to clean up after yourself.", "response": "def stop(self):\n        \"\"\"Stop serving. Always call this to clean up after yourself.\"\"\"\n        self._stopped = True\n        threads = [self._accept_thread]\n        threads.extend(self._server_threads)\n        self._listening_sock.close()\n        for sock in list(self._server_socks):\n            try:\n                sock.shutdown(socket.SHUT_RDWR)\n            except socket.error:\n                pass\n\n            try:\n                sock.close()\n            except socket.error:\n                pass\n\n        with self._unlock():\n            for thread in threads:\n                thread.join(10)\n\n        if self._uds_path:\n            try:\n                os.unlink(self._uds_path)\n            except OSError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receives(self, *args, **kwargs):\n        timeout = kwargs.pop('timeout', self._request_timeout)\n        end = time.time() + timeout\n        matcher = Matcher(*args, **kwargs)\n        while not self._stopped:\n            try:\n                # Short timeout so we notice if the server is stopped.\n                request = self._request_q.get(timeout=0.05)\n            except Empty:\n                if time.time() > end:\n                    raise AssertionError('expected to receive %r, got nothing'\n                                         % matcher.prototype)\n            else:\n                if matcher.matches(request):\n                    return request\n                else:\n                    raise AssertionError('expected to receive %r, got %r'\n                                         % (matcher.prototype, request))", "response": "Pop the next Request and assert it matches."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndo `.request` match the given :ref:`message spec <message spec>`? >>> s = MockupDB(auto_ismaster=True) >>> port = s.run() >>> s.got(timeout=0) # No request enqueued. False >>> from pymongo import MongoClient >>> client = MongoClient(s.uri) >>> future = go(client.db.command, 'foo') >>> s.got('foo') True >>> s.got(OpMsg('foo', namespace='db')) True >>> s.got(OpMsg('foo', key='value')) False >>> s.ok() >>> future() == {'ok': 1} True >>> s.stop()", "response": "def got(self, *args, **kwargs):\n        \"\"\"Does `.request` match the given :ref:`message spec <message spec>`?\n\n        >>> s = MockupDB(auto_ismaster=True)\n        >>> port = s.run()\n        >>> s.got(timeout=0)  # No request enqueued.\n        False\n        >>> from pymongo import MongoClient\n        >>> client = MongoClient(s.uri)\n        >>> future = go(client.db.command, 'foo')\n        >>> s.got('foo')\n        True\n        >>> s.got(OpMsg('foo', namespace='db'))\n        True\n        >>> s.got(OpMsg('foo', key='value'))\n        False\n        >>> s.ok()\n        >>> future() == {'ok': 1}\n        True\n        >>> s.stop()\n        \"\"\"\n        timeout = kwargs.pop('timeout', self._request_timeout)\n        end = time.time() + timeout\n        matcher = make_matcher(*args, **kwargs)\n\n        while not self._stopped:\n            try:\n                # Short timeout so we notice if the server is stopped.\n                request = self._request_q.peek(timeout=timeout)\n            except Empty:\n                if time.time() > end:\n                    return False\n            else:\n                return matcher.matches(request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autoresponds(self, matcher, *args, **kwargs):\n        return self._insert_responder(\"top\", matcher, *args, **kwargs)", "response": "Send a canned reply to all matching client requests."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a responder to the bottom of the stack.", "response": "def append_responder(self, matcher, *args, **kwargs):\n        \"\"\"Add a responder of last resort.\n\n        Like `.autoresponds`, but instead of adding a responder to the top of\n        the stack, add it to the bottom. This responder will be called if no\n        others match.\n        \"\"\"\n        return self._insert_responder(\"bottom\", matcher, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uri(self):\n        if self._uds_path:\n            uri = 'mongodb://%s' % (quote_plus(self._uds_path),)\n        else:\n            uri = 'mongodb://%s' % (format_addr(self._address),)\n        return uri + '/?ssl=true' if self._ssl else uri", "response": "Connection string to pass to pymongo. mongo_client. MongoClient."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _accept_loop(self):\n        self._listening_sock.setblocking(0)\n        while not self._stopped and not _shutting_down:\n            try:\n                # Wait a short time to accept.\n                if select.select([self._listening_sock.fileno()], [], [], 1):\n                    client, client_addr = self._listening_sock.accept()\n                    client.setblocking(True)\n                    self._log('connection from %s' % format_addr(client_addr))\n                    server_thread = threading.Thread(\n                        target=functools.partial(\n                            self._server_loop, client, client_addr))\n\n                    # Store weakrefs to the thread and socket, so we can\n                    # dispose them in stop().\n                    self._server_threads[server_thread] = None\n                    self._server_socks[client] = None\n\n                    server_thread.daemon = True\n                    server_thread.start()\n            except socket.error as error:\n                if error.errno not in (\n                    errno.EAGAIN, errno.EBADF, errno.EWOULDBLOCK):\n                    raise\n            except select.error as error:\n                if error.args[0] == errno.EBADF:\n                    # Closed.\n                    break\n                else:\n                    raise", "response": "Accept client connections and spawn a thread for each."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _server_loop(self, client, client_addr):\n        while not self._stopped and not _shutting_down:\n            try:\n                with self._unlock():\n                    request = mock_server_receive_request(client, self)\n\n                self._requests_count += 1\n                self._log('%d\\t%r' % (request.client_port, request))\n\n                # Give most recently added responders precedence.\n                for responder in reversed(self._autoresponders):\n                    if responder.handle(request):\n                        self._log('\\t(autoresponse)')\n                        break\n                else:\n                    self._request_q.put(request)\n            except socket.error as error:\n                if error.errno in (errno.ECONNRESET, errno.EBADF):\n                    # We hung up, or the client did.\n                    break\n                raise\n            except select.error as error:\n                if error.args[0] == errno.EBADF:\n                    # Closed.\n                    break\n                else:\n                    raise\n            except AssertionError:\n                traceback.print_exc()\n                break\n\n        self._log('disconnected: %s' % format_addr(client_addr))\n        client.close()", "response": "Read requests from one client socket client socket client."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_password(self, username, password):\n        try:\n            if SUPPORTS_VERIFY:\n                kerberos.checkPassword(username.lower(), password, getattr(settings, \"KRB5_SERVICE\", \"\"), getattr(settings, \"KRB5_REALM\", \"\"), getattr(settings, \"KRB5_VERIFY_KDC\", True))\n            else:\n                kerberos.checkPassword(username.lower(), password, getattr(settings, \"KRB5_SERVICE\", \"\"), getattr(settings, \"KRB5_REALM\", \"\"))\n            return True\n        except kerberos.BasicAuthError:\n            if getattr(settings, \"KRB5_DEBUG\", False):\n                logger.exception(\"Failure during authentication\")\n            return False\n        except:\n            if getattr(settings, \"KRB5_DEBUG\", False):\n                logger.exception(\"Failure during authentication\")\n            # for all other execptions also deny access\n            return False", "response": "The actual password checking logic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart an interactive mockup DB server.", "response": "def main():\n    \"\"\"Start an interactive `MockupDB`.\n\n    Use like ``python -m mockupdb``.\n    \"\"\"\n    from optparse import OptionParser\n    parser = OptionParser('Start mock MongoDB server')\n    parser.add_option('-p', '--port', dest='port', default=27017,\n                      help='port on which mock mongod listens')\n    parser.add_option('-q', '--quiet',\n                      action='store_false', dest='verbose', default=True,\n                      help=\"don't print messages to stdout\")\n\n    options, cmdline_args = parser.parse_args()\n    if cmdline_args:\n        parser.error('Unrecognized argument(s): %s' % ' '.join(cmdline_args))\n\n    server = interactive_server(port=options.port, verbose=options.verbose)\n    try:\n        server.run()\n        print('Listening on port %d' % server.port)\n        time.sleep(1e6)\n    except KeyboardInterrupt:\n        server.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _calculate_influence(self, neighborhood):\n        grid = np.exp(-self.distance_grid / (neighborhood ** 2))\n        return grid.reshape(self.num_neurons, self.num_neurons)[:, :, None]", "response": "Calculates the influence of a given neighborhood."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the distance grid by calling _grid_dist.", "response": "def _initialize_distance_grid(self):\n        \"\"\"Initialize the distance grid by calls to _grid_dist.\"\"\"\n        p = [self._grid_distance(i) for i in range(self.num_neurons)]\n        return np.array(p)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _grid_distance(self, index):\n        # Take every dimension but the first in reverse\n        # then reverse that list again.\n        dimensions = np.cumprod(self.map_dimensions[1::][::-1])[::-1]\n\n        coord = []\n        for idx, dim in enumerate(dimensions):\n            if idx != 0:\n                value = (index % dimensions[idx-1]) // dim\n            else:\n                value = index // dim\n            coord.append(value)\n\n        coord.append(index % self.map_dimensions[-1])\n\n        for idx, (width, row) in enumerate(zip(self.map_dimensions, coord)):\n            x = np.abs(np.arange(width) - row) ** 2\n            dims = self.map_dimensions[::-1]\n            if idx:\n                dims = dims[:-idx]\n            x = np.broadcast_to(x, dims).T\n            if idx == 0:\n                distance = np.copy(x)\n            else:\n                distance += x.T\n\n        return distance", "response": "Calculate the distance between a single index position and a list of neighbors."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef topographic_error(self, X, batch_size=1):\n        dist = self.transform(X, batch_size)\n        # Sort the distances and get the indices of the two smallest distances\n        # for each datapoint.\n        res = dist.argsort(1)[:, :2]\n        # Lookup the euclidean distance between these points in the distance\n        # grid\n        dgrid = self.distance_grid.reshape(self.num_neurons, self.num_neurons)\n        res = np.asarray([dgrid[x, y] for x, y in res])\n        # Subtract 1.0 because 1.0 is the smallest distance.\n        return np.sum(res > 1.0) / len(res)", "response": "Calculates the topographic error of a set of data points."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef neighbors(self, distance=2.0):\n        dgrid = self.distance_grid.reshape(self.num_neurons, self.num_neurons)\n        for x, y in zip(*np.nonzero(dgrid <= distance)):\n            if x != y:\n                yield x, y", "response": "Get all neighbors for all neurons."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the euclidean distance between a node and its neighbors.", "response": "def neighbor_difference(self):\n        \"\"\"Get the euclidean distance between a node and its neighbors.\"\"\"\n        differences = np.zeros(self.num_neurons)\n        num_neighbors = np.zeros(self.num_neurons)\n\n        distance, _ = self.distance_function(self.weights, self.weights)\n        for x, y in self.neighbors():\n            differences[x] += distance[x, y]\n            num_neighbors[x] += 1\n\n        return differences / num_neighbors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spread(self, X):\n        distance, _ = self.distance_function(X, self.weights)\n        dists_per_neuron = defaultdict(list)\n        for x, y in zip(np.argmin(distance, 1), distance):\n            dists_per_neuron[x].append(y[x])\n\n        out = np.zeros(self.num_neurons)\n        average_spread = {k: np.mean(v)\n                          for k, v in dists_per_neuron.items()}\n\n        for x, y in average_spread.items():\n            out[x] = y\n        return out", "response": "Calculate the average spread for each node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef receptive_field(self,\n                        X,\n                        identities,\n                        max_len=10,\n                        threshold=0.9,\n                        batch_size=1):\n        \"\"\"\n        Calculate the receptive field of the SOM on some data.\n\n        The receptive field is the common ending of all sequences which\n        lead to the activation of a given BMU. If a SOM is well-tuned to\n        specific sequences, it will have longer receptive fields, and therefore\n        gives a better description of the dynamics of a given system.\n\n        Parameters\n        ----------\n        X : numpy array\n            Input data.\n        identities : list\n            A list of symbolic identities associated with each input.\n            We expect this list to be as long as the input data.\n        max_len : int, optional, default 10\n            The maximum length to attempt to find. Raising this increases\n            memory use.\n        threshold : float, optional, default .9\n            The threshold at which we consider a receptive field\n            valid. If at least this proportion of the sequences of a neuron\n            have the same suffix, that suffix is counted as acquired by the\n            SOM.\n        batch_size : int, optional, default 1\n            The batch size to use in prediction\n\n        Returns\n        -------\n        receptive_fields : dict\n            A dictionary mapping from the neuron id to the found sequences\n            for that neuron. The sequences are represented as lists of\n            symbols from identities.\n\n        \"\"\"\n        receptive_fields = defaultdict(list)\n        predictions = self.predict(X, batch_size)\n\n        if len(predictions) != len(identities):\n            raise ValueError(\"X and identities are not the same length: \"\n                             \"{0} and {1}\".format(len(X), len(identities)))\n\n        for idx, p in enumerate(predictions.tolist()):\n            receptive_fields[p].append(identities[idx+1 - max_len:idx+1])\n\n        rec = {}\n\n        for k, v in receptive_fields.items():\n            # if there's only one sequence, we don't know\n            # anything abouw how salient it is.\n            seq = []\n            if len(v) <= 1:\n                continue\n            else:\n                for x in reversed(list(zip(*v))):\n                    x = Counter(x)\n                    if x.most_common(1)[0][1] / sum(x.values()) > threshold:\n                        seq.append(x.most_common(1)[0][0])\n                    else:\n                        rec[k] = seq\n                        break\n\n        return rec", "response": "Calculate the receptive field of a given BMU on some data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef invert_projection(self, X, identities):\n        distances = self.transform(X)\n\n        if len(distances) != len(identities):\n            raise ValueError(\"X and identities are not the same length: \"\n                             \"{0} and {1}\".format(len(X), len(identities)))\n\n        node_match = []\n\n        for d in distances.__getattribute__(self.argfunc)(0):\n            node_match.append(identities[d])\n\n        return np.array(node_match)", "response": "Calculates the inverted projection of a SOM."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_weights(self):\n        first_dim = self.map_dimensions[0]\n        if len(self.map_dimensions) != 1:\n            second_dim = np.prod(self.map_dimensions[1:])\n        else:\n            second_dim = 1\n\n        # Reshape to appropriate dimensions\n        return self.weights.reshape((first_dim,\n                                     second_dim,\n                                     self.data_dimensionality))", "response": "Returns a 2D array containing the weights for the hyper - dimensional entry sets."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(cls, path):\n        data = json.load(open(path))\n\n        weights = data['weights']\n        weights = np.asarray(weights, dtype=np.float64)\n\n        s = cls(data['map_dimensions'],\n                data['params']['lr']['orig'],\n                data['data_dimensionality'],\n                influence=data['params']['infl']['orig'],\n                lr_lambda=data['params']['lr']['factor'],\n                infl_lambda=data['params']['infl']['factor'])\n\n        s.weights = weights\n        s.trained = True\n\n        return s", "response": "Loads a SOM from a JSON file saved with this package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self):\n        LOG.info('Interacting with the CDN...')\n        with indicator.Spinner(run=self.run_indicator):\n            cdn_item = self._cdn()\n\n        self.print_virt_table(cdn_item.headers)", "response": "Return a list of objects from the API for a container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving a long list of all files in a container.", "response": "def _cdn(self):\n        \"\"\"Retrieve a long list of all files in a container.\n\n        :return final_list, list_count, last_obj:\n        \"\"\"\n\n        headers = dict()\n\n        cdn_enabled = self.job_args.get('cdn_enabled')\n        if cdn_enabled:\n            headers['x-cdn-enabled'] = True\n\n        cdn_disabled = self.job_args.get('cdn_disabled')\n        if cdn_disabled:\n            headers['x-cdn-enabled'] = False\n\n        cdn_logs_enabled = self.job_args.get('cdn_logs_enabled')\n        if cdn_logs_enabled:\n            headers['x-log-retention'] = True\n\n        cdn_logs_disabled = self.job_args.get('cdn_logs_disabled')\n        if cdn_logs_disabled:\n            headers['x-log-retention'] = False\n\n        cnd_web_listing_enabled = self.job_args.get('cdn_web_enabled')\n        if cnd_web_listing_enabled:\n            headers['x-container-meta-web-listings'] = True\n\n        cnd_web_listing_disabled = self.job_args.get('cdn_web_disabled')\n        if cnd_web_listing_disabled:\n            headers['x-container-meta-web-listings'] = False\n\n        cdn_web_error_content = self.job_args.get('cdn_web_error_content')\n        if cdn_web_error_content:\n            headers['x-container-meta-web-error'] = cdn_web_error_content\n\n        cdn_web_dir_type = self.job_args.get('cdn_web_dir_type')\n        if cdn_web_error_content:\n            headers['x-container-meta-web-directory-type'] = cdn_web_dir_type\n\n        cdn_web_css_object = self.job_args.get('cdn_web_css_object')\n        if cdn_web_css_object:\n            headers['x-container-meta-web-listings-css'] = cdn_web_css_object\n\n        cdn_web_index_object = self.job_args.get('cdn_web_index_object')\n        if cdn_web_css_object:\n            headers['X-Container-Meta-Web-Index'] = cdn_web_index_object\n\n        headers['x-ttl'] = self.job_args.get('cdn_ttl')\n\n        return self.job.container_cdn_command(\n            url=self.job_args['cdn_storage_url'],\n            container=self.job_args['container'],\n            container_object=self.job_args['object'],\n            cdn_headers=headers\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a directory recursively.", "response": "def remove_dirs(self, directory):\n        \"\"\"Delete a directory recursively.\n\n        :param directory: $PATH to directory.\n        :type directory: ``str``\n        \"\"\"\n\n        LOG.info('Removing directory [ %s ]', directory)\n        local_files = self._drectory_local_files(directory=directory)\n        for file_name in local_files:\n            try:\n                os.remove(file_name['local_object'])\n            except OSError as exp:\n                LOG.error(str(exp))\n\n        # Build a list of all local directories\n        directories = sorted(\n            [i for i, _, _ in os.walk(directory)],\n            reverse=True\n        )\n\n        # Remove directories\n        for directory_path in directories:\n            try:\n                os.removedirs(directory_path)\n            except OSError as exp:\n                if exp.errno != 2:\n                    LOG.error(str(exp))\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _list_contents(self, last_obj=None, single_page_return=False):\n        if self.job_args.get('cdn_containers'):\n            if not self.job_args.get('fields'):\n                self.job_args['fields'] = [\n                    'name',\n                    'cdn_enabled',\n                    'log_retention',\n                    'ttl'\n                ]\n            url = self.job_args['cdn_storage_url']\n        else:\n            url = self.job_args['storage_url']\n\n        objects_list = self.job.list_items(\n            url=url,\n            container=self.job_args['container'],\n            last_obj=last_obj,\n            spr=single_page_return\n        )\n\n        pattern_match = self.job_args.get('pattern_match')\n        if pattern_match:\n            self.match_filter(\n                idx_list=objects_list,\n                pattern=pattern_match,\n                dict_type=True\n            )\n\n        LOG.debug('List of objects: \"%s\"', objects_list)\n        return objects_list", "response": "Retrieve a long list of all files in a container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _return_container_objects(self):\n\n        container_objects = self.job_args.get('object')\n        if container_objects:\n            return True, [{'container_object': i} for i in container_objects]\n\n        container_objects = self.job_args.get('objects_file')\n        if container_objects:\n            container_objects = os.path.expanduser(container_objects)\n            if os.path.isfile(container_objects):\n                with open(container_objects) as f:\n                    return True, [\n                        {'container_object': i.rstrip('\\n')}\n                        for i in f.readlines()\n                    ]\n\n        container_objects = self._list_contents()\n        pattern_match = self.job_args.get('pattern_match')\n        if pattern_match:\n            container_objects = self.match_filter(\n                idx_list=container_objects,\n                pattern=pattern_match,\n                dict_type=True,\n                dict_key='name'\n            )\n\n        # Reformat list for processing\n        if container_objects and isinstance(container_objects[0], dict):\n            return False, self._return_deque([\n                {'container_object': i['name']} for i in container_objects\n            ])\n        else:\n            return False, self._return_deque()", "response": "Return a list of objects to delete."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a deque object full of local file system items.", "response": "def _index_fs(self):\n        \"\"\"Returns a deque object full of local file system items.\n\n        :returns: ``deque``\n        \"\"\"\n\n        indexed_objects = self._return_deque()\n\n        directory = self.job_args.get('directory')\n        if directory:\n            indexed_objects = self._return_deque(\n                deque=indexed_objects,\n                item=self._drectory_local_files(\n                    directory=directory\n                )\n            )\n\n        object_names = self.job_args.get('object')\n        if object_names:\n            indexed_objects = self._return_deque(\n                deque=indexed_objects,\n                item=self._named_local_files(\n                    object_names=object_names\n                )\n            )\n\n        return indexed_objects"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef match_filter(self, idx_list, pattern, dict_type=False,\n                     dict_key='name'):\n        \"\"\"Return Matched items in indexed files.\n\n        :param idx_list:\n        :return list\n        \"\"\"\n\n        if dict_type is False:\n            return self._return_deque([\n                obj for obj in idx_list\n                if re.search(pattern, obj)\n            ])\n        elif dict_type is True:\n            return self._return_deque([\n                obj for obj in idx_list\n                if re.search(pattern, obj.get(dict_key))\n            ])\n        else:\n            return self._return_deque()", "response": "Return a list of items in indexed files that match a pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef print_horiz_table(self, data):\n\n        # Build list of returned objects\n        return_objects = list()\n        fields = self.job_args.get('fields')\n        if not fields:\n            fields = set()\n            for item_dict in data:\n                for field_item in item_dict.keys():\n                    fields.add(field_item)\n            fields = sorted(fields)\n\n        for obj in data:\n            item_struct = dict()\n            for item in fields:\n                item_struct[item] = obj.get(item)\n            else:\n                return_objects.append(item_struct)\n\n        table = prettytable.PrettyTable(fields)\n        for obj in return_objects:\n            table.add_row([obj.get(i) for i in fields])\n\n        for tbl in table.align.keys():\n            table.align[tbl] = 'l'\n\n        sort_key = self.job_args.get('sort_by')\n        if sort_key:\n            table.sortby = sort_key\n\n        self.printer(table)", "response": "Print a horizontal pretty table from data."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef print_virt_table(self, data):\n\n        table = prettytable.PrettyTable()\n        keys = sorted(data.keys())\n        table.add_column('Keys', keys)\n        table.add_column('Values', [data.get(i) for i in keys])\n        for tbl in table.align.keys():\n            table.align[tbl] = 'l'\n\n        self.printer(table)", "response": "Print a vertical pretty table from data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef printer(self, message, color_level='info'):\n\n        if self.job_args.get('colorized'):\n            print(cloud_utils.return_colorized(msg=message, color=color_level))\n        else:\n            print(message)", "response": "Print a message to screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dice(edge=15, fn=32):\n        edge = float(edge)\n        # dice\n        c = ops.Cube(edge, center=True)\n        s = ops.Sphere(edge * 3 / 4, center=True)\n        dice = c & s\n        # points\n        c = ops.Circle(edge / 12, _fn=fn)\n        h = 0.7\n        point = c.linear_extrude(height=h)\n        point1 = point.translate([0, 0, edge / 2 - h / 2])\n        point2_1 = point1.rotate(a=90, v=[1, 0, 0]).translate([edge / 6, 0, edge / 6])\n        point2_2 = point2_1.mirror([-edge / 6, 0, -edge / 6])\n        point2 = point2_1 + point2_2\n        point3 = point2.rotate(a=90, v=[0, 0, 1]) + point1.rotate(a=90, v=[0, 1, 0])\n        point4_12 = point2.rotate(a=-90, v=[0, 0, 1])\n        point4 = point4_12 + point4_12.mirror([0, 1, 0])\n        point5_123 = point3.rotate(a=90, v=[0, 0, 1])\n        point5 = point5_123 + point5_123.mirror([1, 0, 0])\n        point6_1 = point.translate([0, 0, -(edge / 2 + h / 2)]).translate([0, edge / 6, 0])\n        point6_2 = point6_1.translate([edge / 4, 0, 0])\n        point6_3 = point6_1.translate([-edge / 4, 0, 0])\n        point6_123 = point6_1 + point6_2 + point6_3\n        point6_456 = point6_123.mirror([0, 1, 0])\n        point6 = point6_123 + point6_456\n        dice_with_holes = dice - point1 - point2 - point3 - point4 - point5 - point6\n        dice_with_holes = dice_with_holes.mirror([0, 0, 1])\n        return(dice_with_holes)", "response": "Generate a dice with holes and points."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_method(method):\n\n        # Split the class out from the job\n        module = method.split(':')\n\n        # Set the import module\n        _module_import = module[0]\n\n        # Set the class name to use\n        class_name = module[-1]\n\n        # import the module\n        module_import = __import__(_module_import, fromlist=[class_name])\n\n        # Return the attributes for the imported module and class\n        return getattr(module_import, class_name)", "response": "Return an imported object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef range_initialization(X, num_weights):\n    # Randomly initialize weights to cover the range of each feature.\n    X_ = X.reshape(-1, X.shape[-1])\n    min_val, max_val = X_.min(0), X_.max(0)\n    data_range = max_val - min_val\n\n    return data_range * np.random.rand(num_weights,\n                                       X.shape[-1]) + min_val", "response": "Initialize the weights for the next set of features."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nuse login to Log in with a username and password.", "response": "def login(self, usr, pwd):\n        \"\"\" Use login() to Log in with a username and password. \"\"\"\n        self._usr = usr\n        self._pwd = pwd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a message to the specified user.", "response": "def send(self, me, to, subject, msg):\n        \"\"\" Send Message \"\"\"\n        msg = MIMEText(msg)\n        msg['Subject'] = subject\n        msg['From'] = me\n        msg['To'] = to\n        server = smtplib.SMTP(self.host, self.port)\n        server.starttls()\n        # Check if user and password defined\n        if self._usr and self._pwd:\n            server.login(self._usr, self._pwd)\n        try:\n            # Send email\n            server.sendmail(me, [x.strip() for x in to.split(\",\")], msg.as_string())\n        except:\n            # Error sending email\n            raise Exception(\"Error Sending Message.\")\n        # Quit!\n        server.quit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfit the learner to some data.", "response": "def fit(self,\n            X,\n            num_epochs=10,\n            updates_epoch=None,\n            stop_param_updates=dict(),\n            batch_size=1,\n            show_progressbar=False,\n            show_epoch=False,\n            refit=True):\n        \"\"\"\n        Fit the learner to some data.\n\n        Parameters\n        ----------\n        X : numpy array.\n            The input data.\n        num_epochs : int, optional, default 10\n            The number of epochs to train for.\n        updates_epoch : int, optional, default 10\n            The number of updates to perform on the learning rate and\n            neighborhood per epoch. 10 suffices for most problems.\n        stop_param_updates : dict\n            The epoch at which to stop updating each param. This means\n            that the specified parameter will be reduced to 0 at the specified\n            epoch.\n        batch_size : int, optional, default 100\n            The batch size to use. Warning: batching can change your\n            performance dramatically, depending on the task.\n        show_progressbar : bool, optional, default False\n            Whether to show a progressbar during training.\n        show_epoch : bool, optional, default False\n            Whether to print the epoch number to stdout\n\n        \"\"\"\n        if self.data_dimensionality is None:\n            self.data_dimensionality = X.shape[-1]\n            self.weights = np.zeros((self.num_neurons,\n                                     self.data_dimensionality))\n        X = self._check_input(X)\n        if not self.trained or refit:\n            X = self._init_weights(X)\n        else:\n            if self.scaler is not None:\n                self.weights = self.scaler.transform(self.weights)\n\n        if updates_epoch is None:\n            X_len = X.shape[0]\n            updates_epoch = np.min([50, X_len // batch_size])\n\n        constants = self._pre_train(stop_param_updates,\n                                    num_epochs,\n                                    updates_epoch)\n        start = time.time()\n        for epoch in tqdm(range(num_epochs), disable=not show_epoch):\n            logger.info(\"Epoch {0} of {1}\".format(epoch+1, num_epochs))\n\n            self._epoch(X,\n                        epoch,\n                        batch_size,\n                        updates_epoch,\n                        constants,\n                        show_progressbar)\n\n        self.trained = True\n        if self.scaler is not None:\n            self.weights = self.scaler.inverse_transform(self.weights)\n        logger.info(\"Total train time: {0}\".format(time.time() - start))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the weights and normalize data before starting training.", "response": "def _init_weights(self,\n                      X):\n        \"\"\"Set the weights and normalize data before starting training.\"\"\"\n        X = np.asarray(X, dtype=np.float64)\n\n        if self.scaler is not None:\n            X = self.scaler.fit_transform(X)\n\n        if self.initializer is not None:\n            self.weights = self.initializer(X, self.num_neurons)\n\n        for v in self.params.values():\n            v['value'] = v['orig']\n\n        return X"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _pre_train(self,\n                   stop_param_updates,\n                   num_epochs,\n                   updates_epoch):\n        \"\"\"Set parameters and constants before training.\"\"\"\n        # Calculate the total number of updates given early stopping.\n        updates = {k: stop_param_updates.get(k, num_epochs) * updates_epoch\n                   for k, v in self.params.items()}\n\n        # Calculate the value of a single step given the number of allowed\n        # updates.\n        single_steps = {k: np.exp(-((1.0 - (1.0 / v)))\n                        * self.params[k]['factor'])\n                        for k, v in updates.items()}\n\n        # Calculate the factor given the true factor and the value of a\n        # single step.\n        constants = {k: np.exp(-self.params[k]['factor']) / v\n                     for k, v in single_steps.items()}\n\n        return constants", "response": "Set parameters and constants before training."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit_predict(self,\n                    X,\n                    num_epochs=10,\n                    updates_epoch=10,\n                    stop_param_updates=dict(),\n                    batch_size=1,\n                    show_progressbar=False):\n        \"\"\"First fit, then predict.\"\"\"\n        self.fit(X,\n                 num_epochs,\n                 updates_epoch,\n                 stop_param_updates,\n                 batch_size,\n                 show_progressbar)\n\n        return self.predict(X, batch_size=batch_size)", "response": "Fits and predicts the logistic model."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting and transforms the logistic model.", "response": "def fit_transform(self,\n                      X,\n                      num_epochs=10,\n                      updates_epoch=10,\n                      stop_param_updates=dict(),\n                      batch_size=1,\n                      show_progressbar=False,\n                      show_epoch=False):\n        \"\"\"First fit, then transform.\"\"\"\n        self.fit(X,\n                 num_epochs,\n                 updates_epoch,\n                 stop_param_updates,\n                 batch_size,\n                 show_progressbar,\n                 show_epoch)\n\n        return self.transform(X, batch_size=batch_size)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _epoch(self,\n               X,\n               epoch_idx,\n               batch_size,\n               updates_epoch,\n               constants,\n               show_progressbar):\n        \"\"\"\n        Run a single epoch.\n\n        This function shuffles the data internally,\n        as this improves performance.\n\n        Parameters\n        ----------\n        X : numpy array\n            The training data.\n        epoch_idx : int\n            The current epoch\n        batch_size : int\n            The batch size\n        updates_epoch : int\n            The number of updates to perform per epoch\n        constants : dict\n            A dictionary containing the constants with which to update the\n            parameters in self.parameters.\n        show_progressbar : bool\n            Whether to show a progressbar during training.\n\n        \"\"\"\n        # Create batches\n        X_ = self._create_batches(X, batch_size)\n        X_len = np.prod(X.shape[:-1])\n\n        update_step = np.ceil(X_.shape[0] / updates_epoch)\n\n        # Initialize the previous activation\n        prev = self._init_prev(X_)\n        influences = self._update_params(constants)\n\n        # Iterate over the training data\n        for idx, x in enumerate(tqdm(X_, disable=not show_progressbar)):\n\n            # Our batches are padded, so we need to\n            # make sure we know when we hit the padding\n            # so we don't inadvertently learn zeroes.\n            diff = X_len - (idx * batch_size)\n            if diff and diff < batch_size:\n                x = x[:diff]\n                # Prev_activation may be None\n                if prev is not None:\n                    prev = prev[:diff]\n\n            # If we hit an update step, perform an update.\n            if idx % update_step == 0:\n                influences = self._update_params(constants)\n                logger.info(self.params)\n\n            prev = self._propagate(x,\n                                   influences,\n                                   prev_activation=prev)", "response": "This function runs a single epoch of the training data."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates params and return new influence.", "response": "def _update_params(self, constants):\n        \"\"\"Update params and return new influence.\"\"\"\n        for k, v in constants.items():\n            self.params[k]['value'] *= v\n\n        influence = self._calculate_influence(self.params['infl']['value'])\n        return influence * self.params['lr']['value']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_batches(self, X, batch_size, shuffle_data=True):\n        if shuffle_data:\n            X = shuffle(X)\n\n        if batch_size > X.shape[0]:\n            batch_size = X.shape[0]\n\n        max_x = int(np.ceil(X.shape[0] / batch_size))\n        X = np.resize(X, (max_x, batch_size, X.shape[-1]))\n\n        return X", "response": "Create batches out of a sequence of data."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npropagate a single batch of examples through the network.", "response": "def _propagate(self, x, influences, **kwargs):\n        \"\"\"Propagate a single batch of examples through the network.\"\"\"\n        activation, difference_x = self.forward(x)\n        update = self.backward(difference_x, influences, activation)\n        # If batch size is 1 we can leave out the call to mean.\n        if update.shape[0] == 1:\n            self.weights += update[0]\n        else:\n            self.weights += update.mean(0)\n\n        return activation"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backward(self, diff_x, influences, activations, **kwargs):\n        bmu = self._get_bmu(activations)\n        influence = influences[bmu]\n        update = np.multiply(diff_x, influence)\n        return update", "response": "This function is used to calculate the update of a set of updates to the input neurons."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _check_input(self, X):\n        if np.ndim(X) == 1:\n            X = np.reshape(X, (1, -1))\n\n        if X.ndim != 2:\n            raise ValueError(\"Your data is not a 2D matrix. \"\n                             \"Actual size: {0}\".format(X.shape))\n\n        if X.shape[1] != self.data_dimensionality:\n            raise ValueError(\"Your data size != weight dim: {0}, \"\n                             \"expected {1}\".format(X.shape[1],\n                                                   self.data_dimensionality))\n        return X", "response": "Check the input for validity."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef transform(self, X, batch_size=100, show_progressbar=False):\n        X = self._check_input(X)\n\n        batched = self._create_batches(X, batch_size, shuffle_data=False)\n\n        activations = []\n        prev = self._init_prev(batched)\n\n        for x in tqdm(batched, disable=not show_progressbar):\n            prev = self.forward(x, prev_activation=prev)[0]\n            activations.extend(prev)\n\n        activations = np.asarray(activations, dtype=np.float64)\n        activations = activations[:X.shape[0]]\n        return activations.reshape(X.shape[0], self.num_neurons)", "response": "Transform input to a distance matrix by measuring the L2 distance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npredicting the BMU for each input data point X.", "response": "def predict(self, X, batch_size=1, show_progressbar=False):\n        \"\"\"\n        Predict the BMU for each input data.\n\n        Parameters\n        ----------\n        X : numpy array.\n            The input data.\n        batch_size : int, optional, default 100\n            The batch size to use in prediction. This may affect prediction\n            in stateful, i.e. sequential SOMs.\n        show_progressbar : bool\n            Whether to show a progressbar during prediction.\n\n        Returns\n        -------\n        predictions : numpy array\n            An array containing the BMU for each input data point.\n\n        \"\"\"\n        dist = self.transform(X, batch_size, show_progressbar)\n        res = dist.__getattribute__(self.argfunc)(1)\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quantization_error(self, X, batch_size=1):\n        dist = self.transform(X, batch_size)\n        res = dist.__getattribute__(self.valfunc)(1)\n\n        return res", "response": "Calculates the quantization error for each data point in X."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(cls, path):\n        data = json.load(open(path))\n\n        weights = data['weights']\n        weights = np.asarray(weights, dtype=np.float64)\n\n        s = cls(data['num_neurons'],\n                data['data_dimensionality'],\n                data['params']['lr']['orig'],\n                neighborhood=data['params']['infl']['orig'],\n                valfunc=data['valfunc'],\n                argfunc=data['argfunc'],\n                lr_lambda=data['params']['lr']['factor'],\n                nb_lambda=data['params']['nb']['factor'])\n\n        s.weights = weights\n        s.trained = True\n\n        return s", "response": "Loads a SOM from a JSON file saved with this package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving a SOM to a JSON file.", "response": "def save(self, path):\n        \"\"\"Save a SOM to a JSON file.\"\"\"\n        to_save = {}\n        for x in self.param_names:\n            attr = self.__getattribute__(x)\n            if type(attr) == np.ndarray:\n                attr = [[float(x) for x in row] for row in attr]\n            elif isinstance(attr, types.FunctionType):\n                attr = attr.__name__\n            to_save[x] = attr\n\n        json.dump(to_save, open(path, 'w'))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_authversion(job_args):\n\n    _version = job_args.get('os_auth_version')\n    for version, variants in AUTH_VERSION_MAP.items():\n        if _version in variants:\n            authversion = job_args['os_auth_version'] = version\n            return authversion\n    else:\n        raise exceptions.AuthenticationProblem(\n            \"Auth Version must be one of %s.\",\n            list(AUTH_VERSION_MAP.keys())\n        )", "response": "Get or infer the auth version."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_headers(self):\n\n        try:\n            return {\n                'X-Auth-User': self.job_args['os_user'],\n                'X-Auth-Key': self.job_args['os_apikey']\n            }\n        except KeyError as exp:\n            raise exceptions.AuthenticationProblem(\n                'Missing Credentials. Error: %s',\n                exp\n            )", "response": "Setup headers for authentication request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the auth response and return the tenant token and username.", "response": "def parse_auth_response(auth_response):\n        \"\"\"Parse the auth response and return the tenant, token, and username.\n\n        :param auth_response: the full object returned from an auth call\n        :returns: ``dict``\n        \"\"\"\n\n        auth_dict = dict()\n        LOG.debug('Authentication Headers %s', auth_response.headers)\n        try:\n            auth_dict['os_token'] = auth_response.headers['x-auth-token']\n            auth_dict['storage_url'] = urlparse.urlparse(\n                auth_response.headers['x-storage-url']\n            )\n        except KeyError as exp:\n            raise exceptions.AuthenticationProblem(\n                'No token was found in the authentication response. Please'\n                ' check your auth URL, your credentials, and your set auth'\n                ' version. Auth Headers: [ %s ] Error: [ %s ]',\n                auth_response.headers,\n                exp\n            )\n        else:\n            return auth_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auth_request(self, url, headers, body):\n\n        return self.req.post(url, headers, body=body)", "response": "Perform auth request for token."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the request type of the user.", "response": "def parse_reqtype(self):\n        \"\"\"Return the authentication body.\"\"\"\n\n        if self.job_args['os_auth_version'] == 'v1.0':\n            return dict()\n        else:\n            setup = {\n                'username': self.job_args.get('os_user')\n            }\n\n            # Check if any prefix items are set. A prefix should be a\n            #  dictionary with keys matching the os_* credential type.\n            prefixes = self.job_args.get('os_prefix')\n\n            if self.job_args.get('os_token') is not None:\n                auth_body = {\n                    'auth': {\n                        'token': {\n                            'id': self.job_args.get('os_token')\n                        }\n                    }\n                }\n                if not self.job_args.get('os_tenant'):\n                    raise exceptions.AuthenticationProblem(\n                        'To use token auth you must specify the tenant id. Set'\n                        ' the tenant ID with [ --os-tenant ]'\n                    )\n            elif self.job_args.get('os_password') is not None:\n                setup['password'] = self.job_args.get('os_password')\n                if prefixes:\n                    prefix = prefixes.get('os_password')\n                    if not prefix:\n                        raise NotImplementedError(\n                            'the `password` method is not implemented for this'\n                            ' auth plugin'\n                        )\n                else:\n                    prefix = 'passwordCredentials'\n                auth_body = {\n                    'auth': {\n                        prefix: setup\n                    }\n                }\n            elif self.job_args.get('os_apikey') is not None:\n                setup['apiKey'] = self.job_args.get('os_apikey')\n                if prefixes:\n                    prefix = prefixes.get('os_apikey')\n                    if not prefix:\n                        raise NotImplementedError(\n                            'the `apikey` method is not implemented for this'\n                            ' auth plugin'\n                        )\n                else:\n                    prefix = 'apiKeyCredentials'\n                auth_body = {\n                    'auth': {\n                        prefix: setup\n                    }\n                }\n            else:\n                raise exceptions.AuthenticationProblem(\n                    'No Password, APIKey, or Token Specified'\n                )\n\n            if self.job_args.get('os_tenant'):\n                auth = auth_body['auth']\n                auth['tenantName'] = self.job_args.get('os_tenant')\n\n            LOG.debug('AUTH Request body: [ %s ]', auth_body)\n            return auth_body"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_auth_response(self, auth_response):\n\n        auth_dict = dict()\n        auth_response = auth_response.json()\n        LOG.debug('Authentication Response Body [ %s ]', auth_response)\n\n        access = auth_response.get('access')\n        access_token = access.get('token')\n        access_tenant = access_token.get('tenant')\n        access_user = access.get('user')\n\n        auth_dict['os_token'] = access_token.get('id')\n        auth_dict['os_tenant'] = access_tenant.get('name')\n        auth_dict['os_user'] = access_user.get('name')\n\n        if not auth_dict['os_token']:\n            raise exceptions.AuthenticationProblem(\n                'When attempting to grab the tenant or user nothing was'\n                ' found. No Token Found to Parse. Here is the DATA: [ %s ]'\n                ' Stack Trace [ %s ]',\n                auth_response,\n                traceback.format_exc()\n            )\n\n        region = self.job_args.get('os_region')\n        print(region)\n        if not region:\n            raise exceptions.SystemProblem('No Region Set')\n\n        service_catalog = access.pop('serviceCatalog')\n\n        # Get the storage URL\n        object_endpoints = self._service_endpoints(\n            service_catalog=service_catalog,\n            types_list=turbolift.__srv_types__\n        )\n\n        # In the legacy internal flag is set override the os_endpoint_type\n        #  TODO(cloudnull) Remove this in future releases\n        if 'internal' in self.job_args and self.job_args['internal']:\n            LOG.warn(\n                'The use of the ``--internal`` flag has been deprecated and'\n                ' will be removed in future releases. Please use the'\n                ' ``--os-endpoint-type`` flag and set the type name'\n                ' instead. In the case of using snet (service net) this is'\n                ' generally noted as \"internalURL\". Example setting:'\n                ' ``--os-endpoint-type internalURL``'\n            )\n            self.job_args['os_endpoint_type'] = 'internalURL'\n\n        auth_dict['storage_url'] = get_service_url(\n            region=region,\n            endpoint_list=object_endpoints,\n            lookup=self.job_args['os_endpoint_type']\n        )\n\n        # Get the CDN URL\n        cdn_endpoints = self._service_endpoints(\n            service_catalog=service_catalog, types_list=turbolift.__cdn_types__\n        )\n\n        if cdn_endpoints:\n            auth_dict['cdn_storage_url'] = get_service_url(\n                region=region,\n                endpoint_list=cdn_endpoints,\n                lookup=self.job_args['cdn_endpoint_type']\n            )\n\n        return auth_dict", "response": "Parse the auth response and return the tenant token and username."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npull region information from context.", "response": "def parse_region(self):\n        \"\"\"Pull region/auth url information from context.\"\"\"\n\n        try:\n            auth_url = self.job_args['os_auth_url']\n            if 'tokens' not in auth_url:\n                if not auth_url.endswith('/'):\n                    auth_url = '%s/' % auth_url\n                auth_url = urlparse.urljoin(auth_url, 'tokens')\n            return auth_url\n        except KeyError:\n            raise exceptions.AuthenticationProblem(\n                'You Are required to specify an Auth URL, Region or Plugin'\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, log_file, msg):\n        try:\n            with open(log_file, 'a') as LogFile:\n                LogFile.write(msg + os.linesep)\n        except:\n            raise Exception('Error Configuring PyLogger.TextStorage Class.')\n\n        return os.path.isfile(log_file)", "response": "Append message to. log file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(self, log_file):\n        if os.path.isdir(os.path.dirname(log_file)) and os.path.isfile(log_file):\n            with open(log_file, 'r') as LogFile:\n                data = LogFile.readlines()\n                data = \"\".join(line for line in data)\n        else:\n            data = ''\n        return data", "response": "Read the log file and return the data as a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fit(self, X):\n        if X.ndim > 2:\n            X = X.reshape((np.prod(X.shape[:-1]), X.shape[-1]))\n        self.mean = X.mean(0)\n        self.std = X.std(0)\n        self.is_fit = True\n        return self", "response": "Fit the scaler based on some data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef transform(self, X):\n        if not self.is_fit:\n            raise ValueError(\"The scaler has not been fit yet.\")\n        return (X-self.mean) / (self.std + 10e-7)", "response": "Transform your data to zero mean unit variance."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretries calling the decorated function using an exponential backoff. http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/ original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry :param ExceptionToCheck: the exception to check. may be a tuple of exceptions to check :type ExceptionToCheck: Exception or tuple :param tries: number of times to try (not retry) before giving up :type tries: int :param delay: initial delay between retries in seconds :type delay: int :param backoff: backoff multiplier e.g. value of 2 will double the delay each retry :type backoff: int", "response": "def retry(ExceptionToCheck, tries=3, delay=1, backoff=1):\n    \"\"\"Retry calling the decorated function using an exponential backoff.\n\n    http://www.saltycrane.com/blog/2009/11/trying-out-retry-decorator-python/\n    original from: http://wiki.python.org/moin/PythonDecoratorLibrary#Retry\n\n    :param ExceptionToCheck: the exception to check. may be a tuple of\n                             exceptions to check\n    :type ExceptionToCheck: Exception or tuple\n    :param tries: number of times to try (not retry) before giving up\n    :type tries: int\n    :param delay: initial delay between retries in seconds\n    :type delay: int\n    :param backoff: backoff multiplier e.g. value of 2 will double the delay\n                    each retry\n    :type backoff: int\n    \"\"\"\n    def deco_retry(f):\n        @functools.wraps(f)\n        def f_retry(*args, **kwargs):\n            mtries, mdelay = tries, delay\n            while mtries > 1:\n                try:\n                    return f(*args, **kwargs)\n                except ExceptionToCheck:\n                    time.sleep(mdelay)\n                    mtries -= 1\n                    mdelay *= backoff\n            return f(*args, **kwargs)\n        return f_retry  # true decorator\n    return deco_retry"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stupid_hack(most=10, wait=None):\n\n    # Stupid Hack For Public Cloud so it is not overwhelmed with API requests.\n    if wait is not None:\n        time.sleep(wait)\n    else:\n        time.sleep(random.randrange(1, most))", "response": "Return a random time between 1 - 10 Seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of dictionaries which are sorted for only unique entries.", "response": "def unique_list_dicts(dlist, key):\n    \"\"\"Return a list of dictionaries which are sorted for only unique entries.\n\n    :param dlist:\n    :param key:\n    :return list:\n    \"\"\"\n\n    return list(dict((val[key], val) for val in dlist).values())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quoter(obj):\n\n    try:\n        try:\n            return urllib.quote(obj)\n        except AttributeError:\n            return urllib.parse.quote(obj)\n    except KeyError:\n        return obj", "response": "Return a Quoted URL."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nclone objects from one container to another. This method was built to clone a container between data-centers while using the same credentials. The method assumes that an authentication token will be valid within the two data centers.", "response": "def start(self):\n        \"\"\"Clone objects from one container to another.\n\n        This method was built to clone a container between data-centers while\n        using the same credentials. The method assumes that an authentication\n        token will be valid within the two data centers.\n        \"\"\"\n\n        LOG.info('Clone warm up...')\n        # Create the target args\n        self._target_auth()\n\n        last_list_obj = None\n        while True:\n            self.indicator_options['msg'] = 'Gathering object list'\n            with indicator.Spinner(**self.indicator_options):\n                objects_list = self._list_contents(\n                    single_page_return=True,\n                    last_obj=last_list_obj\n                )\n                if not objects_list:\n                    return\n\n            last_obj = utils.byte_encode(objects_list[-1].get('name'))\n            LOG.info(\n                'Last object [ %s ] Last object in the list [ %s ]',\n                last_obj,\n                last_list_obj\n            )\n            if last_list_obj == last_obj:\n                return\n            else:\n                last_list_obj = last_obj\n                self._clone_worker(objects_list=objects_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nauthenticates for Openstack API.", "response": "def authenticate(job_args):\n    \"\"\"Authentication For Openstack API.\n\n    Pulls the full Openstack Service Catalog Credentials are the Users API\n    Username and Key/Password.\n\n    Set a DC Endpoint and Authentication URL for the OpenStack environment\n    \"\"\"\n\n    # Load any authentication plugins as needed\n    job_args = utils.check_auth_plugin(job_args)\n\n    # Set the auth version\n    auth_version = utils.get_authversion(job_args=job_args)\n\n    # Define the base headers that are used in all authentications\n    auth_headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n\n    auth_headers.update(job_args['base_headers'])\n\n    if auth_version == 'v1.0':\n        auth = utils.V1Authentication(job_args=job_args)\n        auth_headers.update(auth.get_headers())\n        LOG.debug('Request Headers: [ %s ]', auth_headers)\n\n        auth_url = job_args['os_auth_url']\n        LOG.debug('Parsed Auth URL: [ %s ]', auth_url)\n\n        auth_kwargs = {\n            'url': auth_url,\n            'headers': auth_headers\n        }\n    else:\n        auth = utils.OSAuthentication(job_args=job_args)\n        auth_url = auth.parse_region()\n        LOG.debug('Parsed Auth URL: [ %s ]', auth_url)\n\n        auth_json = auth.parse_reqtype()\n        LOG.debug('Request Headers: [ %s ]', auth_headers)\n\n        auth_body = json.dumps(auth_json)\n        LOG.debug('Request JSON: [ %s ]', auth_body)\n\n        auth_kwargs = {\n            'url': auth_url,\n            'headers': auth_headers,\n            'body': auth_body\n        }\n\n    auth_resp = auth.auth_request(**auth_kwargs)\n    if auth_resp.status_code >= 300:\n        raise exceptions.AuthenticationProblem(\n            'Authentication Failure, Status: [ %s ] Reason: [ %s ]',\n            auth_resp.status_code,\n            auth_resp.reason\n        )\n    else:\n        return auth.parse_auth_response(auth_resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _config(self, **kargs):\n        for key, value in kargs.items():\n            setattr(self, key, value)", "response": "Reconfigure the base class"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Config Value", "response": "def getConfig(self, key):\n        \"\"\" Get a Config Value \"\"\"\n        if hasattr(self, key):\n            return getattr(self, key)\n        else:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addFilter(self, filter):\n        self.FILTERS.append(filter)\n        return \"FILTER#{}\".format(len(self.FILTERS) - 1)", "response": "Register a custom filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the Mailer class", "response": "def _configMailer(self):\n        \"\"\" Config Mailer Class \"\"\"\n        self._MAILER = Mailer(self.MAILER_HOST, self.MAILER_PORT)\n        self._MAILER.login(self.MAILER_USER, self.MAILER_PWD)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending Alert Message To Emails", "response": "def _sendMsg(self, type, msg):\n        \"\"\" Send Alert Message To Emails \"\"\"\n        if self.ALERT_STATUS and type in self.ALERT_TYPES:\n            self._configMailer()\n            self._MAILER.send(self.MAILER_FROM, self.ALERT_EMAIL, self.ALERT_SUBJECT, msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auth_plugins(auth_plugins=None):\n\n    __auth_plugins__ = {\n        'os_rax_auth': {\n            'os_auth_url': 'https://identity.api.rackspacecloud.com/v2.0/'\n                           'tokens',\n            'os_prefix': {\n                'os_apikey': 'RAX-KSKEY:apiKeyCredentials',\n                'os_password': 'passwordCredentials'\n            },\n            'args': {\n                'commands': [\n                    '--os-rax-auth'\n                ],\n                'choices': [\n                    'dfw',\n                    'ord',\n                    'iad',\n                    'syd',\n                    'hkg',\n                    'lon'\n                ],\n                'help': 'Authentication Plugin for Rackspace Cloud'\n                        ' env[OS_RAX_AUTH]',\n                'default': os.environ.get('OS_RAX_AUTH', None),\n                'metavar': '[REGION]'\n            }\n        },\n        'rax_auth_v1': {\n            'os_auth_version': 'v1.0',\n            'os_auth_url': 'https://identity.api.rackspacecloud.com/v1.0',\n            'args': {\n                'commands': [\n                    '--rax-auth-v1'\n                ],\n                'action': 'store_true',\n                'help': 'Authentication Plugin for Rackspace Cloud V1'\n            }\n        },\n        'os_rax_auth_lon': {\n            'os_auth_url': 'https://lon.identity.api.rackspacecloud.com/'\n                           'v2.0/tokens',\n            'os_prefix': {\n                'os_apikey': 'RAX-KSKEY:apiKeyCredentials',\n                'os_password': 'passwordCredentials'\n            },\n            'args': {\n                'commands': [\n                    '--os-rax-auth-lon'\n                ],\n                'choices': [\n                    'lon'\n                ],\n                'help': 'Authentication Plugin for Rackspace Cloud'\n                        ' env[OS_RAX_AUTH_LON]',\n                'default': os.environ.get('OS_RAX_AUTH_LON', None),\n                'metavar': '[REGION]'\n            }\n        },\n        'os_hp_auth': {\n            'os_auth_url': 'https://%(region)s.identity.hpcloudsvc.com:35357/'\n                           'v2.0/tokens',\n            'os_prefix': {\n                'os_password': 'passwordCredentials'\n            },\n            'args': {\n                'commands': [\n                    '--os-hp-auth'\n                ],\n                'choices': [\n                    'region-b.geo-1',\n                    'region-a.geo-1'\n                ],\n                'help': 'Authentication Plugin for HP Cloud'\n                        ' env[OS_HP_AUTH]',\n                'default': os.environ.get('OS_HP_AUTH', None),\n                'metavar': '[REGION]'\n            }\n        }\n    }\n    if auth_plugins:\n        __auth_plugins__.update(auth_plugins)\n\n    return __auth_plugins__", "response": "Add any authentication plugins to the base auth_plugins dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_basestring(item):\n    try:\n        return isinstance(item, (basestring, unicode))\n    except NameError:\n        return isinstance(item, str)", "response": "Check if item is a string"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef predict_distance(self, X, batch_size=1, show_progressbar=False):\n        X = self._check_input(X)\n\n        X_shape = reduce(np.multiply, X.shape[:-1], 1)\n\n        batched = self._create_batches(X, batch_size, shuffle_data=False)\n\n        activations = []\n\n        activation = self._init_prev(batched)\n\n        for x in tqdm(batched, disable=not show_progressbar):\n            activation = self.forward(x, prev_activation=activation)[0]\n            activations.append(activation)\n\n        act = np.asarray(activations, dtype=np.float64).transpose((1, 0, 2))\n        act = act[:X_shape]\n        return act.reshape(X_shape, self.num_neurons)", "response": "Predict distances to some input data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate(self, num_to_generate, starting_place):\n        res = []\n        activ = starting_place[None, :]\n        index = activ.__getattribute__(self.argfunc)(1)\n        item = self.weights[index]\n        for x in range(num_to_generate):\n            activ = self.forward(item, prev_activation=activ)[0]\n            index = activ.__getattribute__(self.argfunc)(1)\n            res.append(index)\n            item = self.weights[index]\n\n        return res", "response": "Generate data based on some initial position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming a forward pass through the network.", "response": "def forward(self, x, **kwargs):\n        \"\"\"\n        Perform a forward pass through the network.\n\n        The forward pass in recursive som is based on a combination between\n        the activation in the last time-step and the current time-step.\n\n        Parameters\n        ----------\n        x : numpy array\n            The input data.\n        prev_activation : numpy array.\n            The activation of the network in the previous time-step.\n\n        Returns\n        -------\n        activations : tuple of activations and differences\n            A tuple containing the activation of each unit, the differences\n            between the weights and input and the differences between the\n            context input and context weights.\n\n        \"\"\"\n        prev = kwargs['prev_activation']\n\n        # Differences is the components of the weights subtracted from\n        # the weight vector.\n        distance_x, diff_x = self.distance_function(x, self.weights)\n        distance_y, diff_y = self.distance_function(prev, self.context_weights)\n\n        x_ = distance_x * self.alpha\n        y_ = distance_y * self.beta\n        activation = np.exp(-(x_ + y_))\n\n        return activation, diff_x, diff_y"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(cls, path):\n        data = json.load(open(path))\n\n        weights = data['weights']\n        weights = np.asarray(weights, dtype=np.float64)\n\n        try:\n            context_weights = data['context_weights']\n            context_weights = np.asarray(context_weights,\n                                         dtype=np.float64)\n        except KeyError:\n            context_weights = np.zeros((len(weights), len(weights)))\n\n        try:\n            alpha = data['alpha']\n            beta = data['beta']\n        except KeyError:\n            alpha = 1.0\n            beta = 1.0\n\n        s = cls(data['map_dimensions'],\n                data['data_dimensionality'],\n                data['params']['lr']['orig'],\n                influence=data['params']['infl']['orig'],\n                alpha=alpha,\n                beta=beta,\n                lr_lambda=data['params']['lr']['factor'],\n                infl_lambda=data['params']['infl']['factor'])\n\n        s.weights = weights\n        s.context_weights = context_weights\n        s.trained = True\n\n        return s", "response": "Loads a recursive SOM from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef backward(self, diff_x, influences, activations, **kwargs):\n        diff_y = kwargs['diff_y']\n        bmu = self._get_bmu(activations)\n        influence = influences[bmu]\n\n        # Update\n        x_update = np.multiply(diff_x, influence)\n        y_update = np.multiply(diff_y, influence)\n\n        return x_update, y_update", "response": "This function is used to calculate the updates to the input and output neurons."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of objects from the API for a container.", "response": "def start(self):\n        \"\"\"Return a list of objects from the API for a container.\"\"\"\n        LOG.info('Listing options...')\n        with indicator.Spinner(**self.indicator_options):\n            objects_list = self._list_contents()\n            if not objects_list:\n                return\n\n        if isinstance(objects_list[0], dict):\n            filter_dlo = self.job_args.get('filter_dlo')\n            if filter_dlo:\n                dynamic_hash = hashlib.sha256(\n                    self.job_args.get('container')\n                )\n                dynamic_hash = dynamic_hash.hexdigest()\n                objects_list = [\n                    i for i in objects_list\n                    if dynamic_hash not in i.get('name')\n                ]\n            string_filter = self.job_args.get('filter')\n            if string_filter:\n                objects_list = [\n                    i for i in objects_list\n                    if string_filter in i.get('name')\n                ]\n            self.print_horiz_table(objects_list)\n        else:\n            self.print_virt_table(objects_list[0].headers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _return_base_data(self, url, container, container_object=None,\n                          container_headers=None, object_headers=None):\n        \"\"\"Return headers and a parsed url.\n\n        :param url:\n        :param container:\n        :param container_object:\n        :param container_headers:\n        :return: ``tuple``\n        \"\"\"\n        headers = self.job_args['base_headers']\n        headers.update({'X-Auth-Token': self.job_args['os_token']})\n\n        _container_uri = url.geturl().rstrip('/')\n\n        if container:\n            _container_uri = '%s/%s' % (\n                _container_uri, cloud_utils.quoter(container)\n            )\n\n        if container_object:\n            _container_uri = '%s/%s' % (\n                _container_uri, cloud_utils.quoter(container_object)\n            )\n\n        if object_headers:\n            headers.update(object_headers)\n\n        if container_headers:\n            headers.update(container_headers)\n\n        return headers, urlparse.urlparse(_container_uri)", "response": "Return headers and a parsed url."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake many PUT request for a single chunked object. Objects that are processed by this method have a SHA256 hash appended to the name as well as a count for object indexing which starts at 0. To make a PUT request pass, ``url`` :param uri: ``str`` :param open_file: ``object`` :param headers: ``dict``", "response": "def _chunk_putter(self, uri, open_file, headers=None):\n        \"\"\"Make many PUT request for a single chunked object.\n\n        Objects that are processed by this method have a SHA256 hash appended\n        to the name as well as a count for object indexing which starts at 0.\n\n        To make a PUT request pass, ``url``\n\n        :param uri: ``str``\n        :param open_file: ``object``\n        :param headers: ``dict``\n        \"\"\"\n        count = 0\n        dynamic_hash = hashlib.sha256(self.job_args.get('container'))\n        dynamic_hash = dynamic_hash.hexdigest()\n        while True:\n            # Read in a chunk of an open file\n            file_object = open_file.read(self.job_args.get('chunk_size'))\n            if not file_object:\n                break\n\n            # When a chuck is present store it as BytesIO\n            with io.BytesIO(file_object) as file_object:\n                # store the parsed URI for the chunk\n                chunk_uri = urlparse.urlparse(\n                    '%s.%s.%s' % (\n                        uri.geturl(),\n                        dynamic_hash,\n                        count\n                    )\n                )\n\n                # Increment the count as soon as it is used\n                count += 1\n\n                # Check if the read chunk already exists\n                sync = self._sync_check(\n                    uri=chunk_uri,\n                    headers=headers,\n                    file_object=file_object\n                )\n                if not sync:\n                    continue\n\n                # PUT the chunk\n                _resp = self.http.put(\n                    url=chunk_uri,\n                    body=file_object,\n                    headers=headers\n                )\n                self._resp_exception(resp=_resp)\n                LOG.debug(_resp.__dict__)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplaces object into the container.", "response": "def _putter(self, uri, headers, local_object=None):\n        \"\"\"Place  object into the container.\n\n        :param uri:\n        :param headers:\n        :param local_object:\n        \"\"\"\n\n        if not local_object:\n            return self.http.put(url=uri, headers=headers)\n\n        with open(local_object, 'rb') as f_open:\n            large_object_size = self.job_args.get('large_object_size')\n            if not large_object_size:\n                large_object_size = 5153960756\n\n            if os.path.getsize(local_object) > large_object_size:\n                # Remove the manifest entry while working with chunks\n                manifest = headers.pop('X-Object-Manifest')\n                # Feed the open file through the chunk process\n                self._chunk_putter(\n                    uri=uri,\n                    open_file=f_open,\n                    headers=headers\n                )\n                # Upload the 0 byte object with the manifest path\n                headers.update({'X-Object-Manifest': manifest})\n                return self.http.put(url=uri, headers=headers)\n            else:\n                if self.job_args.get('sync'):\n                    sync = self._sync_check(\n                        uri=uri,\n                        headers=headers,\n                        local_object=local_object\n                    )\n                    if not sync:\n                        return None\n\n                return self.http.put(\n                    url=uri, body=f_open, headers=headers\n                )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _getter(self, uri, headers, local_object):\n\n        if self.job_args.get('sync'):\n            sync = self._sync_check(\n                uri=uri,\n                headers=headers,\n                local_object=local_object\n            )\n            if not sync:\n                return None\n\n        # perform Object HEAD request\n        resp = self.http.get(url=uri, headers=headers)\n        self._resp_exception(resp=resp)\n\n        # Open our source file and write it\n        chunk_size = self.job_args['download_chunk_size']\n        with open(local_object, 'wb') as f_name:\n            for chunk in resp.iter_content(chunk_size=chunk_size):\n                if chunk:\n                    f_name.write(chunk)\n                    f_name.flush()\n\n        if self.job_args.get('restore_perms'):\n            if 'X-Object-Meta-perms' in resp.headers:\n                os.chmod(\n                    local_object,\n                    int(resp.headers['x-object-meta-perms'], 8)\n                )\n\n            chown_file = {'uid': -1, 'gid': -1}\n            if 'X-Object-Meta-owner' in resp.headers:\n                chown_file['uid'] = pwd.getpwnam(\n                    resp.headers['X-Object-Meta-owner']\n                ).pw_uid\n            if 'X-Object-Meta-group' in resp.headers:\n                chown_file['gid'] = grp.getgrnam(\n                    resp.headers['X-Object-Meta-group']\n                ).gr_gid\n            os.chown(local_object, *chown_file.values())\n\n        return resp", "response": "Perform HEAD request on a specified object in the container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _deleter(self, uri, headers):\n\n        # perform Object HEAD request\n        resp = self.http.delete(url=uri, headers=headers)\n        self._resp_exception(resp=resp)\n        return resp", "response": "Perform a HEAD request on a specified object in the container."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nperform HEAD request on a specified object in the container.", "response": "def _header_getter(self, uri, headers):\n        \"\"\"Perform HEAD request on a specified object in the container.\n\n        :param uri: ``str``\n        :param headers: ``dict``\n        \"\"\"\n\n        # perform Object HEAD request\n        resp = self.http.head(url=uri, headers=headers)\n        self._resp_exception(resp=resp)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nposts Headers on a specified object in the container.", "response": "def _header_poster(self, uri, headers):\n        \"\"\"POST Headers on a specified object in the container.\n\n        :param uri: ``str``\n        :param headers: ``dict``\n        \"\"\"\n\n        resp = self.http.post(url=uri, body=None, headers=headers)\n        self._resp_exception(resp=resp)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _obj_index(self, uri, base_path, marked_path, headers, spr=False):\n        object_list = list()\n        l_obj = None\n        container_uri = uri.geturl()\n\n        while True:\n            marked_uri = urlparse.urljoin(container_uri, marked_path)\n            resp = self.http.get(url=marked_uri, headers=headers)\n            self._resp_exception(resp=resp)\n            return_list = resp.json()\n            if spr:\n                return return_list\n\n            time_offset = self.job_args.get('time_offset')\n            for obj in return_list:\n                if time_offset:\n                    # Get the last_modified data from the Object.\n                    time_delta = cloud_utils.TimeDelta(\n                        job_args=self.job_args,\n                        last_modified=time_offset\n                    )\n                    if time_delta:\n                        object_list.append(obj)\n                else:\n                    object_list.append(obj)\n\n            if object_list:\n                last_obj_in_list = object_list[-1].get('name')\n            else:\n                last_obj_in_list = None\n\n            if l_obj == last_obj_in_list:\n                return object_list\n            else:\n                l_obj = last_obj_in_list\n                marked_path = self._last_marker(\n                    base_path=base_path,\n                    last_object=l_obj\n                )", "response": "Return an index of objects from within the container."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _list_getter(self, uri, headers, last_obj=None, spr=False):\n\n        # Quote the file path.\n        base_path = marked_path = ('%s?limit=10000&format=json' % uri.path)\n\n        if last_obj:\n            marked_path = self._last_marker(\n                base_path=base_path,\n                last_object=cloud_utils.quoter(last_obj)\n            )\n\n        file_list = self._obj_index(\n            uri=uri,\n            base_path=base_path,\n            marked_path=marked_path,\n            headers=headers,\n            spr=spr\n        )\n\n        LOG.debug(\n            'Found [ %d ] entries(s) at [ %s ]',\n            len(file_list),\n            uri.geturl()\n        )\n\n        if spr:\n            return file_list\n        else:\n            return cloud_utils.unique_list_dicts(\n                dlist=file_list, key='name'\n            )", "response": "Get a list of all objects in a container."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _resp_exception(self, resp):\n\n        message = [\n            'Url: [ %s ] Reason: [ %s ] Request: [ %s ] Status Code: [ %s ]. ',\n            resp.url,\n            resp.reason,\n            resp.request,\n            resp.status_code\n        ]\n\n        # Check to make sure we have all the bits needed\n        if not hasattr(resp, 'status_code'):\n            message[0] += 'No Status to check. Turbolift will retry...'\n            raise exceptions.SystemProblem(message)\n        elif resp is None:\n            message[0] += 'No response information. Turbolift will retry...'\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code == 401:\n            message[0] += (\n                'Turbolift experienced an Authentication issue. Turbolift'\n                ' will retry...'\n            )\n            self.job_args.update(auth.authenticate(self.job_args))\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code == 404:\n            message[0] += 'Item not found.'\n            LOG.debug(*message)\n        elif resp.status_code == 409:\n            message[0] += (\n                'Request Conflict. Turbolift is abandoning this...'\n            )\n        elif resp.status_code == 413:\n            return_headers = resp.headers\n            retry_after = return_headers.get('retry_after', 10)\n            cloud_utils.stupid_hack(wait=retry_after)\n            message[0] += (\n                'The System encountered an API limitation and will'\n                ' continue in [ %s ] Seconds' % retry_after\n            )\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code == 502:\n            message[0] += (\n                'Failure making Connection. Turbolift will retry...'\n            )\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code == 503:\n            cloud_utils.stupid_hack(wait=10)\n            message[0] += 'SWIFT-API FAILURE'\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code == 504:\n            cloud_utils.stupid_hack(wait=10)\n            message[0] += 'Gateway Failure.'\n            raise exceptions.SystemProblem(message)\n        elif resp.status_code >= 300:\n            message[0] += 'General exception.'\n            raise exceptions.SystemProblem(message)\n        else:\n            LOG.debug(*message)", "response": "Check if we encounter an exception in our upload."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a long list of objects found in a container.", "response": "def list_items(self, url, container=None, last_obj=None, spr=False):\n        \"\"\"Builds a long list of objects found in a container.\n\n        NOTE: This could be millions of Objects.\n\n        :param url:\n        :param container:\n        :param last_obj:\n        :param spr: \"single page return\" Limit the returned data to one page\n        :type spr: ``bol``\n        :return None | list:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container\n        )\n\n        if container:\n            resp = self._header_getter(uri=container_uri, headers=headers)\n            if resp.status_code == 404:\n                LOG.info('Container [ %s ] not found.', container)\n                return [resp]\n\n        return self._list_getter(\n            uri=container_uri,\n            headers=headers,\n            last_obj=last_obj,\n            spr=spr\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_object(self, url, container, container_object, object_headers,\n                      container_headers):\n        \"\"\"Update an existing object in a swift container.\n\n        This method will place new headers on an existing object or container.\n\n        :param url:\n        :param container:\n        :param container_object:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_object=container_object,\n            container_headers=container_headers,\n            object_headers=object_headers,\n        )\n\n        return self._header_poster(\n            uri=container_uri,\n            headers=headers\n        )", "response": "Update an existing object in a swift container."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef container_cdn_command(self, url, container, container_object,\n                              cdn_headers):\n        \"\"\"Command your CDN enabled Container.\n\n        :param url:\n        :param container:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_object=container_object,\n            object_headers=cdn_headers\n        )\n\n        if self.job_args.get('purge'):\n            return self._deleter(\n                uri=container_uri,\n                headers=headers\n            )\n        else:\n            return self._header_poster(\n                uri=container_uri,\n                headers=headers\n            )", "response": "Command your CDN enabled Container."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a container if it is not Found.", "response": "def put_container(self, url, container, container_headers=None):\n        \"\"\"Create a container if it is not Found.\n\n        :param url:\n        :param container:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_headers=container_headers\n        )\n\n        resp = self._header_getter(\n            uri=container_uri,\n            headers=headers\n        )\n        if resp.status_code == 404:\n            return self._putter(uri=container_uri, headers=headers)\n        else:\n            return resp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef put_object(self, url, container, container_object, local_object,\n                   object_headers, meta=None):\n        \"\"\"This is the Sync method which uploads files to the swift repository\n\n        if they are not already found. If a file \"name\" is found locally and\n        in the swift repository an MD5 comparison is done between the two\n        files. If the MD5 is miss-matched the local file is uploaded to the\n        repository. If custom meta data is specified, and the object exists the\n        method will put the metadata onto the object.\n\n        :param url:\n        :param container:\n        :param container_object:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_object=container_object,\n            container_headers=object_headers,\n            object_headers=meta\n        )\n\n        return self._putter(\n            uri=container_uri,\n            headers=headers,\n            local_object=local_object\n        )", "response": "This method uploads files to the swift repository and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an objects from a container.", "response": "def get_items(self, url, container, container_object, local_object):\n        \"\"\"Get an objects from a container.\n\n        :param url:\n        :param container:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_object=container_object\n        )\n\n        return self._getter(\n            uri=container_uri,\n            headers=headers,\n            local_object=local_object\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete an object in a container.", "response": "def delete_items(self, url, container, container_object=None):\n        \"\"\"Deletes an objects in a container.\n\n        :param url:\n        :param container:\n        \"\"\"\n\n        headers, container_uri = self._return_base_data(\n            url=url,\n            container=container,\n            container_object=container_object\n        )\n\n        return self._deleter(uri=container_uri, headers=headers)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_bmu(self, activations):\n        # If the neural gas is a recursive neural gas, we need reverse argsort.\n        if self.argfunc == 'argmax':\n            activations = -activations\n        sort = np.argsort(activations, 1)\n        return sort.argsort()", "response": "Get indices of bmus sorted by their distance from input."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calculate_influence(self, influence_lambda):\n        return np.exp(-np.arange(self.num_neurons) / influence_lambda)[:, None]", "response": "Calculate the ranking influence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of objects from the API for a container.", "response": "def start(self):\n        \"\"\"Return a list of objects from the API for a container.\"\"\"\n        LOG.info('Listing options...')\n        with indicator.Spinner(**self.indicator_options):\n            objects_list = self._list_contents()\n            if not objects_list:\n                return\n\n        # Index items\n        self._index_objects(objects_list=objects_list)\n        # Create the underlying structure\n        self._make_directory_structure()\n\n        # Download everything\n        LOG.debug('Download Items: %s', self.download_items)\n        self._multi_processor(\n            self._get,\n            items=[i for i in self.download_items.values() for i in i]\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a single epoch. This function shuffles the data internally, as this improves performance. Parameters ---------- X : numpy array The training data. epoch_idx : int The current epoch batch_size : int The batch size updates_epoch : int The number of updates to perform per epoch constants : dict A dictionary containing the constants with which to update the parameters in self.parameters. show_progressbar : bool Whether to show a progressbar during training.", "response": "def _epoch(self,\n               X,\n               epoch_idx,\n               batch_size,\n               updates_epoch,\n               constants,\n               show_progressbar):\n        \"\"\"\n        Run a single epoch.\n\n        This function shuffles the data internally,\n        as this improves performance.\n\n        Parameters\n        ----------\n        X : numpy array\n            The training data.\n        epoch_idx : int\n            The current epoch\n        batch_size : int\n            The batch size\n        updates_epoch : int\n            The number of updates to perform per epoch\n        constants : dict\n            A dictionary containing the constants with which to update the\n            parameters in self.parameters.\n        show_progressbar : bool\n            Whether to show a progressbar during training.\n\n        \"\"\"\n        # Create batches\n        X_ = self._create_batches(X, batch_size)\n        X_len = np.prod(X.shape[:-1])\n\n        # Initialize the previous activation\n        prev = self._init_prev(X_)\n        prev = self.distance_function(X_[0], self.weights)[0]\n        influences = self._update_params(prev)\n\n        # Iterate over the training data\n        for idx, x in enumerate(tqdm(X_, disable=not show_progressbar)):\n\n            # Our batches are padded, so we need to\n            # make sure we know when we hit the padding\n            # so we don't inadvertently learn zeroes.\n            diff = X_len - (idx * batch_size)\n            if diff and diff < batch_size:\n                x = x[:diff]\n                # Prev_activation may be None\n                if prev is not None:\n                    prev = prev[:diff]\n\n            # if idx > 0 and idx % update_step == 0:\n            influences = self._update_params(prev)\n            prev = self._propagate(x,\n                                   influences,\n                                   prev_activation=prev)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calculate_influence(self, neighborhood):\n        n = (self.beta - 1) * np.log(1 + neighborhood*(np.e-1)) + 1\n        grid = np.exp((-self.distance_grid) / n**2)\n        return grid.reshape(self.num_neurons, self.num_neurons)[:, :, None]", "response": "Calculates the influence of a given neuron and a given neighborhood."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nshuffle a list of items in place.", "response": "def _shuffle_items(items, bucket_key=None, disable=None, seed=None, session=None):\n    \"\"\"\n    Shuffles a list of `items` in place.\n\n    If `bucket_key` is None, items are shuffled across the entire list.\n\n    `bucket_key` is an optional function called for each item in `items` to\n    calculate the key of bucket in which the item falls.\n\n    Bucket defines the boundaries across which items will not\n    be shuffled.\n\n    `disable` is a function that takes an item and returns a falsey value\n    if this item is ok to be shuffled. It returns a truthy value otherwise and\n    the truthy value is used as part of the item's key when determining the bucket\n    it belongs to.\n    \"\"\"\n\n    if seed is not None:\n        random.seed(seed)\n\n    # If `bucket_key` is falsey, shuffle is global.\n    if not bucket_key and not disable:\n        random.shuffle(items)\n        return\n\n    def get_full_bucket_key(item):\n        assert bucket_key or disable\n        if bucket_key and disable:\n            return ItemKey(bucket=bucket_key(item, session), disabled=disable(item, session))\n        elif disable:\n            return ItemKey(disabled=disable(item, session))\n        else:\n            return ItemKey(bucket=bucket_key(item, session))\n\n    # For a sequence of items A1, A2, B1, B2, C1, C2,\n    # where key(A1) == key(A2) == key(C1) == key(C2),\n    # items A1, A2, C1, and C2 will end up in the same bucket.\n    buckets = OrderedDict()\n    for item in items:\n        full_bucket_key = get_full_bucket_key(item)\n        if full_bucket_key not in buckets:\n            buckets[full_bucket_key] = []\n        buckets[full_bucket_key].append(item)\n\n    # Shuffle inside a bucket\n\n    bucket_keys = list(buckets.keys())\n\n    for full_bucket_key in buckets.keys():\n        if full_bucket_key.bucket == FAILED_FIRST_LAST_FAILED_BUCKET_KEY:\n            # Do not shuffle the last failed bucket\n            continue\n\n        if not full_bucket_key.disabled:\n            random.shuffle(buckets[full_bucket_key])\n\n    # Shuffle buckets\n\n    # Only the first bucket can be FAILED_FIRST_LAST_FAILED_BUCKET_KEY\n    if bucket_keys and bucket_keys[0].bucket == FAILED_FIRST_LAST_FAILED_BUCKET_KEY:\n        new_bucket_keys = list(buckets.keys())[1:]\n        random.shuffle(new_bucket_keys)\n        new_bucket_keys.insert(0, bucket_keys[0])\n    else:\n        new_bucket_keys = list(buckets.keys())\n        random.shuffle(new_bucket_keys)\n\n    items[:] = [item for bk in new_bucket_keys for item in buckets[bk]]\n    return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a function that calculates test item key for the specified bucket type.", "response": "def bucket_type_key(bucket_type):\n    \"\"\"\n    Registers a function that calculates test item key for the specified bucket type.\n    \"\"\"\n\n    def decorator(f):\n\n        @functools.wraps(f)\n        def wrapped(item, session):\n            key = f(item)\n\n            if session is not None:\n                for handler in session.random_order_bucket_type_key_handlers:\n                    key = handler(item, key)\n\n            return key\n\n        bucket_type_keys[bucket_type] = wrapped\n        return wrapped\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify_tokens(self):\n    xidentity = key_utils.get_compressed_public_key_from_pem(self.pem)\n    url = self.uri + \"/tokens\"\n    xsignature = key_utils.sign(self.uri + \"/tokens\", self.pem)\n    headers = {\"content-type\": \"application/json\", 'accept': 'application/json', 'X-Identity': xidentity, 'X-Signature': xsignature, 'X-accept-version': '2.0.0'}\n    response = requests.get(self.uri + \"/tokens\", headers=headers, verify=self.verify)\n    if response.ok:\n      allTokens = response.json()['data']\n      selfKeys = self.tokens.keys() \n      matchedTokens = [token for token in allTokens for key in selfKeys if token.get(key) == self.tokens.get(key)]\n      if not matchedTokens:\n        return False\n      return True", "response": "Verify that the tokens are valid"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef token_from_response(self, responseJson):\n    token = responseJson['data'][0]['token']\n    facade = responseJson['data'][0]['facade']\n    return {facade: token}\n    raise BitPayBitPayError('%(code)d: %(message)s' % {'code': response.status_code, 'message': response.json()['error']})", "response": "Returns a token from a response JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify that the invoice parameters are valid.", "response": "def verify_invoice_params(self, price, currency):\n    \"\"\"\n    Deprecated, will be made private in 2.4\n    \"\"\"\n    if re.match(\"^[A-Z]{3,3}$\", currency) is None:\n      raise BitPayArgumentError(\"Currency is invalid.\")\n    try: \n      float(price)\n    except:\n      raise BitPayArgumentError(\"Price must be formatted as a float\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unsigned_request(self, path, payload=None):\n    headers = {\"content-type\": \"application/json\", \"accept\": \"application/json\", \"X-accept-version\": \"2.0.0\"}\n    try:\n      if payload:\n        response = requests.post(self.uri + path, verify=self.verify, data=json.dumps(payload), headers=headers)\n      else:\n        response = requests.get(self.uri + path, verify=self.verify, headers=headers)\n    except Exception as pro:\n      raise BitPayConnectionError('Connection refused')\n    return response", "response": "generic bitpay usigned wrapper for GET and POST requests"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handle_rfx(sender, message):\n    # Check for our target serial number and loop\n    if message.serial_number == RF_DEVICE_SERIAL_NUMBER and message.loop[0] == True:\n        print(message.serial_number, 'triggered loop #1')", "response": "Handle RF messages from the AlarmDecoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fire(self, *args, **kwargs):\n\n        \"\"\"Fire event and call all handler functions\n\n        You can call EventHandler object itself like e(*args, **kwargs) instead of\n        e.fire(*args, **kwargs).\n        \"\"\"\n\n        for func in self._getfunctionlist():\n            if type(func) == EventHandler:\n                func.fire(*args, **kwargs)\n            else:\n                func(self.obj, *args, **kwargs)", "response": "Fire event and call all handler functions"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the raw message from the device and populates the internal state.", "response": "def _parse_message(self, data):\n        \"\"\"\n        Parses the raw message from the device.\n\n        :param data: message data\n        :type data: string\n\n        :raises: :py:class:`~alarmdecoder.util.InvalidMessageError`\n        \"\"\"\n        try:\n            _, values = data.split(':')\n            self.serial_number, self.value = values.split(',')\n            self.value = int(self.value, 16)\n\n            is_bit_set = lambda b: self.value & (1 << (b - 1)) > 0\n\n            # Bit 1 = unknown\n            self.battery = is_bit_set(2)\n            self.supervision = is_bit_set(3)\n            # Bit 4 = unknown\n            self.loop[2] = is_bit_set(5)\n            self.loop[1] = is_bit_set(6)\n            self.loop[3] = is_bit_set(7)\n            self.loop[0] = is_bit_set(8)\n\n        except ValueError:\n            raise InvalidMessageError('Received invalid message: {0}'.format(data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary representation of the object.", "response": "def dict(self, **kwargs):\n        \"\"\"\n        Dictionary representation.\n        \"\"\"\n        return dict(\n            time                  = self.timestamp,\n            serial_number         = self.serial_number,\n            value                 = self.value,\n            battery               = self.battery,\n            supervision           = self.supervision,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef open(self, baudrate=None, no_reader_thread=False):\n\n        try:\n            self._read_thread = Device.ReadThread(self)\n\n            self._device = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n\n            if self._use_ssl:\n                self._init_ssl()\n\n            self._device.connect((self._host, self._port))\n\n            if self._use_ssl:\n                while True:\n                    try:\n                        self._device.do_handshake()\n                        break\n                    except SSL.WantReadError:\n                        pass\n\n            self._id = '{0}:{1}'.format(self._host, self._port)\n\n        except socket.error as err:\n            raise NoDeviceError('Error opening device at {0}:{1}'.format(self._host, self._port), err)\n\n        else:\n            self._running = True\n            self.on_open()\n\n            if not no_reader_thread:\n                self._read_thread.start()\n\n        return self", "response": "Opens the device.\n\n        :param baudrate: baudrate to use\n        :type baudrate: int\n        :param no_reader_thread: whether or not to automatically open the reader\n                                 thread.\n        :type no_reader_thread: bool\n\n        :raises: :py:class:`~alarmdecoder.util.NoDeviceError`, :py:class:`~alarmdecoder.util.CommError`"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites data to the device.", "response": "def write(self, data):\n        \"\"\"\n        Writes data to the device.\n\n        :param data: data to write\n        :type data: string\n\n        :returns: number of bytes sent\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n        data_sent = None\n\n        try:\n            if isinstance(data, str):\n                data = data.encode('utf-8')\n\n            data_sent = self._device.send(data)\n\n            if data_sent == 0:\n                raise CommError('Error writing to device.')\n\n            self.on_write(data=data)\n\n        except (SSL.Error, socket.error) as err:\n            raise CommError('Error writing to device.', err)\n\n        return data_sent"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a single character from the device.", "response": "def read(self):\n        \"\"\"\n        Reads a single character from the device.\n\n        :returns: character read from the device\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n        data = ''\n\n        try:\n            read_ready, _, _ = select.select([self._device], [], [], 0.5)\n\n            if len(read_ready) != 0:\n                data = self._device.recv(1)\n\n        except socket.error as err:\n            raise CommError('Error while reading from device: {0}'.format(str(err)), err)\n\n        return data.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a single line from the device.", "response": "def read_line(self, timeout=0.0, purge_buffer=False):\n        \"\"\"\n        Reads a line from the device.\n\n        :param timeout: read timeout\n        :type timeout: float\n        :param purge_buffer: Indicates whether to purge the buffer prior to\n                             reading.\n        :type purge_buffer: bool\n\n        :returns: line that was read\n        :raises: :py:class:`~alarmdecoder.util.CommError`, :py:class:`~alarmdecoder.util.TimeoutError`\n        \"\"\"\n\n        def timeout_event():\n            \"\"\"Handles read timeout event\"\"\"\n            timeout_event.reading = False\n        timeout_event.reading = True\n\n        if purge_buffer:\n            self._buffer = b''\n\n        got_line, ret = False, None\n\n        timer = threading.Timer(timeout, timeout_event)\n        if timeout > 0:\n            timer.start()\n\n        try:\n            while timeout_event.reading:\n                read_ready, _, _ = select.select([self._device], [], [], 0.5)\n\n                if len(read_ready) == 0:\n                    continue\n\n                buf = self._device.recv(1)\n\n                if buf != b'' and buf != b\"\\xff\":\n                    ub = bytes_hack(buf)\n\n                    self._buffer += ub\n\n                    if ub == b\"\\n\":\n                        self._buffer = self._buffer.rstrip(b\"\\r\\n\")\n\n                        if len(self._buffer) > 0:\n                            got_line = True\n                            break\n\n        except socket.error as err:\n            raise CommError('Error reading from device: {0}'.format(str(err)), err)\n\n        except SSL.SysCallError as err:\n            errno, msg = err\n            raise CommError('SSL error while reading from device: {0} ({1})'.format(msg, errno))\n\n        except Exception:\n            raise\n\n        else:\n            if got_line:\n                ret, self._buffer = self._buffer, b''\n\n                self.on_read(data=ret)\n\n            else:\n                raise TimeoutError('Timeout while waiting for line terminator.')\n\n        finally:\n            timer.cancel()\n\n        return ret.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef purge(self):\n        try:\n            self._device.setblocking(0)\n            while(self._device.recv(1)):\n                pass\n        except socket.error as err:\n            pass\n        finally:\n            self._device.setblocking(1)", "response": "Purge all read and write buffers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize our device as an SSL connection.", "response": "def _init_ssl(self):\n        \"\"\"\n        Initializes our device as an SSL connection.\n\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n\n        if not have_openssl:\n            raise ImportError('SSL sockets have been disabled due to missing requirement: pyopenssl.')\n\n        try:\n            ctx = SSL.Context(SSL.TLSv1_METHOD)\n\n            if isinstance(self.ssl_key, crypto.PKey):\n                ctx.use_privatekey(self.ssl_key)\n            else:\n                ctx.use_privatekey_file(self.ssl_key)\n\n            if isinstance(self.ssl_certificate, crypto.X509):\n                ctx.use_certificate(self.ssl_certificate)\n            else:\n                ctx.use_certificate_file(self.ssl_certificate)\n\n            if isinstance(self.ssl_ca, crypto.X509):\n                store = ctx.get_cert_store()\n                store.add_cert(self.ssl_ca)\n            else:\n                ctx.load_verify_locations(self.ssl_ca, None)\n\n            verify_method = SSL.VERIFY_PEER\n            if (self._ssl_allow_self_signed):\n                verify_method = SSL.VERIFY_NONE\n\n            ctx.set_verify(verify_method, self._verify_ssl_callback)\n\n            self._device = SSL.Connection(ctx, self._device)\n\n        except SSL.Error as err:\n            raise CommError('Error setting up SSL connection.', err)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_data(self, mjd, mag, err, whitten=False, **kwarg):\n        \n        self.mjd = mjd\n        self.N = len(mjd)\n        weights = np.power(err, -2.0)\n        self.weights = weights/np.sum(weights)\n        self.scale = robust_scale(mag, self.weights)\n        if whitten:\n            self.mag = (mag - robust_center(mag, self.weights))/self.scale\n            self.err = err/self.scale\n        else:\n            self.mag = mag\n            self.err = err\n        self.mjd = self.mjd.astype('float32')\n        self.mag = self.mag.astype('float32')\n        self.err = self.err.astype('float32')\n        if self.method == 'QMICS' or self.method == 'QMIEU' or self.method == 'QME':\n            if whitten:\n                hm = 0.9*self.N**(-0.2) # Silverman's rule, assuming data is whittened\n            else:\n                hm = 0.9*self.scale*self.N**(-0.2)\n            if 'h_KDE_M' in kwarg:\n                hm = hm*kwarg['h_KDE_M']\n            hp = 1.0 # How to choose this more appropietly?\n            if 'h_KDE_P' in kwarg:\n                hp = hp*kwarg['h_KDE_P']\n            kernel = 0  # Select the kernel for the magnitudes, 0 is safe\n            if 'kernel' in kwarg:\n                kernel = kwarg['kernel']\n            if self.debug:\n                print(\"Kernel bandwidths: %f , %f\" %(hm, hp))\n            self.my_QMI = QMI(self.mjd, self.mag, self.err, hm, hp, kernel)\n        elif self.method == 'LKSL':  # Lafler-Kinman Minimum String Length\n            self.my_SL = LKSL(self.mjd, self.mag, self.err)\n        elif self.method == 'PDM1':  # Phase Dispersion Minimization\n            Nbins = int(self.N/3)\n            if 'Nbins' in kwarg:\n                Nbins = kwarg['Nbins']\n            self.my_PDM = PDM(self.mjd, self.mag, self.err, Nbins)\n        elif self.method == 'MHAOV':  # Orthogonal Multiharmonics AoV periodogram\n            Nharmonics = 1\n            if 'Nharmonics' in kwarg:\n                Nharmonics = kwarg[\"Nharmonics\"]\n            self.my_AOV = AOV(self.mjd, self.mag, self.err, Nharmonics)", "response": "Sets the data for the light curve entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_best_frequencies(self):\n        return self.freq[self.best_local_optima], self.per[self.best_local_optima]", "response": "Returns the best n_local_max frequencies"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncomputes the selected criterion over a grid of frequencies around a specified amount of local optima of the periodograms. This function is intended for additional fine tuning of the results obtained with grid_search", "response": "def finetune_best_frequencies(self, fresolution=1e-5, n_local_optima=10):\n        \"\"\"\n        Computes the selected criterion over a grid of frequencies \n        around a specified amount of  local optima of the periodograms. This\n        function is intended for additional fine tuning of the results obtained\n        with grid_search\n        \"\"\"\n        # Find the local optima\n        local_optima_index = []\n        for k in range(1, len(self.per)-1):\n            if self.per[k-1] < self.per[k] and self.per[k+1] < self.per[k]:\n                local_optima_index.append(k)\n        local_optima_index = np.array(local_optima_index)\n        if(len(local_optima_index) < n_local_optima):\n            print(\"Warning: Not enough local maxima found in the periodogram, skipping finetuning\")\n            return\n        # Keep only n_local_optima\n        best_local_optima = local_optima_index[np.argsort(self.per[local_optima_index])][::-1]\n        if n_local_optima > 0:\n            best_local_optima = best_local_optima[:n_local_optima]\n        else:\n            best_local_optima = best_local_optima[0]\n        # Do finetuning around each local optima\n        for j in range(n_local_optima):\n            freq_fine = self.freq[best_local_optima[j]] - self.fres_grid\n            for k in range(0, int(2.0*self.fres_grid/fresolution)):\n                cost = self.compute_metric(freq_fine)\n                if cost > self.per[best_local_optima[j]]:\n                    self.per[best_local_optima[j]] = cost\n                    self.freq[best_local_optima[j]] = freq_fine\n                freq_fine += fresolution\n        # Sort them in descending order\n        idx = np.argsort(self.per[best_local_optima])[::-1]\n        if n_local_optima > 0:\n            self.best_local_optima = best_local_optima[idx]\n        else:\n            self.best_local_optima = best_local_optima"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef frequency_grid_evaluation(self, fmin=0.0, fmax=1.0, fresolution=1e-4, n_local_max=10):\n        self.fres_grid = fresolution\n        freq = np.arange(np.amax([fmin, fresolution]), fmax, step=fresolution).astype('float32')\n        Nf = len(freq)\n        per = np.zeros(shape=(Nf,)).astype('float32')     \n              \n        for k in range(0, Nf):\n            per[k] = self.compute_metric(freq[k])\n        self.freq = freq\n        self.per = per", "response": "This method evaluates the selected criterion over a grid of frequencies \n        with limits and resolution specified by the inputs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, message):\n        # Firmware version < 2.2a.8.6\n        if message.version == 1:\n            if message.event_type == 'ALARM_PANIC':\n                self._alarmdecoder._update_panic_status(True)\n                \n            elif message.event_type == 'CANCEL':\n                self._alarmdecoder._update_panic_status(False)\n\n        # Firmware version >= 2.2a.8.6\n        elif message.version == 2:\n            source = message.event_source\n            if source == LRR_EVENT_TYPE.CID:\n                self._handle_cid_message(message)\n            elif source == LRR_EVENT_TYPE.DSC:\n                self._handle_dsc_message(message)\n            elif source == LRR_EVENT_TYPE.ADEMCO:\n                self._handle_ademco_message(message)\n            elif source == LRR_EVENT_TYPE.ALARMDECODER:\n                self._handle_alarmdecoder_message(message)\n            elif source == LRR_EVENT_TYPE.UNKNOWN:\n                self._handle_unknown_message(message)\n            else:\n                pass", "response": "Updates the states in the primary AlarmDecoder object based on the provided LRR message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling a contactid LRR message.", "response": "def _handle_cid_message(self, message):\n        \"\"\"\n        Handles ContactID LRR events.\n\n        :param message: LRR message object\n        :type message: :py:class:`~alarmdecoder.messages.LRRMessage`\n        \"\"\"\n        status = self._get_event_status(message)\n        if status is None:\n            return\n\n        if message.event_code in LRR_FIRE_EVENTS:\n            if message.event_code == LRR_CID_EVENT.OPENCLOSE_CANCEL_BY_USER:\n                status = False\n\n            self._alarmdecoder._update_fire_status(status=status)\n            \n        if message.event_code in LRR_ALARM_EVENTS:\n            kwargs = {}\n            field_name = 'zone'\n            if not status:\n                field_name = 'user'\n\n            kwargs[field_name] = int(message.event_data)\n            self._alarmdecoder._update_alarm_status(status=status, **kwargs)\n\n        if message.event_code in LRR_POWER_EVENTS:\n            self._alarmdecoder._update_power_status(status=status)\n\n        if message.event_code in LRR_BYPASS_EVENTS:\n            self._alarmdecoder._update_zone_bypass_status(status=status, zone=int(message.event_data))\n\n        if message.event_code in LRR_BATTERY_EVENTS:\n            self._alarmdecoder._update_battery_status(status=status)\n\n        if message.event_code in LRR_PANIC_EVENTS:\n            if message.event_code == LRR_CID_EVENT.OPENCLOSE_CANCEL_BY_USER:\n                status = False\n\n            self._alarmdecoder._update_panic_status(status=status)\n\n        if message.event_code in LRR_ARM_EVENTS:\n            # NOTE: status on OPENCLOSE messages is backwards.\n            status_stay = (message.event_status == LRR_EVENT_STATUS.RESTORE \\\n                            and message.event_code in LRR_STAY_EVENTS)\n\n            if status_stay:\n                status = False\n            else:\n                status = not status\n\n            self._alarmdecoder._update_armed_status(status=status, status_stay=status_stay)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_event_status(self, message):\n        status = None\n\n        if message.event_status == LRR_EVENT_STATUS.TRIGGER:\n            status = True\n        elif message.event_status == LRR_EVENT_STATUS.RESTORE:\n            status = False\n\n        return status", "response": "Returns the boolean status of an LRR message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning all serial ports present.", "response": "def find_all(pattern=None):\n        \"\"\"\n        Returns all serial ports present.\n\n        :param pattern: pattern to search for when retrieving serial ports\n        :type pattern: string\n\n        :returns: list of devices\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n        devices = []\n\n        try:\n            if pattern:\n                devices = serial.tools.list_ports.grep(pattern)\n            else:\n                devices = serial.tools.list_ports.comports()\n\n        except serial.SerialException as err:\n            raise CommError('Error enumerating serial devices: {0}'.format(str(err)), err)\n\n        return devices"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open(self, baudrate=BAUDRATE, no_reader_thread=False):\n        # Set up the defaults\n        if baudrate is None:\n            baudrate = SerialDevice.BAUDRATE\n\n        if self._port is None:\n            raise NoDeviceError('No device interface specified.')\n\n        self._read_thread = Device.ReadThread(self)\n\n        # Open the device and start up the reader thread.\n        try:\n            self._device.port = self._port\n            self._device.open()\n            # NOTE: Setting the baudrate before opening the\n            #       port caused issues with Moschip 7840/7820\n            #       USB Serial Driver converter. (mos7840)\n            #\n            #       Moving it to this point seems to resolve\n            #       all issues with it.\n            self._device.baudrate = baudrate\n\n        except (serial.SerialException, ValueError, OSError) as err:\n            raise NoDeviceError('Error opening device on {0}.'.format(self._port), err)\n\n        else:\n            self._running = True\n            self.on_open()\n\n            if not no_reader_thread:\n                self._read_thread.start()\n\n        return self", "response": "Opens the device and starts the reader thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write(self, data):\n        try:\n            # Hack to support unicode under Python 2.x\n            if isinstance(data, str) or (sys.version_info < (3,) and isinstance(data, unicode)):\n                data = data.encode('utf-8')\n\n            self._device.write(data)\n\n        except serial.SerialTimeoutException:\n            pass\n\n        except serial.SerialException as err:\n            raise CommError('Error writing to device.', err)\n\n        else:\n            self.on_write(data=data)", "response": "Writes data to the device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a single character from the device.", "response": "def read(self):\n        \"\"\"\n        Reads a single character from the device.\n\n        :returns: character read from the device\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n        data = ''\n\n        try:\n            read_ready, _, _ = select.select([self._device.fileno()], [], [], 0.5)\n\n            if len(read_ready) != 0:\n                data = self._device.read(1)\n\n        except serial.SerialException as err:\n            raise CommError('Error reading from device: {0}'.format(str(err)), err)\n\n        return data.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a single line from the device.", "response": "def read_line(self, timeout=0.0, purge_buffer=False):\n        \"\"\"\n        Reads a line from the device.\n\n        :param timeout: read timeout\n        :type timeout: float\n        :param purge_buffer: Indicates whether to purge the buffer prior to\n                             reading.\n        :type purge_buffer: bool\n\n        :returns: line that was read\n        :raises: :py:class:`~alarmdecoder.util.CommError`, :py:class:`~alarmdecoder.util.TimeoutError`\n        \"\"\"\n\n        def timeout_event():\n            \"\"\"Handles read timeout event\"\"\"\n            timeout_event.reading = False\n        timeout_event.reading = True\n\n        if purge_buffer:\n            self._buffer = b''\n\n        got_line, data = False, ''\n\n        timer = threading.Timer(timeout, timeout_event)\n        if timeout > 0:\n            timer.start()\n\n        leftovers = b''\n        try:\n            while timeout_event.reading and not got_line:\n                read_ready, _, _ = select.select([self._device.fileno()], [], [], 0.5)\n                if len(read_ready) == 0:\n                    continue\n\n                bytes_avail = 0\n                if hasattr(self._device, \"in_waiting\"):\n                    bytes_avail = self._device.in_waiting\n                else:\n                    bytes_avail = self._device.inWaiting()\n\n                buf = self._device.read(bytes_avail)\n\n                for idx in range(len(buf)):\n                    c = buf[idx]\n\n                    ub = bytes_hack(c)\n                    if sys.version_info > (3,):\n                        ub = bytes([ub])\n\n                    # NOTE: AD2SERIAL and AD2PI apparently sends down \\xFF on boot.\n                    if ub != b'' and ub != b\"\\xff\":\n                        self._buffer += ub\n\n                        if ub == b\"\\n\":\n                            self._buffer = self._buffer.strip(b\"\\r\\n\")\n\n                            if len(self._buffer) > 0:\n                                got_line = True\n                                leftovers = buf[idx:]\n                                break\n\n        except (OSError, serial.SerialException) as err:\n            raise CommError('Error reading from device: {0}'.format(str(err)), err)\n\n        else:\n            if got_line:\n                data, self._buffer = self._buffer, leftovers\n\n                self.on_read(data=data)\n\n            else:\n                raise TimeoutError('Timeout while waiting for line terminator.')\n\n        finally:\n            timer.cancel()\n\n        return data.decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the message from the device and stores the attributes of the object.", "response": "def _parse_message(self, data):\n        \"\"\"\n        Parse the message from the device.\n\n        :param data: message data\n        :type data: string\n\n        :raises: :py:class:`~alarmdecoder.util.InvalidMessageError`\n        \"\"\"\n        match = self._regex.match(str(data))\n\n        if match is None:\n            raise InvalidMessageError('Received invalid message: {0}'.format(data))\n\n        header, self.bitfield, self.numeric_code, self.panel_data, alpha = match.group(1, 2, 3, 4, 5)\n\n        is_bit_set = lambda bit: not self.bitfield[bit] == \"0\"\n\n        self.ready = is_bit_set(1)\n        self.armed_away = is_bit_set(2)\n        self.armed_home = is_bit_set(3)\n        self.backlight_on = is_bit_set(4)\n        self.programming_mode = is_bit_set(5)\n        self.beeps = int(self.bitfield[6], 16)\n        self.zone_bypassed = is_bit_set(7)\n        self.ac_power = is_bit_set(8)\n        self.chime_on = is_bit_set(9)\n        self.alarm_event_occurred = is_bit_set(10)\n        self.alarm_sounding = is_bit_set(11)\n        self.battery_low = is_bit_set(12)\n        self.entry_delay_off = is_bit_set(13)\n        self.fire_alarm = is_bit_set(14)\n        self.check_zone = is_bit_set(15)\n        self.perimeter_only = is_bit_set(16)\n        self.system_fault = is_bit_set(17)\n        if self.bitfield[18] in list(PANEL_TYPES):\n            self.panel_type = PANEL_TYPES[self.bitfield[18]]\n        # pos 20-21 - Unused.\n        self.text = alpha.strip('\"')\n        self.mask = int(self.panel_data[3:3+8], 16)\n\n        if self.panel_type in (ADEMCO, DSC):\n            if int(self.panel_data[19:21], 16) & 0x01 > 0:\n                # Current cursor location on the alpha display.\n                self.cursor_location = int(self.panel_data[21:23], 16)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing and returns the numeric code as an integer.", "response": "def parse_numeric_code(self, force_hex=False):\n        \"\"\"\n        Parses and returns the numeric code as an integer.\n\n        The numeric code can be either base 10 or base 16, depending on\n        where the message came from.\n\n        :param force_hex: force the numeric code to be processed as base 16.\n        :type force_hex: boolean\n\n        :raises: ValueError\n        \"\"\"\n        code = None\n        got_error = False\n\n        if not force_hex:\n            try:\n                code = int(self.numeric_code)\n            except ValueError:\n                got_error = True\n\n        if force_hex or got_error:\n            try:\n                code = int(self.numeric_code, 16)\n            except ValueError:\n                raise\n\n        return code"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dict(self, **kwargs):\n        return dict(\n            time                  = self.timestamp,\n            bitfield              = self.bitfield,\n            numeric_code          = self.numeric_code,\n            panel_data            = self.panel_data,\n            mask                  = self.mask,\n            ready                 = self.ready,\n            armed_away            = self.armed_away,\n            armed_home            = self.armed_home,\n            backlight_on          = self.backlight_on,\n            programming_mode      = self.programming_mode,\n            beeps                 = self.beeps,\n            zone_bypassed         = self.zone_bypassed,\n            ac_power              = self.ac_power,\n            chime_on              = self.chime_on,\n            alarm_event_occurred  = self.alarm_event_occurred,\n            alarm_sounding        = self.alarm_sounding,\n            battery_low           = self.battery_low,\n            entry_delay_off       = self.entry_delay_off,\n            fire_alarm            = self.fire_alarm,\n            check_zone            = self.check_zone,\n            perimeter_only        = self.perimeter_only,\n            text                  = self.text,\n            cursor_location       = self.cursor_location,\n            **kwargs\n        )", "response": "Return a dictionary representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef LoadCHM(self, archiveName):\n        '''Loads a CHM archive.\n        This function will also call GetArchiveInfo to obtain information\n        such as the index file name and the topics file. It returns 1 on\n        success, and 0 if it fails.\n        '''\n        if self.filename is not None:\n            self.CloseCHM()\n\n        self.file = chmlib.chm_open(archiveName)\n        if self.file is None:\n            return 0\n\n        self.filename = archiveName\n        self.GetArchiveInfo()\n\n        return 1", "response": "Loads a CHM archive. This function will also call GetArchiveInfo to obtain information about the topics file. It will also call GetArchiveInfo to obtain information about the topics file. It will return 1 on success and 0 on failure."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclose the CHM archive. This function will close the CHM file. All variables are reset.", "response": "def CloseCHM(self):\n        '''Closes the CHM archive.\n        This function will close the CHM file, if it is open. All variables\n        are also reset.\n        '''\n        if self.filename is not None:\n            chmlib.chm_close(self.file)\n            self.file = None\n            self.filename = ''\n            self.title = \"\"\n            self.home = \"/\"\n            self.index = None\n            self.topics = None\n            self.encoding = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef GetArchiveInfo(self):\n        '''Obtains information on CHM archive.\n        This function checks the /#SYSTEM file inside the CHM archive to\n        obtain the index, home page, topics, encoding and title. It is called\n        from LoadCHM.\n        '''\n\n        self.searchable = extra.is_searchable(self.file)\n        self.lcid = None\n\n        result, ui = chmlib.chm_resolve_object(self.file, '/#SYSTEM')\n        if (result != chmlib.CHM_RESOLVE_SUCCESS):\n            sys.stderr.write('GetArchiveInfo: #SYSTEM does not exist\\n')\n            return 0\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 4l, ui.length)\n        if (size == 0):\n            sys.stderr.write('GetArchiveInfo: file size = 0\\n')\n            return 0\n\n        buff = array.array('B', text)\n\n        index = 0\n        while (index < size):\n            cursor = buff[index] + (buff[index+1] * 256)\n\n            if (cursor == 0):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.topics = '/' + text[index:index+cursor-1]\n            elif (cursor == 1):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.index = '/' + text[index:index+cursor-1]\n            elif (cursor == 2):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.home = '/' + text[index:index+cursor-1]\n            elif (cursor == 3):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.title = text[index:index+cursor-1]\n            elif (cursor == 4):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.lcid = buff[index] + (buff[index+1] * 256)\n            elif (cursor == 6):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                tmp = text[index:index+cursor-1]\n                if not self.topics:\n                    tmp1 = '/' + tmp + '.hhc'\n                    tmp2 = '/' + tmp + '.hhk'\n                    res1, ui1 = chmlib.chm_resolve_object(self.file, tmp1)\n                    res2, ui2 = chmlib.chm_resolve_object(self.file, tmp2)\n                    if not self.topics and res1 == chmlib.CHM_RESOLVE_SUCCESS:\n                        self.topics = '/' + tmp + '.hhc'\n                    if not self.index and res2 == chmlib.CHM_RESOLVE_SUCCESS:\n                        self.index = '/' + tmp + '.hhk'\n            elif (cursor == 16):\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n                self.encoding = text[index:index+cursor-1]\n            else:\n                index += 2\n                cursor = buff[index] + (buff[index+1] * 256)\n                index += 2\n            index += cursor\n\n        self.GetWindowsInfo()\n\n        if not self.lcid:\n            self.lcid = extra.get_lcid(self.file)\n\n        return 1", "response": "This function retrieves the index home page topics encoding and title from the CHM archive. It is called by LoadCHM. It is called by LoadCHM. It is called by LoadCHM."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef GetTopicsTree(self):\n        '''Reads and returns the topics tree.\n        This auxiliary function reads and returns the topics tree file\n        contents for the CHM archive.\n        '''\n        if self.topics is None:\n            return None\n\n        if self.topics:\n            res, ui = chmlib.chm_resolve_object(self.file, self.topics)\n            if (res != chmlib.CHM_RESOLVE_SUCCESS):\n                return None\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 0l, ui.length)\n        if (size == 0):\n            sys.stderr.write('GetTopicsTree: file size = 0\\n')\n            return None\n        return text", "response": "Reads and returns the topics tree file. This auxiliary function reads and returns the topics tree file. This auxiliary function reads and returns the topics tree file. This auxiliary function reads and returns the topics tree file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef GetIndex(self):\n        '''Reads and returns the index tree.\n        This auxiliary function reads and returns the index tree file\n        contents for the CHM archive.\n        '''\n        if self.index is None:\n            return None\n\n        if self.index:\n            res, ui = chmlib.chm_resolve_object(self.file, self.index)\n            if (res != chmlib.CHM_RESOLVE_SUCCESS):\n                return None\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 0l, ui.length)\n        if (size == 0):\n            sys.stderr.write('GetIndex: file size = 0\\n')\n            return None\n        return text", "response": "Reads and returns the index tree. This auxiliary function reads and returns the index tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ResolveObject(self, document):\n        '''Tries to locate a document in the archive.\n        This function tries to locate the document inside the archive. It\n        returns a tuple where the first element is zero if the function\n        was successful, and the second is the UnitInfo for that document.\n        The UnitInfo is used to retrieve the document contents\n        '''\n        if self.file:\n            path = os.path.abspath(document)\n            return chmlib.chm_resolve_object(self.file, path)\n        else:\n            return (1, None)", "response": "Tries to locate a document in the archive. It returns a tuple where the first element is the number of times the function was successful and the second is the UnitInfo for that document."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the contents of a document.", "response": "def RetrieveObject(self, ui, start=-1, length=-1):\n        '''Retrieves the contents of a document.\n        This function takes a UnitInfo and two optional arguments, the first\n        being the start address and the second is the length. These define\n        the amount of data to be read from the archive.\n        '''\n        if self.file and ui:\n            if length == -1:\n                len = ui.length\n            else:\n                len = length\n            if start == -1:\n                st = 0l\n            else:\n                st = long(start)\n            return chmlib.chm_retrieve_object(self.file, ui, st, len)\n        else:\n            return (0, '')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming full - text search on the archive.", "response": "def Search(self, text, wholewords=0, titleonly=0):\n        '''Performs full-text search on the archive.\n        The first parameter is the word to look for, the second\n        indicates if the search should be for whole words only, and\n        the third parameter indicates if the search should be\n        restricted to page titles.\n        This method will return a tuple, the first item\n        indicating if the search results were partial, and the second\n        item being a dictionary containing the results.'''\n        if text and text != '' and self.file:\n            return extra.search(self.file, text, wholewords,\n                                titleonly)\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string that can be used with the codecs python package to encode or decode the files in the chm archive.", "response": "def GetEncoding(self):\n        '''Returns a string that can be used with the codecs python package\n        to encode or decode the files in the chm archive. If an error is\n        found, or if it is not possible to find the encoding, None is\n        returned.'''\n        if self.encoding:\n            vals = string.split(self.encoding, ',')\n            if len(vals) > 2:\n                try:\n                    return charset_table[int(vals[2])]\n                except KeyError:\n                    pass\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef GetString(self, text, idx):\n        '''Internal method.\n        Retrieves a string from the #STRINGS buffer.\n        '''\n        next = string.find(text, '\\x00', idx)\n        chunk = text[idx:next]\n        return chunk", "response": "Internal method. Gets a string from the STRINGS buffer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef GetWindowsInfo(self):\n        '''Gets information from the #WINDOWS file.\n        Checks the #WINDOWS file to see if it has any info that was\n        not found in #SYSTEM (topics, index or default page.\n        '''\n        result, ui = chmlib.chm_resolve_object(self.file, '/#WINDOWS')\n        if (result != chmlib.CHM_RESOLVE_SUCCESS):\n            return -1\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 0l, 8)\n        if (size < 8):\n            return -2\n\n        buff = array.array('B', text)\n        num_entries = self.GetDWORD(buff, 0)\n        entry_size = self.GetDWORD(buff, 4)\n\n        if num_entries < 1:\n            return -3\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 8l, entry_size)\n        if (size < entry_size):\n            return -4\n\n        buff = array.array('B', text)\n        toc_index = self.GetDWORD(buff, 0x60)\n        idx_index = self.GetDWORD(buff, 0x64)\n        dft_index = self.GetDWORD(buff, 0x68)\n\n        result, ui = chmlib.chm_resolve_object(self.file, '/#STRINGS')\n        if (result != chmlib.CHM_RESOLVE_SUCCESS):\n            return -5\n\n        size, text = chmlib.chm_retrieve_object(self.file, ui, 0l, ui.length)\n        if (size == 0):\n            return -6\n\n        if (not self.topics):\n            self.topics = self.GetString(text, toc_index)\n            if not self.topics.startswith(\"/\"):\n                self.topics = \"/\" + self.topics\n\n        if (not self.index):\n            self.index = self.GetString(text, idx_index)\n            if not self.index.startswith(\"/\"):\n                self.index = \"/\" + self.index\n\n        if (dft_index != 0):\n            self.home = self.GetString(text, dft_index)\n            if not self.home.startswith(\"/\"):\n                self.home = \"/\" + self.home", "response": "Gets information from the Windows file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the raw message from the device.", "response": "def _parse_message(self, data):\n        \"\"\"\n        Parse the raw message from the device.\n\n        :param data: message data\n        :type data: string\n\n        :raises: :py:class:`~alarmdecoder.util.InvalidMessageError`\n        \"\"\"\n        try:\n            header, values = data.split(':')\n            address, channel, value = values.split(',')\n\n            self.address = int(address)\n            self.channel = int(channel)\n            self.value = int(value)\n\n        except ValueError:\n            raise InvalidMessageError('Received invalid message: {0}'.format(data))\n\n        if header == '!EXP':\n            self.type = ExpanderMessage.ZONE\n        elif header == '!REL':\n            self.type = ExpanderMessage.RELAY\n        else:\n            raise InvalidMessageError('Unknown expander message header: {0}'.format(data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dict(self, **kwargs):\n        return dict(\n            time                  = self.timestamp,\n            address               = self.address,\n            channel               = self.channel,\n            value                 = self.value,\n            **kwargs\n        )", "response": "Dictionary representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef irregular_sampling(T, N, rseed=None):\n    sampling_period = (T/float(N))\n    N = int(N)\n    np.random.seed(rseed)    \n    t = np.linspace(0, T, num=5*N)\n    # First we add jitter\n    t[1:-1] += sampling_period*0.5*np.random.randn(5*N-2)\n    # Then we do a random permutation and keep only N points \n    P = np.random.permutation(5*N)\n    t_irr = np.sort(t[P[:N]])\n    return t_irr", "response": "Generate an irregularly sampled time vector by perturbating a linearly spaced vector and deleting a certain number of points from the time vector."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef trigonometric_model(t, f0, A):\n    y = 0.0\n    M = len(A)\n    var_y = 0.0\n    for k in range(0, M):\n        y += A[k]*np.sin(2.0*np.pi*t*f0*(k+1))\n        var_y += 0.5*A[k]**2\n    return y, var_y", "response": "Generates a simple trigonometric model based on a sum of sine waves \n A"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef first_order_markov_process(t, variance, time_scale, rseed=None):\n    if variance < 0.0:\n        raise ValueError(\"Variance must be positive\")\n    if time_scale < 0.0:\n        raise ValueError(\"Time scale must be positive\")\n    np.random.seed(rseed)\n    N = len(t)\n    mu = np.zeros(shape=(N,))\n    if variance == 0.0:\n        return mu\n    dt = np.repeat(np.reshape(t, (1, -1)), N, axis=0)\n    dt = np.absolute(dt - dt.T)  # This is NxN\n    S = variance*np.exp(-np.absolute(dt)/time_scale)\n    red_noise = np.random.multivariate_normal(mu, S)\n    return red_noise", "response": "This function generates a correlated noise vector using a multivariate normal generator with zero mean and covariance matrix and the power spectral density associated to this covariance matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncautioning NOT THOROUGHLY TESTED Generates a red noise vector by first generating a covariance function based on the expected red noise spectra. Red noise spectrum follows a power law S(f) = A*f^(-2), where A is a constant. Pink noise can be obtained if the exponent is changed to -1, and white noise if it is changed to 0. This Power Spectral density (PSD) is real and even then r(tau) = AT sum cos(2pi k tau/T)/k**2, where we assume f[k] = k*df, df = 1/T, Fs = N/T. The basel problem gives us: sum (1/k**2) approx pi**2/6, hence we can set c according to the desired variance at lag=0 After the covariance is computed we can draw from a multivariate normal distribution to obtain a noise vector Parameters --------- t: ndarray A time vector for which the red noise vector will be sampled variance: positive float variance of the resulting red noise vector Returns ------- red_noise: ndarray Vector containing the red noise realizations See also -------- first_order_markov_process", "response": "def power_law_noise(t, variance):\n    \"\"\"\n    CAUTION: NOT THOROUGHLY TESTED\n    Generates a red noise vector by first generating a covariance \n    function based on the expected red noise spectra. Red noise spectrum\n    follows a power law\n    \n        S(f) = A*f^(-2),\n    \n    where A is a constant. Pink noise can be obtained if the exponent is\n    changed to -1, and white noise if it is changed to 0.\n    \n    This Power Spectral density (PSD) is real and even then\n    \n        r(tau) = AT sum cos(2pi k tau/T)/k**2,\n    \n    where we assume f[k] = k*df, df = 1/T, Fs = N/T.\n    \n    The basel problem gives us: sum (1/k**2) approx pi**2/6, hence we can\n    set c according to the desired variance at lag=0\n     \n    After the covariance is computed we can draw from a multivariate\n    normal distribution to obtain a noise vector\n    \n    Parameters\n    ---------\n    t: ndarray\n        A time vector for which the red noise vector will be sampled\n    variance: positive float\n        variance of the resulting red noise vector\n        \n    Returns\n    -------\n    red_noise: ndarray\n        Vector containing the red noise realizations\n        \n    See also\n    --------\n    first_order_markov_process\n    \n    \"\"\"\n    if variance < 0.0:\n        raise ValueError(\"Variance must be positive\")\n    mu = np.zeros(shape=(N,))\n    if variance == 0.0:\n        return mu\n    N = len(t)    \n    T = (t[-1] - t[0])\n    c = (6.0*variance)/(T*np.pi**2)\n    f = np.arange(1.0/T, 0.5*N/T, step=1.0/T)  # We ommit f=0.0\n    k = f*T\n    dt = np.repeat(np.reshape(t, (1, -1)), N, axis=0)\n    dt = np.absolute(dt - dt.T)  # This is NxN\n    S = np.zeros(shape=(N, N))\n    for i in range(0, N):\n        for j in range(i, N):\n            S[i, j] = np.sum(np.cos(2.0*np.pi*k*dt[i, j]/T)/k**2)*T*c\n            S[j, i] = S[i, j] \n    red_noise = np.random.multivariate_normal(mu, S)\n    return red_noise"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_uncertainties(N, dist='Gamma', rseed=None):\n    np.random.seed(rseed)  \n    #print(dist)\n    if dist == 'EMG':  # Exponential modified Gaussian\n        # the mean of a EMG rv is mu + 1/(K*sigma)\n        # the variance of a EMG rv is sigma**2 + 1/(K*sigma)**2\n        K = 1.824328605481941\n        sigma = 0.05*0.068768312946785953\n        mu = 0.05*0.87452567616276777\n        # IMPORTANT NOTE\n        # These parameters were obtained after fitting uncertainties\n        # coming from 10,000 light curves of the VVV survey\n        expected_s_2 = sigma**2 + mu**2 + 2*K*mu*sigma + 2*K**2*sigma**2 \n        s = exponnorm.rvs(K, loc=mu, scale=sigma, size=N)\n    elif dist == 'Gamma':\n        # The mean of a gamma rv is k*sigma\n        # The variance of a gamma rv is k*sigma**2\n        k = 3.0\n        sigma = 0.05/k  #  mean=0.05, var=0.05**2/k\n        s = gamma.rvs(k, loc=0.0, scale=sigma, size=N)\n        expected_s_2 = k*(1+k)*sigma**2  \n    return s, expected_s_2", "response": "This function generates a synthetic uncertainties vector for the given distribution of white noise components."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef draw_noisy_time_series(self, SNR=1.0, red_noise_ratio=0.25, outlier_ratio=0.0):\n        if outlier_ratio < 0.0 or outlier_ratio > 1.0:\n            raise ValueError(\"Outlier ratio must be in [0, 1]\")\n        if red_noise_ratio < 0.0:\n            raise ValueError(\"Red noise ratio must be positive\")\n        np.random.seed(self.rseed)\n        t = self.t\n        y_clean = self.y_clean\n        N = len(t)\n        # First we generate s \n        s, mean_s_squared = generate_uncertainties(N, rseed=self.rseed)\n        #print(mean_s_squared)\n        #print(np.mean(s**2))\n        # Draw a heteroscedastic white noise vector\n        white_noise = np.random.multivariate_normal(np.zeros(N,), np.diag(s**2))\n        # Now we generate a colored noise vector which is unaccounted by s\n        red_noise_variance = mean_s_squared*red_noise_ratio\n        # First order markovian process to generate \n        red_noise = first_order_markov_process(t, red_noise_variance, 1.0, rseed=self.rseed)\n        \n        # The following is not ok for irregularly sampled time series because\n        # it assumes constant dt=1\n        #phi=0.5\n        #red_noise = np.random.randn(N)*np.sqrt(red_noise_variance)\n        #for i in range(1, N):\n        #    red_noise[i] = phi*red_noise[i-1] + np.sqrt(1 - phi**2)*red_noise[i]\n        \n        # The final noise vector\n        #print(\"%f %f\" % (np.var(white_noise)*red_noise_ratio, np.var(red_noise)))\n        noise = white_noise + red_noise \n        var_noise = mean_s_squared + red_noise_variance\n        SNR_unitless = 10.0**(SNR/10.0)\n        self.A = np.sqrt(SNR_unitless*var_noise)\n        y = self.A*y_clean\n        y_noisy = y + noise\n        # Add outliers with a certain percentage\n        rperm = np.where(np.random.uniform(size=N) < outlier_ratio)[0]    \n        outlier = np.random.uniform(5.0*np.std(y), 10.0*np.std(y), size=len(rperm))\n        y_noisy[rperm] += outlier\n        return t, y_noisy, s", "response": "This function generates a noisy time series based on the clean model and the signal - to - noise ratio."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_event_description(event_type, event_code):\n    description = 'Unknown'\n    lookup_map = LRR_TYPE_MAP.get(event_type, None)\n\n    if lookup_map is not None:\n        description = lookup_map.get(event_code, description)\n\n    return description", "response": "Returns the human - readable description of an LRR event."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_event_source(prefix):\n    source = LRR_EVENT_TYPE.UNKNOWN\n\n    if prefix == 'CID':\n        source = LRR_EVENT_TYPE.CID\n    elif prefix == 'DSC':\n        source = LRR_EVENT_TYPE.DSC\n    elif prefix == 'AD2':\n        source = LRR_EVENT_TYPE.ALARMDECODER\n    elif prefix == 'ADEMCO':\n        source = LRR_EVENT_TYPE.ADEMCO\n\n    return source", "response": "Returns the LRR_EVENT_TYPE corresponding to the prefix provided."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef open(self, baudrate=None, no_reader_thread=False):\n        self._wire_events()\n        try:\n            self._device.open(baudrate=baudrate,\n                              no_reader_thread=no_reader_thread)\n        except:\n            self._unwire_events\n            raise\n\n        return self", "response": "Opens the device and returns the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send(self, data):\n\n        if self._device:\n            if isinstance(data, str):\n                data = str.encode(data)\n\n            # Hack to support unicode under Python 2.x\n            if sys.version_info < (3,):\n                if isinstance(data, unicode):\n                    data = bytes(data)\n\n            self._device.write(data)", "response": "Sends data to the AlarmDecoder_ device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a configuration string that s compatible with the AlarmDecoder configuration command from the current values in the object.", "response": "def get_config_string(self):\n        \"\"\"\n        Build a configuration string that's compatible with the AlarmDecoder configuration\n        command from the current values in the object.\n\n        :returns: string\n        \"\"\"\n        config_entries = []\n\n        # HACK: This is ugly.. but I can't think of an elegant way of doing it.\n        config_entries.append(('ADDRESS', '{0}'.format(self.address)))\n        config_entries.append(('CONFIGBITS', '{0:x}'.format(self.configbits)))\n        config_entries.append(('MASK', '{0:x}'.format(self.address_mask)))\n        config_entries.append(('EXP',\n                               ''.join(['Y' if z else 'N' for z in self.emulate_zone])))\n        config_entries.append(('REL',\n                               ''.join(['Y' if r else 'N' for r in self.emulate_relay])))\n        config_entries.append(('LRR', 'Y' if self.emulate_lrr else 'N'))\n        config_entries.append(('DEDUPLICATE', 'Y' if self.deduplicate else 'N'))\n        config_entries.append(('MODE', list(PANEL_TYPES)[list(PANEL_TYPES.values()).index(self.mode)]))\n        config_entries.append(('COM', 'Y' if self.emulate_com else 'N'))\n\n        config_string = '&'.join(['='.join(t) for t in config_entries])\n\n        return '&'.join(['='.join(t) for t in config_entries])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fault_zone(self, zone, simulate_wire_problem=False):\n\n        # Allow ourselves to also be passed an address/channel combination\n        # for zone expanders.\n        #\n        # Format (expander index, channel)\n        if isinstance(zone, tuple):\n            expander_idx, channel = zone\n\n            zone = self._zonetracker.expander_to_zone(expander_idx, channel)\n\n        status = 2 if simulate_wire_problem else 1\n\n        self.send(\"L{0:02}{1}\\r\".format(zone, status))", "response": "Faults a zone if we are emulating a zone expander."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwire up the internal device events.", "response": "def _wire_events(self):\n        \"\"\"\n        Wires up the internal device events.\n        \"\"\"\n        self._device.on_open += self._on_open\n        self._device.on_close += self._on_close\n        self._device.on_read += self._on_read\n        self._device.on_write += self._on_write\n        self._zonetracker.on_fault += self._on_zone_fault\n        self._zonetracker.on_restore += self._on_zone_restore"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the message from the keyboard and returns a Message object.", "response": "def _handle_message(self, data):\n        \"\"\"\n        Parses keypad messages from the panel.\n\n        :param data: keypad data to parse\n        :type data: string\n\n        :returns: :py:class:`~alarmdecoder.messages.Message`\n        \"\"\"\n\n        try:\n            data = data.decode('utf-8')\n        except:\n            raise InvalidMessageError('Decode failed for message: {0}'.format(data))\n\n        if data is not None:\n            data = data.lstrip('\\0')\n\n        if data is None or data == '':\n            raise InvalidMessageError()\n\n        msg = None\n        header = data[0:4]\n\n        if header[0] != '!' or header == '!KPM':\n            msg = self._handle_keypad_message(data)\n\n        elif header == '!EXP' or header == '!REL':\n            msg = self._handle_expander_message(data)\n\n        elif header == '!RFX':\n            msg = self._handle_rfx(data)\n\n        elif header == '!LRR':\n            msg = self._handle_lrr(data)\n\n        elif header == '!AUI':\n            msg = self._handle_aui(data)\n\n        elif data.startswith('!Ready'):\n            self.on_boot()\n\n        elif data.startswith('!CONFIG'):\n            self._handle_config(data)\n\n        elif data.startswith('!VER'):\n            self._handle_version(data)\n\n        elif data.startswith('!Sending'):\n            self._handle_sending(data)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nhandles a keypad message.", "response": "def _handle_keypad_message(self, data):\n        \"\"\"\n        Handle keypad messages.\n\n        :param data: keypad message to parse\n        :type data: string\n\n        :returns: :py:class:`~alarmdecoder.messages.Message`\n        \"\"\"\n\n        msg = Message(data)\n\n        if self._internal_address_mask & msg.mask > 0:\n            if not self._ignore_message_states:\n                self._update_internal_states(msg)\n\n            self.on_message(message=msg)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_expander_message(self, data):\n        msg = ExpanderMessage(data)\n\n        self._update_internal_states(msg)\n        self.on_expander_message(message=msg)\n\n        return msg", "response": "Handle expander messages.\n\n        :param data: expander message to parse\n        :type data: string\n\n        :returns: :py:class:`~alarmdecoder.messages.ExpanderMessage`"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handle_rfx(self, data):\n        msg = RFMessage(data)\n\n        self.on_rfx_message(message=msg)\n\n        return msg", "response": "Handle RF messages.\n\n        :param data: RF message to parse\n        :type data: string\n\n        :returns: :py:class:`~alarmdecoder.messages.RFMessage`"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles the LRR messages.", "response": "def _handle_lrr(self, data):\n        \"\"\"\n        Handle Long Range Radio messages.\n\n        :param data: LRR message to parse\n        :type data: string\n\n        :returns: :py:class:`~alarmdecoder.messages.LRRMessage`\n        \"\"\"\n        msg = LRRMessage(data)\n\n        if not self._ignore_lrr_states:\n            self._lrr_system.update(msg)\n        self.on_lrr_message(message=msg)\n\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _handle_aui(self, data):\n        msg = AUIMessage(data)\n\n        self.on_aui_message(message=msg)\n\n        return msg", "response": "Handle AUI messages.\n\n        :param data: RF message to parse\n        :type data: string\n\n        :returns: :py:class`~alarmdecoder.messages.AUIMessage`"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling received version data.", "response": "def _handle_version(self, data):\n        \"\"\"\n        Handles received version data.\n\n        :param data: Version string to parse\n        :type data: string\n        \"\"\"\n\n        _, version_string = data.split(':')\n        version_parts = version_string.split(',')\n\n        self.serial_number = version_parts[0]\n        self.version_number = version_parts[1]\n        self.version_flags = version_parts[2]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _handle_config(self, data):\n        _, config_string = data.split('>')\n        for setting in config_string.split('&'):\n            key, val = setting.split('=')\n\n            if key == 'ADDRESS':\n                self.address = int(val)\n            elif key == 'CONFIGBITS':\n                self.configbits = int(val, 16)\n            elif key == 'MASK':\n                self.address_mask = int(val, 16)\n            elif key == 'EXP':\n                self.emulate_zone = [val[z] == 'Y' for z in list(range(5))]\n            elif key == 'REL':\n                self.emulate_relay = [val[r] == 'Y' for r in list(range(4))]\n            elif key == 'LRR':\n                self.emulate_lrr = (val == 'Y')\n            elif key == 'DEDUPLICATE':\n                self.deduplicate = (val == 'Y')\n            elif key == 'MODE':\n                self.mode = PANEL_TYPES[val]\n            elif key == 'COM':\n                self.emulate_com = (val == 'Y')\n\n        self.on_config_received()", "response": "Handles received configuration data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _handle_sending(self, data):\n\n        matches = re.match('^!Sending(\\.{1,5})done.*', data)\n        if matches is not None:\n            good_send = False\n            if len(matches.group(1)) < 5:\n                good_send = True\n\n            self.on_sending_received(status=good_send, message=data)", "response": "Handles the results of a keypress send."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating internal states of the internal states of the specified message.", "response": "def _update_internal_states(self, message):\n        \"\"\"\n        Updates internal device states.\n\n        :param message: :py:class:`~alarmdecoder.messages.Message` to update internal states with\n        :type message: :py:class:`~alarmdecoder.messages.Message`, :py:class:`~alarmdecoder.messages.ExpanderMessage`, :py:class:`~alarmdecoder.messages.LRRMessage`, or :py:class:`~alarmdecoder.messages.RFMessage`\n        \"\"\"\n        if isinstance(message, Message) and not self._ignore_message_states:\n            self._update_armed_ready_status(message)\n            self._update_power_status(message)\n            self._update_chime_status(message)\n            self._update_alarm_status(message)\n            self._update_zone_bypass_status(message)\n            self._update_battery_status(message)\n            self._update_fire_status(message)\n\n        elif isinstance(message, ExpanderMessage):\n            self._update_expander_status(message)\n\n        self._update_zone_tracker(message)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_power_status(self, message=None, status=None):\n        power_status = status\n        if isinstance(message, Message):\n            power_status = message.ac_power\n\n        if power_status is None:\n            return\n\n        if power_status != self._power_status:\n            self._power_status, old_status = power_status, self._power_status\n\n            if old_status is not None:\n                self.on_power_changed(status=self._power_status)\n\n        return self._power_status", "response": "Updates the status of the AC power state."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_chime_status(self, message=None, status=None):\n        chime_status = status\n        if isinstance(message, Message):\n            chime_status = message.chime_on\n\n        if chime_status is None:\n            return\n\n        if chime_status != self._chime_status:\n            self._chime_status, old_status = chime_status, self._chime_status\n\n            if old_status is not None:\n                self.on_chime_changed(status=self._chime_status)\n\n        return self._chime_status", "response": "Updates the Chime status based on the provided message and status."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the alarm state based on the provided message bits.", "response": "def _update_alarm_status(self, message=None, status=None, zone=None, user=None):\n        \"\"\"\n        Uses the provided message to update the alarm state.\n\n        :param message: message to use to update\n        :type message: :py:class:`~alarmdecoder.messages.Message`\n        :param status: alarm status, overrides message bits.\n        :type status: bool\n        :param user: user associated with alarm event\n        :type user: string\n\n        :returns: bool indicating the new status\n        \"\"\"\n\n        alarm_status = status\n        alarm_zone = zone\n        if isinstance(message, Message):\n            alarm_status = message.alarm_sounding\n            alarm_zone = message.parse_numeric_code()\n\n        if alarm_status != self._alarm_status:\n            self._alarm_status, old_status = alarm_status, self._alarm_status\n\n            if old_status is not None or status is not None:\n                if self._alarm_status:\n                    self.on_alarm(zone=alarm_zone)\n                else:\n                    self.on_alarm_restored(zone=alarm_zone, user=user)\n\n        return self._alarm_status"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the zone bypass status for the specified message and zone.", "response": "def _update_zone_bypass_status(self, message=None, status=None, zone=None):\n        \"\"\"\n        Uses the provided message to update the zone bypass state.\n\n        :param message: message to use to update\n        :type message: :py:class:`~alarmdecoder.messages.Message`\n        :param status: bypass status, overrides message bits.\n        :type status: bool\n        :param zone: zone associated with bypass event\n        :type zone: int\n\n        :returns: dictionary {Zone:True|False,...}\n           Zone can be None if LRR CID Bypass checking is disabled\n           or we do not know what zones but know something is bypassed.\n        \"\"\"\n        bypass_status = status\n        if isinstance(message, Message):\n            bypass_status = message.zone_bypassed\n\n        if bypass_status is None:\n            return\n\n        old_bypass_status = self._bypass_status.get(zone, None)\n\n        if bypass_status != old_bypass_status:\n            if bypass_status == False and zone is None:\n                self._bypass_status = {}\n            else:\n                self._bypass_status[zone] = bypass_status\n\n            if old_bypass_status is not None or message is None or (old_bypass_status is None and bypass_status is True):\n                self.on_bypass(status=bypass_status, zone=zone)\n\n        return bypass_status"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the armed state and ready state at once.", "response": "def _update_armed_ready_status(self, message=None):\n        \"\"\"\n        Uses the provided message to update the armed state\n        and ready state at once as they can change in the same\n        message and we want both events to have the same states.\n        :param message: message to use to update\n        :type message: :py:class:`~alarmdecoder.messages.Message`\n\n        \"\"\"\n\n        arm_status = None\n        stay_status = None\n        ready_status = None\n\n        send_ready = False\n        send_arm = False\n\n        if isinstance(message, Message):\n            arm_status = message.armed_away\n            stay_status = message.armed_home\n            ready_status = message.ready\n\n        if arm_status is None or stay_status is None or ready_status is None:\n            return\n\n        self._armed_stay, old_stay = stay_status, self._armed_stay\n        self._armed_status, old_arm = arm_status, self._armed_status\n        self._ready_status, old_ready_status = ready_status, self._ready_status\n\n        if old_arm is not None:\n            if arm_status != old_arm or stay_status != old_stay:\n                send_arm = True\n\n        if old_ready_status is not None:\n            if ready_status != old_ready_status:\n                send_ready = True\n\n        if send_ready:\n            self.on_ready_changed(status=self._ready_status)\n\n        if send_arm:\n            if self._armed_status or self._armed_stay:\n                self.on_arm(stay=stay_status)\n            else:\n                self.on_disarm()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_armed_status(self, message=None, status=None, status_stay=None):\n        arm_status = status\n        stay_status = status_stay\n\n        if isinstance(message, Message):\n            arm_status = message.armed_away\n            stay_status = message.armed_home\n\n        if arm_status is None or stay_status is None:\n            return\n\n        self._armed_status, old_status = arm_status, self._armed_status\n        self._armed_stay, old_stay = stay_status, self._armed_stay\n        if arm_status != old_status or stay_status != old_stay:\n            if old_status is not None or message is None:\n                if self._armed_status or self._armed_stay:\n                    self.on_arm(stay=stay_status)\n                else:\n                    self.on_disarm()\n\n        return self._armed_status or self._armed_stay", "response": "Updates the armed state of the current state of the current state of the armed state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the internal state of the battery state.", "response": "def _update_battery_status(self, message=None, status=None):\n        \"\"\"\n        Uses the provided message to update the battery state.\n\n        :param message: message to use to update\n        :type message: :py:class:`~alarmdecoder.messages.Message`\n        :param status: battery status, overrides message bits\n        :type status: bool\n\n        :returns: boolean indicating the new status\n        \"\"\"\n        battery_status = status\n        if isinstance(message, Message):\n            battery_status = message.battery_low\n\n        if battery_status is None:\n            return\n\n        last_status, last_update = self._battery_status\n        if battery_status == last_status:\n            self._battery_status = (last_status, time.time())\n        else:\n            if battery_status is True or time.time() > last_update + self._battery_timeout:\n                self._battery_status = (battery_status, time.time())\n                self.on_low_battery(status=battery_status)\n\n        return self._battery_status[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_fire_status(self, message=None, status=None):\n        fire_status = status\n        last_status = self._fire_status\n        if isinstance(message, Message):\n            # Quirk in Ademco panels. The fire bit drops on \"SYSTEM LO BAT\" messages.\n            # FIXME: does not support non english panels.\n            if self.mode == ADEMCO and message.text.startswith(\"SYSTEM\"):\n                fire_status = last_status\n            else:\n                fire_status = message.fire_alarm\n\n        if fire_status is None:\n            return\n\n        if fire_status != self._fire_status:\n            self._fire_status, old_status = fire_status, self._fire_status\n\n            if old_status is not None:\n                self.on_fire(status=self._fire_status)\n\n        return self._fire_status", "response": "Updates the fire alarm status based on the provided message and status."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update_panic_status(self, status=None):\n        if status is None:\n            return\n\n        if status != self._panic_status:\n            self._panic_status, old_status = status, self._panic_status\n\n            if old_status is not None:\n                self.on_panic(status=self._panic_status)\n\n        return self._panic_status", "response": "Updates the panic status of the alarm panel."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the status of the expander states.", "response": "def _update_expander_status(self, message):\n        \"\"\"\n        Uses the provided message to update the expander states.\n\n        :param message: message to use to update\n        :type message: :py:class:`~alarmdecoder.messages.ExpanderMessage`\n\n        :returns: boolean indicating the new status\n        \"\"\"\n\n        if message.type == ExpanderMessage.RELAY:\n            self._relay_status[(message.address, message.channel)] = message.value\n\n            self.on_relay_changed(message=message)\n\n            return self._relay_status[(message.address, message.channel)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the zone tracker with the given message.", "response": "def _update_zone_tracker(self, message):\n        \"\"\"\n        Trigger an update of the :py:class:`~alarmdecoder.messages.Zonetracker`.\n\n        :param message: message to update the zonetracker with\n        :type message: :py:class:`~alarmdecoder.messages.Message`, :py:class:`~alarmdecoder.messages.ExpanderMessage`, :py:class:`~alarmdecoder.messages.LRRMessage`, or :py:class:`~alarmdecoder.messages.RFMessage`\n        \"\"\"\n\n        # Retrieve a list of faults.\n        # NOTE: This only happens on first boot or after exiting programming mode.\n        if isinstance(message, Message):\n            if not message.ready and (\"Hit * for faults\" in message.text or \"Press *  to show faults\" in message.text):\n                if time.time() > self.last_fault_expansion + self.fault_expansion_time_limit:\n                    self.last_fault_expansion = time.time()\n                    self.send('*')\n                    return\n\n        self._zonetracker.update(message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, message):\n        if isinstance(message, ExpanderMessage):\n            zone = -1\n\n            if message.type == ExpanderMessage.ZONE:\n                zone = self.expander_to_zone(message.address, message.channel, self.alarmdecoder_object.mode)\n\n            if zone != -1:\n                status = Zone.CLEAR\n                if message.value == 1:\n                    status = Zone.FAULT\n                elif message.value == 2:\n                    status = Zone.CHECK\n\n                # NOTE: Expander zone faults are handled differently than\n                #       regular messages.  We don't include them in\n                #       self._zones_faulted because they are not reported\n                #       by the panel in it's rolling list of faults.\n                try:\n                    self._update_zone(zone, status=status)\n\n                except IndexError:\n                    self._add_zone(zone, status=status, expander=True)\n\n        else:\n            # Panel is ready, restore all zones.\n            #\n            # NOTE: This will need to be updated to support panels with\n            #       multiple partitions.  In it's current state a ready on\n            #       partition #1 will end up clearing all zones, even if they\n            #       exist elsewhere and it shouldn't.\n            #\n            # NOTE: SYSTEM messages provide inconsistent ready statuses.  This\n            #       may need to be extended later for other panels.\n            if message.ready and not message.text.startswith(\"SYSTEM\"):\n                for zone in self._zones_faulted:\n                    self._update_zone(zone, Zone.CLEAR)\n\n                self._last_zone_fault = 0\n\n            # Process fault\n            elif self.alarmdecoder_object.mode != DSC and (message.check_zone or message.text.startswith(\"FAULT\") or message.text.startswith(\"ALARM\")):\n                zone = message.parse_numeric_code()\n\n                # NOTE: Odd case for ECP failures.  Apparently they report as\n                #       zone 191 (0xBF) regardless of whether or not the\n                #       3-digit mode is enabled... so we have to pull it out\n                #       of the alpha message.\n                if zone == 191:\n                    zone_regex = re.compile('^CHECK (\\d+).*$')\n\n                    match = zone_regex.match(message.text)\n                    if match is None:\n                        return\n\n                    zone = match.group(1)\n\n                # Add new zones and clear expired ones.\n                if zone in self._zones_faulted:\n                    self._update_zone(zone)\n                    self._clear_zones(zone)\n\n                else:\n                    status = Zone.FAULT\n                    if message.check_zone:\n                        status = Zone.CHECK\n\n                    self._add_zone(zone, status=status)\n                    self._zones_faulted.append(zone)\n                    self._zones_faulted.sort()\n\n                # Save our spot for the next message.\n                self._last_zone_fault = zone\n\n            self._clear_expired_zones()", "response": "Update the status of the current zone tracking."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef expander_to_zone(self, address, channel, panel_type=ADEMCO):\n\n        zone = -1\n\n        if panel_type == ADEMCO:\n            # TODO: This is going to need to be reworked to support the larger\n            #       panels without fixed addressing on the expanders.\n\n            idx = address - 7   # Expanders start at address 7.\n            zone = address + channel + (idx * 7) + 1\n\n        elif panel_type == DSC:\n            zone = (address * 8) + channel\n\n        return zone", "response": "Convert an address and channel into a zone number."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nclear all expired zones from our status list.", "response": "def _clear_zones(self, zone):\n        \"\"\"\n        Clear all expired zones from our status list.\n\n        :param zone: current zone being processed\n        :type zone: int\n        \"\"\"\n        cleared_zones = []\n        found_last_faulted = found_current = at_end = False\n\n        # First pass: Find our start spot.\n        it = iter(self._zones_faulted)\n        try:\n            while not found_last_faulted:\n                z = next(it)\n\n                if z == self._last_zone_fault:\n                    found_last_faulted = True\n                    break\n\n        except StopIteration:\n            at_end = True\n\n        # Continue until we find our end point and add zones in\n        # between to our clear list.\n        try:\n            while not at_end and not found_current:\n                z = next(it)\n\n                if z == zone:\n                    found_current = True\n                    break\n                else:\n                    cleared_zones += [z]\n\n        except StopIteration:\n            pass\n\n        # Second pass: roll through the list again if we didn't find\n        # our end point and remove everything until we do.\n        if not found_current:\n            it = iter(self._zones_faulted)\n\n            try:\n                while not found_current:\n                    z = next(it)\n\n                    if z == zone:\n                        found_current = True\n                        break\n                    else:\n                        cleared_zones += [z]\n\n            except StopIteration:\n                pass\n\n        # Actually remove the zones and trigger the restores.\n        for z in cleared_zones:\n            self._update_zone(z, Zone.CLEAR)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates zone status for all expired zones.", "response": "def _clear_expired_zones(self):\n        \"\"\"\n        Update zone status for all expired zones.\n        \"\"\"\n        zones = []\n\n        for z in list(self._zones.keys()):\n            zones += [z]\n\n        for z in zones:\n            if self._zones[z].status != Zone.CLEAR and self._zone_expired(z):\n                self._update_zone(z, Zone.CLEAR)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a zone to the internal zone list.", "response": "def _add_zone(self, zone, name='', status=Zone.CLEAR, expander=False):\n        \"\"\"\n        Adds a zone to the internal zone list.\n\n        :param zone: zone number\n        :type zone: int\n        :param name: human readable zone name\n        :type name: string\n        :param status: zone status\n        :type status: int\n        \"\"\"\n        if not zone in self._zones:\n            self._zones[zone] = Zone(zone=zone, name=name, status=None, expander=expander)\n\n        self._update_zone(zone, status=status)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_zone(self, zone, status=None):\n        if not zone in self._zones:\n            raise IndexError('Zone does not exist and cannot be updated: %d', zone)\n\n        old_status = self._zones[zone].status\n        if status is None:\n            status = old_status\n\n        self._zones[zone].status = status\n        self._zones[zone].timestamp = time.time()\n\n        if status == Zone.CLEAR:\n            if zone in self._zones_faulted:\n                self._zones_faulted.remove(zone)\n\n            self.on_restore(zone=zone)\n        else:\n            if old_status != status and status is not None:\n                self.on_fault(zone=zone)", "response": "Updates a zone status."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetermines if a zone is expired or not.", "response": "def _zone_expired(self, zone):\n        \"\"\"\n        Determine if a zone is expired or not.\n\n        :param zone: zone number\n        :type zone: int\n\n        :returns: whether or not the zone is expired\n        \"\"\"\n        return (time.time() > self._zones[zone].timestamp + Zonetracker.EXPIRE) and self._zones[zone].expander is False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bytes_available(device):\n    bytes_avail = 0\n\n    if isinstance(device, alarmdecoder.devices.SerialDevice):\n        if hasattr(device._device, \"in_waiting\"):\n            bytes_avail = device._device.in_waiting\n        else:\n            bytes_avail = device._device.inWaiting()\n    elif isinstance(device, alarmdecoder.devices.SocketDevice):\n        bytes_avail = 4096\n\n    return bytes_avail", "response": "Determines the number of bytes available for reading from an animal base."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_firmware_file(file_path):\n    data_queue = deque()\n\n    with open(file_path) as firmware_handle:\n        for line in firmware_handle:\n            line = line.rstrip()\n            if line != '' and line[0] == ':':\n                data_queue.append(line + \"\\r\")\n\n    return data_queue", "response": "Reads a firmware file into a deque for processing."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read(device):\n        response = None\n        bytes_avail = bytes_available(device)\n\n        if isinstance(device, alarmdecoder.devices.SerialDevice):\n            response = device._device.read(bytes_avail)\n        elif isinstance(device, alarmdecoder.devices.SocketDevice):\n            response = device._device.recv(bytes_avail)\n\n        return response", "response": "Reads data from the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads a firmware file to an AlarmDecoder_ device.", "response": "def upload(device, file_path, progress_callback=None, debug=False):\n        \"\"\"\n        Uploads firmware to an `AlarmDecoder`_ device.\n\n        :param file_path: firmware file path\n        :type file_path: string\n        :param progress_callback: callback function used to report progress\n        :type progress_callback: function\n\n        :raises: :py:class:`~alarmdecoder.util.NoDeviceError`, :py:class:`~alarmdecoder.util.TimeoutError`\n        \"\"\"\n\n        def progress_stage(stage, **kwargs):\n            \"\"\"Callback to update progress for the specified stage.\"\"\"\n            if progress_callback is not None:\n                progress_callback(stage, **kwargs)\n\n            return stage\n\n        if device is None:\n            raise NoDeviceError('No device specified for firmware upload.')\n\n        fds = [device._device.fileno()]\n\n        # Read firmware file into memory\n        try:\n            write_queue = read_firmware_file(file_path)\n        except IOError as err:\n            stage = progress_stage(Firmware.STAGE_ERROR, error=str(err))\n            return\n\n        data_read = ''\n        got_response = False\n        running = True\n        stage = progress_stage(Firmware.STAGE_START)\n\n        if device.is_reader_alive():\n            # Close the reader thread and wait for it to die, otherwise\n            # it interferes with our reading.\n            device.stop_reader()\n            while device._read_thread.is_alive():\n                stage = progress_stage(Firmware.STAGE_WAITING)\n                time.sleep(0.5)\n\n            time.sleep(3)\n\n        try:\n            while running:\n                rr, wr, _ = select.select(fds, fds, [], 0.5)\n\n                if len(rr) != 0:\n                    response = Firmware.read(device)\n\n                    for c in response:\n                        # HACK: Python 3 / PySerial hack.\n                        if isinstance(c, int):\n                            c = chr(c)\n\n                        if c == '\\xff' or c == '\\r':    # HACK: odd case for our mystery \\xff byte.\n                            # Boot started, start looking for the !boot message\n                            if data_read.startswith(\"!sn\"):\n                                stage = progress_stage(Firmware.STAGE_BOOT)\n                            # Entered bootloader upload mode, start uploading\n                            elif data_read.startswith(\"!load\"):\n                                got_response = True\n                                stage = progress_stage(Firmware.STAGE_UPLOADING)\n                            # Checksum error\n                            elif data_read == '!ce':\n                                running = False\n                                raise UploadChecksumError(\"Checksum error in {0}\".format(file_path))\n                            # Bad data\n                            elif data_read == '!no':\n                                running = False\n                                raise UploadError(\"Incorrect data sent to bootloader.\")\n                            # Firmware upload complete\n                            elif data_read == '!ok':\n                                running = False\n                                stage = progress_stage(Firmware.STAGE_DONE)\n                            # All other responses are valid during upload.\n                            else:\n                                got_response = True\n                                if stage == Firmware.STAGE_UPLOADING:\n                                    progress_stage(stage)\n\n                            data_read = ''\n                        elif c == '\\n':\n                            pass\n                        else:\n                            data_read += c\n\n                if len(wr) != 0:\n                    # Reboot device\n                    if stage in [Firmware.STAGE_START, Firmware.STAGE_WAITING]:\n                        device.write('=')\n                        stage = progress_stage(Firmware.STAGE_WAITING_ON_LOADER)\n\n                    # Enter bootloader\n                    elif stage == Firmware.STAGE_BOOT:\n                        device.write('=')\n                        stage = progress_stage(Firmware.STAGE_LOAD)\n\n                    # Upload firmware\n                    elif stage == Firmware.STAGE_UPLOADING:\n                        if len(write_queue) > 0 and got_response == True:\n                            got_response = False\n                            device.write(write_queue.popleft())\n\n        except UploadError as err:\n            stage = progress_stage(Firmware.STAGE_ERROR, error=str(err))\n        else:\n            stage = progress_stage(Firmware.STAGE_DONE)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    try:\n        # Start up the detection thread such that handle_attached and handle_detached will\n        # be called when devices are attached and detached, respectively.\n        USBDevice.start_detection(on_attached=handle_attached, on_detached=handle_detached)\n\n        # Wait for events.\n        while True:\n            time.sleep(1)\n\n    except Exception as ex:\n        print('Exception:', ex)\n\n    finally:\n        # Close all devices and stop detection.\n        for sn, device in __devices.items():\n            device.close()\n\n        USBDevice.stop_detection()", "response": "This is the main function for the USB device management. It is a simple example application that shows how to handle attach and detach events generated by USB devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_device(device_args):\n    device = AlarmDecoder(USBDevice.find(device_args))\n    device.on_message += handle_message\n    device.open()\n\n    return device", "response": "Creates an AlarmDecoder from the specified USB device arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nhandling attached events from USBDevice. start_detection.", "response": "def handle_attached(sender, device):\n    \"\"\"\n    Handles attached events from USBDevice.start_detection().\n    \"\"\"\n    # Create the device from the specified device arguments.\n    dev = create_device(device)\n    __devices[dev.id] = dev\n\n    print('attached', dev.id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_detached(sender, device):\n    vendor, product, sernum, ifcount, description = device\n\n    # Close and remove the device from our list.\n    if sernum in list(__devices.keys()):\n        __devices[sernum].close()\n\n        del __devices[sernum]\n\n    print('detached', sernum)", "response": "Handle a USBDevice. DETACH event from USBDevice. start_detection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the encoded version of a string.", "response": "def encode(cls, string, errors='strict'):\n        \"\"\"Return the encoded version of a string.\n\n        :param string:\n            The input string to encode.\n        :type string:\n            `basestring`\n\n        :param errors:\n            The error handling scheme. Only 'strict' is supported.\n        :type errors:\n            `basestring`\n\n        :return:\n            Tuple of encoded string and number of input bytes consumed.\n        :rtype:\n            `tuple` (`unicode`, `int`)\n        \"\"\"\n        if errors != 'strict':\n            raise UnicodeError('Unsupported error handling {0}'.format(errors))\n\n        unicode_string = cls._ensure_unicode_string(string)\n        encoded = unicode_string.translate(cls._encoding_table)\n        return encoded, len(string)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef decode(cls, string, errors='strict'):\n        if errors != 'strict':\n            raise UnicodeError('Unsupported error handling {0}'.format(errors))\n\n        unicode_string = cls._ensure_unicode_string(string)\n        decoded = unicode_string.translate(cls._decoding_table)\n        return decoded, len(string)", "response": "Return the decoded version of a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch function to find a codec in the codec manager.", "response": "def search_function(cls, encoding):\n        \"\"\"Search function to find 'rotunicode' codec.\"\"\"\n        if encoding == cls._codec_name:\n            return codecs.CodecInfo(\n                name=cls._codec_name,\n                encode=cls.encode,\n                decode=cls.decode,\n            )\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _ensure_unicode_string(string):\n        if not isinstance(string, six.text_type):\n            string = string.decode('utf-8')\n        return string", "response": "Ensures that the input string is a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncommanding line tool for listing the current state of a single resource.", "response": "def cli():\n    \"\"\"Command line tool.\"\"\"\n    parser = argparse.ArgumentParser()\n    parser.add_argument('api', help=\"\"\"\n        API to call.\n        One one of 'article', 'frontpage', 'product', 'image', 'analyze', or\n        'discussion'.\n    \"\"\")\n    parser.add_argument('url', help=\"\"\"\n        URL to pass as the 'url' parameter.\n    \"\"\")\n    parser.add_argument('token', help=\"\"\"\n        API key (token).\n        Get one at https://www.diffbot.com/.\n    \"\"\")\n    parser.add_argument('-a', '--all', help=\"\"\"\n        Request all fields.\n    \"\"\", action='store_true')\n    parser.add_argument('-f', '--file', help=\"\"\"\n        File to read data from.\n        Use '-' to read from STDIN.\n    \"\"\")\n    fields = text = html = None\n    _args = parser.parse_args()\n    if _args.all:\n        fields = '*'\n    if _args.file == '-':\n        text = sys.stdin.read()\n    elif _args.file:\n        with open(_args.file, 'rb') as src:\n            if os.path.splitext(_args.file)[1] in ('.html', '.htm'):\n                html = src.read().decode(ENCODING)\n            else:\n                text = src.read().decode(ENCODING)\n    print(json.dumps((api(_args.api, _args.url, _args.token,\n                          html=html or None,\n                          text=text or None,\n                          fields=fields)),\n                     sort_keys=True,\n                     indent=2))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crawl(self, urls, name='crawl', api='analyze', **kwargs):\n        # If multiple seed URLs are specified, join with whitespace.\n        if isinstance(urls, list):\n            urls = ' '.join(urls)\n        url = self.endpoint('crawl')\n        process_url = self.endpoint(api)\n        params = {\n            'token': self._token,\n            'seeds': urls,\n            'name': name,\n            'apiUrl': process_url,\n        }\n\n        # Add any additional named parameters as accepted by Crawlbot\n        params['maxToCrawl'] = 10\n        params.update(kwargs)\n\n        self._get(url, params=params)\n\n        return Job(self._token, name, self._version)", "response": "Crawl the given seed URLs and return a Job object to check and retrieve crawl status."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n    try:\n        # Retrieve the first USB device\n        device = AlarmDecoder(SerialDevice(interface=SERIAL_DEVICE))\n\n        # Set up an event handler and open the device\n        device.on_lrr_message += handle_lrr_message\n        with device.open(baudrate=BAUDRATE):\n            while True:\n                time.sleep(1)\n\n    except Exception as ex:\n        print('Exception:', ex)", "response": "This is the main function that opens the USB device and prints messages from the panel to the terminal."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nhandle messages from the AlarmDecoder.", "response": "def handle_lrr_message(sender, message):\n    \"\"\"\n    Handles message events from the AlarmDecoder.\n    \"\"\"\n    print(sender, message.partition, message.event_type, message.event_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_alarm(sender, **kwargs):\n    zone = kwargs.pop('zone', None)\n    text = \"Alarm: Zone {0}\".format(zone)\n\n    # Build the email message\n    msg = MIMEText(text)\n    msg['Subject'] = SUBJECT\n    msg['From'] = FROM_ADDRESS\n    msg['To'] = TO_ADDRESS\n\n    s = smtplib.SMTP(SMTP_SERVER)\n\n    # Authenticate if needed\n    if SMTP_USERNAME is not None:\n        s.login(SMTP_USERNAME, SMTP_PASSWORD)\n\n    # Send the email\n    s.sendmail(FROM_ADDRESS, TO_ADDRESS, msg.as_string())\n    s.quit()\n\n    print('sent alarm email:', text)", "response": "Handles alarm events from the AlarmDecoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the raw message from the device and sets the attributes of the object.", "response": "def _parse_message(self, data):\n        \"\"\"\n        Parses the raw message from the device.\n\n        :param data: message data to parse\n        :type data: string\n\n        :raises: :py:class:`~alarmdecoder.util.InvalidMessageError`\n        \"\"\"\n        try:\n            _, values = data.split(':')\n            values = values.split(',')\n\n            # Handle older-format events\n            if len(values) <= 3:\n                self.event_data, self.partition, self.event_type = values\n                self.version = 1\n\n            # Newer-format events\n            else:\n                self.event_data, self.partition, self.event_type, self.report_code = values\n                self.version = 2\n\n                event_type_data = self.event_type.split('_')\n                self.event_prefix = event_type_data[0]                      # Ex: CID\n                self.event_source = get_event_source(self.event_prefix)     # Ex: LRR_EVENT_TYPE.CID\n                self.event_status = int(event_type_data[1][0])              # Ex: 1 or 3\n                self.event_code = int(event_type_data[1][1:], 16)           # Ex: 0x100 = Medical\n\n                # replace last 2 digits of event_code with report_code, if applicable.\n                if not self.skip_report_override and self.report_code not in ['00', 'ff']:\n                    self.event_code = int(event_type_data[1][1] + self.report_code, 16)\n                self.event_description = get_event_description(self.event_source, self.event_code)\n\n        except ValueError:\n            raise InvalidMessageError('Received invalid message: {0}'.format(data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary representation of the object.", "response": "def dict(self, **kwargs):\n        \"\"\"\n        Dictionary representation\n        \"\"\"\n        return dict(\n            time                  = self.timestamp,\n            event_data            = self.event_data,\n            event_type            = self.event_type,\n            partition             = self.partition,\n            report_code           = self.report_code,\n            event_prefix          = self.event_prefix,\n            event_source          = self.event_source,\n            event_status          = self.event_status,\n            event_code            = hex(self.event_code),\n            event_description     = self.event_description,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrotate ASCII < > non - ASCII characters in a file.", "response": "def rotunicode(io_object, decode=False):\n    \"\"\"Rotate ASCII <-> non-ASCII characters in a file.\n\n    :param io_object:\n        The file object to convert.\n    :type io_object:\n        :class:`io.TextIOWrapper`\n    :param decode:\n        If True, perform a rotunicode-decode (rotate from non-ASCII to ASCII).\n        Defaults to False (rotate from ASCII to non-ASCII).\n    :type decode:\n        `bool`\n    :return:\n        Yield the converted lines of the file.\n    :rtype:\n        `generator` of `unicode`\n    \"\"\"\n    rotu_fn = get_rotunicode_function_for_decode_argument(decode=decode)\n    return map(rotu_fn, map(safe_unicode, stream_file_lines(io_object)))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ruencode(string, extension=False):\n    if extension:\n        file_name = string\n        file_ext = ''\n    else:\n        file_name, file_ext = splitext(string)\n\n    encoded_value, _ = _ROT_UNICODE.encode(file_name)\n    return encoded_value + file_ext", "response": "Encode a string using rotunicode codec."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a string for possible escape sequences.", "response": "def parse_escape_sequences(string):\n    \"\"\"Parse a string for possible escape sequences.\n\n    Sample usage:\n    >>> parse_escape_sequences('foo\\\\nbar')\n    'foo\\nbar'\n    >>> parse_escape_sequences('foo\\\\\\\\u0256')\n    'foo\\\\u0256'\n\n    :param string:\n        Any string.\n    :type string:\n        `basestring`\n    :raises:\n        :class:`ValueError` if a backslash character is found, but it doesn't\n        form a proper escape sequence with the character(s) that follow.\n    :return:\n        The parsed string. Will parse the standard escape sequences, and also\n        basic \\\\uxxxx escape sequences.\n        \\\\uxxxxxxxxxx escape sequences are not currently supported.\n    :rtype:\n        `unicode`\n    \"\"\"\n    string = safe_unicode(string)\n    characters = []\n    i = 0\n    string_len = len(string)\n    while i < string_len:\n        character = string[i]\n        if character == '\\\\':\n            # Figure out the size of the escape sequence. Most escape sequences\n            # are two characters (e.g. '\\\\' and 'n'), with the sole exception\n            # being \\uxxxx escape sequences, which are six characters.\n            if string[(i + 1):(i + 2)] == 'u':\n                offset = 6\n            else:\n                offset = 2\n\n            try:\n                # `json.decoder.scanstring()` mostly does what we want, but it\n                # also does some stuff that we don't want, like parsing quote\n                # characters. This will mess us up. The iteration and scanning\n                # within this loop is meant to isolate the escape sequences, so\n                # that we'll always be calling it with something like\n                # >>> scanstring('\"\\n\"', 1)\n                # or\n                # >>> scanstring('\"\\u0256\"', 1)\n                # The 1 refers to the location of the first character after the\n                # open quote character.\n                json_string = '\"' + string[i:(i + offset)] + '\"'\n                character = scanstring(json_string, 1)[0]\n                characters.append(character)\n                i += offset\n            except ValueError:\n                # If an exception was raised, raise a new `ValueError`. The\n                # reason we don't re-raise the original exception is because,\n                # in Python 3, it is a custom JSON `ValueError` subclass. We\n                # don't want to raise a JSON error from a function that has\n                # nothing to do with JSON, so we create a new `ValueError`. The\n                # error message is also nonsensical to the caller, in all\n                # cases.\n                raise_from(ValueError(string), None)\n        else:\n            characters.append(character)\n            i += 1\n    return ''.join(characters)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_all(cls, vid=None, pid=None):\n        if not have_pyftdi:\n            raise ImportError('The USBDevice class has been disabled due to missing requirement: pyftdi or pyusb.')\n\n        cls.__devices = []\n\n        query = cls.PRODUCT_IDS\n        if vid and pid:\n            query = [(vid, pid)]\n\n        try:\n            cls.__devices = Ftdi.find_all(query, nocache=True)\n\n        except (usb.core.USBError, FtdiError) as err:\n            raise CommError('Error enumerating AD2USB devices: {0}'.format(str(err)), err)\n\n        return cls.__devices", "response": "Returns all FTDI devices matching our vendor and product IDs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(cls, device=None):\n        if not have_pyftdi:\n            raise ImportError('The USBDevice class has been disabled due to missing requirement: pyftdi or pyusb.')\n\n        cls.find_all()\n\n        if len(cls.__devices) == 0:\n            raise NoDeviceError('No AD2USB devices present.')\n\n        if device is None:\n            device = cls.__devices[0]\n\n        vendor, product, sernum, ifcount, description = device\n\n        return USBDevice(interface=sernum, vid=vendor, pid=product)", "response": "Returns the USBDevice object for the specified device."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstart the device detection thread.", "response": "def start_detection(cls, on_attached=None, on_detached=None):\n        \"\"\"\n        Starts the device detection thread.\n\n        :param on_attached: function to be called when a device is attached  **Callback definition:** *def callback(thread, device)*\n        :type on_attached: function\n        :param on_detached: function to be called when a device is detached  **Callback definition:** *def callback(thread, device)*\n\n        :type on_detached: function\n        \"\"\"\n        if not have_pyftdi:\n            raise ImportError('The USBDevice class has been disabled due to missing requirement: pyftdi or pyusb.')\n\n        cls.__detect_thread = USBDevice.DetectThread(on_attached, on_detached)\n\n        try:\n            cls.find_all()\n        except CommError:\n            pass\n\n        cls.__detect_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interface(self, value):\n        self._interface = value\n        if isinstance(value, int):\n            self._device_number = value\n        else:\n            self._serial_number = value", "response": "Sets the interface used to connect to the device."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef open(self, baudrate=BAUDRATE, no_reader_thread=False):\n        # Set up defaults\n        if baudrate is None:\n            baudrate = USBDevice.BAUDRATE\n\n        self._read_thread = Device.ReadThread(self)\n\n        # Open the device and start up the thread.\n        try:\n            self._device.open(self._vendor_id,\n                              self._product_id,\n                              self._endpoint,\n                              self._device_number,\n                              self._serial_number,\n                              self._description)\n\n            self._device.set_baudrate(baudrate)\n\n            if not self._serial_number:\n                self._serial_number = self._get_serial_number()\n\n            self._id = self._serial_number\n\n        except (usb.core.USBError, FtdiError) as err:\n            raise NoDeviceError('Error opening device: {0}'.format(str(err)), err)\n\n        except KeyError as err:\n            raise NoDeviceError('Unsupported device. ({0:04x}:{1:04x})  You probably need a newer version of pyftdi.'.format(err[0][0], err[0][1]))\n\n        else:\n            self._running = True\n            self.on_open()\n\n            if not no_reader_thread:\n                self._read_thread.start()\n\n        return self", "response": "Opens the device and starts the read thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, data):\n        try:\n            self._device.write_data(data)\n\n            self.on_write(data=data)\n\n        except FtdiError as err:\n            raise CommError('Error writing to device: {0}'.format(str(err)), err)", "response": "Writes data to the device."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread a single character from the device.", "response": "def read(self):\n        \"\"\"\n        Reads a single character from the device.\n\n        :returns: character read from the device\n        :raises: :py:class:`~alarmdecoder.util.CommError`\n        \"\"\"\n        ret = None\n\n        try:\n            ret = self._device.read_data(1)\n\n        except (usb.core.USBError, FtdiError) as err:\n            raise CommError('Error reading from device: {0}'.format(str(err)), err)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a single line from the device.", "response": "def read_line(self, timeout=0.0, purge_buffer=False):\n        \"\"\"\n        Reads a line from the device.\n\n        :param timeout: read timeout\n        :type timeout: float\n        :param purge_buffer: Indicates whether to purge the buffer prior to\n                             reading.\n        :type purge_buffer: bool\n\n        :returns: line that was read\n        :raises: :py:class:`~alarmdecoder.util.CommError`, :py:class:`~alarmdecoder.util.TimeoutError`\n        \"\"\"\n\n        def timeout_event():\n            \"\"\"Handles read timeout event\"\"\"\n            timeout_event.reading = False\n        timeout_event.reading = True\n\n        if purge_buffer:\n            self._buffer = b''\n\n        got_line, ret = False, None\n\n        timer = threading.Timer(timeout, timeout_event)\n        if timeout > 0:\n            timer.start()\n\n        try:\n            while timeout_event.reading:\n                buf = self._device.read_data(1)\n\n                if buf != b'':\n                    ub = bytes_hack(buf)\n\n                    self._buffer += ub\n\n                    if ub == b\"\\n\":\n                        self._buffer = self._buffer.rstrip(b\"\\r\\n\")\n\n                        if len(self._buffer) > 0:\n                            got_line = True\n                            break\n                else:\n                    time.sleep(0.01)\n\n        except (usb.core.USBError, FtdiError) as err:\n            raise CommError('Error reading from device: {0}'.format(str(err)), err)\n\n        else:\n            if got_line:\n                ret, self._buffer = self._buffer, b''\n\n                self.on_read(data=ret)\n\n            else:\n                raise TimeoutError('Timeout while waiting for line terminator.')\n\n        finally:\n            timer.cancel()\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the FTDI device serial number.", "response": "def _get_serial_number(self):\n        \"\"\"\n        Retrieves the FTDI device serial number.\n\n        :returns: string containing the device serial number\n        \"\"\"\n        return usb.util.get_string(self._device.usb_dev, 64, self._device.usb_dev.iSerialNumber)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_color(color):\n    if len(color) not in (3, 4, 6, 8):\n        raise ValueError('bad color %s' % repr(color))\n    if len(color) in (3, 4):\n        r = int(color[0], 16) * 0x11\n        g = int(color[1], 16) * 0x11\n        b = int(color[2], 16) * 0x11\n    elif len(color) in (6, 8):\n        r = int(color[0:2], 16)\n        g = int(color[2:4], 16)\n        b = int(color[4:6], 16)\n    if len(color) == 4:\n        a = int(color[3], 16) * 0x11\n    elif len(color) == 8:\n        a = int(color[6:8], 16)\n    else:\n        a = 0xff\n    return (r, g, b, a)", "response": "Parse a color value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_color(option, opt, value):\n    try:\n        return parse_color(value)\n    except ValueError:\n        raise optparse.OptionValueError(\"option %s: invalid color value: %r\"\n                                         % (opt, value))", "response": "Validate and convert an option value of type color."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npick a tiling orientation for two images.", "response": "def pick_orientation(img1, img2, spacing, desired_aspect=1.618):\n    \"\"\"Pick a tiling orientation for two images.\n\n    Returns either 'lr' for left-and-right, or 'tb' for top-and-bottom.\n\n    Picks the one that makes the combined image have a better aspect\n    ratio, where 'better' is defined as 'closer to 1:1.618'.\n    \"\"\"\n    w1, h1 = img1.size\n    w2, h2 = img2.size\n\n    size_a = (w1 + spacing + w2, max(h1, h2, 1))\n    size_b = (max(w1, w2, 1), h1 + spacing + h2)\n\n    aspect_a = size_a[0] / size_a[1]\n    aspect_b = size_b[0] / size_b[1]\n\n    goodness_a = min(desired_aspect, aspect_a) / max(desired_aspect, aspect_a)\n    goodness_b = min(desired_aspect, aspect_b) / max(desired_aspect, aspect_b)\n\n    return 'lr' if goodness_a >= goodness_b else 'tb'"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tile_images(img1, img2, mask1, mask2, opts):\n    w1, h1 = img1.size\n    w2, h2 = img2.size\n\n    if opts.orientation == 'auto':\n        opts.orientation = pick_orientation(img1, img2, opts.spacing)\n\n    B, S = opts.border, opts.spacing\n\n    if opts.orientation == 'lr':\n        w, h = (B + w1 + S + w2 + B, B + max(h1, h2) + B)\n        pos1 = (B, (h - h1) // 2)\n        pos2 = (B + w1 + S, (h - h2) // 2)\n        separator_line = [(B + w1 + S//2, 0), (B + w1 + S//2, h)]\n    else:\n        w, h = (B + max(w1, w2) + B, B + h1 + S + h2 + B)\n        pos1 = ((w - w1) // 2, B)\n        pos2 = ((w - w2) // 2, B + h1 + S)\n        separator_line = [(0, B + h1 + S//2), (w, B + h1 + S//2)]\n\n    img = Image.new('RGBA', (w, h), opts.bgcolor)\n\n    img.paste(img1, pos1, mask1)\n    img.paste(img2, pos2, mask2)\n\n    ImageDraw.Draw(img).line(separator_line, fill=opts.sepcolor)\n\n    return img", "response": "Combine two images into one by tiling them."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef spawn_viewer(viewer, img, filename, grace):\n    tempdir = tempfile.mkdtemp(prefix='imgdiff-')\n    try:\n        imgfile = os.path.join(tempdir, filename)\n        img.save(imgfile)\n        started = time.time()\n        subprocess.call([viewer, imgfile])\n        elapsed = time.time() - started\n        if elapsed < grace:\n            # Program exited too quickly. I think it forked and so may not\n            # have had enough time to even start looking for the temp file\n            # we just created. Wait a bit before removing the temp file.\n            time.sleep(grace - elapsed)\n    finally:\n        shutil.rmtree(tempdir)", "response": "Spawns an external viewer to view an image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tweak_diff(diff, opacity):\n    mask = diff.point(lambda i: opacity + i * (255 - opacity) // 255)\n    return mask", "response": "Adjust a difference map into an opacity mask for a given lowest opacity."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef diff(img1, img2, x1y1, x2y2):\n    x1, y1 = x1y1\n    x2, y2 = x2y2\n    w1, h1 = img1.size\n    w2, h2 = img2.size\n    w, h = min(w1, w2), min(h1, h2)\n    diff = ImageChops.difference(img1.crop((x1, y1, x1+w, y1+h)),\n                                 img2.crop((x2, y2, x2+w, y2+h)))\n    diff = diff.convert('L')\n    return diff", "response": "Compare two images with given alignments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nestimate the badness value of a difference map.", "response": "def diff_badness(diff):\n    \"\"\"Estimate the \"badness\" value of a difference map.\n\n    Returns 0 if the pictures are identical\n\n    Returns a large number if the pictures are completely different\n    (e.g. a black field and a white field).  More specifically, returns\n    ``255 * width * height`` where ``(width, height) == diff.size``.\n\n    Returns something in between for other situations.\n    \"\"\"\n    # identical pictures = black image = return 0\n    # completely different pictures = white image = return lots\n    return sum(i * n for i, n in enumerate(diff.histogram()))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef best_diff(img1, img2, opts):\n    w1, h1 = img1.size\n    w2, h2 = img2.size\n    w, h = min(w1, w2), min(h1, h2)\n    best = None\n    best_value = 255 * w * h + 1\n\n    xr = abs(w1 - w2) + 1\n    yr = abs(h1 - h2) + 1\n\n    p = Progress(xr * yr, timeout=opts.timeout)\n    for x in range(xr):\n        if w1 > w2:\n            x1, x2 = x, 0\n        else:\n            x1, x2 = 0, x\n        for y in range(yr):\n            if h1 > h2:\n                y1, y2 = y, 0\n            else:\n                y1, y2 = 0, y\n            p.next()\n            this = diff(img1, img2, (x1, y1), (x2, y2))\n            this_value = diff_badness(this)\n            if this_value < best_value:\n                best = this\n                best_value = this_value\n                best_pos = (x1, y1), (x2, y2)\n    return best, best_pos", "response": "Find the best alignment of two images that minimizes the differences."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to align the two images to minimize pixel differences. Produces two masks for img1 and img2. The algorithm works by comparing every possible alignment of the images, finding the aligment that minimzes the differences, and then smoothing it a bit to reduce spurious matches in areas that are perceptibly different (e.g. text).", "response": "def simple_highlight(img1, img2, opts):\n    \"\"\"Try to align the two images to minimize pixel differences.\n\n    Produces two masks for img1 and img2.\n\n    The algorithm works by comparing every possible alignment of the images,\n    finding the aligment that minimzes the differences, and then smoothing\n    it a bit to reduce spurious matches in areas that are perceptibly\n    different (e.g. text).\n    \"\"\"\n\n    try:\n        diff, ((x1, y1), (x2, y2)) = best_diff(img1, img2, opts)\n    except KeyboardInterrupt:\n        return None, None\n    diff = diff.filter(ImageFilter.MaxFilter(9))\n    diff = tweak_diff(diff, opts.opacity)\n    # If the images have different sizes, the areas outside the alignment\n    # zone are considered to be dissimilar -- filling them with 0xff.\n    # Perhaps it would be better to compare those bits with bars of solid\n    # color, filled with opts.bgcolor?\n    mask1 = Image.new('L', img1.size, 0xff)\n    mask2 = Image.new('L', img2.size, 0xff)\n    mask1.paste(diff, (x1, y1))\n    mask2.paste(diff, (x2, y2))\n    return mask1, mask2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntry to find similar areas between two images.", "response": "def slow_highlight(img1, img2, opts):\n    \"\"\"Try to find similar areas between two images.\n\n    Produces two masks for img1 and img2.\n\n    The algorithm works by comparing every possible alignment of the images,\n    smoothing it a bit to reduce spurious matches in areas that are\n    perceptibly different (e.g. text), and then taking the point-wise minimum\n    of all those difference maps.\n\n    This way if you insert a few pixel rows/columns into an image, similar\n    areas should match even if different areas need to be aligned with\n    different shifts.\n\n    As you can imagine, this brute-force approach can be pretty slow, if\n    there are many possible alignments.  The closer the images are in size,\n    the faster this will work.\n\n    If would work better if it could compare alignments that go beyond the\n    outer boundaries of the images, in case some pixels got shifted closer\n    to an edge.\n    \"\"\"\n    w1, h1 = img1.size\n    w2, h2 = img2.size\n    W, H = max(w1, w2), max(h1, h2)\n\n    pimg1 = Image.new('RGB', (W, H), opts.bgcolor)\n    pimg2 = Image.new('RGB', (W, H), opts.bgcolor)\n\n    pimg1.paste(img1, (0, 0))\n    pimg2.paste(img2, (0, 0))\n\n    diff = Image.new('L', (W, H), 255)\n    # It is not a good idea to keep one diff image; it should track the\n    # relative positions of the two images.  I think that's what explains\n    # the fuzz I see near the edges of the different areas.\n\n    xr = abs(w1 - w2) + 1\n    yr = abs(h1 - h2) + 1\n\n    try:\n        p = Progress(xr * yr, timeout=opts.timeout)\n        for x in range(xr):\n            for y in range(yr):\n                p.next()\n                this = ImageChops.difference(pimg1, pimg2).convert('L')\n                this = this.filter(ImageFilter.MaxFilter(7))\n                diff = ImageChops.darker(diff, this)\n                if h1 > h2:\n                    pimg2 = ImageChops.offset(pimg2, 0, 1)\n                else:\n                    pimg1 = ImageChops.offset(pimg1, 0, 1)\n            if h1 > h2:\n                pimg2 = ImageChops.offset(pimg2, 0, -yr)\n            else:\n                pimg1 = ImageChops.offset(pimg1, 0, -yr)\n            if w1 > w2:\n                pimg2 = ImageChops.offset(pimg2, 1, 0)\n            else:\n                pimg1 = ImageChops.offset(pimg1, 1, 0)\n    except KeyboardInterrupt:\n        return None, None\n\n    diff = diff.filter(ImageFilter.MaxFilter(5))\n\n    diff1 = diff.crop((0, 0, w1, h1))\n    diff2 = diff.crop((0, 0, w2, h2))\n\n    mask1 = tweak_diff(diff1, opts.opacity)\n    mask2 = tweak_diff(diff2, opts.opacity)\n\n    return mask1, mask2"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(path, broken=False):\n    with maybe_gzip_open(path) as f:\n        yield reader(f, broken=broken)", "response": "Context manager for opening and reading json lines files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the control parameters as XML.", "response": "def controlParameters(self, module, status):\n        \"\"\"Returns control parameters as XML.\n\n        :type module: str\n        :type status: str\n        :param module: The module number/ID\n        :param status: The state to set (i.e. true (on) or false (off))\n        :return XML string to join with payload\n        \"\"\"\n        if self.use_legacy_protocol :\n            return '''{}<NickName>Socket 1</NickName><Description>Socket 1</Description>\n                      <OPStatus>{}</OPStatus><Controller>1</Controller>'''.format(self.moduleParameters(module), status)\n        else:\n            return '''{}<NickName>Socket 1</NickName><Description>Socket 1</Description>\n                      <OPStatus>{}</OPStatus>'''.format(self.moduleParameters(module), status)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the SOAP action call. :type Action: str :type responseElement: str :type params: str :type recursive: bool :param Action: The action to perform on the device :param responseElement: The XML element that is returned upon success :param params: Any additional parameters required for performing request (i.e. RadioID, moduleID, ect) :param recursive: True if first attempt failed and now attempting to re-authenticate prior :return: Text enclosed in responseElement brackets", "response": "def SOAPAction(self, Action, responseElement, params = \"\", recursive = False):\n        \"\"\"Generate the SOAP action call.\n\n        :type Action: str\n        :type responseElement: str\n        :type params: str\n        :type recursive: bool\n        :param Action: The action to perform on the device\n        :param responseElement: The XML element that is returned upon success\n        :param params: Any additional parameters required for performing request (i.e. RadioID, moduleID, ect)\n        :param recursive: True if first attempt failed and now attempting to re-authenticate prior\n        :return: Text enclosed in responseElement brackets\n        \"\"\"\n        # Authenticate client\n        if self.authenticated is None:\n            self.authenticated = self.auth()\n        auth = self.authenticated\n        #If not legacy protocol, ensure auth() is called for every call\n        if not self.use_legacy_protocol:\n            self.authenticated = None\n\n        if auth is None:\n            return None\n        payload = self.requestBody(Action, params)\n\n        # Timestamp in microseconds\n        time_stamp = str(round(time.time()/1e6))\n\n        action_url = '\"http://purenetworks.com/HNAP1/{}\"'.format(Action)\n        AUTHKey = hmac.new(auth[0].encode(), (time_stamp+action_url).encode()).hexdigest().upper() + \" \" + time_stamp\n\n        headers = {'Content-Type' : '\"text/xml; charset=utf-8\"',\n                   'SOAPAction': '\"http://purenetworks.com/HNAP1/{}\"'.format(Action),\n                   'HNAP_AUTH' : '{}'.format(AUTHKey),\n                   'Cookie' : 'uid={}'.format(auth[1])}\n\n        try:\n            response = urlopen(Request(self.url, payload.encode(), headers))\n        except (HTTPError, URLError):\n            # Try to re-authenticate once\n            self.authenticated = None\n            # Recursive call to retry action\n            if not recursive:\n                return_value = self.SOAPAction(Action, responseElement, params, True)\n            if recursive or return_value is None:\n                _LOGGER.warning(\"Failed to open url to {}\".format(self.ip))\n                self._error_report = True\n                return None\n            else:\n                return return_value\n\n        xmlData = response.read().decode()\n        root = ET.fromstring(xmlData)\n\n        # Get value from device\n        try:\n            value = root.find('.//{http://purenetworks.com/HNAP1/}%s' % (responseElement)).text\n        except AttributeError:\n            _LOGGER.warning(\"Unable to find %s in response.\" % responseElement)\n            return None\n\n        if value is None and self._error_report is False:\n            _LOGGER.warning(\"Could not find %s in response.\" % responseElement)\n            self._error_report = True\n            return None\n\n        self._error_report = False\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching statistics from my_cgi. cgi.", "response": "def fetchMyCgi(self):\n        \"\"\"Fetches statistics from my_cgi.cgi\"\"\"\n        try:\n            response = urlopen(Request('http://{}/my_cgi.cgi'.format(self.ip), b'request=create_chklst'));\n        except (HTTPError, URLError):\n            _LOGGER.warning(\"Failed to open url to {}\".format(self.ip))\n            self._error_report = True\n            return None\n\n        lines = response.readlines()\n        return {line.decode().split(':')[0].strip(): line.decode().split(':')[1].strip() for line in lines}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef current_consumption(self):\n        res = 'N/A'\n        if self.use_legacy_protocol:\n            # Use /my_cgi.cgi to retrieve current consumption\n            try:\n                res = self.fetchMyCgi()['Meter Watt']\n            except:\n                return 'N/A'\n        else:\n            try:\n                res = self.SOAPAction('GetCurrentPowerConsumption', 'CurrentConsumption', self.moduleParameters(\"2\"))\n            except:\n                return 'N/A'\n\n        if res is None:\n            return 'N/A'\n\n        try:\n            res = float(res)\n        except ValueError:\n            _LOGGER.error(\"Failed to retrieve current power consumption from SmartPlug\")\n\n        return res", "response": "Get the current power consumption in Watt."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the total power consumption in the device lifetime.", "response": "def total_consumption(self):\n        \"\"\"Get the total power consumpuntion in the device lifetime.\"\"\"\n        if self.use_legacy_protocol:\n            # TotalConsumption currently fails on the legacy protocol and\n            # creates a mess in the logs. Just return 'N/A' for now.\n            return 'N/A'\n\n        res = 'N/A'\n        try:\n            res = self.SOAPAction(\"GetPMWarningThreshold\", \"TotalConsumption\", self.moduleParameters(\"2\"))\n        except:\n            return 'N/A'\n\n        if res is None:\n            return 'N/A'\n\n        try:\n            float(res)\n        except ValueError:\n            _LOGGER.error(\"Failed to retrieve total power consumption from SmartPlug\")\n\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the device state.", "response": "def state(self):\n        \"\"\"Get the device state (i.e. ON or OFF).\"\"\"\n        response =  self.SOAPAction('GetSocketSettings', 'OPStatus', self.moduleParameters(\"1\"))\n        if response is None:\n            return 'unknown'\n        elif response.lower() == 'true':\n            return ON\n        elif response.lower() == 'false':\n            return OFF\n        else:\n            _LOGGER.warning(\"Unknown state %s returned\" % str(response.lower()))\n            return 'unknown'"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset device state. :type value: str :param value: Future state (either ON or OFF)", "response": "def state(self, value):\n        \"\"\"Set device state.\n\n        :type value: str\n        :param value: Future state (either ON or OFF)\n        \"\"\"\n        if value.upper() == ON:\n            return self.SOAPAction('SetSocketSettings', 'SetSocketSettingsResult', self.controlParameters(\"1\", \"true\"))\n        elif value.upper() == OFF:\n            return self.SOAPAction('SetSocketSettings', 'SetSocketSettingsResult', self.controlParameters(\"1\", \"false\"))\n        else:\n            raise TypeError(\"State %s is not valid.\" % str(value))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auth(self):\n\n        payload = self.initial_auth_payload()\n\n        # Build initial header\n        headers = {'Content-Type' : '\"text/xml; charset=utf-8\"',\n           'SOAPAction': '\"http://purenetworks.com/HNAP1/Login\"'}\n\n        # Request privatekey, cookie and challenge\n        try:\n            response = urlopen(Request(self.url, payload, headers))\n        except URLError:\n            if self._error_report is False:\n                _LOGGER.warning('Unable to open a connection to dlink switch {}'.format(self.ip))\n                self._error_report = True\n            return None\n        xmlData = response.read().decode()\n        root = ET.fromstring(xmlData)\n\n        # Find responses\n        ChallengeResponse = root.find('.//{http://purenetworks.com/HNAP1/}Challenge')\n        CookieResponse = root.find('.//{http://purenetworks.com/HNAP1/}Cookie')\n        PublickeyResponse = root.find('.//{http://purenetworks.com/HNAP1/}PublicKey')\n\n        if (ChallengeResponse == None or CookieResponse == None or PublickeyResponse == None) and self._error_report is False:\n            _LOGGER.warning(\"Failed to receive initial authentication from smartplug.\")\n            self._error_report = True\n            return None\n\n        if self._error_report is True:\n            return None\n\n        Challenge = ChallengeResponse.text\n        Cookie = CookieResponse.text\n        Publickey = PublickeyResponse.text\n\n        # Generate hash responses\n        PrivateKey = hmac.new((Publickey+self.password).encode(), (Challenge).encode()).hexdigest().upper()\n        login_pwd = hmac.new(PrivateKey.encode(), Challenge.encode()).hexdigest().upper()\n\n        response_payload = self.auth_payload(login_pwd)\n        # Build response to initial request\n        headers = {'Content-Type' : '\"text/xml; charset=utf-8\"',\n           'SOAPAction': '\"http://purenetworks.com/HNAP1/Login\"',\n           'HNAP_AUTH' : '\"{}\"'.format(PrivateKey),\n           'Cookie' : 'uid={}'.format(Cookie)}\n        response = urlopen(Request(self.url, response_payload, headers))\n        xmlData = response.read().decode()\n        root = ET.fromstring(xmlData)\n\n        # Find responses\n        login_status = root.find('.//{http://purenetworks.com/HNAP1/}LoginResult').text.lower()\n\n        if login_status != \"success\" and self._error_report is False:\n            _LOGGER.error(\"Failed to authenticate with SmartPlug {}\".format(self.ip))\n            self._error_report = True\n            return None\n\n        self._error_report = False # Reset error logging\n        return (PrivateKey, Cookie)", "response": "Authenticate using the SOAP interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef auth_payload(self, login_pwd):\n\n        payload = '''<?xml version=\"1.0\" encoding=\"utf-8\"?>\n        <soap:Envelope xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\">\n        <soap:Body>\n        <Login xmlns=\"http://purenetworks.com/HNAP1/\">\n        <Action>login</Action>\n        <Username>{}</Username>\n        <LoginPassword>{}</LoginPassword>\n        <Captcha/>\n        </Login>\n        </soap:Body>\n        </soap:Envelope>\n        '''.format(self.user, login_pwd)\n\n        return payload.encode()", "response": "Generate a new payload containing generated hash information."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_known_read_position(fp, buffered=True):\n    buffer_size = io.DEFAULT_BUFFER_SIZE if buffered else 0\n    return max(fp.tell() - buffer_size, 0)", "response": "Returns a position in a file which is known to be read & handled."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef recover(gzfile, last_good_position):\n    # type: (gzip.GzipFile, int) -> gzip.GzipFile\n    \"\"\" \n    Skip to the next possibly decompressable part of a gzip file.\n    Return a new GzipFile object if such part is found or None\n    if it is not found.\n    \"\"\"\n    pos = get_recover_position(gzfile, last_good_position=last_good_position)\n    if pos == -1:\n        return None\n    fp = gzfile.fileobj\n    fp.seek(pos)\n#     gzfile.close()\n    return gzip.GzipFile(fileobj=fp, mode='r')", "response": "Returns a GzipFile object for the next possibly decompressable part of a gzip file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_recover_position(gzfile, last_good_position):\n    # type: (gzip.GzipFile, int) -> int\n    \"\"\"\n    Return position of a next gzip stream in a GzipFile, \n    or -1 if it is not found.\n    \n    XXX: caller must ensure that the same last_good_position\n    is not used multiple times for the same gzfile.\n    \"\"\"\n    with closing(mmap.mmap(gzfile.fileno(), 0, access=mmap.ACCESS_READ)) as m:\n        return m.find(GZIP_SIGNATURE, last_good_position + 1)", "response": "Returns the position of the next gzip stream in a GzipFile or - 1 if it is not found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening file with either open or gzip. open depending on file extension.", "response": "def maybe_gzip_open(path, *args, **kwargs):\n    \"\"\"\n    Open file with either open or gzip.open, depending on file extension.\n\n    This function doesn't handle json lines format, just opens a file\n    in a way it is decoded transparently if needed.\n    \"\"\"\n    path = path_to_str(path)\n    if path.endswith('.gz') or path.endswith('.gzip'):\n        _open = gzip.open\n    else:\n        _open = open\n    return _open(path, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting pathlib. Path objects to str ; return other objects as - is.", "response": "def path_to_str(path):\n    \"\"\" Convert pathlib.Path objects to str; return other objects as-is. \"\"\"\n    try:\n        from pathlib import Path as _Path\n    except ImportError:  # Python < 3.4\n        class _Path:\n            pass\n    if isinstance(path, _Path):\n        return str(path)\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of all the factor names in the current locale.", "response": "def get_factor_list(self):\n        \"\"\"\n        get_factors: [['2', 3], ['3', 2]]\n        Returns: [2, 2, 2, 3, 3]\n        \"\"\"\n        factors = self.get_factor_from_api()\n        if not factors:\n            return []\n        ml = [[int(x)] * y for x, y in factors]\n        return [y for x in ml for y in x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates the signature for the given request data.", "response": "def calculate_signature(key, data, timestamp=None):\n    \"\"\"\n    Calculates the signature for the given request data.\n    \"\"\"\n    # Create a timestamp if one was not given\n    if timestamp is None:\n        timestamp = int(time.time())\n\n    # Construct the message from the timestamp and the data in the request\n    message = str(timestamp) + ''.join(\"%s%s\" % (k,v) for k,v in sorted(data.items()))\n\n    # Calculate the signature (HMAC SHA256) according to RFC 2104\n    signature = hmac.HMAC(str(key), message, hashlib.sha256).hexdigest()\n\n    return signature"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nauthenticates the user with a 401.", "response": "def authenticate(self):\n        \"\"\"\n        Indicate to the client that it needs to authenticate via a 401.\n        \"\"\"\n        if request.headers.get('Authorization') or request.args.get('access_token'):\n            realm = 'Bearer realm=\"%s\", error=\"invalid_token\"' % __package__\n        else:\n            realm = 'Bearer realm=\"%s\"' % __package__\n        resp = Response(None, 401, {'WWW-Authenticate': realm})\n        abort(401, description='Please provide proper credentials', response=resp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_token(self, token, allowed_roles, resource, method):\n        resource_conf = config.DOMAIN[resource]\n        audiences = resource_conf.get('audiences', config.JWT_AUDIENCES)\n        return self._perform_verification(token, audiences, allowed_roles)", "response": "This function is called by the OAuth 2. 0 authorization header and the OAuth 2. 0 authorization header."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef requires_token(self, audiences=None, allowed_roles=None):\n        def requires_token_wrapper(f):\n            @wraps(f)\n            def decorated(*args, **kwargs):\n                try:\n                    token = request.args['access_token']\n                except KeyError:\n                    token = request.headers.get('Authorization', '').partition(' ')[2]\n\n                if not self._perform_verification(token, audiences, allowed_roles):\n                    abort(401)\n\n                return f(*args, **kwargs)\n            return decorated\n        return requires_token_wrapper", "response": "Decorator for functions that will be protected with token authentication."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_library(self,libname):\n        paths = self.getpaths(libname)\n\n        for path in paths:\n            if os.path.exists(path):\n                return self.load(path)\n\n        raise ImportError(\"%s not found.\" % libname)", "response": "Given the name of a library load it."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getpaths(self,libname):\n        if os.path.isabs(libname):\n            yield libname\n        else:\n            # FIXME / TODO return '.' and os.path.dirname(__file__)\n            for path in self.getplatformpaths(libname):\n                yield path\n\n            path = ctypes.util.find_library(libname)\n            if path: yield path", "response": "Return a list of paths where the library might be found."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nimplementing the dylib search as specified in Apple documentation", "response": "def getdirs(self,libname):\n        '''Implements the dylib search as specified in Apple documentation:\n\n        http://developer.apple.com/documentation/DeveloperTools/Conceptual/\n            DynamicLibraries/Articles/DynamicLibraryUsageGuidelines.html\n\n        Before commencing the standard search, the method first checks\n        the bundle's ``Frameworks`` directory if the application is running\n        within a bundle (OS X .app).\n        '''\n\n        dyld_fallback_library_path = _environ_path(\"DYLD_FALLBACK_LIBRARY_PATH\")\n        if not dyld_fallback_library_path:\n            dyld_fallback_library_path = [os.path.expanduser('~/lib'),\n                                          '/usr/local/lib', '/usr/lib']\n\n        dirs = []\n\n        if '/' in libname:\n            dirs.extend(_environ_path(\"DYLD_LIBRARY_PATH\"))\n        else:\n            dirs.extend(_environ_path(\"LD_LIBRARY_PATH\"))\n            dirs.extend(_environ_path(\"DYLD_LIBRARY_PATH\"))\n\n        dirs.extend(self.other_dirs)\n        dirs.append(\".\")\n        dirs.append(os.path.dirname(__file__))\n\n        if hasattr(sys, 'frozen') and sys.frozen == 'macosx_app':\n            dirs.append(os.path.join(\n                os.environ['RESOURCEPATH'],\n                '..',\n                'Frameworks'))\n\n        dirs.extend(dyld_fallback_library_path)\n\n        return dirs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef to_json(content, indent=None):\n    if isinstance(content, QuerySet):\n        json_serializer = serializers.get_serializer('json')()\n        serialized_content = json_serializer.serialize(content, ensure_ascii=False, indent=indent)\n    else:\n        try:\n            serialized_content = json.dumps(content, cls=DecimalEncoder, ensure_ascii=False, indent=indent)\n        except TypeError:\n            # Fix for Django 1.5\n            serialized_content = json.dumps(content, ensure_ascii=False, indent=indent)\n    return serialized_content", "response": "Serializes a python object as JSON"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a python object into an HTML tree.", "response": "def to_html(data):\n    \"\"\"\n    Serializes a python object as HTML\n\n    This method uses the to_json method to turn the given data object into\n    formatted JSON that is displayed in an HTML page. If pygments in installed,\n    syntax highlighting will also be applied to the JSON.\n    \"\"\"\n    base_html_template = Template('''\n        <html>\n            <head>\n                {% if style %}\n                <style type=\"text/css\">\n                    {{ style }}\n                </style>\n                {% endif %}\n            </head>\n            <body>\n                {% if style %}\n                    {{ body|safe }}\n                {% else %}\n                    <pre></code>{{ body }}</code></pre>\n                {% endif %}\n            </body>\n        </html>\n        ''')\n\n    code = to_json(data, indent=4)\n    if PYGMENTS_INSTALLED:\n        c = Context({\n            'body': highlight(code, JSONLexer(), HtmlFormatter()),\n            'style': HtmlFormatter().get_style_defs('.highlight')\n        })\n        html = base_html_template.render(c)\n    else:\n        c = Context({'body': code})\n        html = base_html_template.render(c)\n    return html"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_text(data):\n    try:\n        serialized_content = to_json(data, indent=4)\n    except Exception, e:\n        serialized_content = data\n    return serialized_content", "response": "Serializes a python object as plain text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrequiring that the user be authenticated either by a signature or by being actively logged in.", "response": "def auth_required(secret_key_func):\n    \"\"\"\n    Requires that the user be authenticated either by a signature or by\n    being actively logged in.\n    \"\"\"\n    def actual_decorator(obj):\n\n        def test_func(request, *args, **kwargs):\n            secret_key = secret_key_func(request, *args, **kwargs)\n            return validate_signature(request, secret_key) or request.user.is_authenticated()\n\n        decorator = request_passes_test(test_func)\n        return wrap_object(obj, decorator)\n\n    return actual_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrequire that the user be logged in to gain access to the resource at the specified URI.", "response": "def login_required(obj):\n    \"\"\"\n    Requires that the user be logged in order to gain access to the resource\n    at the specified the URI.\n    \"\"\"\n    decorator = request_passes_test(lambda r, *args, **kwargs: r.user.is_authenticated())\n    return wrap_object(obj, decorator)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef admin_required(obj):\n    decorator = request_passes_test(lambda r, *args, **kwargs: r.user.is_superuser)\n    return wrap_object(obj, decorator)", "response": "Requires that the user be logged AND be set as a superuser\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrequire that the request contain a valid signature to gain access to a specified resource.", "response": "def signature_required(secret_key_func):\n    \"\"\"\n    Requires that the request contain a valid signature to gain access\n    to a specified resource.\n    \"\"\"\n    def actual_decorator(obj):\n\n        def test_func(request, *args, **kwargs):\n            secret_key = secret_key_func(request, *args, **kwargs)\n            return validate_signature(request, secret_key)\n\n        decorator = request_passes_test(test_func)\n        return wrap_object(obj, decorator)\n\n    return actual_decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates the signature associated with the given request.", "response": "def validate_signature(request, secret_key):\n    \"\"\"\n    Validates the signature associated with the given request.\n    \"\"\"\n\n    # Extract the request parameters according to the HTTP method\n    data = request.GET.copy()\n    if request.method != 'GET':\n        message_body = getattr(request, request.method, {})\n        data.update(message_body)\n\n    # Make sure the request contains a signature\n    if data.get('sig', False):\n        sig = data['sig']\n        del data['sig']\n    else:\n        return False\n\n    # Make sure the request contains a timestamp\n    if data.get('t', False):\n        timestamp = int(data.get('t', False))\n        del data['t']\n    else:\n        return False\n\n    # Make sure the signature has not expired\n    local_time = datetime.utcnow()\n    remote_time = datetime.utcfromtimestamp(timestamp)\n    \n    \n    # this stops a bug if the client clock is ever a little ahead of \n    # the server clock.  Makes the window of acceptable time current +/- 5 mins\n    if local_time > remote_time:\n        delta = local_time - remote_time\n    else:   \n        delta = remote_time - local_time\n    \n    if delta.seconds > 5 * 60:  # If the signature is older than 5 minutes, it's invalid\n        return False\n\n    # Make sure the signature is valid\n    return sig == calculate_signature(secret_key, data, timestamp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchooses k random elements from a population", "response": "def sample_wr(population, k):\r\n    \"Chooses k random elements (with replacement) from a population\"\r\n    n = len(population)\r\n    _random, _int = random.random, int  # speed hack \r\n    result = [None] * k\r\n    for i in xrange(k):\r\n        j = _int(_random() * n)\r\n        result[i] = population[j]\r\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a DynamoDB connection.", "response": "def dynamodb_connection_factory():\n    \"\"\"\n    Since SessionStore is called for every single page view, we'd be\n    establishing new connections so frequently that performance would be\n    hugely impacted. We'll lazy-load this here on a per-worker basis. Since\n    boto3.resource.('dynamodb')objects are state-less (aside from security\n    tokens), we're not too concerned about thread safety issues.\n    \"\"\"\n\n    global _DYNAMODB_CONN\n    global _BOTO_SESSION\n    if not _DYNAMODB_CONN:\n        logger.debug(\"Creating a DynamoDB connection.\")\n        if not _BOTO_SESSION:\n            _BOTO_SESSION = Boto3Session(\n                aws_access_key_id=AWS_ACCESS_KEY_ID,\n                aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n                region_name=AWS_REGION_NAME)\n        _DYNAMODB_CONN = _BOTO_SESSION.resource('dynamodb')\n    return _DYNAMODB_CONN"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the session data from DynamoDB runs it through the session de - decoder and sets self. session.", "response": "def load(self):\n        \"\"\"\n        Loads session data from DynamoDB, runs it through the session\n        data de-coder (base64->dict), sets ``self.session``.\n\n        :rtype: dict\n        :returns: The de-coded session data, as a dict.\n        \"\"\"\n\n        response = self.table.get_item(\n            Key={'session_key': self.session_key},\n            ConsistentRead=ALWAYS_CONSISTENT)\n        if 'Item' in response:\n            session_data = response['Item']['data']\n            return self.decode(session_data)\n        else:\n            self.create()\n            return {}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exists(self, session_key):\n\n        response = self.table.get_item(\n            Key={'session_key': session_key},\n            ConsistentRead=ALWAYS_CONSISTENT)\n        if 'Item' in response:\n            return True\n        else:\n            return False", "response": "Checks to see if a session currently exists in DynamoDB."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, must_create=False):\n\n        # If the save method is called with must_create equal to True, I'm\n        # setting self._session_key equal to None and when\n        # self.get_or_create_session_key is called the new\n        # session_key will be created.\n        if must_create:\n            self._session_key = None\n\n        self._get_or_create_session_key()\n\n        update_kwargs = {\n            'Key': {'session_key': self.session_key},\n        }\n        attribute_names = {'#data': 'data'}\n        attribute_values = {\n            ':data': self.encode(self._get_session(no_load=must_create))\n        }\n        set_updates = ['#data = :data']\n        if must_create:\n            # Set condition to ensure session with same key doesnt exist\n            update_kwargs['ConditionExpression'] = \\\n                DynamoConditionAttr('session_key').not_exists()\n            attribute_values[':created'] = int(time.time())\n            set_updates.append('created = :created')\n        update_kwargs['UpdateExpression'] = 'SET ' + ','.join(set_updates)\n        update_kwargs['ExpressionAttributeValues'] = attribute_values\n        update_kwargs['ExpressionAttributeNames'] = attribute_names\n        try:\n            self.table.update_item(**update_kwargs)\n        except ClientError as e:\n            error_code = e.response['Error']['Code']\n            if error_code == 'ConditionalCheckFailedException':\n                raise CreateError\n            raise", "response": "Saves the current session data to the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes the current session or the one specified in session_key.", "response": "def delete(self, session_key=None):\n        \"\"\"\n        Deletes the current session, or the one specified in ``session_key``.\n\n        :keyword str session_key: Optionally, override the session key\n            to delete.\n        \"\"\"\n\n        if session_key is None:\n            if self.session_key is None:\n                return\n            session_key = self.session_key\n\n        self.table.delete_item(Key={'session_key': session_key})"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef summary(self):\n        m = self\n        txt = \"%-34s (Bits: %5.2f  MAP: %7.2f   D: %5.3f  %3d)  E: %7.3f\"%(\n            m, m.totalbits, m.MAP, m.seeddist, m.seednum, nlog10(m.pvalue))\n        if m.binomial!=None:  txt = txt + '  Bi: %6.2f'%(nlog10(m.binomial))\n        if m.church != None:  txt = txt + '  ch: %6.2f'%(nlog10(m.church))\n        if m.frac   != None:  txt = txt + '  f: %5.3f'%(m.frac)\n        if m.E_site != None:  txt = txt + '  Es: %6.2f'%(nlog10(m.E_site))\n        if m.E_seq  != None:  txt = txt + '  Eq: %6.2f'%(nlog10(m.E_seq))\n        if m.MNCP   != None:  txt = txt + '  mn: %6.2f'%(m.MNCP)\n        if m.ROC_auc!= None:  txt = txt + '  Ra: %6.4f'%(m.ROC_auc)\n        if m.E_chi2 != None:\n            if m.E_chi2 == 0: m.E_chi2=1e-20\n            txt = txt + ' x2: %5.2f'%(nlog10(m.E_chi2))\n        if m.CRA    != None:  txt = txt + '  cR: %6.4f'%(m.CRA)\n        if m.Cfrac  != None:  txt = txt + '  Cf: %5.3f'%(m.Cfrac)\n        if m.realpvalue != None: txt = txt + '  P: %6.4e'%(m.realpvalue)\n        if m.kellis != None:  txt = txt +  '  k: %6.2f'%(m.kellis)\n        if m.numbound      :  txt = txt +  '  b: %3d'%(m.numbound)\n        if m.nummotif      :  txt = txt +  '  nG: %3d'%(m.nummotif)\n        if m.numboundmotif :  txt = txt +  '  bn: %3d'%(m.numboundmotif)\n\n        return txt", "response": "Return a text string one - line summary of motif and its metrics"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning minimal list of seqs that represent consensus", "response": "def minimal_raw_seqs(self):\n        ''' m.minimal_raw_seqs() -- Return minimal list of seqs that represent consensus '''\n        seqs = [[], []]\n        for letter in self.oneletter:\n            if one2two.has_key(letter):\n                seqs[0].append(one2two[letter][0])\n                seqs[1].append(one2two[letter][1])\n            else:\n                seqs[0].append(letter)\n                seqs[1].append(letter)\n        if ''.join(seqs[0]) == ''.join(seqs[1]):\n            return( [''.join(seqs[0])] )\n        else:\n            return( [''.join(seqs[0]), ''.join(seqs[0])] )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compute_oneletter(self):\n        letters = []\n        for i in range(self.width):\n            downcase = None\n            if self.bits[i] < 0.25:\n                letters.append('.')\n                continue\n            if self.bits[i] < 1.0: downcase = 'True'\n            tups = [(self.ll[i][x],x) for x in ACGT if self.ll[i][x] > 0.0]\n            if not tups:  #Kludge if all values are negative (can this really happen?)\n                tups = [(self.ll[i][x],x) for x in ACGT]\n                tups.sort()\n                tups.reverse()\n                tups = [tups[0]]\n                downcase = 'True'\n            tups.sort()      #Rank by LL\n            tups.reverse()\n            bases = [x[1] for x in tups[0:2]]\n            bases.sort()\n            if len(bases) == 2: L = two2one[''.join(bases)]\n            else:               L = bases[0]\n            if downcase: L = L.lower()\n            letters.append(L)\n        self.oneletter = ''.join(letters)", "response": "Compute the oneletter member variable."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the log - likelihood matrix from the count matrix.", "response": "def _compute_ll(self):\n        \"\"\"\n        m._compute_ll() -- [utility] Compute the log-likelihood matrix from the count matrix\n        \"\"\"\n        self.fracs = []\n        self.logP  = []\n        self.ll    = []\n        for i in range(self.width):\n            Dll  = {'A': 0, 'C': 0, 'T': 0, 'G': 0}\n            Df   = {'A': 0, 'C': 0, 'T': 0, 'G': 0}\n            DlogP= {'A': 0, 'C': 0, 'T': 0, 'G': 0}\n            for key in self.counts[i].keys():\n                #print i,key,self.counts[i][key],self.nseqs\n                Pij = self.counts[i][key] / float(self.nseqs)\n                Df [key] = Pij\n                Dll[key] = (math.log( (self.counts[i][key] + self.bgscale*self.background[key] ) / \n                                      ((self.nseqs + self.bgscale) * self.background[key])     ) /\n                            math.log(2))\n                if Pij > 0:\n                    DlogP[key]  = math.log(Pij)/math.log(2)\n                else:\n                    DlogP[key]  = -100  #Near zero\n            self.fracs.append(Df)\n            self.logP.append (DlogP)\n            self.ll.append   (Dll)\n        self.P = self.fracs\n        self._compute_bits()\n        self._compute_ambig_ll()\n        self._maxscore()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the probability matrix for the class entry.", "response": "def _computeP(self):\n        \"\"\"\n        m._computeP() -- [utility] Compute the probability matrix (from the internal log-probability matrix)\n        \"\"\"\n        P = []\n        for i in range(self.width):\n            #print i,\n            _p = {}\n            for L in ACGT: _p[L] = math.pow(2.0,self.logP[i][L])\n            P.append(_p)\n        #print\n        self.P = P"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the number of bits and total bits for the current locale.", "response": "def _compute_bits(self):\n        \"\"\"\n        m._compute_bits() -- [utility] Set m.totbits to the number of bits and m.bits to a list of bits at each position\n        \"\"\"\n        bits = []\n        totbits = 0\n        bgbits  = 0\n        bg      = self.background\n        UNCERT  = lambda x: x*math.log(x)/math.log(2.0)\n        for letter in ACGT:\n            bgbits = bgbits + UNCERT(bg[letter])\n        for i in range(self.width):\n            tot = 0\n            for letter in ACGT:\n                Pij = pow(2.0, self.logP[i][letter])\n                tot = tot + UNCERT(Pij)\n                #bit = Pij * self.ll[i][letter]\n                #if bit > 0:\n                #    tot = tot + bit\n            #print tot, bgbits, tot-bgbits\n            bits.append(max(0,tot-bgbits))\n            totbits = totbits + max(0,tot-bgbits)\n        self.bits = bits\n        self.totalbits = totbits"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef denoise(self,bitthresh=0.5):\n        for i in range(self.width):\n            tot = 0\n            for letter in ACGT:\n                if self.logP:\n                    Pij = pow(2.0, self.logP[i][letter])\n                else:\n                    Pij = pow(2.0, self.ll[i][letter]) * self.background[letter]\n                if Pij > 0.01:\n                    bit = Pij * self.ll[i][letter]\n                    tot = tot + bit\n            if tot < bitthresh:  #Zero Column\n                for letter in ACGT:\n                    self.ll[i][letter] = 0.0\n        self.compute_from_ll(self.ll)", "response": "Denoise the low - information positions of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a gif logo", "response": "def giflogo(self,id,title=None,scale=0.8,info_str=''):\n        \"\"\"\n        m.giflogo(id,title=None,scale=0.8) -- (Requires seqlogo package) Make a gif sequence logo\n        \"\"\"\n        return giflogo(self,id,title,scale)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints a text - rendering of the Motif Logo.", "response": "def _print_bits(self,norm=2.3, height=8.0):\n        \"\"\"\n        m._print_bits(,norm=2.3, height=8.0) -- Print a text-rendering of the Motif Logo\n\n        norm   -- maximum number of bits to show\n        height -- number of lines of text to use to render logo\n        \"\"\"\n        bits   = []\n        tots   = []\n        str    = []\n        for i in range(self.width):\n            D = {}\n            tot = 0\n            for letter in ['A', 'C', 'T', 'G']:\n                if self.logP:\n                    Pij = pow(2.0, self.logP[i][letter])\n                else:\n                    Pij = pow(2.0, self.ll[i][letter]) * self.background[letter]\n                if Pij > 0.01:\n                    '''Old'''\n                    D[letter] = Pij * self.ll[i][letter]\n                    #'''new'''\n                    #Q = self.background[letter]\n                    #D[letter] = ( Pij * math.log(Pij) - Pij * math.log(Q) ) / math.log(2.0)\n                    '''for both old and new'''\n                    tot = tot + D[letter]\n            bits.append(D)\n            tots.append(tot)\n        for i in range(self.width):\n            s = []\n            _l = bits[i].keys()\n            _l.sort(lambda x,y,D=bits[i]: cmp(D[y],D[x]))\n            for key in _l:\n                for j in range(int(bits[i][key] / norm * height)):\n                    s.append(key)\n            str.append(''.join(s))\n        fmt = '%%%ds'%height\n        print '#  %s'%('-'*self.width)\n        for h in range(int(height)):\n            sys.stdout.write(\"#  \")\n            for i in range(self.width):\n                sys.stdout.write((fmt%str[i])[h])\n            if h == 0:\n                sys.stdout.write(' -- %4.2f bits\\n'%norm)\n            elif h == height-1:\n                sys.stdout.write(' -- %4.2f bits\\n'%(norm/height))\n            else:\n                sys.stdout.write('\\n')\n        print '#  %s'%('-'*self.width)\n        print '#  %s'%self.oneletter"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_ambig_ll(self):\n        for Dll in self.ll:\n            for L in one2two.keys():\n                Dll[L] = max(Dll[one2two[L][0]],  Dll[one2two[L][1]] )\n            Dll['N'] = 0.0\n            Dll['B'] = 0.0", "response": "This method is used to extend the log - likelihood matrix to include the ambiguity codes of all tables in the log - likelihood matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_from_text(self,text,beta=0.001):\n        prevlett = {'B':'A', 'D':'C', 'V':'T', 'H':'G'}\n        countmat = []\n        text = re.sub('[\\.\\-]','N',text.upper())\n        for i in range(len(text)):\n            D = {'A': 0, 'C': 0, 'T':0, 'G':0}\n            letter = text[i]\n            if letter in ['B', 'D', 'V', 'H']:  #B == no \"A\", etc...\n                _omit = prevlett[letter]\n                for L in ACGT:\n                    if L != _omit: D[L] = 0.3333\n            elif one2two.has_key(letter):  #Covers WSMYRK\n                for L in list(one2two[letter]):\n                    D[L] = 0.5\n            elif letter == 'N':\n                for L in D.keys():\n                    D[L] = self.background[L]\n            elif letter == '@':\n                for L in D.keys():\n                    D[L] = self.background[L]-(0.0001)\n                D['A'] = D['A'] + 0.0004\n            else:\n                D[letter] = 1.0\n            countmat.append(D)\n        self.compute_from_counts(countmat,beta)", "response": "This method computes a motifs from a text string of ambiguity codes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_bg(self,bg):\n        counts = []\n        for pos in self.logP:\n            D = {}\n            for L,lp in pos.items():\n                D[L] = math.pow(2.0,lp)\n            counts.append(D)\n        self.background = bg\n        self.compute_from_counts(counts,0)", "response": "Change the background frequencies to those in the supplied dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_from_counts(self,countmat,beta=0):\n        self.counts  = countmat\n        self.width   = len(countmat)\n        self.bgscale = 0\n\n        maxcount = 0\n        #Determine Biggest column\n        for col in countmat:\n            tot = 0\n            for v in col.values():\n                tot = tot + v\n            if tot > maxcount: maxcount = tot\n\n        #Pad counts of remaining columns\n        for col in countmat:\n            tot = 0\n            for c in col.values():\n                tot = tot + c\n            pad = maxcount - tot\n            for L in col.keys():\n                col[L] = col[L] + pad * self.background[L]\n                \n        self.nseqs = maxcount\n        nseqs      = maxcount\n        \n        #Add pseudocounts        \n        if beta > 0:  \n            multfactor = {}\n            bgprob = self.background\n            pcounts= {}\n            for L in bgprob.keys():\n                pcounts[L] = beta*bgprob[L]*nseqs \n            for i in range(self.width):\n                for L in countmat[i].keys():\n                    _t = (countmat[i][L] + pcounts[L]) #Add pseudo\n                    _t = _t / (1.0 + beta)    #Renomalize\n                    countmat[i][L] = _t\n\n        #Build Motif\n        self.counts = countmat\n        self._compute_ll()\n        self._compute_oneletter()\n        self._maxscore()", "response": "This method computes a motif object from a matrix of letter counts."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _compute_bg_from_ll(self):\n        \n        pow = math.pow\n        bgATtot = 0\n        nocount = 0\n        near0   = lambda x:(-0.01 < x and x < 0.01)\n        for i in range(self.width):\n            _D = self.ll[i]\n            ATtot = pow(2,_D['A']) + pow(2,_D['T'])\n            GCtot = pow(2,_D['C']) + pow(2,_D['G'])\n            if near0(_D['A']) and near0(_D['T']) and near0(_D['G']) and near0(_D['C']):\n                nocount = nocount + 1\n                continue\n            if near0(ATtot-GCtot):     #Kludge to deal with indeterminate case\n                nocount = nocount + 1\n                continue\n            bgAT   = (1.0 - 0.5*GCtot)/(ATtot - GCtot)\n            if (bgAT < 0.1) or (bgAT > 1.1):\n                nocount = nocount + 1\n                continue\n            bgATtot = bgATtot + bgAT\n        if nocount == self.width:  #Kludge to deal with different indeterminate case\n            self.background = {'A':0.25, 'C':0.25, 'G':0.25, 'T':0.25}\n            return\n        bgAT = bgATtot / (self.width - nocount)\n        bgGC = 0.5 - bgAT\n        self.background = {'A':bgAT, 'C':bgGC, 'G':bgGC, 'T':bgAT}", "response": "Compute background model from log - likelihood matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the logP matrix from the self. ll.", "response": "def _compute_logP_from_ll(self):\n        \"\"\"\n        m._compute_logP_from_ll() -- Compute self's logP matrix from the self.ll (log-likelihood)\n        \"\"\"\n        log = math.log\n        logP = []\n        for i in range(self.width):\n            D = {}\n            for L in ACGT:\n                ''' if   ll = log(p/b) then\n                       2^ll = p/b\n                  and    ll = log(p) - log(b)\n                  so log(p) = ll + log(b)'''\n                #Pij = pow(2.0, self.ll[i][letter]) * self.background[letter]\n                D[L] = self.ll[i][L] + log(self.background[L])/log(2.)\n            logP.append(D)\n        self.logP = logP"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _print_ll(self):\n        print \"#  \",\n        for i in range(self.width):\n            print \"  %4d   \"%i,\n        print\n        for L in ['A', 'C', 'T', 'G']:\n            print \"#%s \"%L,\n            for i in range(self.width):\n                print  \"%8.3f \"%self.ll[i][L],\n            print", "response": "Print log - likelihood of the current set of items."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints probability of the logarithmic matrix.", "response": "def _print_p(self):\n        \"\"\"\n        m._print_p() -- Print probability (frequency) matrix\n        \"\"\"\n        print \"#  \",\n        for i in range(self.width):\n            print \"  %4d   \"%i,\n        print\n        for L in ['A', 'C', 'T', 'G']:\n            print \"#%s \"%L,\n            for i in range(self.width):\n                print  \"%8.3f \"%math.pow(2,self.logP[i][L]),\n            print"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the threshold based on the z - score of the original Motif objects.", "response": "def _compute_threshold(self,z=2.0):\n        \"\"\"\n        m._compute_threshold(z=2.0) -- For Motif objects assembled from a set of sequence,\n                                       compute a self.threshold with a z-score based on the distribution\n                                       of scores in among the original input sequences.\n        \"\"\"\n        scoretally = []\n        for seq in self.seqs:\n            matches,endpoints,scores = self.scan(seq,-100)\n            scoretally.append(scores[0])\n        ave,std = avestd(scoretally)\n        self.threshold = ave - z *std"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn score and sequence of the best match to the motif in the supplied sequence", "response": "def bestscanseq(self,seq):\n        \"\"\"\n        m.bestscanseq(seq) -- Return score,sequence of the best match to the motif in the supplied sequence\n        \"\"\"\n        matches,endpoints,scores = self.scan(seq,-100)\n        t = zip(scores,matches)\n        t.sort()\n        bestseq   = t[-1][1]\n        bestscore = t[-1][0]\n        return bestscore, bestseq"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the score of the best match to the motif in the supplied sequence", "response": "def bestscan(self,seq):\n        \"\"\"\n        m.bestscan(seq) -- Return the score of the best match to the motif in the supplied sequence\n        \"\"\"\n        matches,endpoints,scores = self.scan(seq,-100)\n        if not scores: return -100\n        scores.sort()\n        best = scores[-1]\n        return best"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matchstartorient(self,seq, factor=0.7):\n        ans = []\n        txts,endpoints,scores = self.scan(seq,factor=factor)\n        for txt, startstop in zip(txts,endpoints):\n            start, stop = startstop\n            rctxt  = revcomplement(txt)\n            orient = (self.bestscore(txt,1) >= self.bestscore(rctxt,1))\n            ans.append((start,orient))\n        return ans", "response": "Match start and orientation of a sequence of motif in the motif."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nscan the sequence for a given threshold and return a list of tuples of the matching sequences endpoints and scores.", "response": "def scan(self, seq, threshold = '', factor=0.7):\n        \"\"\"\n        m.scan(seq, threshold = '', factor=0.7) -- Scan the sequence.  Returns three lists:\n                                                   matching sequences, endpoints, and scores.  The value of \n                                                   'factor' is multiplied by m.maxscore to get a match threshold\n                                                   if none is supplied\n        \"\"\"\n        if len(seq) < self.width:\n            return(self._scan_smaller(seq,threshold))\n        else:\n            return(self._scan(seq,threshold,factor=factor))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef scansum(self,seq,threshold = -1000):\n        ll = self.ll\n        sum = 0\n        width        = self.width\n        width_r      = range(width)\n        width_rcr    = range(width-1,-1,-1)\n        width_ranges = zip(width_r,width_rcr)\n        seqcomp      = seq.translate(revcompTBL)\n\n        total = 0\n        hits  = 0\n        etotal= 0\n        for offset in range(len(seq)-width+1):\n            total_f = 0\n            total_r = 0\n            for i,ir in width_ranges:\n                pos = offset+i\n                total_f = total_f + ll[i][    seq[pos]]\n                total_r = total_r + ll[i][seqcomp[pos]]\n            total_max = max(total_f,total_r)\n            if total_max >= threshold:\n                total = total + total_max\n                etotal = etotal + math.exp(total_max)\n                hits  = hits + 1\n            if not hits:\n                ave = 0\n            else:\n                ave = float(total)/float(hits)\n        return(total,hits,ave,math.log(etotal))", "response": "Returns the sum of scores over every window in the sequence."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the score of the motif with the given sequence.", "response": "def score(self, seq, fwd='Y'):\n        \"\"\"\n        m.score(seq, fwd='Y') -- Returns the score of the first w-bases of the sequence, where w is the motif width.\n        \"\"\"\n        matches, endpoints, scores = self._scan(seq,threshold=-100000,forw_only=fwd)\n        return scores[0]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the score of the best matching subsequence in seq.", "response": "def bestscore(self,seq, fwd=''):\n        \"\"\"\n        m.bestscore(seq, fwd='') -- Returns the score of the best matching subsequence in seq.\n        \"\"\"\n        matches, endpoints, scores = self._scan(seq,threshold=-100000,forw_only=fwd)\n        if scores: return max(scores)\n        else:      return -1000"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _scan(self, seq,threshold='',forw_only='',factor=0.7):\n        ll = self.ll #Shortcut for Log-likelihood matrix\n        if not threshold: threshold = factor * self.maxscore\n        \n        #print '%5.3f'%(threshold/self.maxscore)\n        matches       = []\n        endpoints     = []\n        scores        = []\n        width         = self.width\n        width_r       = range(width)\n        width_rcr     = range(width-1,-1,-1)\n        width_ranges  = zip(width_r,width_rcr)\n\n        \n        oseq = seq\n        seq  = seq.upper()\n        seqcomp = seq.translate(revcompTBL)\n        for offset in range(len(seq)-self.width+1):    #Check if +/-1 needed\n            total_f = 0\n            total_r = 0\n            for i,ir in width_ranges:\n                pos = offset+i\n                total_f = total_f + ll[i ][    seq[pos]]\n                total_r = total_r + ll[ir][seqcomp[pos]]\n\n            if 0 and total_f > 1:\n                for i,ir in width_ranges:\n                    print seq[offset+i],'%6.3f'%ll[i ][        seq[offset+i] ],'   ',\n                print '= %7.3f'%total_f\n                \n            if 0:\n                print \"\\t\\t%s vs %s: F=%6.2f R=%6.2f %6.2f %4.2f\"%(seq[offset:offset+self.width],\n                                                                   self.oneletter,total_f,total_r,\n                                                                   self.maxscore,\n                                                                   max([total_f,total_r])/self.maxscore)\n            if total_f > threshold and ((total_f > total_r) or forw_only):\n                endpoints.append( (offset,offset+self.width-1) )\n                scores.append(total_f)\n                matches.append(oseq[offset:offset+self.width])\n            elif total_r > threshold:\n                endpoints.append( (offset,offset+self.width-1) )\n                scores.append(total_r)\n                matches.append(oseq[offset:offset+self.width])\n        return(matches,endpoints,scores)", "response": "Internal function for performing sequence scans"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _scan_smaller(self, seq, threshold=''):\n        ll = self.ll #Shortcut for Log-likelihood matrix\n        matches   = []\n        endpoints = []\n        scores    = []\n        w         = self.width\n        oseq      = seq\n        seq       = seq.upper()\n        for offset in range(self.width-len(seq)+1):    #Check if +/-1 needed\n            maximum = 0\n            for i in range(len(seq)):\n                maximum = maximum + max(ll[i+offset].values())\n            if not threshold: threshold = 0.8 * maximum\n            total_f = 0\n            total_r = 0\n            for i in range(len(seq)):\n                total_f = total_f + ll[i+offset      ][        seq[i] ]\n                total_r = total_r + ll[w-(i+offset)-1][revcomp[seq[i]]]\n            if 0:\n                print \"\\t\\t%s vs %s: F=%6.2f R=%6.2f %6.2f %4.2f\"%(oseq, self.oneletter[offset:offset+len(seq)],\n                                                                   total_f, total_r,  maximum,\n                                                                   max([total_f,total_r])/self.maxscore)\n            if total_f > threshold and total_f > total_r:\n                endpoints.append( (offset,offset+self.width-1) )\n                scores.append(total_f)\n                matches.append(oseq[offset:offset+self.width])\n            elif total_r > threshold:\n                endpoints.append( (offset,offset+self.width-1) )\n                scores.append(total_r)\n                matches.append(oseq[offset:offset+self.width])\n        return(matches,endpoints,scores)", "response": "Internal function for performing a small sequence scan for matches and endpoints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mask_seq(self,seq):\n        masked = ''\n        matches, endpoints, scores = self.scan(seq)\n        cursor = 0\n        for start, stop in endpoints:\n            masked = masked + seq[cursor:start] + 'N'*self.width\n            cursor = stop+1\n        masked = masked + seq[cursor:]\n        return masked", "response": "mask_seq - Masks the input sequence with N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in - region N s in region N s"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef masked_neighborhoods(self,seq,flanksize):\n        ns = self.seq_neighborhoods(seq,flanksize)\n        return [self.mask_seq(n) for n in ns]", "response": "Returns a list of the neighborhoods in the input sequence that are masked by the motif."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of all the subsequences that are in the input sequence.", "response": "def seq_neighborhoods(self,seq,flanksize):\n        \"\"\"\n        m.seq_neighborhoods(seq,flanksize) -- Chop up the input sequence into regions surrounding matches to the motif.\n        \"\"\"\n        subseqs = []\n        matches, endpoints, scores = self.scan(seq)\n        laststart, laststop = -1, -1\n        for start, stop in endpoints:\n            curstart, curstop = max(0,start-flanksize), min(stop+flanksize,len(seq))\n            if curstart > laststop:\n                if laststop != -1:\n                    subseqs.append(seq[laststart:laststop])\n                laststart, laststop = curstart, curstop\n            else:\n                laststop = curstop\n        if endpoints: subseqs.append(seq[laststart:laststop])\n        return subseqs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef maxdiff(self):\n        POW  = math.pow\n        D = 0\n        for i in range(self.width):\n            _min = 100\n            _max = -100\n            for L in ACGT:\n                val = POW(2,self.logP[i][L])\n                if   val > _max:\n                    _max  = val\n                    _maxL = L\n                elif val < _min:\n                    _min  = val\n                    _minL = L\n            for L in ACGT:\n                if L == _minL:\n                    delta = 1-POW(2,self.logP[i][L])           #1-val\n                    D = D + delta*delta\n                else:\n                    D = D + POW( POW(2,self.logP[i][L]), 2)    #0-val\n        return(math.sqrt(D))", "response": "maxdiff - Compute maximum possible Euclidean distance to another motif"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns motif with low - information flanks removed.", "response": "def trimmed(self,thresh=0.1):\n        \"\"\"\n        m.trimmed(,thresh=0.1)  -- Return motif with low-information flanks removed.  'thresh' is in bits.\n        \"\"\"\n        for start in range(0,self.width-1):\n            if self.bits[start]>=thresh: break\n        for stop  in range(self.width,1,-1):\n            if self.bits[stop-1]>=thresh: break\n        m = self[start,stop]\n        return m"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bestseqs(self,thresh=None):\n        if not thresh:\n            if self._bestseqs:\n                return self._bestseqs\n        if not thresh: thresh = 0.8 * self.maxscore\n        self._bestseqs = bestseqs(self,thresh)\n        return self._bestseqs", "response": "Return all k - mers that match motif with a score > = thresh"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef emit(self,prob_min=0.0,prob_max=1.0):\n        if not self.cumP:\n            for logcol in self.logP:\n                tups = []\n                for L in ACGT:\n                    p = math.pow(2,logcol[L])\n                    tups.append((p,L))\n                tups.sort()\n                cumu = []\n                tot  = 0\n                for p,L in tups:\n                    tot = tot + p\n                    cumu.append((tot,L))\n                self.cumP.append(cumu)\n        s = []\n        #u = random()+0.01 #Can make higher for more consistent motifs\n        u = (prob_max-prob_min)*random() + prob_min\n        for cumu in self.cumP:\n            #u = random()+0.01 #Can make higher for more consistent motifs\n            last = 0\n            for p,L in cumu:\n                if last < u and u <= p:\n                    letter = L\n                    break\n                else: last = p\n#           print L,'%8.4f'%u,cumu\n            s.append(L)\n        #print ''.join(s)\n        return ''.join(s)", "response": "This function is used to emit a sequence of unique identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate one k - mer that matches the motif.", "response": "def random_kmer(self):\n        \"\"\"\n        m.random_kmer() -- Generate one of the many k-mers that matches the motif.  See m.emit() for a more probabilistic generator\n        \n        \"\"\"\n        if not self._bestseqs: self._bestseqs = self.bestseqs()\n        seqs   = self._bestseqs\n        pos = int(random() * len(seqs))\n        print 'Random: ',self.oneletter,seqs[pos][1]\n        return(seqs[pos][1])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a deep copy of the motif", "response": "def copy(self):\n        \"\"\"\n        m.copy() -- Return a 'deep' copy of the motif\n        \"\"\"\n        a = Motif()\n        a.__dict__ = self.__dict__.copy()\n        return a"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a bogus sequence alignment that will reproduce the probability matrix.", "response": "def bogus_kmers(self,count=200):\n        \"\"\"\n        m.bogus_kmers(count=200) --  Generate a faked multiple sequence alignment that will reproduce\n                                     the probability matrix.\n        \"\"\"\n\n        POW  = math.pow\n        #Build p-value inspired matrix\n        #Make totals cummulative:\n        # A: 0.1 C: 0.4 T:0.2 G:0.3\n        #                            ->  A:0.0 C:0.1 T:0.5 G:0.7  0.0\n        \n        #Take bg into account:\n        # We want to pick P' for each letter such that:\n        #     P'/0.25  = P/Q\n        # so  P'       = 0.25*P/Q\n        \n        m = []\n        for i in range(self.width):\n            _col = []\n            tot   = 0.0\n            for L in ACGT:\n                _col.append( tot )\n                tot = tot + POW(2,self.logP[i][L]) * 0.25 / self.background[L]\n            _col.append(tot)\n            #Renormalize\n            for idx in range(len(_col)):\n                _col[idx] = _col[idx] / _col[-1]\n            m.append(_col)\n\n        for p in range(0): #Was 5\n            for i in range(len(m)):\n                print '%6.4f  '%m[i][p],\n            print\n\n        seqs=[]\n        for seqnum in range(count+1):\n            f = float(seqnum)/(count+1)\n            s = []\n            for i in range(self.width):\n                for j in range(4):\n                    if (m[i][j] <= f and f < m[i][j+1]):\n                        s.append(ACGT[j])\n                        break\n            seqs.append(''.join(s))\n\n        del(seqs[0])\n        #for i in range(count):\n        #    print \">%3d\\n%s\"%(i,seqs[i])\n\n        return(seqs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flush(self):\n\n        self.clear()\n        self.delete(self.session_key)\n        self.create()", "response": "Removes the current session data from the database and regenerates the the\n        key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wrap_object(obj, decorator):\n    actual_decorator = method_decorator(decorator)\n\n    if inspect.isfunction(obj):\n        wrapped_obj = actual_decorator(obj)\n        update_wrapper(wrapped_obj, obj, assigned=available_attrs(obj))\n    elif inspect.isclass(obj):\n        for method_name in obj.http_method_names:\n            if hasattr(obj, method_name):\n                method = getattr(obj, method_name)\n                wrapped_method = actual_decorator(method)\n                update_wrapper(wrapped_method, method, assigned=available_attrs(method))\n                setattr(obj, method_name, wrapped_method)\n        wrapped_obj = obj\n    else:\n        raise TypeError(\"received an object of type '{0}' expected 'function' or 'classobj'.\".format(type(obj)))\n\n    return wrapped_obj", "response": "Wraps the given object with the given decorator function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverride Qt method to return the item flags for the item at the given index", "response": "def flags(self, index):\n        \"\"\"Override Qt method\"\"\"\n        column = index.column()\n\n        if index.isValid():\n            if column in [C.COL_START, C.COL_END]:\n#                return Qt.ItemFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)\n                return Qt.ItemFlags(Qt.ItemIsEnabled)\n            else:\n                return Qt.ItemFlags(Qt.ItemIsEnabled | Qt.ItemIsSelectable)\n#                return Qt.ItemFlags(Qt.ItemIsEnabled)\n        else:\n            return Qt.ItemFlags(Qt.ItemIsEnabled)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding Qt method\"\"\"Override Qt method\"\"\"", "response": "def data(self, index, role=Qt.DisplayRole):\n        \"\"\"Override Qt method\"\"\"\n        if not index.isValid() or not 0 <= index.row() < len(self._rows):\n            return to_qvariant()\n\n        row = index.row()\n        column = index.column()\n\n        P = self._palette\n\n        if self._rows[row] == row:\n            action = C.ACTION_NONE\n            type_ = u''\n            name = u''\n            description = u''\n            version = u'-'\n            status = -1\n            # url = u''\n            # license_ = u''\n            i = False\n            r = False\n            u = False\n            d = False\n            # action_version = None\n        else:\n            action = self._rows[row][C.COL_ACTION]\n            type_ = self._rows[row][C.COL_PACKAGE_TYPE]\n            name = self._rows[row][C.COL_NAME]\n            description = self._rows[row][C.COL_DESCRIPTION]\n            version = self._rows[row][C.COL_VERSION]\n            status = self._rows[row][C.COL_STATUS]\n            # url = self._rows[row][C.COL_URL]\n            # license_ = self._rows[row][C.COL_LICENSE]\n            i = self._rows[row][C.COL_INSTALL]\n            r = self._rows[row][C.COL_REMOVE]\n            u = self._rows[row][C.COL_UPGRADE]\n            d = self._rows[row][C.COL_DOWNGRADE]\n            # action_version = self._rows[row][C.COL_ACTION_VERSION]\n\n        is_upgradable = self.is_upgradable(self.index(row, C.COL_VERSION))\n#        if is_upgradable:\n#            version += C.UPGRADE_SYMBOL\n\n        if role == Qt.DisplayRole:\n            if column == C.COL_PACKAGE_TYPE:\n                return to_qvariant(type_)\n            if column == C.COL_NAME:\n                return to_qvariant(name)\n            elif column == C.COL_VERSION:\n                return to_qvariant(version)\n            elif column == C.COL_STATUS:\n                return to_qvariant(status)\n            elif column == C.COL_DESCRIPTION:\n                return to_qvariant(description)\n            elif column == C.COL_ACTION:\n                return to_qvariant(action)\n        elif role == Qt.BackgroundRole:\n            if action == C.ACTION_REMOVE:\n                return to_qvariant(P['background.remove'])\n            elif action == C.ACTION_INSTALL:\n                return to_qvariant(P['background.install'])\n            elif action == C.ACTION_UPGRADE:\n                return to_qvariant(P['background.upgrade'])\n            elif action == C.ACTION_DOWNGRADE:\n                return to_qvariant(P['background.downgrade'])\n        elif role == Qt.TextAlignmentRole:\n            if column in [C.COL_NAME, C.COL_DESCRIPTION]:\n                return to_qvariant(int(Qt.AlignLeft | Qt.AlignVCenter))\n            elif column in [C.COL_VERSION] and is_upgradable:\n                return to_qvariant(int(Qt.AlignLeft | Qt.AlignVCenter))\n            # else:\n            #     return to_qvariant(int(Qt.AlignHCenter | Qt.AlignVCenter))\n        elif role == Qt.DecorationRole:\n            if column == C.COL_ACTION:\n                if action == C.ACTION_NONE:\n                    if status == C.NOT_INSTALLED:\n                        return to_qvariant(P['icon.action.not_installed'])\n                    elif status in [C.UPGRADABLE, C.MIXGRADABLE]:\n                        return to_qvariant(P['icon.action.installed'])\n                    elif status in [C.INSTALLED, C.DOWNGRADABLE,\n                                    C.MIXGRADABLE]:\n                        return to_qvariant(P['icon.action.installed'])\n                elif action == C.ACTION_INSTALL:\n                    return to_qvariant(P['icon.action.add'])\n                elif action == C.ACTION_REMOVE:\n                    return to_qvariant(P['icon.action.remove'])\n                elif action == C.ACTION_UPGRADE:\n                    return to_qvariant(P['icon.action.upgrade'])\n                elif action == C.ACTION_DOWNGRADE:\n                    return to_qvariant(P['icon.action.downgrade'])\n                else:\n                    return to_qvariant()\n            elif column == C.COL_PACKAGE_TYPE:\n                if type_ == C.CONDA_PACKAGE:\n                    return to_qvariant(P['icon.anaconda'])\n                elif type_ == C.PIP_PACKAGE:\n                    return to_qvariant(P['icon.python'])\n                else:\n                    return to_qvariant()\n            elif column == C.COL_INSTALL:\n                if status == C.NOT_INSTALLED:\n                    if i:\n                        return to_qvariant(P['icon.add.pressed'])\n                    else:\n                        return to_qvariant(P['icon.add.active'])\n                elif (status == C.INSTALLED or\n                      status == C.UPGRADABLE or\n                      status == C.DOWNGRADABLE or\n                      status == C.MIXGRADABLE):\n                    if r:\n                        return to_qvariant(P['icon.remove.pressed'])\n                    else:\n                        return to_qvariant(P['icon.remove.active'])\n                else:\n                    return to_qvariant(P['icon.add.inactive'])\n            elif column == C.COL_REMOVE:\n                if (status == C.INSTALLED or\n                    status == C.UPGRADABLE or\n                    status == C.DOWNGRADABLE or\n                   status == C.MIXGRADABLE):\n                    if r:\n                        return to_qvariant(P['icon.remove.pressed'])\n                    else:\n                        return to_qvariant(P['icon.remove.active'])\n                else:\n                    return to_qvariant(P['icon.remove.inactive'])\n            elif column == C.COL_UPGRADE:\n                if status == C.UPGRADABLE or \\\n                  status == C.MIXGRADABLE:\n                    if u:\n                        return to_qvariant(P['icon.upgrade.pressed'])\n                    else:\n                        return to_qvariant(P['icon.upgrade.active'])\n                else:\n                    return to_qvariant(P['icon.upgrade.inactive'])\n            elif column == C.COL_DOWNGRADE:\n                if status == C.DOWNGRADABLE or \\\n                  status == C.MIXGRADABLE:\n                    if d:\n                        return to_qvariant(P['icon.downgrade.pressed'])\n                    else:\n                        return to_qvariant(P['icon.downgrade.active'])\n                else:\n                    return to_qvariant(P['icon.downgrade.inactive'])\n            elif column == C.COL_VERSION:\n                if is_upgradable:\n                    return to_qvariant(P['icon.upgrade.arrow'])\n                else:\n                    return to_qvariant(P['spacer'])\n        elif role == Qt.ToolTipRole:\n            if column == C.COL_INSTALL and status == C.NOT_INSTALLED:\n                return to_qvariant(_('Install package'))\n            elif column == C.COL_INSTALL and (status == C.INSTALLED or\n                                              status == C.UPGRADABLE or\n                                              status == C.DOWNGRADABLE or\n                                              status == C.MIXGRADABLE):\n                return to_qvariant(_('Remove package'))\n            elif column == C.COL_UPGRADE and (status == C.INSTALLED or\n                                              status == C.UPGRADABLE or\n                                              status == C.MIXGRADABLE):\n                return to_qvariant(_('Upgrade package'))\n            elif column == C.COL_DOWNGRADE and (status == C.INSTALLED or\n                                                status == C.DOWNGRADABLE or\n                                                status == C.MIXGRADABLE):\n                return to_qvariant(_('Downgrade package'))\n            elif column == C.COL_PACKAGE_TYPE:\n                if type_ == C.CONDA_PACKAGE:\n                    return to_qvariant(_('Conda package'))\n                elif type_ == C.PIP_PACKAGE:\n                    return to_qvariant(_('Python package'))\n            elif column == C.COL_VERSION:\n                if is_upgradable:\n                    return to_qvariant(_('Update available'))\n        elif role == Qt.ForegroundRole:\n            palette = QPalette()\n            if column in [C.COL_NAME, C.COL_DESCRIPTION]:\n                if status in [C.INSTALLED, C.UPGRADABLE, C.DOWNGRADABLE,\n                              C.MIXGRADABLE]:\n                    color = palette.color(QPalette.WindowText)\n                    return to_qvariant(color)\n                elif status in [C.NOT_INSTALLED]:\n                    color = palette.color(QPalette.Mid)\n                    color = P['foreground.not.installed']\n                    return to_qvariant(color)\n            elif column in [C.COL_VERSION]:\n                if is_upgradable:\n                    return to_qvariant(P['foreground.upgrade'])\n\n        elif role == Qt.SizeHintRole:\n            if column in [C.ACTION_COLUMNS] + [C.COL_PACKAGE_TYPE]:\n                return to_qvariant(QSize(24, 24))\n\n        return to_qvariant()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of all the compatible package canonical name versions", "response": "def get_package_versions(self, name):\n        \"\"\"\n        Gives all the compatible package canonical name\n\n        name : str\n            Name of the package\n        \"\"\"\n        package_data = self._packages.get(name)\n        versions = []\n\n        if package_data:\n            versions = sort_versions(list(package_data.get('versions', [])))\n\n        return versions"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register_plugin(self):\n        main = self.main\n        main.add_dockwidget(self)\n\n        #if getattr(main.projectexplorer, 'sig_project_closed', False):\n        #    pe = main.projectexplorer\n        #    pe.condamanager = self\n        #    pe.sig_project_closed.connect(self.project_closed)\n        #    pe.sig_project_loaded.connect(self.project_loaded)\n        #    self.sig_worker_ready.connect(self._after_load)\n        #    self.sig_environment_created.connect(pe.sig_environment_created)\n\n        self.sig_channels_updated.connect(self._save_channel_settings)", "response": "Register plugin in Spyder s main window"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef closing_plugin(self, cancelable=False):\n        if self.busy:\n            answer = QMessageBox.question(\n                self,\n                'Conda Manager',\n                'Conda Manager is still busy.\\n\\nDo you want to quit?',\n                buttons=QMessageBox.Yes | QMessageBox.No)\n\n            if answer == QMessageBox.Yes:\n                return True\n            else:\n                return False\n        else:\n            return True", "response": "Perform actions before parent main window is closed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning absolute path for configuration file with specified filename.", "response": "def get_conf_path(filename=None):\r\n    \"\"\"Return absolute path for configuration file with specified filename.\"\"\"\r\n    conf_dir = osp.join(get_home_dir(), '.condamanager')\r\n\r\n    if not osp.isdir(conf_dir):\r\n        os.mkdir(conf_dir)\r\n\r\n    if filename is None:\r\n        return conf_dir\r\n    else:\r\n        return osp.join(conf_dir, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsorting a list of version numbers.", "response": "def sort_versions(versions=(), reverse=False, sep=u'.'):\r\n    \"\"\"Sort a list of version number strings.\r\n\r\n    This function ensures that the package sorting based on number name is\r\n    performed correctly when including alpha, dev rc1 etc...\r\n    \"\"\"\r\n    if versions == []:\r\n        return []\r\n\r\n    digits = u'0123456789'\r\n\r\n    def toint(x):\r\n        try:\r\n            n = int(x)\r\n        except:\r\n            n = x\r\n        return n\r\n    versions = list(versions)\r\n    new_versions, alpha, sizes = [], set(), set()\r\n\r\n    for item in versions:\r\n        it = item.split(sep)\r\n        temp = []\r\n        for i in it:\r\n            x = toint(i)\r\n            if not isinstance(x, int):\r\n                x = u(x)\r\n                middle = x.lstrip(digits).rstrip(digits)\r\n                tail = toint(x.lstrip(digits).replace(middle, u''))\r\n                head = toint(x.rstrip(digits).replace(middle, u''))\r\n                middle = toint(middle)\r\n                res = [head, middle, tail]\r\n                while u'' in res:\r\n                    res.remove(u'')\r\n                for r in res:\r\n                    if is_unicode(r):\r\n                        alpha.add(r)\r\n            else:\r\n                res = [x]\r\n            temp += res\r\n        sizes.add(len(temp))\r\n        new_versions.append(temp)\r\n\r\n    # replace letters found by a negative number\r\n    replace_dic = {}\r\n    alpha = sorted(alpha, reverse=True)\r\n    if len(alpha):\r\n        replace_dic = dict(zip(alpha, list(range(-1, -(len(alpha)+1), -1))))\r\n\r\n    # Complete with zeros based on longest item and replace alphas with number\r\n    nmax = max(sizes)\r\n    for i in range(len(new_versions)):\r\n        item = []\r\n        for z in new_versions[i]:\r\n            if z in replace_dic:\r\n                item.append(replace_dic[z])\r\n            else:\r\n                item.append(z)\r\n\r\n        nzeros = nmax - len(item)\r\n        item += [0]*nzeros\r\n        item += [versions[i]]\r\n        new_versions[i] = item\r\n\r\n    new_versions = sorted(new_versions, reverse=reverse)\r\n    return [n[-1] for n in new_versions]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write_file(fname_parts, content):\n\n    fname_parts = [str(part) for part in fname_parts]\n    # try to create the directory\n    if len(fname_parts) > 1:\n        try:\n            os.makedirs(os.path.join(*fname_parts[:-1]))\n        except OSError:\n            pass\n    # write file\n    fhandle = open(os.path.join(*fname_parts), \"w\")\n    fhandle.write(content)\n    fhandle.close()", "response": "write a file and create all needed directories"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the filter for the current object.", "response": "def set_filter(self, text, status):\n        \"\"\"\n        text : string\n            The string to be used for pattern matching.\n        status : int\n            TODO: add description\n        \"\"\"\n        self._filter_string = text.lower()\n        self._filter_status = status\n        self.invalidateFilter()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a filter function to the list of filter functions that can be used to filter the object for the given name.", "response": "def add_filter_function(self, name, new_function):\n        \"\"\"\n        name : hashable object\n            The object to be used as the key for\n            this filter function. Use this object\n            to remove the filter function in the future.\n            Typically this is a self descriptive string.\n\n        new_function : function\n            A new function which must take two arguments,\n            the row to be tested and the ProxyModel's current\n            filterString. The function should return True if\n            the filter accepts the row, False otherwise.\n\n            ex:\n            model.add_filter_function(\n                'test_columns_1_and_2',\n                lambda r,s: (s in r[1] and s in r[2]))\n        \"\"\"\n        self._filter_functions[name] = new_function\n        self.invalidateFilter()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_filter_function(self, name):\n        if name in self._filter_functions.keys():\n            del self._filter_functions[name]\n            self.invalidateFilter()", "response": "Removes the filter function associated with name if it exists."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the row is accepted by the filter functions.", "response": "def filterAcceptsRow(self, row_num, parent):\n        \"\"\"Qt override.\n\n        Reimplemented from base class to allow the use of custom filtering.\n        \"\"\"\n        model = self.sourceModel()\n\n        # The source model should have a method called row()\n        # which returns the table row as a python list.\n        tests = [func(model.row(row_num), self._filter_string,\n                 self._filter_status) for func in\n                 self._filter_functions.values()]\n\n        return False not in tests"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noverrides keyPressEvent to clear text if escape key is pressed.", "response": "def keyPressEvent(self, event):\n        \"\"\"\n        Qt override.\n        \"\"\"\n        key = event.key()\n        if key in [Qt.Key_Escape]:\n            self.clear_text()\n        else:\n            super(LineEditSearch, self).keyPressEvent(event)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_data_files():\n    if sys.platform.startswith('linux'):\n        if PY3:\n            data_files = [('share/applications',\n                           ['scripts/condamanager3.desktop']),\n                          ('share/pixmaps',\n                           ['img_src/condamanager3.png'])]\n        else:\n            data_files = [('share/applications',\n                           ['scripts/condamanager.desktop']),\n                          ('share/pixmaps',\n                           ['img_src/condamanager.png'])]\n    elif os.name == 'nt':\n        data_files = [('scripts', ['img_src/conda-manager.ico'])]\n    else:\n        data_files = []\n    return data_files", "response": "Return data_files in a platform dependent manner"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_coding(text):\r\n    for line in text.splitlines()[:2]:\r\n        result = CODING_RE.search(to_text_string(line))\r\n        if result:\r\n            return result.group(1)\r\n    return None", "response": "Function to get the coding of a text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef encode(text, orig_coding):\r\n    if orig_coding == 'utf-8-bom':\r\n        return BOM_UTF8 + text.encode(\"utf-8\"), 'utf-8-bom'\r\n\r\n    # Try declared coding spec\r\n    coding = get_coding(text)\r\n    if coding:\r\n        try:\r\n            return text.encode(coding), coding\r\n        except (UnicodeError, LookupError):\r\n            raise RuntimeError(\"Incorrect encoding (%s)\" % coding)\r\n    if (orig_coding and orig_coding.endswith('-default') or\r\n       orig_coding.endswith('-guessed')):\r\n        coding = orig_coding.replace(\"-default\", \"\")\r\n        coding = orig_coding.replace(\"-guessed\", \"\")\r\n        try:\r\n            return text.encode(coding), coding\r\n        except (UnicodeError, LookupError):\r\n            pass\r\n\r\n    # Try saving as ASCII\r\n    try:\r\n        return text.encode('ascii'), 'ascii'\r\n    except UnicodeError:\r\n        pass\r\n\r\n    # Save as UTF-8 without BOM\r\n    return text.encode('utf-8'), 'utf-8'", "response": "Function to encode a text with the specified coding."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites text to file filename assuming encoding", "response": "def write(text, filename, encoding='utf-8', mode='wb'):\r\n    \"\"\"\r\n    Write 'text' to file ('filename') assuming 'encoding'\r\n    Return (eventually new) encoding\r\n    \"\"\"\r\n    text, encoding = encode(text, encoding)\r\n    with open(filename, mode) as textfile:\r\n        textfile.write(text)\r\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_text_file(filename):\r\n    try:\r\n        open(filename)\r\n    except Exception:\r\n        return False\r\n    with open(filename, 'rb') as fid:\r\n        try:\r\n            CHUNKSIZE = 1024\r\n            chunk = fid.read(CHUNKSIZE)\r\n            # check for a UTF BOM\r\n            for bom in [BOM_UTF8, BOM_UTF16, BOM_UTF32]:\r\n                if chunk.startswith(bom):\r\n                    return True\r\n            chunk = chunk.decode('utf-8')\r\n            while 1:\r\n                if '\\0' in chunk:  # found null byte\r\n                    return False\r\n                if len(chunk) < CHUNKSIZE:\r\n                    break  # done\r\n                chunk = fid.read(CHUNKSIZE).decode('utf-8')\r\n        except UnicodeDecodeError:\r\n            return False\r\n        except Exception:\r\n            pass\r\n    return True", "response": "Test if the given path is a text - like file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new QApplication instance if it doesn t already exist", "response": "def qapplication(translate=True, test_time=3):\r\n    \"\"\"Return QApplication instance\r\n    Creates it if it doesn't already exist\"\"\"\r\n    app = QApplication.instance()\r\n    if app is None:\r\n        app = QApplication(['Conda-Manager'])\r\n        app.setApplicationName('Conda-Manager')\r\n    if translate:\r\n        install_translator(app)\r\n\r\n    test_travis = os.environ.get('TEST_CI', None)\r\n    if test_travis is not None:\r\n        timer_shutdown = QTimer(app)\r\n        timer_shutdown.timeout.connect(app.quit)\r\n        timer_shutdown.start(test_time*1000)\r\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_action(parent, text, shortcut=None, icon=None, tip=None,\r\n                  toggled=None, triggered=None, data=None, menurole=None,\r\n                  context=Qt.WindowShortcut):\r\n    \"\"\"Create a QAction\"\"\"\r\n    action = QAction(text, parent)\r\n    if triggered is not None:\r\n        action.triggered.connect(triggered)\r\n    if toggled is not None:\r\n        action.toggled.connect(toggled)\r\n        action.setCheckable(True)\r\n    if icon is not None:\r\n        action.setIcon(icon)\r\n    if shortcut is not None:\r\n        action.setShortcut(shortcut)\r\n    if tip is not None:\r\n        action.setToolTip(tip)\r\n        action.setStatusTip(tip)\r\n    if data is not None:\r\n        action.setData(to_qvariant(data))\r\n    if menurole is not None:\r\n        action.setMenuRole(menurole)\r\n    #TODO: Hard-code all shortcuts and choose context=Qt.WidgetShortcut\r\n    # (this will avoid calling shortcuts from another dockwidget\r\n    #  since the context thing doesn't work quite well with these widgets)\r\n    action.setShortcutContext(context)\r\n    return action", "response": "Create a QAction object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning pycrypto s AES mode raise exception if not supported", "response": "def get_aes_mode(mode):\n    \"\"\"Return pycrypto's AES mode, raise exception if not supported\"\"\"\n    aes_mode_attr = \"MODE_{}\".format(mode.upper())\n    try:\n        aes_mode = getattr(AES, aes_mode_attr)\n    except AttributeError:\n        raise Exception(\n            \"Pycrypto/pycryptodome does not seem to support {}. \".format(aes_mode_attr) +\n            \"If you use pycrypto, you need a version >= 2.7a1 (or a special branch).\"\n        )\n    return aes_mode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_proxy_servers(proxy_settings):\n    proxy_settings_dic = {}\n\n    for key in proxy_settings:\n        proxy = proxy_settings[key]\n        proxy_config = [m.groupdict() for m in PROXY_RE.finditer(proxy)]\n        if proxy_config:\n            proxy_config = proxy_config[0]\n            host_port = proxy_config.pop('host_port')\n            if ':' in host_port:\n                host, port = host_port.split(':')\n            else:\n                host, port = host_port, None\n            proxy_config['host'] = host\n            proxy_config['port'] = int(port) if port else None\n            proxy_settings_dic[key] = proxy_config\n            proxy_config['full'] = proxy_settings[key]\n\n    return proxy_settings_dic", "response": "Split the proxy conda configuration to be used by the proxy factory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef proxy_servers(self):\n        proxy_servers = {}\n        if self._load_rc_func is None:\n            return proxy_servers\n        else:\n            HTTP_PROXY = os.environ.get('HTTP_PROXY')\n            HTTPS_PROXY = os.environ.get('HTTPS_PROXY')\n\n            if HTTP_PROXY:\n                proxy_servers['http'] = HTTP_PROXY\n\n            if HTTPS_PROXY:\n                proxy_servers['https'] = HTTPS_PROXY\n\n            proxy_servers_conf = self._load_rc_func().get('proxy_servers', {})\n            proxy_servers.update(proxy_servers_conf)\n\n            return proxy_servers", "response": "Return the proxy servers available for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _create_proxy(proxy_setting):\n        proxy = QNetworkProxy()\n        proxy_scheme = proxy_setting['scheme']\n        proxy_host = proxy_setting['host']\n        proxy_port = proxy_setting['port']\n        proxy_username = proxy_setting['username']\n        proxy_password = proxy_setting['password']\n        proxy_scheme_host = '{0}://{1}'.format(proxy_scheme, proxy_host)\n        proxy.setType(QNetworkProxy.HttpProxy)\n\n        if proxy_scheme_host:\n            # proxy.setHostName(proxy_scheme_host)  # does not work with scheme\n            proxy.setHostName(proxy_host)\n\n        if proxy_port:\n            proxy.setPort(proxy_port)\n\n        if proxy_username:\n            proxy.setUser(proxy_username)\n\n        if proxy_password:\n            proxy.setPassword(proxy_password)\n\n        return proxy", "response": "Create a Network proxy object for the given proxy settings."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck for inactive workers and remove their references.", "response": "def _clean(self):\n        \"\"\"Check for inactive workers and remove their references.\"\"\"\n        if self._workers:\n            for url in self._workers.copy():\n                w = self._workers[url]\n                if w.is_finished():\n                    self._workers.pop(url)\n                    self._paths.pop(url)\n                    if url in self._get_requests:\n                        self._get_requests.pop(url)\n\n        else:\n            self._timer.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _request_finished(self, reply):\n        url = to_text_string(reply.url().toEncoded(), encoding='utf-8')\n\n        if url in self._paths:\n            path = self._paths[url]\n        if url in self._workers:\n            worker = self._workers[url]\n\n        if url in self._head_requests:\n            error = reply.error()\n#            print(url, error)\n            if error:\n                logger.error(str(('Head Reply Error:', error)))\n                worker.sig_download_finished.emit(url, path)\n                worker.sig_finished.emit(worker, path, error)\n                return\n\n            self._head_requests.pop(url)\n            start_download = not bool(error)\n            header_pairs = reply.rawHeaderPairs()\n            headers = {}\n\n            for hp in header_pairs:\n                headers[to_text_string(hp[0]).lower()] = to_text_string(hp[1])\n\n            total_size = int(headers.get('content-length', 0))\n\n            # Check if file exists\n            if os.path.isfile(path):\n                file_size = os.path.getsize(path)\n\n                # Check if existing file matches size of requested file\n                start_download = file_size != total_size\n\n            if start_download:\n                # File sizes dont match, hence download file\n                qurl = QUrl(url)\n                request = QNetworkRequest(qurl)\n                self._get_requests[url] = request\n                reply = self._manager.get(request)\n\n                error = reply.error()\n                if error:\n                    logger.error(str(('Reply Error:', error)))\n\n                reply.downloadProgress.connect(\n                    lambda r, t, w=worker: self._progress(r, t, w))\n            else:\n                # File sizes match, dont download file or error?\n                worker.finished = True\n                worker.sig_download_finished.emit(url, path)\n                worker.sig_finished.emit(worker, path, None)\n        elif url in self._get_requests:\n            data = reply.readAll()\n            self._save(url, path, data)", "response": "Callback for download once the request has finished."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _save(self, url, path, data):\n        worker = self._workers[url]\n        path = self._paths[url]\n\n        if len(data):\n            try:\n                with open(path, 'wb') as f:\n                    f.write(data)\n            except Exception:\n                logger.error((url, path))\n\n        # Clean up\n        worker.finished = True\n        worker.sig_download_finished.emit(url, path)\n        worker.sig_finished.emit(worker, path, None)\n        self._get_requests.pop(url)\n        self._workers.pop(url)\n        self._paths.pop(url)", "response": "Save data of downloaded url in path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download(self, url, path):\n        # original_url = url\n#        print(url)\n        qurl = QUrl(url)\n        url = to_text_string(qurl.toEncoded(), encoding='utf-8')\n\n        logger.debug(str((url, path)))\n        if url in self._workers:\n            while not self._workers[url].finished:\n                return self._workers[url]\n\n        worker = DownloadWorker(url, path)\n\n        # Check download folder exists\n        folder = os.path.dirname(os.path.abspath(path))\n        if not os.path.isdir(folder):\n            os.makedirs(folder)\n\n        request = QNetworkRequest(qurl)\n        self._head_requests[url] = request\n        self._paths[url] = path\n        self._workers[url] = worker\n        self._manager.head(request)\n        self._timer.start()\n\n        return worker", "response": "Download url and save data to path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck for inactive workers and remove their references.", "response": "def _clean(self):\n        \"\"\"Check for inactive workers and remove their references.\"\"\"\n        if self._workers:\n            for w in self._workers:\n                if w.is_finished():\n                    self._workers.remove(w)\n\n        if self._threads:\n            for t in self._threads:\n                if t.isFinished():\n                    self._threads.remove(t)\n        else:\n            self._timer.stop()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts the next threaded worker in the queue.", "response": "def _start(self):\n        \"\"\"Start the next threaded worker in the queue.\"\"\"\n        if len(self._queue) == 1:\n            thread = self._queue.popleft()\n            thread.start()\n            self._timer.start()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new worker instance.", "response": "def _create_worker(self, method, *args, **kwargs):\n        \"\"\"Create a new worker instance.\"\"\"\n        thread = QThread()\n        worker = RequestsDownloadWorker(method, args, kwargs)\n        worker.moveToThread(thread)\n        worker.sig_finished.connect(self._start)\n        self._sig_download_finished.connect(worker.sig_download_finished)\n        self._sig_download_progress.connect(worker.sig_download_progress)\n        worker.sig_finished.connect(thread.quit)\n        thread.started.connect(worker.start)\n        self._queue.append(thread)\n        self._threads.append(thread)\n        self._workers.append(worker)\n        self._start()\n        return worker"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(self, url, path=None, force=False):\n        logger.debug(str((url, path, force)))\n        method = self._download\n        return self._create_worker(method, url, path=path, force=force)", "response": "Download file given by url and save it to path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef terminate(self):\n        for t in self._threads:\n            t.quit()\n        self._thread = []\n        self._workers = []", "response": "Terminate all workers and threads."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if url is valid.", "response": "def is_valid_url(self, url, non_blocking=True):\n        \"\"\"Check if url is valid.\"\"\"\n        logger.debug(str((url)))\n        if non_blocking:\n            method = self._is_valid_url\n            return self._create_worker(method, url)\n        else:\n            return self._is_valid_url(url)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_valid_api_url(self, url, non_blocking=True):\n        logger.debug(str((url)))\n        if non_blocking:\n            method = self._is_valid_api_url\n            return self._create_worker(method, url)\n        else:\n            return self._is_valid_api_url(url=url)", "response": "Check if an anaconda api url is valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_valid_channel(self,\n                         channel,\n                         conda_url='https://conda.anaconda.org',\n                         non_blocking=True):\n        \"\"\"Check if a conda channel is valid.\"\"\"\n        logger.debug(str((channel, conda_url)))\n        if non_blocking:\n            method = self._is_valid_channel\n            return self._create_worker(method, channel, conda_url)\n        else:\n            return self._is_valid_channel(channel, conda_url=conda_url)", "response": "Check if a conda channel is valid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef human_bytes(n):\n    if n < 1024:\n        return '%d B' % n\n    k = n/1024\n    if k < 1024:\n        return '%d KB' % round(k)\n    m = k/1024\n    if m < 1024:\n        return '%.1f MB' % m\n    g = m/1024\n    return '%.2f GB' % g", "response": "Return the number of bytes n in more human readable form."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _partial(self):\n        raw_stdout = self._process.readAllStandardOutput()\n        stdout = handle_qbytearray(raw_stdout, _CondaAPI.UTF8)\n\n        json_stdout = stdout.replace('\\n\\x00', '')\n        try:\n            json_stdout = json.loads(json_stdout)\n        except Exception:\n            json_stdout = stdout\n\n        if self._partial_stdout is None:\n            self._partial_stdout = stdout\n        else:\n            self._partial_stdout += stdout\n\n        self.sig_partial.emit(self, json_stdout, None)", "response": "Callback for partial output."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _clean(self):\n        if self._workers:\n            for w in self._workers:\n                if w.is_finished():\n                    self._workers.remove(w)\n        else:\n            self._current_worker = None\n            self._timer.stop()", "response": "Remove references of inactive workers periodically."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _call_conda(self, extra_args, abspath=True, parse=False,\n                    callback=None):\n        \"\"\"\n        Call conda with the list of extra arguments, and return the worker.\n\n        The result can be force by calling worker.communicate(), which returns\n        the tuple (stdout, stderr).\n        \"\"\"\n        if abspath:\n            if sys.platform == 'win32':\n                python = join(self.ROOT_PREFIX, 'python.exe')\n                conda = join(self.ROOT_PREFIX, 'Scripts',\n                             'conda-script.py')\n            else:\n                python = join(self.ROOT_PREFIX, 'bin/python')\n                conda = join(self.ROOT_PREFIX, 'bin/conda')\n            cmd_list = [python, conda]\n        else:\n            # Just use whatever conda is on the path\n            cmd_list = ['conda']\n\n        cmd_list.extend(extra_args)\n\n        process_worker = ProcessWorker(cmd_list, parse=parse,\n                                       callback=callback)\n        process_worker.sig_finished.connect(self._start)\n        self._queue.append(process_worker)\n        self._start()\n\n        return process_worker", "response": "Call conda with the list of extra arguments and return the worker."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _setup_install_commands_from_kwargs(kwargs, keys=tuple()):\n        cmd_list = []\n        if kwargs.get('override_channels', False) and 'channel' not in kwargs:\n            raise TypeError('conda search: override_channels requires channel')\n\n        if 'env' in kwargs:\n            cmd_list.extend(['--name', kwargs.pop('env')])\n        if 'prefix' in kwargs:\n            cmd_list.extend(['--prefix', kwargs.pop('prefix')])\n        if 'channel' in kwargs:\n            channel = kwargs.pop('channel')\n            if isinstance(channel, str):\n                cmd_list.extend(['--channel', channel])\n            else:\n                cmd_list.append('--channel')\n                cmd_list.extend(channel)\n\n        for key in keys:\n            if key in kwargs and kwargs[key]:\n                cmd_list.append('--' + key.replace('_', '-'))\n\n        return cmd_list", "response": "Setup install commands for conda."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_root_prefix(self, prefix=None):\n        if prefix:\n            self.ROOT_PREFIX = prefix\n        else:\n            # Find some conda instance, and then use info to get 'root_prefix'\n            worker = self._call_and_parse(['info', '--json'], abspath=False)\n            info = worker.communicate()[0]\n            self.ROOT_PREFIX = info['root_prefix']", "response": "Set the prefix to the root environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning environment list of absolute path to their prefixes.", "response": "def get_envs(self, log=True):\n        \"\"\"Return environment list of absolute path to their prefixes.\"\"\"\n        if log:\n            logger.debug('')\n#        return self._call_and_parse(['info', '--json'],\n#                                    callback=lambda o, e: o['envs'])\n        envs = os.listdir(os.sep.join([self.ROOT_PREFIX, 'envs']))\n        envs = [os.sep.join([self.ROOT_PREFIX, 'envs', i]) for i in envs]\n\n        valid_envs = [e for e in envs if os.path.isdir(e) and\n                      self.environment_exists(prefix=e)]\n\n        return valid_envs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_prefix_envname(self, name, log=False):\n        prefix = None\n        if name == 'root':\n            prefix = self.ROOT_PREFIX\n\n#        envs, error = self.get_envs().communicate()\n        envs = self.get_envs()\n        for p in envs:\n            if basename(p) == name:\n                prefix = p\n\n        return prefix", "response": "Return full prefix path of environment defined by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn set of canonical names of linked packages in prefix.", "response": "def linked(prefix):\n        \"\"\"Return set of canonical names of linked packages in `prefix`.\"\"\"\n        logger.debug(str(prefix))\n\n        if not isdir(prefix):\n            return set()\n\n        meta_dir = join(prefix, 'conda-meta')\n        if not isdir(meta_dir):\n            # We might have nothing in linked (and no conda-meta directory)\n            return set()\n\n        return set(fn[:-5] for fn in os.listdir(meta_dir)\n                   if fn.endswith('.json'))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a dictionary with configuration information.", "response": "def info(self, abspath=True):\n        \"\"\"\n        Return a dictionary with configuration information.\n\n        No guarantee is made about which keys exist.  Therefore this function\n        should only be used for testing and debugging.\n        \"\"\"\n        logger.debug(str(''))\n        return self._call_and_parse(['info', '--json'], abspath=abspath)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary with package information.", "response": "def package_info(self, package, abspath=True):\n        \"\"\"Return a dictionary with package information.\"\"\"\n        return self._call_and_parse(['info', package, '--json'],\n                                    abspath=abspath)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_from_yaml(self, name, yamlfile):\n        logger.debug(str((name, yamlfile)))\n        cmd_list = ['env', 'create', '-n', name, '-f', yamlfile, '--json']\n        return self._call_and_parse(cmd_list)", "response": "Create new environment using conda - env via a yaml specification file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, name=None, prefix=None, pkgs=None, channels=None):\n        logger.debug(str((prefix, pkgs, channels)))\n\n        # TODO: Fix temporal hack\n        if (not pkgs or (not isinstance(pkgs, (list, tuple)) and\n                         not is_text_string(pkgs))):\n            raise TypeError('must specify a list of one or more packages to '\n                            'install into new environment')\n\n        cmd_list = ['create', '--yes', '--json', '--mkdir']\n        if name:\n            ref = name\n            search = [os.path.join(d, name) for d in\n                      self.info().communicate()[0]['envs_dirs']]\n            cmd_list.extend(['--name', name])\n        elif prefix:\n            ref = prefix\n            search = [prefix]\n            cmd_list.extend(['--prefix', prefix])\n        else:\n            raise TypeError('must specify either an environment name or a '\n                            'path for new environment')\n\n        if any(os.path.exists(prefix) for prefix in search):\n            raise CondaEnvExistsError('Conda environment {0} already '\n                                      'exists'.format(ref))\n\n        # TODO: Fix temporal hack\n        if isinstance(pkgs, (list, tuple)):\n            cmd_list.extend(pkgs)\n        elif is_text_string(pkgs):\n            cmd_list.extend(['--file', pkgs])\n\n        # TODO: Check if correct\n        if channels:\n            cmd_list.extend(['--override-channels'])\n\n            for channel in channels:\n                cmd_list.extend(['--channel'])\n                cmd_list.extend([channel])\n\n        return self._call_and_parse(cmd_list)", "response": "Create an environment with a specified set of packages."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_token_channel(self, channel, token):\n        if (token and channel not in self.DEFAULT_CHANNELS and\n                channel != 'defaults'):\n            url_parts = channel.split('/')\n            start = url_parts[:-1]\n            middle = 't/{0}'.format(token)\n            end = url_parts[-1]\n            token_channel = '{0}/{1}/{2}'.format('/'.join(start), middle, end)\n            return token_channel\n        else:\n            return channel", "response": "Adapt a channel to include token of the logged user."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls a set of packages into an environment by name or path.", "response": "def install(self, name=None, prefix=None, pkgs=None, dep=True,\n                channels=None, token=None):\n        \"\"\"\n        Install a set of packages into an environment by name or path.\n\n        If token is specified, the channels different from the defaults will\n        get the token appended.\n        \"\"\"\n        logger.debug(str((prefix, pkgs, channels)))\n\n        # TODO: Fix temporal hack\n        if not pkgs or not isinstance(pkgs, (list, tuple, str)):\n            raise TypeError('must specify a list of one or more packages to '\n                            'install into existing environment')\n\n        cmd_list = ['install', '--yes', '--json', '--force-pscheck']\n        if name:\n            cmd_list.extend(['--name', name])\n        elif prefix:\n            cmd_list.extend(['--prefix', prefix])\n        else:\n            # Just install into the current environment, whatever that is\n            pass\n\n        # TODO: Check if correct\n        if channels:\n            cmd_list.extend(['--override-channels'])\n\n            for channel in channels:\n                cmd_list.extend(['--channel'])\n                channel = self.parse_token_channel(channel, token)\n                cmd_list.extend([channel])\n\n        # TODO: Fix temporal hack\n        if isinstance(pkgs, (list, tuple)):\n            cmd_list.extend(pkgs)\n        elif isinstance(pkgs, str):\n            cmd_list.extend(['--file', pkgs])\n\n        if not dep:\n            cmd_list.extend(['--no-deps'])\n\n        return self._call_and_parse(cmd_list)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, *pkgs, **kwargs):\n        cmd_list = ['update', '--json', '--yes']\n\n        if not pkgs and not kwargs.get('all'):\n            raise TypeError(\"Must specify at least one package to update, or \"\n                            \"all=True.\")\n\n        cmd_list.extend(\n            self._setup_install_commands_from_kwargs(\n                kwargs,\n                ('dry_run', 'no_deps', 'override_channels',\n                 'no_pin', 'force', 'all', 'use_index_cache', 'use_local',\n                 'alt_hint')))\n\n        cmd_list.extend(pkgs)\n\n        return self._call_and_parse(cmd_list, abspath=kwargs.get('abspath',\n                                                                 True))", "response": "Update the package list in an environment by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove(self, name=None, prefix=None, pkgs=None, all_=False):\n        logger.debug(str((prefix, pkgs)))\n\n        cmd_list = ['remove', '--json', '--yes']\n\n        if not pkgs and not all_:\n            raise TypeError(\"Must specify at least one package to remove, or \"\n                            \"all=True.\")\n\n        if name:\n            cmd_list.extend(['--name', name])\n        elif prefix:\n            cmd_list.extend(['--prefix', prefix])\n        else:\n            raise TypeError('must specify either an environment name or a '\n                            'path for package removal')\n\n        if all_:\n            cmd_list.extend(['--all'])\n        else:\n            cmd_list.extend(pkgs)\n\n        return self._call_and_parse(cmd_list)", "response": "Remove a package from an environment by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef remove_environment(self, name=None, path=None, **kwargs):\n        return self.remove(name=name, path=path, all=True, **kwargs)", "response": "Remove an environment entirely."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone_environment(self, clone, name=None, prefix=None, **kwargs):\n        cmd_list = ['create', '--json']\n\n        if (name and prefix) or not (name or prefix):\n            raise TypeError(\"conda clone_environment: exactly one of `name` \"\n                            \"or `path` required\")\n\n        if name:\n            cmd_list.extend(['--name', name])\n\n        if prefix:\n            cmd_list.extend(['--prefix', prefix])\n\n        cmd_list.extend(['--clone', clone])\n\n        cmd_list.extend(\n            self._setup_install_commands_from_kwargs(\n                kwargs,\n                ('dry_run', 'unknown', 'use_index_cache', 'use_local',\n                 'no_pin', 'force', 'all', 'channel', 'override_channels',\n                 'no_default_packages')))\n\n        return self._call_and_parse(cmd_list, abspath=kwargs.get('abspath',\n                                                                 True))", "response": "Clone the environment into name or prefix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config_add(self, key, value, **kwargs):\n        cmd_list = ['config', '--add', key, value]\n        cmd_list.extend(self._setup_config_from_kwargs(kwargs))\n\n        return self._call_and_parse(\n            cmd_list,\n            abspath=kwargs.get('abspath', True),\n            callback=lambda o, e: o.get('warnings', []))", "response": "Add a value to a key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of dependencies for packages to be installed in an environment.", "response": "def dependencies(self, name=None, prefix=None, pkgs=None, channels=None,\n                     dep=True):\n        \"\"\"Get dependenciy list for packages to be installed in an env.\"\"\"\n        if not pkgs or not isinstance(pkgs, (list, tuple)):\n            raise TypeError('must specify a list of one or more packages to '\n                            'install into existing environment')\n\n        cmd_list = ['install', '--dry-run', '--json', '--force-pscheck']\n\n        if not dep:\n            cmd_list.extend(['--no-deps'])\n\n        if name:\n            cmd_list.extend(['--name', name])\n        elif prefix:\n            cmd_list.extend(['--prefix', prefix])\n        else:\n            pass\n\n        cmd_list.extend(pkgs)\n\n        # TODO: Check if correct\n        if channels:\n            cmd_list.extend(['--override-channels'])\n\n            for channel in channels:\n                cmd_list.extend(['--channel'])\n                cmd_list.extend([channel])\n\n        return self._call_and_parse(cmd_list)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if an environment exists by name or by prefix.", "response": "def environment_exists(self, name=None, prefix=None, abspath=True,\n                           log=True):\n        \"\"\"Check if an environment exists by 'name' or by 'prefix'.\n\n        If query is by 'name' only the default conda environments directory is\n        searched.\n        \"\"\"\n        if log:\n            logger.debug(str((name, prefix)))\n\n        if name and prefix:\n            raise TypeError(\"Exactly one of 'name' or 'prefix' is required.\")\n\n        if name:\n            prefix = self.get_prefix_envname(name, log=log)\n\n        if prefix is None:\n            prefix = self.ROOT_PREFIX\n\n        return os.path.isdir(os.path.join(prefix, 'conda-meta'))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clear_lock(self, abspath=True):\n        cmd_list = ['clean', '--lock', '--json']\n        return self._call_and_parse(cmd_list, abspath=abspath)", "response": "Clean any conda lock in the system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef package_version(self, prefix=None, name=None, pkg=None, build=False):\n        package_versions = {}\n\n        if name and prefix:\n            raise TypeError(\"Exactly one of 'name' or 'prefix' is required.\")\n\n        if name:\n            prefix = self.get_prefix_envname(name)\n\n        if self.environment_exists(prefix=prefix):\n\n            for package in self.linked(prefix):\n                if pkg in package:\n                    n, v, b = self.split_canonical_name(package)\n                    if build:\n                        package_versions[n] = '{0}={1}'.format(v, b)\n                    else:\n                        package_versions[n] = v\n\n        return package_versions.get(pkg)", "response": "Get installed package version in a given env."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_platform():\n        _sys_map = {'linux2': 'linux', 'linux': 'linux',\n                    'darwin': 'osx', 'win32': 'win', 'openbsd5': 'openbsd'}\n\n        non_x86_linux_machines = {'armv6l', 'armv7l', 'ppc64le'}\n        sys_platform = _sys_map.get(sys.platform, 'unknown')\n        bits = 8 * tuple.__itemsize__\n\n        if (sys_platform == 'linux' and\n                platform.machine() in non_x86_linux_machines):\n            arch_name = platform.machine()\n            subdir = 'linux-{0}'.format(arch_name)\n        else:\n            arch_name = {64: 'x86_64', 32: 'x86'}[bits]\n            subdir = '{0}-{1}'.format(sys_platform, bits)\n\n        return subdir", "response": "Get platform of current system."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_rc(self, path=None, system=False):\n        if os.path.isfile(self.user_rc_path) and not system:\n            path = self.user_rc_path\n        elif os.path.isfile(self.sys_rc_path):\n            path = self.sys_rc_path\n\n        if not path or not os.path.isfile(path):\n            return {}\n\n        with open(path) as f:\n            return yaml.load(f) or {}", "response": "Load the conda configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_condarc_channels(self,\n                             normalize=False,\n                             conda_url='https://conda.anaconda.org',\n                             channels=None):\n        \"\"\"Return all the channel urls defined in .condarc.\n\n        If no condarc file is found, use the default channels.\n        the `default_channel_alias` key is ignored and only the anaconda client\n        `url` key is used.\n        \"\"\"\n        # https://docs.continuum.io/anaconda-repository/configuration\n        # They can only exist on a system condarc\n        default_channels = self.load_rc(system=True).get('default_channels',\n                                                         self.DEFAULT_CHANNELS)\n\n        normalized_channels = []\n        if channels is None:\n            condarc = self.load_rc()\n            channels = condarc.get('channels')\n\n            if channels is None:\n                channels = ['defaults']\n\n        if normalize:\n            template = '{0}/{1}' if conda_url[-1] != '/' else '{0}{1}'\n            for channel in channels:\n                if channel == 'defaults':\n                    normalized_channels += default_channels\n                elif channel.startswith('http'):\n                    normalized_channels.append(channel)\n                else:\n                    # Append to the conda_url that comes from anaconda client\n                    # default_channel_alias key is deliberately ignored\n                    normalized_channels.append(template.format(conda_url,\n                                                               channel))\n            channels = normalized_channels\n\n        return channels", "response": "Return all the channel urls defined in. condarc."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling pip in QProcess worker.", "response": "def _call_pip(self, name=None, prefix=None, extra_args=None,\n                  callback=None):\n        \"\"\"Call pip in QProcess worker.\"\"\"\n        cmd_list = self._pip_cmd(name=name, prefix=prefix)\n        cmd_list.extend(extra_args)\n\n        process_worker = ProcessWorker(cmd_list, pip=True, callback=callback)\n        process_worker.sig_finished.connect(self._start)\n        self._queue.append(process_worker)\n        self._start()\n\n        return process_worker"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _pip_cmd(self, name=None, prefix=None):\n        if (name and prefix) or not (name or prefix):\n            raise TypeError(\"conda pip: exactly one of 'name' \"\"or 'prefix' \"\n                            \"required.\")\n\n        if name and self.environment_exists(name=name):\n            prefix = self.get_prefix_envname(name)\n\n        if sys.platform == 'win32':\n            python = join(prefix, 'python.exe')  # FIXME:\n            pip = join(prefix, 'pip.exe')        # FIXME:\n        else:\n            python = join(prefix, 'bin/python')\n            pip = join(prefix, 'bin/pip')\n\n        cmd_list = [python, pip]\n\n        return cmd_list", "response": "Get pip command list based on environment name or prefix."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pip_list(self, name=None, prefix=None, abspath=True):\n        if (name and prefix) or not (name or prefix):\n            raise TypeError(\"conda pip: exactly one of 'name' \"\"or 'prefix' \"\n                            \"required.\")\n\n        if name:\n            prefix = self.get_prefix_envname(name)\n\n        pip_command = os.sep.join([prefix, 'bin', 'python'])\n        cmd_list = [pip_command, PIP_LIST_SCRIPT]\n        process_worker = ProcessWorker(cmd_list, pip=True, parse=True,\n                                       callback=self._pip_list,\n                                       extra_kwargs={'prefix': prefix})\n        process_worker.sig_finished.connect(self._start)\n        self._queue.append(process_worker)\n        self._start()\n\n        return process_worker", "response": "Get list of pip installed packages."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a pip package in given environment by name or prefix.", "response": "def pip_remove(self, name=None, prefix=None, pkgs=None):\n        \"\"\"Remove a pip package in given environment by `name` or `prefix`.\"\"\"\n        logger.debug(str((prefix, pkgs)))\n\n        if isinstance(pkgs, (list, tuple)):\n            pkg = ' '.join(pkgs)\n        else:\n            pkg = pkgs\n\n        extra_args = ['uninstall', '--yes', pkg]\n\n        return self._call_pip(name=name, prefix=prefix, extra_args=extra_args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pip_search(self, search_string=None):\n        extra_args = ['search', search_string]\n        return self._call_pip(name='root', extra_args=extra_args,\n                              callback=self._pip_search)", "response": "Search for pip packages in PyPI matching search_string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _timer_update(self):\n        self._timer_counter += 1\n        dot = self._timer_dots.pop(0)\n        self._timer_dots = self._timer_dots + [dot]\n        self._rows = [[_(u'Resolving dependencies') + dot, u'', u'', u'']]\n        index = self.createIndex(0, 0)\n        self.dataChanged.emit(index, index)\n\n        if self._timer_counter > 150:\n            self._timer.stop()\n            self._timer_counter = 0", "response": "Update the timer to update the text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef flags(self, index):\n        if not index.isValid():\n            return Qt.ItemIsEnabled\n        column = index.column()\n        if column in [0, 1, 2, 3]:\n            return Qt.ItemFlags(Qt.ItemIsEnabled)\n        else:\n            return Qt.ItemFlags(Qt.NoItemFlags)", "response": "Override Qt method to return item flags"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart the worker process.", "response": "def start(self):\n        \"\"\"Start the worker process.\"\"\"\n        error, output = None, None\n        try:\n            time.sleep(0.1)\n            output = self.method(*self.args, **self.kwargs)\n        except Exception as err:\n            logger.debug(str((self.method.__module__, self.method.__name__,\n                              err)))\n            error = str(err)\n            error = error.replace('(', '')\n            error = error.replace(')', '')\n#            try:\n#                error = err[0]\n#            except Exception:\n#                try:\n#                    error = err.message\n#                except Exception as err2:\n#                    error = ''\n\n        self.sig_finished.emit(self, output, str(error))\n        self._is_finished = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a worker for this client to be run in a separate thread.", "response": "def _create_worker(self, method, *args, **kwargs):\n        \"\"\"Create a worker for this client to be run in a separate thread.\"\"\"\n        # FIXME: this might be heavy...\n        thread = QThread()\n        worker = ClientWorker(method, args, kwargs)\n        worker.moveToThread(thread)\n        worker.sig_finished.connect(self._start)\n        worker.sig_finished.connect(thread.quit)\n        thread.started.connect(worker.start)\n        self._queue.append(thread)\n        self._threads.append(thread)\n        self._workers.append(worker)\n        self._start()\n        return worker"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading all the available pacakges information.", "response": "def _load_repodata(filepaths, extra_data=None, metadata=None):\n        \"\"\"Load all the available pacakges information.\n\n        For downloaded repodata files (repo.continuum.io), additional\n        data provided (anaconda cloud), and additional metadata and merge into\n        a single set of packages and apps.\n        \"\"\"\n        extra_data = extra_data if extra_data else {}\n        metadata = metadata if metadata else {}\n        repodata = []\n        for filepath in filepaths:\n            compressed = filepath.endswith('.bz2')\n            mode = 'rb' if filepath.endswith('.bz2') else 'r'\n\n            if os.path.isfile(filepath):\n                with open(filepath, mode) as f:\n                    raw_data = f.read()\n\n                if compressed:\n                    data = bz2.decompress(raw_data)\n                else:\n                    data = raw_data\n\n                try:\n                    data = json.loads(to_text_string(data, 'UTF-8'))\n                except Exception as error:\n                    logger.error(str(error))\n                    data = {}\n\n                repodata.append(data)\n\n        all_packages = {}\n        for data in repodata:\n            packages = data.get('packages', {})\n            for canonical_name in packages:\n                data = packages[canonical_name]\n                name, version, b = tuple(canonical_name.rsplit('-', 2))\n\n                if name not in all_packages:\n                    all_packages[name] = {'versions': set(),\n                                          'size': {},\n                                          'type': {},\n                                          'app_entry': {},\n                                          'app_type': {},\n                                          }\n                elif name in metadata:\n                    temp_data = all_packages[name]\n                    temp_data['home'] = metadata[name].get('home', '')\n                    temp_data['license'] = metadata[name].get('license', '')\n                    temp_data['summary'] = metadata[name].get('summary', '')\n                    temp_data['latest_version'] = metadata[name].get('version')\n                    all_packages[name] = temp_data\n\n                all_packages[name]['versions'].add(version)\n                all_packages[name]['size'][version] = data.get('size', '')\n\n                # Only the latest builds will have the correct metadata for\n                # apps, so only store apps that have the app metadata\n                if data.get('type'):\n                    all_packages[name]['type'][version] = data.get('type')\n                    all_packages[name]['app_entry'][version] = data.get(\n                        'app_entry')\n                    all_packages[name]['app_type'][version] = data.get(\n                        'app_type')\n\n        all_apps = {}\n        for name in all_packages:\n            versions = sort_versions(list(all_packages[name]['versions']))\n            all_packages[name]['versions'] = versions[:]\n\n            for version in versions:\n                has_type = all_packages[name].get('type')\n                # Has type in this case implies being an app\n                if has_type:\n                    all_apps[name] = all_packages[name].copy()\n                    # Remove all versions that are not apps!\n                    versions = all_apps[name]['versions'][:]\n                    types = all_apps[name]['type']\n                    app_versions = [v for v in versions if v in types]\n                    all_apps[name]['versions'] = app_versions\n\n        return all_packages, all_apps"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _prepare_model_data(packages, linked, pip=None,\n                            private_packages=None):\n        \"\"\"Prepare model data for the packages table model.\"\"\"\n        pip = pip if pip else []\n        private_packages = private_packages if private_packages else {}\n\n        data = []\n\n        if private_packages is not None:\n            for pkg in private_packages:\n                if pkg in packages:\n                    p_data = packages.get(pkg)\n                    versions = p_data.get('versions', '') if p_data else []\n                    private_versions = private_packages[pkg]['versions']\n                    all_versions = sort_versions(list(set(versions +\n                                                          private_versions)))\n                    packages[pkg]['versions'] = all_versions\n                else:\n                    private_versions = sort_versions(\n                        private_packages[pkg]['versions'])\n                    private_packages[pkg]['versions'] = private_versions\n                    packages[pkg] = private_packages[pkg]\n        else:\n            private_packages = {}\n\n        linked_packages = {}\n        for canonical_name in linked:\n            name, version, b = tuple(canonical_name.rsplit('-', 2))\n            linked_packages[name] = {'version': version}\n\n        pip_packages = {}\n        for canonical_name in pip:\n            name, version, b = tuple(canonical_name.rsplit('-', 2))\n            pip_packages[name] = {'version': version}\n\n        packages_names = sorted(list(set(list(linked_packages.keys()) +\n                                         list(pip_packages.keys()) +\n                                         list(packages.keys()) +\n                                         list(private_packages.keys())\n                                         )\n                                     )\n                                )\n\n        for name in packages_names:\n            p_data = packages.get(name)\n\n            summary = p_data.get('summary', '') if p_data else ''\n            url = p_data.get('home', '') if p_data else ''\n            license_ = p_data.get('license', '') if p_data else ''\n            versions = p_data.get('versions', '') if p_data else []\n            version = p_data.get('latest_version', '') if p_data else ''\n\n            if name in pip_packages:\n                type_ = C.PIP_PACKAGE\n                version = pip_packages[name].get('version', '')\n                status = C.INSTALLED\n            elif name in linked_packages:\n                type_ = C.CONDA_PACKAGE\n                version = linked_packages[name].get('version', '')\n                status = C.INSTALLED\n\n                if version in versions:\n                    vers = versions\n                    upgradable = not version == vers[-1] and len(vers) != 1\n                    downgradable = not version == vers[0] and len(vers) != 1\n\n                    if upgradable and downgradable:\n                        status = C.MIXGRADABLE\n                    elif upgradable:\n                        status = C.UPGRADABLE\n                    elif downgradable:\n                        status = C.DOWNGRADABLE\n            else:\n                type_ = C.CONDA_PACKAGE\n                status = C.NOT_INSTALLED\n\n                if version == '' and len(versions) != 0:\n                    version = versions[-1]\n\n            row = {C.COL_ACTION: C.ACTION_NONE,\n                   C.COL_PACKAGE_TYPE: type_,\n                   C.COL_NAME: name,\n                   C.COL_DESCRIPTION: summary.capitalize(),\n                   C.COL_VERSION: version,\n                   C.COL_STATUS: status,\n                   C.COL_URL: url,\n                   C.COL_LICENSE: license_,\n                   C.COL_INSTALL: False,\n                   C.COL_REMOVE: False,\n                   C.COL_UPGRADE: False,\n                   C.COL_DOWNGRADE: False,\n                   C.COL_ACTION_VERSION: None\n                   }\n\n            data.append(row)\n        return data", "response": "Prepare model data for the packages table model."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef login(self, username, password, application, application_url):\n        logger.debug(str((username, application, application_url)))\n        method = self._anaconda_client_api.authenticate\n        return self._create_worker(method, username, password, application,\n                                   application_url)", "response": "Login to anaconda cloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload all the available pacakges information for downloaded repodata.", "response": "def load_repodata(self, filepaths, extra_data=None, metadata=None):\n        \"\"\"\n        Load all the available pacakges information for downloaded repodata.\n\n        Files include repo.continuum.io, additional data provided (anaconda\n        cloud), and additional metadata and merge into a single set of packages\n        and apps.\n        \"\"\"\n        logger.debug(str((filepaths)))\n        method = self._load_repodata\n        return self._create_worker(method, filepaths, extra_data=extra_data,\n                                   metadata=metadata)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_model_data(self, packages, linked, pip=None,\n                           private_packages=None):\n        \"\"\"Prepare downloaded package info along with pip pacakges info.\"\"\"\n        logger.debug('')\n        return self._prepare_model_data(packages, linked, pip=pip,\n                                        private_packages=private_packages)", "response": "Prepare downloaded package info along with pip pacakges info."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets current api domain.", "response": "def set_domain(self, domain='https://api.anaconda.org'):\n        \"\"\"Reset current api domain.\"\"\"\n        logger.debug(str((domain)))\n        config = binstar_client.utils.get_config()\n        config['url'] = domain\n        binstar_client.utils.set_config(config)\n\n        self._anaconda_client_api = binstar_client.utils.get_server_api(\n            token=None, log_level=logging.NOTSET)\n\n        return self.user()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all the available packages for a given user.", "response": "def packages(self, login=None, platform=None, package_type=None,\n                 type_=None, access=None):\n        \"\"\"Return all the available packages for a given user.\n\n        Parameters\n        ----------\n        type_: Optional[str]\n            Only find packages that have this conda `type`, (i.e. 'app').\n        access : Optional[str]\n            Only find packages that have this access level (e.g. 'private',\n            'authenticated', 'public').\n        \"\"\"\n        logger.debug('')\n        method = self._anaconda_client_api.user_packages\n        return self._create_worker(method, login=login, platform=platform,\n                                   package_type=package_type,\n                                   type_=type_, access=access)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _multi_packages(self, logins=None, platform=None, package_type=None,\n                        type_=None, access=None, new_client=True):\n        \"\"\"Return the private packages for a given set of usernames/logins.\"\"\"\n        private_packages = {}\n\n        if not new_client:\n            time.sleep(0.3)\n            return private_packages\n\n        for login in logins:\n            data = self._anaconda_client_api.user_packages(\n                login=login,\n                platform=platform,\n                package_type=package_type,\n                type_=type_,\n                access=access)\n            for item in data:\n                name = item.get('name', '')\n                public = item.get('public', True)\n                package_types = item.get('package_types', [])\n                latest_version = item.get('latest_version', '')\n                if name and not public and 'conda' in package_types:\n                    if name in private_packages:\n                        versions = private_packages.get('versions', []),\n                        new_versions = item.get('versions', []),\n                        vers = sort_versions(list(set(versions +\n                                                      new_versions)))\n                        private_packages[name]['versions'] = vers\n                        private_packages[name]['latest_version'] = vers[-1]\n                    else:\n                        private_packages[name] = {\n                            'versions': item.get('versions', []),\n                            'app_entry': {},\n                            'type': {},\n                            'size': {},\n                            'latest_version': latest_version, }\n\n        return private_packages", "response": "Return the private packages for a given set of usernames / logins."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef multi_packages(self, logins=None, platform=None, package_type=None,\n                       type_=None, access=None):\n        \"\"\"Return the private packages for a given set of usernames/logins.\"\"\"\n        logger.debug('')\n        method = self._multi_packages\n        new_client = True\n\n        try:\n            # Only the newer versions have extra keywords like `access`\n            self._anaconda_client_api.user_packages(access='private')\n        except Exception:\n            new_client = False\n\n        return self._create_worker(method, logins=logins,\n                                   platform=platform,\n                                   package_type=package_type,\n                                   type_=type_, access=access,\n                                   new_client=new_client)", "response": "Return the private packages for a given set of usernames / logins."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating and returns a mapper function that returns a 3 - letter ISO_3166 - 1 code for the specified country attribute.", "response": "def country(from_key='name', to_key='iso'):\n    \"\"\"Creates and returns a mapper function to access country data.\n\n    The mapper function that is returned must be called with one argument. In\n    the default case you call it with a name and it returns a 3-letter\n    ISO_3166-1 code, e. g. called with ``Spain`` it would return ``ESP``.\n\n    :param from_key: (optional) the country attribute you give as input.\n        Defaults to ``name``.\n    :param to_key: (optional) the country attribute you want as output.\n        Defaults to ``iso``.\n    :return: mapper\n    :rtype: function\n    \"\"\"\n\n    gc = GeonamesCache()\n    dataset = gc.get_dataset_by_key(gc.get_countries(), from_key)\n\n    def mapper(input):\n        # For country name inputs take the names mapping into account.\n        if 'name' == from_key:\n            input = mappings.country_names.get(input, input)\n        # If there is a record return the demanded attribute.\n        item = dataset.get(input)\n        if item:\n            return item[to_key]\n\n    return mapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cities(self):\n\n        if self.cities is None:\n            self.cities = self._load_data(self.cities, 'cities.json')\n        return self.cities", "response": "Get a dictionary of cities keyed by geonameid."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cities_by_name(self, name):\n\n        if name not in self.cities_by_names:\n            if self.cities_items is None:\n                self.cities_items = list(self.get_cities().items())\n            self.cities_by_names[name] = [dict({gid: city})\n                for gid, city in self.cities_items if city['name'] == name]\n        return self.cities_by_names[name]", "response": "Get a list of city dictionaries with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_repo_urls_from_channels(self, channels):\n        repos = []\n        sys_platform = self._conda_api.get_platform()\n\n        for channel in channels:\n            url = '{0}/{1}/repodata.json.bz2'.format(channel, sys_platform)\n            repos.append(url)\n\n        return repos", "response": "Convert a channel into a normalized url form including."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_repos(self, repos):\n        self._checking_repos = []\n        self._valid_repos = []\n\n        for repo in repos:\n            worker = self.download_is_valid_url(repo)\n            worker.sig_finished.connect(self._repos_checked)\n            worker.repo = repo\n            self._checking_repos.append(repo)", "response": "Check if repodata urls are valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts a repo url to a file path for local storage.", "response": "def _repo_url_to_path(self, repo):\n        \"\"\"Convert a `repo` url to a file path for local storage.\"\"\"\n        repo = repo.replace('http://', '')\n        repo = repo.replace('https://', '')\n        repo = repo.replace('/', '_')\n\n        return os.sep.join([self._data_directory, repo])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndownloading repodata from conda - meta and save it to the internal list.", "response": "def _download_repodata(self, checked_repos):\n        \"\"\"Dowload repodata.\"\"\"\n        self._files_downloaded = []\n        self._repodata_files = []\n        self.__counter = -1\n\n        if checked_repos:\n            for repo in checked_repos:\n                path = self._repo_url_to_path(repo)\n                self._files_downloaded.append(path)\n                self._repodata_files.append(path)\n                worker = self.download_async(repo, path)\n                worker.url = repo\n                worker.path = path\n                worker.sig_finished.connect(self._repodata_downloaded)\n        else:\n            # Empty, maybe there is no internet connection\n            # Load information from conda-meta and save that file\n            path = self._get_repodata_from_meta()\n            self._repodata_files = [path]\n            self._repodata_downloaded()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_repodata_from_meta(self):\n        path = os.sep.join([self.ROOT_PREFIX, 'conda-meta'])\n        packages = os.listdir(path)\n        meta_repodata = {}\n        for pkg in packages:\n            if pkg.endswith('.json'):\n                filepath = os.sep.join([path, pkg])\n                with open(filepath, 'r') as f:\n                    data = json.load(f)\n\n                if 'files' in data:\n                    data.pop('files')\n                if 'icondata' in data:\n                    data.pop('icondata')\n\n                name = pkg.replace('.json', '')\n                meta_repodata[name] = data\n\n        meta_repodata_path = os.sep.join([self._data_directory,\n                                          'offline.json'])\n        repodata = {'info': [],\n                    'packages': meta_repodata}\n\n        with open(meta_repodata_path, 'w') as f:\n            json.dump(repodata, f, sort_keys=True,\n                      indent=4, separators=(',', ': '))\n\n        return meta_repodata_path", "response": "Generate repodata from local meta files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef repodata_files(self, channels=None):\n        if channels is None:\n            channels = self.conda_get_condarc_channels()\n\n        repodata_urls = self._set_repo_urls_from_channels(channels)\n\n        repopaths = []\n\n        for repourl in repodata_urls:\n            fullpath = os.sep.join([self._repo_url_to_path(repourl)])\n            repopaths.append(fullpath)\n\n        return repopaths", "response": "Return the list of repodata files based on channels and the data_directory."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_repodata(self, channels=None):\n        norm_channels = self.conda_get_condarc_channels(channels=channels,\n                                                        normalize=True)\n        repodata_urls = self._set_repo_urls_from_channels(norm_channels)\n        self._check_repos(repodata_urls)", "response": "Update repodata from channels or use condarc channels if None."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_metadata(self):\n        if self._data_directory is None:\n            raise Exception('Need to call `api.set_data_directory` first.')\n\n        metadata_url = 'https://repo.continuum.io/pkgs/metadata.json'\n        filepath = os.sep.join([self._data_directory, 'metadata.json'])\n        worker = self.download_requests(metadata_url, filepath)\n        return worker", "response": "Update the metadata available for packages in repo. continuum. io. Returns a download worker."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_valid_channel(self,\n                            channel,\n                            conda_url='https://conda.anaconda.org'):\n        \"\"\"Check if channel is valid.\"\"\"\n        if channel.startswith('https://') or channel.startswith('http://'):\n            url = channel\n        else:\n            url = \"{0}/{1}\".format(conda_url, channel)\n\n        if url[-1] == '/':\n            url = url[:-1]\n        plat = self.conda_platform()\n        repodata_url = \"{0}/{1}/{2}\".format(url, plat, 'repodata.json')\n        worker = self.download_is_valid_url(repodata_url)\n        worker.url = url\n        return worker", "response": "Check if channel is valid."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _aws_get_instance_by_tag(region, name, tag, raw):\n    client = boto3.session.Session().client('ec2', region)\n    matching_reservations = client.describe_instances(Filters=[{'Name': tag, 'Values': [name]}]).get('Reservations', [])\n    instances = []\n    [[instances.append(_aws_instance_from_dict(region, instance, raw))  # pylint: disable=expression-not-assigned\n      for instance in reservation.get('Instances')] for reservation in matching_reservations if reservation]\n    return instances", "response": "Get all instances matching a tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn instances mathing an id.", "response": "def aws_get_instances_by_id(region, instance_id, raw=True):\n    \"\"\"Returns instances mathing an id.\"\"\"\n    client = boto3.session.Session().client('ec2', region)\n    try:\n        matching_reservations = client.describe_instances(InstanceIds=[instance_id]).get('Reservations', [])\n    except ClientError as exc:\n        if exc.response.get('Error', {}).get('Code') != 'InvalidInstanceID.NotFound':\n            raise\n        return []\n    instances = []\n    [[instances.append(_aws_instance_from_dict(region, instance, raw))  # pylint: disable=expression-not-assigned\n      for instance in reservation.get('Instances')] for reservation in matching_reservations if reservation]\n    return instances"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_instances_by_name(name, sort_by_order=('cloud', 'name'), projects=None, raw=True, regions=None, gcp_credentials=None, clouds=SUPPORTED_CLOUDS):\n    matching_instances = all_clouds_get_instances_by_name(\n        name, projects, raw, credentials=gcp_credentials, clouds=clouds)\n    if regions:\n        matching_instances = [instance for instance in matching_instances if instance.region in regions]\n    matching_instances.sort(key=lambda instance: [getattr(instance, field) for field in sort_by_order])\n    return matching_instances", "response": "Get intsances from GCP and AWS by name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting OS Version for instances.", "response": "def get_os_version(instance):\n    \"\"\"Get OS Version for instances.\"\"\"\n    if instance.cloud == 'aws':\n        client = boto3.client('ec2', instance.region)\n        image_id = client.describe_instances(InstanceIds=[instance.id])['Reservations'][0]['Instances'][0]['ImageId']\n        return '16.04' if '16.04' in client.describe_images(ImageIds=[image_id])['Images'][0]['Name'] else '14.04'\n    if instance.cloud == 'gcp':\n        credentials = GoogleCredentials.get_application_default()\n        compute = discovery.build('compute', 'v1', credentials=credentials)\n        for disk in compute.instances().get(instance=instance.name,\n                                            zone=instance.zone,\n                                            project=instance.project).execute()['disks']:\n            if not disk.get('boot'):\n                continue\n            for value in disk.get('licenses', []):\n                if '1604' in value:\n                    return '16.04'\n                if '1404' in value:\n                    return '14.04'\n        return '14.04'\n    return '14.04'"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn all the volumes of an instance.", "response": "def get_volumes(instance):\n    \"\"\"Returns all the volumes of an instance.\"\"\"\n    if instance.cloud == 'aws':\n        client = boto3.client('ec2', instance.region)\n        devices = client.describe_instance_attribute(\n            InstanceId=instance.id, Attribute='blockDeviceMapping').get('BlockDeviceMappings', [])\n        volumes = client.describe_volumes(VolumeIds=[device['Ebs']['VolumeId']\n                                                     for device in devices if device.get('Ebs', {}).get('VolumeId')]).get('Volumes', [])\n        return {volume['Attachments'][0]['Device']: {'size': volume['Size'], 'volume_type': volume['VolumeType']} for volume in volumes}\n    if instance.cloud == 'gcp':\n        credentials = GoogleCredentials.get_application_default()\n        compute = discovery.build('compute', 'v1', credentials=credentials)\n        volumes = {}\n        for disk in compute.instances().get(instance=instance.id,\n                                            zone=instance.zone,\n                                            project=instance.project).execute()['disks']:\n            index = disk['index']\n            name = disk['deviceName'] if disk['deviceName'] not in [u'persistent-disk-0', 'boot'] else instance.id\n            if 'local-ssd' in disk['deviceName']:\n                size = 375.0\n            if 'local-ssd' in disk['deviceName']:\n                size = 375.0\n                disk_type = 'local-ssd'\n            else:\n                disk_data = compute.disks().get(disk=name,\n                                                zone=instance.zone,\n                                                project=instance.project).execute()\n                size = float(disk_data['sizeGb'])\n                disk_type = 'pd-ssd'\n            volumes[index] = {'size': size,\n                              'type': disk['type'],\n                              'deviceName': disk['deviceName'],\n                              'interface': disk['interface'],\n                              'diskType': disk_type}\n        return volumes\n    raise ValueError('Unknown cloud %s' % instance.cloud)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_persistent_address(instance):\n    if instance.cloud == 'aws':\n        client = boto3.client('ec2', instance.region)\n        try:\n            client.describe_addresses(PublicIps=[instance.ip_address])\n            return instance.ip_address\n        except botocore.client.ClientError as exc:\n            if exc.response.get('Error', {}).get('Code') != 'InvalidAddress.NotFound':\n                raise\n            # Address is not public\n            return None\n    if instance.cloud == 'gcp':\n        credentials = GoogleCredentials.get_application_default()\n        compute = discovery.build('compute', 'v1', credentials=credentials)\n        try:\n            return compute.addresses().get(address=instance.name, project=instance.project, region=instance.region).execute()['address']\n        except errors.HttpError as exc:\n            if 'was not found' in str(exc):\n                return None\n            raise\n    raise ValueError('Unknown cloud %s' % instance.cloud)", "response": "Returns the public ip address of an instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef main():\n    pip_packages = {}\n    for package in pip.get_installed_distributions():\n        name = package.project_name\n        version = package.version\n        full_name = \"{0}-{1}-pip\".format(name.lower(), version)\n        pip_packages[full_name] = {'version': version}\n    data = json.dumps(pip_packages)\n    print(data)", "response": "Use pip to find pip installed packages in a given prefix."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsaving data to file.", "response": "def _save(file, data, mode='w+'):\n    \"\"\"\n    Write all data to created file. Also overwrite previous file.\n    \"\"\"\n    with open(file, mode) as fh:\n        fh.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge contents of all static and template files.", "response": "def merge(obj):\n    \"\"\"\n    Merge contents.\n\n    It does a simply merge of all files defined under 'static' key.\n\n    If you have JS or CSS file with embeded django tags like {% url ... %} or\n    {% static ... %} you should declare them under 'template' key. This\n    function will render them and append to the merged output.\n\n    To use the render option you have to define both 'config' and 'path' on\n    merger dictionary.\n    \"\"\"\n\n    merge = ''\n\n    for f in obj.get('static', []):\n        print 'Merging: {}'. format(f)\n        merge += _read(f)\n\n    def doless(f):\n        print 'Compiling LESS: {}'.format(f)\n        ret, tmp = commands.getstatusoutput('lesscpy '+f)\n        if ret == 0:\n            return tmp\n        else:\n            print 'LESS to CSS failed for: {} (Do you have lesscpy installed?)'.format(f)\n        return ''\n\n    if merger.get('config'): #only imports django if we have a config file defined\n        import re\n\n        for p in merger['path']: sys.path.append(p)\n        os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", merger['config'])\n\n        try:\n            from django.template.loader import get_template_from_string\n            from django.template.base import Context\n            from django.utils.encoding import smart_str\n            from django.conf import settings\n        except:\n            print 'Do you really have django well installed?'\n            sys.exit(1)\n\n        for f in obj.get('template', []):\n            print 'Merging django template: {}'. format(f)\n            t = _read(f)\n\n            if settings.FORCE_SCRIPT_NAME:\n                t = re.sub(r'\\{%\\s+url\\b', settings.FORCE_SCRIPT_NAME+'{% url ', t)\n\n            tmp = smart_str(get_template_from_string(t).render(Context({})))\n\n            if f.endswith('.less'):\n                pass\n                #TODO compilar tmp para css\n\n            merge += tmp\n\n    for f in obj.get('less', []):\n        merge += doless(f)\n\n    return merge"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef jsMin(data, file):\n    print 'Minifying JS... ',\n    url = 'http://javascript-minifier.com/raw' #POST\n    req = urllib2.Request(url, urllib.urlencode({'input': data}))\n    try:\n        f = urllib2.urlopen(req)\n        response = f.read()\n        f.close()\n        print 'Final: {:.1f}%'.format(100.0*len(response)/len(data))\n        print 'Saving: {} ({:.2f}kB)'.format(file, len(response)/1024.0)\n        _save(file, response)\n    except:\n        print 'Oops!! Failed :('\n        return 1\n    return 0", "response": "Minify JS data and saves to file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntries to optimise a JPG file. The original will be saved at the same place with '.original' appended to its name. Once a .original exists the function will ignore this file unless force is True.", "response": "def jpgMin(file, force=False):\n    \"\"\"\n    Try to optimise a JPG file.\n\n    The original will be saved at the same place with '.original' appended to its name.\n\n    Once a .original exists the function will ignore this file unless force is True.\n    \"\"\"\n    if not os.path.isfile(file+'.original') or force:\n        data = _read(file, 'rb')\n        _save(file+'.original', data, 'w+b')\n        print 'Optmising JPG {} - {:.2f}kB'.format(file, len(data)/1024.0),\n        url = 'http://jpgoptimiser.com/optimise'\n        parts, headers = encode_multipart({}, {'input': {'filename': 'wherever.jpg', 'content': data}})\n        req = urllib2.Request(url, data=parts, headers=headers)\n        try:\n            f = urllib2.urlopen(req)\n            response = f.read()\n            f.close()\n            print ' - {:.2f} - {:.1f}%'.format(len(response)/1024.0, 100.0*len(response)/len(data))\n            _save(file, response, 'w+b')\n        except:\n            print 'Oops!! Failed :('\n            return 1\n    else:\n        print 'Ignoring file: {}'.format(file)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef process(obj):\n    #merge all static and templates and less files\n    merged = merge(obj)\n\n    #save the full file if name defined\n    if obj.get('full'):\n        print 'Saving: {} ({:.2f}kB)'.format(obj['full'], len(merged)/1024.0)\n        _save(obj['full'], merged)\n    else:\n        print 'Full merged size: {:.2f}kB'.format(len(merged)/1024.0)\n\n    #minify js and save to file\n    if obj.get('jsmin'):\n        jsMin(merged, obj['jsmin'])\n\n    #minify css and save to file\n    if obj.get('cssmin'):\n        cssMin(merged, obj['cssmin'])", "response": "Process each block of the merger object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef optimize(exp_rets, covs):\n    _cov_inv = np.linalg.inv(covs)        \n\n    # unit vector\n    _u = np.ones((len(exp_rets)))\n\n    # compute some dot products one time only\n    _u_cov_inv = _u.dot(_cov_inv)\n    _rets_cov_inv = exp_rets.dot(_cov_inv)\n\n    # helper matrix for deriving Lagrange multipliers\n    _m = np.empty((2, 2))\n    _m[0, 0] = _rets_cov_inv.dot(exp_rets)\n    _m[0, 1] = _u_cov_inv.dot(exp_rets)\n    _m[1, 0] = _rets_cov_inv.dot(_u)\n    _m[1, 1] = _u_cov_inv.dot(_u)\n\n    # compute values to return\n    _m_inv = np.linalg.inv(_m)\n    a = _m_inv[0, 0] * _rets_cov_inv + _m_inv[1, 0] * _u_cov_inv\n    b = _m_inv[0, 1] * _rets_cov_inv + _m_inv[1, 1] * _u_cov_inv\n    least_risk_ret = _m[0, 1] / _m[1, 1]\n    return a, b, least_risk_ret", "response": "This function calculates the return parameters for a single portfolio."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an Annual growth given growth from start date to end date.", "response": "def growthfromrange(rangegrowth, startdate, enddate):\n    \"\"\"\n    Annual growth given growth from start date to end date.\n    \"\"\"\n    _yrs = (pd.Timestamp(enddate) - pd.Timestamp(startdate)).total_seconds() /\\\n            dt.timedelta(365.25).total_seconds()\n    return yrlygrowth(rangegrowth, _yrs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a DataFrame of current US equities.", "response": "def equities(country='US'):\n    \"\"\"\n    Return a DataFrame of current US equities.\n\n    .. versionadded:: 0.4.0\n\n    .. versionchanged:: 0.5.0\n       Return a DataFrame\n\n    Parameters\n    ----------\n    country : str, optional\n        Country code for equities to return, defaults to 'US'.\n\n    Returns\n    -------\n    eqs : :class:`pandas.DataFrame`\n        DataFrame whose index is a list of all current ticker symbols.\n        Columns are 'Security Name' (e.g. 'Zynerba Pharmaceuticals, Inc. - Common Stock')\n        and 'Exchange' ('NASDAQ', 'NYSE', 'NYSE MKT', etc.)\n\n    Examples\n    --------\n    >>> eqs = pn.data.equities('US')\n\n    Notes\n    -----\n    Currently only US markets are supported.\n    \"\"\"\n    nasdaqblob, otherblob = _getrawdata()\n    eq_triples = []\n    eq_triples.extend(_get_nas_triples(nasdaqblob))\n    eq_triples.extend(_get_other_triples(otherblob))\n    eq_triples.sort()\n    index = [triple[0] for triple in eq_triples]\n    data = [triple[1:] for triple in eq_triples]\n    return pd.DataFrame(data, index, columns=['Security Name', 'Exchange'], dtype=str)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef call(self, lowstrike, highstrike, expiry):\n        assert lowstrike < highstrike\n        _rows = {}\n        _prices = {}\n        _opttype = 'call'\n        for _strike in (lowstrike, highstrike):\n            _rows[_strike] = _relevant_rows(self.data, (_strike, expiry, _opttype,),\n                    \"No key for {} strike {} {}\".format(expiry, _strike, _opttype))\n            _prices[_strike] = _getprice(_rows[_strike])\n        _eq = _rows[lowstrike].loc[:, 'Underlying_Price'].values[0]\n        _qt = _rows[lowstrike].loc[:, 'Quote_Time'].values[0]\n        _debit = _prices[lowstrike] - _prices[highstrike]\n        _breakeven = lowstrike + _debit\n        if _breakeven > highstrike:\n            _breakeven = np.nan\n        _maxprof = highstrike - lowstrike -_debit\n        _index = ['Low Strike Call', 'High Strike Call', 'Debit',  'Break_Even',\n                'Max Profit', 'Underlying_Price', 'Quote_Time']\n        _vals = np.array([_prices[lowstrike], _prices[highstrike], _debit,\n                _breakeven, _maxprof, _eq, _qt])\n        return pd.DataFrame(_vals, index=_index, columns=['Value'])", "response": "Returns a DataFrame that contains the metrics for evaluating a bull call spread."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef straddle(self, strike, expiry):\n        _rows = {}\n        _prices = {}\n        for _opttype in _constants.OPTTYPES:\n            _rows[_opttype] = _relevant_rows(self.data, (strike, expiry, _opttype,),\n                    \"No key for {} strike {} {}\".format(expiry, strike, _opttype))\n            _prices[_opttype] = _getprice(_rows[_opttype])\n        _eq = _rows[_constants.OPTTYPES[0]].loc[:, 'Underlying_Price'].values[0]\n        _qt = _rows[_constants.OPTTYPES[0]].loc[:, 'Quote_Time'].values[0]\n        _index = ['Call', 'Put', 'Credit', 'Underlying_Price', 'Quote_Time']\n        _vals = np.array([_prices['call'], _prices['put'], _prices['call'] + _prices['put'], _eq, _qt])\n        return pd.DataFrame(_vals, index=_index, columns=['Value'])", "response": "Computes the straddle of a specific strike and expiration date."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(equity):\n    _optmeta = pdr.data.Options(equity, 'yahoo')\n    _optdata = _optmeta.get_all_data()\n    return Options(_optdata)", "response": "Retrieve all current options for given equity."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a transformed DataFrame.", "response": "def transform(data_frame, **kwargs):\n    \"\"\"\n    Return a transformed DataFrame.\n\n    Transform data_frame along the given axis. By default, each row will be normalized (axis=0).\n\n    Parameters\n    -----------\n    data_frame : DataFrame\n        Data to be normalized.\n    axis : int, optional\n        0 (default) to normalize each row, 1 to normalize each column.\n    method : str, optional\n        Valid methods are:\n        \n        -  \"vector\" : Default for normalization by row (axis=0).\n           Normalize along axis as a vector with norm `norm`\n        -  \"last\" : Linear normalization setting last value along the axis to `norm`\n        -  \"first\" : Default for normalization of columns (axis=1).\n           Linear normalization setting first value along the given axis to `norm`\n        -  \"mean\" : Normalize so that the mean of each vector along the given axis is `norm`\n    norm : float, optional\n        Target value of normalization, defaults to 1.0.\n    labels : DataFrame, optional\n        Labels may be passed as keyword argument, in which\n        case the label values will also be normalized and returned.\n\n    Returns\n    -----------\n    df : DataFrame\n        Normalized data.\n    labels : DataFrame, optional\n        Normalized labels, if provided as input.\n\n    Notes\n    -----------\n    If labels are real-valued, they should also be normalized.\n\n    ..\n        Having row_norms as a numpy array should be benchmarked against \n        using a DataFrame:\n        http://stackoverflow.com/questions/12525722/normalize-data-in-pandas\n        Note: This isn't a bottleneck. Using a feature set with 13k rows and 256\n        data_frame ('ge' from 1962 until now), the normalization was immediate.\n    \"\"\"\n    norm = kwargs.get('norm', 1.0)\n    axis = kwargs.get('axis', 0)\n    if axis == 0:\n        norm_vector = _get_norms_of_rows(data_frame, kwargs.get('method', 'vector'))\n    else:\n        norm_vector = _get_norms_of_cols(data_frame, kwargs.get('method', 'first'))\n\n    if 'labels' in kwargs:\n        if axis == 0:\n            return data_frame.apply(lambda col: col * norm / norm_vector, axis=0), \\\n                    kwargs['labels'].apply(lambda col: col * norm / norm_vector, axis=0)\n        else:\n            raise ValueError(\"label normalization incompatible with normalization by column\")\n    else:\n        if axis == 0:\n            return data_frame.apply(lambda col: col * norm / norm_vector, axis=0)\n        else:\n            return data_frame.apply(lambda row: row * norm / norm_vector, axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a column vector containing the norm of each row", "response": "def _get_norms_of_rows(data_frame, method):\n    \"\"\" return a column vector containing the norm of each row \"\"\"\n    if method == 'vector':\n        norm_vector = np.linalg.norm(data_frame.values, axis=1)\n    elif method == 'last':\n        norm_vector = data_frame.iloc[:, -1].values\n    elif method == 'mean':\n        norm_vector = np.mean(data_frame.values, axis=1)\n    elif method == 'first':\n        norm_vector = data_frame.iloc[:, 0].values\n    else:\n        raise ValueError(\"no normalization method '{0}'\".format(method))\n    return norm_vector"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nplotting the candlestick plot for the given axes.", "response": "def _candlestick_ax(df, ax):\n    \"\"\"\n    # Alternatively: (but hard to get dates set up properly)\n    plt.xticks(range(len(df.index)), df.index, rotation=45)\n    fplt.candlestick2_ohlc(ax, df.loc[:, 'Open'].values, df.loc[:, 'High'].values, \n            df.loc[:, 'Low'].values, df.loc[:, 'Close'].values, width=0.2)\n    \"\"\"\n    quotes = df.reset_index()\n    quotes.loc[:, 'Date'] = mdates.date2num(quotes.loc[:, 'Date'].astype(dt.date))\n    fplt.candlestick_ohlc(ax, quotes.values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, opttype, strike, expiry):\n        _optrow = _relevant_rows(self.data, (strike, expiry, opttype,),\n                \"No key for {} strike {} {}\".format(expiry, strike, opttype))\n        return _getprice(_optrow)", "response": "Get the price of a specific opttype and strike."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef metrics(self, opttype, strike, expiry):\n        _optrow = _relevant_rows(self.data, (strike, expiry, opttype,),\n                \"No key for {} strike {} {}\".format(expiry, strike, opttype))\n        _index = ['Opt_Price', 'Time_Val', 'Last', 'Bid', 'Ask', 'Vol', 'Open_Int', 'Underlying_Price', 'Quote_Time']\n        _out = pd.DataFrame(index=_index, columns=['Value'])\n        _out.loc['Opt_Price', 'Value'] = _opt_price = _getprice(_optrow)\n        for _name in _index[2:]:\n            _out.loc[_name, 'Value'] = _optrow.loc[:, _name].values[0]\n        _eq_price = _out.loc['Underlying_Price', 'Value']\n        if opttype == 'put':\n            _out.loc['Time_Val'] = _get_put_time_val(_opt_price, strike, _eq_price)\n        else:\n            _out.loc['Time_Val'] = _get_call_time_val(_opt_price, strike, _eq_price)\n        return _out", "response": "Basic metrics for a specific option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nretrieving option prices for all strikes of a given type with a given expiration date.", "response": "def strikes(self, opttype, expiry):\n        \"\"\"\n        Retrieve option prices for all strikes of a given type with a given expiration.\n\n        Parameters\n        ----------\n        opttype : str ('call' or 'put')\n        expiry : date-like\n            Expiration date. Can be a :class:`datetime.datetime` or\n            a string that :mod:`pandas` can interpret as such, e.g.\n            '2015-01-01'.\n\n        Returns\n        ----------\n        df : :class:`pandas.DataFrame`\n        eq : float\n            Price of underlying.\n        qt : datetime.datetime\n            Time of quote.\n\n        See Also\n        --------\n        :meth:`exps`\n        \"\"\"\n        _relevant = _relevant_rows(self.data, (slice(None), expiry, opttype,),\n                \"No key for {} {}\".format(expiry, opttype))\n        _index = _relevant.index.get_level_values('Strike')\n        _columns = ['Price', 'Time_Val', 'Last', 'Bid', 'Ask', 'Vol', 'Open_Int']\n        _df = pd.DataFrame(index=_index, columns=_columns)\n        _underlying = _relevant.loc[:, 'Underlying_Price'].values[0]\n        _quotetime = pd.to_datetime(_relevant.loc[:, 'Quote_Time'].values[0], utc=True).to_datetime()\n        for _col in _columns[2:]:\n            _df.loc[:, _col] = _relevant.loc[:, _col].values\n        _df.loc[:, 'Price'] = (_df.loc[:, 'Bid'] + _df.loc[:, 'Ask']) / 2.\n        _set_tv_strike_ix(_df, opttype, 'Price', 'Time_Val', _underlying)\n        return _df, _underlying, _quotetime"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exps(self, opttype, strike):\n        _relevant = _relevant_rows(self.data, (strike, slice(None), opttype,),\n                \"No key for {} {}\".format(strike, opttype))\n        _index = _relevant.index.get_level_values('Expiry')\n        _columns = ['Price', 'Time_Val', 'Last', 'Bid', 'Ask', 'Vol', 'Open_Int']\n        _df = pd.DataFrame(index=_index, columns=_columns)\n        _eq = _relevant.loc[:, 'Underlying_Price'].values[0]\n        _qt = pd.to_datetime(_relevant.loc[:, 'Quote_Time'].values[0], utc=True).to_datetime()\n        for _col in _columns[2:]:\n            _df.loc[:, _col] = _relevant.loc[:, _col].values\n        _df.loc[:, 'Price'] = (_df.loc[:, 'Bid'] + _df.loc[:, 'Ask']) / 2.\n        _set_tv_other_ix(_df, opttype, 'Price', 'Time_Val', _eq, strike)\n        return _df, _eq, _qt", "response": "Returns a pandas. DataFrame containing the relevant items for the given strike on all available dates."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef labeledfeatures(eqdata, featurefunc, labelfunc):\n    _size = len(eqdata.index)\n    _labels, _skipatend = labelfunc(eqdata)\n    _features, _skipatstart = featurefunc(eqdata.iloc[:(_size - _skipatend), :])\n    return _features, _labels.iloc[_skipatstart:, :]", "response": "Returns the features and labels for the given equity data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving growth labels for a given period.", "response": "def growth(interval, pricecol, eqdata):\n    \"\"\"\n    Retrieve growth labels.\n\n    Parameters\n    --------------\n    interval : int\n        Number of sessions over which growth is measured. For example, if\n        the value of 32 is passed for `interval`, the data returned will \n        show the growth 32 sessions ahead for each data point.\n    eqdata : DataFrame\n        Data for evaluating growth.\n    pricecol : str\n        Column of `eqdata` to be used for prices (Normally 'Adj Close').\n\n    Returns\n    --------\n    labels : DataFrame\n        Growth labels for the specified period\n    skipatend : int\n        Number of rows skipped at the end of `eqdata` for the given labels.\n        Used to synchronize labels and features.\n\n    Examples\n    ---------------\n    >>> from functools import partial\n    >>> features, labels = pn.data.labeledfeatures(eqdata, 256, \n    ...        partial(pn.data.lab.growth, 32, 'Adj Close'))\n    \"\"\"\n    size = len(eqdata.index)\n    labeldata = eqdata.loc[:, pricecol].values[interval:] /\\\n            eqdata.loc[:, pricecol].values[:(size - interval)]\n    df = pd.DataFrame(data=labeldata, index=eqdata.index[:(size - interval)],\n            columns=['Growth'], dtype='float64')\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a DataFrame containing the exponential moving average of the given time series.", "response": "def ema(eqdata, **kwargs):\n    \"\"\"\n    Exponential moving average with the given span.\n\n    Parameters\n    ----------\n    eqdata : DataFrame\n        Must have exactly 1 column on which to calculate EMA\n    span : int, optional\n        Span for exponential moving average. Cf. `pandas.stats.moments.ewma \n        <http://pandas.pydata.org/pandas-docs/stable/generated/pandas.stats.moments.ewma.html>`_ and\n        `additional Pandas documentation \n        <http://pandas.pydata.org/pandas-docs/stable/computation.html#exponentially-weighted-moment-functions>`_.\n    outputcol : str, optional\n        Column to use for output. Defaults to 'EMA'.\n    selection : str, optional\n        Column of eqdata on which to calculate ema. If\n        `eqdata` has only 1 column, `selection` is ignored,\n        and ema is calculated on that column. Defaults\n        to 'Adj Close'.\n\n    Returns\n    ---------\n    emadf : DataFrame\n        Exponential moving average using the given `span`.\n    \"\"\"\n    if len(eqdata.shape) > 1 and eqdata.shape[1] != 1:\n        _selection = kwargs.get('selection', 'Adj Close')\n        _eqdata = eqdata.loc[:, _selection]\n    else:\n        _eqdata = eqdata\n    _span = kwargs.get('span', 20)\n    _col = kwargs.get('outputcol', 'EMA')\n    _emadf = pd.DataFrame(index=_eqdata.index, columns=[_col], dtype=np.float64)\n    _emadf.loc[:, _col] = _eqdata.ewm(span=_span, min_periods=0, adjust=True, ignore_na=False).mean().values.flatten()\n    return _emadf"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn DataFrame containing the exponential moving average of the next available entry in the specified column.", "response": "def ema_growth(eqdata, **kwargs):\n    \"\"\"\n    Growth of exponential moving average.\n\n    Parameters\n    ----------\n    eqdata : DataFrame\n    span : int, optional\n        Span for exponential moving average. Defaults to 20.\n    outputcol : str, optional.\n        Column to use for output. Defaults to 'EMA Growth'.\n    selection : str, optional\n        Column of eqdata on which to calculate ema growth. If\n        `eqdata` has only 1 column, `selection` is ignored,\n        and ema growth is calculated on that column. Defaults\n        to 'Adj Close'.\n\n    Returns\n    ---------\n    out : DataFrame\n        Growth of exponential moving average from one day to next\n    \"\"\"\n    _growth_outputcol = kwargs.get('outputcol', 'EMA Growth')\n    _ema_outputcol = 'EMA'\n    kwargs['outputcol'] = _ema_outputcol\n    _emadf = ema(eqdata, **kwargs)\n    return simple.growth(_emadf, selection=_ema_outputcol, outputcol=_growth_outputcol)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a DataFrame containing the volatility over a given window.", "response": "def volatility(eqdata, **kwargs):\n    \"\"\"\n    Volatility (standard deviation) over the given window\n\n    Parameters\n    ----------\n    eqdata : DataFrame\n    window : int, optional\n        Lookback period. Defaults to 20.\n    outputcol : str, optional\n        Name of column to be used in returned dataframe. Defaults to 'Risk'.\n    selection : str, optional\n        Column of eqdata on which to calculate volatility. If\n        `eqdata` has only 1 column, `selection` is ignored,\n        and volatility is calculated on that column. Defaults\n        to 'Adj Close'.\n\n    Returns\n    ---------\n    risk : DataFrame\n        Moving volatility with the given lookback.\n    \"\"\"\n    if len(eqdata.shape) > 1 and eqdata.shape[1] != 1:\n        _selection = kwargs.get('selection', 'Adj Close')\n        _eqdata = eqdata.loc[:, _selection]\n    else:\n        _eqdata = eqdata\n    _window = kwargs.get('window', 20)\n    _colname = kwargs.get('outputcol', 'Risk')\n    _risk = pd.DataFrame(index=_eqdata.index, columns=[_colname], dtype=np.float64)\n    _risk.loc[:, _colname] = _eqdata.rolling(center=False, window=_window).std().values.flatten()\n    return _risk"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the volatility of growth.", "response": "def growth_volatility(eqdata, **kwargs):\n    \"\"\"\n    Return the volatility of growth.\n\n    Note that, like :func:`pynance.tech.simple.growth` but in contrast to \n    :func:`volatility`, :func:`growth_volatility`\n    applies directly to a dataframe like that returned by \n    :func:`pynance.data.retrieve.get`, not necessarily to a single-column dataframe.\n\n    Parameters\n    ----------\n    eqdata : DataFrame\n        Data from which to extract growth volatility. An exception\n        will be raised if `eqdata` does not contain a column 'Adj Close'\n        or an optional name specified by the `selection` parameter.\n    window : int, optional\n        Window on which to calculate volatility. Defaults to 20.\n    selection : str, optional\n        Column of eqdata on which to calculate volatility of growth. Defaults\n        to 'Adj Close'\n    outputcol : str, optional\n        Column to use for output. Defaults to 'Growth Risk'.\n\n    Returns\n    ---------\n    out : DataFrame\n        Dataframe showing the volatility of growth over the specified `window`.\n    \"\"\"\n    _window = kwargs.get('window', 20)\n    _selection = kwargs.get('selection', 'Adj Close')\n    _outputcol = kwargs.get('outputcol', 'Growth Risk')\n    _growthdata = simple.growth(eqdata, selection=_selection)\n    return volatility(_growthdata, outputcol=_outputcol, window=_window)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bollinger(eqdata, **kwargs):\n    _window = kwargs.get('window', 20)\n    _multiple = kwargs.get('multiple', 2.)\n    _selection = kwargs.get('selection', 'Adj Close')\n    # ensures correct name for output column of sma()\n    kwargs['outputcol'] = 'SMA'\n    _smadf = sma(eqdata, **kwargs)\n    _sigmas = eqdata.loc[:, _selection].rolling(center=False, window=_window).std().values.flatten()\n    _diff = _multiple * _sigmas\n    _bolldf = pd.DataFrame(index=eqdata.index, columns=['Upper', 'Lower'], dtype=np.float64)\n    _bolldf.loc[:, 'Upper'] = _smadf.iloc[:, 0].values + _diff\n    _bolldf.loc[:, 'Lower'] = _smadf.iloc[:, 0].values - _diff\n    return _bolldf, _smadf", "response": "Calculates the Bollinger bands and smadf for a given set of conditions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ratio_to_ave(window, eqdata, **kwargs):\n    _selection = kwargs.get('selection', 'Volume')\n    _skipstartrows = kwargs.get('skipstartrows', 0)\n    _skipendrows = kwargs.get('skipendrows', 0)\n    _outputcol = kwargs.get('outputcol', 'Ratio to Ave')\n    _size = len(eqdata.index)\n    _eqdata = eqdata.loc[:, _selection]\n\n    _sma = _eqdata.iloc[:-1 - _skipendrows].rolling(window=window, center=False).mean().values\n    _outdata = _eqdata.values[window + _skipstartrows:_size - _skipendrows] /\\\n            _sma[window + _skipstartrows - 1:]\n    _index = eqdata.index[window + _skipstartrows:_size - _skipendrows]\n    return pd.DataFrame(_outdata, index=_index, columns=[_outputcol], dtype=np.float64)", "response": "Returns values expressed as ratios to the average over some number\n    prior sessions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(features, labels, regularization=0., constfeat=True):\n    n_col = (features.shape[1] if len(features.shape) > 1 else 1)\n    reg_matrix = regularization * np.identity(n_col, dtype='float64')\n    if constfeat:\n        reg_matrix[0, 0] = 0.\n    # http://stackoverflow.com/questions/27476933/numpy-linear-regression-with-regularization\n    return np.linalg.lstsq(features.T.dot(features) + reg_matrix, features.T.dot(labels))[0]", "response": "Run linear regression on the given data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the calendar spread for the given option and strike and expiration date.", "response": "def cal(self, opttype, strike, exp1, exp2):\n        \"\"\"\n        Metrics for evaluating a calendar spread.\n\n        Parameters\n        ------------\n        opttype : str ('call' or 'put')\n            Type of option on which to collect data.\n        strike : numeric\n            Strike price.\n        exp1 : date or date str (e.g. '2015-01-01')\n            Earlier expiration date.\n        exp2 : date or date str (e.g. '2015-01-01')\n            Later expiration date.\n\n        Returns\n        ------------\n        metrics : DataFrame\n            Metrics for evaluating spread.\n        \"\"\"\n        assert pd.Timestamp(exp1) < pd.Timestamp(exp2)\n        _row1 = _relevant_rows(self.data, (strike, exp1, opttype,),\n                \"No key for {} strike {} {}\".format(exp1, strike, opttype))\n        _row2 = _relevant_rows(self.data, (strike, exp2, opttype,),\n                \"No key for {} strike {} {}\".format(exp2, strike, opttype))\n        _price1 = _getprice(_row1)\n        _price2 = _getprice(_row2)\n        _eq = _row1.loc[:, 'Underlying_Price'].values[0]\n        _qt = _row1.loc[:, 'Quote_Time'].values[0]\n        _index = ['Near', 'Far', 'Debit', 'Underlying_Price', 'Quote_Time']\n        _vals = np.array([_price1, _price2, _price2 - _price1, _eq, _qt])\n        return pd.DataFrame(_vals, index=_index, columns=['Value'])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a raw feature set from the input data.", "response": "def featurize(equity_data, n_sessions, **kwargs):\n    \"\"\"\n    Generate a raw (unnormalized) feature set from the input data.\n    The value at `column` on the given date is taken\n    as a feature, and each row contains values for n_sessions\n\n    Parameters\n    -----------\n    equity_data : DataFrame\n        data from which to generate features\n\n    n_sessions : int\n        number of sessions to use as features\n\n    selection : str, default: 'Adj Close'\n        column of `equity_data` from which to generate features.\n\n    columns : list, default: ``map(str, range((-n_sessions + 1), 1))``\n        column names for output DataFrame. Default will look like:\n        ['-5', '-4', '-3', '-2', '-1', '0'].\n\n    Returns\n    ----------\n    out : DataFrame\n        Each row is a sequence of `n_sessions` session values where\n        the last column matches the value on the date specified by\n        the DataFrame index.\n\n    Examples\n    --------\n    >>> pn.featurize(equity_data, n_sessions, **kwargs)\n    \"\"\"\n    #Benchmarking\n    #>>> s = 'from __main__ import data\\nimport datetime as dt\\n'\n    #>>> timeit.timeit('data.featurize(data.get(\"ge\", dt.date(1960, 1, 1), \n    #        dt.date(2014, 12, 31)), 256)', setup=s, number=1)\n    #1.6771750450134277\n    columns = kwargs.get('columns', map(str, range(-n_sessions + 1, 1)))\n    selection = kwargs.get('selection', 'Adj Close')\n    # empty DataFrame with desired index and column labels\n    features = pd.DataFrame(index=equity_data.index[(n_sessions - 1):],\n            columns=columns, dtype='float64')\n    values = equity_data[selection].values\n    for i in range(n_sessions - 1):\n        features.iloc[:, i] = values[i:(-n_sessions + i + 1)]\n    features.iloc[:, n_sessions - 1] = values[(n_sessions - 1):]\n    return features"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a new function that replicates the behavior of the input but also returns an additional value. Used for creating functions of the proper type to pass to `labeledfeatures()`. Parameters ---------- fn : function *args : any Additional parameters that the returned function will return **kwargs : dict Each element in `kwargs` will become an attribute of the output function. Returns ---------- wrapped : function New function that acts like `fn` except that it also returns an additional value. Examples ---------- >>> from functools import partial >>> forecast_interval = 32 >>> features, labels = pn.data.labeledfeatures(eqdata, 256, featurefn, ... decorate(partial(pn.data.lab.growth, forecast_interval, 'Adj Close'), forecast_interval)) >>> def f(): ... return 0, 1 ... >>> pn.decorate(f, 3, 4, 5)() (0, 1, 3, 4, 5) >>> pn.decorate(lambda x: x * .5, 3, 4, 5)(1.) (1., 3, 4, 5) >>> pn.decorate(lambda x: x, 1 2)('foo') ('foo', 1, 2) >>> pn.decorate(f, 'foo'): (0, 1, 'foo') pn.decorate(f, 0, foo='bar').foo >>> 'bar' Notes ---------- If `fn` returns multiple values, these will be returned in sequence as the first values returned by `add_rets(fn, arg0, arg1, arg2)`. See example above.", "response": "def decorate(fn, *args, **kwargs):\n    \"\"\"\n    Return a new function that replicates the behavior of the input\n    but also returns an additional value. Used for creating functions\n    of the proper type to pass to `labeledfeatures()`.\n\n    Parameters\n    ----------\n    fn : function\n\n    *args : any\n        Additional parameters that the returned function will return\n\n    **kwargs : dict\n        Each element in `kwargs` will become an attribute of the output\n        function.\n\n    Returns\n    ----------\n    wrapped : function\n        New function that acts like `fn` except that it also returns\n        an additional value.\n\n    Examples\n    ----------\n    >>> from functools import partial\n    >>> forecast_interval = 32\n    >>> features, labels = pn.data.labeledfeatures(eqdata, 256, featurefn,\n    ...        decorate(partial(pn.data.lab.growth, forecast_interval, 'Adj Close'), forecast_interval))\n    >>> def f():\n    ...    return 0, 1 \n    ...\n    >>> pn.decorate(f, 3, 4, 5)()\n    (0, 1, 3, 4, 5)\n    >>> pn.decorate(lambda x: x * .5, 3, 4, 5)(1.)\n    (1., 3, 4, 5)\n    >>> pn.decorate(lambda x: x, 1 2)('foo')\n    ('foo', 1, 2)\n    >>> pn.decorate(f, 'foo'):\n    (0, 1, 'foo')\n    pn.decorate(f, 0, foo='bar').foo\n    >>> 'bar'\n\n    Notes\n    ----------\n    If `fn` returns multiple values, these will be returned in sequence\n    as the first values returned by `add_rets(fn, arg0, arg1, arg2)`. See example\n    above.\n    \"\"\"\n    def _wrapper(*_args, **kwargs):\n        _ret = fn(*_args, **kwargs)\n        if isinstance(_ret, tuple):\n            return _ret + args\n        if len(args) == 0:\n            return _ret\n        return (_ret,) + args\n    for key, value in kwargs.items():\n        _wrapper.__dict__[key] = value\n    return _wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwraps a function that applies to a single column to make a function applying to a multi - dimensional dataframe or ndarray.", "response": "def expand(fn, col, inputtype=pd.DataFrame):\n    \"\"\"\n    Wrap a function applying to a single column to make a function\n    applying to a multi-dimensional dataframe or ndarray\n\n    Parameters\n    ----------\n    fn : function\n        Function that applies to a series or vector.\n\n    col : str or int\n        Index of column to which to apply `fn`.\n\n    inputtype : class or type\n        Type of input to be expected by the wrapped function.\n        Normally pd.DataFrame or np.ndarray. Defaults to pd.DataFrame.\n\n    Returns\n    ----------\n    wrapped : function\n        Function that takes an input of type `inputtype` and applies\n        `fn` to the specified `col`.\n    \"\"\"\n    if inputtype == pd.DataFrame:\n        if isinstance(col, int):\n            def _wrapper(*args, **kwargs):\n                return fn(args[0].iloc[:, col], *args[1:], **kwargs)\n            return _wrapper\n        def _wrapper(*args, **kwargs):\n            return fn(args[0].loc[:, col], *args[1:], **kwargs)\n        return _wrapper\n    elif inputtype == np.ndarray:\n        def _wrapper(*args, **kwargs):\n            return fn(args[0][:, col], *args[1:], **kwargs)\n        return _wrapper\n    raise TypeError(\"invalid input type\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if eqdata contains no missing values.", "response": "def has_na(eqdata):\n    \"\"\"\n    Return false if `eqdata` contains no missing values.\n\n    Parameters\n    ----------\n    eqdata : DataFrame or ndarray\n        Data to check for missing values (NaN, None)\n\n    Returns\n    ----------\n    answer : bool\n        False iff `eqdata` contains no missing values.\n    \"\"\"\n    if isinstance(eqdata, pd.DataFrame):\n        _values = eqdata.values\n    else:\n        _values = eqdata\n    return len(_values[pd.isnull(_values)]) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd constant features to the first feature in the features set and returns the modified feature set.", "response": "def add_const(features):\n    \"\"\"\n    Prepend the constant feature 1 as first feature and return the modified\n    feature set.\n\n    Parameters\n    ----------\n    features : ndarray or DataFrame\n    \"\"\"\n    content = np.empty((features.shape[0], features.shape[1] + 1), dtype='float64')\n    content[:, 0] = 1.\n    if isinstance(features, np.ndarray):\n        content[:, 1:] = features\n        return content\n    content[:, 1:] = features.iloc[:, :].values\n    cols = ['Constant'] + features.columns.tolist()\n    return pd.DataFrame(data=content, index=features.index, columns=cols, dtype='float64')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating features from selected columns of a dataframe.", "response": "def fromcols(selection, n_sessions, eqdata, **kwargs):\n    \"\"\"\n    Generate features from selected columns of a dataframe.\n\n    Parameters\n    ----------\n    selection : list or tuple of str\n        Columns to be used as features.\n\n    n_sessions : int\n        Number of sessions over which to create features.\n\n    eqdata : DataFrame\n        Data from which to generate feature set. Must contain\n        as columns the values from which the features are to\n        be generated.\n\n    constfeat : bool, optional\n        Whether or not the returned features will have the constant\n        feature.\n\n    Returns\n    ----------\n    features : DataFrame\n    \"\"\"\n    _constfeat = kwargs.get('constfeat', True)\n    _outcols = ['Constant'] if _constfeat else []\n    _n_rows = len(eqdata.index)\n    for _col in selection:\n        _outcols += map(partial(_concat, strval=' ' + _col), range(-n_sessions + 1, 1))\n    _features = pd.DataFrame(index=eqdata.index[n_sessions - 1:], columns=_outcols, dtype=np.float64)\n    _offset = 0\n    if _constfeat:\n        _features.iloc[:, 0] = 1.\n        _offset += 1\n    for _col in selection:\n        _values = eqdata.loc[:, _col].values\n        for i in range(n_sessions):\n            _features.iloc[:, _offset + i] = _values[i:_n_rows - n_sessions + i + 1]\n        _offset += n_sessions\n    return _features"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating features from a list of functions to apply to a DataFrame of data.", "response": "def fromfuncs(funcs, n_sessions, eqdata, **kwargs):\n    \"\"\"\n    Generate features using a list of functions to apply to input data\n\n    Parameters\n    ----------\n    funcs : list of function\n        Functions to apply to eqdata. Each function is expected\n        to output a dataframe with index identical to a slice of `eqdata`.\n        The slice must include at least `eqdata.index[skipatstart + n_sessions - 1:]`.\n        Each function is also expected to have a function attribute\n        `title`, which is used to generate the column names of the\n        output features.\n\n    n_sessions : int\n        Number of sessions over which to create features.\n\n    eqdata : DataFrame\n        Data from which to generate features. The data will often\n        be retrieved using `pn.get()`.\n\n    constfeat : bool, optional\n        Whether or not the returned features will have the constant\n        feature.\n\n    skipatstart : int, optional\n        Number of rows to omit at the start of the output DataFrame.\n        This parameter is necessary if any of the functions requires\n        a rampup period before returning valid results, e.g. `sma()` or\n        functions calculating volume relative to a past baseline.\n        Defaults to 0.\n\n    Returns\n    ----------\n    features : DataFrame\n    \"\"\"\n    _skipatstart = kwargs.get('skipatstart', 0)\n    _constfeat = kwargs.get('constfeat', True)\n    _outcols = ['Constant'] if _constfeat else []\n    _n_allrows = len(eqdata.index)\n    _n_featrows = _n_allrows - _skipatstart - n_sessions + 1\n    for _func in funcs:\n        _outcols += map(partial(_concat, strval=' ' + _func.title), range(-n_sessions + 1, 1))\n    _features = pd.DataFrame(index=eqdata.index[_skipatstart + n_sessions - 1:],\n            columns=_outcols, dtype=np.float64)\n    _offset = 0\n    if _constfeat:\n        _features.iloc[:, 0] = 1.\n        _offset += 1\n    for _func in funcs:\n        _values = _func(eqdata).values\n        _n_values = len(_values)\n        for i in range(n_sessions):\n            _val_end = _n_values - n_sessions + i + 1\n            _features.iloc[:, _offset + i] = _values[_val_end - _n_featrows:_val_end]\n        _offset += n_sessions\n    return _features"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a DataFrame where the sole column growth is the growth for the equity over the given number of sessions.", "response": "def growth(eqdata, **kwargs):\n    \"\"\"\n    Generate a DataFrame where the sole column, 'Growth',\n    is the growth for the equity over the given number of sessions.\n    \n    For example, if 'XYZ' has 'Adj Close' of `100.0` on 2014-12-15 and \n    `90.0` 4 *sessions* later on 2014-12-19, then the 'Growth' value\n    for 2014-12-19 will be `0.9`.\n\n    Parameters\n    ----------\n    eqdata : DataFrame\n        Data such as that returned by :func:`pynance.data.retrieve.get`\n    selection : str, optional\n        Column from which to determine growth values. Defaults to\n        'Adj Close'.\n    n_sessions : int\n        Number of sessions to count back for calculating today's\n        growth. For example, if `n_sessions` is set to 4, growth is\n        calculated relative to the price 4 sessions ago. Defaults\n        to 1 (price of previous session).\n    skipstartrows : int\n        Rows to skip at beginning of `eqdata` in addition to the 1 row that must\n        be skipped because the calculation relies on a prior data point.\n        Defaults to 0.\n    skipendrows : int\n        Rows to skip at end of `eqdata`. Defaults to 0.\n    outputcol : str, optional\n        Name to use for output column. Defaults to 'Growth'\n\n    Returns\n    ----------\n    out : DataFrame\n\n    Notes\n    ----------\n    The interval is the number of *sessions* between the 2 values\n    whose ratio is being measured, *not* the number of days (which\n    includes days on which the market is closed).\n\n    Growth is measured relative to the earlier\n    date, but the index date is the later date. This index is chosen because\n    it is the date on which the value is known.\n    \"\"\"\n    selection = kwargs.get('selection', 'Adj Close')\n    n_sessions = kwargs.get('n_sessions', 1)\n    skipstartrows = kwargs.get('skipstartrows', 0)\n    skipendrows = kwargs.get('skipendrows', 0)\n    outputcol = kwargs.get('outputcol', 'Growth')\n    size = len(eqdata.index)\n    growthdata = eqdata.loc[:, selection].values[(skipstartrows + n_sessions):(size - skipendrows)] / \\\n            eqdata.loc[:, selection].values[skipstartrows:(-n_sessions - skipendrows)]\n    growthindex = eqdata.index[(skipstartrows + n_sessions):(size - skipendrows)]\n    return pd.DataFrame(data=growthdata, index=growthindex, columns=[outputcol], dtype='float64')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ln_growth(eqdata, **kwargs):\n    if 'outputcol' not in kwargs:\n        kwargs['outputcol'] = 'LnGrowth'\n    return np.log(growth(eqdata, **kwargs))", "response": "Returns the natural log of growth."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ret(eqdata, **kwargs):\n    if 'outputcol' not in kwargs:\n        kwargs['outputcol'] = 'Return'\n    result = growth(eqdata, **kwargs)\n    result.values[:, :] -= 1.\n    return result", "response": "Generate a DataFrame where the sole column Return is the return for the given number of sessions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mse(predicted, actual):\n    diff = predicted - actual\n    return np.average(diff * diff, axis=0)", "response": "Mean squared error of predictions relative to actual."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(eqprice, callprice, strike, shares=1, buycomm=0., excomm=0., dividend=0.):\n    _index = ['Eq Cost', 'Option Premium', 'Commission', 'Total Invested', 'Dividends', 'Eq if Ex', \n            'Comm if Ex', 'Profit if Ex', 'Ret if Ex', 'Profit if Unch', 'Ret if Unch', 'Break_Even Price',\n            'Protection Pts', 'Protection Pct']\n    _metrics = pd.DataFrame(index=_index, columns=['Value'])\n    _shares = float(shares)\n    _dividends = _shares * dividend\n    _metrics.loc['Eq Cost', 'Value'] = _eqcost = _shares * eqprice\n    _metrics.loc['Option Premium', 'Value'] = _optprem = _shares * callprice\n    _metrics.loc['Commission', 'Value'] = float(buycomm)\n    _metrics.loc['Total Invested', 'Value'] = _invested = _eqcost - _optprem + buycomm\n    _metrics.loc['Dividends', 'Value'] = _dividends\n    _metrics.loc['Eq if Ex', 'Value'] = _eqsale = strike * _shares\n    _metrics.loc['Comm if Ex', 'Value'] = float(excomm)\n    _metrics.loc['Profit if Ex', 'Value'] = _profitex = _eqsale + _dividends - _invested - excomm\n    _metrics.loc['Ret if Ex', 'Value'] = round(_profitex / _invested, _constants.NDIGITS_SIG)\n    _metrics.loc['Profit if Unch', 'Value'] = _profitunch = _eqcost + _dividends - _invested\n    _metrics.loc['Ret if Unch', 'Value'] = round(_profitunch / _invested, _constants.NDIGITS_SIG)\n    _metrics.loc['Break_Even Price', 'Value'] = _breakeven = round((_invested - _dividends) / _shares, \n            _constants.NDIGITS_SIG)\n    _metrics.loc['Protection Pts', 'Value'] = _protpts = eqprice - _breakeven\n    _metrics.loc['Protection Pct', 'Value'] = round(_protpts / eqprice, _constants.NDIGITS_SIG)\n    return _metrics", "response": "Returns a DataFrame of metrics for covered calls."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_bday(date, bday=None):\n    _date = Timestamp(date)\n    if bday is None:\n        bday = CustomBusinessDay(calendar=USFederalHolidayCalendar())\n    return _date == (_date + bday) - bday", "response": "Return true iff the given date is a business day."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compare(eq_dfs, columns=None, selection='Adj Close'):\n    content = np.empty((eq_dfs[0].shape[0], len(eq_dfs)), dtype=np.float64)\n    rel_perf = pd.DataFrame(content, eq_dfs[0].index, columns, dtype=np.float64)\n    for i in range(len(eq_dfs)):\n        rel_perf.iloc[:, i] = eq_dfs[i].loc[:, selection] / eq_dfs[i].iloc[0].loc[selection]\n    return rel_perf", "response": "Returns the relative performance of multiple equities."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the metrics for evaluating a diagonal butterfly spread.", "response": "def diagbtrfly(self, lowstrike, midstrike, highstrike, expiry1, expiry2):\n        \"\"\"\n        Metrics for evaluating a diagonal butterfly spread.\n\n        Parameters\n        ------------\n        opttype : str ('call' or 'put')\n            Type of option on which to collect data.\n        lowstrike : numeric\n            Lower strike price. To be used for far put.\n        midstrike : numeric\n            Middle strike price. To be used for near straddle.\n            Typically at the money.\n        highstrike : numeric\n            Higher strike price. To be used for far call.\n        expiry1 : date or date str (e.g. '2015-01-01')\n            Earlier expiration date.\n        expiry2 : date or date str (e.g. '2015-01-01')\n            Later expiration date.\n\n        Returns\n        ------------\n        metrics : DataFrame\n            Metrics for evaluating spread.\n        \"\"\"\n        assert lowstrike < midstrike\n        assert midstrike < highstrike\n        assert pd.Timestamp(expiry1) < pd.Timestamp(expiry2)\n        _rows1 = {}\n        _rows2 = {}\n        _prices1 = {}\n        _prices2 = {}\n        _index = ['Straddle Call', 'Straddle Put', 'Straddle Total', 'Far Call', 'Far Put', 'Far Total',\n                'Straddle to Far Ratio', 'Credit', 'Underlying_Price', 'Quote_Time']\n        _metrics = pd.DataFrame(index=_index, columns=['Value'])\n        _errmsg = \"No key for {} strike {} {}\"\n        _opttype = 'call'\n        _rows1[_opttype] = _relevant_rows(self.data, (midstrike, expiry1, _opttype),\n                _errmsg.format(expiry1, midstrike, _opttype))\n        _prices1[_opttype] = _getprice(_rows1[_opttype])\n        _rows2[_opttype] = _relevant_rows(self.data, (highstrike, expiry2, _opttype),\n                _errmsg.format(expiry2, highstrike, _opttype))\n        _prices2[_opttype] = _getprice(_rows2[_opttype])\n        _metrics.loc['Straddle Call', 'Value'] = _prices1[_opttype]\n        _metrics.loc['Far Call', 'Value'] = _prices2[_opttype]\n        _metrics.loc['Underlying_Price', 'Value'], _metrics.loc['Quote_Time', 'Value'] =\\\n                _getkeys(_rows1[_opttype], ['Underlying_Price', 'Quote_Time'])\n        _opttype = 'put'\n        _rows1[_opttype] = _relevant_rows(self.data, (midstrike, expiry1, _opttype),\n                _errmsg.format(expiry1, midstrike, _opttype))\n        _prices1[_opttype] = _getprice(_rows1[_opttype])\n        _rows2[_opttype] = _relevant_rows(self.data, (lowstrike, expiry2, _opttype),\n                _errmsg.format(expiry2, lowstrike, _opttype))\n        _prices2[_opttype] = _getprice(_rows2[_opttype])\n        _metrics.loc['Straddle Put', 'Value'] = _prices1[_opttype]\n        _metrics.loc['Far Put', 'Value'] = _prices2[_opttype]\n        _metrics.loc['Straddle Total', 'Value'] = _neartot = sum(_prices1.values())\n        _metrics.loc['Far Total', 'Value'] = _fartot = sum(_prices2.values())\n        _metrics.loc['Straddle to Far Ratio', 'Value'] = _neartot / _fartot \n        _metrics.loc['Credit', 'Value'] = _neartot - _fartot\n        return _metrics"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshow expiration dates equity price and quote time.", "response": "def info(self):\n        \"\"\"\n        Show expiration dates, equity price, quote time.\n\n        Returns\n        -------\n        self : :class:`~pynance.opt.core.Options`\n            Returns a reference to the calling object to allow\n            chaining.\n\n        expiries : :class:`pandas.tseries.index.DatetimeIndex`\n\n        Examples\n        --------\n        >>> fopt, fexp = pn.opt.get('f').info()\n        Expirations:\n        ...\n        Stock: 16.25\n        Quote time: 2015-03-01 16:00\n        \"\"\"\n        print(\"Expirations:\")\n        _i = 0\n        for _datetime in self.data.index.levels[1].to_pydatetime():\n            print(\"{:2d} {}\".format(_i, _datetime.strftime('%Y-%m-%d')))\n            _i += 1\n        print(\"Stock: {:.2f}\".format(self.data.iloc[0].loc['Underlying_Price']))\n        print(\"Quote time: {}\".format(self.quotetime().strftime('%Y-%m-%d %H:%M%z')))\n        return self, self.exps()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the array as a list of rows.", "response": "def tolist(self):\n        \"\"\"\n        Return the array as a list of rows.\n\n        Each row is a `dict` of values. Facilitates inserting data into a database.\n\n        .. versionadded:: 0.3.1\n\n        Returns\n        -------\n        quotes : list\n            A list in which each entry is a dictionary representing\n            a single options quote.\n        \"\"\"\n        return [_todict(key, self.data.loc[key, :]) for key in self.data.index]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a unique username for the user.", "response": "def _generate_username(self):\n        \"\"\" Generate a unique username \"\"\"\n        while True:\n            # Generate a UUID username, removing dashes and the last 2 chars\n            # to make it fit into the 30 char User.username field. Gracefully\n            # handle any unlikely, but possible duplicate usernames.\n            username = str(uuid.uuid4())\n            username = username.replace('-', '')\n            username = username[:-2]\n\n            try:\n                User.objects.get(username=username)\n            except User.DoesNotExist:\n                return username"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the model cache by generating a new key for the model", "response": "def update_model_cache(table_name):\n    \"\"\"\n    Updates model cache by generating a new key for the model\n    \"\"\"\n    model_cache_info = ModelCacheInfo(table_name, uuid.uuid4().hex)\n    model_cache_backend.share_model_cache_info(model_cache_info)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invalidate_model_cache(sender, instance, **kwargs):\n    logger.debug('Received post_save/post_delete signal from sender {0}'.format(sender))\n    if django.VERSION >= (1, 8):\n        related_tables = set(\n            [f.related_model._meta.db_table for f in sender._meta.get_fields()\n             if f.related_model is not None\n             and (((f.one_to_many or f.one_to_one) and f.auto_created)\n                 or f.many_to_one or (f.many_to_many and not f.auto_created))])\n    else:\n        related_tables = set([rel.model._meta.db_table for rel in sender._meta.get_all_related_objects()])\n        # temporary fix for m2m relations with an intermediate model, goes away after better join caching\n        related_tables |= set([field.rel.to._meta.db_table for field in sender._meta.fields if issubclass(type(field), RelatedField)])\n    logger.debug('Related tables of sender {0} are {1}'.format(sender, related_tables))\n    update_model_cache(sender._meta.db_table)\n    for related_table in related_tables:\n        update_model_cache(related_table)", "response": "Signal receiver for models to invalidate model cache of sender and related models."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef invalidate_m2m_cache(sender, instance, model, **kwargs):\n    logger.debug('Received m2m_changed signals from sender {0}'.format(sender))\n    update_model_cache(instance._meta.db_table)\n    update_model_cache(model._meta.db_table)", "response": "Signal receiver for models to invalidate model cache for many - to - many relationship."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of the parameters that are used to get the current value", "response": "def get_params(self):\n        \"\"\"\n        returns a list\n        \"\"\"\n        value = self._get_lookup(self.operator, self.value)\n        self.params.append(self.value)\n        return self.params"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of where clauses", "response": "def get_wheres(self):\n        \"\"\"\n        returns a list\n        \"\"\"\n        self.wheres.append(u\"%s %s\"\n                           % (lookup_cast(operator) % self.db_field,\n                              self.operator))\n        return self.wheres"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef generate_key(self):\n        sql = self.sql()\n        key, created = self.get_or_create_model_key()\n        if created:\n            db_table = self.model._meta.db_table\n            logger.debug('created new key {0} for model {1}'.format(key, db_table))\n            model_cache_info = ModelCacheInfo(db_table, key)\n            model_cache_backend.share_model_cache_info(model_cache_info)\n        query_key = u'{model_key}{qs}{db}'.format(model_key=key,\n                                                  qs=sql,\n                                                  db=self.db)\n        key = hashlib.md5(query_key.encode('utf-8')).hexdigest()\n        return key", "response": "Generate cache key for the current query."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets sql for the current query.", "response": "def sql(self):\n        \"\"\"\n        Get sql for the current query.\n        \"\"\"\n        clone = self.query.clone()\n        sql, params = clone.get_compiler(using=self.db).as_sql()\n        return sql % params"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_or_create_model_key(self):\n        model_cache_info = model_cache_backend.retrieve_model_cache_info(self.model._meta.db_table)\n        if not model_cache_info:\n            return uuid.uuid4().hex, True\n        return model_cache_info.table_key, False", "response": "Get or create the model key for the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef invalidate_model_cache(self):\n        logger.info('Invalidating cache for table {0}'.format(self.model._meta.db_table))\n        if django.VERSION >= (1, 8):\n            related_tables = set(\n                [f.related_model._meta.db_table for f in self.model._meta.get_fields()\n                 if ((f.one_to_many or f.one_to_one) and f.auto_created)\n                 or f.many_to_one or (f.many_to_many and not f.auto_created)])\n        else:\n            related_tables = set([rel.model._meta.db_table for rel in self.model._meta.get_all_related_objects()])\n            # temporary fix for m2m relations with an intermediate model, goes away after better join caching\n            related_tables |= set([field.rel.to._meta.db_table for field in self.model._meta.fields if issubclass(type(field), RelatedField)])\n\n        logger.debug('Related tables of model {0} are {1}'.format(self.model, related_tables))\n        update_model_cache(self.model._meta.db_table)\n        for related_table in related_tables:\n            update_model_cache(related_table)", "response": "Invalidate model cache by generating new key for the model."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cache_backend(self):\n        if not hasattr(self, '_cache_backend'):\n            if hasattr(django.core.cache, 'caches'):\n                self._cache_backend = django.core.cache.caches[_cache_name]\n            else:\n                self._cache_backend = django.core.cache.get_cache(_cache_name)\n\n        return self._cache_backend", "response": "Get the cache backend that contains this instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_file(filename):\n    pathname, filename = os.path.split(filename)\n    modname = re.match(\n        r'(?P<modname>\\w+)\\.py', filename).group('modname')\n    file, path, desc = imp.find_module(modname, [pathname])\n\n    try:\n        imp.load_module(modname, file, path, desc)\n    finally:\n        file.close()", "response": "Imports a file that will trigger the population of Orca."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_is_column(func):\n    @wraps(func)\n    def wrapper(**kwargs):\n        table_name = kwargs['table_name']\n        col_name = kwargs['col_name']\n        if not orca.is_table(table_name):\n            abort(404)\n        if col_name not in orca.get_table(table_name).columns:\n            abort(404)\n\n        return func(**kwargs)\n    return wrapper", "response": "Decorator that will check whether the table_name and col_name keyword arguments to the wrapped function match a registered Orca\n    table and column."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef schema():\n    tables = orca.list_tables()\n    cols = {t: orca.get_table(t).columns for t in tables}\n    steps = orca.list_steps()\n    injectables = orca.list_injectables()\n    broadcasts = orca.list_broadcasts()\n\n    return jsonify(\n        tables=tables, columns=cols, steps=steps, injectables=injectables,\n        broadcasts=broadcasts)", "response": "Return a JSON object that contains all tables columns steps injectables and broadcasts registered with\n    Orca. Includes local columns on tables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the text result of table. info", "response": "def table_info(table_name):\n    \"\"\"\n    Return the text result of table.info(verbose=True).\n\n    \"\"\"\n    table = orca.get_table(table_name).to_frame()\n    buf = StringIO()\n    table.info(verbose=True, buf=buf)\n    info = buf.getvalue()\n    return info, 200, {'Content-Type': 'text/plain'}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef table_preview(table_name):\n    preview = orca.get_table(table_name).to_frame().head()\n    return (\n        preview.to_json(orient='split', date_format='iso'),\n        200,\n        {'Content-Type': 'application/json'})", "response": "Returns the first five rows of a table as JSON. Inlcudes all columns."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn summary statistics of a table as JSON.", "response": "def table_describe(table_name):\n    \"\"\"\n    Return summary statistics of a table as JSON. Includes all columns.\n    Uses Pandas' \"split\" JSON format.\n\n    \"\"\"\n    desc = orca.get_table(table_name).to_frame().describe()\n    return (\n        desc.to_json(orient='split', date_format='iso'),\n        200,\n        {'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the source of a table function.", "response": "def table_definition(table_name):\n    \"\"\"\n    Get the source of a table function.\n\n    If a table is registered DataFrame and not a function then all that is\n    returned is {'type': 'dataframe'}.\n\n    If the table is a registered function then the JSON returned has keys\n    \"type\", \"filename\", \"lineno\", \"text\", and \"html\". \"text\" is the raw\n    text of the function, \"html\" has been marked up by Pygments.\n\n    \"\"\"\n    if orca.table_type(table_name) == 'dataframe':\n        return jsonify(type='dataframe')\n\n    filename, lineno, source = \\\n        orca.get_raw_table(table_name).func_source_data()\n\n    html = highlight(source, PythonLexer(), HtmlFormatter())\n\n    return jsonify(\n        type='function', filename=filename, lineno=lineno, text=source,\n        html=html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef table_groupbyagg(table_name):\n    table = orca.get_table(table_name)\n\n    # column to aggregate\n    column = request.args.get('column', None)\n    if not column or column not in table.columns:\n        abort(400)\n\n    # column or index level to group by\n    by = request.args.get('by', None)\n    level = request.args.get('level', None)\n    if (not by and not level) or (by and level):\n        abort(400)\n\n    # aggregation type\n    agg = request.args.get('agg', None)\n    if not agg or agg not in _GROUPBY_AGG_MAP:\n        abort(400)\n\n    column = table.get_column(column)\n\n    # level can either be an integer level number or a string level name.\n    # try converting to integer, but if that doesn't work\n    # we go ahead with the string.\n    if level:\n        try:\n            level = int(level)\n        except ValueError:\n            pass\n        gby = column.groupby(level=level)\n    else:\n        by = table.get_column(by)\n        gby = column.groupby(by)\n\n    result = _GROUPBY_AGG_MAP[agg](gby)\n\n    return (\n        result.to_json(orient='split', date_format='iso'),\n        200,\n        {'Content-Type': 'application/json'})", "response": "Perform a groupby on a table and return an aggregation on a single column."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the first 10 elements of a column as JSON in Pandas ' split format.", "response": "def column_preview(table_name, col_name):\n    \"\"\"\n    Return the first ten elements of a column as JSON in Pandas'\n    \"split\" format.\n\n    \"\"\"\n    col = orca.get_table(table_name).get_column(col_name).head(10)\n\n    return (\n        col.to_json(orient='split', date_format='iso'),\n        200,\n        {'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the source of a column function.", "response": "def column_definition(table_name, col_name):\n    \"\"\"\n    Get the source of a column function.\n\n    If a column is a registered Series and not a function then all that is\n    returned is {'type': 'series'}.\n\n    If the column is a registered function then the JSON returned has keys\n    \"type\", \"filename\", \"lineno\", \"text\", and \"html\". \"text\" is the raw\n    text of the function, \"html\" has been marked up by Pygments.\n\n    \"\"\"\n    col_type = orca.get_table(table_name).column_type(col_name)\n\n    if col_type != 'function':\n        return jsonify(type=col_type)\n\n    filename, lineno, source = \\\n        orca.get_raw_column(table_name, col_name).func_source_data()\n\n    html = highlight(source, PythonLexer(), HtmlFormatter())\n\n    return jsonify(\n        type='function', filename=filename, lineno=lineno, text=source,\n        html=html)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn summary statistics of a column as JSON. Uses Pandas split JSON format.", "response": "def column_describe(table_name, col_name):\n    \"\"\"\n    Return summary statistics of a column as JSON.\n    Uses Pandas' \"split\" JSON format.\n\n    \"\"\"\n    col_desc = orca.get_table(table_name).get_column(col_name).describe()\n    return (\n        col_desc.to_json(orient='split'),\n        200,\n        {'Content-Type': 'application/json'})"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a column as CSV using Pandas default CSV output.", "response": "def column_csv(table_name, col_name):\n    \"\"\"\n    Return a column as CSV using Pandas' default CSV output.\n\n    \"\"\"\n    csv = orca.get_table(table_name).get_column(col_name).to_csv(path=None)\n    return csv, 200, {'Content-Type': 'text/csv'}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef injectable_repr(inj_name):\n    i = orca.get_injectable(inj_name)\n    return jsonify(type=str(type(i)), repr=repr(i))", "response": "Returns the type and repr of an injectable. JSON response has\n    type and repr keys."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef injectable_definition(inj_name):\n    inj_type = orca.injectable_type(inj_name)\n\n    if inj_type == 'variable':\n        return jsonify(type='variable')\n    else:\n        filename, lineno, source = \\\n            orca.get_injectable_func_source_data(inj_name)\n        html = highlight(source, PythonLexer(), HtmlFormatter())\n        return jsonify(\n            type='function', filename=filename, lineno=lineno, text=source,\n            html=html)", "response": "Get the source of an injectable function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_broadcasts():\n    casts = [{'cast': b[0], 'onto': b[1]} for b in orca.list_broadcasts()]\n    return jsonify(broadcasts=casts)", "response": "List all registered broadcasts as a list of objects with\n    keys cast and onto."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the definition of a broadcast as an object with keys cast onto cast_on and onto_on and cast_index and onto_index.", "response": "def broadcast_definition(cast_name, onto_name):\n    \"\"\"\n    Return the definition of a broadcast as an object with keys\n    \"cast\", \"onto\", \"cast_on\", \"onto_on\", \"cast_index\", and \"onto_index\".\n    These are the same as the arguments to the ``broadcast`` function.\n\n    \"\"\"\n    if not orca.is_broadcast(cast_name, onto_name):\n        abort(404)\n\n    b = orca.get_broadcast(cast_name, onto_name)\n\n    return jsonify(\n        cast=b.cast, onto=b.onto, cast_on=b.cast_on, onto_on=b.onto_on,\n        cast_index=b.cast_index, onto_index=b.onto_index)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef step_definition(step_name):\n    if not orca.is_step(step_name):\n        abort(404)\n\n    filename, lineno, source = \\\n        orca.get_step(step_name).func_source_data()\n    html = highlight(source, PythonLexer(), HtmlFormatter())\n    return jsonify(filename=filename, lineno=lineno, text=source, html=html)", "response": "Get the source of a step function. Returned object has keys\n    filename lineno text and html."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _add_log_handler(\n        handler, level=None, fmt=None, datefmt=None, propagate=None):\n    \"\"\"\n    Add a logging handler to Orca.\n\n    Parameters\n    ----------\n    handler : logging.Handler subclass\n    level : int, optional\n        An optional logging level that will apply only to this stream\n        handler.\n    fmt : str, optional\n        An optional format string that will be used for the log\n        messages.\n    datefmt : str, optional\n        An optional format string for formatting dates in the log\n        messages.\n    propagate : bool, optional\n        Whether the Orca logger should propagate. If None the\n        propagation will not be modified, otherwise it will be set\n        to this value.\n\n    \"\"\"\n    if not fmt:\n        fmt = US_LOG_FMT\n    if not datefmt:\n        datefmt = US_LOG_DATE_FMT\n\n    handler.setFormatter(logging.Formatter(fmt=fmt, datefmt=datefmt))\n\n    if level is not None:\n        handler.setLevel(level)\n\n    logger = logging.getLogger('orca')\n    logger.addHandler(handler)\n\n    if propagate is not None:\n        logger.propagate = propagate", "response": "Adds a logging handler to the Orca log."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending log messages to the console.", "response": "def log_to_stream(level=None, fmt=None, datefmt=None):\n    \"\"\"\n    Send log messages to the console.\n\n    Parameters\n    ----------\n    level : int, optional\n        An optional logging level that will apply only to this stream\n        handler.\n    fmt : str, optional\n        An optional format string that will be used for the log\n        messages.\n    datefmt : str, optional\n        An optional format string for formatting dates in the log\n        messages.\n\n    \"\"\"\n    _add_log_handler(\n        logging.StreamHandler(), fmt=fmt, datefmt=datefmt, propagate=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends log output to a file.", "response": "def log_to_file(filename, level=None, fmt=None, datefmt=None):\n    \"\"\"\n    Send log output to the given file.\n\n    Parameters\n    ----------\n    filename : str\n    level : int, optional\n        An optional logging level that will apply only to this stream\n        handler.\n    fmt : str, optional\n        An optional format string that will be used for the log\n        messages.\n    datefmt : str, optional\n        An optional format string for formatting dates in the log\n        messages.\n\n    \"\"\"\n    _add_log_handler(\n        logging.FileHandler(filename), fmt=fmt, datefmt=datefmt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclears any and all stored state from Orca.", "response": "def clear_all():\n    \"\"\"\n    Clear any and all stored state from Orca.\n\n    \"\"\"\n    _TABLES.clear()\n    _COLUMNS.clear()\n    _STEPS.clear()\n    _BROADCASTS.clear()\n    _INJECTABLES.clear()\n    _TABLE_CACHE.clear()\n    _COLUMN_CACHE.clear()\n    _INJECTABLE_CACHE.clear()\n    for m in _MEMOIZED.values():\n        m.value.clear_cached()\n    _MEMOIZED.clear()\n    logger.debug('pipeline state cleared')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_cache(scope=None):\n    if not scope:\n        _TABLE_CACHE.clear()\n        _COLUMN_CACHE.clear()\n        _INJECTABLE_CACHE.clear()\n        for m in _MEMOIZED.values():\n            m.value.clear_cached()\n        logger.debug('pipeline cache cleared')\n    else:\n        for d in (_TABLE_CACHE, _COLUMN_CACHE, _INJECTABLE_CACHE):\n            items = tz.valfilter(lambda x: x.scope == scope, d)\n            for k in items:\n                del d[k]\n        for m in tz.filter(lambda x: x.scope == scope, _MEMOIZED.values()):\n            m.value.clear_cached()\n        logger.debug('cleared cached values with scope {!r}'.format(scope))", "response": "Clear all cached data for a given scope."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _collect_variables(names, expressions=None):\n    # Map registered variable labels to expressions.\n    if not expressions:\n        expressions = []\n    offset = len(names) - len(expressions)\n    labels_map = dict(tz.concatv(\n        tz.compatibility.zip(names[:offset], names[:offset]),\n        tz.compatibility.zip(names[offset:], expressions)))\n\n    all_variables = tz.merge(_INJECTABLES, _TABLES)\n    variables = {}\n    for label, expression in labels_map.items():\n        # In the future, more registered variable expressions could be\n        # supported. Currently supports names of registered variables\n        # and references to table columns.\n        if '.' in expression:\n            # Registered variable expression refers to column.\n            table_name, column_name = expression.split('.')\n            table = get_table(table_name)\n            variables[label] = table.get_column(column_name)\n        else:\n            thing = all_variables[expression]\n            if isinstance(thing, (_InjectableFuncWrapper, TableFuncWrapper)):\n                # Registered variable object is function.\n                variables[label] = thing()\n            else:\n                variables[label] = thing\n\n    return variables", "response": "Returns a dict of registered variables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_table(\n        table_name, table, cache=False, cache_scope=_CS_FOREVER,\n        copy_col=True):\n    \"\"\"\n    Register a table with Orca.\n\n    Parameters\n    ----------\n    table_name : str\n        Should be globally unique to this table.\n    table : pandas.DataFrame or function\n        If a function, the function should return a DataFrame.\n        The function's argument names and keyword argument values\n        will be matched to registered variables when the function\n        needs to be evaluated by Orca.\n    cache : bool, optional\n        Whether to cache the results of a provided callable. Does not\n        apply if `table` is a DataFrame.\n    cache_scope : {'step', 'iteration', 'forever'}, optional\n        Scope for which to cache data. Default is to cache forever\n        (or until manually cleared). 'iteration' caches data for each\n        complete iteration of the pipeline, 'step' caches data for\n        a single step of the pipeline.\n    copy_col : bool, optional\n        Whether to return copies when evaluating columns.\n\n    Returns\n    -------\n    wrapped : `DataFrameWrapper` or `TableFuncWrapper`\n\n    \"\"\"\n    if isinstance(table, Callable):\n        table = TableFuncWrapper(table_name, table, cache=cache,\n                                 cache_scope=cache_scope, copy_col=copy_col)\n    else:\n        table = DataFrameWrapper(table_name, table, copy_col=copy_col)\n\n    # clear any cached data from a previously registered table\n    table.clear_cached()\n\n    logger.debug('registering table {!r}'.format(table_name))\n    _TABLES[table_name] = table\n\n    return table", "response": "Register a table with Orca."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecorating functions that return DataFrames. Decorator version of `add_table`. Table name defaults to name of function. The function's argument names and keyword argument values will be matched to registered variables when the function needs to be evaluated by Orca. The argument name \"iter_var\" may be used to have the current iteration variable injected.", "response": "def table(\n        table_name=None, cache=False, cache_scope=_CS_FOREVER, copy_col=True):\n    \"\"\"\n    Decorates functions that return DataFrames.\n\n    Decorator version of `add_table`. Table name defaults to\n    name of function.\n\n    The function's argument names and keyword argument values\n    will be matched to registered variables when the function\n    needs to be evaluated by Orca.\n    The argument name \"iter_var\" may be used to have the current\n    iteration variable injected.\n\n    \"\"\"\n    def decorator(func):\n        if table_name:\n            name = table_name\n        else:\n            name = func.__name__\n        add_table(\n            name, func, cache=cache, cache_scope=cache_scope,\n            copy_col=copy_col)\n        return func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a registered table.", "response": "def get_table(table_name):\n    \"\"\"\n    Get a registered table.\n\n    Decorated functions will be converted to `DataFrameWrapper`.\n\n    Parameters\n    ----------\n    table_name : str\n\n    Returns\n    -------\n    table : `DataFrameWrapper`\n\n    \"\"\"\n    table = get_raw_table(table_name)\n    if isinstance(table, TableFuncWrapper):\n        table = table()\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the type of a table.", "response": "def table_type(table_name):\n    \"\"\"\n    Returns the type of a registered table.\n\n    The type can be either \"dataframe\" or \"function\".\n\n    Parameters\n    ----------\n    table_name : str\n\n    Returns\n    -------\n    table_type : {'dataframe', 'function'}\n\n    \"\"\"\n    table = get_raw_table(table_name)\n\n    if isinstance(table, DataFrameWrapper):\n        return 'dataframe'\n    elif isinstance(table, TableFuncWrapper):\n        return 'function'"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_column(\n        table_name, column_name, column, cache=False, cache_scope=_CS_FOREVER):\n    \"\"\"\n    Add a new column to a table from a Series or callable.\n\n    Parameters\n    ----------\n    table_name : str\n        Table with which the column will be associated.\n    column_name : str\n        Name for the column.\n    column : pandas.Series or callable\n        Series should have an index matching the table to which it\n        is being added. If a callable, the function's argument\n        names and keyword argument values will be matched to\n        registered variables when the function needs to be\n        evaluated by Orca. The function should return a Series.\n    cache : bool, optional\n        Whether to cache the results of a provided callable. Does not\n        apply if `column` is a Series.\n    cache_scope : {'step', 'iteration', 'forever'}, optional\n        Scope for which to cache data. Default is to cache forever\n        (or until manually cleared). 'iteration' caches data for each\n        complete iteration of the pipeline, 'step' caches data for\n        a single step of the pipeline.\n\n    \"\"\"\n    if isinstance(column, Callable):\n        column = \\\n            _ColumnFuncWrapper(\n                table_name, column_name, column,\n                cache=cache, cache_scope=cache_scope)\n    else:\n        column = _SeriesWrapper(table_name, column_name, column)\n\n    # clear any cached data from a previously registered column\n    column.clear_cached()\n\n    logger.debug('registering column {!r} on table {!r}'.format(\n        column_name, table_name))\n    _COLUMNS[(table_name, column_name)] = column\n\n    return column", "response": "Add a new column to a table from a Series or callable."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndecorate functions that return a Series. Decorator version of `add_column`. Series index must match the named table. Column name defaults to name of function. The function's argument names and keyword argument values will be matched to registered variables when the function needs to be evaluated by Orca. The argument name \"iter_var\" may be used to have the current iteration variable injected. The index of the returned Series must match the named table.", "response": "def column(table_name, column_name=None, cache=False, cache_scope=_CS_FOREVER):\n    \"\"\"\n    Decorates functions that return a Series.\n\n    Decorator version of `add_column`. Series index must match\n    the named table. Column name defaults to name of function.\n\n    The function's argument names and keyword argument values\n    will be matched to registered variables when the function\n    needs to be evaluated by Orca.\n    The argument name \"iter_var\" may be used to have the current\n    iteration variable injected.\n    The index of the returned Series must match the named table.\n\n    \"\"\"\n    def decorator(func):\n        if column_name:\n            name = column_name\n        else:\n            name = func.__name__\n        add_column(\n            table_name, name, func, cache=cache, cache_scope=cache_scope)\n        return func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _columns_for_table(table_name):\n    return {cname: col\n            for (tname, cname), col in _COLUMNS.items()\n            if tname == table_name}", "response": "Returns all of the columns registered for a given table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a wrapped column.", "response": "def get_raw_column(table_name, column_name):\n    \"\"\"\n    Get a wrapped, registered column.\n\n    This function cannot return columns that are part of wrapped\n    DataFrames, it's only for columns registered directly through Orca.\n\n    Parameters\n    ----------\n    table_name : str\n    column_name : str\n\n    Returns\n    -------\n    wrapped : _SeriesWrapper or _ColumnFuncWrapper\n\n    \"\"\"\n    try:\n        return _COLUMNS[(table_name, column_name)]\n    except KeyError:\n        raise KeyError('column {!r} not found for table {!r}'.format(\n            column_name, table_name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwraps a function for memoization and ties it's cache into the Orca cacheing system. Parameters ---------- f : function name : str Name of injectable. cache_scope : {'step', 'iteration', 'forever'}, optional Scope for which to cache data. Default is to cache forever (or until manually cleared). 'iteration' caches data for each complete iteration of the pipeline, 'step' caches data for a single step of the pipeline.", "response": "def _memoize_function(f, name, cache_scope=_CS_FOREVER):\n    \"\"\"\n    Wraps a function for memoization and ties it's cache into the\n    Orca cacheing system.\n\n    Parameters\n    ----------\n    f : function\n    name : str\n        Name of injectable.\n    cache_scope : {'step', 'iteration', 'forever'}, optional\n        Scope for which to cache data. Default is to cache forever\n        (or until manually cleared). 'iteration' caches data for each\n        complete iteration of the pipeline, 'step' caches data for\n        a single step of the pipeline.\n\n    \"\"\"\n    cache = {}\n\n    @wraps(f)\n    def wrapper(*args, **kwargs):\n        try:\n            cache_key = (\n                args or None, frozenset(kwargs.items()) if kwargs else None)\n            in_cache = cache_key in cache\n        except TypeError:\n            raise TypeError(\n                'function arguments must be hashable for memoization')\n\n        if _CACHING and in_cache:\n            return cache[cache_key]\n        else:\n            result = f(*args, **kwargs)\n            cache[cache_key] = result\n            return result\n\n    wrapper.__wrapped__ = f\n    wrapper.cache = cache\n    wrapper.clear_cached = lambda: cache.clear()\n    _MEMOIZED[name] = CacheItem(name, wrapper, cache_scope)\n\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_injectable(\n        name, value, autocall=True, cache=False, cache_scope=_CS_FOREVER,\n        memoize=False):\n    \"\"\"\n    Add a value that will be injected into other functions.\n\n    Parameters\n    ----------\n    name : str\n    value\n        If a callable and `autocall` is True then the function's\n        argument names and keyword argument values will be matched\n        to registered variables when the function needs to be\n        evaluated by Orca. The return value will\n        be passed to any functions using this injectable. In all other\n        cases, `value` will be passed through untouched.\n    autocall : bool, optional\n        Set to True to have injectable functions automatically called\n        (with argument matching) and the result injected instead of\n        the function itself.\n    cache : bool, optional\n        Whether to cache the return value of an injectable function.\n        Only applies when `value` is a callable and `autocall` is True.\n    cache_scope : {'step', 'iteration', 'forever'}, optional\n        Scope for which to cache data. Default is to cache forever\n        (or until manually cleared). 'iteration' caches data for each\n        complete iteration of the pipeline, 'step' caches data for\n        a single step of the pipeline.\n    memoize : bool, optional\n        If autocall is False it is still possible to cache function results\n        by setting this flag to True. Cached values are stored in a dictionary\n        keyed by argument values, so the argument values must be hashable.\n        Memoized functions have their caches cleared according to the same\n        rules as universal caching.\n\n    \"\"\"\n    if isinstance(value, Callable):\n        if autocall:\n            value = _InjectableFuncWrapper(\n                name, value, cache=cache, cache_scope=cache_scope)\n            # clear any cached data from a previously registered value\n            value.clear_cached()\n        elif not autocall and memoize:\n            value = _memoize_function(value, name, cache_scope=cache_scope)\n\n    logger.debug('registering injectable {!r}'.format(name))\n    _INJECTABLES[name] = value", "response": "Adds a value to the injectable list of the specified name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecorates functions that will be injected into other functions. Decorator version of `add_injectable`. Name defaults to name of function. The function's argument names and keyword argument values will be matched to registered variables when the function needs to be evaluated by Orca. The argument name \"iter_var\" may be used to have the current iteration variable injected.", "response": "def injectable(\n        name=None, autocall=True, cache=False, cache_scope=_CS_FOREVER,\n        memoize=False):\n    \"\"\"\n    Decorates functions that will be injected into other functions.\n\n    Decorator version of `add_injectable`. Name defaults to\n    name of function.\n\n    The function's argument names and keyword argument values\n    will be matched to registered variables when the function\n    needs to be evaluated by Orca.\n    The argument name \"iter_var\" may be used to have the current\n    iteration variable injected.\n\n    \"\"\"\n    def decorator(func):\n        if name:\n            n = name\n        else:\n            n = func.__name__\n        add_injectable(\n            n, func, autocall=autocall, cache=cache, cache_scope=cache_scope,\n            memoize=memoize)\n        return func\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting an injectable by name. Does not evaluate wrapped functions.", "response": "def get_injectable(name):\n    \"\"\"\n    Get an injectable by name. *Does not* evaluate wrapped functions.\n\n    Parameters\n    ----------\n    name : str\n\n    Returns\n    -------\n    injectable\n        Original value or evaluated value of an _InjectableFuncWrapper.\n\n    \"\"\"\n    i = get_raw_injectable(name)\n    return i() if isinstance(i, _InjectableFuncWrapper) else i"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn data about an injectable function s source including file name line number and source code.", "response": "def get_injectable_func_source_data(name):\n    \"\"\"\n    Return data about an injectable function's source, including file name,\n    line number, and source code.\n\n    Parameters\n    ----------\n    name : str\n\n    Returns\n    -------\n    filename : str\n    lineno : int\n        The line number on which the function starts.\n    source : str\n\n    \"\"\"\n    if injectable_type(name) != 'function':\n        raise ValueError('injectable {!r} is not a function'.format(name))\n\n    inj = get_raw_injectable(name)\n\n    if isinstance(inj, _InjectableFuncWrapper):\n        return utils.func_source_data(inj._func)\n    elif hasattr(inj, '__wrapped__'):\n        return utils.func_source_data(inj.__wrapped__)\n    else:\n        return utils.func_source_data(inj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a step function to the internal list of available steps.", "response": "def add_step(step_name, func):\n    \"\"\"\n    Add a step function to Orca.\n\n    The function's argument names and keyword argument values\n    will be matched to registered variables when the function\n    needs to be evaluated by Orca.\n    The argument name \"iter_var\" may be used to have the current\n    iteration variable injected.\n\n    Parameters\n    ----------\n    step_name : str\n    func : callable\n\n    \"\"\"\n    if isinstance(func, Callable):\n        logger.debug('registering step {!r}'.format(step_name))\n        _STEPS[step_name] = _StepFuncWrapper(step_name, func)\n    else:\n        raise TypeError('func must be a callable')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef step(step_name=None):\n    def decorator(func):\n        if step_name:\n            name = step_name\n        else:\n            name = func.__name__\n        add_step(name, func)\n        return func\n    return decorator", "response": "Decorator for adding a step to the Orca object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister a rule for merging two tables by broadcasting one onto another.", "response": "def broadcast(cast, onto, cast_on=None, onto_on=None,\n              cast_index=False, onto_index=False):\n    \"\"\"\n    Register a rule for merging two tables by broadcasting one onto\n    the other.\n\n    Parameters\n    ----------\n    cast, onto : str\n        Names of registered tables.\n    cast_on, onto_on : str, optional\n        Column names used for merge, equivalent of ``left_on``/``right_on``\n        parameters of pandas.merge.\n    cast_index, onto_index : bool, optional\n        Whether to use table indexes for merge. Equivalent of\n        ``left_index``/``right_index`` parameters of pandas.merge.\n\n    \"\"\"\n    logger.debug(\n        'registering broadcast of table {!r} onto {!r}'.format(cast, onto))\n    _BROADCASTS[(cast, onto)] = \\\n        Broadcast(cast, onto, cast_on, onto_on, cast_index, onto_index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the broadcasts associated with a set of tables.", "response": "def _get_broadcasts(tables):\n    \"\"\"\n    Get the broadcasts associated with a set of tables.\n\n    Parameters\n    ----------\n    tables : sequence of str\n        Table names for which broadcasts have been registered.\n\n    Returns\n    -------\n    casts : dict of `Broadcast`\n        Keys are tuples of strings like (cast_name, onto_name).\n\n    \"\"\"\n    tables = set(tables)\n    casts = tz.keyfilter(\n        lambda x: x[0] in tables and x[1] in tables, _BROADCASTS)\n    if tables - set(tz.concat(casts.keys())):\n        raise ValueError('Not enough links to merge all tables.')\n    return casts"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a single broadcast.", "response": "def get_broadcast(cast_name, onto_name):\n    \"\"\"\n    Get a single broadcast.\n\n    Broadcasts are stored data about how to do a Pandas join.\n    A Broadcast object is a namedtuple with these attributes:\n\n        - cast: the name of the table being broadcast\n        - onto: the name of the table onto which \"cast\" is broadcast\n        - cast_on: The optional name of a column on which to join.\n          None if the table index will be used instead.\n        - onto_on: The optional name of a column on which to join.\n          None if the table index will be used instead.\n        - cast_index: True if the table index should be used for the join.\n        - onto_index: True if the table index should be used for the join.\n\n    Parameters\n    ----------\n    cast_name : str\n        The name of the table being braodcast.\n    onto_name : str\n        The name of the table onto which `cast_name` is broadcast.\n\n    Returns\n    -------\n    broadcast : Broadcast\n\n    \"\"\"\n    if is_broadcast(cast_name, onto_name):\n        return _BROADCASTS[(cast_name, onto_name)]\n    else:\n        raise KeyError(\n            'no rule found for broadcasting {!r} onto {!r}'.format(\n                cast_name, onto_name))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _all_reachable_tables(t):\n    for k, v in t.items():\n        for tname in _all_reachable_tables(v):\n            yield tname\n        yield k", "response": "A generator that provides all the names of tables that can be merged by merges starting at the given target table."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndescend into a dict of dicts to return the one that contains a given key. Every value in the dict must be another dict.", "response": "def _recursive_getitem(d, key):\n    \"\"\"\n    Descend into a dict of dicts to return the one that contains\n    a given key. Every value in the dict must be another dict.\n\n    \"\"\"\n    if key in d:\n        return d\n    else:\n        for v in d.values():\n            return _recursive_getitem(v, key)\n        else:\n            raise KeyError('Key not found: {}'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _dict_value_to_pairs(d):\n    d = d[tz.first(d)]\n\n    for k, v in d.items():\n        yield {k: v}", "response": "Takes a dictionary and returns a series of key - value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef merge_tables(target, tables, columns=None, drop_intersection=True):\n    # allow target to be string or table wrapper\n    if isinstance(target, (DataFrameWrapper, TableFuncWrapper)):\n        target = target.name\n\n    # allow tables to be strings or table wrappers\n    tables = [get_table(t)\n              if not isinstance(t, (DataFrameWrapper, TableFuncWrapper)) else t\n              for t in tables]\n\n    merges = {t.name: {} for t in tables}\n    tables = {t.name: t for t in tables}\n    casts = _get_broadcasts(tables.keys())\n    logger.debug(\n        'attempting to merge tables {} to target table {}'.format(\n            tables.keys(), target))\n\n    # relate all the tables by registered broadcasts\n    for table, onto in casts:\n        merges[onto][table] = merges[table]\n    merges = {target: merges[target]}\n\n    # verify that all the tables can be merged to the target\n    all_tables = set(_all_reachable_tables(merges))\n\n    if all_tables != set(tables.keys()):\n        raise RuntimeError(\n            ('Not all tables can be merged to target \"{}\". Unlinked tables: {}'\n             ).format(target, list(set(tables.keys()) - all_tables)))\n\n    # add any columns necessary for indexing into other tables\n    # during merges\n    if columns:\n        columns = list(columns)\n        for c in casts.values():\n            if c.onto_on:\n                columns.append(c.onto_on)\n            if c.cast_on:\n                columns.append(c.cast_on)\n\n    # get column map for which columns go with which table\n    colmap = column_map(tables.values(), columns)\n\n    # get frames\n    frames = {name: t.to_frame(columns=colmap[name])\n              for name, t in tables.items()}\n\n    past_intersections = set()\n\n    # perform merges until there's only one table left\n    while merges[target]:\n        nm = _next_merge(merges)\n        onto = tz.first(nm)\n        onto_table = frames[onto]\n\n        # loop over all the tables that can be broadcast onto\n        # the onto_table and merge them all in.\n        for cast in nm[onto]:\n            cast_table = frames[cast]\n            bc = casts[(cast, onto)]\n\n            with log_start_finish(\n                    'merge tables {} and {}'.format(onto, cast), logger):\n\n                intersection = set(onto_table.columns).\\\n                    intersection(cast_table.columns)\n                # intersection is ok if it's the join key\n                intersection.discard(bc.onto_on)\n                intersection.discard(bc.cast_on)\n                # otherwise drop so as not to create conflicts\n                if drop_intersection:\n                    cast_table = cast_table.drop(intersection, axis=1)\n                else:\n                    # add suffix to past intersections which wouldn't get\n                    # picked up by the merge - these we have to rename by hand\n                    renames = dict(zip(\n                        past_intersections,\n                        [c+'_'+onto for c in past_intersections]\n                    ))\n                    onto_table = onto_table.rename(columns=renames)\n\n                # keep track of past intersections in case there's an odd\n                # number of intersections\n                past_intersections = past_intersections.union(intersection)\n\n                onto_table = pd.merge(\n                    onto_table, cast_table,\n                    suffixes=['_'+onto, '_'+cast],\n                    left_on=bc.onto_on, right_on=bc.cast_on,\n                    left_index=bc.onto_index, right_index=bc.cast_index)\n\n        # replace the existing table with the merged one\n        frames[onto] = onto_table\n\n        # free up space by dropping the cast table\n        del frames[cast]\n\n        # mark the onto table as having no more things to broadcast\n        # onto it.\n        _recursive_getitem(merges, onto)[onto] = {}\n\n    logger.debug('finished merge')\n    return frames[target]", "response": "Returns a new DataFrame containing the merged tables."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of table names injected into the provided steps.", "response": "def get_step_table_names(steps):\n    \"\"\"\n    Returns a list of table names injected into the provided steps.\n\n    Parameters\n    ----------\n    steps: list of str\n        Steps to gather table inputs from.\n\n    Returns\n    -------\n    list of str\n\n    \"\"\"\n    table_names = set()\n    for s in steps:\n        table_names |= get_step(s)._tables_used()\n    return list(table_names)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_tables(fname, table_names=None, prefix=None, compress=False, local=False):\n    if table_names is None:\n        table_names = list_tables()\n\n    tables = (get_table(t) for t in table_names)\n    key_template = '{}/{{}}'.format(prefix) if prefix is not None else '{}'\n\n    # set compression options to zlib level-1 if compress arg is True\n    complib = compress and 'zlib' or None\n    complevel = compress and 1 or 0\n\n    with pd.HDFStore(fname, mode='a', complib=complib, complevel=complevel) as store:\n        for t in tables:\n            # if local arg is True, store only local columns\n            columns = None\n            if local is True:\n                columns = t.local_columns\n            store[key_template.format(t.name)] = t.to_frame(columns=columns)", "response": "Writes tables to a pandas. HDFStore file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning a series of steps in series.", "response": "def run(steps, iter_vars=None, data_out=None, out_interval=1,\n        out_base_tables=None, out_run_tables=None, compress=False,\n        out_base_local=True, out_run_local=True):\n    \"\"\"\n    Run steps in series, optionally repeatedly over some sequence.\n    The current iteration variable is set as a global injectable\n    called ``iter_var``.\n\n    Parameters\n    ----------\n    steps : list of str\n        List of steps to run identified by their name.\n    iter_vars : iterable, optional\n        The values of `iter_vars` will be made available as an injectable\n        called ``iter_var`` when repeatedly running `steps`.\n    data_out : str, optional\n        An optional filename to which all tables injected into any step\n        in `steps` will be saved every `out_interval` iterations.\n        File will be a pandas HDF data store.\n    out_interval : int, optional\n        Iteration interval on which to save data to `data_out`. For example,\n        2 will save out every 2 iterations, 5 every 5 iterations.\n        Default is every iteration.\n        The results of the first and last iterations are always included.\n        The input (base) tables are also included and prefixed with `base/`,\n        these represent the state of the system before any steps have been\n        executed.\n        The interval is defined relative to the first iteration. For example,\n        a run begining in 2015 with an out_interval of 2, will write out\n        results for 2015, 2017, etc.\n    out_base_tables: list of str, optional, default None\n        List of base tables to write. If not provided, tables injected\n        into 'steps' will be written.\n    out_run_tables: list of str, optional, default None\n        List of run tables to write. If not provided, tables injected\n        into 'steps' will be written.\n    compress: boolean, optional, default False\n        Whether to compress output file using standard HDF5 zlib compression.\n        Compression yields much smaller files using slightly more CPU.\n    out_base_local: boolean, optional, default True\n        For tables in out_base_tables, whether to store only local columns (True)\n        or both, local and computed columns (False).\n    out_run_local: boolean, optional, default True\n        For tables in out_run_tables, whether to store only local columns (True)\n        or both, local and computed columns (False).\n    \"\"\"\n    iter_vars = iter_vars or [None]\n    max_i = len(iter_vars)\n\n    # get the tables to write out\n    if out_base_tables is None or out_run_tables is None:\n        step_tables = get_step_table_names(steps)\n\n        if out_base_tables is None:\n            out_base_tables = step_tables\n\n        if out_run_tables is None:\n            out_run_tables = step_tables\n\n    # write out the base (inputs)\n    if data_out:\n        add_injectable('iter_var', iter_vars[0])\n        write_tables(data_out, out_base_tables, 'base', compress=compress, local=out_base_local)\n\n    # run the steps\n    for i, var in enumerate(iter_vars, start=1):\n        add_injectable('iter_var', var)\n\n        if var is not None:\n            print('Running iteration {} with iteration value {!r}'.format(\n                i, var))\n            logger.debug(\n                'running iteration {} with iteration value {!r}'.format(\n                    i, var))\n\n        t1 = time.time()\n        for j, step_name in enumerate(steps):\n            add_injectable('iter_step', iter_step(j, step_name))\n            print('Running step {!r}'.format(step_name))\n            with log_start_finish(\n                    'run step {!r}'.format(step_name), logger,\n                    logging.INFO):\n                step = get_step(step_name)\n                t2 = time.time()\n                step()\n                print(\"Time to execute step '{}': {:.2f} s\".format(\n                      step_name, time.time() - t2))\n            clear_cache(scope=_CS_STEP)\n\n        print(\n            ('Total time to execute iteration {} '\n             'with iteration value {!r}: '\n             '{:.2f} s').format(i, var, time.time() - t1))\n\n        # write out the results for the current iteration\n        if data_out:\n            if (i - 1) % out_interval == 0 or i == max_i:\n                write_tables(data_out, out_run_tables, var, compress=compress, local=out_run_local)\n\n        clear_cache(scope=_CS_ITER)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_variable(name, **kwargs):\n    with injectables(**kwargs):\n        vars = _collect_variables([name], [name])\n        return vars[name]", "response": "Execute a single variable function registered with Orca\n    and return the result."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a DataFrame with the given columns.", "response": "def to_frame(self, columns=None):\n        \"\"\"\n        Make a DataFrame with the given columns.\n\n        Will always return a copy of the underlying table.\n\n        Parameters\n        ----------\n        columns : sequence or string, optional\n            Sequence of the column names desired in the DataFrame. A string\n            can also be passed if only one column is desired.\n            If None all columns are returned, including registered columns.\n\n        Returns\n        -------\n        frame : pandas.DataFrame\n\n        \"\"\"\n        extra_cols = _columns_for_table(self.name)\n\n        if columns is not None:\n            columns = [columns] if isinstance(columns, str) else columns\n            columns = set(columns)\n            set_extra_cols = set(extra_cols)\n            local_cols = set(self.local.columns) & columns - set_extra_cols\n            df = self.local[list(local_cols)].copy()\n            extra_cols = {k: extra_cols[k] for k in (columns & set_extra_cols)}\n        else:\n            df = self.local.copy()\n\n        with log_start_finish(\n                'computing {!r} columns for table {!r}'.format(\n                    len(extra_cols), self.name),\n                logger):\n            for name, col in extra_cols.items():\n                with log_start_finish(\n                        'computing column {!r} for table {!r}'.format(\n                            name, self.name),\n                        logger):\n                    df[name] = col()\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd or replace a column in the underlying DataFrame.", "response": "def update_col(self, column_name, series):\n        \"\"\"\n        Add or replace a column in the underlying DataFrame.\n\n        Parameters\n        ----------\n        column_name : str\n            Column to add or replace.\n        series : pandas.Series or sequence\n            Column data.\n\n        \"\"\"\n        logger.debug('updating column {!r} in table {!r}'.format(\n            column_name, self.name))\n        self.local[column_name] = series"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a column as a Series.", "response": "def get_column(self, column_name):\n        \"\"\"\n        Returns a column as a Series.\n\n        Parameters\n        ----------\n        column_name : str\n\n        Returns\n        -------\n        column : pandas.Series\n\n        \"\"\"\n        with log_start_finish(\n                'getting single column {!r} from table {!r}'.format(\n                    column_name, self.name),\n                logger):\n            extra_cols = _columns_for_table(self.name)\n            if column_name in extra_cols:\n                with log_start_finish(\n                        'computing column {!r} for table {!r}'.format(\n                            column_name, self.name),\n                        logger):\n                    column = extra_cols[column_name]()\n            else:\n                column = self.local[column_name]\n            if self.copy_col:\n                return column.copy()\n            else:\n                return column"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef column_type(self, column_name):\n        extra_cols = list_columns_for_table(self.name)\n\n        if column_name in extra_cols:\n            col = _COLUMNS[(self.name, column_name)]\n\n            if isinstance(col, _SeriesWrapper):\n                return 'series'\n            elif isinstance(col, _ColumnFuncWrapper):\n                return 'function'\n\n        elif column_name in self.local_columns:\n            return 'local'\n\n        raise KeyError('column {!r} not found'.format(column_name))", "response": "Report column type as one of local series or function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_col_from_series(self, column_name, series, cast=False):\n        logger.debug('updating column {!r} in table {!r}'.format(\n            column_name, self.name))\n\n        col_dtype = self.local[column_name].dtype\n        if series.dtype != col_dtype:\n            if cast:\n                series = series.astype(col_dtype)\n            else:\n                err_msg = \"Data type mismatch, existing:{}, update:{}\"\n                err_msg = err_msg.format(col_dtype, series.dtype)\n                raise ValueError(err_msg)\n\n        self.local.loc[series.index, column_name] = series", "response": "Update existing values in a column from another series."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear_cached(self):\n        _TABLE_CACHE.pop(self.name, None)\n        for col in _columns_for_table(self.name).values():\n            col.clear_cached()\n        logger.debug('cleared cached columns for table {!r}'.format(self.name))", "response": "Remove cached results from this table s computed columns."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef local_columns(self):\n        if self._columns:\n            return self._columns\n        else:\n            self._call_func()\n            return self._columns", "response": "Returns a list of columns that are local."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _call_func(self):\n        if _CACHING and self.cache and self.name in _TABLE_CACHE:\n            logger.debug('returning table {!r} from cache'.format(self.name))\n            return _TABLE_CACHE[self.name].value\n\n        with log_start_finish(\n                'call function to get frame for table {!r}'.format(\n                    self.name),\n                logger):\n            kwargs = _collect_variables(names=self._argspec.args,\n                                        expressions=self._argspec.defaults)\n            frame = self._func(**kwargs)\n\n        self._columns = list(frame.columns)\n        self._index = frame.index\n        self._len = len(frame)\n\n        wrapped = DataFrameWrapper(self.name, frame, copy_col=self.copy_col)\n\n        if self.cache:\n            _TABLE_CACHE[self.name] = CacheItem(\n                self.name, wrapped, self.cache_scope)\n\n        return wrapped", "response": "Call the wrapped function and return the result wrapped by DataFrameWrapper."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_column(self, column_name):\n        frame = self._call_func()\n        return DataFrameWrapper(self.name, frame,\n                                copy_col=self.copy_col).get_column(column_name)", "response": "Returns a column as a Series."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clear_cached(self):\n        x = _COLUMN_CACHE.pop((self.table_name, self.name), None)\n        if x is not None:\n            logger.debug(\n                'cleared cached value for column {!r} in table {!r}'.format(\n                    self.name, self.table_name))", "response": "Remove any cached result of this column."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clear_cached(self):\n        x = _INJECTABLE_CACHE.pop(self.name, None)\n        if x:\n            logger.debug(\n                'injectable {!r} removed from cache'.format(self.name))", "response": "Clear a cached result for this injectable."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _tables_used(self):\n        args = list(self._argspec.args)\n        if self._argspec.defaults:\n            default_args = list(self._argspec.defaults)\n        else:\n            default_args = []\n        # Combine names from argument names and argument default values.\n        names = args[:len(args) - len(default_args)] + default_args\n        tables = set()\n        for name in names:\n            parent_name = name.split('.')[0]\n            if is_table(parent_name):\n                tables.add(parent_name)\n        return tables", "response": "Returns a set of tables that are used in the step."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a graph and a list of nodes to explore and an optinal root return a tree of nodes.", "response": "def qbe_tree(graph, nodes, root=None):\n    \"\"\"\n    Given a graph, nodes to explore and an optinal root, do a breadth-first\n    search in order to return the tree.\n    \"\"\"\n    if root:\n        start = root\n    else:\n        index = random.randint(0, len(nodes) - 1)\n        start = nodes[index]\n    # A queue to BFS instead DFS\n    to_visit = deque()\n    cnodes = copy(nodes)\n    visited = set()\n    # Format is (parent, parent_edge, neighbor, neighbor_field)\n    to_visit.append((None, None, start, None))\n    tree = {}\n    while len(to_visit) != 0 and nodes:\n        parent, parent_edge, v, v_edge = to_visit.pop()\n        # Prune\n        if v in nodes:\n            nodes.remove(v)\n        node = graph[v]\n        if v not in visited and len(node) > 1:\n            visited.add(v)\n            # Preorder process\n            if all((parent, parent_edge, v, v_edge)):\n                if parent not in tree:\n                    tree[parent] = []\n                if (parent_edge, v, v_edge) not in tree[parent]:\n                    tree[parent].append((parent_edge, v, v_edge))\n                if v not in tree:\n                    tree[v] = []\n                if (v_edge, parent, parent_edge) not in tree[v]:\n                    tree[v].append((v_edge, parent, parent_edge))\n            # Iteration\n            for node_edge, neighbor, neighbor_edge in node:\n                value = (v, node_edge, neighbor, neighbor_edge)\n                to_visit.append(value)\n    remove_leafs(tree, cnodes)\n    return tree, (len(nodes) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef combine(items, k=None):\n    length_items = len(items)\n    lengths = [len(i) for i in items]\n    length = reduce(lambda x, y: x * y, lengths)\n    repeats = [reduce(lambda x, y: x * y, lengths[i:])\n               for i in range(1, length_items)] + [1]\n    if k is not None:\n        k = k % length\n        # Python division by default is integer division (~ floor(a/b))\n        indices = [old_div((k % (lengths[i] * repeats[i])), repeats[i])\n                   for i in range(length_items)]\n        return [items[i][indices[i]] for i in range(length_items)]\n    else:\n        matrix = []\n        for i, item in enumerate(items):\n            row = []\n            for subset in item:\n                row.extend([subset] * repeats[i])\n            times = old_div(length, len(row))\n            matrix.append(row * times)\n        # Transpose the matrix or return the columns instead rows\n        return list(zip(*matrix))", "response": "Create a matrix in wich each row is a tuple containing one of solutions or\n    solution k - esima."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the given session dictionary pickled and encoded as a string.", "response": "def pickle_encode(session_dict):\n    \"Returns the given session dictionary pickled and encoded as a string.\"\n    pickled = pickle.dumps(session_dict, pickle.HIGHEST_PROTOCOL)\n    return base64.encodestring(pickled + get_query_hash(pickled).encode())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef func_source_data(func):\n    filename = inspect.getsourcefile(func)\n    lineno = inspect.getsourcelines(func)[1]\n    source = inspect.getsource(func)\n\n    return filename, lineno, source", "response": "Return data about a function source including file name line number and source code."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(self):\n        if any(self.errors):\n            # Don't bother validating the formset unless each form is valid on\n            # its own\n            return\n        (selects, aliases, froms, wheres, sorts, groups_by,\n         params) = self.get_query_parts()\n        if not selects:\n            validation_message = _(u\"At least you must check a row to get.\")\n            raise forms.ValidationError(validation_message)\n        self._selects = selects\n        self._aliases = aliases\n        self._froms = froms\n        self._wheres = wheres\n        self._sorts = sorts\n        self._groups_by = groups_by\n        self._params = params", "response": "Checks that there is almost one field to select\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_query_parts(self):\n        selects = []\n        aliases = []\n        froms = []\n        wheres = []\n        sorts = []\n        groups_by = []\n        params = []\n        app_model_labels = None\n        lookup_cast = self._db_operations.lookup_cast\n        qn = self._db_operations.quote_name\n        uqn = self._unquote_name\n        for data in self.cleaned_data:\n            if not (\"model\" in data and \"field\" in data):\n                break\n            model = data[\"model\"]\n            # HACK: Workaround to handle tables created\n            #       by django for its own\n            if not app_model_labels:\n                app_models = get_models(include_auto_created=True,\n                                        include_deferred=True)\n                app_model_labels = [u\"%s_%s\" % (a._meta.app_label,\n                                                a._meta.model_name)\n                                    for a in app_models]\n            if model in app_model_labels:\n                position = app_model_labels.index(model)\n                model = app_models[position]._meta.db_table\n                self._models[model] = app_models[position]\n            field = data[\"field\"]\n            show = data[\"show\"]\n            alias = data[\"alias\"]\n            criteria = data[\"criteria\"]\n            sort = data[\"sort\"]\n            group_by = data[\"group_by\"]\n            operator, over = criteria\n            olower = operator.lower()\n            if 'contains' in olower:\n                over = '%' + over + '%'\n            elif 'endswith' in olower:\n                over = '%' + over\n            elif 'startswith' in olower:\n                over = over + '%'\n\n            is_join = operator.lower() == 'join'\n            db_field = self.get_db_field(model, field, qn, is_join=is_join)\n            if show and not is_join:\n                selects.append(db_field)\n            if alias is not None and not is_join:\n                aliases.append(alias)\n            if sort:\n                sorts.append(db_field + ('' if sort == 'asc' else ' DESC'))\n            if group_by:\n                groups_by.append(db_field)\n            if all(criteria):\n                if is_join:\n                    over_split = over.lower().rsplit(\".\", 1)\n                    join_model = qn(over_split[0].replace(\".\", \"_\"))\n                    join_field = qn(over_split[1])\n                    join = u\"%s.%s = %s\" % (join_model, join_field, db_field)\n                    if (join not in wheres\n                            and uqn(join_model) in self._db_table_names):\n                        wheres.append(join)\n                        if join_model not in froms:\n                            froms.append(join_model)\n                    # join_select = u\"%s.%s\" % (join_model, join_field)\n                    # if join_select not in selects:\n                    #     selects.append(join_select)\n                elif operator in self._db_operators:\n                    # db_operator = self._db_operators[operator] % over\n                    db_operator = self._db_operators[operator]\n                    lookup = self._get_lookup(operator, over)\n                    params.append(lookup)\n                    wheres.append(u\"%s %s\"\n                                  % (lookup_cast(operator) % db_field,\n                                     db_operator))\n                elif operator in self._custom_operators:\n                    CustOperator = self._custom_operators[operator]\n                    custom_operator = CustOperator(db_field, operator, over)\n\n                    # make sure the operators params are iterable:\n                    custom_params = custom_operator.get_params()\n                    if isinstance(custom_params, collections.Iterable):\n                        params += custom_params\n                    else:\n                        params += [custom_params, ]\n\n                    # make sure the operators wheres are iterable:\n                    custom_wheres = custom_operator.get_wheres()\n                    if isinstance(custom_wheres, collections.Iterable):\n                        wheres += custom_wheres\n                    else:\n                        wheres += [custom_wheres, ]\n\n            if qn(model) not in froms and model in self._db_table_names:\n                froms.append(qn(model))\n        return selects, aliases, froms, wheres, sorts, groups_by, params", "response": "Return a list of SQL query parts for the cleaned data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfetch all results after perform SQL query and return them as a list of lists.", "response": "def get_results(self, limit=None, offset=None, query=None, admin_name=None,\n                    row_number=False):\n        \"\"\"\n        Fetch all results after perform SQL query and\n        \"\"\"\n        add_extra_ids = (admin_name is not None)\n        if not query:\n            sql = self.get_raw_query(limit=limit, offset=offset,\n                                     add_extra_ids=add_extra_ids)\n        else:\n            sql = query\n        if settings.DEBUG:\n            print(sql)\n        cursor = self._db_connection.cursor()\n        cursor.execute(sql, tuple(self._params))\n        query_results = cursor.fetchall()\n        if admin_name and not self._groups_by:\n            selects = self._get_selects_with_extra_ids()\n            results = []\n            try:\n                offset = int(offset)\n            except ValueError:\n                offset = 0\n            for r, row in enumerate(query_results):\n                i = 0\n                l = len(row)\n                if row_number:\n                    result = [(r + offset + 1, u\"#row%s\" % (r + offset + 1))]\n                else:\n                    result = []\n                while i < l:\n                    appmodel, field = selects[i].split(\".\")\n                    appmodel = self._unquote_name(appmodel)\n                    field = self._unquote_name(field)\n                    try:\n                        if appmodel in self._models:\n                            _model = self._models[appmodel]\n                            _appmodel = u\"%s_%s\" % (_model._meta.app_label,\n                                                    _model._meta.model_name)\n                        else:\n                            _appmodel = appmodel\n                        admin_url = reverse(\"%s:%s_change\" % (\n                            admin_name,\n                            _appmodel),\n                            args=[row[i + 1]]\n                        )\n                    except NoReverseMatch:\n                        admin_url = None\n                    result.append((row[i], admin_url))\n                    i += 2\n                results.append(result)\n            return results\n        else:\n            if row_number:\n                results = []\n                for r, row in enumerate(query_results):\n                    result = [r + 1]\n                    for cell in row:\n                        result.append(cell)\n                    results.append(result)\n                return results\n            else:\n                return query_results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses a content type and charset.", "response": "def parse_content_type(content_type):\n    \"\"\"\n    Return a tuple of content type and charset.\n\n    :param content_type: A string describing a content type.\n    \"\"\"\n    if '; charset=' in content_type:\n        return tuple(content_type.split('; charset='))\n    else:\n        if 'text' in content_type:\n            encoding = 'ISO-8859-1'\n        else:\n            try:\n                format = formats.find_by_content_type(content_type)\n            except formats.UnknownFormat:\n                encoding = 'ISO-8859-1'\n            else:\n                encoding = format.default_encoding or 'ISO-8859-1'\n\n        return (content_type, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the HTTP Accept header and return a list of content types listed in the HTTP Accept header ordered by quality.", "response": "def parse_http_accept_header(header):\n    \"\"\"\n    Return a list of content types listed in the HTTP Accept header\n    ordered by quality.\n\n    :param header: A string describing the contents of the HTTP Accept header.\n    \"\"\"\n    components = [item.strip() for item in header.split(',')]\n\n    l = []\n    for component in components:\n        if ';' in component:\n            subcomponents = [item.strip() for item in component.split(';')]\n            l.append(\n                (\n                    subcomponents[0], # eg. 'text/html'\n                    subcomponents[1][2:] # eg. 'q=0.9'\n                )\n            )\n        else:\n            l.append((component, '1'))\n\n    l.sort(\n        key = lambda i: i[1],\n        reverse = True\n    )\n\n    content_types = []\n    for i in l:\n        content_types.append(i[0])\n\n    return content_types"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a request with multipart data.", "response": "def parse_multipart_data(request):\n    \"\"\"\n    Parse a request with multipart data.\n\n    :param request: A HttpRequest instance.\n    \"\"\"\n    return MultiPartParser(\n        META=request.META,\n        input_data=StringIO(request.body),\n        upload_handlers=request.upload_handlers,\n        encoding=request.encoding\n    ).parse()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resource(views, routes, prefix=''):\n    routes = deepcopy(routes)\n\n    def dispatch(request, GET=False, POST=False, PUT=False, DELETE=False, PATCH=False, **kwargs):\n        \"\"\"\n        Dispatch the request according to the request method and the string contained in\n        the corresponding keyword argument.\n\n        For example, if the request method is HTTP GET and the 'GET' argument to this function is\n        set to 'index', the 'index' function of the views class will be invoked and returned.\n\n        Arguments:\n        :param request: A django.http.HttpRequest object.\n        :param GET: A string describing the function to delegate the request to on HTTP GET.\n        :param POST: A string describing the function to delegate the request to on HTTP POST.\n        :param PUT: A string describing the function to delegate the request to on HTTP PUT.\n        :param DELETE: A string describing the function to delegate the request to on HTTP DELETE.\n        :param PATCH: A string describing the function to delegate the request to on HTTP PATCH.\n        \"\"\"\n\n        # Return HTTP 405 Method Not Allowed if the request method isn't routed\n        if request.method == 'GET' and not GET \\\n        or request.method == 'POST' and not POST \\\n        or request.method == 'PUT' and not PUT \\\n        or request.method == 'DELETE' and not DELETE \\\n        or request.method == 'PATCH' and not PATCH \\\n        or request.method not in ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS', 'HEAD']:\n            allowed_methods = []\n\n            if GET:\n                allowed_methods.append('GET')\n            if POST:\n                allowed_methods.append('POST')\n            if PUT:\n                allowed_methods.append('PUT')\n            if DELETE:\n                allowed_methods.append('DELETE')\n\n            response = HttpResponse()\n            response.status_code = 405\n            response['Allow'] = ', '.join(allowed_methods)\n            return response\n\n        # Dispatch the request\n        if request.method in ['GET', 'HEAD']:\n            return getattr(views(), GET)(request, **kwargs)\n        if request.method == 'POST':\n            return getattr(views(), POST)(request, **kwargs)\n        if request.method == 'PUT':\n            return getattr(views(), PUT)(request, **kwargs)\n        if request.method == 'DELETE':\n            return getattr(views(), DELETE)(request, **kwargs)\n        if request.method == 'PATCH':\n            return getattr(views(), PATCH)(request, **kwargs)\n        if request.method == 'OPTIONS':\n            map = {}\n\n            if GET:\n                map['GET'] = getattr(views(), GET)\n            if POST:\n                map['POST'] = getattr(views(), POST)\n            if PUT:\n                map['PUT'] = getattr(views(), PUT)\n            if DELETE:\n                map['DELETE'] = getattr(views(), DELETE)\n\n            return views().options(request, map, **kwargs)\n\n    def urlify(routes):\n        \"\"\"\n        Transform routes into urlpatterns.\n\n        Arguments:\n        :param routes: A list of routes.\n        \"\"\"\n        urls = []\n\n        # Route regular expressions and names may be lambdas; expand them.\n        for i, route in enumerate(routes):\n            if callable(route.regex):\n                routes[i].regex = route.regex(prefix)\n            else:\n                routes[i].regex = string_concat('^', prefix, route.regex)\n\n            if callable(route.name):\n                routes[i].name = route.name(views)\n\n        for route in list(routes):\n            # Collect this route and its siblings (i.e. routes that share\n            # same regular expression) in a dictionary of keys that describe\n            # HTTP methods and values that describe the corresponding\n            # view function.\n            #\n            # Example:\n            #\n            # {\n            #   'GET': 'index',\n            #   'POST': 'create'\n            # }\n            kwargs = {}\n            for sibling in list(routes):\n                if sibling.regex == route.regex:\n                    kwargs[sibling.method] = sibling.view\n                    routes.remove(sibling)\n\n            urls.append(\n                url(\n                    regex = route.regex,\n                    view = dispatch,\n                    kwargs = kwargs,\n                    name = route.name\n                )\n            )\n\n        return urls\n\n    return urlify(routes)", "response": "A function that dispatches the request to the views class and routes class."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef override_supported_formats(formats):\n    def decorator(function):\n        @wraps(function)\n        def wrapper(self, *args, **kwargs):\n            self.supported_formats = formats\n            return function(self, *args, **kwargs)\n        return wrapper\n    return decorator", "response": "Decorator to override the views class supported formats for the decorated function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nroute the decorated view. :param regex: A string describing a regular expression to which the request path will be matched. :param method: A string describing the HTTP method that this view accepts. :param name: A string describing the name of the URL pattern. ``regex`` may also be a lambda that accepts the parent resource's ``prefix`` argument and returns a string describing a regular expression to which the request path will be matched. ``name`` may also be a lambda that accepts the parent resource's ``views`` argument and returns a string describing the name of the URL pattern.", "response": "def route(regex, method, name):\n    \"\"\"\n    Route the decorated view.\n\n    :param regex: A string describing a regular expression to which the request path will be matched.\n    :param method: A string describing the HTTP method that this view accepts.\n    :param name: A string describing the name of the URL pattern.\n    \n    ``regex`` may also be a lambda that accepts the parent resource's ``prefix`` argument and returns\n    a string describing a regular expression to which the request path will be matched.\n    \n    ``name`` may also be a lambda that accepts the parent resource's ``views`` argument and returns\n    a string describing the name of the URL pattern.\n    \"\"\"\n\n    def decorator(function):\n        function.route = routes.route(\n            regex = regex,\n            view = function.__name__,\n            method = method,\n            name = name\n        )\n\n        @wraps(function)\n        def wrapper(self, *args, **kwargs):\n            return function(self, *args, **kwargs)\n        return wrapper\n\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the given method prior to the decorated view.", "response": "def before(method_name):\n    \"\"\"\n    Run the given method prior to the decorated view.\n\n    If you return anything besides ``None`` from the given method,\n    its return values will replace the arguments of the decorated\n    view.\n\n    If you return an instance of ``HttpResponse`` from the given method,\n    Respite will return it immediately without delegating the request to the\n    decorated view.\n\n    Example usage::\n\n        class ArticleViews(Views):\n\n            @before('_load')\n            def show(self, request, article):\n                return self._render(\n                    request = request,\n                    template = 'show',\n                    context = {\n                        'article': article\n                    }\n                )\n\n            def _load(self, request, id):\n                try:\n                    return request, Article.objects.get(id=id)\n                except Article.DoesNotExist:\n                    return self._error(request, 404, message='The article could not be found.')\n\n    :param method: A string describing a class method.\n    \"\"\"\n    def decorator(function):\n        @wraps(function)\n        def wrapper(self, *args, **kwargs):\n            returns = getattr(self, method_name)(*args, **kwargs)\n\n            if returns is None:\n                return function(self, *args, **kwargs)\n            else:\n                if isinstance(returns, HttpResponse):\n                    return returns\n                else:\n                    return function(self, *returns)\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index(self, request):\n        objects = self.model.objects.all()\n\n        return self._render(\n            request = request,\n            template = 'index',\n            context = {\n                cc2us(pluralize(self.model.__name__)): objects,\n            },\n            status = 200\n        )", "response": "Render a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering a form to create a new object.", "response": "def new(self, request):\n        \"\"\"Render a form to create a new object.\"\"\"\n        form = (self.form or generate_form(self.model))()\n\n        return self._render(\n            request = request,\n            template = 'new',\n            context = {\n                'form': form\n            },\n            status = 200\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new object.", "response": "def create(self, request):\n        \"\"\"Create a new object.\"\"\"\n        form = (self.form or generate_form(self.model))(request.POST)\n\n        if form.is_valid():\n            object = form.save()\n\n            return self._render(\n                request = request,\n                template = 'show',\n                context = {\n                    cc2us(self.model.__name__): object\n                },\n                status = 201\n            )\n        else:\n            return self._render(\n                request = request,\n                template = 'new',\n                context = {\n                    'form': form\n                },\n                status = 400\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a form to edit an object.", "response": "def edit(self, request, id):\n        \"\"\"Render a form to edit an object.\"\"\"\n        try:\n            object = self.model.objects.get(id=id)\n        except self.model.DoesNotExist:\n            return self._render(\n                request = request,\n                template = '404',\n                context = {\n                    'error': 'The %s could not be found.' % self.model.__name__.lower()\n                },\n                status = 404,\n                prefix_template_path = False\n            )\n\n        form = (self.form or generate_form(self.model))(instance=object)\n\n        # Add \"_method\" field to override request method to PUT\n        form.fields['_method'] = CharField(required=True, initial='PUT', widget=HiddenInput)\n\n        return self._render(\n            request = request,\n            template = 'edit',\n            context = {\n                cc2us(self.model.__name__): object,\n                'form': form\n            },\n            status = 200\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbuilding a Q object from filters config and actual parmeters.", "response": "def build_q(fields_dict, params_dict, request=None):\n    \"\"\"\n    Returns a Q object from filters config and actual parmeters.\n    \"\"\"\n    # Building search query\n    # queries generated by different search_fields are ANDed\n    # if a search field is defined for more than one field, are put together with OR\n    and_query = Q()\n\n    for fieldname in fields_dict:\n        search_field = fields_dict[fieldname]\n        if fieldname in params_dict and params_dict[fieldname] != '' and params_dict[fieldname] != []:\n            or_query = None\n\n            if type(search_field) == type(list()):\n                field_list = search_field\n                search_operator = \"__icontains\"\n                fixed_filters = None\n                multiple_values = False\n                custom_query_method = None\n                value_mapper = None\n\n            else: # dictionary of field definitions\n                if search_field.get('ignore', False):\n                    continue\n\n                field_list = search_field['fields']\n                search_operator = search_field.get('operator', None)\n                fixed_filters = search_field.get('fixed_filters', None)\n                multiple_values = search_field.get('multiple', False)\n                custom_query_method =  search_field.get('custom_query', None)\n                value_mapper =  search_field.get('value_mapper', None)\n\n            for model_field in field_list:\n\n                if multiple_values:\n                    if hasattr(params_dict, \"getlist\"):\n                        request_field_value = params_dict.getlist(fieldname)\n                    elif type(params_dict[fieldname]) == list:\n                        request_field_value = params_dict[fieldname]\n                    else:\n                        request_field_value = [params_dict[fieldname]]\n                    if value_mapper:\n                        request_field_value = [value_mapper(value) for value in request_field_value]\n                else:\n                    request_field_value = params_dict[fieldname] if not value_mapper else value_mapper(params_dict[fieldname])\n\n                if not custom_query_method:\n                    fieldname_key = model_field + search_operator\n                    filter_dict = { fieldname_key : request_field_value}\n                    if not or_query:\n                        or_query = Q(**filter_dict)\n                    else:\n                        or_query = or_query | Q(**filter_dict)\n                else:\n                    #TODO: this is a hack for using request data in custom_query\n                    #it would be better to pass ALSO the request to custom_query_method\n                    if not request:\n                        cf = custom_query_method(model_field, request_field_value, params_dict)\n                    else:\n                        cf = custom_query_method(model_field, request_field_value, request)\n\n                    if not or_query:\n                        or_query = cf\n                    else:\n                        or_query = or_query | cf\n\n            #fixed_filters\n            fixed_filters_q = Q()\n            #fixed_filters must return a Q object or None\n            if fixed_filters:\n                if callable(fixed_filters):\n                    fixed_filters_q = fixed_filters(params_dict)\n                elif type(fixed_filters) is dict:\n                    fixed_filters_q = Q(**fixed_filters)\n\n            and_query = and_query & or_query\n            and_query = and_query & fixed_filters_q\n\n\n    return and_query"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_search_fields(cls):\n        sfdict = {}\n        for klass in tuple(cls.__bases__) + (cls, ):\n            if hasattr(klass, 'search_fields'):\n                sfdict.update(klass.search_fields)\n        return sfdict", "response": "Returns a dictionary of search fields in the class."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfinds and return a format by name acronym or extension.", "response": "def find(identifier):\n    \"\"\"\n    Find and return a format by name, acronym or extension.\n\n    :param identifier: A string describing the format.\n    \"\"\"\n    for format in FORMATS:\n        if identifier in [format.name, format.acronym, format.extension]:\n            return format\n\n    raise UnknownFormat('No format found with name, acronym or extension \"%s\"' % identifier)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_by_name(name):\n    for format in FORMATS:\n        if name == format.name:\n            return format\n\n    raise UnknownFormat('No format found with name \"%s\"' % name)", "response": "Find and return a format by name."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding and return a format by extension.", "response": "def find_by_extension(extension):\n    \"\"\"\n    Find and return a format by extension.\n\n    :param extension: A string describing the extension of the format.\n    \"\"\"\n    for format in FORMATS:\n        if extension in format.extensions:\n            return format\n\n    raise UnknownFormat('No format found with extension \"%s\"' % extension)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding and return a format by content type.", "response": "def find_by_content_type(content_type):\n    \"\"\"\n    Find and return a format by content type.\n\n    :param content_type: A string describing the internet media type of the format.\n    \"\"\"\n    for format in FORMATS:\n        if content_type in format.content_types:\n            return format\n\n    raise UnknownFormat('No format found with content type \"%s\"' % content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_format(self, request):\n\n        # Derive a list of 'formats.Format' instances from the list of formats these views support.\n        supported_formats = [formats.find(format) for format in self.supported_formats]\n\n        # Determine format by extension...\n        if '.' in request.path:\n            extension = request.path.split('.')[-1]\n\n            try:\n                format = formats.find_by_extension(extension)\n            except formats.UnknownFormat:\n                return None\n\n            if format in supported_formats:\n                return format\n            else:\n                return None\n\n        # Determine format by HTTP Accept header...\n        if 'HTTP_ACCEPT' in request.META:\n            content_types = parse_http_accept_header(request.META['HTTP_ACCEPT'])\n\n            # Only consider 'accept' headers with a single format in an attempt to play nice\n            # with browsers that ask for formats they really should not want.\n            if len(content_types) == 1:\n                content_type = content_types[0]\n\n                # If the request has no preference as to the format of its response, prefer the\n                # first of the view's supported formats.\n                if content_type == '*/*':\n                    return supported_formats[0]\n\n                try:\n                    format = formats.find_by_content_type(content_type)\n                except formats.UnknownFormat:\n                    return None\n\n                if format in supported_formats:\n                    return format\n                else:\n                    return None\n\n        # If no format is given by either extension or header, default to the format given in\n        # RESPITE_DEFAULT_FORMAT (given, of course, that it's supported by the view).\n        if DEFAULT_FORMAT:\n            format = formats.find(DEFAULT_FORMAT)\n\n            if format in supported_formats:\n                return format\n            else:\n                return None", "response": "Determine and return a format instance describing the most desired response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender a HTTP response for a specific resource.", "response": "def _render(self, request, template=None, status=200, context={}, headers={}, prefix_template_path=True):\n        \"\"\"\n        Render a HTTP response.\n\n        :param request: A django.http.HttpRequest instance.\n        :param template: A string describing the path to a template.\n        :param status: An integer describing the HTTP status code to respond with.\n        :param context: A dictionary describing variables to populate the template with.\n        :param headers: A dictionary describing HTTP headers.\n        :param prefix_template_path: A boolean describing whether to prefix the template with the view's template path.\n\n        Please note that ``template`` must not specify an extension, as one will be appended\n        according to the request format. For example, a value of ``blog/posts/index``\n        would populate ``blog/posts/index.html`` for requests that query the resource's\n        HTML representation.\n\n        If no template that matches the request format exists at the given location, or if ``template`` is ``None``,\n        Respite will attempt to serialize the template context automatically. You can change the way your models\n        are serialized by defining ``serialize`` methods that return a dictionary::\n\n            class NuclearMissile(models.Model):\n                serial_number = models.IntegerField()\n                is_armed = models.BooleanField()\n                launch_code = models.IntegerField()\n\n                def serialize(self):\n                    return {\n                        'serial_number': self.serial_number,\n                        'is_armed': self.is_armed\n                    }\n\n        If the request format is not supported by the view (as determined by the ``supported_formats``\n        property or a specific view's ``override_supported_formats`` decorator), this function will\n        yield HTTP 406 Not Acceptable.\n        \"\"\"\n\n        format = self._get_format(request)\n\n        # Render 406 Not Acceptable if the requested format isn't supported.\n        if not format:\n            return HttpResponse(status=406)\n\n        if template:\n\n            if prefix_template_path:\n                template_path = '%s.%s' % (self.template_path + template, format.extension)\n            else:\n                template_path = '%s.%s' % (template, format.extension)\n\n            try:\n                response = render(\n                    request = request,\n                    template_name = template_path,\n                    dictionary = context,\n                    status = status,\n                    content_type = '%s; charset=%s' % (format.content_type, settings.DEFAULT_CHARSET)\n                )\n            except TemplateDoesNotExist:\n                try:\n                    response = HttpResponse(\n                        content = serializers.find(format)(context).serialize(request),\n                        content_type = '%s; charset=%s' % (format.content_type, settings.DEFAULT_CHARSET),\n                        status = status\n                    )\n                except serializers.UnknownSerializer:\n                    raise self.Error(\n                        'No template exists at %(template_path)s, and no serializer found for %(format)s' % {\n                            'template_path': template_path,\n                            'format': format\n                        }\n                    )\n        else:\n            response = HttpResponse(\n                content = serializers.find(format)(context).serialize(request),\n                content_type = '%s; charset=%s' % (format.content_type, settings.DEFAULT_CHARSET),\n                status = status\n            )\n\n        for header, value in headers.items():\n            response[header] = value\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _error(self, request, status, headers={}, prefix_template_path=False, **kwargs):\n\n        return self._render(\n            request = request,\n            template = str(status),\n            status = status,\n            context = {\n                'error': kwargs\n            },\n            headers = headers,\n            prefix_template_path = prefix_template_path\n        )", "response": "Helper method to render an error response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding and return a serializer for the given format.", "response": "def find(format):\n    \"\"\"\n    Find and return a serializer for the given format.\n\n    Arguments:\n    format -- A Format instance.\n    \"\"\"\n    try:\n        serializer = SERIALIZERS[format]\n    except KeyError:\n        raise UnknownSerializer('No serializer found for %s' % format.acronym)\n\n    return serializer"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef serialize(self, request):\n\n        def serialize(anything):\n\n            def serialize_dictionary(dictionary):\n                \"\"\"Dictionaries are serialized recursively.\"\"\"\n                data = OrderedDict()\n\n                # Serialize each of the dictionary's keys\n                for key, value in dictionary.items():\n                    data.update({ key: serialize(value) })\n\n                return data\n\n            def serialize_list(list):\n                \"\"\"Lists are serialized recursively.\"\"\"\n                data = []\n\n                # Serialize each of the list's items\n                for item in list:\n                    data.append(serialize(item))\n\n                return data\n\n            def serialize_queryset(queryset):\n                \"\"\"Querysets are serialized as lists of models.\"\"\"\n                data = []\n\n                # Serialize queryset as a list of models\n                for model in queryset:\n                    data.append(serialize_model(model))\n\n                return data\n\n            def serialize_datequeryset(datequeryset):\n                \"\"\"DateQuerysets are serialized as lists of dates.\"\"\"\n                data = []\n\n                # Serialize datequeryset as a list of datetime objects\n                for date in datequeryset:\n                    data.append(serialize_date(date))\n\n                return data\n\n            def serialize_valueslistqueryset(valueslistqueryset):\n                \"\"\"DateQuerysets are serialized as lists of values.\"\"\"\n                data = []\n\n                # Serialize valueslistqueryset as a list of values\n                for value in valueslistqueryset:\n                    if isinstance(value, tuple):\n                        data.append(serialize_list(value))\n                    else:\n                        data.append(serialize(value))\n\n                return data\n\n            def serialize_manager(manager):\n                \"\"\"Managers are serialized as list of models.\"\"\"\n                data = []\n\n                for model in manager.all():\n                    data.append(serialize_model(model))\n\n                return data\n\n            def serialize_model(model):\n                \"\"\"\n                Models are serialized by calling their 'serialize' method.\n\n                Models that don't define a 'serialize' method are\n                serialized as a dictionary of fields.\n\n                Example:\n\n                    {\n                        'id': 1,\n                        'title': 'Mmmm pie',\n                        'content: 'Pie is good!'\n                    }\n\n                \"\"\"\n\n                if hasattr(model, 'serialize'):\n                    return serialize(model.serialize())\n                else:\n                    data = OrderedDict()\n                    for field in model._meta.fields + model._meta.many_to_many:\n                        data.update({\n                            field.name: serialize(getattr(model, field.name ))\n                        })\n\n                    return data\n\n            def serialize_form(form):\n                \"\"\"\n                Forms are serialized as a dictionary of fields and errors (if any).\n\n                Example:\n\n                    {\n                        'fields': ['title', 'content'],\n                        'errors': {\n                            'content': 'Must describe pie.'\n                        }\n                    }\n\n                \"\"\"\n                data = OrderedDict()\n\n                # Serialize form fields as a list of strings\n                data['fields'] = []\n                for field in form.fields:\n                    data['fields'].append(field)\n\n                # Serialize form errors as a dictionary with keys 'field' and 'error'\n                if form.errors:\n                    data['errors'] = []\n                    for field in form:\n                        data['errors'].append(\n                            {\n                                'field': field.name,\n                                'error': field.errors.as_text()\n                            }\n                        )\n\n                return data\n\n            def serialize_date(datetime):\n                \"\"\"Dates are serialized as ISO 8601-compatible strings.\"\"\"\n                return datetime.isoformat()\n\n            def serialize_field_file(field_file):\n                \"\"\"Filefields are serialized as strings describing their URL.\"\"\"\n                try:\n                    return field_file.url\n                except ValueError:\n                    return None\n\n            def serialize_image_field_file(image_field_file):\n                \"\"\"Imagefields are serialized as strings describing their URL.\"\"\"\n                try:\n                    return image_field_file.url\n                except ValueError:\n                    return None\n\n            def serialize_decimal_field(decimal_field):\n                \"\"\"Decimal fields are serialized as strings.\"\"\"\n                try:\n                    return str(decimal_field)\n                except ValueError:\n                    return None\n\n            if isinstance(anything, dict):\n                return serialize_dictionary(anything)\n\n            if isinstance(anything, (list, set)):\n                return serialize_list(anything)\n\n            if isinstance(anything, django.db.models.query.DateQuerySet):\n                return serialize_datequeryset(anything)\n\n            if isinstance(anything, django.db.models.query.DateTimeQuerySet):\n                return serialize_datequeryset(anything)\n\n            if isinstance(anything, django.db.models.query.ValuesListQuerySet):\n                return serialize_valueslistqueryset(anything)\n\n            if isinstance(anything, django.db.models.query.QuerySet):\n                return serialize_queryset(anything)\n\n            if isinstance(anything, django.db.models.Model):\n                return serialize_model(anything)\n\n            if isinstance(anything, (django.forms.Form, django.forms.ModelForm)):\n                return serialize_form(anything)\n\n            if isinstance(anything, (str, unicode)):\n                return anything\n\n            if isinstance(anything, (int, float, long)):\n                return anything\n\n            if isinstance(anything, (datetime.date, datetime.datetime)):\n                return serialize_date(anything)\n\n            if isinstance(anything, django.db.models.manager.Manager):\n                return serialize_manager(anything)\n\n            if isinstance(anything, Decimal):\n                return serialize_decimal_field(anything)\n\n            if isinstance(anything, django.core.files.base.File):\n                return serialize_field_file(anything)\n\n            if anything is None:\n                return None\n\n            if hasattr(anything, 'serialize'):\n                return serialize(anything.serialize())\n\n            raise TypeError(\"Respite doesn't know how to serialize %s\" % anything.__class__.__name__)\n\n        return serialize(self.source)", "response": "Serialize the given object into a list of simpleCOOKIE data types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_form_kwargs(self):\n        update_data ={}\n        sfdict = self.filter_class.get_search_fields()\n        for fieldname in sfdict:\n            try:\n                has_multiple = sfdict[fieldname].get('multiple', False)\n            except:\n                has_multiple = False\n\n            if has_multiple:\n                value = self.request.GET.getlist(fieldname, [])\n            else:\n                value = self.request.GET.get(fieldname, None)\n\n            update_data[fieldname] =  value\n\n        if self.order_field:\n            update_data[self.order_field] = self.request.GET.get(self.order_field, None)\n\n        initial = self.get_initial()\n        initial.update(update_data)\n        kwargs = {'initial': initial }\n\n        if self.groups_for_userlist != None:\n            pot_users = User.objects.exclude(id=self.request.user.id)\n            if len(self.groups_for_userlist):\n                pot_users = pot_users.filter(groups__name__in = self.groups_for_userlist)\n            pot_users = pot_users.distinct().order_by('username')\n            user_choices = tuple([(user.id, str(user)) for user in pot_users])\n            kwargs['user_choices'] = user_choices\n\n        return kwargs", "response": "Returns the keyword arguments for instantiating the search form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npluralize an English noun.", "response": "def pluralize(word) :\n        \"\"\"Pluralize an English noun.\"\"\"\n\n        rules = [\n            ['(?i)(quiz)$' , '\\\\1zes'],\n            ['^(?i)(ox)$' , '\\\\1en'],\n            ['(?i)([m|l])ouse$' , '\\\\1ice'],\n            ['(?i)(matr|vert|ind)ix|ex$' , '\\\\1ices'],\n            ['(?i)(x|ch|ss|sh)$' , '\\\\1es'],\n            ['(?i)([^aeiouy]|qu)ies$' , '\\\\1y'],\n            ['(?i)([^aeiouy]|qu)y$' , '\\\\1ies'],\n            ['(?i)(hive)$' , '\\\\1s'],\n            ['(?i)(?:([^f])fe|([lr])f)$' , '\\\\1\\\\2ves'],\n            ['(?i)sis$' , 'ses'],\n            ['(?i)([ti])um$' , '\\\\1a'],\n            ['(?i)(buffal|tomat)o$' , '\\\\1oes'],\n            ['(?i)(bu)s$' , '\\\\1ses'],\n            ['(?i)(alias|status)' , '\\\\1es'],\n            ['(?i)(octop|vir)us$' , '\\\\1i'],\n            ['(?i)(ax|test)is$' , '\\\\1es'],\n            ['(?i)s$' , 's'],\n            ['(?i)$' , 's']\n        ]\n\n        uncountable_words = ['equipment', 'information', 'rice', 'money', 'species', 'series', 'fish', 'sheep']\n\n        irregular_words = {\n            'person' : 'people',\n            'man' : 'men',\n            'child' : 'children',\n            'sex' : 'sexes',\n            'move' : 'moves'\n        }\n\n        lower_cased_word = word.lower();\n\n        for uncountable_word in uncountable_words:\n            if lower_cased_word[-1*len(uncountable_word):] == uncountable_word :\n                return word\n\n        for irregular in irregular_words.keys():\n            match = re.search('('+irregular+')$',word, re.IGNORECASE)\n            if match:\n                return re.sub('(?i)'+irregular+'$', match.expand('\\\\1')[0]+irregular_words[irregular][1:], word)\n\n        for rule in range(len(rules)):\n            match = re.search(rules[rule][0], word, re.IGNORECASE)\n            if match :\n                groups = match.groups()\n                for k in range(0,len(groups)) :\n                    if groups[k] == None :\n                        rules[rule][1] = rules[rule][1].replace('\\\\'+str(k+1), '')\n\n                return re.sub(rules[rule][0], rules[rule][1], word)\n\n        return word"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms an underscore_case string to a mixedCase string", "response": "def us2mc(string):\n    \"\"\"Transform an underscore_case string to a mixedCase string\"\"\"\n    return re.sub(r'_([a-z])', lambda m: (m.group(1).upper()), string)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_form(model, form=None, fields=False, exclude=False):\n    _model, _fields, _exclude = model, fields, exclude\n\n    class Form(form or forms.ModelForm):\n        class Meta:\n            model = _model\n\n            if _fields is not False:\n                fields = _fields\n\n            if _exclude is not False:\n                exclude = _exclude\n\n    return Form", "response": "Generates a form from a Django model."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrouting the given view to the given method and name.", "response": "def route(regex, view, method, name):\n    \"\"\"\n    Route the given view.\n    \n    :param regex: A string describing a regular expression to which the request path will be matched.\n    :param view: A string describing the name of the view to delegate the request to.\n    :param method: A string describing the HTTP method that this view accepts.\n    :param name: A string describing the name of the URL pattern.\n    \n    ``regex`` may also be a lambda that accepts the parent resource's ``prefix`` argument and returns\n    a string describing a regular expression to which the request path will be matched.\n    \n    ``name`` may also be a lambda that accepts the parent resource's ``views`` argument and returns\n    a string describing the name of the URL pattern.\n    \"\"\"\n    return _Route(regex, view, method, name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnotes that this function requires Scipy.", "response": "def sample_double_norm(mean, std_upper, std_lower, size):\n    \"\"\"Note that this function requires Scipy.\"\"\"\n    from scipy.special import erfinv\n\n    # There's probably a better way to do this. We first draw percentiles\n    # uniformly between 0 and 1. We want the peak of the distribution to occur\n    # at `mean`. However, if we assign 50% of the samples to the lower half\n    # and 50% to the upper half, the side with the smaller variance will be\n    # overrepresented because of the 1/sigma normalization of the Gaussian\n    # PDF. Therefore we need to divide points between the two halves with a\n    # fraction `cutoff` (defined below) going to the lower half. Having\n    # partitioned them this way, we can then use the standard Gaussian\n    # quantile function to go from percentiles to sample values -- except that\n    # we must remap from [0, cutoff] to [0, 0.5] and from [cutoff, 1] to [0.5,\n    # 1].\n\n    samples = np.empty(size)\n    percentiles = np.random.uniform(0., 1., size)\n    cutoff = std_lower / (std_lower + std_upper)\n\n    w = (percentiles < cutoff)\n    percentiles[w] *= 0.5 / cutoff\n    samples[w] = mean + np.sqrt(2) * std_lower * erfinv(2 * percentiles[w] - 1)\n\n    w = ~w\n    percentiles[w] = 1 - (1 - percentiles[w]) * 0.5 / (1 - cutoff)\n    samples[w] = mean + np.sqrt(2) * std_upper * erfinv(2 * percentiles[w] - 1)\n\n    return samples"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef sample_gamma(alpha, beta, size):\n\n    if alpha <= 0:\n        raise ValueError('alpha must be positive; got %e' % alpha)\n    if beta <= 0:\n        raise ValueError('beta must be positive; got %e' % beta)\n    return np.random.gamma(alpha, scale=1./beta, size=size)", "response": "Sample from the gamma distribution."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_gamma_params(mode, std):\n    if mode < 0:\n        raise ValueError('input mode must be positive for gamma; got %e' % mode)\n\n    var = std**2\n    beta = (mode + np.sqrt(mode**2 + 4 * var)) / (2 * var)\n    j = 2 * var / mode**2\n    alpha = (j + 1 + np.sqrt(2 * j + 1)) / j\n\n    if alpha <= 1:\n        raise ValueError('couldn\\'t compute self-consistent gamma parameters: '\n                         'mode=%e std=%e alpha=%e beta=%e' % (mode, std, alpha, beta))\n\n    return alpha, beta", "response": "Given a modal value and a standard deviation compute corresponding gamma parameters for the gamma distribution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the appropriate Lval for the limit of value x towards polarity. Either toinf or pastzero depending on the sign of x towards polarity. Either toinf or pastzero depending on the sign of x towards polarity. Either toinf or pastzero depending on the infinity direction of polarity.", "response": "def _lval_add_towards_polarity(x, polarity):\n    \"\"\"Compute the appropriate Lval \"kind\" for the limit of value `x` towards\n    `polarity`. Either 'toinf' or 'pastzero' depending on the sign of `x` and\n    the infinity direction of polarity.\n\n    \"\"\"\n    if x < 0:\n        if polarity < 0:\n            return Lval('toinf', x)\n        return Lval('pastzero', x)\n    elif polarity > 0:\n        return Lval('toinf', x)\n    return Lval('pastzero', x)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unwrap(msmt):\n\n    if np.isscalar(msmt):\n        return float(msmt)\n    if isinstance(msmt, (Uval, Lval)):\n        return msmt\n    if isinstance(msmt, Textual):\n        return msmt.unwrap()\n    raise ValueError('don\\'t know how to treat %r as a measurement' % msmt)", "response": "Convert the value into the most basic representation that we can do."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef repval(msmt, limitsok=False):\n\n    if np.isscalar(msmt):\n        return float(msmt)\n    if isinstance(msmt, Uval):\n        return msmt.repvals(uval_default_repval_method)[0]\n    if isinstance(msmt, Lval):\n        if not limitsok and msmt.kind in('tozero', 'toinf', 'pastzero'):\n            raise LimitError()\n        return msmt.value\n    if isinstance(msmt, Textual):\n        return msmt.repval(limitsok=limitsok)\n\n    raise ValueError('don\\'t know how to treat %r as a measurement' % msmt)", "response": "Return a best -effort representative value as a float. This is DANGEROUS\n    because it discards limit information."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef limtype(msmt):\n\n    if np.isscalar(msmt):\n        return 0\n    if isinstance(msmt, Uval):\n        return 0\n    if isinstance(msmt, Lval):\n        if msmt.kind == 'undef':\n            raise ValueError('no simple limit type for Lval %r' % msmt)\n\n        # Quasi-hack here: limits of ('tozero', [positive number]) are\n        # reported as upper limits. In a plot full of fluxes this would be\n        # what makes sense, but note that this would be misleading if the\n        # quantity in question was something that could go negative.\n        p = msmt._polarity()\n        if p == -2 or p == 1:\n            return -1\n        if p == 2 or p == -1:\n            return 1\n        return 0\n    if isinstance(msmt, Textual):\n        return msmt.limtype()\n    raise ValueError('don\\'t know how to treat %r as a measurement' % msmt)", "response": "Return - 1 if this value is some kind of upper limit 1 if this value is some kind of lower limit 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the error bar information for the given measurement.", "response": "def errinfo(msmt):\n    \"\"\"Return (limtype, repval, errval1, errval2). Like m_liminfo, but also\n    provides error bar information for values that have it.\"\"\"\n\n    if isinstance(msmt, Textual):\n        msmt = msmt.unwrap()\n\n    if np.isscalar(msmt):\n        return 0, msmt, msmt, msmt\n\n    if isinstance(msmt, Uval):\n        rep, plus1, minus1 = msmt.repvals(uval_default_repval_method)\n        return 0, rep, plus1, minus1\n\n    if isinstance(msmt, Lval):\n        return limtype(msmt), msmt.value, msmt.value, msmt.value\n\n    raise ValueError('don\\'t know how to treat %r as a measurement' % msmt)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fmtinfo(value):\n    if value is None:\n        raise ValueError('cannot format None!')\n\n    if isinstance(value, text_type):\n        return '', value, False\n\n    if isinstance(value, bool):\n        # Note: isinstance(True, int) = True, so this must come before the next case.\n        if value:\n            return 'b', 'y', False\n        return 'b', '', False\n\n    if isinstance(value, six.integer_types):\n        return 'i', text_type(value), False\n\n    if isinstance(value, float):\n        return 'f', text_type(value), True\n\n    if hasattr(value, '__pk_fmtinfo__'):\n        return value.__pk_fmtinfo__()\n\n    raise ValueError('don\\'t know how to format %r as a measurement' % value)", "response": "Returns a string that can be used to format a single object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_pcount(nevents):\n        if nevents < 0:\n            raise ValueError('Poisson parameter `nevents` must be nonnegative')\n        return Uval(np.random.gamma(nevents + 1, size=uval_nsamples))", "response": "We assume a Poisson process and return a random Uval object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute the representative statistical values for this Uval.", "response": "def repvals(self, method):\n        \"\"\"Compute representative statistical values for this Uval. `method`\n        may be either 'pct' or 'gauss'.\n\n        Returns (best, plus_one_sigma, minus_one_sigma), where `best` is the\n        \"best\" value in some sense, and the others correspond to values at\n        the ~84 and 16 percentile limits, respectively. Because of the\n        sampled nature of the Uval system, there is no single method to\n        compute these numbers.\n\n        The \"pct\" method returns the 50th, 15.866th, and 84.134th percentile\n        values.\n\n        The \"gauss\" method computes the mean \u03bc and standard deviation \u03c3 of the\n        samples and returns [\u03bc, \u03bc+\u03c3, \u03bc-\u03c3].\n\n        \"\"\"\n        if method == 'pct':\n            return pk_scoreatpercentile(self.d, [50., 84.134, 15.866])\n        if method == 'gauss':\n            m, s = self.d.mean(), self.d.std()\n            return np.asarray([m, m + s, m - s])\n        raise ValueError('unknown representative-value method \"%s\"' % method)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the main dhigh dlow sharedexponent and all as strings.", "response": "def text_pieces(self, method, uplaces=2, use_exponent=True):\n        \"\"\"Return (main, dhigh, dlow, sharedexponent), all as strings. The\n        delta terms do not have sign indicators. Any item except the first\n        may be None.\n\n        `method` is passed to Uval.repvals() to compute representative\n        statistical limits.\n\n        \"\"\"\n        md, hi, lo = self.repvals(method)\n\n        if hi == lo:\n            return '%g' % lo, None, None, None\n\n        if not np.isfinite([lo, md, hi]).all():\n            raise ValueError('got nonfinite values when formatting Uval')\n\n        # Deltas. Round to limited # of places because we don't actually know\n        # the fourth moment of the thing we're trying to describe.\n\n        from numpy import abs, ceil, floor, log10\n\n        dh = hi - md\n        dl = md - lo\n\n        if dh <= 0:\n            raise ValueError('strange problem formatting Uval; '\n                             'hi=%g md=%g dh=%g' % (hi, md, dh))\n        if dl <= 0:\n            raise ValueError('strange problem formatting Uval; '\n                             'lo=%g md=%g dl=%g' % (lo, md, dl))\n\n        p = int(ceil(log10(dh)))\n        rdh = round(dh * 10**(-p), uplaces) * 10**p\n        p = int(ceil(log10(dl)))\n        rdl = round(dl * 10**(-p), uplaces) * 10**p\n\n        # The least significant place to worry about is the L.S.P. of one of\n        # the deltas, which we can find relative to its M.S.P. Any precision\n        # in the datum beyond this point is false.\n\n        lsp = int(ceil(log10(min(rdh, rdl)))) - uplaces\n\n        # We should round the datum since it might be something like\n        # 0.999+-0.1 and we're about to try to decide what its most\n        # significant place is. Might get -1 rather than 0.\n\n        rmd = round(md, -lsp)\n\n        if rmd == -0.: # 0 = -0, too, but no problem there.\n            rmd = 0.\n\n        # The most significant place to worry about is the M.S.P. of any of\n        # the datum or the deltas. rdl and rdl must be positive, but not\n        # necessarily rmd.\n\n        msp = int(floor(log10(max(abs(rmd), rdh, rdl))))\n\n        # If we're not very large or very small, or it's been explicitly\n        # disabled, don't use scientific notation.\n\n        if (msp > -3 and msp < 3) or not use_exponent:\n            srmd = '%.*f' % (-lsp, rmd)\n            srdh = '%.*f' % (-lsp, rdh)\n            srdl = '%.*f' % (-lsp, rdl)\n            return srmd, srdh, srdl, None\n\n        # Use scientific notation. Adjust values, then format.\n\n        armd = rmd * 10**-msp\n        ardh = rdh * 10**-msp\n        ardl = rdl * 10**-msp\n        prec = msp - lsp\n\n        sarmd = '%.*f' % (prec, armd)\n        sardh = '%.*f' % (prec, ardh)\n        sardl = '%.*f' % (prec, ardl)\n        return sarmd, sardh, sardl, str(msp)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a best - effective representative value as a float. This can be DANGEROUS because it discards limit information which is rarely wise.", "response": "def repval(self, limitsok=False):\n        \"\"\"Get a best-effort representative value as a float. This can be\n        DANGEROUS because it discards limit information, which is rarely wise.\"\"\"\n\n        if not limitsok and self.dkind in ('lower', 'upper'):\n            raise LimitError()\n\n        if self.dkind == 'unif':\n            lower, upper = map(float, self.data)\n            v = 0.5 * (lower + upper)\n        elif self.dkind in _noextra_dkinds:\n            v = float(self.data)\n        elif self.dkind in _yesextra_dkinds:\n            v = float(self.data[0])\n        else:\n            raise RuntimeError('can\\'t happen')\n\n        if self.tkind == 'log10':\n            return 10**v\n        return v"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef in_casapy (helper, vis=None, figfile=None):\n    if vis is None:\n        raise ValueError ('vis')\n\n    helper.casans.plotants (vis=vis, figfile=figfile)", "response": "This function is run inside the weirdo casapy IPython environment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(dataset, node, entityids, products, api_key=None):\n\n    payload = {\n        \"datasetName\": dataset,\n        \"node\": node,\n        \"apiKey\": api_key,\n        \"entityIds\": entityids,\n        \"products\": products\n    }\n\n    return json.dumps(payload)", "response": "This function returns a JSON string that can be used to obtain valid data download URLs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download_options(dataset, node, entityids, api_key=None):\n\n    payload = {\n        \"apiKey\": api_key,\n        \"datasetName\": dataset,\n        \"node\": node,\n        \"entityIds\": entityids\n    }\n\n    return json.dumps(payload)", "response": "This function returns the JSON response of the download options for each scene."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search(dataset, node,\n    lat=None, lng=None,\n    distance=100,\n    ll=None, ur=None,\n    start_date=None, end_date=None,\n    where=None,\n    max_results=50000,\n    starting_number=1,\n    sort_order=\"DESC\",\n    api_key=None):\n    \"\"\"\n    :param dataset:\n    \n    :param node:\n    \n    :param lat:\n    \n    :param lng:\n    \n    :param ll:\n    \n    :param distance:\n    \n    :param ur:\n    \n    :param start_date:\n    \n    :param end_date:\n    \n    :param where:\n        Specify additional search criteria\n    \n    :param max_results:\n    \n    :param starting_number:\n    \n    :param sort_order:\n    \n    :param api_key:\n        API key is not required.\n    \"\"\"\n\n    payload = {\n        \"datasetName\": dataset,\n        \"node\": node,\n        \"apiKey\": api_key,\n    }\n\n    # Latitude and longitude take precedence over ll and ur\n    if lat and lng:\n\n        lats, lngs = great_circle_dist(lat, lng, distance / 2.0)\n\n        ll = { \"longitude\": min(*lngs), \"latitude\": min(*lats) }\n        ur = { \"longitude\": max(*lngs), \"latitude\": max(*lats) }\n\n    if ll and ur:\n        payload[\"spatialFilter\"] = {\n            \"filterType\": \"mbr\",\n            \"lowerLeft\": ll,\n            \"upperRight\": ur\n        }\n\n    if start_date or end_date:\n        payload[\"temporalFilter\"] = {\n            \"dateField\": \"search_date\"\n        }\n\n        if start_date:\n            payload[\"temporalFilter\"][\"startDate\"] = start_date\n        if end_date:\n            payload[\"temporalFilter\"][\"endDate\"] = end_date\n\n    if where:\n\n        # TODO: Support more than AND key/value equality queries\n        # usgs search --node EE LANDSAT_8_C1 --start-date 20170410 --end-date 20170411 --where wrs-row 032 | jq \"\"\n        # LC81810322017101LGN00\n        payload[\"additionalCriteria\"] = {\n            \"filterType\": \"and\",\n            \"childFilters\": [\n                {\n                    \"filterType\": \"value\",\n                    \"fieldId\": field_id,\n                    \"value\": value,\n                    \"operand\": \"=\"\n                }\n                for field_id, value in iter(where.items())\n            ]\n        }\n\n    if max_results:\n        payload[\"maxResults\"] = max_results\n\n    if starting_number:\n        payload[\"startingNumber\"] = starting_number\n\n    if sort_order:\n        payload[\"sortOrder\"] = sort_order\n\n    return json.dumps(payload)", "response": "Search the node in the specified dataset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef approx_colormap (samples, transform='none', fitfactor=1.):\n    import scipy.interpolate as SI\n\n    values = samples[0]\n    if transform == 'none':\n        pass\n    elif transform == 'reverse':\n        samples = samples[:,::-1]\n    elif transform == 'sqrt':\n        values = np.sqrt (values)\n    else:\n        raise ValueError ('unknown transformation: ' + str (transform))\n\n    nsamp = samples.shape[1]\n    rspline = SI.splrep (values, samples[R+1], s=fitfactor/nsamp)\n    gspline = SI.splrep (values, samples[G+1], s=fitfactor/nsamp)\n    bspline = SI.splrep (values, samples[B+1], s=fitfactor/nsamp)\n\n    def colormap (values):\n        values = np.asarray (values)\n        mapped = np.empty (values.shape + (3,))\n\n        flatvalues = values.flatten ()\n        flatmapped = mapped.reshape (flatvalues.shape + (3,))\n\n        flatmapped[:,R] = SI.splev (flatvalues, rspline)\n        flatmapped[:,G] = SI.splev (flatvalues, gspline)\n        flatmapped[:,B] = SI.splev (flatvalues, bspline)\n\n        return mapped\n\n    return colormap", "response": "Compute a colormap that is approximately applied to the given samples."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef srgb_to_linsrgb (srgb):\n    gamma = ((srgb + 0.055) / 1.055)**2.4\n    scale = srgb / 12.92\n    return np.where (srgb > 0.04045, gamma, scale)", "response": "Convert sRGB values to physically linear ones."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef linsrgb_to_srgb (linsrgb):\n    # From Wikipedia, but easy analogue to the above.\n    gamma = 1.055 * linsrgb**(1./2.4) - 0.055\n    scale = linsrgb * 12.92\n    return np.where (linsrgb > 0.0031308, gamma, scale)", "response": "Convert physically linear RGB values into sRGB ones."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting XYZ color values to CIE XYZ color values in CIE L * a * b *.", "response": "def xyz_to_cielab (xyz, refwhite):\n    \"\"\"Convert CIE XYZ color values to CIE L*a*b*.\n\n    *xyz* should be of shape (*, 3). *refwhite* is the reference white value, of\n    shape (3, ).\n\n    Return value will have same shape as *xyz*, but be in CIE L*a*b*\n    coordinates.\n\n    \"\"\"\n    norm = xyz / refwhite\n    pow = norm**0.333333333333333\n    scale = 7.787037 * norm + 16./116\n    mapped = np.where (norm > 0.008856, pow, scale)\n\n    cielab = np.empty_like (xyz)\n    cielab[...,L] = 116 * mapped[...,Y] - 16\n    cielab[...,A] = 500 * (mapped[...,X] - mapped[...,Y])\n    cielab[...,B] = 200 * (mapped[...,Y] - mapped[...,Z])\n\n    return cielab"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a CIE L * a * b color value to XYZ", "response": "def cielab_to_xyz (cielab, refwhite):\n    \"\"\"Convert CIE L*a*b* color values to CIE XYZ,\n\n    *cielab* should be of shape (*, 3). *refwhite* is the reference white\n    value in the L*a*b* color space, of shape (3, ).\n\n    Return value has same shape as *cielab*\n\n    \"\"\"\n    def func (t):\n        pow = t**3\n        scale = 0.128419 * t - 0.0177129\n        return np.where (t > 0.206897, pow, scale)\n\n    xyz = np.empty_like (cielab)\n    lscale = 1./116 * (cielab[...,L] + 16)\n    xyz[...,X] = func (lscale + 0.002 * cielab[...,A])\n    xyz[...,Y] = func (lscale)\n    xyz[...,Z] = func (lscale - 0.005 * cielab[...,B])\n    xyz *= refwhite\n    return xyz"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert CIE L a b to Moreland s Msh colorspace.", "response": "def cielab_to_msh (cielab):\n    \"\"\"Convert CIE L*a*b* to Moreland's Msh colorspace.\n\n    *cielab* should be of shape (*, 3).\n\n    Return value will have same shape.\n\n    \"\"\"\n    msh = np.empty_like (cielab)\n    msh[...,M] = np.sqrt ((cielab**2).sum (axis=-1))\n    msh[...,S] = np.arccos (cielab[...,L] / msh[...,M])\n    msh[...,H] = np.arctan2 (cielab[...,B], cielab[...,A])\n    return msh"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef msh_to_cielab (msh):\n    cielab = np.empty_like (msh)\n    cielab[...,L] = msh[...,M] * np.cos (msh[...,S])\n    cielab[...,A] = msh[...,M] * np.sin (msh[...,S]) * np.cos (msh[...,H])\n    cielab[...,B] = msh[...,M] * np.sin (msh[...,S]) * np.sin (msh[...,H])\n    return cielab", "response": "Convert Moreland s Msh colorspace to CIE L * a * b."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef moreland_interpolate_sampled (srgb1, srgb2, refwhite=CIELAB_D65,\n                                  nsamples=DEFAULT_SAMPLE_POINTS):\n    \"\"\"Adapted from Moreland's InterpolateColor. This uses the full\n    transformations to compute a color mapping at a set of sampled points.\"\"\"\n\n    msh1, msh2 = srgb_to_msh (np.asarray ([srgb1, srgb2],\n                                          dtype=np.float), refwhite)\n\n    raddiff = msh1[H] - msh2[H]\n    while raddiff > np.pi:\n        raddiff -= 2 * np.pi\n    while raddiff < -np.pi:\n        raddiff += 2 * np.pi\n    raddiff = np.abs (raddiff)\n\n    x = np.linspace (0, 1, nsamples).reshape ((nsamples, 1))\n    x = np.repeat (x, 3, 1)\n\n    if msh1[S] <= 0.05 or msh2[S] <= 0.05 or raddiff < np.pi/3:\n        # Colors are too close together to comfortably put white in between.\n        # Our interpolation won't have a control point, and won't actually be\n        # divergent.\n\n        if msh1[S] < 0.05 and msh2[S] > 0.05:\n            msh1[H] = moreland_adjusthue (msh1, msh1[M])\n        elif msh2[S] < 0.05 and msh1[S] > 0.05:\n            msh2[H] = moreland_adjusthue (msh2, msh2[M])\n\n        samples = np.empty ((4, nsamples))\n\n        msh = (1 - x) * msh1 + x * msh2\n        samples[0] = x[:,0]\n        samples[1:4] = msh_to_srgb (msh, refwhite).T\n    else:\n        # Colors are not too close together -- we can add a white control\n        # point in the middle, and do two interpolations joined piecewise. We\n        # then use 2*nsamples-1 (not actually nsamples -- shhh) samples for\n        # the spline fit\n\n        msh3 = msh2\n        msh2a = np.asarray ([np.max ([msh1[M], msh3[M], 88]), 0, 0])\n        msh2b = msh2a.copy ()\n\n        if msh1[S] < 0.05 and msh2a[S] > 0.05:\n            msh1[H] = moreland_adjusthue (msh2a, msh1[M])\n        elif msh2a[S] < 0.05 and msh1[S] > 0.05:\n            msh2a[H] = moreland_adjusthue (msh1, msh2a[M])\n\n        if msh2b[S] < 0.05 and msh3[S] > 0.05:\n            msh2b[H] = moreland_adjusthue (msh3, msh2b[M])\n        elif msh3[S] < 0.05 and msh2b[S] > 0.05:\n            msh3[H] = moreland_adjusthue (msh2b, msh3[M])\n\n        samples = np.empty ((4, 2*nsamples-1))\n\n        msh = (1 - x) * msh1 + x * msh2a\n        samples[0,:nsamples] = 0.5 * x[:,0]\n        samples[1:4,:nsamples] = msh_to_srgb (msh, refwhite).T\n\n        msh = (1 - x) * msh2b + x * msh3\n        samples[0,nsamples-1:] = 0.5 * x[:,0] + 0.5\n        samples[1:4,nsamples-1:] = msh_to_srgb (msh, refwhite).T\n\n    return samples", "response": "Adapted from Moreland s InterpolateColor. This uses the full\n    transformations to compute a color mapping at a set of sampled points."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the node associated with each dataset.", "response": "def get_datasets_in_nodes():\n    \"\"\"\n    Get the node associated with each dataset. Some datasets\n    will have an ambiguous node since they exists in more than\n    one node.\n    \"\"\"\n\n    data_dir = os.path.join(scriptdir, \"..\", \"usgs\", \"data\")\n\n    cwic = map(lambda d: d[\"datasetName\"], api.datasets(None, CWIC_LSI_EXPLORER_CATALOG_NODE)['data'])\n    ee = map(lambda d: d[\"datasetName\"], api.datasets(None, EARTH_EXPLORER_CATALOG_NODE)['data'])\n    hdds = map(lambda d: d[\"datasetName\"], api.datasets(None, HDDS_EXPLORER_CATALOG_NODE)['data'])\n    lpcs = map(lambda d: d[\"datasetName\"], api.datasets(None, LPCS_EXPLORER_CATALOG_NODE)['data'])\n\n    # Create mapping from dataset to node\n    datasets = {}\n    datasets.update( { ds : \"CWIC\" for ds in cwic } )\n    datasets.update( { ds : \"EE\" for ds in ee } )\n    datasets.update( { ds : \"HDDS\" for ds in hdds } )\n    datasets.update( { ds : \"LPCS\" for ds in lpcs } )\n\n    datasets_path = os.path.join(data_dir, \"datasets.json\")\n    with open(datasets_path, \"w\") as f:\n        f.write(json.dumps(datasets))\n\n    # Find the datasets with ambiguous nodes\n    cwic_ee = [ds for ds in cwic if ds in ee]\n    cwic_hdds = [ds for ds in cwic if ds in hdds]\n    cwic_lpcs = [ds for ds in cwic if ds in lpcs]\n    ee_hdds = [ds for ds in ee if ds in hdds]\n    ee_lpcs = [ds for ds in ee if ds in lpcs]\n    hdds_lpcs = [ds for ds in hdds if ds in lpcs]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pivot_wavelength_ee(bpass):\n    from scipy.integrate import simps\n    return np.sqrt(simps(bpass.resp, bpass.wlen) /\n                   simps(bpass.resp / bpass.wlen**2, bpass.wlen))", "response": "Compute the pivot wavelength assuming equal - energy convention."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a curve x y find the x coordinates of points that have half the max value of y.", "response": "def interpolated_halfmax_points(x, y):\n    \"\"\"Given a curve y(x), find the x coordinates of points that have half the\n    value of max(y), using linear interpolation. We're assuming that y(x) has\n    a bandpass-ish shape, i.e., a single maximum and a drop to zero as we go\n    to the edges of the function's domain. We also assume that x is sorted\n    increasingly.\n\n    \"\"\"\n    from scipy.interpolate import interp1d\n    from scipy.optimize import fmin\n\n    x = np.asarray(x)\n    y = np.asarray(y)\n    halfmax = 0.5 * y.max()\n\n    # Guess from the actual samples.\n\n    delta = y - halfmax\n    guess1 = 0\n    while delta[guess1] < 0:\n        guess1 += 1\n    guess2 = y.size - 1\n    while delta[guess2] < 0:\n        guess2 -= 1\n\n    # Interpolate for fanciness.\n\n    terp = interp1d(x, y, kind='linear', bounds_error=False, fill_value=0.)\n    x1 = fmin(lambda x: (terp(x) - halfmax)**2, x[guess1], disp=False)\n    x2 = fmin(lambda x: (terp(x) - halfmax)**2, x[guess2], disp=False)\n\n    x1 = np.asscalar(x1)\n    x2 = np.asscalar(x2)\n\n    if x1 == x2:\n        raise PKError('halfmax finding failed')\n\n    if x1 > x2:\n        x1, x2 = x2, x1\n\n    return x1, x2"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_std_registry():\n    from six import itervalues\n    reg = Registry()\n    for fn in itervalues(builtin_registrars):\n        fn(reg)\n    return reg", "response": "Get a Registry object pre - filled with information for standard\n    telescopes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pivot_wavelength(self):\n        wl = self.registry._pivot_wavelengths.get((self.telescope, self.band))\n        if wl is not None:\n            return wl\n\n        wl = self.calc_pivot_wavelength()\n        self.registry.register_pivot_wavelength(self.telescope, self.band, wl)\n        return wl", "response": "Get the bandpass pivot wavelength."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_halfmax_points(self):\n        d = self._ensure_data()\n        return interpolated_halfmax_points(d.wlen, d.resp)", "response": "Calculate the wavelengths of the filter half - maximum values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef halfmax_points(self):\n        t = self.registry._halfmaxes.get((self.telescope, self.band))\n        if t is not None:\n            return t\n\n        t = self.calc_halfmax_points()\n        self.registry.register_halfmaxes(self.telescope, self.band, t[0], t[1])\n        return t", "response": "Get the bandpass half - maximum wavelengths."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mag_to_fnu(self, mag):\n        if self.native_flux_kind == 'flam':\n            return flam_ang_to_fnu_cgs(self.mag_to_flam(mag), self.pivot_wavelength())\n        raise PKError('dont\\'t know how to get f_\u03bd from mag for bandpass %s/%s',\n                      self.telescope, self.band)", "response": "Convert a magnitude in this band to a f_\u03bd flux density."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef blackbody(self, T):\n        from scipy.integrate import simps\n\n        d = self._ensure_data()\n\n        # factor of pi is going from specific intensity (sr^-1) to unidirectional\n        # inner factor of 1e-8 is \u00c5 to cm\n        # outer factor of 1e-8 is f_\u03bb in cm^-1 to f_\u03bb in \u00c5^-1\n        from .cgs import blambda\n        numer_samples = d.resp * np.pi * blambda(d.wlen * 1e-8, T) * 1e-8\n\n        numer = simps(numer_samples, d.wlen)\n        denom = simps(d.resp, d.wlen)\n        return numer / denom", "response": "Calculate the contribution of a blackbody through this filter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of bands associated with the specified telescope.", "response": "def bands(self, telescope):\n        \"\"\"Return a list of bands associated with the specified telescope.\"\"\"\n        q = self._seen_bands.get(telescope)\n        if q is None:\n            return []\n        return list(q)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef register_pivot_wavelength(self, telescope, band, wlen):\n        if (telescope, band) in self._pivot_wavelengths:\n            raise AlreadyDefinedError('pivot wavelength for %s/%s already '\n                                      'defined', telescope, band)\n        self._note(telescope, band)\n        self._pivot_wavelengths[telescope,band] = wlen\n        return self", "response": "Register precomputed pivot wavelengths."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef register_halfmaxes(self, telescope, band, lower, upper):\n\n        if (telescope, band) in self._halfmaxes:\n            raise AlreadyDefinedError('half-max points for %s/%s already '\n                                      'defined', telescope, band)\n        self._note(telescope, band)\n        self._halfmaxes[telescope,band] = (lower, upper)\n        return self", "response": "Register precomputed half - max points."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a Bandpass class.", "response": "def register_bpass(self, telescope, klass):\n        \"\"\"Register a Bandpass class.\"\"\"\n\n        if telescope in self._bpass_classes:\n            raise AlreadyDefinedError('bandpass class for %s already '\n                                      'defined', telescope)\n        self._note(telescope, None)\n        self._bpass_classes[telescope] = klass\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a Bandpass object for a known telescope and filter.", "response": "def get(self, telescope, band):\n        \"\"\"Get a Bandpass object for a known telescope and filter.\"\"\"\n\n        klass = self._bpass_classes.get(telescope)\n        if klass is None:\n            raise NotDefinedError('bandpass data for %s not defined', telescope)\n\n        bp = klass()\n        bp.registry = self\n        bp.telescope = telescope\n        bp.band = band\n        return bp"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_data(self, band):\n        # `band` should be 'nuv' or 'fuv'\n        df = bandpass_data_frame('filter_galex_' + band + '.dat', 'wlen resp')\n        df.resp *= df.wlen # QE -> EE response convention.\n        return df", "response": "Load the data from the filter_galex_band. dat file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the data frame for MKO NIR filters.", "response": "def _load_data(self, band):\n        \"\"\"Filter responses for MKO NIR filters as specified in Tokunaga+ 2002 (see\n        also Tokunaga+ 2005). I downloaded the L' profile from\n        http://irtfweb.ifa.hawaii.edu/~nsfcam/hist/filters.2006.html.\n\n        Pivot wavelengths from Tokunaga+ 2005 (Table 2) confirm that the\n        profile is in QE convention, although my calculation of the pivot\n        wavelength for L' is actually closer if I assume otherwise. M' and K_s\n        are substantially better in QE convention, though, and based on the\n        paper and nomenclature it seems more appropriate.\n\n        \"\"\"\n        # `band` should be 'Lp'.\n        df = bandpass_data_frame('filter_mko_' + band + '.dat', 'wlen resp')\n        # Put in increasing wavelength order:\n        df = df[::-1]\n        df.index = np.arange(df.shape[0])\n        df.wlen *= 1e4 # micron to Angstrom\n        df.resp *= df.wlen # QE to equal-energy response.\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing F_\u03bd for a MKO IR filter band.", "response": "def mag_to_fnu(self, mag):\n        \"\"\"Compute F_\u03bd for an MKO IR filter band. There are some problems here since\n        \"MKO\" is filters, not a photometric system, but people try to make\n        Vega = 0.\n\n        \"\"\"\n        return cgs.cgsperjy * self._zeropoints[self.band] * 10**(-0.4 * mag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_data(self, band):\n        h = bandpass_data_fits('sdss3_filter_responses.fits')\n        section = 'ugriz'.index(band[0]) + 1\n        d = h[section].data\n        if d.wavelength.dtype.isnative:\n            df = pd.DataFrame({'wlen': d.wavelength, 'resp': d.respt})\n        else:\n            df = pd.DataFrame({'wlen': d.wavelength.byteswap(True).newbyteorder(),\n                               'resp': d.respt.byteswap(True).newbyteorder()})\n        df.resp *= df.wlen # QE to equal-energy response.\n        return df", "response": "Load the data table from the SDSS 3. 5m filter curves."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a magnitude in the standard - star system to the F_\u03bd format.", "response": "def mag_to_fnu(self, mag):\n        \"\"\"SDSS *primed* magnitudes to F_\u03bd. The primed magnitudes are the \"USNO\"\n        standard-star system defined in Smith+ (2002AJ....123.2121S) and\n        Fukugita+ (1996AJ....111.1748F). This system is anchored to the AB\n        magnitude system, and as far as I can tell it is not known to have\n        measurable offsets from that system. (As of DR10, the *unprimed* SDSS\n        system is known to have small offsets from AB, but I do not believe\n        that that necessarily has implications for u'g'r'i'z'.)\n\n        However, as far as I can tell the filter responses of the USNO\n        telescope are not published -- only those of the main SDSS 2.5m\n        telescope. The whole reason for the existence of both the primed and\n        unprimed ugriz systems is that their responses do not quite match. For\n        my current application, which involves a completely different\n        telescope anyway, the difference shouldn't matter.\n\n        \"\"\"\n        # `band` should be 'up', 'gp', 'rp', 'ip', or 'zp'.\n        if len(band) != 2 or band[1] != 'p':\n            raise ValueError('band: ' + band)\n        return abmag_to_fnu_cgs(mag)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading the data from the CALDB and return a DataFrame.", "response": "def _load_data(self, band):\n        \"\"\"In-flight effective areas for the Swift UVOT, as obtained from the CALDB.\n        See Breeveld+ 2011. XXX: confirm that these are equal-energy, not\n        quantum-efficiency.\n\n        \"\"\"\n        d = bandpass_data_fits('sw' + self._band_map[band] + '_20041120v106.arf')[1].data\n\n        # note:\n        #   data.WAVE_MIN[i] < data.WAVE_MIN[i+1], but\n        #   data.WAVE_MIN[i] > data.WAVE_MAX[i] (!)\n        #   data.WAVE_MIN[i] = data.WAVE_MAX[i+1] (!)\n\n        wmid = 0.5 * (d.WAVE_MIN + d.WAVE_MAX) # in \u00c5ngstr\u00f6m\n        df = pd.DataFrame({'wlen': wmid, 'resp': d.SPECRESP,\n                           'wlo': d.WAVE_MAX, 'whi': d.WAVE_MIN})\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads the data from the WISE All - Sky Explanatory Supplement IV. 4. h. i. 1 and Jarrett + 2011.", "response": "def _load_data(self, band):\n        \"\"\"From the WISE All-Sky Explanatory Supplement, IV.4.h.i.1, and Jarrett+\n        2011. These are relative response per erg and so can be integrated\n        directly against F_nu spectra. Wavelengths are in micron,\n        uncertainties are in parts per thousand.\n\n        \"\"\"\n        # `band` should be 1, 2, 3, or 4.\n        df = bandpass_data_frame('filter_wise_' + str(band) + '.dat', 'wlen resp uncert')\n        df.wlen *= 1e4 # micron to Angstrom\n        df.uncert *= df.resp / 1000. # parts per thou. to absolute values.\n        lo, hi = self._filter_subsets[band]\n        df = df[lo:hi] # clip zero parts of response.\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef invoke (self, args, **kwargs):\n\n        if len (args) not in (3, 6):\n            raise multitool.UsageError ('c2m expected exactly 3 or 6 arguments')\n\n        year = int (args[0])\n        month = int (args[1])\n\n        import astropy.time\n\n        if len (args) == 3:\n            day = float (args[2])\n            iday = int (math.floor (day))\n            r = 24 * (day - iday)\n            hour = int (np.floor (r))\n            r = 60 * (r - hour)\n            minute = int (np.floor (r))\n            second = 60 * (r - minute)\n        else:\n            iday = int (args[2])\n            hour = int (args[3])\n            minute = int (args[4])\n            second = float (args[5])\n\n        s = '%d-%02d-%02d %02d:%02d:%02.8f' % (year, month, iday,\n                                               hour, minute, second)\n        t = astropy.time.Time (s, format='iso', scale='utc')\n        print ('%.4f' % t.tai.mjd)", "response": "This method is invoked by astropy. time. c2m to get the UTC calendar to MJD [ TAI ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef run(argv=argv):\n  config_file = kwconfig.manage(\n    file_path=resource_filename(Requirement.parse('search_google'), 'search_google/config.json'),\n    defaults={\n      'build_serviceName': 'customsearch',\n      'build_version': 'v1',\n      'num': 3,\n      'fileType': 'png',\n      'option_silent': 'False',\n      'option_preview' : 10})\n  \n  # (commands) Main command calls\n  if len(argv) > 1:\n    if argv[1] == '-i': # browse docs\n      open_new_tab(_doc_link)\n      exit()\n    elif argv[1] == '-a': # browse arguments\n      open_new_tab(_cse_link)\n      exit()\n  config_file.command(argv, i=1, doc=__doc__, quit=True, silent=False)\n  \n  # (parse_args) Parse command arguments into dict\n  kwargs = kwconfig.parse(argv[2:])\n  kwargs['q'] = argv[1]\n  kwargs = config_file.add(kwargs)\n  \n  # (split_args) Split args into build, cse, and save arguments\n  buildargs = {}\n  cseargs = {}\n  saveargs = {}\n  optionargs = {}\n  for k, v in kwargs.items():\n    if 'build_' == k[0:6]:\n      buildargs[k[6:]] = v\n    elif 'save_' == k[0:5]:\n      saveargs[k[5:]] = v\n    elif 'option_' == k[0:7]:\n      optionargs[k[7:]] = v\n    else:\n      cseargs[k] = v\n  \n  # (cse_results) Get google api results\n  results = search_google.api.results(buildargs, cseargs)\n  \n  # (cse_print) Print a preview of results\n  if 'silent' in optionargs:\n    if optionargs['silent'].lower() != 'true':\n      results.preview(n=int(optionargs['preview']))\n  \n  # (cse_save) Save links and metadata\n  if 'links' in saveargs:\n    results.save_links(saveargs['links'])\n  if 'metadata' in saveargs:\n    results.save_metadata(saveargs['metadata'])\n  \n  # (cse_download) Download links\n  if 'downloads' in saveargs:\n    results.download_links(saveargs['downloads'])", "response": "This function runs the search_google command line tool. It is intended for use inside a python file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pdm (t, x, u, periods, nbin, nshift=8, nsmc=256, numc=256, weights=False, parallel=True):\n    t = np.asfarray (t)\n    x = np.asfarray (x)\n    u = np.asfarray (u)\n    periods = np.asfarray (periods)\n    t, x, u, periods = np.atleast_1d (t, x, u, periods)\n    nbin = int (nbin)\n    nshift = int (nshift)\n    nsmc = int (nsmc)\n    numc = int (numc)\n    phelp = make_parallel_helper (parallel)\n\n    if t.ndim != 1:\n        raise ValueError ('`t` must be <= 1D')\n\n    if x.shape != t.shape:\n        raise ValueError ('`t` and `x` arguments must be the same size')\n\n    if u.shape != t.shape:\n        raise ValueError ('`t` and `u` arguments must be the same size')\n\n    if periods.ndim != 1:\n        raise ValueError ('`periods` must be <= 1D')\n\n    if nbin < 2:\n        raise ValueError ('`nbin` must be at least 2')\n\n    if nshift < 1:\n        raise ValueError ('`nshift` must be at least 1')\n\n    if nsmc < 0:\n        raise ValueError ('`nsmc` must be nonnegative')\n\n    if numc < 0:\n        raise ValueError ('`numc` must be nonnegative')\n\n    # We can finally get started!\n\n    if weights:\n        wt = u\n        u = wt ** -0.5\n    else:\n        wt = u ** -2\n\n    v_all = weighted_variance (x, wt)\n\n    with phelp.get_map () as map:\n        get_thetas = lambda args: np.asarray (map (_map_one_theta, args))\n        thetas = get_thetas ((t, x, wt, p, nbin, nshift, v_all)\n                             for p in periods)\n        imin = thetas.argmin ()\n        pmin = periods[imin]\n\n        # Now do the Monte Carlo jacknifing so that the caller can have some idea\n        # as to the significance of the minimal value of `thetas`.\n\n        mc_thetas = np.empty (periods.shape)\n        mc_tmins = np.empty (nsmc)\n\n        for i in range (nsmc):\n            shuf = np.random.permutation (x.size)\n            # Note that what we do here is very MapReduce-y. I'm not aware of\n            # an easy way to implement this computation in that model, though.\n            mc_thetas = get_thetas ((t, x[shuf], wt[shuf], p, nbin, nshift, v_all)\n                                    for p in periods)\n            mc_tmins[i] = mc_thetas.min ()\n\n        mc_tmins.sort ()\n        mc_pvalue = mc_tmins.searchsorted (thetas[imin]) / nsmc\n\n        # Now add noise to assess the uncertainty of the period.\n\n        mc_pmins = np.empty (numc)\n\n        for i in range (numc):\n            noised = np.random.normal (x, u)\n            mc_thetas = get_thetas ((t, noised, wt, p, nbin, nshift, v_all)\n                                    for p in periods)\n            mc_pmins[i] = periods[mc_thetas.argmin ()]\n\n        mc_pmins.sort ()\n        mc_puncert = mc_pmins.std ()\n\n    # All done.\n\n    return PDMResult (thetas=thetas, imin=imin, pmin=pmin, mc_tmins=mc_tmins,\n                      mc_pvalue=mc_pvalue, mc_pmins=mc_pmins,\n                      mc_puncert=mc_puncert)", "response": "Perform phase dispersion minimization."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning given comment HTML as plaintext.", "response": "def clean_comment_body(body):\n    \"\"\"Returns given comment HTML as plaintext.\n\n    Converts all HTML tags and entities within 4chan comments\n    into human-readable text equivalents.\n    \"\"\"\n    body = _parser.unescape(body)\n    body = re.sub(r'<a [^>]+>(.+?)</a>', r'\\1', body)\n    body = body.replace('<br>', '\\n')\n    body = re.sub(r'<.+?>', '', body)\n    return body"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef datadir(*subdirs):\n    import os.path\n    data = None\n\n    if 'CASAPATH' in os.environ:\n        data = os.path.join(os.environ['CASAPATH'].split()[0], 'data')\n\n    if data is None:\n        # The Conda CASA directory layout:\n        try:\n            import casadef\n        except ImportError:\n            pass\n        else:\n            data = os.path.join(os.path.dirname(casadef.task_directory), 'data')\n            if not os.path.isdir(data):\n                # Sigh, hack for CASA 4.7 + Conda; should be straightened out:\n                dn = os.path.dirname\n                data = os.path.join(dn(dn(dn(casadef.task_directory))), 'lib', 'casa', 'data')\n                if not os.path.isdir(data):\n                    data = None\n\n    if data is None:\n        import casac\n\n        prevp = None\n        p = os.path.dirname(casac.__file__)\n        while len(p) and p != prevp:\n            data = os.path.join(p, 'data')\n            if os.path.isdir(data):\n                break\n            prevp = p\n            p = os.path.dirname(p)\n\n    if not os.path.isdir(data):\n        raise RuntimeError('cannot identify CASA data directory')\n\n    return os.path.join(data, *subdirs)", "response": "Get a path within the CASA data directory."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting up CASA to write log messages to standard output.", "response": "def logger(filter='WARN'):\n    \"\"\"Set up CASA to write log messages to standard output.\n\n    filter\n      The log level filter: less urgent messages will not be shown. Valid values\n      are strings: \"DEBUG1\", \"INFO5\", ... \"INFO1\", \"INFO\", \"WARN\", \"SEVERE\".\n\n    This function creates and returns a CASA \u201dlog sink\u201d object that is\n    configured to write to standard output. The default CASA implementation\n    would *always* create a file named ``casapy.log`` in the current\n    directory; this function safely prevents such a file from being left\n    around. This is particularly important if you don\u2019t have write permissions\n    to the current directory.\n\n    \"\"\"\n    import os, shutil, tempfile\n\n    cwd = os.getcwd()\n    tempdir = None\n\n    try:\n        tempdir = tempfile.mkdtemp(prefix='casautil')\n\n        try:\n            os.chdir(tempdir)\n            sink = tools.logsink()\n            sink.setlogfile(sanitize_unicode(os.devnull))\n            try:\n                os.unlink('casapy.log')\n            except OSError as e:\n                if e.errno != 2:\n                    raise\n                # otherwise, it's a ENOENT, in which case, no worries.\n        finally:\n            os.chdir(cwd)\n    finally:\n        if tempdir is not None:\n            shutil.rmtree(tempdir, onerror=_rmtree_error)\n\n    sink.showconsole(True)\n    sink.setglobal(True)\n    sink.filter(sanitize_unicode(filter.upper()))\n    return sink"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nforking a child process and read its CASA log output.", "response": "def forkandlog(function, filter='INFO5', debug=False):\n    \"\"\"Fork a child process and read its CASA log output.\n\n    function\n      A function to run in the child process\n    filter\n      The CASA log level filter to apply in the child process: less urgent\n      messages will not be shown. Valid values are strings: \"DEBUG1\", \"INFO5\",\n      ... \"INFO1\", \"INFO\", \"WARN\", \"SEVERE\".\n    debug\n      If true, the standard output and error of the child process are *not*\n      redirected to /dev/null.\n\n    Some CASA tools produce important results that are *only* provided via log\n    messages. This is a problem for automation, since there\u2019s no way for\n    Python code to intercept those log messages and extract the results of\n    interest. This function provides a framework for working around this\n    limitation: by forking a child process and sending its log output to a\n    pipe, the parent process can capture the log messages.\n\n    This function is a generator. It yields lines from the child process\u2019 CASA\n    log output.\n\n    Because the child process is a fork of the parent, it inherits a complete\n    clone of the parent\u2019s state at the time of forking. That means that the\n    *function* argument you pass it can do just about anything you\u2019d do in a\n    regular program.\n\n    The child process\u2019 standard output and error streams are redirected to\n    ``/dev/null`` unless the *debug* argument is true. Note that the CASA log\n    output is redirected to a pipe that is neither of these streams. So, if\n    the function raises an unhandled Python exception, the Python traceback\n    will not pollute the CASA log output. But, by the same token, the calling\n    program will not be able to detect that the exception occurred except by\n    its impact on the expected log output.\n\n    \"\"\"\n    import sys, os\n\n    readfd, writefd = os.pipe()\n    pid = os.fork()\n\n    if pid == 0:\n        # Child process. We never leave this branch.\n        #\n        # Log messages of priority >WARN are sent to stderr regardless of the\n        # status of log.showconsole(). The idea is for this subprocess to be\n        # something super lightweight and constrained, so it seems best to\n        # nullify stderr, and stdout, to not pollute the output of the calling\n        # process.\n        #\n        # I thought of using the default logger() setup and dup2'ing stderr to\n        # the pipe fd, but then if anything else gets printed to stderr (e.g.\n        # Python exception info), it'll get sent along the pipe too. The\n        # caller would have to be much more complex to be able to detect and\n        # handle such output.\n\n        os.close(readfd)\n\n        if not debug:\n            f = open(os.devnull, 'w')\n            os.dup2(f.fileno(), 1)\n            os.dup2(f.fileno(), 2)\n\n        sink = logger(filter=filter)\n        sink.setlogfile(b'/dev/fd/%d' % writefd)\n        function(sink)\n        sys.exit(0)\n\n    # Original process.\n\n    os.close(writefd)\n\n    with os.fdopen(readfd) as readhandle:\n        for line in readhandle:\n            yield line\n\n    info = os.waitpid(pid, 0)\n\n    if info[1]:\n        # Because we're a generator, this is the only way for us to signal if\n        # the process died. We could be rewritten as a context manager.\n        e = RuntimeError('logging child process PID %d exited '\n                         'with error code %d' % tuple(info))\n        e.pid, e.exitcode = info\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the metadata returned from the metadataUrl of a USGS scene and add it to the extended dictionary.", "response": "def _get_extended(scene, resp):\n    \"\"\"\n    Parse metadata returned from the metadataUrl of a USGS scene.\n\n    :param scene:\n        Dictionary representation of a USGS scene\n    :param resp:\n        Response object from requests/grequests\n    \"\"\"\n    root = ElementTree.fromstring(resp.text)\n    items = root.findall(\"eemetadata:metadataFields/eemetadata:metadataField\", NAMESPACES)\n    scene['extended'] = {item.attrib.get('name').strip(): xsi.get(item[0]) for item in items}\n\n    return scene"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _async_requests(urls):\n    session = FuturesSession(max_workers=30)\n    futures = [\n        session.get(url)\n        for url in urls\n    ]\n    return [ future.result() for future in futures ]", "response": "Sends multiple non - blocking requests. Returns a list of responses."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrequests metadata for a given USGS dataset.", "response": "def metadata(dataset, node, entityids, extended=False, api_key=None):\n    \"\"\"\n    Request metadata for a given scene in a USGS dataset.\n\n    :param dataset:\n    :param node:\n    :param entityids:\n    :param extended:\n        Send a second request to the metadata url to get extended metadata on the scene.\n    :param api_key:\n    \"\"\"\n    api_key = _get_api_key(api_key)\n\n    url = '{}/metadata'.format(USGS_API)\n    payload = {\n        \"jsonRequest\": payloads.metadata(dataset, node, entityids, api_key=api_key)\n    }\n    r = requests.post(url, payload)\n    response = r.json()\n\n    _check_for_usgs_error(response)\n\n    if extended:\n        metadata_urls = map(_get_metadata_url, response['data'])\n        results = _async_requests(metadata_urls)\n        data = map(lambda idx: _get_extended(response['data'][idx], results[idx]), range(len(response['data'])))\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reraise_context(fmt, *args):\n    import sys\n\n    if len(args):\n        cstr = fmt % args\n    else:\n        cstr = text_type(fmt)\n\n    ex = sys.exc_info()[1]\n\n    if isinstance(ex, EnvironmentError):\n        ex.strerror = '%s: %s' % (cstr, ex.strerror)\n        ex.args = (ex.errno, ex.strerror)\n    else:\n        if len(ex.args):\n            cstr = '%s: %s' % (cstr, ex.args[0])\n        ex.args = (cstr, ) + ex.args[1:]\n\n    raise", "response": "Reraise an exception with its message modified to specify additional context."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self):\n        new = self.__class__()\n        new.__dict__ = dict(self.__dict__)\n        return new", "response": "Return a shallow copy of this object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_pretty(self, format='str'):\n        if format == 'str':\n            template = '%-*s = %s'\n        elif format == 'repr':\n            template = '%-*s = %r'\n        else:\n            raise ValueError('unrecognized value for \"format\": %r' % format)\n\n        d = self.__dict__\n        maxlen = 0\n\n        for k in six.iterkeys(d):\n            maxlen = max(maxlen, len(k))\n\n        return '\\n'.join(template % (maxlen, k, d[k])\n                         for k in sorted(six.iterkeys(d)))", "response": "Return a string with a prettified version of this object s contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef write_stream (stream, holders, defaultsection=None, extrapos=(), sha1sum=False, **kwargs):\n    if sha1sum:\n        import hashlib\n        sha1 = hashlib.sha1 ()\n    else:\n        sha1 = None\n\n    inifile.write_stream (stream,\n                          _format_many (holders, defaultsection, extrapos, sha1),\n                          defaultsection=defaultsection,\n                          **kwargs)\n\n    if sha1sum:\n        return sha1.digest ()", "response": "Write out a sequence of fluxes to a stream."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noutputting a single line of data to the destination.", "response": "def output(self, kind, line):\n        \"*line* should be bytes\"\n        self.destination.write(b''.join([\n            self._cyan,\n            b't=%07d' % (time.time() - self._t0),\n            self._reset,\n            self._kind_prefixes[kind],\n            self.markers[kind],\n            line,\n            self._reset,\n        ]))\n        self.destination.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef output_stderr(self, text):\n        \"*text* should be bytes\"\n        binary_stderr.write(b''.join([\n            self._red,\n            b't=%07d' % (time.time() - self._t0),\n            self._reset,\n            b' ',\n            text,\n        ]))\n        binary_stderr.flush()", "response": "Write to stderr the text should be bytes"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_boards(board_name_list, *args, **kwargs):\n    if isinstance(board_name_list, basestring):\n        board_name_list = board_name_list.split()\n    return [Board(name, *args, **kwargs) for name in board_name_list]", "response": "Given a list of boards return a dict of : class :asc_py4chan. Board objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn every board on 4chan.", "response": "def get_all_boards(*args, **kwargs):\n    \"\"\"Returns every board on 4chan.\n\n    Returns:\n        dict of :class:`basc_py4chan.Board`: All boards.\n    \"\"\"\n    # Use https based on how the Board class instances are to be instantiated\n    https = kwargs.get('https', args[1] if len(args) > 1 else False)\n\n    # Dummy URL generator, only used to generate the board list which doesn't\n    # require a valid board name\n    url_generator = Url(None, https)\n    _fetch_boards_metadata(url_generator)\n    return get_boards(_metadata.keys(), *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_thread(self, thread_id, update_if_cached=True, raise_404=False):\n        # see if already cached\n        cached_thread = self._thread_cache.get(thread_id)\n        if cached_thread:\n            if update_if_cached:\n                cached_thread.update()\n            return cached_thread\n\n        res = self._requests_session.get(\n            self._url.thread_api_url(\n                thread_id = thread_id\n                )\n        )\n\n        # check if thread exists\n        if raise_404:\n            res.raise_for_status()\n        elif not res.ok:\n            return None\n\n        thread = Thread._from_request(self, res, thread_id)\n        self._thread_cache[thread_id] = thread\n\n        return thread", "response": "Get a thread from 4chan via API."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef thread_exists(self, thread_id):\n        return self._requests_session.head(\n            self._url.thread_api_url(\n                thread_id=thread_id\n                )\n        ).ok", "response": "Check if a thread exists or has 404'd."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of Thread objects for every thread on a certain page.", "response": "def get_threads(self, page=1):\n        \"\"\"Returns all threads on a certain page.\n\n        Gets a list of Thread objects for every thread on the given page. If a thread is\n        already in our cache, the cached version is returned and thread.want_update is\n        set to True on the specific thread object.\n\n        Pages on 4chan are indexed from 1 onwards.\n\n        Args:\n            page (int): Page to request threads for. Defaults to the first page.\n\n        Returns:\n            list of :mod:`basc_py4chan.Thread`: List of Thread objects representing the threads on the given page.\n        \"\"\"\n        url = self._url.page_url(page)\n        return self._request_threads(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_thread_ids(self):\n        json = self._get_json(self._url.thread_list())\n        return [thread['no'] for page in json for thread in page['threads']]", "response": "Return the ID of every thread on this board."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_all_threads(self, expand=False):\n        if not expand:\n            return self._request_threads(self._url.catalog())\n\n        thread_ids = self.get_all_thread_ids()\n        threads = [self.get_thread(id, raise_404=False) for id in thread_ids]\n\n        return filter(None, threads)", "response": "Return every thread on this board."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate all threads currently stored in our cache.", "response": "def refresh_cache(self, if_want_update=False):\n        \"\"\"Update all threads currently stored in our cache.\"\"\"\n        for thread in tuple(self._thread_cache.values()):\n            if if_want_update:\n                if not thread.want_update:\n                    continue\n            thread.update()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmodifying the environment variables for the CASA - based CASA process.", "response": "def modify_environment(self, env):\n        \"\"\"Maintaining compatibility with different CASA versions is a pain.\"\"\"\n\n        # Ugh. I don't see any way out of special-casing the RPM-based\n        # installations ... which only exist on NRAO computers, AFAICT.\n        # Hardcoding 64-bitness, hopefully that won't come back to bite me.\n        is_rpm_install = self._rootdir.startswith('/usr/lib64/casapy/release/')\n\n        def path(*args):\n            return os.path.join(self._rootdir, *args)\n\n        env['CASAROOT'] = path()\n        env['CASAPATH'] = ' '.join([path(),\n                                    os.uname()[0].lower(),\n                                    'local',\n                                    os.uname()[1]])\n\n        if is_rpm_install:\n            env['CASA_INSTALLATION_TYPE'] = 'rpm-installation'\n            prepend_environ_path(env, 'PATH', '/usr/lib64/casa/01/bin')\n            prepend_environ_path(env, 'PATH', path('bin'))\n        else:\n            env['CASA_INSTALLATION_TYPE'] = 'tar-installation'\n\n            lib = 'lib64' if os.path.isdir(path('lib64')) else 'lib'\n            # 4.3.1 comes with both python2.6 and python2.7???\n            pydir = sorted(glob.glob(path(lib, 'python2*')))[-1]\n\n            tcldir = path('share', 'tcl')\n            if os.path.isdir(tcldir):\n                env['TCL_LIBRARY'] = tcldir\n            else:\n                tcl_versioned_dirs = glob.glob(path('share', 'tcl*'))\n                if len(tcl_versioned_dirs):\n                    env['TCL_LIBRARY'] = tcl_versioned_dirs[-1]\n\n            bindir = path(lib, 'casa', 'bin')\n            if not os.path.isdir(bindir):\n                bindir = path(lib, 'casapy', 'bin')\n            prepend_environ_path(env, 'PATH', bindir)\n\n            env['CASA_INSTALLATION_DIRECTORY'] = env['CASAROOT']\n            env['__CASAPY_PYTHONDIR'] = pydir\n            env['MATPLOTLIBRC'] = path('share', 'matplotlib')\n            env['PYTHONHOME'] = env['CASAROOT']\n            env['TK_LIBRARY'] = path('share', 'tk')\n            env['QT_PLUGIN_PATH'] = path(lib, 'qt4', 'plugins')\n\n            prepend_environ_path(env, 'LD_LIBRARY_PATH', path(lib))\n            # should we overwite PYTHONPATH instead?\n            prepend_environ_path(env, 'PYTHONPATH', os.path.join(pydir, 'site-packages'))\n            prepend_environ_path(env, 'PYTHONPATH', os.path.join(pydir, 'heuristics'))\n            prepend_environ_path(env, 'PYTHONPATH', pydir)\n\n        return env"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting node from dataset.", "response": "def get_node(dataset, node):\n    \"\"\"\n    .. todo:: Move to more appropriate place in module.\n    \"\"\"\n    \n    if node is None:\n        \n        cur_dir = os.path.dirname(os.path.realpath(__file__))\n        data_dir = os.path.join(cur_dir, \"..\", \"data\")\n        dataset_path = os.path.join(data_dir, \"datasets.json\")\n        \n        with open(dataset_path, \"r\") as f:\n            datasets = json.loads(f.read())\n        \n        node = datasets[dataset].upper()\n    \n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncount the number of events in a file", "response": "def count_events (env, evtpath, filter):\n    \"\"\"TODO: this can probably be replaced with simply reading the file\n    ourselves!\n\n    \"\"\"\n    with env.slurp (argv=['dmstat', '%s%s[cols energy]' % (evtpath, filter)], linebreak=True) as s:\n        for etype, payload in s:\n            if etype != 'stdout':\n                continue\n\n            if b'good:' not in payload:\n                continue\n\n            return int (payload.split ()[-1])\n\n    raise Exception ('parsing of dmlist output failed')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_bgband (evtpath, srcreg, bkgreg, ebins, env=None):\n    import numpy as np\n    import pandas as pd\n    from scipy.special import erfcinv, gammaln\n\n    if env is None:\n        from . import CiaoEnvironment\n        env = CiaoEnvironment ()\n\n    srcarea = get_region_area (env, evtpath, srcreg)\n    bkgarea = get_region_area (env, evtpath, bkgreg)\n\n    srccounts = [count_events (env, evtpath, '[sky=%s][energy=%d:%d]' % (srcreg, elo, ehi))\n                 for elo, ehi in ebins]\n    bkgcounts = [count_events (env, evtpath, '[sky=%s][energy=%d:%d]' % (bkgreg, elo, ehi))\n                 for elo, ehi in ebins]\n\n    df = pd.DataFrame ({\n        'elo': [t[0] for t in ebins],\n        'ehi': [t[1] for t in ebins],\n        'nsrc': srccounts,\n        'nbkg': bkgcounts\n    })\n\n    df['ewidth'] = np.abs (df['ehi'] - df['elo'])\n    df['nbkg_scaled'] = df['nbkg'] * srcarea / bkgarea\n    df['log_prob_bkg'] = df['nsrc'] * np.log (df['nbkg_scaled']) - df['nbkg_scaled'] - gammaln (df['nsrc'] + 1)\n    df['src_sigma'] = np.sqrt (2) * erfcinv (np.exp (df['log_prob_bkg']))\n    df['nsrc_subbed'] = df['nsrc'] - df['nbkg_scaled']\n    return df", "response": "Compute background information for a source in one or more energy bands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef simple_srcflux(env, infile=None, psfmethod='arfcorr', conf=0.68,\n                   verbose=0, **kwargs):\n    \"\"\"Run the CIAO \"srcflux\" script and retrieve its results.\n\n    *infile*\n      The input events file; must be specified. The computation is done\n      in a temporary directory, so this path \u2014 and all others passed in\n      as arguments \u2014 **must be made absolute**.\n    *psfmethod* = \"arfcorr\"\n      The PSF modeling method to be used; see the \"srcflux\" documentation.\n    *conf* = 0.68\n      The confidence limit to detect. We default to 1 sigma, instead of\n      the 90% mark, which is the srcflux default.\n    *verbose* = 0\n      The level of verbosity to be used by the tool.\n    *kwargs*\n      Remaining keyword arguments are passed to the tool as command-line\n      keyword arguments, with values stringified.\n    Returns:\n      A :class:`pandas.DataFrame` extracted from the results table generated\n      by the tool. There is one row for each source analyzed; in common usage,\n      this means that there will be one row.\n\n    \"\"\"\n    from ...io import Path\n    import shutil, signal, tempfile\n\n    if infile is None:\n        raise ValueError('must specify infile')\n\n    kwargs.update(dict(\n        infile = infile,\n        psfmethod = psfmethod,\n        conf = conf,\n        verbose = verbose,\n        clobber = 'yes',\n        outroot = 'sf',\n    ))\n\n    argv = ['srcflux'] + ['%s=%s' % t for t in kwargs.items()]\n    argstr = ' '.join(argv)\n    tempdir = None\n\n    try:\n        tempdir = tempfile.mkdtemp(prefix='srcflux')\n\n        proc = env.launch(argv, cwd=tempdir, shell=False)\n        retcode = proc.wait()\n\n        if retcode > 0:\n            raise RuntimeError('command \"%s\" failed with exit code %d' % (argstr, retcode))\n        elif retcode == -signal.SIGINT:\n            raise KeyboardInterrupt()\n        elif retcode < 0:\n            raise RuntimeError('command \"%s\" killed by signal %d' % (argstr, -retcode))\n\n        tables = list(Path(tempdir).glob('*.flux'))\n        if len(tables) != 1:\n            raise RuntimeError('expected exactly one flux table from srcflux; got %d' % len(tables))\n\n        return tables[0].read_fits_bintable(hdu=1)\n    finally:\n        if tempdir is not None:\n            shutil.rmtree(tempdir, onerror=_rmtree_error)", "response": "Run the simple srcflux script and retrieve its results."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef prepend_path(orig, text, pathsep=os.pathsep):\n    if orig is None:\n        orig = ''\n    if not len(orig):\n        return text\n    return ''.join([text, pathsep, orig])", "response": "Returns a string with text prepended."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef prepend_environ_path(env, name, text, pathsep=os.pathsep):\n    env[name] = prepend_path(env.get(name), text, pathsep=pathsep)\n    return env", "response": "Prepend text into an environment variable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreproducing the calculation used to produce Figure 9 of the Fleischman Kuznetsov 2000 paper using our low - level interfaces.", "response": "def do_figure9_calc_lowlevel(shlib_path, set_unused=True):\n    \"\"\"Reproduce the calculation used to produce Figure 9 of the Fleischman &\n    Kuznetsov (2010) paper, using our low-level interfaces.\n\n    Input parameters, etc., come from the file ``Flare071231a.pro`` that is\n    distributed with the paper\u2019s Supplementary Data archive.\n\n    Invoke with something like::\n\n      from pwkit import fk10\n      arr = fk10.do_figure9_calc('path/to/libGS_Std_HomSrc_CEH.so.64')\n\n    \"\"\"\n    fk10func = FK10Invoker(shlib_path)\n\n    in_vals = make_in_vals_array()\n    in_vals[IN_VAL_AREA] = 1.33e18\n    in_vals[IN_VAL_DEPTH] = 6e8\n    in_vals[IN_VAL_T0] = 2.1e7\n    # EPSILON (these markers are to aid counting indices)\n    # KAPPA\n    in_vals[IN_VAL_INTEG_METH] = 16\n    in_vals[IN_VAL_EMIN] = 0.016\n    in_vals[IN_VAL_EMAX] = 4.0\n    # EBREAK\n    in_vals[IN_VAL_DELTA1] = 3.7\n    # DELTA2\n    in_vals[IN_VAL_N0] = 3e9\n    in_vals[IN_VAL_NB] = 5e9 / 3\n    in_vals[IN_VAL_B] = 48\n    in_vals[IN_VAL_THETA] = 50\n    in_vals[IN_VAL_FREQ0] = 5e8\n    in_vals[IN_VAL_LOGDFREQ] = 0.02\n    in_vals[IN_VAL_EDIST] = EDIST_PLW\n    in_vals[IN_VAL_NFREQ] = 100\n    in_vals[IN_VAL_PADIST] = PADIST_GLC\n    in_vals[IN_VAL_LCBDY] = 90\n    # BEAMDIR\n    in_vals[IN_VAL_DELTAMU] = 0.4\n    # A4\n    # (slot 24 unused)\n    in_vals[IN_VAL_FCCR] = 12\n    in_vals[IN_VAL_FWHCR] = in_vals[IN_VAL_FCCR]\n    in_vals[IN_VAL_RENORMFLAG] = 1\n    in_vals[IN_VAL_QFLAG] = 2\n\n    if set_unused:\n        # Sanity-checking: these parameters shouldn't affect the calculated\n        # result.\n        in_vals[IN_VAL_EPSILON] = 0.05\n        in_vals[IN_VAL_KAPPA] = 4.0\n        in_vals[IN_VAL_EBREAK] = 1.0\n        in_vals[IN_VAL_DELTA2] = 6.0\n        in_vals[IN_VAL_BEAMDIR] = 90\n        in_vals[IN_VAL_A4] = 1\n\n    return fk10func(in_vals)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreproduce Figure 9 of the Fleischman & Kuznetsov paper using our base class.", "response": "def make_figure9_plot(shlib_path, use_lowlevel=True, **kwargs):\n    \"\"\"Reproduce Figure 9 of the Fleischman & Kuznetsov (2010) paper, using our\n    low-level interfaces. Uses OmegaPlot, of course.\n\n    Input parameters, etc., come from the file ``Flare071231a.pro`` that is\n    distributed with the paper\u2019s Supplementary Data archive.\n\n    Invoke with something like::\n\n      from pwkit import fk10\n      fk10.make_figure9_plot('path/to/libGS_Std_HomSrc_CEH.so.64').show()\n\n    \"\"\"\n    import omega as om\n\n    if use_lowlevel:\n        out_vals = do_figure9_calc_lowlevel(shlib_path, **kwargs)\n    else:\n        out_vals = do_figure9_calc_highlevel(shlib_path, **kwargs)\n\n    freqs = out_vals[:,OUT_VAL_FREQ]\n    tot_ints = out_vals[:,OUT_VAL_OINT] + out_vals[:,OUT_VAL_XINT]\n    pos = (tot_ints > 0)\n\n    p = om.quickXY(freqs[pos], tot_ints[pos], 'Calculation', xlog=1, ylog=1)\n\n    nu_obs = np.array([1.0, 2.0, 3.75, 9.4, 17.0, 34.0])\n    int_obs = np.array([12.0, 43.0, 29.0, 6.3, 1.7, 0.5])\n    p.addXY(nu_obs, int_obs, 'Observations', lines=False)\n\n    p.defaultKeyOverlay.hAlign = 0.93\n    p.setBounds(0.5, 47, 0.1, 60)\n    p.setLabels('Emission frequency, GHz', 'Total intensity, sfu')\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_for_fk10_fig9(cls, shlib_path):\n        inst = (cls(shlib_path)\n            .set_thermal_background(2.1e7, 3e9)\n            .set_bfield(48)\n            .set_edist_powerlaw(0.016, 4.0, 3.7, 5e9/3)\n            .set_freqs(100, 0.5, 50)\n            .set_hybrid_parameters(12, 12)\n            .set_ignore_q_terms(False)\n            .set_obs_angle(50 * np.pi / 180)\n            .set_padist_gaussian_loss_cone(0.5 * np.pi, 0.4)\n            .set_trapezoidal_integration(15))\n\n        # haven't yet figure out how to deal with this part:\n        inst.in_vals[0] = 1.33e18\n        inst.in_vals[1] = 6e8\n        return inst", "response": "Create a new instance of the class FK9."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_bfield(self, B_G):\n        if not (B_G > 0):\n            raise ValueError('must have B_G > 0; got %r' % (B_G,))\n\n        self.in_vals[IN_VAL_B] = B_G\n        return self", "response": "Set the strength of the local magnetic field."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the B field to probe at a certain harmonic number.", "response": "def set_bfield_for_s0(self, s0):\n        \"\"\"Set B to probe a certain harmonic number.\n\n        **Call signature**\n\n        *s0*\n          The harmonic number to probe at the lowest frequency\n        Returns\n          *self* for convenience in chaining.\n\n        This just proceeds from the relation ``nu = s nu_c = s e B / 2 pi m_e\n        c``. Since *s* and *nu* scale with each other, if multiple frequencies\n        are being probed, the harmonic numbers being probed will scale in the\n        same way.\n\n        \"\"\"\n        if not (s0 > 0):\n            raise ValueError('must have s0 > 0; got %r' % (s0,))\n\n        B0 = 2 * np.pi * cgs.me * cgs.c * self.in_vals[IN_VAL_FREQ0] / (cgs.e * s0)\n        self.in_vals[IN_VAL_B] = B0\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_edist_powerlaw(self, emin_mev, emax_mev, delta, ne_cc):\n        if not (emin_mev >= 0):\n            raise ValueError('must have emin_mev >= 0; got %r' % (emin_mev,))\n        if not (emax_mev >= emin_mev):\n            raise ValueError('must have emax_mev >= emin_mev; got %r, %r' % (emax_mev, emin_mev))\n        if not (delta >= 0):\n            raise ValueError('must have delta >= 0; got %r, %r' % (delta,))\n        if not (ne_cc >= 0):\n            raise ValueError('must have ne_cc >= 0; got %r, %r' % (ne_cc,))\n\n        self.in_vals[IN_VAL_EDIST] = EDIST_PLW\n        self.in_vals[IN_VAL_EMIN] = emin_mev\n        self.in_vals[IN_VAL_EMAX] = emax_mev\n        self.in_vals[IN_VAL_DELTA1] = delta\n        self.in_vals[IN_VAL_NB] = ne_cc\n        return self", "response": "Set the energy distribution function to a power law."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the energy distribution function to a power law in the Lorentz factor and the power - law index of the energy distribution function.", "response": "def set_edist_powerlaw_gamma(self, gmin, gmax, delta, ne_cc):\n        \"\"\"Set the energy distribution function to a power law in the Lorentz factor\n\n        **Call signature**\n\n        *gmin*\n          The minimum Lorentz factor of the distribution\n        *gmax*\n          The maximum Lorentz factor of the distribution\n        *delta*\n          The power-law index of the distribution\n        *ne_cc*\n          The number density of energetic electrons, in cm^-3.\n        Returns\n          *self* for convenience in chaining.\n        \"\"\"\n        if not (gmin >= 1):\n            raise ValueError('must have gmin >= 1; got %r' % (gmin,))\n        if not (gmax >= gmin):\n            raise ValueError('must have gmax >= gmin; got %r, %r' % (gmax, gmin))\n        if not (delta >= 0):\n            raise ValueError('must have delta >= 0; got %r, %r' % (delta,))\n        if not (ne_cc >= 0):\n            raise ValueError('must have ne_cc >= 0; got %r, %r' % (ne_cc,))\n\n        self.in_vals[IN_VAL_EDIST] = EDIST_PLG\n        self.in_vals[IN_VAL_EMIN] = (gmin - 1) * E0_MEV\n        self.in_vals[IN_VAL_EMAX] = (gmax - 1) * E0_MEV\n        self.in_vals[IN_VAL_DELTA1] = delta\n        self.in_vals[IN_VAL_NB] = ne_cc\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the frequency grid on which to perform the calculations.", "response": "def set_freqs(self, n, f_lo_ghz, f_hi_ghz):\n        \"\"\"Set the frequency grid on which to perform the calculations.\n\n        **Call signature**\n\n        *n*\n          The number of frequency points to sample.\n        *f_lo_ghz*\n          The lowest frequency to sample, in GHz.\n        *f_hi_ghz*\n          The highest frequency to sample, in GHz.\n        Returns\n          *self* for convenience in chaining.\n\n        \"\"\"\n        if not (f_lo_ghz >= 0):\n            raise ValueError('must have f_lo_ghz >= 0; got %r' % (f_lo_ghz,))\n        if not (f_hi_ghz >= f_lo_ghz):\n            raise ValueError('must have f_hi_ghz >= f_lo_ghz; got %r, %r' % (f_hi_ghz, f_lo_ghz))\n        if not n >= 1:\n            raise ValueError('must have n >= 1; got %r' % (n,))\n\n        self.in_vals[IN_VAL_NFREQ] = n\n        self.in_vals[IN_VAL_FREQ0] = f_lo_ghz * 1e9 # GHz => Hz\n        self.in_vals[IN_VAL_LOGDFREQ] = np.log10(f_hi_ghz / f_lo_ghz) / n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_hybrid_parameters(self, s_C, s_WH, do_renorm=True):\n        self.in_vals[IN_VAL_FCCR] = s_C\n        self.in_vals[IN_VAL_FWHCR] = s_WH\n        self.in_vals[IN_VAL_RENORMFLAG] = 1 if do_renorm else 0\n        return self", "response": "Set the hybrid control parameters for a specific set of time intervals."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the observer angle relative to the field.", "response": "def set_obs_angle(self, theta_rad):\n        \"\"\"Set the observer angle relative to the field.\n\n        **Call signature**\n\n        *theta_rad*\n          The angle between the ray path and the local magnetic field,\n          in radians.\n        Returns\n          *self* for convenience in chaining.\n        \"\"\"\n        self.in_vals[IN_VAL_THETA] = theta_rad * 180 / np.pi # rad => deg\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_one_freq(self, f_ghz):\n        if not (f_ghz >= 0):\n            raise ValueError('must have f_lo_ghz >= 0; got %r' % (f_lo_ghz,))\n\n        self.in_vals[IN_VAL_NFREQ] = 1\n        self.in_vals[IN_VAL_FREQ0] = f_ghz * 1e9 # GHz -> Hz\n        self.in_vals[IN_VAL_LOGDFREQ] = 1.0\n        return self", "response": "Set the code to calculate results at just one frequency."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_padist_gaussian_loss_cone(self, boundary_rad, expwidth):\n        self.in_vals[IN_VAL_PADIST] = PADIST_GLC\n        self.in_vals[IN_VAL_LCBDY] = boundary_rad * 180 / np.pi # rad => deg\n        self.in_vals[IN_VAL_DELTAMU] = expwidth\n        return self", "response": "Set the pitch - angle distribution to a Gaussian loss cone."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the properties of the thermal background plasma.", "response": "def set_thermal_background(self, T_K, nth_cc):\n        \"\"\"Set the properties of the background thermal plasma.\n\n        **Call signature**\n\n        *T_K*\n          The temperature of the background plasma, in Kelvin.\n        *nth_cc*\n          The number density of thermal electrons, in cm^-3.\n        Returns\n          *self* for convenience in chaining.\n\n        Note that the parameters set here are the same as the ones that\n        describe the thermal electron distribution, if you choose one of the\n        electron energy distributions that explicitly models a thermal\n        component (\"thm\", \"tnt\", \"tnp\", \"tng\", \"kappa\" in the code's\n        terminology). For the power-law-y electron distributions, these\n        parameters are used to calculate dispersion parameters (e.g.\n        refractive indices) and a free-free contribution, but their\n        synchrotron contribution is ignored.\n\n        \"\"\"\n        if not (T_K >= 0):\n            raise ValueError('must have T_K >= 0; got %r' % (T_K,))\n        if not (nth_cc >= 0):\n            raise ValueError('must have nth_cc >= 0; got %r, %r' % (nth_cc,))\n\n        self.in_vals[IN_VAL_T0] = T_K\n        self.in_vals[IN_VAL_N0] = nth_cc\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_trapezoidal_integration(self, n):\n        if not (n >= 2):\n            raise ValueError('must have n >= 2; got %r' % (n,))\n\n        self.in_vals[IN_VAL_INTEG_METH] = n + 1\n        return self", "response": "Set the code to use trapezoidal integration."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_rt_coefficients(self, depth0=None):\n        if self.in_vals[IN_VAL_NFREQ] != 1:\n            raise Exception('must have nfreq=1 to run Calculator.find_rt_coefficients()')\n\n        if depth0 is not None:\n            depth = depth0\n            self.in_vals[IN_VAL_DEPTH] = depth0\n        else:\n            depth = self.in_vals[IN_VAL_DEPTH]\n\n        scale_factor = 100\n        buf = np.empty((1, 5), dtype=np.float32)\n\n        def classify(damping_factor):\n            if damping_factor >= 0.99:\n                return 1\n            if damping_factor <= 0.01:\n                return -1\n            return 0\n\n        DONE, SHRINK, GROW, ABORT = 0, 1, 2, 3\n\n        actions = {\n            (-1, -1): SHRINK,\n            (-1,  0): SHRINK,\n            (-1,  1): ABORT,\n            ( 0, -1): SHRINK,\n            ( 0,  0): DONE,\n            ( 0,  1): GROW,\n            ( 1, -1): ABORT,\n            ( 1,  0): GROW,\n            ( 1,  1): GROW,\n        }\n\n        last_change = DONE # our first change will be treated as a change in direction\n\n        for attempt_number in range(20):\n            self.compute_lowlevel(out_values=buf)\n            co = classify(buf[0,OUT_VAL_ODAMP])\n            cx = classify(buf[0,OUT_VAL_XDAMP])\n            action = actions[co, cx]\n            ###print('Z', attempt_number, self.in_vals[IN_VAL_DEPTH], last_change, buf, co, cx, action)\n\n            if action == DONE:\n                break\n            elif action == ABORT:\n                raise Exception('depths of X and O modes are seriously incompatible')\n            elif action == GROW:\n                if last_change != GROW:\n                    scale_factor *= 0.3\n                depth *= scale_factor\n                last_change = GROW\n            elif action == SHRINK:\n                if last_change != SHRINK:\n                    scale_factor *= 0.3\n                depth /= scale_factor\n                last_change = SHRINK\n\n            self.in_vals[IN_VAL_DEPTH] = depth\n        else:\n            # If we get here, we never explicitly quit the loop\n            raise Exception('depth-finding algorithm did not converge!')\n\n        # OK, we found some good depths! Now calculate the RT coefficients. I believe that\n        # I'm doing this right ...\n\n        sfu_to_specintens = 1e4 * cgs.cgsperjy * cgs.cmperau**2 / self.in_vals[IN_VAL_AREA]\n\n        damp_X = buf[0,OUT_VAL_XDAMP]\n        alpha_X = -np.log(damp_X) / depth\n        si_X = buf[0,OUT_VAL_XINT] * sfu_to_specintens\n        j_X = si_X * alpha_X / (1 - damp_X)\n\n        damp_O = buf[0,OUT_VAL_ODAMP]\n        alpha_O = -np.log(damp_O) / depth\n        si_O = buf[0,OUT_VAL_OINT] * sfu_to_specintens\n        j_O = si_O * alpha_O / (1 - damp_O)\n\n        return (j_O, alpha_O, j_X, alpha_X)", "response": "Figure out emission and absorption coefficients for the current parameter set."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfigure out total-intensity emission and absorption coefficients for the current parameters. **Argument** *depth0* (default None) A first guess to use for a good integration depth, in cm. If None, the most recent value is used. **Return value** A tuple ``(j_I, alpha_I)``, where: *j_I* The total intensity emission coefficient, in erg/s/cm^3/Hz/sr. *alpha_I* The total intensity absorption coefficient, in cm^-1. See :meth:`find_rt_coefficients` for an explanation how this routine works. This version merely postprocesses the results from that method to convert the coefficients to refer to total intensity.", "response": "def find_rt_coefficients_tot_intens(self, depth0=None):\n        \"\"\"Figure out total-intensity emission and absorption coefficients for the\n        current parameters.\n\n        **Argument**\n\n        *depth0* (default None)\n          A first guess to use for a good integration depth, in cm. If None,\n          the most recent value is used.\n\n        **Return value**\n\n        A tuple ``(j_I, alpha_I)``, where:\n\n        *j_I*\n          The total intensity emission coefficient, in erg/s/cm^3/Hz/sr.\n        *alpha_I*\n          The total intensity absorption coefficient, in cm^-1.\n\n        See :meth:`find_rt_coefficients` for an explanation how this routine\n        works. This version merely postprocesses the results from that method\n        to convert the coefficients to refer to total intensity.\n\n        \"\"\"\n        j_O, alpha_O, j_X, alpha_X = self.find_rt_coefficients(depth0=depth0)\n        j_I = j_O + j_X\n        alpha_I = 0.5 * (alpha_O + alpha_X) # uhh... right?\n        return (j_I, alpha_I)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef try_open (*args, **kwargs):\n    try:\n        return io.open (*args, **kwargs)\n    except IOError as e:\n        if e.errno == 2:\n            return None\n        raise", "response": "Wrapper for io. open that returns None if the file is not found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_path_func (*baseparts):\n    from os.path import join\n    base = join (*baseparts)\n    def path_func (*args):\n        return join (base, *args)\n    return path_func", "response": "Return a function that joins paths onto some base directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rellink (source, dest):\n    from os.path import isabs, dirname, relpath, abspath\n\n    if isabs (source):\n        os.symlink (source, dest)\n    elif isabs (dest):\n        os.symlink (abspath (source), dest)\n    else:\n        os.symlink (relpath (source, dirname (dest)), dest)", "response": "Create a symbolic link to source and dest."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nensuring that a symbolic link pointing to src named dst is created. Returns a boolean indicating whether the symlink already existed.", "response": "def ensure_symlink (src, dst):\n    \"\"\"Ensure the existence of a symbolic link pointing to src named dst. Returns\n    a boolean indicating whether the symlink already existed.\n\n    \"\"\"\n    try:\n        os.symlink (src, dst)\n    except OSError as e:\n        if e.errno == 17: # EEXIST\n            return True\n        raise\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new Path object with various expansion performed.", "response": "def expand (self, user=False, vars=False, glob=False, resolve=False):\n        \"\"\"Return a new :class:`Path` with various expansions performed. All\n\texpansions are disabled by default but can be enabled by passing in\n\ttrue values in the keyword arguments.\n\n\tuser : bool (default False)\n\t  Expand ``~`` and ``~user`` home-directory constructs. If a username is\n\t  unmatched or ``$HOME`` is unset, no change is made. Calls\n\t  :func:`os.path.expanduser`.\n\tvars : bool (default False)\n\t  Expand ``$var`` and ``${var}`` environment variable constructs. Unknown\n\t  variables are not substituted. Calls :func:`os.path.expandvars`.\n\tglob : bool (default False)\n\t  Evaluate the path as a :mod:`glob` expression and use the matched path.\n\t  If the glob does not match anything, do not change anything. If the\n\t  glob matches more than one path, raise an :exc:`IOError`.\n\tresolve : bool (default False)\n\t  Call :meth:`resolve` on the return value before returning it.\n\n        \"\"\"\n        from os import path\n        from glob import glob\n\n        text = text_type (self)\n        if user:\n            text = path.expanduser (text)\n        if vars:\n            text = path.expandvars (text)\n        if glob:\n            results = glob (text)\n            if len (results) == 1:\n                text = results[0]\n            elif len (results) > 1:\n                raise IOError ('glob of %r should\\'ve returned 0 or 1 matches; got %d'\n                               % (text, len (results)))\n\n        other = self.__class__ (text)\n        if resolve:\n            other = other.resolve ()\n\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new path formed by calling str. format on the textualization of this path.", "response": "def format (self, *args, **kwargs):\n        \"\"\"Return a new path formed by calling :meth:`str.format` on the\n        textualization of this path.\n\n        \"\"\"\n        return self.__class__ (str (self).format (*args, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the path of this path s parent directory.", "response": "def get_parent (self, mode='naive'):\n        \"\"\"Get the path of this path\u2019s parent directory.\n\n        Unlike the :attr:`parent` attribute, this function can correctly\n        ascend into parent directories if *self* is ``\".\"`` or a sequence of\n        ``\"..\"``. The precise way in which it handles these kinds of paths,\n        however, depends on the *mode* parameter:\n\n        ``\"textual\"``\n          Return the same thing as the :attr:`parent` attribute.\n        ``\"resolved\"``\n          As *textual*, but on the :meth:`resolve`-d version of the path. This\n          will always return the physical parent directory in the filesystem.\n          The path pointed to by *self* must exist for this call to succeed.\n        ``\"naive\"``\n          As *textual*, but the parent of ``\".\"`` is ``\"..\"``, and the parent of\n          a sequence of ``\"..\"`` is the same sequence with another ``\"..\"``. Note\n          that this manipulation is still strictly textual, so results when called\n          on paths like ``\"foo/../bar/../other\"`` will likely not be what you want.\n          Furthermore, ``p.get_parent(mode=\"naive\")`` never yields a path equal to\n          ``p``, so some kinds of loops will execute infinitely.\n\n        \"\"\"\n        if mode == 'textual':\n            return self.parent\n\n        if mode == 'resolved':\n            return self.resolve ().parent\n\n        if mode == 'naive':\n            from os.path import pardir\n\n            if not len (self.parts):\n                return self.__class__ (pardir)\n            if all (p == pardir for p in self.parts):\n                return self / pardir\n            return self.parent\n\n        raise ValueError ('unhandled get_parent() mode %r' % (mode, ))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_relative (self, other):\n        if self.is_absolute ():\n            return self\n\n        from os.path import relpath\n        other = self.__class__ (other)\n        return self.__class__ (relpath (text_type (self), text_type (other)))", "response": "Return a new path that is the equivalent of this one relative to the pathother."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef copy_to (self, dest, preserve='mode'):\n        # shutil.copyfile() doesn't let the destination be a directory, so we\n        # have to manage that possibility ourselves.\n\n        import shutil\n        dest = Path (dest)\n\n        if dest.is_dir ():\n            dest = dest / self.name\n\n        if preserve == 'none':\n            shutil.copyfile (str(self), str(dest))\n        elif preserve == 'mode':\n            shutil.copy (str(self), str(dest))\n        elif preserve == 'all':\n            shutil.copy2 (str(self), str(dest))\n        else:\n            raise ValueError ('unrecognized \"preserve\" value %r' % (preserve,))\n\n        return dest", "response": "Copy this path as a file to another path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_dir (self, mode=0o777, parents=False):\n        if parents:\n            p = self.parent\n            if p == self:\n                return False # can never create root; avoids loop when parents=True\n            p.ensure_dir (mode, True)\n\n        made_it = False\n\n        try:\n            self.mkdir (mode)\n            made_it = True\n        except OSError as e:\n            if e.errno == 17: # EEXIST?\n                return False # that's fine\n            raise # other exceptions are not fine\n\n        if not self.is_dir ():\n            import errno\n            raise OSError (errno.ENOTDIR, 'Not a directory', str(self))\n\n        return made_it", "response": "Ensures that this path exists as a directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ensure_parent (self, mode=0o777, parents=False):\n        return self.parent.ensure_dir (mode, parents)", "response": "Ensure that this path s parent directory exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a context manager that creates and cleans up a uniquely - named temporary file with a name similar to this path.", "response": "def make_tempfile (self, want='handle', resolution='try_unlink', suffix='', **kwargs):\n        \"\"\"Get a context manager that creates and cleans up a uniquely-named temporary\n        file with a name similar to this path.\n\n        This function returns a context manager that creates a secure\n        temporary file with a path similar to *self*. In particular, if\n        ``str(self)`` is something like ``foo/bar``, the path of the temporary\n        file will be something like ``foo/bar.ame8_2``.\n\n        The object returned by the context manager depends on the *want* argument:\n\n        ``\"handle\"``\n          An open file-like object is returned. This is the object returned by\n          :class:`tempfile.NamedTemporaryFile`. Its name on the filesystem is\n          accessible as a string as its `name` attribute, or (a customization here)\n          as a :class:`Path` instance as its `path` attribute.\n        ``\"path\"``\n          The temporary file is created as in ``\"handle\"``, but is then immediately\n          closed. A :class:`Path` instance pointing to the path of the temporary file is\n          instead returned.\n\n        If an exception occurs inside the context manager block, the temporary file is\n        left lying around. Otherwise, what happens to it upon exit from the context\n        manager depends on the *resolution* argument:\n\n        ``\"try_unlink\"``\n          Call :meth:`try_unlink` on the temporary file \u2014 no exception is raised if\n          the file did not exist.\n        ``\"unlink\"``\n          Call :meth:`unlink` on the temporary file \u2014 an exception is raised if\n          the file did not exist.\n        ``\"keep\"``\n          The temporary file is left lying around.\n        ``\"overwrite\"``\n          The temporary file is :meth:`rename`-d to overwrite *self*.\n\n        For instance, when rewriting important files, it\u2019s typical to write\n        the new data to a temporary file, and only rename the temporary file\n        to the final destination at the end \u2014 that way, if a problem happens\n        while writing the new data, the original file is left unmodified;\n        otherwise you\u2019d be stuck with a partially-written version of the file.\n        This pattern can be accomplished with::\n\n          p = Path ('path/to/important/file')\n          with p.make_tempfile (resolution='overwrite', mode='wt') as h:\n              print ('important stuff goes here', file=h)\n\n        The *suffix* argument is appended to the temporary file name after the\n        random portion. It defaults to the empty string. If you want it to\n        operate as a typical filename suffix, include a leading ``\".\"``.\n\n        Other **kwargs** are passed to :class:`tempfile.NamedTemporaryFile`.\n\n        \"\"\"\n        if want not in ('handle', 'path'):\n            raise ValueError ('unrecognized make_tempfile() \"want\" mode %r' % (want,))\n        if resolution not in ('unlink', 'try_unlink', 'keep', 'overwrite'):\n            raise ValueError ('unrecognized make_tempfile() \"resolution\" mode %r' % (resolution,))\n        return Path._PathTempfileContextManager (self, want, resolution, suffix, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking this path a symlink pointing to the given target.", "response": "def rellink_to (self, target, force=False):\n        \"\"\"Make this path a symlink pointing to the given *target*, generating the\n\tproper relative path using :meth:`make_relative`. This gives different\n\tbehavior than :meth:`symlink_to`. For instance, ``Path\n\t('a/b').symlink_to ('c')`` results in ``a/b`` pointing to the path\n\t``c``, whereas :meth:`rellink_to` results in it pointing to ``../c``.\n\tThis can result in broken relative paths if (continuing the example)\n\t``a`` is a symbolic link to a directory.\n\n\tIf either *target* or *self* is absolute, the symlink will point at\n\tthe absolute path to *target*. The intention is that if you\u2019re trying\n\tto link ``/foo/bar`` to ``bee/boo``, it probably makes more sense for\n\tthe link to point to ``/path/to/.../bee/boo`` rather than\n\t``../../../../bee/boo``.\n\n\tIf *force* is true, :meth:`try_unlink` will be called on *self* before\n\tthe link is made, forcing its re-creation.\n\n        \"\"\"\n        target = self.__class__ (target)\n\n        if force:\n            self.try_unlink ()\n\n        if self.is_absolute ():\n            target = target.absolute () # force absolute link\n\n        return self.symlink_to (target.make_relative (self.parent))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef rmtree (self, errors='warn'):\n        import shutil\n\n        if errors == 'ignore':\n            ignore_errors = True\n            onerror = None\n        elif errors == 'warn':\n            ignore_errors = False\n            from .cli import warn\n\n            def onerror (func, path, exc_info):\n                warn ('couldn\\'t rmtree %s: in %s of %s: %s', self, func.__name__,\n                      path, exc_info[1])\n        else:\n            raise ValueError ('unexpected \"errors\" keyword %r' % (errors,))\n\n        shutil.rmtree (text_type (self), ignore_errors=ignore_errors, onerror=onerror)\n        return self", "response": "Recursively delete this directory and its contents."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef try_unlink (self):\n        try:\n            self.unlink ()\n            return True\n        except OSError as e:\n            if e.errno == 2:\n                return False # ENOENT\n            raise", "response": "Try to unlink this path. Returns True if the path was really unlinked False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef try_open (self, null_if_noexist=False, **kwargs):\n        try:\n            return self.open (**kwargs)\n        except IOError as e:\n            if e.errno == 2:\n                if null_if_noexist:\n                    import io, os\n                    return io.open (os.devnull, **kwargs)\n                return None\n            raise", "response": "Try to open the file on this path and return the theCOOKIE file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_hdf_store (self, mode='r', **kwargs):\n        from pandas import HDFStore\n        return HDFStore (text_type (self), mode=mode, **kwargs)", "response": "Return the path as an opened HDFStore object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_astropy_ascii (self, **kwargs):\n        from astropy.io import ascii\n        return ascii.read (text_type (self), **kwargs)", "response": "Open as an ASCII table returning a table object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_fits (self, **kwargs):\n        from astropy.io import fits\n        return fits.open (text_type (self), **kwargs)", "response": "Open as a FITS file returning a list of HDUList objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_fits_bintable (self, hdu=1, drop_nonscalar_ok=True, **kwargs):\n        from astropy.io import fits\n        from .numutil import fits_recarray_to_data_frame as frtdf\n\n        with fits.open (text_type (self), mode='readonly', **kwargs) as hdulist:\n            return frtdf (hdulist[hdu].data, drop_nonscalar_ok=drop_nonscalar_ok)", "response": "Open as a FITS file and return a Pandas DataFrame with the data in that table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nopens as an HDF5 file using pandas and return the item stored under the key key.", "response": "def read_hdf (self, key, **kwargs):\n        \"\"\"Open as an HDF5 file using :mod:`pandas` and return the item stored under\n        the key *key*. *kwargs* are passed to :func:`pandas.read_hdf`.\n\n        \"\"\"\n        # This one needs special handling because of the \"key\" and path input.\n        import pandas\n        return pandas.read_hdf (text_type (self), key, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_inifile (self, noexistok=False, typed=False):\n        if typed:\n            from .tinifile import read_stream\n        else:\n            from .inifile import read_stream\n\n        try:\n            with self.open ('rb') as f:\n                for item in read_stream (f):\n                    yield item\n        except IOError as e:\n            if e.errno != 2 or not noexistok:\n                raise", "response": "Open assuming an INI - file format and return a generator yielding the data\n        records."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread in the current object as a JSON - formatted data structure.", "response": "def read_json (self, mode='rt', **kwargs):\n        \"\"\"Use the :mod:`json` module to read in this file as a JSON-formatted data\n        structure. Keyword arguments are passed to :func:`json.load`. Returns the\n        read-in data structure.\n\n        \"\"\"\n        import json\n\n        with self.open (mode=mode) as f:\n            return json.load (f, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_lines (self, mode='rt', noexistok=False, **kwargs):\n        try:\n            with self.open (mode=mode, **kwargs) as f:\n                for line in f:\n                    yield line\n        except IOError as e:\n            if e.errno != 2 or not noexistok:\n                raise", "response": "Generate a sequence of lines from the file pointed to by this path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef read_numpy (self, **kwargs):\n        import numpy as np\n        with self.open ('rb') as f:\n            return np.load (f, **kwargs)", "response": "Read this path into a numpy. ndarray using numpy. load."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread this path into a numpy. ndarray.", "response": "def read_numpy_text (self, dfcols=None, **kwargs):\n        \"\"\"Read this path into a :class:`numpy.ndarray` as a text file using\n        :func:`numpy.loadtxt`. In normal conditions the returned array is\n        two-dimensional, with the first axis spanning the rows in the file and\n        the second axis columns (but see the *unpack* and *dfcols* keywords).\n\n        If *dfcols* is not None, the return value is a\n        :class:`pandas.DataFrame` constructed from the array. *dfcols* should\n        be an iterable of column names, one for each of the columns returned\n        by the :func:`numpy.loadtxt` call. For convenience, if *dfcols* is a\n        single string, it will by turned into an iterable by a call to\n        :func:`str.split`.\n\n        The remaining *kwargs* are passed to :func:`numpy.loadtxt`; they likely are:\n\n\tdtype : data type\n\t  The data type of the resulting array.\n\tcomments : str\n\t  If specific, a character indicating the start of a comment.\n\tdelimiter : str\n\t  The string that separates values. If unspecified, any span of whitespace works.\n\tconverters : dict\n\t  A dictionary mapping zero-based column *number* to a function that will\n\t  turn the cell text into a number.\n\tskiprows : int (default=0)\n\t  Skip this many lines at the top of the file\n\tusecols : sequence\n\t  Which columns keep, by number, starting at zero.\n\tunpack : bool (default=False)\n\t  If true, the return value is transposed to be of shape ``(cols, rows)``.\n\tndmin : int (default=0)\n\t  The returned array will have at least this many dimensions; otherwise\n\t  mono-dimensional axes will be squeezed.\n\n        \"\"\"\n        import numpy as np\n\n        if dfcols is not None:\n            kwargs['unpack'] = True\n\n        retval = np.loadtxt (text_type (self), **kwargs)\n\n        if dfcols is not None:\n            import pandas as pd\n            if isinstance (dfcols, six.string_types):\n                dfcols = dfcols.split ()\n            retval = pd.DataFrame (dict (zip (dfcols, retval)))\n\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread the record from the file using pandas.", "response": "def read_pandas (self, format='table', **kwargs):\n        \"\"\"Read using :mod:`pandas`. The function ``pandas.read_FORMAT`` is called\n        where ``FORMAT`` is set from the argument *format*. *kwargs* are\n        passed to this function. Supported formats likely include\n        ``clipboard``, ``csv``, ``excel``, ``fwf``, ``gbq``, ``html``,\n        ``json``, ``msgpack``, ``pickle``, ``sql``, ``sql_query``,\n        ``sql_table``, ``stata``, ``table``. Note that ``hdf`` is not\n        supported because it requires a non-keyword argument; see\n        :meth:`Path.read_hdf`.\n\n        \"\"\"\n        import pandas\n\n        reader = getattr (pandas, 'read_' + format, None)\n        if not callable (reader):\n            raise PKError ('unrecognized Pandas format %r: no function pandas.read_%s',\n                           format, format)\n\n        with self.open ('rb') as f:\n            return reader (f, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the file and unpickle one object from it using pickle and return the object.", "response": "def read_pickle (self):\n        \"\"\"Open the file, unpickle one object from it using :mod:`pickle`, and return\n        it.\n\n        \"\"\"\n        gen = self.read_pickles ()\n        value = gen.next ()\n        gen.close ()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a sequence of objects by opening the path and unpickling items until EOF is reached.", "response": "def read_pickles (self):\n        \"\"\"Generate a sequence of objects by opening the path and unpickling items\n        until EOF is reached.\n\n        \"\"\"\n        try:\n            import cPickle as pickle\n        except ImportError:\n            import pickle\n\n        with self.open (mode='rb') as f:\n            while True:\n                try:\n                    obj = pickle.load (f)\n                except EOFError:\n                    break\n                yield obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_text(self, encoding=None, errors=None, newline=None):\n        with self.open (mode='rt', encoding=encoding, errors=errors, newline=newline) as f:\n            return f.read()", "response": "Read this path as one large piece of text and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_toml(self, encoding=None, errors=None, newline=None, **kwargs):\n        import pytoml\n\n        with self.open (mode='rt', encoding=encoding, errors=errors, newline=newline) as f:\n            return pytoml.load (f, **kwargs)", "response": "Read this path as a TOML document."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef read_yaml (self, encoding=None, errors=None, newline=None, **kwargs):\n        import yaml\n\n        with self.open (mode='rt', encoding=encoding, errors=errors, newline=newline) as f:\n            return yaml.load (f, **kwargs)", "response": "Read this path as a YAML document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_pickles (self, objs):\n        try:\n            import cPickle as pickle\n        except ImportError:\n            import pickle\n\n        with self.open (mode='wb') as f:\n            for obj in objs:\n                pickle.dump (obj, f)", "response": "Write the pickles of the given objects to the current path in sequence\n        using pickle."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_yaml (self, data, encoding=None, errors=None, newline=None, **kwargs):\n        import yaml\n\n        with self.open (mode='wt', encoding=encoding, errors=errors, newline=newline) as f:\n            return yaml.dump (data, stream=f, **kwargs)", "response": "Write data to this path as a YAML document."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a Numpy record array into a Pandas DataFrame.", "response": "def fits_recarray_to_data_frame (recarray, drop_nonscalar_ok=True):\n    \"\"\"Convert a FITS data table, stored as a Numpy record array, into a Pandas\n    DataFrame object. By default, non-scalar columns are discarded, but if\n    *drop_nonscalar_ok* is False then a :exc:`ValueError` is raised. Column\n    names are lower-cased. Example::\n\n      from pwkit import io, numutil\n      hdu_list = io.Path ('my-table.fits').read_fits ()\n      # assuming the first FITS extension is a binary table:\n      df = numutil.fits_recarray_to_data_frame (hdu_list[1].data)\n\n    FITS data are big-endian, whereas nowadays almost everything is\n    little-endian. This seems to be an issue for Pandas DataFrames, where\n    ``df[['col1', 'col2']]`` triggers an assertion for me if the underlying\n    data are not native-byte-ordered. This function normalizes the read-in\n    data to native endianness to avoid this.\n\n    See also :meth:`pwkit.io.Path.read_fits_bintable`.\n\n    \"\"\"\n    from pandas import DataFrame\n\n    def normalize ():\n        for column in recarray.columns:\n            n = column.name\n            d = recarray[n]\n\n            if d.ndim != 1:\n                if not drop_nonscalar_ok:\n                    raise ValueError ('input must have only scalar columns')\n                continue\n\n            if d.dtype.isnative:\n                yield (n.lower (), d)\n            else:\n                yield (n.lower (), d.byteswap (True).newbyteorder ())\n\n    return DataFrame (dict (normalize ()))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data_frame_to_astropy_table (dataframe):\n    from astropy.utils import OrderedDict\n    from astropy.table import Table, Column, MaskedColumn\n    from astropy.extern import six\n\n    out = OrderedDict()\n\n    for name in dataframe.columns:\n        column = dataframe[name]\n        mask = np.array (column.isnull ())\n        data = np.array (column)\n\n        if data.dtype.kind == 'O':\n            # If all elements of an object array are string-like or np.nan\n            # then coerce back to a native numpy str/unicode array.\n            string_types = six.string_types\n            if six.PY3:\n                string_types += (bytes,)\n            nan = np.nan\n            if all(isinstance(x, string_types) or x is nan for x in data):\n                # Force any missing (null) values to b''.  Numpy will\n                # upcast to str/unicode as needed.\n                data[mask] = b''\n\n                # When the numpy object array is represented as a list then\n                # numpy initializes to the correct string or unicode type.\n                data = np.array([x for x in data])\n\n        if np.any(mask):\n            out[name] = MaskedColumn(data=data, name=name, mask=mask)\n        else:\n            out[name] = Column(data=data, name=name)\n\n    return Table(out)", "response": "This method converts a Pandas\n   object to an Astropy table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef page_data_frame (df, pager_argv=['less'], **kwargs):\n    import codecs, subprocess, sys\n\n    pager = subprocess.Popen (pager_argv, shell=False,\n                              stdin=subprocess.PIPE,\n                              close_fds=True)\n\n    try:\n        enc = codecs.getwriter (sys.stdout.encoding or 'utf8') (pager.stdin)\n        df.to_string (enc, **kwargs)\n    finally:\n        enc.close ()\n        pager.stdin.close ()\n        pager.wait ()", "response": "Render a DataFrame as text and send it to a terminal pager program."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an ordered array of values generate a set of slices that traverse all of the values separated by gaps of size larger than maxgap.", "response": "def slice_around_gaps (values, maxgap):\n    \"\"\"Given an ordered array of values, generate a set of slices that traverse\n    all of the values. Within each slice, no gap between adjacent values is\n    larger than `maxgap`. In other words, these slices break the array into\n    chunks separated by gaps of size larger than maxgap.\n\n    \"\"\"\n    if not (maxgap > 0):\n        # above test catches NaNs, other weird cases\n        raise ValueError ('maxgap must be positive; got %r' % maxgap)\n\n    values = np.asarray (values)\n    delta = values[1:] - values[:-1]\n\n    if np.any (delta < 0):\n        raise ValueError ('values must be in nondecreasing order')\n\n    whgap = np.where (delta > maxgap)[0] + 1\n    prev_idx = None\n\n    for gap_idx in whgap:\n        yield slice (prev_idx, gap_idx)\n        prev_idx = gap_idx\n\n    yield slice (prev_idx, None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving an ordered array of values generate a set of slices that traverse all of the items in the a .", "response": "def slice_evenly_with_gaps (values, target_len, maxgap):\n    \"\"\"Given an ordered array of values, generate a set of slices that traverse\n    all of the values. Each slice contains about `target_len` items. However,\n    no slice contains a gap larger than `maxgap`, so a slice may contain only\n    a single item (if it is surrounded on both sides by a large gap). If a\n    non-gapped run of values does not divide evenly into `target_len`, the\n    algorithm errs on the side of making the slices contain more than\n    `target_len` items, rather than fewer. It also attempts to keep the slice\n    size uniform within each non-gapped run.\n\n    \"\"\"\n    if not (target_len > 0):\n        raise ValueError ('target_len must be positive; got %r' % target_len)\n\n    values = np.asarray (values)\n    l = values.size\n\n    for gapslice in slice_around_gaps (values, maxgap):\n        start, stop, ignored_stride = gapslice.indices (l)\n        num_elements = stop - start\n        nsegments = int (np.floor (float (num_elements) / target_len))\n        nsegments = max (nsegments, 1)\n        nsegments = min (nsegments, num_elements)\n        segment_len = num_elements / nsegments\n        offset = 0.\n        prev = start\n\n        for _ in range (nsegments):\n            offset += segment_len\n            next = start + int (round (offset))\n            if next > prev:\n                yield slice (prev, next)\n            prev = next"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef reduce_data_frame (df, chunk_slicers,\n                       avg_cols=(),\n                       uavg_cols=(),\n                       minmax_cols=(),\n                       nchunk_colname='nchunk',\n                       uncert_prefix='u',\n                       min_points_per_chunk=3):\n    \"\"\"\"Reduce\" a DataFrame by collapsing rows in grouped chunks. Returns another\n    DataFrame with similar columns but fewer rows.\n\n    Arguments:\n\n    df\n      The input :class:`pandas.DataFrame`.\n    chunk_slicers\n      An iterable that returns values that are used to slice *df* with its\n      :meth:`pandas.DataFrame.iloc` indexer. An example value might be the\n      generator returned from :func:`slice_evenly_with_gaps`.\n    avg_cols\n      An iterable of names of columns that are to be reduced by taking the mean.\n    uavg_cols\n      An iterable of names of columns that are to be reduced by taking a\n      weighted mean.\n    minmax_cols\n      An iterable of names of columns that are to be reduced by reporting minimum\n      and maximum values.\n    nchunk_colname\n      The name of a column to create reporting the number of rows contributing\n      to each chunk.\n    uncert_prefix\n      The column name prefix for locating uncertainty estimates. By default, the\n      uncertainty on the column ``\"temp\"`` is given in the column ``\"utemp\"``.\n    min_points_per_chunk\n      Require at least this many rows in each chunk. Smaller chunks are discarded.\n\n    Returns a new :class:`pandas.DataFrame`.\n\n    \"\"\"\n    subds = [df.iloc[idx] for idx in chunk_slicers]\n    subds = [sd for sd in subds if sd.shape[0] >= min_points_per_chunk]\n\n    chunked = df.__class__ ({nchunk_colname: np.zeros (len (subds), dtype=np.int)})\n\n    # Some future-proofing: allow possibility of different ways of mapping\n    # from a column giving a value to a column giving its uncertainty.\n\n    uncert_col_name = lambda c: uncert_prefix + c\n\n    for i, subd in enumerate (subds):\n        label = chunked.index[i]\n        chunked.loc[label,nchunk_colname] = subd.shape[0]\n\n        for col in avg_cols:\n            chunked.loc[label,col] = subd[col].mean ()\n\n        for col in uavg_cols:\n            ucol = uncert_col_name (col)\n            v, u = weighted_mean (subd[col], subd[ucol])\n            chunked.loc[label,col] = v\n            chunked.loc[label,ucol] = u\n\n        for col in minmax_cols:\n            chunked.loc[label, 'min_'+col] = subd[col].min ()\n            chunked.loc[label, 'max_'+col] = subd[col].max ()\n\n    return chunked", "response": "Reduce a DataFrame by collapsing rows in grouped chunks."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reduce_data_frame_evenly_with_gaps (df, valcol, target_len, maxgap, **kwargs):\n    return reduce_data_frame (df,\n                              slice_evenly_with_gaps (df[valcol], target_len, maxgap),\n                              **kwargs)", "response": "Reduce a DataFrame by collapsing rows in grouped chunks grouping based on gaps in each column."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsmooths data series according to a window weighting based on uncertainties.", "response": "def usmooth (window, uncerts, *data, **kwargs):\n    \"\"\"Smooth data series according to a window, weighting based on uncertainties.\n\n    Arguments:\n\n    window\n      The smoothing window.\n    uncerts\n      An array of uncertainties used to weight the smoothing.\n    data\n      One or more data series, of the same size as *uncerts*.\n    k = None\n      If specified, only every *k*-th point of the results will be kept. If k\n      is None (the default), it is set to ``window.size``, i.e. correlated\n      points will be discarded.\n\n    Returns: ``(s_uncerts, s_data[0], s_data[1], ...)``, the smoothed\n    uncertainties and data series.\n\n    Example::\n\n        u, x, y = numutil.usmooth (np.hamming (7), u, x, y)\n\n    \"\"\"\n    window = np.asarray (window)\n    uncerts = np.asarray (uncerts)\n\n    # Hacky keyword argument handling because you can't write \"def foo (*args,\n    # k=0)\".\n\n    k = kwargs.pop ('k', None)\n\n    if len (kwargs):\n        raise TypeError (\"smooth() got an unexpected keyword argument '%s'\"\n                         % kwargs.keys ()[0])\n\n    # Done with kwargs futzing.\n\n    if k is None:\n        k = window.size\n\n    conv = lambda q, r: np.convolve (q, r, mode='valid')\n\n    if uncerts is None:\n        w = np.ones_like (x)\n    else:\n        w = uncerts ** -2\n\n    cw = conv (w, window)\n    cu = np.sqrt (conv (w, window**2)) / cw\n    result = [cu] + [conv (w * np.asarray (x), window) / cw for x in data]\n\n    if k != 1:\n        result = [x[::k] for x in result]\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dfsmooth (window, df, ucol, k=None):\n    import pandas as pd\n\n    if k is None:\n        k = window.size\n\n    conv = lambda q, r: np.convolve (q, r, mode='valid')\n    w = df[ucol] ** -2\n    invcw = 1. / conv (w, window)\n\n    # XXX: we're not smoothing the index.\n\n    res = {}\n\n    for col in df.columns:\n        if col == ucol:\n            res[col] = np.sqrt (conv (w, window**2)) * invcw\n        else:\n            res[col] = conv (w * df[col], window) * invcw\n\n    res = pd.DataFrame (res)\n    return res[::k]", "response": "Smooth a dataframe according to a window weighting based on a uncertainties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parallel_newton (func, x0, fprime=None, par_args=(), simple_args=(), tol=1.48e-8,\n                     maxiter=50, parallel=True, **kwargs):\n    \"\"\"A parallelized version of :func:`scipy.optimize.newton`.\n\n    Arguments:\n\n    func\n      The function to search for zeros, called as ``f(x, [*par_args...], [*simple_args...])``.\n    x0\n      The initial point for the zero search.\n    fprime\n      (Optional) The first derivative of *func*, called the same way.\n    par_args\n      Tuple of additional parallelized arguments.\n    simple_args\n      Tuple of additional arguments passed identically to every invocation.\n    tol\n      The allowable error of the zero value.\n    maxiter\n      Maximum number of iterations.\n    parallel\n      Controls parallelization; default uses all available cores. See\n      :func:`pwkit.parallel.make_parallel_helper`.\n    kwargs\n      Passed to :func:`scipy.optimize.newton`.\n\n    Returns: an array of locations of zeros.\n\n    Finds zeros in parallel. The values *x0*, *tol*, *maxiter*, and the items\n    of *par_args* should all be numeric, and may be N-dimensional Numpy\n    arrays. They are all broadcast to a common shape, and one zero-finding run\n    is performed for each element in the resulting array. The return value is\n    an array of zero locations having the same shape as the common broadcast\n    of the parameters named above.\n\n    The *simple_args* are passed to each function identically for each\n    integration. They do not need to be Pickle-able.\n\n    Example::\n\n       >>> parallel_newton (lambda x, a: x - 2 * a, 2,\n                            par_args=(np.arange (6),))\n       <<< array([  0.,   2.,   4.,   6.,   8.,  10.])\n       >>> parallel_newton (lambda x: np.sin (x), np.arange (6))\n       <<< array([  0.00000000e+00,   3.65526589e-26,   3.14159265e+00,\n                    3.14159265e+00,   3.14159265e+00,   6.28318531e+00])\n\n    \"\"\"\n    from scipy.optimize import newton\n\n    from .parallel import make_parallel_helper\n    phelp = make_parallel_helper (parallel)\n\n    if not isinstance (par_args, tuple):\n        raise ValueError ('par_args must be a tuple')\n\n    if not isinstance (simple_args, tuple):\n        raise ValueError ('simple_args must be a tuple')\n\n    bc_raw = np.broadcast_arrays (x0, tol, maxiter, *par_args)\n    bc_1d = tuple (np.atleast_1d (a) for a in bc_raw)\n\n    def gen_var_args ():\n        for i in range (bc_1d[0].size):\n            yield tuple (x.flat[i] for x in bc_1d)\n\n    def helper (i, _, var_args):\n        x0, tol, maxiter = var_args[:3]\n        args = var_args[3:] + simple_args\n        return newton (func, x0, fprime=fprime, args=args, tol=tol,\n                       maxiter=maxiter, **kwargs)\n\n    with phelp.get_ppmap () as ppmap:\n        result = np.asarray (ppmap (helper, None, gen_var_args ()))\n\n    if bc_raw[0].ndim == 0:\n        return np.asscalar (result)\n    return result", "response": "A parallelized version of scipy. optimize. newton."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parallel_quad (func, a, b, par_args=(), simple_args=(), parallel=True, **kwargs):\n    from scipy.integrate import quad\n\n    from .parallel import make_parallel_helper\n    phelp = make_parallel_helper (parallel)\n\n    if not isinstance (par_args, tuple):\n        raise ValueError ('par_args must be a tuple')\n\n    if not isinstance (simple_args, tuple):\n        raise ValueError ('simple_args must be a tuple')\n\n    bc_raw = np.broadcast_arrays (a, b, *par_args)\n    bc_1d = tuple (np.atleast_1d (a) for a in bc_raw)\n\n    def gen_var_args ():\n        for i in range (bc_1d[0].size):\n            yield tuple (x.flat[i] for x in bc_1d)\n\n    def helper (i, _, var_args):\n        a, b = var_args[:2]\n        return quad (func, a, b, var_args[2:] + simple_args, **kwargs)\n\n    with phelp.get_ppmap () as ppmap:\n        result_list = ppmap (helper, None, gen_var_args ())\n\n    if bc_raw[0].ndim == 0:\n        return np.asarray (result_list[0])\n\n    result_arr = np.empty ((2,) + bc_raw[0].shape)\n    for i in range (bc_1d[0].size):\n        result_arr[0].flat[i], result_arr[1].flat[i] = result_list[i]\n    return result_arr", "response": "A parallelized version of scipy. integrate. quad."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the variance of a weighted sample.", "response": "def weighted_variance (x, weights):\n    \"\"\"Return the variance of a weighted sample.\n\n    The weighted sample mean is calculated and subtracted off, so the returned\n    variance is upweighted by ``n / (n - 1)``. If the sample mean is known to\n    be zero, you should just compute ``np.average (x**2, weights=weights)``.\n\n    \"\"\"\n    n = len (x)\n    if n < 3:\n        raise ValueError ('cannot calculate meaningful variance of fewer '\n                          'than three samples')\n    wt_mean = np.average (x, weights=weights)\n    return np.average (np.square (x - wt_mean), weights=weights) * n / (n - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unit_tophat_ee (x):\n    x = np.asarray (x)\n    x1 = np.atleast_1d (x)\n    r = ((0 < x1) & (x1 < 1)).astype (x.dtype)\n    if x.ndim == 0:\n        return np.asscalar (r)\n    return r", "response": "Tophat function on the unit interval left - exclusive and right - exclusive."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_tophat_ee (lower, upper):\n    if not np.isfinite (lower):\n        raise ValueError ('\"lower\" argument must be finite number; got %r' % lower)\n    if not np.isfinite (upper):\n        raise ValueError ('\"upper\" argument must be finite number; got %r' % upper)\n\n    def range_tophat_ee (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = ((lower < x1) & (x1 < upper)).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    range_tophat_ee.__doc__ = ('Ranged tophat function, left-exclusive and '\n                               'right-exclusive. Returns 1 if %g < x < %g, '\n                               '0 otherwise.') % (lower, upper)\n    return range_tophat_ee", "response": "Return a ufunc - like tophat function on the defined range left - exclusive\n    and right - exclusive. Returns 1 if lower < x < upper 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_tophat_ei (lower, upper):\n    if not np.isfinite (lower):\n        raise ValueError ('\"lower\" argument must be finite number; got %r' % lower)\n    if not np.isfinite (upper):\n        raise ValueError ('\"upper\" argument must be finite number; got %r' % upper)\n\n    def range_tophat_ei (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = ((lower < x1) & (x1 <= upper)).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    range_tophat_ei.__doc__ = ('Ranged tophat function, left-exclusive and '\n                               'right-inclusive. Returns 1 if %g < x <= %g, '\n                               '0 otherwise.') % (lower, upper)\n    return range_tophat_ei", "response": "Return a ufunc - like tophat function on the defined range left - exclusive\n    and right - inclusive. Returns 1 if lower < x < upper 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a ufunc - like tophat function on the defined range left - inclusive and right - exclusive. Returns 1 if lower < x < upper 0 otherwise.", "response": "def make_tophat_ie (lower, upper):\n    \"\"\"Return a ufunc-like tophat function on the defined range, left-inclusive\n    and right-exclusive. Returns 1 if lower <= x < upper, 0 otherwise.\n\n    \"\"\"\n    if not np.isfinite (lower):\n        raise ValueError ('\"lower\" argument must be finite number; got %r' % lower)\n    if not np.isfinite (upper):\n        raise ValueError ('\"upper\" argument must be finite number; got %r' % upper)\n\n    def range_tophat_ie (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = ((lower <= x1) & (x1 < upper)).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    range_tophat_ie.__doc__ = ('Ranged tophat function, left-inclusive and '\n                               'right-exclusive. Returns 1 if %g <= x < %g, '\n                               '0 otherwise.') % (lower, upper)\n    return range_tophat_ie"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_tophat_ii (lower, upper):\n    if not np.isfinite (lower):\n        raise ValueError ('\"lower\" argument must be finite number; got %r' % lower)\n    if not np.isfinite (upper):\n        raise ValueError ('\"upper\" argument must be finite number; got %r' % upper)\n\n    def range_tophat_ii (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = ((lower <= x1) & (x1 <= upper)).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    range_tophat_ii.__doc__ = ('Ranged tophat function, left-inclusive and '\n                               'right-inclusive. Returns 1 if %g <= x <= %g, '\n                               '0 otherwise.') % (lower, upper)\n    return range_tophat_ii", "response": "Return a ufunc - like tophat function on the defined range left - inclusive\n    and right - inclusive. Returns 1 if lower < x < upper 0 otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a ufunc - like step function that is left - continuous. Returns 1 if x > transition 0 otherwise.", "response": "def make_step_lcont (transition):\n    \"\"\"Return a ufunc-like step function that is left-continuous. Returns 1 if\n    x > transition, 0 otherwise.\n\n    \"\"\"\n    if not np.isfinite (transition):\n        raise ValueError ('\"transition\" argument must be finite number; got %r' % transition)\n\n    def step_lcont (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = (x1 > transition).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    step_lcont.__doc__ = ('Left-continuous step function. Returns 1 if x > %g, '\n                          '0 otherwise.') % (transition,)\n    return step_lcont"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a ufunc - like step function that is right - continuous. Returns 1 if x < transition 0 otherwise.", "response": "def make_step_rcont (transition):\n    \"\"\"Return a ufunc-like step function that is right-continuous. Returns 1 if\n    x >= transition, 0 otherwise.\n\n    \"\"\"\n    if not np.isfinite (transition):\n        raise ValueError ('\"transition\" argument must be finite number; got %r' % transition)\n\n    def step_rcont (x):\n        x = np.asarray (x)\n        x1 = np.atleast_1d (x)\n        r = (x1 >= transition).astype (x.dtype)\n        if x.ndim == 0:\n            return np.asscalar (r)\n        return r\n\n    step_rcont.__doc__ = ('Right-continuous step function. Returns 1 if x >= '\n                          '%g, 0 otherwise.') % (transition,)\n    return step_rcont"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a model summing multiple APEC components at fixed temperatures.", "response": "def make_fixed_temp_multi_apec(kTs, name_template='apec%d', norm=None):\n    \"\"\"Create a model summing multiple APEC components at fixed temperatures.\n\n    *kTs*\n      An iterable of temperatures for the components, in keV.\n    *name_template* = 'apec%d'\n      A template to use for the names of each component; it is string-formatted\n      with the 0-based component number as an argument.\n    *norm* = None\n      An initial normalization to be used for every component, or None to use\n      the Sherpa default.\n    Returns:\n      A tuple ``(total_model, sub_models)``, where *total_model* is a Sherpa\n      model representing the sum of the APEC components and *sub_models* is\n      a list of the individual models.\n\n    This function creates a vector of APEC model components and sums them.\n    Their *kT* parameters are set and then frozen (using\n    :func:`sherpa.astro.ui.freeze`), so that upon exit from this function, the\n    amplitude of each component is the only free parameter.\n\n    \"\"\"\n    total_model = None\n    sub_models = []\n\n    for i, kT in enumerate(kTs):\n        component = ui.xsapec(name_template % i)\n        component.kT = kT\n        ui.freeze(component.kT)\n        if norm is not None:\n            component.norm = norm\n        sub_models.append(component)\n\n        if total_model is None:\n            total_model = component\n        else:\n            total_model = total_model + component\n\n    return total_model, sub_models"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand_rmf_matrix(rmf):\n    n_chan = rmf.e_min.size\n    n_energy = rmf.n_grp.size\n\n    expanded = np.zeros((n_energy, n_chan))\n    mtx_ofs = 0\n    grp_ofs = 0\n\n    for i in range(n_energy):\n        for j in range(rmf.n_grp[i]):\n            f = rmf.f_chan[grp_ofs]\n            n = rmf.n_chan[grp_ofs]\n            expanded[i,f:f+n] = rmf.matrix[mtx_ofs:mtx_ofs+n]\n            mtx_ofs += n\n            grp_ofs += 1\n\n    return expanded", "response": "Expand an RMF matrix stored in compressed form."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nderives an identity RMF from an existing one.", "response": "def derive_identity_rmf(name, rmf):\n    \"\"\"Create an \"identity\" RMF that does not mix energies.\n\n    *name*\n      The name of the RMF object to be created; passed to Sherpa.\n    *rmf*\n      An existing RMF object on which to base this one.\n    Returns:\n      A new RMF1D object that has a response matrix that is as close to\n      diagonal as we can get in energy space, and that has a constant\n      sensitivity as a function of detector channel.\n\n    In many X-ray observations, the relevant background signal does not behave\n    like an astrophysical source that is filtered through the telescope's\n    response functions. However, I have been unable to get current Sherpa\n    (version 4.9) to behave how I want when working with backround models that\n    are *not* filtered through these response functions. This function\n    constructs an \"identity\" RMF response matrix that provides the best\n    possible approximation of a passthrough \"instrumental response\": it mixes\n    energies as little as possible and has a uniform sensitivity as a function\n    of detector channel.\n\n    \"\"\"\n    from sherpa.astro.data import DataRMF\n    from sherpa.astro.instrument import RMF1D\n\n    # The \"x\" axis of the desired matrix -- the columnar direction; axis 1 --\n    # is \"channels\". There are n_chan of them and each maps to a notional\n    # energy range specified by \"e_min\" and \"e_max\".\n    #\n    # The \"y\" axis of the desired matrix -- the row direction; axis 1 -- is\n    # honest-to-goodness energy. There are tot_n_energy energy bins, each\n    # occupying a range specified by \"energ_lo\" and \"energ_hi\".\n    #\n    # We want every channel that maps to a valid output energy to have a\n    # nonzero entry in the matrix. The relative sizes of n_energy and n_cell\n    # can vary, as can the bounds of which regions of each axis can be validly\n    # mapped to each other. So this problem is basically equivalent to that of\n    # drawing an arbitrary pixelated line on bitmap, without anti-aliasing.\n    #\n    # The output matrix is represented in a row-based sparse format.\n    #\n    # - There is a integer vector \"n_grp\" of size \"n_energy\". It gives the\n    #   number of \"groups\" needed to fill in each row of the matrix. Let\n    #   \"tot_groups = sum(n_grp)\". For a given row, \"n_grp[row_index]\" may\n    #   be zero, indicating that the row is all zeros.\n    # - There are integer vectors \"f_chan\" and \"n_chan\", each of size\n    #   \"tot_groups\", that define each group. \"f_chan\" gives the index of\n    #   the first channel column populated by the group; \"n_chan\" gives the\n    #   number of columns populated by the group. Note that there can\n    #   be multiple groups for a single row, so successive group records\n    #   may fill in different pieces of the same row.\n    # - Let \"tot_cells = sum(n_chan)\".\n    # - There is a vector \"matrix\" of size \"tot_cells\" that stores the actual\n    #   matrix data. This is just a concatenation of all the data corresponding\n    #   to each group.\n    # - Unpopulated matrix entries are zero.\n    #\n    # See expand_rmf_matrix() for a sloppy implementation of how to unpack\n    # this sparse format.\n\n    n_chan = rmf.e_min.size\n    n_energy = rmf.energ_lo.size\n\n    c_lo_offset = rmf.e_min[0]\n    c_lo_slope = (rmf.e_min[-1] - c_lo_offset) / (n_chan - 1)\n\n    c_hi_offset = rmf.e_max[0]\n    c_hi_slope = (rmf.e_max[-1] - c_hi_offset) / (n_chan - 1)\n\n    e_lo_offset = rmf.energ_lo[0]\n    e_lo_slope = (rmf.energ_lo[-1] - e_lo_offset) / (n_energy - 1)\n\n    e_hi_offset = rmf.energ_hi[0]\n    e_hi_slope = (rmf.energ_hi[-1] - e_hi_offset) / (n_energy - 1)\n\n    all_e_indices = np.arange(n_energy)\n    all_e_los = e_lo_slope * all_e_indices + e_lo_offset\n    start_chans = np.floor((all_e_los - c_lo_offset) / c_lo_slope).astype(np.int)\n\n    all_e_his = e_hi_slope * all_e_indices + e_hi_offset\n    stop_chans = np.ceil((all_e_his - c_hi_offset) / c_hi_slope).astype(np.int)\n\n    first_e_index_on_channel_grid = 0\n    while stop_chans[first_e_index_on_channel_grid] < 0:\n        first_e_index_on_channel_grid += 1\n\n    last_e_index_on_channel_grid = n_energy - 1\n    while start_chans[last_e_index_on_channel_grid] >= n_chan:\n        last_e_index_on_channel_grid -= 1\n\n    n_nonzero_rows = last_e_index_on_channel_grid + 1 - first_e_index_on_channel_grid\n    e_slice = slice(first_e_index_on_channel_grid, last_e_index_on_channel_grid + 1)\n    n_grp = np.zeros(n_energy, dtype=np.int)\n    n_grp[e_slice] = 1\n\n    start_chans = np.maximum(start_chans[e_slice], 0)\n    stop_chans = np.minimum(stop_chans[e_slice], n_chan - 1)\n\n    # We now have a first cut at a row-oriented expression of our \"identity\"\n    # RMF. However, it's conservative. Trim down to eliminate overlaps between\n    # sequences.\n\n    for i in range(n_nonzero_rows - 1):\n        my_end = stop_chans[i]\n        next_start = start_chans[i+1]\n        if next_start <= my_end:\n            stop_chans[i] = max(start_chans[i], next_start - 1)\n\n    # Results are funky unless the sums along the vertical axis are constant.\n    # Ideally the sum along the *horizontal* axis would add up to 1 (since,\n    # ideally, each row is a probability distribution), but it is not\n    # generally possible to fulfill both of these constraints simultaneously.\n    # The latter constraint does not seem to matter in practice so we ignore it.\n    # Due to the funky encoding of the matrix, we need to build a helper table\n    # to meet the vertical-sum constraint.\n\n    counts = np.zeros(n_chan, dtype=np.int)\n\n    for i in range(n_nonzero_rows):\n        counts[start_chans[i]:stop_chans[i]+1] += 1\n\n    counts[:start_chans.min()] = 1\n    counts[stop_chans.max()+1:] = 1\n    assert (counts > 0).all()\n\n    # We can now build the matrix.\n\n    f_chan = start_chans\n    rmfnchan = stop_chans + 1 - f_chan\n    assert (rmfnchan > 0).all()\n\n    matrix = np.zeros(rmfnchan.sum())\n    amounts = 1. / counts\n    ofs = 0\n\n    for i in range(n_nonzero_rows):\n        f = f_chan[i]\n        n = rmfnchan[i]\n        matrix[ofs:ofs+n] = amounts[f:f+n]\n        ofs += n\n\n    # All that's left to do is create the Python objects.\n\n    drmf = DataRMF(\n        name,\n        rmf.detchans,\n        rmf.energ_lo,\n        rmf.energ_hi,\n        n_grp,\n        f_chan,\n        rmfnchan,\n        matrix,\n        offset = 0,\n        e_min = rmf.e_min,\n        e_max = rmf.e_max,\n        header = None\n    )\n\n    return RMF1D(drmf, pha=rmf._pha)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef derive_identity_arf(name, arf):\n    from sherpa.astro.data import DataARF\n    from sherpa.astro.instrument import ARF1D\n\n    darf = DataARF(\n        name,\n        arf.energ_lo,\n        arf.energ_hi,\n        np.ones(arf.specresp.shape),\n        arf.bin_lo,\n        arf.bin_hi,\n        arf.exposure,\n        header = None,\n    )\n    return ARF1D(darf, pha=arf._pha)", "response": "Derive an identity ARF from an existing ARF object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets data for a quantile - quantile plot of the source data and model.", "response": "def get_source_qq_data(id=None):\n    \"\"\"Get data for a quantile-quantile plot of the source data and model.\n\n    *id*\n      The dataset id for which to get the data; defaults if unspecified.\n    Returns:\n      An ndarray of shape ``(3, npts)``. The first slice is the energy axis in\n      keV; the second is the observed values in each bin (counts, or rate, or\n      rate per keV, etc.); the third is the corresponding model value in each\n      bin.\n\n    The inputs are implicit; the data are obtained from the current state of\n    the Sherpa ``ui`` module.\n\n    \"\"\"\n    sdata = ui.get_data(id=id)\n    kev = sdata.get_x()\n    obs_data = sdata.counts\n    model_data = ui.get_model(id=id)(kev)\n    return np.vstack((kev, obs_data, model_data))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_bkg_qq_data(id=None, bkg_id=None):\n    bdata = ui.get_bkg(id=id, bkg_id=bkg_id)\n    kev = bdata.get_x()\n    obs_data = bdata.counts\n    model_data = ui.get_bkg_model(id=id, bkg_id=bkg_id)(kev)\n    return np.vstack((kev, obs_data, model_data))", "response": "Get data for a quantile - quantile plot of the background data and model."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_qq_plot(kev, obs, mdl, unit, key_text):\n    import omega as om\n\n    kev = np.asarray(kev)\n    obs = np.asarray(obs)\n    mdl = np.asarray(mdl)\n\n    c_obs = np.cumsum(obs)\n    c_mdl = np.cumsum(mdl)\n    mx = max(c_obs[-1], c_mdl[-1])\n\n    p = om.RectPlot()\n    p.addXY([0, mx], [0, mx], '1:1')\n    p.addXY(c_mdl, c_obs, key_text)\n\n    # HACK: this range of numbers is chosen to give reasonable sampling for my\n    # sources, which are typically quite soft.\n    locs = np.array([0, 0.05, 0.08, 0.11, 0.17, 0.3, 0.4, 0.7, 1]) * (kev.size - 2)\n    c0 = mx * 1.05\n    c1 = mx * 1.1\n\n    for loc in locs:\n        i0 = int(np.floor(loc))\n        frac = loc - i0\n        kevval = (1 - frac) * kev[i0] + frac * kev[i0+1]\n        mdlval = (1 - frac) * c_mdl[i0] + frac * c_mdl[i0+1]\n        obsval = (1 - frac) * c_obs[i0] + frac * c_obs[i0+1]\n        p.addXY([mdlval, mdlval], [c0, c1], '%.2f keV' % kevval, dsn=2)\n        p.addXY([c0, c1], [obsval, obsval], None, dsn=2)\n\n    p.setLabels('Cumulative model ' + unit, 'Cumulative data ' + unit)\n    p.defaultKeyOverlay.vAlign = 0.3\n    return p", "response": "Make a quantile - quantile plot comparing events and a modeled number or rate of events in each bin."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_multi_qq_plots(arrays, key_text):\n    import omega as om\n\n    p = om.RectPlot()\n    p.addXY([0, 1.], [0, 1.], '1:1')\n\n    for index, array in enumerate(arrays):\n        kev, obs, mdl = array\n        c_obs = np.cumsum(obs)\n        c_mdl = np.cumsum(mdl)\n\n        mx = 0.5 * (c_obs[-1] + c_mdl[-1])\n        c_obs /= mx\n        c_mdl /= mx\n\n        p.addXY(c_mdl, c_obs, '%s #%d' % (key_text, index))\n\n    # HACK: this range of numbers is chosen to give reasonable sampling for my\n    # sources, which are typically quite soft.\n    #\n    # Note: this reuses the variables from the last loop iteration.\n    locs = np.array([0, 0.05, 0.08, 0.11, 0.17, 0.3, 0.4, 0.7, 1]) * (kev.size - 2)\n    c0 = 1.05\n    c1 = 1.1\n\n    for loc in locs:\n        i0 = int(np.floor(loc))\n        frac = loc - i0\n        kevval = (1 - frac) * kev[i0] + frac * kev[i0+1]\n        mdlval = (1 - frac) * c_mdl[i0] + frac * c_mdl[i0+1]\n        obsval = (1 - frac) * c_obs[i0] + frac * c_obs[i0+1]\n        p.addXY([mdlval, mdlval], [c0, c1], '%.2f keV' % kevval, dsn=2)\n        p.addXY([c0, c1], [obsval, obsval], None, dsn=2)\n\n    p.setLabels('Cumulative rescaled model', 'Cumulative rescaled data')\n    p.defaultKeyOverlay.vAlign = 0.3\n    return p", "response": "Make a quantile - quantile plot comparing multiple sets of events and models."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes a plot of a spectral model and data.", "response": "def make_spectrum_plot(model_plot, data_plot, desc, xmin_clamp=0.01,\n                       min_valid_x=None, max_valid_x=None):\n    \"\"\"Make a plot of a spectral model and data.\n\n    *model_plot*\n      A model plot object returned by Sherpa from a call like `ui.get_model_plot()`\n      or `ui.get_bkg_model_plot()`.\n    *data_plot*\n      A data plot object returned by Sherpa from a call like `ui.get_source_plot()`\n      or `ui.get_bkg_plot()`.\n    *desc*\n      Text describing the origin of the data; will be shown in the plot legend\n      (with \"Model\" and \"Data\" appended).\n    *xmin_clamp*\n      The smallest \"x\" (energy axis) value that will be plotted; default is 0.01.\n      This is needed to allow the plot to be shown on a logarithmic scale if\n      the energy axes of the model go all the way to 0.\n    *min_valid_x*\n      Either None, or the smallest \"x\" (energy axis) value in which the model and\n      data are valid; this could correspond to a range specified in the \"notice\"\n      command during analysis. If specified, a gray band will be added to the plot\n      showing the invalidated regions.\n    *max_valid_x*\n      Like *min_valid_x* but for the largest \"x\" (energy axis) value in which the\n      model and data are valid.\n    Returns:\n      A tuple ``(plot, xlow, xhigh)``, where *plot* an OmegaPlot RectPlot\n      instance, *xlow* is the left edge of the plot bounds, and *xhigh* is the\n      right edge of the plot bounds.\n\n    \"\"\"\n    import omega as om\n\n    model_x = np.concatenate((model_plot.xlo, [model_plot.xhi[-1]]))\n    model_x[0] = max(model_x[0], xmin_clamp)\n    model_y = np.concatenate((model_plot.y, [0.]))\n\n    # Sigh, sometimes Sherpa gives us bad values.\n    is_bad = ~np.isfinite(model_y)\n    if is_bad.sum():\n        from .cli import warn\n        warn('bad Sherpa model Y value(s) at: %r', np.where(is_bad)[0])\n        model_y[is_bad] = 0\n\n    data_left_edges = data_plot.x - 0.5 * data_plot.xerr\n    data_left_edges[0] = max(data_left_edges[0], xmin_clamp)\n    data_hist_x = np.concatenate((data_left_edges, [data_plot.x[-1] + 0.5 * data_plot.xerr[-1]]))\n    data_hist_y = np.concatenate((data_plot.y, [0.]))\n\n    log_bounds_pad_factor = 0.9\n    xlow = model_x[0] * log_bounds_pad_factor\n    xhigh = model_x[-1] / log_bounds_pad_factor\n\n    p = om.RectPlot()\n\n    if min_valid_x is not None:\n        p.add(om.rect.XBand(1e-3 * xlow, min_valid_x, keyText=None), zheight=-1, dsn=1)\n    if max_valid_x is not None:\n        p.add(om.rect.XBand(max_valid_x, xhigh * 1e3, keyText=None), zheight=-1, dsn=1)\n\n    csp = om.rect.ContinuousSteppedPainter(keyText=desc + ' Model')\n    csp.setFloats(model_x, model_y)\n    p.add(csp)\n\n    csp = om.rect.ContinuousSteppedPainter(keyText=None)\n    csp.setFloats(data_hist_x, data_hist_y)\n    p.add(csp)\n    p.addXYErr(data_plot.x, data_plot.y, data_plot.yerr, desc + ' Data', lines=0, dsn=1)\n\n    p.setLabels(data_plot.xlabel, data_plot.ylabel)\n    p.setLinLogAxes(True, False)\n    p.setBounds (xlow, xhigh)\n    return p, xlow, xhigh"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_multi_spectrum_plots(model_plot, plotids, data_getter, desc, xmin_clamp=0.01,\n                              min_valid_x=None, max_valid_x=None):\n    \"\"\"Make a plot of multiple spectral models and data.\n\n    *model_plot*\n      A model plot object returned by Sherpa from a call like\n      ``ui.get_model_plot()`` or ``ui.get_bkg_model_plot()``.\n    *data_plots*\n      An iterable of data plot objects returned by Sherpa from calls like\n      ``ui.get_source_plot(id)`` or ``ui.get_bkg_plot(id)``.\n    *desc*\n      Text describing the origin of the data; will be shown in the plot legend\n      (with \"Model\" and \"Data #<number>\" appended).\n    *xmin_clamp*\n      The smallest \"x\" (energy axis) value that will be plotted; default is 0.01.\n      This is needed to allow the plot to be shown on a logarithmic scale if\n      the energy axes of the model go all the way to 0.\n    *min_valid_x*\n      Either None, or the smallest \"x\" (energy axis) value in which the model and\n      data are valid; this could correspond to a range specified in the \"notice\"\n      command during analysis. If specified, a gray band will be added to the plot\n      showing the invalidated regions.\n    *max_valid_x*\n      Like *min_valid_x* but for the largest \"x\" (energy axis) value in which the\n      model and data are valid.\n    Returns:\n      A tuple ``(plot, xlow, xhigh)``, where *plot* an OmegaPlot RectPlot\n      instance, *xlow* is the left edge of the plot bounds, and *xhigh* is the\n      right edge of the plot bounds.\n\n    TODO: not happy about the code duplication with :func:`make_spectrum_plot`\n    but here we are.\n\n    \"\"\"\n    import omega as om\n    from omega.stamps import DataThemedStamp, WithYErrorBars\n\n    model_x = np.concatenate((model_plot.xlo, [model_plot.xhi[-1]]))\n    model_x[0] = max(model_x[0], xmin_clamp)\n    model_y = np.concatenate((model_plot.y, [0.]))\n\n    # Sigh, sometimes Sherpa gives us bad values.\n    is_bad = ~np.isfinite(model_y)\n    if is_bad.sum():\n        from .cli import warn\n        warn('bad Sherpa model Y value(s) at: %r', np.where(is_bad)[0])\n        model_y[is_bad] = 0\n\n    p = om.RectPlot()\n    data_csps = []\n    data_lines = []\n    xlow = xhigh = None\n\n    for index, plotid in enumerate(plotids):\n        data_plot = data_getter(plotid)\n        data_left_edges = data_plot.x - 0.5 * data_plot.xerr\n        data_left_edges[0] = max(data_left_edges[0], xmin_clamp)\n        data_hist_x = np.concatenate((data_left_edges, [data_plot.x[-1] + 0.5 * data_plot.xerr[-1]]))\n        data_hist_y = np.concatenate((data_plot.y, [0.]))\n\n        if xlow is None:\n            xlow = model_x[0]\n            xhigh = model_x[-1]\n        else:\n            xlow = min(xlow, model_x[0])\n            xhigh = max(xhigh, model_x[-1])\n\n        csp = om.rect.ContinuousSteppedPainter(keyText=None)\n        csp.setFloats(data_hist_x, data_hist_y)\n        data_csps.append(csp)\n\n        inner_stamp = DataThemedStamp(None)\n        stamp = WithYErrorBars(inner_stamp)\n\n        lines = om.rect.XYDataPainter(\n            lines = False,\n            pointStamp = stamp,\n            keyText = '%s Data #%d' % (desc, index)\n        )\n        lines.setFloats(data_plot.x, data_plot.y,\n                        data_plot.y + data_plot.yerr,\n                        data_plot.y - data_plot.yerr)\n        inner_stamp.setHolder(lines)\n        data_lines.append(lines)\n\n    log_bounds_pad_factor = 0.9\n    xlow *= log_bounds_pad_factor\n    xhigh /= log_bounds_pad_factor\n\n    if min_valid_x is not None:\n        p.add(om.rect.XBand(1e-3 * xlow, min_valid_x, keyText=None), zheight=-1, dsn=1)\n    if max_valid_x is not None:\n        p.add(om.rect.XBand(max_valid_x, xhigh * 1e3, keyText=None), zheight=-1, dsn=1)\n\n    model_csp = om.rect.ContinuousSteppedPainter(keyText=desc + ' Model')\n    model_csp.setFloats(model_x, model_y)\n    p.add(model_csp)\n\n    for index, (data_csp, lines) in enumerate(zip(data_csps, data_lines)):\n        p.add(data_csp, dsn=index + 1)\n        p.add(lines, dsn=index + 1)\n\n    p.setLabels(data_plot.xlabel, data_plot.ylabel) # data_plot = last one from the for loop\n    p.setLinLogAxes(True, False)\n    p.setBounds (xlow, xhigh)\n    return p, xlow, xhigh", "response": "Make a plot of multiple spectral models and data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_file(local_filename, url, clobber=False):\n    dir_name = os.path.dirname(local_filename)\n    mkdirs(dir_name)\n\n    if clobber or not os.path.exists(local_filename):\n        i = requests.get(url)\n\n        # if not exists\n        if i.status_code == 404:\n            print('Failed to download file:', local_filename, url)\n            return False\n\n        # write out in 1MB chunks\n        chunk_size_in_bytes = 1024*1024  # 1MB\n        with open(local_filename, 'wb') as local_file:\n            for chunk in i.iter_content(chunk_size=chunk_size_in_bytes):\n                local_file.write(chunk)\n\n    return True", "response": "Download the given file. Clobber overwrites file if exists."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_json(local_filename, url, clobber=False):\n    with open(local_filename, 'w') as json_file:\n        json_file.write(json.dumps(requests.get(url).json(), sort_keys=True, indent=2, separators=(',', ': ')))", "response": "Download the given JSON file and pretty - print before we output it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nturn arbitrary data values into ARGB32 colors.", "response": "def data_to_argb32 (data, cmin=None, cmax=None, stretch='linear', cmap='black_to_blue'):\n    \"\"\"Turn arbitrary data values into ARGB32 colors.\n\n    There are three steps to this process: clipping the data values to a\n    maximum and minimum; stretching the spacing between those values; and\n    converting their amplitudes into colors with some kind of color map.\n\n    `data`    - Input data; can (and should) be a MaskedArray if some values are\n                invalid.\n    `cmin`    - The data clip minimum; all values <= cmin are treated\n                identically. If None (the default), `data.min ()` is used.\n    `cmax`    - The data clip maximum; all values >= cmax are treated\n                identically. If None (the default), `data.max ()` is used.\n    `stretch` - The stretch function name; 'linear', 'sqrt', or 'square'; see\n                the Stretcher class.\n    `cmap`    - The color map name; defaults to 'black_to_blue'. See the\n                `pwkit.colormaps` module for more choices.\n\n    Returns a Numpy array of the same shape as `data` with dtype `np.uint32`,\n    which represents the ARGB32 colorized version of the data. If your\n    colormap is restricted to a single R or G or B channel, you can make color\n    images by bitwise-or'ing together different such arrays.\n\n    \"\"\"\n    # This could be more efficient, but whatever. This lets us share code with\n    # the ndshow module.\n\n    clipper = Clipper ()\n    clipper.alloc_buffer (data)\n    clipper.set_tile_size ()\n    clipper.dmin = cmin if cmin is not None else data.min ()\n    clipper.dmax = cmax if cmax is not None else data.max ()\n    clipper.ensure_all_updated (data)\n\n    stretcher = Stretcher (stretch)\n    stretcher.alloc_buffer (clipper.buffer)\n    stretcher.set_tile_size ()\n    stretcher.ensure_all_updated (clipper.buffer)\n\n    mapper = ColorMapper (cmap)\n    mapper.alloc_buffer (stretcher.buffer)\n    mapper.set_tile_size ()\n    mapper.ensure_all_updated (stretcher.buffer)\n\n    return mapper.buffer"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns arbitrary data values into a Cairo ImageSurface object.", "response": "def data_to_imagesurface (data, **kwargs):\n    \"\"\"Turn arbitrary data values into a Cairo ImageSurface.\n\n    The method and arguments are the same as data_to_argb32, except that the\n    data array will be treated as 2D, and higher dimensionalities are not\n    allowed. The return value is a Cairo ImageSurface object.\n\n    Combined with the write_to_png() method on ImageSurfaces, this is an easy\n    way to quickly visualize 2D data.\n\n    \"\"\"\n    import cairo\n\n    data = np.atleast_2d (data)\n    if data.ndim != 2:\n        raise ValueError ('input array may not have more than 2 dimensions')\n\n    argb32 = data_to_argb32 (data, **kwargs)\n\n    format = cairo.FORMAT_ARGB32\n    height, width = argb32.shape\n    stride = cairo.ImageSurface.format_stride_for_width (format, width)\n\n    if argb32.strides[0] != stride:\n        raise ValueError ('stride of data array not compatible with ARGB32')\n\n    return cairo.ImageSurface.create_for_data (argb32, format,\n                                               width, height, stride)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning pipeline_token for API elastic network.", "response": "def get_token(filename=TOKEN_PATH, envvar=TOKEN_ENVVAR):\n    \"\"\"\n    Returns pipeline_token for API\n\n    Tries local file first, then env variable\n    \"\"\"\n    if os.path.isfile(filename):\n        with open(filename) as token_file:\n            token = token_file.readline().strip()\n\n    else:\n        token = os.environ.get(envvar)\n\n        if not token:\n            raise ValueError(\"No token found.\\n\"\n                             \"{} file doesn't exist.\\n{} environment variable is not set.\".format(filename, envvar))\n\n    return token"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stats (self, antnames):\n        nbyant = np.zeros (self.nants, dtype=np.int)\n        sum = np.zeros (self.nants, dtype=np.complex)\n        sumsq = np.zeros (self.nants)\n        q = np.abs (self.normvis - 1)\n\n        for i in range (self.nsamps):\n            i1, i2 = self.blidxs[i]\n            nbyant[i1] += 1\n            nbyant[i2] += 1\n            sum[i1] += q[i]\n            sum[i2] += q[i]\n            sumsq[i1] += q[i]**2\n            sumsq[i2] += q[i]**2\n\n        avg = sum / nbyant\n        std = np.sqrt (sumsq / nbyant - avg**2)\n        navg = 1. / np.median (avg)\n        nstd = 1. / np.median (std)\n\n        for i in range (self.nants):\n            print ('  %2d %10s %3d %f %f %f %f' %\n                   (i, antnames[i], nbyant[i], avg[i], std[i], avg[i] * navg, std[i] * nstd))", "response": "prints stats about the set of entries in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading a file - like object from a stream.", "response": "def read_stream (stream):\n    \"\"\"Python 3 compat note: we're assuming `stream` gives bytes not unicode.\"\"\"\n\n    section = None\n    key = None\n    data = None\n\n    for fullline in stream:\n        line = fullline.split ('#', 1)[0]\n\n        m = sectionre.match (line)\n        if m is not None:\n            # New section\n            if section is not None:\n                if key is not None:\n                    section.set_one (key, data.strip ().decode ('utf8'))\n                    key = data = None\n                yield section\n\n            section = Holder ()\n            section.section = m.group (1)\n            continue\n\n        if len (line.strip ()) == 0:\n            if key is not None:\n                section.set_one (key, data.strip ().decode ('utf8'))\n                key = data = None\n            continue\n\n        m = escre.match (fullline)\n        if m is not None:\n            if section is None:\n                raise InifileError ('key seen without section!')\n            if key is not None:\n                section.set_one (key, data.strip ().decode ('utf8'))\n            key = m.group (1)\n            data = m.group (2).replace (r'\\\"', '\"').replace (r'\\n', '\\n').replace (r'\\\\', '\\\\')\n            section.set_one (key, data.decode ('utf8'))\n            key = data = None\n            continue\n\n        m = keyre.match (line)\n        if m is not None:\n            if section is None:\n                raise InifileError ('key seen without section!')\n            if key is not None:\n                section.set_one (key, data.strip ().decode ('utf8'))\n            key = m.group (1)\n            data = m.group (2)\n            if not len (data):\n                data = ' '\n            elif not data[-1].isspace ():\n                data += ' '\n            continue\n\n        if line[0].isspace () and key is not None:\n            data += line.strip () + ' '\n            continue\n\n        raise InifileError ('unparsable line: ' + line[:-1])\n\n    if section is not None:\n        if key is not None:\n            section.set_one (key, data.strip ().decode ('utf8'))\n        yield section"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_stream (stream, holders, defaultsection=None):\n    anybefore = False\n\n    for h in holders:\n        if anybefore:\n            print ('', file=stream)\n\n        s = h.get ('section', defaultsection)\n        if s is None:\n            raise ValueError ('cannot determine section name for item <%s>' % h)\n        print ('[%s]' % s, file=stream)\n\n        for k in sorted (x for x in six.iterkeys (h.__dict__) if x != 'section'):\n            v = h.get (k)\n            if v is None:\n                continue\n\n            print ('%s = %s' % (k, v), file=stream)\n\n        anybefore = True", "response": "Very simple writing in ini format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write (stream_or_path, holders, **kwargs):\n    if isinstance (stream_or_path, six.string_types):\n        return write_stream (io.open (stream_or_path, 'wt'), holders, **kwargs)\n    else:\n        return write_stream (stream_or_path, holders, **kwargs)", "response": "Very simple writing in ini format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef mutate_stream (instream, outstream):\n\n    chunk = None\n    key = None\n    data = None\n    misclines = []\n\n    for fullline in instream:\n        line = fullline.split ('#', 1)[0]\n\n        m = sectionre.match (line)\n        if m is not None:\n            # New chunk\n            if chunk is not None:\n                if key is not None:\n                    chunk.data.set_one (key, data.strip ().decode ('utf8'))\n                    key = data = None\n                yield chunk\n                chunk.emit (outstream)\n\n            chunk = FileChunk ()\n            for miscline in misclines:\n                chunk._addLine (miscline, None)\n            misclines = []\n            chunk.data.section = m.group (1)\n            chunk._addLine (fullline, None)\n            continue\n\n        if len (line.strip ()) == 0:\n            if key is not None:\n                chunk.data.set_one (key, data.strip ().decode ('utf8'))\n                key = data = None\n            if chunk is not None:\n                chunk._addLine (fullline, None)\n            else:\n                misclines.append (fullline)\n            continue\n\n        m = escre.match (fullline)\n        if m is not None:\n            if chunk is None:\n                raise InifileError ('key seen without section!')\n            if key is not None:\n                chunk.data.set_one (key, data.strip ().decode ('utf8'))\n            key = m.group (1)\n            data = m.group (2).replace (r'\\\"', '\"').replace (r'\\n', '\\n').replace (r'\\\\', '\\\\')\n            chunk.data.set_one (key, data.decode ('utf8'))\n            chunk._addLine (fullline, key)\n            key = data = None\n            continue\n\n        m = keyre.match (line)\n        if m is not None:\n            if chunk is None:\n                raise InifileError ('key seen without section!')\n            if key is not None:\n                chunk.data.set_one (key, data.strip ().decode ('utf8'))\n            key = m.group (1)\n            data = m.group (2)\n            if not data[-1].isspace ():\n                data += ' '\n            chunk._addLine (fullline, key)\n            continue\n\n        if line[0].isspace () and key is not None:\n            data += line.strip () + ' '\n            chunk._addLine (fullline, key)\n            continue\n\n        raise InifileError ('unparsable line: ' + line[:-1])\n\n    if chunk is not None:\n        if key is not None:\n            chunk.data.set_one (key, data.strip ().decode ('utf8'))\n        yield chunk\n        chunk.emit (outstream)", "response": "Yields the contents of the stream in order to be written to outstream."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef in_casapy (helper, caltable=None, selectcals={}, plotoptions={},\n               xaxis=None, yaxis=None, figfile=None):\n    \"\"\"This function is run inside the weirdo casapy IPython environment! A\n    strange set of modules is available, and the\n    `pwkit.environments.casa.scripting` system sets up a very particular\n    environment to allow encapsulated scripting.\n\n    \"\"\"\n    if caltable is None:\n        raise ValueError ('caltable')\n\n    show_gui = (figfile is None)\n    cp = helper.casans.cp\n\n    helper.casans.tp.setgui (show_gui)\n    cp.open (caltable)\n    cp.selectcal (**selectcals)\n    cp.plotoptions (**plotoptions)\n    cp.plot (xaxis, yaxis)\n\n    if show_gui:\n        import pylab as pl\n        pl.show ()\n    else:\n        cp.savefig (figfile)", "response": "This function is run inside the casapy IPython environment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the packed pivoting Q-R factorization of a matrix. Parameters: a - An n-by-m matrix, m >= n. This will be *overwritten* by this function as described below! enorm - A Euclidian-norm-computing function. finfo - A Numpy finfo object. Returns: pmut - An n-element permutation vector rdiag - An n-element vector of the diagonal of R acnorm - An n-element vector of the norms of the rows of the input matrix 'a'. Computes the transposed Q-R factorization of the matrix 'a', with pivoting, in a packed form, in-place. The packed information can be used to construct matrices Q and R such that A P = R Q or, in Python, np.dot(r, q) = a[pmut] where q is m-by-m and q q^T = ident and r is n-by-m and is lower triangular. The function _qr_factor_full can compute these matrices. The packed form of output is all that is used by the main LM fitting algorithm. \"Pivoting\" refers to permuting the rows of 'a' to have their norms in nonincreasing order. The return value 'pmut' maps the unpermuted rows of 'a' to permuted rows. That is, the norms of the rows of a[pmut] are in nonincreasing order. The parameter 'a' is overwritten by this function. Its new value should still be interpreted as an n-by-m array. It comes in two parts. Its strict lower triangular part contains the struct lower triangular part of R. (The diagonal of R is returned in 'rdiag' and the strict upper trapezoidal part of R is zero.) The upper trapezoidal part of 'a' contains Q as factorized into a series of Householder transformation vectors. Q can be reconstructed as the matrix product of n Householder matrices, where the i'th Householder matrix is defined by H_i = I - 2 (v^T v) / (v v^T) where 'v' is the pmut[i]'th row of 'a' with its strict lower triangular part set to zero. See _qr_factor_full for more information. 'rdiag' contains the diagonal part of the R matrix, taking into account the permutation of 'a'. The strict lower triangular part of R is stored in 'a' *with permutation*, so that the i'th row of R has rdiag[i] as its diagonal and a[pmut[i],:i] as its upper part. See _qr_factor_full for more information. 'acnorm' contains the norms of the rows of the original input matrix 'a' without permutation. The form of this transformation and the method of pivoting first appeared in Linpack.", "response": "def _qr_factor_packed(a, enorm, finfo):\n    \"\"\"Compute the packed pivoting Q-R factorization of a matrix.\n\nParameters:\na     - An n-by-m matrix, m >= n. This will be *overwritten*\n        by this function as described below!\nenorm - A Euclidian-norm-computing function.\nfinfo - A Numpy finfo object.\n\nReturns:\npmut   - An n-element permutation vector\nrdiag  - An n-element vector of the diagonal of R\nacnorm - An n-element vector of the norms of the rows\n         of the input matrix 'a'.\n\nComputes the transposed Q-R factorization of the matrix 'a', with\npivoting, in a packed form, in-place. The packed information can be\nused to construct matrices Q and R such that\n\n  A P = R Q or, in Python,\n  np.dot(r, q) = a[pmut]\n\nwhere q is m-by-m and q q^T = ident and r is n-by-m and is lower\ntriangular. The function _qr_factor_full can compute these\nmatrices. The packed form of output is all that is used by the main LM\nfitting algorithm.\n\n\"Pivoting\" refers to permuting the rows of 'a' to have their norms in\nnonincreasing order. The return value 'pmut' maps the unpermuted rows\nof 'a' to permuted rows. That is, the norms of the rows of a[pmut] are\nin nonincreasing order.\n\nThe parameter 'a' is overwritten by this function. Its new value\nshould still be interpreted as an n-by-m array. It comes in two\nparts. Its strict lower triangular part contains the struct lower\ntriangular part of R. (The diagonal of R is returned in 'rdiag' and\nthe strict upper trapezoidal part of R is zero.) The upper trapezoidal\npart of 'a' contains Q as factorized into a series of Householder\ntransformation vectors. Q can be reconstructed as the matrix product\nof n Householder matrices, where the i'th Householder matrix is\ndefined by\n\nH_i = I - 2 (v^T v) / (v v^T)\n\nwhere 'v' is the pmut[i]'th row of 'a' with its strict lower\ntriangular part set to zero. See _qr_factor_full for more information.\n\n'rdiag' contains the diagonal part of the R matrix, taking into\naccount the permutation of 'a'. The strict lower triangular part of R\nis stored in 'a' *with permutation*, so that the i'th row of R has\nrdiag[i] as its diagonal and a[pmut[i],:i] as its upper part. See\n_qr_factor_full for more information.\n\n'acnorm' contains the norms of the rows of the original input\nmatrix 'a' without permutation.\n\nThe form of this transformation and the method of pivoting first\nappeared in Linpack.\"\"\"\n\n    machep = finfo.eps\n    n, m = a.shape\n\n    if m < n:\n        raise ValueError('\"a\" must be at least as tall as it is wide')\n\n    acnorm = np.empty(n, finfo.dtype)\n    for j in range(n):\n        acnorm[j] = enorm(a[j], finfo)\n\n    rdiag = acnorm.copy()\n    wa = acnorm.copy()\n    pmut = np.arange(n)\n\n    for i in range(n):\n        # Find the row of a with the i'th largest norm, and note it in\n        # the pivot vector.\n\n        kmax = rdiag[i:].argmax() + i\n\n        if kmax != i:\n            temp = pmut[i]\n            pmut[i] = pmut[kmax]\n            pmut[kmax] = temp\n\n            rdiag[kmax] = rdiag[i]\n            wa[kmax] = wa[i]\n\n            temp = a[i].copy()\n            a[i] = a[kmax]\n            a[kmax] = temp\n\n        # Compute the Householder transformation to reduce the i'th\n        # row of A to a multiple of the i'th unit vector.\n\n        ainorm = enorm(a[i,i:], finfo)\n\n        if ainorm == 0:\n            rdiag[i] = 0\n            continue\n\n        if a[i,i] < 0:\n            # Doing this apparently improves FP precision somehow.\n            ainorm = -ainorm\n\n        a[i,i:] /= ainorm\n        a[i,i] += 1\n\n        # Apply the transformation to the remaining rows and update\n        # the norms.\n\n        for j in range(i + 1, n):\n            a[j,i:] -= a[i,i:] * np.dot(a[i,i:], a[j,i:]) / a[i,i]\n\n            if rdiag[j] != 0:\n                rdiag[j] *= np.sqrt(max(1 - (a[j,i] / rdiag[j])**2, 0))\n\n                if 0.05 * (rdiag[j] / wa[j])**2 <= machep:\n                    # What does this do???\n                    wa[j] = rdiag[j] = enorm(a[j,i+1:], finfo)\n\n        rdiag[i] = -ainorm\n\n    return pmut, rdiag, acnorm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _qr_factor_full(a, dtype=np.float):\n\n    n, m = a.shape\n\n    # Compute the packed Q and R matrix information.\n\n    packed, pmut, rdiag, acnorm = \\\n        _manual_qr_factor_packed(a, dtype)\n\n    # Now we unpack. Start with the R matrix, which is easy: we just\n    # have to piece it together from the strict lower triangle of 'a'\n    # and the diagonal in 'rdiag'.\n\n    r = np.zeros((n, m))\n\n    for i in range(n):\n        r[i,:i] = packed[i,:i]\n        r[i,i] = rdiag[i]\n\n    # Now the Q matrix. It is the concatenation of n Householder\n    # transformations, each of which is defined by a row in the upper\n    # trapezoidal portion of 'a'. We extract the appropriate vector,\n    # construct the matrix for the Householder transform, and build up\n    # the Q matrix.\n\n    q = np.eye(m)\n    v = np.empty(m)\n\n    for i in range(n):\n        v[:] = packed[i]\n        v[:i] = 0\n\n        hhm = np.eye(m) - 2 * np.outer(v, v) / np.dot(v, v)\n        q = np.dot(hhm, q)\n\n    return q, r, pmut", "response": "Compute the QR factorization of a matrix with pivoting."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsolving an equation given a QR factored matrix and a diagonal.", "response": "def _qrd_solve(r, pmut, ddiag, bqt, sdiag):\n    \"\"\"Solve an equation given a QR factored matrix and a diagonal.\n\nParameters:\nr     - **input-output** n-by-n array. The full lower triangle contains\n        the full lower triangle of R. On output, the strict upper\n        triangle contains the transpose of the strict lower triangle of\n        S.\npmut  - n-vector describing the permutation matrix P.\nddiag - n-vector containing the diagonal of the matrix D in the base\n        problem (see below).\nbqt   - n-vector containing the first n elements of B Q^T.\nsdiag - output n-vector. It is filled with the diagonal of S. Should\n        be preallocated by the caller -- can result in somewhat greater\n        efficiency if the vector is reused from one call to the next.\n\nReturns:\nx     - n-vector solving the equation.\n\nCompute the n-vector x such that\n\nA^T x = B, D x = 0\n\nwhere A is an n-by-m matrix, B is an m-vector, and D is an n-by-n\ndiagonal matrix. We are given information about pivoted QR\nfactorization of A with permutation, such that\n\nA P = R Q\n\nwhere P is a permutation matrix, Q has orthogonal rows, and R is lower\ntriangular with nonincreasing diagonal elements. Q is m-by-m, R is\nn-by-m, and P is n-by-n. If x = P z, then we need to solve\n\nR z = B Q^T,\nP^T D P z = 0 (why the P^T? and do these need to be updated for the transposition?)\n\nIf the system is rank-deficient, these equations are solved as well as\npossible in a least-squares sense. For the purposes of the LM\nalgorithm we also compute the lower triangular n-by-n matrix S such\nthat\n\nP^T (A^T A + D D) P = S^T S. (transpose?)\n\"\"\"\n\n    n, m = r.shape\n\n    # \"Copy r and bqt to preserve input and initialize s.  In\n    # particular, save the diagonal elements of r in x.\"  Recall that\n    # on input only the full lower triangle of R is meaningful, so we\n    # can mirror that into the upper triangle without issues.\n\n    for i in range(n):\n        r[i,i:] = r[i:,i]\n\n    x = r.diagonal().copy()\n    zwork = bqt.copy()\n\n    # \"Eliminate the diagonal matrix d using a Givens rotation.\"\n\n    for i in range(n):\n        # \"Prepare the row of D to be eliminated, locating the\n        # diagonal element using P from the QR factorization.\"\n\n        li = pmut[i]\n        if ddiag[li] == 0:\n            sdiag[i] = r[i,i]\n            r[i,i] = x[i]\n            continue\n\n        sdiag[i:] = 0\n        sdiag[i] = ddiag[li]\n\n        # \"The transformations to eliminate the row of d modify only a\n        # single element of (q transpose)*b beyond the first n, which\n        # is initially zero.\"\n\n        bqtpi = 0.\n\n        for j in range(i, n):\n            # \"Determine a Givens rotation which eliminates the\n            # appropriate element in the current row of D.\"\n\n            if sdiag[j] == 0:\n                continue\n\n            if abs(r[j,j]) < abs(sdiag[j]):\n                cot = r[j,j] / sdiag[j]\n                sin = 0.5 / np.sqrt(0.25 + 0.25 * cot**2)\n                cos = sin * cot\n            else:\n                tan = sdiag[j] / r[j,j]\n                cos = 0.5 / np.sqrt(0.25 + 0.25 * tan**2)\n                sin = cos * tan\n\n            # \"Compute the modified diagonal element of r and the\n            # modified element of ((q transpose)*b,0).\"\n            r[j,j] = cos * r[j,j] + sin * sdiag[j]\n            temp = cos * zwork[j] + sin * bqtpi\n            bqtpi = -sin * zwork[j] + cos * bqtpi\n            zwork[j] = temp\n\n            # \"Accumulate the transformation in the row of s.\"\n            if j + 1 < n:\n                temp = cos * r[j,j+1:] + sin * sdiag[j+1:]\n                sdiag[j+1:] = -sin * r[j,j+1:] + cos * sdiag[j+1:]\n                r[j,j+1:] = temp\n\n        # Save the diagonal of S and restore the diagonal of R\n        # from its saved location in x.\n        sdiag[i] = r[i,i]\n        r[i,i] = x[i]\n\n    # \"Solve the triangular system for z.  If the system is singular\n    # then obtain a least squares solution.\"\n\n    nsing = n\n\n    for i in range(n):\n        if sdiag[i] == 0.:\n            nsing = i\n            zwork[i:] = 0\n            break\n\n    if nsing > 0:\n        zwork[nsing-1] /= sdiag[nsing-1] # Degenerate case\n        # \"Reverse loop\"\n        for i in range(nsing - 2, -1, -1):\n            s = np.dot(zwork[i+1:nsing], r[i,i+1:nsing])\n            zwork[i] = (zwork[i] - s) / sdiag[i]\n\n    # \"Permute the components of z back to components of x.\"\n    x[pmut] = zwork\n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsolving the equation A^T x = B D x = 0.", "response": "def _qrd_solve_full(a, b, ddiag, dtype=np.float):\n    \"\"\"Solve the equation A^T x = B, D x = 0.\n\nParameters:\na     - an n-by-m array, m >= n\nb     - an m-vector\nddiag - an n-vector giving the diagonal of D. (The rest of D is 0.)\n\nReturns:\nx    - n-vector solving the equation.\ns    - the n-by-n supplementary matrix s.\npmut - n-element permutation vector defining the permutation matrix P.\n\nThe equations are solved in a least-squares sense if the system is\nrank-deficient.  D is a diagonal matrix and hence only its diagonal is\nin fact supplied as an argument. The matrix s is full lower triangular\nand solves the equation\n\nP^T (A A^T + D D) P = S^T S (needs transposition?)\n\nwhere P is the permutation matrix defined by the vector pmut; it puts\nthe rows of 'a' in order of nonincreasing rank, so that a[pmut]\nhas its rows sorted that way.\n\"\"\"\n\n    a = np.asarray(a, dtype)\n    b = np.asarray(b, dtype)\n    ddiag = np.asarray(ddiag, dtype)\n\n    n, m = a.shape\n    assert m >= n\n    assert b.shape == (m, )\n    assert ddiag.shape == (n, )\n\n    # The computation is straightforward.\n\n    q, r, pmut = _qr_factor_full(a)\n    bqt = np.dot(b, q.T)\n    x, s = _manual_qrd_solve(r[:,:n], pmut, ddiag, bqt,\n                             dtype=dtype, build_s=True)\n\n    return x, s, pmut"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _lm_solve(r, pmut, ddiag, bqt, delta, par0, enorm, finfo):\n    dwarf = finfo.tiny\n    n, m = r.shape\n    x = np.empty_like(bqt)\n    sdiag = np.empty_like(bqt)\n\n    # \"Compute and store x in the Gauss-Newton direction. If the\n    # Jacobian is rank-deficient, obtain a least-squares solution.\"\n\n    nnonsingular = n\n    wa1 = bqt.copy()\n\n    for i in range(n):\n        if r[i,i] == 0:\n            nnonsingular = i\n            wa1[i:] = 0\n            break\n\n    for j in range(nnonsingular - 1, -1, -1):\n        wa1[j] /= r[j,j]\n        wa1[:j] -= r[j,:j] * wa1[j]\n\n    x[pmut] = wa1\n\n    # Initial function evaluation. Check if the Gauss-Newton direction\n    # was good enough.\n\n    wa2 = ddiag * x\n    dxnorm = enorm(wa2, finfo)\n    normdiff = dxnorm - delta\n\n    if normdiff <= 0.1 * delta:\n        return 0, x\n\n    # If the Jacobian is not rank deficient, the Newton step provides\n    # a lower bound for the zero of the function.\n\n    par_lower = 0.\n\n    if nnonsingular == n:\n        wa1 = ddiag[pmut] * wa2[pmut] / dxnorm\n        wa1[0] /= r[0,0] # \"Degenerate case\"\n\n        for j in range(1, n):\n            wa1[j] = (wa1[j] - np.dot(wa1[:j], r[j,:j])) / r[j,j]\n\n        temp = enorm(wa1, finfo)\n        par_lower = normdiff / delta / temp**2\n\n    # We can always find an upper bound.\n\n    for j in range(n):\n        wa1[j] = np.dot(bqt[:j+1], r[j,:j+1]) / ddiag[pmut[j]]\n\n    gnorm = enorm(wa1, finfo)\n    par_upper = gnorm / delta\n    if par_upper == 0:\n        par_upper = dwarf / min(delta, 0.1)\n\n    # Now iterate our way to victory.\n\n    par = np.clip(par0, par_lower, par_upper)\n    if par == 0:\n        par = gnorm / dxnorm\n\n    itercount = 0\n\n    while True:\n        itercount += 1\n\n        if par == 0:\n            par = max(dwarf, par_upper * 0.001)\n\n        temp = np.sqrt(par)\n        wa1 = temp * ddiag\n        x = _qrd_solve(r[:,:n], pmut, wa1, bqt, sdiag) # sdiag is an output arg here\n        wa2 = ddiag * x\n        dxnorm = enorm(wa2, finfo)\n        olddiff = normdiff\n        normdiff = dxnorm - delta\n\n        if abs(normdiff) < 0.1 * delta:\n            break # converged\n        if par_lower == 0 and normdiff <= olddiff and olddiff < 0:\n            break # overshot, I guess?\n        if itercount == 10:\n            break # this is taking too long\n\n        # Compute and apply the Newton correction\n\n        wa1 = ddiag[pmut] * wa2[pmut] / dxnorm\n\n        for j in range(n - 1):\n            wa1[j] /= sdiag[j]\n            wa1[j+1:n] -= r[j,j+1:n] * wa1[j]\n        wa1[n-1] /= sdiag[n-1] # degenerate case\n\n        par_delta = normdiff / delta / enorm(wa1, finfo)**2\n\n        if normdiff > 0:\n            par_lower = max(par_lower, par)\n        elif normdiff < 0:\n            par_upper = min(par_upper, par)\n\n        par = max(par_lower, par + par_delta)\n\n    return par, x", "response": "This routine computes the Levenberg - Marquardt parameter and solution vector for a given set of parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the Levenberg-Marquardt parameter and solution vector. Parameters: a - n-by-m matrix, m >= n (only the n-by-n component is used) b - n-by-n matrix ddiag - n-vector, diagonal elements of D delta - positive scalar, specifies scale of enorm(Dx) par0 - positive scalar, initial estimate of the LM parameter Returns: par - positive scalar, final estimate of LM parameter x - n-vector, least-squares solution of LM equation dxnorm - positive scalar, enorm(D x) relnormdiff - scalar, (dxnorm - delta) / delta, maybe abs-ified This routine computes the Levenberg-Marquardt parameter 'par' and a LM solution vector 'x'. Given an n-by-n matrix A, an n-by-n nonsingular diagonal matrix D, an m-vector B, and a positive number delta, the problem is to determine values such that 'x' is the least-squares solution to A x = B sqrt(par) * D x = 0 and either (1) par = 0, dxnorm - delta <= 0.1 delta or (2) par > 0 and |dxnorm - delta| <= 0.1 delta where dxnorm = enorm(D x).", "response": "def _lm_solve_full(a, b, ddiag, delta, par0, dtype=np.float):\n    \"\"\"Compute the Levenberg-Marquardt parameter and solution vector.\n\nParameters:\na     - n-by-m matrix, m >= n (only the n-by-n component is used)\nb     - n-by-n matrix\nddiag - n-vector, diagonal elements of D\ndelta - positive scalar, specifies scale of enorm(Dx)\npar0  - positive scalar, initial estimate of the LM parameter\n\nReturns:\npar    - positive scalar, final estimate of LM parameter\nx      - n-vector, least-squares solution of LM equation\ndxnorm - positive scalar, enorm(D x)\nrelnormdiff - scalar, (dxnorm - delta) / delta, maybe abs-ified\n\nThis routine computes the Levenberg-Marquardt parameter 'par' and a LM\nsolution vector 'x'. Given an n-by-n matrix A, an n-by-n nonsingular\ndiagonal matrix D, an m-vector B, and a positive number delta, the\nproblem is to determine values such that 'x' is the least-squares\nsolution to\n\n A x = B\n sqrt(par) * D x = 0\n\nand either\n\n (1) par = 0, dxnorm - delta <= 0.1 delta or\n (2) par > 0 and |dxnorm - delta| <= 0.1 delta\n\nwhere dxnorm = enorm(D x).\n\"\"\"\n    a = np.asarray(a, dtype)\n    b = np.asarray(b, dtype)\n    ddiag = np.asarray(ddiag, dtype)\n\n    n, m = a.shape\n    assert m >= n\n    assert b.shape == (m, )\n    assert ddiag.shape == (n, )\n\n    q, r, pmut = _qr_factor_full(a)\n    bqt = np.dot(b, q.T)\n    par, x = _lm_solve(r, pmut, ddiag, bqt, delta, par0,\n                       enorm_mpfit_careful, np.finfo(dtype))\n    dxnorm = enorm_mpfit_careful(ddiag * x, np.finfo(dtype))\n    relnormdiff = (dxnorm - delta) / delta\n\n    if par > 0:\n        relnormdiff = abs(relnormdiff)\n\n    return par, x, dxnorm, relnormdiff"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the covariance matrix of the fitted parameters.", "response": "def _calc_covariance(r, pmut, tol=1e-14):\n    \"\"\"Calculate the covariance matrix of the fitted parameters\n\nParameters:\nr    - n-by-n matrix, the full upper triangle of R\npmut - n-vector, defines the permutation of R\ntol  - scalar, relative column scale for determining rank\n       deficiency. Default 1e-14.\n\nReturns:\ncov  - n-by-n matrix, the covariance matrix C\n\nGiven an n-by-n matrix A, the corresponding covariance matrix\nis\n\n  C = inverse(A^T A)\n\nThis routine is given information relating to the pivoted transposed\nQR factorization of A, which is defined by matrices such that\n\n A P = R Q\n\nwhere P is a permutation matrix, Q has orthogonal rows, and R is a\nlower triangular matrix with diagonal elements of nonincreasing\nmagnitude. In particular we take the full lower triangle of R ('r')\nand a vector describing P ('pmut'). The covariance matrix is then\n\n C = P inverse(R^T R) P^T\n\nIf A is nearly rank-deficient, it may be desirable to compute the\ncovariance matrix corresponding to the linearly-independent columns of\nA. We use a tolerance, 'tol', to define the numerical rank of A. If j\nis the largest integer such that |R[j,j]| > tol*|R[0,0]|, then we\ncompute the covariance matrix for the first j columns of R. For k > j,\nthe corresponding covariance entries (pmut[k]) are set to zero.\n\"\"\"\n    # This routine could save an allocation by operating on r in-place,\n    # which might be worthwhile for large n, and is what the original\n    # Fortran does.\n\n    n = r.shape[1]\n    assert r.shape[0] >= n\n    r = r.copy()\n\n    # Form the inverse of R in the full lower triangle of R.\n\n    jrank = -1\n    abstol = tol * abs(r[0,0])\n\n    for i in range(n):\n        if abs(r[i,i]) <= abstol:\n            break\n\n        r[i,i] **= -1\n\n        for j in range(i):\n            temp = r[i,i] * r[i,j]\n            r[i,j] = 0.\n            r[i,:j+1] -= temp * r[j,:j+1]\n\n        jrank = i\n\n    # Form the full lower triangle of the inverse(R^T R) in the full\n    # lower triangle of R.\n\n    for i in range(jrank + 1):\n        for j in range(i):\n            r[j,:j+1] += r[i,j] * r[i,:j+1]\n        r[i,:i+1] *= r[i,i]\n\n    # Form the full upper triangle of the covariance matrix in the\n    # strict upper triangle of R and in wa.\n\n    wa = np.empty(n)\n    wa.fill(r[0,0])\n\n    for i in range(n):\n        pi = pmut[i]\n        sing = i > jrank\n\n        for j in range(i + 1):\n            if sing:\n                r[i,j] = 0.\n\n            pj = pmut[j]\n            if pj > pi:\n                r[pi,pj] = r[i,j]\n            elif pj < pi:\n                r[pj,pi] = r[i,j]\n\n        wa[pi] = r[i,i]\n\n    # Symmetrize.\n\n    for i in range(n):\n        r[i,:i+1] = r[:i+1,i]\n        r[i,i] = wa[i]\n\n    return r"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _lmder1_linear_full_rank(n, m, factor, target_fnorm1, target_fnorm2):\n\n    def func(params, vec):\n        s = params.sum()\n        temp = 2. * s / m + 1\n        vec[:] = -temp\n        vec[:params.size] += params\n\n    def jac(params, jac):\n        # jac.shape = (n, m) by LMDER standards\n        jac.fill(-2. / m)\n        for i in range(n):\n            jac[i,i] += 1\n\n    guess = np.ones(n) * factor\n\n    #_lmder1_test(m, func, jac, guess)\n    _lmder1_driver(m, func, jac, guess,\n                   target_fnorm1, target_fnorm2,\n                   [-1] * n)", "response": "A full - rank linear function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _lmder1_linear_r1zcr(n, m, factor, target_fnorm1, target_fnorm2, target_params):\n\n    def func(params, vec):\n        s = 0\n        for j in range(1, n - 1):\n            s += (j + 1) * params[j]\n        for i in range(m):\n            vec[i] = i * s - 1\n        vec[m-1] = -1\n\n    def jac(params, jac):\n        jac.fill(0)\n\n        for i in range(1, n - 1):\n            for j in range(1, m - 1):\n                jac[i,j] = j * (i + 1)\n\n    guess = np.ones(n) * factor\n\n    #_lmder1_test(m, func, jac, guess)\n    _lmder1_driver(m, func, jac, guess,\n                   target_fnorm1, target_fnorm2, None)", "response": "A rank - 1 linear function with zero columns and rows"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _lmder1_freudenstein_roth():\n\n    def func(params, vec):\n        vec[0] = -13 + params[0] + ((5 - params[1]) * params[1] - 2) * params[1]\n        vec[1] = -29 + params[0] + ((1 + params[1]) * params[1] - 14) * params[1]\n\n    def jac(params, jac):\n        jac[0] = 1\n        jac[1,0] = params[1] * (10 - 3 * params[1]) - 2\n        jac[1,1] = params[1] * (2 + 3 * params[1]) - 14\n\n    guess = np.asfarray([0.5, -2])\n\n    _lmder1_driver(2, func, jac, guess,\n                   0.200124960962e+02, 0.699887517585e+01,\n                   [0.114124844655e+02, -0.896827913732e+00])\n    _lmder1_driver(2, func, jac, guess * 10,\n                   0.124328339489e+05, 0.699887517449e+01,\n                   [0.114130046615e+02, -0.896796038686e+00])\n    _lmder1_driver(2, func, jac, guess * 100,\n                   0.11426454595762e+08, 0.699887517243e+01,\n                   [0.114127817858e+02, -0.896805107492e+00])", "response": "Freudenstein and Roth function"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _lmder1_bard():\n\n    y1 = np.asfarray([0.14, 0.18, 0.22, 0.25, 0.29,\n                      0.32, 0.35, 0.39, 0.37, 0.58,\n                      0.73, 0.96, 1.34, 2.10, 4.39])\n\n    def func(params, vec):\n        for i in range(15):\n            tmp2 = 15 - i\n\n            if i > 7:\n                tmp3 = tmp2\n            else:\n                tmp3 = i + 1\n\n            vec[i] = y1[i] - (params[0] + (i + 1) / (params[1] * tmp2 + params[2] * tmp3))\n\n    def jac(params, jac):\n        for i in range(15):\n            tmp2 = 15 - i\n\n            if i > 7:\n                tmp3 = tmp2\n            else:\n                tmp3 = i + 1\n\n            tmp4 = (params[1] * tmp2 + params[2] * tmp3)**2\n            jac[0,i] = -1\n            jac[1,i] = (i + 1) * tmp2 / tmp4\n            jac[2,i] = (i + 1) * tmp3 / tmp4\n\n    guess = np.asfarray([1, 1, 1])\n\n    _lmder1_driver(15, func, jac, guess,\n                   0.6456136295159668e+01, 0.9063596033904667e-01,\n                   [0.8241057657583339e-01, 0.1133036653471504e+01, 0.2343694638941154e+01])\n    _lmder1_driver(15, func, jac, guess * 10,\n                   0.3614185315967845e+02, 0.4174768701385386e+01,\n                   [0.8406666738183293e+00, -0.1588480332595655e+09, -0.1643786716535352e+09])\n    _lmder1_driver(15, func, jac, guess * 100,\n                   0.3841146786373992e+03, 0.4174768701359691e+01,\n                   [0.8406666738676455e+00, -0.1589461672055184e+09, -0.1644649068577712e+09])", "response": "Bard function for lmder1 test."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _lmder1_kowalik_osborne():\n    v = np.asfarray([4, 2, 1, 0.5, 0.25, 0.167, 0.125, 0.1, 0.0833, 0.0714, 0.0625])\n    y2 = np.asfarray([0.1957, 0.1947, 0.1735, 0.16, 0.0844, 0.0627, 0.0456,\n                      0.0342, 0.0323, 0.0235, 0.0246])\n\n    def func(params, vec):\n        tmp1 = v * (v + params[1])\n        tmp2 = v * (v + params[2]) + params[3]\n        vec[:] = y2 - params[0] * tmp1 / tmp2\n\n    def jac(params, jac):\n        tmp1 = v * (v + params[1])\n        tmp2 = v * (v + params[2]) + params[3]\n        jac[0] = -tmp1 / tmp2\n        jac[1] = -v * params[0] / tmp2\n        jac[2] = jac[0] * jac[1]\n        jac[3] = jac[2] / v\n\n    guess = np.asfarray([0.25, 0.39, 0.415, 0.39])\n\n    _lmder1_driver(11, func, jac, guess,\n                   0.7289151028829448e-01, 0.1753583772112895e-01,\n                   [0.1928078104762493e+00, 0.1912626533540709e+00,\n                    0.1230528010469309e+00, 0.1360532211505167e+00])\n    _lmder1_driver(11, func, jac, guess * 10,\n                   0.2979370075552020e+01, 0.3205219291793696e-01,\n                   [0.7286754737686598e+06, -0.1407588031293926e+02,\n                    -0.3297779778419661e+08, -0.2057159419780170e+08])", "response": "Kowalik & Osborne function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _lmder1_meyer():\n\n    y3 = np.asarray([3.478e4, 2.861e4, 2.365e4, 1.963e4, 1.637e4, 1.372e4, 1.154e4,\n                     9.744e3, 8.261e3, 7.03e3, 6.005e3, 5.147e3, 4.427e3, 3.82e3,\n                     3.307e3, 2.872e3])\n\n    def func(params, vec):\n        temp = 5 * (np.arange(16) + 1) + 45 + params[2]\n        tmp1 = params[1] / temp\n        tmp2 = np.exp(tmp1)\n        vec[:] = params[0] * tmp2 - y3\n\n    def jac(params, jac):\n        temp = 5 * (np.arange(16) + 1) + 45 + params[2]\n        tmp1 = params[1] / temp\n        tmp2 = np.exp(tmp1)\n        jac[0] = tmp2\n        jac[1] = params[0] * tmp2 / temp\n        jac[2] = -tmp1 * jac[1]\n\n    guess = np.asfarray([0.02, 4000, 250])\n\n    _lmder1_driver(16, func, jac, guess,\n                   0.4115346655430312e+05, 0.9377945146518742e+01,\n                   [0.5609636471026614e-02, 0.6181346346286591e+04,\n                    0.3452236346241440e+03])", "response": "Meyer function for lmder1 test"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _lmder1_watson():\n\n    def func(params, vec):\n        div = (np.arange(29) + 1.) / 29\n        s1 = 0\n        dx = 1\n\n        for j in range(1, params.size):\n            s1 += j * dx * params[j]\n            dx *= div\n\n        s2 = 0\n        dx = 1\n\n        for j in range(params.size):\n            s2 += dx * params[j]\n            dx *= div\n\n        vec[:29] = s1 - s2**2 - 1\n        vec[29] = params[0]\n        vec[30] = params[1] - params[0]**2 - 1\n\n    def jac(params, jac):\n        jac.fill(0)\n        div = (np.arange(29) + 1.) / 29\n        s2 = 0\n        dx = 1\n\n        for j in range(params.size):\n            s2 += dx * params[j]\n            dx *= div\n\n        temp = 2 * div * s2\n        dx = 1. / div\n\n        for j in range(params.size):\n            jac[j,:29] = dx * (j - temp)\n            dx *= div\n\n        jac[0,29] = 1\n        jac[0,30] = -2 * params[0]\n        jac[1,30] = 1\n\n    _lmder1_driver(31, func, jac, np.zeros(6),\n                   0.5477225575051661e+01, 0.4782959390976008e-01,\n                   [-0.1572496150837816e-01, 0.1012434882329655e+01,\n                    -0.2329917223876733e+00, 0.1260431011028184e+01,\n                    -0.1513730313944205e+01, 0.9929972729184200e+00])\n    _lmder1_driver(31, func, jac, np.zeros(6) + 10,\n                   0.6433125789500264e+04, 0.4782959390969513e-01,\n                   [-0.1572519013866769e-01, 0.1012434858601051e+01,\n                    -0.2329915458438287e+00, 0.1260429320891626e+01,\n                    -0.1513727767065747e+01, 0.9929957342632802e+00])\n    _lmder1_driver(31, func, jac, np.zeros(6) + 100,\n                   0.6742560406052133e+06, 0.4782959391154397e-01,\n                   [-0.1572470197125856e-01, 0.1012434909256583e+01,\n                    -0.2329919227616415e+00, 0.1260432929295546e+01,\n                    -0.1513733204527065e+01, 0.9929990192232198e+00])\n    _lmder1_driver(31, func, jac, np.zeros(9),\n                   0.5477225575051661e+01, 0.1183114592124197e-02,\n                   [-0.1530706441667223e-04, 0.9997897039345969e+00, 0.1476396349109780e-01,\n                    0.1463423301459916e+00, 0.1000821094548170e+01, -0.2617731120705071e+01,\n                    0.4104403139433541e+01, -0.3143612262362414e+01, 0.1052626403787590e+01],\n                   decimal=8) # good enough for me\n    _lmder1_driver(31, func, jac, np.zeros(9) + 10,\n                   0.1208812706930700e+05, 0.1183114592125130e-02,\n                   [-0.1530713348492787e-04, 0.9997897039412339e+00, 0.1476396297862168e-01,\n                    0.1463423348188364e+00, 0.1000821073213860e+01, -0.2617731070847222e+01,\n                    0.4104403076555641e+01, -0.3143612221786855e+01, 0.1052626393225894e+01],\n                   decimal=7) # ditto\n    _lmder1_driver(31, func, jac, np.zeros(9) + 100,\n                   0.1269109290438338e+07, 0.1183114592123836e-02,\n                   [-0.1530695233521759e-04, 0.9997897039583713e+00, 0.1476396251853923e-01,\n                    0.1463423410963262e+00, 0.1000821047291639e+01, -0.2617731015736446e+01,\n                    0.4104403014272860e+01, -0.3143612186025031e+01, 0.1052626385167739e+01],\n                   decimal=7)\n    # I've hacked params[0] below to agree with the Python since most everything else\n    # is a lot closer. Fortran value is -0.6602660013963822D-08.\n    _lmder1_driver(31, func, jac, np.zeros(12),\n                   0.5477225575051661e+01, 0.2173104025358612e-04,\n                   [-0.66380604e-08, 0.1000001644118327e+01, -0.5639321469801545e-03,\n                    0.3478205400507559e+00, -0.1567315002442332e+00, 0.1052815158255932e+01,\n                    -0.3247271095194506e+01, 0.7288434783750497e+01, -0.1027184809861398e+02,\n                    0.9074113537157828e+01, -0.4541375419181941e+01, 0.1012011879750439e+01],\n                   decimal=7)\n    # These last two don't need any hacking or decimal < 10 ...\n    _lmder1_driver(31, func, jac, np.zeros(12) + 10,\n                   0.1922075897909507e+05, 0.2173104025185086e-04,\n                   [-0.6637102230174097e-08, 0.1000001644117873e+01, -0.5639322083473270e-03,\n                    0.3478205404869979e+00, -0.1567315039556524e+00, 0.1052815176545732e+01,\n                    -0.3247271151521395e+01, 0.7288434894306651e+01, -0.1027184823696385e+02,\n                    0.9074113643837332e+01, -0.4541375465336661e+01, 0.1012011888308566e+01],\n                   decimal=7)\n    _lmder1_driver(31, func, jac, np.zeros(12) + 100,\n                   0.2018918044623666e+07, 0.2173104025398453e-04,\n                   [-0.6638060464852487e-08, 0.1000001644117862e+01, -0.5639322103249589e-03,\n                    0.3478205405035875e+00, -0.1567315040913747e+00, 0.1052815177180306e+01,\n                    -0.3247271153370249e+01, 0.7288434897753017e+01, -0.1027184824108129e+02,\n                    0.9074113646884637e+01, -0.4541375466608216e+01, 0.1012011888536897e+01])", "response": "Watson function for lmder1 test. 11"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the physical side of the entry at the given index.", "response": "def p_side(self, idx, sidedness):\n        \"\"\"Acceptable values for *sidedness* are \"auto\", \"pos\",\n        \"neg\", and \"two\".\"\"\"\n        dsideval = _dside_names.get(sidedness)\n        if dsideval is None:\n            raise ValueError('unrecognized sidedness \"%s\"' % sidedness)\n\n        p = self._pinfob\n        p[idx] = (p[idx] & ~PI_M_SIDE) | dsideval\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck that value is a subclass of klass but that it is not actually .", "response": "def is_strict_subclass (value, klass):\n    \"\"\"Check that `value` is a subclass of `klass` but that it is not actually\n    `klass`. Unlike issubclass(), does not raise an exception if `value` is\n    not a type.\n\n    \"\"\"\n    return (isinstance (value, type) and\n            issubclass (value, klass) and\n            value is not klass)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef invoke_tool (namespace, tool_class=None):\n    import sys\n    from .. import cli\n    cli.propagate_sigint ()\n    cli.unicode_stdio ()\n    cli.backtrace_on_usr1 ()\n\n    if tool_class is None:\n        for value in itervalues (namespace):\n            if is_strict_subclass (value, Multitool):\n                if tool_class is not None:\n                    raise PKError ('do not know which Multitool implementation to use')\n                tool_class = value\n\n    if tool_class is None:\n        raise PKError ('no Multitool implementation to use')\n\n    tool = tool_class ()\n    tool.populate (itervalues (namespace))\n    tool.commandline (sys.argv)", "response": "Invoke a tool and exit."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninvokes the command with standardized usage - help processing. Same calling convention as Command. invoke.", "response": "def invoke_with_usage (self, args, **kwargs):\n        \"\"\"Invoke the command with standardized usage-help processing. Same calling\n        convention as `Command.invoke()`.\n\n        \"\"\"\n        argv0 = kwargs['argv0']\n        usage = self._usage (argv0)\n        argv = [argv0] + args\n        uina = 'long' if self.help_if_no_args else False\n        check_usage (usage, argv, usageifnoargs=uina)\n\n        try:\n            return self.invoke (args, **kwargs)\n        except UsageError as e:\n            wrong_usage (usage, str (e))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an instance of argparse. ArgumentParser used to process this tool s command - line arguments.", "response": "def get_arg_parser (self, **kwargs):\n        \"\"\"Return an instance of `argparse.ArgumentParser` used to process\n        this tool's command-line arguments.\n\n        \"\"\"\n        import argparse\n        ap = argparse.ArgumentParser (\n            prog = kwargs['argv0'],\n            description = self.summary,\n        )\n        return ap"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninvoke the command with standardized usage - help processing.", "response": "def invoke_with_usage (self, args, **kwargs):\n        \"\"\"Invoke the command with standardized usage-help processing. Same\n        calling convention as `Command.invoke()`, except here *args* is an\n        un-parsed list of strings.\n\n        \"\"\"\n        ap = self.get_arg_parser (**kwargs)\n        args = ap.parse_args (args)\n        return self.invoke (args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef register (self, cmd):\n        if cmd.name is None:\n            raise ValueError ('no name set for Command object %r' % cmd)\n        if cmd.name in self.commands:\n            raise ValueError ('a command named \"%s\" has already been '\n                              'registered' % cmd.name)\n\n        self.commands[cmd.name] = cmd\n        return self", "response": "Register a new command with the tool."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npopulate the internal state with the given values.", "response": "def populate (self, values):\n        \"\"\"Register multiple new commands by investigating the iterable `values`. For\n        each item in `values`, instances of `Command` are registered, and\n        subclasses of `Command` are instantiated (with no arguments passed to\n        the constructor) and registered. Other kinds of values are ignored.\n        Returns 'self'.\n\n        \"\"\"\n        for value in values:\n            if isinstance (value, Command):\n                self.register (value)\n            elif is_strict_subclass (value, Command) and getattr (value, 'name') is not None:\n                self.register (value ())\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef commandline (self, argv):\n        self.invoke_with_usage (argv[1:],\n                                tool=self,\n                                argv0=self.cli_name)", "response": "Run as if invoked from the command line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a LaTeX. aux file and generate a list of names cited according to the LaTeX. citation commands.", "response": "def cited_names_from_aux_file(stream):\n    \"\"\"Parse a LaTeX \".aux\" file and generate a list of names cited according to\n    LaTeX ``\\\\citation`` commands. Repeated names are generated only once. The\n    argument should be a opened I/O stream.\n\n    \"\"\"\n    cited = set()\n\n    for line in stream:\n        if not line.startswith(r'\\citation{'):\n            continue\n\n        line = line.rstrip()\n        if line[-1] != '}':\n            continue # should issue a warning or something\n\n        entries = line[10:-1]\n\n        for name in entries.split(','):\n            name = name.strip()\n\n            if name not in cited:\n                yield name\n                cited.add(name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmerge two BibTeX records into one.", "response": "def merge_bibtex_collections(citednames, maindict, extradicts, allow_missing=False):\n    \"\"\"There must be a way to be efficient and stream output instead of loading\n    everything into memory at once, but, meh.\n\n    Note that we augment `citednames` with all of the names in `maindict`. The\n    intention is that if we've gone to the effort of getting good data for\n    some record, we don't want to trash it if the citation is temporarily\n    removed (even if it ought to be manually recoverable from version\n    control). Seems better to err on the side of preservation; I can write a\n    quick pruning tool later if needed.\n\n    \"\"\"\n    allrecords = {}\n\n    for ed in extradicts:\n        allrecords.update(ed)\n\n    allrecords.update(maindict)\n\n    missing = []\n    from collections import OrderedDict\n    records = OrderedDict()\n    from itertools import chain\n    wantednames = sorted(chain(citednames, six.viewkeys(maindict)))\n\n    for name in wantednames:\n        rec = allrecords.get(name)\n        if rec is None:\n            missing.append(name)\n        else:\n            records[name] = rec\n\n    if len(missing) and not allow_missing:\n        # TODO: custom exception so caller can actually see what's missing;\n        # could conceivably stub out missing records or something.\n        raise PKError('missing BibTeX records: %s', ' '.join(missing))\n\n    return records"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_bibtex_dict(stream, entries):\n    from bibtexparser.bwriter import BibTexWriter\n\n    writer = BibTexWriter()\n    writer.indent = '  '\n    writer.entry_separator = ''\n    first = True\n\n    for rec in entries:\n        if first:\n            first = False\n        else:\n            stream.write(b'\\n')\n        stream.write(writer._entry_to_bibtex(rec).encode('utf8'))", "response": "Write a list of entries to a BibTeX file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmerges multiple BibTeX files into a single homogeneously - formatted output.", "response": "def merge_bibtex_with_aux(auxpath, mainpath, extradir, parse=get_bibtex_dict, allow_missing=False):\n    \"\"\"Merge multiple BibTeX files into a single homogeneously-formatted output,\n    using a LaTeX .aux file to know which records are worth paying attention\n    to.\n\n    The file identified by `mainpath` will be overwritten with the new .bib\n    contents. This function is intended to be used in a version-control\n    context.\n\n    Files matching the glob \"*.bib\" in `extradir` will be read in to\n    supplement the information in `mainpath`. Records already in the file in\n    `mainpath` always take precedence.\n\n    \"\"\"\n    auxpath = Path(auxpath)\n    mainpath = Path(mainpath)\n    extradir = Path(extradir)\n\n    with auxpath.open('rt') as aux:\n        citednames = sorted(cited_names_from_aux_file(aux))\n\n    main = mainpath.try_open(mode='rt')\n    if main is None:\n        maindict = {}\n    else:\n        maindict = parse(main)\n        main.close()\n\n    def gen_extra_dicts():\n        # If extradir does not exist, Path.glob() will return an empty list,\n        # which seems acceptable to me.\n        for item in sorted(extradir.glob('*.bib')):\n            with item.open('rt') as extra:\n                yield parse(extra)\n\n    merged = merge_bibtex_collections(citednames, maindict, gen_extra_dicts(),\n                                      allow_missing=allow_missing)\n\n    with mainpath.make_tempfile(want='handle', resolution='overwrite') as newbib:\n        write_bibtex_dict(newbib, six.viewvalues(merged))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef just_smart_bibtools(bib_style, aux, bib):\n    extradir = Path('.bibtex')\n    extradir.ensure_dir(parents=True)\n\n    bib_export(bib_style, aux, extradir / 'ZZ_bibtools.bib',\n               no_tool_ok=True, quiet=True, ignore_missing=True)\n    merge_bibtex_with_aux(aux, bib, extradir)", "response": "This function is just a hack to keep my smart. bib file generation working."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bp_to_aap (bp):\n\n    ap1, ap2 = bp\n    if ap1 < 0:\n        raise ValueError ('first antpol %d is negative' % ap1)\n    if ap2 < 0:\n        raise ValueError ('second antpol %d is negative' % ap2)\n\n    pol = _fpol_to_pol[((ap1 & 0x7) << 4) + (ap2 & 0x7)]\n    if pol == 0xFF:\n        raise ValueError ('no CASA polarization code for pairing '\n                          '%c-%c' % (fpol_names[ap1 & 0x7],\n                                     fpol_names[ap2 & 0x7]))\n\n    return ap1 >> 3, ap2 >> 3, pol", "response": "Converts a basepol into a tuple of ( ant1 ant2 pol )."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a basepol from antenna numbers and a CASA polarization code.", "response": "def aap_to_bp (ant1, ant2, pol):\n    \"\"\"Create a basepol from antenna numbers and a CASA polarization code.\"\"\"\n\n    if ant1 < 0:\n        raise ValueError ('first antenna is below 0: %s' % ant1)\n    if ant2 < ant1:\n        raise ValueError ('second antenna is below first: %s' % ant2)\n    if pol < 1 or pol > 12:\n        raise ValueError ('illegal polarization code %s' % pol)\n\n    fps = _pol_to_fpol[pol]\n    ap1 = (ant1 << 3) + ((fps >> 4) & 0x07)\n    ap2 = (ant2 << 3) + (fps & 0x07)\n    return ap1, ap2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef postproc (stats_result):\n    n, mean, scat = stats_result\n    mean *= 180 / np.pi # rad => deg\n    scat /= n # variance-of-samples => variance-of-mean\n    scat **= 0.5 # variance => stddev\n    scat *= 180 / np.pi # rad => deg\n    return mean, scat", "response": "Simple helper to postprocess angular outputs from StatsCollectors in the\n    way we want to postprocess the stats_result."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grid_bp_data (bps, items, mask=True):\n    seen_ants = set ()\n    seen_pols = set ()\n\n    for ant1, ant2, pol in (bp_to_aap (bp) for bp in bps):\n        seen_ants.add (ant1)\n        seen_ants.add (ant2)\n        seen_pols.add (pol)\n\n    if len (seen_pols) != 2:\n        raise Exception ('can only work with 2 polarizations')\n    pol1, pol2 = sorted (seen_pols)\n\n    seen_ants = np.array (sorted (seen_ants))\n    ant_map = dict ((a, i) for (i, a) in enumerate (seen_ants))\n\n    data = None\n    n = len (seen_ants)\n\n    for bp, value in items:\n        if data is None:\n            data = np.empty ((n, n), dtype=np.result_type (value))\n            data.fill (np.nan)\n\n        ant1, ant2, pol = bp_to_aap (bp)\n        i1 = ant_map[ant1]\n        i2 = ant_map[ant2]\n\n        if pol == pol1:\n            data[i1,i2] = value\n        else:\n            data[i2,i1] = value\n\n    if mask:\n        data = np.ma.MaskedArray (data, ~np.isfinite (data))\n\n    return pol1, pol2, seen_ants, data", "response": "Given a bunch of scalars associated with intensity - type basepols place them onto a grid."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinishing the process of computing weights means and variances for each keyset.", "response": "def finish (self, keyset, mask=True):\n        \"\"\"Returns (weights, means, variances), where:\n\n        weights\n          ndarray of number of samples per key\n        means\n          computed mean value for each key\n        variances\n          computed variance for each key\n\n        \"\"\"\n        n_us = len (self._keymap)\n        # By definition (for now), wt >= 1 everywhere, so we don't need to\n        # worry about div-by-zero.\n        wt_us = self._m0[:n_us]\n        mean_us = self._m1[:n_us] / wt_us\n        var_us = self._m2[:n_us] / wt_us - mean_us**2\n\n        n_them = len (keyset)\n        wt = np.zeros (n_them, dtype=self._m0.dtype)\n        mean = np.empty (n_them, dtype=self._m1.dtype)\n        mean.fill (np.nan)\n        var = np.empty_like (mean)\n        var.fill (np.nan)\n\n        us_idx = []\n        them_idx = []\n\n        for them_i, key in enumerate (keyset):\n            us_i = self._keymap[key]\n            if us_i < n_us:\n                them_idx.append (them_i)\n                us_idx.append (us_i)\n            # otherwise, we must not have seen that key\n\n        wt[them_idx] = wt_us[us_idx]\n        mean[them_idx] = mean_us[us_idx]\n        var[them_idx] = var_us[us_idx]\n\n        if mask:\n            m = ~np.isfinite (mean)\n            mean = np.ma.MaskedArray (mean, m)\n            var = np.ma.MaskedArray (var, m)\n\n        self._m0 = self._m1 = self._m2 = None\n        self._keymap.clear ()\n\n        return wt, mean, var"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef finish (self, key1set, key2set, mask=True):\n        n1_us = len (self._key1map)\n        n2_us = len (self._key2map)\n        wt_us = self._m0[:n1_us,:n2_us]\n        badwt = (wt_us == 0) | ~np.isfinite (wt_us)\n        wt_us[badwt] = 1\n        mean_us = self._m1[:n1_us,:n2_us] / wt_us\n        var_us = self._m2[:n1_us,:n2_us] / wt_us - mean_us**2\n        wt_us[badwt] = 0\n        mean_us[badwt] = np.nan\n        var_us[badwt] = np.nan\n\n        n1_them = len (key1set)\n        n2_them = len (key2set)\n        wt = np.zeros ((n1_them, n2_them), dtype=self._m0.dtype)\n        mean = np.empty ((n1_them, n2_them), dtype=self._m1.dtype)\n        mean.fill (np.nan)\n        var = np.empty_like (mean)\n        var.fill (np.nan)\n\n        # You can't fancy-index on two axes simultaneously, so we do a manual\n        # loop on the first axis.\n\n        us_idx2 = []\n        them_idx2 = []\n\n        for them_i2, key2 in enumerate (key2set):\n            us_i2 = self._key2map[key2]\n            if us_i2 < n2_us:\n                them_idx2.append (them_i2)\n                us_idx2.append (us_i2)\n            # otherwise, we must not have seen that key\n\n        for them_i1, key1 in enumerate (key1set):\n            us_i1 = self._key1map[key1]\n            if us_i1 >= n1_us:\n                continue # don't have this key\n\n            wt[them_i1,them_idx2] = wt_us[us_i1,us_idx2]\n            mean[them_i1,them_idx2] = mean_us[us_i1,us_idx2]\n            var[them_i1,them_idx2] = var_us[us_i1,us_idx2]\n\n        if mask:\n            m = ~np.isfinite (mean)\n            mean = np.ma.MaskedArray (mean, m)\n            var = np.ma.MaskedArray (var, m)\n\n        self._m0 = self._m1 = self._m2 = None\n        self._key1map.clear ()\n        self._key2map.clear ()\n\n        return wt, mean, var", "response": "Finishes the process of computing weights means and variances for each key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _finish_timeslot (self):\n        for fpol, aps in self.ap_by_fpol.items ():\n            aps = sorted (aps)\n            nap = len (aps)\n\n            for i1, ap1 in enumerate (aps):\n                for i2 in range (i1, nap):\n                    ap2 = aps[i2]\n                    bp1 = (ap1, ap2)\n                    info = self.data_by_bp.get (bp1)\n                    if info is None:\n                        continue\n\n                    data1, flags1 = info\n\n                    for i3 in range (i2, nap):\n                        ap3 = aps[i3]\n                        bp2 = (ap2, ap3)\n                        info = self.data_by_bp.get (bp2)\n                        if info is None:\n                            continue\n\n                        data2, flags2 = info\n                        bp3 = (ap1, aps[i3])\n                        info = self.data_by_bp.get (bp3)\n                        if info is None:\n                            continue\n\n                        data3, flags3 = info\n\n                        # try to minimize allocations:\n                        tflags = flags1 & flags2\n                        np.logical_and (tflags, flags3, tflags)\n                        if not tflags.any ():\n                            continue\n\n                        triple = data3.conj ()\n                        np.multiply (triple, data1, triple)\n                        np.multiply (triple, data2, triple)\n                        self._process_sample (ap1, ap2, ap3, triple, tflags)\n\n        # Reset for next timeslot\n\n        self.cur_time = -1.\n        self.bp_by_ap = None\n        self.ap_by_fpol = None", "response": "This function is called by _process_sample to process all of the visibilities in one timeslot."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _process_sample (self, ap1, ap2, ap3, triple, tflags):\n        # Frequency-resolved:\n        np.divide (triple, np.abs (triple), triple)\n        phase = np.angle (triple)\n\n        self.ap_spec_stats_by_ddid[self.cur_ddid].accum (ap1, phase, tflags + 0.)\n        self.ap_spec_stats_by_ddid[self.cur_ddid].accum (ap2, phase, tflags + 0.)\n        self.ap_spec_stats_by_ddid[self.cur_ddid].accum (ap3, phase, tflags + 0.)\n\n        # Frequency-averaged:\n        triple = np.dot (triple, tflags) / tflags.sum ()\n        phase = np.angle (triple)\n\n        self.global_stats_by_time.accum (self.cur_time, phase)\n\n        self.ap_stats_by_ddid[self.cur_ddid].accum (ap1, phase)\n        self.ap_stats_by_ddid[self.cur_ddid].accum (ap2, phase)\n        self.ap_stats_by_ddid[self.cur_ddid].accum (ap3, phase)\n        self.bp_stats_by_ddid[self.cur_ddid].accum ((ap1, ap2), phase)\n        self.bp_stats_by_ddid[self.cur_ddid].accum ((ap1, ap3), phase)\n        self.bp_stats_by_ddid[self.cur_ddid].accum ((ap2, ap3), phase)\n\n        self.ap_time_stats_by_ddid[self.cur_ddid].accum (self.cur_time, ap1, phase)\n        self.ap_time_stats_by_ddid[self.cur_ddid].accum (self.cur_time, ap2, phase)\n        self.ap_time_stats_by_ddid[self.cur_ddid].accum (self.cur_time, ap3, phase)", "response": "Process one sample in one timeslot."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dftphotom(cfg):\n    tb = util.tools.table()\n    ms = util.tools.ms()\n    me = util.tools.measures()\n\n    # Read stuff in. Even if the weight values don't have their\n    # absolute scale set correctly, we can still use them to set the\n    # relative weighting of the data points.\n    #\n    # datacol is (ncorr, nchan, nchunk)\n    # flag is (ncorr, nchan, nchunk)\n    # weight is (ncorr, nchunk)\n    # uvw is (3, nchunk)\n    # time is (nchunk)\n    # axis_info.corr_axis is (ncorr)\n    # axis_info.freq_axis.chan_freq is (nchan, 1) [for now?]\n    #\n    # Note that we apply msselect() again when reading the data because\n    # selectinit() is broken, but the invocation here is good because it\n    # affects the results from ms.range() and friends.\n\n    if ':' in (cfg.spw or ''):\n        warn('it looks like you are attempting to select channels within one or more spws')\n        warn('this is NOT IMPLEMENTED; I will average over the whole spw instead')\n\n    ms.open(b(cfg.vis))\n    totrows = ms.nrow()\n    ms_sels = dict((n, cfg.get(n)) for n in util.msselect_keys\n                   if cfg.get(n) is not None)\n    ms.msselect(b(ms_sels))\n\n    rangeinfo = ms.range(b'data_desc_id field_id'.split())\n    ddids = rangeinfo['data_desc_id']\n    fields = rangeinfo['field_id']\n    colnames = [cfg.datacol] + 'flag weight time axis_info'.split()\n    rephase = (cfg.rephase is not None)\n\n    if fields.size != 1:\n        # I feel comfortable making this a fatal error, even if we're\n        # not rephasing.\n        die('selected data should contain precisely one field; got %d', fields.size)\n\n    if rephase:\n        fieldid = fields[0]\n        tb.open(b(os.path.join(cfg.vis, 'FIELD')))\n        phdirinfo = tb.getcell(b'PHASE_DIR', fieldid)\n        tb.close()\n\n        if phdirinfo.shape[1] != 1:\n            die('trying to rephase but target field (#%d) has a '\n                'time-variable phase center, which I can\\'t handle', fieldid)\n        ra0, dec0 = phdirinfo[:,0] # in radians.\n\n        # based on intflib/pwflux.py, which was copied from\n        # hex/hex-lib-calcgainerr:\n\n        dra = cfg.rephase[0] - ra0\n        dec = cfg.rephase[1]\n        l = np.sin(dra) * np.cos(dec)\n        m = np.sin(dec) * np.cos(dec0) - np.cos(dra) * np.cos(dec) * np.sin(dec0)\n        n = np.sin(dec) * np.sin(dec0) + np.cos(dra) * np.cos(dec) * np.cos(dec0)\n        n -= 1 # makes the work below easier\n        lmn = np.asarray([l, m, n])\n        colnames.append('uvw')\n\n        # Also need this although 99% of the time `ddid` and `spwid` are the same\n        tb.open(b(os.path.join(cfg.vis, 'DATA_DESCRIPTION')))\n        ddspws = np.asarray(tb.getcol(b'SPECTRAL_WINDOW_ID'))\n        tb.close()\n\n    tbins = {}\n    colnames = b(colnames)\n\n    for ddindex, ddid in enumerate(ddids):\n        # Starting in CASA 4.6, selectinit(ddid) stopped actually filtering\n        # your data to match the specified DDID! What garbage. Work around\n        # with our own filtering.\n        ms_sels['taql'] = 'DATA_DESC_ID == %d' % ddid\n        ms.msselect(b(ms_sels))\n\n        ms.selectinit(ddid)\n        if cfg.polarization is not None:\n            ms.selectpolarization(b(cfg.polarization.split(',')))\n        ms.iterinit(maxrows=4096)\n        ms.iterorigin()\n\n        while True:\n            cols = ms.getdata(items=colnames)\n\n            if rephase:\n                # With appropriate spw/DDID selection, `freqs` has shape\n                # (nchan, 1). Convert to m^-1 so we can multiply against UVW\n                # directly.\n                freqs = cols['axis_info']['freq_axis']['chan_freq']\n                assert freqs.shape[1] == 1, 'internal inconsistency, chan_freq??'\n                freqs = freqs[:,0] * util.INVERSE_C_MS\n\n            for i in range(cols['time'].size): # all records\n                time = cols['time'][i]\n                # get out of UTC as fast as we can! For some reason\n                # giving 'unit=s' below doesn't do what one might hope it would.\n                # CASA can convert to a variety of timescales; TAI is probably\n                # the safest conversion in terms of being helpful while remaining\n                # close to the fundamental data, but TT is possible and should\n                # be perfectly precise for standard applications.\n                mq = me.epoch(b'utc', b({'value': time / 86400., 'unit': 'd'}))\n                mjdtt = me.measure(b(mq), b'tt')['m0']['value']\n\n                tdata = tbins.get(mjdtt, None)\n                if tdata is None:\n                    tdata = tbins[mjdtt] = [0., 0., 0., 0., 0]\n\n                if rephase:\n                    uvw = cols['uvw'][:,i]\n                    ph = np.exp((0-2j) * np.pi * np.dot(lmn, uvw) * freqs)\n\n                for j in range(cols['flag'].shape[0]): # all polns\n                    # We just average together all polarizations right now!\n                    # (Not actively, but passively by just iterating over them.)\n                    data = cols[cfg.datacol][j,:,i]\n                    flags = cols['flag'][j,:,i]\n\n                    # XXXXX casacore is currently (ca. 2012) broken and\n                    # returns the raw weights from the dataset rather than\n                    # applying the polarization selection. Fortunately all of\n                    # our weights are the same, and you can never fetch more\n                    # pol types than the dataset has, so this bit works\n                    # despite the bug.\n\n                    w = np.where(~flags)[0]\n                    if not w.size:\n                        continue # all flagged\n\n                    if rephase:\n                        data *= ph\n\n                    d = data[w].mean()\n                    # account for flagged parts. 90% sure this is the\n                    # right thing to do:\n                    wt = cols['weight'][j,i] * w.size / data.size\n                    wd = wt * d\n                    # note a little bit of a hack here to encode real^2 and\n                    # imag^2 separately:\n                    wd2 = wt * (d.real**2 + (1j) * d.imag**2)\n\n                    tdata[0] += wd\n                    tdata[1] += wd2\n                    tdata[2] += wt\n                    tdata[3] += wt**2\n                    tdata[4] += 1\n\n            if not ms.iternext():\n                break\n\n        ms.reset() # reset selection filter so we can get next DDID\n\n    ms.close()\n\n    # Could gain some efficiency by using a better data structure than a dict().\n    smjd = sorted(six.iterkeys(tbins))\n    cfg.format.header(cfg)\n\n    for mjd in smjd:\n        wd, wd2, wt, wt2, n = tbins[mjd]\n        if n < 3: # not enough data for meaningful statistics\n            continue\n\n        dtmin = 1440 * (mjd - smjd[0])\n        r_sc = wd.real / wt * cfg.datascale\n        i_sc = wd.imag / wt * cfg.datascale\n        r2_sc = wd2.real / wt * cfg.datascale**2\n        i2_sc = wd2.imag / wt * cfg.datascale**2\n\n        if cfg.believeweights:\n            ru_sc = wt**-0.5 * cfg.datascale\n            iu_sc = wt**-0.5 * cfg.datascale\n        else:\n            rv_sc = r2_sc - r_sc**2 # variance among real/imag msmts\n            iv_sc = i2_sc - i_sc**2\n            ru_sc = np.sqrt(rv_sc * wt2) / wt # uncert in mean real/img values\n            iu_sc = np.sqrt(iv_sc * wt2) / wt\n\n        mag = np.sqrt(r_sc**2 + i_sc**2)\n        umag = np.sqrt(r_sc**2 * ru_sc**2 + i_sc**2 * iu_sc**2) / mag\n        cfg.format.row(cfg, mjd, dtmin, r_sc, ru_sc, i_sc, iu_sc, mag, umag, n)", "response": "Run discrete - Fourier - transform photometry algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncommand - line access to the dftphotom algorithm.", "response": "def dftphotom_cli(argv):\n    \"\"\"Command-line access to the :func:`dftphotom` algorithm.\n\n    This function implements the behavior of the command-line ``casatask\n    dftphotom`` tool, wrapped up into a single callable function. The argument\n    *argv* is a list of command-line arguments, in Unix style where the zeroth\n    item is the name of the command.\n\n    \"\"\"\n    check_usage(dftphotom_doc, argv, usageifnoargs=True)\n    cfg = Config().parse(argv[1:])\n    util.logger(cfg.loglevel)\n    dftphotom(cfg)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef download_links(self, dir_path):\n    links = self.links\n    if not path.exists(dir_path):\n      makedirs(dir_path)\n    for i, url in enumerate(links):\n      if 'start' in self.cseargs:\n        i += int(self.cseargs['start'])\n      ext = self.cseargs['fileType']\n      ext = '.html' if ext == '' else '.' + ext\n      file_name = self.cseargs['q'].replace(' ', '_') + '_' + str(i) + ext\n      file_path = path.join(dir_path, file_name)\n      r = requests.get(url, stream=True)\n      if r.status_code == 200:\n        with open(file_path, 'wb') as f:\n          r.raw.decode_content = True\n          shutil.copyfileobj(r.raw, f)", "response": "Download web pages or images from search result links."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list of values from the key value metadata attribute.", "response": "def get_values(self, k, v):\n    \"\"\"Get a list of values from the key value metadata attribute.\n    \n    Args:\n      k (str):\n        Key in :class:`api.results`.metadata\n      v (str):\n        Values from each item in the key of :class:`api.results`.metadata\n    \n    Returns:\n      A list containing all the ``v`` values in the ``k`` key for the  :class:`api.results`.metadata attribute.\n    \"\"\"\n    metadata = self.metadata\n    values = []\n    if metadata != None:\n      if k in metadata:\n        for metav in metadata[k]:\n          if v in metav:\n            values.append(metav[v])\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef preview(self, n=10, k='items', kheader='displayLink', klink='link', kdescription='snippet'):\n    if 'searchType' in self.cseargs:\n      searchType = self.cseargs['searchType']\n    else:\n      searchType = None\n    items = self.metadata[k]\n  \n    # (cse_print) Print results\n    for i, kv in enumerate(items[:n]):\n      if 'start' in self.cseargs:\n        i += int(self.cseargs['start'])\n      \n      # (print_header) Print result header\n      header = '\\n[' + str(i) + '] ' + kv[kheader]\n      print(header)\n      print('=' * len(header))\n      \n      # (print_image) Print result image file\n      if searchType == 'image':\n        link = '\\n' + path.basename(kv[klink])\n        print(link)\n        \n      # (print_description) Print result snippet\n      description = '\\n' + kv[kdescription]\n      print(description)", "response": "Print a preview of the search results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave a text file of the search result links.", "response": "def save_links(self, file_path):\n    \"\"\"Saves a text file of the search result links.\n    \n    Saves a text file of the search result links, where each link \n    is saved in a new line. An example is provided below::\n      \n      http://www.google.ca\n      http://www.gmail.com\n    \n    Args:\n      file_path (str):\n        Path to the text file to save links to.\n    \"\"\"\n    data = '\\n'.join(self.links)\n    with open(file_path, 'w') as out_file:\n      out_file.write(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_metadata(self, file_path):\n    data = self.metadata\n    with open(file_path, 'w')  as out_file:\n      json.dump(data, out_file)", "response": "Saves the search result metadata to a json file of the search result metadata."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_spectrum(path, smoothing=181, DF=-8.):\n    try:\n        ang, lflam = np.loadtxt(path, usecols=(0,1)).T\n    except ValueError:\n        # In some files, the numbers in the first columns fill up the\n        # whole 12-character column width, and are given in exponential\n        # notation with a 'D' character, so we must be more careful:\n        with open(path, 'rb') as f:\n            def lines():\n                for line in f:\n                    yield line.replace(b'D', b'e')\n            ang, lflam = np.genfromtxt(lines(), delimiter=(13, 12)).T\n\n    # Data files do not come sorted!\n    z = ang.argsort()\n    ang = ang[z]\n    flam = 10**(lflam[z] + DF)\n    del z\n\n    if smoothing is not None:\n        if isinstance(smoothing, int):\n            smoothing = np.hamming(smoothing)\n        else:\n            smoothing = np.asarray(smoothing)\n\n        wnorm = np.convolve(np.ones_like(smoothing), smoothing, mode='valid')\n        smoothing = smoothing / wnorm # do not alter original array.\n        smooth = lambda a: np.convolve(a, smoothing, mode='valid')[::smoothing.size]\n        ang = smooth(ang)\n        flam = smooth(flam)\n\n    return pd.DataFrame({'wlen': ang, 'flam': flam})", "response": "Load a Phoenix model atmosphere spectrum from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bcj_from_spt (spt):\n    return np.where ((spt >= 0) & (spt <= 10),\n                     1.53 + 0.148 * spt - 0.0105 * spt**2,\n                     np.nan)", "response": "Calculate a bolometric correction constant for a J band magnitude based on a spectral type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bck_from_spt (spt):\n\n    # NOTE: the way np.piecewise() is implemented, the last 'true' value in\n    # the condition list is the one that takes precedence. This motivates the\n    # construction of our condition list.\n    #\n    # XXX: I've restructured the implementation; this needs testing!\n\n    spt = np.asfarray (spt) # we crash with integer inputs for some reason.\n    return np.piecewise (spt,\n                         [spt < 30,\n                          spt < 19,\n                          spt <= 14,\n                          spt < 10,\n                          (spt < 2) | (spt >= 30)],\n                         [lambda s: 3.41 - 0.21 * (s - 20), # Nakajima\n                          lambda s: 3.42 - 0.075 * (s - 14), # Dahn, Nakajima\n                          lambda s: 3.42 + 0.075 * (s - 14), # Dahn, Nakajima\n                          lambda s: 2.43 + 0.0895 * s, # Wilking; only ok for spt >= M2!\n                          np.nan])", "response": "Calculate a bolometric correction constant for a J band magnitude based on a spectral type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nestimate a UCD s bolometric luminosity given some basic parameters.", "response": "def lbol_from_spt_dist_mag (sptnum, dist_pc, jmag, kmag, format='cgs'):\n    \"\"\"Estimate a UCD's bolometric luminosity given some basic parameters.\n\n    sptnum: the spectral type as a number; 8 -> M8; 10 -> L0 ; 20 -> T0\n      Valid values range between 0 and 30, ie M0 to Y0.\n    dist_pc: distance to the object in parsecs\n    jmag: object's J-band magnitude or NaN (*not* None) if unavailable\n    kmag: same with K-band magnitude\n    format: either 'cgs', 'logcgs', or 'logsun', defining the form of the\n      outputs. Logarithmic quantities are base 10.\n\n    This routine can be used with vectors of measurements. The result will be\n    NaN if a value cannot be computed. This routine implements the method\n    documented in the Appendix of Williams et al., 2014ApJ...785....9W\n    (doi:10.1088/0004-637X/785/1/9).\n\n    \"\"\"\n    bcj = bcj_from_spt (sptnum)\n    bck = bck_from_spt (sptnum)\n\n    n = np.zeros (sptnum.shape, dtype=np.int)\n    app_mbol = np.zeros (sptnum.shape)\n\n    w = np.isfinite (bcj) & np.isfinite (jmag)\n    app_mbol[w] += jmag[w] + bcj[w]\n    n[w] += 1\n\n    w = np.isfinite (bck) & np.isfinite (kmag)\n    app_mbol[w] += kmag[w] + bck[w]\n    n[w] += 1\n\n    w = (n != 0)\n    abs_mbol = (app_mbol[w] / n[w]) - 5 * (np.log10 (dist_pc[w]) - 1)\n    # note: abs_mbol is filtered by `w`\n\n    lbol = np.empty (sptnum.shape)\n    lbol.fill (np.nan)\n    lbol[w] = lbol_from_mbol (abs_mbol, format=format)\n    return lbol"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nestimates mass in cgs from absolute J magnitude using the relationship of Delfosse + ( 2000A... 364..217D.", "response": "def mass_from_j (j_abs):\n    \"\"\"Estimate mass in cgs from absolute J magnitude, using the relationship of\n    Delfosse+ (2000A&A...364..217D).\n\n    j_abs - The absolute J magnitude.\n\n    Returns: the estimated mass in grams.\n\n    If j_abs > 11, a fixed result of 0.1 Msun is returned. Values of j_abs <\n    5.5 are illegal and get NaN. There is a discontinuity in the relation at\n    j_abs = 11, which yields 0.0824 Msun.\n\n    \"\"\"\n    j_abs = np.asfarray (j_abs)\n    return np.piecewise (j_abs,\n                         [j_abs > 11,\n                          j_abs <= 11,\n                          j_abs < 5.5],\n                         [0.1 * cgs.msun,\n                          _delfosse_mass_from_j_helper,\n                          np.nan])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_bcah98_mass_radius (tablelines, metallicity=0, heliumfrac=0.275,\n                             age_gyr=5., age_tol=0.05):\n    \"\"\"Load mass and radius from the main data table for the famous models of\n    Baraffe+ (1998A&A...337..403B).\n\n    tablelines\n      An iterable yielding lines from the table data file.\n      I've named the file '1998A&A...337..403B_tbl1-3.dat'\n      in some repositories (it's about 150K, not too bad).\n    metallicity\n      The metallicity of the model to select.\n    heliumfrac\n      The helium fraction of the model to select.\n    age_gyr\n      The age of the model to select, in Gyr.\n    age_tol\n      The tolerance on the matched age, in Gyr.\n\n    Returns: (mass, radius), where both are Numpy arrays.\n\n    The ages in the data table vary slightly at fixed metallicity and helium\n    fraction. Therefore, there needs to be a tolerance parameter for matching\n    the age.\n\n    \"\"\"\n    mdata, rdata = [], []\n\n    for line in tablelines:\n        a = line.strip ().split ()\n\n        thismetallicity = float (a[0])\n        if thismetallicity != metallicity:\n            continue\n\n        thisheliumfrac = float (a[1])\n        if thisheliumfrac != heliumfrac:\n            continue\n\n        thisage = float (a[4])\n        if abs (thisage - age_gyr) > age_tol:\n            continue\n\n        mass = float (a[3]) * cgs.msun\n        teff = float (a[5])\n        mbol = float (a[7])\n\n        # XXX to check: do they specify m_bol_sun = 4.64? IIRC, yes.\n        lbol = 10**(0.4 * (4.64 - mbol)) * cgs.lsun\n        area = lbol / (cgs.sigma * teff**4)\n        r = np.sqrt (area / (4 * np.pi))\n\n        mdata.append (mass)\n        rdata.append (r)\n\n    return np.asarray (mdata), np.asarray (rdata)", "response": "Load the mass and radius of a BCAH98 model from the main data table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a function that maps the sub - stellar mass to radius based on the Baraffe + model.", "response": "def mk_radius_from_mass_bcah98 (*args, **kwargs):\n    \"\"\"Create a function that maps (sub)stellar mass to radius, based on the\n    famous models of Baraffe+ (1998A&A...337..403B).\n\n    tablelines\n      An iterable yielding lines from the table data file.\n      I've named the file '1998A&A...337..403B_tbl1-3.dat'\n      in some repositories (it's about 150K, not too bad).\n    metallicity\n      The metallicity of the model to select.\n    heliumfrac\n      The helium fraction of the model to select.\n    age_gyr\n      The age of the model to select, in Gyr.\n    age_tol\n      The tolerance on the matched age, in Gyr.\n\n    Returns: a function mtor(mass_g), return a radius in cm as a function of a\n    mass in grams. The mass must be between 0.05 and 0.7 Msun.\n\n    The ages in the data table vary slightly at fixed metallicity and helium\n    fraction. Therefore, there needs to be a tolerance parameter for matching\n    the age.\n\n    This function requires Scipy.\n\n    \"\"\"\n    from scipy.interpolate import UnivariateSpline\n    m, r = load_bcah98_mass_radius (*args, **kwargs)\n    spl = UnivariateSpline (m, r, s=1)\n\n    # This allows us to do range-checking with either scalars or vectors with\n    # minimal gymnastics.\n    @numutil.broadcastize (1)\n    def interp (mass_g):\n        if np.any (mass_g < 0.05 * cgs.msun) or np.any (mass_g > 0.7 * cgs.msun):\n            raise ValueError ('mass_g must must be between 0.05 and 0.7 Msun')\n        return spl (mass_g)\n\n    return interp"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tauc_from_mass (mass_g):\n    m = mass_g / cgs.msun\n    return np.piecewise (m,\n                         [m < 1.3,\n                          m < 0.82,\n                          m < 0.65,\n                          m < 0.1],\n                         [lambda x: 61.7 - 44.7 * x,\n                          25.,\n                          lambda x: 86.9 - 94.3 * x,\n                          70.,\n                          np.nan]) * 86400.", "response": "Estimate the convective turnover time from mass."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef multiprocessing_ppmap_worker(in_queue, out_queue, func, fixed_arg):\n    while True:\n        i, var_arg = in_queue.get()\n        if i is None:\n            break\n        out_queue.put((i, func(i, fixed_arg, var_arg)))", "response": "Worker for the multiprocessing ppmap implementation."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_parallel_helper(parallel_arg, **kwargs):\n    if parallel_arg is True: # note: (True == 1) is True\n        return MultiprocessingPoolHelper(**kwargs)\n\n    if parallel_arg is False or parallel_arg == 1:\n        return SerialHelper(**kwargs)\n\n    if parallel_arg > 0 and parallel_arg < 1:\n        from multiprocessing import cpu_count\n        n = int(round(parallel_arg * cpu_count()))\n        return MultiprocessingPoolHelper(processes=n, **kwargs)\n\n    if isinstance(parallel_arg, ParallelHelper):\n        return parallel_arg\n\n    if isinstance(parallel_arg, six.integer_types):\n        return MultiprocessingPoolHelper(processes=parallel_arg, **kwargs)\n\n    raise ValueError('don\\'t understand make_parallel_helper() argument %r'\n                     % parallel_arg)", "response": "Return a new instance of a : class : ParallelHelper that can be used for easy - pickling of computations."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef map(self, func, iterable, chunksize=None):\n        # The key magic is that we must call r.get() with a timeout, because a\n        # Condition.wait() without a timeout swallows KeyboardInterrupts.\n        r = self.map_async(func, iterable, chunksize)\n\n        while True:\n            try:\n                return r.get(self.wait_timeout)\n            except TimeoutError:\n                pass\n            except KeyboardInterrupt:\n                self.terminate()\n                self.join()\n                raise", "response": "Equivalent of `map` built-in, without swallowing KeyboardInterrupt.\n\n        func\n          The function to apply to the items.\n        iterable\n          An iterable of items that will have `func` applied to them."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef kbn_conf (N, B, CL):\n\n    tol = 1e-6\n\n    origN = N\n    try:\n        N = int (N)\n        assert N == origN\n    except Exception:\n        raise ValueError ('N must be an integer')\n\n    CL = float (CL)\n    if CL <= 0. or CL >= 1.:\n        raise ValueError ('CL must be between 0 and 1, noninclusive')\n\n    B = float (B)\n    if B < 0:\n        raise ValueError ('B must be nonnegative')\n\n    # OK, arg-checking is out of the way. Precompute some things ...\n\n    C = _cconst (N, B)\n    f = lambda s: _fcnb (C, N, B, s)\n\n    # The goal is find Smin and Smax such that the integral of _fnb between\n    # Smin and Smax is CL, and _fnb (Smin) = _fnb (Smax). Follow the\n    # suggestion in Kraft, Burrows, & Nousek (1991) and start at the\n    # maximum-probability value, integrating outwards trying to maintain the\n    # constraints. We have to be careful because smin cannot go below zero,\n    # and to ignore the enormous typo (\"local maximum at S = B + N\"!) in the\n    # paper!\n\n    smin = smax = max (N - B, 0.)\n    fmin = f (smin)\n    fmax = f (smax)\n    conf = 0.\n\n    while conf < CL:\n        if smin == 0. or fmin < fmax:\n            stepsize = max (0.2 * abs (CL - conf) / CL / fmax, tol)\n            conf += quad (f, smax, smax + stepsize)[0]\n            smax += stepsize\n            fmax = f (smax)\n        else:\n            stepsize = max (min (0.2 * abs (CL - conf) / CL / fmin, 0.1 * smin), tol)\n            if smin - stepsize < tol:\n                conf += quad (f, 0, smin)[0]\n                smin = 0.\n            else:\n                conf += quad (f, smin - stepsize, smin)[0]\n                smin -= stepsize\n            fmin = f (smin)\n\n    return smin, smax", "response": "This function calculates the confidence interval of a given number of observed Poisson events N and a confidence limit CL and returns the smallest possible interval on the source event\n   ."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bin_bblock (widths, counts, p0=0.05):\n    widths = np.asarray (widths)\n    counts = np.asarray (counts)\n    ncells = widths.size\n    origp0 = p0\n\n    if np.any (widths <= 0):\n        raise ValueError ('bin widths must be positive')\n    if widths.size != counts.size:\n        raise ValueError ('widths and counts must have same size')\n    if p0 < 0 or p0 >= 1.:\n        raise ValueError ('p0 must lie within [0, 1)')\n\n    vedges = np.cumsum (np.concatenate (([0], widths))) # size: ncells + 1\n    block_remainders = vedges[-1] - vedges # size: nedges = ncells + 1\n    ccounts = np.cumsum (np.concatenate (([0], counts)))\n    count_remainders = ccounts[-1] - ccounts\n\n    prev_blockstarts = None\n    best = np.zeros (ncells, dtype=np.float)\n    last = np.zeros (ncells, dtype=np.int)\n\n    for _ in range (10):\n        # Pluggable num-change-points prior-weight expression:\n        ncp_prior = 4 - np.log (p0 / (0.0136 * ncells**0.478))\n\n        for r in range (ncells):\n            tk = block_remainders[:r+1] - block_remainders[r+1]\n            nk = count_remainders[:r+1] - count_remainders[r+1]\n\n            # Pluggable fitness expression:\n            fit_vec = nlogn (nk, tk)\n\n            # This incrementally penalizes partitions with more blocks:\n            tmp = fit_vec - ncp_prior\n            tmp[1:] += best[:r]\n\n            imax = np.argmax (tmp)\n            last[r] = imax\n            best[r] = tmp[imax]\n\n        # different semantics than Scargle impl: our blockstarts is similar to\n        # their changepoints, but we always finish with blockstarts[0] = 0.\n\n        work = np.zeros (ncells, dtype=int)\n        workidx = 0\n        ind = last[-1]\n\n        while True:\n            work[workidx] = ind\n            workidx += 1\n            if ind == 0:\n                break\n            ind = last[ind - 1]\n\n        blockstarts = work[:workidx][::-1]\n\n        if prev_blockstarts is not None:\n            if (blockstarts.size == prev_blockstarts.size and\n                (blockstarts == prev_blockstarts).all ()):\n                break # converged\n\n        if blockstarts.size == 1:\n            break # can't shrink any farther\n\n        # Recommended ad-hoc iteration to favor fewer blocks above and beyond\n        # the value of p0:\n        p0 = 1. - (1. - p0)**(1. / (blockstarts.size - 1))\n        prev_blockstarts = blockstarts\n\n    assert blockstarts[0] == 0\n    nblocks = blockstarts.size\n\n    info = Holder ()\n    info.ncells = ncells\n    info.nblocks = nblocks\n    info.origp0 = origp0\n    info.finalp0 = p0\n    info.blockstarts = blockstarts\n    info.counts = np.empty (nblocks, dtype=np.int)\n    info.widths = np.empty (nblocks)\n\n    for iblk in range (nblocks):\n        cellstart = blockstarts[iblk]\n        if iblk == nblocks - 1:\n            cellend = ncells - 1\n        else:\n            cellend = blockstarts[iblk+1] - 1\n\n        info.widths[iblk] = widths[cellstart:cellend+1].sum ()\n        info.counts[iblk] = counts[cellstart:cellend+1].sum ()\n\n    info.rates = info.counts / info.widths\n    return info", "response": "Fundamental Bayesian Blocks algorithm. Returns a Holder object with the output blocks binned by the given widths and counts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tt_bblock (tstarts, tstops, times, p0=0.05, intersect_with_bins=False):\n    tstarts = np.asarray (tstarts)\n    tstops = np.asarray (tstops)\n    times = np.asarray (times)\n\n    if tstarts.size != tstops.size:\n        raise ValueError ('must have same number of starts and stops')\n\n    ngti = tstarts.size\n\n    if ngti < 1:\n        raise ValueError ('must have at least one goodtime interval')\n    if np.any ((tstarts[1:] - tstarts[:-1]) <= 0):\n        raise ValueError ('tstarts must be ordered and distinct')\n    if np.any ((tstops[1:] - tstops[:-1]) <= 0):\n        raise ValueError ('tstops must be ordered and distinct')\n    if np.any (tstarts >= tstops):\n        raise ValueError ('tstarts must come before tstops')\n    if np.any ((times[1:] - times[:-1]) < 0):\n        raise ValueError ('times must be ordered')\n    if times.min () < tstarts[0]:\n        raise ValueError ('no times may be smaller than first tstart')\n    if times.max () > tstops[-1]:\n        raise ValueError ('no times may be larger than last tstop')\n    for i in range (1, ngti):\n        if np.where ((times > tstops[i-1]) & (times < tstarts[i]))[0].size:\n            raise ValueError ('no times may fall in goodtime gap #%d' % i)\n    if p0 < 0 or p0 >= 1.:\n        raise ValueError ('p0 must lie within [0, 1)')\n\n    utimes, uidxs = np.unique (times, return_index=True)\n    nunique = utimes.size\n\n    counts = np.empty (nunique)\n    counts[:-1] = uidxs[1:] - uidxs[:-1]\n    counts[-1] = times.size - uidxs[-1]\n    assert counts.sum () == times.size\n\n    # we grow these arrays with concats, which will perform badly with lots of\n    # GTIs. Not expected to be a big deal.\n    widths = np.empty (0)\n    ledges = np.empty (0)\n    redges = np.empty (0)\n\n    for i in range (ngti):\n        tstart, tstop = tstarts[i], tstops[i]\n\n        w = np.where ((utimes >= tstart) & (utimes <= tstop))[0]\n\n        if not w.size:\n            # No events during this goodtime! We have to insert a zero-count\n            # event block. This may break assumptions within bin_bblock()?\n\n            # j = idx of first event after this GTI\n            wafter = np.where (utimes > tstop)[0]\n            if wafter.size:\n                j = wafter[0]\n            else:\n                j = utimes.size\n            assert j == 0 or np.where (utimes < tstart)[0][-1] == j - 1\n\n            counts = np.concatenate ((counts[:j], [0], counts[j:]))\n            widths = np.concatenate ((widths, [tstop - tstart]))\n            ledges = np.concatenate ((ledges, [tstart]))\n            redges = np.concatenate ((redges, [tstop]))\n        else:\n            gtutimes = utimes[w]\n            midpoints = 0.5 * (gtutimes[1:] + gtutimes[:-1]) # size: n - 1\n            gtedges = np.concatenate (([tstart], midpoints, [tstop])) # size: n + 1\n            gtwidths = gtedges[1:] - gtedges[:-1] # size: n\n            assert gtwidths.sum () == tstop - tstart\n            widths = np.concatenate ((widths, gtwidths))\n            ledges = np.concatenate ((ledges, gtedges[:-1]))\n            redges = np.concatenate ((redges, gtedges[1:]))\n\n    assert counts.size == widths.size\n    info = bin_bblock (widths, counts, p0=p0)\n    info.ledges = ledges[info.blockstarts]\n    # The right edge of the i'th block is the right edge of its rightmost\n    # bin, which is the bin before the leftmost bin of the (i+1)'th block:\n    info.redges = np.concatenate ((redges[info.blockstarts[1:] - 1], [redges[-1]]))\n    info.midpoints = 0.5 * (info.ledges + info.redges)\n    del info.blockstarts\n\n    if intersect_with_bins:\n        # OK, we now need to intersect the bblock bins with the input bins.\n        # This can fracture one bblock bin into multiple ones but shouldn't\n        # make any of them disappear, since they're definitionally constrained\n        # to contain events.\n        #\n        # First: sorted list of all timestamps at which *something* changes:\n        # either a bblock edge, or a input bin edge. We drop the last entry,\n        # giving is a list of left edges of bins in which everything is the\n        # same.\n\n        all_times = set(tstarts)\n        all_times.update(tstops)\n        all_times.update(info.ledges)\n        all_times.update(info.redges)\n        all_times = np.array(sorted(all_times))[:-1]\n\n        # Now, construct a lookup table of which bblock number each of these\n        # bins corresponds to. More than one bin may have the same bblock\n        # number, if a GTI change slices a single bblock into more than one\n        # piece. We do this in a somewhat non-obvious way since we know that\n        # the bblocks completely cover the overall GTI span in order.\n\n        bblock_ids = np.zeros(all_times.size)\n\n        for i in range(1, info.nblocks):\n            bblock_ids[all_times >= info.ledges[i]] = i\n\n        # Now, a lookup table of which bins are within a good GTI span. Again,\n        # we know that all bins are either entirely in a good GTI or entirely\n        # outside, so the logic is simplified but not necessarily obvious.\n\n        good_timeslot = np.zeros(all_times.size, dtype=np.bool)\n\n        for t0, t1 in zip(tstarts, tstops):\n            ok = (all_times >= t0) & (all_times < t1)\n            good_timeslot[ok] = True\n\n        # Finally, look for contiguous spans that are in a good timeslot *and*\n        # have the same underlying bblock number. These are our intersected\n        # blocks.\n\n        old_bblock_ids = []\n        ledges = []\n        redges = []\n        cur_bblock_id = -1\n\n        for i in range(all_times.size):\n            if bblock_ids[i] != cur_bblock_id or not good_timeslot[i]:\n                if cur_bblock_id >= 0:\n                    # Ending a previous span.\n                    redges.append(all_times[i])\n                    cur_bblock_id = -1\n\n                if good_timeslot[i]:\n                    # Starting a new span.\n                    ledges.append(all_times[i])\n                    old_bblock_ids.append(bblock_ids[i])\n                    cur_bblock_id = bblock_ids[i]\n\n        if cur_bblock_id >= 0:\n            # End the last span.\n            redges.append(tstops[-1])\n\n        # Finally, rewrite all of the data as planned.\n\n        old_bblock_ids = np.array(old_bblock_ids, dtype=np.int)\n        info.counts = info.counts[old_bblock_ids]\n        info.rates = info.rates[old_bblock_ids]\n        info.widths = info.widths[old_bblock_ids]\n\n        info.ledges = np.array(ledges)\n        info.redges = np.array(redges)\n        info.midpoints = 0.5 * (info.ledges + info.redges)\n        info.nblocks = info.ledges.size\n\n    return info", "response": "Returns a Bayesian Blocks for time - tagged events."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bs_tt_bblock (times, tstarts, tstops, p0=0.05, nbootstrap=512):\n    times = np.asarray (times)\n    tstarts = np.asarray (tstarts)\n    tstops = np.asarray (tstops)\n\n    nevents = times.size\n    if nevents < 1:\n        raise ValueError ('must be given at least 1 event')\n\n    info = tt_bblock (tstarts, tstops, times, p0)\n\n    # Now bootstrap resample to assess uncertainties on the bin heights. This\n    # is the approach recommended by Scargle+.\n\n    bsrsums = np.zeros (info.nblocks)\n    bsrsumsqs = np.zeros (info.nblocks)\n\n    for _ in range (nbootstrap):\n        bstimes = times[np.random.randint (0, times.size, times.size)]\n        bstimes.sort ()\n        bsinfo = tt_bblock (tstarts, tstops, bstimes, p0)\n        blocknums = np.minimum (np.searchsorted (bsinfo.redges, info.midpoints),\n                                bsinfo.nblocks - 1)\n        samprates = bsinfo.rates[blocknums]\n        bsrsums += samprates\n        bsrsumsqs += samprates**2\n\n    bsrmeans = bsrsums / nbootstrap\n    mask = bsrsumsqs / nbootstrap <= bsrmeans**2\n    bsrstds = np.sqrt (np.where (mask, 0, bsrsumsqs / nbootstrap - bsrmeans**2))\n    info.bsrates = bsrmeans\n    info.bsrstds = bsrstds\n    return info", "response": "This function returns a Holder object that contains a bayesian block for time - tagged events with bootstrapping uncertainty."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fmthours (radians, norm='wrap', precision=3, seps='::'):\n    return _fmtsexagesimal (radians * R2H, norm, 24, seps, precision=precision)", "response": "Formats an angle as sexagesimal hours in a string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fmtdeglon (radians, norm='wrap', precision=2, seps='::'):\n    return _fmtsexagesimal (radians * R2D, norm, 360, seps, precision=precision)", "response": "Formats a longitudinal angle as sexagesimal degrees in a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fmtdeglat (radians, norm='raise', precision=2, seps='::'):\n    if norm == 'none':\n        pass\n    elif norm == 'raise':\n        if radians > halfpi or radians < -halfpi:\n            raise ValueError ('illegal latitude of %f radians' % radians)\n    elif norm == 'wrap':\n        radians = angcen (radians)\n        if radians > halfpi:\n            radians = pi - radians\n        elif radians < -halfpi:\n            radians = -pi - radians\n    else:\n        raise ValueError ('unrecognized normalization type \"%s\"' % norm)\n\n    if len (seps) < 2:\n        # To ponder: we accept len(seps) > 3; seems OK.\n        raise ValueError ('there must be at least two sexagesimal separators; '\n                          'got value \"%s\"' % seps)\n\n    precision = max (int (precision), 0)\n    if precision == 0:\n        width = 2\n    else:\n        width = precision + 3\n\n    degrees = radians * R2D\n\n    if degrees >= 0:\n        sgn = '+'\n    else:\n        sgn = '-'\n        degrees = -degrees\n\n    deg = int (np.floor (degrees))\n    amin = int (np.floor ((degrees - deg) * 60))\n    asec = round (3600 * (degrees - deg - amin / 60.), precision)\n\n    if asec >= 60:\n        # Can happen if we round up\n        asec -= 60\n        amin += 1\n\n        if amin >= 60:\n            amin -= 60\n            deg += 1\n\n    if len (seps) > 2:\n        sep2 = seps[2]\n    else:\n        sep2 = ''\n\n    return '%s%02d%s%02d%s%0*.*f%s' % \\\n        (sgn, deg, seps[0], amin, seps[1], width, precision, asec, sep2)", "response": "Formats a latitude in degrees as sexagesimal degrees in a string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nformats equatorial coordinates in a single sexagesimal string.", "response": "def fmtradec (rarad, decrad, precision=2, raseps='::', decseps='::', intersep=' '):\n    \"\"\"Format equatorial coordinates in a single sexagesimal string.\n\n    Returns a string of the RA/lon coordinate, formatted as sexagesimal hours,\n    then *intersep*, then the Dec/lat coordinate, formatted as degrees. This\n    yields something like \"12:34:56.78 -01:23:45.6\". Arguments are:\n\n    rarad\n      The right ascension coordinate, in radians. More generically, this is\n      the longitudinal coordinate; note that the ordering in this function\n      differs than the other spherical functions, which generally prefer\n      coordinates in \"lat, lon\" order.\n    decrad\n      The declination coordinate, in radians. More generically, this is the\n      latitudinal coordinate.\n    precision (default 2)\n      The number of decimal places in the \"arcseconds\" place of the\n      latitudinal (declination) coordinate. The longitudinal (right ascension)\n      coordinate gets one additional place, since hours are bigger than\n      degrees.\n    raseps (default \"::\")\n      A two- or three-item iterable, used to separate the hours, minutes, and\n      seconds components of the RA/lon coordinate. If a third element is\n      present, it appears after the seconds component. Specifying \"hms\" yields\n      something like \"12h34m56s\"; specifying ``['', '']`` yields something\n      like \"123456\".\n    decseps (default \"::\")\n      A two- or three-item iterable, used to separate the degrees, arcminutes,\n      and arcseconds components of the Dec/lat coordinate.\n    intersep (default \" \")\n      The string separating the RA/lon and Dec/lat coordinates\n\n    \"\"\"\n    return (fmthours (rarad, precision=precision + 1, seps=raseps) +\n            text_type (intersep) +\n            fmtdeglat (decrad, precision=precision, seps=decseps))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a string formatted as sexagesimal hours into a floating point value measured in radians.", "response": "def parsehours (hrstr):\n    \"\"\"Parse a string formatted as sexagesimal hours into an angle.\n\n    This function converts a textual representation of an angle, measured in\n    hours, into a floating point value measured in radians. The format of\n    *hrstr* is very limited: it may not have leading or trailing whitespace,\n    and the components of the sexagesimal representation must be separated by\n    colons. The input must therefore resemble something like\n    ``\"12:34:56.78\"``. A :exc:`ValueError` will be raised if the input does\n    not resemble this template. Hours greater than 24 are not allowed, but\n    negative values are.\n\n    \"\"\"\n    hr = _parsesexagesimal (hrstr, 'hours', False)\n    if hr >= 24:\n        raise ValueError ('illegal hour specification: ' + hrstr)\n    return hr * H2R"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a latitude formatted as sexagesimal degrees into a floating point value measured in radians.", "response": "def parsedeglat (latstr):\n    \"\"\"Parse a latitude formatted as sexagesimal degrees into an angle.\n\n    This function converts a textual representation of a latitude, measured in\n    degrees, into a floating point value measured in radians. The format of\n    *latstr* is very limited: it may not have leading or trailing whitespace,\n    and the components of the sexagesimal representation must be separated by\n    colons. The input must therefore resemble something like\n    ``\"-00:12:34.5\"``. A :exc:`ValueError` will be raised if the input does\n    not resemble this template. Latitudes greater than 90 or less than -90\n    degrees are not allowed.\n\n    \"\"\"\n    deg = _parsesexagesimal (latstr, 'latitude', True)\n    if abs (deg) > 90:\n        raise ValueError ('illegal latitude specification: ' + latstr)\n    return deg * D2R"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the distance between two locations on a sphere.", "response": "def sphdist (lat1, lon1, lat2, lon2):\n    \"\"\"Calculate the distance between two locations on a sphere.\n\n    lat1\n      The latitude of the first location.\n    lon1\n      The longitude of the first location.\n    lat2\n      The latitude of the second location.\n    lon2\n      The longitude of the second location.\n\n    Returns the separation in radians. All arguments are in radians as well.\n    The arguments may be vectors.\n\n    Note that the ordering of the arguments maps to the nonstandard ordering\n    ``(Dec, RA)`` in equatorial coordinates. In a spherical projection it maps\n    to ``(Y, X)`` which may also be unexpected.\n\n    The distance is computed with the \"specialized Vincenty formula\". Faster\n    but more error-prone formulae are possible; see Wikipedia on Great-circle\n    Distance.\n\n    \"\"\"\n    cd = np.cos (lon2 - lon1)\n    sd = np.sin (lon2 - lon1)\n    c2 = np.cos (lat2)\n    c1 = np.cos (lat1)\n    s2 = np.sin (lat2)\n    s1 = np.sin (lat1)\n    a = np.sqrt ((c2 * sd)**2 + (c1 * s2 - s1 * c2 * cd)**2)\n    b = s1 * s2 + c1 * c2 * cd\n    return np.arctan2 (a, b)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the bearing between two points on a spherical sphere.", "response": "def sphbear (lat1, lon1, lat2, lon2, tol=1e-15):\n    \"\"\"Calculate the bearing between two locations on a sphere.\n\n    lat1\n      The latitude of the first location.\n    lon1\n      The longitude of the first location.\n    lat2\n      The latitude of the second location.\n    lon2\n      The longitude of the second location.\n    tol\n      Tolerance for checking proximity to poles and rounding to zero.\n\n    The bearing (AKA the position angle, PA) is the orientation of point 2\n    with regards to point 1 relative to the longitudinal axis. Returns the\n    bearing in radians. All arguments are in radians as well. The arguments\n    may be vectors.\n\n    Note that the ordering of the arguments maps to the nonstandard ordering\n    ``(Dec, RA)`` in equatorial coordinates. In a spherical projection it maps\n    to ``(Y, X)`` which may also be unexpected.\n\n    The sign convention is astronomical: bearings range from -\u03c0 to \u03c0, with\n    negative values if point 2 is in the western hemisphere with regards to\n    point 1, positive if it is in the eastern. (That is, \u201ceast from north\u201d.)\n    If point 1 is very near the pole, the bearing is undefined and the result\n    is NaN.\n\n    The *tol* argument is used for checking proximity to the poles and for\n    rounding the bearing to precisely zero if it's extremely small.\n\n    Derived from ``bear()`` in `angles.py from Prasanth Nair\n    <https://github.com/phn/angles>`_. His version is BSD licensed. This one\n    is sufficiently different that I think it counts as a separate\n    implementation.\n\n    \"\"\"\n    # cross product on outer axis:\n    ocross = lambda a, b: np.cross (a, b, axisa=0, axisb=0, axisc=0)\n\n    # if args have shape S, this has shape (3, S)\n    v1 = np.asarray ([np.cos (lat1) * np.cos (lon1),\n                      np.cos (lat1) * np.sin (lon1),\n                      np.sin (lat1)])\n\n    v2 = np.asarray ([np.cos (lat2) * np.cos (lon2),\n                      np.cos (lat2) * np.sin (lon2),\n                      np.sin (lat2)])\n\n    is_bad = (v1[0]**2 + v1[1]**2) < tol\n\n    p12 = ocross (v1, v2) # ~\"perpendicular to great circle containing points\"\n    p1z = np.asarray ([v1[1], -v1[0], np.zeros_like (lat1)]) # ~\"perp to base and Z axis\"\n    cm = np.sqrt ((ocross (p12, p1z)**2).sum (axis=0)) # ~\"angle between the vectors\"\n    bearing = np.arctan2 (cm, np.sum (p12 * p1z, axis=0))\n    bearing = np.where (p12[2] < 0, -bearing, bearing) # convert to [-pi/2, pi/2]\n    bearing = np.where (np.abs (bearing) < tol, 0, bearing) # clamp\n    bearing[np.where (is_bad)] = np.nan\n    return bearing"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\noffsets from one location on the sphere to another. This function is given a start location, expressed as a latitude and longitude, a distance to offset, and a direction to offset (expressed as a bearing, AKA position angle). It uses these to compute a final location. This function mirrors :func:`sphdist` and :func:`sphbear` such that:: # If: r = sphdist (lat1, lon1, lat2a, lon2a) pa = sphbear (lat1, lon1, lat2a, lon2a) lat2b, lon2b = sphofs (lat1, lon1, r, pa) # Then lat2b = lat2a and lon2b = lon2a Arguments are: lat1 The latitude of the start location. lon1 The longitude of the start location. r The distance to offset by. pa The position angle (\u201cPA\u201d or bearing) to offset towards. tol The tolerance for the accuracy of the calculation. rmax The maximum allowed offset distance. Returns a pair ``(lat2, lon2)``. All arguments and the return values are measured in radians. The arguments may be vectors. The PA sign convention is astronomical, measuring orientation east from north. Note that the ordering of the arguments and return values maps to the nonstandard ordering ``(Dec, RA)`` in equatorial coordinates. In a spherical projection it maps to ``(Y, X)`` which may also be unexpected. The offset is computed naively as:: lat2 = lat1 + r * cos (pa) lon2 = lon1 + r * sin (pa) / cos (lat2) This will fail for large offsets. Error checking can be done in two ways. If *tol* is not None, :func:`sphdist` is used to calculate the actual distance between the two locations, and if the magnitude of the fractional difference between that and *r* is larger than *tol*, :exc:`ValueError` is raised. This will add an overhead to the computation that may be significant if you're going to be calling this function a lot. Additionally, if *rmax* is not None, magnitudes of *r* greater than *rmax* are rejected. For reference, an *r* of 0.2 (~11 deg) gives a maximum fractional distance error of ~3%.", "response": "def sphofs (lat1, lon1, r, pa, tol=1e-2, rmax=None):\n    \"\"\"Offset from one location on the sphere to another.\n\n    This function is given a start location, expressed as a latitude and\n    longitude, a distance to offset, and a direction to offset (expressed as a\n    bearing, AKA position angle). It uses these to compute a final location.\n    This function mirrors :func:`sphdist` and :func:`sphbear` such that::\n\n      # If:\n      r = sphdist (lat1, lon1, lat2a, lon2a)\n      pa = sphbear (lat1, lon1, lat2a, lon2a)\n      lat2b, lon2b = sphofs (lat1, lon1, r, pa)\n      # Then lat2b = lat2a and lon2b = lon2a\n\n    Arguments are:\n\n    lat1\n      The latitude of the start location.\n    lon1\n      The longitude of the start location.\n    r\n      The distance to offset by.\n    pa\n      The position angle (\u201cPA\u201d or bearing) to offset towards.\n    tol\n      The tolerance for the accuracy of the calculation.\n    rmax\n      The maximum allowed offset distance.\n\n    Returns a pair ``(lat2, lon2)``. All arguments and the return values are\n    measured in radians. The arguments may be vectors. The PA sign convention\n    is astronomical, measuring orientation east from north.\n\n    Note that the ordering of the arguments and return values maps to the\n    nonstandard ordering ``(Dec, RA)`` in equatorial coordinates. In a\n    spherical projection it maps to ``(Y, X)`` which may also be unexpected.\n\n    The offset is computed naively as::\n\n      lat2 = lat1 + r * cos (pa)\n      lon2 = lon1 + r * sin (pa) / cos (lat2)\n\n    This will fail for large offsets. Error checking can be done in two ways.\n    If *tol* is not None, :func:`sphdist` is used to calculate the actual\n    distance between the two locations, and if the magnitude of the fractional\n    difference between that and *r* is larger than *tol*, :exc:`ValueError` is\n    raised. This will add an overhead to the computation that may be\n    significant if you're going to be calling this function a lot.\n\n    Additionally, if *rmax* is not None, magnitudes of *r* greater than *rmax*\n    are rejected. For reference, an *r* of 0.2 (~11 deg) gives a maximum\n    fractional distance error of ~3%.\n\n    \"\"\"\n    if rmax is not None and np.abs (r) > rmax:\n        raise ValueError ('sphofs radius value %f is too big for '\n                          'our approximation' % r)\n\n    lat2 = lat1 + r * np.cos (pa)\n    lon2 = lon1 + r * np.sin (pa) / np.cos (lat2)\n\n    if tol is not None:\n        s = sphdist (lat1, lon1, lat2, lon2)\n        if np.any (np.abs ((s - r) / s) > tol):\n            raise ValueError ('sphofs approximation broke down '\n                              '(%s %s %s %s %s %s %s)' % (lat1, lon1,\n                                                          lat2, lon2,\n                                                          r, s, pa))\n\n    return lat2, lon2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parang (hourangle, declination, latitude):\n    return -np.arctan2 (-np.sin (hourangle),\n                        np.cos (declination) * np.tan (latitude)\n                        - np.sin (declination) * np.cos (hourangle))", "response": "Calculate the parallactic angle of a position in terms of a given hour angle and declination and latitude."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gaussian_deconvolve (smaj, smin, spa, bmaj, bmin, bpa):\n    # I've added extra code to ensure ``smaj >= bmaj``, ``smin >= bmin``, and\n    # increased the coefficient in front of \"limit\" from 0.1 to 0.5. Feel a\n    # little wary about that first change.\n\n    from numpy import cos, sin, sqrt, min, abs, arctan2\n\n    if smaj < bmaj:\n        smaj = bmaj\n    if smin < bmin:\n        smin = bmin\n\n    alpha = ((smaj * cos (spa))**2 + (smin * sin (spa))**2 -\n             (bmaj * cos (bpa))**2 - (bmin * sin (bpa))**2)\n    beta = ((smaj * sin (spa))**2 + (smin * cos (spa))**2 -\n            (bmaj * sin (bpa))**2 - (bmin * cos (bpa))**2)\n    gamma = 2 * ((smin**2 - smaj**2) * sin (spa) * cos (spa) -\n                 (bmin**2 - bmaj**2) * sin (bpa) * cos (bpa))\n\n    s = alpha + beta\n    t = sqrt ((alpha - beta)**2 + gamma**2)\n    limit = 0.5 * min ([smaj, smin, bmaj, bmin])**2\n    status = 'ok'\n\n    if alpha < 0 or beta < 0 or s < t:\n        dmaj = dmin = dpa = 0\n\n        if 0.5 * (s - t) < limit and alpha > -limit and beta > -limit:\n            status = 'pointlike'\n        else:\n            status = 'fail'\n    else:\n        dmaj = sqrt (0.5 * (s + t))\n        dmin = sqrt (0.5 * (s - t))\n\n        if abs (gamma) + abs (alpha - beta) == 0:\n            dpa = 0\n        else:\n            dpa = 0.5 * arctan2 (-gamma, alpha - beta)\n\n    return dmaj, dmin, dpa, status", "response": "Deconvolve two Gaussians analytically."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_skyfield_data():\n    import os.path\n    from astropy.config import paths\n    from skyfield.api import Loader\n\n    cache_dir = os.path.join(paths.get_cache_dir(), 'pwkit')\n    loader = Loader(cache_dir)\n    planets = loader('de421.bsp')\n    ts = loader.timescale()\n    return planets, ts", "response": "Load data files used in Skyfield."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a 2MASS position, look up the epoch when it was observed. This function uses the CDS Vizier web service to look up information in the 2MASS point source database. Arguments are: tmra The source's J2000 right ascension, in radians. tmdec The source's J2000 declination, in radians. debug If True, the web server's response will be printed to :data:`sys.stdout`. The return value is an MJD. If the lookup fails, a message will be printed to :data:`sys.stderr` (unconditionally!) and the :data:`J2000` epoch will be returned.", "response": "def get_2mass_epoch (tmra, tmdec, debug=False):\n    \"\"\"Given a 2MASS position, look up the epoch when it was observed.\n\n    This function uses the CDS Vizier web service to look up information in\n    the 2MASS point source database. Arguments are:\n\n    tmra\n      The source's J2000 right ascension, in radians.\n    tmdec\n      The source's J2000 declination, in radians.\n    debug\n      If True, the web server's response will be printed to :data:`sys.stdout`.\n\n    The return value is an MJD. If the lookup fails, a message will be printed\n    to :data:`sys.stderr` (unconditionally!) and the :data:`J2000` epoch will\n    be returned.\n\n    \"\"\"\n    import codecs\n    try:\n        from urllib.request import urlopen\n    except ImportError:\n        from urllib2 import urlopen\n    postdata = b'''-mime=csv\n-source=2MASS\n-out=_q,JD\n-c=%.6f %.6f\n-c.eq=J2000''' % (tmra * R2D, tmdec * R2D)\n\n    jd = None\n\n    for line in codecs.getreader('utf-8')(urlopen (_vizurl, postdata)):\n        line = line.strip ()\n        if debug:\n            print_ ('D: 2M >>', line)\n\n        if line.startswith ('1;'):\n            jd = float (line[2:])\n\n    if jd is None:\n        import sys\n        print_ ('warning: 2MASS epoch lookup failed; astrometry could be very wrong!',\n                file=sys.stderr)\n        return J2000\n\n    return jd - 2400000.5"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching astrometric information from the Simbad web service.", "response": "def get_simbad_astrometry_info (ident, items=_simbaditems, debug=False):\n    \"\"\"Fetch astrometric information from the Simbad web service.\n\n    Given the name of a source as known to the CDS Simbad service, this\n    function looks up its positional information and returns it in a\n    dictionary. In most cases you should use an :class:`AstrometryInfo` object\n    and its :meth:`~AstrometryInfo.fill_from_simbad` method instead of this\n    function.\n\n    Arguments:\n\n    ident\n      The Simbad name of the source to look up.\n    items\n      An iterable of data items to look up. The default fetches position,\n      proper motion, parallax, and radial velocity information. Each item name\n      resembles the string ``COO(d;A)`` or ``PLX(E)``. The allowed formats are\n      defined `on this CDS page\n      <http://simbad.u-strasbg.fr/Pages/guide/sim-fscript.htx>`_.\n    debug\n      If true, the response from the webserver will be printed.\n\n    The return value is a dictionary with a key corresponding to the textual\n    result returned for each requested item.\n\n    \"\"\"\n    import codecs\n    try:\n        from urllib.parse import quote\n    except ImportError:\n        from urllib import quote\n    try:\n        from urllib.request import urlopen\n    except ImportError:\n        from urllib2 import urlopen\n\n    s = '\\\\n'.join ('%s %%%s' % (i, i) for i in items)\n    s = '''output console=off script=off\nformat object \"%s\"\nquery id %s''' % (s, ident)\n    url = _simbadbase + quote (s)\n    results = {}\n    errtext = None\n\n    for line in codecs.getreader('utf-8')(urlopen (url)):\n        line = line.strip ()\n        if debug:\n            print_ ('D: SA >>', line)\n\n        if errtext is not None:\n            errtext += line\n        elif line.startswith ('::error'):\n            errtext = ''\n        elif len (line):\n            k, v = line.split (' ', 1)\n            results[k] = v\n\n    if errtext is not None:\n        raise Exception ('SIMBAD query error: ' + errtext)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating that the attributes of the object are self - consistent.", "response": "def verify (self, complain=True):\n        \"\"\"Validate that the attributes are self-consistent.\n\n        This function does some basic checks of the object attributes to\n        ensure that astrometric calculations can legally be performed. If the\n        *complain* keyword is true, messages may be printed to\n        :data:`sys.stderr` if non-fatal issues are encountered.\n\n        Returns *self*.\n\n        \"\"\"\n        import sys\n\n        if self.ra is None:\n            raise ValueError ('AstrometryInfo missing \"ra\"')\n        if self.dec is None:\n            raise ValueError ('AstrometryInfo missing \"dec\"')\n\n        if self._partial_info (self.promo_ra, self.promo_dec):\n            raise ValueError ('partial proper-motion info in AstrometryInfo')\n\n        if self._partial_info (self.pos_u_maj, self.pos_u_min, self.pos_u_pa):\n            raise ValueError ('partial positional uncertainty info in AstrometryInfo')\n\n        if self._partial_info (self.promo_u_maj, self.promo_u_min, self.promo_u_pa):\n            raise ValueError ('partial proper-motion uncertainty info in AstrometryInfo')\n\n        if self.pos_u_maj is None:\n            if complain:\n                print_ ('AstrometryInfo: no positional uncertainty info', file=sys.stderr)\n        elif self.pos_u_maj < self.pos_u_min:\n            # Based on experience with PM, this may be possible\n            if complain:\n                print_ ('AstrometryInfo: swapped positional uncertainty '\n                        'major/minor axes', file=sys.stderr)\n            self.pos_u_maj, self.pos_u_min = self.pos_u_min, self.pos_u_maj\n            self.pos_u_pa += 0.5 * np.pi\n\n        if self.pos_epoch is None:\n            if complain:\n                print_('AstrometryInfo: assuming epoch of position is J2000.0', file=sys.stderr)\n\n        if self.promo_ra is None:\n            if complain:\n                print_ ('AstrometryInfo: assuming zero proper motion', file=sys.stderr)\n        elif self.promo_u_maj is None:\n            if complain:\n                print_ ('AstrometryInfo: no uncertainty on proper motion', file=sys.stderr)\n        elif self.promo_u_maj < self.promo_u_min:\n            # I've seen this: V* V374 Peg\n            if complain:\n                print_ ('AstrometryInfo: swapped proper motion uncertainty '\n                        'major/minor axes', file=sys.stderr)\n            self.promo_u_maj, self.promo_u_min = self.promo_u_min, self.promo_u_maj\n            self.promo_u_pa += 0.5 * np.pi\n\n        if self.parallax is None:\n            if complain:\n                print_ ('AstrometryInfo: assuming zero parallax', file=sys.stderr)\n        else:\n            if self.parallax < 0.:\n                raise ValueError ('negative parallax in AstrometryInfo')\n            if self.u_parallax is None:\n                if complain:\n                    print_ ('AstrometryInfo: no uncertainty on parallax', file=sys.stderr)\n\n        if self.vradial is None:\n            pass # not worth complaining\n        elif self.u_vradial is None:\n            if complain:\n                print_ ('AstrometryInfo: no uncertainty on v_radial', file=sys.stderr)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef predict_without_uncertainties(self, mjd, complain=True):\n        import sys\n\n        self.verify(complain=complain)\n\n        planets, ts = load_skyfield_data() # might download stuff from the internet\n        earth = planets['earth']\n        t = ts.tdb(jd = mjd + 2400000.5)\n\n        # \"Best\" position. The implementation here is a bit weird to keep\n        # parallelism with predict().\n\n        args = {\n            'ra_hours': self.ra * R2H,\n            'dec_degrees': self.dec * R2D,\n        }\n\n        if self.pos_epoch is not None:\n            args['jd_of_position'] = self.pos_epoch + 2400000.5\n\n        if self.promo_ra is not None:\n            args['ra_mas_per_year'] = self.promo_ra\n            args['dec_mas_per_year'] = self.promo_dec\n        if self.parallax is not None:\n            args['parallax_mas'] = self.parallax\n        if self.vradial is not None:\n            args['radial_km_per_s'] = self.vradial\n\n        bestra, bestdec, _ = earth.at(t).observe(PromoEpochStar(**args)).radec()\n        return bestra.radians, bestdec.radians", "response": "Predict the object position at a given MJD."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npredicting the position of the object at a given MJD.", "response": "def predict (self, mjd, complain=True, n=20000):\n        \"\"\"Predict the object position at a given MJD.\n\n        The return value is a tuple ``(ra, dec, major, minor, pa)``, all in\n        radians. These are the predicted position of the object and its\n        uncertainty at *mjd*. If *complain* is True, print out warnings for\n        incomplete information. *n* is the number of Monte Carlo samples to\n        draw for computing the positional uncertainty.\n\n        The uncertainty ellipse parameters are sigmas, not FWHM. These may be\n        converted with the :data:`S2F` constant.\n\n        This function relies on the external :mod:`skyfield` package.\n\n        \"\"\"\n        import sys\n        from . import ellipses\n\n        self.verify (complain=complain)\n\n        planets, ts = load_skyfield_data() # might download stuff from the internet\n        earth = planets['earth']\n        t = ts.tdb(jd = mjd + 2400000.5)\n\n        # \"Best\" position.\n\n        args = {\n            'ra_hours': self.ra * R2H,\n            'dec_degrees': self.dec * R2D,\n        }\n\n        if self.pos_epoch is not None:\n            args['jd_of_position'] = self.pos_epoch + 2400000.5\n\n        if self.promo_ra is not None:\n            args['ra_mas_per_year'] = self.promo_ra\n            args['dec_mas_per_year'] = self.promo_dec\n        if self.parallax is not None:\n            args['parallax_mas'] = self.parallax\n        if self.vradial is not None:\n            args['radial_km_per_s'] = self.vradial\n\n        bestra, bestdec, _ = earth.at(t).observe(PromoEpochStar(**args)).radec()\n        bestra = bestra.radians\n        bestdec = bestdec.radians\n\n        # Monte Carlo to get an uncertainty. As always, astronomy position\n        # angle convention requires that we treat declination as X and RA as\n        # Y. First, we check sanity and generate randomized parameters:\n\n        if self.pos_u_maj is None and self.promo_u_maj is None and self.u_parallax is None:\n            if complain:\n                print_ ('AstrometryInfo.predict(): no uncertainties '\n                        'available; cannot Monte Carlo!', file=sys.stderr)\n            return (bestra, bestdec, 0., 0., 0.)\n\n        if self.pos_u_maj is not None:\n            sd, sr, cdr = ellipses.ellbiv (self.pos_u_maj, self.pos_u_min, self.pos_u_pa)\n            decs, ras = ellipses.bivrandom (self.dec, self.ra, sd, sr, cdr, n).T\n        else:\n            ras = np.zeros (n) + self.ra\n            decs = np.zeros (n) + self.dec\n\n        if self.promo_ra is None:\n            pmras = np.zeros (n)\n            pmdecs = np.zeros (n)\n        elif self.promo_u_maj is not None:\n            sd, sr, cdr = ellipses.ellbiv (self.promo_u_maj, self.promo_u_min, self.promo_u_pa)\n            pmdecs, pmras = ellipses.bivrandom (self.promo_dec, self.promo_ra, sd, sr, cdr, n).T\n        else:\n            pmras = np.zeros (n) + self.promo_ra\n            pmdecs = np.zeros (n) + self.promo_dec\n\n        if self.parallax is None:\n            parallaxes = np.zeros (n)\n        elif self.u_parallax is not None:\n            parallaxes = np.random.normal (self.parallax, self.u_parallax, n)\n        else:\n            parallaxes = np.zeros (n) + self.parallax\n\n        if self.vradial is None:\n            vradials = np.zeros (n)\n        elif self.u_vradial is not None:\n            vradials = np.random.normal (self.vradial, self.u_vradial, n)\n        else:\n            vradials = np.zeros (n) + self.vradial\n\n        # Now we compute the positions and summarize as an ellipse:\n\n        results = np.empty ((n, 2))\n\n        for i in range (n):\n            args['ra_hours'] = ras[i] * R2H\n            args['dec_degrees'] = decs[i] * R2D\n            args['ra_mas_per_year'] = pmras[i]\n            args['dec_mas_per_year'] = pmdecs[i]\n            args['parallax_mas'] = parallaxes[i]\n            args['radial_km_per_s'] = vradials[i]\n            ara, adec, _ = earth.at(t).observe(PromoEpochStar(**args)).radec()\n            results[i] = adec.radians, ara.radians\n\n        maj, min, pa = ellipses.bivell (*ellipses.databiv (results))\n\n        # All done.\n\n        return bestra, bestdec, maj, min, pa"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_prediction (self, ptup, precision=2):\n        from . import ellipses\n        bestra, bestdec, maj, min, pa = ptup\n\n        f = ellipses.sigmascale (1)\n        maj *= R2A\n        min *= R2A\n        pa *= R2D\n\n        print_ ('position =', fmtradec (bestra, bestdec, precision=precision))\n        print_ ('err(1\u03c3)  = %.*f\" \u00d7 %.*f\" @ %.0f\u00b0' % (precision, maj * f, precision,\n                                                      min * f, pa))", "response": "Print a summary of a predicted position."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfills in astrometric information using the Simbad web service.", "response": "def fill_from_simbad (self, ident, debug=False):\n        \"\"\"Fill in astrometric information using the Simbad web service.\n\n        This uses the CDS Simbad web service to look up astrometric\n        information for the source name *ident* and fills in attributes\n        appropriately. Values from Simbad are not always reliable.\n\n        Returns *self*.\n\n        \"\"\"\n        info = get_simbad_astrometry_info (ident, debug=debug)\n        posref = 'unknown'\n\n        for k, v in six.iteritems (info):\n            if '~' in v:\n                continue # no info\n\n            if k == 'COO(d;A)':\n                self.ra = float (v) * D2R\n            elif k == 'COO(d;D)':\n                self.dec = float (v) * D2R\n            elif k == 'COO(E)':\n                a = v.split ()\n                self.pos_u_maj = float (a[0]) * A2R * 1e-3 # mas -> rad\n                self.pos_u_min = float (a[1]) * A2R * 1e-3\n                self.pos_u_pa = float (a[2]) * D2R\n            elif k == 'COO(B)':\n                posref = v\n            elif k == 'PM(A)':\n                self.promo_ra = float (v) # mas/yr\n            elif k == 'PM(D)':\n                self.promo_dec = float (v) # mas/yr\n            elif k == 'PM(E)':\n                a = v.split ()\n                self.promo_u_maj = float (a[0]) # mas/yr\n                self.promo_u_min = float (a[1])\n                self.promo_u_pa = float (a[2]) * D2R # rad!\n            elif k == 'PLX(V)':\n                self.parallax = float (v) # mas\n            elif k == 'PLX(E)':\n                self.u_parallax = float (v) # mas\n            elif k == 'RV(V)':\n                self.vradial = float (v) # km/s\n            elif k == 'RV(E)':\n                self.u_vradial = float (v) #km/s\n\n        if self.ra is None:\n            raise Exception ('no position returned by Simbad for \"%s\"' % ident)\n        if self.u_parallax == 0:\n            self.u_parallax = None\n        if self.u_vradial == 0:\n            self.u_vradial = None\n\n        # Get the right epoch of position for 2MASS positions\n\n        if posref == '2003yCat.2246....0C':\n            self.pos_epoch = get_2mass_epoch (self.ra, self.dec, debug)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfilling in astrometric information from the AllWISE catalog using Astroquery.", "response": "def fill_from_allwise (self, ident, catalog_ident='II/328/allwise'):\n        \"\"\"Fill in astrometric information from the AllWISE catalog using Astroquery.\n\n        This uses the :mod:`astroquery` module to query the AllWISE\n        (2013wise.rept....1C) source catalog through the Vizier\n        (2000A&AS..143...23O) web service. It then fills in the instance with\n        the relevant information. Arguments are:\n\n        ident\n          The AllWISE catalog identifier of the form ``\"J112254.70+255021.9\"``.\n        catalog_ident\n          The Vizier designation of the catalog to query. The default is\n          \"II/328/allwise\", the current version of the AllWISE catalog.\n\n        Raises :exc:`~pwkit.PKError` if something unexpected happens that\n        doesn't itself result in an exception within :mod:`astroquery`.\n\n        You should probably prefer :meth:`fill_from_simbad` for objects that\n        are known to the CDS Simbad service, but not all objects in the\n        AllWISE catalog are so known.\n\n        If you use this function, you should `acknowledge AllWISE\n        <http://irsadist.ipac.caltech.edu/wise-allwise/>`_ and `Vizier\n        <http://cds.u-strasbg.fr/vizier-org/licences_vizier.html>`_.\n\n        Returns *self*.\n\n        \"\"\"\n        from astroquery.vizier import Vizier\n        import numpy.ma.core as ma_core\n\n        # We should match exactly one table and one row within that table, but\n        # for robustness we ignore additional results if they happen to\n        # appear. Strangely, querying for an invalid identifier yields a table\n        # with two rows that are filled with masked out data.\n\n        table_list = Vizier.query_constraints (catalog=catalog_ident, AllWISE=ident)\n        if not len (table_list):\n            raise PKError ('Vizier query returned no tables (catalog=%r AllWISE=%r)',\n                           catalog_ident, ident)\n\n        table = table_list[0]\n        if not len (table):\n            raise PKError ('Vizier query returned empty %s table (catalog=%r AllWISE=%r)',\n                           table.meta['name'], catalog_ident, ident)\n\n        row = table[0]\n        if isinstance (row['_RAJ2000'], ma_core.MaskedConstant):\n            raise PKError ('Vizier query returned flagged row in %s table; your AllWISE '\n                           'identifier likely does not exist (it should be of the form '\n                           '\"J112254.70+255021.9\"; catalog=%r AllWISE=%r)',\n                           table.meta['name'], catalog_ident, ident)\n\n        # OK, we can actually do this.\n\n        self.ra = row['RA_pm'] * D2R\n        self.dec = row['DE_pm'] * D2R\n\n        if row['e_RA_pm'] > row['e_DE_pm']:\n            self.pos_u_maj = row['e_RA_pm'] * A2R\n            self.pos_u_min = row['e_DE_pm'] * A2R\n            self.pos_u_pa = halfpi\n        else:\n            self.pos_u_maj = row['e_DE_pm'] * A2R\n            self.pos_u_min = row['e_RA_pm'] * A2R\n            self.pos_u_pa = 0\n\n        self.pos_epoch = 55400. # hardcoded in the catalog\n        self.promo_ra = row['pmRA']\n        self.promo_dec = row['pmDE']\n\n        if row['e_pmRA'] > row['e_pmDE']:\n            self.promo_u_maj = row['e_pmRA'] * 1.\n            self.promo_u_min = row['e_pmDE'] * 1.\n            self.promo_u_pa = halfpi\n        else:\n            self.promo_u_maj = row['e_pmDE'] * 1.\n            self.promo_u_min = row['e_pmRA'] * 1.\n            self.promo_u_pa = 0.\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsamples a 2D analytic function.", "response": "def analytic_2d (f, df, x0, y0,\n                 maxiters=5000,\n                 defeta=0.05,\n                 netastep=12,\n                 vtol1=1e-3,\n                 vtol2=1e-8,\n                 maxnewt=20,\n                 dorder=7,\n                 goright=False):\n    \"\"\"Sample a contour in a 2D analytic function. Arguments:\n\n    f\n      A function, mapping (x, y) -> z.\n    df\n      The partial derivative: df (x, y) -> [dz/dx, dz/dy]. If None,\n      the derivative of f is approximated numerically with\n      scipy.derivative.\n    x0\n      Initial x value. Should be of \"typical\" size for the problem;\n      avoid 0.\n    y0\n      Initial y value. Should be of \"typical\" size for the problem;\n      avoid 0.\n\n    Optional arguments:\n\n    maxiters\n      Maximum number of points to create. Default 5000.\n    defeta\n      Initially offset by distances of defeta*[df/dx, df/dy]\n      Default 0.05.\n    netastep\n      Number of steps between defeta and the machine resolution\n      in which we test eta values for goodness. (OMG FIXME doc).\n      Default 12.\n    vtol1\n      Tolerance for constancy in the value of the function in the\n      initial offset step. The value is only allowed to vary by\n      ``f(x0,y0) * vtol1``. Default 1e-3.\n    vtol2\n      Tolerance for constancy in the value of the function in the\n      along the contour. The value is only allowed to vary by\n      ``f(x0,y0) * vtol2``. Default 1e-8.\n    maxnewt\n      Maximum number of Newton's method steps to take when\n      attempting to hone in on the desired function value. Default 20.\n    dorder\n      Number of function evaluations to perform when evaluating\n      the derivative of f numerically. Must be an odd integer greater\n      than 1. Default 7.\n    goright\n      If True, trace the contour rightward (as looking uphill),\n      rather than leftward (the default).\n\n    \"\"\"\n    # Coerce argument types.\n\n    if not callable (f):\n        raise ValueError ('f')\n\n    if df is not None and not callable (df):\n        raise ValueError ('df')\n\n    x0 = float (x0)\n    if x0 == 0.:\n        raise ValueError ('x0')\n\n    y0 = float (y0)\n    if y0 == 0.:\n        raise ValueError ('y0')\n\n    maxiters = int (maxiters)\n    if maxiters < 3:\n        raise ValueError ('maxiters')\n\n    defeta = float (defeta)\n    if defeta <= 0:\n        raise ValueError ('defeta')\n\n    netastep = int (netastep)\n    if netastep < 2:\n        raise ValueError ('netastep')\n\n    vtol1 = float (vtol1)\n    if vtol1 <= 0:\n        raise ValueError ('vtol1')\n\n    vtol2 = float (vtol2)\n    if vtol2 >= vtol1:\n        raise ValueError ('vtol2')\n\n    maxnewt = int (maxnewt)\n    if maxnewt < 1:\n        raise ValueError ('maxnewt')\n\n    # What value are we contouring?\n    v = f (x0, y0)\n\n    # If no derivative is given, use a numerical approximation.\n\n    if df is None:\n        derivx = abs (x0 * 0.025)\n        derivy = abs (y0 * 0.025)\n        from scipy import derivative\n\n        if dorder == 2:\n            # simple derivative\n            def df (x1, y1):\n                z0 = f (x1, y1)\n                dx = max (abs (x1) * 1e-5, 1e-8)\n                dy = max (abs (y1) * 1e-5, 1e-8)\n                dzdx = (f (x1 + dx, y1) - z0) / dx\n                dzdy = (f (x1, y1 + dy) - z0) / dy\n                return [dzdx, dzdy]\n        else:\n            def df (x1, y1):\n                dx = derivative (lambda x: f (x, y1), x1, derivx, order=dorder)\n                dy = derivative (lambda y: f (x1, y), y1, derivy, order=dorder)\n                return [dx, dy]\n\n    # Init eta progression.\n    rez = np.finfo (np.double).resolution\n    if rez > defeta:\n        raise PKError ('defeta below resolution!')\n    eta_scale = np.exp ((np.log (rez) - np.log (defeta)) / netastep)\n\n    # Init data storage\n    n = 1\n    pts = np.empty ((maxiters, 2))\n    pts[0] = (x0, y0)\n    x = x0\n    y = y0\n\n    # Quitflag: 0 if first iteration\n    #           1 if inited but not yet ok to quit (definition of this below)\n    #           2 if ok to quit\n    # initquad: 0 if x > 0, y > 0\n    #           1 if x < 0, y > 0\n    #           2 if x < 0, y < 0\n    #           3 if x > 0, y < 0\n    # We invert these senses in the in-loop test to make comparison easy.\n\n    quitflag = 0\n    initquad = -1\n\n    # Start finding contours.\n\n    while n < maxiters:\n        dfdx, dfdy = df (x, y)\n\n        # If we're booting up, remember the quadrant that df/dx points in.\n        # Once we've rotated around to the other direction, it is safe to quit\n        # once we return close to the original point, since we must have\n        # completed a circle.\n\n        if quitflag == 0:\n            if dfdx > 0:\n                if dfdy > 0:\n                    initquad = 0\n                else:\n                    initquad = 3\n            else:\n                if dfdy > 0:\n                    initquad = 1\n                else:\n                    initquad = 2\n            quitflag = 1\n        elif quitflag == 1:\n            if dfdx > 0:\n                if dfdy > 0:\n                    curquad = 2\n                else:\n                    curquad = 1\n            else:\n                if dfdy > 0:\n                    curquad = 3\n                else:\n                    curquad = 0\n\n            if curquad == initquad:\n                quitflag = 2\n\n        # We will move perpendicular to [df/dx, df/dy], rotating to the left\n        # (arbitrarily) from that direction. We need to figure out how far we\n        # can safely move in this direction.\n\n        if goright:\n            dx = dfdy * defeta\n            dy = -dfdx * defeta\n        else:\n            dx = -dfdy * defeta\n            dy = dfdx * defeta\n\n        i = 0\n\n        while i < netastep:\n            nx = x + dx\n            ny = y + dy\n            nv = f (nx, ny)\n\n            # Is the value of the function sufficently close to what\n            # we're aiming for?\n            if abs (nv / v - 1) < vtol1:\n                break\n\n            # No. Try a smaller dx/dy.\n            dx *= eta_scale\n            dy *= eta_scale\n            i += 1\n        else:\n            # Failed to find a sufficiently small eta (did not break out of\n            # loop)\n            raise PKError ('failed to find sufficiently small eta: xy %g,%g; '\n                           'dv %g; df %g,%g; dxy %g,%g; defeta %g; eta_scale '\n                           '%g' % (x, y, nv - v, dfdx, dfdy, dx, dy, defeta,\n                                   eta_scale))\n\n        # Now compute a new [df/dx, df/dy], and move along it, finding our way\n        # back to the desired value, 'v'. Newton's method should suffice. This\n        # loop usually exits after one iteration.\n\n        i = 0\n\n        while i < maxnewt:\n            dfdx, dfdy = df (nx, ny)\n            df2 = dfdx**2 + dfdy**2\n            dv = nv - v\n\n            nx -= dv * dfdx / df2\n            ny -= dv * dfdy / df2\n            nv = f (nx, ny)\n\n            if abs (nv/v - 1) < vtol2:\n                break\n\n            i += 1\n        else:\n            # Did not break out of loop.\n            raise PKError ('failed to converge with Newton\\'s method')\n\n        # Ok, we found our next value.\n        pts[n] = (nx, ny)\n        x = nx\n        y = ny\n        n += 1\n\n        # Time to stop? Make sure we've gone at least a half-turn so that we\n        # don't just exit on the first iteration.\n        if quitflag == 2:\n            dist2 = (x/x0 - 1)**2 + (y/y0 - 1)**2\n            if dist2 < 3 * (dx**2 + dy**2):\n                break\n    else:\n        raise PKError ('needed too many points to close contour')\n\n    # Woohoo! All done.\n    return pts[:n]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake sure that the standard I/O streams accept Unicode. In Python 2, the standard I/O streams accept bytes, not Unicode characters. This means that in principle every Unicode string that we want to output should be encoded to utf-8 before print()ing. But Python 2.X has a hack where, if the output is a terminal, it will automatically encode your strings, using UTF-8 in most cases. BUT this hack doesn't kick in if you pipe your program's output to another program. So it's easy to write a tool that works fine in most cases but then blows up when you log its output to a file. The proper solution is just to do the encoding right. This function sets things up to do this in the most sensible way I can devise, if we're running on Python 2. This approach sets up compatibility with Python 3, which has the stdio streams be in text mode rather than bytes mode to begin with. Basically, every command-line Python program should call this right at startup. I'm tempted to just invoke this code whenever this module is imported since I foresee many accidentally omissions of the call.", "response": "def unicode_stdio ():\n    \"\"\"Make sure that the standard I/O streams accept Unicode.\n\n    In Python 2, the standard I/O streams accept bytes, not Unicode\n    characters. This means that in principle every Unicode string that we want\n    to output should be encoded to utf-8 before print()ing. But Python 2.X has\n    a hack where, if the output is a terminal, it will automatically encode\n    your strings, using UTF-8 in most cases.\n\n    BUT this hack doesn't kick in if you pipe your program's output to another\n    program. So it's easy to write a tool that works fine in most cases but then\n    blows up when you log its output to a file.\n\n    The proper solution is just to do the encoding right. This function sets\n    things up to do this in the most sensible way I can devise, if we're\n    running on Python 2. This approach sets up compatibility with Python 3,\n    which has the stdio streams be in text mode rather than bytes mode to\n    begin with.\n\n    Basically, every command-line Python program should call this right at\n    startup. I'm tempted to just invoke this code whenever this module is\n    imported since I foresee many accidentally omissions of the call.\n\n    \"\"\"\n    if six.PY3:\n        return\n\n    enc = sys.stdin.encoding or 'utf-8'\n    sys.stdin = codecs.getreader (enc) (sys.stdin)\n    enc = sys.stdout.encoding or enc\n    sys.stdout = codecs.getwriter (enc) (sys.stdout)\n    enc = sys.stderr.encoding or enc\n    sys.stderr = codecs.getwriter (enc) (sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninstall a signal handler that prints a Python traceback upon receipt of SIGUSR1.", "response": "def backtrace_on_usr1 ():\n    \"\"\"Install a signal handler such that this program prints a Python traceback\n    upon receipt of SIGUSR1. This could be useful for checking that\n    long-running programs are behaving properly, or for discovering where an\n    infinite loop is occurring.\n\n    Note, however, that the Python interpreter does not invoke Python signal\n    handlers exactly when the process is signaled. For instance, a signal\n    delivered in the midst of a time.sleep() call will only be seen by Python\n    code after that call completes. This means that this feature may not be as\n    helpful as one might like for debugging certain kinds of problems.\n\n    \"\"\"\n    import signal\n    try:\n        signal.signal (signal.SIGUSR1, _print_backtrace_signal_handler)\n    except Exception as e:\n        warn ('failed to set up Python backtraces on SIGUSR1: %s', e)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nraising a SystemExit exception with a formatted error message.", "response": "def die (fmt, *args):\n    \"\"\"Raise a :exc:`SystemExit` exception with a formatted error message.\n\n    :arg str fmt: a format string\n    :arg args: arguments to the format string\n\n    If *args* is empty, a :exc:`SystemExit` exception is raised with the\n    argument ``'error: ' + str (fmt)``. Otherwise, the string component is\n    ``fmt % args``. If uncaught, the interpreter exits with an error code and\n    prints the exception argument.\n\n    Example::\n\n       if ndim != 3:\n          die ('require exactly 3 dimensions, not %d', ndim)\n\n    \"\"\"\n    if not len (args):\n        raise SystemExit ('error: ' + text_type (fmt))\n    raise SystemExit ('error: ' + (fmt % args))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fork_detached_process ():\n    import os, struct\n    from .. import Holder\n    payload = struct.Struct ('L')\n\n    info = Holder ()\n    readfd, writefd = os.pipe ()\n\n    pid1 = os.fork ()\n    if pid1 > 0:\n        info.whoami = 'original'\n        info.pipe = os.fdopen (readfd, 'rb')\n        os.close (writefd)\n\n        retcode = os.waitpid (pid1, 0)[1]\n        if retcode:\n            raise Exception ('child process exited with error code %d' % retcode)\n\n        (info.forkedpid,) = payload.unpack (info.pipe.read (payload.size))\n    else:\n        # We're the intermediate child process. Start new session and process\n        # groups, detaching us from TTY signals and whatnot.\n        os.setsid ()\n\n        pid2 = os.fork ()\n        if pid2 > 0:\n            # We're the intermediate process; we're all done\n            os._exit (0)\n\n        # If we get here, we're the detached child process.\n        info.whoami = 'forked'\n        info.pipe = os.fdopen (writefd, 'wb')\n        os.close (readfd)\n        info.forkedpid = os.getpid ()\n        info.pipe.write (payload.pack (info.forkedpid))\n\n    return info", "response": "Fork this process creating a subprocess detached from the current context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef show_usage (docstring, short, stream, exitcode):\n    if stream is None:\n        from sys import stdout as stream\n\n    if not short:\n        print ('Usage:', docstring.strip (), file=stream)\n    else:\n        intext = False\n        for l in docstring.splitlines ():\n            if intext:\n                if not len (l):\n                    break\n                print (l, file=stream)\n            elif len (l):\n                intext = True\n                print ('Usage:', l, file=stream)\n\n        print ('\\nRun with a sole argument --help for more detailed '\n               'usage information.', file=stream)\n\n    raise SystemExit (exitcode)", "response": "Print program usage information and exit."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the program has been run with a help argument and if so print usage information and exit.", "response": "def check_usage (docstring, argv=None, usageifnoargs=False):\n    \"\"\"Check if the program has been run with a --help argument; if so,\n    print usage information and exit.\n\n    :arg str docstring: the program help text\n    :arg argv: the program arguments; taken as :data:`sys.argv` if\n        given as :const:`None` (the default). (Note that this implies\n        ``argv[0]`` should be the program name and not the first option.)\n    :arg bool usageifnoargs: if :const:`True`, usage information will be\n        printed and the program will exit if no command-line arguments are\n        passed. If \"long\", print long usasge. Default is :const:`False`.\n\n    This function is intended for small programs launched from the command\n    line. The intention is for the program help information to be written in\n    its docstring, and then for the preamble to contain something like::\n\n        \\\"\\\"\\\"myprogram - this is all the usage help you get\\\"\\\"\\\"\n        import sys\n        ... # other setup\n        check_usage (__doc__)\n        ... # go on with business\n\n    If it is determined that usage information should be shown,\n    :func:`show_usage` is called and the program exits.\n\n    See also :func:`wrong_usage`.\n\n    \"\"\"\n    if argv is None:\n        from sys import argv\n\n    if len (argv) == 1 and usageifnoargs:\n        show_usage (docstring, (usageifnoargs != 'long'), None, 0)\n    if len (argv) == 2 and argv[1] in ('-h', '--help'):\n        show_usage (docstring, False, None, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wrong_usage (docstring, *rest):\n    intext = False\n\n    if len (rest) == 0:\n        detail = 'invalid command-line arguments'\n    elif len (rest) == 1:\n        detail = rest[0]\n    else:\n        detail = rest[0] % tuple (rest[1:])\n\n    print ('error:', detail, '\\n', file=sys.stderr) # extra NL\n    show_usage (docstring, True, sys.stderr, 1)", "response": "Print a message indicating invalid command - line arguments and exit with an error code."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nhandling an uncaught exception.", "response": "def excepthook (self, etype, evalue, etb):\n        \"\"\"Handle an uncaught exception. We always forward the exception on to\n        whatever `sys.excepthook` was present upon setup. However, if the\n        exception is a KeyboardInterrupt, we additionally kill ourselves with\n        an uncaught SIGINT, so that invoking programs know what happened.\n\n        \"\"\"\n        self.inner_excepthook (etype, evalue, etb)\n\n        if issubclass (etype, KeyboardInterrupt):\n            # Don't try this at home, kids. On some systems os.kill (0, ...)\n            # signals our entire progress group, which is not what we want,\n            # so we use os.getpid ().\n            signal.signal (signal.SIGINT, signal.SIG_DFL)\n            os.kill (os.getpid (), signal.SIGINT)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_nu_b(b):\n    return cgs.e * b / (2 * cgs.pi * cgs.me * cgs.c)", "response": "Calculate the cyclotron frequency in Hz given a magnetic field strength in Gauss."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef calc_snu(eta, kappa, width, elongation, dist):\n    omega = (width / dist)**2\n    depth = width * elongation\n    tau = depth * kappa\n    sourcefn = eta / kappa\n    return 2 * omega * sourcefn * (1 - np.exp(-tau))", "response": "Calculate the flux density S_\u03bd given a simple physical configuration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate a flux density from pure free - free emission.", "response": "def calc_freefree_snu_ujy(ne, t, width, elongation, dist, ghz):\n    \"\"\"Calculate a flux density from pure free-free emission.\n\n    \"\"\"\n    hz = ghz * 1e9\n    eta = calc_freefree_eta(ne, t, hz)\n    kappa = calc_freefree_kappa(ne, t, hz)\n    snu = calc_snu(eta, kappa, width, elongation, dist)\n    ujy = snu * cgs.jypercgs * 1e6\n    return ujy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calc_gs_eta(b, ne, delta, sinth, nu):\n    s = nu / calc_nu_b(b)\n    return (b * ne *\n            3.3e-24 *\n            10**(-0.52 * delta) *\n            sinth**(-0.43 + 0.65 * delta) *\n            s**(1.22 - 0.90 * delta))", "response": "Calculates the gyrosynchrotron emission coefficient \u03b7_\u03bd."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate the gyrosynchrotron absorption coefficient \u03ba_\u03bd.", "response": "def calc_gs_kappa(b, ne, delta, sinth, nu):\n    \"\"\"Calculate the gyrosynchrotron absorption coefficient \u03ba_\u03bd.\n\n    This is Dulk (1985) equation 36, which is a fitting function assuming a\n    power-law electron population. Arguments are:\n\n    b\n      Magnetic field strength in Gauss\n    ne\n      The density of electrons per cubic centimeter with energies greater than 10 keV.\n    delta\n      The power-law index defining the energy distribution of the electron population,\n      with ``n(E) ~ E^(-delta)``. The equation is valid for ``2 <~ delta <~ 7``.\n    sinth\n      The sine of the angle between the line of sight and the magnetic field direction.\n      The equation is valid for \u03b8 > 20\u00b0 or ``sinth > 0.34`` or so.\n    nu\n      The frequency at which to calculate \u03b7, in Hz. The equation is valid for\n      ``10 <~ nu/nu_b <~ 100``, which sets a limit on the ratio of ``nu`` and ``b``.\n\n    The return value is the absorption coefficient, in units of ``cm^-1``.\n\n    No complaints are raised if you attempt to use the equation outside of its\n    range of validity.\n\n    \"\"\"\n    s = nu / calc_nu_b(b)\n    return (ne / b *\n            1.4e-9 *\n            10**(-0.22 * delta) *\n            sinth**(-0.09 + 0.72 * delta) *\n            s**(-1.30 - 0.98 * delta))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_gs_nu_pk(b, ne, delta, sinth, depth):\n    coldens = ne * depth\n    return (2.72e3 *\n            10**(0.27 * delta) *\n            sinth**(0.41 + 0.03 * delta) *\n            coldens**(0.32 - 0.03 * delta) *\n            b**(0.68 + 0.03 * delta))", "response": "Calculates the frequency of peak synchrotron emission in Gauss - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov - Kolmogorov"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate a flux density from pure gyrosynchrotron emission.", "response": "def calc_gs_snu_ujy(b, ne, delta, sinth, width, elongation, dist, ghz):\n    \"\"\"Calculate a flux density from pure gyrosynchrotron emission.\n\n    This combines Dulk (1985) equations 35 and 36, which are fitting functions\n    assuming a power-law electron population, with standard radiative transfer\n    through a uniform medium. Arguments are:\n\n    b\n      Magnetic field strength in Gauss\n    ne\n      The density of electrons per cubic centimeter with energies greater than 10 keV.\n    delta\n      The power-law index defining the energy distribution of the electron population,\n      with ``n(E) ~ E^(-delta)``. The equation is valid for ``2 <~ delta <~ 7``.\n    sinth\n      The sine of the angle between the line of sight and the magnetic field direction.\n      The equation is valid for \u03b8 > 20\u00b0 or ``sinth > 0.34`` or so.\n    width\n      The characteristic cross-sectional width of the emitting region, in cm.\n    elongation\n      The the elongation of the emitting region; ``depth = width * elongation``.\n    dist\n      The distance to the emitting region, in cm.\n    ghz\n      The frequencies at which to evaluate the spectrum, **in GHz**.\n\n    The return value is the flux density **in \u03bcJy**. The arguments can be\n    Numpy arrays.\n\n    No complaints are raised if you attempt to use the equations outside of\n    their range of validity.\n\n    \"\"\"\n    hz = ghz * 1e9\n    eta = calc_gs_eta(b, ne, delta, sinth, hz)\n    kappa = calc_gs_kappa(b, ne, delta, sinth, hz)\n    snu = calc_snu(eta, kappa, width, elongation, dist)\n    ujy = snu * cgs.jypercgs * 1e6\n    return ujy"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the relativistic synchrotron emission coefficient \u03b7_\u03bd.", "response": "def calc_synch_eta(b, ne, delta, sinth, nu, E0=1.):\n    \"\"\"Calculate the relativistic synchrotron emission coefficient \u03b7_\u03bd.\n\n    This is Dulk (1985) equation 40, which is an approximation assuming a\n    power-law electron population. Arguments are:\n\n    b\n      Magnetic field strength in Gauss\n    ne\n      The density of electrons per cubic centimeter with energies greater than E0.\n    delta\n      The power-law index defining the energy distribution of the electron population,\n      with ``n(E) ~ E^(-delta)``. The equation is valid for ``2 <~ delta <~ 5``.\n    sinth\n      The sine of the angle between the line of sight and the magnetic field direction.\n      It's not specified for what range of values the expressions work well.\n    nu\n      The frequency at which to calculate \u03b7, in Hz. The equation is valid for\n      It's not specified for what range of values the expressions work well.\n    E0\n      The minimum energy of electrons to consider, in MeV. Defaults to 1 so that\n      these functions can be called identically to the gyrosynchrotron functions.\n\n    The return value is the emission coefficient (AKA \"emissivity\"), in units\n    of ``erg s^-1 Hz^-1 cm^-3 sr^-1``.\n\n    No complaints are raised if you attempt to use the equation outside of its\n    range of validity.\n\n    \"\"\"\n    s = nu / calc_nu_b(b)\n    return (b * ne *\n            8.6e-24 * (delta - 1) * sinth *\n            (0.175 * s / (E0**2 * sinth))**(0.5 * (1 - delta)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the frequency of peak synchrotron emission in a Gauss - based model.", "response": "def calc_synch_nu_pk(b, ne, delta, sinth, depth, E0=1.):\n    \"\"\"Calculate the frequency of peak synchrotron emission, \u03bd_pk.\n\n    This is Dulk (1985) equation 43, which is a fitting function assuming a\n    power-law electron population. Arguments are:\n\n    b\n      Magnetic field strength in Gauss\n    ne\n      The density of electrons per cubic centimeter with energies greater than 10 keV.\n    delta\n      The power-law index defining the energy distribution of the electron population,\n      with ``n(E) ~ E^(-delta)``. The equation is valid for ``2 <~ delta <~ 5``.\n    sinth\n      The sine of the angle between the line of sight and the magnetic field direction.\n      It's not specified for what range of values the expressions work well.\n    depth\n      The path length through the emitting medium, in cm.\n    E0\n      The minimum energy of electrons to consider, in MeV. Defaults to 1 so that\n      these functions can be called identically to the gyrosynchrotron functions.\n\n    The return value is peak frequency in Hz.\n\n    No complaints are raised if you attempt to use the equation outside of its\n    range of validity.\n\n    \"\"\"\n    coldens = ne * depth\n    return (3.2e7 * sinth *\n            E0**((2 * delta - 2) / (delta + 4)) *\n            (8.7e-12 * (delta - 1) * coldens / sinth)**(2./(delta + 4)) *\n            b**((delta + 2) / (delta + 4)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calc_synch_snu_ujy(b, ne, delta, sinth, width, elongation, dist, ghz, E0=1.):\n    hz = ghz * 1e9\n    eta = calc_synch_eta(b, ne, delta, sinth, hz, E0=E0)\n    kappa = calc_synch_kappa(b, ne, delta, sinth, hz, E0=E0)\n    snu = calc_snu(eta, kappa, width, elongation, dist)\n    ujy = snu * cgs.jypercgs * 1e6\n    return ujy", "response": "Calculates a flux density from pure gyrosynchrotron emission."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clearcal(vis, weightonly=False):\n    tb = util.tools.table()\n    cb = util.tools.calibrater()\n\n    # cb.open() will create the tables if they're not present, so\n    # if that's the case, we don't actually need to run initcalset()\n\n    tb.open(b(vis), nomodify=False)\n    colnames = tb.colnames()\n    needinit = ('MODEL_DATA' in colnames) or('CORRECTED_DATA' in colnames)\n    if 'IMAGING_WEIGHT' not in colnames:\n        c = dict(clearcal_imaging_col_tmpl)\n        c['shape'] = tb.getcell(b'DATA', 0).shape[-1:]\n        tb.addcols({b'IMAGING_WEIGHT': c}, clearcal_imaging_dminfo_tmpl)\n    tb.close()\n\n    if not weightonly:\n        import casadef\n\n        if casadef.casa_version.startswith('5.'):\n            cb.setvi(old=True, quiet=False)\n\n        cb.open(b(vis))\n        if needinit:\n            cb.initcalset()\n        cb.close()", "response": "Fill the imaging and calibration columns of each measurement set with default values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconcatenate the input measurement sets and the output measurement sets.", "response": "def concat(invises, outvis, timesort=False):\n    \"\"\"Concatenate visibility measurement sets.\n\n    invises (list of str)\n      Paths to the input measurement sets\n    outvis (str)\n      Path to the output measurement set.\n    timesort (boolean)\n      If true, sort the output in time after concatenation.\n\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.concat(['epoch1.ms', 'epoch2.ms'], 'combined.ms')\n\n    \"\"\"\n    tb = util.tools.table()\n    ms = util.tools.ms()\n\n    if os.path.exists(outvis):\n        raise RuntimeError('output \"%s\" already exists' % outvis)\n\n    for invis in invises:\n        if not os.path.isdir(invis):\n            raise RuntimeError('input \"%s\" does not exist' % invis)\n\n    tb.open(b(invises[0]))\n    tb.copy(b(outvis), deep=True, valuecopy=True)\n    tb.close()\n\n    ms.open(b(outvis), nomodify=False)\n\n    for invis in invises[1:]:\n        ms.concatenate(msfile=b(invis), freqtol=b(concat_freqtol),\n                        dirtol=b(concat_dirtol))\n\n    ms.writehistory(message=b'taskname=tasklib.concat', origin=b'tasklib.concat')\n    ms.writehistory(message=b('vis = ' + ', '.join(invises)), origin=b'tasklib.concat')\n    ms.writehistory(message=b('timesort = ' + 'FT'[int(timesort)]), origin=b'tasklib.concat')\n\n    if timesort:\n        ms.timesort()\n\n    ms.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete the MODEL_DATA and CORRECTED_DATA columns from a measurement set.", "response": "def delcal(mspath):\n    \"\"\"Delete the ``MODEL_DATA`` and ``CORRECTED_DATA`` columns from a measurement set.\n\n    mspath (str)\n      The path to the MS to modify\n\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.delcal('dataset.ms')\n\n    \"\"\"\n    wantremove = 'MODEL_DATA CORRECTED_DATA'.split()\n    tb = util.tools.table()\n    tb.open(b(mspath), nomodify=False)\n    cols = frozenset(tb.colnames())\n    toremove = [b(c) for c in wantremove if c in cols]\n    if len(toremove):\n        tb.removecols(toremove)\n    tb.close()\n\n    # We want to return a `str` type, which is what we already\n    # have in Python 2 but not in 3.\n    if six.PY2:\n        return toremove\n    else:\n        return [c.decode('utf8') for c in toremove]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract the flags from a bandpass calibration table and write them to a stream - like object deststream", "response": "def extractbpflags(calpath, deststream):\n    \"\"\"Make a flags file out of a bandpass calibration table\n\n    calpath (str)\n      The path to the bandpass calibration table\n    deststream (stream-like object, e.g. an opened file)\n      Where to write the flags data\n\n    Below is documentation written for the command-line interface to this\n    functionality:\n\n    \"\"\"\n    tb = util.tools.table()\n    tb.open(b(os.path.join(calpath, 'ANTENNA')))\n    antnames = tb.getcol(b'NAME')\n    tb.close()\n\n    tb.open(b(calpath))\n    try:\n        t = tb.getkeyword(b'VisCal')\n    except RuntimeError:\n        raise PKError('no \"VisCal\" keyword in %s; it doesn\\'t seem to be a '\n                       'bandpass calibration table', calpath)\n\n    if t != 'B Jones':\n        raise PKError('table %s doesn\\'t seem to be a bandpass calibration '\n                       'table; its type is \"%s\"', calpath, t)\n\n    def emit(antidx, spwidx, chanstart, chanend):\n        # Channel ranges are inclusive, unlike Python syntax.\n        print(\"antenna='%s&*' spw='%d:%d~%d' reason='BANDPASS_FLAGGED'\" % \\\n              (antnames[antidx], spwidx, chanstart, chanend), file=deststream)\n\n    for row in range(tb.nrows()):\n        ant = tb.getcell(b'ANTENNA1', row)\n        spw = tb.getcell(b'SPECTRAL_WINDOW_ID', row)\n        flag = tb.getcell(b'FLAG', row)\n\n        # This is the logical 'or' of the two polarizations: i.e., anything that\n        # is flagged in either poln is flagged in this.\n        sqflag = ~((~flag).prod(axis=0, dtype=np.bool))\n\n        runstart = None\n\n        for i in range(sqflag.size):\n            if sqflag[i]:\n                # This channel is flagged. Start a run if not already in one.\n                if runstart is None:\n                    runstart = i\n            elif runstart is not None:\n                # The current run just ended.\n                emit(ant, spw, runstart, i - 1)\n                runstart = None\n\n        if runstart is not None:\n            emit(ant, spw, runstart, i)\n\n    tb.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef flagmanager_cli(argv, alter_logger=True):\n    check_usage(flagmanager_doc, argv, usageifnoargs=True)\n\n    if len(argv) < 3:\n        wrong_usage(flagmanager_doc, 'expect at least a mode and an MS name')\n\n    mode = argv[1]\n    ms = argv[2]\n\n    if alter_logger:\n        if mode == 'list':\n            util.logger('info')\n        elif mode == 'delete':\n            # it WARNs 'deleting version xxx' ... yargh\n            util.logger('severe')\n        else:\n            util.logger()\n\n    try:\n        factory = util.tools.agentflagger\n    except AttributeError:\n        factory = util.tools.testflagger\n\n    af = factory()\n    af.open(b(ms))\n\n    if mode == 'list':\n        if len(argv) != 3:\n            wrong_usage(flagmanager_doc, 'expect exactly one argument in list mode')\n        af.getflagversionlist()\n    elif mode == 'save':\n        if len(argv) != 4:\n            wrong_usage(flagmanager_doc, 'expect exactly two arguments in save mode')\n        from time import strftime\n        name = argv[3]\n        af.saveflagversion(versionname=b(name), merge=b'replace',\n                            comment=b('created %s(casatask flagmanager)'\n                                      % strftime('%Y-%m-%dT%H:%M:%SZ')))\n    elif mode == 'restore':\n        if len(argv) != 4:\n            wrong_usage(flagmanager_doc, 'expect exactly two arguments in restore mode')\n        name = argv[3]\n        af.restoreflagversion(versionname=b(name), merge=b'replace')\n    elif mode == 'delete':\n        if len(argv) != 4:\n            wrong_usage(flagmanager_doc, 'expect exactly two arguments in delete mode')\n        name = argv[3]\n\n        if not os.path.isdir(os.path.join(ms + '.flagversions', 'flags.' + name)):\n            # This condition only results in a WARN from deleteflagversion()!\n            raise RuntimeError('version \"%s\" doesn\\'t exist in \"%s.flagversions\"'\n                                % (name, ms))\n\n        af.deleteflagversion(versionname=b(name))\n    else:\n        wrong_usage(flagmanager_doc, 'unknown flagmanager mode \"%s\"' % mode)\n\n    af.done()", "response": "Command - line access to flagmanager."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an image in MS format to FITS format.", "response": "def image2fits(mspath, fitspath, velocity=False, optical=False, bitpix=-32,\n                minpix=0, maxpix=-1, overwrite=False, dropstokes=False, stokeslast=True,\n                history=True, **kwargs):\n    \"\"\"Convert an image in MS format to FITS format.\n\n    mspath (str)\n      The path to the input MS.\n    fitspath (str)\n      The path to the output FITS file.\n    velocity (boolean)\n      (To be documented.)\n    optical (boolean)\n      (To be documented.)\n    bitpix (integer)\n      (To be documented.)\n    minpix (integer)\n      (To be documented.)\n    maxpix (integer)\n      (To be documented.)\n    overwrite (boolean)\n      Whether the task is allowed to overwrite an existing destination file.\n    dropstokes (boolean)\n      Whether the \"Stokes\" (polarization) axis of the image should be dropped.\n    stokeslast (boolean)\n      Whether the \"Stokes\" (polarization) axis of the image should be placed as the last\n      (innermost?) axis of the image cube.\n    history (boolean)\n      (To be documented.)\n    ``**kwargs``\n      Forwarded on to the ``tofits`` function of the CASA ``image`` tool.\n\n    \"\"\"\n    ia = util.tools.image()\n    ia.open(b(mspath))\n    ia.tofits(outfile=b(fitspath), velocity=velocity, optical=optical, bitpix=bitpix,\n               minpix=minpix, maxpix=maxpix, overwrite=overwrite, dropstokes=dropstokes,\n               stokeslast=stokeslast, history=history, **kwargs)\n    ia.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert an ALMA low - level ASDM dataset to Measurement Set format.", "response": "def importalma(asdm, ms):\n    \"\"\"Convert an ALMA low-level ASDM dataset to Measurement Set format.\n\n    asdm (str)\n      The path to the input ASDM dataset.\n    ms (str)\n      The path to the output MS dataset.\n\n    This implementation automatically infers the value of the \"tbuff\"\n    parameter.\n\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.importalma('myalma.asdm', 'myalma.ms')\n\n    \"\"\"\n    from .scripting import CasapyScript\n\n    script = os.path.join(os.path.dirname(__file__), 'cscript_importalma.py')\n    with CasapyScript(script, asdm=asdm, ms=ms) as cs:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert an EVLA low - level SDM dataset to Measurement Set format.", "response": "def importevla(asdm, ms):\n    \"\"\"Convert an EVLA low-level SDM dataset to Measurement Set format.\n\n    asdm (str)\n      The path to the input ASDM dataset.\n    ms (str)\n      The path to the output MS dataset.\n\n    This implementation automatically infers the value of the \"tbuff\"\n    parameter.\n\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.importevla('myvla.sdm', 'myvla.ms')\n\n    \"\"\"\n    from .scripting import CasapyScript\n\n    # Here's the best way I can figure to find the recommended value of tbuff\n    #(= 1.5 * integration time). Obviously you might have different\n    # integration times in the dataset and such, and we're just going to\n    # ignore that possibility.\n\n    bdfstem = os.listdir(os.path.join(asdm, 'ASDMBinary'))[0]\n    bdf = os.path.join(asdm, 'ASDMBinary', bdfstem)\n    tbuff = None\n\n    with open(bdf, 'rb') as f:\n        for linenum, line in enumerate(f):\n            if linenum > 60:\n                raise PKError('cannot find integration time info in %s', bdf)\n\n            if not line.startswith(b'<sdmDataSubsetHeader'):\n                continue\n\n            try:\n                i1 = line.index(b'<interval>') + len(b'<interval>')\n                i2 = line.index(b'</interval>')\n                if i2 <= i1:\n                    raise ValueError()\n            except ValueError:\n                raise PKError('cannot parse integration time info in %s', bdf)\n\n            tbuff = float(line[i1:i2]) * 1.5e-9 # nanosecs, and want 1.5x\n            break\n\n    if tbuff is None:\n        raise PKError('found no integration time info')\n\n    print('importevla: %s -> %s with tbuff=%.2f' % (asdm, ms, tbuff))\n\n    script = os.path.join(os.path.dirname(__file__), 'cscript_importevla.py')\n    with CasapyScript(script, asdm=asdm, ms=ms, tbuff=tbuff) as cs:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a standard listsdm listing of A dataset contents.", "response": "def listsdm(sdm, file=None):\n    \"\"\"Generate a standard \"listsdm\" listing of(A)SDM dataset contents.\n\n    sdm (str)\n      The path to the (A)SDM dataset to parse\n    file (stream-like object, such as an opened file)\n      Where to print the human-readable listing. If unspecified, results\n      go to :data:`sys.stdout`.\n    Returns\n      A dictionary of information about the dataset. Contents not yet\n      documented.\n\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.listsdm('myalmaa.asdm')\n\n    This code based on CASA's `task_listsdm.py`, with this version info::\n\n      # v1.0: 2010.12.07, M. Krauss\n      # v1.1: 2011.02.23, M. Krauss: added functionality for ALMA data\n      #\n      # Original code based on readscans.py, courtesy S. Meyers\n\n    \"\"\"\n    from xml.dom import minidom\n    import string\n\n    def printf(fmt, *args):\n        if len(args):\n            s = fmt % args\n        else:\n            s = str(fmt)\n        print(s, file=file)\n\n    qa = util.tools.quanta()\n    me = util.tools.measures()\n\n    list_scans = True\n    list_antennas = False\n    list_fields = True\n    list_spws = False\n\n    # read Scan.xml\n    xmlscans = minidom.parse(sdm+'/Scan.xml')\n    scandict = {}\n    startTimeShort = []\n    endTimeShort = []\n    rowlist = xmlscans.getElementsByTagName('row')\n    for rownode in rowlist:\n        rowfid = rownode.getElementsByTagName('scanNumber')\n        fid = int(rowfid[0].childNodes[0].nodeValue)\n        scandict[fid] = {}\n\n        # number of subscans\n        rowsubs = rownode.getElementsByTagName('numSubscan')\n        if len(rowsubs) == 0:\n            # EVLA and old ALMA data\n            rowsubs = rownode.getElementsByTagName('numSubScan')\n        nsubs = int(rowsubs[0].childNodes[0].nodeValue)\n\n        # intents\n        rownint = rownode.getElementsByTagName('numIntent')\n        nint = int(rownint[0].childNodes[0].nodeValue)\n\n        rowintents = rownode.getElementsByTagName('scanIntent')\n        sint = str(rowintents[0].childNodes[0].nodeValue)\n        sints = sint.split()\n        rint = ''\n        for r in range(nint):\n            intent = sints[2+r]\n            if rint=='':\n                rint = intent\n            else:\n                rint += ' '+intent\n\n        # start and end times in mjd ns\n        rowstart = rownode.getElementsByTagName('startTime')\n        start = int(rowstart[0].childNodes[0].nodeValue)\n        startmjd = float(start)*1.0E-9/86400.0\n        t = b(qa.quantity(startmjd,b'd'))\n        starttime = qa.time(t,form=b'ymd',prec=8)[0]\n        startTimeShort.append(qa.time(t,prec=8)[0])\n        rowend = rownode.getElementsByTagName('endTime')\n        end = int(rowend[0].childNodes[0].nodeValue)\n        endmjd = float(end)*1.0E-9/86400.0\n        t = b(qa.quantity(endmjd,b'd'))\n        endtime = qa.time(t,form=b'ymd',prec=8)[0]\n        endTimeShort.append(qa.time(t,prec=8)[0])\n\n        # source name\n        rowsrc = rownode.getElementsByTagName('sourceName')\n        try:\n            src = str(rowsrc[0].childNodes[0].nodeValue)\n        except:\n            src = '???' # PKGW\n\n        scandict[fid]['start'] = starttime\n        scandict[fid]['end'] = endtime\n        timestr = starttime+'~'+endtime\n        scandict[fid]['timerange'] = timestr\n        scandict[fid]['source'] = src\n        scandict[fid]['intent'] = rint\n        scandict[fid]['nsubs'] = nsubs\n\n    # read Main.xml\n    xmlmain = minidom.parse(sdm+'/Main.xml')\n    rowlist = xmlmain.getElementsByTagName('row')\n    mainScanList = []\n    mainConfigList = []\n    fieldIdList = []\n    for rownode in rowlist:\n\n        # get the scan numbers\n        rowfid = rownode.getElementsByTagName('scanNumber')\n        fid = int(rowfid[0].childNodes[0].nodeValue)\n        mainScanList.append(fid)\n\n        # get the configuration description\n        rowconfig = rownode.getElementsByTagName('configDescriptionId')\n        config = str(rowconfig[0].childNodes[0].nodeValue)\n        mainConfigList.append(config)\n\n        # get the field ID\n        rowfieldid = rownode.getElementsByTagName('fieldId')\n        fieldid = string.split(str(rowfieldid[0].childNodes[0].nodeValue), '_')[1]\n        fieldIdList.append(fieldid)\n\n    # read ConfigDescription.xml to relate the configuration\n    # description to a(set) of data description IDs\n    xmlconfig = minidom.parse(sdm+'/ConfigDescription.xml')\n    rowlist = xmlconfig.getElementsByTagName('row')\n    configDescList = []\n    dataDescList = []\n    for rownode in rowlist:\n\n        # get the configuration description\n        rowConfigDesc = rownode.getElementsByTagName('configDescriptionId')\n        configDesc = str(rowConfigDesc[0].childNodes[0].nodeValue)\n        configDescList.append(configDesc)\n\n        # make a list of the data description IDs:\n        rowNumDataDesc = rownode.getElementsByTagName('numDataDescription')\n        numDataDesc = int(rowNumDataDesc[0].childNodes[0].nodeValue)\n\n        rowDataDesc = rownode.getElementsByTagName('dataDescriptionId')\n        dataDescStr = str(rowDataDesc[0].childNodes[0].nodeValue)\n        dataDescSplit = dataDescStr.split()\n        dataDesc = []\n        for i in range(numDataDesc):\n            dataDesc.append(dataDescSplit[i+2])\n        dataDescList.append(dataDesc)\n\n    # read DataDescription.xml to relate the data description IDs to\n    # spectral window IDs\n    xmlDataDesc = minidom.parse(sdm+'/DataDescription.xml')\n    rowlist = xmlDataDesc.getElementsByTagName('row')\n    dataDescElList = []\n    spwIdDataDescList = []\n    for rownode in rowlist:\n\n        # get the data description ID, make another list:\n        rowDataDescEl = rownode.getElementsByTagName('dataDescriptionId')\n        dataDescEl = str(rowDataDescEl[0].childNodes[0].nodeValue)\n        dataDescElList.append(dataDescEl)\n\n        # get the related spectral window ID:\n        rowSpwIdDataDesc = rownode.getElementsByTagName('spectralWindowId')\n        spwIdDataDesc = str(rowSpwIdDataDesc[0].childNodes[0].nodeValue)\n        spwIdDataDescList.append(spwIdDataDesc)\n\n    # read SpectralWindow.xml, get information about number of\n    # channels, reference frequency, baseband name, channel width.\n    # Interesting that there seem to be multiple fields that give the\n    # same information: chanFreqStart=reFreq,\n    # chanFreqStep=chanWidth=resolution.  Why?(Note: all units are Hz)\n    # Note: this is where the script breaks for ALMA data, since there\n    # are different tags in SpectraWindow.xml(for varying channel widths).\n    xmlSpecWin = minidom.parse(sdm+'/SpectralWindow.xml')\n    rowlist = xmlSpecWin.getElementsByTagName('row')\n    spwIdList = []\n    nChanList = []\n    refFreqList = []\n    chanWidthList = []\n    basebandList = []\n    for rownode in rowlist:\n\n        # get the various row values:\n        rowSpwId = rownode.getElementsByTagName('spectralWindowId')\n        rowNChan = rownode.getElementsByTagName('numChan')\n        rowRefFreq = rownode.getElementsByTagName('refFreq')\n        # For EVLA\n        rowChanWidth = rownode.getElementsByTagName('chanWidth')\n        # For ALMA\n        rowChanWidthArr = rownode.getElementsByTagName('chanWidthArray')\n        rowBaseband = rownode.getElementsByTagName('basebandName')\n\n        # convert to values or strings and append to the relevant lists:\n        spwId = str(rowSpwId[0].childNodes[0].nodeValue)\n        spwIdList.append(spwId)\n        nChan = int(rowNChan[0].childNodes[0].nodeValue)\n        nChanList.append(nChan)\n        refFreq = float(rowRefFreq[0].childNodes[0].nodeValue)\n        refFreqList.append(refFreq)\n        if rowChanWidth:\n            chanWidth = float(rowChanWidth[0].childNodes[0].nodeValue)\n            chanWidthList.append(chanWidth)\n        if rowChanWidthArr:\n            tmpArr = str(rowChanWidthArr[0].childNodes[0].nodeValue).split(' ')\n            tmpWidth = []\n            for cw in range(2, len(tmpArr)):\n                thisWidth = float(tmpArr[cw])\n                tmpWidth.append(thisWidth)\n            chanWidthList.append(tmpWidth)\n        baseband = str(rowBaseband[0].childNodes[0].nodeValue)\n        basebandList.append(baseband)\n\n    # read Field.xml\n    xmlField = minidom.parse(sdm+'/Field.xml')\n    rowlist = xmlField.getElementsByTagName('row')\n    fieldList = []\n    fieldNameList = []\n    fieldCodeList = []\n    fieldRAList = []\n    fieldDecList = []\n    fieldSrcIDList = []\n    for rownode in rowlist:\n        rowField = rownode.getElementsByTagName('fieldId')\n        rowName = rownode.getElementsByTagName('fieldName')\n        rowCode = rownode.getElementsByTagName('code')\n        rowCoords = rownode.getElementsByTagName('referenceDir')\n        rowSrcId = rownode.getElementsByTagName('sourceId')\n\n        # convert to values or strings and append to relevent lists:\n        fieldList.append(int(string.split(str(rowField[0].childNodes[0].nodeValue),'_')[1]))\n        fieldNameList.append(str(rowName[0].childNodes[0].nodeValue))\n        fieldCodeList.append(str(rowCode[0].childNodes[0].nodeValue))\n        coordInfo = rowCoords[0].childNodes[0].nodeValue.split()\n        RADeg = float(coordInfo[3])* (180.0/np.pi)\n        DecDeg = float(coordInfo[4])* (180.0/np.pi)\n        RAInp = {'unit': 'deg', 'value': RADeg}\n        DecInp = {'unit': 'deg', 'value': DecDeg}\n        RAHMS = b(qa.formxxx(b(RAInp), format=b'hms'))\n        DecDMS = b(qa.formxxx(b(DecInp), format=b'dms'))\n        fieldRAList.append(RAHMS)\n        fieldDecList.append(DecDMS)\n        fieldSrcIDList.append(int(rowSrcId[0].childNodes[0].nodeValue))\n\n    # read Antenna.xml\n    xmlAnt = minidom.parse(sdm+'/Antenna.xml')\n    rowlist = xmlAnt.getElementsByTagName('row')\n    antList = []\n    antNameList = []\n    dishDiamList = []\n    stationList = []\n    for rownode in rowlist:\n        rowAnt = rownode.getElementsByTagName('antennaId')\n        rowAntName = rownode.getElementsByTagName('name')\n        rowDishDiam = rownode.getElementsByTagName('dishDiameter')\n        rowStation = rownode.getElementsByTagName('stationId')\n\n        # convert and append\n        antList.append(int(string.split(str(rowAnt[0].childNodes[0].nodeValue), '_')[1]))\n        antNameList.append(str(rowAntName[0].childNodes[0].nodeValue))\n        dishDiamList.append(float(rowDishDiam[0].childNodes[0].nodeValue))\n        stationList.append(str(rowStation[0].childNodes[0].nodeValue))\n\n    # read Station.xml\n    xmlStation = minidom.parse(sdm+'/Station.xml')\n    rowlist = xmlStation.getElementsByTagName('row')\n    statIdList = []\n    statNameList = []\n    statLatList = []\n    statLonList = []\n    for rownode in rowlist:\n        rowStatId = rownode.getElementsByTagName('stationId')\n        rowStatName = rownode.getElementsByTagName('name')\n        rowStatPos = rownode.getElementsByTagName('position')\n\n        # convert and append\n        statIdList.append(str(rowStatId[0].childNodes[0].nodeValue))\n        statNameList.append(str(rowStatName[0].childNodes[0].nodeValue))\n        posInfo = string.split(str(rowStatPos[0].childNodes[0].nodeValue))\n        x = b(qa.quantity([float(posInfo[2])], b'm'))\n        y = b(qa.quantity([float(posInfo[3])], b'm'))\n        z = b(qa.quantity([float(posInfo[4])], b'm'))\n        pos = b(me.position(b'ITRF', x, y, z))\n        qLon = pos['m0']\n        qLat = pos['m1']\n        statLatList.append(qa.formxxx(qLat, b'dms', prec=0))\n        statLonList.append(qa.formxxx(qLon, b'dms', prec=0))\n\n    # associate antennas with stations:\n    assocStatList = []\n    for station in stationList:\n        i = np.where(np.array(statIdList) == station)[0][0]\n        assocStatList.append(statNameList[i])\n\n    # read ExecBlock.xml\n    xmlExecBlock = minidom.parse(sdm+'/ExecBlock.xml')\n    rowlist = xmlExecBlock.getElementsByTagName('row')\n    sTime = float(rowlist[0].getElementsByTagName('startTime')[0].childNodes[0].nodeValue)*1.0E-9\n    eTime = float(rowlist[0].getElementsByTagName('endTime')[0].childNodes[0].nodeValue)*1.0E-9\n    # integration time in seconds, start and end times:\n    intTime = eTime - sTime\n    t = b(qa.quantity(sTime/86400.0, b'd'))\n    obsStart = qa.time(t, form=b'ymd', prec=8)[0]\n    t = b(qa.quantity(eTime/86400.0, b'd'))\n    obsEnd = qa.time(t, form=b'ymd', prec=8)[0]\n    # observer name and obs. info:\n    observerName = str(rowlist[0].getElementsByTagName('observerName')[0].childNodes[0].nodeValue)\n    configName = str(rowlist[0].getElementsByTagName('configName')[0].childNodes[0].nodeValue)\n    telescopeName = str(rowlist[0].getElementsByTagName('telescopeName')[0].childNodes[0].nodeValue)\n    numAntenna = int(rowlist[0].getElementsByTagName('numAntenna')[0].childNodes[0].nodeValue)\n\n    # make lists like the dataDescList for spectral windows & related info:\n    spwOrd = []\n    nChanOrd = []\n    rFreqOrd = []\n    cWidthOrd = []\n    bbandOrd = []\n    for i in range(0, len(configDescList)):\n        spwTempList = []\n        nChanTempList = []\n        rFreqTempList = []\n        cWidthTempList = []\n        bbandTempList = []\n\n        for dDesc in dataDescList[i]:\n            el = np.where(np.array(dataDescElList) == dDesc)[0][0]\n            spwIdN = spwIdDataDescList[el]\n            spwEl = np.where(np.array(spwIdList) == spwIdN)[0][0]\n            spwTempList.append(int(string.split(spwIdList[spwEl], '_')[1]))\n            nChanTempList.append(nChanList[spwEl])\n            rFreqTempList.append(refFreqList[spwEl])\n            cWidthTempList.append(chanWidthList[spwEl])\n            bbandTempList.append(basebandList[spwEl])\n        spwOrd.append(spwTempList)\n        nChanOrd.append(nChanTempList)\n        rFreqOrd.append(rFreqTempList)\n        cWidthOrd.append(cWidthTempList)\n        bbandOrd.append(bbandTempList)\n\n    # add this info to the scan dictionary:\n    for scanNum in scandict:\n        spwOrdList = []\n        nChanOrdList = []\n        rFreqOrdList = []\n        cWidthOrdList = []\n        bbandOrdList = []\n        # scanEl could have multiple elements if subscans are present,\n        # or for ALMA data:\n        scanEl = np.where(np.array(mainScanList) == scanNum)[0]\n        for thisEl in scanEl:\n            configEl = mainConfigList[thisEl]\n            listEl = np.where(np.array(configDescList) == configEl)[0][0]\n            spwOrdList.append(spwOrd[listEl])\n            nChanOrdList.append(nChanOrd[listEl])\n            rFreqOrdList.append(rFreqOrd[listEl])\n            cWidthOrdList.append(cWidthOrd[listEl])\n            bbandOrdList.append(bbandOrd[listEl])\n        try:\n            scandict[scanNum]['field'] = int(fieldIdList[scanEl[0]])\n        except:\n            scandict[scanNum]['field'] = -1 # PKGW\n        scandict[scanNum]['spws'] = spwOrdList\n        scandict[scanNum]['nchan'] = nChanOrdList\n        scandict[scanNum]['reffreq'] = rFreqOrdList\n        scandict[scanNum]['chanwidth'] = cWidthOrdList\n        scandict[scanNum]['baseband'] = bbandOrdList\n\n    # report information to the logger\n    printf('================================================================================')\n    printf('   SDM File: %s', sdm)\n    printf('================================================================================')\n    printf('   Observer: %s', observerName)\n    printf('   Facility: %s, %s-configuration', telescopeName, configName)\n    printf('      Observed from %s to %s(UTC)', obsStart, obsEnd)\n    printf('      Total integration time = %.2f seconds(%.2f hours)', intTime, intTime / 3600)\n\n    if list_scans:\n        printf(' ')\n        printf('Scan listing:')\n\n        maxspwlen = 0\n\n        for scaninfo in scandict.values():\n            SPWs = []\n            for spw in scaninfo['spws']:\n                SPWs += spw\n\n            scaninfo['spwstr'] = str(list(set(SPWs)))\n            maxspwlen = max(maxspwlen, len(scaninfo['spwstr']))\n\n        fmt = '  %-25s  %-4s %-5s %-15s %-*s %s'\n        printf(fmt, 'Timerange(UTC)', 'Scan', 'FldID', 'FieldName', maxspwlen, 'SpwIDs', 'Intent(s)')\n\n        for i,(scanid, scaninfo) in enumerate(scandict.items()):\n            printf(fmt, startTimeShort[i] + ' - ' + endTimeShort[i], scanid,\n                    scaninfo['field'], scaninfo['source'], maxspwlen,\n                    scaninfo['spwstr'], scaninfo['intent'])\n\n    if list_spws:\n        printf(' ')\n        printf('Spectral window information:')\n        printf('  SpwID  #Chans  Ch0(MHz)  ChWidth(kHz) TotBW(MHz)  Baseband')\n\n        for i in range(0, len(spwIdList)):\n            printf(' %s %s %s %s %s %s', string.split(spwIdList[i],\n                                                       '_')[1].ljust(4), str(nChanList[i]).ljust(4),\n                    str(refFreqList[i]/1e6).ljust(8),\n                    str(np.array(chanWidthList[i])/1e3).ljust(8),\n                    str(np.array(chanWidthList[i])*nChanList[i]/1e6).ljust(8),\n                    basebandList[i].ljust(8))\n\n    if list_fields:\n        printf(' ')\n        printf('Field information:')\n        printf('  FldID  Code   Name            RA            Dec             SrcID')\n\n        for i in range(0, len(fieldList)):\n            printf('  %-6d %-6s %-15s %-13s %-15s %-5d', fieldList[i], fieldCodeList[i],\n                    fieldNameList[i], fieldRAList[i], fieldDecList[i],\n                    fieldSrcIDList[i])\n\n    if list_antennas:\n        printf(' ')\n        printf('Antennas(%i):' % len(antList))\n        printf('  ID    Name   Station   Diam.(m)  Lat.          Long.')\n\n        for i in range(0, len(antList)):\n            printf(' %s %s %s %s %s %s ', str(antList[i]).ljust(5),\n                    antNameList[i].ljust(6), assocStatList[i].ljust(5),\n                    str(dishDiamList[i]).ljust(5), statLatList[i].ljust(12),\n                    statLonList[i].ljust(12))\n\n    # return the scan dictionary\n    return scandict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert an MJD value to a date string in the format used by CASA.", "response": "def mjd2date(mjd, precision=3):\n    \"\"\"Convert an MJD to a data string in the format used by CASA.\n\n    mjd (numeric)\n      An MJD value in the UTC timescale.\n    precision (integer, default 3)\n      The number of digits of decimal precision in the seconds portion of\n      the returned string\n    Returns\n      A string representing the input argument in CASA format:\n      ``YYYY/MM/DD/HH:MM:SS.SSS``.\n\n    Example::\n\n      from pwkit.environment.casa import tasks\n      print(tasks.mjd2date(55555))\n      # yields '2010/12/25/00:00:00.000'\n\n    \"\"\"\n    from astropy.time import Time\n    dt = Time(mjd, format='mjd', scale='utc').to_datetime()\n    fracsec = ('%.*f' % (precision, 1e-6 * dt.microsecond)).split('.')[1]\n    return '%04d/%02d/%02d/%02d:%02d:%02d.%s' % (\n        dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, fracsec\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting the physical layout of the antennas described in the MS.", "response": "def plotants(vis, figfile):\n    \"\"\"Plot the physical layout of the antennas described in the MS.\n\n    vis (str)\n      Path to the input dataset\n    figfile (str)\n      Path to the output image file.\n\n    The output image format will be inferred from the extension of *figfile*.\n    Example::\n\n      from pwkit.environments.casa import tasks\n      tasks.plotants('dataset.ms', 'antennas.png')\n\n    \"\"\"\n    from .scripting import CasapyScript\n\n    script = os.path.join(os.path.dirname(__file__), 'cscript_plotants.py')\n\n    with CasapyScript(script, vis=vis, figfile=figfile) as cs:\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef latexify(obj, **kwargs):\n    if hasattr(obj, '__pk_latex__'):\n        return obj.__pk_latex__(**kwargs)\n\n    if isinstance(obj, text_type):\n        from .unicode_to_latex import unicode_to_latex\n        return unicode_to_latex(obj)\n\n    if isinstance(obj, bool):\n        # isinstance(True, int) = True, so gotta handle this first.\n        raise ValueError('no well-defined LaTeXification of bool %r' % obj)\n\n    if isinstance(obj, float):\n        nplaces = kwargs.get('nplaces')\n        if nplaces is None:\n            return '$%f$' % obj\n        return '$%.*f$' % (nplaces, obj)\n\n    if isinstance(obj, int):\n        return '$%d$' % obj\n\n    if isinstance(obj, binary_type):\n        if all(c in _printable_ascii for c in obj):\n            return obj.decode('ascii')\n        raise ValueError('no safe LaTeXification of binary string %r' % obj)\n\n    raise ValueError('can\\'t LaTeXify %r' % obj)", "response": "Render an object in LaTeX appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef latexify_n2col(x, nplaces=None, **kwargs):\n    if nplaces is not None:\n        t = '%.*f' % (nplaces, x)\n    else:\n        t = '%f' % x\n\n    if '.' not in t:\n        return '$%s$ &' % t\n\n    left, right = t.split('.')\n    return '$%s$ & $.%s$' % (left, right)", "response": "Render a number into LaTeX in a 2 - column format where the columns split by the left of the decimal point."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef latexify_u3col(obj, **kwargs):\n    if hasattr(obj, '__pk_latex_u3col__'):\n        return obj.__pk_latex_u3col__(**kwargs)\n\n    # TODO: there are reasonable ways to format many basic types, but I'm not\n    # going to implement them until I need to.\n\n    raise ValueError('can\\'t LaTeXify %r in 3-column uncertain format' % obj)", "response": "Convert an object to special LaTeX for uncertainty tables."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an object to LaTeX for limit tables.", "response": "def latexify_l3col(obj, **kwargs):\n    \"\"\"Convert an object to special LaTeX for limit tables.\n\n    This conversion is meant for limit values in a table. The return value\n    should span three columns. The first column is the limit indicator: <, >,\n    ~, etc. The second column is the whole part of the value, up until just\n    before the decimal point. The third column is the decimal point and the\n    fractional part of the value, if present. If the item being formatted does\n    not fit this schema, it can be wrapped in something like\n    '\\multicolumn{3}{c}{...}'.\n\n    \"\"\"\n    if hasattr(obj, '__pk_latex_l3col__'):\n        return obj.__pk_latex_l3col__(**kwargs)\n\n    if isinstance(obj, bool):\n        # isinstance(True, int) = True, so gotta handle this first.\n        raise ValueError('no well-defined l3col LaTeXification of bool %r' % obj)\n\n    if isinstance(obj, float):\n        return '&' + latexify_n2col(obj, **kwargs)\n\n    if isinstance(obj, int):\n        return '& $%d$ &' % obj\n\n    raise ValueError('can\\'t LaTeXify %r in 3-column limit format' % obj)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read (path, tabwidth=8, **kwargs):\n    datamode = False\n    fixedcols = {}\n\n    for text in _trimmedlines (path, **kwargs):\n        text = text.expandtabs (tabwidth)\n\n        if datamode:\n            # table row\n            h = Holder ()\n            h.set (**fixedcols)\n            for name, cslice, parser in info:\n                try:\n                    v = parser (text[cslice].strip ())\n                except:\n                    reraise_context ('while parsing \"%s\"', text[cslice].strip ())\n                h.set_one (name, v)\n            yield h\n        elif text[0] != '@':\n            # fixed column\n            padnamekind, padval = text.split ('=', 1)\n            name, parser = _getparser (padnamekind.strip ())\n            fixedcols[name] = parser (padval.strip ())\n        else:\n            # column specification\n            n = len (text)\n            assert n > 1\n            start = 0\n            info = []\n\n            while start < n:\n                end = start + 1\n                while end < n and (not text[end].isspace ()):\n                    end += 1\n\n                if start == 0:\n                    namekind = text[start+1:end] # eat leading @\n                else:\n                    namekind = text[start:end]\n\n                while end < n and text[end].isspace ():\n                    end += 1\n\n                name, parser = _getparser (namekind)\n                if parser is None: # allow columns to be ignored\n                    skippedlast = True\n                else:\n                    skippedlast = False\n                    info.append ((name, slice (start, end), parser))\n                start = end\n\n            datamode = True\n\n            if not skippedlast:\n                # make our last column go as long as the line goes\n                # (e.g. for \"comments\" columns)\n                # but if the real last column is \":x\"-type, then info[-1]\n                # doesn't run up to the end of the line, so do nothing in that case.\n                lname, lslice, lparser = info[-1]\n                info[-1] = lname, slice (lslice.start, None), lparser", "response": "Read a typed tabular text file into a stream of Holders."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write (stream, items, fieldnames, tabwidth=8):\n    if isinstance (fieldnames, six.string_types):\n        fieldnames = fieldnames.split ()\n\n    maxlens = [0] * len (fieldnames)\n\n    # We have to make two passes, so listify:\n    items = list (items)\n\n    # pass 1: get types and maximum lengths for each record. Pad by 1 to\n    # ensure there's at least one space between all columns.\n\n    coltypes = [None] * len (fieldnames)\n\n    for i in items:\n        for idx, fn in enumerate (fieldnames):\n            val = i.get (fn)\n            if val is None:\n                continue\n\n            typetag, text, inexact = msmt.fmtinfo (val)\n            maxlens[idx] = max (maxlens[idx], len (text) + 1)\n\n            if coltypes[idx] is None:\n                coltypes[idx] = typetag\n                continue\n\n            if coltypes[idx] == typetag:\n                continue\n\n            if coltypes[idx][-1] == 'f' and typetag[-1] == 'u':\n                # Can upcast floats to uvals\n                if coltypes[idx][:-1] == typetag[:-1]:\n                    coltypes[idx] = coltypes[idx][:-1] + 'u'\n                    continue\n\n            if coltypes[idx][-1] == 'u' and typetag[-1] == 'f':\n                if coltypes[idx][:-1] == typetag[:-1]:\n                    continue\n\n            raise PKError ('irreconcilable column types: %s and %s', coltypes[idx], typetag)\n\n    # Compute column headers and their widths\n\n    headers = list (fieldnames)\n    headers[0] = '@' + headers[0]\n\n    for idx, fn in enumerate (fieldnames):\n        if coltypes[idx] != '':\n            headers[idx] += ':' + coltypes[idx]\n\n        maxlens[idx] = max (maxlens[idx], len (headers[idx]))\n\n    widths = [tabwidth * ((k + tabwidth - 1) // tabwidth) for k in maxlens]\n\n    # pass 2: write out\n\n    print (''.join (_tabpad (h, widths[idx], tabwidth)\n                    for (idx, h) in enumerate (headers)), file=stream)\n\n    def ustr (i, f):\n        v = i.get (f)\n        if v is None:\n            return ''\n        return msmt.fmtinfo (v)[1]\n\n    for i in items:\n        print (''.join (_tabpad (ustr (i, fn), widths[idx], tabwidth)\n                        for (idx, fn) in enumerate (fieldnames)), file=stream)", "response": "Writes a typed tabular text file to the specified stream."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vizread (descpath, descsection, tabpath, tabwidth=8, **kwargs):\n    from .inifile import read as iniread\n\n    cols = []\n\n    for i in iniread (descpath):\n        if i.section != descsection:\n            continue\n\n        for field, desc in six.iteritems (i.__dict__):\n            if field == 'section':\n                continue\n\n            a = desc.split ()\n            idx0 = int (a[0]) - 1\n\n            if len (a) == 1:\n                cols.append ((field, slice (idx0, idx0 + 1), msmt.parsers['s']))\n                continue\n\n            if len (a) == 2:\n                parser = msmt.parsers['s']\n            else:\n                parser = msmt.parsers[a[2]]\n\n            cols.append ((field, slice (idx0, int (a[1])), parser))\n\n    for text in _trimmedlines (tabpath, **kwargs):\n        text = text.expandtabs (tabwidth)\n\n        h = Holder ()\n        for name, cslice, parser in cols:\n            try:\n                v = parser (text[cslice].strip ())\n            except:\n                reraise_context ('while parsing \"%s\"', text[cslice].strip ())\n            h.set_one (name, v)\n\n        yield h", "response": "Read a headerless tabular text file into a generator of Holders."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving array shapes s1 and s2 compute the shape of the array that would result from broadcasting them together.", "response": "def _broadcast_shapes(s1, s2):\n    \"\"\"Given array shapes `s1` and `s2`, compute the shape of the array that would\n    result from broadcasting them together.\"\"\"\n\n    n1 = len(s1)\n    n2 = len(s2)\n    n = max(n1, n2)\n    res = [1] * n\n\n    for i in range(n):\n        if i >= n1:\n            c1 = 1\n        else:\n            c1 = s1[n1-1-i]\n\n        if i >= n2:\n            c2 = 1\n        else:\n            c2 = s2[n2-1-i]\n\n        if c1 == 1:\n            rc = c2\n        elif c2 == 1 or c1 == c2:\n            rc = c1\n        else:\n            raise ValueError('array shapes %r and %r are not compatible' % (s1, s2))\n\n        res[n-1-i] = rc\n\n    return tuple(res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naccesses value and uncert as a : class : pwkit. msmt. Uval.", "response": "def uval(self):\n        \"Accesses :attr:`value` and :attr:`uncert` as a :class:`pwkit.msmt.Uval`.\"\n        from .msmt import Uval\n        return Uval.from_norm(self.value, self.uncert)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the data to be modeled. Returns self.", "response": "def set_data(self, data, invsigma=None):\n        \"\"\"Set the data to be modeled.\n\n        Returns *self*.\n\n        \"\"\"\n        self.data = np.array(data, dtype=np.float, ndmin=1)\n\n        if invsigma is None:\n            self.invsigma = np.ones(self.data.shape)\n        else:\n            i = np.array(invsigma, dtype=np.float)\n            self.invsigma = np.broadcast_arrays(self.data, i)[1] # allow scalar invsigma\n\n        if self.invsigma.shape != self.data.shape:\n            raise ValueError('data values and inverse-sigma values must have same shape')\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprints information about the model solution.", "response": "def print_soln(self):\n        \"\"\"Print information about the model solution.\"\"\"\n        lmax = reduce(max,(len(x) for x in self.pnames), len('r chi sq'))\n\n        if self.puncerts is None:\n            for pn, val in zip(self.pnames, self.params):\n                print('%s: %14g' % (pn.rjust(lmax), val))\n        else:\n            for pn, val, err in zip(self.pnames, self.params, self.puncerts):\n                frac = abs(100. * err / val)\n                print('%s: %14g +/- %14g (%.2f%%)' % (pn.rjust(lmax), val, err, frac))\n\n        if self.rchisq is not None:\n            print('%s: %14g' % ('r chi sq'.rjust(lmax), self.rchisq))\n        elif self.chisq is not None:\n            print('%s: %14g' % ('chi sq'.rjust(lmax), self.chisq))\n        else:\n            print('%s: unknown/undefined' % ('r chi sq'.rjust(lmax)))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot(self, modelx, dlines=False, xmin=None, xmax=None,\n             ymin=None, ymax=None, **kwargs):\n        \"\"\"Plot the data and model (requires `omega`).\n\n        This assumes that `data` is 1D and that `mfunc` takes one argument\n        that should be treated as the X variable.\n\n        \"\"\"\n        import omega as om\n\n        modelx = np.asarray(modelx)\n        if modelx.shape != self.data.shape:\n            raise ValueError('modelx and data arrays must have same shape')\n\n        modely = self.mfunc(modelx)\n        sigmas = self.invsigma**-1 # TODO: handle invsigma = 0\n\n        vb = om.layout.VBox(2)\n        vb.pData = om.quickXYErr(modelx, self.data, sigmas,\n                                 'Data', lines=dlines, **kwargs)\n\n        vb[0] = vb.pData\n        vb[0].addXY(modelx, modely, 'Model')\n        vb[0].setYLabel('Y')\n        vb[0].rebound(False, True)\n        vb[0].setBounds(xmin, xmax, ymin, ymax)\n\n        vb[1] = vb.pResid = om.RectPlot()\n        vb[1].defaultField.xaxis = vb[1].defaultField.xaxis\n        vb[1].addXYErr(modelx, self.resids, sigmas, None, lines=False)\n        vb[1].setLabels('X', 'Residuals')\n        vb[1].rebound(False, True)\n        # ignore Y values since residuals are on different scale:\n        vb[1].setBounds(xmin, xmax)\n\n        vb.setWeight(0, 3)\n        return vb", "response": "Plot the data and model and return a VBox object with the data and model and residuals."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nshows the parameter correlation matrix with pwkit. ndshow_gtk3.", "response": "def show_corr(self):\n        \"Show the parameter correlation matrix with `pwkit.ndshow_gtk3`.\"\n        from .ndshow_gtk3 import view\n        d = np.diag(self.covar) ** -0.5\n        corr = self.covar * d[np.newaxis,:] * d[:,np.newaxis]\n        view(corr, title='Correlation Matrix')"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_func(self, func, pnames, args=()):\n        from .lmmin import Problem\n\n        self.func = func\n        self._args = args\n        self.pnames = list(pnames)\n        self.lm_prob = Problem(len(self.pnames))\n        return self", "response": "Set the model function to use an efficient but tedious calling convention."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the model function to use a simple but somewhat inefficient calling.", "response": "def set_simple_func(self, func, args=()):\n        \"\"\"Set the model function to use a simple but somewhat inefficient calling\n        convention.\n\n        The function should obey the following convention::\n\n            def func(param0, param1, ..., paramN, *args):\n                modeled_data = { do something using the parameters }\n                return modeled_data\n\n        Returns *self*.\n\n        \"\"\"\n        code = get_function_code(func)\n        npar = code.co_argcount - len(args)\n        pnames = code.co_varnames[:npar]\n\n        def wrapper(params, *args):\n            return func(*(tuple(params) + args))\n\n        return self.set_func(wrapper, pnames, args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a model function frozen to the specified parameter values.", "response": "def make_frozen_func(self, params):\n        \"\"\"Returns a model function frozen to the specified parameter values.\n\n        Any remaining arguments are left free and must be provided when the\n        function is called.\n\n        For this model, the returned function is the application of\n        :func:`functools.partial` to the :attr:`func` property of this object.\n\n        \"\"\"\n        params = np.array(params, dtype=np.float, ndmin=1)\n        from functools import partial\n        return partial(self.func, params)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsolve for the parameters using an initial guess.", "response": "def solve(self, guess):\n        \"\"\"Solve for the parameters, using an initial guess.\n\n        This uses the Levenberg-Marquardt optimizer described in\n        :mod:`pwkit.lmmin`.\n\n        Returns *self*.\n\n        \"\"\"\n        guess = np.array(guess, dtype=np.float, ndmin=1)\n        f = self.func\n        args = self._args\n\n        def lmfunc(params, vec):\n            vec[:] = f(params, *args).flatten()\n\n        self.lm_prob.set_residual_func(self.data.flatten(),\n                                       self.invsigma.flatten(),\n                                       lmfunc, None)\n        self.lm_soln = soln = self.lm_prob.solve(guess)\n\n        self.params = soln.params\n        self.puncerts = soln.perror\n        self.covar = soln.covar\n        self.mfunc = self.make_frozen_func(soln.params)\n\n        # fvec = resids * invsigma = (data - mdata) * invsigma\n        self.resids = soln.fvec.reshape(self.data.shape) / self.invsigma\n        self.mdata = self.data - self.resids\n\n        # lm_soln.fnorm can be unreliable (\"max(fnorm, fnorm1)\" branch)\n        self.chisq = (self.lm_soln.fvec**2).sum()\n        if soln.ndof > 0:\n            self.rchisq = self.chisq / soln.ndof\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a Model equivalent to this object.", "response": "def as_nonlinear(self, params=None):\n        \"\"\"Return a `Model` equivalent to this object. The nonlinear solver is less\n        efficient, but lets you freeze parameters, compute uncertainties, etc.\n\n        If the `params` argument is provided, solve() will be called on the\n        returned object with those parameters. If it is `None` and this object\n        has parameters in `self.params`, those will be use. Otherwise, solve()\n        will not be called on the returned object.\n\n        \"\"\"\n        if params is None:\n            params = self.params\n\n        nlm = Model(None, self.data, self.invsigma)\n        nlm.set_func(lambda p, x: npoly.polyval(x, p),\n                     self.pnames,\n                     args=(self.x,))\n\n        if params is not None:\n            nlm.solve(params)\n        return nlm"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef modify_environment (self, env):\n        plat = self._platform\n\n        def path (*args):\n            return os.path.join (self._installdir, *args)\n\n        env['CALDB'] = b'http://heasarc.gsfc.nasa.gov/FTP/caldb'\n        env['CALDBCONFIG'] = path ('caldb.config')\n        env['CALDBALIAS'] = path ('alias_config.fits')\n\n        env['HEADAS'] = path (plat)\n        env['LHEASOFT'] = env['HEADAS']\n        env['FTOOLS'] = env['HEADAS']\n\n        prepend_environ_path (env, 'PATH', path (plat, 'bin'))\n        prepend_environ_path (env, 'LD_LIBRARY_PATH', path (plat, 'lib'))\n        prepend_environ_path (env, 'PERLLIB', path (plat, 'lib', 'perl'))\n        prepend_environ_path (env, 'PERL5LIB', path (plat, 'lib', 'perl'))\n        prepend_environ_path (env, 'PYTHONPATH', path (plat, 'lib'))\n        prepend_environ_path (env, 'PYTHONPATH', path (plat, 'lib', 'python'))\n\n        userpfiles = user_data_path ('hea-pfiles')\n        io.ensure_dir (userpfiles, parents=True)\n        env['PFILES'] = ';'.join ([userpfiles,\n                                   path (plat, 'syspfiles')])\n\n        env['LHEA_DATA'] = path (plat, 'refdata')\n        env['LHEA_HELP'] = path (plat, 'help')\n        env['PGPLOT_DIR'] = path (plat, 'lib')\n        env['PGPLOT_FONT'] = path (plat, 'lib', 'grfont.dat')\n        env['PGPLOT_RGB'] = path (plat, 'lib', 'rgb.txt')\n        env['POW_LIBRARY'] = path (plat, 'lib', 'pow')\n        env['TCLRL_LIBDIR'] = path (plat, 'lib')\n        env['XANADU'] = path ()\n        env['XANBIN'] = path (plat)\n        env['XRDEFAULTS'] = path (plat, 'xrdefaults')\n\n        env['EXT'] = b'lnx' # XXX portability probably ...\n        env['LHEAPERL'] = b'/usr/bin/perl' # what could go wrong?\n        env['PFCLOBBER'] = b'1'\n        env['FTOOLSINPUT'] = b'stdin'\n        env['FTOOLSOUTPUT'] = b'stdout'\n        return env", "response": "Modify the environment variables that are set in headas - init. sh."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the URLs of all files attached to the thread.", "response": "def files(self):\n        \"\"\"Returns the URLs of all files attached to posts in the thread.\"\"\"\n        if self.topic.has_file:\n            yield self.topic.file.file_url\n        for reply in self.replies:\n            if reply.has_file:\n                yield reply.file.file_url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the URLs of all thumbnails in the thread.", "response": "def thumbs(self):\n        \"\"\"Returns the URLs of all thumbnails in the thread.\"\"\"\n        if self.topic.has_file:\n            yield self.topic.file.thumbnail_url\n        for reply in self.replies:\n            if reply.has_file:\n                yield reply.file.thumbnail_url"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef filenames(self):\n        if self.topic.has_file:\n            yield self.topic.file.filename\n        for reply in self.replies:\n            if reply.has_file:\n                yield reply.file.filename", "response": "Returns the filenames of all files attached to the thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the filenames of all thumbnails in the thread.", "response": "def thumbnames(self):\n        \"\"\"Returns the filenames of all thumbnails in the thread.\"\"\"\n        if self.topic.has_file:\n            yield self.topic.file.thumbnail_fname\n        for reply in self.replies:\n            if reply.has_file:\n                yield reply.file.thumbnail_fname"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef file_objects(self):\n        if self.topic.has_file:\n            yield self.topic.file\n        for reply in self.replies:\n            if reply.has_file:\n                yield reply.file", "response": "Returns the list of file objects attached to the thread."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfetching new posts from the server and update the thread s attributes.", "response": "def update(self, force=False):\n        \"\"\"Fetch new posts from the server.\n\n        Arguments:\n            force (bool): Force a thread update, even if thread has 404'd.\n\n        Returns:\n            int: How many new posts have been fetched.\n        \"\"\"\n\n        # The thread has already 404'ed, this function shouldn't do anything anymore.\n        if self.is_404 and not force:\n            return 0\n\n        if self._last_modified:\n            headers = {'If-Modified-Since': self._last_modified}\n        else:\n            headers = None\n\n        # random connection errors, just return 0 and try again later\n        try:\n            res = self._board._requests_session.get(self._api_url, headers=headers)\n        except:\n            # try again later\n            return 0\n\n        # 304 Not Modified, no new posts.\n        if res.status_code == 304:\n            return 0\n\n        # 404 Not Found, thread died.\n        elif res.status_code == 404:\n            self.is_404 = True\n            # remove post from cache, because it's gone.\n            self._board._thread_cache.pop(self.id, None)\n            return 0\n\n        elif res.status_code == 200:\n            # If we somehow 404'ed, we should put ourself back in the cache.\n            if self.is_404:\n                self.is_404 = False\n                self._board._thread_cache[self.id] = self\n\n            # Remove\n            self.want_update = False\n            self.omitted_images = 0\n            self.omitted_posts = 0\n\n            self._last_modified = res.headers['Last-Modified']\n            posts = res.json()['posts']\n\n            original_post_count = len(self.replies)\n            self.topic = Post(self, posts[0])\n\n            if self.last_reply_id and not force:\n                self.replies.extend(Post(self, p) for p in posts if p['no'] > self.last_reply_id)\n            else:\n                self.replies[:] = [Post(self, p) for p in posts[1:]]\n\n            new_post_count = len(self.replies)\n            post_count_delta = new_post_count - original_post_count\n            if not post_count_delta:\n                return 0\n\n            self.last_reply_id = self.replies[-1].post_number\n\n            return post_count_delta\n\n        else:\n            res.raise_for_status()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the string list args as a set of keyword arguments in a very simple - minimal way.", "response": "def basic(args=None):\n    \"\"\"Parse the string list *args* as a set of keyword arguments in a very\n    simple-minded way, splitting on equals signs. Returns a\n    :class:`pwkit.Holder` instance with attributes set to strings. The form\n    ``+foo`` is mapped to setting ``foo = True`` on the :class:`pwkit.Holder`\n    instance. If *args* is ``None``, ``sys.argv[1:]`` is used. Raises\n    :exc:`KwargvError` on invalid arguments (i.e., ones without an equals sign\n    or a leading plus sign).\n\n    \"\"\"\n    if args is None:\n        import sys\n        args = sys.argv[1:]\n\n    parsed = Holder()\n\n    for arg in args:\n        if arg[0] == '+':\n            for kw in arg[1:].split(','):\n                parsed.set_one(kw, True)\n            # avoid analogous -a,b,c syntax because it gets confused with -a --help, etc.\n        else:\n            t = arg.split('=', 1)\n            if len(t) < 2:\n                raise KwargvError('don\\'t know what to do with argument \"%s\"', arg)\n            if not len(t[1]):\n                raise KwargvError('empty value for keyword argument \"%s\"', t[0])\n            parsed.set_one(t[0], t[1])\n\n    return parsed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse(self, args=None):\n        if args is None:\n            import sys\n            args = sys.argv[1:]\n\n        seen = set()\n\n        for arg in args:\n            t = arg.split('=', 1)\n            if len(t) < 2:\n                raise KwargvError('don\\'t know what to do with argument \"%s\"', arg)\n\n            kw, val = t\n            ki = self._kwinfos.get(kw)\n\n            if ki is None:\n                raise KwargvError('unrecognized keyword argument \"%s\"', kw)\n\n            if not len(val):\n                raise KwargvError('empty value for keyword argument \"%s\"', kw)\n\n            try:\n                pval = ki.parser(val)\n            except ParseError as e :\n                raise KwargvError('cannot parse value \"%s\" for keyword '\n                                  'argument \"%s\": %s', val, kw, e)\n            except Exception as e:\n                if ki.printexc:\n                    raise KwargvError('cannot parse value \"%s\" for keyword '\n                                      'argument \"%s\": %s', val, kw, e)\n                raise KwargvError('cannot parse value \"%s\" for keyword '\n                                  'argument \"%s\"', val, kw)\n\n            if ki.maxvals is not None and len(pval) > ki.maxvals:\n                raise KwargvError('keyword argument \"%s\" may have at most %d'\n                                  ' values, but got %s (\"%s\")', kw,\n                                  ki.maxvals, len(pval), val)\n\n            if ki.scale is not None:\n                pval = pval * ki.scale\n\n            if ki.fixupfunc is not None:\n                pval = ki.fixupfunc(pval)\n\n            if ki.repeatable:\n                # We can't just unilaterally append to the preexisting\n                # list, since if we did that starting with the default value\n                # we'd mutate the default list.\n                cur = self.get(ki._attrname)\n                if not len(cur):\n                    pval = [pval]\n                else:\n                    cur.append(pval)\n                    pval = cur\n\n            seen.add(kw)\n            self.set_one(ki._attrname, pval)\n\n        for kw, ki in six.iteritems(self._kwinfos):\n            if kw not in seen:\n                if ki.required:\n                    raise KwargvError('required keyword argument \"%s\" was not provided', kw)\n\n                # If there's a fixup, process it even if the keyword wasn't\n                # provided. This lets code use \"interesting\" defaults with\n                # types that you might prefer to use when launching a task\n                # programmatically; e.g. a default output stream that is\n                # `sys.stdout`, not \"-\".\n                if ki.fixupfunc is not None:\n                    self.set_one(ki._attrname, ki.fixupfunc(None))\n\n        return self", "response": "Parse the textual keywords as described by this class s attributes and update the attributes of the current instance with the parsed values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlike ParseKeywords. parse but calls die.", "response": "def parse_or_die(self, args=None):\n        \"\"\"Like :meth:`ParseKeywords.parse`, but calls :func:`pkwit.cli.die` if a\n        :exc:`KwargvError` is raised, printing the exception text. Returns\n        *self* for convenience.\n\n        \"\"\"\n        from .cli import die\n\n        try:\n            return self.parse(args)\n        except KwargvError as e:\n            die(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cas_a (freq_mhz, year):\n    # The snu rule is right out of Baars et al. The dnu is corrected\n    # for the frequency being measured in MHz, not GHz.\n\n    snu = 10. ** (5.745 - 0.770 * np.log10 (freq_mhz)) # Jy\n    dnu = 0.01 * (0.07 - 0.30 * np.log10 (freq_mhz)) # percent per yr.\n    loss = (1 - dnu) ** (year - 1980.)\n    return snu * loss", "response": "Return the flux of Cas A given a frequency and year."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes the table of models for Cas A.", "response": "def init_cas_a (year):\n    \"\"\"Insert an entry for Cas A into the table of models. Need to specify the\n    year of the observations to account for the time variation of Cas A's\n    emission.\n\n    \"\"\"\n    year = float (year)\n    models['CasA'] = lambda f: cas_a (f, year)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an entry into the models table for a source based on L - band and C - band flux densities.", "response": "def add_from_vla_obs (src, Lband, Cband):\n    \"\"\"Add an entry into the models table for a source based on L-band and\n    C-band flux densities.\n\n    \"\"\"\n    if src in models:\n        raise PKError ('already have a model for ' + src)\n\n    fL = np.log10 (1425)\n    fC = np.log10 (4860)\n\n    lL = np.log10 (Lband)\n    lC = np.log10 (Cband)\n\n    A = (lL - lC) / (fL - fC)\n    B = lL - A * fL\n\n    def fluxdens (freq_mhz):\n        return 10. ** (A * np.log10 (freq_mhz) + B)\n\n    def spindex (freq_mhz):\n        return A\n\n    models[src] = fluxdens\n    spindexes[src] = spindex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsay we take a Gaussian bivariate and convert the parameters of the the distribution to an ellipse. By what factor should we scale the axes to make the area of the ellipse correspond to the n - sigma confidence interval?", "response": "def sigmascale (nsigma):\n    \"\"\"Say we take a Gaussian bivariate and convert the parameters of the\n    distribution to an ellipse (major, minor, PA). By what factor should we\n    scale those axes to make the area of the ellipse correspond to the n-sigma\n    confidence interval?\n\n    Negative or zero values result in NaN.\n\n    \"\"\"\n    from scipy.special import erfc\n    return np.sqrt (-2 * np.log (erfc (nsigma / np.sqrt (2))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsays we take a Gaussian bivariate and convert the parameters of the the distribution to an ellipse", "response": "def clscale (cl):\n    \"\"\"Say we take a Gaussian bivariate and convert the parameters of the\n    distribution to an ellipse (major, minor, PA). By what factor should we\n    scale those axes to make the area of the ellipse correspond to the\n    confidence interval CL? (I.e. 0 < CL < 1)\n\n    \"\"\"\n    rv = np.sqrt (-2 * np.log (1 - cl))\n    rv[np.where (cl <= 0)] = np.nan\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bivell (sx, sy, cxy):\n    # See CfA notebook #1 pp. 129-133.\n    _bivcheck (sx, sy, cxy)\n    from numpy import arctan2, sqrt\n\n    sx2, sy2, cxy2 = sx**2, sy**2, cxy**2\n\n    pa = 0.5 * arctan2 (2 * cxy, sx2 - sy2)\n    h = sqrt ((sx2 - sy2)**2 + 4*cxy2)\n\n    t = 2 * (sx2 * sy2 - cxy2) / (sx2 + sy2 - h)\n    if t < 0:\n        raise ValueError ('covariance just barely out of bounds [1] '\n                          '(sx=%.10e, sy=%.10e, cxy=%.10e, cxy/sxsy=%.16f)' %\n                          (sx, sy, cxy, cxy / (sx * sy)))\n    mjr = sqrt (t)\n\n    t = 2 * (sx2 * sy2 - cxy2) / (sx2 + sy2 + h)\n    if t < 0: # if we got this far, shouldn't happen, but ...\n        raise ValueError ('covariance just barely out of bounds [2] '\n                          '(sx=%.10e, sy=%.10e, cxy=%.10e, cxy/sxsy=%.16f)' %\n                          (sx, sy, cxy, cxy / (sx * sy)))\n    mnr = sqrt (t)\n\n    return ellnorm (mjr, mnr, pa)", "response": "Compute the parameters of a Gaussian bivariate distribution in an ellipse form."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute nontrivial parameters for evaluating a bivariate distribution as a 2D Gaussian.", "response": "def bivabc (sx, sy, cxy):\n    \"\"\"Compute nontrivial parameters for evaluating a bivariate distribution\n    as a 2D Gaussian. Inputs:\n\n    * sx: standard deviation (not variance) of x var\n    * sy: standard deviation (not variance) of y var\n    * cxy: covariance (not correlation coefficient) of x and y\n\n    Returns: (a, b, c), where z = k exp (ax\u00b2 + bxy + cy\u00b2)\n\n    The proper value for k can be obtained from bivnorm().\n\n    \"\"\"\n    _bivcheck (sx, sy, cxy)\n\n    sx2, sy2, cxy2 = sx**2, sy**2, cxy**2\n    t = 1. / (sx2 * sy2 - cxy2)\n    if t <= 0:\n        raise ValueError ('covariance just barely out of bounds '\n                          '(sx=%.10e, sy=%.10e, cxy=%.10e, cxy/sxsy=%.16f)' %\n                          (sx, sy, cxy, cxy / (sx * sy)))\n\n    a = -0.5 * sy2 * t\n    c = -0.5 * sx2 * t\n    b = cxy * t\n    return _abccheck (a, b, c)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the main parameters of a bivariate distribution from data.", "response": "def databiv (xy, coordouter=False, **kwargs):\n    \"\"\"Compute the main parameters of a bivariate distribution from data. The\n    parameters are returned in the same format as used in the rest of this\n    module.\n\n    * xy: a 2D data array of shape (2, nsamp) or (nsamp, 2)\n    * coordouter: if True, the coordinate axis is the outer axis; i.e.\n      the shape is (2, nsamp). Otherwise, the coordinate axis is the\n      inner axis; i.e. shape is (nsamp, 2).\n\n    Returns: (sx, sy, cxy)\n\n    In both cases, the first slice along the coordinate axis gives the X data\n    (i.e., xy[0] or xy[:,0]) and the second slice gives the Y data (xy[1] or\n    xy[:,1]).\n\n    \"\"\"\n    xy = np.asarray (xy)\n    if xy.ndim != 2:\n        raise ValueError ('\"xy\" must be a 2D array')\n\n    if coordouter:\n        if xy.shape[0] != 2:\n            raise ValueError ('if \"coordouter\" is True, first axis of \"xy\" '\n                              'must have size 2')\n    else:\n        if xy.shape[1] != 2:\n            raise ValueError ('if \"coordouter\" is False, second axis of \"xy\" '\n                              'must have size 2')\n\n    cov = np.cov (xy, rowvar=coordouter, **kwargs)\n    sx, sy = np.sqrt (np.diag (cov))\n    cxy = cov[0,1]\n    return _bivcheck (sx, sy, cxy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes random values distributed according to the specified bivariate distribution.", "response": "def bivrandom (x0, y0, sx, sy, cxy, size=None):\n    \"\"\"Compute random values distributed according to the specified bivariate\n    distribution.\n\n    Inputs:\n\n    * x0: the center of the x distribution (i.e. its intended mean)\n    * y0: the center of the y distribution\n    * sx: standard deviation (not variance) of x var\n    * sy: standard deviation (not variance) of y var\n    * cxy: covariance (not correlation coefficient) of x and y\n    * size (optional): the number of values to compute\n\n    Returns: array of shape (size, 2); or just (2, ), if size was not\n      specified.\n\n    The bivariate parameters of the generated data are approximately\n    recoverable by calling 'databiv(retval)'.\n\n    \"\"\"\n    from numpy.random import multivariate_normal as mvn\n    p0 = np.asarray ([x0, y0])\n    cov = np.asarray ([[sx**2, cxy],\n                       [cxy, sy**2]])\n    return mvn (p0, cov, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bivconvolve (sx_a, sy_a, cxy_a, sx_b, sy_b, cxy_b):\n    _bivcheck (sx_a, sy_a, cxy_a)\n    _bivcheck (sx_b, sy_b, cxy_b)\n\n    sx_c = np.sqrt (sx_a**2 + sx_b**2)\n    sy_c = np.sqrt (sy_a**2 + sy_b**2)\n    cxy_c = cxy_a + cxy_b\n\n    return _bivcheck (sx_c, sy_c, cxy_c)", "response": "Given two independent bivariate distributions compute a bivariate\n    distribution corresponding to their convolution."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes a point on an ellipse parametrically.", "response": "def ellpoint (mjr, mnr, pa, th):\n    \"\"\"Compute a point on an ellipse parametrically. Inputs:\n\n    * mjr: major axis (sigma not FWHM) of the ellipse\n    * mnr: minor axis (sigma not FWHM) of the ellipse\n    * pa: position angle (from +x to +y) of the ellipse, radians\n    * th: the parameter, 0 <= th < 2pi: the eccentric anomaly\n\n    Returns: (x, y)\n\n    th may be a vector, in which case x and y will be as well.\n    \"\"\"\n    _ellcheck (mjr, mnr, pa)\n    from numpy import cos, sin\n\n    ct, st = cos (th), sin (th)\n    cp, sp = cos (pa), sin (pa)\n    x = mjr * cp * ct - mnr * sp * st\n    y = mjr * sp * ct + mnr * cp * st\n    return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the squared distance parameter of an ellipse in the 2D Gaussian.", "response": "def elld2 (x0, y0, mjr, mnr, pa, x, y):\n    \"\"\"Given an 2D Gaussian expressed as an ellipse (major, minor, pa), compute a\n    \"squared distance parameter\" such that\n\n       z = exp (-0.5 * d2)\n\n    Inputs:\n\n    * x0: position of Gaussian center on x axis\n    * y0: position of Gaussian center on y axis\n    * mjr: major axis (sigma not FWHM) of the Gaussian\n    * mnr: minor axis (sigma not FWHM) of the Gaussian\n    * pa: position angle (from +x to +y) of the Gaussian, radians\n    * x: x coordinates of the locations for which to evaluate d2\n    * y: y coordinates of the locations for which to evaluate d2\n\n    Returns: d2, distance parameter defined as above.\n\n    x0, y0, mjr, and mnr may be in any units so long as they're consistent. x\n    and y may be arrays (of the same shape), in which case d2 will be an array\n    as well.\n\n    \"\"\"\n    _ellcheck (mjr, mnr, pa)\n\n    dx, dy = x - x0, y - y0\n    c, s = np.cos (pa), np.sin (pa)\n    a = c * dx + s * dy\n    b = -s * dx + c * dy\n    return (a / mjr)**2 + (b / mnr)**2"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ellbiv (mjr, mnr, pa):\n    _ellcheck (mjr, mnr, pa)\n\n    cpa, spa = np.cos (pa), np.sin (pa)\n    q = np.asarray ([[cpa, -spa],\n                     [spa, cpa]])\n    cov = np.dot (q, np.dot (np.diag ([mjr**2, mnr**2]), q.T))\n    sx = np.sqrt (cov[0,0])\n    sy = np.sqrt (cov[1,1])\n    cxy = cov[0,1]\n\n    return _bivcheck (sx, sy, cxy)", "response": "Compute the equivalent parameters for a 2D Gaussian in an ellipse."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the 2D Gaussian expressed as an ellipse.", "response": "def ellabc (mjr, mnr, pa):\n    \"\"\"Given a 2D Gaussian expressed as an ellipse (major, minor, pa), compute the\n    nontrivial parameters for its evaluation.\n\n    * mjr: major axis (sigma not FWHM) of the Gaussian\n    * mnr: minor axis (sigma not FWHM) of the Gaussian\n    * pa: position angle (from +x to +y) of the Gaussian, radians\n\n    Returns: (a, b, c), where z = exp (ax\u00b2 + bxy + cy\u00b2)\n\n    \"\"\"\n    _ellcheck (mjr, mnr, pa)\n\n    cpa, spa = np.cos (pa), np.sin (pa)\n    mjrm2, mnrm2 = mjr**-2, mnr**-2\n\n    a = -0.5 * (cpa**2 * mjrm2 + spa**2 * mnrm2)\n    c = -0.5 * (spa**2 * mjrm2 + cpa**2 * mnrm2)\n    b = cpa * spa * (mnrm2 - mjrm2)\n\n    return _abccheck (a, b, c)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncomputes the distance between two ellipses.", "response": "def double_ell_distance (mjr0, mnr0, pa0, mjr1, mnr1, pa1, dx, dy):\n    \"\"\"Given two ellipses separated by *dx* and *dy*, compute their separation in\n    terms of \u03c3. Based on Pineau et al (2011A&A...527A.126P).\n\n    The \"0\" ellipse is taken to be centered at (0, 0), while the \"1\"\n    ellipse is centered at (dx, dy).\n\n    \"\"\"\n    # 1. We need to rotate the frame so that ellipse 1 lies on the X axis.\n    theta = -np.arctan2 (dy, dx)\n\n    # 2. We also need to express these rotated ellipses in \"biv\" format.\n    sx0, sy0, cxy0 = ellbiv (mjr0, mnr0, pa0 + theta)\n    sx1, sy1, cxy1 = ellbiv (mjr1, mnr1, pa1 + theta)\n\n    # 3. Their convolution is:\n    sx, sy, cxy = bivconvolve (sx0, sy0, cxy0, sx1, sy1, cxy1)\n\n    # 4. The separation between the centers is still just:\n    d = np.sqrt (dx**2 + dy**2)\n\n    # 5. The effective sigma in the purely X direction, taking into account\n    # the covariance term, is:\n    sigma_eff = sx * np.sqrt (1 - (cxy / (sx * sy))**2)\n\n    # 6. Therefore the answer is:\n    return d / sigma_eff"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef abcell (a, b, c):\n    from numpy import arctan2, sqrt\n\n    bad = _abccheck (a, b, c)\n    pa = 0.5 * arctan2 (b, a - c)\n\n    t1 = np.sqrt ((a - c)**2 + b**2)\n    t2 = -t1 - a - c\n    bad |= (t2 <= 0)\n    mjr = t2**-0.5\n\n    t2 = t1 - a - c\n    bad |= (t2 <= 0)\n    mnr = t2**-0.5\n\n    w = np.where (bad)\n    mjr[w] = np.nan\n    mnr[w] = np.nan\n    pa[w] = np.nan\n\n    return ellnorm (mjr, mnr, pa)", "response": "Evaluates the nontrivial parameters for evaluation a 2D Gaussian as a\n    polynomial."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the 2D Gaussian expressed as the ABC polynomial coefficients and compute the squared distance parameter", "response": "def abcd2 (x0, y0, a, b, c, x, y):\n    \"\"\"Given an 2D Gaussian expressed as the ABC polynomial coefficients, compute\n    a \"squared distance parameter\" such that\n\n       z = exp (-0.5 * d2)\n\n    Inputs:\n\n    * x0: position of Gaussian center on x axis\n    * y0: position of Gaussian center on y axis\n    * a: such that z = exp (ax\u00b2 + bxy + cy\u00b2)\n    * b: see above\n    * c: see above\n    * x: x coordinates of the locations for which to evaluate d2\n    * y: y coordinates of the locations for which to evaluate d2\n\n    Returns: d2, distance parameter defined as above.\n\n    This is pretty trivial.\n\n    \"\"\"\n    _abccheck (a, b, c)\n    dx, dy = x - x0, y - y0\n    return -2 * (a * dx**2 + b * dx * dy + c * dy**2)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _compute_projection(self, X, W):\n        # TODO: check W input; handle sparse case\n        X = check_array(X)\n\n        D = np.diag(W.sum(1))\n        L = D - W\n        evals, evecs = eigh_robust(np.dot(X.T, np.dot(L, X)),\n                                   np.dot(X.T, np.dot(D, X)),\n                                   eigvals=(0, self.n_components - 1))\n        return evecs", "response": "Compute the LPP projection matrix for a set of locality preserving features."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_common_dtype(*args):\n    '''Returns common dtype of numpy and scipy objects.\n\n    Recognizes ndarray, spmatrix and LinearOperator. All other objects are\n    ignored (most notably None).'''\n    dtypes = []\n    for arg in args:\n        if type(arg) is numpy.ndarray or  \\\n                isspmatrix(arg) or \\\n                isinstance(arg, LinearOperator):\n            if hasattr(arg, 'dtype'):\n                dtypes.append(arg.dtype)\n            else:\n                warnings.warn('object %s does not have a dtype.'\n                              % arg.__repr__)\n    return numpy.find_common_type(dtypes, [])", "response": "Returns common dtype of numpy and scipy objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef inner(X, Y, ip_B=None):\n    '''Euclidean and non-Euclidean inner product.\n\n    numpy.vdot only works for vectors and numpy.dot does not use the conjugate\n    transpose.\n\n    :param X: numpy array with ``shape==(N,m)``\n    :param Y: numpy array with ``shape==(N,n)``\n    :param ip_B: (optional) May be one of the following\n\n        * ``None``: Euclidean inner product.\n        * a self-adjoint and positive definite operator :math:`B` (as\n          ``numpy.array`` or ``LinearOperator``). Then :math:`X^*B Y` is\n          returned.\n        * a callable which takes 2 arguments X and Y and returns\n          :math:`\\\\langle X,Y\\\\rangle`.\n\n    **Caution:** a callable should only be used if necessary. The choice\n    potentially has an impact on the round-off behavior, e.g. of projections.\n\n    :return: numpy array :math:`\\\\langle X,Y\\\\rangle` with ``shape==(m,n)``.\n    '''\n    if ip_B is None or isinstance(ip_B, IdentityLinearOperator):\n        return numpy.dot(X.T.conj(), Y)\n    (N, m) = X.shape\n    (_, n) = Y.shape\n    try:\n        B = get_linearoperator((N, N), ip_B)\n    except TypeError:\n        return ip_B(X, Y)\n    if m > n:\n        return numpy.dot((B*X).T.conj(), Y)\n    else:\n        return numpy.dot(X.T.conj(), B*Y)", "response": "Euclidean and non - Euclidean inner product."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef norm_squared(x, Mx=None, inner_product=ip_euclid):\n    '''Compute the norm^2 w.r.t. to a given scalar product.'''\n    assert(len(x.shape) == 2)\n    if Mx is None:\n        rho = inner_product(x, x)\n    else:\n        assert(len(Mx.shape) == 2)\n        rho = inner_product(x, Mx)\n\n    if rho.shape == (1, 1):\n        if abs(rho[0, 0].imag) > abs(rho[0, 0])*1e-10 or rho[0, 0].real < 0.0:\n            raise InnerProductError(('<x,Mx> = %g. Is the inner product '\n                                     'indefinite?') % rho[0, 0])\n\n    return numpy.linalg.norm(rho, 2)", "response": "Compute the norm^2 w. r. t. to a given scalar product."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef norm(x, y=None, ip_B=None):\n    r'''Compute norm (Euclidean and non-Euclidean).\n\n    :param x: a 2-dimensional ``numpy.array``.\n    :param y: a 2-dimensional ``numpy.array``.\n    :param ip_B: see :py:meth:`inner`.\n\n    Compute :math:`\\sqrt{\\langle x,y\\rangle}` where the inner product is\n    defined via ``ip_B``.\n    '''\n    # Euclidean inner product?\n    if y is None and (ip_B is None\n                      or isinstance(ip_B, IdentityLinearOperator)):\n        return numpy.linalg.norm(x, 2)\n    if y is None:\n        y = x\n    ip = inner(x, y, ip_B=ip_B)\n    nrm_diag = numpy.linalg.norm(numpy.diag(ip), 2)\n    nrm_diag_imag = numpy.linalg.norm(numpy.imag(numpy.diag(ip)), 2)\n    if nrm_diag_imag > nrm_diag*1e-10:\n        raise InnerProductError('inner product defined by ip_B not positive '\n                                'definite? ||diag(ip).imag||/||diag(ip)||={0}'\n                                .format(nrm_diag_imag/nrm_diag))\n    return numpy.sqrt(numpy.linalg.norm(ip, 2))", "response": "Compute norm of x y."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_linearoperator(shape, A, timer=None):\n    ret = None\n    import scipy.sparse.linalg as scipylinalg\n    if isinstance(A, LinearOperator):\n        ret = A\n    elif A is None:\n        ret = IdentityLinearOperator(shape)\n    elif isinstance(A, numpy.ndarray) or isspmatrix(A):\n        ret = MatrixLinearOperator(A)\n    elif isinstance(A, numpy.matrix):\n        ret = MatrixLinearOperator(numpy.atleast_2d(numpy.asarray(A)))\n    elif isinstance(A, scipylinalg.LinearOperator):\n        if not hasattr(A, 'dtype'):\n            raise ArgumentError('scipy LinearOperator has no dtype.')\n        ret = LinearOperator(A.shape, dot=A.matvec, dot_adj=A.rmatvec,\n                             dtype=A.dtype)\n    else:\n        raise TypeError('type not understood')\n\n    # set up timer if requested\n    if A is not None and not isinstance(A, IdentityLinearOperator) \\\n            and timer is not None:\n        ret = TimedLinearOperator(ret, timer)\n\n    # check shape\n    if shape != ret.shape:\n        raise LinearOperatorError('shape mismatch')\n\n    return ret", "response": "Enhances aslinearoperator if A is None."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef orthonormality(V, ip_B=None):\n    return norm(numpy.eye(V.shape[1]) - inner(V, V, ip_B=ip_B))", "response": "Measure orthonormality of given basis."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef arnoldi_res(A, V, H, ip_B=None):\n    N = V.shape[0]\n    invariant = H.shape[0] == H.shape[1]\n    A = get_linearoperator((N, N), A)\n    if invariant:\n        res = A*V - numpy.dot(V, H)\n    else:\n        res = A*V[:, :-1] - numpy.dot(V, H)\n    return norm(res, ip_B=ip_B)", "response": "Measure Arnoldi residual.\n\n    :param A: a linear operator that can be used with scipy's aslinearoperator\n      with ``shape==(N,N)``.\n    :param V: Arnoldi basis matrix with ``shape==(N,n)``.\n    :param H: Hessenberg matrix: either :math:`\\\\underline{H}_{n-1}` with\n      ``shape==(n,n-1)`` or :math:`H_n` with ``shape==(n,n)`` (if the Arnoldi\n      basis spans an A-invariant subspace).\n    :param ip_B: (optional) the inner product to use, see :py:meth:`inner`.\n\n    :returns: either :math:`\\\\|AV_{n-1} - V_n \\\\underline{H}_{n-1}\\\\|` or\n      :math:`\\\\|A V_n - V_n H_n\\\\|` (in the invariant case)."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hegedus(A, b, x0, M=None, Ml=None, ip_B=None):\n    N = len(b)\n    shape = (N, N)\n    A = get_linearoperator(shape, A)\n    M = get_linearoperator(shape, M)\n    Ml = get_linearoperator(shape, Ml)\n\n    MlAx0 = Ml*(A*x0)\n    z = M*MlAx0\n    znorm2 = inner(z, MlAx0, ip_B=ip_B)\n    if znorm2 <= 1e-15:\n        return numpy.zeros((N, 1))\n    gamma = inner(z, Ml*b, ip_B=ip_B) / znorm2\n    return gamma*x0", "response": "Rescale initial guess appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef arnoldi_projected(H, P, k, ortho='mgs'):\n    n = H.shape[1]\n    dtype = find_common_dtype(H, P)\n    invariant = H.shape[0] == n\n    hlast = 0 if invariant else H[-1, -1]\n    H = get_linearoperator((n, n), H if invariant else H[:-1, :])\n    P = get_linearoperator((n, n), P)\n    v = P * numpy.eye(n, 1)\n    maxiter = n-k+1\n    F = numpy.zeros((1, maxiter), dtype=dtype)\n    PH = lambda x: P*(H*x)\n    PH = LinearOperator((n, n), dtype, PH)\n    _arnoldi = Arnoldi(PH, v, maxiter=maxiter, ortho=ortho)\n    while _arnoldi.iter < _arnoldi.maxiter and not _arnoldi.invariant:\n        u, _ = _arnoldi.get_last()\n        F[0, _arnoldi.iter] = hlast * u[-1, 0]\n        _arnoldi.advance()\n    U, G = _arnoldi.get()\n    return U, G, F[[0], :_arnoldi.iter]", "response": "Compute the Arnoldi relation for projected operator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ritz(H, V=None, hermitian=False, type='ritz'):\n    # TODO: enhance ritz to accept an augmented space\n\n    n = H.shape[1]\n    if V is not None and V.shape[1] != H.shape[0]:\n        raise ArgumentError('shape mismatch with V and H')\n    if not H.shape[0] in [n, n+1]:\n        raise ArgumentError('H not of shape (n+1,n) or (n,n)')\n    symmres = numpy.linalg.norm(H[:n, :] - H[:n, :].T.conj())\n    if hermitian and symmres >= 5e-14:\n        warnings.warn('Hessenberg matrix is not symmetric: |H-H^*|={0}'\n                      .format(symmres))\n\n    # choose eig for Hermitian or non-Hermitian matrices\n    eig = scipy.linalg.eigh if hermitian else scipy.linalg.eig\n\n    if type == 'ritz':\n        theta, U = eig(H[:n, :])\n        beta = 0 if H.shape[0] == n else H[-1, -1]\n        resnorm = numpy.abs(beta * U[-1, :])\n    elif type == 'harmonic':\n        theta, U = eig(H[:n, :].T.conj(), numpy.dot(H.T.conj(), H))\n        theta = 1/theta\n        resnorm = []\n        for i in range(n):\n            U[:, i] /= numpy.linalg.norm(U[:, i], 2)\n            resi = numpy.dot(H, U[:, i])\n            if resi.dtype != numpy.complex and theta.dtype == numpy.complex:\n                resi = numpy.array(resi, dtype=numpy.complex)\n            resi[:n] -= theta[i]*U[:, i]\n            resnorm.append(numpy.linalg.norm(resi, 2))\n        resnorm = numpy.array(resnorm)\n    elif type == 'harmonic_improved':\n        theta, U = eig(H[:n, :].T.conj(), numpy.dot(H.T.conj(), H))\n        rho = []\n        for i in range(n):\n            U[:, i] /= numpy.linalg.norm(U[:, i], 2)\n            rho.append(numpy.dot(U[:, i].T.conj(),\n                                 numpy.dot(H[:n, :], U[:, i])))\n        theta = numpy.array(rho)\n        resnorm = []\n        for i in range(n):\n            resi = numpy.dot(H, U[:, i])\n            resi[:n] -= theta[i]*U[:, i]\n            resnorm.append(numpy.linalg.norm(resi, 2))\n        resnorm = numpy.array(resnorm)\n        pass\n    else:\n        raise ArgumentError('unknown Ritz type {0}'.format(type))\n\n    if V is not None:\n        return theta, U, resnorm, numpy.dot(V[:, :n], U)\n\n    return theta, U, resnorm", "response": "This function computes several kinds of Ritz pairs from an Arnoldi or Lanczos relation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef strakos(n, l_min=0.1, l_max=100, rho=0.9):\n    d = [l_min + (i-1)*1./(n-1)*(l_max-l_min)*(rho**(n-i))\n         for i in range(1, n+1)]\n    return numpy.diag(d)", "response": "Return the Strako\u0161 matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gap(lamda, sigma, mode='individual'):\n    # sanitize input\n    if numpy.isscalar(lamda):\n        lamda = [lamda]\n    lamda = numpy.array(lamda)\n    if numpy.isscalar(sigma):\n        sigma = [sigma]\n    sigma = numpy.array(sigma)\n\n    if not numpy.isreal(lamda).all() or not numpy.isreal(sigma).all():\n        raise ArgumentError('complex spectra not yet implemented')\n\n    if mode == 'individual':\n        return numpy.min(numpy.abs(numpy.reshape(lamda, (len(lamda), 1))\n                         - numpy.reshape(sigma, (1, len(sigma)))))\n    elif mode == 'interval':\n        lamda_min, lamda_max = numpy.min(lamda), numpy.max(lamda)\n        # determine all values in sigma<lamda_min or >lamda_max\n        sigma_lo = sigma <= lamda_min\n        sigma_hi = sigma >= lamda_max\n        # is a sigma value in lamda interval?\n        if not numpy.all(sigma_lo + sigma_hi):\n            return None\n        delta = numpy.Infinity\n        if numpy.any(sigma_lo):\n            delta = lamda_min - numpy.max(sigma[sigma_lo])\n        if numpy.any(sigma_hi):\n            delta = numpy.min([delta, numpy.min(sigma[sigma_hi]) - lamda_max])\n\n        return delta", "response": "Compute the spectral gap between two sets of real numbers lamda and sigma."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute relative residual norms from Hessenberg matrix.", "response": "def get_residual_norms(H, self_adjoint=False):\n    '''Compute relative residual norms from Hessenberg matrix.\n\n    It is assumed that the initial guess is chosen as zero.'''\n    H = H.copy()\n    n_, n = H.shape\n    y = numpy.eye(n_, 1, dtype=H.dtype)\n    resnorms = [1.]\n    for i in range(n_-1):\n        G = Givens(H[i:i+2, [i]])\n        if self_adjoint:\n            H[i:i+2, i:i+3] = G.apply(H[i:i+2, i:i+3])\n        else:\n            H[i:i+2, i:] = G.apply(H[i:i+2, i:])\n        y[i:i+2] = G.apply(y[i:i+2])\n        resnorms.append(numpy.abs(y[i+1, 0]))\n    if n_ == n:\n        resnorms.append(0.)\n    return numpy.array(resnorms)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply(self, x):\n        # make sure that x is a (N,*) matrix\n        if len(x.shape) != 2:\n            raise ArgumentError('x is not a matrix of shape (N,*)')\n        if self.beta == 0:\n            return x\n        return x - self.beta * self.v * numpy.dot(self.v.T.conj(), x)", "response": "Applies the Householder transformation efficiently to vector x."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding matrix representation of Householder transformation.", "response": "def matrix(self):\n        \"\"\"Build matrix representation of Householder transformation.\n\n        Builds the matrix representation\n        :math:`H = I - \\\\beta vv^*`.\n\n        **Use with care!** This routine may be helpful for testing purposes but\n        should not be used in production codes for high dimensions since\n        the resulting matrix is dense.\n        \"\"\"\n        n = self.v.shape[0]\n        return numpy.eye(n, n) - self.beta * numpy.dot(self.v, self.v.T.conj())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _apply_adj(self, a):\n        # is projection the zero operator?\n        if self.V.shape[1] == 0:\n            return numpy.zeros(a.shape)\n        '''Single application of the adjoint projection.'''\n        c = inner(self.V, a, ip_B=self.ip_B)\n        if self.Q is not None and self.R is not None:\n            c = self.Q.dot(scipy.linalg.solve_triangular(self.R.T.conj(), c,\n                                                         lower=True))\n        return self.W.dot(c)", "response": "Single application of the adjoint projection."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply(self, a, return_Ya=False):\n        # is projection the zero operator?\n        if self.V.shape[1] == 0:\n            Pa = numpy.zeros(a.shape)\n            if return_Ya:\n                return Pa, numpy.zeros((0, a.shape[1]))\n            return Pa\n        if return_Ya:\n            x, Ya = self._apply(a, return_Ya=return_Ya)\n        else:\n            x = self._apply(a)\n        for i in range(self.iterations-1):\n            z = a - x\n            w = self._apply(z)\n            x = x + w\n        if return_Ya:\n            return x, Ya\n        return x", "response": "r Apply the projection to an array."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying the complementary projection to an array.", "response": "def apply_complement(self, a, return_Ya=False):\n        \"\"\"Apply the complementary projection to an array.\n\n        :param z: array with ``shape==(N,m)``.\n\n        :return: :math:`P_{\\\\mathcal{Y}^\\\\perp,\\\\mathcal{X}}z =\n            z - P_{\\\\mathcal{X},\\\\mathcal{Y}^\\\\perp} z`.\n        \"\"\"\n        # is projection the zero operator? --> complement is identity\n        if self.V.shape[1] == 0:\n            if return_Ya:\n                return a.copy(), numpy.zeros((0, a.shape[1]))\n            return a.copy()\n        if return_Ya:\n            x, Ya = self._apply(a, return_Ya=True)\n        else:\n            x = self._apply(a)\n        z = a - x\n        for i in range(self.iterations-1):\n            w = self._apply(z)\n            z = z - w\n        if return_Ya:\n            return z, Ya\n        return z"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a LinearOperator corresponding to apply.", "response": "def operator(self):\n        \"\"\"Get a ``LinearOperator`` corresponding to apply().\n\n        :return: a LinearOperator that calls apply().\n        \"\"\"\n        # is projection the zero operator?\n        if self.V.shape[1] == 0:\n            N = self.V.shape[0]\n            return ZeroLinearOperator((N, N))\n        return self._get_operator(self.apply, self.apply_adj)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a LinearOperator corresponding to apply_complement.", "response": "def operator_complement(self):\n        \"\"\"Get a ``LinearOperator`` corresponding to apply_complement().\n\n        :return: a LinearOperator that calls apply_complement().\n        \"\"\"\n        # is projection the zero operator? --> complement is identity\n        if self.V.shape[1] == 0:\n            N = self.V.shape[0]\n            return IdentityLinearOperator((N, N))\n        return self._get_operator(self.apply_complement,\n                                  self.apply_complement_adj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef advance(self):\n        if self.iter >= self.maxiter:\n            raise ArgumentError('Maximum number of iterations reached.')\n        if self.invariant:\n            raise ArgumentError('Krylov subspace was found to be invariant '\n                                'in the previous iteration.')\n\n        N = self.V.shape[0]\n        k = self.iter\n\n        # the matrix-vector multiplication\n        Av = self.A * self.V[:, [k]]\n\n        if self.ortho == 'house':\n            # Householder\n            for j in range(k+1):\n                Av[j:] = self.houses[j].apply(Av[j:])\n                Av[j] *= numpy.conj(self.houses[j].alpha)\n            if k+1 < N:\n                house = House(Av[k+1:])\n                self.houses.append(house)\n                Av[k+1:] = house.apply(Av[k+1:]) * numpy.conj(house.alpha)\n                self.H[:k+2, [k]] = Av[:k+2]\n            else:\n                self.H[:k+1, [k]] = Av[:k+1]\n            # next line is safe due to the multiplications with alpha\n            self.H[k+1, k] = numpy.abs(self.H[k+1, k])\n            if self.H[k+1, k] / numpy.linalg.norm(self.H[:k+2, :k+1], 2)\\\n                    <= 1e-14:\n                self.invariant = True\n            else:\n                vnew = numpy.zeros((N, 1), dtype=self.dtype)\n                vnew[k+1] = 1\n                for j in range(k+1, -1, -1):\n                    vnew[j:] = self.houses[j].apply(vnew[j:])\n                self.V[:, [k+1]] = vnew * self.houses[-1].alpha\n        else:\n            # determine vectors for orthogonalization\n            start = 0\n\n            # Lanczos?\n            if self.ortho == 'lanczos':\n                start = k\n                if k > 0:\n                    self.H[k-1, k] = self.H[k, k-1]\n                    if self.M is not None \\\n                            and not isinstance(self.M, IdentityLinearOperator):\n                        Av -= self.H[k, k-1] * self.P[:, [k-1]]\n                    else:\n                        Av -= self.H[k, k-1] * self.V[:, [k-1]]\n\n            # (double) modified Gram-Schmidt\n            for reortho in range(self.reorthos+1):\n                # orthogonalize\n                for j in range(start, k+1):\n                    alpha = inner(self.V[:, [j]], Av, ip_B=self.ip_B)[0, 0]\n                    if self.ortho == 'lanczos':\n                        # check if alpha is real\n                        if abs(alpha.imag) > 1e-10:\n                            warnings.warn(\n                                'Iter {0}: abs(alpha.imag) = {1} > 1e-10. '\n                                'Is your operator self-adjoint in the '\n                                'provided inner product?'\n                                .format(self.iter, abs(alpha.imag)))\n                        alpha = alpha.real\n                    self.H[j, k] += alpha\n                    if self.M is not None:\n                        Av -= alpha * self.P[:, [j]]\n                    else:\n                        Av -= alpha * self.V[:, [j]]\n            if self.M is not None:\n                MAv = self.M * Av\n                self.H[k+1, k] = norm(Av, MAv, ip_B=self.ip_B)\n            else:\n                self.H[k+1, k] = norm(Av, ip_B=self.ip_B)\n            if self.H[k+1, k] / numpy.linalg.norm(self.H[:k+2, :k+1], 2)\\\n                    <= 1e-14:\n                self.invariant = True\n            else:\n                if self.M is not None:\n                    self.P[:, [k+1]] = Av / self.H[k+1, k]\n                    self.V[:, [k+1]] = MAv / self.H[k+1, k]\n                else:\n                    self.V[:, [k+1]] = Av / self.H[k+1, k]\n\n        # increase iteration counter\n        self.iter += 1", "response": "Advance the subspace by one iteration of Arnoldi."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, key):\n        '''Return timings for `key`. Returns 0 if not present.'''\n        if key in self and len(self[key]) > 0:\n            return min(self[key])\n        else:\n            return 0", "response": "Return timings for key. Returns 0 if not present. Returns 0 if not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_ops(self, ops):\n        '''Return timings for dictionary ops holding the operation names as\n        keys and the number of applications as values.'''\n        time = 0.\n        for op, count in ops.items():\n            time += self.get(op) * count\n        return time", "response": "Return timings for dictionary ops holding the operation names as\n        keys and the number of applications as values."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef distance(self, other):\n        '''Returns the distance to other (0 if intersection is nonempty).'''\n        if self & other:\n            return 0\n        return numpy.max([other.left-self.right, self.left-other.right])", "response": "Returns the distance to other."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning minimal positive value or None.", "response": "def min_pos(self):\n        '''Returns minimal positive value or None.'''\n        if self.__len__() == 0:\n            return ArgumentError('empty set has no minimum positive value.')\n        if self.contains(0):\n            return None\n        positive = [interval for interval in self.intervals\n                    if interval.left > 0]\n        if len(positive) == 0:\n            return None\n        return numpy.min(list(map(lambda i: i.left, positive)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef max_neg(self):\n        '''Returns maximum negative value or None.'''\n        if self.__len__() == 0:\n            return ArgumentError('empty set has no maximum negative value.')\n        if self.contains(0):\n            return None\n        negative = [interval for interval in self.intervals\n                    if interval.right < 0]\n        if len(negative) == 0:\n            return None\n        return numpy.max(list(map(lambda i: i.right, negative)))", "response": "Returns maximum negative value or None."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning minimum absolute value.", "response": "def min_abs(self):\n        '''Returns minimum absolute value.'''\n        if self.__len__() == 0:\n            return ArgumentError('empty set has no minimum absolute value.')\n        if self.contains(0):\n            return 0\n        return numpy.min([numpy.abs(val)\n                          for val in [self.max_neg(), self.min_pos()]\n                          if val is not None])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef max_abs(self):\n        '''Returns maximum absolute value.'''\n        if self.__len__() == 0:\n            return ArgumentError('empty set has no maximum absolute value.')\n        return numpy.max(numpy.abs([self.max(), self.min()]))", "response": "Returns maximum absolute value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_step(self, tol):\n        '''Return step at which bound falls below tolerance. '''\n        return 2 * numpy.log(tol/2.)/numpy.log(self.base)", "response": "Return step at which bound falls below tolerance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef minmax_candidates(self):\n        '''Get points where derivative is zero.\n\n        Useful for computing the extrema of the polynomial over an interval if\n        the polynomial has real roots. In this case, the maximum is attained\n        for one of the interval endpoints or a point from the result of this\n        function that is contained in the interval.\n        '''\n        from numpy.polynomial import Polynomial as P\n        p = P.fromroots(self.roots)\n        return p.deriv(1).roots()", "response": "Get points where derivative is zero."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef config():\n    alarm_day = alarm_time = alarm_attempts = song = []\n    for line in open(alarm_config, \"r\"):\n        line = line.lstrip()\n        if line.startswith(\"DAY\"):\n            alarm_day = line[4:].split()\n        if line.startswith(\"ALARM_TIME\"):\n            alarm_time = line[11:].split()\n        if line.startswith(\"ATTEMPTS\"):\n            alarm_attempts = line[9:].split()\n        if line.startswith(\"SONG\"):\n            song = line[5:].split()\n    if alarm_day == [\"today\"]:\n        alarm_day = time.strftime(\"%d\").split()\n    alarm_args = alarm_day + alarm_time + alarm_attempts + song\n    if alarm_args:\n        if len(alarm_args) == 4:\n            return alarm_args\n        else:\n            print(\"Error: config file: missing argument\")\n            sys.exit()\n    else:\n        print(\"Error: config file: missing argument\")\n        sys.exit()", "response": "Read the config file in the user s alarm directory and return the list of arguments that can be used to set up the alarm."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks for usage errors and return False if there are any errors", "response": "def errors(self):\n        \"\"\"\n        Check for usage errors\n        \"\"\"\n        try:\n            self.now = datetime.datetime.now()\n            if len(self.alarm_day) < 2 or len(self.alarm_day) > 2:\n                print(\"error: day: usage 'DD' such us '0%s' not '%s'\" % (\n                    self.alarm_day, self.alarm_day))\n                self.RUN_ALARM = False\n            if int(self.alarm_day) > calendar.monthrange(\n                    self.now.year, self.now.month)[1] or int(\n                        self.alarm_day) < 1:\n                print(\"error: day: out of range\")\n                self.RUN_ALARM = False\n            # compare alarm time with alarm pattern\n            if (len(self.alarm_time) != len(self.alarm_pattern) or\n                    len(self.alarm_time[0]) < 2 or\n                    len(self.alarm_time[0]) > 2 or\n                    len(self.alarm_time[1]) < 2 or len(self.alarm_time[1]) > 2):\n                print(\"error: time: usage '%s'\" % \":\".join(self.alarm_pattern))\n                self.RUN_ALARM = False\n            # compare if alarm hour or alarm minutes\n            # is within the range\n            if int(self.alarm_hour) not in range(0, 24):\n                print(\"error: hour: out of range\")\n                self.RUN_ALARM = False\n            if int(self.alarm_minutes) not in range(0, 60):\n                print(\"error: minutes: out of range\")\n                self.RUN_ALARM = False\n        except ValueError:\n            print(\"Usage '%s'\" % \":\".join(self.alarm_pattern))\n            self.RUN_ALARM = False\n        if not os.path.isfile(self.song):\n            print(\"error: song: file does not exist\")\n            self.RUN_ALARM = False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npositions text at x y.", "response": "def position(self, x, y, text):\n        \"\"\"\n            ANSI Escape sequences\n            http://ascii-table.com/ansi-escape-sequences.php\n        \"\"\"\n        sys.stdout.write(\"\\x1b7\\x1b[%d;%df%s\\x1b8\" % (x, y, text))\n        sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_best_subset(self, ritz):\n        '''Return candidate set with smallest goal functional.'''\n\n        # (c,\\omega(c)) for all considered subsets c\n        overall_evaluations = {}\n\n        def evaluate(_subset, _evaluations):\n            try:\n                _evaluations[_subset] = \\\n                    self.subset_evaluator.evaluate(ritz, _subset)\n            except utils.AssumptionError:\n                # no evaluation possible -> move on\n                pass\n\n        # I in algo\n        current_subset = frozenset()\n\n        # evaluate empty set\n        evaluate(current_subset, overall_evaluations)\n\n        while True:\n            # get a list of subset candidates for inclusion in current_subset\n            # (S in algo)\n            remaining_subset = set(range(len(ritz.values))) \\\n                .difference(current_subset)\n            subsets = self.subsets_generator.generate(ritz, remaining_subset)\n\n            # no more candidates to check?\n            if len(subsets) == 0:\n                break\n\n            # evaluate candidates\n            evaluations = {}\n            for subset in subsets:\n                eval_subset = current_subset.union(subset)\n                evaluate(eval_subset, evaluations)\n\n            if len(evaluations) > 0:\n                current_subset = min(evaluations, key=evaluations.get)\n            else:\n                # fallback: pick the subset with smallest residual\n                # note: only a bound is used if the subset consists of more\n                #       than one index.\n                resnorms = [numpy.sum(ritz.resnorms[list(subset)])\n                            for subset in subsets]\n                subset = subsets[numpy.argmin(resnorms)]\n                current_subset = current_subset.union(subset)\n\n            overall_evaluations.update(evaluations)\n\n        if len(overall_evaluations) > 0:\n        # if there was a successfull evaluation: pick the best one\n            selection = list(min(overall_evaluations,\n                             key=overall_evaluations.get))\n        else:\n            # otherwise: return empty list\n            selection = []\n\n        # debug output requested?\n        if self.print_results == 'number':\n            print('# of selected deflation vectors: {0}'\n                  .format(len(selection)))\n        elif self.print_results == 'values':\n            print('{0} Ritz values corresponding to selected deflation '\n                  .format(len(selection)) + 'vectors: '\n                  + (', '.join([str(el) for el in ritz.values[selection]])))\n        elif self.print_results == 'timings':\n            import operator\n            print('Timings for all successfully evaluated choices of '\n                  'deflation vectors with corresponding Ritz values:')\n            for subset, time in sorted(overall_evaluations.items(),\n                                       key=operator.itemgetter(1)):\n                print(' {0}s: '.format(time)\n                      + ', '.join([str(el)\n                                   for el in ritz.values[list(subset)]]))\n        elif self.print_results is None:\n            pass\n        else:\n            raise utils.ArgumentError(\n                'Invalid value `{0}` for argument `print_result`. '\n                .format(self.print_results)\n                + 'Valid are `None`, `number`, `values` and `timings`.')\n\n        return selection", "response": "Return candidate set with smallest goal functional."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_default_command(self, command):\n        cmd_name = command.name\n        self.add_command(command)\n        self.default_cmd_name = cmd_name", "response": "Sets a command function as the default command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the inner product that is implicitly used with the positive definite preconditioner M.", "response": "def get_ip_Minv_B(self):\n        '''Returns the inner product that is implicitly used with the positive\n        definite preconditioner ``M``.'''\n        if not isinstance(self.M, utils.IdentityLinearOperator):\n            if isinstance(self.Minv, utils.IdentityLinearOperator):\n                raise utils.ArgumentError(\n                    'Minv has to be provided for the evaluation of the inner '\n                    'product that is implicitly defined by M.')\n            if isinstance(self.ip_B, utils.LinearOperator):\n                return self.Minv*self.ip_B\n            else:\n                return lambda x, y: self.ip_B(x, self.Minv*y)\n        return self.ip_B"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_xk(self, yk):\n        '''Compute approximate solution from initial guess and approximate\n        solution of the preconditioned linear system.'''\n        if yk is not None:\n            return self.x0 + self.linear_system.Mr * yk\n        return self.x0", "response": "Compute approximate solution from initial guess and approximate\n        solution of the preconditioned linear system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _finalize_iteration(self, yk, resnorm):\n        '''Compute solution, error norm and residual norm if required.\n\n        :return: the residual norm or ``None``.\n        '''\n        self.xk = None\n        # compute error norm if asked for\n        if self.linear_system.exact_solution is not None:\n            self.xk = self._get_xk(yk)\n            self.errnorms.append(utils.norm(\n                self.linear_system.exact_solution - self.xk,\n                ip_B=self.linear_system.ip_B))\n\n        rkn = None\n\n        # compute explicit residual if asked for or if the updated residual\n        # is below the tolerance or if this is the last iteration\n        if self.explicit_residual or \\\n            resnorm/self.linear_system.MMlb_norm <= self.tol \\\n                or self.iter+1 == self.maxiter:\n            # compute xk if not yet done\n            if self.xk is None:\n                self.xk = self._get_xk(yk)\n\n            # compute residual norm\n            _, _, rkn = self.linear_system.get_residual(self.xk,\n                                                        compute_norm=True)\n\n            # store relative residual norm\n            self.resnorms.append(rkn/self.linear_system.MMlb_norm)\n\n            # no convergence?\n            if self.resnorms[-1] > self.tol:\n                # no convergence in last iteration -> raise exception\n                # (approximate solution can be obtained from exception)\n                if self.iter+1 == self.maxiter:\n                    self._finalize()\n                    raise utils.ConvergenceError(\n                        ('No convergence in last iteration '\n                         '(maxiter: {0}, residual: {1}).')\n                        .format(self.maxiter, self.resnorms[-1]), self)\n                # updated residual was below but explicit is not: warn\n                elif not self.explicit_residual \\\n                        and resnorm/self.linear_system.MMlb_norm <= self.tol:\n                    warnings.warn(\n                        'updated residual is below tolerance, explicit '\n                        'residual is NOT! (upd={0} <= tol={1} < exp={2})'\n                        .format(resnorm, self.tol, self.resnorms[-1]))\n        else:\n            # only store updated residual\n            self.resnorms.append(resnorm/self.linear_system.MMlb_norm)\n\n        return rkn", "response": "Compute solution error norm and residual norm if required."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef operations(nsteps):\n        '''Returns the number of operations needed for nsteps of GMRES'''\n        return {'A': 1 + nsteps,\n                'M': 2 + nsteps,\n                'Ml': 2 + nsteps,\n                'Mr': 1 + nsteps,\n                'ip_B': 2 + nsteps + nsteps*(nsteps+1)/2,\n                'axpy': 4 + 2*nsteps + nsteps*(nsteps+1)/2\n                }", "response": "Returns the number of operations needed for nsteps of GMRES"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsolving the given linear system with recycling.", "response": "def solve(self, linear_system,\n              vector_factory=None,\n              *args, **kwargs):\n        '''Solve the given linear system with recycling.\n\n        The provided `vector_factory` determines which vectors are used for\n        deflation.\n\n        :param linear_system: the :py:class:`~krypy.linsys.LinearSystem` that\n          is about to be solved.\n        :param vector_factory: (optional) see description in constructor.\n\n        All remaining arguments are passed to the ``DeflatedSolver``.\n\n        :returns: instance of ``DeflatedSolver`` which was used to obtain the\n          approximate solution. The approximate solution is available under the\n          attribute ``xk``.\n        '''\n\n        # replace linear_system with equivalent TimedLinearSystem on demand\n        if not isinstance(linear_system, linsys.TimedLinearSystem):\n            linear_system = linsys.ConvertedTimedLinearSystem(linear_system)\n\n        with self.timings['vector_factory']:\n            if vector_factory is None:\n                vector_factory = self._vector_factory\n\n            # construct vector_factory if strings are provided\n            if vector_factory == 'RitzApproxKrylov':\n                vector_factory = factories.RitzFactory(\n                    subset_evaluator=evaluators.RitzApproxKrylov()\n                    )\n            elif vector_factory == 'RitzAprioriCg':\n                vector_factory = factories.RitzFactory(\n                    subset_evaluator=evaluators.RitzApriori(\n                        Bound=utils.BoundCG\n                        )\n                    )\n            elif vector_factory == 'RitzAprioriMinres':\n                vector_factory = factories.RitzFactory(\n                    subset_evaluator=evaluators.RitzApriori(\n                        Bound=utils.BoundMinres\n                        )\n                    )\n\n            # get deflation vectors\n            if self.last_solver is None or vector_factory is None:\n                U = numpy.zeros((linear_system.N, 0))\n            else:\n                U = vector_factory.get(self.last_solver)\n\n        with self.timings['solve']:\n            # solve deflated linear system\n            self.last_solver = self._DeflatedSolver(linear_system,\n                                                    U=U,\n                                                    store_arnoldi=True,\n                                                    *args, **kwargs)\n\n        # return solver instance\n        return self.last_solver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef compute_hash(func, string):\n    h = func()\n    h.update(string)\n    return h.hexdigest()", "response": "compute hash of string using given hash function"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_local_serial():\n    ''' Retrieves the serial number from the executing host.\n        For example, 'C02NT43PFY14'\n    '''\n    return [x for x in [subprocess.Popen(\"system_profiler SPHardwareDataType |grep -v tray |awk '/Serial/ {print $4}'\", shell=True, stdout=subprocess.PIPE).communicate()[0].strip()] if x]", "response": "Retrieves the serial number from the executing host."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _estimate_eval_intervals(ritz, indices, indices_remaining,\n                                 eps_min=0,\n                                 eps_max=0,\n                                 eps_res=None):\n        '''Estimate evals based on eval inclusion theorem + heuristic.\n\n        :returns: Intervals object with inclusion intervals for eigenvalues\n        '''\n        if len(indices) == 0:\n            return utils.Intervals(\n                [utils.Interval(mu-resnorm, mu+resnorm)\n                 for mu, resnorm in zip(ritz.values, ritz.resnorms)])\n        if len(ritz.values) == len(indices):\n            raise utils.AssumptionError(\n                'selection of all Ritz pairs does not allow estimation.')\n        if eps_res is None:\n            eps_res = numpy.max(numpy.abs([eps_min, eps_max]))\n\n        # compute quantities for bound\n        delta_sel = numpy.linalg.norm(ritz.resnorms[indices], 2)\n        delta_non_sel = numpy.linalg.norm(ritz.resnorms[indices_remaining], 2)\n        delta = utils.gap(ritz.values[indices],\n                          ritz.values[indices_remaining])\n        mu_ints = utils.Intervals(\n            [utils.Interval(mu+eps_min, mu+eps_max)\n             for mu in ritz.values[indices]])\n        mu_min = mu_ints.min_abs()\n\n        # check gap assumption\n        #if delta_sel + delta_non_sel + eps_max - eps_min >= delta:\n        if delta_sel + eps_max - eps_min >= delta:\n            raise utils.AssumptionError(\n                'delta_sel + delta_non_sel + eps_max - eps_min >= delta'\n                + '({0} >= {1}'.format(\n                    delta_sel + delta_non_sel + eps_max - eps_min,\n                    delta)\n                )\n\n        # check assumption on mu_min\n        if mu_min == 0:\n            raise utils.AssumptionError('mu_min == 0 not allowed')\n\n        # compute eta\n        #eta = (delta_sel+eps_res)**2 * (\n        #    1/(delta-delta_non_sel-eps_max+eps_min)\n        #    + 1/mu_min\n        #    )\n        #left = - delta_non_sel + eps_min - eta\n        #right = delta_non_sel + eps_max + eta\n        eta = (delta_sel+eps_res)**2 * (\n            1/(delta-eps_max+eps_min)\n            + 1/mu_min\n            )\n        left = eps_min - eta\n        right = eps_max + eta\n\n        # return bound\n        return utils.Intervals(\n            [utils.Interval(mu+left, mu+right)\n             for mu in ritz.values[indices_remaining]])", "response": "Estimate evals based on eval inclusion theorem + heuristic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef correct(self, z):\n        '''Correct the given approximate solution ``z`` with respect to the\n        linear system ``linear_system`` and the deflation space defined by\n        ``U``.'''\n        c = self.linear_system.Ml*(\n            self.linear_system.b - self.linear_system.A*z)\n        c = utils.inner(self.W, c, ip_B=self.ip_B)\n        if self.Q is not None and self.R is not None:\n            c = scipy.linalg.solve_triangular(self.R, self.Q.T.conj().dot(c))\n        if self.WR is not self.VR:\n            c = self.WR.dot(scipy.linalg.solve_triangular(self.VR, c))\n        return z + self.W.dot(c)", "response": "Correct the given approximate solution z with respect to the\n        linear system and the deflation space defined by the\n        U."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef MAU(self):\n        '''Result of preconditioned operator to deflation space, i.e.,\n        :math:`MM_lAM_rU`.'''\n        if self._MAU is None:\n            self._MAU = self.linear_system.M * self.AU\n        return self._MAU", "response": "Result of preconditioned operator to deflation space i. e. M * A."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply_projection(self, Av):\n        '''Apply the projection and store inner product.\n\n        :param v: the vector resulting from an application of :math:`M_lAM_r`\n          to the current Arnoldi vector. (CG needs special treatment, here).\n        '''\n        PAv, UAv = self.projection.apply_complement(Av, return_Ya=True)\n        self.C = numpy.c_[self.C, UAv]\n        return PAv", "response": "Apply the projection and store inner product."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_initial_residual(self, x0):\n        '''Return the projected initial residual.\n\n        Returns :math:`MPM_l(b-Ax_0)`.\n        '''\n        if x0 is None:\n            Mlr = self.linear_system.Mlb\n        else:\n            r = self.linear_system.b - self.linear_system.A*x0\n            Mlr = self.linear_system.Ml*r\n\n        PMlr, self.UMlr = self.projection.apply_complement(Mlr, return_Ya=True)\n        MPMlr = self.linear_system.M*PMlr\n        MPMlr_norm = utils.norm(PMlr, MPMlr, ip_B=self.linear_system.ip_B)\n        return MPMlr, PMlr, MPMlr_norm", "response": "Return the projected initial residual."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nestimate time needed to run nsteps iterations with deflation Uses timings from linear_system.", "response": "def estimate_time(self, nsteps, ndefl, deflweight=1.0):\n        '''Estimate time needed to run nsteps iterations with deflation\n\n        Uses timings from :py:attr:`linear_system` if it is an instance of\n        :py:class:`~krypy.linsys.TimedLinearSystem`. Otherwise, an\n        :py:class:`~krypy.utils.OtherError`\n        is raised.\n\n        :param nsteps: number of iterations.\n        :param ndefl: number of deflation vectors.\n        :param deflweight: (optional) the time for the setup and application of\n          the projection for deflation is multiplied by this factor. This can\n          be used as a counter measure for the evaluation of Ritz vectors.\n          Defaults to 1.\n        '''\n        # get ops for nsteps of this solver\n        solver_ops = self.operations(nsteps)\n\n        # define ops for deflation setup + application with ndefl deflation\n        # vectors\n        proj_ops = {'A': ndefl,\n                    'M': ndefl,\n                    'Ml': ndefl,\n                    'Mr': ndefl,\n                    'ip_B': (ndefl*(ndefl+1)/2\n                             + ndefl**2 + 2*ndefl*solver_ops['Ml']),\n                    'axpy': (ndefl*(ndefl+1)/2 + ndefl*ndefl\n                             + (2*ndefl+2)*solver_ops['Ml'])\n                    }\n\n        # get timings from linear_system\n        if not isinstance(self.linear_system, linsys.TimedLinearSystem):\n            raise utils.RuntimeError(\n                'A `TimedLinearSystem` has to be used in order to obtain '\n                'timings.')\n        timings = self.linear_system.timings\n\n        return (timings.get_ops(solver_ops)\n                + deflweight*timings.get_ops(proj_ops))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_explicit_residual(self, indices=None):\n        '''Explicitly computes the Ritz residual.'''\n        ritz_vecs = self.get_vectors(indices)\n        return self._deflated_solver.linear_system.MlAMr * ritz_vecs \\\n            - ritz_vecs * self.values", "response": "Explicitly computes the Ritz residual."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_explicit_resnorms(self, indices=None):\n        '''Explicitly computes the Ritz residual norms.'''\n        res = self.get_explicit_residual(indices)\n\n        # apply preconditioner\n        linear_system = self._deflated_solver.linear_system\n        Mres = linear_system.M * res\n\n        # compute norms\n        resnorms = numpy.zeros(res.shape[1])\n        for i in range(resnorms.shape[0]):\n            resnorms[i] = utils.norm(res[:, [i]], Mres[:, [i]],\n                                     ip_B=linear_system.ip_B)\n        return resnorms", "response": "Explicitly computes the Ritz residual norms."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the IPython notebook display elements", "response": "def initialize_notebook():\n    \"\"\"Initialize the IPython notebook display elements\"\"\"\n    try:\n        from IPython.core.display import display, HTML\n    except ImportError:\n        print(\"IPython Notebook could not be loaded.\")\n\n    lib_js = ENV.get_template('ipynb_init_js.html')\n    lib_css = ENV.get_template('ipynb_init_css.html')\n\n    display(HTML(lib_js.render()))\n    display(HTML(lib_css.render()))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntransforming Pandas Timeseries into JSON format.", "response": "def transform_data(self, data):\n        '''Transform Pandas Timeseries into JSON format\n\n        Parameters\n        ----------\n        data: DataFrame or Series\n            Pandas DataFrame or Series must have datetime index\n\n        Returns\n        -------\n        JSON to object.json_data\n\n        Example\n        -------\n        >>>vis.transform_data(df)\n        >>>vis.json_data\n\n        '''\n\n        def type_check(value):\n            '''Type check values for JSON serialization. Native Python JSON\n            serialization will not recognize some Numpy data types properly,\n            so they must be explictly converted.'''\n            if pd.isnull(value):\n                return None\n            elif (isinstance(value, pd.tslib.Timestamp) or\n                  isinstance(value, pd.Period)):\n                return time.mktime(value.timetuple())\n            elif isinstance(value, (int, np.integer)):\n                return int(value)\n            elif isinstance(value, (float, np.float_)):\n                return float(value)\n            elif isinstance(value, str):\n                return str(value)\n            else:\n                return value\n\n        objectify = lambda dat: [{\"x\": type_check(x), \"y\": type_check(y)}\n                                 for x, y in dat.iteritems()]\n\n        self.raw_data = data\n        if isinstance(data, pd.Series):\n            data.name = data.name or 'data'\n            self.json_data = [{'name': data.name, 'data': objectify(data)}]\n        elif isinstance(data, pd.DataFrame):\n            self.json_data = [{'name': x[0], 'data': objectify(x[1])}\n                              for x in data.iteritems()]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_graph(self):\n        '''Build Rickshaw graph syntax with all data'''\n\n        # Set palette colors if necessary\n        if not self.colors:\n            self.palette = self.env.get_template('palette.js')\n            self.template_vars.update({'palette': self.palette.render()})\n            self.colors = {x['name']: 'palette.color()' for x in self.json_data}\n\n        template_vars = []\n        for index, dataset in enumerate(self.json_data):\n            group = 'datagroup' + str(index)\n            template_vars.append({'name': str(dataset['name']),\n                                  'color': self.colors[dataset['name']],\n                                  'data': 'json[{0}].data'.format(index)})\n\n        variables = {'dataset': template_vars, 'width': self.width,\n                     'height': self.height, 'render': self.renderer,\n                     'chart_id': self.chart_id}\n        if not self.y_zero:\n            variables.update({'min': \"min: 'auto',\"})\n\n        graph = self.env.get_template('graph.js')\n        self.template_vars.update({'graph': graph.render(variables)})", "response": "Build Rickshaw graph syntax with all data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_chart(self, html_path='index.html', data_path='data.json',\n                     js_path='rickshaw.min.js', css_path='rickshaw.min.css',\n                     html_prefix=''):\n        '''Save bearcart output to HTML and JSON.\n\n        Parameters\n        ----------\n        html_path: string, default 'index.html'\n            Path for html output\n        data_path: string, default 'data.json'\n            Path for data JSON output\n        js_path: string, default 'rickshaw.min.js'\n            If passed, the Rickshaw javascript library will be saved to the\n            path. The file must be named \"rickshaw.min.js\"\n        css_path: string, default 'rickshaw.min.css'\n            If passed, the Rickshaw css library will be saved to the\n            path. The file must be named \"rickshaw.min.css\"\n        html_prefix: Prefix path to be appended to all the other paths for file\n            creation, but not in the generated html file. This is needed if the\n            html file does not live in the same folder as the running python\n            script.\n\n        Returns\n        -------\n        HTML, JSON, JS, and CSS\n\n        Example\n        --------\n        >>>vis.create_chart(html_path='myvis.html', data_path='visdata.json'),\n                            js_path='rickshaw.min.js',\n                            cs_path='rickshaw.min.css')\n        '''\n\n        self.template_vars.update({'data_path': str(data_path),\n                                   'js_path': js_path,\n                                   'css_path': css_path,\n                                   'chart_id': self.chart_id,\n                                   'y_axis_id': self.y_axis_id,\n                                   'legend_id': self.legend_id,\n                                   'slider_id': self.slider_id})\n\n        self._build_graph()\n        html = self.env.get_template('bcart_template.html')\n        self.HTML = html.render(self.template_vars)\n\n        with open(os.path.join(html_prefix, html_path), 'w') as f:\n            f.write(self.HTML)\n\n        with open(os.path.join(html_prefix, data_path), 'w') as f:\n            json.dump(self.json_data, f, sort_keys=True, indent=4,\n                      separators=(',', ': '))\n\n        if js_path:\n            js = resource_string('bearcart', 'rickshaw.min.js')\n            with open(os.path.join(html_prefix, js_path), 'w') as f:\n                f.write(js)\n        if css_path:\n            css = resource_string('bearcart', 'rickshaw.min.css')\n            with open(os.path.join(html_prefix, css_path), 'w') as f:\n                    f.write(css)", "response": "Create a new chart and save it to the output file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the HTML representation for IPython.", "response": "def _repr_html_(self):\n        \"\"\"Build the HTML representation for IPython.\"\"\"\n        self.chart_id = '_'.join(['bearcart', uuid4().hex])\n        self.template_vars.update({'chart_id': self.chart_id,\n                                   'y_axis_id': self.y_axis_id,\n                                   'legend_id': self.legend_id,\n                                   'slider_id': self.slider_id,\n                                   'export_json': json.dumps(self.json_data)})\n\n        self._build_graph()\n        html = self.env.get_template('ipynb_repr.html')\n        return html.render(self.template_vars)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_image(self, image = None):\n        \n        if image is None or type(image) is not int:\n            raise KPError(\"Need a new image number\")\n        else:\n            self.image = image\n            self.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "This method is used to set the image number."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_url(self, url = None):\n                \n        if url is None or type(url) is not str:\n            raise KPError(\"Need a new image number\")\n        else:\n            self.url = url\n            self.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "This method is used to set the url of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_username(self, username = None):\n        \n        if username is None or type(username) is not str:\n            raise KPError(\"Need a new image number\")\n        else:\n            self.username = username\n            self.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "This method is used to set the username of the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_password(self, password = None):\n        \n        if password is None or type(password) is not str:\n            raise KPError(\"Need a new image number\")\n        else:\n            self.password = password\n            self.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "This method is used to set the password of the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_comment(self, comment = None):\n        \n        if comment is None or type(comment) is not str:\n            raise KPError(\"Need a new image number\")\n        else:\n            self.comment = comment\n            self.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "This method is used to set the comment of the image."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_buf(self):\n\n        with open(self.filepath, 'rb') as handler:\n            try:\n                buf = handler.read()\n                \n                # There should be a header at least\n                if len(buf) < 124:\n                    raise KPError('Unexpected file size. It should be more or'\n                                  'equal 124 bytes but it is '\n                                  '{0}!'.format(len(buf)))\n            except:\n                raise\n        return buf", "response": "Read the database file and return the buffer."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef close(self):\n        \n        if self.filepath is not None:\n            if path.isfile(self.filepath+'.lock'):\n                remove(self.filepath+'.lock')\n            self.filepath = None\n            self.read_only = False\n            self.lock()\n            return True\n        else:\n            raise KPError('Can\\'t close a not opened file')", "response": "This method closes the database correctly."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nunlocking the database. masterkey is needed.", "response": "def unlock(self, password = None, keyfile = None, buf = None):\n        \"\"\"Unlock the database.\n        \n        masterkey is needed.\n\n        \"\"\"\n\n        if ((password is None or password == \"\") and (keyfile is None or\n             keyfile == \"\")):\n            raise KPError(\"A password/keyfile is needed\")\n        elif ((type(password) is not str and password is not None) or\n              (type(keyfile) is not str and keyfile is not None)):\n            raise KPError(\"password/keyfile must be a string.\")\n        if keyfile == \"\":\n            keyfile = None\n        if password == \"\":\n            password = None\n        self.password = password\n        self.keyfile = keyfile\n        return self.load(buf)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef remove_group(self, group = None):\n\n        if group is None:\n            raise KPError(\"Need group to remove a group\")\n        elif type(group) is not v1Group:\n            raise KPError(\"group must be v1Group\")\n\n        children = []\n        entries = []\n        if group in self.groups:\n            # Save all children and entries to\n            # delete them later\n            children.extend(group.children)\n            entries.extend(group.entries)\n            # Finally remove group\n            group.parent.children.remove(group)\n            self.groups.remove(group)\n        else:\n            raise KPError(\"Given group doesn't exist\")\n        self._num_groups -= 1\n        \n        for i in children:\n            self.remove_group(i)\n        for i in entries:\n            self.remove_entry(i)     \n        return True", "response": "This method removes a group from the current object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving group to a new parent.", "response": "def move_group(self, group = None, parent = None):\n        \"\"\"Append group to a new parent.\n\n        group and parent must be v1Group-instances.\n\n        \"\"\"\n\n        if group is None or type(group) is not v1Group:\n            raise KPError(\"A valid group must be given.\")\n        elif parent is not None and type(parent) is not v1Group:\n            raise KPError(\"parent must be a v1Group.\")\n        elif group is parent:\n            raise KPError(\"group and parent must not be the same group\")\n        if parent is None:\n            parent = self.root_group\n        if group in self.groups:\n            self.groups.remove(group)\n            group.parent.children.remove(group)\n            group.parent = parent\n            if parent.children:\n                if parent.children[-1] is self.groups[-1]:\n                    self.groups.append(group)\n                else:\n                    new_index = self.groups.index(parent.children[-1]) + 1\n                    self.groups.insert(new_index, group)\n            else:\n                new_index = self.groups.index(parent) + 1\n                self.groups.insert(new_index, group)\n            parent.children.append(group)\n            if parent is self.root_group:\n                group.level = 0\n            else:\n                group.level = parent.level + 1\n            if group.children:\n                self._move_group_helper(group)\n            group.last_mod = datetime.now().replace(microsecond=0)\n            return True\n        else:\n            raise KPError(\"Didn't find given group.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_group_in_parent(self, group = None, index = None):\n        \n        if group is None or index is None:\n            raise KPError(\"group and index must be set\")\n        elif type(group) is not v1Group or type(index) is not int:\n            raise KPError(\"group must be a v1Group-instance and index \"\n                          \"must be an integer.\")\n        elif group not in self.groups:\n            raise KPError(\"Given group doesn't exist\")\n        elif index < 0 or index >= len(group.parent.children):\n            raise KPError(\"index must be a valid index if group.parent.groups\")\n        else:\n            group_at_index = group.parent.children[index]\n            pos_in_parent = group.parent.children.index(group) \n            pos_in_groups = self.groups.index(group)\n            pos_in_groups2 = self.groups.index(group_at_index)\n\n            group.parent.children[index] = group\n            group.parent.children[pos_in_parent] = group_at_index\n            self.groups[pos_in_groups2] = group\n            self.groups[pos_in_groups] = group_at_index\n            if group.children:\n                self._move_group_helper(group)\n            if group_at_index.children:\n                self._move_group_helper(group_at_index)\n            group.last_mod = datetime.now().replace(microsecond=0)\n            return True", "response": "Move group to another position in group s parent."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_entry(self, group = None, title = \"\", image = 1, url = \"\",\n                     username = \"\", password = \"\", comment = \"\",\n                     y = 2999, mon = 12, d = 28, h = 23, min_ = 59,\n                     s = 59):\n        \"\"\"This method creates a new entry.\n        \n        The group which should hold the entry is needed.\n\n        image must be an unsigned int >0, group a v1Group.\n        \n        It is possible to give an expire date in the following way:\n            - y is the year between 1 and 9999 inclusive\n            - mon is the month between 1 and 12\n            - d is a day in the given month\n            - h is a hour between 0 and 23\n            - min_ is a minute between 0 and 59\n            - s is a second between 0 and 59\n\n        The special date 2999-12-28 23:59:59 means that entry expires never.\n        \n        \"\"\"\n        \n        if (type(title) is not str or\n            type(image) is not int or image < 0 or\n            type(url) is not str or\n            type(username) is not str or\n            type(password) is not str or\n            type(comment) is not str or\n            type(y) is not int or\n            type(mon) is not int or\n            type(d) is not int or\n            type(h) is not int or\n            type(min_) is not int\n            or type(s) is not int or\n            type(group) is not v1Group):\n            raise KPError(\"One argument has not a valid type.\")\n        elif group not in self.groups:\n            raise KPError(\"Group doesn't exist.\")\n        elif (y > 9999 or y < 1 or mon > 12 or mon < 1 or d > 31 or d < 1 or\n              h > 23 or h < 0 or min_ > 59 or min_ < 0 or s > 59 or s < 0):\n            raise KPError(\"No legal date\")\n        elif (((mon == 1 or mon == 3 or mon == 5 or mon == 7 or mon == 8 or\n                mon == 10 or mon == 12) and d > 31) or\n               ((mon == 4 or mon == 6 or mon == 9 or mon == 11) and d > 30) or\n               (mon == 2 and d > 28)):\n            raise KPError(\"Given day doesn't exist in given month\")\n\n        Random.atfork()\n        uuid = Random.get_random_bytes(16)\n        entry = v1Entry(group.id_, group, image, title, url, username,\n                         password, comment, \n                         datetime.now().replace(microsecond = 0),\n                         datetime.now().replace(microsecond = 0),\n                         datetime.now().replace(microsecond = 0),\n                         datetime(y, mon, d, h, min_, s),\n                         uuid)\n        self.entries.append(entry)\n        group.entries.append(entry)\n        self._num_entries += 1\n        return True", "response": "This method creates a new entry in the system. It is possible to create a new entry in the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves an entry to another group.", "response": "def move_entry(self, entry = None, group = None):\n        \"\"\"Move an entry to another group.\n\n        A v1Group group and a v1Entry entry are needed.\n\n        \"\"\"\n\n        if entry is None or group is None or type(entry) is not v1Entry or \\\n            type(group) is not v1Group:\n            raise KPError(\"Need an entry and a group.\")\n        elif entry not in self.entries:\n            raise KPError(\"No entry found.\")\n        elif group in self.groups:\n            entry.group.entries.remove(entry)\n            group.entries.append(entry)\n            entry.group_id = group.id_\n            entry.group = group\n            return True\n        else:\n            raise KPError(\"No group found.\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_entry_in_group(self, entry = None, index = None):\n\n        if entry is None or index is None or type(entry) is not v1Entry \\\n            or type(index) is not int:\n            raise KPError(\"Need an entry and an index.\")\n        elif index < 0 or index > len(entry.group.entries)-1:\n            raise KPError(\"Index is not valid.\")\n        elif entry not in self.entries:\n            raise KPError(\"Entry not found.\")\n        \n        pos_in_group = entry.group.entries.index(entry)\n        pos_in_entries = self.entries.index(entry)\n        entry_at_index = entry.group.entries[index]\n        pos_in_entries2 = self.entries.index(entry_at_index)\n\n        entry.group.entries[index] = entry\n        entry.group.entries[pos_in_group] = entry_at_index\n        self.entries[pos_in_entries2] = entry\n        self.entries[pos_in_entries] = entry_at_index\n        return True", "response": "Move an entry to another position inside a group."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _transform_key(self, masterkey):\n\n        aes = AES.new(self._transf_randomseed, AES.MODE_ECB)\n\n        # Encrypt the created hash\n        for _ in range(self._key_transf_rounds):\n            masterkey = aes.encrypt(masterkey)\n\n        # Finally, hash it again...\n        sha_obj = SHA256.new()\n        sha_obj.update(masterkey)\n        masterkey = sha_obj.digest()\n        # ...and hash the result together with the randomseed\n        sha_obj = SHA256.new()\n        sha_obj.update(self._final_randomseed + masterkey)\n        return sha_obj.digest()", "response": "This method creates the key to decrypt the database and then hash it with the final random seed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_passwordkey(self):\n\n        sha = SHA256.new()\n        sha.update(self.password.encode('utf-8'))\n        return sha.digest()", "response": "This method just hashes self. password and returns the key."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_filekey(self):\n\n        if not os.path.exists(self.keyfile):\n            raise KPError('Keyfile not exists.')\n        try:\n            with open(self.keyfile, 'rb') as handler:\n                handler.seek(0, os.SEEK_END)\n                size = handler.tell()\n                handler.seek(0, os.SEEK_SET)\n\n                if size == 32:\n                    return handler.read(32)\n                elif size == 64:\n                    try:\n                        return binascii.unhexlify(handler.read(64))\n                    except (TypeError, binascii.Error):\n                        handler.seek(0, os.SEEK_SET)\n\n                sha = SHA256.new()\n                while True:\n                    buf = handler.read(2048)\n                    sha.update(buf)\n                    if len(buf) < 2048:\n                        break\n                return sha.digest()\n        except IOError as e:\n            raise KPError('Could not read file: %s' % e)", "response": "This method creates a key from a keyfile."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _cbc_decrypt(self, final_key, crypted_content):\n\n        # Just decrypt the content with the created key\n        aes = AES.new(final_key, AES.MODE_CBC, self._enc_iv)\n        decrypted_content = aes.decrypt(crypted_content)\n        padding = decrypted_content[-1]\n        if sys.version > '3':\n            padding = decrypted_content[-1]\n        else:\n            padding = ord(decrypted_content[-1])\n        decrypted_content = decrypted_content[:len(decrypted_content)-padding]\n        \n        return decrypted_content", "response": "This method decrypts the database content with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _read_group_field(self, group, levels, field_type, field_size,  \n                          decrypted_content):\n        \"\"\"This method handles the different fields of a group\"\"\"\n\n        if field_type == 0x0000:\n            # Ignored (commentar block)\n            pass\n        elif field_type == 0x0001:\n            group.id_ = struct.unpack('<I', decrypted_content[:4])[0]\n        elif field_type == 0x0002:\n            try:\n                group.title = struct.unpack('<{0}s'.format(field_size-1),\n                    decrypted_content[:field_size-1])[0].decode('utf-8')\n            except UnicodeDecodeError:\n                group.title = struct.unpack('<{0}s'.format(field_size-1),\n                    decrypted_content[:field_size-1])[0].decode('latin-1')\n            decrypted_content = decrypted_content[1:]\n        elif field_type == 0x0003:\n            group.creation = self._get_date(decrypted_content)\n        elif field_type == 0x0004:\n            group.last_mod = self._get_date(decrypted_content)\n        elif field_type == 0x0005:\n            group.last_access = self._get_date(decrypted_content)\n        elif field_type == 0x0006:\n            group.expire = self._get_date(decrypted_content)\n        elif field_type == 0x0007:\n            group.image = struct.unpack('<I', decrypted_content[:4])[0]\n        elif field_type == 0x0008:\n            level = struct.unpack('<H', decrypted_content[:2])[0]\n            group.level = level\n            levels.append(level)\n        elif field_type == 0x0009:\n            group.flags = struct.unpack('<I', decrypted_content[:4])[0]\n        elif field_type == 0xFFFF:\n            pass\n        else:\n            return False\n        return True", "response": "This method handles the fields of a group from the decrypted content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_group_tree(self, levels):\n\n        if levels[0] != 0:\n            raise KPError(\"Invalid group tree\")\n        \n        for i in range(len(self.groups)):\n            if(levels[i] == 0):\n                self.groups[i].parent = self.root_group\n                self.groups[i].index = len(self.root_group.children)\n                self.root_group.children.append(self.groups[i])\n                continue\n\n            j = i-1\n            while j >= 0:\n                if levels[j] < levels[i]:\n                    if levels[i]-levels[j] != 1:\n                        raise KPError(\"Invalid group tree\")\n                    \n                    self.groups[i].parent = self.groups[j]\n                    self.groups[i].index = len(self.groups[j].children)\n                    self.groups[i].parent.children.append(self.groups[i])\n                    break\n                if j == 0:\n                    raise KPError(\"Invalid group tree\")\n                j -= 1\n            \n        for e in range(len(self.entries)):\n            for g in range(len(self.groups)):\n                if self.entries[e].group_id == self.groups[g].id_:\n                    self.groups[g].entries.append(self.entries[e])\n                    self.entries[e].group = self.groups[g]\n                    # from original KeePassX-code, but what does it do?\n                    self.entries[e].index = 0           \n        return True", "response": "This method creates a group tree"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _save_entry_field(self, field_type, entry):\n\n        if field_type == 0x0000:\n            # Ignored\n            pass\n        elif field_type == 0x0001:\n            if entry.uuid is not None:\n                return (16, entry.uuid)\n        elif field_type == 0x0002:\n            if entry.group_id is not None:\n                return (4, struct.pack('<I', entry.group_id))\n        elif field_type == 0x0003:\n            if entry.image is not None:\n                return (4, struct.pack('<I', entry.image))\n        elif field_type == 0x0004:\n            if entry.title is not None:\n                return (len(entry.title.encode())+1,\n                         (entry.title+'\\0').encode())\n        elif field_type == 0x0005:\n            if entry.url is not None:\n                return (len(entry.url.encode())+1, (entry.url+'\\0').encode())\n        elif field_type == 0x0006:\n            if entry.username is not None:\n                return (len(entry.username.encode())+1,\n                        (entry.username+'\\0').encode())\n        elif field_type == 0x0007:\n            if entry.password is not None:\n                return (len(entry.password.encode())+1,\n                        (entry.password+'\\0').encode())\n        elif field_type == 0x0008:\n            if entry.comment is not None:\n                return (len(entry.comment.encode())+1,\n                       (entry.comment+'\\0').encode())\n        elif field_type == 0x0009:\n            if entry.creation is not None:\n                return (5, self._pack_date(entry.creation))\n        elif field_type == 0x000A:\n            if entry.last_mod is not None:\n                return (5, self._pack_date(entry.last_mod))\n        elif field_type == 0x000B:\n            if entry.last_access is not None:\n                return (5, self._pack_date(entry.last_access))\n        elif field_type == 0x000C:\n            if entry.expire is not None:\n                return (5, self._pack_date(entry.expire))\n        elif field_type == 0x000D:\n            if entry.binary_desc is not None:\n                return (len(entry.binary_desc.encode())+1,\n                        (entry.binary_desc+'\\0').encode())\n        elif field_type == 0x000E:\n            if entry.binary is not None:\n                return (len(entry.binary), entry.binary)\n        return False", "response": "This method packs a single entry field into a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getsecret(self, section, option, **kwargs):\n        # keyword-only arguments, vars and fallback are directly passed through\n        raw = kwargs.get('raw', False)\n        value = self.get(section, option, **kwargs)\n        if raw:\n            return value\n        return self.custodia_client.get_secret(value)", "response": "Get a secret from Custodia\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_plugin_class(menu, name):\n    group = 'custodia.{}'.format(menu)\n    eps = list(pkg_resources.iter_entry_points(group, name))\n    if len(eps) > 1:\n        raise ValueError(\n            \"Multiple entry points for {} {}: {}\".format(menu, name, eps))\n    elif len(eps) == 1:\n        # backwards compatibility with old setuptools\n        ep = eps[0]\n        if hasattr(ep, 'resolve'):\n            return ep.resolve()\n        else:\n            return ep.load(require=False)\n    elif '.' in name:\n        # fall back to old style dotted name\n        module, classname = name.rsplit('.', 1)\n        m = importlib.import_module(module)\n        return getattr(m, classname)\n    else:\n        raise ValueError(\"{}: {} not found\".format(menu, name))", "response": "Load Custodia plugin\nTaxonomy"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _load_plugins(config, cfgparser):\n    # set umask before any plugin gets a chance to create a file\n    os.umask(config['umask'])\n\n    for s in cfgparser.sections():\n        if s in {'ENV', 'global'}:\n            # ENV section is only used for interpolation\n            continue\n\n        if s.startswith('/'):\n            menu = 'consumers'\n            path_chain = s.split('/')\n            if path_chain[-1] == '':\n                path_chain = path_chain[:-1]\n            name = tuple(path_chain)\n        else:\n            if s.startswith('auth:'):\n                menu = 'authenticators'\n                name = s[5:]\n            elif s.startswith('authz:'):\n                menu = 'authorizers'\n                name = s[6:]\n            elif s.startswith('store:'):\n                menu = 'stores'\n                name = s[6:]\n            else:\n                raise ValueError('Invalid section name [%s].\\n' % s)\n\n        try:\n            config[menu][name] = _create_plugin(cfgparser, s, menu)\n        except Exception as e:\n            logger.debug(\"Plugin '%s' failed to load.\", name, exc_info=True)\n            raise RuntimeError(menu, name, e)\n\n    # 2nd initialization stage\n    for menu in ['authenticators', 'authorizers', 'consumers', 'stores']:\n        plugins = config[menu]\n        for name in sorted(plugins):\n            plugin = plugins[name]\n            plugin.finalize_init(config, cfgparser, context=None)", "response": "Load and initialize plugins\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, po):\n        name = po.name\n        typ = po.typ\n        default = po.default\n\n        handler = getattr(self, '_get_{}'.format(typ), None)\n        if handler is None:\n            raise ValueError(typ)\n        self.seen.add(name)\n\n        # pylint: disable=not-callable\n        if not self.parser.has_option(self.section, name):\n            if default is REQUIRED:\n                raise NameError(self.section, name)\n            if isinstance(default, INHERIT_GLOBAL):\n                return handler('global', name, default.default)\n            # don't return default here, give the handler a chance to modify\n            # the default, e.g. pw_uid with default='root' returns 0.\n\n        return handler(self.section, name, default)", "response": "Lookup value for a PluginOption instance returning the converted value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse(self, msg, name):\n\n        # On requests we imply 'simple' if there is no input message\n        if msg is None:\n            return\n\n        if not isinstance(msg, string_types):\n            raise InvalidMessage(\"The 'value' attribute is not a string\")\n\n        self.name = name\n        self.payload = msg\n        self.msg_type = 'simple'", "response": "Parses a simple message and sets the name and payload attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking and format -- server arg", "response": "def server_check(arg):\n    \"\"\"Check and format --server arg\n    \"\"\"\n    if arg.startswith(('http://', 'https://', 'http+unix://')):\n        return arg\n    if arg.startswith('./'):\n        arg = os.path.abspath(arg)\n    elif not arg.startswith('/'):\n        raise argparse.ArgumentTypeError(\n            'Unix socket path must start with / or ./')\n    # assume it is a unix socket\n    return 'http+unix://{}'.format(url_escape(arg, ''))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a Kerberos principal name into parts LogEntry and krb5_entry.", "response": "def krb5_unparse_principal_name(name):\n    \"\"\"Split a Kerberos principal name into parts\n\n    Returns:\n       * ('host', hostname, realm) for a host principal\n       * (servicename, hostname, realm) for a service principal\n       * (None, username, realm) for a user principal\n\n    :param text name: Kerberos principal name\n    :return: (service, host, realm) or (None, username, realm)\n    \"\"\"\n    prefix, realm = name.split(u'@')\n    if u'/' in prefix:\n        service, host = prefix.rsplit(u'/', 1)\n        return service, host, realm\n    else:\n        return None, prefix, realm"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a logger with custom exception method", "response": "def getLogger(name):\n    \"\"\"Create logger with custom exception() method\n    \"\"\"\n    def exception(self, msg, *args, **kwargs):\n        extra = kwargs.setdefault('extra', {})\n        extra['exc_fullstack'] = self.isEnabledFor(logging.DEBUG)\n        kwargs['exc_info'] = True\n        self.log(logging.ERROR, msg, *args, **kwargs)\n\n    logger = logging.getLogger(name)\n    logger.exception = six.create_bound_method(exception, logger)\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef exception(self, msg, *args, **kwargs):\n        extra = kwargs.setdefault('extra', {})\n        extra['exc_fullstack'] = self.isEnabledFor(logging.DEBUG)\n        kwargs['exc_info'] = True\n        self.log(logging.ERROR, msg, *args, **kwargs)", "response": "Like standard exception logger but only print stack in debug mode"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse the message and returns the payload.", "response": "def parse(self, msg, name):\n        \"\"\"Parses the message.\n\n        We check that the message is properly formatted.\n\n        :param msg: a json-encoded value containing a JWS or JWE+JWS token\n\n        :raises InvalidMessage: if the message cannot be parsed or validated\n\n        :returns: A verified payload\n        \"\"\"\n\n        try:\n            jtok = JWT(jwt=msg)\n        except Exception as e:\n            raise InvalidMessage('Failed to parse message: %s' % str(e))\n\n        try:\n            token = jtok.token\n            if isinstance(token, JWE):\n                token.decrypt(self.kkstore.server_keys[KEY_USAGE_ENC])\n                # If an encrypted payload is received then there must be\n                # a nested signed payload to verify the provenance.\n                payload = token.payload.decode('utf-8')\n                token = JWS()\n                token.deserialize(payload)\n            elif isinstance(token, JWS):\n                pass\n            else:\n                raise TypeError(\"Invalid Token type: %s\" % type(jtok))\n\n            # Retrieve client keys for later use\n            self.client_keys = [\n                JWK(**self._get_key(token.jose_header, KEY_USAGE_SIG)),\n                JWK(**self._get_key(token.jose_header, KEY_USAGE_ENC))]\n\n            # verify token and get payload\n            token.verify(self.client_keys[KEY_USAGE_SIG])\n            claims = json_decode(token.payload)\n        except Exception as e:\n            logger.debug('Failed to validate message', exc_info=True)\n            raise InvalidMessage('Failed to validate message: %s' % str(e))\n\n        check_kem_claims(claims, name)\n        self.name = name\n        self.payload = claims.get('value')\n        self.msg_type = 'kem'\n\n        return {'type': self.msg_type,\n                'value': {'kid': self.client_keys[KEY_USAGE_ENC].key_id,\n                          'claims': claims}}"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef instance_name(string):\n    invalid = ':/@'\n    if set(string).intersection(invalid):\n        msg = 'Invalid instance name {}'.format(string)\n        raise argparse.ArgumentTypeError(msg)\n    return string", "response": "Check for valid instance name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pipeline(self, config, request):\n        path_chain = request['path_chain']\n        if not path_chain or path_chain[0] != '':\n            # no path or not an absolute path\n            raise HTTPError(400)\n\n        # auth framework here\n        authers = config.get('authenticators')\n        if authers is None:\n            raise HTTPError(403)\n        valid_once = False\n        for auth in authers:\n            valid = authers[auth].handle(request)\n            if valid is False:\n                raise HTTPError(403)\n            elif valid is True:\n                valid_once = True\n        if valid_once is not True:\n            self.server.auditlog.svc_access(self.__class__.__name__,\n                                            log.AUDIT_SVC_AUTH_FAIL,\n                                            request['client_id'], 'No auth')\n            raise HTTPError(403)\n\n        # auhz framework here\n        authzers = config.get('authorizers')\n        if authzers is None:\n            raise HTTPError(403)\n        authz_ok = None\n        for authz in authzers:\n            valid = authzers[authz].handle(request)\n            if valid is True:\n                authz_ok = True\n            elif valid is False:\n                authz_ok = False\n                break\n        if authz_ok is not True:\n            self.server.auditlog.svc_access(self.__class__.__name__,\n                                            log.AUDIT_SVC_AUTHZ_FAIL,\n                                            request['client_id'],\n                                            path_chain)\n            raise HTTPError(403)\n\n        # Select consumer\n        trail = []\n        while path_chain:\n            if path_chain in config['consumers']:\n                con = config['consumers'][path_chain]\n                if len(trail) != 0:\n                    request['trail'] = trail\n                return con.handle(request)\n            trail.insert(0, path_chain[-1])\n            path_chain = path_chain[:-1]\n\n        raise HTTPError(404)", "response": "This function handles the processing of the request and returns the entry of the consumer entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef image_request(self, image, filename, params=None):\n        data = self._init_data(params)\n        response = requests.post(REQUESTS_URL, headers={\n            'Authorization': self.auth.authorize('POST', REQUESTS_URL, params),\n            'User-Agent': USER_AGENT,\n        }, data=data, files={'image_request[image]': (filename, image)})\n        return self._unwrap_error(response)", "response": "Send an image for classification."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remote_image_request(self, image_url, params=None):\n        data = self._init_data(params)\n        data['image_request[remote_image_url]'] = image_url\n        response = requests.post(REQUESTS_URL, headers={\n            'Authorization': self.auth.authorize('POST', REQUESTS_URL, data),\n            'User-Agent': USER_AGENT,\n        }, data=data)\n        return self._unwrap_error(response)", "response": "Send an image for classification to the CloudSight server."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the response from the cloudsight server.", "response": "def image_response(self, token):\n        \"\"\"\n        Contact the server and update the job status.\n        \n        After a request has been submitted, it usually takes 6-12 seconds to\n        receive a completed response. We recommend polling for a response every\n        1 second after a 4 second delay from the initial request, while the\n        status is :py:data:`cloudsight.STATUS_NOT_COMPLETED`.\n        :py:meth:`cloudsight.API.wait` method does this automatically.\n\n        :param token: Job token as returned from\n                        :py:meth:`cloudsight.API.image_request` or\n                        :py:meth:`cloudsight.API.remote_image_request`\n        \"\"\"\n        url = RESPONSES_URL + token\n        response = requests.get(url, headers={\n            'Authorization': self.auth.authorize('GET', url),\n            'User-Agent': USER_AGENT,\n        })\n        return self._unwrap_error(response)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait(self, token, timeout=DEFAULT_POLL_TIMEOUT):\n        delta = datetime.timedelta(seconds=timeout)\n        timeout_at = datetime.datetime.now() + delta\n        time.sleep(min(timeout, INITIAL_POLL_WAIT))\n        response = self.image_response(token)\n\n        while response['status'] == STATUS_NOT_COMPLETED \\\n              and datetime.datetime.now() < timeout_at:\n            time.sleep(1)\n            response = self.image_response(token)\n\n        return response", "response": "Wait for the job to be processed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncopy the bytecode of a module into a Python file.", "response": "def copy_magic_into_pyc(input_pyc, output_pyc,\n                        src_version, dest_version):\n    \"\"\"Bytecodes are the same except the magic number, so just change\n    that\"\"\"\n    (version, timestamp, magic_int,\n     co, is_pypy, source_size) = load_module(input_pyc)\n    assert version == float(src_version), (\n        \"Need Python %s bytecode; got bytecode for version %s\" %\n        (src_version, version))\n    magic_int = magic2int(magics[dest_version])\n    write_bytecode_file(output_pyc, co, magic_int)\n    print(\"Wrote %s\" % output_pyc)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntransform JUMP_IF_FALSE and POP_JUMP_IF_TRUE to JUMP_IF_FALSE and POP_JUMP_IF_TRUE to POP_TOP and POP_JUMP_IF_FALSE and POP_JUMP_IF_TRUE to JUMP_IF_TRUE and POP_JUMP_IF_FALSE and POP_JUMP_IF_TRUE to JUMP_IF_FALSE and POP_JUMP_IF_TRUE to POP_TOP.", "response": "def transform_26_27(inst, new_inst, i, n, offset,\n                    instructions, new_asm):\n    \"\"\"Change JUMP_IF_FALSE and JUMP_IF_TRUE to\n    POP_JUMP_IF_FALSE and POP_JUMP_IF_TRUE\"\"\"\n    if inst.opname in ('JUMP_IF_FALSE', 'JUMP_IF_TRUE'):\n        i += 1\n        assert i < n\n        assert instructions[i].opname == 'POP_TOP'\n        new_inst.offset = offset\n        new_inst.opname = (\n            'POP_JUMP_IF_FALSE' if inst.opname == 'JUMP_IF_FALSE' else 'POP_JUMP_IF_TRUE'\n        )\n        new_asm.backpatch[-1].remove(inst)\n        new_inst.arg = 'L%d' % (inst.offset + inst.arg + 3)\n        new_asm.backpatch[-1].add(new_inst)\n    else:\n        xlate26_27(new_inst)\n    return xdis.op_size(new_inst.opcode, opcode_27)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransforms a MAKEFUNCTION or MAKECLOSURE instruction into a LOAD_CONST instruction.", "response": "def transform_32_33(inst, new_inst, i, n, offset,\n                    instructions, new_asm):\n    \"\"\"MAKEFUNCTION adds another const. probably MAKECLASS as well\n    \"\"\"\n    add_size = xdis.op_size(new_inst.opcode, opcode_33)\n    if inst.opname in ('MAKE_FUNCTION','MAKE_CLOSURE'):\n        # Previous instruction should be a load const which\n        # contains the name of the function to call\n        prev_inst = instructions[i-1]\n        assert prev_inst.opname == 'LOAD_CONST'\n        assert isinstance(prev_inst.arg, int)\n\n        # Add the function name as an additional LOAD_CONST\n        load_fn_const = Instruction()\n        load_fn_const.opname = 'LOAD_CONST'\n        load_fn_const.opcode = opcode_33.opmap['LOAD_CONST']\n        load_fn_const.line_no = None\n        prev_const = new_asm.code.co_consts[prev_inst.arg]\n        if hasattr(prev_const, 'co_name'):\n            fn_name = new_asm.code.co_consts[prev_inst.arg].co_name\n        else:\n            fn_name = 'what-is-up'\n        const_index = len(new_asm.code.co_consts)\n        new_asm.code.co_consts = list(new_asm.code.co_consts)\n        new_asm.code.co_consts.append(fn_name)\n        load_fn_const.arg = const_index\n        load_fn_const.offset = offset\n        load_fn_const.starts_line = False\n        load_fn_const.is_jump_target = False\n        new_asm.code.instructions.append(load_fn_const)\n        load_const_size = xdis.op_size(load_fn_const.opcode, opcode_33)\n        add_size += load_const_size\n        new_inst.offset = offset + add_size\n        pass\n    return add_size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform_33_32(inst, new_inst, i, n, offset,\n                    instructions, new_asm):\n    \"\"\"MAKE_FUNCTION, and MAKE_CLOSURE have an additional LOAD_CONST of a name\n    that are not in Python 3.2. Remove these.\n    \"\"\"\n    add_size = xdis.op_size(new_inst.opcode, opcode_33)\n    if inst.opname in ('MAKE_FUNCTION','MAKE_CLOSURE'):\n        # Previous instruction should be a load const which\n        # contains the name of the function to call\n        prev_inst = instructions[i-1]\n        assert prev_inst.opname == 'LOAD_CONST'\n        assert isinstance(prev_inst.arg, int)\n        assert len(instructions) > 2\n        assert len(instructions) > 2\n        prev_inst2 = instructions[i-2]\n        assert prev_inst2.opname == 'LOAD_CONST'\n        assert isinstance(prev_inst2.arg, int)\n\n        # Remove the function name as an additional LOAD_CONST\n        prev2_const = new_asm.code.co_consts[prev_inst.arg]\n        assert hasattr(prev2_const, 'co_name')\n        new_asm.code.instructions = new_asm.code.instructions[:-1]\n        load_const_size = xdis.op_size(prev_inst.opcode, opcode_33)\n        add_size -= load_const_size\n        new_inst.offset = offset - add_size\n        return -load_const_size\n    return 0", "response": "Transform a LOAD_CONST instruction to the instruction of the LOAD_CONST instruction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a Python bytecode from one version to another.", "response": "def main(conversion_type, input_pyc, output_pyc):\n    \"\"\"Convert Python bytecode from one version to another.\n\n    INPUT_PYC contains the input bytecode path name\n    OUTPUT_PYC  contians the output bytecode path name if supplied\n    The --conversion type option specifies what conversion to do.\n\n    Note: there are a very limited set of conversions currently supported.\n    Help out and write more!\"\"\"\n\n    shortname = osp.basename(input_pyc)\n    if shortname.endswith('.pyc'):\n        shortname = shortname[:-4]\n    src_version = conversion_to_version(conversion_type, is_dest=False)\n    dest_version = conversion_to_version(conversion_type, is_dest=True)\n    if output_pyc is None:\n        output_pyc = \"%s-%s.pyc\" % (shortname, dest_version)\n\n    if conversion_type in UPWARD_COMPATABLE:\n        copy_magic_into_pyc(input_pyc, output_pyc, src_version, dest_version)\n        return\n    temp_asm = NamedTemporaryFile('w', suffix='.pyasm', prefix=shortname, delete=False)\n    (filename, co, version,\n     timestamp, magic_int) = disassemble_file(input_pyc, temp_asm, asm_format=True)\n    temp_asm.close()\n    assert version == float(src_version), (\n        \"Need Python %s bytecode; got bytecode for version %s\" %\n        (src_version, version))\n    asm = asm_file(temp_asm.name)\n    new_asm = transform_asm(asm, conversion_type, src_version, dest_version)\n    os.unlink(temp_asm.name)\n    write_pycfile(output_pyc, new_asm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate fingerprints of the input string", "response": "def generate(self, str=None, fpath=None):\n        \"\"\"generates fingerprints of the input. Either provide `str` to compute fingerprint directly from your string or `fpath` to compute fingerprint from the text of the file. Make sure to have your text decoded in `utf-8` format if you pass the input string.\n\n        Args:\n            str (Optional(str)): string whose fingerprint is to be computed.\n            fpath (Optional(str)): absolute path of the text file whose fingerprint is to be computed.\n\n        Returns:\n            List(int): fingerprints of the input.\n\n        Raises:\n            FingerprintException: If the input string do not meet the requirements of parameters provided for fingerprinting.\n        \"\"\"\n        self.prepare_storage()\n        self.str = self.load_file(fpath) if fpath else self.sanitize(str)\n        self.validate_config()\n        self.generate_kgrams()\n        self.hash_kgrams()\n        self.generate_fingerprints()\n        return self.fingerprints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new Python bytecode from a Python assembly file.", "response": "def main(pyc_file, asm_path):\n    \"\"\"\n    Create Python bytecode from a Python assembly file.\n\n    ASM_PATH gives the input Python assembly file. We suggest ending the\n    file in .pyc\n\n    If --pyc-file is given, that indicates the path to write the\n    Python bytecode. The path should end in '.pyc'.\n\n    See https://github.com/rocky/python-xasm/blob/master/HOW-TO-USE.rst\n    for how to write a Python assembler file.\n    \"\"\"\n    if os.stat(asm_path).st_size == 0:\n        print(\"Size of assembly file %s is zero\" % asm_path)\n        sys.exit(1)\n    asm = asm_file(asm_path)\n\n    if not pyc_file and asm_path.endswith('.pyasm'):\n        pyc_file = asm_path[:-len('.pyasm')] + '.pyc'\n\n    write_pycfile(pyc_file, asm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary that will include the sha256 signature of the request s body.", "response": "def payload_body(req):\n    \"\"\"\n    A generator that will include the sha256 signature of the request's body\n    in the JWT payload.  This is only done if the request could have a body:\n    if the method is POST or PUT.\n\n    >>> auth = JWTAuth('secret')\n    >>> auth.add_field('body', payload_body)\n    \"\"\"\n    to_hash = req.body if type(req.body) is bytes else req.body.encode('utf-8')\n\n    if req.method in ('POST', 'PUT'):\n        return {\n                'hash': hashlib.sha256(to_hash).hexdigest(),\n                'alg': 'sha256',\n                }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding the standard exp field to the payload.", "response": "def expire(self, secs):\n        \"\"\"\n        Adds the standard 'exp' field, used to prevent replay attacks.\n\n        Adds the 'exp' field to the payload.  When a request is made,\n        the field says that it should expire at now + `secs` seconds.\n\n        Of course, this provides no protection unless the server reads\n        and interprets this field.\n        \"\"\"\n        self.add_field('exp',\n                lambda req: int(time.time() + secs))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a payload for the given request.", "response": "def _generate(self, request):\n        \"\"\"\n        Generate a payload for the given request.\n        \"\"\"\n        payload = {}\n        for field, gen in self._generators.items():\n            value = None\n            if callable(gen):\n                value = gen(request)\n            else:\n                value = gen\n\n            if value:\n                payload[field] = value\n        return payload"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tt2nav(toctree, klass=None, appendix=None, divider=False):\n    \n    tt = toctree\n    divider = '<li class=\"divider\"></li>' if divider else ''\n    \n    # Append anything just before the closing </ul>.\n    if appendix:\n        tt = re.sub(r'(</ul>$)', r'{}\\1'.format(appendix), tt)\n    \n    # Add class attribute to all <ul> elements.\n    tt = re.sub(r'<ul>', r'<ul class=\"\">', tt)\n    \n    # Add class to first <ul> tag.\n    if klass:\n        tt = re.sub(r'(^<ul[\\s\\w-]+class=\")', r'\\1{} '.format(klass), tt)\n    \n    # Add class \"active\" to all <li> tags with \"current\" class.\n#    tt = re.sub(r'(<li[\\s\\w-]+class=\"[^\"]*current)([^\"]*\")', r'\\1 active\\2', tt)\n    \n    # Match each <li> that contains <ul>.\n    pattern = r'(<li[\\s\\w-]+class=\")([^>]*>[^<]*<a[^>]*>[^<]*</a>[^<]*<ul[\\s\\w]+class=\")'\n    \n    # Inject the classes.\n    replace = r'{}\\1has-dropdown \\2dropdown '.format(divider)\n    \n    # Do the replace and return.\n    return re.sub(pattern, replace, tt)", "response": "Convert a toctree to a nav string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngives a shell script, returns a list of shell variable names. Note: this method executes the script, so beware if it contains side-effects. :param script_path: Path the a shell script :type script_path: str or unicode :param ignore: variable names to ignore. By default we ignore variables that env injects into the script's environment. See IGNORE_DEFAULT. :type ignore: iterable :return: Key value pairs representing the environment variables defined in the script. :rtype: list", "response": "def list_vars(script_path, ignore=IGNORE_DEFAULT):\n    \"\"\"\n    Given a shell script, returns a list of shell variable names.\n    Note: this method executes the script, so beware if it contains side-effects.\n    :param script_path: Path the a shell script\n    :type script_path: str or unicode\n    :param ignore: variable names to ignore.  By default we ignore variables\n                    that env injects into the script's environment.\n                    See IGNORE_DEFAULT.\n    :type ignore: iterable\n    :return: Key value pairs representing the environment variables defined\n            in the script.\n    :rtype: list\n    \"\"\"\n    if path.isfile(script_path):\n        input = (\"\"\". \"%s\"; env | awk -F = '/[a-zA-Z_][a-zA-Z_0-9]*=/ \"\"\" % script_path +\n                 \"\"\"{ if (!system(\"[ -n \\\\\"${\" $1 \"}\\\\\" ]\")) print $1 }'\"\"\")\n        cmd = \"env -i bash\".split()\n\n        p = Popen(cmd, stdout=PIPE, stdin=PIPE, stderr=PIPE)\n        stdout_data, stderr_data = p.communicate(input=input)\n        if stderr_data:\n            raise ShellScriptException(script_path, stderr_data)\n        else:\n            lines = stdout_data.split()\n            return [elt for elt in lines if elt not in ignore]\n    else:\n        raise _noscripterror(script_path)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_vars(script_path, ignore=IGNORE_DEFAULT):\n\n    # Iterate over every var independently:\n    # This is slower than using env, but enables us to capture multiline variables\n    return dict((var, get_var(script_path, var)) for var in list_vars(script_path))", "response": "Gets the values of environment variables defined in a shell script."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_var(script_path, var):\n    if path.isfile(script_path):\n        input = '. \"%s\"; echo -n \"$%s\"\\n'% (script_path, var)\n        pipe = Popen([\"bash\"],  stdout=PIPE, stdin=PIPE, stderr=PIPE)\n        stdout_data, stderr_data = pipe.communicate(input=input)\n        if stderr_data:\n            raise ShellScriptException(script_path, stderr_data)\n        else:\n            return stdout_data\n    else:\n        raise _noscripterror(script_path)", "response": "Returns the value of an environment variable in a sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_current_price(fsyms, tsyms, e='all', try_conversion=True, full=False, \r\n                     format='raw'):\r\n\t\"\"\"Get latest trading price or full trading information in display or raw \r\n\tformat for the specified FROM/TO currency pairs.\r\n\r\n\tArgs:\r\n\t\tfsyms: Single string or list of FROM symbols.\r\n\t\ttsyms: Single string or list of TO symbols.\r\n\t\te: Default returns average price across all exchanges. Can be set to the\r\n\t\t\tname of a single exchange.\r\n\t\ttry_conversion: If the crypto does not trade directly into the toSymbol \r\n\t\t\trequested, BTC will be used for conversion. If set to false, it will \r\n\t\t\ttry to get values without using any conversion at all.\r\n\t\tfull: Default of False returns only the latest price. True returns the \r\n\t\t\tfollowing dictionary structure containing the full trading info:\r\n\t\tformat: Default returns the 'RAW' format. Can be set to 'DISPLAY' \r\n\t\t\tformat.\r\n\tReturns:\r\n\t\tReturns a dictionary containing the latest price pairs if full is set to\r\n\t\tfalse:\r\n\t\t\r\n\t\t{fsym1: {tsym1: ..., tsym2:..., ...},\r\n\t\t fsym2: {...},\r\n\t\t ...}\r\n\r\n\t\tor full trading info dictionaries for all the price pairs in the other\r\n\t\tcase:\r\n\r\n\t\t{fsym1: {tsym1: {'CHANGE24HOUR': ...,\r\n\t\t \t\t\t\t 'CHANGEPCT24HOUR': ...,\r\n \t                     'FLAGS': ...,\r\n\t\t\t\t \t     'FROMSYMBOL': ...,\r\n\t\t\t\t\t \t 'HIGH24HOUR': ...,\r\n\t\t\t\t\t \t 'LASTMARKET': ...,\r\n\t\t\t\t\t \t 'LASTTRADEID': ...,\r\n\t\t\t\t\t \t 'LASTUPDATE': ..., \r\n\t\t\t\t\t \t 'LASTVOLUME': ...,\r\n\t\t\t\t\t \t 'LASTVOLUMETO': ...,\r\n\t\t\t\t\t \t 'LOW24HOUR': ...,\r\n\t\t\t\t\t \t 'MARKET' ...,\r\n\t\t\t\t\t\t 'MKTCAP': ...,\r\n\t\t\t\t\t\t 'OPEN24HOUR': ...,\r\n\t\t\t\t\t\t 'PRICE': ...,\r\n\t\t\t\t\t \t 'SUPPLY': ...,\r\n\t\t\t\t\t \t 'TOSYMBOL': ...,\r\n\t\t\t\t\t \t 'TYPE': ..., \r\n\t\t\t\t\t \t 'VOLUME24HOUR': ...,\r\n\t\t\t\t\t \t 'VOLUME24HOURTO': ...},\r\n\t\t\t\t tsym2: ..., ...},\r\n\t\tfsym2: {...},\r\n\t\t...}\r\n\t\"\"\"\r\n\r\n\t# select API function based on 'full' parameter value\r\n\tif not full:\r\n\t\tfunc = 'pricemulti'\r\n\telse:\r\n\t\tfunc = 'pricemultifull'\r\n\r\n\t# convert single fsym and tsym input to single element lists\r\n\tif not isinstance(fsyms, list):\r\n\t\tfsyms = [fsyms]\r\n\tif not isinstance(tsyms, list):\r\n\t\ttsyms = [tsyms]\r\n\r\n\t# load data\r\n\turl = build_url(func, fsyms=fsyms, tsyms=tsyms, e=e, \r\n\t                try_conversion=try_conversion)\r\n\tdata = load_data(url)\r\n\r\n\t#  select right format to return for full requests\r\n\tif full and format == 'raw':\r\n\t\tdata = data['RAW']\r\n\telif full and format == 'display':\r\n\t\tdata = data['DISPLAY']\r\n\r\n\treturn data", "response": "Returns the current trading price for the specified FROM and TO currency pairs."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the latest average trading info of the requested pair as a volume weighted by the markets requested.", "response": "def get_current_trading_info(fsym, tsym, markets='all', try_conversion=True, \r\n                       \t\t format='raw'):\r\n\t\"\"\"\r\n\tGet the latest trading info of the requested pair as a volume weighted \r\n\taverage based on the markets requested.\r\n\t\r\n\tArgs:\r\n\t\tfsym: FROM symbol.\r\n\t\ttsym: TO symbol.\r\n\t\tmarkets: List containing the market names.\r\n\t\ttry_conversion: If the crypto does not trade directly into the toSymbol \r\n\t\t\trequested, BTC will be used for conversion. If set to false, it will \r\n\t\t\ttry to get values without using any conversion at all.\r\n\t\tformat: Default returns the 'RAW' format. Can be set to 'DISPLAY' \r\n\t\t\tformat.\r\n\r\n\tReturns:\r\n\t\tThe returned latest average trading information dictionary contains\r\n\t\tthe following key value pairs:\r\n\t\t\r\n\t\t{'PRICE': ...,\r\n\t\t 'LASTVOLUMETO': ...,\r\n\t\t 'TOSYMBOL': ...,\r\n\t\t 'LOW24HOUR': ...,\r\n\t\t 'CHANGE24HOUR': ...,\r\n\t\t 'FROMSYMBOL': ...,\r\n\t\t 'FLAGS': ...,\r\n\t\t 'VOLUME24HOUR': ...,\r\n\t\t 'HIGH24HOUR': ...,\r\n\t\t 'LASTUPDATE': ...,\r\n\t\t 'VOLUME24HOURT': ...,\r\n\t\t 'LASTMARKET': ...,\r\n\t\t 'CHANGEPCT24HOUR': ...,\r\n\t\t 'OPEN24HOUR': ...,\r\n\t\t 'MARKET': ...,\r\n\t\t 'LASTTRADEID': ...,\r\n\t\t 'LASTVOLUME': ...}\r\n\t\"\"\"\r\n\t\r\n\t# load data \r\n\turl = build_url('generateAvg', fsym=fsym, tsym=tsym, markets=markets,\r\n\t                try_conversion=try_conversion)\r\n\tdata = load_data(url)\r\n\r\n\t# select format to return\r\n\tif format == 'raw':\r\n\t\tdata = data['RAW']\r\n\telif format == 'display':\r\n\t\tdata = data['DISPLAY']\r\n\r\n\treturn {fsym: {tsym: data}}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the current days average price of a currency pair.", "response": "def get_day_average_price(fsym, tsym, e='all', try_conversion=True, \r\n                    \t  avg_type='HourVWAP', utc_hour_diff=0):\r\n\t\"\"\"\r\n\tGet the current days average price of a currency pair.\r\n\r\n\tArgs:\r\n\t\tfsym: FROM symbol.\r\n\t\ttsym: TO symbol.\r\n\t\te: Default returns average price across all exchanges. Can be set to the\r\n\t\t\tname of a single exchange.\r\n\t\ttry_conversion: If the crypto does not trade directly into the toSymbol \r\n\t\t\trequested, BTC will be used for conversion. If set to false, it will \r\n\t\t\ttry to get values without using any conversion at all.\r\n\t\tavg_type: 'HourVWAP' returns a volume weighted average of the hourly\r\n\t\t\tclose price. The other option 'MidHighLow' gives the average between\r\n\t\t\tthe 24 hour high and low.\r\n\t\tutc_hour_diff: Pass hour difference to UTC for different time zone.\r\n\r\n\t\t# add 'toTs' parameter\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\r\n\tReturns:\r\n\t\tReturns a price dictionairy containing the current days average price as \r\n\t\tfloat.\r\n\r\n\t\t{fsym: {tsym: price}}\r\n\t\"\"\"\r\n\r\n\t# load data\r\n\turl = build_url('dayAvg', fsym=fsym, tsym=tsym, e=e, \r\n\t                try_conversion=try_conversion, avg_type=avg_type, \r\n\t                utc_hour_diff=utc_hour_diff)\r\n\tdata = load_data(url)\r\n\r\n\t# remove 'ConversionType' information\r\n\tdel data['ConversionType']\r\n\t\r\n\treturn {fsym: data}"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_historical_eod_price(fsym, tsyms, date, e='all', try_conversion=True):\r\n\r\n\t# convert single fsym and tsym input to single element lists\r\n\tif not isinstance(tsyms, list):\r\n\t\ttsyms = [tsyms]\r\n\r\n\t# convert date to timestamp\r\n\tts = date_to_timestamp(date)\r\n\r\n\t# load data\r\n\turl = build_url(\"pricehistorical\", fsym=fsym, tsyms=tsyms, ts=ts, \r\n\t                e=e, try_conversion=try_conversion)\r\n\tdata = load_data(url)\r\n\r\n\treturn data", "response": "Get the end of day price for a given cryptocurrency in any other currency for the \r."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_historical_data(fsym, tsym, freq, info='full', e='all', \r\n                        try_conversion=True, aggregate=1, limit=1440, \r\n                        to_ts=False):\r\n\t\"\"\"Get minute-by-minute historical price and volume information for \r\n\tthe requested currency pair. Available data is limited to the last 7 days.\r\n\t\r\n\tArgs:\r\n\t\tfsym: FROM symbol.\r\n\t\ttsym: TO symbol.\r\n\t\tfreq: Frequency of the data. Can be set to 'minute', 'hour' or 'day'.\r\n\t\tinfo: Select price or volume information to return. Default of 'full'\r\n\t\t\treturns all of them. Can be set to 'high', 'low', 'open', 'close', \r\n\t\t\t'volumefrom', and 'volumeto' or a list containing several of those\r\n\t\t\tvalues.\r\n\t\te: Default returns average price across all exchanges. Can be set to the\r\n\t\t   name of a single exchange.\r\n\t\ttry_conversion: If the crypto does not trade directly into the toSymbol \r\n\t\t\trequested, BTC will be used for conversion. If set to false, it will \r\n\t\t\ttry to get values without using any conversion at all.\r\n\t\taggregate: Aggregates the minute prices into bins of the specified size.\r\n\t\tlimit: Number of minute prices. The limit settings depend on the freq\r\n\t\t\tselected:\r\n\t\t\t\tminute: default = 1440, min = 1, max = 2000\r\n\t\t\t\thour: default = 168, min = 1, max 2000\r\n\t\t\t\tday: default = 30, min = 1, max 2000\r\n\t\t\t\r\n\t\t\tUsing aggregate reduces the maximum number of points that can be \r\n\t\t\treturned by a factor equal to the chosen bin size.\r\n\t\t\r\n\t\t# add 'toTs' parameter\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\t######################\r\n\t\r\n\tReturns:\r\n\t\tList of dictionairies containing the price and volume information for\r\n\t\teach requested tick.\r\n\r\n\t\t[{'time': ..., 'close': ..., 'high': ..., 'low': ..., 'open': ...,\r\n\t\t  'volumefrom': ..., 'volumeto': ...},\r\n\t\t  {...},\r\n\t\t ...]\r\n\t\"\"\"\r\n\r\n\t# load data\r\n\turl = build_url(freq, fsym=fsym, tsym=tsym, freq=freq, e=e, \r\n\t                try_conversion=try_conversion, aggregate=aggregate, \r\n\t                limit=limit, to_ts=to_ts)\r\n\tdata = load_data(url)\r\n\tdata = data['Data']\r\n\r\n\t# convert timestamps to nice date format\r\n\tfor d in data:\r\n\t\td['time'] = timestamp_to_date(d['time'])\r\n\r\n\t# convert single input info to single element list\r\n\tif not isinstance(info, list):\r\n\t\tinfo = [info]\r\n\r\n\t# select information to return\r\n\tif info[0] == 'full':\r\n\t\treturn data\r\n\telse:\r\n\t\tfor d in data:\r\n\t\t\tfor k, v in list(d.items()):\r\n\t\t\t\tif k not in info and k != 'time':\r\n\t\t\t\t\tdel d[k]\r\n\t\t\t\t\r\n\t\treturn data", "response": "Get historical data for a currency pair."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef url2fs(url):\n    uri, extension = posixpath.splitext(url)\n    return safe64.dir(uri) + extension", "response": "encode a URL to be safe as a filename"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xindexes(slots):\n    # the first response...\n    slot = [0] * len(slots)\n    \n    for i in range(reduce(operator.mul, slots)):\n        yield slot\n        \n        carry = 1\n        \n        # iterate from the least to the most significant digit\n        for j in range(len(slots), 0, -1):\n            k = j - 1\n            \n            slot[k] += carry\n            \n            if slot[k] >= slots[k]:\n                carry = 1 + slot[k] - slots[k]\n                slot[k] = 0\n            else:\n                carry = 0", "response": "Generate a list of possible indexes into a list of slots."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the map projection matches that used by VEarth Google OSM etc.", "response": "def is_merc_projection(srs):\n    \"\"\" Return true if the map projection matches that used by VEarth, Google, OSM, etc.\n    \n        Is currently necessary for zoom-level shorthand for scale-denominator.\n    \"\"\"\n    if srs.lower() == '+init=epsg:900913':\n        return True\n\n    # observed\n    srs = dict([p.split('=') for p in srs.split() if '=' in p])\n    \n    # expected\n    # note, common optional modifiers like +no_defs, +over, and +wkt\n    # are not pairs and should not prevent matching\n    gym = '+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null'\n    gym = dict([p.split('=') for p in gym.split() if '=' in p])\n        \n    for p in gym:\n        if srs.get(p, None) != gym.get(p, None):\n            return False\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef extract_declarations(map_el, dirs, scale=1, user_styles=[]):\n    styles = []\n    \n    #\n    # First, look at all the stylesheets defined in the map itself.\n    #\n    for stylesheet in map_el.findall('Stylesheet'):\n        map_el.remove(stylesheet)\n\n        content, mss_href = fetch_embedded_or_remote_src(stylesheet, dirs)\n        \n        if content:\n            styles.append((content, mss_href))\n    \n    #\n    # Second, look through the user-supplied styles for override rules.\n    #\n    for stylesheet in user_styles:\n        mss_href = urljoin(dirs.source.rstrip('/')+'/', stylesheet)\n        content = urllib.urlopen(mss_href).read().decode(DEFAULT_ENCODING)\n\n        styles.append((content, mss_href))\n    \n    declarations = []\n    \n    for (content, mss_href) in styles:\n        is_merc = is_merc_projection(map_el.get('srs',''))\n        \n        for declaration in stylesheet_declarations(content, is_merc, scale):\n            #\n            # Change the value of each URI relative to the location\n            # of the containing stylesheet. We generally just have\n            # the one instance of \"dirs\" around for a full parse cycle,\n            # so it's necessary to perform this normalization here\n            # instead of later, while mss_href is still available.\n            #\n            uri_value = declaration.value.value\n            \n            if uri_value.__class__ is uri:\n                uri_value.address = urljoin(mss_href, uri_value.address)\n\n            declarations.append(declaration)\n\n    return declarations", "response": "Given a Map element and directories object remove and return a complete\n    list of style declarations from any Stylesheet elements found within the Map element."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngives a Filter and some symbolizers return a Rule prepopulated by the filter and other symbolizers.", "response": "def make_rule(filter, *symbolizers):\n    \"\"\" Given a Filter and some symbolizers, return a Rule prepopulated\n        with applicable min/max scale denominator and filter.\n    \"\"\"\n    scale_tests = [test for test in filter.tests if test.isMapScaled()]\n    other_tests = [test for test in filter.tests if not test.isMapScaled()]\n    \n    # these will be replaced with values as necessary\n    minscale, maxscale, filter = None, None, None\n    \n    for scale_test in scale_tests:\n\n        if scale_test.op in ('>', '>='):\n            if scale_test.op == '>=':\n                value = scale_test.value\n            elif scale_test.op == '>':\n                value = scale_test.value + 1\n\n            minscale = output.MinScaleDenominator(value)\n\n        if scale_test.op in ('<', '<='):\n            if scale_test.op == '<=':\n                value = scale_test.value\n            elif scale_test.op == '<':\n                value = scale_test.value - 1\n\n            maxscale = output.MaxScaleDenominator(value)\n    \n    filter_text = ' and '.join(test2str(test) for test in other_tests)\n    \n    if filter_text:\n        filter = output.Filter(filter_text)\n\n    rule = output.Rule(minscale, maxscale, filter, [s for s in symbolizers if s])\n    \n    return rule"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_applicable_selector(selector, filter):\n    for test in selector.allTests():\n        if not test.isCompatible(filter.tests):\n            return False\n    \n    return True", "response": "Given a Selector and Filter return True if the given Selector is compatible with the given Filter and False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_polygon_rules(declarations):\n    property_map = {'polygon-fill': 'fill', 'polygon-opacity': 'fill-opacity',\n                    'polygon-gamma': 'gamma',\n                    'polygon-meta-output': 'meta-output', 'polygon-meta-writer': 'meta-writer'}\n\n    property_names = property_map.keys()\n    \n    # a place to put rules\n    rules = []\n    \n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n        color = values.has_key('polygon-fill') and values['polygon-fill'].value\n        opacity = values.has_key('polygon-opacity') and values['polygon-opacity'].value or None\n        gamma = values.has_key('polygon-gamma') and values['polygon-gamma'].value or None\n        symbolizer = color and output.PolygonSymbolizer(color, opacity, gamma)\n        \n        if symbolizer:\n            rules.append(make_rule(filter, symbolizer))\n    \n    return rules", "response": "Given a list of declarations and a Map element create a new Style element with a PolygonSymbolizer add it to Layer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a list of declarations create a new Style element with a RasterSymbolizer and add it to Layer.", "response": "def get_raster_rules(declarations):\n    \"\"\" Given a Map element, a Layer element, and a list of declarations,\n        create a new Style element with a RasterSymbolizer, add it to Map\n        and refer to it in Layer.\n        \n        The RasterSymbolizer will always created, even if there are\n        no applicable declarations.\n    \"\"\"\n    property_map = {'raster-opacity': 'opacity',\n                    'raster-mode': 'mode',\n                    'raster-scaling': 'scaling'\n                    }\n\n    property_names = property_map.keys()\n\n    # a place to put rules\n    rules = []\n\n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n        sym_params = {}\n        for prop,attr in property_map.items():\n            sym_params[attr] = values.has_key(prop) and values[prop].value or None\n        \n        symbolizer = output.RasterSymbolizer(**sym_params)\n\n        rules.append(make_rule(filter, symbolizer))\n\n    if not rules:\n        # No raster-* rules were created, but we're here so we must need a symbolizer.\n        rules.append(make_rule(Filter(), output.RasterSymbolizer()))\n    \n    return rules"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_line_rules(declarations):\n    property_map = {'line-color': 'stroke', 'line-width': 'stroke-width',\n                    'line-opacity': 'stroke-opacity', 'line-join': 'stroke-linejoin',\n                    'line-cap': 'stroke-linecap', 'line-dasharray': 'stroke-dasharray',\n                    'line-meta-output': 'meta-output', 'line-meta-writer': 'meta-writer'}\n\n\n    property_names = property_map.keys()\n    \n    # prepend parameter names with 'in' and 'out'\n    for i in range(len(property_names)):\n        property_names.append('in' + property_names[i])\n        property_names.append('out' + property_names[i])\n\n    # a place to put rules\n    rules = []\n    \n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n    \n        width = values.has_key('line-width') and values['line-width'].value\n        color = values.has_key('line-color') and values['line-color'].value\n\n        opacity = values.has_key('line-opacity') and values['line-opacity'].value or None\n        join = values.has_key('line-join') and values['line-join'].value or None\n        cap = values.has_key('line-cap') and values['line-cap'].value or None\n        dashes = values.has_key('line-dasharray') and values['line-dasharray'].value or None\n\n        line_symbolizer = color and width and output.LineSymbolizer(color, width, opacity, join, cap, dashes) or False\n\n        width = values.has_key('inline-width') and values['inline-width'].value\n        color = values.has_key('inline-color') and values['inline-color'].value\n\n        opacity = values.has_key('inline-opacity') and values['inline-opacity'].value or None\n        join = values.has_key('inline-join') and values['inline-join'].value or None\n        cap = values.has_key('inline-cap') and values['inline-cap'].value or None\n        dashes = values.has_key('inline-dasharray') and values['inline-dasharray'].value or None\n\n        inline_symbolizer = color and width and output.LineSymbolizer(color, width, opacity, join, cap, dashes) or False\n\n        # outline requires regular line to have a meaningful width\n        width = values.has_key('outline-width') and values.has_key('line-width') \\\n            and values['line-width'].value + values['outline-width'].value * 2\n        color = values.has_key('outline-color') and values['outline-color'].value\n\n        opacity = values.has_key('outline-opacity') and values['outline-opacity'].value or None\n        join = values.has_key('outline-join') and values['outline-join'].value or None\n        cap = values.has_key('outline-cap') and values['outline-cap'].value or None\n        dashes = values.has_key('outline-dasharray') and values['outline-dasharray'].value or None\n\n        outline_symbolizer = color and width and output.LineSymbolizer(color, width, opacity, join, cap, dashes) or False\n        \n        if outline_symbolizer or line_symbolizer or inline_symbolizer:\n            rules.append(make_rule(filter, outline_symbolizer, line_symbolizer, inline_symbolizer))\n\n    return rules", "response": "Given a list of declarations return a list of output. Rule objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_text_rule_groups(declarations):\n    property_map = {'text-anchor-dx': 'anchor_dx', # does nothing\n                    'text-anchor-dy': 'anchor_dy', # does nothing\n                    'text-align': 'horizontal_alignment',\n                    'text-allow-overlap': 'allow_overlap',\n                    'text-avoid-edges': 'avoid_edges',\n                    'text-character-spacing': 'character_spacing',\n                    'text-dx': 'dx',\n                    'text-dy': 'dy',\n                    'text-face-name': 'face_name',\n                    'text-fill': 'fill',\n                    'text-fontset': 'fontset',\n                    'text-halo-fill': 'halo_fill',\n                    'text-halo-radius': 'halo_radius',\n                    'text-justify-align': 'justify_alignment',\n                    'text-label-position-tolerance': 'label_position_tolerance',\n                    'text-line-spacing': 'line_spacing',\n                    'text-max-char-angle-delta': 'max_char_angle_delta',\n                    'text-min-distance': 'minimum_distance',\n                    'text-placement': 'label_placement',\n                    'text-ratio': 'text_ratio',\n                    'text-size': 'size', \n                    'text-spacing': 'spacing',\n                    'text-transform': 'text_convert',\n                    'text-vertical-align': 'vertical_alignment',\n                    'text-wrap-width': 'wrap_width',\n                    'text-meta-output': 'meta-output',\n                    'text-meta-writer': 'meta-writer'\n                    }\n\n    property_names = property_map.keys()\n    \n    # pull out all the names\n    text_names = [dec.selector.elements[1].names[0]\n                  for dec in declarations\n                  if len(dec.selector.elements) is 2 and len(dec.selector.elements[1].names) is 1]\n    \n    # a place to put groups\n    groups = []\n    \n    # a separate style element for each text name\n    for text_name in set(text_names):\n    \n        # just the ones we care about here.\n        # the complicated conditional means: get all declarations that\n        # apply to this text_name specifically, or text in general.\n        name_declarations = [dec for dec in declarations\n                             if dec.property.name in property_map\n                                and (len(dec.selector.elements) == 1\n                                     or (len(dec.selector.elements) == 2\n                                         and dec.selector.elements[1].names[0] in (text_name, '*')))]\n        \n        # a place to put rules\n        rules = []\n        \n        for (filter, values) in filtered_property_declarations(name_declarations, property_names):\n            \n            face_name = values.has_key('text-face-name') and values['text-face-name'].value or None\n            fontset = values.has_key('text-fontset') and values['text-fontset'].value or None\n            size = values.has_key('text-size') and values['text-size'].value\n            color = values.has_key('text-fill') and values['text-fill'].value\n            \n            ratio = values.has_key('text-ratio') and values['text-ratio'].value or None\n            wrap_width = values.has_key('text-wrap-width') and values['text-wrap-width'].value or None\n            label_spacing = values.has_key('text-spacing') and values['text-spacing'].value or None\n            label_position_tolerance = values.has_key('text-label-position-tolerance') and values['text-label-position-tolerance'].value or None\n            max_char_angle_delta = values.has_key('text-max-char-angle-delta') and values['text-max-char-angle-delta'].value or None\n            halo_color = values.has_key('text-halo-fill') and values['text-halo-fill'].value or None\n            halo_radius = values.has_key('text-halo-radius') and values['text-halo-radius'].value or None\n            dx = values.has_key('text-dx') and values['text-dx'].value or None\n            dy = values.has_key('text-dy') and values['text-dy'].value or None\n            avoid_edges = values.has_key('text-avoid-edges') and values['text-avoid-edges'].value or None\n            minimum_distance = values.has_key('text-min-distance') and values['text-min-distance'].value or None\n            allow_overlap = values.has_key('text-allow-overlap') and values['text-allow-overlap'].value or None\n            label_placement = values.has_key('text-placement') and values['text-placement'].value or None\n            text_transform = values.has_key('text-transform') and values['text-transform'].value or None\n            anchor_dx = values.has_key('text-anchor-dx') and values['text-anchor-dx'].value or None\n            anchor_dy = values.has_key('text-anchor-dy') and values['text-anchor-dy'].value or None\n            horizontal_alignment = values.has_key('text-horizontal-align') and values['text-horizontal-align'].value or None\n            vertical_alignment = values.has_key('text-vertical-align') and values['text-vertical-align'].value or None\n            justify_alignment = values.has_key('text-justify-align') and values['text-justify-align'].value or None\n            line_spacing = values.has_key('text-line-spacing') and values['text-line-spacing'].value or None\n            character_spacing = values.has_key('text-character-spacing') and values['text-character-spacing'].value or None\n            \n            if (face_name or fontset) and size and color:\n                symbolizer = output.TextSymbolizer(text_name, face_name, size, color, \\\n                                              wrap_width, label_spacing, label_position_tolerance, \\\n                                              max_char_angle_delta, halo_color, halo_radius, dx, dy, \\\n                                              avoid_edges, minimum_distance, allow_overlap, label_placement, \\\n                                              line_spacing, character_spacing, text_transform, fontset,\n                                              anchor_dx, anchor_dy,horizontal_alignment, \\\n                                              vertical_alignment, justify_alignment)\n            \n                rules.append(make_rule(filter, symbolizer))\n        \n        groups.append((text_name, rules))\n    \n    return dict(groups)", "response": "Given a list of declarations return a list of output. Rule objects."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef post_process_symbolizer_image_file(file_href, dirs):\n    # support latest mapnik features of auto-detection\n    # of image sizes and jpeg reading support...\n    # http://trac.mapnik.org/ticket/508\n\n    mapnik_auto_image_support = (MAPNIK_VERSION >= 701)\n    mapnik_requires_absolute_paths = (MAPNIK_VERSION < 601)\n    file_href = urljoin(dirs.source.rstrip('/')+'/', file_href)\n    scheme, n, path, p, q, f = urlparse(file_href)\n    if scheme in ('http','https'):\n        scheme, path = '', locally_cache_remote_file(file_href, dirs.cache)\n    \n    if scheme not in ('file', '') or not systempath.exists(un_posix(path)):\n        raise Exception(\"Image file needs to be a working, fetchable resource, not %s\" % file_href)\n        \n    if not mapnik_auto_image_support and not Image:\n        raise SystemExit('PIL (Python Imaging Library) is required for handling image data unless you are using PNG inputs and running Mapnik >=0.7.0')\n\n    img = Image.open(un_posix(path))\n    \n    if mapnik_requires_absolute_paths:\n        path = posixpath.realpath(path)\n    \n    else:\n        path = dirs.output_path(path)\n\n    msg('reading symbol: %s' % path)\n\n    image_name, ext = posixpath.splitext(path)\n    \n    if ext in ('.png', '.tif', '.tiff'):\n        output_ext = ext\n    else:\n        output_ext = '.png'\n    \n    # new local file name\n    dest_file = un_posix('%s%s' % (image_name, output_ext))\n    \n    if not posixpath.exists(dest_file):\n        img.save(dest_file,'PNG')\n\n    msg('Destination file: %s' % dest_file)\n\n    return dest_file, output_ext[1:], img.size[0], img.size[1]", "response": "This function is used to post - process a single image file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngiving a list of declarations return a list of output. Rule objects. Optionally provide an output directory for local copies of image files.", "response": "def get_shield_rule_groups(declarations, dirs):\n    \"\"\" Given a list of declarations, return a list of output.Rule objects.\n        \n        Optionally provide an output directory for local copies of image files.\n    \"\"\"\n    property_map = {'shield-face-name': 'face_name',\n                    'shield-fontset': 'fontset',\n                    'shield-size': 'size', \n                    'shield-fill': 'fill', 'shield-character-spacing': 'character_spacing',\n                    'shield-line-spacing': 'line_spacing',\n                    'shield-spacing': 'spacing', 'shield-min-distance': 'minimum_distance',\n                    'shield-file': 'file', 'shield-width': 'width', 'shield-height': 'height',\n                    'shield-meta-output': 'meta-output', 'shield-meta-writer': 'meta-writer',\n                    'shield-text-dx': 'dx', 'shield-text-dy': 'dy'}\n\n    property_names = property_map.keys()\n    \n    # pull out all the names\n    text_names = [dec.selector.elements[1].names[0]\n                  for dec in declarations\n                  if len(dec.selector.elements) is 2 and len(dec.selector.elements[1].names) is 1]\n    \n    # a place to put groups\n    groups = []\n    \n    # a separate style element for each text name\n    for text_name in set(text_names):\n    \n        # just the ones we care about here.\n        # the complicated conditional means: get all declarations that\n        # apply to this text_name specifically, or text in general.\n        name_declarations = [dec for dec in declarations\n                             if dec.property.name in property_map\n                                and (len(dec.selector.elements) == 1\n                                     or (len(dec.selector.elements) == 2\n                                         and dec.selector.elements[1].names[0] in (text_name, '*')))]\n        \n        # a place to put rules\n        rules = []\n        \n        for (filter, values) in filtered_property_declarations(name_declarations, property_names):\n        \n            face_name = values.has_key('shield-face-name') and values['shield-face-name'].value or None\n            fontset = values.has_key('shield-fontset') and values['shield-fontset'].value or None\n            size = values.has_key('shield-size') and values['shield-size'].value or None\n            \n            file, filetype, width, height \\\n                = values.has_key('shield-file') \\\n                and post_process_symbolizer_image_file(str(values['shield-file'].value), dirs) \\\n                or (None, None, None, None)\n            \n            width = values.has_key('shield-width') and values['shield-width'].value or width\n            height = values.has_key('shield-height') and values['shield-height'].value or height\n            \n            color = values.has_key('shield-fill') and values['shield-fill'].value or None\n            minimum_distance = values.has_key('shield-min-distance') and values['shield-min-distance'].value or None\n            \n            character_spacing = values.has_key('shield-character-spacing') and values['shield-character-spacing'].value or None\n            line_spacing = values.has_key('shield-line-spacing') and values['shield-line-spacing'].value or None\n            label_spacing = values.has_key('shield-spacing') and values['shield-spacing'].value or None\n            \n            text_dx = values.has_key('shield-text-dx') and values['shield-text-dx'].value or 0\n            text_dy = values.has_key('shield-text-dy') and values['shield-text-dy'].value or 0\n            \n            if file and (face_name or fontset):\n                symbolizer = output.ShieldSymbolizer(text_name, face_name, size, file, filetype, \n                                            width, height, color, minimum_distance, character_spacing,\n                                            line_spacing, label_spacing, text_dx=text_dx, text_dy=text_dy,\n                                            fontset=fontset)\n            \n                rules.append(make_rule(filter, symbolizer))\n        \n        groups.append((text_name, rules))\n    \n    return dict(groups)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of declarations return a list of output. Rule objects.", "response": "def get_point_rules(declarations, dirs):\n    \"\"\" Given a list of declarations, return a list of output.Rule objects.\n        \n        Optionally provide an output directory for local copies of image files.\n    \"\"\"\n    property_map = {'point-file': 'file', 'point-width': 'width',\n                    'point-height': 'height', 'point-type': 'type',\n                    'point-allow-overlap': 'allow_overlap',\n                    'point-meta-output': 'meta-output', 'point-meta-writer': 'meta-writer'}\n    \n    property_names = property_map.keys()\n    \n    # a place to put rules\n    rules = []\n    \n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n        point_file, point_type, point_width, point_height \\\n            = values.has_key('point-file') \\\n            and post_process_symbolizer_image_file(str(values['point-file'].value), dirs) \\\n            or (None, None, None, None)\n        \n        point_width = values.has_key('point-width') and values['point-width'].value or point_width\n        point_height = values.has_key('point-height') and values['point-height'].value or point_height\n        point_allow_overlap = values.has_key('point-allow-overlap') and values['point-allow-overlap'].value or None\n        \n        symbolizer = point_file and output.PointSymbolizer(point_file, point_type, point_width, point_height, point_allow_overlap)\n\n        if symbolizer:\n            rules.append(make_rule(filter, symbolizer))\n    \n    return rules"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_polygon_pattern_rules(declarations, dirs):\n    property_map = {'polygon-pattern-file': 'file', 'polygon-pattern-width': 'width',\n                    'polygon-pattern-height': 'height', 'polygon-pattern-type': 'type',\n                    'polygon-meta-output': 'meta-output', 'polygon-meta-writer': 'meta-writer'}\n\n    \n    property_names = property_map.keys()\n    \n    # a place to put rules\n    rules = []\n    \n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n    \n        poly_pattern_file, poly_pattern_type, poly_pattern_width, poly_pattern_height \\\n            = values.has_key('polygon-pattern-file') \\\n            and post_process_symbolizer_image_file(str(values['polygon-pattern-file'].value), dirs) \\\n            or (None, None, None, None)\n        \n        poly_pattern_width = values.has_key('polygon-pattern-width') and values['polygon-pattern-width'].value or poly_pattern_width\n        poly_pattern_height = values.has_key('polygon-pattern-height') and values['polygon-pattern-height'].value or poly_pattern_height\n        symbolizer = poly_pattern_file and output.PolygonPatternSymbolizer(poly_pattern_file, poly_pattern_type, poly_pattern_width, poly_pattern_height)\n        \n        if symbolizer:\n            rules.append(make_rule(filter, symbolizer))\n    \n    return rules", "response": "Given a list of declarations return a list of output. Rule objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_line_pattern_rules(declarations, dirs):\n    property_map = {'line-pattern-file': 'file', 'line-pattern-width': 'width',\n                    'line-pattern-height': 'height', 'line-pattern-type': 'type',\n                    'line-pattern-meta-output': 'meta-output', 'line-pattern-meta-writer': 'meta-writer'}\n\n    \n    property_names = property_map.keys()\n    \n    # a place to put rules\n    rules = []\n    \n    for (filter, values) in filtered_property_declarations(declarations, property_names):\n    \n        line_pattern_file, line_pattern_type, line_pattern_width, line_pattern_height \\\n            = values.has_key('line-pattern-file') \\\n            and post_process_symbolizer_image_file(str(values['line-pattern-file'].value), dirs) \\\n            or (None, None, None, None)\n        \n        line_pattern_width = values.has_key('line-pattern-width') and values['line-pattern-width'].value or line_pattern_width\n        line_pattern_height = values.has_key('line-pattern-height') and values['line-pattern-height'].value or line_pattern_height\n        symbolizer = line_pattern_file and output.LinePatternSymbolizer(line_pattern_file, line_pattern_type, line_pattern_width, line_pattern_height)\n        \n        if symbolizer:\n            rules.append(make_rule(filter, symbolizer))\n    \n    return rules", "response": "Given a list of declarations return a list of output. Rule objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_applicable_declarations(element, declarations):\n    element_tag = element.tag\n    element_id = element.get('id', None)\n    element_classes = element.get('class', '').split()\n\n    return [dec for dec in declarations\n            if dec.selector.matches(element_tag, element_id, element_classes)]", "response": "Given an XML element and a list of declarations return the ones\n        that match as a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngiving a shapefile href and a set of directories modify the shapefile name so it s correct with respect to the output and cache directories.", "response": "def localize_shapefile(shp_href, dirs):\n    \"\"\" Given a shapefile href and a set of directories, modify the shapefile\n        name so it's correct with respect to the output and cache directories.\n    \"\"\"\n    # support latest mapnik features of auto-detection\n    # of image sizes and jpeg reading support...\n    # http://trac.mapnik.org/ticket/508\n\n    mapnik_requires_absolute_paths = (MAPNIK_VERSION < 601)\n\n    shp_href = urljoin(dirs.source.rstrip('/')+'/', shp_href)\n    scheme, host, path, p, q, f = urlparse(shp_href)\n    \n    if scheme in ('http','https'):\n        msg('%s | %s' % (shp_href, dirs.cache))\n        scheme, path = '', locally_cache_remote_file(shp_href, dirs.cache)\n    else:\n        host = None\n    \n    # collect drive for windows\n    to_posix(systempath.realpath(path))\n\n    if scheme not in ('file', ''):\n        raise Exception(\"Shapefile needs to be local, not %s\" % shp_href)\n        \n    if mapnik_requires_absolute_paths:\n        path = posixpath.realpath(path)\n        original = path\n\n    path = dirs.output_path(path)\n    \n    if path.endswith('.zip'):\n        # unzip_shapefile_into needs a path it can find\n        path = posixpath.join(dirs.output, path)\n        path = unzip_shapefile_into(path, dirs.cache, host)\n\n    return dirs.output_path(path)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef localize_file_datasource(file_href, dirs):\n    # support latest mapnik features of auto-detection\n    # of image sizes and jpeg reading support...\n    # http://trac.mapnik.org/ticket/508\n\n    mapnik_requires_absolute_paths = (MAPNIK_VERSION < 601)\n\n    file_href = urljoin(dirs.source.rstrip('/')+'/', file_href)\n    scheme, n, path, p, q, f = urlparse(file_href)\n    \n    if scheme in ('http','https'):\n        scheme, path = '', locally_cache_remote_file(file_href, dirs.cache)\n\n    if scheme not in ('file', ''):\n        raise Exception(\"Datasource file needs to be a working, fetchable resource, not %s\" % file_href)\n\n    if mapnik_requires_absolute_paths:\n        return posixpath.realpath(path)\n    \n    else:\n        return dirs.output_path(path)", "response": "Handle localizing file - based datasources other than shapefiles."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compile(src, dirs, verbose=False, srs=None, datasources_cfg=None, user_styles=[], scale=1):\n    global VERBOSE\n\n    if verbose:\n        VERBOSE = True\n        sys.stderr.write('\\n')\n    \n    msg('Targeting mapnik version: %s | %s' % (MAPNIK_VERSION, MAPNIK_VERSION_STR))\n        \n    if posixpath.exists(src):\n        doc = ElementTree.parse(src)\n        map_el = doc.getroot()\n    else:\n        try:\n            # guessing src is a literal XML string?\n            map_el = ElementTree.fromstring(src)\n    \n        except:\n            if not (src[:7] in ('http://', 'https:/', 'file://')):\n                src = \"file://\" + src\n            try:\n                doc = ElementTree.parse(urllib.urlopen(src))\n            except IOError, e:\n                raise IOError('%s: %s' % (e,src))\n            map_el = doc.getroot()\n\n    expand_source_declarations(map_el, dirs, datasources_cfg)\n    declarations = extract_declarations(map_el, dirs, scale, user_styles)\n    \n    # a list of layers and a sequential ID generator\n    layers, ids = [], (i for i in xrange(1, 999999))\n\n\n    # Handle base datasources\n    # http://trac.mapnik.org/changeset/574\n    datasource_templates = {}\n    for base_el in map_el:\n        if base_el.tag != 'Datasource':\n            continue\n        datasource_templates[base_el.get('name')] = dict(((p.get('name'),p.text) for p in base_el.findall('Parameter')))\n    \n    for layer_el in map_el.findall('Layer'):\n    \n        # nevermind with this one\n        if layer_el.get('status', None) in ('off', '0', 0):\n            continue\n\n        # build up a map of Parameters for this Layer\n        datasource_params = dict((p.get('name'),p.text) for p in layer_el.find('Datasource').findall('Parameter'))\n\n        base = layer_el.find('Datasource').get('base')\n        if base:\n            datasource_params.update(datasource_templates[base])\n\n        if datasource_params.get('table'):\n            # remove line breaks from possible SQL, using a possibly-unsafe regexp\n            # that simply blows away anything that looks like it might be a SQL comment.\n            # http://trac.mapnik.org/ticket/173\n            if not MAPNIK_VERSION >= 601:\n                sql = datasource_params.get('table')\n                sql = compile(r'--.*$', MULTILINE).sub('', sql)\n                sql = sql.replace('\\r', ' ').replace('\\n', ' ')\n                datasource_params['table'] = sql\n\n        elif datasource_params.get('file') is not None:\n            # make sure we localize any remote files\n            file_param = datasource_params.get('file')\n\n            if datasource_params.get('type') == 'shape':\n                # handle a local shapefile or fetch a remote, zipped shapefile\n                msg('Handling shapefile datasource...')\n                file_param = localize_shapefile(file_param, dirs)\n\n                # TODO - support datasource reprojection to make map srs\n                # TODO - support automatically indexing shapefiles\n\n            else: # ogr,raster, gdal, sqlite\n                # attempt to generically handle other file based datasources\n                msg('Handling generic datasource...')\n                file_param = localize_file_datasource(file_param, dirs)\n\n            msg(\"Localized path = %s\" % un_posix(file_param))\n            datasource_params['file'] = un_posix(file_param)\n\n            # TODO - consider custom support for other mapnik datasources:\n            # sqlite, oracle, osm, kismet, gdal, raster, rasterlite\n\n        layer_declarations = get_applicable_declarations(layer_el, declarations)\n        \n        # a list of styles\n        styles = []\n        \n        if datasource_params.get('type', None) == 'gdal':\n            styles.append(output.Style('raster style %d' % ids.next(),\n                                       get_raster_rules(layer_declarations)))\n    \n        else:\n            styles.append(output.Style('polygon style %d' % ids.next(),\n                                       get_polygon_rules(layer_declarations)))\n    \n            styles.append(output.Style('polygon pattern style %d' % ids.next(),\n                                       get_polygon_pattern_rules(layer_declarations, dirs)))\n    \n            styles.append(output.Style('line style %d' % ids.next(),\n                                       get_line_rules(layer_declarations)))\n    \n            styles.append(output.Style('line pattern style %d' % ids.next(),\n                                       get_line_pattern_rules(layer_declarations, dirs)))\n    \n            for (shield_name, shield_rules) in get_shield_rule_groups(layer_declarations, dirs).items():\n                styles.append(output.Style('shield style %d (%s)' % (ids.next(), shield_name), shield_rules))\n    \n            for (text_name, text_rules) in get_text_rule_groups(layer_declarations).items():\n                styles.append(output.Style('text style %d (%s)' % (ids.next(), text_name), text_rules))\n    \n            styles.append(output.Style('point style %d' % ids.next(),\n                                       get_point_rules(layer_declarations, dirs)))\n                                   \n        styles = [s for s in styles if s.rules]\n        \n        if styles:\n            datasource = output.Datasource(**datasource_params)\n            \n            layer = output.Layer('layer %d' % ids.next(),\n                                 datasource, styles,\n                                 layer_el.get('srs', None),\n                                 layer_el.get('min_zoom', None) and int(layer_el.get('min_zoom')) or None,\n                                 layer_el.get('max_zoom', None) and int(layer_el.get('max_zoom')) or None)\n    \n            layers.append(layer)\n    \n    map_attrs = get_map_attributes(get_applicable_declarations(map_el, declarations))\n    \n    # if a target srs is profiled, override whatever is in mml\n    if srs is not None:\n        map_el.set('srs', srs)\n    \n    return output.Map(map_el.attrib.get('srs', None), layers, **map_attrs)", "response": "Compile a Cascadenik MML file into a cascadenik. output. Map object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmodifies a path so it fits expectations.", "response": "def output_path(self, path_name):\n        \"\"\" Modify a path so it fits expectations.\n        \n            Avoid returning relative paths that start with '../' and possibly\n            return relative paths when output and cache directories match.\n        \"\"\"        \n        # make sure it is a valid posix format\n        path = to_posix(path_name)\n        \n        assert (path == path_name), \"path_name passed to output_path must be in posix format\"\n        \n        if posixpath.isabs(path):\n            if self.output == self.cache:\n                # worth seeing if an absolute path can be avoided\n                path = posixpath.relpath(path, self.output)\n\n            else:\n                return posixpath.realpath(path)\n    \n        if path.startswith('../'):\n            joined = posixpath.join(self.output, path)\n            return posixpath.realpath(joined)\n    \n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the midpoint of the assessment.", "response": "def midpoint(self):\n        \"\"\" Return a point guranteed to fall within this range, hopefully near the middle.\n        \"\"\"\n        minpoint = self.leftedge\n\n        if self.leftop is gt:\n            minpoint += 1\n    \n        maxpoint = self.rightedge\n\n        if self.rightop is lt:\n            maxpoint -= 1\n\n        if minpoint is None:\n            return maxpoint\n            \n        elif maxpoint is None:\n            return minpoint\n            \n        else:\n            return (minpoint + maxpoint) / 2"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef isOpen(self):\n        if self.leftedge and self.rightedge and self.leftedge > self.rightedge:\n            return False\n    \n        if self.leftedge == self.rightedge:\n            if self.leftop is gt or self.rightop is lt:\n                return False\n\n        return True", "response": "Return True if this range is open."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef toFilter(self, property):\n        if self.leftedge == self.rightedge and self.leftop is ge and self.rightop is le:\n            # equivalent to ==\n            return Filter(style.SelectorAttributeTest(property, '=', self.leftedge))\n    \n        try:\n            return Filter(style.SelectorAttributeTest(property, opstr[self.leftop], self.leftedge),\n                          style.SelectorAttributeTest(property, opstr[self.rightop], self.rightedge))\n        except KeyError:\n            try:\n                return Filter(style.SelectorAttributeTest(property, opstr[self.rightop], self.rightedge))\n            except KeyError:\n                try:\n                    return Filter(style.SelectorAttributeTest(property, opstr[self.leftop], self.leftedge))\n                except KeyError:\n                    return Filter()", "response": "Convert this range to a Filter with a given property."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new Filter that s equal to this one without extra terms that don t add meaning.", "response": "def minusExtras(self):\n        \"\"\" Return a new Filter that's equal to this one,\n            without extra terms that don't add meaning.\n        \"\"\"\n        assert self.isOpen()\n        \n        trimmed = self.clone()\n        \n        equals = {}\n        \n        for test in trimmed.tests:\n            if test.op == '=':\n                equals[test.property] = test.value\n\n        extras = []\n\n        for (i, test) in enumerate(trimmed.tests):\n            if test.op == '!=' and equals.has_key(test.property) and equals[test.property] != test.value:\n                extras.append(i)\n\n        while extras:\n            trimmed.tests.pop(extras.pop())\n\n        return trimmed"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunk_generator(N, n):\n\n    chunk_size = get_chunk_size(N, n)\n    \n    for start in range(0, N, chunk_size):\n        yield slice(start, min(start + chunk_size, N))", "response": "Returns a generator of slice objects representing the set of N elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the command line options for the affinity propagation clustering.", "response": "def parse_options():\n    \"\"\"Specify the command line options to parse.\n    \n    Returns\n    -------\n    opts : optparse.Values instance\n        Contains the option values in its 'dict' member variable.\n    \n    args[0] : string or file-handler\n        The name of the file storing the data-set submitted\n        for Affinity Propagation clustering.\n    \"\"\"\n\n    parser = optparse.OptionParser(\n                        usage = \"Usage: %prog [options] file_name\\n\\n\"\n                        \"file_name denotes the path where the data to be \"\n                        \"processed by affinity propagation clustering is stored\"\n                        )\n    parser.add_option('-m', '--multiprocessing', dest = 'count', \n                      default = multiprocessing.cpu_count(), type = 'int', \n                      help = (\"The number of processes to use (1..20) \" \n                              \"[default %default]\"))\n    parser.add_option('-f', '--file', dest = 'hdf5_file', default = None,\n                     type = 'str', \n                     help = (\"File name or file handle of the HDF5 \"\n                             \"data structure holding the matrices involved in \"\n                             \"affinity propagation clustering \"\n                             \"[default %default]\"))\n    parser.add_option('-s', '--similarities', dest = 'similarities', \n                      default = False, action = 'store_true',\n                      help = (\"Specifies if a matrix of similarities \"\n                              \"has already been computed; only makes sense \"\n                              \"with -f or --file in effect [default %default]\"))\n    parser.add_option('-i', '--iterations', dest = 'max_iter', \n                      default = 200, type = 'int', \n                      help = (\"The maximum number of message passing \"   \n                              \"iterations undergone before affinity \"\n                              \"propagation returns, having reached \"\n                              \"convergence or not [default %default]\"))\n    parser.add_option('-c', '--convergence', dest = 'convergence_iter', \n                      default = 15, type = 'int', \n                      help = (\"Specifies the number of consecutive \"\n                              \"iterations without change in the number \"\n                              \"of clusters that signals convergence \"\n                              \"[default %default]\") )\n    parser.add_option('-p', '--preference', dest = 'preference', \n                      default = None, type = 'float', \n                      help = (\"The preference parameter of affinity \"\n                              \"propagation [default %default]\"))\n    parser.add_option('-d', '--damping', dest = 'damping',\n                      default = 0.5, type = 'float',\n                      help = (\"The damping parameter of affinity \" \n                              \"propagation; must be within 0.5 and 1.0 \"\n                              \"[default %default]\"))\n    parser.add_option('-v', '--verbose', dest = 'verbose', \n                      default = False, action = 'store_true', \n                      help = (\"Turns on the display of messaging regarding \" \n                              \"the status of the various stages of affinity \"\n                              \"propagation clustering currently ongoing \"\n                              \"on the user-specified data-set \"\n                              \"[default %default]\"))\n                    \n    opts, args = parser.parse_args()\n    \n    if len(args) == 0:\n        parser.error('A data file must be specified')\n    \n    if opts.similarities and (opts.hdf5_file is None):\n        parser.error(\"Option -s is conditional on -f\")\n    \n    if not (1 <= opts.count <= 20):\n        parser.error(\"The number of processes must range \"\n                     \"from 1 to 20, inclusive\")\n                     \n    if opts.max_iter <= 0:\n        parser.error(\"The number of iterations must be \"\n                     \"a non-negative integer\")\n                                      \n    if opts.convergence_iter >= opts.max_iter:\n        parser.error(\"The number of iterations signalling convergence \"\n                     \"cannot exceed the maximum number of iterations possibly \"\n                     \"required\")\n                     \n    if not (0.5 <= opts.damping <= 1.0):\n        parser.error(\"The damping parameter is restricted to values \"\n                     \"between 0.5 and 1.0\")\n        \n    return opts, args[0]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_HDF5_arrays(hdf5_file, N, convergence_iter):\n    \n    Worker.hdf5_lock.acquire()\n\n    with tables.open_file(hdf5_file, 'r+') as fileh:\n        if not hasattr(fileh.root, 'aff_prop_group'):\n            fileh.create_group(fileh.root, \"aff_prop_group\")\n\n        atom = tables.Float32Atom()\n        filters = None\n        #filters = tables.Filters(5, 'blosc')\n            \n        for feature in ('availabilities', 'responsibilities',\n                            'similarities', 'temporaries'):\n            if not hasattr(fileh.root.aff_prop_group, feature):\n                fileh.create_carray(fileh.root.aff_prop_group, feature, \n                         atom, (N, N), \"Matrix of {0} for affinity \"\n                         \"propagation clustering\".format(feature), \n                         filters = filters)\n\n        if not hasattr(fileh.root.aff_prop_group, 'parallel_updates'):\n            fileh.create_carray(fileh.root.aff_prop_group,\n                     'parallel_updates', atom, (N, convergence_iter), \n                     \"Matrix of parallel updates for affinity propagation \"\n                     \"clustering\", filters = filters)\n                     \n    Worker.hdf5_lock.release()", "response": "Checks that the HDF5 file contains all the required two - dimensional arrays organizing the various two - dimensional arrays required for affinity propagation clustering."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_sum(hdf5_file, path, array_out, out_lock, rows_slice):\n    \n    Worker.hdf5_lock.acquire()\n    \n    with tables.open_file(hdf5_file, 'r+') as fileh:\n        hdf5_array = fileh.get_node(path)\n        tmp = hdf5_array[rows_slice, ...]\n        \n    Worker.hdf5_lock.release()\n    \n    szum = np.sum(tmp, axis = 0)\n    with out_lock: \n        array_out += szum\n        \n    del tmp", "response": "Compute the sum of the values of the rows specified by rows_slice along a slice of rows specified by rows_slice and add the resulting \n        vector to array_out."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef terminate_processes(pid_list):\n\n    for proc in psutil.process_iter():\n        if proc.pid in pid_list:\n            proc.terminate()", "response": "Terminate processes by sending to each of them a SIGTERM signal and pre -emptively checking if its PID has been reused."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute a matrix of pairwise L2 Euclidean distances among samples from data.", "response": "def compute_similarities(hdf5_file, data, N_processes):\n    \"\"\"Compute a matrix of pairwise L2 Euclidean distances among samples from 'data'.\n        This computation is to be done in parallel by 'N_processes' distinct processes. \n        Those processes (which are instances of the class 'Similarities_worker') \n        are prevented from simultaneously accessing the HDF5 data structure \n        at 'hdf5_file' through the use of a multiprocessing.Lock object.\n    \"\"\"\n\n    slice_queue = multiprocessing.JoinableQueue()\n    \n    pid_list = []\n    for i in range(N_processes):\n        worker = Similarities_worker(hdf5_file, '/aff_prop_group/similarities',\n                                     data, slice_queue)\n        worker.daemon = True\n        worker.start()\n        pid_list.append(worker.pid)\n    \n    for rows_slice in chunk_generator(data.shape[0], 2 * N_processes):\n        slice_queue.put(rows_slice)\n        \n    slice_queue.join()    \n    slice_queue.close()\n    \n    terminate_processes(pid_list)\n    gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassigns the value preference to the diagonal entries CTYPE of the matrix of similarities stored in the HDF5 data structure at hdf5_file at hdf5_file.", "response": "def add_preference(hdf5_file, preference):\n    \"\"\"Assign the value 'preference' to the diagonal entries\n        of the matrix of similarities stored in the HDF5 data structure \n        at 'hdf5_file'.\n    \"\"\"\n\n    Worker.hdf5_lock.acquire()\n    \n    with tables.open_file(hdf5_file, 'r+') as fileh:\n        S = fileh.root.aff_prop_group.similarities\n        diag_ind = np.diag_indices(S.nrows)\n        S[diag_ind] = preference\n        \n    Worker.hdf5_lock.release()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_fluctuations(hdf5_file, N_columns, N_processes):\n\n    random_state = np.random.RandomState(0)\n        \n    slice_queue = multiprocessing.JoinableQueue()\n        \n    pid_list = []\n    for i in range(N_processes):\n        worker = Fluctuations_worker(hdf5_file,\n                   '/aff_prop_group/similarities', random_state, \n                   N_columns, slice_queue)\n        worker.daemon = True\n        worker.start()\n        pid_list.append(worker.pid)\n            \n    for rows_slice in chunk_generator(N_columns, 4 * N_processes):\n        slice_queue.put(rows_slice)\n        \n    slice_queue.join()\n    slice_queue.close()\n    \n    terminate_processes(pid_list)\n    gc.collect()", "response": "This procedure organizes the addition of small fluctuations on top of \n        a matrix of similarities at hdf5_file across N_processes different processes. Each process is started and the process is terminated."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\norganizing the computation and update of the responsibility matrix for Affinity Propagation clustering with damping parameter.", "response": "def compute_responsibilities(hdf5_file, N_columns, damping, N_processes):\n    \"\"\"Organize the computation and update of the responsibility matrix\n        for Affinity Propagation clustering with 'damping' as the eponymous \n        damping parameter. Each of the processes concurrently involved in this task \n        is an instance of the class 'Responsibilities_worker' defined above.\n    \"\"\"\n\n    slice_queue = multiprocessing.JoinableQueue()\n    \n    pid_list = []\n    for i in range(N_processes):\n        worker = Responsibilities_worker(hdf5_file, '/aff_prop_group',\n                   N_columns, damping, slice_queue)\n        worker.daemon = True\n        worker.start()\n        pid_list.append(worker.pid)\n        \n    for rows_slice in chunk_generator(N_columns, 8 * N_processes):\n        slice_queue.put(rows_slice)\n        \n    slice_queue.join()\n    slice_queue.close()\n    \n    terminate_processes(pid_list)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the tables and tables for the rows_sum_store.", "response": "def rows_sum_init(hdf5_file, path, out_lock, *numpy_args):\n    \"\"\"Create global variables sharing the same object as the one pointed by\n        'hdf5_file', 'path' and 'out_lock'.\n        Also Create a NumPy array copy of a multiprocessing.Array ctypes array \n        specified by '*numpy_args'.\n    \"\"\"\n\n    global g_hdf5_file, g_path, g_out, g_out_lock\n        \n    g_hdf5_file, g_path, g_out_lock = hdf5_file, path, out_lock\n    g_out = to_numpy_array(*numpy_args)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a share multiprocessing array to a numpy array.", "response": "def to_numpy_array(multiprocessing_array, shape, dtype):\n    \"\"\"Convert a share multiprocessing array to a numpy array.\n        No data copying involved.\n    \"\"\"\n\n    return np.frombuffer(multiprocessing_array.get_obj(),\n                         dtype = dtype).reshape(shape)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the sums of the rows of the hierarchical data format.", "response": "def compute_rows_sum(hdf5_file, path, N_columns, N_processes, method = 'Process'):\n    \"\"\"Parallel computation of the sums across the rows of two-dimensional array\n        accessible at the node specified by 'path' in the 'hdf5_file' \n        hierarchical data format. \n    \"\"\"                 \n\n    assert isinstance(method, str), \"parameter 'method' must consist in a string of characters\"\n    assert method in ('Ordinary', 'Pool'), \"parameter 'method' must be set to either of 'Ordinary' or 'Pool'\"\n    \n    if method == 'Ordinary':\n        rows_sum = np.zeros(N_columns, dtype = float)\n        \n        chunk_size = get_chunk_size(N_columns, 2)\n        with Worker.hdf5_lock:\n            with tables.open_file(hdf5_file, 'r+') as fileh:\n                hdf5_array = fileh.get_node(path)\n                \n                N_rows = hdf5_array.nrows\n                assert N_columns == N_rows\n                \n                for i in range(0, N_columns, chunk_size):\n                    slc = slice(i, min(i+chunk_size, N_columns))\n                    tmp = hdf5_array[:, slc]\n                    rows_sum[slc] = tmp[:].sum(axis = 0)\n                        \n    else:\n        rows_sum_array = multiprocessing.Array(c_double, N_columns, lock = True)\n    \n        chunk_size = get_chunk_size(N_columns, 2 * N_processes)\n        numpy_args = rows_sum_array, N_columns, np.float64\n    \n        with closing(multiprocessing.Pool(N_processes, \n                     initializer = rows_sum_init, \n                     initargs = (hdf5_file, path, rows_sum_array.get_lock()) +\n                     numpy_args)) as pool:\n            pool.map_async(multiprocessing_get_sum, \n                  chunk_generator(N_columns, 2 * N_processes), chunk_size)\n        \n        pool.close()\n        pool.join()\n    \n        rows_sum = to_numpy_array(*numpy_args)\n    \n    gc.collect()\n    \n    return rows_sum"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the availability matrix for the given data - set and the given damping parameter.", "response": "def compute_availabilities(hdf5_file, N_columns, damping, N_processes, rows_sum):\n    \"\"\"Coordinates the computation and update of the availability matrix\n        for Affinity Propagation clustering. \n    \n    Parameters\n    ----------\n    hdf5_file : string or file handle\n        Specify access to the hierarchical data format used throughout all the iterations\n        of message-passing between data-points involved in Affinity Propagation clustering.\n    \n    N_columns : int\n        The number of samples in the data-set subjected to Affinity Propagation clustering.\n    \n    damping : float\n        The damping parameter of Affinity Propagation clustering, typically set to 0.5.\n    \n    N_processes : int\n        The number of subprocesses involved in the parallel computation and update of the\n        matrix of availabitilies.\n    \n    rows_sum : array of shape (N_columns,)\n        A vector containing, for each column entry of the similarities matrix, the sum\n        of its rows entries. \n    \"\"\"\n    \n    slice_queue = multiprocessing.JoinableQueue()\n    \n    pid_list = []\n    for i in range(N_processes):\n        worker = Availabilities_worker(hdf5_file, '/aff_prop_group',\n                   N_columns, damping, slice_queue, rows_sum)\n        worker.daemon = True\n        worker.start()\n        pid_list.append(worker.pid)\n        \n    for rows_slice in chunk_generator(N_columns, 8 * N_processes):\n        slice_queue.put(rows_slice)\n        \n    slice_queue.join()\n    slice_queue.close()\n    \n    terminate_processes(pid_list)\n    gc.collect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the estimated number of clusters has not changed for a given number of times convergence_iter consecutive iterations in a total of max_iter rounds of message - passing .", "response": "def check_convergence(hdf5_file, iteration, convergence_iter, max_iter):\n    \"\"\"If the estimated number of clusters has not changed for 'convergence_iter'\n        consecutive iterations in a total of 'max_iter' rounds of message-passing, \n        the procedure herewith returns 'True'.\n        Otherwise, returns 'False'.\n        Parameter 'iteration' identifies the run of message-passing \n        that has just completed.\n    \"\"\"\n\n    Worker.hdf5_lock.acquire()\n    \n    with tables.open_file(hdf5_file, 'r+') as fileh:\n        A = fileh.root.aff_prop_group.availabilities\n        R = fileh.root.aff_prop_group.responsibilities\n        P = fileh.root.aff_prop_group.parallel_updates\n        \n        N = A.nrows\n        diag_ind = np.diag_indices(N)\n        \n        E = (A[diag_ind] + R[diag_ind]) > 0\n        P[:, iteration % convergence_iter] = E\n        \n        e_mat = P[:]\n        K = E.sum(axis = 0)\n        \n    Worker.hdf5_lock.release()\n        \n    if iteration >= convergence_iter:\n        se = e_mat.sum(axis = 1)\n        unconverged = (np.sum((se == convergence_iter) + (se == 0)) != N)\n        if (not unconverged and (K > 0)) or (iteration == max_iter):\n                return True\n                \n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nseconds task to be performed by a pool of subprocesses before the cluster labels and cluster center indices can be identified.", "response": "def cluster_labels_B(hdf5_file, s_reduced, lock, I, ii, iix, rows_slice):\n    \"\"\"Second task to be performed by a pool of subprocesses before\n        the cluster labels and cluster center indices can be identified.\n    \"\"\"\n\n    with Worker.hdf5_lock:\n        with tables.open_file(hdf5_file, 'r+') as fileh:\n            S = fileh.root.aff_prop_group.similarities\n            s = S[rows_slice, ...]\n           \n    s = s[:, ii]\n    s = s[iix[rows_slice]]\n    \n    with lock:                \n        s_reduced += s[:].sum(axis = 0)\n        \n    del s"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_cluster_labels(hdf5_file, N_processes):\n\n    with Worker.hdf5_lock:\n        with tables.open_file(hdf5_file, 'r+') as fileh:\n            A = fileh.root.aff_prop_group.availabilities\n            R = fileh.root.aff_prop_group.responsibilities\n    \n            N = A.nrows\n            diag_ind = np.diag_indices(N)\n            \n            a = A[diag_ind]\n            r = R[diag_ind]\n    \n    I = np.where(np.add(a[:], r[:]) > 0)[0]\n    K = I.size\n    \n    if K == 0:\n        labels = np.empty((N, 1))\n        labels.fill(np.nan)\n        cluster_centers_indices = None\n        \n    else:\n        c_array = multiprocessing.Array(c_int, N, lock = True)\n    \n        chunk_size = get_chunk_size(N, 3 * N_processes)\n        numpy_args = c_array, N, np.int32\n    \n        with closing(multiprocessing.Pool(N_processes, \n                     initializer = cluster_labels_init, \n                     initargs = (hdf5_file, I, c_array.get_lock()) \n                               + numpy_args)) as pool:\n            pool.map_async(multiprocessing_cluster_labels_A, \n                  chunk_generator(N, 3 * N_processes), chunk_size)\n        \n        pool.close()\n        pool.join()\n        \n        gc.collect()\n        \n        c = to_numpy_array(*numpy_args)\n        c[I] = np.arange(K)\n        # determine the exemplars of clusters, applying some \n        # cosmetics to our results before returning them\n        for k in range(K):\n            ii = np.where(c == k)[0]\n            \n            iix = np.full(N, False, dtype = bool)\n            iix[ii] = True\n            \n            s_reduced_array = multiprocessing.Array(c_double, ii.size, \n                                                    lock = True)\n        \n            chunk_size = get_chunk_size(N, 3 * N_processes)\n            numpy_args = s_reduced_array, ii.size, np.float64\n            \n            with closing(multiprocessing.Pool(N_processes,\n                         initializer = cluster_labels_init_B,\n                         initargs = (hdf5_file, I, ii, iix, \n                         s_reduced_array.get_lock())\n                         + numpy_args)) as pool:\n                pool.map_async(multiprocessing_cluster_labels_B,\n                      chunk_generator(N, 3 * N_processes), chunk_size)\n                               \n            pool.close()\n            pool.join()\n            \n            s_reduced = to_numpy_array(*numpy_args)\n            \n            j = np.argmax(s_reduced)\n            I[k] = ii[j]\n            \n            gc.collect()\n            \n        c_array = multiprocessing.Array(c_int, N, lock = True)\n        \n        chunk_size = get_chunk_size(N, 3 * N_processes)\n        numpy_args = c_array, N, np.int32\n    \n        with closing(multiprocessing.Pool(N_processes, \n                     initializer = cluster_labels_init, \n                     initargs = (hdf5_file, I, c_array.get_lock()) \n                               + numpy_args)) as pool:\n            pool.map_async(multiprocessing_cluster_labels_C, \n                  chunk_generator(N, 3 * N_processes), chunk_size)\n        \n        pool.close()\n        pool.join()\n        \n        c = to_numpy_array(*numpy_args)\n        c[I] = np.arange(K)\n        labels = I[c]\n        \n        gc.collect()\n\n        cluster_centers_indices = np.unique(labels)\n        labels = np.searchsorted(cluster_centers_indices, labels)\n        \n    return cluster_centers_indices, labels", "response": "Returns a list of labels for each cluster in the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef output_clusters(labels, cluster_centers_indices):\n            \n    here = os.getcwd()\n    try:\n        output_directory = os.path.join(here, 'concurrent_AP_output')\n        os.makedirs(output_directory)\n    except OSError:\n        if not os.path.isdir(output_directory):\n            print(\"ERROR: concurrent_AP: output_clusters: cannot create a directory \"\n                  \"for storage of the results of Affinity Propagation clustering \"\n                  \"in your current working directory\")\n            sys.exit(1)\n            \n    if any(np.isnan(labels)):\n        fmt = '%.1f'\n    else:\n        fmt = '%d'\n                \n    with open(os.path.join(output_directory, 'labels.tsv'), 'w') as fh:\n        np.savetxt(fh, labels, fmt = fmt, delimiter = '\\t')\n        \n    if cluster_centers_indices is not None:    \n        with open(os.path.join(output_directory, 'cluster_centers_indices.tsv'), 'w') as fh:\n            np.savetxt(fh, cluster_centers_indices, fmt = '%.1f', \n                       delimiter = '\\t')", "response": "Write in tab - separated files the vectors of cluster identities and cluster centers and indices of indices of cluster centers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the median of the distribution of pairwise L2 Euclidean distances between the data - points and the default preference parameter for Affinity Propagation clustering.", "response": "def set_preference(data, chunk_size):\n    \"\"\"Return the median of the distribution of pairwise L2 Euclidean distances \n        between samples (the rows of 'data') as the default preference parameter\n        for Affinity Propagation clustering.\n\n    Parameters\n    ----------\n    data : array of shape (N_samples, N_features)\n        The data-set submitted for Affinity Propagation clustering.\n        \n    chunk_size : int\n        The size of random subsamples from the data-set whose similarity\n        matrix is computed. The resulting median of the distribution of \n        pairwise distances between the data-points selected as part of a\n        given subsample is stored into a list of medians. \n\n    Returns\n    -------\n    preference : float\n        The preference parameter for Affinity Propagation clustering is computed\n        as the median of the list of median pairwise distances between the data-points\n        selected as part of each of 15 rounds of random subsampling.\n    \"\"\"\n\n    N_samples, N_features = data.shape\n    \n    rng = np.arange(0, N_samples, dtype = int)\n    medians = []\n    \n    for i in range(15):\n        selected_samples = np.random.choice(N_samples, size = chunk_size, replace = False)\n        samples = data[selected_samples, :]\n                \n        S = - euclidean_distances(samples, data, squared = True)\n                \n        n = chunk_size * N_samples - (chunk_size * (chunk_size + 1) / 2)\n                \n        rows = np.zeros(0, dtype = int)\n        for i in range(chunk_size):\n            rows = np.append(rows, np.full(N_samples - i, i, dtype = int))\n                \n        cols = np.zeros(0, dtype = int)\n        for i in range(chunk_size):\n            cols = np.append(cols, np.delete(rng, selected_samples[:i+1]))\n                        \n        triu_indices = tuple((rows, cols))\n                \n        preference = np.median(S, overwrite_input = True)\n        medians.append(preference)\n                \n        del S\n                \n        if i % 4 == 3:\n            gc.collect()       \n            \n    preference = np.median(medians)\n\n    return preference"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a list of Term objects from the retina", "response": "def getTerms(self, term=None, getFingerprint=None, startIndex=0, maxResults=10):\n        \"\"\"Get term objects\n        Args:\n            term, str: A term in the retina (optional)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            startIndex, int: The start-index for pagination (optional)\n            maxResults, int: Max results per page (optional)\n        Returns: \n            list of Term\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._terms.getTerm(self._retina, term, getFingerprint, startIndex, maxResults)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getContextsForTerm(self, term, getFingerprint=None, startIndex=0, maxResults=5):\n        return self._terms.getContextsForTerm(self._retina, term, getFingerprint, startIndex, maxResults)", "response": "Returns a list of Context objects for a given term in the retina."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of similar terms for a given term in the retina context.", "response": "def getSimilarTermsForTerm(self, term, contextId=None, posType=None, getFingerprint=None, startIndex=0, maxResults=10):\n        \"\"\"Get the similar terms of a given term\n        Args:\n            term, str: A term in the retina (required)\n            contextId, int: The identifier of a context (optional)\n            posType, str: Part of speech (optional)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            startIndex, int: The start-index for pagination (optional)\n            maxResults, int: Max results per page (optional)\n        Returns:\n            list of Term\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._terms.getSimilarTerms(self._retina, term, contextId, posType, getFingerprint, startIndex, maxResults)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getTokensForText(self, body, POStags=None):\n        return self._text.getTokensForText(self._retina, body, POStags)", "response": "Get tokenized input text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getSlicesForText(self, body, getFingerprint=None, startIndex=0, maxResults=10):\n        return self._text.getSlicesForText(self._retina, body, getFingerprint, startIndex, maxResults)", "response": "Returns a list of slices of the text that are part of the results of the text."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getFingerprintsForTexts(self, strings, sparsity=1.0):\n        body = [{\"text\": s} for s in strings]\n        return self._text.getRepresentationsForBulkText(self._retina, json.dumps(body), sparsity)", "response": "Bulk get Fingerprint for text."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getFingerprintForExpression(self, body, sparsity=1.0):\n        return self._expressions.resolveExpression(self._retina, body, sparsity)", "response": "Resolve an expression to a unique fingerprint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of semantic contexts for the input expression.", "response": "def getContextsForExpression(self, body, getFingerprint=None, startIndex=0, maxResults=5, sparsity=1.0):\n        \"\"\"Get semantic contexts for the input expression\n        Args:\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            startIndex, int: The start-index for pagination (optional)\n            maxResults, int: Max results per page (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n        Returns:\n            list of Context\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._expressions.getContextsForExpression(self._retina, body, getFingerprint, startIndex, maxResults, sparsity)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getSimilarTermsForExpression(self, body, contextId=None, posType=None, getFingerprint=None, startIndex=0, maxResults=10, sparsity=1.0):\n        return self._expressions.getSimilarTermsForExpressionContext(self._retina, body, contextId, posType, getFingerprint, startIndex, maxResults, sparsity)", "response": "Returns a list of similar terms for the contexts of an expression"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getFingerprintsForExpressions(self, body, sparsity=1.0):\n        return self._expressions.resolveBulkExpression(self._retina, body, sparsity)", "response": "Bulk resolution of expressions\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbulks get contexts for input expressions", "response": "def getContextsForExpressions(self, body, getFingerprint=None, startIndex=0, maxResults=5, sparsity=1.0):\n        \"\"\"Bulk get contexts for input expressions\n        Args:\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            startIndex, int: The start-index for pagination (optional)\n            maxResults, int: Max results per page (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n        Returns:\n            list of Context\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._expressions.getContextsForBulkExpression(self._retina, body, getFingerprint, startIndex, maxResults, sparsity)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbulks get similar terms for expressions in a context", "response": "def getSimilarTermsForExpressions(self, body, contextId=None, posType=None, getFingerprint=None, startIndex=0, maxResults=10, sparsity=1.0):\n        \"\"\"Bulk get similar terms for input expressions\n        Args:\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            contextId, int: The identifier of a context (optional)\n            posType, str: Part of speech (optional)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            startIndex, int: The start-index for pagination (optional)\n            maxResults, int: Max results per page (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n        Returns:\n            list of Term\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._expressions.getSimilarTermsForBulkExpressionContext(self._retina, body, contextId, posType, getFingerprint, startIndex, maxResults, sparsity)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getImage(self, body, imageScalar=2, plotShape=\"circle\", imageEncoding=\"base64/png\", sparsity=1.0):\n        return self._image.getImageForExpression(self._retina, body, imageScalar, plotShape, imageEncoding, sparsity)", "response": "Get the image for the expressions\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget an overlay image for two expressions", "response": "def compareImage(self, body, plotShape=\"circle\", imageScalar=2, imageEncoding=\"base64/png\"):\n        \"\"\"Get an overlay image for two expressions\n        Args:\n            body, ExpressionOperation: The JSON encoded comparison array to be evaluated (required)\n            plotShape, str: The image shape (optional)\n            imageScalar, int: The scale of the image (optional)\n            imageEncoding, str: The encoding of the returned image (optional)\n        Returns:\n            str with the raw byte data of the image\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._image.getOverlayImage(self._retina, body, plotShape, imageScalar, imageEncoding)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbulks get images for expressions", "response": "def getImages(self, body, getFingerprint=None, imageScalar=2, plotShape=\"circle\", sparsity=1.0):\n        \"\"\"Bulk get images for expressions\n        Args:\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            getFingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            imageScalar, int: The scale of the image (optional)\n            plotShape, str: The image shape (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n        Returns:\n            list of Image\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        return self._image.getImageForBulkExpressions(self._retina, body, getFingerprint, imageScalar, plotShape, sparsity)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef createCategoryFilter(self, filterName, positiveExamples, negativeExamples=[]):\n        samples = {\"positiveExamples\": [{\"text\": s} for s in positiveExamples],\n                   \"negativeExamples\": [{\"text\": s} for s in negativeExamples]}\n        body = json.dumps(samples)\n        return self._classify.createCategoryFilter(self._retina, filterName, body)", "response": "Create a classifier filter for positive and negative text samples\n            - > CategoryFilter"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the list of contexts for a given term in the retina", "response": "def getContextsForTerm(self, retina_name, term, get_fingerprint=None, start_index=0, max_results=5):\n        \"\"\"Get the contexts for a given term\n        Args:\n            retina_name, str: The retina name (required)\n            term, str: A term in the retina (required)\n            get_fingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            start_index, int: The start-index for pagination (optional) (optional)\n            max_results, int: Max results per page (optional) (optional)\n            Returns: Array[Context]\n        \"\"\"\n\n        resourcePath = '/terms/contexts'\n        method = 'GET'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['term'] = term\n        queryParams['start_index'] = start_index\n        queryParams['max_results'] = max_results\n        queryParams['get_fingerprint'] = get_fingerprint\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [context.Context(**r) for r in response.json()]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getSimilarTerms(self, retina_name, term, context_id=None, pos_type=None, get_fingerprint=None, start_index=0, max_results=10):\n\n        resourcePath = '/terms/similar_terms'\n        method = 'GET'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['term'] = term\n        queryParams['context_id'] = context_id\n        queryParams['start_index'] = start_index\n        queryParams['max_results'] = max_results\n        queryParams['pos_type'] = pos_type\n        queryParams['get_fingerprint'] = get_fingerprint\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [Term(**r) for r in response.json()]", "response": "Returns the similar terms of a given term in a given retina context."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef createCategoryFilter(self, retina_name, filter_name, body, ):\n\n        resourcePath = '/classify/create_category_filter'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['filter_name'] = filter_name\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n            \n        return category_filter.CategoryFilter(**response.json())", "response": "create a category filter for the classifier"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getImageForExpression(self, retina_name, body, image_scalar=2, plot_shape=\"circle\", image_encoding=\"base64/png\", sparsity=1.0):\n\n        resourcePath = '/image'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'image/png', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['image_scalar'] = image_scalar\n        queryParams['plot_shape'] = plot_shape\n        queryParams['image_encoding'] = image_encoding\n        queryParams['sparsity'] = sparsity\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return response.content", "response": "Get the image for the expressions that match the given retina name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbulks get images for expressions", "response": "def getImageForBulkExpressions(self, retina_name, body, get_fingerprint=None, image_scalar=2, plot_shape=\"circle\", sparsity=1.0):\n        \"\"\"Bulk get images for expressions\n        Args:\n            retina_name, str: The retina name (required)\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            get_fingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            image_scalar, int: The scale of the image (optional) (optional)\n            plot_shape, str: The image shape (optional) (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n            Returns: Array[Image]\n        \"\"\"\n\n        resourcePath = '/image/bulk'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['image_scalar'] = image_scalar\n        queryParams['plot_shape'] = plot_shape\n        queryParams['sparsity'] = sparsity\n        queryParams['get_fingerprint'] = get_fingerprint\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [image.Image(**r) for r in response.json()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a list of keywords for a text in the retina user.", "response": "def getKeywordsForText(self, retina_name, body, ):\n        \"\"\"Get a list of keywords from the text\n        Args:\n            retina_name, str: The retina name (required)\n            body, str: The text to be evaluated (required)\n            Returns: Array[str]\n        \"\"\"\n\n        resourcePath = '/text/keywords'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return response.json()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a list of slices of the text Args: retina_name, str: The retina name (required) body, str: The text to be evaluated (required) get_fingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional) start_index, int: The start-index for pagination (optional) (optional) max_results, int: Max results per page (optional) (optional) Returns: Array[Text]", "response": "def getSlicesForText(self, retina_name, body, get_fingerprint=None, start_index=0, max_results=10):\n        \"\"\"Get a list of slices of the text\n        Args:\n            retina_name, str: The retina name (required)\n            body, str: The text to be evaluated (required)\n            get_fingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            start_index, int: The start-index for pagination (optional) (optional)\n            max_results, int: Max results per page (optional) (optional)\n            Returns: Array[Text]\n        \"\"\"\n\n        resourcePath = '/text/slices'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['start_index'] = start_index\n        queryParams['max_results'] = max_results\n        queryParams['get_fingerprint'] = get_fingerprint\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [text.Text(**r) for r in response.json()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetecting the language of a text Args: body, str: Your input text (UTF-8) (required) Returns: LanguageRest", "response": "def getLanguage(self, body, ):\n        \"\"\"Detect the language of a text\n        Args:\n            body, str: Your input text (UTF-8) (required)\n            Returns: LanguageRest\n        \"\"\"\n\n        resourcePath = '/text/detect_language'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return language_rest.LanguageRest(**response.json())"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a string representing a stylesheet into a list of declarations.", "response": "def stylesheet_declarations(string, is_merc=False, scale=1):\n    \"\"\" Parse a string representing a stylesheet into a list of declarations.\n    \n        Required boolean is_merc indicates whether the projection should\n        be interpreted as spherical mercator, so we know what to do with\n        zoom/scale-denominator in parse_rule().\n    \"\"\"\n    # everything is display: map by default\n    display_map = Declaration(Selector(SelectorElement(['*'], [])),\n                              Property('display'), Value('map', False),\n                              (False, (0, 0, 0), (0, 0)))\n    \n    declarations = [display_map]\n\n    tokens = cssTokenizer().tokenize(string)\n    variables = {}\n    \n    while True:\n        try:\n            for declaration in parse_rule(tokens, variables, [], [], is_merc):\n                if scale != 1:\n                    declaration.scaleBy(scale)\n            \n                declarations.append(declaration)\n        except StopIteration:\n            break\n    \n    # sort by a css-like method\n    return sorted(declarations, key=operator.attrgetter('sort_key'))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing an attribute selector from a token stream.", "response": "def parse_attribute(tokens, is_merc):\n    \"\"\" Parse a token stream from inside an attribute selector.\n    \n        Enter this function after a left-bracket is found:\n        http://www.w3.org/TR/CSS2/selector.html#attribute-selectors\n    \"\"\"\n    #\n    # Local helper functions\n    #\n\n    def next_scalar(tokens, op):\n        \"\"\" Look for a scalar value just after an attribute selector operator.\n        \"\"\"\n        while True:\n            tname, tvalue, line, col = tokens.next()\n            if tname == 'NUMBER':\n                try:\n                    value = int(tvalue)\n                except ValueError:\n                    value = float(tvalue)\n                return value\n            elif (tname, tvalue) == ('CHAR', '-'):\n                tname, tvalue, line, col = tokens.next()\n                if tname == 'NUMBER':\n                    try:\n                        value = int(tvalue)\n                    except ValueError:\n                        value = float(tvalue)\n                    return -value\n                else:\n                    raise ParseException('Unexpected non-number after a minus sign', line, col)\n            elif tname in ('STRING', 'IDENT'):\n                if op in ('<', '<=', '=>', '>'):\n                    raise ParseException('Selector attribute must use a number for comparison tests', line, col)\n                if tname == 'STRING':\n                    return tvalue[1:-1]\n                else:\n                    return tvalue\n            elif tname != 'S':\n                raise ParseException('Unexpected non-scalar token in attribute', line, col)\n    \n    def finish_attribute(tokens):\n        \"\"\" Look for the end of an attribute selector operator.\n        \"\"\"\n        while True:\n            tname, tvalue, line, col = tokens.next()\n            if (tname, tvalue) == ('CHAR', ']'):\n                return\n            elif tname != 'S':\n                raise ParseException('Found something other than a closing right-bracket at the end of attribute', line, col)\n    \n    #\n    # The work.\n    #\n    \n    while True:\n        tname, tvalue, line, col = tokens.next()\n        \n        if tname == 'IDENT':\n            property = tvalue\n            \n            while True:\n                tname, tvalue, line, col = tokens.next()\n                \n                if (tname, tvalue) in [('CHAR', '<'), ('CHAR', '>')]:\n                    _tname, _tvalue, line, col = tokens.next()\n        \n                    if (_tname, _tvalue) == ('CHAR', '='):\n                        #\n                        # Operator is one of '<=', '>='\n                        #\n                        op = tvalue + _tvalue\n                        value = next_scalar(tokens, op)\n                        finish_attribute(tokens)\n                        return SelectorAttributeTest(property, op, value)\n                    \n                    else:\n                        #\n                        # Operator is one of '<', '>' and we popped a token too early\n                        #\n                        op = tvalue\n                        value = next_scalar(chain([(_tname, _tvalue, line, col)], tokens), op)\n                        finish_attribute(tokens)\n                        return SelectorAttributeTest(property, op, value)\n                \n                elif (tname, tvalue) == ('CHAR', '!'):\n                    _tname, _tvalue, line, col = tokens.next()\n        \n                    if (_tname, _tvalue) == ('CHAR', '='):\n                        #\n                        # Operator is '!='\n                        #\n                        op = tvalue + _tvalue\n                        value = next_scalar(tokens, op)\n                        finish_attribute(tokens)\n                        return SelectorAttributeTest(property, op, value)\n                    \n                    else:\n                        raise ParseException('Malformed operator in attribute selector', line, col)\n                \n                elif (tname, tvalue) == ('CHAR', '='):\n                    #\n                    # Operator is '='\n                    #\n                    op = tvalue\n                    value = next_scalar(tokens, op)\n                    finish_attribute(tokens)\n                    return SelectorAttributeTest(property, op, value)\n                \n                elif tname != 'S':\n                    raise ParseException('Missing operator in attribute selector', line, col)\n        \n        elif tname != 'S':\n            raise ParseException('Unexpected token in attribute selector', line, col)\n\n    raise ParseException('Malformed attribute selector', line, col)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a list of property value tokens into a single Value instance.", "response": "def postprocess_value(property, tokens, important, line, col):\n    \"\"\" Convert a list of property value tokens into a single Value instance.\n    \n        Values can be numbers, strings, colors, uris, or booleans:\n        http://www.w3.org/TR/CSS2/syndata.html#values\n    \"\"\"\n    #\n    # Helper function.\n    #\n    \n    def combine_negative_numbers(tokens, line, col):\n        \"\"\" Find negative numbers in a list of tokens, return a new list.\n        \n            Negative numbers come as two tokens, a minus sign and a number.\n        \"\"\"\n        tokens, original_tokens = [], iter(tokens)\n        \n        while True:\n            try:\n                tname, tvalue = original_tokens.next()[:2]\n                \n                if (tname, tvalue) == ('CHAR', '-'):\n                    tname, tvalue = original_tokens.next()[:2]\n    \n                    if tname == 'NUMBER':\n                        # minus sign with a number is a negative number\n                        tokens.append(('NUMBER', '-'+tvalue))\n                    else:\n                        raise ParseException('Unexpected non-number after a minus sign', line, col)\n    \n                else:\n                    tokens.append((tname, tvalue))\n    \n            except StopIteration:\n                break\n        \n        return tokens\n    \n    #\n    # The work.\n    #\n    \n    tokens = combine_negative_numbers(tokens, line, col)\n    \n    if properties[property.name] in (int, float, str, color, uri, boolean) or type(properties[property.name]) is tuple:\n        if len(tokens) != 1:\n            raise ParseException('Single value only for property \"%(property)s\"' % locals(), line, col)\n\n    if properties[property.name] is int:\n        if tokens[0][0] != 'NUMBER':\n            raise ParseException('Number value only for property \"%(property)s\"' % locals(), line, col)\n\n        value = int(tokens[0][1])\n\n    elif properties[property.name] is float:\n        if tokens[0][0] != 'NUMBER':\n            raise ParseException('Number value only for property \"%(property)s\"' % locals(), line, col)\n\n        value = float(tokens[0][1])\n\n    elif properties[property.name] is str:\n        if tokens[0][0] != 'STRING':\n            raise ParseException('String value only for property \"%(property)s\"' % locals(), line, col)\n\n        value = str(tokens[0][1][1:-1])\n\n    elif properties[property.name] is color_transparent:\n        if tokens[0][0] != 'HASH' and (tokens[0][0] != 'IDENT' or tokens[0][1] != 'transparent'):\n            raise ParseException('Hash or transparent value only for property \"%(property)s\"' % locals(), line, col)\n\n        if tokens[0][0] == 'HASH':\n            if not re.match(r'^#([0-9a-f]{3}){1,2}$', tokens[0][1], re.I):\n                raise ParseException('Unrecognized color value for property \"%(property)s\"' % locals(), line, col)\n    \n            hex = tokens[0][1][1:]\n            \n            if len(hex) == 3:\n                hex = hex[0]+hex[0] + hex[1]+hex[1] + hex[2]+hex[2]\n            \n            rgb = (ord(unhex(h)) for h in (hex[0:2], hex[2:4], hex[4:6]))\n            \n            value = color(*rgb)\n\n        else:\n            value = 'transparent'\n\n    elif properties[property.name] is color:\n        if tokens[0][0] != 'HASH':\n            raise ParseException('Hash value only for property \"%(property)s\"' % locals(), line, col)\n\n        if not re.match(r'^#([0-9a-f]{3}){1,2}$', tokens[0][1], re.I):\n            raise ParseException('Unrecognized color value for property \"%(property)s\"' % locals(), line, col)\n\n        hex = tokens[0][1][1:]\n        \n        if len(hex) == 3:\n            hex = hex[0]+hex[0] + hex[1]+hex[1] + hex[2]+hex[2]\n        \n        rgb = (ord(unhex(h)) for h in (hex[0:2], hex[2:4], hex[4:6]))\n        \n        value = color(*rgb)\n\n    elif properties[property.name] is uri:\n        if tokens[0][0] != 'URI':\n            raise ParseException('URI value only for property \"%(property)s\"' % locals(), line, col)\n\n        raw = str(tokens[0][1])\n\n        if raw.startswith('url(\"') and raw.endswith('\")'):\n            raw = raw[5:-2]\n            \n        elif raw.startswith(\"url('\") and raw.endswith(\"')\"):\n            raw = raw[5:-2]\n            \n        elif raw.startswith('url(') and raw.endswith(')'):\n            raw = raw[4:-1]\n\n        value = uri(raw)\n            \n    elif properties[property.name] is boolean:\n        if tokens[0][0] != 'IDENT' or tokens[0][1] not in ('true', 'false'):\n            raise ParseException('true/false value only for property \"%(property)s\"' % locals(), line, col)\n\n        value = boolean(tokens[0][1] == 'true')\n            \n    elif type(properties[property.name]) is tuple:\n        if tokens[0][0] != 'IDENT':\n            raise ParseException('Identifier value only for property \"%(property)s\"' % locals(), line, col)\n\n        if tokens[0][1] not in properties[property.name]:\n            raise ParseException('Unrecognized value for property \"%(property)s\"' % locals(), line, col)\n\n        value = str(tokens[0][1])\n            \n    elif properties[property.name] is numbers:\n        values = []\n        \n        # strip spaces from the list\n        relevant_tokens = [token for token in tokens if token[0] != 'S']\n        \n        for (i, token) in enumerate(relevant_tokens):\n            if (i % 2) == 0 and token[0] == 'NUMBER':\n                try:\n                    value = int(token[1])\n                except ValueError:\n                    value = float(token[1])\n\n                values.append(value)\n\n            elif (i % 2) == 1 and token[0] == 'CHAR':\n                # fine, it's a comma\n                continue\n\n            else:\n                raise ParseException('Value for property \"%(property)s\" should be a comma-delimited list of numbers' % locals(), line, col)\n\n        value = numbers(*values)\n\n    elif properties[property.name] is strings:\n        values = []\n    \n        # strip spaces from the list\n        relevant_tokens = [token for token in tokens if token[0] != 'S']\n        \n        for (i, token) in enumerate(relevant_tokens):\n            if (i % 2) == 0 and token[0] == 'STRING':\n                values.append(str(token[1][1:-1]))\n            \n            elif (i % 2) == 1 and token == ('CHAR', ','):\n                # fine, it's a comma\n                continue\n            \n            else:\n                raise ParseException('Value for property \"%(property)s\" should be a comma-delimited list of strings' % locals(), line, col)\n    \n        value = strings(*values)\n\n    return Value(value, important)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing a block of declarations.", "response": "def parse_block(tokens, variables, selectors, is_merc):\n    \"\"\" Parse a token stream into an array of declaration tuples.\n    \n        In addition to tokens, requires a dictionary of declared variables,\n        a list of selectors that will apply to the declarations parsed in\n        this block, and a boolean flag for mercator projection, both needed\n        by possible recursive calls back to parse_rule().\n    \n        Return an array of (property, value, (line, col), importance).\n    \n        Enter this function after a left-brace is found:\n        http://www.w3.org/TR/CSS2/syndata.html#block\n    \"\"\"\n    #\n    # Local helper functions\n    #\n\n    def parse_value(tokens, variables):\n        \"\"\" Look for value tokens after a property name, possibly !important.\n        \"\"\"\n        value = []\n        while True:\n            tname, tvalue, line, col = tokens.next()\n            if (tname, tvalue) == ('CHAR', '!'):\n                while True:\n                    tname, tvalue, line, col = tokens.next()\n                    if (tname, tvalue) == ('IDENT', 'important'):\n                        while True:\n                            tname, tvalue, line, col = tokens.next()\n                            if (tname, tvalue) == ('CHAR', ';'):\n                                #\n                                # end of a high-importance value\n                                #\n                                return value, True\n                            elif (tname, tvalue) == ('CHAR', '}'):\n                                #\n                                # end of a block means end of a value\n                                #\n                                raise BlockTerminatedValue(value, True, line, col)\n                            elif (tname, tvalue) == ('S', '\\n'):\n                                raise ParseException('Unexpected end of line', line, col)\n                            elif tname not in ('S', 'COMMENT'):\n                                raise ParseException('Unexpected values after !important declaration', line, col)\n                        break\n                    else:\n                        raise ParseException('Malformed declaration after \"!\"', line, col)\n                break\n            elif (tname, tvalue) == ('CHAR', ';'):\n                #\n                # end of a low-importance value\n                #\n                return value, False\n            elif (tname, tvalue) == ('CHAR', '}'):\n                #\n                # end of a block means end of a value\n                #\n                raise BlockTerminatedValue(value, False, line, col)\n            elif tname == 'ATKEYWORD':\n                #\n                # Possible variable use:\n                # http://lesscss.org/#-variables\n                #\n                tokens = chain(iter(variables[tvalue]), tokens)\n            elif (tname, tvalue) == ('S', '\\n'):\n                raise ParseException('Unexpected end of line', line, col)\n            elif tname not in ('S', 'COMMENT'):\n                #\n                # Legitimate-looking value token.\n                #\n                value.append((tname, tvalue))\n        raise ParseException('Malformed property value', line, col)\n    \n    #\n    # The work.\n    #\n    \n    ruleset = []\n    property_values = []\n    \n    while True:\n        tname, tvalue, line, col = tokens.next()\n        \n        if tname == 'IDENT':\n            _tname, _tvalue, _line, _col = tokens.next()\n            \n            if (_tname, _tvalue) == ('CHAR', ':'):\n                #\n                # Retrieve and process a value after a property name.\n                # http://www.w3.org/TR/CSS2/syndata.html#declaration\n                #\n                if tvalue not in properties:\n                    raise ParseException('Unsupported property name, %s' % tvalue, line, col)\n\n                try:\n                    property = Property(tvalue)\n                    vtokens, importance = parse_value(tokens, variables)\n                except BlockTerminatedValue, e:\n                    vtokens, importance = e.tokens, e.important\n                    tokens = chain([('CHAR', '}', e.line, e.col)], tokens)\n\n                value = postprocess_value(property, vtokens, importance, line, col)\n                property_values.append((property, value, (line, col), importance))\n                \n            else:\n                #\n                # We may have just found the start of a nested block.\n                # http://lesscss.org/#-nested-rules\n                #\n                tokens_ = chain([(tname, tvalue, line, col), (_tname, _tvalue, _line, _col)], tokens)\n                ruleset += parse_rule(tokens_, variables, [], selectors, is_merc)\n        \n        elif (tname, tvalue) == ('CHAR', '}'):\n            #\n            # Closing out a block\n            #\n            for (selector, property_value) in product(selectors, property_values):\n\n                property, value, (line, col), importance = property_value\n                sort_key = value.importance(), selector.specificity(), (line, col)\n\n                ruleset.append(Declaration(selector, property, value, sort_key))\n                \n            return ruleset\n        \n        elif tname in ('HASH', ) or (tname, tvalue) in [('CHAR', '.'), ('CHAR', '*'), ('CHAR', '['), ('CHAR', '&')]:\n            #\n            # One of a bunch of valid ways to start a nested rule.\n            #\n            # Most will end up rejected by Cascadenik as parsing errors,\n            # except for identifiers for text rules and the start of\n            # nested blocks with a \"&\" combinator:\n            # http://lesscss.org/#-nested-rules\n            #\n            tokens_ = chain([(tname, tvalue, line, col)], tokens)\n            ruleset += parse_rule(tokens_, variables, [], selectors, is_merc)\n        \n        elif tname not in ('S', 'COMMENT'):\n            raise ParseException('Malformed style rule', line, col)\n\n    raise ParseException('Malformed block', line, col)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a single rule set and return a list of declarations.", "response": "def parse_rule(tokens, variables, neighbors, parents, is_merc):\n    \"\"\" Parse a rule set, return a list of declarations.\n        \n        Requires a dictionary of declared variables. Selectors in the neighbors\n        list are simply grouped, and are generated from comma-delimited lists\n        of selectors in the stylesheet. Selectors in the parents list should\n        be combined with those found by this functions, and are generated\n        from nested, Less-style rulesets.\n        \n        A rule set is a combination of selectors and declarations:\n        http://www.w3.org/TR/CSS2/syndata.html#rule-sets\n        \n        Nesting is described in the Less CSS spec:\n        http://lesscss.org/#-nested-rules\n    \n        To handle groups of selectors, use recursion:\n        http://www.w3.org/TR/CSS2/selector.html#grouping\n    \"\"\"\n    #\n    # Local helper function\n    #\n\n    def validate_selector_elements(elements, line, col):\n        if len(elements) > 2:\n            raise ParseException('Only two-element selectors are supported for Mapnik styles', line, col)\n    \n        if len(elements) == 0:\n            raise ParseException('At least one element must be present in selectors for Mapnik styles', line, col)\n    \n        if elements[0].names[0] not in ('Map', 'Layer') and elements[0].names[0][0] not in ('.', '#', '*'):\n            raise ParseException('All non-ID, non-class first elements must be \"Layer\" Mapnik styles', line, col)\n        \n        if set([name[:1] for name in elements[0].names[1:]]) - set('#.'):\n            raise ParseException('All names after the first must be IDs or classes', line, col)\n        \n        if len(elements) == 2 and elements[1].countTests():\n            raise ParseException('Only the first element in a selector may have attributes in Mapnik styles', line, col)\n    \n        if len(elements) == 2 and elements[1].countIDs():\n            raise ParseException('Only the first element in a selector may have an ID in Mapnik styles', line, col)\n    \n        if len(elements) == 2 and elements[1].countClasses():\n            raise ParseException('Only the first element in a selector may have a class in Mapnik styles', line, col)\n    \n    def parse_variable_definition(tokens):\n        \"\"\" Look for variable value tokens after an @keyword, return an array.\n        \"\"\"\n        while True:\n            tname, tvalue, line, col = tokens.next()\n            \n            if (tname, tvalue) == ('CHAR', ':'):\n                vtokens = []\n            \n                while True:\n                    tname, tvalue, line, col = tokens.next()\n            \n                    if (tname, tvalue) in (('CHAR', ';'), ('S', '\\n')):\n                        return vtokens\n                    \n                    elif tname not in ('S', 'COMMENT'):\n                        vtokens.append((tname, tvalue, line, col))\n\n            elif tname not in ('S', 'COMMENT'):\n                raise ParseException('Unexpected token in variable definition: \"%s\"' % tvalue, line, col)\n            \n    #\n    # The work.\n    #\n    \n    ElementClass = SelectorElement\n    element = None\n    elements = []\n    \n    while True:\n        tname, tvalue, line, col = tokens.next()\n        \n        if tname == 'ATKEYWORD':\n            #\n            # Likely variable definition:\n            # http://lesscss.org/#-variables\n            #\n            variables[tvalue] = parse_variable_definition(tokens)\n        \n        elif (tname, tvalue) == ('CHAR', '&'):\n            #\n            # Start of a nested block with a \"&\" combinator\n            # http://lesscss.org/#-nested-rules\n            #\n            ElementClass = ConcatenatedElement\n        \n        elif tname == 'S':\n            #\n            # Definitely no longer in a \"&\" combinator.\n            #\n            ElementClass = SelectorElement\n        \n        elif tname == 'IDENT':\n            #\n            # Identifier always starts a new element.\n            #\n            element = ElementClass()\n            elements.append(element)\n            element.addName(tvalue)\n            \n        elif tname == 'HASH':\n            #\n            # Hash is an ID selector:\n            # http://www.w3.org/TR/CSS2/selector.html#id-selectors\n            #\n            if not element:\n                element = ElementClass()\n                elements.append(element)\n        \n            element.addName(tvalue)\n        \n        elif (tname, tvalue) == ('CHAR', '.'):\n            while True:\n                tname, tvalue, line, col = tokens.next()\n                \n                if tname == 'IDENT':\n                    #\n                    # Identifier after a period is a class selector:\n                    # http://www.w3.org/TR/CSS2/selector.html#class-html\n                    #\n                    if not element:\n                        element = ElementClass()\n                        elements.append(element)\n                \n                    element.addName('.'+tvalue)\n                    break\n                \n                else:\n                    raise ParseException('Malformed class selector', line, col)\n        \n        elif (tname, tvalue) == ('CHAR', '*'):\n            #\n            # Asterisk character is a universal selector:\n            # http://www.w3.org/TR/CSS2/selector.html#universal-selector\n            #\n            if not element:\n                element = ElementClass()\n                elements.append(element)\n        \n            element.addName(tvalue)\n\n        elif (tname, tvalue) == ('CHAR', '['):\n            #\n            # Left-bracket is the start of an attribute selector:\n            # http://www.w3.org/TR/CSS2/selector.html#attribute-selectors\n            #\n            if not element:\n                element = ElementClass()\n                elements.append(element)\n        \n            test = parse_attribute(tokens, is_merc)\n            element.addTest(test)\n        \n        elif (tname, tvalue) == ('CHAR', ','):\n            #\n            # Comma delineates one of a group of selectors:\n            # http://www.w3.org/TR/CSS2/selector.html#grouping\n            #\n            # Recurse here.\n            #\n            neighbors.append(Selector(*elements))\n            \n            return parse_rule(tokens, variables, neighbors, parents, is_merc)\n        \n        elif (tname, tvalue) == ('CHAR', '{'):\n            #\n            # Left-brace is the start of a block:\n            # http://www.w3.org/TR/CSS2/syndata.html#block\n            #\n            # Return a full block here.\n            #\n            class DummySelector:\n                def __init__(self, *elements):\n                    self.elements = elements[:]\n            \n            neighbors.append(DummySelector(*elements))\n            \n            selectors = []\n\n            #\n            # Combine lists of parents and neighbors into a single list of\n            # selectors, for passing off to parse_block(). There might not\n            # be any parents, but there will definitely be neighbors.\n            #\n            for parent in (parents or [DummySelector()]):\n                for neighbor in neighbors:\n                    if len(neighbor.elements) == 0:\n                        raise ParseException('At least one element must be present in selectors for Mapnik styles', line, col)\n                    \n                    elements = chain(parent.elements + neighbor.elements)\n                    selector = Selector(deepcopy(elements.next()))\n                    \n                    for element in elements:\n                        if element.__class__ is ConcatenatedElement:\n                            for name in element.names: selector.elements[-1].addName(deepcopy(name))\n                            for test in element.tests: selector.elements[-1].addTest(deepcopy(test))\n                        else:\n                            selector.addElement(deepcopy(element))\n                    \n                    # selector should be fully valid at this point.\n                    validate_selector_elements(selector.elements, line, col)\n                    selector.convertZoomTests(is_merc)\n                    selectors.append(selector)\n            \n            return parse_block(tokens, variables, selectors, is_merc)\n        \n        elif tname not in ('S', 'COMMENT'):\n            raise ParseException('Unexpected token in selector: \"%s\"' % tvalue, line, col)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget general information about all the coins available on cryptocompare.com. Args: coins: Default value of 'all' returns information about all the coins available on the site. Otherwise a single string or list of coin symbols can be used. Returns: The function returns a dictionairy containing individual dictionairies for the coins specified by the input. The key of the top dictionary corresponds to the coin symbol. Each coin dictionary has the following structure: {coin_symbol1: {'Algorithm' : ..., 'CoinName': ..., 'FullName': ..., 'FullyPremined': ..., 'Id': ..., 'ImageUrl': ..., 'Name': ..., 'PreMinedValue': ..., 'ProofType': ..., 'SortOrder': ..., 'TotalCoinsFreeFloat': ..., 'TotalCoinSupply': ..., 'Url': ...}, coin_symbol2: {...}, ...}", "response": "def get_coin_list(coins='all'):\n\t\"\"\"\n\tGet general information about all the coins available on \n\tcryptocompare.com.\n\t\n\tArgs:\n\t\tcoins: Default value of 'all' returns information about all the coins\n\t\t\tavailable on the site. Otherwise a single string or list of coin \n\t\t\tsymbols can be used.\n\n\tReturns:\n\t\tThe function returns a dictionairy containing individual dictionairies \n\t\tfor the coins specified by the input. The key of the top dictionary \n\t\tcorresponds to the coin symbol. Each coin dictionary has the following \n\t\tstructure:\n\t\t\n\t\t\t{coin_symbol1: {'Algorithm' : ...,\n\t                'CoinName': ...,\n\t                'FullName': ...,\n\t                'FullyPremined': ...,\n\t                'Id': ...,\n\t                'ImageUrl': ...,\n\t                'Name': ...,\n\t                'PreMinedValue': ...,\n\t                'ProofType': ...,\n\t                'SortOrder': ...,\n\t                'TotalCoinsFreeFloat': ...,\n\t                'TotalCoinSupply': ...,\n\t\t\t\t    'Url': ...},\n\t \t\tcoin_symbol2: {...},\n \t\t\t...}\n\t\"\"\"\n\t\n\t# convert single coins input to single element lists\n\tif not isinstance(coins, list) and coins != 'all':\n\t\tcoins = [coins]\n\n\t# load data\n\turl = build_url('coinlist')\n\tdata = load_data(url)['Data']\n\n\t# coins specified\n\tif coins != 'all':\n\t\tdata = {c: data[c] for c in coins}\n\n\treturn data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets blockchain information, aggregated data as well as data for the individual exchanges available for the specified currency pair. Args: fsym: FROM symbol. tsym: TO symbol. Returns: The function returns a dictionairy containing blockain as well as trading information from the different exchanges were the specified currency pair is available. {'AggregatedData': dict, 'Algorithm': ..., 'BlockNumber': ..., 'BlockReward': ..., 'Exchanges': [dict1, dict2, ...], 'NetHashesPerSecond': ..., 'ProofType': ..., 'TotalCoinsMined': ...} dict = {'FLAGS': ..., 'FROMSYMBOL': ..., 'HIGH24HOUR': ..., 'LASTMARKET': ..., 'LASTTRADEID': ..., 'LASTUPDATE': ..., 'LASTVOLUME': ..., 'LASTVOLUMETO': ..., 'LOW24HOUR': ..., 'MARKET': ..., 'OPEN24HOUR': ..., 'PRICE': ..., 'TOSYMBOL': ..., 'TYPE': ..., 'VOLUME24HOUR': ..., 'VOLUME24HOURTO': ...}", "response": "def get_coin_snapshot(fsym, tsym):\n\t\"\"\"\n\tGet blockchain information, aggregated data as well as data for the \n\tindividual exchanges available for the specified currency pair.\n\n\tArgs:\n\t\tfsym: FROM symbol.\n\t\ttsym: TO symbol.\n\t\n\tReturns:\n\t\tThe function returns a dictionairy containing blockain as well as \n\t\ttrading information from the different exchanges were the specified \n\t\tcurrency pair is available.\n\n\t\t{'AggregatedData': dict,\n \t\t 'Algorithm': ...,\n\t\t 'BlockNumber': ...,\n\t\t 'BlockReward': ...,\n\t\t 'Exchanges': [dict1, dict2, ...],\n\t\t 'NetHashesPerSecond': ...,\n\t\t 'ProofType': ...,\n\t\t 'TotalCoinsMined': ...}\n\n\t\tdict = {'FLAGS': ...,\n\t\t        'FROMSYMBOL': ...,\n\t\t        'HIGH24HOUR': ...,\n\t\t        'LASTMARKET': ...,\n\t\t        'LASTTRADEID': ...,\n\t\t        'LASTUPDATE': ...,\n\t\t        'LASTVOLUME': ...,\n\t\t        'LASTVOLUMETO': ...,\n\t\t        'LOW24HOUR': ...,\n\t\t        'MARKET': ...,\n\t\t        'OPEN24HOUR': ...,\n\t\t        'PRICE': ...,\n\t\t        'TOSYMBOL': ...,\n\t\t        'TYPE': ...,\n\t\t        'VOLUME24HOUR': ...,\n\t\t        'VOLUME24HOURTO': ...}\n\t\"\"\"\n\n\t# load data\n\turl = build_url('coinsnapshot', fsym=fsym, tsym=tsym)\n\tdata = load_data(url)['Data']\n\n\treturn data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compareBulk(self, retina_name, body):\n\n        resourcePath = '/compare/bulk'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [metric.Metric(**r) for r in response.json()]", "response": "Bulk compare an element by another"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getRetinas(self, retina_name=None):\n\n        resourcePath = '/retinas'\n        method = 'GET'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [retina.Retina(**r) for r in response.json()]", "response": "Returns a list of retinas for a given retina name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef specificity(self):\n        ids = sum(a.countIDs() for a in self.elements)\n        non_ids = sum((a.countNames() - a.countIDs()) for a in self.elements)\n        tests = sum(len(a.tests) for a in self.elements)\n        \n        return (ids, non_ids, tests)", "response": "Return the number of non - unique IDs and tests for the current page."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matches(self, tag, id, classes):\n        element = self.elements[0]\n        unmatched_ids = [name[1:] for name in element.names if name.startswith('#')]\n        unmatched_classes = [name[1:] for name in element.names if name.startswith('.')]\n        unmatched_tags = [name for name in element.names if name is not '*' and not name.startswith('#') and not name.startswith('.')]\n        \n        if tag and tag in unmatched_tags:\n            unmatched_tags.remove(tag)\n\n        if id and id in unmatched_ids:\n            unmatched_ids.remove(id)\n\n        for class_ in classes:\n            if class_ in unmatched_classes:\n                unmatched_classes.remove(class_)\n        \n        if unmatched_tags or unmatched_ids or unmatched_classes:\n            return False\n\n        else:\n            return True", "response": "Given an id and a list of classes return True if this selector would match."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scaledBy(self, scale):\n        scaled = deepcopy(self)\n    \n        for test in scaled.elements[0].tests:\n            if type(test.value) in (int, float):\n                if test.property == 'scale-denominator':\n                    test.value /= scale\n                elif test.property == 'zoom':\n                    test.value += log(scale)/log(2)\n        \n        return scaled", "response": "Return a new Selector with scale denominators scaled by a number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new Value scaled by a given number for ints and floats.", "response": "def scaledBy(self, scale):\n        \"\"\" Return a new Value scaled by a given number for ints and floats.\n        \"\"\"\n        scaled = deepcopy(self)\n    \n        if type(scaled.value) in (int, float):\n            scaled.value *= scale\n        elif isinstance(scaled.value, numbers):\n            scaled.value.values = tuple(v * scale for v in scaled.value.values)\n\n        return scaled"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload a mapnik Map from a source file.", "response": "def load_map(map, src_file, output_dir, scale=1, cache_dir=None, datasources_cfg=None, user_styles=[], verbose=False):\n    \"\"\" Apply a stylesheet source file to a given mapnik Map instance, like mapnik.load_map().\n    \n        Parameters:\n        \n          map:\n            Instance of mapnik.Map.\n        \n          src_file:\n            Location of stylesheet .mml file. Can be relative path, absolute path,\n            or fully-qualified URL of a remote stylesheet.\n        \n          output_dir:\n            ...\n        \n        Keyword Parameters:\n        \n          scale:\n            Optional scale value for output map, 2 doubles the size for high-res displays.\n        \n          cache_dir:\n            ...\n        \n          datasources_cfg:\n            ...\n        \n          user_styles:\n            A optional list of files or URLs, that override styles defined in\n            the map source. These are evaluated in order, with declarations from\n            later styles overriding those from earlier styles.\n        \n          verbose:\n            ...\n    \"\"\"\n    scheme, n, path, p, q, f = urlparse(src_file)\n    \n    if scheme in ('file', ''):\n        assert exists(src_file), \"We'd prefer an input file that exists to one that doesn't\"\n    \n    if cache_dir is None:\n        cache_dir = expanduser(CACHE_DIR)\n        \n        # only make the cache dir if it wasn't user-provided\n        if not isdir(cache_dir):\n            mkdir(cache_dir)\n            chmod(cache_dir, 0755)\n\n    dirs = Directories(output_dir, realpath(cache_dir), dirname(src_file))\n    compile(src_file, dirs, verbose, datasources_cfg=datasources_cfg, user_styles=user_styles, scale=scale).to_mapnik(map, dirs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getSimilarTerms(self, textOrFingerprint):\n        expression = self._createDictionary(textOrFingerprint)\n        terms = self._fullClient.getSimilarTermsForExpression(json.dumps(expression), maxResults=20)\n        return [t.term for t in terms]", "response": "Get the most similar terms for a given text or fingerprint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the semantic fingerprint of the input text.", "response": "def getFingerprint(self, text):\n        \"\"\"Get the semantic fingerprint of the input text.\n        Args:\n            text, str: The text to be evaluated\n        Returns:\n            list of str: the positions of the semantic fingerprint\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        fp = self._fullClient.getFingerprintForText(text)\n        return fp.positions"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the semantic similarity of texts or fingerprints. Each argument can be eiter a text or a fingerprint. Each argument can be eiter a text or a fingerprint. Each argument can be eiter a fingerprint.", "response": "def compare(self, textOrFingerprint1, textOrFingerprint2):\n        \"\"\"Returns the semantic similarity of texts or fingerprints. Each argument can be eiter a text or a fingerprint.\n        Args:\n            textOrFingerprint1, str OR list of integers\n            textOrFingerprint2, str OR list of integers\n        Returns:\n            float: the semantic similarity in the range [0;1]\n        Raises:\n            CorticalioException: if the request was not successful\n        \"\"\"\n        compareList = [self._createDictionary(textOrFingerprint1), self._createDictionary(textOrFingerprint2)]\n        metric = self._fullClient.compare(json.dumps(compareList))\n        return metric.cosineSimilarity"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef createCategoryFilter(self, positiveExamples):\n        categoryFilter = self._fullClient.createCategoryFilter(\"CategoryFilter\", positiveExamples)\n        return categoryFilter.positions", "response": "Creates a category filter fingerprint."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the available mining contracts information.", "response": "def get_mining_contracts():\n\t\"\"\"\n \tGet all the mining contracts information available.\n\n \tReturns:\n \t\tThis function returns two major dictionaries. The first one contains \n \t\tinformation about the coins for which mining contracts data is \n \t\tavailable: \n\n\t\tcoin_data: \n\n\n\t\t\t{symbol1: {'BlockNumber': ...,\n\t\t\t           'BlockReward': ...,\n\t\t\t           'BlockRewardReduction': ...,\n\t\t\t           'BlockTime': ...,\n\t\t\t           'DifficultyAdjustment': ...,\n\t\t\t           'NetHashesPerSecond': ...,\n\t\t\t           'PreviousTotalCoinsMined': ...,\n\t\t\t           'PriceUSD': ...,\n\t\t\t           'Symbol': ...,\n\t\t\t           'TotalCoinsMined': ...},\n \t\t\t symbol2: {...},\n \t\t\t ...}\n\n\t\tThe other one contains all the available mining contracts:\n\n\t\tmining_data: \n\n\t\t\t{id1: {'AffiliateURL': ...,\n\t\t\t       'Algorithm': ...,\n\t\t\t       'Company': ...,\n\t\t\t       'ContractLength': ...,\n\t\t\t       'Cost': ...,\n\t\t\t       'CurrenciesAvailable': ...,\n\t\t\t       'CurrenciesAvailableLogo': ...,\n\t\t\t       'CurrenciesAvailableName': ...,\n\t\t\t       'Currency': ...,\n\t\t\t       'FeePercentage': ...,\n\t\t\t       'FeeValue': ...,\n\t\t\t       'FeeValueCurrency': ...,\n\t\t\t       'HashesPerSecond': ...,\n\t\t\t       'Id': id1,\n\t\t\t       'LogoUrl': ...,\n\t\t\t       'Name': ...,\n\t\t\t       'ParentId': ...,\n\t\t\t       'Recommended': ...,\n\t\t\t       'Sponsored': ...,\n\t\t\t       'Url': ...},\n\t\t\t id2: {...},\n\t\t\t ...} \n\t\"\"\"\n\n\t# load data\n\turl = build_url('miningcontracts')\n\tdata = load_data(url)\n\tcoin_data = data['CoinData']\n\tmining_data = data['MiningData']\n\n\treturn coin_data, mining_data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget all the mining equipment information available. Returns: This function returns two major dictionaries. The first one contains information about the coins for which mining equipment data is available. coin_data: {symbol1: {'BlockNumber': ..., 'BlockReward': ..., 'BlockRewardReduction': ..., 'BlockTime': ..., 'DifficultyAdjustment': ..., 'NetHashesPerSecond': ..., 'PreviousTotalCoinsMined': ..., 'PriceUSD': ..., 'Symbol': ..., 'TotalCoinsMined': ...}, symbol2: {...}, ...} The other one contains all the available mining equipment. mining_data: {id1: {'AffiliateURL': ..., 'Algorithm': ..., 'Company': ..., 'Cost': ..., 'CurrenciesAvailable': ..., 'CurrenciesAvailableLogo': ..., 'CurrenciesAvailableName': ..., 'Currency': ..., 'EquipmentType': ..., 'HashesPerSecond': ..., 'Id': ..., 'LogoUrl': ..., 'Name': ..., 'ParentId': ..., 'PowerConsumption': ..., 'Recommended': ..., 'Sponsored': ..., 'Url': ...}, id2: {...},", "response": "def get_mining_equipment():\n\t\"\"\"Get all the mining equipment information available.\n\n\tReturns:\n\t\tThis function returns two major dictionaries. The first one contains information about the coins for which mining equipment data is available.\n\n\t\tcoin_data: \n\n\t\t\t{symbol1: {'BlockNumber': ...,\n\t\t\t           'BlockReward': ...,\n\t\t\t           'BlockRewardReduction': ...,\n\t\t\t           'BlockTime': ...,\n\t\t\t           'DifficultyAdjustment': ...,\n\t\t\t           'NetHashesPerSecond': ...,\n\t\t\t           'PreviousTotalCoinsMined': ...,\n\t\t\t           'PriceUSD': ...,\n\t\t\t           'Symbol': ...,\n\t\t\t           'TotalCoinsMined': ...},\n\t\t\t symbol2: {...},\n\t\t\t ...}\n\n\t\tThe other one contains all the available mining equipment.\n\n\t\tmining_data:\n\n\t\t\t{id1: {'AffiliateURL': ...,\n\t\t\t       'Algorithm': ...,\n\t\t\t       'Company': ...,\n\t\t\t       'Cost': ...,\n\t\t\t       'CurrenciesAvailable': ...,\n\t\t\t       'CurrenciesAvailableLogo': ...,\n\t\t\t       'CurrenciesAvailableName': ...,\n\t\t\t       'Currency': ...,\n\t\t\t       'EquipmentType': ...,\n\t\t\t       'HashesPerSecond': ...,\n\t\t\t       'Id': ...,\n\t\t\t       'LogoUrl': ...,\n\t\t\t       'Name': ...,\n\t\t\t       'ParentId': ...,\n\t\t\t       'PowerConsumption': ...,\n\t\t\t       'Recommended': ...,\n\t\t\t       'Sponsored': ...,\n\t\t\t       'Url': ...},\n\t\t\t id2: {...},\n\t\"\"\"\n\n\t# load data\n\turl = build_url('miningequipment')\n\tdata = load_data(url)\n\tcoin_data = data['CoinData']\n\tmining_data = data['MiningData']\n\n\treturn coin_data, mining_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite an. ini - format representation of the configuration state.", "response": "def write(self, fp):\n        \"\"\"Write an .ini-format representation of the configuration state.\"\"\"\n        if self._defaults:\n            fp.write(\"[%s]\\n\" % ConfigParser.DEFAULTSECT)\n            for (key, value) in sorted(self._defaults.items(), key=lambda x: x[0]):\n                fp.write(\"%s = %s\\n\" % (key, str(value).replace('\\n', '\\n\\t')))\n            fp.write(\"\\n\")\n        for section in sorted(self._sections):\n            fp.write(\"[%s]\\n\" % section)\n            for (key, value) in sorted(self._sections[section].items(), key=lambda x: x[0]):\n                if key != \"__name__\":\n                    fp.write(\"%s = %s\\n\" %\n                             (key, str(value).replace('\\n', '\\n\\t')))\n            fp.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive an input layers file and a directory, print the compiled XML file to stdout and save any encountered external image files to the named directory.", "response": "def main(src_file, dest_file, **kwargs):\n    \"\"\" Given an input layers file and a directory, print the compiled\n        XML file to stdout and save any encountered external image files\n        to the named directory.\n    \"\"\"\n    mmap = mapnik.Map(1, 1)\n    # allow [zoom] filters to work\n    mmap.srs = '+proj=merc +a=6378137 +b=6378137 +lat_ts=0.0 +lon_0=0.0 +x_0=0.0 +y_0=0 +k=1.0 +units=m +nadgrids=@null'\n    load_kwargs = dict([(k, v) for (k, v) in kwargs.items() if k in ('cache_dir', 'scale', 'verbose', 'datasources_cfg', 'user_styles')])\n    cascadenik.load_map(mmap, src_file, dirname(realpath(dest_file)), **load_kwargs)\n    \n    (handle, tmp_file) = tempfile.mkstemp(suffix='.xml', prefix='cascadenik-mapnik-')\n    os.close(handle)\n    mapnik.save_map(mmap, tmp_file)\n    \n    if kwargs.get('pretty'):\n        doc = ElementTree.fromstring(open(tmp_file, 'rb').read())\n        cascadenik._compile.indent(doc)\n        f = open(tmp_file, 'wb')\n        ElementTree.ElementTree(doc).write(f)\n        f.close()\n        \n    # manually unlinking seems to be required on windows\n    if os.path.exists(dest_file):\n        os.unlink(dest_file)\n\n    os.chmod(tmp_file, 0666^os.umask(0))\n    shutil.move(tmp_file, dest_file)\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nresolve an expression in a specific retina name.", "response": "def resolveExpression(self, retina_name, body, sparsity=1.0):\n        \"\"\"Resolve an expression\n        Args:\n            retina_name, str: The retina name (required)\n            body, ExpressionOperation: The JSON formatted encoded to be evaluated (required)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n            Returns: Fingerprint\n        \"\"\"\n\n        resourcePath = '/expressions'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['sparsity'] = sparsity\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return fingerprint.Fingerprint(**response.json())"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of semantic contexts for the input expression.", "response": "def getContextsForExpression(self, retina_name, body, get_fingerprint=None, start_index=0, max_results=5, sparsity=1.0):\n        \"\"\"Get semantic contexts for the input expression\n        Args:\n            retina_name, str: The retina name (required)\n            body, ExpressionOperation: The JSON encoded expression to be evaluated (required)\n            get_fingerprint, bool: Configure if the fingerprint should be returned as part of the results (optional)\n            start_index, int: The start-index for pagination (optional) (optional)\n            max_results, int: Max results per page (optional) (optional)\n            sparsity, float: Sparsify the resulting expression to this percentage (optional)\n            Returns: Array[Context]\n        \"\"\"\n\n        resourcePath = '/expressions/contexts'\n        method = 'POST'\n\n        queryParams = {}\n        headerParams = {'Accept': 'Application/json', 'Content-Type': 'application/json'}\n        postData = None\n\n        queryParams['retina_name'] = retina_name\n        queryParams['start_index'] = start_index\n        queryParams['max_results'] = max_results\n        queryParams['sparsity'] = sparsity\n        queryParams['get_fingerprint'] = get_fingerprint\n        postData = body\n        response = self.apiClient._callAPI(resourcePath, method, queryParams, postData, headerParams)\n        return [context.Context(**r) for r in response.json()]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_top_exchanges(fsym, tsym, limit=5):\n\n\t# load data\n\turl = build_url('exchanges', fsym=fsym, tsym=tsym, limit=limit)\n\tdata = load_data(url)\n\n\t# price_data = data['Data']\n\t# return [{'exchange': p['exchange'],\n\t#\t\t  'volume24hto': p['volume24hTo']} for p in price_data]\n\n\treturn data['Data']", "response": "Get the top exchanges by 24 hour trading volume for the currency pair."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the top coins by 24 hour trading volume value in the requested currency.", "response": "def get_top_coins(tsym, limit=20):\n\t\"\"\"Get top coins by 24 hour trading volume value in the requested currency.\n\t\n\tArgs:\n\t\ttsym: TO symbol.\n\t\tlimit: Number of results. Default value returns top 20 coins.\n\t\n\tReturns:\n\t\tFunction returns a list containing a dictionary for each result:\n\n\t\t[{'SUPPLY': ..., 'SYMBOL': ..., 'VOLUME24HOURTO': ...}, \n\t\t {...}, \n\t\t ...]\n\n\t\tThe list is ordered based on the volume of the TO currency starting with \n\t\tthe highest value.\n\t\"\"\"\n\t\n\t# load data\n\turl = build_url('volumes', tsym=tsym, limit=limit)\n\tdata = load_data(url)\n\n\treturn data['Data']"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets top trading pairs by 24 hour aggregated volume for a FROM currency.", "response": "def get_top_pairs(fsym, limit=5):\n\t\"\"\"Get top trading pairs by 24 hour aggregated volume for a currency.\n\t\n\tArgs:\n\t\tfsym: FROM symbol.\n\t\tlimit: Number of results. Default value returns top 5 pairs.\n\t\n\tReturns:\n\t\tFunction returns a list containing a dictionary for each result:\n\n\t\t[{'exchange': ..., 'fromSymbol': ..., 'toSymbol': ..., 'volume24h': ..., \n\t\t  'volume24hTo': ...}, \n \t\t {...}, \n \t\t ...]\n\n\t\tThe list is ordered based on the volume of the FROM currency starting \n\t\twith the highest value.\n\t\"\"\"\n\n\t# load data\n\turl = build_url('pairs', fsym=fsym, limit=limit)\n\tdata = load_data(url)\n\n\treturn data['Data']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef key(base):\n    for root, dirs, files in os.walk(base, topdown=False):\n        for file in files:\n            yield os.path.join(root, file)", "response": "get a list of all leaf directories as strings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating filesystem - safe places for url - keyed data to be stored", "response": "def chunk(url):\n    \"\"\" create filesystem-safe places for url-keyed data to be stored \"\"\"\n    chunks = lambda l, n: [l[x: x+n] for x in xrange(0, len(l), n)]\n    url_64 = base64.urlsafe_b64encode(url)\n    return chunks(url_64, 255)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving an input file containing nothing but styles, print out an unrolled list of declarations in cascade order.", "response": "def main(filename):\n    \"\"\" Given an input file containing nothing but styles, print out an\n        unrolled list of declarations in cascade order.\n    \"\"\"\n    input = open(filename, 'r').read()\n    declarations = cascadenik.stylesheet_declarations(input, is_merc=True)\n    \n    for dec in declarations:\n        print dec.selector,\n        print '{',\n        print dec.property.name+':',\n        \n        if cascadenik.style.properties[dec.property.name] in (cascadenik.style.color, cascadenik.style.boolean, cascadenik.style.numbers):\n            print str(dec.value.value)+';',\n        \n        elif cascadenik.style.properties[dec.property.name] is cascadenik.style.uri:\n            print 'url(\"'+str(dec.value.value)+'\");',\n        \n        elif cascadenik.style.properties[dec.property.name] is str:\n            print '\"'+str(dec.value.value)+'\";',\n        \n        elif cascadenik.style.properties[dec.property.name] in (int, float) or type(cascadenik.style.properties[dec.property.name]) is tuple:\n            print str(dec.value.value)+';',\n        \n        print '}'\n    \n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _check_connection(self):\n        if ((self.tcp_disconnect_timer + 2 * self.reconnect_timeout) <\n                time.time()):\n            self.tcp_disconnect_timer = time.time()\n            raise OSError('No response from {}. Disconnecting'.format(\n                self.server_address))\n        if (self.tcp_check_timer + self.reconnect_timeout) >= time.time():\n            return\n        msg = Message().modify(\n            child_id=255, type=self.const.MessageType.internal,\n            sub_type=self.const.Internal.I_VERSION)\n        self.add_job(msg.encode)\n        self.tcp_check_timer = time.time()", "response": "Check if connection is alive every reconnect_timeout seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a unique id for the gateway.", "response": "def get_gateway_id(self):\n        \"\"\"Return a unique id for the gateway.\"\"\"\n        host, _ = self.server_address\n        try:\n            ip_address = ipaddress.ip_address(host)\n        except ValueError:\n            # Only hosts using ip address supports unique id.\n            return None\n        if ip_address.version == 6:\n            mac = get_mac_address(ip6=host)\n        else:\n            mac = get_mac_address(ip=host)\n        return mac"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _connect(self):\n        while self.protocol:\n            _LOGGER.info('Trying to connect to %s', self.server_address)\n            try:\n                sock = socket.create_connection(\n                    self.server_address, self.reconnect_timeout)\n            except socket.timeout:\n                _LOGGER.error(\n                    'Connecting to socket timed out for %s',\n                    self.server_address)\n                _LOGGER.info(\n                    'Waiting %s secs before trying to connect again',\n                    self.reconnect_timeout)\n                time.sleep(self.reconnect_timeout)\n            except OSError:\n                _LOGGER.error(\n                    'Failed to connect to socket at %s', self.server_address)\n                _LOGGER.info(\n                    'Waiting %s secs before trying to connect again',\n                    self.reconnect_timeout)\n                time.sleep(self.reconnect_timeout)\n            else:\n                self.tcp_check_timer = time.time()\n                self.tcp_disconnect_timer = time.time()\n                transport = TCPTransport(\n                    sock, lambda: self.protocol, self._check_connection)\n                poll_thread = threading.Thread(target=self._poll_queue)\n                self._stop_event.clear()\n                poll_thread.start()\n                transport.start()\n                transport.connect()\n                return", "response": "Connect to the server. This should be run in a new thread."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to the socket.", "response": "def _connect(self):\n        \"\"\"Connect to the socket.\"\"\"\n        try:\n            while True:\n                _LOGGER.info('Trying to connect to %s', self.server_address)\n                try:\n                    yield from asyncio.wait_for(\n                        self.loop.create_connection(\n                            lambda: self.protocol, *self.server_address),\n                        self.reconnect_timeout, loop=self.loop)\n                    self.tcp_check_timer = time.time()\n                    self.tcp_disconnect_timer = time.time()\n                    self._check_connection()\n                    return\n                except asyncio.TimeoutError:\n                    _LOGGER.error(\n                        'Connecting to socket timed out for %s',\n                        self.server_address)\n                    _LOGGER.info(\n                        'Waiting %s secs before trying to connect again',\n                        self.reconnect_timeout)\n                    yield from asyncio.sleep(\n                        self.reconnect_timeout, loop=self.loop)\n                except OSError:\n                    _LOGGER.error(\n                        'Failed to connect to socket at %s',\n                        self.server_address)\n                    _LOGGER.info(\n                        'Waiting %s secs before trying to connect again',\n                        self.reconnect_timeout)\n                    yield from asyncio.sleep(\n                        self.reconnect_timeout, loop=self.loop)\n        except asyncio.CancelledError:\n            _LOGGER.debug(\n                'Connect attempt to %s cancelled', self.server_address)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_connection(self):\n        try:\n            super()._check_connection()\n        except OSError as exc:\n            _LOGGER.error(exc)\n            self.protocol.transport.close()\n            self.protocol.conn_lost_callback()\n            return\n        task = self.loop.call_later(\n            self.reconnect_timeout + 0.1, self._check_connection)\n        self.cancel_check_conn = task.cancel", "response": "Check if connection is alive every reconnect_timeout seconds."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if socket is readable or writable.", "response": "def _check_socket(self, timeout=None):\n        \"\"\"Check if socket is readable/writable.\"\"\"\n        sock = self.sock\n        available_socks = select.select([sock], [sock], [sock], timeout)\n        if available_socks[2]:\n            raise OSError\n        return available_socks"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a decorator to register a function with a specific name.", "response": "def register(self, name):\n        \"\"\"Return decorator to register item with a specific name.\"\"\"\n        def decorator(func):\n            \"\"\"Register decorated function.\"\"\"\n            self[name] = func\n            return func\n\n        return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _handle_subscription(self, topics):\n        if not isinstance(topics, list):\n            topics = [topics]\n        for topic in topics:\n            topic_levels = topic.split('/')\n            try:\n                qos = int(topic_levels[-2])\n            except ValueError:\n                qos = 0\n            try:\n                _LOGGER.debug('Subscribing to: %s, qos: %s', topic, qos)\n                self._sub_callback(topic, self.recv, qos)\n            except Exception as exception:  # pylint: disable=broad-except\n                _LOGGER.exception(\n                    'Subscribe to %s failed: %s', topic, exception)", "response": "Handle subscription of topics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset up initial subscription of mysensors topics.", "response": "def _init_topics(self):\n        \"\"\"Set up initial subscription of mysensors topics.\"\"\"\n        _LOGGER.info('Setting up initial MQTT topic subscription')\n        init_topics = [\n            '{}/+/+/0/+/+'.format(self._in_prefix),\n            '{}/+/+/3/+/+'.format(self._in_prefix),\n        ]\n        self._handle_subscription(init_topics)\n        if not self.persistence:\n            return\n        topics = [\n            '{}/{}/{}/{}/+/+'.format(\n                self._in_prefix, str(sensor.sensor_id), str(child.id),\n                msg_type) for sensor in self.sensors.values()\n            for child in sensor.children.values()\n            for msg_type in (int(self.const.MessageType.set),\n                             int(self.const.MessageType.req))\n        ]\n        topics.extend([\n            '{}/{}/+/{}/+/+'.format(\n                self._in_prefix, str(sensor.sensor_id),\n                int(self.const.MessageType.stream))\n            for sensor in self.sensors.values()])\n        self._handle_subscription(topics)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_mqtt_to_message(self, topic, payload, qos):\n        topic_levels = topic.split('/')\n        topic_levels = not_prefix = topic_levels[-5:]\n        prefix_end_idx = topic.find('/'.join(not_prefix)) - 1\n        prefix = topic[:prefix_end_idx]\n        if prefix != self._in_prefix:\n            return None\n        if qos and qos > 0:\n            ack = '1'\n        else:\n            ack = '0'\n        topic_levels[3] = ack\n        topic_levels.append(str(payload))\n        return ';'.join(topic_levels)", "response": "Parse a MQTT topic and payload."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a mysensors command string. Return a MQTT topic payload and qos - level as a tuple.", "response": "def _parse_message_to_mqtt(self, data):\n        \"\"\"Parse a mysensors command string.\n\n        Return a MQTT topic, payload and qos-level as a tuple.\n        \"\"\"\n        msg = Message(data, self)\n        payload = str(msg.payload)\n        msg.payload = ''\n        # prefix/node/child/type/ack/subtype : payload\n        return ('{}/{}'.format(self._out_prefix, msg.encode('/'))[:-2],\n                payload, msg.ack)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _handle_presentation(self, msg):\n        ret_msg = handle_presentation(msg)\n        if msg.child_id == 255 or ret_msg is None:\n            return\n        # this is a presentation of a child sensor\n        topics = [\n            '{}/{}/{}/{}/+/+'.format(\n                self._in_prefix, str(msg.node_id), str(msg.child_id),\n                msg_type)\n            for msg_type in (int(self.const.MessageType.set),\n                             int(self.const.MessageType.req))\n        ]\n        topics.append('{}/{}/+/{}/+/+'.format(\n            self._in_prefix, str(msg.node_id),\n            int(self.const.MessageType.stream)))\n        self._handle_subscription(topics)", "response": "Process a MQTT presentation message."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef recv(self, topic, payload, qos):\n        data = self._parse_mqtt_to_message(topic, payload, qos)\n        if data is None:\n            return\n        _LOGGER.debug('Receiving %s', data)\n        self.add_job(self.logic, data)", "response": "Receive a MQTT message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npublish a command string to the gateway via MQTT.", "response": "def send(self, message):\n        \"\"\"Publish a command string to the gateway via MQTT.\"\"\"\n        if not message:\n            return\n        topic, payload, qos = self._parse_message_to_mqtt(message)\n        try:\n            _LOGGER.debug('Publishing %s', message.strip())\n            self._pub_callback(topic, payload, qos, self._retain)\n        except Exception as exception:  # pylint: disable=broad-except\n            _LOGGER.exception('Publish to %s failed: %s', topic, exception)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef start(self):\n        self._init_topics()\n        poll_thread = threading.Thread(target=self._poll_queue)\n        poll_thread.start()", "response": "Start the connection to a transport."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncasting to the correct value everywhere.", "response": "def contribute_to_class(self, cls, name, virtual_only=False):\n        \"\"\"\n        Cast to the correct value every\n        \"\"\"\n        super(RegexField, self).contribute_to_class(cls, name, virtual_only)\n        setattr(cls, name, CastOnAssignDescriptor(self))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_python(self, value):\n        if isinstance(value, type(re.compile(''))):\n            return value\n        else:\n            if value is None and self.null:\n                return None\n            else:\n                try:\n                    return self.get_compiled_regex(value)\n                except:\n                    raise ValidationError('Invalid regex {0}'.format(value))", "response": "Converts the value to a Python value."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmakes sure value is a string so it can be run through django validators", "response": "def run_validators(self, value):\n        \"\"\"\n        Make sure value is a string so it can run through django validators\n        \"\"\"\n        value = self.to_python(value)\n        value = self.value_to_string(value)\n        return super(RegexField, self).run_validators(value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate that value is of hex format.", "response": "def validate_hex(value):\n    \"\"\"Validate that value has hex format.\"\"\"\n    try:\n        binascii.unhexlify(value)\n    except Exception:\n        raise vol.Invalid(\n            '{} is not of hex format'.format(value))\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef validate_v_rgb(value):\n    if len(value) != 6:\n        raise vol.Invalid(\n            '{} is not six characters long'.format(value))\n    return validate_hex(value)", "response": "Validate a V_RGB value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef validate_v_rgbw(value):\n    if len(value) != 8:\n        raise vol.Invalid(\n            '{} is not eight characters long'.format(value))\n    return validate_hex(value)", "response": "Validate a V_RGBW value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef copy(self, **kwargs):\n        msg = Message(self.encode(), self.gateway)\n        for key, val in kwargs.items():\n            setattr(msg, key, val)\n        return msg", "response": "Copy a message optionally replace attributes with kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modify(self, **kwargs):\n        for key, val in kwargs.items():\n            setattr(self, key, val)\n        return self", "response": "Modify and return message with attributes with kwargs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decode(self, data, delimiter=';'):\n        try:\n            list_data = data.rstrip().split(delimiter)\n            self.payload = list_data.pop()\n            (self.node_id,\n             self.child_id,\n             self.type,\n             self.ack,\n             self.sub_type) = [int(f) for f in list_data]\n        except ValueError:\n            _LOGGER.warning('Error decoding message from gateway, '\n                            'bad data received: %s', data.rstrip())\n            raise", "response": "Decode a message from command string."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encode(self, delimiter=';'):\n        try:\n            return delimiter.join([str(f) for f in [\n                self.node_id,\n                self.child_id,\n                int(self.type),\n                self.ack,\n                int(self.sub_type),\n                self.payload,\n            ]]) + '\\n'\n        except ValueError:\n            _LOGGER.error('Error encoding message to gateway')", "response": "Encode a command string from message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _save_pickle(self, filename):\n        with open(filename, 'wb') as file_handle:\n            pickle.dump(self._sensors, file_handle, pickle.HIGHEST_PROTOCOL)\n            file_handle.flush()\n            os.fsync(file_handle.fileno())", "response": "Save sensors to pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_pickle(self, filename):\n        with open(filename, 'rb') as file_handle:\n            self._sensors.update(pickle.load(file_handle))", "response": "Load sensors from pickle file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _save_json(self, filename):\n        with open(filename, 'w') as file_handle:\n            json.dump(self._sensors, file_handle, cls=MySensorsJSONEncoder,\n                      indent=4)\n            file_handle.flush()\n            os.fsync(file_handle.fileno())", "response": "Save sensors to json file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _load_json(self, filename):\n        with open(filename, 'r') as file_handle:\n            self._sensors.update(json.load(\n                file_handle, cls=MySensorsJSONDecoder))", "response": "Load sensors from json file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save_sensors(self):\n        if not self.need_save:\n            return\n        fname = os.path.realpath(self.persistence_file)\n        exists = os.path.isfile(fname)\n        dirname = os.path.dirname(fname)\n        if (not os.access(dirname, os.W_OK) or exists and\n                not os.access(fname, os.W_OK)):\n            _LOGGER.error('Permission denied when writing to %s', fname)\n            return\n        split_fname = os.path.splitext(fname)\n        tmp_fname = '{}.tmp{}'.format(split_fname[0], split_fname[1])\n        _LOGGER.debug('Saving sensors to persistence file %s', fname)\n        self._perform_file_action(tmp_fname, 'save')\n        if exists:\n            os.rename(fname, self.persistence_bak)\n        os.rename(tmp_fname, fname)\n        if exists:\n            os.remove(self.persistence_bak)\n        self.need_save = False", "response": "Save sensors to file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _load_sensors(self, path=None):\n        if path is None:\n            path = self.persistence_file\n        exists = os.path.isfile(path)\n        if exists and os.access(path, os.R_OK):\n            if path == self.persistence_bak:\n                os.rename(path, self.persistence_file)\n                path = self.persistence_file\n            _LOGGER.debug('Loading sensors from persistence file %s', path)\n            self._perform_file_action(path, 'load')\n            return True\n        _LOGGER.warning('File does not exist or is not readable: %s', path)\n        return False", "response": "Load sensors from file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef safe_load_sensors(self):\n        try:\n            loaded = self._load_sensors()\n        except (EOFError, ValueError):\n            _LOGGER.error('Bad file contents: %s', self.persistence_file)\n            loaded = False\n        if not loaded:\n            _LOGGER.warning('Trying backup file: %s', self.persistence_bak)\n            try:\n                if not self._load_sensors(self.persistence_bak):\n                    _LOGGER.warning('Failed to load sensors from file: %s',\n                                    self.persistence_file)\n            except (EOFError, ValueError):\n                _LOGGER.error('Bad file contents: %s', self.persistence_file)\n                _LOGGER.warning('Removing file: %s', self.persistence_file)\n                os.remove(self.persistence_file)", "response": "Load sensors safely from file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform action on specific file types. Dynamic dispatch function for performing actions on specific file types.", "response": "def _perform_file_action(self, filename, action):\n        \"\"\"Perform action on specific file types.\n\n        Dynamic dispatch function for performing actions on\n        specific file types.\n        \"\"\"\n        ext = os.path.splitext(filename)[1]\n        try:\n            func = getattr(self, '_{}_{}'.format(action, ext[1:]))\n        except AttributeError:\n            raise Exception('Unsupported file type {}'.format(ext[1:]))\n        func(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef default(self, obj):\n        # pylint: disable=method-hidden, protected-access, arguments-differ\n        if isinstance(obj, Sensor):\n            return {\n                'sensor_id': obj.sensor_id,\n                'children': obj.children,\n                'type': obj.type,\n                'sketch_name': obj.sketch_name,\n                'sketch_version': obj.sketch_version,\n                'battery_level': obj.battery_level,\n                'protocol_version': obj.protocol_version,\n                'heartbeat': obj.heartbeat,\n            }\n        if isinstance(obj, ChildSensor):\n            return {\n                'id': obj.id,\n                'type': obj.type,\n                'description': obj.description,\n                'values': obj.values,\n            }\n        return json.JSONEncoder.default(self, obj)", "response": "Serialize obj into JSON."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn object from dict.", "response": "def dict_to_object(self, obj):  # pylint: disable=no-self-use\n        \"\"\"Return object from dict.\"\"\"\n        if not isinstance(obj, dict):\n            return obj\n        if 'sensor_id' in obj:\n            sensor = Sensor(obj['sensor_id'])\n            for key, val in obj.items():\n                setattr(sensor, key, val)\n            return sensor\n        if all(k in obj for k in ['id', 'type', 'values']):\n            child = ChildSensor(\n                obj['id'], obj['type'], obj.get('description', ''))\n            child.values = obj['values']\n            return child\n        if all(k.isdigit() for k in obj.keys()):\n            return {int(k): v for k, v in obj.items()}\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the const module for the protocol_version.", "response": "def get_const(protocol_version):\n    \"\"\"Return the const module for the protocol_version.\"\"\"\n    path = next((\n        CONST_VERSIONS[const_version]\n        for const_version in sorted(CONST_VERSIONS, reverse=True)\n        if parse_ver(protocol_version) >= parse_ver(const_version)\n    ), 'mysensors.const_14')\n    if path in LOADED_CONST:\n        return LOADED_CONST[path]\n    const = import_module(path)\n    LOADED_CONST[path] = const  # Cache the module\n    return const"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nunpack hex string into integers.", "response": "def fw_hex_to_int(hex_str, words):\n    \"\"\"Unpack hex string into integers.\n\n    Use little-endian and unsigned int format. Specify number of words to\n    unpack with argument words.\n    \"\"\"\n    return struct.unpack('<{}H'.format(words), binascii.unhexlify(hex_str))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npacking integers into hex string.", "response": "def fw_int_to_hex(*args):\n    \"\"\"Pack integers into hex string.\n\n    Use little-endian and unsigned int format.\n    \"\"\"\n    return binascii.hexlify(\n        struct.pack('<{}H'.format(len(args)), *args)).decode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes CRC16 of data and return an int.", "response": "def compute_crc(data):\n    \"\"\"Compute CRC16 of data and return an int.\"\"\"\n    crc16 = crcmod.predefined.Crc('modbus')\n    crc16.update(data)\n    return int(crc16.hexdigest(), 16)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nopen firmware file and return a binary string.", "response": "def load_fw(path):\n    \"\"\"Open firmware file and return a binary string.\"\"\"\n    fname = os.path.realpath(path)\n    exists = os.path.isfile(fname)\n    if not exists or not os.access(fname, os.R_OK):\n        _LOGGER.error(\n            'Firmware path %s does not exist or is not readable',\n            path)\n        return None\n    try:\n        intel_hex = IntelHex()\n        with open(path, 'r') as file_handle:\n            intel_hex.fromfile(file_handle, format='hex')\n        return intel_hex.tobinstr()\n    except (IntelHexError, TypeError, ValueError) as exc:\n        _LOGGER.error(\n            'Firmware not valid, check the hex file at %s: %s', path, exc)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_fw(bin_string):\n    pads = len(bin_string) % 128  # 128 bytes per page for atmega328\n    for _ in range(128 - pads):  # pad up to even 128 bytes\n        bin_string += b'\\xff'\n    fware = {\n        'blocks': int(len(bin_string) / FIRMWARE_BLOCK_SIZE),\n        'crc': compute_crc(bin_string),\n        'data': bin_string,\n    }\n    return fware", "response": "Check that firmware is valid and return dict with binary data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget firmware type version and binary data.", "response": "def _get_fw(self, msg, updates, req_fw_type=None, req_fw_ver=None):\n        \"\"\"Get firmware type, version and a dict holding binary data.\"\"\"\n        fw_type = None\n        fw_ver = None\n        if not isinstance(updates, tuple):\n            updates = (updates, )\n        for store in updates:\n            fw_id = store.pop(msg.node_id, None)\n            if fw_id is not None:\n                fw_type, fw_ver = fw_id\n                updates[-1][msg.node_id] = fw_id\n                break\n        if fw_type is None or fw_ver is None:\n            _LOGGER.debug(\n                'Node %s is not set for firmware update', msg.node_id)\n            return None, None, None\n        if req_fw_type is not None and req_fw_ver is not None:\n            fw_type, fw_ver = req_fw_type, req_fw_ver\n        fware = self.firmware.get((fw_type, fw_ver))\n        if fware is None:\n            _LOGGER.debug(\n                'No firmware of type %s and version %s found',\n                fw_type, fw_ver)\n            return None, None, None\n        return fw_type, fw_ver, fware"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef respond_fw(self, msg):\n        req_fw_type, req_fw_ver, req_blk = fw_hex_to_int(msg.payload, 3)\n        _LOGGER.debug(\n            'Received firmware request with firmware type %s, '\n            'firmware version %s, block index %s',\n            req_fw_type, req_fw_ver, req_blk)\n        fw_type, fw_ver, fware = self._get_fw(\n            msg, (self.unstarted, self.started), req_fw_type, req_fw_ver)\n        if fware is None:\n            return None\n        blk_data = fware['data'][\n            req_blk * FIRMWARE_BLOCK_SIZE:\n            req_blk * FIRMWARE_BLOCK_SIZE + FIRMWARE_BLOCK_SIZE]\n        msg = msg.copy(sub_type=self._const.Stream.ST_FIRMWARE_RESPONSE)\n        msg.payload = fw_int_to_hex(fw_type, fw_ver, req_blk)\n        # format blk_data into payload format\n        msg.payload = msg.payload + binascii.hexlify(blk_data).decode('utf-8')\n        return msg", "response": "Respond to a firmware request."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nresponding to a firmware config request.", "response": "def respond_fw_config(self, msg):\n        \"\"\"Respond to a firmware config request.\"\"\"\n        (req_fw_type,\n         req_fw_ver,\n         req_blocks,\n         req_crc,\n         bloader_ver) = fw_hex_to_int(msg.payload, 5)\n        _LOGGER.debug(\n            'Received firmware config request with firmware type %s, '\n            'firmware version %s, %s blocks, CRC %s, bootloader %s',\n            req_fw_type, req_fw_ver, req_blocks, req_crc, bloader_ver)\n        fw_type, fw_ver, fware = self._get_fw(\n            msg, (self.requested, self.unstarted))\n        if fware is None:\n            return None\n        if fw_type != req_fw_type:\n            _LOGGER.warning(\n                'Firmware type %s of update is not identical to existing '\n                'firmware type %s for node %s',\n                fw_type, req_fw_type, msg.node_id)\n        _LOGGER.info(\n            'Updating node %s to firmware type %s version %s from type %s '\n            'version %s', msg.node_id, fw_type, fw_ver, req_fw_type,\n            req_fw_ver)\n        msg = msg.copy(sub_type=self._const.Stream.ST_FIRMWARE_CONFIG_RESPONSE)\n        msg.payload = fw_int_to_hex(\n            fw_type, fw_ver, fware['blocks'], fware['crc'])\n        return msg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting firmware update process for one or more node_id.", "response": "def make_update(self, nids, fw_type, fw_ver, fw_bin=None):\n        \"\"\"Start firmware update process for one or more node_id.\"\"\"\n        try:\n            fw_type, fw_ver = int(fw_type), int(fw_ver)\n        except ValueError:\n            _LOGGER.error(\n                'Firmware type %s or version %s not valid, '\n                'please enter integers', fw_type, fw_ver)\n            return\n        if fw_bin is not None:\n            fware = prepare_fw(fw_bin)\n            self.firmware[fw_type, fw_ver] = fware\n        if (fw_type, fw_ver) not in self.firmware:\n            _LOGGER.error(\n                'No firmware of type %s and version %s found, '\n                'please enter path to firmware in call', fw_type, fw_ver)\n            return\n        if not isinstance(nids, list):\n            nids = [nids]\n        for node_id in nids:\n            if node_id not in self._sensors:\n                continue\n            for store in self.unstarted, self.started:\n                store.pop(node_id, None)\n            self.requested[node_id] = fw_type, fw_ver\n            self._sensors[node_id].reboot = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses a message before going back to smartsleep.", "response": "def handle_smartsleep(msg):\n    \"\"\"Process a message before going back to smartsleep.\"\"\"\n    while msg.gateway.sensors[msg.node_id].queue:\n        msg.gateway.add_job(\n            str, msg.gateway.sensors[msg.node_id].queue.popleft())\n    for child in msg.gateway.sensors[msg.node_id].children.values():\n        new_child = msg.gateway.sensors[msg.node_id].new_state.get(\n            child.id, ChildSensor(child.id, child.type, child.description))\n        msg.gateway.sensors[msg.node_id].new_state[child.id] = new_child\n        for value_type, value in child.values.items():\n            new_value = new_child.values.get(value_type)\n            if new_value is not None and new_value != value:\n                msg.gateway.add_job(\n                    msg.gateway.sensors[msg.node_id].set_child_value,\n                    child.id, value_type, new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprocess a presentation message.", "response": "def handle_presentation(msg):\n    \"\"\"Process a presentation message.\"\"\"\n    if msg.child_id == SYSTEM_CHILD_ID:\n        # this is a presentation of the sensor platform\n        sensorid = msg.gateway.add_sensor(msg.node_id)\n        if sensorid is None:\n            return None\n        msg.gateway.sensors[msg.node_id].type = msg.sub_type\n        msg.gateway.sensors[msg.node_id].protocol_version = msg.payload\n        # Set reboot to False after a node reboot.\n        msg.gateway.sensors[msg.node_id].reboot = False\n        msg.gateway.alert(msg)\n        return msg\n    # this is a presentation of a child sensor\n    if not msg.gateway.is_sensor(msg.node_id):\n        _LOGGER.error('Node %s is unknown, will not add child %s',\n                      msg.node_id, msg.child_id)\n        return None\n    child_id = msg.gateway.sensors[msg.node_id].add_child_sensor(\n        msg.child_id, msg.sub_type, msg.payload)\n    if child_id is None:\n        return None\n    msg.gateway.alert(msg)\n    return msg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_set(msg):\n    if not msg.gateway.is_sensor(msg.node_id, msg.child_id):\n        return None\n    msg.gateway.sensors[msg.node_id].set_child_value(\n        msg.child_id, msg.sub_type, msg.payload)\n    if msg.gateway.sensors[msg.node_id].new_state:\n        msg.gateway.sensors[msg.node_id].set_child_value(\n            msg.child_id, msg.sub_type, msg.payload,\n            children=msg.gateway.sensors[msg.node_id].new_state)\n    msg.gateway.alert(msg)\n    # Check if reboot is true\n    if msg.gateway.sensors[msg.node_id].reboot:\n        return msg.copy(\n            child_id=SYSTEM_CHILD_ID,\n            type=msg.gateway.const.MessageType.internal, ack=0,\n            sub_type=msg.gateway.const.Internal.I_REBOOT, payload='')\n    return None", "response": "Process a set message."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef handle_req(msg):\n    if not msg.gateway.is_sensor(msg.node_id, msg.child_id):\n        return None\n    value = msg.gateway.sensors[msg.node_id].children[\n        msg.child_id].values.get(msg.sub_type)\n    if value is not None:\n        return msg.copy(\n            type=msg.gateway.const.MessageType.set, payload=value)\n    return None", "response": "Process a req message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an internal message.", "response": "def handle_internal(msg):\n    \"\"\"Process an internal message.\"\"\"\n    internal = msg.gateway.const.Internal(msg.sub_type)\n    handler = internal.get_handler(msg.gateway.handlers)\n    if handler is None:\n        return None\n    return handler(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing a stream type message.", "response": "def handle_stream(msg):\n    \"\"\"Process a stream type message.\"\"\"\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    stream = msg.gateway.const.Stream(msg.sub_type)\n    handler = stream.get_handler(msg.gateway.handlers)\n    if handler is None:\n        return None\n    return handler(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprocessing an internal id request message.", "response": "def handle_id_request(msg):\n    \"\"\"Process an internal id request message.\"\"\"\n    node_id = msg.gateway.add_sensor()\n    return msg.copy(\n        ack=0, sub_type=msg.gateway.const.Internal['I_ID_RESPONSE'],\n        payload=node_id) if node_id is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef handle_time(msg):\n    return msg.copy(ack=0, payload=calendar.timegm(time.localtime()))", "response": "Process an internal time request message."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess an internal battery level message.", "response": "def handle_battery_level(msg):\n    \"\"\"Process an internal battery level message.\"\"\"\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    msg.gateway.sensors[msg.node_id].battery_level = msg.payload\n    msg.gateway.alert(msg)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_sketch_name(msg):\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    msg.gateway.sensors[msg.node_id].sketch_name = msg.payload\n    msg.gateway.alert(msg)\n    return None", "response": "Process an internal sketch name message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an internal sketch version message.", "response": "def handle_sketch_version(msg):\n    \"\"\"Process an internal sketch version message.\"\"\"\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    msg.gateway.sensors[msg.node_id].sketch_version = msg.payload\n    msg.gateway.alert(msg)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an internal log message.", "response": "def handle_log_message(msg):  # pylint: disable=useless-return\n    \"\"\"Process an internal log message.\"\"\"\n    msg.gateway.can_log = True\n    _LOGGER.debug(\n        'n:%s c:%s t:%s s:%s p:%s', msg.node_id, msg.child_id, msg.type,\n        msg.sub_type, msg.payload)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an internal gateway ready message.", "response": "def handle_gateway_ready(msg):  # pylint: disable=useless-return\n    \"\"\"Process an internal gateway ready message.\"\"\"\n    _LOGGER.info(\n        'n:%s c:%s t:%s s:%s p:%s', msg.node_id, msg.child_id, msg.type,\n        msg.sub_type, msg.payload)\n    msg.gateway.alert(msg)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses an internal gateway ready message.", "response": "def handle_gateway_ready_20(msg):\n    \"\"\"Process an internal gateway ready message.\"\"\"\n    _LOGGER.info(\n        'n:%s c:%s t:%s s:%s p:%s', msg.node_id, msg.child_id, msg.type,\n        msg.sub_type, msg.payload)\n    msg.gateway.alert(msg)\n    return msg.copy(\n        node_id=255, ack=0,\n        sub_type=msg.gateway.const.Internal.I_DISCOVER, payload='')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef handle_heartbeat_response(msg):\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    handle_smartsleep(msg)\n    msg.gateway.sensors[msg.node_id].heartbeat = msg.payload\n    msg.gateway.alert(msg)\n    return None", "response": "Process an internal heartbeat response message."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_heartbeat_response_22(msg):\n    if not msg.gateway.is_sensor(msg.node_id):\n        return None\n    msg.gateway.sensors[msg.node_id].heartbeat = msg.payload\n    msg.gateway.alert(msg)\n    return None", "response": "Process an internal heartbeat response message."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npublishes an MQTT message.", "response": "def publish(self, topic, payload, qos, retain):\n        \"\"\"Publish an MQTT message.\"\"\"\n        self._mqttc.publish(topic, payload, qos, retain)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subscribe(self, topic, callback, qos):\n        if topic in self.topics:\n            return\n\n        def _message_callback(mqttc, userdata, msg):\n            \"\"\"Callback added to callback list for received message.\"\"\"\n            callback(msg.topic, msg.payload.decode('utf-8'), msg.qos)\n\n        self._mqttc.subscribe(topic, qos)\n        self._mqttc.message_callback_add(topic, _message_callback)\n        self.topics[topic] = callback", "response": "Subscribe to an MQTT topic."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a unique id for the gateway.", "response": "def get_gateway_id(self):\n        \"\"\"Return a unique id for the gateway.\"\"\"\n        info = next(serial.tools.list_ports.grep(self.port), None)\n        return info.serial_number if info is not None else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _connect(self):\n        while self.protocol:\n            _LOGGER.info('Trying to connect to %s', self.port)\n            try:\n                ser = serial.serial_for_url(\n                    self.port, self.baud, timeout=self.timeout)\n            except serial.SerialException:\n                _LOGGER.error('Unable to connect to %s', self.port)\n                _LOGGER.info(\n                    'Waiting %s secs before trying to connect again',\n                    self.reconnect_timeout)\n                time.sleep(self.reconnect_timeout)\n            else:\n                transport = serial.threaded.ReaderThread(\n                    ser, lambda: self.protocol)\n                transport.daemon = False\n                poll_thread = threading.Thread(target=self._poll_queue)\n                self._stop_event.clear()\n                poll_thread.start()\n                transport.start()\n                transport.connect()\n                return", "response": "Connect to the serial port. This should be run in a new thread."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects to the serial port.", "response": "def _connect(self):\n        \"\"\"Connect to the serial port.\"\"\"\n        try:\n            while True:\n                _LOGGER.info('Trying to connect to %s', self.port)\n                try:\n                    yield from serial_asyncio.create_serial_connection(\n                        self.loop, lambda: self.protocol, self.port, self.baud)\n                    return\n                except serial.SerialException:\n                    _LOGGER.error('Unable to connect to %s', self.port)\n                    _LOGGER.info(\n                        'Waiting %s secs before trying to connect again',\n                        self.reconnect_timeout)\n                    yield from asyncio.sleep(\n                        self.reconnect_timeout, loop=self.loop)\n        except asyncio.CancelledError:\n            _LOGGER.debug('Connect attempt to %s cancelled', self.port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_version(value):\n    try:\n        value = str(value)\n        if not parse_ver('1.4') <= parse_ver(value):\n            raise ValueError()\n        return value\n    except (AttributeError, TypeError, ValueError):\n        raise vol.Invalid(\n            '{} is not a valid version specifier'.format(value))", "response": "Validate that value is a valid version string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_battery_level(value):\n    try:\n        value = percent_int(value)\n        return value\n    except vol.Invalid:\n        _LOGGER.warning(\n            '%s is not a valid battery level, falling back to battery level 0',\n            value)\n        return 0", "response": "Validate that value is a valid battery level integer."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_heartbeat(value):\n    try:\n        value = vol.Coerce(int)(value)\n        return value\n    except vol.Invalid:\n        _LOGGER.warning(\n            '%s is not a valid heartbeat value, falling back to heartbeat 0',\n            value)\n        return 0", "response": "Validate that value is a valid heartbeat integer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef mksalt(method=None, rounds=None):\n    if method is None:\n        method = methods[0]\n    salt = ['${0}$'.format(method.ident) if method.ident else '']\n    if rounds:\n        salt.append('rounds={0:d}$'.format(rounds))\n    salt.append(''.join(_sr.choice(_BASE64_CHARACTERS) for char in range(method.salt_chars)))\n    return ''.join(salt)", "response": "Generate a salt for the specified method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string representing the one - way hash of a password.", "response": "def crypt(word, salt=None, rounds=_ROUNDS_DEFAULT):\n    \"\"\"Return a string representing the one-way hash of a password, with a salt\n    prepended.\n    If ``salt`` is not specified or is ``None``, the strongest\n    available method will be selected and a salt generated.  Otherwise,\n    ``salt`` may be one of the ``crypt.METHOD_*`` values, or a string as\n    returned by ``crypt.mksalt()``.\n    \"\"\"\n    if salt is None or isinstance(salt, _Method):\n        salt = mksalt(salt, rounds)\n\n    algo, rounds, salt = extract_components_from_salt(salt)\n    if algo == 5:\n        hashfunc = hashlib.sha256\n    elif algo == 6:\n        hashfunc = hashlib.sha512\n    else:\n        raise ValueError('Unsupported algorithm, must be either 5 (sha256) or 6 (sha512)')\n\n    return sha2_crypt(word, salt, hashfunc, rounds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sha2_crypt(key, salt, hashfunc, rounds=_ROUNDS_DEFAULT):\n    key = key.encode('utf-8')\n    h = hashfunc()\n    alt_h = hashfunc()\n    digest_size = h.digest_size\n    key_len = len(key)\n\n    # First, feed key, salt and then key again to the alt hash\n    alt_h.update(key)\n    alt_h.update(salt.encode('utf-8'))\n    alt_h.update(key)\n    alt_result = alt_h.digest()\n\n    # Feed key and salt to the primary hash\n    h.update(key)\n    h.update(salt.encode('utf-8'))\n\n    # Feed as many (loopping) bytes from alt digest as the length of the key\n    for i in range(key_len//digest_size):\n        h.update(alt_result)\n    h.update(alt_result[:(key_len % digest_size)])\n\n    # Take the binary representation of the length of the key and for every\n    # 1 add the alternate digest, for every 0 the key\n    bits = key_len\n    while bits > 0:\n        if bits & 1 == 0:\n            h.update(key)\n        else:\n            h.update(alt_result)\n        bits >>= 1\n\n    # Store the results from the primary hash\n    alt_result = h.digest()\n\n    h = hashfunc()\n\n    # Add password for each character in the password\n    for i in range(key_len):\n        h.update(key)\n\n    temp_result = h.digest()\n\n    # Compute a P array of the bytes in temp repeated for the length of the key\n    p_bytes = temp_result * (key_len // digest_size)\n    p_bytes += temp_result[:(key_len % digest_size)]\n\n    alt_h = hashfunc()\n\n    # Add the salt 16 + arbitrary amount decided by first byte in alt digest\n    for i in range(16 + byte2int(alt_result[0])):\n        alt_h.update(salt.encode('utf-8'))\n\n    temp_result = alt_h.digest()\n\n    # Compute a S array of the bytes in temp_result repeated for the length\n    # of the salt\n    s_bytes = temp_result * (len(salt) // digest_size)\n    s_bytes += temp_result[:(len(salt) % digest_size)]\n\n    # Do the actual iterations\n    for i in range(rounds):\n        h = hashfunc()\n\n        # Alternate adding either the P array or the alt digest\n        if i & 1 != 0:\n            h.update(p_bytes)\n        else:\n            h.update(alt_result)\n\n        # If the round is divisible by 3, add the S array\n        if i % 3 != 0:\n            h.update(s_bytes)\n\n        # If the round is divisible by 7, add the P array\n        if i % 7 != 0:\n            h.update(p_bytes)\n\n        # Alternate adding either the P array or the alt digest, opposite\n        # of first step\n        if i & 1 != 0:\n            h.update(alt_result)\n        else:\n            h.update(p_bytes)\n\n        alt_result = h.digest()\n\n    # Compute the base64-ish representation of the hash\n    ret = []\n    if digest_size == 64:\n        # SHA-512\n        ret.append(b64_from_24bit(alt_result[0], alt_result[21], alt_result[42], 4))\n        ret.append(b64_from_24bit(alt_result[22], alt_result[43], alt_result[1], 4))\n        ret.append(b64_from_24bit(alt_result[44], alt_result[2], alt_result[23], 4))\n        ret.append(b64_from_24bit(alt_result[3], alt_result[24], alt_result[45], 4))\n        ret.append(b64_from_24bit(alt_result[25], alt_result[46], alt_result[4], 4))\n        ret.append(b64_from_24bit(alt_result[47], alt_result[5], alt_result[26], 4))\n        ret.append(b64_from_24bit(alt_result[6], alt_result[27], alt_result[48], 4))\n        ret.append(b64_from_24bit(alt_result[28], alt_result[49], alt_result[7], 4))\n        ret.append(b64_from_24bit(alt_result[50], alt_result[8], alt_result[29], 4))\n        ret.append(b64_from_24bit(alt_result[9], alt_result[30], alt_result[51], 4))\n        ret.append(b64_from_24bit(alt_result[31], alt_result[52], alt_result[10], 4))\n        ret.append(b64_from_24bit(alt_result[53], alt_result[11], alt_result[32], 4))\n        ret.append(b64_from_24bit(alt_result[12], alt_result[33], alt_result[54], 4))\n        ret.append(b64_from_24bit(alt_result[34], alt_result[55], alt_result[13], 4))\n        ret.append(b64_from_24bit(alt_result[56], alt_result[14], alt_result[35], 4))\n        ret.append(b64_from_24bit(alt_result[15], alt_result[36], alt_result[57], 4))\n        ret.append(b64_from_24bit(alt_result[37], alt_result[58], alt_result[16], 4))\n        ret.append(b64_from_24bit(alt_result[59], alt_result[17], alt_result[38], 4))\n        ret.append(b64_from_24bit(alt_result[18], alt_result[39], alt_result[60], 4))\n        ret.append(b64_from_24bit(alt_result[40], alt_result[61], alt_result[19], 4))\n        ret.append(b64_from_24bit(alt_result[62], alt_result[20], alt_result[41], 4))\n        ret.append(b64_from_24bit(int2byte(0), int2byte(0), alt_result[63], 2))\n    else:\n        # SHA-256\n        ret.append(b64_from_24bit(alt_result[0], alt_result[10], alt_result[20], 4))\n        ret.append(b64_from_24bit(alt_result[21], alt_result[1], alt_result[11], 4))\n        ret.append(b64_from_24bit(alt_result[12], alt_result[22], alt_result[2], 4))\n        ret.append(b64_from_24bit(alt_result[3], alt_result[13], alt_result[23], 4))\n        ret.append(b64_from_24bit(alt_result[24], alt_result[4], alt_result[14], 4))\n        ret.append(b64_from_24bit(alt_result[15], alt_result[25], alt_result[5], 4))\n        ret.append(b64_from_24bit(alt_result[6], alt_result[16], alt_result[26], 4))\n        ret.append(b64_from_24bit(alt_result[27], alt_result[7], alt_result[17], 4))\n        ret.append(b64_from_24bit(alt_result[18], alt_result[28], alt_result[8], 4))\n        ret.append(b64_from_24bit(alt_result[9], alt_result[19], alt_result[29], 4))\n        ret.append(b64_from_24bit(int2byte(0), alt_result[31], alt_result[30], 3))\n\n    algo = 6 if digest_size == 64 else 5\n    if rounds == _ROUNDS_DEFAULT:\n        return '${0}${1}${2}'.format(algo, salt, ''.join(ret))\n    else:\n        return '${0}$rounds={1}${2}${3}'.format(algo, rounds, salt, ''.join(ret))", "response": "This function is used to generate the key and salt for the key and then hash the key with the salt."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef double_prompt_for_plaintext_password():\n    password = 1\n    password_repeat = 2\n    while password != password_repeat:\n        password = getpass.getpass('Enter password: ')\n        password_repeat = getpass.getpass('Repeat password: ')\n        if password != password_repeat:\n            sys.stderr.write('Passwords do not match, try again.\\n')\n    return password", "response": "Get the desired password from the user through a double prompt."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef logic(self, data):\n        try:\n            msg = Message(data, self)\n            msg.validate(self.protocol_version)\n        except (ValueError, vol.Invalid) as exc:\n            _LOGGER.warning('Not a valid message: %s', exc)\n            return None\n\n        message_type = self.const.MessageType(msg.type)\n        handler = message_type.get_handler(self.handlers)\n        ret = handler(msg)\n        ret = self._route_message(ret)\n        ret = ret.encode() if ret else None\n        return ret", "response": "Parse the data and respond to it appropriately."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef alert(self, msg):\n        if self.event_callback is not None:\n            try:\n                self.event_callback(msg)\n            except Exception as exception:  # pylint: disable=broad-except\n                _LOGGER.exception(exception)\n\n        if self.persistence:\n            self.persistence.need_save = True", "response": "Tell anyone who wants to know that a sensor was updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the next available sensor id.", "response": "def _get_next_id(self):\n        \"\"\"Return the next available sensor id.\"\"\"\n        if self.sensors:\n            next_id = max(self.sensors.keys()) + 1\n        else:\n            next_id = 1\n        if next_id <= self.const.MAX_NODE_ID:\n            return next_id\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a sensor to the gateway.", "response": "def add_sensor(self, sensorid=None):\n        \"\"\"Add a sensor to the gateway.\"\"\"\n        if sensorid is None:\n            sensorid = self._get_next_id()\n        if sensorid is not None and sensorid not in self.sensors:\n            self.sensors[sensorid] = Sensor(sensorid)\n        return sensorid if sensorid in self.sensors else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if a sensor and its child exist.", "response": "def is_sensor(self, sensorid, child_id=None):\n        \"\"\"Return True if a sensor and its child exist.\"\"\"\n        ret = sensorid in self.sensors\n        if not ret:\n            _LOGGER.warning('Node %s is unknown', sensorid)\n        if ret and child_id is not None:\n            ret = child_id in self.sensors[sensorid].children\n            if not ret:\n                _LOGGER.warning('Child %s is unknown', child_id)\n        if not ret and parse_ver(self.protocol_version) >= parse_ver('2.0'):\n            _LOGGER.info('Requesting new presentation for node %s',\n                         sensorid)\n            msg = Message(gateway=self).modify(\n                node_id=sensorid, child_id=SYSTEM_CHILD_ID,\n                type=self.const.MessageType.internal,\n                sub_type=self.const.Internal.I_PRESENTATION)\n            if self._route_message(msg):\n                self.add_job(msg.encode)\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nruns a job from the queue.", "response": "def run_job(self, job=None):\n        \"\"\"Run a job, either passed in or from the queue.\n\n        A job is a tuple of function and optional args. Keyword arguments\n        can be passed via use of functools.partial. The job should return a\n        string that should be sent by the gateway protocol. The function will\n        be called with the arguments and the result will be returned.\n        \"\"\"\n        if job is None:\n            if not self.queue:\n                return None\n            job = self.queue.popleft()\n        start = timer()\n        func, args = job\n        reply = func(*args)\n        end = timer()\n        if end - start > 0.1:\n            _LOGGER.debug(\n                'Handle queue with call %s(%s) took %.3f seconds',\n                func, args, end - start)\n        return reply"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_child_value(\n            self, sensor_id, child_id, value_type, value, **kwargs):\n        \"\"\"Add a command to set a sensor value, to the queue.\n\n        A queued command will be sent to the sensor when the gateway\n        thread has sent all previously queued commands.\n\n        If the sensor attribute new_state returns True, the command will be\n        buffered in a queue on the sensor, and only the internal sensor state\n        will be updated. When a smartsleep message is received, the internal\n        state will be pushed to the sensor, via _handle_smartsleep method.\n        \"\"\"\n        if not self.is_sensor(sensor_id, child_id):\n            return\n        if self.sensors[sensor_id].new_state:\n            self.sensors[sensor_id].set_child_value(\n                child_id, value_type, value,\n                children=self.sensors[sensor_id].new_state)\n        else:\n            self.add_job(partial(\n                self.sensors[sensor_id].set_child_value, child_id, value_type,\n                value, **kwargs))", "response": "Add a command to set a sensor value to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the connection to a transport.", "response": "def start(self):\n        \"\"\"Start the connection to a transport.\"\"\"\n        connect_thread = threading.Thread(target=self._connect)\n        connect_thread.start()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npolling the queue for work.", "response": "def _poll_queue(self):\n        \"\"\"Poll the queue for work.\"\"\"\n        while not self._stop_event.is_set():\n            reply = self.run_job()\n            self.send(reply)\n            if self.queue:\n                continue\n            time.sleep(0.02)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a function to schedule saving sensors and schedule a new save.", "response": "def _create_scheduler(self, save_sensors):\n        \"\"\"Return function to schedule saving sensors.\"\"\"\n        def schedule_save():\n            \"\"\"Save sensors and schedule a new save.\"\"\"\n            save_sensors()\n            scheduler = threading.Timer(10.0, schedule_save)\n            scheduler.start()\n            self._cancel_save = scheduler.cancel\n        return schedule_save"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef start_persistence(self):\n        if not self.persistence:\n            return\n        self.persistence.safe_load_sensors()\n        self.persistence.schedule_save_sensors()", "response": "Load persistence file and schedule saving of persistence file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef stop(self):\n        self._stop_event.set()\n        if not self.persistence:\n            return\n        if self._cancel_save is not None:\n            self._cancel_save()\n            self._cancel_save = None\n        self.persistence.save_sensors()", "response": "Stop the background thread."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate firwmare of all node_ids in nids.", "response": "def update_fw(self, nids, fw_type, fw_ver, fw_path=None):\n        \"\"\"Update firwmare of all node_ids in nids.\"\"\"\n        fw_bin = None\n        if fw_path:\n            fw_bin = load_fw(fw_path)\n            if not fw_bin:\n                return\n        self.ota.make_update(nids, fw_type, fw_ver, fw_bin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndisconnect from the transport.", "response": "def _disconnect(self):\n        \"\"\"Disconnect from the transport.\"\"\"\n        if not self.protocol or not self.protocol.transport:\n            self.protocol = None  # Make sure protocol is None\n            return\n        _LOGGER.info('Disconnecting from gateway')\n        self.protocol.transport.close()\n        self.protocol = None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef send(self, message):\n        if not message or not self.protocol or not self.protocol.transport:\n            return\n        if not self.can_log:\n            _LOGGER.debug('Sending %s', message.strip())\n        try:\n            self.protocol.transport.write(message.encode())\n        except OSError as exc:\n            _LOGGER.error(\n                'Failed writing to transport %s: %s',\n                self.protocol.transport, exc)\n            self.protocol.transport.close()\n            self.protocol.conn_lost_callback()", "response": "Write a message to the gateway."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a job that should return a reply to be sent.", "response": "def add_job(self, func, *args):\n        \"\"\"Add a job that should return a reply to be sent.\n\n        A job is a tuple of function and optional args. Keyword arguments\n        can be passed via use of functools.partial. The job should return a\n        string that should be sent by the gateway protocol.\n\n        The async version of this method will send the reply directly.\n        \"\"\"\n        job = func, args\n        reply = self.run_job(job)\n        self.send(reply)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a scheduler function that schedules sensors and returns a new save.", "response": "def _create_scheduler(self, save_sensors):\n        \"\"\"Return function to schedule saving sensors.\"\"\"\n        @asyncio.coroutine\n        def schedule_save():\n            \"\"\"Save sensors and schedule a new save.\"\"\"\n            yield from self.loop.run_in_executor(None, save_sensors)\n            callback = partial(self.loop.create_task, schedule_save())\n            task = self.loop.call_later(10.0, callback)\n            self._cancel_save = task.cancel\n        return schedule_save"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef start_persistence(self):\n        if not self.persistence:\n            return\n        yield from self.loop.run_in_executor(\n            None, self.persistence.safe_load_sensors)\n        yield from self.persistence.schedule_save_sensors()", "response": "Load persistence file and schedule saving of persistence file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef handle_line(self, line):\n        if not self.gateway.can_log:\n            _LOGGER.debug('Receiving %s', line)\n        self.gateway.add_job(self.gateway.logic, line)", "response": "Handle incoming string data one line at a time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_child_sensor(self, child_id, child_type, description=''):\n        if child_id in self.children:\n            _LOGGER.warning(\n                'child_id %s already exists in children of node %s, '\n                'cannot add child', child_id, self.sensor_id)\n            return None\n        self.children[child_id] = ChildSensor(\n            child_id, child_type, description)\n        return child_id", "response": "Create and add a child sensor."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_child_value(self, child_id, value_type, value, **kwargs):\n        children = kwargs.get('children', self.children)\n        if not isinstance(children, dict) or child_id not in children:\n            return None\n        msg_type = kwargs.get('msg_type', 1)\n        ack = kwargs.get('ack', 0)\n        msg = Message().modify(\n            node_id=self.sensor_id, child_id=child_id, type=msg_type, ack=ack,\n            sub_type=value_type, payload=value)\n        msg_string = msg.encode()\n        if msg_string is None:\n            _LOGGER.error(\n                'Not a valid message: node %s, child %s, type %s, ack %s, '\n                'sub_type %s, payload %s',\n                self.sensor_id, child_id, msg_type, ack, value_type, value)\n            return None\n        try:\n            msg = Message(msg_string)\n            msg.validate(self.protocol_version)\n        except (ValueError, AttributeError, vol.Invalid) as exc:\n            _LOGGER.error('Not a valid message: %s', exc)\n            return None\n        child = children[msg.child_id]\n        child.values[msg.sub_type] = msg.payload\n        return msg_string", "response": "Set a child sensor s value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the child schema for the correct const version.", "response": "def get_schema(self, protocol_version):\n        \"\"\"Return the child schema for the correct const version.\"\"\"\n        const = get_const(protocol_version)\n        custom_schema = vol.Schema({\n            typ.value: const.VALID_SETREQ[typ]\n            for typ in const.VALID_TYPES[const.Presentation.S_CUSTOM]})\n        return custom_schema.extend({\n            typ.value: const.VALID_SETREQ[typ]\n            for typ in const.VALID_TYPES[self.type]})"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate child value types and values against protocol_version.", "response": "def validate(self, protocol_version, values=None):\n        \"\"\"Validate child value types and values against protocol_version.\"\"\"\n        if values is None:\n            values = self.values\n        return self.get_schema(protocol_version)(values)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting where package was shipped from.", "response": "def _get_shipped_from(row):\n    \"\"\"Get where package was shipped from.\"\"\"\n    try:\n        spans = row.find('div', {'id': 'coltextR2'}).find_all('span')\n        if len(spans) < 2:\n            return None\n        return spans[1].string\n    except AttributeError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_status_timestamp(row):\n    try:\n        divs = row.find('div', {'id': 'coltextR3'}).find_all('div')\n        if len(divs) < 2:\n            return None\n        timestamp_string = divs[1].string\n    except AttributeError:\n        return None\n    try:\n        return parse(timestamp_string)\n    except ValueError:\n        return None", "response": "Get latest package timestamp."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_delivery_date(row):\n    try:\n        month = row.find('div', {'class': 'date-small'}).string\n        day = row.find('div', {'class': 'date-num-large'}).string\n    except AttributeError:\n        return None\n    try:\n        return parse('{} {}'.format(month, day)).date()\n    except ValueError:\n        return None", "response": "Get delivery date (estimated or actual)."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef authenticated(function):\n    def wrapped(*args):\n        \"\"\"Wrap function.\"\"\"\n        try:\n            return function(*args)\n        except USPSError:\n            _LOGGER.info(\"attempted to access page before login\")\n            _login(args[0])\n            return function(*args)\n    return wrapped", "response": "Wrap function to re - authenticate session."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_session(username, password, cookie_path=COOKIE_PATH, cache=True,\n                cache_expiry=300, cache_path=CACHE_PATH, driver='phantomjs'):\n    \"\"\"Get session, existing or new.\"\"\"\n    class USPSAuth(AuthBase):  # pylint: disable=too-few-public-methods\n        \"\"\"USPS authorization storage.\"\"\"\n\n        def __init__(self, username, password, cookie_path, driver):\n            \"\"\"Init.\"\"\"\n            self.username = username\n            self.password = password\n            self.cookie_path = cookie_path\n            self.driver = driver\n\n        def __call__(self, r):\n            \"\"\"Call is no-op.\"\"\"\n            return r\n\n    session = requests.Session()\n    if cache:\n        session = requests_cache.core.CachedSession(cache_name=cache_path,\n                                                    expire_after=cache_expiry)\n    session.auth = USPSAuth(username, password, cookie_path, driver)\n    session.headers.update({'User-Agent': USER_AGENT})\n    if os.path.exists(cookie_path):\n        _LOGGER.debug(\"cookie found at: %s\", cookie_path)\n        session.cookies = _load_cookies(cookie_path)\n    else:\n        _login(session)\n    return session", "response": "Get a new session."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates an email confirmation for a given content_object and send a confirmation mail.", "response": "def verify_email_for_object(self, email, content_object, email_field_name='email'):\n        \"\"\"\n        Create an email confirmation for `content_object` and send a confirmation mail.\n\n        The email will be directly saved to `content_object.email_field_name` when `is_primary` and `skip_verify` both are true.\n        \"\"\"\n\n        confirmation_key = generate_random_token()\n\n        try:\n            confirmation = EmailConfirmation()\n            confirmation.content_object = content_object\n            confirmation.email_field_name = email_field_name\n            confirmation.email = email\n            confirmation.confirmation_key = confirmation_key\n            confirmation.save()\n        except IntegrityError:\n            confirmation = EmailConfirmation.objects.get_for_object(content_object, email_field_name)\n            confirmation.email = email\n            confirmation.confirmation_key = confirmation_key\n            confirmation.save(update_fields=['email', 'confirmation_key'])\n\n        confirmation.send()\n\n        return confirmation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete all confirmations for the same content_object and same field_name", "response": "def clean(self):\n        \"\"\"\n        delete all confirmations for the same content_object and the same field\n        \"\"\"\n\n        EmailConfirmation.objects.filter(content_type=self.content_type, object_id=self.object_id, email_field_name=self.email_field_name).delete()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_paginate(request, template, objects, per_page, extra_context={}):\n    paginator = Paginator(objects, per_page)\n    page = request.GET.get('page', 1)\n    get_params = '&'.join(['%s=%s' % (k, request.GET[k])\n                           for k in request.GET if k != 'page'])\n\n    try:\n        page_number = int(page)\n    except ValueError:\n        if page == 'last':\n            page_number = paginator.num_pages\n        else:\n            raise Http404\n\n    try:\n        page_obj = paginator.page(page_number)\n    except InvalidPage:\n        raise Http404\n\n    context = {\n        'object_list': page_obj.object_list,\n        'paginator': paginator,\n        'page_obj': page_obj,\n        'is_paginated': page_obj.has_other_pages(),\n        'get_params': get_params\n    }\n\n    context.update(extra_context)\n\n    return render(request, template, context)", "response": "Paginate list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef values(self):\n        report = {}\n        for k, k_changes in self._changes.items():\n            if len(k_changes) == 1:\n                report[k] = k_changes[0].new_value\n            elif k_changes[0].old_value != k_changes[-1].new_value:\n                report[k] = k_changes[-1].new_value\n        return report", "response": "Returns a mapping of items to their new values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef changes(self):\n        report = {}\n        for k, k_changes in self._changes.items():\n            if len(k_changes) == 1:\n                report[k] = k_changes[0]\n            else:\n                first = k_changes[0]\n                last = k_changes[-1]\n                if first.old_value != last.new_value or first.old_raw_str_value != last.new_raw_str_value:\n                    report[k] = _Change(\n                        first.old_value,\n                        last.new_value,\n                        first.old_raw_str_value,\n                        last.new_raw_str_value,\n                    )\n        return report", "response": "Returns a mapping of items to their effective change objects which include the old values\n        and the new values\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload configuration values from the specified source.", "response": "def load(self, source, as_defaults=False):\n        \"\"\"\n        Load configuration values from the specified source.\n\n        Args:\n            source:\n            as_defaults (bool): if ``True``, contents of ``source`` will be treated as schema of configuration items.\n\n        \"\"\"\n        if isinstance(source, six.string_types):\n            source = os.path.expanduser(source)\n            with open(source, encoding='utf-8') as f:\n                self._rw.load_config_from_file(self._config, f, as_defaults=as_defaults)\n\n        elif isinstance(source, (list, tuple)):\n            for s in source:\n                with open(s, encoding='utf-8') as f:\n                    self._rw.load_config_from_file(self._config, f, as_defaults=as_defaults)\n\n        else:\n            self._rw.load_config_from_file(self._config, source, as_defaults=as_defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload configuration values from a string.", "response": "def loads(self, config_str, as_defaults=False):\n        \"\"\"\n        Load configuration values from the specified source string.\n\n        Args:\n            config_str:\n            as_defaults (bool): if ``True``, contents of ``source`` will be treated as schema of configuration items.\n\n        \"\"\"\n        self._rw.load_config_from_string(self._config, config_str, as_defaults=as_defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dump(self, destination, with_defaults=False):\n        if isinstance(destination, six.string_types):\n            with open(destination, 'w', encoding='utf-8') as f:\n                self._rw.dump_config_to_file(self._config, f, with_defaults=with_defaults)\n        else:\n            self._rw.dump_config_to_file(self._config, destination, with_defaults=with_defaults)", "response": "Write the configuration values to the specified destination."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate a string representing all the configuration values.", "response": "def dumps(self, with_defaults=False):\n        \"\"\"\n        Generate a string representing all the configuration values.\n\n        Args:\n            with_defaults (bool): if ``True``, values of items with no custom values will be included in the output\n                if they have a default value set.\n        \"\"\"\n        return self._rw.dump_config_to_string(self._config, with_defaults=with_defaults)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_by_key(self, key, handle_not_found=True):\n        resolution = self._get_item_or_section(key, handle_not_found=handle_not_found)\n        if self.settings.key_getter:\n            return self.settings.key_getter(parent=self, subject=resolution)\n        else:\n            return resolution", "response": "Get a key from the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_item_or_section(self, key, handle_not_found=True):\n        if isinstance(key, six.string_types):\n            if self.settings.str_path_separator in key:\n                return self._get_item_or_section(key.split(self.settings.str_path_separator))\n\n            if key.endswith('_') and keyword.iskeyword(key[:-1]):\n                key = key[:-1]\n\n            if key in self._tree:\n                resolution = self._tree[key]\n            else:\n                if handle_not_found:\n                    result = self.dispatch_event(self.hooks.not_found, name=key, section=self)\n                    if result is not None:\n                        resolution = result\n                    else:\n                        raise NotFound(key, section=self)\n                else:\n                    raise NotFound(key, section=self)\n\n        elif isinstance(key, (tuple, list)) and len(key) > 0:\n            if len(key) == 1:\n                resolution = self._get_item_or_section(key[0], handle_not_found=handle_not_found)\n            else:\n                resolution = self._get_item_or_section(\n                    key[0], handle_not_found=handle_not_found\n                )._get_item_or_section(key[1:], handle_not_found=handle_not_found)\n        else:\n            raise TypeError('Expected either a string or a tuple as key, got {!r}'.format(key))\n\n        return resolution", "response": "This method returns the item or section from the tree or the section with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_item(self, *key):\n        item = self._get_item_or_section(key)\n        if not item.is_item:\n            raise RuntimeError('{} is a section, not an item'.format(key))\n        return item", "response": "Returns the item with the given key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_section(self, *key):\n        section = self._get_item_or_section(key)\n        if not section.is_section:\n            raise RuntimeError('{} is an item, not a section'.format(key))\n        return section", "response": "Get a section by key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a config item to this section.", "response": "def add_item(self, alias, item):\n        \"\"\"\n        Add a config item to this section.\n        \"\"\"\n        if not isinstance(alias, six.string_types):\n            raise TypeError('Item name must be a string, got a {!r}'.format(type(alias)))\n        item = copy.deepcopy(item)\n        if item.name is not_set:\n            item.name = alias\n\n        if self.settings.str_path_separator in item.name:\n            raise ValueError(\n                'Item name must not contain str_path_separator which is configured for this Config -- {!r} -- '\n                'but {!r} does.'.format(self.settings.str_path_separator, item)\n            )\n\n        self._tree[item.name] = item\n\n        if item.name != alias:\n            if self.settings.str_path_separator in alias:\n                raise ValueError(\n                    'Item alias must not contain str_path_separator which is configured for this Config -- {!r} --'\n                    'but {!r} used for {!r} does.'.format(self.settings.str_path_separator, alias, item)\n                )\n            self._tree[alias] = item\n\n        item._section = self\n\n        self.dispatch_event(self.hooks.item_added_to_section, alias=alias, section=self, subject=item)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a sub - section to this section.", "response": "def add_section(self, alias, section):\n        \"\"\"\n        Add a sub-section to this section.\n        \"\"\"\n        if not isinstance(alias, six.string_types):\n            raise TypeError('Section name must be a string, got a {!r}'.format(type(alias)))\n\n        self._tree[alias] = section\n\n        if self.settings.str_path_separator in alias:\n            raise ValueError(\n                'Section alias must not contain str_path_separator which is configured for this Config -- {!r} -- '\n                'but {!r} does.'.format(self.settings.str_path_separator, alias)\n            )\n\n        section._section = self\n        section._section_alias = alias\n\n        self.dispatch_event(self.hooks.section_added_to_section, alias=alias, section=self, subject=section)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over all items and items in this section.", "response": "def iter_all(self, recursive=False, path=None, key='path'):\n        \"\"\"\n        Args:\n            recursive: if ``True``, recurse into sub-sections\n\n            path (tuple or string): optional path to limit iteration over.\n\n            key: ``path`` (default), ``str_path``, ``name``, ``None``, or a function to calculate the key from\n                ``(k, v)`` tuple.\n\n        Returns:\n            iterator: iterator over ``(path, obj)`` pairs of all items and\n            sections contained in this section.\n        \"\"\"\n        if isinstance(key, six.string_types) or key is None:\n            if key in _iter_emitters:\n                emitter = _iter_emitters[key]\n            else:\n                raise ValueError('Invalid key {!r}'.format(key))\n        else:\n            emitter = lambda k, v, _, f=key: (f(k, v), v)\n\n        for p, obj in self._get_path_iterator(recursive=recursive, path=path):\n            yield emitter(p, obj, self.settings.str_path_separator)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over all sections in this article.", "response": "def iter_sections(self, recursive=False, path=None, key='path'):\n        \"\"\"\n        See :meth:`.iter_all` for standard iterator argument descriptions.\n\n        Returns:\n            iterator: iterator over ``(key, section)`` pairs of all sections\n                in this section (and sub-sections if ``recursive=True``).\n\n        \"\"\"\n        for x in self.iter_all(recursive=recursive, path=path, key=key):\n            if key is None:\n                if x.is_section:\n                    yield x\n            elif x[1].is_section:\n                yield x"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset(self):\n        for _, item in self.iter_items(recursive=True):\n            item.reset()", "response": "Resets all values of all items contained in this section to their default values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_default(self):\n        for _, item in self.iter_items(recursive=True):\n            if not item.is_default:\n                return False\n        return True", "response": "Returns True if all items in this section have values equal to defaults False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump all items contained in this section to a dictionary.", "response": "def dump_values(self, with_defaults=True, dict_cls=dict, flat=False):\n        \"\"\"\n        Export values of all items contained in this section to a dictionary.\n\n        Items with no values set (and no defaults set if ``with_defaults=True``) will be excluded.\n\n        Returns:\n            dict: A dictionary of key-value pairs, where for sections values are dictionaries\n            of their contents.\n\n        \"\"\"\n        values = dict_cls()\n\n        if flat:\n            for str_path, item in self.iter_items(recursive=True, key='str_path'):\n                if item.has_value:\n                    if with_defaults or not item.is_default:\n                        values[str_path] = item.value\n        else:\n            for item_name, item in self._tree.items():\n                if is_config_section(item):\n                    section_values = item.dump_values(with_defaults=with_defaults, dict_cls=dict_cls)\n                    if section_values:\n                        values[item_name] = section_values\n                else:\n                    if item.has_value:\n                        if with_defaults or not item.is_default:\n                            values[item.name] = item.value\n        return values"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_values(self, dictionary, as_defaults=False, flat=False):\n        if flat:\n            # Deflatten the dictionary and then pass on to the normal case.\n            separator = self.settings.str_path_separator\n            flat_dictionary = dictionary\n            dictionary = collections.OrderedDict()\n            for k, v in flat_dictionary.items():\n                k_parts = k.split(separator)\n                c = dictionary\n                for i, kp in enumerate(k_parts):\n                    if i >= len(k_parts) - 1:\n                        c[kp] = v\n                    else:\n                        if kp not in c:\n                            c[kp] = collections.OrderedDict()\n                        c = c[kp]\n\n        for name, value in dictionary.items():\n            if name not in self:\n                if as_defaults:\n                    if isinstance(value, dict):\n                        self[name] = self.create_section()\n                        self[name].load_values(value, as_defaults=as_defaults)\n                    else:\n                        self[name] = self.create_item(name, default=value)\n                else:\n                    # Skip unknown names if not interpreting dictionary as defaults\n                    pass\n                continue\n\n            resolution = self._get_item_or_section(name, handle_not_found=False)\n            if is_config_item(resolution):\n                if as_defaults:\n                    resolution.default = value\n                else:\n                    resolution.value = value\n            else:\n                resolution.load_values(value, as_defaults=as_defaults)", "response": "Load config values from a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalculates section s path in configuration tree.", "response": "def get_path(self):\n        \"\"\"\n        Calculate section's path in configuration tree.\n        Use this sparingly -- path is calculated by going up the configuration tree.\n        For a large number of sections, it is more efficient to use iterators that return paths\n        as keys.\n\n        Path value is stable only once the configuration tree is completely initialised.\n        \"\"\"\n\n        if not self.alias:\n            return ()\n\n        if self.section:\n            return self.section.get_path() + (self.alias,)\n        else:\n            return self.alias,"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dispatch_event(self, event_, **kwargs):\n        if self.settings.hooks_enabled:\n            result = self.hooks.dispatch_event(event_, **kwargs)\n            if result is not None:\n                return result\n\n            # Must also dispatch the event in parent section\n            if self.section:\n                return self.section.dispatch_event(event_, **kwargs)\n\n        elif self.section:\n            # Settings only apply to one section, so must still\n            # dispatch the event in parent sections recursively.\n            self.section.dispatch_event(event_, **kwargs)", "response": "Dispatches an event in the section tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef configparser(self):\n        if self._configparser_adapter is None:\n            self._configparser_adapter = ConfigPersistenceAdapter(\n                config=self,\n                reader_writer=ConfigParserReaderWriter(\n                    config_parser_factory=self.settings.configparser_factory,\n                ),\n            )\n        return self._configparser_adapter", "response": "Returns a ConfigPersistenceAdapter to dump or load INI format strings and files using standard library s configparser module."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a ConfigPersistenceAdapter to dump or load JSON format strings and files.", "response": "def json(self):\n        \"\"\"\n        Adapter to dump/load JSON format strings and files.\n        \n        Returns:\n            ConfigPersistenceAdapter\n        \"\"\"\n        if self._json_adapter is None:\n            self._json_adapter = ConfigPersistenceAdapter(\n                config=self,\n                reader_writer=JsonReaderWriter(),\n            )\n        return self._json_adapter"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a ConfigPersistenceAdapter to dump or load YAML format strings and files.", "response": "def yaml(self):\n        \"\"\"\n        Adapter to dump/load YAML format strings and files.\n        \n        Returns:\n            ConfigPersistenceAdapter\n        \"\"\"\n        if self._yaml_adapter is None:\n            self._yaml_adapter = ConfigPersistenceAdapter(\n                config=self,\n                reader_writer=YamlReaderWriter(),\n            )\n        return self._yaml_adapter"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclick extension Returns: ClickExtension", "response": "def click(self):\n        \"\"\"\n        click extension\n\n        Returns:\n            ClickExtension\n        \"\"\"\n        if self._click_extension is None:\n            from .click_ext import ClickExtension\n            self._click_extension = ClickExtension(\n                config=self\n            )\n        return self._click_extension"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nloading user configuration based on settings. load_sources.", "response": "def load(self):\n        \"\"\"\n        Load user configuration based on settings.\n        \"\"\"\n\n        # Must reverse because we want the sources assigned to higher-up Config instances\n        # to overrides sources assigned to lower Config instances.\n        for section in reversed(list(self.iter_sections(recursive=True, key=None))):\n            if section.is_config:\n                section.load()\n\n        for source in self.settings.load_sources:\n            adapter = getattr(self, _get_persistence_adapter_for(source))\n            if adapter.store_exists(source):\n                adapter.load(source)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nregisters a click. option which falls back to a configmanager Item which falls back to a configmanager Item", "response": "def option(self, *args, **kwargs):\n        \"\"\"\n        Registers a click.option which falls back to a configmanager Item\n        if user hasn't provided a value in the command line.\n\n        Item must be the last of ``args``.\n\n        Examples::\n\n            config = Config({'greeting': 'Hello'})\n\n            @click.command()\n            @config.click.option('--greeting', config.greeting)\n            def say_hello(greeting):\n                click.echo(greeting)\n\n        \"\"\"\n        args, kwargs = _config_parameter(args, kwargs)\n        return self._click.option(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a click. argument which falls back to a configmanager Item", "response": "def argument(self, *args, **kwargs):\n        \"\"\"\n        Registers a click.argument which falls back to a configmanager Item\n        if user hasn't provided a value in the command line.\n\n        Item must be the last of ``args``.\n        \"\"\"\n\n        if kwargs.get('required', True):\n            raise TypeError(\n                'In click framework, arguments are mandatory, unless marked required=False. '\n                'Attempt to use configmanager as a fallback provider suggests that this is an optional option, '\n                'not a mandatory argument.'\n            )\n\n        args, kwargs = _config_parameter(args, kwargs)\n        return self._click.argument(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_kwarg(self, name, kwargs):\n        at_name = '@{}'.format(name)\n\n        if name in kwargs:\n            if at_name in kwargs:\n                raise ValueError('Both {!r} and {!r} specified in kwargs'.format(name, at_name))\n            return kwargs[name]\n\n        if at_name in kwargs:\n            return kwargs[at_name]\n\n        return not_set", "response": "Helper to get value of a named attribute irrespective of whether it is passed\n            or not."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_envvar_value(self):\n        envvar_name = None\n\n        if self.envvar is True:\n            envvar_name = self.envvar_name\n            if envvar_name is None:\n                envvar_name = '_'.join(self.get_path()).upper()\n        elif self.envvar:\n            envvar_name = self.envvar\n\n        if envvar_name and envvar_name in os.environ:\n            return self.type.deserialize(os.environ[envvar_name])\n        else:\n            return not_set", "response": "Internal helper to get item value from an environment variable. Returns not_set if the variable is not set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the config value.", "response": "def get(self, fallback=not_set):\n        \"\"\"\n        Returns config value.\n\n        See Also:\n            :meth:`.set` and :attr:`.value`\n        \"\"\"\n\n        envvar_value = self._get_envvar_value()\n        if envvar_value is not not_set:\n            return envvar_value\n\n        if self.has_value:\n            if self._value is not not_set:\n                return self._value\n            else:\n                return copy.deepcopy(self.default)\n        elif fallback is not not_set:\n            return fallback\n        elif self.required:\n            raise RequiredValueMissing(name=self.name, item=self)\n        return fallback"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the value of the item.", "response": "def set(self, value):\n        \"\"\"\n        Sets config value.\n        \"\"\"\n        old_value = self._value\n        old_raw_str_value = self.raw_str_value\n\n        self.type.set_item_value(self, value)\n\n        new_value = self._value\n\n        if old_value is not_set and new_value is not_set:\n            # Nothing to report\n            return\n\n        if self.section:\n            self.section.dispatch_event(\n                self.section.hooks.item_value_changed,\n                item=self,\n                old_value=old_value,\n                new_value=new_value,\n                old_raw_str_value=old_raw_str_value,\n                new_raw_str_value=self.raw_str_value\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets the value of the config item to its default value.", "response": "def reset(self):\n        \"\"\"\n        Resets the value of config item to its default value.\n        \"\"\"\n        old_value = self._value\n        old_raw_str_value = self.raw_str_value\n\n        self._value = not_set\n        self.raw_str_value = not_set\n\n        new_value = self._value\n\n        if old_value is not_set:\n            # Nothing to report\n            return\n\n        if self.section:\n            self.section.dispatch_event(\n                self.section.hooks.item_value_changed,\n                item=self,\n                old_value=old_value,\n                new_value=new_value,\n                old_raw_str_value=old_raw_str_value,\n                new_raw_str_value=self.raw_str_value,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn True if the item s value is the default value.", "response": "def is_default(self):\n        \"\"\"\n        ``True`` if the item's value is its default value or if no value and no default value are set.\n\n        If the item is backed by an environment variable, this will be ``True`` only\n        if the environment variable is set and is different to the\n        default value of the item.\n        \"\"\"\n        envvar_value = self._get_envvar_value()\n        if envvar_value is not not_set:\n            return envvar_value == self.default\n        else:\n            return self._value is not_set or self._value == self.default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has_value(self):\n        if self._get_envvar_value() is not not_set:\n            return True\n        else:\n            return self.default is not not_set or self._value is not not_set", "response": "Return True if the item has a value set."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the path of the item in the configuration tree.", "response": "def get_path(self):\n        \"\"\"\n        Calculate item's path in configuration tree.\n        Use this sparingly -- path is calculated by going up the configuration tree.\n        For a large number of items, it is more efficient to use iterators that return paths\n        as keys.\n\n        Path value is stable only once the configuration tree is completely initialised.\n        \"\"\"\n        if self.section:\n            return self.section.get_path() + (self.name,)\n        else:\n            return self.name,"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntranslating a type name to a built - in type or a name of known type.", "response": "def translate(self, type_):\n        \"\"\"\n        Given a built-in, an otherwise known type, or a name of known type, return its corresponding wrapper type::\n\n            >>> Types.translate(int)\n            <_IntType ('int', 'integer')>\n\n            >>> Types.translate('string')\n            <_StrType ('str', 'string', 'unicode')>\n\n        \"\"\"\n        if isinstance(type_, six.string_types):\n            for t in self.all_types:\n                if type_ in t.aliases:\n                    return t\n            raise ValueError('Failed to recognise type by name {!r}'.format(type_))\n\n        for t in self.all_types:\n            if type_ in t.builtin_types:\n                return t\n\n        return type_"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filebrowser(request, file_type):\n    template = 'filebrowser.html'\n    upload_form = FileUploadForm()\n    uploaded_file = None\n    upload_tab_active = False\n    is_images_dialog = (file_type == 'img')\n    is_documents_dialog = (file_type == 'doc')\n    \n    files = FileBrowserFile.objects.filter(file_type=file_type)\n    \n    if request.POST:\n        upload_form = FileUploadForm(request.POST, request.FILES)\n        upload_tab_active = True\n        \n        if upload_form.is_valid():\n            uploaded_file = upload_form.save(commit=False)\n            uploaded_file.file_type = file_type\n            uploaded_file.save()\n    \n    data = {\n        'upload_form': upload_form,\n        'uploaded_file': uploaded_file,\n        'upload_tab_active': upload_tab_active,\n        'is_images_dialog': is_images_dialog,\n        'is_documents_dialog': is_documents_dialog\n    }\n    per_page = getattr(settings, 'FILEBROWSER_PER_PAGE', 20)\n    return render_paginate(request, template, files, per_page, data)", "response": "Trigger view for filebrowser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef filebrowser_remove_file(request, item_id, file_type):\n    fobj = get_object_or_404(FileBrowserFile, file_type=file_type, id=item_id)\n    fobj.delete()\n    \n    if file_type == 'doc':\n        return HttpResponseRedirect(reverse('mce-filebrowser-documents'))\n    \n    return HttpResponseRedirect(reverse('mce-filebrowser-images'))", "response": "Remove file from filebrowser"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef available_domains(self):\n        if not hasattr(self, '_available_domains'):\n            url = 'http://{0}/request/domains/format/json/'.format(\n                self.api_domain)\n            req = requests.get(url)\n            domains = req.json()\n            setattr(self, '_available_domains', domains)\n        return self._available_domains", "response": "Return list of available domains for use in email address."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a random string for email address login.", "response": "def generate_login(self, min_length=6, max_length=10, digits=True):\n        \"\"\"\n        Generate string for email address login with defined length and\n        alphabet.\n\n        :param min_length: (optional) min login length.\n        Default value is ``6``.\n        :param max_length: (optional) max login length.\n        Default value is ``10``.\n        :param digits: (optional) use digits in login generation.\n        Default value is ``True``.\n        \"\"\"\n        chars = string.ascii_lowercase\n        if digits:\n            chars += string.digits\n        length = random.randint(min_length, max_length)\n        return ''.join(random.choice(chars) for x in range(length))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns full email address from login and domain from params in class initialization or generate new.", "response": "def get_email_address(self):\n        \"\"\"\n        Return full email address from login and domain from params in class\n        initialization or generate new.\n        \"\"\"\n        if self.login is None:\n            self.login = self.generate_login()\n\n        available_domains = self.available_domains\n        if self.domain is None:\n            self.domain = random.choice(available_domains)\n        elif self.domain not in available_domains:\n            raise ValueError('Domain not found in available domains!')\n        return u'{0}{1}'.format(self.login, self.domain)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_mailbox(self, email=None, email_hash=None):\n        if email is None:\n            email = self.get_email_address()\n        if email_hash is None:\n            email_hash = self.get_hash(email)\n\n        url = 'http://{0}/request/mail/id/{1}/format/json/'.format(\n            self.api_domain, email_hash)\n        req = requests.get(url)\n        return req.json()", "response": "Get list of emails in given email address."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconnecting to the specified telegram - cli socket and return None", "response": "def _connect(self):\n\n        '''\n            Connect\n\n            Setup a socket connection to the specified telegram-cli socket\n\n            --\n            @return None\n        '''\n\n        if self.connection_type.lower() == 'tcp':\n            self.connection = sockets.setup_tcp_socket(self.location, self.port)\n\n        elif self.connection_type.lower() == 'unix':\n            self.connection = sockets.setup_domain_socket(self.location)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend a payload over a telegram - cli socket.", "response": "def _send(self, payload):\n\n        '''\n            Send\n\n            Send a payload to a telegram-cli socket.\n\n            --\n            @param  payload:str     The Payload to send over a socket connection.\n            @return bool\n        '''\n\n        if not self.connection:\n            self._connect()\n\n        # Send the payload, adding a newline to the end\n        self.connection.send(payload + '\\n')\n\n        # Read 256 bytes off the socket and check the\n        # status that returned.\n        try:\n            data = self.connection.recv(256)\n\n        except socket.timeout, e:\n            print 'Failed to read response in a timely manner to determine the status.'\n            return False\n\n        if data.split('\\n')[1] == 'FAIL':\n            print 'Failed to send payload: {payload}'.format(payload = payload)\n            return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_domain_socket(location):\n\n    '''\n        Setup Domain Socket\n\n        Setup a connection to a Unix Domain Socket\n\n        --\n        @param  location:str    The path to the Unix Domain Socket to connect to.\n        @return <class 'socket._socketobject'>\n    '''\n\n    clientsocket = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)\n    clientsocket.settimeout(timeout)\n    clientsocket.connect(location)\n\n    return clientsocket", "response": "Setup a connection to a Unix Domain Socket"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_primary_zone(self, account_name, zone_name):\n        zone_properties = {\"name\": zone_name, \"accountName\": account_name, \"type\": \"PRIMARY\"}\n        primary_zone_info = {\"forceImport\": True, \"createType\": \"NEW\"}\n        zone_data = {\"properties\": zone_properties, \"primaryCreateInfo\": primary_zone_info}\n        return self.rest_api_connection.post(\"/v1/zones\", json.dumps(zone_data))", "response": "Creates a new primary zone."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new primary zone by uploading a bind file.", "response": "def create_primary_zone_by_upload(self, account_name, zone_name, bind_file):\n        \"\"\"Creates a new primary zone by uploading a bind file\n\n        Arguments:\n        account_name -- The name of the account that will contain this zone.\n        zone_name -- The name of the zone.  It must be unique.\n        bind_file -- The file to upload.\n\n        \"\"\"\n        zone_properties = {\"name\": zone_name, \"accountName\": account_name, \"type\": \"PRIMARY\"}\n        primary_zone_info = {\"forceImport\": True, \"createType\": \"UPLOAD\"}\n        zone_data = {\"properties\": zone_properties, \"primaryCreateInfo\": primary_zone_info}\n        files = {'zone': ('', json.dumps(zone_data), 'application/json'),\n                 'file': ('file', open(bind_file, 'rb'), 'application/octet-stream')}\n        return self.rest_api_connection.post_multi_part(\"/v1/zones\", files)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_primary_zone_by_axfr(self, account_name, zone_name, master, tsig_key=None, key_value=None):\n        zone_properties = {\"name\": zone_name, \"accountName\": account_name, \"type\": \"PRIMARY\"}\n        if tsig_key is not None and key_value is not None:\n            name_server_info = {\"ip\": master, \"tsigKey\": tsig_key, \"tsigKeyValue\": key_value}\n        else:\n            name_server_info = {\"ip\": master}\n        primary_zone_info = {\"forceImport\": True, \"createType\": \"TRANSFER\", \"nameServer\": name_server_info}\n        zone_data = {\"properties\": zone_properties, \"primaryCreateInfo\": primary_zone_info}\n        return self.rest_api_connection.post(\"/v1/zones\", json.dumps(zone_data))", "response": "Creates a new primary zone by zone transferring off a master."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a secondary zone.", "response": "def create_secondary_zone(self, account_name, zone_name, master, tsig_key=None, key_value=None):\n        \"\"\"Creates a new secondary zone.\n\n        Arguments:\n        account_name -- The name of the account.\n        zone_name -- The name of the zone.\n        master -- Primary name server IP address.\n\n        Keyword Arguments:\n        tsig_key -- For TSIG-enabled zones: The transaction signature key.\n                    NOTE: Requires key_value.\n        key_value -- TSIG key secret.\n\n        \"\"\"\n        zone_properties = {\"name\": zone_name, \"accountName\": account_name, \"type\": \"SECONDARY\"}\n        if tsig_key is not None and key_value is not None:\n            name_server_info = {\"ip\": master, \"tsigKey\": tsig_key, \"tsigKeyValue\": key_value}\n        else:\n            name_server_info = {\"ip\": master}\n        name_server_ip_1 = {\"nameServerIp1\": name_server_info}\n        name_server_ip_list = {\"nameServerIpList\": name_server_ip_1}\n        secondary_zone_info = {\"primaryNameServers\": name_server_ip_list}\n        zone_data = {\"properties\": zone_properties, \"secondaryCreateInfo\": secondary_zone_info}\n        return self.rest_api_connection.post(\"/v1/zones\", json.dumps(zone_data))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_zones_of_account(self, account_name, q=None, **kwargs):\n        uri = \"/v1/accounts/\" + account_name + \"/zones\"\n        params = build_params(q, kwargs)\n        return self.rest_api_connection.get(uri, params)", "response": "Returns a list of zones for the specified account."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_zones(self, q=None, **kwargs):\n        uri = \"/v1/zones\"\n        params = build_params(q, kwargs)\n        return self.rest_api_connection.get(uri, params)", "response": "Returns a list of zones across all of the user s accounts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nediting the axfr name servers of a secondary zone. Arguments: zone_name -- The name of the secondary zone being edited. primary -- The primary name server value. Keyword Arguments: backup -- The backup name server if any. second_backup -- The second backup name server.", "response": "def edit_secondary_name_server(self, zone_name, primary=None, backup=None, second_backup=None):\n        \"\"\"Edit the axfr name servers of a secondary zone.\n\n        Arguments:\n        zone_name -- The name of the secondary zone being edited.\n        primary -- The primary name server value.\n\n        Keyword Arguments:\n        backup -- The backup name server if any.\n        second_backup -- The second backup name server.\n\n        \"\"\"\n        name_server_info = {}\n        if primary is not None:\n            name_server_info['nameServerIp1'] = {'ip':primary}\n        if backup is not None:\n            name_server_info['nameServerIp2'] = {'ip':backup}\n        if second_backup is not None:\n            name_server_info['nameServerIp3'] = {'ip':second_backup}\n        name_server_ip_list = {\"nameServerIpList\": name_server_info}\n        secondary_zone_info = {\"primaryNameServers\": name_server_ip_list}\n        zone_data = {\"secondaryCreateInfo\": secondary_zone_info}\n        return self.rest_api_connection.patch(\"/v1/zones/\" + zone_name, json.dumps(zone_data))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_rrsets(self, zone_name, q=None, **kwargs):\n        uri = \"/v1/zones/\" + zone_name + \"/rrsets\"\n        params = build_params(q, kwargs)\n        return self.rest_api_connection.get(uri, params)", "response": "Returns the list of RRSets in the specified zone."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of RRSets in the specified zone of the specified type.", "response": "def get_rrsets_by_type(self, zone_name, rtype, q=None, **kwargs):\n        \"\"\"Returns the list of RRSets in the specified zone of the specified type.\n\n        Arguments:\n        zone_name -- The name of the zone.\n        rtype -- The type of the RRSets.  This can be numeric (1) or\n                 if a well-known name is defined for the type (A), you can use it instead.\n\n        Keyword Arguments:\n        q -- The search parameters, in a dict.  Valid keys are:\n             ttl - must match the TTL for the rrset\n             owner - substring match of the owner name\n             value - substring match of the first BIND field value\n        sort -- The sort column used to order the list. Valid values for the sort field are:\n                OWNER\n                TTL\n                TYPE\n        reverse -- Whether the list is ascending(False) or descending(True)\n        offset -- The position in the list for the first returned element(0 based)\n        limit -- The maximum number of rows to be returned.\n\n        \"\"\"\n        uri = \"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype\n        params = build_params(q, kwargs)\n        return self.rest_api_connection.get(uri, params)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_rrsets_by_type_owner(self, zone_name, rtype, owner_name, q=None, **kwargs):\n        uri = \"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype + \"/\" + owner_name\n        params = build_params(q, kwargs)\n        return self.rest_api_connection.get(uri, params)", "response": "Returns the list of RRSets in the specified zone of the specified type and owner."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_rrset(self, zone_name, rtype, owner_name, ttl, rdata):\n        if type(rdata) is not list:\n            rdata = [rdata]\n        rrset = {\"ttl\": ttl, \"rdata\": rdata}\n        return self.rest_api_connection.post(\"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype + \"/\" + owner_name, json.dumps(rrset))", "response": "Creates a new RRSet in the specified zone."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate an existing RRSet in the specified zone.", "response": "def edit_rrset(self, zone_name, rtype, owner_name, ttl, rdata, profile=None):\n        \"\"\"Updates an existing RRSet in the specified zone.\n\n        Arguments:\n        zone_name -- The zone that contains the RRSet.  The trailing dot is optional.\n        rtype -- The type of the RRSet.  This can be numeric (1) or\n                 if a well-known name is defined for the type (A), you can use it instead.\n        owner_name -- The owner name for the RRSet.\n                      If no trailing dot is supplied, the owner_name is assumed to be relative (foo).\n                      If a trailing dot is supplied, the owner name is assumed to be absolute (foo.zonename.com.)\n        ttl -- The updated TTL value for the RRSet.\n        rdata -- The updated BIND data for the RRSet as a string.\n                 If there is a single resource record in the RRSet, you can pass in the single string.\n                 If there are multiple resource records  in this RRSet, pass in a list of strings.\n        profile -- The profile info if this is updating a resource pool\n\n        \"\"\"\n        if type(rdata) is not list:\n            rdata = [rdata]\n        rrset = {\"ttl\": ttl, \"rdata\": rdata}\n        if profile:\n            rrset[\"profile\"] = profile\n        uri = \"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype + \"/\" + owner_name\n        return self.rest_api_connection.put(uri, json.dumps(rrset))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit_rrset_rdata(self, zone_name, rtype, owner_name, rdata, profile=None):\n        if type(rdata) is not list:\n            rdata = [rdata]\n        rrset = {\"rdata\": rdata}\n        method = \"patch\"\n        if profile:\n            rrset[\"profile\"] = profile\n            method = \"put\"\n        uri = \"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype + \"/\" + owner_name\n        return getattr(self.rest_api_connection, method)(uri,json.dumps(rrset))", "response": "Updates an existing RRSet s Rdata in the specified zone."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_rrset(self, zone_name, rtype, owner_name):\n        return self.rest_api_connection.delete(\"/v1/zones/\" + zone_name + \"/rrsets/\" + rtype + \"/\" + owner_name)", "response": "Deletes an RRSet.\n\n        Arguments:\n        zone_name -- The zone containing the RRSet to be deleted.  The trailing dot is optional.\n        rtype -- The type of the RRSet.  This can be numeric (1) or\n                 if a well-known name is defined for the type (A), you can use it instead.\n        owner_name -- The owner name for the RRSet.\n                      If no trailing dot is supplied, the owner_name is assumed to be relative (foo).\n                      If a trailing dot is supplied, the owner name is assumed to be absolute (foo.zonename.com.)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a web forward record.", "response": "def create_web_forward(self, zone_name, request_to, redirect_to, forward_type):\n        \"\"\"Create a web forward record.\n\n        Arguments:\n        zone_name -- The zone in which the web forward is to be created.\n        request_to -- The URL to be redirected. You may use http:// and ftp://.\n        forward_type -- The type of forward. Valid options include:\n                                   Framed\n                                   HTTP_301_REDIRECT\n                                   HTTP_302_REDIRECT\n                                   HTTP_303_REDIRECT\n                                   HTTP_307_REDIRECT\n\n        \"\"\"\n        web_forward = {\"requestTo\": request_to, \"defaultRedirectTo\": redirect_to, \"defaultForwardType\": forward_type}\n        return self.rest_api_connection.post(\"/v1/zones/\" + zone_name + \"/webforwards\", json.dumps(web_forward))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_sb_pool(self, zone_name, owner_name, ttl, pool_info, rdata_info, backup_record_list):\n\n        rrset = self._build_sb_rrset(backup_record_list, pool_info, rdata_info, ttl)\n        return self.rest_api_connection.post(\"/v1/zones/\" + zone_name + \"/rrsets/A/\" + owner_name, json.dumps(rrset))", "response": "Creates a new SB Pool."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef edit_sb_pool(self, zone_name, owner_name, ttl, pool_info, rdata_info, backup_record_list):\n        rrset = self._build_sb_rrset(backup_record_list, pool_info, rdata_info, ttl)\n        return self.rest_api_connection.put(\"/v1/zones/\" + zone_name + \"/rrsets/A/\" + owner_name, json.dumps(rrset))", "response": "Edit an existing SB Pool in the specified zone."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_tc_pool(self, zone_name, owner_name, ttl, pool_info, rdata_info, backup_record):\n\n        rrset = self._build_tc_rrset(backup_record, pool_info, rdata_info, ttl)\n        return self.rest_api_connection.post(\"/v1/zones/\" + zone_name + \"/rrsets/A/\" + owner_name, json.dumps(rrset))", "response": "Creates a TC Pool."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates an existing TC Pool in the specified zone.", "response": "def edit_tc_pool(self, zone_name, owner_name, ttl, pool_info, rdata_info, backup_record):\n        \"\"\"Updates an existing TC Pool in the specified zone.\n        :param zone_name: The zone that contains the RRSet.  The trailing dot is optional.\n        :param owner_name: The owner name for the RRSet.\n                      If no trailing dot is supplied, the owner_name is assumed to be relative (foo).\n                      If a trailing dot is supplied, the owner name is assumed to be absolute (foo.zonename.com.)\n        :param ttl: The updated TTL value for the RRSet.\n        :param pool_info: dict of information about the pool\n        :param rdata_info: dict of information about the records in the pool.\n                      The keys in the dict are the A and CNAME records that make up the pool.\n                      The values are the rdataInfo for each of the records\n        :param backup_record: dict of information about the backup (all-fail) records in the pool.\n                        There are two key/value in the dict:\n                            rdata - the A or CNAME for the backup record\n                            failoverDelay - the time to wait to fail over (optional, defaults to 0)\n        \"\"\"\n        rrset = self._build_tc_rrset(backup_record, pool_info, rdata_info, ttl)\n        return self.rest_api_connection.put(\"/v1/zones/\" + zone_name + \"/rrsets/A/\" + owner_name, json.dumps(rrset))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dumpf(obj, path, encoding=None):\n    path = str(path)\n    if path.endswith('.gz'):\n        with gzip.open(path, mode='wt', encoding=encoding) as f:\n            return dump(obj, f)\n    else:\n        with open(path, mode='wt', encoding=encoding) as f:\n            dump(obj, f)", "response": "Serialize obj to path in ARPA format."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load(fp, model=None, parser=None):\n    if not model:\n        model = 'simple'\n    if not parser:\n        parser = 'quick'\n\n    if model not in ['simple']:\n        raise ValueError\n    if parser not in ['quick']:\n        raise ValueError\n\n    if model == 'simple' and parser == 'quick':\n        return ARPAParserQuick(ARPAModelSimple).parse(fp)\n    else:\n        raise ValueError", "response": "Deserialize fp to a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_message(self, recipient, message):\n\n        '''\n            Send Message\n\n            Sends a message to a Telegram Recipient.\n            From telegram-cli:\n                msg <peer> <text>       Sends text message to peer\n\n            --\n            @param  recipient:str   The telegram recipient the message is intended\n                                    for. Can be either a Person or a Group.\n            @param  message:str     The message to send.\n            @return None\n        '''\n\n        payload = 'msg {recipient} {message}'.format(\n            recipient = strings.escape_recipient(recipient),\n            message = strings.escape_newlines(message.strip())\n        )\n        self._send(payload)\n\n        return", "response": "Send a message to a Telegram Recipient."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend an image to a Telegram Recipient.", "response": "def send_image(self, recipient, path):\n\n        '''\n            Send Image\n\n            Sends a an image to a Telegram Recipient. The image needs\n            to be readable to the telegram-cli instance where the\n            socket is created.\n            From telegram-cli:\n                send_photo <peer> <file>        Sends photo to peer\n\n            --\n            @param  recipient:str   The telegram recipient the message is intended\n                                    for. Can be either a Person or a Group.\n            @param  path:str        The full path to the image to send.\n            @return None\n        '''\n\n        payload = 'send_photo {recipient} {path}'.format(\n            recipient = strings.escape_recipient(recipient),\n            path = path\n        )\n        self._send(payload)\n\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks whether two Hilbert spaces are disjoint.", "response": "def isdisjoint(self, other):\n        \"\"\"Check whether two Hilbert spaces are disjoint (do not have any\n        common local factors). Note that `FullSpace` is *not* disjoint with any\n        other Hilbert space, while `TrivialSpace` *is* disjoint with any other\n        HilbertSpace (even itself)\n        \"\"\"\n        if other == FullSpace:\n            return False\n        else:\n            for ls in self.local_factors:\n                if isinstance(ls.label, StrLabel):\n                    return False\n            for ls in other.local_factors:\n                if isinstance(ls.label, StrLabel):\n                    return False\n            return set(self.local_factors).isdisjoint(set(other.local_factors))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _check_basis_label_type(cls, label_or_index):\n        if not isinstance(label_or_index, cls._basis_label_types):\n            raise TypeError(\n                \"label_or_index must be an instance of one of %s; not %s\" % (\n                    \", \".join([t.__name__ for t in cls._basis_label_types]),\n                    label_or_index.__class__.__name__))", "response": "Checks that label_or_index is of the correct type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nunpack a label or index into a tuple.", "response": "def _unpack_basis_label_or_index(self, label_or_index):\n        \"\"\"return tuple (label, ind) from `label_or_index`\n\n        If `label_or_int` is a :class:`.SymbolicLabelBase` sub-instance, it\n        will be stored in the `label` attribute, and the `ind` attribute will\n        return the value of the label's :attr:`.FockIndex.fock_index`\n        attribute.  No checks are performed for symbolic labels.\n\n        :meth:`_check_basis_label_type` is called on `label_or_index`.\n\n        Raises:\n            ValueError: if `label_or_index` is a :class:`str` referencing an\n                invalid basis state; or, if `label_or_index` is an :class:`int`\n                < 0 or >= the dimension of the Hilbert space\n            BasisNotSetError: if `label_or_index` is a :class:`str`, but the\n                Hilbert space has no defined basis\n            TypeError: if `label_or_int` is not a :class:`str`, :class:`int`,\n                or :class:`.SymbolicLabelBase`, or more generally whatever\n                types are allowed through the `_basis_label_types` attribute of\n                the Hilbert space.\n        \"\"\"\n        self._check_basis_label_type(label_or_index)\n        if isinstance(label_or_index, str):\n            label = label_or_index\n            try:\n                ind = self.basis_labels.index(label)\n                # the above line may also raise BasisNotSetError, which we\n                # don't want to catch here\n            except ValueError:\n                # a less confusing error message:\n                raise ValueError(\n                    \"%r is not one of the basis labels %r\"\n                    % (label, self.basis_labels))\n        elif isinstance(label_or_index, int):\n            ind = label_or_index\n            if ind < 0:\n                raise ValueError(\"Index %d must be >= 0\" % ind)\n            if self.has_basis:\n                if ind >= self.dimension:\n                    raise ValueError(\n                        \"Index %s must be < the dimension %d of Hilbert \"\n                        \"space %s\" % (ind, self.dimension, self))\n                label = self.basis_labels[label_or_index]\n            else:\n                label = str(label_or_index)\n        elif isinstance(label_or_index, SymbolicLabelBase):\n            label = label_or_index\n            try:\n                ind = label_or_index.fock_index\n            except AttributeError:\n                raise TypeError(\n                    \"label_or_index must define a fock_index attribute in \"\n                    \"order to be used for identifying a level in a Hilbert \"\n                    \"space\")\n        else:\n            raise TypeError(\n                \"label_or_index must be an int or str, or SymbolicLabelBase, \"\n                \"not %s\" % type(label_or_index))\n        return label, ind"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef basis_states(self):\n        from qnet.algebra.core.state_algebra import BasisKet  # avoid circ. import\n        for label in self.basis_labels:\n            yield BasisKet(label, hs=self)", "response": "Yields the states that form the canonical basis of the Hilbert space."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef basis_state(self, index_or_label):\n        from qnet.algebra.core.state_algebra import BasisKet  # avoid circ. import\n        try:\n            return BasisKet(index_or_label, hs=self)\n        except ValueError as exc_info:\n            if isinstance(index_or_label, int):\n                raise IndexError(str(exc_info))\n            else:\n                raise KeyError(str(exc_info))", "response": "Return the basis state with the given index or label."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngiving a label or index of a basis state return the next basis state.", "response": "def next_basis_label_or_index(self, label_or_index, n=1):\n        \"\"\"Given the label or index of a basis state, return the label/index of\n        the next basis state.\n\n        More generally, if `n` is given, return the `n`'th next basis state\n        label/index; `n` may also be negative to obtain previous basis state\n        labels/indices.\n\n        The return type is the same as the type of `label_or_index`.\n\n        Args:\n            label_or_index (int or str or SymbolicLabelBase): If `int`, the\n                index of a basis state; if `str`, the label of a basis state\n            n (int): The increment\n\n        Raises:\n            IndexError: If going beyond the last or first basis state\n            ValueError: If `label` is not a label for any basis state in the\n                Hilbert space\n            .BasisNotSetError: If the Hilbert space has no defined basis\n            TypeError: if `label_or_index` is neither a :class:`str` nor an\n                :class:`int`, nor a :class:`SymbolicLabelBase`\n        \"\"\"\n        if isinstance(label_or_index, int):\n            new_index = label_or_index + n\n            if new_index < 0:\n                raise IndexError(\"index %d < 0\" % new_index)\n            if self.has_basis:\n                if new_index >= self.dimension:\n                    raise IndexError(\"index %d out of range for basis %s\"\n                                     % (new_index, self._basis))\n            return new_index\n        elif isinstance(label_or_index, str):\n            label_index = self.basis_labels.index(label_or_index)\n            new_index = label_index + n\n            if (new_index < 0) or (new_index >= len(self._basis)):\n                raise IndexError(\"index %d out of range for basis %s\"\n                                 % (new_index, self._basis))\n            return self._basis[new_index]\n        elif isinstance(label_or_index, SymbolicLabelBase):\n            return label_or_index.__class__(expr=label_or_index.expr + n)\n        else:\n            raise TypeError(\n                \"Invalid type for label_or_index: %s\"\n                % label_or_index.__class__.__name__)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef basis_states(self):\n        from qnet.algebra.core.state_algebra import BasisKet, TensorKet\n        # importing locally avoids circular import\n        ls_bases = [ls.basis_labels for ls in self.local_factors]\n        for label_tuple in cartesian_product(*ls_bases):\n            yield TensorKet(\n                *[BasisKet(label, hs=ls) for (ls, label)\n                  in zip(self.local_factors, label_tuple)])", "response": "Yields the states that form the canonical basis of the Hilbert space."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef basis_state(self, index_or_label):\n        from qnet.algebra.core.state_algebra import BasisKet, TensorKet\n        if isinstance(index_or_label, int):  # index\n            ls_bases = [ls.basis_labels for ls in self.local_factors]\n            label_tuple = list(cartesian_product(*ls_bases))[index_or_label]\n            try:\n                return TensorKet(\n                    *[BasisKet(label, hs=ls) for (ls, label)\n                        in zip(self.local_factors, label_tuple)])\n            except ValueError as exc_info:\n                raise IndexError(str(exc_info))\n        else:  # label\n            local_labels = index_or_label.split(\",\")\n            if len(local_labels) != len(self.local_factors):\n                raise KeyError(\n                    \"label %s for Hilbert space %s must be comma-separated \"\n                    \"concatenation of local labels\" % (index_or_label, self))\n            try:\n                return TensorKet(\n                    *[BasisKet(label, hs=ls) for (ls, label)\n                      in zip(self.local_factors, local_labels)])\n            except ValueError as exc_info:\n                raise KeyError(str(exc_info))", "response": "Return the basis state with the given index or label."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a particular factor from a tensor product space.", "response": "def remove(self, other):\n        \"\"\"Remove a particular factor from a tensor product space.\"\"\"\n        if other is FullSpace:\n            return TrivialSpace\n        if other is TrivialSpace:\n            return self\n        if isinstance(other, ProductSpace):\n            oops = set(other.operands)\n        else:\n            oops = {other}\n        return ProductSpace.create(\n                *sorted(set(self.operands).difference(oops)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef intersect(self, other):\n        if other is FullSpace:\n            return self\n        if other is TrivialSpace:\n            return TrivialSpace\n        if isinstance(other, ProductSpace):\n            other_ops = set(other.operands)\n        else:\n            other_ops = {other}\n        return ProductSpace.create(\n                *sorted(set(self.operands).intersection(other_ops)))", "response": "Find the mutual tensor factors of two Hilbert spaces."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef identifier(self):\n        identifier = self._hs._local_identifiers.get(\n            self.__class__.__name__, self._hs._local_identifiers.get(\n                'Create', self._identifier))\n        if not self._rx_identifier.match(identifier):\n            raise ValueError(\n                \"identifier '%s' does not match pattern '%s'\"\n                % (identifier, self._rx_identifier.pattern))\n        return identifier", "response": "The identifier that is used when printing the annihilation\n        operator. This is identical to the identifier of the annihilation\n        operator."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck whether expr is an instance of the class with name classname", "response": "def _isinstance(expr, classname):\n        \"\"\"Check whether `expr` is an instance of the class with name\n        `classname`\n\n        This is like the builtin `isinstance`, but it take the `classname` a\n        string, instead of the class directly. Useful for when we don't want to\n        import the class for which we want to check (also, remember that\n        printer choose rendering method based on the class name, so this is\n        totally ok)\n        \"\"\"\n        for cls in type(expr).__mro__:\n            if cls.__name__ == classname:\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_from_cache(self, expr):\n        # The reason method this is separated out from `doprint` is that\n        # printers that use identation, e.g. IndentedSReprPrinter, need to\n        # override how caching is handled, applying variable indentation even\n        # for cached results\n        try:\n            is_cached = expr in self.cache\n        except TypeError:\n            # expr is unhashable\n            is_cached = False\n        if is_cached:\n            return True, self.cache[expr]\n        else:\n            return False,  None", "response": "Get the result of : meth : doprint expr from the internal cache"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders scalars and numeric types", "response": "def _print_SCALAR_TYPES(self, expr, *args, **kwargs):\n        \"\"\"Render scalars\"\"\"\n        adjoint = kwargs.get('adjoint', False)\n        if adjoint:\n            expr = expr.conjugate()\n        if isinstance(expr, SympyBasic):\n            self._sympy_printer._print_level = self._print_level + 1\n            res = self._sympy_printer.doprint(expr)\n        else:  # numeric type\n            try:\n                if int(expr) == expr:\n                    # In Python, objects that evaluate equal (e.g. 2.0 == 2)\n                    # have the same hash. We want to normalize this, so that we\n                    # get consistent results when printing with a cache\n                    expr = int(expr)\n            except TypeError:\n                pass\n            if adjoint:\n                kwargs = {\n                    key: val for (key, val) in kwargs.items()\n                    if key != 'adjoint'}\n            res = self._print(expr, *args, **kwargs)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the printer s representation for expr.", "response": "def doprint(self, expr, *args, **kwargs):\n        \"\"\"Returns printer's representation for expr (as a string)\n\n        The representation is obtained by the following methods:\n\n        1. from the :attr:`cache`\n        2. If `expr` is a Sympy object, delegate to the\n           :meth:`~sympy.printing.printer.Printer.doprint` method of\n           :attr:`_sympy_printer`\n        3. Let the `expr` print itself if has the :attr:`printmethod`\n        4. Take the best fitting ``_print_*`` method of the printer\n        5. As fallback, delegate to :meth:`emptyPrinter`\n\n        Any extra `args` or `kwargs` are passed to the internal `_print`\n        method.\n        \"\"\"\n        allow_caching = self._allow_caching\n        is_cached = False\n        if len(args) > 0 or len(kwargs) > 0:\n            # we don't want to cache \"custom\" rendering, such as the adjoint of\n            # the actual expression (kwargs['adjoint'] is True). Otherwise, we\n            # might return a cached values for args/kwargs that are different\n            # from the the expression was originally cached.\n            allow_caching = False\n\n        if allow_caching:\n            is_cached, res = self._get_from_cache(expr)\n        if not is_cached:\n            if isinstance(expr, Scalar._val_types):\n                res = self._print_SCALAR_TYPES(expr, *args, **kwargs)\n            elif isinstance(expr, str):\n                return self._render_str(expr)\n            else:\n                # the _print method, inherited from SympyPrinter implements the\n                # internal dispatcher for (3-5)\n                res = self._str(self._print(expr, *args, **kwargs))\n            if allow_caching:\n                self._write_to_cache(expr, res)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsimplify OperatorTrace expressions over tensor - product spaces by turning it into iterated partial traces.", "response": "def decompose_space(H, A):\n    \"\"\"Simplifies OperatorTrace expressions over tensor-product spaces by\n    turning it into iterated partial traces.\n\n    Args:\n        H (ProductSpace): The full space.\n        A (Operator):\n\n    Returns:\n        Operator: Iterative partial trace expression\n    \"\"\"\n    return OperatorTrace.create(\n        OperatorTrace.create(A, over_space=H.operands[-1]),\n        over_space=ProductSpace.create(*H.operands[:-1]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a dictionary with all Operator terms and their coefficients as keys and their coefficients as values.", "response": "def get_coeffs(expr, expand=False, epsilon=0.):\n    \"\"\"Create a dictionary with all Operator terms of the expression\n    (understood as a sum) as keys and their coefficients as values.\n\n    The returned object is a defaultdict that return 0. if a term/key\n    doesn't exist.\n\n    Args:\n        expr: The operator expression to get all coefficients from.\n        expand: Whether to expand the expression distributively.\n        epsilon: If non-zero, drop all Operators with coefficients that have\n            absolute value less than epsilon.\n\n    Returns:\n        dict: A dictionary ``{op1: coeff1, op2: coeff2, ...}``\n    \"\"\"\n    if expand:\n        expr = expr.expand()\n    ret = defaultdict(int)\n    operands = expr.operands if isinstance(expr, OperatorPlus) else [expr]\n    for e in operands:\n        c, t = _coeff_term(e)\n        try:\n            if abs(complex(c)) < epsilon:\n                continue\n        except TypeError:\n            pass\n        ret[t] += c\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfactor out coefficients of all factors.", "response": "def factor_coeff(cls, ops, kwargs):\n    \"\"\"Factor out coefficients of all factors.\"\"\"\n    coeffs, nops = zip(*map(_coeff_term, ops))\n    coeff = 1\n    for c in coeffs:\n        coeff *= c\n    if coeff == 1:\n        return nops, coeffs\n    else:\n        return coeff * cls.create(*nops, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rewrite_with_operator_pm_cc(expr):\n    # TODO: move this to the toolbox\n    from qnet.algebra.toolbox.core import temporary_rules\n\n    def _combine_operator_p_cc(A, B):\n        if B.adjoint() == A:\n            return OperatorPlusMinusCC(A, sign=+1)\n        else:\n            raise CannotSimplify\n\n    def _combine_operator_m_cc(A, B):\n        if B.adjoint() == A:\n            return OperatorPlusMinusCC(A, sign=-1)\n        else:\n            raise CannotSimplify\n\n    def _scal_combine_operator_pm_cc(c, A, d, B):\n        if B.adjoint() == A:\n            if c == d:\n                return c * OperatorPlusMinusCC(A, sign=+1)\n            elif c == -d:\n                return c * OperatorPlusMinusCC(A, sign=-1)\n        raise CannotSimplify\n\n    A = wc(\"A\", head=Operator)\n    B = wc(\"B\", head=Operator)\n    c = wc(\"c\", head=Scalar)\n    d = wc(\"d\", head=Scalar)\n\n    with temporary_rules(OperatorPlus, clear=True):\n        OperatorPlus.add_rule(\n            'PM1', pattern_head(A, B), _combine_operator_p_cc)\n        OperatorPlus.add_rule(\n            'PM2',\n            pattern_head(pattern(ScalarTimesOperator, -1, B), A),\n            _combine_operator_m_cc)\n        OperatorPlus.add_rule(\n            'PM3',\n            pattern_head(\n                pattern(ScalarTimesOperator, c, A),\n                pattern(ScalarTimesOperator, d, B)),\n            _scal_combine_operator_pm_cc)\n        return expr.rebuild()", "response": "Try to rewrite expr using operator - plus - CC operator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef expand_in_basis(self, basis_states=None, hermitian=False):\n        from qnet.algebra.core.state_algebra import KetBra\n        # KetBra is imported locally to avoid circular imports\n        if basis_states is None:\n            basis_states = list(self.space.basis_states)\n        else:\n            basis_states = list(basis_states)\n        diag_terms = []\n        terms = []\n        for i, ket_i in enumerate(basis_states):\n            for j, ket_j in enumerate(basis_states):\n                if i > j and hermitian:\n                    continue\n                op_ij = (ket_i.dag() * self * ket_j).expand()\n                ketbra = KetBra(ket_i, ket_j)\n                term = op_ij * ketbra\n                if term is not ZeroOperator:\n                    if i == j:\n                        diag_terms.append(op_ij * ketbra)\n                    else:\n                        terms.append(op_ij * ketbra)\n        if hermitian:\n            res = OperatorPlus.create(*diag_terms)\n            if len(terms) > 0:\n                res = res + OperatorPlusMinusCC(OperatorPlus.create(*terms))\n            return res\n        else:\n            return (\n                OperatorPlus.create(*diag_terms) +\n                OperatorPlus.create(*terms))", "response": "Write the operator as an expansion into all the other elements of the current state in the basis of the current state."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doit(self, classes=None, recursive=True, **kwargs):\n        return super().doit(classes, recursive, **kwargs)", "response": "Write out commutator\n\n        Write out the commutator according to its definition\n        $[\\Op{A}, \\Op{B}] = \\Op{A}\\Op{B} - \\Op{A}\\Op{B}$.\n\n        See :meth:`.Expression.doit`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _attrprint(d, delimiter=', '):\n    return delimiter.join(('\"%s\"=\"%s\"' % item) for item in sorted(d.items()))", "response": "Print a dictionary of attributes in the DOT format"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _styleof(expr, styles):\n    style = dict()\n    for expr_filter, sty in styles:\n        if expr_filter(expr):\n            style.update(sty)\n    return style", "response": "Merge style dictionaries in order"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a function that returns a label for the expression.", "response": "def expr_labelfunc(leaf_renderer=str, fallback=str):\n    \"\"\"Factory for function ``labelfunc(expr, is_leaf)``\n\n    It has the following behavior:\n\n    * If ``is_leaf`` is True, return ``leaf_renderer(expr)``.\n\n    * Otherwise,\n\n      - if `expr` is an Expression, return a custom string similar to\n        :func:`~qnet.printing.srepr`, but with an ellipsis for ``args``\n      - otherwise, return ``fallback(expr)``\n    \"\"\"\n\n    def _labelfunc(expr, is_leaf):\n        if is_leaf:\n            label = leaf_renderer(expr)\n        elif isinstance(expr, Expression):\n            if len(expr.kwargs) == 0:\n                label = expr.__class__.__name__\n            else:\n                label = \"%s(..., %s)\" % (\n                    expr.__class__.__name__,\n                    \", \".join([\n                        \"%s=%s\" % (key, val)\n                        for (key, val) in expr.kwargs.items()]))\n        else:\n            label = fallback(expr)\n        return label\n\n    return _labelfunc"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the DOT_ representation of an Expression tree as a string.", "response": "def dotprint(\n        expr, styles=None, maxdepth=None, repeat=True,\n        labelfunc=expr_labelfunc(str, str),\n        idfunc=None, get_children=_op_children, **kwargs):\n    \"\"\"Return the `DOT`_ (graph) description of an Expression tree as a string\n\n    Args:\n        expr (object): The expression to render into a graph. Typically an\n            instance of :class:`~qnet.algebra.abstract_algebra.Expression`, but\n            with appropriate `get_children`, `labelfunc`, and `id_func`, this\n            could be any tree-like object\n        styles (list or None): A list of tuples ``(expr_filter, style_dict)``\n            where ``expr_filter`` is a callable and ``style_dict`` is a list\n            of `DOT`_ node properties that should be used when rendering a node\n            for which ``expr_filter(expr)`` return True.\n        maxdepth (int or None): The maximum depth of the resulting tree (any\n            node at `maxdepth` will be drawn as a leaf)\n        repeat (bool): By default, if identical sub-expressions occur in\n            multiple locations (as identified by `idfunc`, they will be\n            repeated in the graph. If ``repeat=False`` is given, each unique\n            (sub-)expression is only drawn once.  The resulting graph may no\n            longer be a proper tree, as recurring expressions will have\n            multiple parents.\n        labelfunc (callable): A function that receives `expr` and a boolean\n            ``is_leaf`` and returns the label of the corresponding node in the\n            graph. Defaults to ``expr_labelfunc(str, str)``.\n        idfunc (callable or None): A function that returns the ID of the node\n            representing a given expression. Expressions for which `idfunc`\n            returns identical results are considered identical if `repeat` is\n            False. The default value None uses a function that is appropriate\n            to a single standalone DOT file. If this is insufficient, something\n            like ``hash`` or ``str`` would make a good `idfunc`.\n        get_children (callable): A function that return a list of\n            sub-expressions (the children of `expr`). Defaults to the operands\n            of an :class:`~qnet.algebra.abstract_algebra.Operation` (thus,\n            anything that is not an Operation is a leaf)\n        kwargs: All further keyword arguments set custom `DOT`_ graph\n            attributes\n\n    Returns:\n        str: a multiline str representing a graph in the `DOT`_ language\n\n    Notes:\n        The node `styles` are additive. For example, consider the following\n        custom styles::\n\n            styles = [\n                (lambda expr: isinstance(expr, SCALAR_TYPES),\n                    {'color': 'blue', 'shape': 'box', 'fontsize': 12}),\n                (lambda expr: isinstance(expr, Expression),\n                    {'color': 'red', 'shape': 'box', 'fontsize': 12}),\n                (lambda expr: isinstance(expr, Operation),\n                    {'color': 'black', 'shape': 'ellipse'})]\n\n        For Operations (which are a subclass of Expression) the color and shape\n        are overwritten, while the fontsize 12 is inherited.\n\n        Keyword arguments are directly translated into graph styles. For\n        example, in order to produce a horizontal instead of vertical graph,\n        use ``dotprint(..., rankdir='LR')``.\n\n    See also:\n        :func:`sympy.printing.dot.dotprint` provides an equivalent function for\n        SymPy expressions.\n    \"\"\"\n    # the routine is called 'dotprint' to match sympy (even though most of the\n    # similar routines for the other printers are called e.g. 'latex', not\n    # 'latexprint'\n    if idfunc is None:\n        if repeat:\n            idfunc = lambda expr: 'node'\n        else:\n            idfunc = hash\n    graphstyle = {'rankdir': 'TD', 'ordering': 'out'}\n    graphstyle.update(kwargs)\n    nodes = []\n    edges = []\n    level = 0\n    pos = 0\n    pos_counter = defaultdict(int)  # level => current pos\n    stack = [(level, pos, expr)]\n    if styles is None:\n        styles = []\n    while len(stack) > 0:\n        level, pos, expr = stack.pop(0)\n        node_id = _node_id(expr, (level, pos), idfunc, repeat)\n        children = get_children(expr)\n        is_leaf = len(children) == 0\n        if maxdepth is not None and level >= maxdepth:\n            is_leaf = True\n        style = _styleof(expr, styles)\n        style['label'] = labelfunc(expr, is_leaf)\n        nodes.append('\"%s\" [%s];' % (node_id, _attrprint(style)))\n        if not is_leaf:\n            try:\n                for expr_sub in children:\n                    i_sub = pos_counter[level+1]\n                    id_sub = _node_id(\n                        expr_sub, (level+1, i_sub), idfunc, repeat)\n                    edges.append('\"%s\" -> \"%s\"' % (node_id, id_sub))\n                    stack.append((level+1, i_sub, expr_sub))\n                    pos_counter[level+1] += 1\n            except AttributeError:\n                pass\n    return template % {\n        'graphstyle': _attrprint(graphstyle, delimiter='\\n'),\n        'nodes': '\\n'.join(nodes),\n        'edges': '\\n'.join(edges)}"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current git revision as a string", "response": "def _git_version():\n    \"\"\"If installed with 'pip installe -e .' from inside a git repo, the\n    current git revision as a string\"\"\"\n\n    import subprocess\n    import os\n\n    def _minimal_ext_cmd(cmd):\n        # construct minimal environment\n        env = {}\n        for k in ['SYSTEMROOT', 'PATH']:\n            v = os.environ.get(k)\n            if v is not None:\n                env[k] = v\n        # LANGUAGE is used on win32\n        env['LANGUAGE'] = 'C'\n        env['LANG'] = 'C'\n        env['LC_ALL'] = 'C'\n        FNULL = open(os.devnull, 'w')\n        cwd = os.path.dirname(os.path.realpath(__file__))\n        proc = subprocess.Popen(\n            cmd, stdout=subprocess.PIPE, stderr=FNULL, env=env, cwd=cwd)\n        out = proc.communicate()[0]\n        return out\n\n    try:\n        out = _minimal_ext_cmd(['git', 'rev-parse', 'HEAD'])\n        return out.strip().decode('ascii')\n    except OSError:\n        return \"unknown\""}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap for Feedback. create", "response": "def FB(circuit, *, out_port=None, in_port=None):\n    \"\"\"Wrapper for :class:`.Feedback`, defaulting to last channel\n\n    Args:\n        circuit (Circuit): The circuit that undergoes self-feedback\n        out_port (int): The output port index, default = None --> last port\n        in_port (int): The input port index, default = None --> last port\n\n    Returns:\n        Circuit: The circuit with applied feedback operation.\n    \"\"\"\n    if out_port is None:\n        out_port = circuit.cdim - 1\n    if in_port is None:\n        in_port = circuit.cdim - 1\n    return Feedback.create(circuit, out_port=out_port, in_port=in_port)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a : class : CPermutation that extracts the k - th output to the last output of all other channels.", "response": "def extract_channel(k, cdim):\n    \"\"\"Create a :class:`CPermutation` that extracts channel `k`\n\n    Return a permutation circuit that maps the k-th (zero-based)\n    input to the last output, while preserving the relative order of all other\n    channels.\n\n    Args:\n        k (int): Extracted channel index\n        cdim (int): The circuit dimension (number of channels)\n\n    Returns:\n        Circuit: Permutation circuit\n    \"\"\"\n    n = cdim\n    perm = tuple(list(range(k)) + [n - 1] + list(range(k, n - 1)))\n    return CPermutation.create(perm)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a CPermutation based on a dictionary of channel mappings and the circuit dimension cdim.", "response": "def map_channels(mapping, cdim):\n    \"\"\"Create a :class:`CPermuation` based on a dict of channel mappings\n\n    For a given mapping in form of a dictionary, generate the channel\n    permutating circuit that achieves the specified mapping while leaving the\n    relative order of all non-specified channels intact.\n\n    Args:\n        mapping (dict): Input-output mapping of indices (zero-based)\n            ``{in1:out1, in2:out2,...}``\n        cdim (int): The circuit dimension (number of channels)\n\n    Returns:\n        CPermutation: Circuit mapping the channels as specified\n    \"\"\"\n    n = cdim\n    free_values = list(range(n))\n\n    for v in mapping.values():\n        if v >= n:\n            raise ValueError('the mapping cannot take on values larger than '\n                             'cdim - 1')\n        free_values.remove(v)\n    for k in mapping:\n        if k >= n:\n            raise ValueError('the mapping cannot map keys larger than '\n                             'cdim - 1')\n    permutation = []\n    for k in range(n):\n        if k in mapping:\n            permutation.append(mapping[k])\n        else:\n            permutation.append(free_values.pop(0))\n\n    return CPermutation.create(tuple(permutation))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pad_with_identity(circuit, k, n):\n    circuit_n = circuit.cdim\n    combined_circuit = circuit + circuit_identity(n)\n    permutation = (list(range(k)) + list(range(circuit_n, circuit_n + n)) +\n                   list(range(k, circuit_n)))\n    return (CPermutation.create(invert_permutation(permutation)) <<\n            combined_circuit << CPermutation.create(permutation))", "response": "Pad a circuit by adding a n - channel identity circuit at index k."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the ABCD - linearization of an object - level SLH model.", "response": "def getABCD(slh, a0=None, doubled_up=True):\n    \"\"\"Calculate the ABCD-linearization of an SLH model\n\n    Return the A, B, C, D and (a, c) matrices that linearize an SLH model\n    about a coherent displacement amplitude a0.\n\n    The equations of motion and the input-output relation are then:\n\n    dX = (A X + a) dt + B dA_in\n    dA_out = (C X + c) dt + D dA_in\n\n    where, if doubled_up == False\n\n        dX = [a_1, ..., a_m]\n        dA_in = [dA_1, ..., dA_n]\n\n    or if doubled_up == True\n\n        dX = [a_1, ..., a_m, a_1^*, ... a_m^*]\n        dA_in = [dA_1, ..., dA_n, dA_1^*, ..., dA_n^*]\n\n    Args:\n        slh: SLH object\n        a0: dictionary of coherent amplitudes ``{a1: a1_0, a2: a2_0, ...}``\n            with annihilation mode operators as keys and (numeric or symbolic)\n            amplitude as values.\n        doubled_up: boolean, necessary for phase-sensitive / active systems\n\n\n    Returns:\n\n        A tuple (A, B, C, D, a, c])\n\n        with\n\n        * `A`: coupling of modes to each other\n        * `B`: coupling of external input fields to modes\n        * `C`: coupling of internal modes to output\n        * `D`: coupling of external input fields to output fields\n\n        * `a`: constant coherent input vector for mode e.o.m.\n        * `c`: constant coherent input vector of scattered amplitudes\n            contributing to the output\n    \"\"\"\n    from qnet.algebra.library.fock_operators import Create, Destroy\n    if a0 is None:\n        a0 = {}\n\n    # the different degrees of freedom\n    full_space = ProductSpace.create(slh.S.space, slh.L.space, slh.H.space)\n    modes = sorted(full_space.local_factors)\n\n    # various dimensions\n    ncav = len(modes)\n    cdim = slh.cdim\n\n    # initialize the matrices\n    if doubled_up:\n        A = np.zeros((2*ncav, 2*ncav), dtype=object)\n        B = np.zeros((2*ncav, 2*cdim), dtype=object)\n        C = np.zeros((2*cdim, 2*ncav), dtype=object)\n        a = np.zeros(2*ncav, dtype=object)\n        c = np.zeros(2*cdim, dtype=object)\n\n    else:\n        A = np.zeros((ncav, ncav), dtype=object)\n        B = np.zeros((ncav, cdim), dtype=object)\n        C = np.zeros((cdim, ncav), dtype=object)\n        a = np.zeros(ncav, dtype=object)\n        c = np.zeros(cdim, dtype=object)\n\n    def _as_complex(o):\n        if isinstance(o, Operator):\n            o = o.expand()\n            if o is IdentityOperator:\n                o = 1\n            elif o is ZeroOperator:\n                o = 0\n            elif isinstance(o, ScalarTimesOperator):\n                assert o.term is IdentityOperator\n                o = o.coeff\n            else:\n                raise ValueError(\"{} is not trivial operator\".format(o))\n        try:\n            return complex(o)\n        except TypeError:\n            return o\n\n    D = np.array([[_as_complex(o) for o in Sjj] for Sjj in slh.S.matrix])\n\n    if doubled_up:\n        # need to explicitly compute D^* because numpy object-dtype array's\n        # conjugate() method doesn't work\n        Dc = np.array([[D[ii, jj].conjugate() for jj in range(cdim)]\n                       for ii in range(cdim)])\n        D = np.vstack((np.hstack((D, np.zeros((cdim, cdim)))),\n                       np.hstack((np.zeros((cdim, cdim)), Dc))))\n\n    # create substitutions to displace the model\n    mode_substitutions = {aj: aj + aj_0 * IdentityOperator\n                          for aj, aj_0 in a0.items()}\n    mode_substitutions.update({\n        aj.dag(): aj.dag() + aj_0.conjugate() * IdentityOperator\n        for aj, aj_0 in a0.items()\n    })\n    if len(mode_substitutions):\n        slh_displaced = (slh.substitute(mode_substitutions).expand()\n                         .simplify_scalar())\n    else:\n        slh_displaced = slh\n\n    # make symbols for the external field modes\n    noises = [OperatorSymbol('b_{}'.format(n), hs=\"ext_{}\".format(n))\n              for n in range(cdim)]\n\n    # compute the QSDEs for the internal operators\n    eoms = [slh_displaced.symbolic_heisenberg_eom(Destroy(hs=s), noises=noises)\n            for s in modes]\n\n    # use the coefficients to generate A, B matrices\n    for jj in range(len(modes)):\n        coeffsjj = get_coeffs(eoms[jj])\n        a[jj] = coeffsjj[IdentityOperator]\n        if doubled_up:\n            a[jj+ncav] = coeffsjj[IdentityOperator].conjugate()\n\n        for kk, skk in enumerate(modes):\n            A[jj, kk] = coeffsjj[Destroy(hs=skk)]\n            if doubled_up:\n                A[jj+ncav, kk+ncav] = coeffsjj[Destroy(hs=skk)].conjugate()\n                A[jj, kk + ncav] = coeffsjj[Create(hs=skk)]\n                A[jj+ncav, kk] = coeffsjj[Create(hs=skk)].conjugate()\n\n        for kk, dAkk in enumerate(noises):\n            B[jj, kk] = coeffsjj[dAkk]\n            if doubled_up:\n                B[jj+ncav, kk+cdim] = coeffsjj[dAkk].conjugate()\n                B[jj, kk+cdim] = coeffsjj[dAkk.dag()]\n                B[jj + ncav, kk] = coeffsjj[dAkk.dag()].conjugate()\n\n    # use the coefficients in the L vector to generate the C, D\n    # matrices\n    for jj, Ljj in enumerate(slh_displaced.Ls):\n        coeffsjj = get_coeffs(Ljj)\n        c[jj] = coeffsjj[IdentityOperator]\n        if doubled_up:\n            c[jj+cdim] = coeffsjj[IdentityOperator].conjugate()\n\n        for kk, skk in enumerate(modes):\n            C[jj, kk] = coeffsjj[Destroy(hs=skk)]\n            if doubled_up:\n                C[jj+cdim, kk+ncav] = coeffsjj[Destroy(hs=skk)].conjugate()\n                C[jj, kk+ncav] = coeffsjj[Create(hs=skk)]\n                C[jj+cdim, kk] = coeffsjj[Create(hs=skk)].conjugate()\n\n    return map(SympyMatrix, (A, B, C, D, a, c))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move_drive_to_H(slh, which=None, expand_simplify=True):\n    r'''Move coherent drives from the Lindblad operators to the Hamiltonian.\n\n    For the given SLH model, move inhomogeneities in the Lindblad operators (resulting\n    from the presence of a coherent drive, see :class:`CoherentDriveCC`) to the\n    Hamiltonian.\n\n    This exploits the invariance of the Lindblad master equation under the\n    transformation  (cf. Breuer and Pettrucione, Ch 3.2.1)\n\n    .. math::\n        :nowrap:\n\n        \\begin{align}\n            \\Op{L}_i &\\longrightarrow \\Op{L}_i' = \\Op{L}_i - \\alpha_i  \\\\\n            \\Op{H}   &\\longrightarrow\n            \\Op{H}' = \\Op{H} + \\frac{1}{2i} \\sum_j\n                    (\\alpha_j \\Op{L}_j^{\\dagger} - \\alpha_j^* \\Op{L}_j)\n        \\end{align}\n\n    In the context of SLH, this transformation is achieved by feeding `slh` into\n\n    .. math::\n        \\SLH(\\identity, -\\mat{\\alpha}, 0)\n\n    where $\\mat{\\alpha}$ has the elements $\\alpha_i$.\n\n    Parameters\n    ----------\n    slh : SLH\n        SLH model to transform. If `slh` does not contain any inhomogeneities, it is\n        invariant under the transformation.\n\n    which : sequence or None\n        Sequence of circuit dimensions to apply the transform to. If None, all\n        dimensions are transformed.\n\n    expand_simplify : bool\n        if True, expand and simplify the new SLH object before returning. This has no\n        effect if `slh` does not contain any inhomogeneities.\n\n    Returns\n    -------\n    new_slh : SLH\n        Transformed SLH model.\n\n    '''\n    if which is None:\n        which = []\n    scalarcs = []\n    for jj, L in enumerate(slh.Ls):\n        if not which or jj in which:\n            scalarcs.append(-get_coeffs(L.expand())[IdentityOperator])\n        else:\n            scalarcs.append(0)\n\n    if np.all(np.array(scalarcs) == 0):\n        return slh\n    new_slh = SLH(identity_matrix(slh.cdim), scalarcs, 0) << slh\n    if expand_simplify:\n        return new_slh.expand().simplify_scalar()\n    return new_slh", "response": "Move coherent drives from the Lindblad model to the Hamiltonian."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prepare_adiabatic_limit(slh, k=None):\n    if k is None:\n        k = symbols('k', positive=True)\n    Ld = slh.L.dag()\n    LdL = (Ld * slh.L)[0, 0]\n    K = (-LdL / 2 + I * slh.H).expand().simplify_scalar()\n    N = slh.S.dag()\n    B, A, Y = K.series_expand(k, 0, 2)\n    G, F = Ld.series_expand(k, 0, 1)\n\n    return Y, A, B, F, G, N", "response": "Prepare the adiabatic elimination on an object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eval_adiabatic_limit(YABFGN, Ytilde, P0):\n    Y, A, B, F, G, N = YABFGN\n\n    Klim = (P0 * (B - A * Ytilde * A) * P0).expand().simplify_scalar()\n    Hlim = ((Klim - Klim.dag())/2/I).expand().simplify_scalar()\n\n    Ldlim = (P0 * (G - A * Ytilde * F) * P0).expand().simplify_scalar()\n\n    dN = identity_matrix(N.shape[0]) + F.H * Ytilde * F\n    Nlim = (P0 * N * dN * P0).expand().simplify_scalar()\n\n    return SLH(Nlim.dag(), Ldlim.dag(), Hlim.dag())", "response": "Compute the limiting SLH model for the adiabatic approximation of the given set of classes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef try_adiabatic_elimination(slh, k=None, fock_trunc=6, sub_P0=True):\n    ops = prepare_adiabatic_limit(slh, k)\n    Y = ops[0]\n    if isinstance(Y.space, LocalSpace):\n        try:\n            b = Y.space.basis_labels\n            if len(b) > fock_trunc:\n                b = b[:fock_trunc]\n        except BasisNotSetError:\n            b = range(fock_trunc)\n        projectors = set(LocalProjector(ll, hs=Y.space) for ll in b)\n        Id_trunc = sum(projectors, ZeroOperator)\n        Yprojection = (\n            ((Id_trunc * Y).expand() * Id_trunc)\n            .expand().simplify_scalar())\n        termcoeffs = get_coeffs(Yprojection)\n        terms = set(termcoeffs.keys())\n\n        for term in terms - projectors:\n            cannot_eliminate = (\n                not isinstance(term, LocalSigma) or\n                not term.operands[1] == term.operands[2])\n            if cannot_eliminate:\n                raise CannotEliminateAutomatically(\n                    \"Proj. Y operator has off-diagonal term: ~{}\".format(term))\n        P0 = sum(projectors - terms, ZeroOperator)\n        if P0 == ZeroOperator:\n            raise CannotEliminateAutomatically(\"Empty null-space of Y!\")\n\n        Yinv = sum(t/termcoeffs[t] for t in terms & projectors)\n        assert (\n            (Yprojection*Yinv).expand().simplify_scalar() ==\n            (Id_trunc - P0).expand())\n        slhlim = eval_adiabatic_limit(ops, Yinv, P0)\n\n        if sub_P0:\n            # TODO for non-unit rank P0, this will not work\n            slhlim = slhlim.substitute(\n                {P0: IdentityOperator}).expand().simplify_scalar()\n        return slhlim\n\n    else:\n        raise CannotEliminateAutomatically(\n            \"Currently only single degree of freedom Y-operators supported\")", "response": "Attempt to automatically do adiabatic elimination on an object SLH object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef index_in_block(self, channel_index: int) -> int:\n        if channel_index < 0 or channel_index >= self.cdim:\n            raise ValueError()\n\n        struct = self.block_structure\n\n        if len(struct) == 1:\n            return channel_index, 0\n        i = 1\n        while sum(struct[:i]) <= channel_index and i < self.cdim:\n            i += 1\n        block_index = i - 1\n        index_in_block = channel_index - sum(struct[:block_index])\n\n        return index_in_block, block_index", "response": "Return the index a channel has within the subblock it belongs to."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a circuit with self - feedback from the output port in_port.", "response": "def feedback(self, *, out_port=None, in_port=None):\n        \"\"\"Return a circuit with self-feedback from the output port\n        (zero-based) ``out_port`` to the input port ``in_port``.\n\n        Args:\n            out_port (int or None): The output port from which the feedback\n                connection leaves (zero-based, default ``None`` corresponds\n                to the *last* port).\n            in_port (int or None): The input port into which the feedback\n                connection goes (zero-based, default ``None`` corresponds to\n                the *last* port).\n        \"\"\"\n        if out_port is None:\n            out_port = self.cdim - 1\n        if in_port is None:\n            in_port = self.cdim - 1\n        return self._feedback(out_port=out_port, in_port=in_port)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nshows the circuit expression in an IPython notebook.", "response": "def show(self):\n        \"\"\"Show the circuit expression in an IPython notebook.\"\"\"\n\n        # noinspection PyPackageRequirements\n        from IPython.display import Image, display\n\n        fname = self.render()\n        display(Image(filename=fname))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrender the circuit expression and store the result in a file.", "response": "def render(self, fname=''):\n        \"\"\"Render the circuit expression and store the result in a file\n\n        Args:\n            fname (str): Path to an image file to store the result in.\n\n        Returns:\n            str: The path to the image file\n        \"\"\"\n        import qnet.visualization.circuit_pyx as circuit_visualization\n        from tempfile import gettempdir\n        from time import time, sleep\n\n        if not fname:\n\n            tmp_dir = gettempdir()\n            fname = os.path.join(tmp_dir, \"tmp_{}.png\".format(hash(time)))\n\n        if circuit_visualization.draw_circuit(self, fname):\n            done = False\n            for k in range(20):\n                if os.path.exists(fname):\n\n                    done = True\n                    break\n                else:\n                    sleep(.5)\n            if done:\n                return fname\n\n        raise CannotVisualize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets of all free symbols occcuring in S L or H.", "response": "def free_symbols(self):\n        \"\"\"Set of all symbols occcuring in S, L, or H\"\"\"\n        return set.union(\n            self.S.free_symbols, self.L.free_symbols, self.H.free_symbols)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef concatenate_slh(self, other):\n        selfS = self.S\n        otherS = other.S\n        new_S = block_matrix(\n                selfS, zerosm((selfS.shape[0], otherS.shape[1]), dtype=int),\n                zerosm((otherS.shape[0], selfS.shape[1]), dtype=int), otherS)\n        new_L = vstackm((self.L, other.L))\n        new_H = self.H + other.H\n\n        return SLH(new_S, new_L, new_H)", "response": "Concatenation with another : class : SLH object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef expand(self):\n        return SLH(self.S.expand(), self.L.expand(), self.H.expand())", "response": "Expand out all operator expressions within S L and H return a new SLH object with these expanded expressions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef simplify_scalar(self, func=sympy.simplify):\n        return SLH(\n            self.S.simplify_scalar(func=func),\n            self.L.simplify_scalar(func=func),\n            self.H.simplify_scalar(func=func))", "response": "Simplify all scalar expressions within S L and H and return a new SLH object with the simplified expressions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomputes the symbolic Liouvillian acting on a state rho.", "response": "def symbolic_master_equation(self, rho=None):\n        \"\"\"Compute the symbolic Liouvillian acting on a state rho\n\n        If no rho is given, an OperatorSymbol is created in its place.\n        This correspnds to the RHS of the master equation\n        in which an average is taken over the external noise degrees of\n        freedom.\n\n        Args:\n            rho (Operator): A symbolic density matrix operator\n\n        Returns:\n            Operator: The RHS of the master equation.\n\n        \"\"\"\n        L, H = self.L, self.H\n        if rho is None:\n            rho = OperatorSymbol('rho', hs=self.space)\n        return (-I * (H * rho - rho * H) +\n                sum(Lk * rho * adjoint(Lk) -\n                    (adjoint(Lk) * Lk * rho + rho * adjoint(Lk) * Lk) / 2\n                    for Lk in L.matrix.ravel()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef symbolic_heisenberg_eom(\n            self, X=None, noises=None, expand_simplify=True):\n        \"\"\"Compute the symbolic Heisenberg equations of motion of a system\n        operator X.  If no X is given, an OperatorSymbol is created in its\n        place.  If no noises are given, this correspnds to the\n        ensemble-averaged Heisenberg equation of motion.\n\n        Args:\n            X (Operator): A system operator\n            noises (Operator): A vector of noise inputs\n\n        Returns:\n            Operator: The RHS of the Heisenberg equations of motion of X.\n        \"\"\"\n        L, H = self.L, self.H\n\n        if X is None:\n            X = OperatorSymbol('X', hs=(L.space | H.space))\n\n        summands = [I * (H * X - X * H), ]\n        for Lk in L.matrix.ravel():\n            summands.append(adjoint(Lk) * X * Lk)\n            summands.append(-(adjoint(Lk) * Lk * X + X * adjoint(Lk) * Lk) / 2)\n\n        if noises is not None:\n            if not isinstance(noises, Matrix):\n                noises = Matrix(noises)\n            LambdaT = (noises.adjoint().transpose() * noises.transpose()).transpose()\n            assert noises.shape == L.shape\n            S = self.S\n            summands.append((adjoint(noises) * S.adjoint() * (X * L - L * X))\n                            .expand()[0, 0])\n            summand = (((L.adjoint() * X - X * L.adjoint()) * S * noises)\n                       .expand()[0, 0])\n            summands.append(summand)\n            if len(S.space & X.space):\n                comm = (S.adjoint() * X * S - X)\n                summands.append((comm * LambdaT).expand().trace())\n\n        ret = OperatorPlus.create(*summands)\n        if expand_simplify:\n            ret = ret.expand().simplify_scalar()\n        return ret", "response": "Compute the symbolic Heisenberg equations of motion of a system."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef series_with_permutation(self, other):\n        combined_permutation = tuple([self.permutation[p]\n                                      for p in other.permutation])\n        return CPermutation.create(combined_permutation)", "response": "Compute the series product with another permutation circuit."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfactorizing a permutation circuit according the block - permutation of the upstream circuit.", "response": "def _factorize_for_rhs(self, rhs):\n        \"\"\"Factorize a channel permutation circuit according the block\n        structure of the upstream circuit.  This allows to move as much of the\n        permutation as possible *around* a reducible circuit upstream.  It\n        basically decomposes\n\n            ``permutation << rhs --> permutation' << rhs' << residual'``\n\n        where rhs' is just a block permutated version of rhs and residual'\n        is the maximal part of the permutation that one may move around rhs.\n\n        Args:\n            rhs (Circuit): An upstream circuit object\n\n        Returns:\n            tuple: new_lhs_circuit, permuted_rhs_circuit, new_rhs_circuit\n\n        Raises:\n            .BadPermutationError\n        \"\"\"\n        block_structure = rhs.block_structure\n\n        block_perm, perms_within_blocks \\\n            = block_perm_and_perms_within_blocks(self.permutation,\n                                                 block_structure)\n        fblockp = full_block_perm(block_perm, block_structure)\n\n        if not sorted(fblockp) == list(range(self.cdim)):\n            raise BadPermutationError()\n\n        new_rhs_circuit = CPermutation.create(fblockp)\n        within_blocks = [CPermutation.create(within_block)\n                         for within_block in perms_within_blocks]\n        within_perm_circuit = Concatenation.create(*within_blocks)\n        rhs_blocks = rhs.get_blocks(block_structure)\n\n        summands = [SeriesProduct.create(within_blocks[p], rhs_blocks[p])\n                    for p in invert_permutation(block_perm)]\n        permuted_rhs_circuit = Concatenation.create(*summands)\n\n        new_lhs_circuit = (self << within_perm_circuit.series_inverse() <<\n                           new_rhs_circuit.series_inverse())\n\n        return new_lhs_circuit, permuted_rhs_circuit, new_rhs_circuit"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _factor_rhs(self, in_port):\n        n = self.cdim\n        if not (0 <= in_port < n):\n            raise Exception\n        in_im = self.permutation[in_port]\n        # (I) is equivalent to\n        #       m_{in_im -> (n-1)} <<  self << m_{(n-1) -> in_port}\n        #           == (red_self + cid(1))     (I')\n        red_self_plus_cid1 = (map_channels({in_im: (n - 1)}, n) <<\n                              self <<\n                              map_channels({(n - 1): in_port}, n))\n        if isinstance(red_self_plus_cid1, CPermutation):\n\n            #make sure we can factor\n            assert red_self_plus_cid1.permutation[(n - 1)] == (n - 1)\n\n            #form reduced permutation object\n            red_self = CPermutation.create(red_self_plus_cid1.permutation[:-1])\n\n            return in_im, red_self\n        else:\n            # 'red_self_plus_cid1' must be the identity for n channels.\n            # Actually, this case can only occur\n            # when self == m_{in_port ->  in_im}\n\n            return in_im, circuit_identity(n - 1)", "response": "This function factorizes the RHS of a specific entry in the internal state."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _factor_lhs(self, out_port):\n        n = self.cdim\n        assert (0 <= out_port < n)\n        out_inv = self.permutation.index(out_port)\n\n        # (I) is equivalent to\n        #       m_{out_port -> (n-1)} <<  self << m_{(n-1)\n        #           -> out_inv} == (red_self + cid(1))     (I')\n\n        red_self_plus_cid1 = (map_channels({out_port: (n - 1)}, n) <<\n                              self <<\n                              map_channels({(n - 1): out_inv}, n))\n\n        if isinstance(red_self_plus_cid1, CPermutation):\n\n            #make sure we can factor\n            assert red_self_plus_cid1.permutation[(n - 1)] == (n - 1)\n\n            #form reduced permutation object\n            red_self = CPermutation.create(red_self_plus_cid1.permutation[:-1])\n\n            return out_inv, red_self\n        else:\n            # 'red_self_plus_cid1' must be the identity for n channels.\n            # Actually, this case can only occur\n            # when self == m_{in_port ->  in_im}\n\n            return out_inv, circuit_identity(n - 1)", "response": "This function factorizes the LHS of a channel."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the sum of the dimensions of the operands.", "response": "def cdim(self):\n        \"\"\"Circuit dimension (sum of dimensions of the operands)\"\"\"\n        if self._cdim is None:\n            self._cdim = sum((circuit.cdim for circuit in self.operands))\n        return self._cdim"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef immutable_attribs(cls):\n    cls = attr.s(cls, frozen=True)\n    defaults = OrderedDict([(a.name, a.default) for a in cls.__attrs_attrs__])\n\n    def repr_(self):\n        from qnet.printing import srepr\n        real_cls = self.__class__\n        class_name = real_cls.__name__\n        args = []\n        for name in defaults.keys():\n            val = getattr(self, name)\n            positional = defaults[name] == attr.NOTHING\n            if val != defaults[name]:\n                args.append(\n                    srepr(val) if positional else \"%s=%s\" % (name, srepr(val)))\n        return \"{0}({1})\".format(class_name, \", \".join(args))\n\n    cls.__repr__ = repr_\n    return cls", "response": "Class decorator that returns immutable attributes of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self,\n             data,\n             chart_type,\n             options=None,\n             filename='chart',\n             w=800,\n             h=420,\n             overwrite=True):\n        \"\"\"Save the rendered html to a file in the same directory as the notebook.\"\"\"\n        html = self.render(\n            data=data,\n            chart_type=chart_type,\n            options=options,\n            div_id=filename,\n            head=self.head,\n            w=w,\n            h=h)\n\n        if overwrite:\n            with open(filename.replace(\" \", \"_\") + '.html', 'w') as f:\n                f.write(html)\n        else:\n            if not os.path.exists(filename.replace(\" \", \"_\") + '.html'):\n                with open(filename.replace(\" \", \"_\") + '.html', 'w') as f:\n                    f.write(html)\n            else:\n                raise IOError('File Already Exists!')", "response": "Save the rendered html to a file in the same directory as the notebook."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nassembles a string from the primary name and the given subscript and superscript list and return a new list of unicode sub - and - super subscripts.", "response": "def render_unicode_sub_super(\n        name, subs=None, supers=None, sub_first=True, translate_symbols=True,\n        unicode_sub_super=True, sep=',', subscript_max_len=1):\n    \"\"\"Assemble a string from the primary name and the given sub- and\n    superscripts::\n\n    >>> render_unicode_sub_super(name='alpha', subs=['mu', 'nu'], supers=[2])\n    '\u03b1_\u03bc,\u03bd^2'\n\n    >>> render_unicode_sub_super(\n    ...     name='alpha', subs=['1', '2'], supers=['(1)'], sep='')\n    '\u03b1\u2081\u2082\u207d\u00b9\u207e'\n\n    >>> render_unicode_sub_super(\n    ...     name='alpha', subs=['1', '2'], supers=['(1)'], sep='',\n    ...     unicode_sub_super=False)\n    '\u03b1_12^(1)'\n\n    Args:\n        name (str):  the string without the subscript/superscript\n        subs (list or None): list of subscripts\n        supers (list or None): list of superscripts\n        translate_symbols (bool): If True, try to translate (Greek) symbols in\n            `name, `subs`, and `supers` to unicode\n        unicode_sub_super (bool): It True, try to use unicode\n            subscript/superscript symbols\n        sep (str): Separator to use if there are multiple\n            subscripts/superscripts\n        subscript_max_len (int): Maximum character length of subscript that is\n            eligible to be rendered in unicode. This defaults to 1, because\n            spelling out enire words as a unicode subscript looks terrible in\n            monospace (letter spacing too large)\n    \"\"\"\n    if subs is None:\n        subs = []\n    if supers is None:\n        supers = []\n    if translate_symbols:\n        supers = [_translate_symbols(sup) for sup in supers]\n        subs = [_translate_symbols(sub) for sub in subs]\n        name = _translate_symbols(name)\n    res = name\n    try:\n        if unicode_sub_super:\n            supers_modified = [\n                    _unicode_sub_super(s, _SUPERSCRIPT_MAPPING)\n                    for s in supers]\n            subs_modified = [\n                    _unicode_sub_super(\n                        s, _SUBSCRIPT_MAPPING, max_len=subscript_max_len)\n                    for s in subs]\n            if sub_first:\n                if len(subs_modified) > 0:\n                    res += sep.join(subs_modified)\n                if len(supers_modified) > 0:\n                    res += sep.join(supers_modified)\n            else:\n                if len(supers_modified) > 0:\n                    res += sep.join(supers_modified)\n                if len(subs_modified) > 0:\n                    res += sep.join(subs_modified)\n    except KeyError:\n        unicode_sub_super = False\n    if not unicode_sub_super:\n        sub = sep.join(subs)\n        sup = sep.join(supers)\n        if sub_first:\n            if len(sub) > 0:\n                res += \"_%s\" % sub\n            if len(sup) > 0:\n                res += \"^%s\" % sup\n        else:\n            if len(sup) > 0:\n                res += \"^%s\" % sup\n            if len(sub) > 0:\n                res += \"_%s\" % sub\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _unicode_sub_super(string, mapping, max_len=None):\n    string = str(string)\n    if string.startswith('(') and string.endswith(')'):\n        len_string = len(string) - 2\n    else:\n        len_string = len(string)\n    if max_len is not None:\n        if len_string > max_len:\n            raise KeyError(\"max_len exceeded\")\n    unicode_letters = []\n    for letter in string:\n        unicode_letters.append(mapping[letter])\n    return ''.join(unicode_letters)", "response": "Try to render a subscript or superscript string in unicode fall back on\n    ascii"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _translate_symbols(string):\n    res = []\n    string = str(string)\n    for s in re.split(r'(\\W+)', string, flags=re.UNICODE):\n        tex_str = _GREEK_DICTIONARY.get(s)\n        if tex_str:\n            res.append(tex_str)\n        elif s.lower() in _GREEK_DICTIONARY:\n            res.append(_GREEK_DICTIONARY[s])\n        else:\n            res.append(s)\n    return \"\".join(res)", "response": "Given a description of a Greek letter or other special character return the appropriate unicode letter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the data in HTML template.", "response": "def render(self, data, div_id=\"chart\", head=\"\"):\n        \"\"\"Render the data in HTML template.\"\"\"\n        if not self.is_valid_name(div_id):\n            raise ValueError(\n                \"Name {} is invalid. Only letters, numbers, '_', and '-' are permitted \".format(\n                    div_id))\n\n        return Template(head + self.template).render(\n            div_id=div_id.replace(\" \", \"_\"),\n            data=json.dumps(\n                data, indent=4).replace(\"'\", \"\\\\'\").replace('\"', \"'\"))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave the rendered html to a file and return an IFrame to display the plot in the notebook.", "response": "def plot_and_save(self,\n                      data,\n                      w=800,\n                      h=420,\n                      filename='chart',\n                      overwrite=True):\n        \"\"\"Save the rendered html to a file and returns an IFrame to display the plot in the notebook.\"\"\"\n        self.save(data, filename, overwrite)\n        return IFrame(filename + '.html', w, h)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plot(self, data, w=800, h=420):\n        return HTML(\n            self.iframe.format(\n                source=self.render(\n                    data=data, div_id=\"chart\", head=self.head),\n                w=w,\n                h=h))", "response": "Output an iframe containing the plot in the notebook without saving."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_from_cache(self, expr):\n        is_cached, res = super()._get_from_cache(expr)\n        if is_cached:\n            indent_str = \"    \" * self._print_level\n            return True, indent(res, indent_str)\n        else:\n            return False,  None", "response": "Obtain cached result prepend with the keyname if necessary and return the result if necessary and return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstores the cached result without indentation and without the keyname", "response": "def _write_to_cache(self, expr, res):\n        \"\"\"Store the cached result without indentation, and without the\n        keyname\"\"\"\n        res = dedent(res)\n        super()._write_to_cache(expr, res)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives a description of a Greek letter or other special character return the appropriate latex.", "response": "def _translate_symbols(string):\n    \"\"\"Given a description of a Greek letter or other special character,\n    return the appropriate latex.\"\"\"\n    res = []\n    for s in re.split(r'([,.:\\s=]+)', string):\n        tex_str = _TEX_GREEK_DICTIONARY.get(s)\n        if tex_str:\n            res.append(tex_str)\n        elif s.lower() in greek_letters_set:\n            res.append(\"\\\\\" + s.lower())\n        elif s in other_symbols:\n            res.append(\"\\\\\" + s)\n        else:\n            if re.match(r'^[a-zA-Z]{4,}$', s):\n                res.append(r'\\text{' + s + '}')\n            else:\n                res.append(s)\n    return \"\".join(res)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef render_latex_sub_super(\n        name, subs=None, supers=None, translate_symbols=True, sep=','):\n    r'''Assemble a string from the primary name and the given sub- and\n    superscripts::\n\n        >>> render_latex_sub_super(name='alpha', subs=['mu', 'nu'], supers=[2])\n        '\\\\alpha_{\\\\mu,\\\\nu}^{2}'\n\n        >>> render_latex_sub_super(\n        ...     name='alpha', subs=['1', '2'], supers=['(1)'], sep='')\n        '\\\\alpha_{12}^{(1)}'\n\n    Args:\n        name (str):  the string without the subscript/superscript\n        subs (list or None): list of subscripts\n        supers (list or None): list of superscripts\n        translate_symbols (bool): If True, try to translate (Greek) symbols in\n            `name, `subs`, and `supers` to unicode\n        sep (str): Separator to use if there are multiple\n            subscripts/superscripts\n    '''\n    if subs is None:\n        subs = []\n    if supers is None:\n        supers = []\n    if translate_symbols:\n        supers = [_translate_symbols(str(sup)) for sup in supers]\n        subs = [_translate_symbols(str(sub)) for sub in subs]\n        name = _translate_symbols(name)\n    res = name\n    sub = sep.join(subs)\n    sup = sep.join(supers)\n    if len(sub) > 0:\n        res += \"_{%s}\" % sub\n    if len(sup) > 0:\n        res += \"^{%s}\" % sup\n    return res", "response": "Assemble a string from the primary name and the given subscript and superscript."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _render_str(self, string):\n        if isinstance(string, StrLabel):\n            string = string._render(string.expr)\n        string = str(string)\n        if len(string) == 0:\n            return ''\n        name, supers, subs = split_super_sub(string)\n        return render_latex_sub_super(\n            name, subs, supers, translate_symbols=True)", "response": "Returns a texified version of the string"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a format string for printing an expression type", "response": "def _braket_fmt(self, expr_type):\n        \"\"\"Return a format string for printing an `expr_type`\n        ket/bra/ketbra/braket\"\"\"\n        mapping = {\n            True: {  # use braket package\n                'bra': {\n                    True: r'\\Bra{{{label}}}^{{({space})}}',\n                    'subscript': r'\\Bra{{{label}}}_{{({space})}}',\n                    False:  r'\\Bra{{{label}}}'},\n                'ket': {\n                    True: r'\\Ket{{{label}}}^{{({space})}}',\n                    'subscript': r'\\Ket{{{label}}}_{{({space})}}',\n                    False:  r'\\Ket{{{label}}}'},\n                'ketbra': {\n                    True:\n                        r'\\Ket{{{label_i}}}\\!\\Bra{{{label_j}}}^{{({space})}}',\n                    'subscript':\n                        r'\\Ket{{{label_i}}}\\!\\Bra{{{label_j}}}_{{({space})}}',\n                    False: r'\\Ket{{{label_i}}}\\!\\Bra{{{label_j}}}'},\n                'braket': {\n                    True: r'\\Braket{{{label_i} | {label_j}}}^({space})',\n                    'subscript': r'\\Braket{{{label_i} | {label_j}}}_({space})',\n                    False:  r'\\Braket{{{label_i} | {label_j}}}'}},\n            False: {  # explicit tex macros\n                'bra': {\n                    True:\n                        r'\\left\\langle {label} \\right\\rvert^{{({space})}}',\n                    'subscript':\n                        r'\\left\\langle {label} \\right\\rvert^{{({space})}}',\n                    False:\n                        r'\\left\\langle {label} \\right\\rvert'},\n                'ket': {\n                    True:\n                        r'\\left\\lvert {label} \\right\\rangle^{{({space})}}',\n                    'subscript':\n                        r'\\left\\lvert {label} \\right\\rangle_{{({space})}}',\n                    False:  r'\\left\\lvert {label} \\right\\rangle'},\n                'ketbra': {\n                    True:\n                        r'\\left\\lvert {label_i} \\middle\\rangle\\!'\n                        r'\\middle\\langle {label_j} \\right\\rvert^{{({space})}}',\n                    'subscript':\n                        r'\\left\\lvert {label_i} \\middle\\rangle\\!'\n                        r'\\middle\\langle {label_j} \\right\\rvert_{{({space})}}',\n                    False:\n                        r'\\left\\lvert {label_i} \\middle\\rangle\\!'\n                        r'\\middle\\langle {label_j} \\right\\rvert'},\n                'braket': {\n                    True:\n                        r'\\left\\langle {label_i} \\middle\\vert '\n                        r'{label_j} \\right\\rangle^{{({space})}}',\n                    'subscript':\n                        r'\\left\\langle {label_i} \\middle\\vert '\n                        r'{label_j} \\right\\rangle_{{({space})}}',\n                    False:\n                        r'\\left\\langle {label_i} \\middle\\vert '\n                        r'{label_j} \\right\\rangle'}}\n            }\n        hs_setting = bool(self._settings['show_hs_label'])\n        if self._settings['show_hs_label'] == 'subscript':\n            hs_setting = 'subscript'\n        return mapping[self._settings['tex_use_braket']][expr_type][hs_setting]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender an operator in LaTeX format.", "response": "def _render_op(\n            self, identifier, hs=None, dagger=False, args=None, superop=False):\n        \"\"\"Render an operator\n\n        Args:\n            identifier (str): The identifier (name/symbol) of the operator. May\n                include a subscript, denoted by '_'.\n            hs (qnet.algebra.hilbert_space_algebra.HilbertSpace): The Hilbert\n                space in which the operator is defined\n            dagger (bool): Whether the operator should be daggered\n            args (list): A list of expressions that will be rendered with\n                :meth:`doprint`, joined with commas, enclosed in parenthesis\n            superop (bool): Whether the operator is a super-operator\n        \"\"\"\n        hs_label = None\n        if hs is not None and self._settings['show_hs_label']:\n            hs_label = self._render_hs_label(hs)\n        name, total_subscript, total_superscript, args_str \\\n            = self._split_op(identifier, hs_label, dagger, args)\n        if name.startswith(r'\\text{'):\n            name = name[6:-1]\n        if self._is_single_letter(name):\n            if superop:\n                name_fmt = self._settings['tex_sop_macro']\n            else:\n                name_fmt = self._settings['tex_op_macro']\n        else:\n            if superop:\n                name_fmt = self._settings['tex_textsop_macro']\n            else:\n                name_fmt = self._settings['tex_textop_macro']\n        res = name_fmt.format(name=name)\n        res = render_latex_sub_super(\n            res, [total_subscript], [total_superscript],\n            translate_symbols=True)\n        res += args_str\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn true if the string is a mathematical symbol.", "response": "def is_symbol(string):\n    \"\"\"\n    Return true if the string is a mathematical symbol.\n    \"\"\"\n    return (\n        is_int(string) or is_float(string) or\n        is_constant(string) or is_unary(string) or\n        is_binary(string) or\n        (string == '(') or (string == ')')\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_word_groups(string, words):\n    scale_pattern = '|'.join(words)\n    # For example:\n    # (?:(?:\\d+)\\s+(?:hundred|thousand)*\\s*)+(?:\\d+|hundred|thousand)+\n    regex = re.compile(\n        r'(?:(?:\\d+)\\s+(?:' +\n        scale_pattern +\n        r')*\\s*)+(?:\\d+|' +\n        scale_pattern + r')+'\n    )\n    result = regex.findall(string)\n    return result", "response": "Find matches for words in the format 3 thousand 6 hundred 2."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_word_tokens(string, language):\n    words = mathwords.word_groups_for_language(language)\n\n    # Replace operator words with numeric operators\n    operators = words['binary_operators'].copy()\n    if 'unary_operators' in words:\n        operators.update(words['unary_operators'])\n\n    for operator in list(operators.keys()):\n        if operator in string:\n            string = string.replace(operator, operators[operator])\n\n    # Replace number words with numeric values\n    numbers = words['numbers']\n    for number in list(numbers.keys()):\n        if number in string:\n            string = string.replace(number, str(numbers[number]))\n\n    # Replace scaling multipliers with numeric values\n    scales = words['scales']\n    end_index_characters = mathwords.BINARY_OPERATORS\n    end_index_characters.add('(')\n\n    word_matches = find_word_groups(string, list(scales.keys()))\n\n    for match in word_matches:\n        string = string.replace(match, '(' + match + ')')\n\n    for scale in list(scales.keys()):\n        for _ in range(0, string.count(scale)):\n            start_index = string.find(scale) - 1\n            end_index = len(string)\n\n            while is_int(string[start_index - 1]) and start_index > 0:\n                start_index -= 1\n\n            end_index = string.find(' ', start_index) + 1\n            end_index = string.find(' ', end_index) + 1\n\n            add = ' + '\n            if string[end_index] in end_index_characters:\n                add = ''\n\n            string = string[:start_index] + '(' + string[start_index:]\n            string = string.replace(\n                scale, '* ' + str(scales[scale]) + ')' + add,\n                1\n            )\n\n    string = string.replace(') (', ') + (')\n\n    return string", "response": "Given a string and an ISO 639 - 2 language code return the string with the words replaced with\n    an operational equivalent."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_postfix(tokens):\n    precedence = {\n        '/': 4,\n        '*': 4,\n        '+': 3,\n        '-': 3,\n        '^': 2,\n        '(': 1\n    }\n\n    postfix = []\n    opstack = []\n\n    for token in tokens:\n        if is_int(token):\n            postfix.append(int(token))\n        elif is_float(token):\n            postfix.append(float(token))\n        elif token in mathwords.CONSTANTS:\n            postfix.append(mathwords.CONSTANTS[token])\n        elif is_unary(token):\n            opstack.append(token)\n        elif token == '(':\n            opstack.append(token)\n        elif token == ')':\n            top_token = opstack.pop()\n            while top_token != '(':\n                postfix.append(top_token)\n                top_token = opstack.pop()\n        else:\n            while (opstack != []) and (\n                precedence[opstack[-1]] >= precedence[token]\n            ):\n                postfix.append(opstack.pop())\n            opstack.append(token)\n\n    while opstack != []:\n        postfix.append(opstack.pop())\n\n    return postfix", "response": "Convert a list of evaluatable tokens to postfix format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef evaluate_postfix(tokens):\n    stack = []\n\n    for token in tokens:\n        total = None\n\n        if is_int(token) or is_float(token) or is_constant(token):\n            stack.append(token)\n        elif is_unary(token):\n            a = stack.pop()\n            total = mathwords.UNARY_FUNCTIONS[token](a)\n        elif len(stack):\n            b = stack.pop()\n            a = stack.pop()\n            if token == '+':\n                total = a + b\n            elif token == '-':\n                total = a - b\n            elif token == '*':\n                total = a * b\n            elif token == '^':\n                total = a ** b\n            elif token == '/':\n                if Decimal(str(b)) == 0:\n                    total = 'undefined'\n                else:\n                    total = Decimal(str(a)) / Decimal(str(b))\n            else:\n                raise PostfixTokenEvaluationException(\n                    'Unknown token {}'.format(token)\n                )\n\n        if total is not None:\n            stack.append(total)\n\n    # If the stack is empty the tokens could not be evaluated\n    if not stack:\n        raise PostfixTokenEvaluationException(\n            'The postfix expression resulted in an empty stack'\n        )\n\n    return stack.pop()", "response": "Given a list of evaluatable tokens in postfix format calculate a solution."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a string return a list of math symbol tokens", "response": "def tokenize(string, language=None, escape='___'):\n    \"\"\"\n    Given a string, return a list of math symbol tokens\n    \"\"\"\n    # Set all words to lowercase\n    string = string.lower()\n\n    # Ignore punctuation\n    if len(string) and not string[-1].isalnum():\n        character = string[-1]\n        string = string[:-1] + ' ' + character\n\n    # Parenthesis must have space around them to be tokenized properly\n    string = string.replace('(', ' ( ')\n    string = string.replace(')', ' ) ')\n\n    if language:\n        words = mathwords.words_for_language(language)\n\n        for phrase in words:\n            escaped_phrase = phrase.replace(' ', escape)\n            string = string.replace(phrase, escaped_phrase)\n\n    tokens = string.split()\n\n    for index, token in enumerate(tokens):\n        tokens[index] = token.replace(escape, ' ')\n\n    return tokens"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a string into a solution to the equation in the input string.", "response": "def parse(string, language=None):\n    \"\"\"\n    Return a solution to the equation in the input string.\n    \"\"\"\n    if language:\n        string = replace_word_tokens(string, language)\n\n    tokens = tokenize(string)\n    postfix = to_postfix(tokens)\n\n    return evaluate_postfix(postfix)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extract_expression(dirty_string, language):\n    tokens = tokenize(dirty_string, language)\n\n    start_index = 0\n    end_index = len(tokens)\n\n    for part in tokens:\n        if is_symbol(part) or is_word(part, language):\n            break\n        else:\n            start_index += 1\n\n    for part in reversed(tokens):\n        if is_symbol(part) or is_word(part, language):\n            break\n        else:\n            end_index -= 1\n\n    return ' '.join(tokens[start_index:end_index])", "response": "Extracts the expression from a string such as what is 4 + 4? Return the string"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Sum(idx, *args, **kwargs):\n    from qnet.algebra.core.hilbert_space_algebra import LocalSpace\n    from qnet.algebra.core.scalar_algebra import ScalarValue\n    from qnet.algebra.library.spin_algebra import SpinSpace\n    dispatch_table = {\n        tuple(): _sum_over_fockspace,\n        (LocalSpace, ): _sum_over_fockspace,\n        (SpinSpace, ): _sum_over_fockspace,\n        (list, ): _sum_over_list,\n        (tuple, ): _sum_over_list,\n        (int, ): _sum_over_range,\n        (int, int): _sum_over_range,\n        (int, int, int): _sum_over_range,\n    }\n    key = tuple((type(arg) for arg in args))\n    try:\n        idx_range_func = dispatch_table[key]\n    except KeyError:\n        raise TypeError(\"No implementation for args of type %s\" % str(key))\n\n    def sum(term):\n        if isinstance(term, ScalarValue._val_types):\n            term = ScalarValue.create(term)\n        idx_range = idx_range_func(term, idx, *args, **kwargs)\n        return term._indexed_sum_cls.create(term, idx_range)\n\n    return sum", "response": "Instantiator for an arbitrary indexed sum."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure that the given Hilbert space is an instance of cls.", "response": "def ensure_local_space(hs, cls=LocalSpace):\n    \"\"\"Ensure that the given `hs` is an instance of :class:`LocalSpace`.\n\n    If `hs` an instance of :class:`str` or :class:`int`, it will be converted\n    to a `cls` (if possible). If it already is an instace of `cls`, `hs`\n    will be returned unchanged.\n\n    Args:\n        hs (HilbertSpace or str or int): The Hilbert space (or label) to\n            convert/check\n        cls (type): The class to which an int/str label for a Hilbert space\n            should be converted. Must be a subclass of :class:`LocalSpace`.\n\n    Raises:\n        TypeError: If `hs` is not a :class:`.LocalSpace`, :class:`str`, or\n            :class:`int`.\n\n    Returns:\n        LocalSpace: original or converted `hs`\n\n    Examples:\n        >>> srepr(ensure_local_space(0))\n        \"LocalSpace('0')\"\n        >>> srepr(ensure_local_space('tls'))\n        \"LocalSpace('tls')\"\n        >>> srepr(ensure_local_space(0, cls=LocalSpace))\n        \"LocalSpace('0')\"\n        >>> srepr(ensure_local_space(LocalSpace(0)))\n        \"LocalSpace('0')\"\n        >>> srepr(ensure_local_space(LocalSpace(0)))\n        \"LocalSpace('0')\"\n        >>> srepr(ensure_local_space(LocalSpace(0) * LocalSpace(1)))\n        Traceback (most recent call last):\n           ...\n        TypeError: hs must be an instance of LocalSpace\n    \"\"\"\n    if isinstance(hs, (str, int)):\n        try:\n            hs = cls(hs)\n        except TypeError as exc_info:\n            raise TypeError(\n                \"Cannot convert %s '%s' into a %s instance: %s\"\n                % (hs.__class__.__name__, hs, cls.__name__, str(exc_info)))\n    if not isinstance(hs, LocalSpace):\n        raise TypeError(\"hs must be an instance of LocalSpace\")\n    return hs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _series_expand_combine_prod(c1, c2, order):\n    from qnet.algebra.core.scalar_algebra import Zero\n    res = []\n    c1 = list(c1)\n    c2 = list(c2)\n    for n in range(order + 1):\n        summands = []\n        for k in range(n + 1):\n            if c1[k].is_zero or c2[n-k].is_zero:\n                summands.append(Zero)\n            else:\n                summands.append(c1[k] * c2[n - k])\n        sum = summands[0]\n        for summand in summands[1:]:\n            if summand != 0:\n                sum += summand\n        res.append(sum)\n    return tuple(res)", "response": "Given the result of the c1. _series_expand(... ) and c2. _series_expand(... ) construct the result of the c1. _series_expand(... ) and c2. _series_expand(... ) and order returns the result of the c1. _series_expand method."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndifferentiates by scalar parameter sym.", "response": "def diff(self, sym: Symbol, n: int = 1, expand_simplify: bool = True):\n        \"\"\"Differentiate by scalar parameter `sym`.\n\n        Args:\n            sym: What to differentiate by.\n            n: How often to differentiate\n            expand_simplify: Whether to simplify the result.\n\n        Returns:\n            The n-th derivative.\n        \"\"\"\n        if not isinstance(sym, sympy.Basic):\n            raise TypeError(\"%s needs to be a Sympy symbol\" % sym)\n        if sym.free_symbols.issubset(self.free_symbols):\n            # QuantumDerivative.create delegates internally to _diff (the\n            # explicit non-trivial derivative). Using `create` gives us free\n            # caching\n            deriv = QuantumDerivative.create(self, derivs={sym: n}, vals=None)\n            if not deriv.is_zero and expand_simplify:\n                deriv = deriv.expand().simplify_scalar()\n            return deriv\n        else:\n            # the \"issubset\" of free symbols is a sufficient, but not a\n            # necessary condition; if `sym` is non-atomic, determining whether\n            # `self` depends on `sym` is not completely trivial (you'd have to\n            # substitute with a Dummy)\n            return self.__class__._zero"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef series_expand(\n            self, param: Symbol, about, order: int) -> tuple:\n        r\"\"\"Expand the expression as a truncated power series in a\n        scalar parameter.\n\n        When expanding an expr for a parameter $x$ about the point $x_0$ up to\n        order $N$, the resulting coefficients $(c_1, \\dots, c_N)$ fulfill\n\n        .. math::\n\n            \\text{expr} = \\sum_{n=0}^{N} c_n (x - x_0)^n + O(N+1)\n\n        Args:\n            param: Expansion parameter $x$\n            about (Scalar): Point $x_0$ about which to expand\n            order: Maximum order $N$ of expansion (>= 0)\n\n        Returns:\n            tuple of length ``order + 1``, where the entries are the\n            expansion coefficients, $(c_0, \\dots, c_N)$.\n\n        Note:\n            The expansion coefficients are\n            \"type-stable\", in that they share a common base class with the\n            original expression. In particular, this applies to \"zero\"\n            coefficients::\n\n                >>> expr = KetSymbol(\"Psi\", hs=0)\n                >>> t = sympy.symbols(\"t\")\n                >>> assert expr.series_expand(t, 0, 1) == (expr, ZeroKet)\n        \"\"\"\n        expansion = self._series_expand(param, about, order)\n        # _series_expand is generally not \"type-stable\", so we continue to\n        # ensure the type-stability\n        res = []\n        for v in expansion:\n            if v == 0 or v.is_zero:\n                v = self._zero\n            elif v == 1:\n                v = self._one\n            assert isinstance(v, self._base_cls)\n            res.append(v)\n        return tuple(res)", "response": "r Expands the expression as a truncated power series in a\n            scalar parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef factor_for_space(self, spc):\n        if spc == TrivialSpace:\n            ops_on_spc = [\n                o for o in self.operands if o.space is TrivialSpace]\n            ops_not_on_spc = [\n                o for o in self.operands if o.space > TrivialSpace]\n        else:\n            ops_on_spc = [\n                o for o in self.operands if (o.space & spc) > TrivialSpace]\n            ops_not_on_spc = [\n                o for o in self.operands if (o.space & spc) is TrivialSpace]\n        return (\n            self.__class__._times_cls.create(*ops_on_spc),\n            self.__class__._times_cls.create(*ops_not_on_spc))", "response": "Return a tuple of two products where the first product contains the\n            given Hilbert space and the second product is disjunct from it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nevaluate the derivative at a specific point", "response": "def evaluate_at(self, vals):\n        \"\"\"Evaluate the derivative at a specific point\"\"\"\n        new_vals = self._vals.copy()\n        new_vals.update(vals)\n        return self.__class__(self.operand, derivs=self._derivs, vals=new_vals)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef free_symbols(self):\n        if self._free_symbols is None:\n            if len(self._vals) == 0:\n                self._free_symbols = self.operand.free_symbols\n            else:\n                dummy_map = {}\n                for sym in self._vals.keys():\n                    dummy_map[sym] = sympy.Dummy()\n                # bound symbols may not be atomic, so we have to replace them\n                # with dummies\n                self._free_symbols = {\n                    sym for sym\n                    in self.operand.substitute(dummy_map).free_symbols\n                    if not isinstance(sym, sympy.Dummy)}\n                for val in self._vals.values():\n                    self._free_symbols.update(val.free_symbols)\n        return self._free_symbols", "response": "Set of free SymPy symbols contained within the expression."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting of Sympy symbols that are eliminated by evaluation.", "response": "def bound_symbols(self):\n        \"\"\"Set of Sympy symbols that are eliminated by evaluation.\"\"\"\n        if self._bound_symbols is None:\n            res = set()\n            self._bound_symbols = res.union(\n                *[sym.free_symbols for sym in self._vals.keys()])\n        return self._bound_symbols"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef render_dot(self, code, options, format, prefix='graphviz'):\n    # type: (nodes.NodeVisitor, unicode, Dict, unicode, unicode) -> Tuple[unicode, unicode]\n    \"\"\"Render graphviz code into a PNG or PDF output file.\"\"\"\n    graphviz_dot = options.get('graphviz_dot', self.builder.config.graphviz_dot)\n    hashkey = (code + str(options) + str(graphviz_dot) +\n               str(self.builder.config.graphviz_dot_args)).encode('utf-8')\n\n    fname = '%s-%s.%s' % (prefix, sha1(hashkey).hexdigest(), format)\n    relfn = posixpath.join(self.builder.imgpath, fname)\n    outfn = path.join(self.builder.outdir, self.builder.imagedir, fname)\n\n    if path.isfile(outfn):\n        return relfn, outfn\n\n    if (hasattr(self.builder, '_graphviz_warned_dot') and\n       self.builder._graphviz_warned_dot.get(graphviz_dot)):\n        return None, None\n\n    ensuredir(path.dirname(outfn))\n\n    # graphviz expects UTF-8 by default\n    if isinstance(code, text_type):\n        code = code.encode('utf-8')\n\n    dot_args = [graphviz_dot]\n    dot_args.extend(self.builder.config.graphviz_dot_args)\n    dot_args.extend(['-T' + format, '-o' + outfn])\n    if format == 'png':\n        dot_args.extend(['-Tcmapx', '-o%s.map' % outfn])\n    try:\n        p = Popen(dot_args, stdout=PIPE, stdin=PIPE, stderr=PIPE)\n    except OSError as err:\n        if err.errno != ENOENT:   # No such file or directory\n            raise\n        logger.warning(__('dot command %r cannot be run (needed for graphviz '\n                          'output), check the graphviz_dot setting'), graphviz_dot)\n        if not hasattr(self.builder, '_graphviz_warned_dot'):\n            self.builder._graphviz_warned_dot = {}\n        self.builder._graphviz_warned_dot[graphviz_dot] = True\n        return None, None\n    try:\n        # Graphviz may close standard input when an error occurs,\n        # resulting in a broken pipe on communicate()\n        stdout, stderr = p.communicate(code)\n    except (OSError, IOError) as err:\n        if err.errno not in (EPIPE, EINVAL):\n            raise\n        # in this case, read the standard output and standard error streams\n        # directly, to get the error message(s)\n        stdout, stderr = p.stdout.read(), p.stderr.read()\n        p.wait()\n    if p.returncode != 0:\n        raise GraphvizError(__('dot exited with error:\\n[stderr]\\n%s\\n'\n                               '[stdout]\\n%s') % (stderr, stdout))\n    if not path.isfile(outfn):\n        raise GraphvizError(__('dot did not produce an output file:\\n[stderr]\\n%s\\n'\n                               '[stdout]\\n%s') % (stderr, stdout))\n    return relfn, outfn", "response": "Render a graphviz code into a PNG or PDF output file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef generate_clickable_map(self):\n        # type: () -> unicode\n        \"\"\"Generate clickable map tags if clickable item exists.\n\n        If not exists, this only returns empty string.\n        \"\"\"\n        if self.clickable:\n            return '\\n'.join([self.content[0]] + self.clickable + [self.content[-1]])\n        else:\n            return ''", "response": "Generate clickable map tags if clickable item exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef SpinBasisKet(*numer_denom, hs):\n    try:\n        spin_numer, spin_denom = hs.spin.as_numer_denom()\n    except AttributeError:\n        raise TypeError(\n            \"hs=%s for SpinBasisKet must be a SpinSpace instance\" % hs)\n    assert spin_denom in (1, 2)\n    if spin_denom == 1:  # integer spin\n        if len(numer_denom) != 1:\n            raise TypeError(\n                \"SpinBasisKet requires exactly one positional argument for an \"\n                \"integer-spin Hilbert space\")\n        numer = numer_denom[0]\n        if numer < -spin_numer or numer > spin_numer:\n            raise ValueError(\n                \"spin quantum number %s must be in range (%s, %s)\"\n                % (numer, -spin_numer, spin_numer))\n        label = str(numer)\n        if numer > 0:\n            label = \"+\" + label\n        return BasisKet(label, hs=hs)\n    else:  # half-integer spin\n        if len(numer_denom) != 2:\n            raise TypeError(\n                \"SpinBasisKet requires exactly two positional arguments for a \"\n                \"half-integer-spin Hilbert space\")\n        numer, denom = numer_denom\n        numer = int(numer)\n        denom = int(denom)\n        if denom != 2:\n            raise ValueError(\n                \"The second positional argument (denominator of the spin \"\n                \"quantum number) must be 2, not %s\" % denom)\n        if numer < -spin_numer or numer > spin_numer:\n            raise ValueError(\n                \"spin quantum number %s/%s must be in range (%s/2, %s/2)\"\n                % (numer, denom, -spin_numer, spin_numer))\n        label = str(numer)\n        if numer > 0:\n            label = \"+\" + label\n        label = label + \"/2\"\n        return BasisKet(label, hs=hs)", "response": "Return a list of base classes that can be used to create a base class for a given number of non - zero spin quantum numbers."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the JPJMcoeff of the Hilbert space with multiplicity m.", "response": "def Jpjmcoeff(ls, m, shift=False) -> sympy.Expr:\n    r'''Eigenvalue of the $\\Op{J}_{+}$ (:class:`Jplus`) operator\n\n    .. math::\n\n        \\Op{J}_{+} \\ket{s, m} = \\sqrt{s (s+1) - m (m+1)} \\ket{s, m}\n\n    where the multiplicity $s$ is implied by the size of the Hilbert space\n    `ls`: there are $2s+1$ eigenstates with $m = -s, -s+1, \\dots, s$.\n\n    Args:\n        ls (LocalSpace): The Hilbert space in which the $\\Op{J}_{+}$ operator\n            acts.\n        m (str or int): If str, the label of the basis state of `hs` to which\n            the operator is applied. If integer together with ``shift=True``,\n            the zero-based index of the basis state. Otherwise, directly the\n            quantum number $m$.\n        shift (bool): If True for a integer value of `m`, treat `m` as the\n            zero-based index of the basis state (i.e., shift `m` down by $s$ to\n            obtain the quantum number $m$)\n    '''\n    assert isinstance(ls, SpinSpace)\n    n = ls.dimension\n    s = sympify(n - 1) / 2\n    assert n == int(2 * s + 1)\n    if isinstance(m, str):\n        m = ls.basis_labels.index(m) - s  # m is now Sympy expression\n    elif isinstance(m, int):\n        if shift:\n            assert 0 <= m < n\n            m = m - s\n    return sqrt(s * (s + 1) - m * (m + 1))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the eigenvalue of the J_z operator.", "response": "def Jzjmcoeff(ls, m, shift) -> sympy.Expr:\n    r'''Eigenvalue of the $\\Op{J}_z$ (:class:`Jz`) operator\n\n    .. math::\n\n        \\Op{J}_{z} \\ket{s, m} = m \\ket{s, m}\n\n    See also :func:`Jpjmcoeff`.\n    '''\n    assert isinstance(ls, SpinSpace)\n    n = ls.dimension\n    s = sympify(n - 1) / 2\n    assert n == int(2 * s + 1)\n    if isinstance(m, str):\n        return ls.basis.index(m) - s\n    elif isinstance(m, int):\n        if shift:\n            assert 0 <= m < n\n            return m - s\n    else:\n        return sympify(m)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a label or index of a basis state return the next basis state label or index.", "response": "def next_basis_label_or_index(self, label_or_index, n=1):\n        \"\"\"Given the label or index of a basis state, return the label\n        the next basis state.\n\n        More generally, if `n` is given, return the `n`'th next basis state\n        label/index; `n` may also be negative to obtain previous basis state\n        labels. Returns a :class:`str` label if `label_or_index` is a\n        :class:`str` or :class:`int`, or a :class:`SpinIndex` if\n        `label_or_index` is a :class:`SpinIndex`.\n\n        Args:\n            label_or_index (int or str or SpinIndex): If `int`, the\n                zero-based index of a basis state; if `str`, the label of a\n                basis state\n            n (int): The increment\n\n        Raises:\n            IndexError: If going beyond the last or first basis state\n            ValueError: If `label` is not a label for any basis state in the\n                Hilbert space\n            .BasisNotSetError: If the Hilbert space has no defined basis\n            TypeError: if `label_or_index` is neither a :class:`str` nor an\n                :class:`int`, nor a :class:`SpinIndex`\n\n        Note:\n            This differs from its super-method only by never returning an\n            integer index (which is not accepted when instantiating a\n            :class:`BasisKet` for a :class:`SpinSpace`)\n        \"\"\"\n        if isinstance(label_or_index, int):\n            new_index = label_or_index + n\n            if new_index < 0:\n                raise IndexError(\"index %d < 0\" % new_index)\n            if new_index >= self.dimension:\n                raise IndexError(\n                    \"index %d out of range for basis %s\"\n                    % (new_index, self._basis))\n            return self.basis_labels[new_index]\n        elif isinstance(label_or_index, str):\n            label_index = self.basis_labels.index(label_or_index)\n            new_index = label_index + n\n            if (new_index < 0) or (new_index >= len(self._basis)):\n                raise IndexError(\n                    \"index %d out of range for basis %s\"\n                    % (new_index, self._basis))\n            return self.basis_labels[new_index]\n        elif isinstance(label_or_index, SpinIndex):\n            return label_or_index.__class__(expr=label_or_index.expr + n)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef try_import(objname):\n    # type: (unicode) -> Any\n    \"\"\"Import a object or module using *name* and *currentmodule*.\n    *name* should be a relative name from *currentmodule* or\n    a fully-qualified name.\n\n    Returns imported object or module.  If failed, returns None value.\n    \"\"\"\n    try:\n        __import__(objname)\n        return sys.modules.get(objname)  # type: ignore\n    except (ImportError, ValueError):  # ValueError,py27 -> ImportError,py3\n        matched = module_sig_re.match(objname)  # type: ignore\n\n        if not matched:\n            return None\n\n        modname, attrname = matched.groups()\n\n        if modname is None:\n            return None\n        try:\n            __import__(modname)\n            return getattr(sys.modules.get(modname), attrname, None)\n        except (ImportError, ValueError):  # ValueError,py27 -> ImportError,py3\n            return None", "response": "Try to import an object or module using the given name and return the imported object or module."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef import_classes(name, currmodule):\n    # type: (unicode, unicode) -> Any\n    \"\"\"Import a class using its fully-qualified *name*.\"\"\"\n    target = None\n\n    # import class or module using currmodule\n    if currmodule:\n        target = try_import(currmodule + '.' + name)\n\n    # import class or module without currmodule\n    if target is None:\n        target = try_import(name)\n\n    if target is None:\n        raise InheritanceException(\n            'Could not import class or module %r specified for '\n            'inheritance diagram' % name)\n\n    if inspect.isclass(target):\n        # If imported object is a class, just return it\n        return [target]\n    elif inspect.ismodule(target):\n        # If imported object is a module, return classes defined on it\n        classes = []\n        for cls in target.__dict__.values():\n            if inspect.isclass(cls) and cls_is_in_module(cls, mod=target):\n                classes.append(cls)\n        return classes\n    raise InheritanceException('%r specified for inheritance diagram is '\n                               'not a class or module' % name)", "response": "Import a class using its fully - qualified name *."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\noutputs the inheritance diagram of the node.", "response": "def html_visit_inheritance_diagram(self, node):\n    # type: (nodes.NodeVisitor, inheritance_diagram) -> None\n    \"\"\"\n    Output the graph for HTML.  This will insert a PNG with clickable\n    image map.\n    \"\"\"\n    graph = node['graph']\n\n    graph_hash = get_graph_hash(node)\n    name = 'inheritance%s' % graph_hash\n\n    # Create a mapping from fully-qualified class names to URLs.\n    graphviz_output_format = self.builder.env.config.graphviz_output_format.upper()\n    current_filename = self.builder.current_docname + self.builder.out_suffix\n    urls = {}\n    for child in node:\n        if child.get('refuri') is not None:\n            if graphviz_output_format == 'SVG':\n                urls[child['reftitle']] = os.path.join(\"..\", child.get('refuri'))\n            else:\n                urls[child['reftitle']] = child.get('refuri')\n        elif child.get('refid') is not None:\n            if graphviz_output_format == 'SVG':\n                urls[child['reftitle']] = os.path.join('..', current_filename + '#' + child.get('refid'))\n            else:\n                urls[child['reftitle']] = '#' + child.get('refid')\n\n    dotcode = graph.generate_dot(name, urls, env=self.builder.env)\n    render_dot_html(\n        self, node, dotcode, {}, 'inheritance', 'inheritance',\n        alt='Inheritance diagram of ' + node['content'],\n        link_to_svg='<i class=\"fa fa-external-link\" aria-hidden=\"true\"></i>'' SVG')\n    raise nodes.SkipNode"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef latex_visit_inheritance_diagram(self, node):\n    # type: (nodes.NodeVisitor, inheritance_diagram) -> None\n    \"\"\"\n    Output the graph for LaTeX.  This will insert a PDF.\n    \"\"\"\n    graph = node['graph']\n\n    graph_hash = get_graph_hash(node)\n    name = 'inheritance%s' % graph_hash\n\n    dotcode = graph.generate_dot(name, env=self.builder.env,\n                                 graph_attrs={'size': '\"6.0,6.0\"'})\n    render_dot_latex(self, node, dotcode, {}, 'inheritance')\n    raise nodes.SkipNode", "response": "Output the graph for LaTeX."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noutputting the graph for Texinfo.", "response": "def texinfo_visit_inheritance_diagram(self, node):\n    # type: (nodes.NodeVisitor, inheritance_diagram) -> None\n    \"\"\"\n    Output the graph for Texinfo.  This will insert a PNG.\n    \"\"\"\n    graph = node['graph']\n\n    graph_hash = get_graph_hash(node)\n    name = 'inheritance%s' % graph_hash\n\n    dotcode = graph.generate_dot(name, env=self.builder.env,\n                                 graph_attrs={'size': '\"6.0,6.0\"'})\n    render_dot_texinfo(self, node, dotcode, {}, 'inheritance')\n    raise nodes.SkipNode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _import_classes(self, class_names, currmodule):\n        # type: (unicode, str) -> List[Any]\n        \"\"\"Import a list of classes.\"\"\"\n        classes = []  # type: List[Any]\n        for name in class_names:\n            classes.extend(import_classes(name, currmodule))\n        return classes", "response": "Imports a list of classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _class_info(self, classes, show_builtins, private_bases, parts, aliases, top_classes):\n        # type: (List[Any], bool, bool, int, Optional[Dict[unicode, unicode]], List[Any]) -> List[Tuple[unicode, unicode, List[unicode], unicode]]  # NOQA\n        \"\"\"Return name and bases for all classes that are ancestors of\n        *classes*.\n\n        *parts* gives the number of dotted name parts that is removed from the\n        displayed node names.\n\n        *top_classes* gives the name(s) of the top most ancestor class to traverse\n        to. Multiple names can be specified separated by comma.\n        \"\"\"\n        all_classes = {}\n        py_builtins = vars(builtins).values()\n\n        def recurse(cls):\n            # type: (Any) -> None\n            if not show_builtins and cls in py_builtins:\n                return\n            if not private_bases and cls.__name__.startswith('_'):\n                return\n\n            nodename = self.class_name(cls, parts, aliases)\n            fullname = self.class_name(cls, 0, aliases)\n\n            # Use first line of docstring as tooltip, if available\n            tooltip = None\n            try:\n                if cls.__doc__:\n                    enc = ModuleAnalyzer.for_module(cls.__module__).encoding\n                    doc = cls.__doc__.strip().split(\"\\n\")[0]\n                    if not isinstance(doc, text_type):\n                        doc = force_decode(doc, enc)\n                    if doc:\n                        tooltip = '\"%s\"' % doc.replace('\"', '\\\\\"')\n            except Exception:  # might raise AttributeError for strange classes\n                pass\n\n            baselist = []  # type: List[unicode]\n            all_classes[cls] = (nodename, fullname, baselist, tooltip)\n\n            if fullname in top_classes:\n                return\n\n            for base in cls.__bases__:\n                if not show_builtins and base in py_builtins:\n                    continue\n                if not private_bases and base.__name__.startswith('_'):\n                    continue\n                baselist.append(self.class_name(base, parts, aliases))\n                if base not in all_classes:\n                    recurse(base)\n\n        for cls in classes:\n            recurse(cls)\n\n        return list(all_classes.values())", "response": "Return a list of tuples containing the name and base names for all classes in classes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef class_name(self, cls, parts=0, aliases=None):\n        # type: (Any, int, Optional[Dict[unicode, unicode]]) -> unicode\n        \"\"\"Given a class object, return a fully-qualified name.\n\n        This works for things I've tested in matplotlib so far, but may not be\n        completely general.\n        \"\"\"\n        module = cls.__module__\n        if module in ('__builtin__', 'builtins'):\n            fullname = cls.__name__\n        else:\n            fullname = '%s.%s' % (module, cls.__name__)\n        if parts == 0:\n            result = fullname\n        else:\n            name_parts = fullname.split('.')\n            result = '.'.join(name_parts[-parts:])\n        if aliases is not None and result in aliases:\n            return aliases[result]\n        return result", "response": "Given a class object return a fully - qualified name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_dot(self, name, urls={}, env=None,\n                     graph_attrs={}, node_attrs={}, edge_attrs={}):\n        # type: (unicode, Dict, BuildEnvironment, Dict, Dict, Dict) -> unicode\n        \"\"\"Generate a graphviz dot graph from the classes that were passed in\n        to __init__.\n\n        *name* is the name of the graph.\n\n        *urls* is a dictionary mapping class names to HTTP URLs.\n\n        *graph_attrs*, *node_attrs*, *edge_attrs* are dictionaries containing\n        key/value pairs to pass on as graphviz properties.\n        \"\"\"\n        g_attrs = self.default_graph_attrs.copy()\n        n_attrs = self.default_node_attrs.copy()\n        e_attrs = self.default_edge_attrs.copy()\n        c_attrs = self.default_cluster_attrs.copy()\n        g_attrs.update(graph_attrs)\n        n_attrs.update(node_attrs)\n        e_attrs.update(edge_attrs)\n        if env:\n            g_attrs.update(env.config.inheritance_graph_attrs)\n            n_attrs.update(env.config.inheritance_node_attrs)\n            e_attrs.update(env.config.inheritance_edge_attrs)\n            c_attrs.update(env.config.inheritance_cluster_attrs)\n\n        res = []  # type: List[unicode]\n        res.append('digraph %s {\\n' % name)\n        res.append(self._format_graph_attrs(g_attrs))\n\n        subgraphs = defaultdict(list)  # subgraph_name => list of node names\n\n        for name, fullname, bases, tooltip in sorted(self.class_info):\n            subgraph_name = \".\".join(fullname.split(\".\")[:-1])\n            subgraphs[subgraph_name].append(name)\n            # Write the node\n            this_node_attrs = n_attrs.copy()\n            if fullname in urls:\n                this_node_attrs['URL'] = '\"%s\"' % urls[fullname]\n                this_node_attrs['target'] = '\"_top\"'\n            if tooltip:\n                this_node_attrs['tooltip'] = tooltip\n            res.append('  \"%s\" [%s];\\n' %\n                       (name, self._format_node_attrs(this_node_attrs)))\n\n            # Write the edges\n            for base_name in bases:\n                res.append('  \"%s\" -> \"%s\" [%s];\\n' %\n                           (base_name, name,\n                            self._format_node_attrs(e_attrs)))\n\n        if self.cluster_modules:\n            for subgraph_name in subgraphs:\n                res.append('subgraph cluster_%s {\\n'\n                           % subgraph_name.replace('.', '_'))\n                res.append('  label=\"%s\";\\n' % subgraph_name)\n                res.append('  graph[' + self._format_node_attrs(c_attrs) +\n                           \"];\\n\")\n                res.append('  ' + \"; \".join(subgraphs[subgraph_name]) + \"\\n\")\n                res.append('}\\n')\n\n        res.append('}\\n')\n        return ''.join(res)", "response": "Generate a graphviz dot graph from the classes that were passed in."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef codemirror_settings_update(configs, parameters, on=None, names=None):\n    # Deep copy of given config\n    output = copy.deepcopy(configs)\n\n    # Optionnaly filtering config from given names\n    if names:\n        output = {k: output[k] for k in names}\n\n    # Select every config if selectors is empty\n    if not on:\n        on = output.keys()\n\n    for k in on:\n        output[k].update(parameters)\n\n    return output", "response": "Update a dictionary of codemirror settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef lhs(self):\n        lhs = self._lhs\n        i = 0\n        while lhs is None:\n            i -= 1\n            lhs = self._prev_lhs[i]\n        return lhs", "response": "The left - hand - side of the equation"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_tag(self, tag):\n        return Eq(\n            self._lhs, self._rhs, tag=tag,\n            _prev_lhs=self._prev_lhs, _prev_rhs=self._prev_rhs,\n            _prev_tags=self._prev_tags)", "response": "Return a copy of the equation with a new tag."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\napplying a function to both sides of the equation returns a new equation where the left - hand - side and right - hand - side are replaced by the application of func.", "response": "def apply(self, func, *args, cont=False, tag=None, **kwargs):\n        \"\"\"Apply `func` to both sides of the equation\n\n        Returns a new equation where the left-hand-side and right-hand side\n        are replaced by the application of `func`::\n\n            lhs=func(lhs, *args, **kwargs)\n            rhs=func(rhs, *args, **kwargs)\n\n        If ``cont=True``, the resulting equation will keep a history of its\n        previous state (resulting in multiple lines of equations when printed,\n        as in the main example above).\n\n        The resulting equation with have the given `tag`.\n        \"\"\"\n        new_lhs = func(self.lhs, *args, **kwargs)\n        if new_lhs == self.lhs and cont:\n            new_lhs = None\n        new_rhs = func(self.rhs, *args, **kwargs)\n        new_tag = tag\n        return self._update(new_lhs, new_rhs, new_tag, cont)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall the method `mtd` on both sides of the equation That is, the left-hand-side and right-hand-side are replaced by:: lhs=lhs.<mtd>(*args, **kwargs) rhs=rhs.<mtd>(*args, **kwargs) The `cont` and `tag` parameters are as in :meth:`apply`.", "response": "def apply_mtd(self, mtd, *args, cont=False, tag=None, **kwargs):\n        \"\"\"Call the method `mtd` on both sides of the equation\n\n        That is, the left-hand-side and right-hand-side are replaced by::\n\n            lhs=lhs.<mtd>(*args, **kwargs)\n            rhs=rhs.<mtd>(*args, **kwargs)\n\n        The `cont` and `tag` parameters are as in :meth:`apply`.\n        \"\"\"\n        new_lhs = getattr(self.lhs, mtd)(*args, **kwargs)\n        if new_lhs == self.lhs and cont:\n            new_lhs = None\n        new_rhs = getattr(self.rhs, mtd)(*args, **kwargs)\n        new_tag = tag\n        return self._update(new_lhs, new_rhs, new_tag, cont)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsubstitutes sub - expressions between the lhs and rhs of the object.", "response": "def substitute(self, var_map, cont=False, tag=None):\n        \"\"\"Substitute sub-expressions both on the lhs and rhs\n\n        Args:\n            var_map (dict): Dictionary with entries of the form\n                ``{expr: substitution}``\n        \"\"\"\n        return self.apply(substitute, var_map=var_map, cont=cont, tag=tag)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef verify(self, func=None, *args, **kwargs):\n        res = (\n            self.lhs.expand().simplify_scalar() -\n            self.rhs.expand().simplify_scalar())\n        if func is not None:\n            return func(res, *args, **kwargs)\n        else:\n            return res", "response": "This method is used to verify that the equation is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the equation", "response": "def copy(self):\n        \"\"\"Return a copy of the equation\"\"\"\n        return Eq(\n            self._lhs, self._rhs, tag=self._tag,\n            _prev_lhs=self._prev_lhs, _prev_rhs=self._prev_rhs,\n            _prev_tags=self._prev_tags)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef free_symbols(self):\n        try:\n            lhs_syms = self.lhs.free_symbols\n        except AttributeError:\n            lhs_syms = set()\n        try:\n            rhs_syms = self.rhs.free_symbols\n        except AttributeError:\n            rhs_syms = set()\n        return lhs_syms | rhs_syms", "response": "Set of free SymPy symbols contained within the equation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bound_symbols(self):\n        try:\n            lhs_syms = self.lhs.bound_symbols\n        except AttributeError:\n            lhs_syms = set()\n        try:\n            rhs_syms = self.rhs.bound_symbols\n        except AttributeError:\n            rhs_syms = set()\n        return lhs_syms | rhs_syms", "response": "Set of bound SymPy symbols contained within the equation."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a matrix representing the ith eigenstate of an analytical Hilbert space.", "response": "def basis_state(i, n):\n    \"\"\"``n x 1`` `sympy.Matrix` representing the `i`'th eigenstate of an\n    `n`-dimensional Hilbert space (`i` >= 0)\"\"\"\n    v = sympy.zeros(n, 1)\n    v[i] = 1\n    return v"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert a QNET expression to an explicit n x n matrix.", "response": "def convert_to_sympy_matrix(expr, full_space=None):\n    \"\"\"Convert a QNET expression to an explicit ``n x n`` instance of\n    `sympy.Matrix`, where ``n`` is the dimension of `full_space`. The entries\n    of the matrix may contain symbols.\n\n    Parameters:\n        expr: a QNET expression\n        full_space (qnet.algebra.hilbert_space_algebra.HilbertSpace): The\n            Hilbert space in which `expr` is defined. If not given,\n            ``expr.space`` is used. The Hilbert space must have a well-defined\n            basis.\n\n    Raises:\n        qnet.algebra.hilbert_space_algebra.BasisNotSetError: if `full_space`\n            does not have a defined basis\n        ValueError: if `expr` is not in `full_space`, or if `expr` cannot be\n            converted.\n    \"\"\"\n    if full_space is None:\n        full_space = expr.space\n    if not expr.space.is_tensor_factor_of(full_space):\n        raise ValueError(\"expr must be in full_space\")\n    if expr is IdentityOperator:\n        return sympy.eye(full_space.dimension)\n    elif expr is ZeroOperator:\n        return 0\n    elif isinstance(expr, LocalOperator):\n        n = full_space.dimension\n        if full_space != expr.space:\n            all_spaces = full_space.local_factors\n            own_space_index = all_spaces.index(expr.space)\n            factors = [sympy.eye(s.dimension)\n                       for s in all_spaces[:own_space_index]]\n            factors.append(convert_to_sympy_matrix(expr, expr.space))\n            factors.extend([sympy.eye(s.dimension)\n                            for s in all_spaces[own_space_index + 1:]])\n            return tensor(*factors)\n        if isinstance(expr, (Create, Jz, Jplus)):\n            return SympyCreate(n)\n        elif isinstance(expr, (Destroy, Jminus)):\n            return SympyCreate(n).H\n        elif isinstance(expr, Phase):\n            phi = expr.phase\n            result = sympy.zeros(n)\n            for i in range(n):\n                result[i, i] = sympy.exp(sympy.I * i * phi)\n            return result\n        elif isinstance(expr, Displace):\n            alpha = expr.operands[1]\n            a = SympyCreate(n)\n            return (alpha * a - alpha.conjugate() * a.H).exp()\n        elif isinstance(expr, Squeeze):\n            eta = expr.operands[1]\n            a = SympyCreate(n)\n            return ((eta/2) * a**2 - (eta.conjugate()/2) * (a.H)**2).exp()\n        elif isinstance(expr, LocalSigma):\n            ket = basis_state(expr.index_j, n)\n            bra = basis_state(expr.index_k, n).H\n            return ket * bra\n        else:\n            raise ValueError(\"Cannot convert '%s' of type %s\"\n                             % (str(expr), type(expr)))\n    elif (isinstance(expr, Operator) and isinstance(expr, Operation)):\n        if isinstance(expr, OperatorPlus):\n            s = convert_to_sympy_matrix(expr.operands[0], full_space)\n            for op in expr.operands[1:]:\n                s += convert_to_sympy_matrix(op, full_space)\n            return s\n        elif isinstance(expr, OperatorTimes):\n            # if any factor acts non-locally, we need to expand distributively.\n            if any(len(op.space) > 1 for op in expr.operands):\n                se = expr.expand()\n                if se == expr:\n                    raise ValueError(\"Cannot represent as sympy matrix: %s\"\n                                     % expr)\n                return convert_to_sympy_matrix(se, full_space)\n            all_spaces = full_space.local_factors\n            by_space = []\n            ck = 0\n            for ls in all_spaces:\n                # group factors by associated local space\n                ls_ops = [convert_to_sympy_matrix(o, o.space)\n                          for o in expr.operands if o.space == ls]\n                if len(ls_ops):\n                    # compute factor associated with local space\n                    by_space.append(ls_ops[0])\n                    for ls_op in ls_ops[1:]:\n                        by_space[-1] *= ls_op\n                    ck += len(ls_ops)\n                else:\n                    # if trivial action, take identity matrix\n                    by_space.append(sympy.eye(ls.dimension))\n            assert ck == len(expr.operands)\n            # combine local factors in tensor product\n            if len(by_space) == 1:\n                return by_space[0]\n            else:\n                return tensor(*by_space)\n        elif isinstance(expr, Adjoint):\n            return convert_to_sympy_matrix(expr.operand, full_space).H\n        elif isinstance(expr, PseudoInverse):\n            raise NotImplementedError(\n                'Cannot convert PseudoInverse to sympy matrix')\n        elif isinstance(expr, NullSpaceProjector):\n            raise NotImplementedError(\n                'Cannot convert NullSpaceProjector to sympy')\n        elif isinstance(expr, ScalarTimesOperator):\n            return expr.coeff * convert_to_sympy_matrix(expr.term, full_space)\n        else:\n            raise ValueError(\n                \"Cannot convert '%s' of type %s\" % (str(expr), type(expr)))\n    else:\n        raise ValueError(\n            \"Cannot convert '%s' of type %s\" % (str(expr), type(expr)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef formfield_for_dbfield(self, db_field, **kwargs):\n        overrides = self.formfield_overrides.get(db_field.name)\n        if overrides:\n            kwargs.update(overrides)\n\n        field = super(AbstractEntryBaseAdmin, self).formfield_for_dbfield(db_field, **kwargs)\n\n        # Pass user to the form.\n        if db_field.name == 'author':\n            field.user = kwargs['request'].user\n        return field", "response": "Override the default formfield_for_dbfield method to pass the user to the form."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator that yields tuples of items from the input iterable.", "response": "def product(*generators, repeat=1):\n    \"\"\"Cartesian product akin to :func:`itertools.product`, but accepting\n    generator functions\n\n    Unlike :func:`itertools.product` this function does not convert the input\n    iterables into tuples. Thus, it can handle large or infinite inputs. As a\n    drawback, however, it only works with \"restartable\" iterables (something\n    that :func:`iter` can repeatably turn into an iterator, or a generator\n    function (but not the generator iterator that is returned by that\n    generator function)\n\n    Args:\n        generators: list of restartable iterators or generator functions\n        repeat: number of times `generators` should be repeated\n\n    Adapted from https://stackoverflow.com/q/12093364/\n    \"\"\"\n    if len(generators) == 0:\n        yield ()\n    else:\n        generators = generators * repeat\n        it = generators[0]\n        for item in it() if callable(it) else iter(it):\n            for items in product(*generators[1:]):\n                yield (item, ) + items"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a copy of the index with an incremented : attr : primed.", "response": "def incr_primed(self, incr=1):\n        \"\"\"Return a copy of the index with an incremented :attr:`primed`\"\"\"\n        return self.__class__(\n            self.name, primed=self._primed + incr,\n            **self._assumptions.generator)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef temporary_instance_cache(*classes):\n    orig_instances = []\n    for cls in classes:\n        orig_instances.append(cls._instances)\n        cls._instances = {}\n    try:\n        yield\n    finally:\n        for i, cls in enumerate(classes):\n            cls._instances = orig_instances[i]", "response": "Use a temporary cache for instances in managed\n    classes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing temporary modification of rules for :meth:`~.Expression.create` For every one of the given `classes`, protect the rules (processed by :func:`.match_replace` or :func:`.match_replace_binary`) associated with that class from modification beyond the managed context. Implies :func:`temporary_instance_cache`. If `clear` is given as True, all existing rules are temporarily cleared from the given classes on entering the managed context. Within the managed context, :meth:`~.Expression.add_rule` may be used for any class in `classes` to define local rules, or :meth:`~.Expression.del_rules` to disable specific existing rules (assuming `clear` is False). Upon leaving the managed context all original rules will be restored, removing any local rules. The `classes`' :obj:`simplifications <.Expression>` attribute is also protected from permanent modification. Locally modifying :obj:`simplifications <.Expression>` should be done with care, but allows complete control over the creation of expressions.", "response": "def temporary_rules(*classes, clear=False):\n    \"\"\"Allow temporary modification of rules for :meth:`~.Expression.create`\n\n    For every one of the given `classes`, protect the rules (processed by\n    :func:`.match_replace` or :func:`.match_replace_binary`) associated with\n    that class from modification beyond the managed context.\n    Implies :func:`temporary_instance_cache`. If `clear` is given as\n    True, all existing rules are temporarily cleared from the given classes on\n    entering the managed context.\n\n    Within the managed context, :meth:`~.Expression.add_rule` may be used for\n    any class in `classes` to define local rules, or\n    :meth:`~.Expression.del_rules` to disable specific existing rules (assuming\n    `clear` is False). Upon leaving the managed context all original rules will\n    be restored, removing any local rules.\n\n    The `classes`' :obj:`simplifications <.Expression>` attribute is also\n    protected from permanent modification. Locally modifying\n    :obj:`simplifications <.Expression>` should be done with care, but allows\n    complete control over the creation of expressions.\n    \"\"\"\n    orig_instances = []\n    orig_rules = []\n    orig_binary_rules = []\n    orig_simplifications = []\n\n    for cls in classes:\n        orig_instances.append(cls._instances)\n        cls._instances = {}\n        orig_simplifications.append(cls.simplifications)\n        cls.simplifications = cls.simplifications.copy()\n        try:\n            orig_rules.append(cls._rules)\n            if clear:\n                cls._rules = OrderedDict([])\n            else:\n                cls._rules = cls._rules.copy()\n        except AttributeError:\n            orig_rules.append(None)\n        try:\n            orig_binary_rules.append(cls._binary_rules)\n            if clear:\n                cls._binary_rules = OrderedDict([])\n            else:\n                cls._binary_rules = cls._binary_rules.copy()\n        except AttributeError:\n            orig_binary_rules.append(None)\n\n    try:\n        yield\n    finally:\n        for i, cls in enumerate(classes):\n            cls._instances = orig_instances[i]\n            cls.simplifications = orig_simplifications[i]\n            if orig_rules[i] is not None:\n                cls._rules = orig_rules[i]\n            if orig_binary_rules[i] is not None:\n                cls._binary_rules = orig_binary_rules[i]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _split_identifier(self, identifier):\n        try:\n            name, subscript = identifier.split(\"_\", 1)\n        except (TypeError, ValueError, AttributeError):\n            name = identifier\n            subscript = ''\n        return self._render_str(name), self._render_str(subscript)", "response": "Split the given identifier at the first underscore into name and subscript. Both name and subscript are rendered as\n        strings."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit an operator into name total subscript total superscript and arguments str.", "response": "def _split_op(\n            self, identifier, hs_label=None, dagger=False, args=None):\n        \"\"\"Return `name`, total `subscript`, total `superscript` and\n        `arguments` str. All of the returned strings are fully rendered.\n\n        Args:\n            identifier (str or SymbolicLabelBase): A (non-rendered/ascii)\n                identifier that may include a subscript. The output `name` will\n                be the `identifier` without any subscript\n            hs_label (str): The rendered label for the Hilbert space of the\n                operator, or None. Returned unchanged.\n            dagger (bool): Flag to indicate whether the operator is daggered.\n                If True, :attr:`dagger_sym` will be included in the\n                `superscript` (or  `subscript`, depending on the settings)\n            args (list or None): List of arguments (expressions). Each element\n                will be rendered with :meth:`doprint`. The total list of args\n                will then be joined with commas, enclosed\n                with :attr:`_parenth_left` and :attr:`parenth_right`, and\n                returnd as the `arguments` string\n        \"\"\"\n        if self._isinstance(identifier, 'SymbolicLabelBase'):\n            identifier = QnetAsciiDefaultPrinter()._print_SCALAR_TYPES(\n                identifier.expr)\n        name, total_subscript = self._split_identifier(identifier)\n        total_superscript = ''\n        if (hs_label not in [None, '']):\n            if self._settings['show_hs_label'] == 'subscript':\n                if len(total_subscript) == 0:\n                    total_subscript = '(' + hs_label + ')'\n                else:\n                    total_subscript += ',(' + hs_label + ')'\n            else:\n                total_superscript += '(' + hs_label + ')'\n        if dagger:\n            total_superscript += self._dagger_sym\n        args_str = ''\n        if (args is not None) and (len(args) > 0):\n            args_str = (self._parenth_left +\n                        \",\".join([self.doprint(arg) for arg in args]) +\n                        self._parenth_right)\n        return name, total_subscript, total_superscript, args_str"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _render_hs_label(self, hs):\n        if isinstance(hs.__class__, Singleton):\n            return self._render_str(hs.label)\n        else:\n            return self._tensor_sym.join(\n                [self._render_str(ls.label) for ls in hs.local_factors])", "response": "Return the label of the given Hilbert space as a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a format string for printing an expr_type", "response": "def _braket_fmt(self, expr_type):\n        \"\"\"Return a format string for printing an `expr_type`\n        ket/bra/ketbra/braket\"\"\"\n        mapping = {\n            'bra': {\n                True: '<{label}|^({space})',\n                'subscript': '<{label}|_({space})',\n                False:  '<{label}|'},\n            'ket': {\n                True: '|{label}>^({space})',\n                'subscript': '|{label}>_({space})',\n                False:  '|{label}>'},\n            'ketbra': {\n                True: '|{label_i}><{label_j}|^({space})',\n                'subscript': '|{label_i}><{label_j}|_({space})',\n                False:  '|{label_i}><{label_j}|'},\n            'braket': {\n                True: '<{label_i}|{label_j}>^({space})',\n                'subscript': '<{label_i}|{label_j}>_({space})',\n                False:  '<{label_i}|{label_j}>'},\n        }\n        hs_setting = bool(self._settings['show_hs_label'])\n        if self._settings['show_hs_label'] == 'subscript':\n            hs_setting = 'subscript'\n        return mapping[expr_type][hs_setting]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender an operator Args: identifier (str or SymbolicLabelBase): The identifier (name/symbol) of the operator. May include a subscript, denoted by '_'. hs (qnet.algebra.hilbert_space_algebra.HilbertSpace): The Hilbert space in which the operator is defined dagger (bool): Whether the operator should be daggered args (list): A list of expressions that will be rendered with :meth:`doprint`, joined with commas, enclosed in parenthesis superop (bool): Whether the operator is a super-operator", "response": "def _render_op(\n            self, identifier, hs=None, dagger=False, args=None, superop=False):\n        \"\"\"Render an operator\n\n        Args:\n            identifier (str or SymbolicLabelBase): The identifier (name/symbol)\n                of the operator. May include a subscript, denoted by '_'.\n            hs (qnet.algebra.hilbert_space_algebra.HilbertSpace): The Hilbert\n                space in which the operator is defined\n            dagger (bool): Whether the operator should be daggered\n            args (list): A list of expressions that will be rendered with\n                :meth:`doprint`, joined with commas, enclosed in parenthesis\n            superop (bool): Whether the operator is a super-operator\n        \"\"\"\n        hs_label = None\n        if hs is not None and self._settings['show_hs_label']:\n            hs_label = self._render_hs_label(hs)\n        name, total_subscript, total_superscript, args_str \\\n            = self._split_op(identifier, hs_label, dagger, args)\n        res = name\n        if len(total_subscript) > 0:\n            res += \"_\" + total_subscript\n        if len(total_superscript) > 0:\n            res += \"^\" + total_superscript\n        if len(args_str) > 0:\n            res += args_str\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parenthesize(self, expr, level, *args, strict=False, **kwargs):\n        needs_parenths = (\n            (precedence(expr) < level) or\n            (strict and precedence(expr) == level))\n        if needs_parenths:\n            return (\n                self._parenth_left + self.doprint(expr, *args, **kwargs) +\n                self._parenth_right)\n        else:\n            return self.doprint(expr, *args, **kwargs)", "response": "Render expr and wrap the result in parentheses if the precedence of expr is below the given level or at the given level."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _curve(x1, y1, x2, y2, hunit = HUNIT, vunit = VUNIT):\n    ax1, ax2, axm = x1 * hunit, x2 * hunit, (x1 + x2) * hunit / 2\n    ay1, ay2 = y1 * vunit, y2 * vunit\n    return pyx.path.curve(ax1, ay1, axm, ay1, axm, ay2, ax2, ay2)", "response": "Return a PyX curved path from x1 y1 x2 y2"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef draw_circuit_canvas(circuit, hunit = HUNIT, vunit = VUNIT, rhmargin = RHMARGIN, rvmargin = RVMARGIN, rpermutation_length = RPLENGTH, draw_boxes = True, permutation_arrows = False):\n\n    if not isinstance(circuit, ca.Circuit):\n        raise ValueError()\n\n    nc = circuit.cdim\n    c = pyx.canvas.canvas()\n\n\n    if circuit is ca.CIdentity:\n        # simply create a line going through\n        c.stroke(pyx.path.line(0, vunit/2, hunit, vunit/2))\n        return c, (1, 1), (.5,), (.5,)\n\n    elif isinstance(circuit, (ca.CircuitSymbol, ca.SeriesInverse, ca.SLH, Component)):\n        # draw box\n        b = pyx.path.rect(rhmargin * hunit, rvmargin * vunit, hunit - 2 * rhmargin * hunit, nc * vunit - 2 * rvmargin * vunit)\n        c.stroke(b)\n\n        texstr = \"${}$\".format(tex(circuit) if not isinstance(circuit, ca.SLH) else r\"{{\\rm SLH}}_{{{}}}\".format(tex(circuit.space)))\n\n        # draw symbol name\n        c.text(hunit/2., nc * vunit/2., texstr , [pyx.text.halign.boxcenter, pyx.text.valign.middle])\n\n        # draw connectors at half-unit positions\n        connector_positions = tuple((.5 + k) for k in range(nc))\n        for y in connector_positions:\n            c.stroke(pyx.path.line(0, y * vunit, rhmargin * hunit, y * vunit), [pyx.deco.earrow()])\n            c.stroke(pyx.path.line(hunit * (1 - rhmargin), y * vunit, hunit, y * vunit))\n\n        return c, (1, nc), connector_positions, connector_positions\n\n    elif isinstance(circuit, ca.CPermutation):\n        permutation = circuit.permutation\n\n        connector_positions = tuple((k + 0.5) for k in range(nc))\n        target_positions = [connector_positions[permutation[k]] for k in range(nc)]\n\n        # draw curves\n        for y1, y2 in zip(connector_positions, target_positions):\n            if permutation_arrows:\n                c.stroke(_curve(0, y1, rpermutation_length, y2, hunit = hunit, vunit = vunit), [pyx.deco.earrow()])\n            else:\n                c.stroke(_curve(0, y1, rpermutation_length, y2, hunit = hunit, vunit = vunit))\n\n        if draw_boxes:\n            b = pyx.path.rect(.5* rhmargin * hunit, .5* rvmargin * vunit, rpermutation_length * hunit -  rhmargin * hunit, nc * vunit -  rvmargin * vunit)\n            c.stroke(b, [pyx.style.linewidth.thin, pyx.style.linestyle.dashed, pyx.color.rgb.green])\n\n\n        return c, (rpermutation_length, nc), connector_positions, connector_positions\n\n    elif isinstance(circuit, ca.SeriesProduct):\n        assert len(circuit.operands) > 1\n\n        # generate graphics of operad subsystems\n        sub_graphics = [draw_circuit_canvas(op, hunit = hunit,\n                                        vunit = vunit, rhmargin = rhmargin,\n                                        rvmargin = rvmargin,\n                                        rpermutation_length = rpermutation_length,\n                                        draw_boxes = draw_boxes,\n                                        permutation_arrows = permutation_arrows) for op in reversed(circuit.operands)]\n\n        # set up first one\n        previous_csub, previous_dims, previous_c_in, previous_c_out = sub_graphics[0]\n        hoffset = 0\n        c.insert(previous_csub)\n        hoffset += previous_dims[0]\n\n        max_height = previous_dims[1]\n\n        # this will later become the full series in-port coordinate tuple\n        first_c_in = previous_c_in\n\n        # now add all other operand subsystems\n        for csub, dims, c_in, c_out in sub_graphics[1:]:\n            assert dims[1] >= 0\n\n            max_height = max(dims[1], max_height)\n\n            if previous_c_out != c_in: # vertical port locations don't agree, map signals correspondingly\n\n                x1 = hoffset\n                x2 = hoffset + rpermutation_length\n\n                # draw connection curves\n                for y1, y2 in zip(previous_c_out, c_in):\n                    c.stroke(_curve(x1, y1, x2, y2, hunit = hunit, vunit = vunit))\n\n                hoffset += rpermutation_length\n\n            previous_c_in, previous_c_out = c_in, c_out\n\n            # now insert current system\n            c.insert(csub, [pyx.trafo.translate(hunit * hoffset, 0)])\n            hoffset += dims[0]\n        if draw_boxes:\n            b = pyx.path.rect(.5 * rhmargin * hunit, .5 * rvmargin * vunit, hoffset * hunit - 1. * rhmargin * hunit, max_height * vunit +  rvmargin * vunit)\n            c.stroke(b, [pyx.style.linewidth.thin, pyx.style.linestyle.dashed, pyx.color.rgb.red])\n\n\n        return c, (hoffset, max_height), first_c_in, c_out\n\n    elif isinstance(circuit, ca.Concatenation):\n\n        voffset = 0\n        total_cin, total_cout = (), ()\n        widths = [] # stores the component width for each channel(!)\n\n        # generate all operand subsystem graphics and stack them vertically\n        for op in circuit.operands:\n            csub, dims, c_in, c_out = draw_circuit_canvas(op, hunit = hunit,\n                                                    vunit = vunit, rhmargin = rhmargin,\n                                                    rvmargin = rvmargin,\n                                                    rpermutation_length = rpermutation_length,\n                                                    draw_boxes = draw_boxes,\n                                                    permutation_arrows = permutation_arrows)\n\n            # add appropriatly offsets to vertical port coordinates\n            total_cin += tuple(y + voffset for y in c_in)\n            total_cout += tuple(y + voffset for y in c_out)\n\n\n            c.insert(csub, [pyx.trafo.translate(0, vunit * voffset)])\n\n            # keep track of width in all channel for this subsystem\n            widths += [dims[0]] * op.cdim\n\n            voffset += dims[1]\n\n        max_width = max(widths)\n\n        if max_width > min(widths): # components differ in width => we must extend the narrow component output lines\n\n            for x,y in zip(widths, total_cout):\n                if x == max_width:\n                    continue\n\n\n                ax, ax_to = x * hunit, max_width * hunit\n                ay = y * vunit\n                c.stroke(pyx.path.line(ax, ay, ax_to, ay))\n\n        if draw_boxes:\n            b = pyx.path.rect(.5 * rhmargin * hunit, .5 * rvmargin * vunit, max_width * hunit - 1. * rhmargin * hunit, voffset * vunit -  rvmargin * vunit)\n            c.stroke(b, [pyx.style.linewidth.thin, pyx.style.linestyle.dashed, pyx.color.rgb.blue])\n\n        return c, (max_width, voffset), total_cin, total_cout\n\n    elif isinstance(circuit, ca.Feedback):\n\n        # generate and insert graphics of subsystem\n        csub, dims, c_in, c_out = draw_circuit_canvas(circuit.operand, hunit = hunit,\n                                                vunit = vunit, rhmargin = rhmargin,\n                                                rvmargin = rvmargin,\n                                                rpermutation_length = rpermutation_length,\n                                                draw_boxes = draw_boxes,\n                                                permutation_arrows = permutation_arrows)\n\n        c.insert(csub, [pyx.trafo.translate(hunit * .5 * rhmargin, 0)])\n        width, height = dims\n\n        # create feedback loop\n        fb_out, fb_in = circuit.out_in_pair\n        out_coords = (width + .5 * rhmargin) * hunit, c_out[fb_out] * vunit\n        in_coords = .5 * rhmargin * hunit, c_in[fb_in] * vunit\n        upper_y = (height) * vunit\n        feedback_line = pyx.path.path(pyx.path.moveto(*out_coords), pyx.path.lineto(out_coords[0], upper_y),\n                                        pyx.path.lineto(in_coords[0], upper_y), pyx.path.lineto(*in_coords))\n        c.stroke(feedback_line)\n\n        # remove feedback port coordinates\n        new_c_in = c_in[:fb_in] + c_in[fb_in + 1 :]\n        new_c_out = c_out[:fb_out] + c_out[fb_out + 1 :]\n\n        # extend port connectors a little bit outward,\n        # such that the feedback loop is not at the edge anymore\n        for y in new_c_in:\n            c.stroke(pyx.path.line(0, y * vunit, .5 * rhmargin * hunit, y * vunit))\n\n        for y in new_c_out:\n            c.stroke(pyx.path.line((width + .5 * rhmargin) * hunit, y * vunit, (width + rhmargin) * hunit, y * vunit))\n\n        return c, (width + rhmargin, height + rvmargin), new_c_in, new_c_out\n\n    raise Exception('Visualization not implemented for type %s' % type(circuit))", "response": "Generates a PyX canvas object that can be further manipulated or printed to an output image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw_circuit(circuit, filename, direction = 'lr',\n            hunit = HUNIT, vunit = VUNIT,\n            rhmargin = RHMARGIN, rvmargin = RVMARGIN,\n            rpermutation_length = RPLENGTH,\n            draw_boxes = True,\n            permutation_arrows = False):\n    \"\"\"\n    Generate a graphic representation of circuit and store them in a file.\n    The graphics format is determined from the file extension.\n\n    :param circuit: The circuit expression\n    :type circuit: ca.Circuit\n    :param filename: A filepath to store the output image under. The file name suffix determines the output graphics format\n    :type filename: str\n    :param direction: The horizontal direction of laying out series products. One of ``'lr'`` and ``'rl'``. This option overrides a negative value for ``hunit``,\n     default = ``'lr'``\n    :param hunit: The horizontal length unit, default = ``HUNIT``\n    :type hunit: float\n    :param vunit: The vertical length unit, default = ``VUNIT``\n    :type vunit: float\n    :param rhmargin: relative horizontal margin, default = ``RHMARGIN``\n    :type rhmargin: float\n    :param rvmargin: relative vertical margin, default = ``RVMARGIN``\n    :type rvmargin: float\n    :param rpermutation_length: the relative length of a permutation circuit, default = ``RPLENGTH``\n    :type rpermutation_length: float\n    :param draw_boxes: Whether to draw indicator boxes to denote subexpressions (Concatenation, SeriesProduct, etc.), default = ``True``\n    :type draw_boxes: bool\n    :param permutation_arrows: Whether to draw arrows within the permutation visualization, default = ``False``\n    :type permutation_arrows: bool\n    :return: ``True`` if printing was successful, ``False`` if not.\n    :rtype: bool\n    \"\"\"\n\n\n    if direction == 'lr':\n        hunit = abs(hunit)\n\n    elif direction == 'rl':\n        hunit = -abs(hunit)\n    try:\n        c, dims, c_in, c_out = draw_circuit_canvas(circuit, hunit = hunit, vunit = vunit,\n                                            rhmargin = rhmargin, rvmargin = rvmargin,\n                                            rpermutation_length = rpermutation_length,\n                                            draw_boxes = draw_boxes,\n                                            permutation_arrows = permutation_arrows)\n    except ValueError as e:\n        print( (\"No graphics returned for circuit {!r}\".format(circuit)))\n        return False\n    ps_suffixes = ['.pdf', '.eps', '.ps']\n    gs_suffixes = ['.png', '.jpg']\n    if any(filename.endswith(suffix) for suffix in ps_suffixes):\n        c.writetofile(filename)\n    elif any(filename.endswith(suffix) for suffix in gs_suffixes):\n        if GS is None:\n            raise FileNotFoundError(\n                \"No Ghostscript executable available. Ghostscript is required for \"\n                \"rendering to {}.\".format(\", \".join(gs_suffixes))\n            )\n        c.writeGSfile(filename, gs=GS)\n    return True", "response": "This function generates a graphic representation of a circuit and stores it in a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the precedence of a given object.", "response": "def precedence(item):\n    \"\"\"Returns the precedence of a given object.\"\"\"\n    try:\n        mro = item.__class__.__mro__\n    except AttributeError:\n        return PRECEDENCE[\"Atom\"]\n    for i in mro:\n        n = i.__name__\n        if n in PRECEDENCE_FUNCTIONS:\n            return PRECEDENCE_FUNCTIONS[n](item)\n        elif n in PRECEDENCE_VALUES:\n            return PRECEDENCE_VALUES[n]\n    return PRECEDENCE[\"Atom\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrenders the data in HTML template.", "response": "def render(self,\n               data,\n               chart_type,\n               chart_package='corechart',\n               options=None,\n               div_id=\"chart\",\n               head=\"\"):\n        \"\"\"Render the data in HTML template.\"\"\"\n        if not self.is_valid_name(div_id):\n            raise ValueError(\n                \"Name {} is invalid. Only letters, numbers, '_', and '-' are permitted \".format(\n                    div_id))\n\n        return Template(head + self.template).render(\n            div_id=div_id.replace(\" \", \"_\"),\n            data=json.dumps(\n                data, indent=4).replace(\"'\", \"\\\\'\").replace('\"', \"'\"),\n            chart_type=chart_type,\n            chart_package=chart_package,\n            options=json.dumps(\n                options, indent=4).replace(\"'\", \"\\\\'\").replace('\"', \"'\"))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noutput an iframe containing the plot in the notebook without saving.", "response": "def plot(self,\n             data,\n             chart_type,\n             chart_package='corechart',\n             options=None,\n             w=800,\n             h=420):\n        \"\"\"Output an iframe containing the plot in the notebook without saving.\"\"\"\n        return HTML(\n            self.iframe.format(\n                source=self.render(\n                    data=data,\n                    options=options,\n                    chart_type=chart_type,\n                    chart_package=chart_package,\n                    head=self.head),\n                w=w,\n                h=h))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef callback_prototype(prototype):\n    protosig = signature(prototype)\n    positional, keyword = [], []\n    for name, param in protosig.parameters.items():\n        if param.kind in (Parameter.VAR_POSITIONAL, Parameter.VAR_KEYWORD):\n            raise TypeError(\"*args/**kwargs not supported in prototypes\")\n\n        if (param.default is not Parameter.empty) \\\n            or (param.kind == Parameter.KEYWORD_ONLY):\n            keyword.append(name)\n        else:\n            positional.append(name)\n        \n    kwargs = dict.fromkeys(keyword)\n    def adapt(callback):\n        \"\"\"Introspect and prepare a third party callback.\"\"\"\n        sig = signature(callback)\n        try:\n            # XXX: callback can have extra optional parameters - OK?\n            sig.bind(*positional, **kwargs)\n            return callback\n        except TypeError:\n            pass\n        \n        # Match up arguments\n        unmatched_pos = positional[:]\n        unmatched_kw = kwargs.copy()\n        unrecognised = []\n        # TODO: unrecognised parameters with default values - OK?\n        for name, param in sig.parameters.items():\n            # print(name, param.kind) #DBG\n            if param.kind == Parameter.POSITIONAL_ONLY:\n                if len(unmatched_pos) > 0:\n                    unmatched_pos.pop(0)\n                else:\n                    unrecognised.append(name)\n            elif param.kind == Parameter.POSITIONAL_OR_KEYWORD:\n                if (param.default is not Parameter.empty) and (name in unmatched_kw):\n                    unmatched_kw.pop(name)\n                elif len(unmatched_pos) > 0:\n                    unmatched_pos.pop(0)    \n                else:\n                    unrecognised.append(name)\n            elif param.kind == Parameter.VAR_POSITIONAL:\n                unmatched_pos = []\n            elif param.kind == Parameter.KEYWORD_ONLY:\n                if name in unmatched_kw:\n                    unmatched_kw.pop(name)\n                else:\n                    unrecognised.append(name)\n            else:  # VAR_KEYWORD\n                unmatched_kw = {}\n        \n            # print(unmatched_pos, unmatched_kw, unrecognised) #DBG\n        \n        if unrecognised:\n            raise TypeError(\"Function {!r} had unmatched arguments: {}\".format(callback, unrecognised))\n\n        n_positional = len(positional) - len(unmatched_pos)\n\n        @wraps(callback)\n        def adapted(*args, **kwargs):\n            \"\"\"Wrapper for third party callbacks that discards excess arguments\"\"\"\n#            print(args, kwargs)\n            args = args[:n_positional]\n            for name in unmatched_kw:\n                # XXX: Could name not be in kwargs?\n                kwargs.pop(name)\n#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\n            return callback(*args, **kwargs)\n        \n        return adapted\n\n    prototype.adapt = adapt\n    return prototype", "response": "Decorator to process a callback prototype."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning only published entries for the current site.", "response": "def published(self, for_user=None):\n        \"\"\"\n        Return only published entries for the current site.\n        \"\"\"\n        if appsettings.FLUENT_BLOGS_FILTER_SITE_ID:\n            qs = self.parent_site(settings.SITE_ID)\n        else:\n            qs = self\n\n        if for_user is not None and for_user.is_staff:\n            return qs\n\n        return qs \\\n            .filter(status=self.model.PUBLISHED) \\\n            .filter(\n                Q(publication_date__isnull=True) |\n                Q(publication_date__lte=now())\n            ).filter(\n                Q(publication_end_date__isnull=True) |\n                Q(publication_end_date__gte=now())\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the entries written by the given usernames", "response": "def authors(self, *usernames):\n        \"\"\"\n        Return the entries written by the given usernames\n        When multiple tags are provided, they operate as \"OR\" query.\n        \"\"\"\n        if len(usernames) == 1:\n            return self.filter(**{\"author__{}\".format(User.USERNAME_FIELD): usernames[0]})\n        else:\n            return self.filter(**{\"author__{}__in\".format(User.USERNAME_FIELD): usernames})"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the entries with the given category slugs.", "response": "def categories(self, *category_slugs):\n        \"\"\"\n        Return the entries with the given category slugs.\n        When multiple tags are provided, they operate as \"OR\" query.\n        \"\"\"\n        categories_field = getattr(self.model, 'categories', None)\n        if categories_field is None:\n            raise AttributeError(\"The {0} does not include CategoriesEntryMixin\".format(self.model.__name__))\n\n        if issubclass(categories_field.rel.model, TranslatableModel):\n            # Needs a different field, assume slug is translated (e.g django-categories-i18n)\n            filters = {\n                'categories__translations__slug__in': category_slugs,\n            }\n\n            # TODO: should the current language also be used as filter somehow?\n            languages = self._get_active_rel_languages()\n            if languages:\n                if len(languages) == 1:\n                    filters['categories__translations__language_code'] = languages[0]\n                else:\n                    filters['categories__translations__language_code__in'] = languages\n\n            return self.filter(**filters).distinct()\n        else:\n            return self.filter(categories__slug=category_slugs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the items which are tagged with a specific tag.", "response": "def tagged(self, *tag_slugs):\n        \"\"\"\n        Return the items which are tagged with a specific tag.\n        When multiple tags are provided, they operate as \"OR\" query.\n        \"\"\"\n        if getattr(self.model, 'tags', None) is None:\n            raise AttributeError(\"The {0} does not include TagsEntryMixin\".format(self.model.__name__))\n\n        if len(tag_slugs) == 1:\n            return self.filter(tags__slug=tag_slugs[0])\n        else:\n            return self.filter(tags__slug__in=tag_slugs).distinct()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports all available submodules and adds them to the internal list of all available submodules.", "response": "def _import_submodules(\n        __all__, __path__, __name__, include=None, exclude=None,\n        include_private_modules=False, require__all__=True, recursive=True):\n    \"\"\"\n    Import all available submodules, all objects defined in the `__all__` lists\n    of those submodules, and extend `__all__` with the imported objects.\n\n    Args:\n        __all__ (list): The list of public objects in the \"root\" module\n        __path__ (str): The path where the ``__init__.py`` file for the \"root\"\n            module is located in the file system (every module has a global\n            `__path__` variable which should be passed here)\n        __name__ (str): The full name of the \"root\" module. Again, every module\n            has a global `__name__` variable.\n        include (list or None): If not None, list of full module names to be\n            included. That is, every module not in the `include` list is\n            ignored\n        exclude (list or None): List of full module names to be\n            excluded from the (recursive) input\n        include_private_modules (bool): Whether to include modules whose name\n            starts with an underscore\n        recursive (bool): Whether to recursively act on submodules of the\n            \"root\" module. This will make sub-submodules available both in the\n            submodule, and in the \"root\" module\n    \"\"\"\n    mod = sys.modules[__name__]\n    if exclude is None:\n        exclude = []\n    for (_, submodname, ispkg) in pkgutil.iter_modules(path=__path__):\n        if submodname.startswith('_') and not include_private_modules:\n            continue\n        submod = importlib.import_module('.' + submodname, __name__)\n        if submod.__name__ in exclude:\n            continue\n        if include is not None:\n            if submod.__name__ not in include:\n                continue\n        if not hasattr(submod, '__all__'):\n            setattr(submod, '__all__', [])\n        if recursive and ispkg:\n            _import_submodules(\n                submod.__all__, submod.__path__, submod.__name__)\n        setattr(mod, submodname, submod)\n        for obj_name in submod.__all__:\n            obj = getattr(submod, obj_name)\n            if hasattr(mod, obj_name):\n                existing_obj = getattr(mod, obj_name)\n                if existing_obj is obj:\n                    continue\n                else:\n                    raise ImportError(\n                        \"{mod}.{attr} points to {submod1}.{attr}. \"\n                        \"Cannot set to {submod2}.{attr}\".format(\n                            mod=mod.__name__, attr=obj_name,\n                            submod1=existing_obj.__module__,\n                            submod2=obj.__module__))\n            setattr(mod, obj_name, obj)\n            __all__.append(obj_name)\n    __all__.sort()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nformats and combine the name subscript and superscript", "response": "def format(self, **kwargs):\n        \"\"\"Format and combine the name, subscript, and superscript\"\"\"\n        name = self.name.format(**kwargs)\n\n        subs = []\n        if self.sub is not None:\n            subs = [self.sub.format(**kwargs)]\n        supers = []\n        if self.sup is not None:\n            supers = [self.sup.format(**kwargs)]\n\n        return render_unicode_sub_super(\n            name, subs, supers, sub_first=True, translate_symbols=True,\n            unicode_sub_super=self.unicode_sub_super)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _render_str(self, string):\n        if isinstance(string, StrLabel):\n            string = string._render(string.expr)\n        string = str(string)\n        if len(string) == 0:\n            return ''\n        name, supers, subs = split_super_sub(string)\n        return render_unicode_sub_super(\n            name, subs, supers, sub_first=True, translate_symbols=True,\n            unicode_sub_super=self._settings['unicode_sub_super'])", "response": "Returns a unicodified version of the string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a format string for printing an expression type.", "response": "def _braket_fmt(self, expr_type):\n        \"\"\"Return a format string for printing an `expr_type`\n        ket/bra/ketbra/braket\"\"\"\n        if self._settings['unicode_sub_super']:\n            sub_sup_fmt = SubSupFmt\n        else:\n            sub_sup_fmt = SubSupFmtNoUni\n        mapping = {\n            'bra': {\n                True: sub_sup_fmt('\u27e8{label}|', sup='({space})'),\n                'subscript': sub_sup_fmt('\u27e8{label}|', sub='({space})'),\n                False:  sub_sup_fmt('\u27e8{label}|')},\n            'ket': {\n                True: sub_sup_fmt('|{label}\u27e9', sup='({space})'),\n                'subscript': sub_sup_fmt('|{label}\u27e9', sub='({space})'),\n                False:  sub_sup_fmt('|{label}\u27e9')},\n            'ketbra': {\n                True: sub_sup_fmt('|{label_i}\u27e9\u27e8{label_j}|', sup='({space})'),\n                'subscript': sub_sup_fmt(\n                    '|{label_i}\u27e9\u27e8{label_j}|', sub='({space})'),\n                False:  sub_sup_fmt('|{label_i}\u27e9\u27e8{label_j}|')},\n            'braket': {\n                True: sub_sup_fmt('\u27e8{label_i}|{label_j}\u27e9', sup='({space})'),\n                'subscript': sub_sup_fmt(\n                    '\u27e8{label_i}|{label_j}\u27e9', sub='({space})'),\n                False:  sub_sup_fmt('\u27e8{label_i}|{label_j}\u27e9')},\n        }\n        hs_setting = bool(self._settings['show_hs_label'])\n        if self._settings['show_hs_label'] == 'subscript':\n            hs_setting = 'subscript'\n        return mapping[expr_type][hs_setting]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _render_op(\n            self, identifier, hs=None, dagger=False, args=None, superop=False):\n        \"\"\"Render an operator\n\n        Args:\n            identifier (str or SymbolicLabelBase): The identifier (name/symbol)\n                of the operator. May include a subscript, denoted by '_'.\n            hs (HilbertSpace): The Hilbert space in which the operator is\n                defined\n            dagger (bool): Whether the operator should be daggered\n            args (list): A list of expressions that will be rendered with\n                :meth:`doprint`, joined with commas, enclosed in parenthesis\n            superop (bool): Whether the operator is a super-operator\n        \"\"\"\n        hs_label = None\n        if hs is not None and self._settings['show_hs_label']:\n            hs_label = self._render_hs_label(hs)\n        name, total_subscript, total_superscript, args_str \\\n            = self._split_op(identifier, hs_label, dagger, args)\n        if self._settings['unicode_op_hats'] and len(name) == 1:\n            if superop:\n                res = name\n            else:\n                res = modifier_dict['hat'](name)\n        else:\n            res = name\n        res = render_unicode_sub_super(\n            res, [total_subscript], [total_superscript], sub_first=True,\n            translate_symbols=True,\n            unicode_sub_super=self._settings['unicode_sub_super'])\n        res += args_str\n        return res", "response": "Render an operator\n\n        Args:\n            identifier (str or SymbolicLabelBase): The identifier (name/symbol)\n                of the operator. May include a subscript, denoted by '_'.\n            hs (HilbertSpace): The Hilbert space in which the operator is\n                defined\n            dagger (bool): Whether the operator should be daggered\n            args (list): A list of expressions that will be rendered with\n                :meth:`doprint`, joined with commas, enclosed in parenthesis\n            superop (bool): Whether the operator is a super-operator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef PauliX(local_space, states=None):\n    local_space, states = _get_pauli_args(local_space, states)\n    g, e = states\n    return (\n        LocalSigma.create(g, e, hs=local_space) +\n        LocalSigma.create(e, g, hs=local_space))", "response": "r A Pauli - type X - operator that creates a new Pauli - type X - operator on an arbitrary two - level system."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_head_repr(\n        expr: Any, sub_render=None, key_sub_render=None) -> str:\n    \"\"\"Render a textual representation of `expr` using\n    Positional and keyword arguments are recursively\n    rendered using `sub_render`, which defaults to `render_head_repr` by\n    default.  If desired, a different renderer may be used for keyword\n    arguments by giving `key_sub_renderer`\n\n    Raises:\n        AttributeError: if `expr` is not an instance of\n            :class:`Expression`, or more specifically, if `expr` does not\n            have `args` and `kwargs` (respectively `minimal_kwargs`)\n            properties\n    \"\"\"\n    head_repr_fmt = r'{head}({args}{kwargs})'\n    if sub_render is None:\n        sub_render = render_head_repr\n    if key_sub_render is None:\n        key_sub_render = sub_render\n    if isinstance(expr.__class__, Singleton):\n        # We exploit that Singletons override __expr__ to directly return\n        # their name\n        return repr(expr)\n    if isinstance(expr, Expression):\n        args = expr.args\n        keys = expr.minimal_kwargs.keys()\n        kwargs = ''\n        if len(keys) > 0:\n            kwargs = \", \".join([\n                \"%s=%s\" % (key, key_sub_render(expr.kwargs[key]))\n                for key in keys])\n            if len(args) > 0:\n                kwargs = \", \" + kwargs\n        return head_repr_fmt.format(\n            head=expr.__class__.__name__,\n            args=\", \".join([sub_render(arg) for arg in args]),\n            kwargs=kwargs)\n    elif isinstance(expr, (tuple, list)):\n        delims = (\"(\", \")\") if isinstance(expr, tuple) else (\"[\", \"]\")\n        if len(expr) == 1:\n            delims = (delims[0], \",\" + delims[1])\n        return (\n            delims[0] +\n            \", \".join([\n                render_head_repr(\n                    v, sub_render=sub_render, key_sub_render=key_sub_render)\n                for v in expr]) +\n            delims[1])\n    else:\n        return sympy_srepr(expr)", "response": "Render a textual representation of expr using a sub - renderer."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef connect(components, connections, force_SLH=False, expand_simplify=True):\n    combined = Concatenation.create(*components)\n    cdims = [c.cdim for c in components]\n    offsets = _cumsum([0] + cdims[:-1])\n    imap = []\n    omap = []\n    counts = defaultdict(int)\n    for component in components:\n        counts[component] += 1\n\n    for (ic, ((c1, op), (c2, ip))) in enumerate(connections):\n\n        # check c1; convert to index int\n        if not isinstance(c1, int):\n            if counts[c1] > 1:\n                raise ValueError(\n                    \"Component %s appears more than once in list of \"\n                    \"components %r. You must reference it by index in the \"\n                    \"connection %r\" % (c1, components, connections[ic]))\n            try:\n                c1 = components.index(c1)\n            except ValueError:\n                raise ValueError(\n                    \"The component %s in connection %r is not in the list of \"\n                    \"components %r\" % (c1, connections[ic], components))\n        else:\n            if c1 < 0 or c1 >= len(components):\n                raise ValueError(\n                    \"Invalid index %d in connection %r\"\n                    % (c1, connections[ic]))\n        # check c2; convert to index int\n        if not isinstance(c2, int):\n            if counts[c2] > 1:\n                raise ValueError(\n                    \"Component %s appears more than once in list of \"\n                    \"components %r. You must reference it by index in the \"\n                    \"connection %r\" % (c2, components, connections[ic]))\n            try:\n                c2 = components.index(c2)\n            except ValueError:\n                raise ValueError(\n                    \"The component %s in connection %r is not in the list of \"\n                    \"components %r\" % (c2, connections[ic], components))\n        else:\n            if c2 < 0 or c2 >= len(components):\n                raise ValueError(\n                    \"Invalid index %d in connection %r\"\n                    % (c2, connections[ic]))\n        # check op; convert to index int\n        if not (isinstance(op, int)):\n            try:\n                op = components[c1].PORTSOUT.index(op)\n            except AttributeError:\n                raise ValueError(\n                    \"The component %s does not define PORTSOUT labels. \"\n                    \"You cannot use the string %r to refer to a port\"\n                    % (components[c1], op))\n            except ValueError:\n                raise ValueError(\n                    \"The connection %r refers to an invalid output \"\n                    \"channel %s for component %r\"\n                    % (connections[ic], op, components[c1]))\n        else:\n            if op < 0 or op >= components[c1].cdim:\n                raise ValueError(\n                    \"Invalid output channel %d <0 or >=%d (cdim of %r) in %r\"\n                    % (op, components[c1].cdim, components[c1],\n                       connections[ic]))\n        # check ip; convert to index int\n        if not (isinstance(ip, int)):\n            try:\n                ip = components[c2].PORTSIN.index(ip)\n            except AttributeError:\n                raise ValueError(\n                    \"The component %s does not define PORTSIN labels. \"\n                    \"You cannot use the string %r to refer to a port\"\n                    % (components[c2], ip))\n            except ValueError:\n                raise ValueError(\n                    \"The connection %r refers to an invalid input channel \"\n                    \"%s for component %r\"\n                    % (connections[ic], ip, components[c2]))\n        else:\n            if ip < 0 or ip >= components[c2].cdim:\n                raise ValueError(\n                    \"Invalid input channel %d <0 or >=%d (cdim of %r) in %r\"\n                    % (ip, components[c2].cdim, components[c2],\n                       connections[ic]))\n\n        op_idx = offsets[c1] + op\n        ip_idx = offsets[c2] + ip\n        imap.append(ip_idx)\n        omap.append(op_idx)\n\n    n = combined.cdim\n    nfb = len(connections)\n\n    imapping = map_channels(\n        {k: im for (k, im) in zip(range(n-nfb, n), imap)},\n        n)\n\n    omapping = map_channels(\n        {om: k for (k, om) in zip(range(n-nfb, n), omap)},\n        n)\n\n    combined = omapping << combined << imapping\n\n    if force_SLH:\n        combined = combined.toSLH()\n\n    for k in range(nfb):\n        combined = combined.feedback()\n        if isinstance(combined, SLH) and expand_simplify:\n            combined = combined.expand().simplify_scalar()\n\n    return combined", "response": "Connect a list of components according to a list of connections."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nverifies the rules that classes may use for the _binary_rules class attribute.", "response": "def check_rules_dict(rules):\n    \"\"\"Verify the `rules` that classes may use for the `_rules` or\n    `_binary_rules` class attribute.\n\n    Specifically, `rules` must be a\n    :class:`~collections.OrderedDict`-compatible object\n    (list of key-value tuples, :class:`dict`,\n    :class:`~collections.OrderedDict`)\n    that maps a rule name (:class:`str`) to a rule. Each rule consists of a\n    :class:`~qnet.algebra.pattern_matching.Pattern` and a replaceent callable.\n    The Pattern must be set up to match a\n    :class:`~qnet.algebra.pattern_matching.ProtoExpr`. That is,\n    the Pattern should be constructed through the\n    :func:`~qnet.algebra.pattern_matching.pattern_head` routine.\n\n    Raises:\n        TypeError: If `rules` is not compatible with\n            :class:`~collections.OrderedDict`, the\n            keys in `rules` are not strings, or rule is not a tuple of\n            (:class:`~qnet.algebra.pattern_matching.Pattern`, `callable`)\n        ValueError: If the `head`-attribute of each Pattern is not an instance\n            of :class:`~qnet.algebra.pattern_matching.ProtoExpr`, or if there\n            are duplicate keys in `rules`\n\n    Returns:\n        :class:`~collections.OrderedDict` of rules\n    \"\"\"\n    from qnet.algebra.pattern_matching import Pattern, ProtoExpr\n\n    if hasattr(rules, 'items'):\n        items = rules.items()  # `rules` is already a dict / OrderedDict\n    else:\n        items = rules  # `rules` is a list of (key, value) tuples\n    keys = set()\n    for key_rule in items:\n        try:\n            key, rule = key_rule\n        except ValueError:\n            raise TypeError(\"rules does not contain (key, rule) tuples\")\n        if not isinstance(key, str):\n            raise TypeError(\"Key '%s' is not a string\" % key)\n        if key in keys:\n            raise ValueError(\"Duplicate key '%s'\" % key)\n        else:\n            keys.add(key)\n        try:\n            pat, replacement = rule\n        except TypeError:\n            raise TypeError(\n                \"Rule in '%s' is not a (pattern, replacement) tuple\" % key)\n        if not isinstance(pat, Pattern):\n            raise TypeError(\n                \"Pattern in '%s' is not a Pattern instance\" % key)\n        if pat.head is not ProtoExpr:\n            raise ValueError(\n                \"Pattern in '%s' does not match a ProtoExpr\" % key)\n        if not callable(replacement):\n            raise ValueError(\n                \"replacement in '%s' is not callable\" % key)\n        else:\n            arg_names = inspect.signature(replacement).parameters.keys()\n            if not arg_names == pat.wc_names:\n                raise ValueError(\n                    \"arguments (%s) of replacement function differ from the \"\n                    \"wildcard names (%s) in pattern\" % (\n                        \", \".join(sorted(arg_names)),\n                        \", \".join(sorted(pat.wc_names))))\n    return OrderedDict(rules)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to de - rationalize the denominator of the given expression.", "response": "def derationalize_denom(expr):\n    \"\"\"Try to de-rationalize the denominator of the given expression.\n\n    The purpose is to allow to reconstruct e.g. ``1/sqrt(2)`` from\n    ``sqrt(2)/2``.\n\n    Specifically, this matches `expr` against the following pattern::\n\n        Mul(..., Rational(n, d), Pow(d, Rational(1, 2)), ...)\n\n    and returns a tuple ``(numerator, denom_sq, post_factor)``, where\n    ``numerator`` and ``denom_sq`` are ``n`` and ``d`` in the above pattern (of\n    type `int`), respectively, and ``post_factor`` is the product of the\n    remaining factors (``...`` in `expr`). The result will fulfill the\n    following identity::\n\n        (numerator / sqrt(denom_sq)) * post_factor == expr\n\n    If `expr` does not follow the appropriate pattern, a :exc:`ValueError` is\n    raised.\n    \"\"\"\n    r_pos = -1\n    p_pos = -1\n    numerator = S.Zero\n    denom_sq = S.One\n    post_factors = []\n    if isinstance(expr, Mul):\n        for pos, factor in enumerate(expr.args):\n            if isinstance(factor, Rational) and r_pos < 0:\n                r_pos = pos\n                numerator, denom_sq = factor.p, factor.q\n            elif isinstance(factor, Pow) and r_pos >= 0:\n                if factor == sqrt(denom_sq):\n                    p_pos = pos\n                else:\n                    post_factors.append(factor)\n            else:\n                post_factors.append(factor)\n        if r_pos >= 0 and p_pos >= 0:\n            return numerator, denom_sq, Mul(*post_factors)\n        else:\n            raise ValueError(\"Cannot derationalize\")\n    else:\n        raise ValueError(\"expr is not a Mul instance\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the entries that are published under this node.", "response": "def entries(self):\n        \"\"\"\n        Return the entries that are published under this node.\n        \"\"\"\n        # Since there is currently no filtering in place, return all entries.\n        EntryModel = get_entry_model()\n        qs = get_entry_model().objects.order_by('-publication_date')\n\n        # Only limit to current language when this makes sense.\n        if issubclass(EntryModel, TranslatableModel):\n            admin_form_language = self.get_current_language()  # page object is in current language tab.\n            qs = qs.active_translations(admin_form_language).language(admin_form_language)\n\n        return qs"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the URL of a blog entry relative to this page.", "response": "def get_entry_url(self, entry):\n        \"\"\"\n        Return the URL of a blog entry, relative to this page.\n        \"\"\"\n        # It could be possible this page is fetched as fallback, while the 'entry' does have a translation.\n        # - Currently django-fluent-pages 1.0b3 `Page.objects.get_for_path()` assigns the language of retrieval\n        #   as current object language. The page is not assigned a fallback language instead.\n        # - With i18n_patterns() that would make strange URLs, such as '/en/blog/2016/05/dutch-entry-title/'\n        # Hence, respect the entry language as starting point to make the language consistent.\n        with switch_language(self, entry.get_current_language()):\n            return self.get_absolute_url() + entry.get_relative_url()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_placeholder(self, slot=\"blog_contents\", role='m', title=None):\n        return Placeholder.objects.create_for_object(self, slot, role=role, title=title)", "response": "Create a placeholder on this entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef similar_objects(self, num=None, **filters):\n        # TODO: filter appsettings.FLUENT_BLOGS_FILTER_SITE_ID:\n        #    filters.setdefault('parent_site', self.parent_site_id)\n\n        # FIXME: Using super() doesn't work, calling directly.\n        return TagsMixin.similar_objects(self, num=num, **filters)", "response": "Find similar objects using related tags."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_as_png(self, filename, width=300, height=250, render_time=1):\n        self.driver.set_window_size(width, height)\n        self.driver.get('file://{path}/{filename}'.format(\n            path=os.getcwd(), filename=filename + \".html\"))\n        time.sleep(render_time)\n        self.driver.save_screenshot(filename + \".png\")", "response": "Open saved html file and save a screen shot to PNG format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_version(filename):\n    with open(filename) as in_fh:\n        for line in in_fh:\n            if line.startswith('__version__'):\n                return line.split('=')[1].strip()[1:-1]\n    raise ValueError(\"Cannot extract version from %s\" % filename)", "response": "Extract the package version from a file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef blogurl(parser, token):\n    if HAS_APP_URLS:\n        from fluent_pages.templatetags.appurl_tags import appurl\n        return appurl(parser, token)\n    else:\n        from django.template.defaulttags import url\n        return url(parser, token)", "response": "Returns the URL for the blog."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef format_year(year):\n    if isinstance(year, (date, datetime)):\n        # Django 1.5 and up, 'year' is a date object, consistent with month+day views.\n        return unicode(year.year)\n    else:\n        # Django 1.4 just passes the kwarg as string.\n        return unicode(year)", "response": "Format the year value of the yearArchiveView."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a set of all free symbols in the term.", "response": "def free_symbols(self):\n        \"\"\"Set of all free symbols\"\"\"\n        return set([\n            sym for sym in self.term.free_symbols\n            if sym not in self.bound_symbols])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef terms(self):\n        from qnet.algebra.core.scalar_algebra import ScalarValue\n        for mapping in yield_from_ranges(self.ranges):\n            term = self.term.substitute(mapping)\n            if isinstance(term, ScalarValue._val_types):\n                term = ScalarValue.create(term)\n            assert isinstance(term, Expression)\n            yield term", "response": "Yields the terms of the sum if there are any ranges in the term"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite out the indexed sum explicitly If `classes` is None or :class:`IndexedSum` is in `classes`, (partially) write out the indexed sum in to an explicit sum of terms. If `recursive` is True, write out each of the new sum's summands by calling its :meth:`doit` method. Args: classes (None or list): see :meth:`.Expression.doit` recursive (bool): see :meth:`.Expression.doit` indices (list): List of :class:`IdxSym` indices for which the sum should be expanded. If `indices` is a subset of the indices over which the sum runs, it will be partially expanded. If not given, expand the sum completely max_terms (int): Number of terms after which to truncate the sum. This is particularly useful for infinite sums. If not given, expand all terms of the sum. Cannot be combined with `indices` kwargs: keyword arguments for recursive calls to :meth:`doit`. See :meth:`.Expression.doit`", "response": "def doit(\n            self, classes=None, recursive=True, indices=None, max_terms=None,\n            **kwargs):\n        \"\"\"Write out the indexed sum explicitly\n\n        If `classes` is None or :class:`IndexedSum` is in `classes`,\n        (partially) write out the indexed sum in to an explicit sum of terms.\n        If `recursive` is True, write out each of the new sum's summands by\n        calling its :meth:`doit` method.\n\n        Args:\n            classes (None or list): see :meth:`.Expression.doit`\n            recursive (bool): see :meth:`.Expression.doit`\n            indices (list): List of :class:`IdxSym` indices for which the sum\n                should be expanded. If `indices` is a subset of the indices\n                over which the sum runs, it will be partially expanded. If not\n                given, expand the sum completely\n            max_terms (int): Number of terms after which to truncate the sum.\n                This is particularly useful for infinite sums. If not given,\n                expand all terms of the sum. Cannot be combined with `indices`\n            kwargs: keyword arguments for recursive calls to\n                :meth:`doit`. See :meth:`.Expression.doit`\n        \"\"\"\n        return super().doit(\n            classes, recursive, indices=indices, max_terms=max_terms, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a copy with modified indices to ensure disjunct indices with the given ones.", "response": "def make_disjunct_indices(self, *others):\n        \"\"\"Return a copy with modified indices to ensure disjunct indices with\n        `others`.\n\n        Each element in `others` may be an index symbol (:class:`.IdxSym`),\n        a index-range object (:class:`.IndexRangeBase`) or list of index-range\n        objects, or an indexed operation (something with a ``ranges`` attribute)\n\n        Each index symbol is primed until it does not match any index symbol in\n        `others`.\n        \"\"\"\n        new = self\n        other_index_symbols = set()\n        for other in others:\n            try:\n                if isinstance(other, IdxSym):\n                    other_index_symbols.add(other)\n                elif isinstance(other, IndexRangeBase):\n                    other_index_symbols.add(other.index_symbol)\n                elif hasattr(other, 'ranges'):\n                    other_index_symbols.update(\n                        [r.index_symbol for r in other.ranges])\n                else:\n                    other_index_symbols.update(\n                        [r.index_symbol for r in other])\n            except AttributeError:\n                raise ValueError(\n                    \"Each element of other must be an an instance of IdxSym, \"\n                    \"IndexRangeBase, an object with a `ranges` attribute \"\n                    \"with a list of IndexRangeBase instances, or a list of\"\n                    \"IndexRangeBase objects.\")\n        for r in self.ranges:\n            index_symbol = r.index_symbol\n            modified = False\n            while index_symbol in other_index_symbols:\n                modified = True\n                index_symbol = index_symbol.incr_primed()\n            if modified:\n                new = new._substitute(\n                    {r.index_symbol: index_symbol}, safe=True)\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntagging to render CodeMirror Javascript assets needed for all given fields.", "response": "def codemirror_field_js_assets(*args):\n    \"\"\"\n    Tag to render CodeMirror Javascript assets needed for all given fields.\n\n    Example:\n        ::\n\n        {% load djangocodemirror_tags %}\n        {% codemirror_field_js_assets form.myfield1 form.myfield2 %}\n    \"\"\"\n    manifesto = CodemirrorAssetTagRender()\n    manifesto.register_from_fields(*args)\n\n    return mark_safe(manifesto.js_html())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntagging to render CodeMirror CSS assets needed for all given fields.", "response": "def codemirror_field_css_assets(*args):\n    \"\"\"\n    Tag to render CodeMirror CSS assets needed for all given fields.\n\n    Example:\n        ::\n\n        {% load djangocodemirror_tags %}\n        {% codemirror_field_css_assets form.myfield1 form.myfield2 %}\n    \"\"\"\n    manifesto = CodemirrorAssetTagRender()\n    manifesto.register_from_fields(*args)\n\n    return mark_safe(manifesto.css_html())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef codemirror_field_js_bundle(field):\n    manifesto = CodemirrorAssetTagRender()\n    manifesto.register_from_fields(field)\n\n    try:\n        bundle_name = manifesto.js_bundle_names()[0]\n    except IndexError:\n        msg = (\"Given field with configuration name '{}' does not have a \"\n               \"Javascript bundle name\")\n        raise CodeMirrorFieldBundleError(msg.format(field.config_name))\n\n    return bundle_name", "response": "Filter to get CodeMirror Javascript bundle name needed for a single field."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef codemirror_field_css_bundle(field):\n    manifesto = CodemirrorAssetTagRender()\n    manifesto.register_from_fields(field)\n\n    try:\n        bundle_name = manifesto.css_bundle_names()[0]\n    except IndexError:\n        msg = (\"Given field with configuration name '{}' does not have a \"\n               \"Javascript bundle name\")\n        raise CodeMirrorFieldBundleError(msg.format(field.config_name))\n\n    return bundle_name", "response": "Returns the CodeMirror CSS bundle name needed for a single field."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a JSON string that includes CodeMirror parameters for a single CodeMirror field.", "response": "def codemirror_parameters(field):\n    \"\"\"\n    Filter to include CodeMirror parameters as a JSON string for a single\n    field.\n\n    This must be called only on an allready rendered field, meaning you must\n    not use this filter on a field before a form. Else, the field widget won't\n    be correctly initialized.\n\n    Example:\n        ::\n\n            {% load djangocodemirror_tags %}\n            {{ form.myfield|codemirror_parameters }}\n\n    Arguments:\n        field (djangocodemirror.fields.CodeMirrorField): A form field.\n\n    Returns:\n        string: JSON object for parameters, marked safe for Django templates.\n    \"\"\"\n    manifesto = CodemirrorAssetTagRender()\n    names = manifesto.register_from_fields(field)\n\n    config = manifesto.get_codemirror_parameters(names[0])\n\n    return mark_safe(json.dumps(config))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef codemirror_instance(config_name, varname, element_id, assets=True):\n    output = io.StringIO()\n\n    manifesto = CodemirrorAssetTagRender()\n    manifesto.register(config_name)\n\n    if assets:\n        output.write(manifesto.css_html())\n        output.write(manifesto.js_html())\n\n    html = manifesto.codemirror_html(config_name, varname, element_id)\n    output.write(html)\n\n    content = output.getvalue()\n    output.close()\n\n    return mark_safe(content)", "response": "Returns an HTML string that can be used to initialize a CodeMirror instance for an element."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef resolve_widget(self, field):\n        # When filter is used within template we have to reach the field\n        # instance through the BoundField.\n        if hasattr(field, 'field'):\n            widget = field.field.widget\n        # When used out of template, we have a direct field instance\n        else:\n            widget = field.widget\n\n        return widget", "response": "Resolves a widget instance from a field object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering config name from field widgets", "response": "def register_from_fields(self, *args):\n        \"\"\"\n        Register config name from field widgets\n\n        Arguments:\n            *args: Fields that contains widget\n                :class:`djangocodemirror.widget.CodeMirrorWidget`.\n\n        Returns:\n            list: List of registered config names from fields.\n        \"\"\"\n        names = []\n        for field in args:\n            widget = self.resolve_widget(field)\n            self.register(widget.config_name)\n            if widget.config_name not in names:\n                names.append(widget.config_name)\n\n        return names"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef render_asset_html(self, path, tag_template):\n        url = os.path.join(settings.STATIC_URL, path)\n\n        return tag_template.format(url=url)", "response": "Render HTML tag for a given path."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef css_html(self):\n        output = io.StringIO()\n\n        for item in self.css():\n            output.write(\n                self.render_asset_html(item, settings.CODEMIRROR_CSS_ASSET_TAG)\n            )\n\n        content = output.getvalue()\n        output.close()\n\n        return content", "response": "Render HTML tags for Javascript assets."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef js_html(self):\n        output = io.StringIO()\n\n        for item in self.js():\n            output.write(\n                self.render_asset_html(item, settings.CODEMIRROR_JS_ASSET_TAG)\n            )\n\n        content = output.getvalue()\n        output.close()\n\n        return content", "response": "Render HTML tags for Javascript assets."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrenders a CodeMirror instance for a field input.", "response": "def codemirror_html(self, config_name, varname, element_id):\n        \"\"\"\n        Render HTML for a CodeMirror instance.\n\n        Since a CodeMirror instance have to be attached to a HTML element, this\n        method requires a HTML element identifier with or without the ``#``\n        prefix, it depends from template in\n        ``settings.CODEMIRROR_FIELD_INIT_JS`` (default one require to not\n        prefix with ``#``).\n\n        Arguments:\n            config_name (string): A registred config name.\n            varname (string): A Javascript variable name.\n            element_id (string): An HTML element identifier (without\n                leading ``#``) to attach to a CodeMirror instance.\n\n        Returns:\n            string: HTML to instanciate CodeMirror for a field input.\n        \"\"\"\n        parameters = json.dumps(self.get_codemirror_parameters(config_name),\n                                sort_keys=True)\n        return settings.CODEMIRROR_FIELD_INIT_JS.format(\n            varname=varname,\n            inputid=element_id,\n            settings=parameters,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the language settings for the current site", "response": "def get_language_settings(language_code, site_id=None):\n    \"\"\"\n    Return the language settings for the current site\n    \"\"\"\n    if site_id is None:\n        site_id = getattr(settings, 'SITE_ID', None)\n\n    for lang_dict in FLUENT_BLOGS_LANGUAGES.get(site_id, ()):\n        if lang_dict['code'] == language_code:\n            return lang_dict\n\n    return FLUENT_BLOGS_LANGUAGES['default']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the API documentation.", "response": "def run_apidoc(_):\n    \"\"\"Generage API documentation\"\"\"\n    import better_apidoc\n    better_apidoc.main([\n        'better-apidoc',\n        '-t',\n        os.path.join('.', '_templates'),\n        '--force',\n        '--no-toc',\n        '--separate',\n        '-o',\n        os.path.join('.', 'API'),\n        os.path.join('..', 'src', 'qnet'),\n    ])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a modified that returns the representation of expr or '...' if there is no such representation.", "response": "def _shorten_render(renderer, max_len):\n    \"\"\"Return a modified that returns the representation of expr, or '...' if\n    that representation is longer than `max_len`\"\"\"\n\n    def short_renderer(expr):\n        res = renderer(expr)\n        if len(res) > max_len:\n            return '...'\n        else:\n            return res\n\n    return short_renderer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_tree(\n        expr, attr='operands', padding='', exclude_type=None, depth=None,\n        unicode=True, srepr_leaves=False, _last=False, _root=True, _level=0,\n        _print=True):\n    \"\"\"Print a tree representation of the structure of `expr`\n\n    Args:\n        expr (Expression): expression to render\n        attr (str): The attribute from which to get the children of `expr`\n        padding (str): Whitespace by which the entire tree is idented\n        exclude_type (type): Type (or list of types) which should never be\n            expanded recursively\n        depth (int or None): Maximum depth of the tree to be printed\n        unicode (bool): If True, use unicode line-drawing symbols for the tree,\n            and print expressions in a unicode representation.\n            If False, use an ASCII approximation.\n        srepr_leaves (bool): Whether or not to render leaves with `srepr`,\n            instead of `ascii`/`unicode`\n\n    See also:\n        :func:`tree` return the result as a string, instead of printing it\n    \"\"\"\n    from qnet.printing import srepr\n    lines = []\n    if unicode:\n        draw = {'leaf': '\u2514\u2500 ', 'branch': '\u251c\u2500 ', 'line': '\u2502'}\n        sub_render = _shorten_render_unicode()\n    else:\n        draw = {'leaf': '+- ', 'branch': '+- ', 'line': '|'}\n        sub_render = _shorten_render_ascii()\n    to_str = lambda expr: render_head_repr(\n            expr, sub_render=sub_render, key_sub_render=sub_render)\n    if _root:\n        lines.append(\". \" + to_str(expr))\n    else:\n        if _last:\n            lines.append(padding[:-1] + draw['leaf'] + to_str(expr))\n        else:\n            lines.append(padding[:-1] + draw['branch'] + to_str(expr))\n    padding = padding + '  '\n    try:\n        children = getattr(expr, attr)\n    except AttributeError:\n        children = []\n    if exclude_type is not None:\n        if isinstance(expr, exclude_type):\n            children = []\n    if depth is not None:\n        if depth <= _level:\n            children = []\n    for count, child in enumerate(children):\n        if hasattr(child, attr):\n            if count == len(children)-1:\n                lines += print_tree(\n                    child, attr, padding + ' ',\n                    exclude_type=exclude_type, depth=depth, unicode=unicode,\n                    srepr_leaves=srepr_leaves, _last=True, _root=False,\n                    _level=_level+1)\n            else:\n                lines += print_tree(\n                    child, attr, padding + draw['line'],\n                    exclude_type=exclude_type, depth=depth, unicode=unicode,\n                    srepr_leaves=srepr_leaves, _last=False, _root=False,\n                    _level=_level+1)\n        else:\n            if count == len(children)-1:\n                if srepr_leaves:\n                    lines.append(padding + draw['leaf'] + srepr(child))\n                else:\n                    lines.append(padding + draw['leaf'] + to_str(child))\n            else:\n                if srepr_leaves:\n                    lines.append(padding + draw['branch'] + srepr(child))\n                else:\n                    lines.append(padding + draw['branch'] + to_str(child))\n    if _root:\n        if _print:\n            print(\"\\n\".join(lines))\n        else:\n            return lines\n    else:\n        return lines", "response": "Print a tree representation of the expression expr"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the algebra system MimeType", "response": "def init_algebra(*, default_hs_cls='LocalSpace'):\n    \"\"\"Initialize the algebra system\n\n    Args:\n        default_hs_cls (str): The name of the :class:`.LocalSpace` subclass\n            that should be used when implicitly creating Hilbert spaces, e.g.\n            in :class:`.OperatorSymbol`\n\n    \"\"\"\n    from qnet.algebra.core.hilbert_space_algebra import LocalSpace\n    from qnet.algebra.core.abstract_quantum_algebra import QuantumExpression\n    default_hs_cls = getattr(importlib.import_module('qnet'), default_hs_cls)\n    if issubclass(default_hs_cls, LocalSpace):\n        QuantumExpression._default_hs_cls = default_hs_cls\n    else:\n        raise TypeError(\"default_hs_cls must be a subclass of LocalSpace\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef register(self, name):\n        if name not in settings.CODEMIRROR_SETTINGS:\n            msg = (\"Given config name '{}' does not exists in \"\n                   \"'settings.CODEMIRROR_SETTINGS'.\")\n            raise UnknowConfigError(msg.format(name))\n\n        parameters = copy.deepcopy(self.default_internal_config)\n        parameters.update(copy.deepcopy(\n            settings.CODEMIRROR_SETTINGS[name]\n        ))\n\n        # Add asset bundles name\n        if 'css_bundle_name' not in parameters:\n            css_template_name = settings.CODEMIRROR_BUNDLE_CSS_NAME\n            parameters['css_bundle_name'] = css_template_name.format(\n                settings_name=name\n            )\n        if 'js_bundle_name' not in parameters:\n            js_template_name = settings.CODEMIRROR_BUNDLE_JS_NAME\n            parameters['js_bundle_name'] = js_template_name.format(\n                settings_name=name\n            )\n\n        self.registry[name] = parameters\n\n        return parameters", "response": "Registers a new config for an editor instance."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef register_many(self, *args):\n        params = []\n        for name in args:\n            params.append(self.register(name))\n\n        return params", "response": "Register many configuration names."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve given mode name and returns mode file path from settings. CODEMIRROR_MODES.", "response": "def resolve_mode(self, name):\n        \"\"\"\n        From given mode name, return mode file path from\n        ``settings.CODEMIRROR_MODES`` map.\n\n        Arguments:\n            name (string): Mode name.\n\n        Raises:\n            KeyError: When given name does not exist in\n                ``settings.CODEMIRROR_MODES``.\n\n        Returns:\n            string: Mode file path.\n        \"\"\"\n        if name not in settings.CODEMIRROR_MODES:\n            msg = (\"Given config name '{}' does not exists in \"\n                   \"'settings.CODEMIRROR_MODES'.\")\n            raise UnknowModeError(msg.format(name))\n\n        return settings.CODEMIRROR_MODES.get(name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef resolve_theme(self, name):\n        if name not in settings.CODEMIRROR_THEMES:\n            msg = (\"Given theme name '{}' does not exists in \"\n                   \"'settings.CODEMIRROR_THEMES'.\")\n            raise UnknowThemeError(msg.format(name))\n\n        return settings.CODEMIRROR_THEMES.get(name)", "response": "Resolves given theme name and returns theme file path from settings. CODEMIRROR_THEMES."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_configs(self, name=None):\n        if name:\n            if name not in self.registry:\n                msg = \"Given config name '{}' is not registered.\"\n                raise NotRegisteredError(msg.format(name))\n\n            return {name: self.registry[name]}\n        return self.registry", "response": "Returns a dictionary of all the registered configurations."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a registred configuration for given config name.", "response": "def get_config(self, name):\n        \"\"\"\n        Return a registred configuration for given config name.\n\n        Arguments:\n            name (string): A registred config name.\n\n        Raises:\n            NotRegisteredError: If given config name does not exist in\n            registry.\n\n        Returns:\n            dict: Configuration.\n        \"\"\"\n        if name not in self.registry:\n            msg = \"Given config name '{}' is not registered.\"\n            raise NotRegisteredError(msg.format(name))\n\n        return copy.deepcopy(self.registry[name])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn CodeMirror parameters for given configuration name.", "response": "def get_codemirror_parameters(self, name):\n        \"\"\"\n        Return CodeMirror parameters for given configuration name.\n\n        This is a reduced configuration from internal parameters.\n\n        Arguments:\n            name (string): Config name from available ones in\n                ``settings.CODEMIRROR_SETTINGS``.\n\n        Returns:\n            dict: Parameters.\n        \"\"\"\n        config = self.get_config(name)\n\n        return {k: config[k] for k in config if k not in self._internal_only}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all needed Javascript filepaths for given config name or every registred config.", "response": "def js(self, name=None):\n        \"\"\"\n        Returns all needed Javascript filepaths for given config name (if\n        given) or every registred config instead (if no name is given).\n\n        Keyword Arguments:\n            name (string): Specific config name to use instead of all.\n\n        Returns:\n            list: List of Javascript file paths.\n        \"\"\"\n        filepaths = copy.copy(settings.CODEMIRROR_BASE_JS)\n\n        configs = self.get_configs(name)\n        names = sorted(configs)\n\n        # Addons first\n        for name in names:\n            opts = configs[name]\n            for item in opts.get('addons', []):\n                if item not in filepaths:\n                    filepaths.append(item)\n\n        # Process modes\n        for name in names:\n            opts = configs[name]\n            for item in opts['modes']:\n                resolved = self.resolve_mode(item)\n                if resolved not in filepaths:\n                    filepaths.append(resolved)\n\n        return filepaths"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef js_bundle_names(self, name=None):\n        configs = self.get_configs(name)\n\n        names = []\n        for k, v in configs.items():\n            if v.get('js_bundle_name'):\n                names.append(v['js_bundle_name'])\n\n        return sorted(names)", "response": "Returns all needed Javascript Bundle names for given config name or every registred config."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef css(self, name=None):\n        filepaths = copy.copy(settings.CODEMIRROR_BASE_CSS)\n\n        configs = self.get_configs(name)\n        names = sorted(configs)\n\n        # Process themes\n        for name in names:\n            opts = configs[name]\n            for item in opts.get('themes', []):\n                resolved = self.resolve_theme(item)\n                if resolved not in filepaths:\n                    filepaths.append(resolved)\n\n        # Then process extra CSS files\n        for name in names:\n            opts = configs[name]\n            for item in opts.get('extra_css', []):\n                if item not in filepaths:\n                    filepaths.append(item)\n\n        return filepaths", "response": "Returns all needed CSS filepaths for given config name or every registred config."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the commutator of A and B.", "response": "def commutator(A, B=None):\n    \"\"\"Commutator of `A` and `B`\n\n    If ``B != None``, return the commutator :math:`[A,B]`, otherwise return\n    the super-operator :math:`[A,\\cdot]`.  The super-operator :math:`[A,\\cdot]`\n    maps any other operator ``B`` to the commutator :math:`[A, B] = A B - B A`.\n\n    Args:\n        A: The first operator to form the commutator of.\n        B: The second operator to form the commutator of, or None.\n\n    Returns:\n        SuperOperator: The linear superoperator :math:`[A,\\cdot]`\n\n    \"\"\"\n    if B:\n        return A * B - B * A\n    return SPre(A) - SPost(A)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the anti - commutator of A and B.", "response": "def anti_commutator(A, B=None):\n    \"\"\"If ``B != None``, return the anti-commutator :math:`\\{A,B\\}`, otherwise\n    return the super-operator :math:`\\{A,\\cdot\\}`.  The super-operator\n    :math:`\\{A,\\cdot\\}` maps any other operator ``B`` to the anti-commutator\n    :math:`\\{A, B\\} = A B + B A`.\n\n    Args:\n        A: The first operator to form all anti-commutators of.\n        B: The second operator to form the anti-commutator of, or None.\n\n    Returns:\n        SuperOperator: The linear superoperator :math:`[A,\\cdot]`\n\n    \"\"\"\n    if B:\n        return A * B + B * A\n    return SPre(A) + SPost(A)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef liouvillian_normal_form(L, symbolic = False):\n    L = L.expand()\n\n    if isinstance(L, SuperOperatorPlus):\n        spres = []\n        sposts = []\n        collapse_form = defaultdict(lambda: defaultdict(int))\n        for s in L.operands:\n            if isinstance(s, ScalarTimesSuperOperator):\n                coeff, term = s.operands\n            else:\n                coeff, term = One, s\n            if isinstance(term, SPre):\n                spres.append(coeff * term.operands[0])\n            elif isinstance(term, SPost):\n                sposts.append((coeff * term.operands[0]))\n            else:\n                if (not isinstance(term, SuperOperatorTimes) or not\n                        len(term.operands) == 2 or not\n                        (isinstance(term.operands[0], SPre) and\n                        isinstance(term.operands[1], SPost))):\n                    raise BadLiouvillianError(\n                            \"All terms of the Liouvillian need to be of form \"\n                            \"SPre(X), SPost(X) or SPre(X)*SPost(X): This term \"\n                            \"is in violation {!s}\".format(term))\n                spreL, spostL = term.operands\n                Li, Ljd = spreL.operands[0], spostL.operands[0]\n\n                try:\n                    complex(coeff)\n                except (ValueError, TypeError):\n                    symbolic = True\n                    coeff = coeff.simplify_scalar()\n\n                collapse_form[Li][Ljd] = coeff\n\n        basis = sorted(collapse_form.keys())\n\n        warn_msg = (\"Warning: the Liouvillian is probably malformed: \"\n                    \"The coefficients of SPre({!s})*SPost({!s}) and \"\n                    \"SPre({!s})*SPost({!s}) should be complex conjugates \"\n                    \"of each other\")\n        for ii, Li in enumerate(basis):\n            for Lj in basis[ii:]:\n                cij = collapse_form[Li][Lj.adjoint()]\n                cji = collapse_form[Lj][Li.adjoint()]\n                if cij !=0 or cji !=0:\n                    diff = (cij.conjugate() - cji)\n                    try:\n                        diff = complex(diff)\n                        if abs(diff) > 1e-6:\n                            print(warn_msg.format(Li, Lj.adjoint(), Lj,\n                                                  Li.adjoint()))\n                    except ValueError:\n                        symbolic = True\n                        if diff.simplify():\n                            print(\"Warning: the Liouvillian my be malformed, \"\n                                  \"convert to numerical representation\")\n        final_Lis = []\n        if symbolic:\n            if len(basis) == 1:\n                l1 = basis[0]\n                kappa1 = collapse_form[l1][l1.adjoint()]\n                final_Lis = [sqrt(kappa1) * l1]\n                sdiff = (l1.adjoint() * l1 * kappa1 / 2)\n                spres.append(sdiff)\n                sposts.append(sdiff)\n#            elif len(basis) == 2:\n#                l1, l2 = basis\n#                kappa_1 = collapse_form[l1][l1.adjoint()]\n#                kappa_2 = collapse_form[l2][l2.adjoint()]\n#                kappa_12 = collapse_form[l1][l2.adjoint()]\n#                kappa_21 = collapse_form[l2][l1.adjoint()]\n##                assert (kappa_12.conjugate() - kappa_21) == 0\n            else:\n                M = SympyMatrix(len(basis), len(basis),\n                                lambda i,j: collapse_form[basis[i]][basis[j]\n                                            .adjoint()])\n\n                # First check if M is already diagonal (sympy does not handle\n                # this well, for some reason)\n                diag = True\n                for i in range(len(basis)):\n                    for j in range(i):\n                        if M[i,j].apply_rules() != 0 or M[j, i].apply_rules != 0:\n                            diag = False\n                            break\n                    if not diag:\n                        break\n                if diag:\n                    for bj in basis:\n                        final_Lis.append(\n                                bj * sqrt(collapse_form[bj][bj.adjoint()]))\n                        sdiff = (bj.adjoint() * bj *\n                                 collapse_form[bj][bj.adjoint()]/2)\n                        spres.append(sdiff)\n                        sposts.append(sdiff)\n\n                # Try sympy algo\n                else:\n                    try:\n                        data = M.eigenvects()\n\n                        for evalue, multiplicity, ebasis in data:\n                            if not evalue:\n                                continue\n                            for b in ebasis:\n                                new_L = (sqrt(evalue) * sum(cj[0] * Lj\n                                         for (cj, Lj)\n                                         in zip(b.tolist(), basis))).expand()\n                                final_Lis.append(new_L)\n                                sdiff = (new_L.adjoint() * new_L / 2).expand()\n                                spres.append(sdiff)\n                                sposts.append(sdiff)\n\n                    except NotImplementedError:\n                        raise CannotSymbolicallyDiagonalize((\n                            \"The matrix {} is too hard to diagonalize \"\n                            \"symbolically. Please try converting to fully \"\n                            \"numerical representation.\").format(M))\n        else:\n            M = np_array([[complex(collapse_form[Li][Lj.adjoint()])\n                           for Lj in basis] for Li in basis])\n\n            vals, vecs = eigh(M)\n            for sv, vec in zip(np_sqrt(vals), vecs.transpose()):\n                new_L = sum((sv * ci) * Li for (ci, Li) in zip(vec, basis))\n                final_Lis.append(new_L)\n                sdiff = (.5 * new_L.adjoint()*new_L).expand()\n                spres.append(sdiff)\n                sposts.append(sdiff)\n\n        miHspre = sum(spres)\n        iHspost = sum(sposts)\n\n        if ((not (miHspre + iHspost) is ZeroOperator) or not\n                (miHspre.adjoint() + miHspre) is ZeroOperator):\n            print(\"Warning, potentially malformed Liouvillian {!s}\".format(L))\n\n        final_H = (I*miHspre).expand()\n        return final_H, final_Lis\n\n    else:\n        if L is ZeroSuperOperator:\n            return ZeroOperator, []\n\n        raise BadLiouvillianError(str(L))", "response": "r Return a Hamilton operator H and a minimal list of collapse operators Ls that generate the liouvillian L."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef vstackm(matrices):\n    arr = np_vstack(tuple(m.matrix for m in matrices))\n    #    print(tuple(m.matrix.dtype for m in matrices))\n    #    print(arr.dtype)\n    return Matrix(arr)", "response": "Generalizes numpy. vstack to Matrix objects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the block - diagonal structure of for the matrix.", "response": "def block_structure(self):\n        \"\"\"For square matrices this gives the block (-diagonal) structure of\n        the matrix as a tuple of integers that sum up to the full dimension.\n\n        :rtype: tuple\n        \"\"\"\n        n, m = self.shape\n        if n != m:\n            raise AttributeError(\"block_structure only defined for square \"\n                                 \"matrices\")\n        for k in range(1, n):\n            if ((self.matrix[:k, k:] == 0).all() and\n                    (self.matrix[k:, :k] == 0).all()):\n                return (k,) + self[k:, k:].block_structure\n        return n,"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if all elements of the matrix are zero.", "response": "def is_zero(self):\n        \"\"\"Are all elements of the matrix zero?\"\"\"\n        for o in self.matrix.ravel():\n            try:\n                if not o.is_zero:\n                    return False\n            except AttributeError:\n                if not o == 0:\n                    return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef conjugate(self):\n        try:\n            return Matrix(np_conjugate(self.matrix))\n        except AttributeError:\n            raise NoConjugateMatrix(\n                \"Matrix %s contains entries that have no defined \"\n                \"conjugate\" % str(self))", "response": "The element - wise conjugate matrix."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef element_wise(self, func, *args, **kwargs):\n        s = self.shape\n        emat = [func(o, *args, **kwargs) for o in self.matrix.ravel()]\n        return Matrix(np_array(emat).reshape(s))", "response": "Applies a function to each matrix element and return the result in a\n            Matrix of the same shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef series_expand(self, param: Symbol, about, order: int):\n        s = self.shape\n        emats = zip(*[o.series_expand(param, about, order)\n                      for o in self.matrix.ravel()])\n        return tuple((Matrix(np_array(em).reshape(s)) for em in emats))", "response": "Expand the matrix expression as a truncated power series in a scalar\n            parameter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef expand(self):\n        return self.element_wise(\n            lambda o: o.expand() if isinstance(o, QuantumExpression) else o)", "response": "Expand each matrix element distributively."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef space(self):\n        arg_spaces = [o.space for o in self.matrix.ravel()\n                      if hasattr(o, 'space')]\n        if len(arg_spaces) == 0:\n            return TrivialSpace\n        else:\n            return ProductSpace.create(*arg_spaces)", "response": "Combined Hilbert space of all matrix elements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef simplify_scalar(self, func=sympy.simplify):\n\n        def element_simplify(v):\n            if isinstance(v, sympy.Basic):\n                return func(v)\n            elif isinstance(v, QuantumExpression):\n                return v.simplify_scalar(func=func)\n            else:\n                return v\n\n        return self.element_wise(element_simplify)", "response": "Simplify all scalar expressions appearing in the Matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_initial(self):\n        initial = {}\n\n        if self.kwargs.get('mode', None):\n            filename = \"{}.txt\".format(self.kwargs['mode'])\n            filepath = os.path.join(settings.BASE_DIR, 'demo_datas', filename)\n            if os.path.exists(filepath):\n                with io.open(filepath, 'r', encoding='utf-8') as fp:\n                    initial['foo'] = fp.read()\n\n        return initial", "response": "Try to find a demo source for given mode if any use it to fill the demo textarea."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the order by syntax for a model.", "response": "def _get_order_by(order, orderby, order_by_fields):\n    \"\"\"\n    Return the order by syntax for a model.\n    Checks whether use ascending or descending order, and maps the fieldnames.\n    \"\"\"\n    try:\n        # Find the actual database fieldnames for the keyword.\n        db_fieldnames = order_by_fields[orderby]\n    except KeyError:\n        raise ValueError(\"Invalid value for 'orderby': '{0}', supported values are: {1}\".format(orderby, ', '.join(sorted(order_by_fields.keys()))))\n\n    # Default to descending for some fields, otherwise be ascending\n    is_desc = (not order and orderby in ORDER_BY_DESC) \\\n        or (order or 'asc').lower() in ('desc', 'descending')\n\n    if is_desc:\n        return map(lambda name: '-' + name, db_fieldnames)\n    else:\n        return db_fieldnames"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nquery the entries using a set of predefined filters.", "response": "def query_entries(\n    queryset=None,\n    year=None, month=None, day=None,\n    category=None, category_slug=None,\n    tag=None, tag_slug=None,\n    author=None, author_slug=None,\n    future=False,\n    order=None,\n    orderby=None,\n    limit=None,\n):\n    \"\"\"\n    Query the entries using a set of predefined filters.\n    This interface is mainly used by the ``get_entries`` template tag.\n    \"\"\"\n    if queryset is None:\n        queryset = get_entry_model().objects.all()\n\n    if appsettings.FLUENT_BLOGS_FILTER_SITE_ID:\n        queryset = queryset.parent_site(settings.SITE_ID)\n\n    if not future:\n        queryset = queryset.published()\n\n    if year:\n        queryset = queryset.filter(publication_date__year=year)\n    if month:\n        queryset = queryset.filter(publication_date__month=month)\n    if day:\n        queryset = queryset.filter(publication_date__day=day)\n\n    # The main category/tag/author filters\n    if category:\n        if isinstance(category, basestring):\n            queryset = queryset.categories(category)\n        elif isinstance(category, (int, long)):\n            queryset = queryset.filter(categories=category)\n        else:\n            raise ValueError(\"Expected slug or ID for the 'category' parameter\")\n    if category_slug:\n        queryset = queryset.categories(category)\n\n    if tag:\n        if isinstance(tag, basestring):\n            queryset = queryset.tagged(tag)\n        elif isinstance(tag, (int, long)):\n            queryset = queryset.filter(tags=tag)\n        else:\n            raise ValueError(\"Expected slug or ID for 'tag' parameter.\")\n    if tag_slug:\n        queryset = queryset.tagged(tag)\n\n    if author:\n        if isinstance(author, basestring):\n            queryset = queryset.authors(author)\n        elif isinstance(author, (int, long)):\n            queryset = queryset.filter(author=author)\n        else:\n            raise ValueError(\"Expected slug or ID for 'author' parameter.\")\n    if author_slug:\n        queryset = queryset.authors(author_slug)\n\n    # Ordering\n    if orderby:\n        queryset = queryset.order_by(*_get_order_by(order, orderby, ENTRY_ORDER_BY_FIELDS))\n    else:\n        queryset = queryset.order_by('-publication_date')\n\n    # Limit\n    if limit:\n        queryset = queryset[:limit]\n\n    return queryset"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_tags(order=None, orderby=None, limit=None):\n    from taggit.models import Tag, TaggedItem    # feature is still optional\n\n    # Get queryset filters for published entries\n    EntryModel = get_entry_model()\n    ct = ContentType.objects.get_for_model(EntryModel)  # take advantage of local caching.\n\n    entry_filter = {\n        'status': EntryModel.PUBLISHED\n    }\n    if appsettings.FLUENT_BLOGS_FILTER_SITE_ID:\n        entry_filter['parent_site'] = settings.SITE_ID\n\n    entry_qs = EntryModel.objects.filter(**entry_filter).values_list('pk')\n\n    # get tags\n    queryset = Tag.objects.filter(\n        taggit_taggeditem_items__content_type=ct,\n        taggit_taggeditem_items__object_id__in=entry_qs\n    ).annotate(\n        count=Count('taggit_taggeditem_items')\n    )\n\n    # Ordering\n    if orderby:\n        queryset = queryset.order_by(*_get_order_by(order, orderby, TAG_ORDER_BY_FIELDS))\n    else:\n        queryset = queryset.order_by('-count')\n\n    # Limit\n    if limit:\n        queryset = queryset[:limit]\n\n    return queryset", "response": "Query the tags for the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds the category for a given slug", "response": "def get_category_for_slug(slug, language_code=None):\n    \"\"\"\n    Find the category for a given slug\n    \"\"\"\n    Category = get_category_model()\n    if issubclass(Category, TranslatableModel):\n        return Category.objects.active_translations(language_code, slug=slug).get()\n    else:\n        return Category.objects.get(slug=slug)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a start.. end range to query for a specific month day or year.", "response": "def get_date_range(year=None, month=None, day=None):\n    \"\"\"\n    Return a start..end range to query for a specific month, day or year.\n    \"\"\"\n    if year is None:\n        return None\n\n    if month is None:\n        # year only\n        start = datetime(year, 1, 1, 0, 0, 0, tzinfo=utc)\n        end = datetime(year, 12, 31, 23, 59, 59, 999, tzinfo=utc)\n        return (start, end)\n\n    if day is None:\n        # year + month only\n        start = datetime(year, month, 1, 0, 0, 0, tzinfo=utc)\n        end = start + timedelta(days=monthrange(year, month)[1], microseconds=-1)\n        return (start, end)\n    else:\n        # Exact day\n        start = datetime(year, month, day, 0, 0, 0, tzinfo=utc)\n        end = start + timedelta(days=1, microseconds=-1)\n        return (start, end)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef singleton_object(cls):\n    assert isinstance(cls, Singleton), \\\n        cls.__name__ + \" must use Singleton metaclass\"\n\n    def self_instantiate(self):\n        return self\n\n    cls.__call__ = self_instantiate\n    if hasattr(cls, '_hash_val'):\n        cls.__hash__ = lambda self: hash(cls._hash_val)\n        cls.__eq__ = lambda self, other: other == cls._hash_val\n    else:\n        cls.__hash__ = lambda self: hash(cls)\n        cls.__eq__ = lambda self, other: other is self\n    cls.__repr__ = lambda self: cls.__name__\n    cls.__reduce__ = lambda self: cls.__name__\n    obj = cls()\n    obj.__name__ = cls.__name__\n    obj.__qualname__ = cls.__qualname__\n    return obj", "response": "Class decorator that returns the object that is a singleton of the given class."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pattern(head, *args, mode=1, wc_name=None, conditions=None, **kwargs) \\\n        -> Pattern:\n    \"\"\"'Flat' constructor for the Pattern class\n\n    Positional and keyword arguments are mapped into `args` and `kwargs`,\n    respectively. Useful for defining rules that match an instantiated\n    Expression with specific arguments\n    \"\"\"\n    if len(args) == 0:\n        args = None\n    if len(kwargs) == 0:\n        kwargs = None\n    return Pattern(head, args, kwargs, mode=mode, wc_name=wc_name,\n                   conditions=conditions)", "response": "A function to create a new Pattern object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new Pattern with the given args and kwargs.", "response": "def pattern_head(*args, conditions=None, wc_name=None, **kwargs) -> Pattern:\n    \"\"\"Constructor for a :class:`Pattern` matching a :class:`ProtoExpr`\n\n    The patterns associated with :attr:`_rules` and :attr:`_binary_rules`\n    of an :class:`Expression` subclass, or those passed to\n    :meth:`Expression.add_rule`, must be instantiated through this\n    routine. The function does not allow to set a wildcard name\n    (`wc_name` must not be given / be None)\"\"\"\n    # This routine is indented for the _rules and _binary_rules class\n    # attributes of algebraic objects, which the match_replace and\n    # match_replace_binary match against a ProtoExpr\n    if len(args) == 0:\n        args = None\n    if len(kwargs) == 0:\n        kwargs = None\n    if wc_name is not None:\n        raise ValueError(\"pattern_head cannot be used to set a wildcard \"\n                         \"(`wc_name` must not be given\")\n    pat = Pattern(head=ProtoExpr, args=args, kwargs=kwargs, wc_name=None,\n                  conditions=conditions)\n    return pat"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wc(name_mode=\"_\", head=None, args=None, kwargs=None, *, conditions=None) \\\n        -> Pattern:\n    \"\"\"Constructor for a wildcard-:class:`Pattern`\n\n    Helper function to create a Pattern object with an emphasis on wildcard\n    patterns, if we don't care about the arguments of the matched expressions\n    (otherwise, use :func:`pattern`)\n\n    Args:\n        name_mode (str): Combined `wc_name` and `mode` for :class:`Pattern`\n            constructor argument. See below for syntax\n        head (type, or None): See :class:`Pattern`\n        args (list or None): See :class:`Pattern`\n        kwargs (dict or None): See :class:`Pattern`\n        conditions (list or None): See :class:`Pattern`\n\n    The `name_mode` argument uses trailing underscored to indicate the `mode`:\n\n        * ``A`` -> ``Pattern(wc_name=\"A\", mode=Pattern.single, ...)``\n        * ``A_`` -> ``Pattern(wc_name=\"A\", mode=Pattern.single, ...)``\n        * ``B__`` -> ``Pattern(wc_name=\"B\", mode=Pattern.one_or_more, ...)``\n        * ``B___`` -> ``Pattern(wc_name=\"C\", mode=Pattern.zero_or_more, ...)``\n    \"\"\"\n    rx = re.compile(r\"^([A-Za-z]?[A-Za-z0-9]*)(_{0,3})$\")\n    m = rx.match(name_mode)\n    if not m:\n        raise ValueError(\"Invalid name_mode: %s\" % name_mode)\n    wc_name, mode_underscores = m.groups()\n    if wc_name == '':\n        wc_name = None\n    mode = len(mode_underscores) or Pattern.single\n    return Pattern(head, args, kwargs, mode=mode, wc_name=wc_name,\n                   conditions=conditions)", "response": "Returns a new wildcard - : class:`Pattern` object that can be used to create a wildcard - : class:`Pattern` object for a wildcard - : class:`Pattern` object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_pattern(expr_or_pattern: object, expr: object) -> MatchDict:\n    try:  # first try expr_or_pattern as a Pattern\n        return expr_or_pattern.match(expr)\n    except AttributeError:  # expr_or_pattern is an expr, not a Pattern\n        if expr_or_pattern == expr:\n            return MatchDict()  # success\n        else:\n            res = MatchDict()\n            res.success = False\n            res.reason = \"Expressions '%s' and '%s' are not the same\" % (\n                          repr(expr_or_pattern), repr(expr))\n            return res", "response": "Recursively match expr with expr_or_pattern."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate dict with entries from other", "response": "def update(self, *others):\n        \"\"\"Update dict with entries from `other`\n\n        If `other` has an attribute ``success=False`` and ``reason``, those\n        attributes are copied as well\n        \"\"\"\n        for other in others:\n            for key, val in other.items():\n                self[key] = val\n            try:\n                if not other.success:\n                    self.success = False\n                    self.reason = other.reason\n            except AttributeError:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef extended_arg_patterns(self):\n        for arg in self._arg_iterator(self.args):\n            if isinstance(arg, Pattern):\n                if arg.mode > self.single:\n                    while True:\n                        yield arg\n                else:\n                    yield arg\n            else:\n                yield arg", "response": "Iterator over patterns for positional arguments to be matched\n\nosity"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks the last argument pattern for the current argument and returns a dict that maps the wildcard name to an empty list of the last argument.", "response": "def _check_last_arg_pattern(self, current_arg_pattern, last_arg_pattern):\n        \"\"\"Given a \"current\" arg pattern (that was used to match the last\n        actual argument of an expression), and another (\"last\") argument\n        pattern, raise a ValueError, unless the \"last\" argument pattern is a\n        \"zero or more\" wildcard. In that case, return a dict that maps the\n        wildcard name to an empty list\n        \"\"\"\n        try:\n            if last_arg_pattern.mode == self.single:\n                raise ValueError(\"insufficient number of arguments\")\n            elif last_arg_pattern.mode == self.zero_or_more:\n                if last_arg_pattern.wc_name is not None:\n                    if last_arg_pattern != current_arg_pattern:\n                        # we have to record an empty match\n                        return {last_arg_pattern.wc_name: []}\n            elif last_arg_pattern.mode == self.one_or_more:\n                if last_arg_pattern != current_arg_pattern:\n                    raise ValueError(\"insufficient number of arguments\")\n        except AttributeError:\n            raise ValueError(\"insufficient number of arguments\")\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmatching the given expression recursively.", "response": "def match(self, expr) -> MatchDict:\n        \"\"\"Match the given expression (recursively)\n\n        Returns a :class:`MatchDict` instance that maps any wildcard names to\n        the expressions that the corresponding wildcard pattern matches. For\n        (sub-)pattern that have a `mode` attribute other than `Pattern.single`,\n        the wildcard name is mapped to a list of all matched expression.\n\n        If the match is successful, the resulting :class:`MatchDict` instance\n        will evaluate to True in a boolean context. If the match is not\n        successful, it will evaluate as False, and the reason for failure is\n        available in the `reason` attribute of the :class:`MatchDict` object.\n        \"\"\"\n        res = MatchDict()\n        if self._has_non_single_arg:\n            if self._non_single_arg_on_left:\n                res.merge_lists = 1\n            else:\n                res.merge_lists = -1\n        if self.head is not None:\n            if not isinstance(expr, self.head):\n                res.reason = (\"%s is not an instance of %s\"\n                              % (repr(expr), self._repr_head()))\n                res.success = False\n                return res\n        for i_cond, condition in enumerate(self.conditions):\n            if not condition(expr):\n                res.reason = (\"%s does not meet condition %d\"\n                              % (repr(expr), i_cond+1))\n                res.success = False\n                return res\n        try:\n            if self.args is not None:\n                arg_pattern = self.extended_arg_patterns()\n                for arg in self._arg_iterator(expr.args):\n                    current_arg_pattern = next(arg_pattern)\n                    res.update(match_pattern(current_arg_pattern, arg))\n                    if not res.success:\n                        return res\n                # ensure that we have matched all arg patterns\n                try:\n                    last_arg_pattern = next(arg_pattern)\n                    res.update(self._check_last_arg_pattern(\n                                    current_arg_pattern, last_arg_pattern))\n                except StopIteration:\n                    pass  # expected, if current_arg_pattern was the last one\n            if self.kwargs is not None:\n                for key, arg_pattern in self.kwargs.items():\n                    res.update(match_pattern(arg_pattern, expr.kwargs[key]))\n                    if not res.success:\n                        return res\n        except AttributeError as exc_info:\n            res.reason = (\"%s is a scalar, not an Expression: %s\"\n                          % (repr(expr), str(exc_info)))\n            res.success = False\n        except ValueError as exc_info:\n            res.reason = \"%s: %s\" % (repr(expr), str(exc_info))\n            res.success = False\n        except StopIteration:\n            res.reason = (\"%s has an too many positional arguments\"\n                          % repr(expr))\n            res.success = False\n        except KeyError as exc_info:\n            if \"has already been set\" in str(exc_info):\n                res.reason = \"Double wildcard: %s\" % str(exc_info)\n            else:\n                res.reason = (\"%s has no keyword argument %s\"\n                              % (repr(expr), str(exc_info)))\n            res.success = False\n        if res.success:\n            if self.wc_name is not None:\n                try:\n                    if self.mode > self.single:\n                        res[self.wc_name] = [expr, ]\n                    else:\n                        res[self.wc_name] = expr\n                except KeyError as exc_info:\n                    res.reason = \"Double wildcard: %s\" % str(exc_info)\n                    res.success = False\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists of all matching ( sub - expressions in expr", "response": "def findall(self, expr):\n        \"\"\"list of all matching (sub-)expressions in `expr`\n\n        See also:\n            :meth:`finditer` yields the matches (:class:`MatchDict` instances)\n            for the matched expressions.\n        \"\"\"\n        result = []\n        try:\n            for arg in expr.args:\n                result.extend(self.findall(arg))\n            for arg in expr.kwargs.values():\n                result.extend(self.findall(arg))\n        except AttributeError:\n            pass\n        if self.match(expr):\n            result.append(expr)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all matches for any matching ( sub - expressions in expr.", "response": "def finditer(self, expr):\n        \"\"\"Return an iterator over all matches in `expr`\n\n        Iterate over all :class:`MatchDict` results of matches for any\n        matching (sub-)expressions in `expr`. The order of the matches conforms\n        to the equivalent matched expressions returned by :meth:`findall`.\n        \"\"\"\n        try:\n            for arg in expr.args:\n                for m in self.finditer(arg):\n                    yield m\n            for arg in expr.kwargs.values():\n                for m in self.finditer(arg):\n                    yield m\n        except AttributeError:\n            pass\n        m = self.match(expr)\n        if m:\n            yield m"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef wc_names(self):\n        if self.wc_name is None:\n            res = set()\n        else:\n            res = set([self.wc_name])\n        if self.args is not None:\n            for arg in self.args:\n                if isinstance(arg, Pattern):\n                    res.update(arg.wc_names)\n        if self.kwargs is not None:\n            for val in self.kwargs.values():\n                if isinstance(val, Pattern):\n                    res.update(val.wc_names)\n        return res", "response": "Returns a set of all wildcard names occurring in the pattern"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an instantiated Expression as", "response": "def instantiate(self, cls=None):\n        \"\"\"Return an instantiated Expression as\n        ``cls.create(*self.args, **self.kwargs)``\n\n        Args:\n            cls (class): The class of the instantiated expression. If not\n            given, ``self.cls`` will be used.\n        \"\"\"\n        if cls is None:\n            cls = self.cls\n        if cls is None:\n            raise TypeError(\"cls must a class\")\n        return cls.create(*self.args, **self.kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef from_expr(cls, expr):\n        return cls(expr.args, expr.kwargs, cls=expr.__class__)", "response": "Instantiate proto - expression from the given Expression"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_entry_model():\n    global _EntryModel\n\n    if _EntryModel is None:\n        # This method is likely called the first time when the admin initializes, the sitemaps module is imported, or BaseBlogMixin is used.\n        # Either way, it needs to happen after all apps have initialized, to make sure the model can be imported.\n        if not appsettings.FLUENT_BLOGS_ENTRY_MODEL:\n            _EntryModel = Entry\n        else:\n            app_label, model_name = appsettings.FLUENT_BLOGS_ENTRY_MODEL.rsplit('.', 1)\n            _EntryModel = apps.get_model(app_label, model_name)\n\n            if _EntryModel is None:\n                raise ImportError(\"{app_label}.{model_name} could not be imported.\".format(app_label=app_label, model_name=model_name))\n\n        # Auto-register with django-fluent-comments moderation\n        if 'fluent_comments' in settings.INSTALLED_APPS and issubclass(_EntryModel, CommentsEntryMixin):\n            from fluent_comments.moderation import moderate_model\n            moderate_model(\n                _EntryModel,\n                publication_date_field='publication_date',\n                enable_comments_field='enable_comments',\n            )\n\n        # Auto-register with django-any-urlfield\n        if 'any_urlfield' in settings.INSTALLED_APPS:\n            from any_urlfield.models import AnyUrlField\n            from any_urlfield.forms.widgets import SimpleRawIdWidget\n            AnyUrlField.register_model(_EntryModel, widget=SimpleRawIdWidget(_EntryModel))\n\n    return _EntryModel", "response": "Returns the actual entry model that is in use."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the category model to use.", "response": "def get_category_model():\n    \"\"\"\n    Return the category model to use.\n\n    This function reads the :ref:`FLUENT_BLOGS_CATEGORY_MODEL` setting to find the model.\n    \"\"\"\n    app_label, model_name = appsettings.FLUENT_BLOGS_CATEGORY_MODEL.rsplit('.', 1)\n    try:\n        return apps.get_model(app_label, model_name)\n    except Exception as e:  # ImportError/LookupError\n        raise ImproperlyConfigured(\"Failed to import FLUENT_BLOGS_CATEGORY_MODEL '{0}': {1}\".format(\n            appsettings.FLUENT_BLOGS_CATEGORY_MODEL, str(e)\n        ))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef blog_reverse(viewname, args=None, kwargs=None, current_app='fluent_blogs', **page_kwargs):\n    return mixed_reverse(viewname, args=args, kwargs=kwargs, current_app=current_app, **page_kwargs)", "response": "Reverse a URL to the blog."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef expand_commutators_leibniz(expr, expand_expr=True):\n    recurse = partial(expand_commutators_leibniz, expand_expr=expand_expr)\n    A = wc('A', head=Operator)\n    C = wc('C', head=Operator)\n    AB = wc('AB', head=OperatorTimes)\n    BC = wc('BC', head=OperatorTimes)\n\n    def leibniz_right(A, BC):\n        \"\"\"[A, BC] -> [A, B] C + B [A, C]\"\"\"\n        B = BC.operands[0]\n        C = OperatorTimes.create(*BC.operands[1:])\n        return Commutator.create(A, B) * C + B * Commutator.create(A, C)\n\n    def leibniz_left(AB, C):\n        \"\"\"[AB, C] -> A [B, C] C + [A, C] B\"\"\"\n        A = AB.operands[0]\n        B = OperatorTimes(*AB.operands[1:])\n        return A * Commutator.create(B, C) + Commutator.create(A, C) * B\n\n    rules = OrderedDict([\n        ('leibniz1', (\n            pattern(Commutator, A, BC),\n            lambda A, BC: recurse(leibniz_right(A, BC).expand()))),\n        ('leibniz2', (\n            pattern(Commutator, AB, C),\n            lambda AB, C: recurse(leibniz_left(AB, C).expand())))])\n\n    if expand_expr:\n        res = _apply_rules(expr.expand(), rules).expand()\n    else:\n        res = _apply_rules(expr, rules)\n    return res", "response": "Recursively expand commutators in expr according to the Leibniz rule."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize the printing system.", "response": "def init_printing(*, reset=False, init_sympy=True, **kwargs):\n    \"\"\"Initialize the printing system.\n\n    This determines the behavior of the :func:`ascii`, :func:`unicode`,\n    and :func:`latex` functions, as well as the ``__str__`` and ``__repr__`` of\n    any :class:`.Expression`.\n\n    The routine may be called in one of two forms. First,\n\n    ::\n\n        init_printing(\n            str_format=<str_fmt>, repr_format=<repr_fmt>,\n            caching=<use_caching>, **settings)\n\n    provides a simplified, \"manual\" setup with the following parameters.\n\n    Args:\n        str_format (str): Format for ``__str__`` representation of an\n            :class:`.Expression`. One of 'ascii', 'unicode', 'latex', 'srepr',\n            'indsrepr' (\"indented `srepr`\"), or 'tree'. The string\n            representation will be affected by the settings for the\n            corresponding print routine, e.g. :func:`unicode` for\n            ``str_format='unicode'``\n        repr_format (str): Like `str_format`, but for ``__repr__``. This is\n            what gets displayed in an interactive (I)Python session.\n        caching (bool): By default, the printing functions  (:func:`ascii`,\n            :func:`unicode`, :func:`latex`) cache their result for any\n            expression and sub-expression. This is both for efficiency and to\n            give the ability to to supply custom strings for subexpression by\n            passing a `cache` parameter to the printing functions. Initializing\n            the printing system with ``caching=False`` disables this\n            possibility.\n        settings: Any setting understood by any of the printing routines.\n\n    Second,\n\n    ::\n\n        init_printing(inifile=<path_to_file>)\n\n\n    allows for more detailed settings through a config file, see the\n    :ref:`notes on using an INI file <ini_file_printing>`.\n\n    If `str_format` or `repr_format` are not given, they will be set to\n    'unicode' if the current terminal is known to support an UTF8 (accordig to\n    ``sys.stdout.encoding``), and 'ascii' otherwise.\n\n    Generally, :func:`init_printing` should be called only once at the\n    beginning of a script or notebook. If it is called multiple times, any\n    settings accumulate. To avoid this and to reset the printing system to the\n    defaults, you may pass ``reset=True``.  In a Jupyter notebook, expressions\n    are rendered graphically via LaTeX, using the settings as they affect the\n    :func:`latex` printer.\n\n    The :func:`sympy.init_printing()` routine is called automatically, unless\n    `init_sympy` is given as ``False``.\n\n    See also:\n        :func:`configure_printing` allows to temporarily change the printing\n        system from what was configured in :func:`init_printing`.\n    \"\"\"\n    # return either None (default) or a dict of frozen attributes if\n    # ``_freeze=True`` is given as a keyword argument (internal use in\n    # `configure_printing` only)\n    logger = logging.getLogger(__name__)\n    if reset:\n        SympyPrinter._global_settings = {}\n    if init_sympy:\n        if kwargs.get('repr_format', '') == 'unicode':\n            sympy_init_printing(use_unicode=True)\n        if kwargs.get('repr_format', '') == 'ascii':\n            sympy_init_printing(use_unicode=False)\n        else:\n            sympy_init_printing()  # let sympy decide by itself\n    if 'inifile' in kwargs:\n        invalid_kwargs = False\n        if '_freeze' in kwargs:\n            _freeze = kwargs['_freeze']\n            if len(kwargs) != 2:\n                invalid_kwargs = True\n        else:\n            _freeze = False\n            if len(kwargs) != 1:\n                invalid_kwargs = True\n        if invalid_kwargs:\n            raise TypeError(\n                \"The `inifile` argument cannot be combined with any \"\n                \"other keyword arguments\")\n        logger.debug(\n            \"Initializating printing from INI file %s\", kwargs['inifile'])\n        return _init_printing_from_file(kwargs['inifile'], _freeze=_freeze)\n    else:\n        logger.debug(\n            \"Initializating printing with direct settings: %s\", repr(kwargs))\n        return _init_printing(**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure_printing(**kwargs):\n    freeze = init_printing(_freeze=True, **kwargs)\n    try:\n        yield\n    finally:\n        for obj, attr_map in freeze.items():\n            for attr, val in attr_map.items():\n                setattr(obj, attr, val)", "response": "Context manager for temporarily changing the printing system."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ascii(expr, cache=None, **settings):\n    try:\n        if cache is None and len(settings) == 0:\n            return ascii.printer.doprint(expr)\n        else:\n            printer = ascii._printer_cls(cache, settings)\n            return printer.doprint(expr)\n    except AttributeError:\n        # init_printing was not called. Setting up defaults\n        ascii._printer_cls = QnetAsciiPrinter\n        ascii.printer = ascii._printer_cls()\n        return ascii(expr, cache, **settings)", "response": "Return an ASCII representation of the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a unicode representation of the given object or expression.", "response": "def unicode(expr, cache=None, **settings):\n    \"\"\"Return a unicode representation of the given object / expression\n\n    Args:\n        expr: Expression to print\n        cache (dict or None): dictionary to use for caching\n        show_hs_label (bool or str): Whether to a label for the Hilbert space\n            of `expr`. By default (``show_hs_label=True``), the label is shown\n            as a superscript. It can be shown as a subscript with\n            ``show_hs_label='subscript'`` or suppressed entirely\n            (``show_hs_label=False``)\n        sig_as_ketbra (bool): Whether to render instances of\n            :class:`.LocalSigma` as a ket-bra (default), or as an operator\n            symbol\n        unicode_sub_super (bool): Whether to try to use unicode symbols for\n            sub- or superscripts if possible\n        unicode_op_hats (bool): Whether to draw unicode hats on single-letter\n            operator symbols\n\n    Examples:\n\n        >>> A = OperatorSymbol('A', hs=1); B = OperatorSymbol('B', hs=1)\n        >>> unicode(A + B)\n        'A\u0302\u207d\u00b9\u207e + B\u0302\u207d\u00b9\u207e'\n        >>> unicode(A + B, cache={A: 'A', B: 'B'})\n        'A + B'\n        >>> unicode(A + B, show_hs_label='subscript')\n        'A\u0302\u208d\u2081\u208e + B\u0302\u208d\u2081\u208e'\n        >>> unicode(A + B, show_hs_label=False)\n        'A\u0302 + B\u0302'\n        >>> unicode(LocalSigma(0, 1, hs=1))\n        '|0\u27e9\u27e81|\u207d\u00b9\u207e'\n        >>> unicode(LocalSigma(0, 1, hs=1), sig_as_ketbra=False)\n        '\u03c3\u0302_0,1^(1)'\n        >>> unicode(A + B, unicode_sub_super=False)\n        'A\u0302^(1) + B\u0302^(1)'\n        >>> unicode(A + B, unicode_op_hats=False)\n        'A\u207d\u00b9\u207e + B\u207d\u00b9\u207e'\n\n    Note that the accepted parameters and their default values may be changed\n    through :func:`init_printing` or :func:`configure_printing`\n    \"\"\"\n    try:\n        if cache is None and len(settings) == 0:\n            return unicode.printer.doprint(expr)\n        else:\n            printer = unicode._printer_cls(cache, settings)\n            return printer.doprint(expr)\n    except AttributeError:\n        # init_printing was not called. Setting up defaults\n        unicode._printer_cls = QnetUnicodePrinter\n        unicode.printer = unicode._printer_cls()\n        return unicode(expr, cache, **settings)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef latex(expr, cache=None, **settings):\n    try:\n        if cache is None and len(settings) == 0:\n            return latex.printer.doprint(expr)\n        else:\n            printer = latex._printer_cls(cache, settings)\n            return printer.doprint(expr)\n    except AttributeError:\n        # init_printing was not called. Setting up defaults\n        latex._printer_cls = QnetLatexPrinter\n        latex.printer = latex._printer_cls()\n        return latex(expr, cache, **settings)", "response": "r Returns a LaTeX representation of the given expression."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrendering the given expression into a string that can be evaluated in an ancestry appropriate context to re - instantiate an identical expression.", "response": "def srepr(expr, indented=False, cache=None):\n    \"\"\"Render the given expression into a string that can be evaluated in an\n    appropriate context to re-instantiate an identical expression. If\n    `indented` is False (default), the resulting string is a single line.\n    Otherwise, the result is a multiline string, and each positional and\n    keyword argument of each `Expression` is on a separate line, recursively\n    indented to produce a tree-like output. The `cache` may be used to generate\n    more readable expressions.\n\n    Example:\n\n        >>> hs = LocalSpace('1')\n        >>> A = OperatorSymbol('A', hs=hs); B = OperatorSymbol('B', hs=hs)\n        >>> expr = A + B\n        >>> srepr(expr)\n        \"OperatorPlus(OperatorSymbol('A', hs=LocalSpace('1')), OperatorSymbol('B', hs=LocalSpace('1')))\"\n        >>> eval(srepr(expr)) == expr\n        True\n        >>> srepr(expr, cache={hs:'hs'})\n        \"OperatorPlus(OperatorSymbol('A', hs=hs), OperatorSymbol('B', hs=hs))\"\n        >>> eval(srepr(expr, cache={hs:'hs'})) == expr\n        True\n        >>> print(srepr(expr, indented=True))\n        OperatorPlus(\n            OperatorSymbol(\n                'A',\n                hs=LocalSpace(\n                    '1')),\n            OperatorSymbol(\n                'B',\n                hs=LocalSpace(\n                    '1')))\n        >>> eval(srepr(expr, indented=True)) == expr\n        True\n\n    See also:\n        :func:`~qnet.printing.tree.print_tree`, respectively\n        :func:`qnet.printing.tree.tree`, produces an output similar to\n        the indented :func:`srepr`, for interactive use. Their result\n        cannot be evaluated and the exact output depends on\n        :func:`init_printing`.\n\n        :func:`~qnet.printing.dot.dotprint` provides a way to graphically\n        explore the tree structure of an expression.\n    \"\"\"\n    if indented:\n        printer = IndentedSReprPrinter(cache=cache)\n    else:\n        printer = QnetSReprPrinter(cache=cache)\n    return printer.doprint(expr)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the last modification of the entry.", "response": "def lastmod(self, category):\n        \"\"\"Return the last modification of the entry.\"\"\"\n        lastitems = EntryModel.objects.published().order_by('-modification_date').filter(categories=category).only('modification_date')\n        return lastitems[0].modification_date"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lastmod(self, author):\n        lastitems = EntryModel.objects.published().order_by('-modification_date').filter(author=author).only('modification_date')\n        return lastitems[0].modification_date", "response": "Return the last modification of the entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the last modification of the entry.", "response": "def lastmod(self, tag):\n        \"\"\"Return the last modification of the entry.\"\"\"\n        lastitems = EntryModel.objects.published().order_by('-modification_date').filter(tags=tag).only('modification_date')\n        return lastitems[0].modification_date"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a QNET expression to a qutip object.", "response": "def convert_to_qutip(expr, full_space=None, mapping=None):\n    \"\"\"Convert a QNET expression to a qutip object\n\n    Args:\n        expr: a QNET expression\n        full_space (HilbertSpace): The\n            Hilbert space in which `expr` is defined. If not given,\n            ``expr.space`` is used. The Hilbert space must have a well-defined\n            basis.\n        mapping (dict): A mapping of any (sub-)expression to either a\n            `quip.Qobj` directly, or to a callable that will convert the\n            expression into a `qutip.Qobj`. Useful for e.g. supplying objects\n            for symbols\n    Raises:\n        ValueError: if `expr` is not in `full_space`, or if `expr` cannot be\n            converted.\n    \"\"\"\n    if full_space is None:\n        full_space = expr.space\n    if not expr.space.is_tensor_factor_of(full_space):\n        raise ValueError(\n            \"expr '%s' must be in full_space %s\" % (expr, full_space))\n    if full_space == TrivialSpace:\n        raise AlgebraError(\n            \"Cannot convert object in TrivialSpace to qutip. \"\n            \"You may pass a non-trivial `full_space`\")\n    if mapping is not None:\n        if expr in mapping:\n            ret = mapping[expr]\n            if isinstance(ret, qutip.Qobj):\n                return ret\n            else:\n                assert callable(ret)\n                return ret(expr)\n    if expr is IdentityOperator:\n        local_spaces = full_space.local_factors\n        if len(local_spaces) == 0:\n            raise ValueError(\"full_space %s does not have local factors\"\n                             % full_space)\n        else:\n            return qutip.tensor(*[qutip.qeye(s.dimension)\n                                  for s in local_spaces])\n    elif expr is ZeroOperator:\n        return qutip.tensor(\n            *[qutip.Qobj(csr_matrix((s.dimension, s.dimension)))\n              for s in full_space.local_factors]\n        )\n    elif isinstance(expr, LocalOperator):\n        return _convert_local_operator_to_qutip(expr, full_space, mapping)\n    elif (isinstance(expr, Operator) and isinstance(expr, Operation)):\n        return _convert_operator_operation_to_qutip(expr, full_space, mapping)\n    elif isinstance(expr, OperatorTrace):\n        raise NotImplementedError('Cannot convert OperatorTrace to '\n                                  'qutip')\n        # actually, this is perfectly doable in principle, but requires a bit\n        # of work\n    elif isinstance(expr, State):\n        return _convert_ket_to_qutip(expr, full_space, mapping)\n    elif isinstance(expr, SuperOperator):\n        return _convert_superoperator_to_qutip(expr, full_space, mapping)\n    elif isinstance(expr, Operation):\n        # This is assumed to be an Operation on states, as we have handled all\n        # other Operations above. Eventually, a StateOperation should be\n        # defined as a common superclass for the Operations in the state\n        # algebra\n        return _convert_state_operation_to_qutip(expr, full_space, mapping)\n    elif isinstance(expr, SLH):\n        # SLH object cannot be converted to a single qutip object, only to a\n        # nested list of qutip object. That's why a separate routine\n        # SLH_to_qutip exists\n        raise ValueError(\"SLH objects can only be converted using \"\n                         \"SLH_to_qutip routine\")\n    else:\n        raise ValueError(\"Cannot convert '%s' of type %s\"\n                         % (str(expr), type(expr)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating and return QuTiP representation matrices for the Hamiltonian and Lindblad operators from the given SLH object.", "response": "def SLH_to_qutip(slh, full_space=None, time_symbol=None,\n                 convert_as='pyfunc'):\n    \"\"\"Generate and return QuTiP representation matrices for the Hamiltonian\n    and the collapse operators. Any inhomogeneities in the Lindblad operators\n    (resulting from coherent drives) will be moved into the Hamiltonian, cf.\n    :func:`~qnet.algebra.circuit_algebra.move_drive_to_H`.\n\n    Args:\n        slh (SLH): The SLH object from which to generate the qutip data\n        full_space (HilbertSpace or None): The Hilbert space in which to\n            represent the operators. If None, the space of `shl` will be used\n        time_symbol (:class:`sympy.Symbol` or None): The symbol (if any)\n            expressing time dependence (usually 't')\n        convert_as (str): How to express time dependencies to qutip. Must be\n            'pyfunc' or 'str'\n\n    Returns:\n        tuple ``(H, [L1, L2, ...])`` as numerical `qutip.Qobj` representations,\n        where ``H`` and each ``L`` may be a nested list to express time\n        dependence, e.g.  ``H = [H0, [H1, eps_t]]``, where ``H0`` and\n        ``H1`` are of type `qutip.Qobj`, and ``eps_t`` is either a string\n        (``convert_as='str'``) or a function (``convert_as='pyfunc'``)\n\n    Raises:\n        AlgebraError: If the Hilbert space (`slh.space` or `full_space`) is\n            invalid for numerical conversion\n    \"\"\"\n    if full_space:\n        if not full_space >= slh.space:\n            raise AlgebraError(\"full_space=\"+str(full_space)+\" needs to \"\n                               \"at least include slh.space = \"+str(slh.space))\n    else:\n        full_space = slh.space\n    if full_space == TrivialSpace:\n        raise AlgebraError(\n            \"Cannot convert SLH object in TrivialSpace. \"\n            \"You may pass a non-trivial `full_space`\")\n    slh = move_drive_to_H(slh)\n    if time_symbol is None:\n        H = convert_to_qutip(slh.H, full_space=full_space)\n        Ls = []\n        for L in slh.Ls:\n            if is_scalar(L):\n                L = L * IdentityOperator\n            L_qutip = convert_to_qutip(L, full_space=full_space)\n            if L_qutip.norm('max') > 0:\n                Ls.append(L_qutip)\n    else:\n        H = _time_dependent_to_qutip(slh.H, full_space, time_symbol,\n                                     convert_as)\n        Ls = []\n        for L in slh.Ls:\n            if is_scalar(L):\n                L = L * IdentityOperator\n            L_qutip = _time_dependent_to_qutip(L, full_space, time_symbol,\n                                               convert_as)\n            Ls.append(L_qutip)\n    return H, Ls"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _convert_local_operator_to_qutip(expr, full_space, mapping):\n    n = full_space.dimension\n    if full_space != expr.space:\n        all_spaces = full_space.local_factors\n        own_space_index = all_spaces.index(expr.space)\n        return qutip.tensor(\n            *([qutip.qeye(s.dimension)\n               for s in all_spaces[:own_space_index]] +\n              [convert_to_qutip(expr, expr.space, mapping=mapping), ] +\n              [qutip.qeye(s.dimension)\n               for s in all_spaces[own_space_index + 1:]])\n        )\n    if isinstance(expr, Create):\n        return qutip.create(n)\n    elif isinstance(expr, Jz):\n        return qutip.jmat((expr.space.dimension-1)/2., \"z\")\n    elif isinstance(expr, Jplus):\n        return qutip.jmat((expr.space.dimension-1)/2., \"+\")\n    elif isinstance(expr, Jminus):\n        return qutip.jmat((expr.space.dimension-1)/2., \"-\")\n    elif isinstance(expr, Destroy):\n        return qutip.destroy(n)\n    elif isinstance(expr, Phase):\n        arg = complex(expr.operands[1]) * arange(n)\n        d = np_cos(arg) + 1j * np_sin(arg)\n        return qutip.Qobj(np_diag(d))\n    elif isinstance(expr, Displace):\n        alpha = expr.operands[1]\n        return qutip.displace(n, alpha)\n    elif isinstance(expr, Squeeze):\n        eta = expr.operands[1]\n        return qutip.displace(n, eta)\n    elif isinstance(expr, LocalSigma):\n        j = expr.j\n        k = expr.k\n        if isinstance(j, str):\n            j = expr.space.basis_labels.index(j)\n        if isinstance(k, str):\n            k = expr.space.basis_labels.index(k)\n        ket = qutip.basis(n, j)\n        bra = qutip.basis(n, k).dag()\n        return ket * bra\n    else:\n        raise ValueError(\"Cannot convert '%s' of type %s\"\n                         % (str(expr), type(expr)))", "response": "Convert a LocalOperator instance to qutip"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _time_dependent_to_qutip(\n        op, full_space=None, time_symbol=symbols(\"t\", real=True),\n        convert_as='pyfunc'):\n    \"\"\"Convert a possiblty time-dependent operator into the nested-list\n    structure required by QuTiP\"\"\"\n    if full_space is None:\n        full_space = op.space\n    if time_symbol in op.free_symbols:\n        op = op.expand()\n        if isinstance(op, OperatorPlus):\n            result = []\n            for o in op.operands:\n                if time_symbol not in o.free_symbols:\n                    if len(result) == 0:\n                        result.append(convert_to_qutip(o,\n                                                       full_space=full_space))\n                    else:\n                        result[0] += convert_to_qutip(o, full_space=full_space)\n            for o in op.operands:\n                if time_symbol in o.free_symbols:\n                    result.append(_time_dependent_to_qutip(o, full_space,\n                                  time_symbol, convert_as))\n            return result\n        elif (\n                isinstance(op, ScalarTimesOperator) and\n                isinstance(op.coeff, ScalarValue)):\n            if convert_as == 'pyfunc':\n                func_no_args = lambdify(time_symbol, op.coeff.val)\n                if {time_symbol, } == op.coeff.free_symbols:\n                    def func(t, args):\n                        # args are ignored for increased efficiency, since we\n                        # know there are no free symbols except t\n                        return func_no_args(t)\n                else:\n                    def func(t, args):\n                        return func_no_args(t).subs(args)\n                coeff = func\n            elif convert_as == 'str':\n                # a bit of a hack to replace imaginary unit\n                # TODO: we can probably use one of the sympy code generation\n                # routines, or lambdify with 'numexpr' to implement this in a\n                # more robust way\n                coeff = re.sub(\"I\", \"(1.0j)\", str(op.coeff.val))\n            else:\n                raise ValueError((\"Invalid value '%s' for `convert_as`, must \"\n                                  \"be one of 'str', 'pyfunc'\") % convert_as)\n            return [convert_to_qutip(op.term, full_space), coeff]\n        else:\n            raise ValueError(\"op cannot be expressed in qutip. It must have \"\n                             \"the structure op = sum_i f_i(t) * op_i\")\n    else:\n        return convert_to_qutip(op, full_space=full_space)", "response": "Convert a possiblty time - dependent operator into a nested - list of related resources."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nleave - justify text to a total of width", "response": "def ljust(text, width, fillchar=' '):\n    \"\"\"Left-justify text to a total of `width`\n\n    The `width` is based on graphemes::\n\n        >>> s = 'A\u0302'\n        >>> s.ljust(2)\n        'A\u0302'\n        >>> ljust(s, 2)\n        'A\u0302 '\n    \"\"\"\n    len_text = grapheme_len(text)\n    return text + fillchar * (width - len_text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrighting - justify text for a total of width graphemes.", "response": "def rjust(text, width, fillchar=' '):\n    \"\"\"Right-justify text for a total of `width` graphemes\n\n    The `width` is based on graphemes::\n\n        >>> s = 'A\u0302'\n        >>> s.rjust(2)\n        'A\u0302'\n        >>> rjust(s, 2)\n        ' A\u0302'\n    \"\"\"\n    len_text = grapheme_len(text)\n    return fillchar * (width - len_text) + text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a Kronecker delta symbol.", "response": "def KroneckerDelta(i, j, simplify=True):\n    \"\"\"Kronecker delta symbol\n\n    Return :class:`One` (`i` equals `j`)), :class:`Zero` (`i` and `j` are\n    non-symbolic an unequal), or a :class:`ScalarValue` wrapping SymPy's\n    :class:`~sympy.functions.special.tensor_functions.KroneckerDelta`.\n\n        >>> i, j = IdxSym('i'), IdxSym('j')\n        >>> KroneckerDelta(i, i)\n        One\n        >>> KroneckerDelta(1, 2)\n        Zero\n        >>> KroneckerDelta(i, j)\n        KroneckerDelta(i, j)\n\n    By default, the Kronecker delta is returned in a simplified form, e.g::\n\n        >>> KroneckerDelta((i+1)/2, (j+1)/2)\n        KroneckerDelta(i, j)\n\n    This may be suppressed by setting `simplify` to False::\n\n        >>> KroneckerDelta((i+1)/2, (j+1)/2, simplify=False)\n        KroneckerDelta(i/2 + 1/2, j/2 + 1/2)\n\n    Raises:\n        TypeError: if `i` or `j` is not an integer or sympy expression. There\n        is no automatic sympification of `i` and `j`.\n    \"\"\"\n    from qnet.algebra.core.scalar_algebra import ScalarValue, One\n    if not isinstance(i, (int, sympy.Basic)):\n        raise TypeError(\n            \"i is not an integer or sympy expression: %s\" % type(i))\n    if not isinstance(j, (int, sympy.Basic)):\n        raise TypeError(\n            \"j is not an integer or sympy expression: %s\" % type(j))\n    if i == j:\n        return One\n    else:\n        delta = sympy.KroneckerDelta(i, j)\n        if simplify:\n            delta = _simplify_delta(delta)\n        return ScalarValue.create(delta)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a symbolic square root of a scalar value.", "response": "def sqrt(scalar):\n    \"\"\"Square root of a :class:`Scalar` or scalar value\n\n    This always returns a :class:`Scalar`, and uses a symbolic square root if\n    possible (i.e., for non-floats)::\n\n        >>> sqrt(2)\n        sqrt(2)\n\n        >>> sqrt(2.0)\n        1.414213...\n\n    For a :class:`ScalarExpression` argument, it returns a\n    :class:`ScalarPower` instance::\n\n        >>> braket = KetSymbol('Psi', hs=0).dag() * KetSymbol('Phi', hs=0)\n        >>> nrm = sqrt(braket * braket.dag())\n        >>> print(srepr(nrm, indented=True))\n        ScalarPower(\n            ScalarTimes(\n                BraKet(\n                    KetSymbol(\n                        'Phi',\n                        hs=LocalSpace(\n                            '0')),\n                    KetSymbol(\n                        'Psi',\n                        hs=LocalSpace(\n                            '0'))),\n                BraKet(\n                    KetSymbol(\n                        'Psi',\n                        hs=LocalSpace(\n                            '0')),\n                    KetSymbol(\n                        'Phi',\n                        hs=LocalSpace(\n                            '0')))),\n            ScalarValue(\n                Rational(1, 2)))\n    \"\"\"\n    if isinstance(scalar, ScalarValue):\n        scalar = scalar.val\n    if scalar == 1:\n        return One\n    elif scalar == 0:\n        return Zero\n    elif isinstance(scalar, (float, complex, complex128, float64)):\n        return ScalarValue.create(numpy.sqrt(scalar))\n    elif isinstance(scalar, (int, sympy.Basic, int64)):\n        return ScalarValue.create(sympy.sqrt(scalar))\n    elif isinstance(scalar, Scalar):\n        return scalar**(sympy.sympify(1) / 2)\n    else:\n        raise TypeError(\"Unknown type of scalar: %r\" % type(scalar))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(cls, val):\n        if val in cls._invalid:\n            raise ValueError(\"Invalid value %r\" % val)\n        if val == 0:\n            return Zero\n        elif val == 1:\n            return One\n        elif isinstance(val, Scalar):\n            return val\n        else:\n            # We instantiate ScalarValue directly to avoid the overhead of\n            # super().create(). Thus, there is no caching for scalars (which is\n            # probably a good thing)\n            return cls(val)", "response": "Instatiate the ScalarValue while recognizing Zero One and Scalar instances as val are left unchanged."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the real part of the object.", "response": "def real(self):\n        \"\"\"Real part\"\"\"\n        if hasattr(self.val, 'real'):\n            return self.val.real\n        else:\n            # SymPy\n            return self.val.as_real_imag()[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef conjugate(self):\n        return self.__class__.create(\n            *[arg.conjugate() for arg in reversed(self.args)])", "response": "Complex conjugate of the product"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncomplexes conjugate of the indexed sum", "response": "def conjugate(self):\n        \"\"\"Complex conjugate of of the indexed sum\"\"\"\n        return self.__class__.create(self.term.conjugate(), *self.ranges)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef real(self):\n        return self.__class__.create(self.term.real, *self.ranges)", "response": "Return a new TermSet containing only the real part of the term."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef imag(self):\n        return self.__class__.create(self.term.imag, *self.ranges)", "response": "getImaginary part of the term"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assoc_indexed(cls, ops, kwargs):\n    from qnet.algebra.core.abstract_quantum_algebra import (\n        ScalarTimesQuantumExpression)\n    term, *ranges = ops\n\n    if isinstance(term, cls):\n        coeff = 1\n    elif isinstance(term, ScalarTimesQuantumExpression):\n        coeff = term.coeff\n        term = term.term\n        if not isinstance(term, cls):\n            return ops, kwargs\n    else:\n        return ops, kwargs\n\n    term = term.make_disjunct_indices(*ranges)\n    combined_ranges = tuple(ranges) + term.ranges\n\n    if coeff == 1:\n        return cls.create(term.term, *combined_ranges)\n    else:\n        bound_symbols = set([r.index_symbol for r in combined_ranges])\n        if len(coeff.free_symbols.intersection(bound_symbols)) == 0:\n            return coeff * cls.create(term.term, *combined_ranges)\n        else:\n            return cls.create(coeff * term.term, *combined_ranges)", "response": "rFlatten nested indexed structures while pulling out possible prefactors\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef idem(cls, ops, kwargs):\n    return sorted(set(ops), key=cls.order_key), kwargs", "response": "Remove duplicate arguments and order them via the cls s order_key key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nre-orders arguments via the class's ``order_key`` key object/function. Use this for commutative operations: E.g.:: >>> class Times(Operation): ... order_key = lambda val: val ... simplifications = [orderby, ] >>> Times.create(2,1) Times(1, 2)", "response": "def orderby(cls, ops, kwargs):\n    \"\"\"Re-order arguments via the class's ``order_key`` key object/function.\n    Use this for commutative operations:\n    E.g.::\n\n        >>> class Times(Operation):\n        ...     order_key = lambda val: val\n        ...     simplifications = [orderby, ]\n        >>> Times.create(2,1)\n        Times(1, 2)\n    \"\"\"\n    return sorted(ops, key=cls.order_key), kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfiltering the list of operations that are neutral elements.", "response": "def filter_neutral(cls, ops, kwargs):\n    \"\"\"Remove occurrences of a neutral element from the argument/operand list,\n    if that list has at least two elements.  To use this, one must also specify\n    a neutral element, which can be anything that allows for an equality check\n    with each argument.  E.g.::\n\n        >>> class X(Operation):\n        ...     _neutral_element = 1\n        ...     simplifications = [filter_neutral, ]\n        >>> X.create(2,1,3,1)\n        X(2, 3)\n    \"\"\"\n    c_n = cls._neutral_element\n    if len(ops) == 0:\n        return c_n\n    fops = [op for op in ops if c_n != op]  # op != c_n does NOT work\n    if len(fops) > 1:\n        return fops, kwargs\n    elif len(fops) == 1:\n        # the remaining operand is the single non-trivial one\n        return fops[0]\n    else:\n        # the original list of operands consists only of neutral elements\n        return ops[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncollect summands that occur multiple times into a single summand.", "response": "def collect_summands(cls, ops, kwargs):\n    \"\"\"Collect summands that occur multiple times into a single summand\n\n    Also filters out zero-summands.\n\n    Example:\n        >>> A, B, C = (OperatorSymbol(s, hs=0) for s in ('A', 'B', 'C'))\n        >>> collect_summands(\n        ...     OperatorPlus, (A, B, C, ZeroOperator, 2 * A, B, -C) , {})\n        ((3 * A^(0), 2 * B^(0)), {})\n        >>> collect_summands(OperatorPlus, (A, -A), {})\n        ZeroOperator\n        >>> collect_summands(OperatorPlus, (B, A, -B), {})\n        A^(0)\n    \"\"\"\n    from qnet.algebra.core.abstract_quantum_algebra import (\n        ScalarTimesQuantumExpression)\n    coeff_map = OrderedDict()\n    for op in ops:\n        if isinstance(op, ScalarTimesQuantumExpression):\n            coeff, term = op.coeff, op.term\n        else:\n            coeff, term = 1, op\n        if term in coeff_map:\n            coeff_map[term] += coeff\n        else:\n            coeff_map[term] = coeff\n    fops = []\n    for (term, coeff) in coeff_map.items():\n        op = coeff * term\n        if not op.is_zero:\n            fops.append(op)\n    if len(fops) == 0:\n        return cls._zero\n    elif len(fops) == 1:\n        return fops[0]\n    else:\n        return tuple(fops), kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef collect_scalar_summands(cls, ops, kwargs):\n    # This routine is required because there is no\n    # \"ScalarTimesQuantumExpression\" for scalars: we have to extract\n    # coefficiencts from ScalarTimes instead\n    from qnet.algebra.core.scalar_algebra import (\n        Zero, One, Scalar, ScalarTimes, ScalarValue)\n    a_0 = Zero\n    coeff_map = OrderedDict()\n    for op in ops:\n        if isinstance(op, ScalarValue) or isinstance(op, Scalar._val_types):\n            a_0 += op\n            continue\n        elif isinstance(op, ScalarTimes):\n            if isinstance(op.operands[0], ScalarValue):\n                coeff = op.operands[0]\n                term = op.operands[1]\n                for sub_op in op.operands[2:]:\n                    term *= sub_op\n            else:\n                coeff, term = One, op\n        else:\n            coeff, term = One, op\n        if term in coeff_map:\n            coeff_map[term] += coeff\n        else:\n            coeff_map[term] = coeff\n    if a_0 == Zero:\n        fops = []\n    else:\n        fops = [a_0]\n    for (term, coeff) in coeff_map.items():\n        op = coeff * term\n        if not op.is_zero:\n            fops.append(op)\n    if len(fops) == 0:\n        return cls._zero\n    elif len(fops) == 1:\n        return fops[0]\n    else:\n        return tuple(fops), kwargs", "response": "Collect all ScalarValue and ScalarTimes summands from a list of ops."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_replace(cls, ops, kwargs):\n    expr = ProtoExpr(ops, kwargs)\n    if LOG:\n        logger = logging.getLogger('QNET.create')\n    for key, rule in cls._rules.items():\n        pat, replacement = rule\n        match_dict = match_pattern(pat, expr)\n        if match_dict:\n            try:\n                replaced = replacement(**match_dict)\n                if LOG:\n                    logger.debug(\n                        \"%sRule %s.%s: (%s, %s) -> %s\", (\"  \" * (LEVEL)),\n                        cls.__name__, key, expr.args, expr.kwargs, replaced)\n                return replaced\n            except CannotSimplify:\n                if LOG_NO_MATCH:\n                    logger.debug(\n                        \"%sRule %s.%s: no match: CannotSimplify\",\n                        (\"  \" * (LEVEL)), cls.__name__, key)\n                continue\n        else:\n            if LOG_NO_MATCH:\n                logger.debug(\n                    \"%sRule %s.%s: no match: %s\", (\"  \" * (LEVEL)),\n                    cls.__name__, key, match_dict.reason)\n    # No matching rules\n    return ops, kwargs", "response": "Match and replace a full operand specification to a function that provides a replacement for the whole expression that is identical to the whole expression."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_binary_replacement(first, second, cls):\n    expr = ProtoExpr([first, second], {})\n    if LOG:\n        logger = logging.getLogger('QNET.create')\n    for key, rule in cls._binary_rules.items():\n        pat, replacement = rule\n        match_dict = match_pattern(pat, expr)\n        if match_dict:\n            try:\n                replaced = replacement(**match_dict)\n                if LOG:\n                    logger.debug(\n                        \"%sRule %s.%s: (%s, %s) -> %s\", (\"  \" * (LEVEL)),\n                        cls.__name__, key, expr.args, expr.kwargs, replaced)\n                return replaced\n            except CannotSimplify:\n                if LOG_NO_MATCH:\n                    logger.debug(\n                        \"%sRule %s.%s: no match: CannotSimplify\",\n                        (\"  \" * (LEVEL)), cls.__name__, key)\n                continue\n        else:\n            if LOG_NO_MATCH:\n                logger.debug(\n                    \"%sRule %s.%s: no match: %s\", (\"  \" * (LEVEL)),\n                    cls.__name__, key, match_dict.reason)\n    return None", "response": "Helper function for match_replace_binary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_replace_binary(cls, ops, kwargs):\n    assert assoc in cls.simplifications, (\n        cls.__name__ + \" must be associative to use match_replace_binary\")\n    assert hasattr(cls, '_neutral_element'), (\n        cls.__name__ + \" must define a neutral element to use \"\n                       \"match_replace_binary\")\n    fops = _match_replace_binary(cls, list(ops))\n    if len(fops) == 1:\n        return fops[0]\n    elif len(fops) == 0:\n        return cls._neutral_element\n    else:\n        return fops, kwargs", "response": "Similar to func. match_replace but for arbitrary length operations and kwargs."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _match_replace_binary(cls, ops: list) -> list:\n    n = len(ops)\n    if n <= 1:\n        return ops\n    ops_left = ops[:n // 2]\n    ops_right = ops[n // 2:]\n    return _match_replace_binary_combine(\n        cls,\n        _match_replace_binary(cls, ops_left),\n        _match_replace_binary(cls, ops_right))", "response": "Reduce list of ops with binary matching"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining two fully reduced lists a b", "response": "def _match_replace_binary_combine(cls, a: list, b: list) -> list:\n    \"\"\"combine two fully reduced lists a, b\"\"\"\n    if len(a) == 0 or len(b) == 0:\n        return a + b\n    r = _get_binary_replacement(a[-1], b[0], cls)\n    if r is None:\n        return a + b\n    if r == cls._neutral_element:\n        return _match_replace_binary_combine(cls, a[:-1], b[1:])\n    if isinstance(r, cls):\n        r = list(r.args)\n    else:\n        r = [r, ]\n    return _match_replace_binary_combine(\n        cls,\n        _match_replace_binary_combine(cls, a[:-1], r),\n        b[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_cdims(cls, ops, kwargs):\n    if not len({o.cdim for o in ops}) == 1:\n        raise ValueError(\"Not all operands have the same cdim:\" + str(ops))\n    return ops, kwargs", "response": "Check that all operands have equal channel dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_cid(cls, ops, kwargs):\n    from qnet.algebra.core.circuit_algebra import CircuitZero, circuit_identity\n    if len(ops) == 0:\n        return CircuitZero\n    fops = [op for op in ops if op != circuit_identity(op.cdim)]\n    if len(fops) > 1:\n        return fops, kwargs\n    elif len(fops) == 1:\n        # the remaining operand is the single non-trivial one\n        return fops[0]\n    else:\n        # the original list of operands consists only of neutral elements\n        return ops[0]", "response": "Filter the given list of operations that are neutral elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts all operands to HilbertSpace objects and return them as a list of kwargs.", "response": "def convert_to_spaces(cls, ops, kwargs):\n    \"\"\"For all operands that are merely of type str or int, substitute\n    LocalSpace objects with corresponding labels:\n    For a string, just itself, for an int, a string version of that int.\n    \"\"\"\n    from qnet.algebra.core.hilbert_space_algebra import (\n        HilbertSpace, LocalSpace)\n    cops = [o if isinstance(o, HilbertSpace) else LocalSpace(o) for o in ops]\n    return cops, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef implied_local_space(*, arg_index=None, keys=None):\n    from qnet.algebra.core.hilbert_space_algebra import (\n        HilbertSpace, LocalSpace)\n\n    def args_to_local_space(cls, args, kwargs):\n        \"\"\"Convert (str, int) of selected args to :class:`.LocalSpace`\"\"\"\n        if isinstance(args[arg_index], LocalSpace):\n            new_args = args\n        else:\n            if isinstance(args[arg_index], (int, str)):\n                try:\n                    hs = cls._default_hs_cls(args[arg_index])\n                except AttributeError:\n                    hs = LocalSpace(args[arg_index])\n            else:\n                hs = args[arg_index]\n                assert isinstance(hs, HilbertSpace)\n            new_args = (tuple(args[:arg_index]) + (hs,) +\n                        tuple(args[arg_index + 1:]))\n        return new_args, kwargs\n\n    def kwargs_to_local_space(cls, args, kwargs):\n        \"\"\"Convert (str, int) of selected kwargs to LocalSpace\"\"\"\n        if all([isinstance(kwargs[key], LocalSpace) for key in keys]):\n            new_kwargs = kwargs\n        else:\n            new_kwargs = {}\n            for key, val in kwargs.items():\n                if key in keys:\n                    if isinstance(val, (int, str)):\n                        try:\n                            val = cls._default_hs_cls(val)\n                        except AttributeError:\n                            val = LocalSpace(val)\n                    assert isinstance(val, HilbertSpace)\n                new_kwargs[key] = val\n        return args, new_kwargs\n\n    def to_local_space(cls, args, kwargs):\n        \"\"\"Convert (str, int) of selected args and kwargs to LocalSpace\"\"\"\n        new_args, __ = args_to_local_space(args, kwargs, arg_index)\n        __, new_kwargs = kwargs_to_local_space(args, kwargs, keys)\n        return new_args, new_kwargs\n\n    if (arg_index is not None) and (keys is None):\n        return args_to_local_space\n    elif (arg_index is None) and (keys is not None):\n        return kwargs_to_local_space\n    elif (arg_index is not None) and (keys is not None):\n        return to_local_space\n    else:\n        raise ValueError(\"must give at least one of arg_index and keys\")", "response": "Returns a simplification that converts the positional argument\n    arg_index from a subclass of LocalSpace and a keyword argument with one of the given keys."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delegate_to_method(mtd):\n\n    def _delegate_to_method(cls, ops, kwargs):\n        assert len(ops) == 1\n        op, = ops\n        if hasattr(op, mtd):\n            return getattr(op, mtd)()\n        else:\n            return ops, kwargs\n\n    return _delegate_to_method", "response": "Create a simplification rule that delegates the instantiation to the\n    method mtd of the operand."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert any scalar in ops into an operator.", "response": "def scalars_to_op(cls, ops, kwargs):\n    r'''Convert any scalar $\\alpha$ in `ops` into an operator $\\alpha\n    \\identity$'''\n    from qnet.algebra.core.scalar_algebra import is_scalar\n    op_ops = []\n    for op in ops:\n        if is_scalar(op):\n            op_ops.append(op * cls._one)\n        else:\n            op_ops.append(op)\n    return op_ops, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_to_scalars(cls, ops, kwargs):\n    from qnet.algebra.core.scalar_algebra import Scalar, ScalarValue\n    scalar_ops = []\n    for op in ops:\n        if not isinstance(op, Scalar):\n            scalar_ops.append(ScalarValue(op))\n        else:\n            scalar_ops.append(op)\n    return scalar_ops, kwargs", "response": "Convert any entry in ops that is not a Scalar instance into\n    a : class : ScalarValue instance"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef disjunct_hs_zero(cls, ops, kwargs):\n    from qnet.algebra.core.hilbert_space_algebra import TrivialSpace\n    from qnet.algebra.core.operator_algebra import ZeroOperator\n    hilbert_spaces = []\n    for op in ops:\n        try:\n            hs = op.space\n        except AttributeError:  # scalars\n            hs = TrivialSpace\n        for hs_prev in hilbert_spaces:\n            if not hs.isdisjoint(hs_prev):\n                return ops, kwargs\n        hilbert_spaces.append(hs)\n    return ZeroOperator", "response": "Return ZeroOperator if all the operators in ops have a disjunct\n    Hilbert space or an unchanged ops and kwargs otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commutator_order(cls, ops, kwargs):\n    from qnet.algebra.core.operator_algebra import Commutator\n    assert len(ops) == 2\n    if cls.order_key(ops[1]) < cls.order_key(ops[0]):\n        return -1 * Commutator.create(ops[1], ops[0])\n    else:\n        return ops, kwargs", "response": "Apply anti - commutative property of the commutator to apply a standard\n    ordering of the commutator arguments"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\naccepts operands that are all bras and turn that into to bra of the operation applied to all corresponding kets", "response": "def accept_bras(cls, ops, kwargs):\n    \"\"\"Accept operands that are all bras, and turn that into to bra of the\n    operation applied to all corresponding kets\"\"\"\n    from qnet.algebra.core.state_algebra import Bra\n    kets = []\n    for bra in ops:\n        if isinstance(bra, Bra):\n            kets.append(bra.ket)\n        else:\n            return ops, kwargs\n    return Bra.create(cls.create(*kets, **kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef basis_ket_zero_outside_hs(cls, ops, kwargs):\n    from qnet.algebra.core.state_algebra import ZeroKet\n    ind, = ops\n    hs = kwargs['hs']\n    if isinstance(ind, int):\n        if ind < 0 or (hs._dimension is not None and ind >= hs._dimension):\n            return ZeroKet\n    return ops, kwargs", "response": "For a basis ket with an integer label ind return a\n    if ind is outside of the underlying Hilbert\n    space otherwise return ZeroKet"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _ranges_key(r, delta_indices):\n    idx = r.index_symbol\n    if idx in delta_indices:\n        return (r.index_symbol.primed, r.index_symbol.name)\n    else:\n        # ranges that are not in delta_indices should remain in the original\n        # order\n        return (0, ' ')", "response": "Return a key for a given index range."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting sums over KroneckerDelta prefactors", "response": "def indexed_sum_over_kronecker(cls, ops, kwargs):\n    \"\"\"Execute sums over KroneckerDelta prefactors\"\"\"\n    from qnet.algebra.core.abstract_quantum_algebra import QuantumExpression\n    term, *ranges = ops\n    assert isinstance(term, QuantumExpression)\n    deltas = set(Pattern(head=sympy.KroneckerDelta).findall(term))\n    if len(deltas) == 0:\n        return ops, kwargs  # nothing to do\n    else:  # the term contains at least one KroneckerDelta\n        delta_indices = set.union(*[set(\n            [idx for idx in delta.free_symbols if isinstance(idx, IdxSym)])\n            for delta in deltas])\n        ranges = sorted(  # sort in the order we'd prefer to eliminate\n            ranges,\n            key=partial(_ranges_key, delta_indices=delta_indices),\n            reverse=True)\n        buffer = [(term, ranges)]\n        i = 0  # position in buffer that we're currently handling\n        i_range = 0  # position of index-range for current buffer item\n        while i < len(buffer):\n            t, rs = buffer[i]\n            if rs[i_range].index_symbol in delta_indices:\n                new_items, flag = _deltasummation(t, rs, i_range)\n                new_rs = new_items[0][1]  # same for all new_items\n                buffer = buffer[:i] + new_items + buffer[i + 1:]\n                assert flag in [1, 2, 3]\n                if flag == 2:\n                    i_range += 1\n                    # * for flag == 1, leaving i_range unchanged will\n                    # effectively to to the next range (as the current range\n                    # was removed)\n                    # * for flag == 3, buffer[i] has changed, and we'll want to\n                    # call it again with the same i_range\n            else:\n                # if the index symbol doesn't occur in any KroneckerDelta,\n                # there is no chance _deltasummation will do anything; so we\n                # just skip to the next index\n                i_range += 1\n                new_rs = rs\n            if i_range >= len(new_rs):\n                # if we've exhausted the index-ranges for the current buffer\n                # item, go to the next buffer item\n                i += 1\n                i_range = 0\n        if len(buffer) == 1 and buffer[0] == (term, ranges):\n            return ops, kwargs  # couldn't resolve deltas\n        else:\n            (t, rs) = buffer[0]\n            res = t\n            if len(rs) > 0:\n                res = cls.create(t, *rs, **kwargs)\n            for (t, rs) in buffer[1:]:\n                if len(rs) > 0:\n                    t = cls.create(t, *rs, **kwargs)\n                res += t\n            return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _factors_for_expand_delta(expr):\n    from qnet.algebra.core.scalar_algebra import ScalarValue\n    from qnet.algebra.core.abstract_quantum_algebra import (\n        ScalarTimesQuantumExpression)\n    if isinstance(expr, ScalarTimesQuantumExpression):\n        yield from _factors_for_expand_delta(expr.coeff)\n        yield expr.term\n    elif isinstance(expr, ScalarValue):\n        yield from _factors_for_expand_delta(expr.val)\n    elif isinstance(expr, sympy.Basic) and expr.is_Mul:\n        yield from expr.args\n    else:\n        yield expr", "response": "Yield factors from expr mixing sympy and QNET\n    Auxiliary routine for _expand_delta."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _expand_delta(expr, idx):\n    found_first_delta = False\n    summands = None\n    for factor in _factors_for_expand_delta(expr):\n        need_to_expand = False\n        if not found_first_delta and isinstance(factor, sympy.Basic):\n            if factor.is_Add and _has_simple_delta(factor, idx):\n                need_to_expand = True\n        if need_to_expand:\n            found_first_delta = True\n            if summands is None:\n                summands = list(factor.args)\n            else:\n                summands = [summands[0]*t for t in factor.args]\n        else:\n            if summands is None:\n                summands = [factor, ]\n            else:\n                summands = [t*factor for t in summands]\n    return summands", "response": "Expand the first simple\nAddon containing a simple\nAddon and a Simple\nAddon."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _split_sympy_quantum_factor(expr):\n    from qnet.algebra.core.abstract_quantum_algebra import (\n        QuantumExpression, ScalarTimesQuantumExpression)\n    from qnet.algebra.core.scalar_algebra import ScalarValue, ScalarTimes, One\n    if isinstance(expr, ScalarTimesQuantumExpression):\n        sympy_factor, quantum_factor = _split_sympy_quantum_factor(expr.coeff)\n        quantum_factor *= expr.term\n    elif isinstance(expr, ScalarValue):\n        sympy_factor = expr.val\n        quantum_factor = expr._one\n    elif isinstance(expr, ScalarTimes):\n        sympy_factor = sympy.S(1)\n        quantum_factor = expr._one\n        for op in expr.operands:\n            op_sympy, op_quantum = _split_sympy_quantum_factor(op)\n            sympy_factor *= op_sympy\n            quantum_factor *= op_quantum\n    elif isinstance(expr, sympy.Basic):\n        sympy_factor = expr\n        quantum_factor = One\n    else:\n        sympy_factor = sympy.S(1)\n        quantum_factor = expr\n    assert isinstance(sympy_factor, sympy.Basic)\n    assert isinstance(quantum_factor, QuantumExpression)\n    return sympy_factor, quantum_factor", "response": "Split a product into sympy and qnet factors\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract a simple Kronecker Delta containing idx from expr.", "response": "def _extract_delta(expr, idx):\n    \"\"\"Extract a \"simple\" Kronecker delta containing `idx` from `expr`.\n\n    Assuming `expr` can be written as the product of a Kronecker Delta and a\n    `new_expr`, return a tuple of the sympy.KroneckerDelta instance and\n    `new_expr`. Otherwise, return a tuple of None and the original `expr`\n    (possibly converted to a :class:`.QuantumExpression`).\n\n    On input, `expr` can be a :class:`QuantumExpression` or a\n    :class:`sympy.Basic` object. On output, `new_expr` is guaranteed to be a\n    :class:`QuantumExpression`.\n    \"\"\"\n    from qnet.algebra.core.abstract_quantum_algebra import QuantumExpression\n    from qnet.algebra.core.scalar_algebra import ScalarValue\n    sympy_factor, quantum_factor = _split_sympy_quantum_factor(expr)\n    delta, new_expr = _sympy_extract_delta(sympy_factor, idx)\n    if delta is None:\n        new_expr = expr\n    else:\n        new_expr = new_expr * quantum_factor\n    if isinstance(new_expr, ScalarValue._val_types):\n        new_expr = ScalarValue.create(new_expr)\n    assert isinstance(new_expr, QuantumExpression)\n    return delta, new_expr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _deltasummation(term, ranges, i_range):\n    from qnet.algebra.core.abstract_quantum_algebra import QuantumExpression\n    idx = ranges[i_range].index_symbol\n    summands = _expand_delta(term, idx)\n    if len(summands) > 1:\n        return [(summand, ranges) for summand in summands], 3\n    else:\n        delta, expr = _extract_delta(summands[0], idx)\n    if not delta:\n        return [(term, ranges)], 2\n    solns = sympy.solve(delta.args[0] - delta.args[1], idx)\n    assert len(solns) > 0  # I can't think of an example that might cause this\n    #     if len(solns) == 0:\n    #         return [(term._zero, [])], 4\n    if len(solns) != 1:\n        return [(term, ranges)], 2\n    value = solns[0]\n    new_term = expr.substitute({idx: value})\n    if _RESOLVE_KRONECKER_WITH_PIECEWISE:\n        new_term *= ranges[i_range].piecewise_one(value)\n    assert isinstance(new_term, QuantumExpression)\n    return [(new_term, ranges[:i_range] + ranges[i_range+1:])], 1", "response": "Partially execute a summation for term with a Kronecker Delta for one\n           ."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef derivative_via_diff(cls, ops, kwargs):\n    assert len(ops) == 1\n    op = ops[0]\n    derivs = kwargs['derivs']\n    vals = kwargs['vals']\n    # both `derivs` and `vals` are guaranteed to be tuples, via the conversion\n    # that's happening in `QuantumDerivative.create`\n    for (sym, n) in derivs:\n        if sym.free_symbols.issubset(op.free_symbols):\n            for k in range(n):\n                op = op._diff(sym)\n        else:\n            return op.__class__._zero\n    if vals is not None:\n        try:\n            # for QuantumDerivative instance\n            return op.evaluate_at(vals)\n        except AttributeError:\n            # for explicit Expression\n            return op.substitute(vals)\n    else:\n        return op", "response": "Implementation of the QuantumDerivative. create interface via the\n    use of the QuantumDerivative. create method via the\n    use of the QuantumDerivative. create method via the\n    use of the QuantumDerivative. create method via the\n    use of QuantumDerivative. create directly"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the math word groups for a language code.", "response": "def word_groups_for_language(language_code):\n    \"\"\"\n    Return the math word groups for a language code.\n    The language_code should be an ISO 639-2 language code.\n    https://www.loc.gov/standards/iso639-2/php/code_list.php\n    \"\"\"\n\n    if language_code not in LANGUAGE_CODES:\n        message = '{} is not an available language code'.format(language_code)\n        raise InvalidLanguageCodeException(message)\n\n    return MATH_WORDS[language_code]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the math words for a language code.", "response": "def words_for_language(language_code):\n    \"\"\"\n    Return the math words for a language code.\n    The language_code should be an ISO 639-2 language code.\n    https://www.loc.gov/standards/iso639-2/php/code_list.php\n    \"\"\"\n    word_groups = word_groups_for_language(language_code)\n    words = []\n\n    for group in word_groups:\n        words.extend(word_groups[group].keys())\n\n    return words"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the image tuple of the inverse permutation.", "response": "def invert_permutation(permutation):\n    \"\"\"Compute the image tuple of the inverse permutation.\n\n    :param permutation: A valid (cf. :py:func:check_permutation) permutation.\n    :return: The inverse permutation tuple\n    :rtype: tuple\n    \"\"\"\n    return tuple([permutation.index(p) for p in range(len(permutation))])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef permutation_from_disjoint_cycles(cycles, offset=0):\n    perm_length = sum(map(len, cycles))\n    res_perm = list(range(perm_length))\n    for c in cycles:\n        p1 = c[0] - offset\n        for p2 in c[1:]:\n            p2 = p2 - offset\n            res_perm[p1] = p2\n            p1 = p2\n        res_perm[p1] = c[0] - offset #close cycle\n    assert sorted(res_perm) == list(range(perm_length))\n    return tuple(res_perm)", "response": "Reconstruct a permutation image tuple from a list of disjoint cycles."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef permutation_to_block_permutations(permutation):\n    if len(permutation) == 0 or not check_permutation(permutation):\n        raise BadPermutationError()\n\n    cycles = permutation_to_disjoint_cycles(permutation)\n\n    if len(cycles) == 1:\n        return (permutation,)\n    current_block_start = cycles[0][0]\n    current_block_end = max(cycles[0])\n    current_block_cycles = [cycles[0]]\n    res_permutations = []\n    for c in cycles[1:]:\n        if c[0] > current_block_end:\n            res_permutations.append(permutation_from_disjoint_cycles(current_block_cycles, current_block_start))\n            assert sum(map(len, current_block_cycles)) == current_block_end - current_block_start + 1\n            current_block_start = c[0]\n            current_block_end = max(c)\n            current_block_cycles = [c]\n        else:\n            current_block_cycles.append(c)\n            if max(c) > current_block_end:\n                current_block_end = max(c)\n\n    res_permutations.append(permutation_from_disjoint_cycles(current_block_cycles, current_block_start))\n\n    assert sum(map(len, current_block_cycles)) == current_block_end - current_block_start + 1\n    assert sum(map(len, res_permutations)) == len(permutation)\n\n    return res_permutations", "response": "Given a permutation image tuple return a list of permutations that are in the block of the permutation image."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreverse operation to permutation_to_block_permutations", "response": "def permutation_from_block_permutations(permutations):\n    \"\"\"Reverse operation to :py:func:`permutation_to_block_permutations`\n    Compute the concatenation of permutations\n\n        ``(1,2,0) [+] (0,2,1) --> (1,2,0,3,5,4)``\n\n    :param permutations: A list of permutation tuples\n                                 ``[t = (t_0,...,t_n1), u = (u_0,...,u_n2),..., z = (z_0,...,z_nm)]``\n    :type permutations: list of tuples\n    :return: permutation image tuple\n                    ``s = t [+] u [+] ... [+] z``\n    :rtype: tuple\n    \"\"\"\n    offset = 0\n    new_perm = []\n    for p in permutations:\n        new_perm[offset: offset +len(p)] = [p_i + offset for p_i in p]\n        offset += len(p)\n    return tuple(new_perm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a permutation sigma to an arbitrary length sequence.", "response": "def permute(sequence, permutation):\n    \"\"\"Apply a permutation sigma({j}) to an arbitrary sequence.\n\n    :param sequence: Any finite length sequence ``[l_1,l_2,...l_n]``. If it is a list, tuple or str, the return type will be the same.\n    :param permutation: permutation image tuple\n    :type permutation: tuple\n    :return: The permuted sequence ``[l_sigma(1), l_sigma(2), ..., l_sigma(n)]``\n    :raise: BadPermutationError or ValueError\n    \"\"\"\n    if len(sequence) != len(permutation):\n        raise ValueError((sequence, permutation))\n    if not check_permutation(permutation):\n        raise BadPermutationError(str(permutation))\n\n    if type(sequence) in (list, tuple, str):\n        constructor = type(sequence)\n    else:\n        constructor = list\n    return constructor((sequence[p] for p in permutation))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextend a permutation of blocks to a single permutation of all channels of all blocks.", "response": "def full_block_perm(block_permutation, block_structure):\n    \"\"\"\n    Extend a permutation of blocks to a permutation for the internal signals of all blocks.\n    E.g., say we have two blocks of sizes ('block structure') ``(2, 3)``,\n    then a block permutation that switches the blocks would be given by the image tuple ``(1,0)``.\n    However, to get a permutation of all 2+3 = 5 channels that realizes that block permutation we would need\n    ``(2, 3, 4, 0, 1)``\n\n    :param block_permutation: permutation image tuple of block indices\n    :type block_permutation: tuple\n    :param block_structure: The block channel dimensions, block structure\n    :type block_structure: tuple\n    :return: A single permutation for all channels of all blocks.\n    :rtype: tuple\n    \"\"\"\n    fblockp = []\n    bp_inv = invert_permutation(block_permutation)\n    for k, block_length in enumerate(block_structure):\n        p_k = block_permutation[k]\n        offset = sum([block_structure[bp_inv[j]] for j in range(p_k)])\n        fblockp += range(offset, offset + block_length)\n\n    assert sorted(fblockp) == list(range(sum(block_structure)))\n\n    return tuple(fblockp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef block_perm_and_perms_within_blocks(permutation, block_structure):\n    nblocks = len(block_structure)\n\n    offsets = [sum(block_structure[:k]) for k in range(nblocks)]\n    images = [permutation[offset: offset + length] for (offset, length) in zip(offsets, block_structure)]\n\n    images_mins = list(map(min, images))\n\n\n    key_block_perm_inv = lambda block_index: images_mins[block_index]\n\n    block_perm_inv = tuple(sorted(range(nblocks), key = key_block_perm_inv))\n    # print(images_mins)\n    # print(permutation, block_structure, \"-->\", block_perm, invert_permutation(block_perm))\n    block_perm = invert_permutation(block_perm_inv)\n\n    assert images_mins[block_perm_inv[0]] == min(images_mins)\n    assert images_mins[block_perm_inv[-1]] == max(images_mins)\n\n    # block_perm = tuple(invert_permutation(block_perm_inv))\n\n    perms_within_blocks = []\n    for (offset, length, image) in zip(offsets, block_structure, images):\n        block_key = lambda elt_index: image[elt_index]\n        within_inv = sorted(range(length), key = block_key)\n        within = invert_permutation(tuple(within_inv))\n        assert permutation[within_inv[0] + offset] == min(image)\n        assert permutation[within_inv[-1] + offset] == max(image)\n        perms_within_blocks.append(within)\n\n    return block_perm, perms_within_blocks", "response": "Decompose a permutation into a block permutation and into permutations\n    acting within each block."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef reverse(self, viewname, args=None, kwargs=None):\n        # TODO: django-fluent-pages needs a public API to get the current page.\n        current_page = getattr(self.request, '_current_fluent_page', None)\n        return blog_reverse(viewname, args=args, kwargs=kwargs, current_page=current_page)", "response": "Reverse a blog page taking different configuration options into account."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_kets(*ops, same_space=False, disjunct_space=False):\n    if not all([(isinstance(o, State) and o.isket) for o in ops]):\n        raise TypeError(\"All operands must be Kets\")\n    if same_space:\n        if not len({o.space for o in ops if o is not ZeroKet}) == 1:\n            raise UnequalSpaces(str(ops))\n    if disjunct_space:\n        spc = TrivialSpace\n        for o in ops:\n            if o.space & spc > TrivialSpace:\n                raise OverlappingSpaces(str(ops))\n            spc *= o.space", "response": "Check that all operands are Kets from the same Hilbert space."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmove up by n steps in the Hilbert space and return the next element of the sequence.", "response": "def next(self, n=1):\n        \"\"\"Move up by `n` steps in the Hilbert space::\n\n            >>> hs =  LocalSpace('tls', basis=('g', 'e'))\n            >>> ascii(BasisKet('g', hs=hs).next())\n            '|e>^(tls)'\n            >>> ascii(BasisKet(0, hs=hs).next())\n            '|e>^(tls)'\n\n        We can also go multiple steps:\n\n            >>> hs =  LocalSpace('ten', dimension=10)\n            >>> ascii(BasisKet(0, hs=hs).next(2))\n            '|2>^(ten)'\n\n        An increment that leads out of the Hilbert space returns zero::\n\n            >>> BasisKet(0, hs=hs).next(10)\n            ZeroKet\n\n        \"\"\"\n        if isinstance(self.label, SymbolicLabelBase):\n            next_label = self.space.next_basis_label_or_index(\n                self.label, n)\n            return BasisKet(next_label, hs=self.space)\n        else:\n            try:\n                next_index = self.space.next_basis_label_or_index(\n                    self.index, n)\n                return BasisKet(next_index, hs=self.space)\n            except IndexError:\n                return ZeroKet"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_fock_representation(self, index_symbol='n', max_terms=None):\n        phase_factor = sympy.exp(\n            sympy.Rational(-1, 2) * self.ampl * self.ampl.conjugate())\n        if not isinstance(index_symbol, IdxSym):\n            index_symbol = IdxSym(index_symbol)\n        n = index_symbol\n        if max_terms is None:\n            index_range = IndexOverFockSpace(n, hs=self._hs)\n        else:\n            index_range = IndexOverRange(n, 0, max_terms-1)\n        term = (\n            (self.ampl**n / sympy.sqrt(sympy.factorial(n))) *\n            BasisKet(FockIndex(n), hs=self._hs))\n        return phase_factor * KetIndexedSum(term, index_range)", "response": "Return the coherent state written out as an indexed sum over Fock\n        basis states."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef codemirror_script(self, inputid):\n        varname = \"{}_codemirror\".format(inputid)\n        html = self.get_codemirror_field_js()\n        opts = self.codemirror_config()\n\n        return html.format(varname=varname, inputid=inputid,\n                           settings=json.dumps(opts, sort_keys=True))", "response": "Build CodeMirror script tag which contains CodeMirror init."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrendering the widget with the given name value and attrs.", "response": "def render(self, name, value, attrs=None, renderer=None):\n        \"\"\"\n        Returns this Widget rendered as HTML, as a Unicode string.\n        \"\"\"\n        if not hasattr(self, \"editor_manifest\"):\n            self.editor_manifest = self.init_manifest(self.config_name)\n\n        config = self.editor_manifest.get_config(self.config_name)\n        if config.get('embed_config'):\n            self.embed_config = True\n\n        context = self.get_context(name, value, attrs)\n\n        return self._render(self.template_name, context, renderer)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new Media object with all assets from registered config.", "response": "def media(self):\n        \"\"\"\n        Adds necessary files (Js/CSS) to the widget's medias.\n\n        Returns:\n            django.forms.Media: Media object with all assets from registered\n            config.\n        \"\"\"\n        if not hasattr(self, \"editor_manifest\"):\n            self.editor_manifest = self.init_manifest(self.config_name)\n\n        return forms.Media(\n            css={\"all\": self.editor_manifest.css()},\n            js=self.editor_manifest.js()\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the default algebraic rules for scalars", "response": "def _algebraic_rules_scalar():\n    \"\"\"Set the default algebraic rules for scalars\"\"\"\n    a = wc(\"a\", head=SCALAR_VAL_TYPES)\n    b = wc(\"b\", head=SCALAR_VAL_TYPES)\n    x = wc(\"x\", head=SCALAR_TYPES)\n    y = wc(\"y\", head=SCALAR_TYPES)\n    z = wc(\"z\", head=SCALAR_TYPES)\n\n    indranges__ = wc(\"indranges__\", head=IndexRangeBase)\n\n    ScalarTimes._binary_rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(a, b),\n            lambda a, b: a * b)),\n        ('R002', (\n            pattern_head(x, x),\n            lambda x: x**2)),\n        ('R003', (\n            pattern_head(Zero, x),\n            lambda x: Zero)),\n        ('R004', (\n            pattern_head(x, Zero),\n            lambda x: Zero)),\n        ('R005', (\n            pattern_head(\n                pattern(ScalarPower, x, y),\n                pattern(ScalarPower, x, z)),\n            lambda x, y, z: x**(y+z))),\n        ('R006', (\n            pattern_head(x, pattern(ScalarPower, x, -1)),\n            lambda x: One)),\n    ]))\n\n    ScalarPower._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(a, b),\n            lambda a, b: a**b)),\n        ('R002', (\n            pattern_head(x, 0),\n            lambda x: One)),\n        ('R003', (\n            pattern_head(x, 1),\n            lambda x: x)),\n        ('R004', (\n            pattern_head(pattern(ScalarPower, x, y), z),\n            lambda x, y, z: x**(y*z))),\n    ]))\n\n    def pull_constfactor_from_sum(x, y, indranges):\n        bound_symbols = set([r.index_symbol for r in indranges])\n        if len(x.free_symbols.intersection(bound_symbols)) == 0:\n            return x * ScalarIndexedSum.create(y, *indranges)\n        else:\n            raise CannotSimplify()\n\n    ScalarIndexedSum._rules.update(check_rules_dict([\n        ('R001', (  # sum over zero -> zero\n            pattern_head(Zero, indranges__),\n            lambda indranges: Zero)),\n        ('R002', (  # pull constant prefactor out of sum\n            pattern_head(pattern(ScalarTimes, x, y), indranges__),\n            lambda x, y, indranges:\n                pull_constfactor_from_sum(x, y, indranges))),\n    ]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the default algebraic rules for the operations defined in this module", "response": "def _algebraic_rules_operator():\n    \"\"\"Set the default algebraic rules for the operations defined in this\n    module\"\"\"\n    u = wc(\"u\", head=SCALAR_TYPES)\n    v = wc(\"v\", head=SCALAR_TYPES)\n\n    n = wc(\"n\", head=(int, str, SymbolicLabelBase))\n    m = wc(\"m\", head=(int, str, SymbolicLabelBase))\n\n    A = wc(\"A\", head=Operator)\n    B = wc(\"B\", head=Operator)\n\n    A_plus = wc(\"A\", head=OperatorPlus)\n    A_times = wc(\"A\", head=OperatorTimes)\n\n    ls = wc(\"ls\", head=LocalSpace)\n    h1 = wc(\"h1\", head=HilbertSpace)\n    H_ProductSpace = wc(\"H\", head=ProductSpace)\n\n    localsigma = wc(\n        'localsigma', head=LocalSigma, kwargs={'hs': ls})\n\n    ra = wc(\"ra\", head=(int, str, SymbolicLabelBase))\n    rb = wc(\"rb\", head=(int, str, SymbolicLabelBase))\n    rc = wc(\"rc\", head=(int, str, SymbolicLabelBase))\n    rd = wc(\"rd\", head=(int, str, SymbolicLabelBase))\n\n    indranges__ = wc(\"indranges__\", head=IndexRangeBase)\n\n    ScalarTimesOperator._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(1, A),\n            lambda A: A)),\n        ('R002', (\n            pattern_head(0, A),\n            lambda A: ZeroOperator)),\n        ('R003', (\n            pattern_head(u, ZeroOperator),\n            lambda u: ZeroOperator)),\n        ('R004', (\n            pattern_head(u, pattern(ScalarTimesOperator, v, A)),\n            lambda u, v, A: (u * v) * A)),\n        ('R005', (\n            pattern_head(-1, A_plus),\n            lambda A: OperatorPlus.create(*[-1 * op for op in A.args]))),\n    ]))\n\n    OperatorTimes._binary_rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(pattern(ScalarTimesOperator, u, A), B),\n            lambda u, A, B: u * (A * B))),\n\n        ('R002', (\n            pattern_head(ZeroOperator, B),\n            lambda B: ZeroOperator)),\n        ('R003', (\n            pattern_head(A, ZeroOperator),\n            lambda A: ZeroOperator)),\n\n        ('R004', (\n            pattern_head(A, pattern(ScalarTimesOperator, u, B)),\n            lambda A, u, B: u * (A * B))),\n\n        ('R005', (\n            pattern_head(\n                pattern(LocalSigma, ra, rb, hs=ls),\n                pattern(LocalSigma, rc, rd, hs=ls)),\n            lambda ls, ra, rb, rc, rd: (\n                KroneckerDelta(\n                    BasisKet(rb, hs=ls).index,\n                    BasisKet(rc, hs=ls).index) *\n                LocalSigma.create(ra, rd, hs=ls)))),\n\n        # Harmonic oscillator rules\n        ('R009', (\n            pattern_head(pattern(Create, hs=ls), localsigma),\n            lambda ls, localsigma:\n                sqrt(localsigma.index_j + 1) * localsigma.raise_jk(j_incr=1))),\n\n        ('R010', (\n            pattern_head(pattern(Destroy, hs=ls), localsigma),\n            lambda ls, localsigma:\n                sqrt(localsigma.index_j) * localsigma.raise_jk(j_incr=-1))),\n\n        ('R011', (\n            pattern_head(localsigma, pattern(Destroy, hs=ls)),\n            lambda ls, localsigma:\n                sqrt(localsigma.index_k + 1) * localsigma.raise_jk(k_incr=1))),\n\n        ('R012', (\n            pattern_head(localsigma, pattern(Create, hs=ls)),\n            lambda ls, localsigma:\n                sqrt(localsigma.index_k) * localsigma.raise_jk(k_incr=-1))),\n\n        # Normal ordering for harmonic oscillator <=> all a^* to the left, a to\n        # the right.\n        ('R013', (\n            pattern_head(pattern(Destroy, hs=ls), pattern(Create, hs=ls)),\n            lambda ls: IdentityOperator + Create(hs=ls) * Destroy(hs=ls))),\n\n        # Oscillator unitary group rules\n        ('R014', (\n            pattern_head(pattern(Phase, u, hs=ls), pattern(Phase, v, hs=ls)),\n            lambda ls, u, v: Phase.create(u + v, hs=ls))),\n        ('R015', (\n            pattern_head(\n                pattern(Displace, u, hs=ls),\n                pattern(Displace, v, hs=ls)),\n            lambda ls, u, v: (\n                exp((u * v.conjugate() - u.conjugate() * v) / 2) *\n                Displace.create(u + v, hs=ls)))),\n\n        ('R016', (\n            pattern_head(pattern(Destroy, hs=ls), pattern(Phase, u, hs=ls)),\n            lambda ls, u:\n                exp(I * u) * Phase.create(u, hs=ls) * Destroy(hs=ls))),\n        ('R017', (\n            pattern_head(pattern(Destroy, hs=ls), pattern(Displace, u, hs=ls)),\n            lambda ls, u: Displace.create(u, hs=ls) * (Destroy(hs=ls) + u))),\n\n        ('R018', (\n            pattern_head(pattern(Phase, u, hs=ls), pattern(Create, hs=ls)),\n            lambda ls, u:\n                exp(I * u) * Create(hs=ls) * Phase.create(u, hs=ls))),\n        ('R019', (\n            pattern_head(pattern(Displace, u, hs=ls), pattern(Create, hs=ls)),\n            lambda ls, u: (((Create(hs=ls) - u.conjugate()) *\n                            Displace.create(u, hs=ls))))),\n\n        ('R020', (\n            pattern_head(pattern(Phase, u, hs=ls), localsigma),\n            lambda ls, u, localsigma:\n            exp(I * u * localsigma.index_j) * localsigma)),\n        ('R021', (\n            pattern_head(localsigma, pattern(Phase, u, hs=ls)),\n            lambda ls, u, localsigma:\n            exp(I * u * localsigma.index_k) * localsigma)),\n\n        # Spin rules\n        ('R022', (\n            pattern_head(pattern(Jplus, hs=ls), localsigma),\n            lambda ls, localsigma:\n                Jpjmcoeff(ls, localsigma.index_j, shift=True) *\n                localsigma.raise_jk(j_incr=1))),\n\n        ('R023', (\n            pattern_head(pattern(Jminus, hs=ls), localsigma),\n            lambda ls, localsigma:\n                Jmjmcoeff(ls, localsigma.index_j, shift=True) *\n                localsigma.raise_jk(j_incr=-1))),\n\n        ('R024', (\n            pattern_head(pattern(Jz, hs=ls), localsigma),\n            lambda ls, localsigma:\n                Jzjmcoeff(ls, localsigma.index_j, shift=True) * localsigma)),\n\n        ('R025', (\n            pattern_head(localsigma, pattern(Jplus, hs=ls)),\n            lambda ls, localsigma:\n                Jmjmcoeff(ls, localsigma.index_k, shift=True) *\n                localsigma.raise_jk(k_incr=-1))),\n\n        ('R026', (\n            pattern_head(localsigma, pattern(Jminus, hs=ls)),\n            lambda ls, localsigma:\n                Jpjmcoeff(ls, localsigma.index_k, shift=True) *\n                localsigma.raise_jk(k_incr=+1))),\n\n        ('R027', (\n            pattern_head(localsigma, pattern(Jz, hs=ls)),\n            lambda ls, localsigma:\n                Jzjmcoeff(ls, localsigma.index_k, shift=True) * localsigma)),\n\n        # Normal ordering for angular momentum <=> all J_+ to the left, J_z to\n        # center and J_- to the right\n        ('R028', (\n            pattern_head(pattern(Jminus, hs=ls), pattern(Jplus, hs=ls)),\n            lambda ls: -2 * Jz(hs=ls) + Jplus(hs=ls) * Jminus(hs=ls))),\n\n        ('R029', (\n            pattern_head(pattern(Jminus, hs=ls), pattern(Jz, hs=ls)),\n            lambda ls: Jz(hs=ls) * Jminus(hs=ls) + Jminus(hs=ls))),\n\n        ('R030', (\n            pattern_head(pattern(Jz, hs=ls), pattern(Jplus, hs=ls)),\n            lambda ls: Jplus(hs=ls) * Jz(hs=ls) + Jplus(hs=ls))),\n    ]))\n\n    Displace._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(0, hs=ls), lambda ls: IdentityOperator))\n    ]))\n    Phase._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(0, hs=ls), lambda ls: IdentityOperator))\n    ]))\n    Squeeze._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(0, hs=ls), lambda ls: IdentityOperator))\n    ]))\n\n    OperatorTrace._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(A, over_space=TrivialSpace),\n            lambda A: A)),\n        ('R002', (\n            pattern_head(ZeroOperator, over_space=h1),\n            lambda h1: ZeroOperator)),\n        ('R003', (\n            pattern_head(IdentityOperator, over_space=h1),\n            lambda h1: h1.dimension * IdentityOperator)),\n        ('R004', (\n            pattern_head(A_plus, over_space=h1),\n            lambda h1, A: OperatorPlus.create(\n                *[OperatorTrace.create(o, over_space=h1)\n                  for o in A.operands]))),\n        ('R005', (\n            pattern_head(pattern(Adjoint, A), over_space=h1),\n            lambda h1, A: Adjoint.create(\n                OperatorTrace.create(A, over_space=h1)))),\n        ('R006', (\n            pattern_head(pattern(ScalarTimesOperator, u, A), over_space=h1),\n            lambda h1, u, A: u * OperatorTrace.create(A, over_space=h1))),\n        ('R007', (\n            pattern_head(A, over_space=H_ProductSpace),\n            lambda H, A: decompose_space(H, A))),\n        ('R008', (\n            pattern_head(pattern(Create, hs=ls), over_space=ls),\n            lambda ls: ZeroOperator)),\n        ('R009', (\n            pattern_head(pattern(Destroy, hs=ls), over_space=ls),\n            lambda ls: ZeroOperator)),\n        ('R010', (\n            pattern_head(pattern(LocalSigma, n, m, hs=ls), over_space=ls),\n            lambda ls, n, m:\n                KroneckerDelta(\n                    BasisKet(n, hs=ls).index,\n                    BasisKet(m, hs=ls).index) *\n                IdentityOperator)),\n        ('R011', (\n            pattern_head(A, over_space=ls),\n            lambda ls, A: factor_for_trace(ls, A))),\n    ]))\n\n    Commutator._rules.update(check_rules_dict([\n        ('R001', (\n            pattern_head(A, A), lambda A: ZeroOperator)),\n        ('R002', (\n            pattern_head(\n                pattern(ScalarTimesOperator, u, A),\n                pattern(ScalarTimesOperator, v, B)),\n            lambda u, v, A, B: u * v * Commutator.create(A, B))),\n        ('R003', (\n            pattern_head(pattern(ScalarTimesOperator, v, A), B),\n            lambda v, A, B: v * Commutator.create(A, B))),\n        ('R004', (\n            pattern_head(A, pattern(ScalarTimesOperator, v, B)),\n            lambda v, A, B: v * Commutator.create(A, B))),\n\n        # special known commutators\n        ('R005', (\n            pattern_head(pattern(Create, hs=ls), pattern(Destroy, hs=ls)),\n            lambda ls: ScalarTimesOperator(-1, IdentityOperator))),\n        # the remaining  rules basically defer to OperatorTimes; just writing\n        # out the commutator will generate something simple\n        ('R006', (\n            pattern_head(\n                wc('A', head=(\n                    Create, Destroy, LocalSigma, Phase, Displace)),\n                wc('B', head=(\n                    Create, Destroy, LocalSigma, Phase, Displace))),\n            lambda A, B: A * B - B * A)),\n        ('R007', (\n            pattern_head(\n                wc('A', head=(LocalSigma, Jplus, Jminus, Jz)),\n                wc('B', head=(LocalSigma, Jplus, Jminus, Jz))),\n            lambda A, B: A * B - B * A)),\n    ]))\n\n    def pull_constfactor_from_sum(u, A, indranges):\n        bound_symbols = set([r.index_symbol for r in indranges])\n        if len(u.free_symbols.intersection(bound_symbols)) == 0:\n            return u * OperatorIndexedSum.create(A, *indranges)\n        else:\n            raise CannotSimplify()\n\n    OperatorIndexedSum._rules.update(check_rules_dict([\n        ('R001', (  # sum over zero -> zero\n            pattern_head(ZeroOperator, indranges__),\n            lambda indranges: ZeroOperator)),\n        ('R002', (  # pull constant prefactor out of sum\n            pattern_head(pattern(ScalarTimesOperator, u, A), indranges__),\n            lambda u, A, indranges:\n                pull_constfactor_from_sum(u, A, indranges))),\n    ]))"}
