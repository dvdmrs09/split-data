{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering new mapper. :param mapper: mapper object needs to implement ``parse()`` and ``format()`` functions.", "response": "def register_mapper(self, mapper, content_type, shortname=None):\n        \"\"\" Register new mapper.\n\n        :param mapper: mapper object needs to implement ``parse()`` and\n        ``format()`` functions.\n        \"\"\"\n\n        self._check_mapper(mapper)\n        cont_type_names = self._get_content_type_names(content_type, shortname)\n        self._datamappers.update(dict([(name, mapper) for name in cont_type_names]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects appropriate formatter based on the request.", "response": "def select_formatter(self, request, resource):\n        \"\"\" Select appropriate formatter based on the request.\n\n        :param request: the HTTP request\n        :param resource: the invoked resource\n        \"\"\"\n\n        # 1. get from resource\n        if resource.mapper:\n            return resource.mapper\n        # 2. get from url\n        mapper_name = self._get_name_from_url(request)\n        if mapper_name:\n            return self._get_mapper(mapper_name)\n        # 3. get from accept header\n        mapper_name = self._get_name_from_accept(request)\n        if mapper_name:\n            return self._get_mapper(mapper_name)\n        # 4. use resource's default\n        if resource.default_mapper:\n            return resource.default_mapper\n        # 5. use manager's default\n        return self._get_default_mapper()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef select_parser(self, request, resource):\n\n        # 1. get from resource\n        if resource.mapper:\n            return resource.mapper\n        # 2. get from content type\n        mapper_name = self._get_name_from_content_type(request)\n        if mapper_name:\n            return self._get_mapper(mapper_name)\n        # 3. get from url\n        mapper_name = self._get_name_from_url(request)\n        if mapper_name:\n            return self._get_mapper(mapper_name)\n        # 4. use resource's default\n        if resource.default_mapper:\n            return resource.default_mapper\n        # 5. use manager's default\n        return self._get_default_mapper()", "response": "Select appropriate parser based on the request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_mapper_by_content_type(self, content_type):\n\n        content_type = util.strip_charset(content_type)\n        return self._get_mapper(content_type)", "response": "Returs mapper based on the content type."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_mapper(self, mapper_name):\n\n        if mapper_name in self._datamappers:\n            # mapper found\n            return self._datamappers[mapper_name]\n        else:\n            # unsupported format\n            return self._unknown_format(mapper_name)", "response": "Returns the mapper based on the given name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget name from Content - Type header", "response": "def _get_name_from_content_type(self, request):\n        \"\"\" Get name from Content-Type header \"\"\"\n\n        content_type = request.META.get('CONTENT_TYPE', None)\n        if content_type:\n            # remove the possible charset-encoding info\n            return util.strip_charset(content_type)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprocessing the Accept HTTP header and return the name of the best mapper that the client wants.", "response": "def _get_name_from_accept(self, request):\n        \"\"\" Process the Accept HTTP header.\n\n        Find the most suitable mapper that the client wants and we support.\n\n        :returns: the preferred mapper based on the accept header or ``None``.\n        \"\"\"\n\n        accepts = util.parse_accept_header(request.META.get(\"HTTP_ACCEPT\", \"\"))\n        if not accepts:\n            return None\n\n        for accept in accepts:\n            if accept[0] in self._datamappers:\n                return accept[0]\n        raise errors.NotAcceptable()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines the short name for the mapper based on the URL.", "response": "def _get_name_from_url(self, request):\n        \"\"\" Determine short name for the mapper based on the URL.\n\n        Short name can be either in query string (e.g. ?format=json)\n        or as an extension to the URL (e.g. myresource.json).\n\n        :returns: short name of the mapper or ``None`` if not found.\n        \"\"\"\n\n        format = request.GET.get('format', None)\n        if not format:\n            match = self._format_query_pattern.match(request.path)\n            if match and match.group('format'):\n                format = match.group('format')\n        return format"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _check_mapper(self, mapper):\n        if not hasattr(mapper, 'parse') or not callable(mapper.parse):\n            raise ValueError('mapper must implement parse()')\n        if not hasattr(mapper, 'format') or not callable(mapper.format):\n            raise ValueError('mapper must implement format()')", "response": "Check that the mapper has valid signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the cluster by running an Ansible playbook and then the Ansible group configuration attributes.", "response": "def setup_cluster(self, cluster, extra_args=tuple()):\n        \"\"\"\n        Configure the cluster by running an Ansible playbook.\n\n        The ElastiCluster configuration attribute `<kind>_groups`\n        determines, for each node kind, what Ansible groups nodes of\n        that kind are assigned to.\n\n        :param cluster: cluster to configure\n        :type cluster: :py:class:`elasticluster.cluster.Cluster`\n\n        :param list extra_args:\n          List of additional command-line arguments\n          that are appended to each invocation of the setup program.\n\n        :return: ``True`` on success, ``False`` otherwise. Please note, if nothing\n                 has to be configured, then ``True`` is returned.\n\n        :raises: `ConfigurationError` if the playbook can not be found\n                 or is corrupt.\n        \"\"\"\n        inventory_path = self._build_inventory(cluster)\n        if inventory_path is None:\n            # No inventory file has been created, maybe an\n            # invalid class has been specified in config file? Or none?\n            # assume it is fine.\n            elasticluster.log.info(\"No setup required for this cluster.\")\n            return True\n        assert os.path.exists(inventory_path), (\n                \"inventory file `{inventory_path}` does not exist\"\n                .format(inventory_path=inventory_path))\n\n        # build list of directories to search for roles/include files\n        ansible_roles_dirs = [\n            # include Ansible default first ...\n            '/etc/ansible/roles',\n        ]\n        for root_path in [\n                # ... then ElastiCluster's built-in defaults\n                resource_filename('elasticluster', 'share/playbooks'),\n                # ... then wherever the playbook is\n                os.path.dirname(self._playbook_path),\n        ]:\n            for path in [\n                    root_path,\n                    os.path.join(root_path, 'roles'),\n            ]:\n                if path not in ansible_roles_dirs and os.path.exists(path):\n                    ansible_roles_dirs.append(path)\n\n\n        # Use env vars to configure Ansible;\n        # see all values in https://github.com/ansible/ansible/blob/devel/lib/ansible/constants.py\n        #\n        # Ansible does not merge keys in configuration files: rather\n        # it uses the first configuration file found.  However,\n        # environment variables can be used to selectively override\n        # parts of the config; according to [1]: \"they are mostly\n        # considered to be a legacy system as compared to the config\n        # file, but are equally valid.\"\n        #\n        # [1]: http://docs.ansible.com/ansible/intro_configuration.html#environmental-configuration\n        #\n        # Provide default values for important configuration variables...\n        ansible_env = {\n            'ANSIBLE_FORKS':             '10',\n            'ANSIBLE_HOST_KEY_CHECKING': 'no',\n            'ANSIBLE_PRIVATE_KEY_FILE':  cluster.user_key_private,\n            'ANSIBLE_ROLES_PATH':        ':'.join(reversed(ansible_roles_dirs)),\n            'ANSIBLE_SSH_PIPELINING':    'yes',\n            'ANSIBLE_TIMEOUT':           '120',\n        }\n        # ...override them with key/values set in the config file(s)\n        for k, v in self.extra_conf.items():\n            if k.startswith('ansible_'):\n                ansible_env[k.upper()] = str(v)\n        # ...finally allow the environment have the final word\n        ansible_env.update(os.environ)\n        if __debug__:\n            elasticluster.log.debug(\n                \"Calling `ansible-playbook` with the following environment:\")\n            for var, value in sorted(ansible_env.items()):\n                elasticluster.log.debug(\"- %s=%r\", var, value)\n\n        elasticluster.log.debug(\"Using playbook file %s.\", self._playbook_path)\n\n        # build `ansible-playbook` command-line\n        cmd = shlex.split(self.extra_conf.get('ansible_command', 'ansible-playbook'))\n        cmd += [\n            os.path.realpath(self._playbook_path),\n            ('--inventory=' + inventory_path),\n        ] + list(extra_args)\n\n        if self._sudo:\n            cmd.extend([\n                # force all plays to use `sudo` (even if not marked as such)\n                '--become',\n                # desired sudo-to user\n                ('--become-user=' + self._sudo_user),\n            ])\n\n        # determine Ansible verbosity as a function of ElastiCluster's\n        # log level (we cannot read `ElastiCluster().params.verbose`\n        # here, still we can access the log configuration since it's\n        # global).\n        verbosity = (logging.WARNING - elasticluster.log.getEffectiveLevel()) / 10\n        if verbosity > 0:\n            cmd.append('-' + ('v' * verbosity))  # e.g., `-vv`\n\n        # append any additional arguments provided by users\n        ansible_extra_args = self.extra_conf.get('ansible_extra_args', None)\n        if ansible_extra_args:\n            cmd += shlex.split(ansible_extra_args)\n\n        cmdline = ' '.join(cmd)\n        elasticluster.log.debug(\"Running Ansible command `%s` ...\", cmdline)\n\n        rc = call(cmd, env=ansible_env, bufsize=1, close_fds=True)\n        if rc == 0:\n            elasticluster.log.info(\"Cluster correctly configured.\")\n            return True\n        else:\n            elasticluster.log.error(\n                \"Command `%s` failed with exit code %d.\", cmdline, rc)\n            elasticluster.log.error(\n                \"Check the output lines above for additional information on this error.\")\n            elasticluster.log.error(\n                \"The cluster has likely *not* been configured correctly.\"\n                \" You may need to re-run `elasticluster setup` or fix the playbooks.\")\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the inventory for the given cluster and returns its path.", "response": "def _build_inventory(self, cluster):\n        \"\"\"\n        Builds the inventory for the given cluster and returns its path\n\n        :param cluster: cluster to build inventory for\n        :type cluster: :py:class:`elasticluster.cluster.Cluster`\n        \"\"\"\n        inventory_data = defaultdict(list)\n        for node in cluster.get_all_nodes():\n            if node.kind not in self.groups:\n                # FIXME: should this raise a `ConfigurationError` instead?\n                warn(\"Node kind `{0}` not defined in cluster!\".format(node.kind))\n                continue\n            extra_vars = ['ansible_user=%s' % node.image_user]\n            # check for nonstandard port, either IPv4 or IPv6\n            if node.preferred_ip and ':' in node.preferred_ip:\n                match = IPV6_RE.match(node.preferred_ip)\n                if match:\n                    host_port = match.groups()[1]\n                else:\n                    _, _, host_port = node.preferred_ip.partition(':')\n                if host_port:\n                    extra_vars.append('ansible_port=%s' % host_port)\n\n            if node.kind in self.environment:\n                extra_vars.extend('%s=%s' % (k, v) for k, v in\n                                  self.environment[node.kind].items())\n            for group in self.groups[node.kind]:\n                connection_ip = node.preferred_ip\n                if connection_ip:\n                    inventory_data[group].append(\n                        (node.name, connection_ip, str.join(' ', extra_vars)))\n\n        if not inventory_data:\n            elasticluster.log.info(\"No inventory file was created.\")\n            return None\n\n        # create a temporary file to pass to ansible, since the\n        # api is not stable yet...\n        if self._storage_path_tmp:\n            if not self._storage_path:\n                self._storage_path = tempfile.mkdtemp()\n            elasticluster.log.warning(\n                \"Writing inventory file to tmp dir `%s`\", self._storage_path)\n\n        inventory_path = os.path.join(\n            self._storage_path, (cluster.name + '.inventory'))\n        log.debug(\"Writing Ansible inventory to file `%s` ...\", inventory_path)\n        with open(inventory_path, 'w+') as inventory_file:\n            for section, hosts in inventory_data.items():\n                # Ansible throws an error \"argument of type 'NoneType' is not\n                # iterable\" if a section is empty, so ensure we have something\n                # to write in there\n                if hosts:\n                    inventory_file.write(\"\\n[\" + section + \"]\\n\")\n                    for host in hosts:\n                        # don't want port, makes it look like ipv6\n                        if ':' in host[1]:\n                            match = IPV6_RE.match(node.preferred_ip)\n                            if match:\n                                host = (host[0], match.groups()[0], host[2])\n                            else:\n                                host = (host[0], host[1].partition(':')[0],\n                                        host[2])\n                        hostline = \"%s ansible_host=%s %s\\n\" % host\n                        inventory_file.write(hostline)\n        return inventory_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef cleanup(self, cluster):\n        if self._storage_path and os.path.exists(self._storage_path):\n            fname = '%s.%s' % (AnsibleSetupProvider.inventory_file_ending,\n                               cluster.name)\n            inventory_path = os.path.join(self._storage_path, fname)\n\n            if os.path.exists(inventory_path):\n                try:\n                    os.unlink(inventory_path)\n                    if self._storage_path_tmp:\n                        if len(os.listdir(self._storage_path)) == 0:\n                            shutil.rmtree(self._storage_path)\n                except OSError as ex:\n                    log.warning(\n                        \"AnsibileProvider: Ignoring error while deleting \"\n                        \"inventory file %s: %s\", inventory_path, ex)", "response": "Deletes the inventory file used last recently used."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef await_task(self, task_id, service_id, callback_fn=None, sleep_sec=15):\n        while True:\n            import time\n            time.sleep(sleep_sec)\n            task_info = self.__metadb.one(\"\"\"\n                SELECT id, service_id, status, result_data \n                FROM job.task\n                WHERE id=:task_id::uuid\n                AND service_id=:service_id::job.service_id\n                LIMIT 1\n            \"\"\", {\n                \"task_id\": task_id,\n                \"service_id\": service_id,\n            })\n            self.log.info(\"\u0416\u0434\u0435\u043c \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f \u0437\u0430\u0434\u0430\u0447\u0438\", {\n                \"task_info\": task_info\n            })\n            if task_info is None:\n                break\n\n            is_finish = task_info['status'] != 'NEW' and task_info['status'] != 'PROCESSING'\n\n            if callback_fn:\n                # \u0423\u0432\u0435\u0434\u043e\u043c\u043b\u044f\u0435\u043c \u0432\u044b\u0437\u044b\u0432\u0430\u044e\u0449\u0435\u0433\u043e\n                callback_fn(task_info, is_finish)\n\n            if is_finish:\n                break", "response": "Wait for a task to finish."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubmits a new task to the service.", "response": "def submit(self, service_id: str, data: dict = None):\n        \"\"\"\n        \u041e\u0442\u043f\u0440\u0430\u0432\u0438\u0442\u044c \u0437\u0430\u0434\u0430\u0447\u0443 \u0432 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u043e\u0440\n\n        :param service_id: ID \u0441\u043b\u0443\u0436\u0431\u044b. \u041d\u0430\u043f\u0440\u0438\u043c\u0435\u0440 \"meta.docs_generate\"\n        :param data: \u041f\u043e\u043b\u0435\u0437\u043d\u0430\u044f \u043d\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0437\u0430\u0434\u0430\u0447\u0438\n        :return: dict\n        \"\"\"\n        if self.__app.starter_api_url == 'http://STUB_URL':\n            self.log.info('STARTER DEV. \u0417\u0430\u0434\u0430\u0447\u0430 \u0443\u0441\u043b\u043e\u0432\u043d\u043e \u043f\u043e\u0441\u0442\u0430\u0432\u043b\u0435\u043d\u0430', {\n                \"service_id\": service_id,\n                \"data\": data,\n            })\n            return\n\n        task = {\"serviceId\": service_id, \"data\": data}\n        url = self.__app.starter_api_url + '/services/' + service_id + '/tasks'\n        last_e = None\n        for _idx in range(self.max_retries):\n            try:\n                resp = requests.post(\n                    url=url,\n                    data=json.dumps(task),\n                    headers=self.headers,\n                    timeout=15\n                )\n                try:\n                    return json.loads(resp.text)\n                except Exception:\n                    raise IOError(\"Starter response read error: \" + resp.text)\n            except (requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n                # \u041f\u0440\u0438 \u043e\u0448\u0438\u0431\u043a\u0430\u0445 \u043f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u043f\u044b\u0442\u0430\u0435\u043c\u0441\u044f \u0435\u0449\u0435 \u0440\u0430\u0437\n                last_e = e\n                sleep(3)\n        raise last_e"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_version_string(version_string):\n    components = version_string.split('-') + [None, None]\n    version = list(map(int, components[0].split('.')))\n    build_tag = components[1] if components[1] else BUILD_TAG\n    build_number = int(components[2]) if components[2] else components[2]\n\n    return (version, build_tag, build_number)", "response": "Parse a version string into its components."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_version(version, build_number=None, build_tag=BUILD_TAG):\n    formatted_version = \".\".join(map(str, version))\n\n    if build_number is not None:\n        return \"{formatted_version}-{build_tag}-{build_number}\".format(**locals())\n    \n    return formatted_version", "response": "Format a version string for use in packaging."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the based_on of this TaxRate.", "response": "def based_on(self, based_on):\n        \"\"\"Sets the based_on of this TaxRate.\n\n\n        :param based_on: The based_on of this TaxRate.\n        :type: str\n        \"\"\"\n        allowed_values = [\"shippingAddress\", \"billingAddress\"]\n        if based_on is not None and based_on not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `based_on` ({0}), must be one of {1}\"\n                .format(based_on, allowed_values)\n            )\n\n        self._based_on = based_on"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_tax_rate(cls, tax_rate, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_tax_rate_with_http_info(tax_rate, **kwargs)\n        else:\n            (data) = cls._create_tax_rate_with_http_info(tax_rate, **kwargs)\n            return data", "response": "Create a new TaxRate with the given tax_rate"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes TaxRate by ID.", "response": "def delete_tax_rate_by_id(cls, tax_rate_id, **kwargs):\n        \"\"\"Delete TaxRate\n\n        Delete an instance of TaxRate by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_tax_rate_by_id(tax_rate_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str tax_rate_id: ID of taxRate to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_tax_rate_by_id_with_http_info(tax_rate_id, **kwargs)\n        else:\n            (data) = cls._delete_tax_rate_by_id_with_http_info(tax_rate_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tax_rate_by_id(cls, tax_rate_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_tax_rate_by_id_with_http_info(tax_rate_id, **kwargs)\n        else:\n            (data) = cls._get_tax_rate_by_id_with_http_info(tax_rate_id, **kwargs)\n            return data", "response": "Find TaxRate by ID Return single instance of TaxRate by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_all_tax_rates(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_tax_rates_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_tax_rates_with_http_info(**kwargs)\n            return data", "response": "List TaxRates\n        Return a list of TaxRates\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_tax_rate_by_id(cls, tax_rate_id, tax_rate, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_tax_rate_by_id_with_http_info(tax_rate_id, tax_rate, **kwargs)\n        else:\n            (data) = cls._replace_tax_rate_by_id_with_http_info(tax_rate_id, tax_rate, **kwargs)\n            return data", "response": "Replace TaxRate by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_tax_rate_by_id(cls, tax_rate_id, tax_rate, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_tax_rate_by_id_with_http_info(tax_rate_id, tax_rate, **kwargs)\n        else:\n            (data) = cls._update_tax_rate_by_id_with_http_info(tax_rate_id, tax_rate, **kwargs)\n            return data", "response": "Update attributes of TaxRate by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild a task to watch a specific remote url and append the new information to the file.", "response": "def build_append_file_task(urllocation, filelocation):\n    \"\"\"Build a task to watch a specific remote url and\nappend that data to the file. This method should be used\nwhen you would like to keep all of the information stored\non the local machine, but also append the new information\nfound at the url.\n\nFor instance, if the local file is:\n\n```\nfoo\n```\n\nAnd the remote file is:\n\n```\nbar\n```\n\nThe resulting file will contain:\n\n```\nfoo\nbar\n```\n    \"\"\"\n\n    config = file_utils.get_celcius_config()\n    basename = filelocation.split('/')[-1]\n    tmp_filelocation = filelocation.replace(basename, 'tmp_'+basename)\n    new_filelocation = filelocation.replace(basename, 'new_'+basename)\n\n    if config['retrieve_command'] == 'curl':\n        download_cmd = curl.build_download_file_command(urllocation, tmp_filelocation)\n    elif config['retrieve_command'] == 'wget':\n        download_cmd = wget.build_download_file_command(urllocation, tmp_filelocation)\n    else:\n        print(\"Invalid retrieve command!\")\n        sys.exit(1)\n\n    diff_cmd = diff.build_append_file_command(filelocation, tmp_filelocation)\n    compare_cmd = concat.build_and_concat_commands([download_cmd, diff_cmd])\n    redirect_cmd = redirect.redirect_output(compare_cmd, new_filelocation)\n    full_cmd = concat.concat_commands([touch.touch(filelocation).build_command(), redirect_cmd, rm.build_force_rm_command(tmp_filelocation).build_command(), rm.build_force_rm_command(filelocation).build_command(), mv.mv(new_filelocation, filelocation).build_command()])\n\n    return full_cmd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_authentic_node_name(self, node_name: str) -> Optional[str]:\n        # Is there a node with the given name?\n        vertex: IGraphVertex = None\n        try:\n            vertex: IGraphVertex = self._wrapped_graph.vs.find(node_name)\n        except ValueError:\n            pass\n\n        # Is node_name a node index?\n        if vertex is None:\n            try:\n                vertex: IGraphVertex = self._wrapped_graph.vs[int(node_name)]\n            except ValueError:\n                return None\n            except IndexError:\n                return None\n\n        try:\n            return vertex[\"name\"]\n        except KeyError:\n            return str(vertex.index)", "response": "Returns the authentic node name for the given node name."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _create_memory_database_interface(self) -> GraphDatabaseInterface:\n        Base = declarative_base()\n        engine = sqlalchemy.create_engine(\"sqlite://\", poolclass=StaticPool)\n        Session = sessionmaker(bind=engine)\n\n        dbi: GraphDatabaseInterface = create_graph_database_interface(\n            sqlalchemy, Session(), Base, sqlalchemy.orm.relationship\n        )\n\n        Base.metadata.drop_all(engine)\n        Base.metadata.create_all(engine)\n\n        return dbi", "response": "Creates and returns the in - memory database interface that will be used for the graph."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _load_neighbors_from_external_source(self) -> None:\n        graph: IGraphWrapper = self._graph\n        ig_vertex: IGraphVertex = graph.wrapped_graph.vs[self._igraph_index]\n        ig_neighbors: List[IGraphVertex] = ig_vertex.neighbors()\n        for ig_neighbor in ig_neighbors:\n            try:\n                name: str = ig_neighbor[\"name\"]\n            except KeyError:\n                name: str = str(ig_neighbor.index)\n\n            try:\n                external_id: Optional[str] = ig_neighbor[\"external_id\"]\n            except KeyError:\n                external_id: Optional[str] = None\n\n            neighbor: IGraphNode = graph.nodes.get_node_by_name(name,\n                                                                can_validate_and_load=True,\n                                                                external_id=external_id)\n            graph.add_edge(self, neighbor)", "response": "Loads the neighbors of the node from the external source that has this node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_node(self, index: int, name: str, external_id: Optional[str] = None) -> IGraphNode:\n        return IGraphNode(graph=self._graph, index=index, name=name, external_id=external_id)", "response": "Creates a new node with the given index and name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self):\n\n        self.parse_fields()\n        records = []\n        for line in self.t['data'].split('\\n'):\n            if EMPTY_ROW.match(line):\n                continue\n            row = [self.autoconvert(line[start_field:end_field+1])\n                   for start_field, end_field in self.fields]\n            records.append(tuple(row))\n        self.records = records", "response": "Parse the table data string into records."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef recarray(self):\n\n        if self.records is None:\n            self.parse()\n        try:\n            # simple (should this also be subjected to convert.to_int64() ?)\n            return numpy.rec.fromrecords(self.records, names=self.names)\n        except ValueError:\n            # complicated because fromrecords cannot deal with records of lists\n            # Quick hack: use objects for lists etc (instead of building the proper\n            # data types (see docs for numpy.dtype , eg dtype('coord', (float, 3)) )\n\n            D = numpy.empty(len(self.records[0]), dtype=object)    # number of fields from first record\n            types = numpy.array([map(type, r) for r in self.records])  # types of all fields\n            for icol, isSame in enumerate([numpy.all(col) for col in types.T]):\n                if isSame:\n                    D[icol] = types[0][icol]\n                else:\n                    D[icol] = object\n            dtype = numpy.dtype(zip(self.names, D))\n            # from numpy.rec.records\n            # TODO: this is not working properly yet; for instance, text fields\n            # are reduced to length 0 (<U0) and the final convert.to_int64 dies\n            # with '<U0'*** TypeError: TypeError('data type not understood',)\n            retval = numpy.array(self.records, dtype=dtype)\n            res = retval.view(numpy.recarray)\n            ## res.dtype = numpy.dtype((numpy.rec.record, res.dtype))  # fails -- ARGH, this makes it a recarray\n            return convert.to_int64(res)", "response": "Return a recarray from the parsed string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndetermine the start and end columns and names of the fields.", "response": "def parse_fields(self):\n        \"\"\"Determine the start and end columns and names of the fields.\"\"\"\n\n        rule = self.t['toprule'].rstrip()  # keep leading space for correct columns!!\n        if not (rule == self.t['midrule'].rstrip() and rule == self.t['botrule'].rstrip()):\n            raise ParseError(\"Table rules differ from each other (check white space).\")\n        names = self.t['fields'].split()\n        nfields = len(rule.split())\n        if nfields != len(names):\n            raise ParseError(\"number of field names (%d) does not match number of fields (%d)\"\n                             % (nfields, len(names)))\n        fields = []     #  list of tuples (first,last) column of the field\n        ifield = 0\n        is_field = rule.startswith('=')  # state\n        len_rule = len(rule)\n        start_field = 0\n        end_field = 0\n        for c in xrange(len_rule):\n            char = rule[c]\n            if not is_field and char == '=':\n                start_field = c\n                is_field = True\n            if is_field and (char == ' ' or c == len_rule-1):\n                # finished field\n                fields.append((start_field, c))\n                ifield += 1\n                is_field = False\n        self.names = names\n        self.fields = fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the object_name of the object is compatible with the other object.", "response": "def check_signature(object_name, reference_object, other_object):\n    \"\"\"\n    Given a reference class or function check if an other class or function\n    could be substituted without causing any instantiation/usage issues.\n\n    :param object_name: the name of the object being checked.\n    :type object_name: string\n    :param reference_object: the reference class or function.\n    :type reference_object: class/function\n    :param other_object: the other class or function to be checked.\n    :type other_object: class/function\n    :raise AutodiscoveryCheckerError: in case the other object is not\n        compatible with the reference object.\n    \"\"\"\n    try:\n        if inspect.isclass(reference_object):\n            # if the reference_object is a class\n            if inspect.isclass(other_object):\n                # if the other_object is a class\n                if issubclass(other_object, reference_object):\n                    # if the other_object is derived from the reference we\n                    # should check for all the method in the former that\n                    # exists in the the latter, wethever they recursively have\n                    # the same signature.\n                    reference_object_map = dict(\n                        inspect.getmembers(reference_object,\n                                           inspect.isroutine))\n                    for other_method_name, other_method_code in \\\n                            inspect.getmembers(other_object,\n                                               inspect.isroutine):\n                        if other_method_name in reference_object_map:\n                            check_signature(\n                                object_name,\n                                reference_object_map[other_method_name],\n                                other_method_code)\n                else:\n                    # if the other_object is not derived from the\n                    # reference_object then all the method declared in the\n                    # latter should exist in the former and they should\n                    # recursively have the same signature.\n                    other_object_map = dict(\n                        inspect.getmembers(other_object, inspect.isroutine))\n                    for reference_method_name, reference_method_code in \\\n                        inspect.getmembers(\n                            reference_object, inspect.isroutine):\n                        if reference_method_name in other_object_map:\n                            check_signature(\n                                object_name, reference_method_code,\n                                other_method_code)\n                        else:\n                            raise AutodiscoveryCheckerError(\n                                '\"%s\", which'\n                                ' exists in the reference class, does not'\n                                ' exist in the other class, and the reference'\n                                ' class is not an anchestor of the other' %\n                                reference_method_name)\n            else:\n                # We are comparing apples and oranges!\n                raise AutodiscoveryCheckerError(\n                    \"%s (the reference object)\"\n                    \" is a class while %s (the other object) is not a class\" %\n                    (reference_object, other_object))\n        elif inspect.isroutine(reference_object):\n            # if the reference_object is a function\n            if inspect.isroutine(other_object):\n                # if the other_object is a function we will compare the\n                # reference_object and other_object function signautre i.e.\n                # their parameters.\n                reference_args, reference_varargs, reference_varkw, \\\n                    reference_defaults = inspect.getargspec(reference_object)\n                other_args, other_varargs, other_varkw, \\\n                    other_defaults = inspect.getargspec(other_object)\n                # We normalize the reference_defaults to be a list\n                if reference_defaults is not None:\n                    reference_defaults = list(reference_defaults)\n                else:\n                    reference_defaults = []\n\n                # We normalize the other_defaults to be a list\n                if other_defaults is not None:\n                    other_defaults = list(other_defaults)\n                else:\n                    other_defaults = []\n\n                # Check for presence of missing parameters in other function\n                if not (other_varargs or other_varkw):\n                    for reference_arg in reference_args:\n                        if reference_arg not in other_args:\n                            raise AutodiscoveryCheckerError(\n                                'Argument \"%s\"'\n                                ' in reference function %s does not exist in'\n                                ' the other function %s' %\n                                (reference_arg, reference_object, other_object)\n                            )\n\n                # Check for presence of additional parameters in other\n                # function\n                if not (reference_varargs or reference_varkw):\n                    for other_arg in other_args:\n                        if other_arg not in reference_args:\n                            raise AutodiscoveryCheckerError(\n                                'Argument \"%s\"'\n                                ' in other function %s does not exist in the'\n                                ' reference function %s' %\n                                (other_arg, other_object, reference_object))\n\n                # Check sorting of arguments\n                for reference_arg, other_arg in map(\n                        None, reference_args, other_args):\n                    if not((reference_arg == other_arg) or\n                           (reference_arg is None and\n                            (reference_varargs or reference_varkw)) or\n                           (other_arg is None and\n                            (other_args or other_varargs))):\n                        raise AutodiscoveryCheckerError(\n                            'Argument \"%s\" in'\n                            ' the other function is in the position of'\n                            ' argument \"%s\" in the reference function, i.e.'\n                            ' the order of arguments is not respected' %\n                            (other_arg, reference_arg))\n\n                if len(reference_defaults) != len(other_defaults) and not (\n                        reference_args or reference_varargs or\n                        other_args or other_varargs):\n                    raise AutodiscoveryCheckerError(\n                        \"Default parameters in\"\n                        \" the other function are not corresponding to the\"\n                        \" default of parameters of the reference function\")\n            else:\n                # We are comparing apples and oranges!\n                raise AutodiscoveryCheckerError(\n                    '%s (the reference object)'\n                    ' is a function while %s (the other object) is not a'\n                    ' function' % (reference_object, other_object))\n    except AutodiscoveryCheckerError as err:\n        try:\n            sourcefile = inspect.getsourcefile(other_object)\n            sourceline = inspect.getsourcelines(other_object)[1]\n        except IOError:\n            # other_object is not loaded from a real file\n            sourcefile = 'N/A'\n            sourceline = 'N/A'\n        raise AutodiscoveryCheckerError(\n            'Error in checking signature for'\n            ' \"%s\" as defined at \"%s\" (line %s): %s' %\n            (object_name, sourcefile, sourceline, err))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_arguments_compatibility(the_callable, argd):\n    if not argd:\n        argd = {}\n    args, dummy, varkw, defaults = inspect.getargspec(the_callable)\n    tmp_args = list(args)\n    optional_args = []\n    args_dict = {}\n    if defaults:\n        defaults = list(defaults)\n    else:\n        defaults = []\n    while defaults:\n        arg = tmp_args.pop()\n        optional_args.append(arg)\n        args_dict[arg] = defaults.pop()\n\n    while tmp_args:\n        args_dict[tmp_args.pop()] = None\n\n    for arg, dummy_value in iteritems(argd):\n        if arg in args_dict:\n            del args_dict[arg]\n        elif not varkw:\n            raise ValueError(\n                'Argument %s not expected when calling callable '\n                '\"%s\" with arguments %s' % (\n                    arg, get_callable_signature_as_string(the_callable), argd))\n\n    for arg in args_dict.keys():\n        if arg in optional_args:\n            del args_dict[arg]\n\n    if args_dict:\n        raise ValueError(\n            'Arguments %s not specified when calling callable '\n            '\"%s\" with arguments %s' % (\n                ', '.join(args_dict.keys()),\n                get_callable_signature_as_string(the_callable),\n                argd))", "response": "Check if calling the_callable with the given arguments would be correct or not."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a plugin builder function suitable to extract some specific objects and other simpler data.", "response": "def create_enhanced_plugin_builder(compulsory_objects=None,\n                                   optional_objects=None,\n                                   other_data=None):\n    \"\"\"\n    Creates a plugin builder function suitable to extract some specific\n    objects (either compulsory or optional) and other simpler data\n\n    >>> def dummy_needed_funct1(foo, bar):\n    ...     pass\n    >>> class dummy_needed_class1:\n    ...     def __init__(self, baz):\n    ...         pass\n    >>> def dummy_optional_funct2(boo):\n    ...     pass\n    >>> create_enhanced_plugin_builder(\n    ...    compulsory_objects={\n    ...         'needed_funct1' : dummy_needed_funct1,\n    ...         'needed_class1' : dummy_needed_class1\n    ...     },\n    ...     optional_objects={\n    ...         'optional_funct2' : dummy_optional_funct2,\n    ...     },\n    ...     other_data={\n    ...         'CFG_SOME_DATA' : (str, ''),\n    ...         'CFG_SOME_INT' : (int, 0),\n    ...     })\n    <function plugin_builder at 0xb7812064>\n\n    :param compulsory_objects: map of name of an object to look for inside\n        the `plugin` and a *signature* for a class or callable. Every\n        name specified in this map **must exists** in the plugin, otherwise\n        the plugin will fail to load.\n    :type compulsory_objects: dict\n    :param optional_objects: map of name of an object to look for inside\n        the C{plugin} and a I{signature} for a class or callable. Every\n        name specified in this map must B{can exists} in the plugin.\n    :type optional_objects: dict\n    :param other_data: map of other simple data that can be loaded from\n        the plugin. The map has the same format of the C{content}\n        parameter of L{invenio_ext.legacy.handler.wash_urlargd}.\n    :type other_data: dict\n    :return: a I{plugin_builder} function that can be used with the\n        map function. Such function will build the plugin\n        in the form of a map, where every key is one of the keys inside\n        the three maps provided as parameters and the corresponding value\n        is the expected class or callable or simple data.\n    \"\"\"\n    from invenio_utils.washers import wash_urlargd\n\n    def plugin_builder(the_plugin):\n        \"\"\"\n        Enhanced plugin_builder created by L{create_enhanced_plugin_builder}.\n\n        :param plugin: the code of the module as just read from package.\n        :return: the plugin in the form of a map.\n        \"\"\"\n        plugin_name = the_plugin.__name__\n        plugin = {}\n\n        if compulsory_objects:\n            for object_name, object_signature in \\\n                    iteritems(compulsory_objects):\n                the_object = getattr(the_plugin, object_name, None)\n                if the_object is None:\n                    raise AutodiscoveryError(\n                        'Plugin \"%s\" does not '\n                        'contain compulsory object \"%s\"' %\n                        (plugin_name, object_name))\n                try:\n                    check_signature(object_name, the_object, object_signature)\n                except AutodiscoveryError as err:\n                    raise AutodiscoveryError(\n                        'Plugin \"%s\" contains '\n                        'object \"%s\" with a wrong signature: %s' %\n                        (plugin_name, object_name, err))\n                plugin[object_name] = the_object\n\n        if optional_objects:\n            for object_name, object_signature in iteritems(optional_objects):\n                the_object = getattr(the_plugin, object_name, None)\n                if the_object is not None:\n                    try:\n                        check_signature(\n                            object_name,\n                            the_object,\n                            object_signature)\n                    except AutodiscoveryError as err:\n                        raise AutodiscoveryError(\n                            'Plugin \"%s\" '\n                            'contains object \"%s\" with a wrong signature: %s' %\n                            (plugin_name, object_name, err))\n                    plugin[object_name] = the_object\n\n        if other_data:\n            the_other_data = {}\n            for data_name, (dummy, data_default) in iteritems(other_data):\n                the_other_data[data_name] = getattr(the_plugin, data_name,\n                                                    data_default)\n\n            try:\n                the_other_data = wash_urlargd(the_other_data, other_data)\n            except Exception as err:\n                raise AutodiscoveryError(\n                    'Plugin \"%s\" contains other '\n                    'data with problems: %s' %\n                    (plugin_name, err))\n\n            plugin.update(the_other_data)\n        return plugin\n\n    return plugin_builder"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_quoted_txt2html(text,\n                          tabs_before=0,\n                          indent_txt='>>',\n                          linebreak_txt=\"\\n\",\n                          indent_html=('<div class=\"commentbox\">', \"</div>\"),\n                          linebreak_html='<br/>',\n                          indent_block=True):\n    \"\"\"\n    Takes a typical mail quoted text, e.g.::\n        hello,\n        you told me:\n        >> Your mother was a hamster and your father smelt of elderberries\n        I must tell you that I'm not convinced. Then in this discussion:\n        >>>> Is there someone else up there we could talk to?\n        >> No. Now, go away, or I shall taunt you a second time-a!\n        I think we're not going to be friends!\n\n    and return an html formatted output, e.g.::\n        hello,<br/>\n        you told me:<br/>\n        <div>\n          Your mother was a hamster and your father smelt of elderberries\n        </div>\n        I must tell you that I'm not convinced. Then in this discussion:\n        <div>\n          <div>\n            Is there someone else up there we could talk to?\n          </div>\n          No. Now, go away, or I shall taunt you a second time-a!\n        </div>\n        I think we're not going to be friends!\n\n    The behaviour is different when C{indent_block} is C{True} or C{False}.\n    When C{True} the when C{indent_html} is only added at each change of\n    level of indentation, while it is added for each line when C{False}.\n    For eg::\n        >> a\n        >> b\n        >>>> c\n\n    would result in (if C{True})::\n        <div class=\"commentbox\">\n            a<br/>\n            b<br/>\n            <div class=\"commentbox\">\n                c<br/>\n            </div>\n        </div>\n\n    or would be (if C{False})::\n        <div class=\"commentbox\"> a</div><br/>\n        <div class=\"commentbox\"> b</div><br/>\n        <div class=\"commentbox\"><div class=\"commentbox\"> c</div></div><br/>\n\n    @param text: the text in quoted format\n    @param tabs_before: number of tabulations before each line\n    @param indent_txt: quote separator in email (default:'>>')\n    @param linebreak_txt: line separator in email\n    @param indent_html: tuple of (opening, closing) html tags.\n                        default: ('<div class=\"commentbox\">', \"</div>\")\n    @param linebreak_html: line separator in html (default: '<br/>')\n    @param indent_block: if indentation should be done per 'block'\n                         i.e. only at changes of indentation level\n                         (+1, -1) or at each line.\n    @return: string containing html formatted output\n    \"\"\"\n    washer = HTMLWasher()\n\n    final_body = \"\"\n    nb_indent = 0\n    text = text.strip('\\n')\n    lines = text.split(linebreak_txt)\n    for line in lines:\n        new_nb_indent = 0\n        while True:\n            if line.startswith(indent_txt):\n                new_nb_indent += 1\n                line = line[len(indent_txt):]\n            else:\n                break\n        if indent_block:\n            if (new_nb_indent > nb_indent):\n                for dummy in range(nb_indent, new_nb_indent):\n                    final_body += tabs_before * \"\\t\" + indent_html[0] + \"\\n\"\n                    tabs_before += 1\n            elif (new_nb_indent < nb_indent):\n                for dummy in range(new_nb_indent, nb_indent):\n                    tabs_before -= 1\n                    final_body += (tabs_before) * \"\\t\" + indent_html[1] + \"\\n\"\n            else:\n                final_body += (tabs_before) * \"\\t\"\n        else:\n            final_body += tabs_before * \"\\t\" + new_nb_indent * indent_html[0]\n        try:\n            line = washer.wash(line)\n        except HTMLParseError:\n            # Line contained something like \"foo<bar\"\n            line = cgi.escape(line)\n        if indent_block:\n            final_body += tabs_before * \"\\t\"\n        final_body += line\n        if not indent_block:\n            final_body += new_nb_indent * indent_html[1]\n        final_body += linebreak_html + \"\\n\"\n        nb_indent = new_nb_indent\n    if indent_block:\n        for dummy in range(0, nb_indent):\n            tabs_before -= 1\n            final_body += (tabs_before) * \"\\t\" + \"</div>\\n\"\n    return final_body", "response": "Takes a typical mail quoted text and returns an html formatted output."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef email_quote_txt(text,\n                    indent_txt='>>',\n                    linebreak_input=\"\\n\",\n                    linebreak_output=\"\\n\"):\n    \"\"\"\n    Takes a text and returns it in a typical mail quoted format, e.g.::\n        C'est un lapin, lapin de bois.\n        >>Quoi?\n        Un cadeau.\n        >>What?\n        A present.\n        >>Oh, un cadeau.\n\n    will return::\n        >>C'est un lapin, lapin de bois.\n        >>>>Quoi?\n        >>Un cadeau.\n        >>>>What?\n        >>A present.\n        >>>>Oh, un cadeau.\n\n    @param text: the string to quote\n    @param indent_txt: the string used for quoting (default: '>>')\n    @param linebreak_input: in the text param, string used for linebreaks\n    @param linebreak_output: linebreak used for output\n    @return: the text as a quoted string\n    \"\"\"\n    if (text == \"\"):\n        return \"\"\n    lines = text.split(linebreak_input)\n    text = \"\"\n    for line in lines:\n        text += indent_txt + line + linebreak_output\n    return text", "response": "Takes a text and returns it in a typical mail quoted format e. g."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nescapes text using an email - like indenting rule.", "response": "def escape_email_quoted_text(text, indent_txt='>>', linebreak_txt='\\n'):\n    \"\"\"\n    Escape text using an email-like indenting rule.\n    As an example, this text::\n        >>Brave Sir Robin ran away...\n        <img src=\"malicious_script />*No!*\n        >>bravely ran away away...\n        I didn't!*<script>malicious code</script>\n        >>When danger reared its ugly head, he bravely turned his tail and fled.\n        <form onload=\"malicious\"></form>*I never did!*\n\n    will be escaped like this::\n        >>Brave Sir Robin ran away...\n        &lt;img src=\"malicious_script /&gt;*No!*\n        >>bravely ran away away...\n        I didn't!*&lt;script&gt;malicious code&lt;/script&gt;\n        >>When danger reared its ugly head, he bravely turned his tail and fled.\n        &lt;form onload=\"malicious\"&gt;&lt;/form&gt;*I never did!*\n\n    @param text: the string to escape\n    @param indent_txt: the string used for quoting\n    @param linebreak_txt: in the text param, string used for linebreaks\n    \"\"\"\n    washer = HTMLWasher()\n    lines = text.split(linebreak_txt)\n    output = ''\n    for line in lines:\n        line = line.strip()\n        nb_indent = 0\n        while True:\n            if line.startswith(indent_txt):\n                nb_indent += 1\n                line = line[len(indent_txt):]\n            else:\n                break\n        output += (nb_indent * indent_txt) + washer.wash(line,\n                                                         render_unallowed_tags=True) + linebreak_txt\n        nb_indent = 0\n    return output[:-1]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _print(self, text, color=None, **kwargs):\n        COLORS = {\n            'red': '\\033[91m{}\\033[00m',\n            'green': '\\033[92m{}\\033[00m',\n            'yellow': '\\033[93m{}\\033[00m',\n            'cyan': '\\033[96m{}\\033[00m'\n        }\n        _ = COLORS[color]\n        six.print_(_.format(text), **kwargs)", "response": "print text with given color to terminal"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _is_unique(self, name, path):\n        project = None\n        try:\n            project = Project.select().where(\n                (Project.name == name) |\n                (Project.path == path)\n            )[0]\n        except:\n            pass\n\n        return project is None", "response": "verify if there is a project with given name or path on the database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating if a given path is valid", "response": "def _path_is_valid(self, path):\n        \"\"\"validates if a given path is:\n        - absolute,\n        - exists on current machine\n        - is a directory\n        \"\"\"\n        VALIDATORS = [\n            (os.path.isabs, self._ERROR_PATH_NOT_ABSOLUTE),\n            (os.path.exists, self._ERROR_PATH_DOESNT_EXISTS),\n            (os.path.isdir, self._ERROR_PATH_NOT_A_DIR),\n        ]\n\n        for validator in VALIDATORS:\n            func, str_err = validator\n            if not func(path):\n                self._print(str_err.format(path), 'red')\n                return\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add(self, name, path=None, **kwargs):\n        path = path or kwargs.pop('default_path', None)\n\n        if not self._path_is_valid(path):\n            return\n\n        if not self._is_unique(name, path):\n            p = Project.select().where(\n                (Project.name == name) |\n                (Project.path == path)\n            )[0]\n            self._print(self._ERROR_PROJECT_EXISTS.format(name, p.path), 'red')\n            return\n\n        Project.create(name=name, path=path)\n        self._print(self._SUCCESS_PROJECT_ADDED.format(name), 'green')", "response": "add new project with given name and path to database\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list(self, **kwargs):\n        projects = Project.select().order_by(Project.name)\n        if len(projects) == 0:\n            self._print('No projects available', 'yellow')\n            return\n\n        for project in projects:\n            project_repr = self._PROJECT_ITEM.format(project.name, project.path)\n            row = '- {}'.format(self._PROJECT_ITEM.format(project.name, project.path))\n            six.print_(row)", "response": "displays all projects on database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parent_tags(self):\n        tags = set()\n\n        for addr in self._addresses:\n            if addr.attr == 'text':\n                tags.add(addr.element.tag)\n            tags.update(el.tag for el in addr.element.iterancestors())\n\n        tags.discard(HTMLFragment._root_tag)\n        return frozenset(tags)", "response": "Provides tags of all parent HTML elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprovides all HTML tags directly involved in this string.", "response": "def involved_tags(self):\n        \"\"\"Provides all HTML tags directly involved in this string.\"\"\"\n        if len(self._addresses) < 2:\n            # there can't be a tag boundary if there's only 1 or 0 characters\n            return frozenset()\n\n        # creating 'parent_sets' mapping, where the first item in tuple\n        # is the address of character and the second is set\n        # of character's parent HTML elements\n        parent_sets = []\n\n        # meanwhile we are creatingalso a set of common parents so we can\n        # put them away later on (we're not interested in them as\n        # they're only some global wrappers)\n        common_parents = set()\n\n        for addr in self._addresses:\n            parents = set()\n            if addr.attr == 'text':\n                parents.add(addr.element)\n            parents.update(addr.element.iterancestors())\n\n            parent_sets.append((addr, parents))\n            if not common_parents:\n                common_parents = parents\n            else:\n                common_parents &= parents\n\n        # constructing final set of involved tags\n        involved_tags = set()\n        prev_addr = None\n\n        for addr, parents in parent_sets:\n            parents = parents - common_parents\n            involved_tags.update(p.tag for p in parents)\n\n            # hidden tags - sometimes there are tags without text which\n            # can hide between characters, but they actually break textflow\n            is_tail_of_hidden = (\n                prev_addr and\n                addr.attr == 'tail' and\n                prev_addr.element != addr.element\n            )\n            if is_tail_of_hidden:\n                involved_tags.add(addr.element)\n\n            prev_addr = addr\n\n        return frozenset(involved_tags)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse(self, html):\n        if self._has_body_re.search(html):\n            tree = lxml.html.document_fromstring(html).find('.//body')\n            self.has_body = True\n        else:\n            tree = lxml.html.fragment_fromstring(html,\n                                                 create_parent=self._root_tag)\n\n        if tree.tag != self._root_tag:\n            # ensure the root element exists even if not really needed,\n            # so the tree has always the same structure\n            root = lxml.html.HtmlElement()\n            root.tag = self._root_tag\n            root.append(tree)\n            return root\n        return tree", "response": "Parse given string as HTML and return it s etree representation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _iter_texts(self, tree):\n        skip = (\n            not isinstance(tree, lxml.html.HtmlElement)  # comments, etc.\n            or tree.tag in self.skipped_tags\n        )\n        if not skip:\n            if tree.text:\n                yield Text(tree.text, tree, 'text')\n            for child in tree:\n                for text in self._iter_texts(child):\n                    yield text\n        if tree.tail:\n            yield Text(tree.tail, tree, 'tail')", "response": "Iterates over texts in given HTML tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nanalyzes given tree and create mapping of indexes to character addresses.", "response": "def _analyze_tree(self, tree):\n        \"\"\"Analyze given tree and create mapping of indexes to character\n        addresses.\n        \"\"\"\n        addresses = []\n        for text in self._iter_texts(tree):\n            for i, char in enumerate(text.content):\n                if char in whitespace:\n                    char = ' '\n                addresses.append(CharAddress(char, text.element, text.attr, i))\n\n        # remove leading and trailing whitespace\n        while addresses and addresses[0].char == ' ':\n            del addresses[0]\n        while addresses and addresses[-1].char == ' ':\n            del addresses[-1]\n\n        return addresses"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nvalidates given index eventually raises errors.", "response": "def _validate_index(self, index):\n        \"\"\"Validates given index, eventually raises errors.\"\"\"\n        if isinstance(index, slice):\n            if index.step and index.step != 1:\n                raise IndexError('Step is not allowed.')\n            indexes = (index.start, index.stop)\n        else:\n            indexes = (index,)\n        for index in indexes:\n            if index is not None and index < 0:\n                raise IndexError('Negative indexes are not allowed.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _find_pivot_addr(self, index):\n        if not self.addresses or index.start == 0:\n            return CharAddress('', self.tree, 'text', -1)  # string beginning\n        if index.start > len(self.addresses):\n            return self.addresses[-1]\n        return self.addresses[index.start]", "response": "Find the pivot address for the given index."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_connectivity_changes(request, add_vlan_action, remove_vlan_action, logger=None):\n\n    if not logger:\n        logger = logging.getLogger(\"apply_connectivity_changes\")\n\n    if request is None or request == '':\n        raise Exception('ConnectivityOperations', 'request is None or empty')\n\n    holder = connectivity_request_from_json(request)\n\n    driver_response = DriverResponse()\n    results = []\n    driver_response_root = DriverResponseRoot()\n\n    for action in holder.actions:\n        logger.info('Action: ', action.__dict__)\n        if action.type == ConnectivityActionRequest.SET_VLAN:\n            action_result = add_vlan_action(action)\n\n        elif action.type == ConnectivityActionRequest.REMOVE_VLAN:\n            action_result = remove_vlan_action(action)\n\n        else:\n            continue\n        results.append(action_result)\n\n    driver_response.actionResults = results\n    driver_response_root.driverResponse = driver_response\n    return driver_response_root", "response": "This function is used to perform the connectivity changes on a node. It will accept as an input the actions to perform for add and remove vlan."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking the API key of the user.", "response": "def check_api_key(email, api_key):\n    \"\"\"Check the API key of the user.\"\"\"\n    table = boto3.resource(\"dynamodb\").Table(os.environ['people'])\n    user = table.get_item(Key={'email': email})\n    if not user:\n        return False\n    user = user.get(\"Item\")\n    if api_key != user.get('api_key', None):\n        return False\n    return user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_email_url(url):\n\n    conf = {}\n\n    url = urlparse.urlparse(url)\n\n    # Remove query strings\n    path = url.path[1:]\n    path = path.split('?', 2)[0]\n\n    # Update with environment configuration\n    conf.update({\n        'EMAIL_FILE_PATH': path,\n        'EMAIL_HOST_USER': url.username,\n        'EMAIL_HOST_PASSWORD': url.password,\n        'EMAIL_HOST': url.hostname,\n        'EMAIL_PORT': url.port,\n    })\n\n    if url.scheme in EMAIL_SCHEMES:\n        conf['EMAIL_BACKEND'] = EMAIL_SCHEMES[url.scheme]\n\n    if url.scheme == 'smtps':\n        conf['EMAIL_USE_TLS'] = True\n    else:\n        conf['EMAIL_USE_TLS'] = False\n\n    return conf", "response": "Parses an email URL and returns a dictionary of environment variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dictionary with EMAIL_* settings from EMAIL_URL.", "response": "def config(name='EMAIL_URL', default='console://'):\n    \"\"\"Returns a dictionary with EMAIL_* settings from EMAIL_URL.\"\"\"\n    conf = {}\n    s = env(name, default)\n    if s:\n        conf = parse_email_url(s)\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace(html, replacements=None):\n    if not replacements:\n        return html  # no replacements\n    html = HTMLFragment(html)\n\n    for r in replacements:\n        r.replace(html)\n\n    return unicode(html)", "response": "Performs replacements on given HTML string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntest whether replacement is allowed on given piece of HTML text.", "response": "def _is_replacement_allowed(self, s):\n        \"\"\"Tests whether replacement is allowed on given piece of HTML text.\"\"\"\n        if any(tag in s.parent_tags for tag in self.skipped_tags):\n            return False\n        if any(tag not in self.textflow_tags for tag in s.involved_tags):\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nperforms replacements on given HTML fragment.", "response": "def replace(self, html):\n        \"\"\"Perform replacements on given HTML fragment.\"\"\"\n        self.html = html\n        text = html.text()\n        positions = []\n\n        def perform_replacement(match):\n            offset = sum(positions)\n            start, stop = match.start() + offset, match.end() + offset\n\n            s = self.html[start:stop]\n            if self._is_replacement_allowed(s):\n                repl = match.expand(self.replacement)\n                self.html[start:stop] = repl\n            else:\n                repl = match.group()  # no replacement takes place\n\n            positions.append(match.end())\n            return repl\n\n        while True:\n            if positions:\n                text = text[positions[-1]:]\n\n            text, n = self.pattern.subn(perform_replacement, text, count=1)\n            if not n:  # all is already replaced\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read_relative_file(filename, relative_to=None):\n    if relative_to is None:\n        relative_to = os.path.dirname(__file__)\n    with open(os.path.join(os.path.dirname(relative_to), filename)) as f:\n        return f.read()", "response": "Reads the contents of the given file which path is supposed relative\n    to this package."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_events(self):\n        to_send = {'limit': 50}\n        response = self._send_data('POST', 'admin', 'get-events', to_send)\n\n        output = {'message': \"\"}\n        for event in response['events']:\n            desc = \"Source IP: {ip}\\n\"\n            desc += \"Datetime: {time}\\n\"\n            desc += \"Indicator: {match}\\n\"\n            desc += \"Method: {method}\\n\"\n            desc += \"URL: {url}\\n\"\n            desc += \"Request Type: {type}\\n\"\n            desc += \"User-Agent: {userAgent}\\n\"\n            desc += \"Contact: {contact}\\n\"\n            desc += \"\\n\"\n            output['message'] += desc.format(**event)\n\n        return output", "response": "Get events from the cloud node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef flush_events(self):\n        response = self._send_data('DELETE', 'admin', 'flush-events', {})\n\n        if response['success']:\n            msg = \"Events flushed\"\n        else:\n            msg = \"Flushing of events failed\"\n        output = {'message': msg}\n\n        return output", "response": "Flushes events from the cloud node."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\npushes the info represented by this Metric to CloudWatch.", "response": "def put(self):\n        \"\"\"Push the info represented by this ``Metric`` to CloudWatch.\"\"\"\n        try:\n            self.cloudwatch.put_metric_data(\n                    Namespace=self.namespace,\n                    MetricData=[{\n                        'MetricName': self.name,\n                        'Value': self.value,\n                        'Timestamp': self.timestamp\n                    }]\n            )\n        except Exception:\n            logging.exception(\"Error pushing {0} to CloudWatch.\".format(str(self)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsending log entry to the log system.", "response": "def log(self, message, level=logging.INFO, *args, **kwargs):\n        \"\"\" Send log entry\n\n        :param str message: log message\n        :param int level: `Logging level <https://docs.python.org/3/library/logging.html#levels>`_\n        :param list args: log record arguments\n        :param dict kwargs: log record key argument\n        \"\"\"\n        msg = \"{}.{}: {}[{}]: {}\".format(\n            self.__class__.__name__, self.status, self.__class__.path,\n            self.uuid, message\n        )\n        extra = kwargs.pop(\"extra\", dict())\n        extra.update(dict(kmsg=Message(\n            self.uuid, entrypoint=self.__class__.path, params=self.params,\n            metadata=self.metadata\n        ).dump()))\n\n        return logger.log(\n            level=level, msg=msg, extra=extra, *args, **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets focus to first field.", "response": "def setFocus(self, reason=None):\r\n        \"\"\"Sets focus to first field. Note: reason is ignored.\"\"\"\r\n        self.formLayout.itemAt(0, QFormLayout.FieldRole).widget().setFocus()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _connect(self):\n        logger.info(\"Connecting to rabbit\")\n        for url in self._urls:\n            try:\n                self._connection = pika.BlockingConnection(pika.URLParameters(url))\n                self._channel = self._connection.channel()\n                self._declare()\n                if self._confirm_delivery:\n                    self._channel.confirm_delivery()\n                    logger.info(\"Enabled delivery confirmation\")\n                logger.debug(\"Connected to rabbit\")\n                return True\n\n            except pika.exceptions.AMQPConnectionError:\n                logger.exception(\"Unable to connect to rabbit\")\n                continue\n            except Exception:\n                logger.exception(\"Unexpected exception connecting to rabbit\")\n                continue\n\n        raise pika.exceptions.AMQPConnectionError", "response": "Connect to a RabbitMQ instance and return True if successful False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef publish_message(self, message, content_type=None, headers=None, mandatory=False, immediate=False):\n        logger.debug(\"Publishing message\")\n        try:\n            self._connect()\n            return self._do_publish(mandatory=mandatory,\n                                    immediate=immediate,\n                                    content_type=content_type,\n                                    headers=headers,\n                                    message=message)\n        except pika.exceptions.AMQPConnectionError:\n            logger.error(\"AMQPConnectionError occurred. Message not published.\")\n            raise PublishMessageError\n        except NackError:\n            # raised when a message published in publisher-acknowledgments mode\n            # is returned via `Basic.Return` followed by `Basic.Ack`.\n            logger.error(\"NackError occurred. Message not published.\")\n            raise PublishMessageError\n        except UnroutableError:\n            # raised when a message published in publisher-acknowledgments\n            # mode is returned via `Basic.Return` followed by `Basic.Ack`.\n            logger.error(\"UnroutableError occurred. Message not published.\")\n            raise PublishMessageError\n        except Exception:\n            logger.exception(\"Unknown exception occurred. Message not published.\")\n            raise PublishMessageError", "response": "Publish a response message to a RabbitMQ instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nvisit all files from a folder into the database.", "response": "def visit(folder, provenance_id, step_name, previous_step_id=None, config=None, db_url=None, is_organised=True):\n    \"\"\"Record all files from a folder into the database.\n\n    Note:\n    If a file has been copied from a previous processing step without any transformation, it will be detected and\n    marked in the DB. The type of file will be detected and stored in the DB (NIFTI, DICOM, ...). If a files\n    (e.g. a DICOM file) contains some meta-data, those will be stored in the DB.\n\n    Arguments:\n    :param folder: folder path.\n    :param provenance_id: provenance label.\n    :param step_name: Name of the processing step that produced the folder to visit.\n    :param previous_step_id: (optional) previous processing step ID. If not defined, we assume this is the first\n    processing step.\n    :param config: List of flags:\n        - boost: (optional) When enabled, we consider that all the files from a same folder share the same meta-data.\n        When enabled, the processing is (about 2 times) faster. This option is enabled by default.\n        - session_id_by_patient: Rarely, a data set might use study IDs which are unique by patient (not for the whole\n        study).\n        E.g.: LREN data. In such a case, you have to enable this flag. This will use PatientID + StudyID as a session\n        ID.\n        - visit_id_in_patient_id: Rarely, a data set might mix patient IDs and visit IDs. E.g. : LREN data. In such a\n        case, you have to enable this flag. This will try to split PatientID into VisitID and PatientID.\n        - visit_id_from_path: Enable this flag to get the visit ID from the folder hierarchy instead of DICOM meta-data\n        (e.g. can be useful for PPMI).\n        - repetition_from_path: Enable this flag to get the repetition ID from the folder hierarchy instead of DICOM\n        meta-data (e.g. can be useful for PPMI).\n    :param db_url: (optional) Database URL. If not defined, it looks for an Airflow configuration file.\n    :param is_organised: (optional) Disable this flag when scanning a folder that has not been organised yet\n    (should only affect nifti files).\n    :return: return processing step ID.\n    \"\"\"\n    config = config if config else []\n\n    logging.info(\"Visiting %s\", folder)\n    logging.info(\"-> is_organised=%s\", str(is_organised))\n    logging.info(\"-> config=%s\", str(config))\n\n    logging.info(\"Connecting to database...\")\n    db_conn = connection.Connection(db_url)\n\n    step_id = _create_step(db_conn, step_name, provenance_id, previous_step_id)\n\n    previous_files_hash = _get_files_hash_from_step(db_conn, previous_step_id)\n\n    checked = dict()\n\n    def process_file(file_path):\n        logging.debug(\"Processing '%s'\" % file_path)\n        file_type = _find_type(file_path)\n        if \"DICOM\" == file_type:\n            is_copy = _hash_file(file_path) in previous_files_hash\n            leaf_folder = os.path.split(file_path)[0]\n            if leaf_folder not in checked or 'boost' not in config:\n                ret = dicom_import.dicom2db(file_path, file_type, is_copy, step_id, db_conn,\n                                            'session_id_by_patient' in config, 'visit_id_in_patient_id' in config,\n                                            'visit_id_in_patient_id' in config, 'repetition_from_path' in config)\n                try:\n                    checked[leaf_folder] = ret['repetition_id']\n                except KeyError:\n                    # TODO: Remove it when dicom2db will be more stable\n                    logging.warning(\"Cannot find repetition ID !\")\n            else:\n                dicom_import.extract_dicom(\n                    file_path, file_type, is_copy, checked[leaf_folder], step_id)\n        elif \"NIFTI\" == file_type and is_organised:\n            is_copy = _hash_file(file_path) in previous_files_hash\n            nifti_import.nifti2db(file_path, file_type, is_copy, step_id, db_conn, 'session_id_by_patient' in config,\n                                  'visit_id_in_patient_id' in config)\n        elif file_type:\n            is_copy = _hash_file(file_path) in previous_files_hash\n            others_import.others2db(\n                file_path, file_type, is_copy, step_id, db_conn)\n\n    if sys.version_info.major == 3 and sys.version_info.minor < 5:\n        matches = []\n        for root, dirnames, filenames in os.walk(folder):\n            for filename in fnmatch.filter(filenames, '*'):\n                matches.append(os.path.join(root, filename))\n        for file_path in matches:\n            process_file(file_path)\n    else:\n        for file_path in glob.iglob(os.path.join(folder, \"**/*\"), recursive=True):\n            process_file(file_path)\n\n    logging.info(\"Closing database connection...\")\n    db_conn.close()\n\n    return step_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_provenance(dataset, software_versions=None, db_url=None):\n    logging.info(\"Connecting to database...\")\n    db_conn = connection.Connection(db_url)\n\n    try:\n        matlab_version = software_versions['matlab_version']\n    except (KeyError, TypeError):\n        matlab_version = None\n    try:\n        spm_version = software_versions['spm_version']\n    except (KeyError, TypeError):\n        spm_version = None\n    try:\n        spm_revision = software_versions['spm_revision']\n    except (KeyError, TypeError):\n        spm_revision = None\n    try:\n        fn_called = software_versions['fn_called']\n    except (KeyError, TypeError):\n        fn_called = None\n    try:\n        fn_version = software_versions['fn_version']\n    except (KeyError, TypeError):\n        fn_version = None\n    try:\n        others = software_versions['others']\n    except (KeyError, TypeError):\n        others = None\n\n    provenance = db_conn.db_session.query(db_conn.Provenance).filter_by(\n        dataset=dataset, matlab_version=matlab_version, spm_version=spm_version, spm_revision=spm_revision,\n        fn_called=fn_called, fn_version=fn_version, others=others\n    ).first()\n\n    if not provenance:\n        provenance = db_conn.Provenance(\n            dataset=dataset, matlab_version=matlab_version, spm_version=spm_version, spm_revision=spm_revision,\n            fn_called=fn_called, fn_version=fn_version, others=others\n        )\n        db_conn.db_session.merge(provenance)\n        db_conn.db_session.commit()\n\n        provenance = db_conn.db_session.query(db_conn.Provenance).filter_by(\n            dataset=dataset, matlab_version=matlab_version, spm_version=spm_version, spm_revision=spm_revision,\n            fn_called=fn_called, fn_version=fn_version, others=others\n        ).first()\n\n    provenance_id = provenance.id\n\n    logging.info(\"Closing database connection...\")\n    db_conn.close()\n\n    return provenance_id", "response": "Create or get a provenance entity from the database and store it in the database and get back a provenance ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking for new messages on sockets and respond accordingly.", "response": "def check_sockets(self):\n        '''\n        Check for new messages on sockets and respond accordingly.\n\n\n        .. versionchanged:: 0.11.3\n            Update routes table by setting ``df_routes`` property of\n            :attr:`parent.canvas_slave`.\n\n        .. versionchanged:: 0.12\n            Update ``dynamic_electrode_state_shapes`` layer of\n            :attr:`parent.canvas_slave` when dynamic electrode actuation states\n            change.\n\n        .. versionchanged:: 0.13\n            Update local global, electrode, and route command lists in response\n            to ``microdrop.command_plugin`` messages.\n        '''\n        try:\n            msg_frames = (self.command_socket\n                          .recv_multipart(zmq.NOBLOCK))\n        except zmq.Again:\n            pass\n        else:\n            self.on_command_recv(msg_frames)\n\n        try:\n            msg_frames = (self.subscribe_socket\n                          .recv_multipart(zmq.NOBLOCK))\n            source, target, msg_type, msg_json = msg_frames\n\n            if ((source == 'microdrop.device_info_plugin') and\n                (msg_type == 'execute_reply')):\n                msg = json.loads(msg_json)\n                if msg['content']['command'] == 'get_device':\n                    data = decode_content_data(msg)\n                    if data is not None:\n                        self.parent.on_device_loaded(data)\n            elif ((source == 'microdrop.electrode_controller_plugin') and\n                (msg_type == 'execute_reply')):\n                msg = json.loads(msg_json)\n                if msg['content']['command'] in ('set_electrode_state',\n                                                 'set_electrode_states'):\n                    data = decode_content_data(msg)\n                    if data is None:\n                        print msg\n                    else:\n                        #self.emit('electrode-states-updated', data)\n                        self.parent.on_electrode_states_updated(data)\n                elif msg['content']['command'] == 'get_channel_states':\n                    data = decode_content_data(msg)\n                    if data is None:\n                        print msg\n                    else:\n                        #self.emit('electrode-states-set', data)\n                        self.parent.on_electrode_states_set(data)\n            elif ((source == 'droplet_planning_plugin') and\n                  (msg_type == 'execute_reply')):\n                msg = json.loads(msg_json)\n                if msg['content']['command'] in ('add_route', ):\n                    self.execute_async('droplet_planning_plugin',\n                                       'get_routes')\n                elif msg['content']['command'] in ('get_routes', ):\n                    data = decode_content_data(msg)\n                    self.parent.canvas_slave.df_routes = data\n            elif ((source == 'microdrop.command_plugin') and\n                  (msg_type == 'execute_reply')):\n                msg = json.loads(msg_json)\n\n                if msg['content']['command'] in ('get_commands',\n                                                 'unregister_command',\n                                                 'register_command'):\n                    df_commands = decode_content_data(msg).set_index('namespace')\n\n                    for group_i, df_i in df_commands.groupby('namespace'):\n                        register = getattr(self.parent.canvas_slave,\n                                           'register_%s_command' % group_i,\n                                           None)\n                        if register is None:\n                            continue\n                        else:\n                            for j, command_ij in df_i.iterrows():\n                                register(command_ij.command_name,\n                                         title=command_ij.title,\n                                         group=command_ij.plugin_name)\n                                _L().debug('registered %s command: `%s`',\n                                           group_i, command_ij)\n            else:\n                self.most_recent = msg_json\n        except zmq.Again:\n            pass\n        except:\n            logger.error('Error processing message from subscription '\n                         'socket.', exc_info=True)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_execute__set_video_config(self, request):\n        '''\n        .. versionchanged:: 0.12\n            Accept empty video configuration as either `None` or an empty\n            `pandas.Series`.\n        '''\n        data = decode_content_data(request)\n        compare_fields = ['device_name', 'width', 'height', 'name', 'fourcc',\n                          'framerate']\n        if data['video_config'] is None or not data['video_config'].shape[0]:\n            i = None\n        else:\n            for i, row in self.parent.video_mode_slave.configs.iterrows():\n                if (row[compare_fields] ==\n                        data['video_config'][compare_fields]).all():\n                    break\n            else:\n                i = None\n        if i is None:\n            logger.error('Unsupported video config:\\n%s', data['video_config'])\n            logger.error('Video configs:\\n%s',\n                         self.parent.video_mode_slave.configs)\n            self.parent.video_mode_slave.config_combo.set_active(0)\n        else:\n            logger.error('Set video config (%d):\\n%s', i + 1,\n                         data['video_config'])\n            self.parent.video_mode_slave.config_combo.set_active(i + 1)", "response": ".. versionchanged:: 0.12\n            Accept empty video configuration as either `None` or an empty\n            `pandas.Series`."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_execute__set_surface_alphas(self, request):\n        '''\n        .. versionchanged:: 0.12\n            Queue redraw after setting surface alphas.\n        '''\n        data = decode_content_data(request)\n        logger.debug('[on_execute__set_surface_alphas] %s',\n                     data['surface_alphas'])\n        for name, alpha in data['surface_alphas'].iteritems():\n            self.parent.canvas_slave.set_surface_alpha(name, alpha)\n        self.parent.canvas_slave.render()\n        gobject.idle_add(self.parent.canvas_slave.draw)", "response": "Set the surface alphas for all the items in the current page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the dynamic electrode states.", "response": "def on_execute__set_dynamic_electrode_states(self, request):\n        '''\n        .. versionadded:: 0.15\n\n        Set dynamic electrode states.\n        '''\n        data = decode_content_data(request)\n        self.parent.on_dynamic_electrode_states_set(data['electrode_states'])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconnecting to Zero MQ plugin hub using the settings from the text entry fields.", "response": "def on_connect_button__clicked(self, event):\n        '''\n        Connect to Zero MQ plugin hub (`zmq_plugin.hub.Hub`) using the settings\n        from the text entry fields (e.g., hub URI, plugin name).\n\n        Emit `plugin-connected` signal with the new plugin instance after hub\n        connection has been established.\n        '''\n        hub_uri = self.plugin_uri.get_text()\n        ui_plugin_name = self.ui_plugin_name.get_text()\n\n        plugin = self.create_plugin(ui_plugin_name, hub_uri)\n        self.init_plugin(plugin)\n\n        self.connect_button.set_sensitive(False)\n        self.emit('plugin-connected', plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating instance of QualiApiHelper based on context and logger", "response": "def create_quali_api_instance(context, logger):\n    \"\"\"\n    Get needed attributes from context and create instance of QualiApiHelper\n    :param context:\n    :param logger:\n    :return:\n    \"\"\"\n    if hasattr(context, 'reservation') and context.reservation:\n        domain = context.reservation.domain\n    elif hasattr(context, 'remote_reservation') and context.remote_reservation:\n        domain = context.remote_reservation.domain\n    else:\n        domain = None\n    address = context.connectivity.server_address\n    token = context.connectivity.admin_auth_token\n    if token:\n        instance = QualiAPIHelper(address, logger, token=token, domain=domain)\n    else:\n        instance = QualiAPIHelper(address, logger, username='admin', password='admin', domain=domain)\n    return instance"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef login(self):\n        uri = 'API/Auth/Login'\n        if self._token:\n            json_data = {'token': self._token, 'domain': self._domain}\n        else:\n            json_data = {'username': self._username, 'password': self._password, 'domain': self._domain}\n        result = self.__rest_client.request_put(uri, json_data)\n        self.__rest_client.session.headers.update(authorization=\"Basic {0}\".format(result.replace('\"', '')))", "response": "Login to the API."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns migrations in offline mode.", "response": "def run_migrations_offline():\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = winchester_config['database']['url']\n    context.configure(url=url)\n\n    with context.begin_transaction():\n        context.run_migrations()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_migrations_online():\n    engine = engine_from_config(\n        winchester_config['database'],\n        prefix='',\n        poolclass=pool.NullPool)\n\n    connection = engine.connect()\n    context.configure(\n        connection=connection,\n        target_metadata=target_metadata\n    )\n\n    try:\n        with context.begin_transaction():\n            context.run_migrations()\n    finally:\n        connection.close()", "response": "Run migrations in online mode."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the quasiparticle weight in single site spin hamiltonian under with N degenerate half - filled orbitals", "response": "def follow_cf(save, Uspan, target_cf, nup, n_tot=5.0, slsp=None):\n    \"\"\"Calculates the quasiparticle weight in single\n       site spin hamiltonian under with N degenerate half-filled orbitals \"\"\"\n\n    if slsp == None:\n        slsp = Spinon(slaves=6, orbitals=3, avg_particles=n_tot,\n                       hopping=[0.5]*6, populations = np.asarray([n_tot]*6)/6)\n\n    zet, lam, mu, mean_f = [], [], [], []\n\n    for co in Uspan:\n        print('U=', co, 'del=', target_cf)\n        res=root(targetpop, nup[-1],(co,target_cf,slsp, n_tot))\n        print(res.x)\n        if res.x>nup[-1]: break\n\n        nup.append(res.x)\n        slsp.param['populations']=population_distri(nup[-1])\n        mean_f.append(slsp.mean_field())\n        zet.append(slsp.quasiparticle_weight())\n        lam.append(slsp.param['lambda'])\n        mu.append(orbital_energies(slsp.param, zet[-1]))\n\n#    plt.plot(np.asarray(zet)[:,0], label='d={}, zl'.format(str(target_cf)))\n#    plt.plot(np.asarray(zet)[:,5], label='d={}, zh'.format(str(target_cf)))\n\n    case = save.createGroup('cf={}'.format(target_cf))\n    varis = st.setgroup(case)\n    st.storegroup(varis, Uspan[:len(zet)], zet, lam, mu, nup[1:],target_cf,mean_f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef targetpop(upper_density, coul, target_cf, slsp, n_tot):\n    if upper_density < 0.503: return 0.\n    trypops=population_distri(upper_density, n_tot)\n    slsp.set_filling(trypops)\n    slsp.selfconsistency(coul,0)\n    efm_free = dos_bethe_find_crystalfield(trypops, slsp.param['hopping'])\n    orb_ener = slsp.param['lambda']+ slsp.quasiparticle_weight()*efm_free\n    obtained_cf = orb_ener[5] - orb_ener[0]\n    return target_cf - obtained_cf", "response": "restriction on finding the right populations that leave the crystal\n    field same"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nproduce a pdf content based of a given rst content doctree_content and filename", "response": "def produce_pdf(rst_content=None, doctree_content=None, filename=None):\n    \"\"\"produce a pdf content based of a given rst content\n\n    If filename is given, it will store the result using the given filename\n    if no filename is given, it will generate a pdf in /tmp/ with a random\n    name\n    \"\"\"\n    if filename is None:\n        filename = os.path.join(\n            \"/tmp\", ''.join([random.choice(string.ascii_letters +\n            string.digits) for n in range(15)]) + '.pdf')\n    r2p = RstToPdf(stylesheets=['pdf.style'],\n                   style_path=[os.path.join(os.path.dirname(__file__),\n                                            'styles')],\n                   breaklevel=0,\n                   splittables=True,\n                   footer=\"\"\"###Title### - ###Page###/###Total###\"\"\")\n    r2p.createPdf(text=rst_content,\n                  doctree=doctree_content,\n                  output=filename)\n    return filename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_save_as(self, filename):\n\n        if len(self.spectrum.x) < 2:\n            raise RuntimeError(\"Spectrum must have at least two points\")\n        if os.path.isfile(filename):\n            os.unlink(filename)  # PyFITS does not overwrite file\n\n        hdu = self.spectrum.to_hdu()\n        overwrite_fits(hdu, filename)", "response": "Saves the current spectrum to a FITS file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef matches():\n    wvw_matches = get_cached(\"wvw/matches.json\", False).get(\"wvw_matches\")\n    for match in wvw_matches:\n        match[\"start_time\"] = parse_datetime(match[\"start_time\"])\n        match[\"end_time\"] = parse_datetime(match[\"end_time\"])\n    return wvw_matches", "response": "This resource returns a list of currently running WvW matches."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef objective_names(lang=\"en\"):\n    params = {\"lang\": lang}\n    cache_name = \"objective_names.%(lang)s.json\" % params\n    data = get_cached(\"wvw/objective_names.json\", cache_name, params=params)\n    return dict([(objective[\"id\"], objective[\"name\"]) for objective in data])", "response": "This resource returns a list of the localized WvW objective names for the specified language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_data(self, data, charset):\n\n        builder = TreeBuilder(numbermode=self._numbermode)\n        if isinstance(data,basestring):\n            xml.sax.parseString(data, builder)\n        else:\n            xml.sax.parse(data, builder)\n        return builder.root[self._root_element_name()]", "response": "Parse the xml data into a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _format_data(self, data, charset):\n\n        if data is None or data == '':\n            return u''\n\n        stream = StringIO.StringIO()\n        xml = SimplerXMLGenerator(stream, charset)\n        xml.startDocument()\n        xml.startElement(self._root_element_name(), {})\n        self._to_xml(xml, data)\n        xml.endElement(self._root_element_name())\n        xml.endDocument()\n        return stream.getvalue()", "response": "Format data into XML."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when the XML element is started.", "response": "def startElement(self, name, attrs):\n        \"\"\" Initialize new node and store current node into stack. \"\"\"\n        self.stack.append((self.current, self.chardata))\n        self.current = {}\n        self.chardata = []"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nend element parsing and add to parent node.", "response": "def endElement(self, name):\n        \"\"\" End current xml element, parse and add to to parent node. \"\"\"\n        if self.current:\n            # we have nested elements\n            obj = self.current\n        else:\n            # text only node\n            text = ''.join(self.chardata).strip()\n            obj = self._parse_node_data(text)\n        newcurrent, self.chardata = self.stack.pop()\n        self.current = self._element_to_node(newcurrent, name, obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_node_data(self, data):\n        data = data or ''\n        if self.numbermode == 'basic':\n            return self._try_parse_basic_number(data)\n        elif self.numbermode == 'decimal':\n            return self._try_parse_decimal(data)\n        else:\n            return data", "response": "Parse the value of a node."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to convert the data into int or float.", "response": "def _try_parse_basic_number(self, data):\n        \"\"\" Try to convert the data into ``int`` or ``float``.\n\n        :returns: ``Decimal`` or ``data`` if conversion fails.\n        \"\"\"\n\n        # try int first\n        try:\n            return int(data)\n        except ValueError:\n            pass\n        # try float next\n        try:\n            return float(data)\n        except ValueError:\n            pass\n        # no luck, return data as it is\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts the parsed element into the node.", "response": "def _element_to_node(self, node, name, value):\n        \"\"\" Insert the parsed element (``name``, ``value`` pair) into the node.\n\n        You should always use the returned node and forget the one\n        that was given in parameter.\n\n        :param node: the node where the is added to\n        :returns: the node. Note that this may be a new node instance.\n        \"\"\"\n\n        # is the target node a list?\n        try:\n            node.append(value)\n        except AttributeError:\n            pass\n        else:\n            return node\n\n        # target node is a dict\n        if name in node:\n            # there's already an element with same name -> convert the node into list\n            node = node.values() + [value]\n        else:\n            # just add the value into the node\n            node[name] = value\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_programs_dict(pkgname_only, flag_protected, flag_no_pfant=False):\n\n    allinfo = f311.get_programs_dict(pkgname_only, flag_protected)\n    if not flag_no_pfant and \"pyfant\" in allinfo:\n        _add_PFANT(allinfo)\n    return allinfo", "response": "Returns dictionary of all program information."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef apize_raw(url, method='GET'):\n\tdef decorator(func):\n\t\tdef wrapper(*args, **kwargs):\n\t\t\telem = func(*args, **kwargs)\n\n\t\t\tif type(elem) is not dict:\n\t\t\t\traise BadReturnVarType(func.__name__)\n\n\t\t\tresponse = send_request(url, method, \n\t\t\t\telem.get('data', {}),\n\t\t\t\telem.get('args', {}),\n\t\t\t\telem.get('params', {}),\n\t\t\t\telem.get('headers', {}),\n\t\t\t\telem.get('cookies', {}),\n\t\t\t\telem.get('timeout', 8),\n\t\t\t\telem.get('is_json', False),\n\t\t\t\telem.get('verify_cert', True)\n\t\t\t)\n\n\t\t\treturn response\n\t\treturn wrapper\n\n\treturn decorator", "response": "A decorator that converts data and params dict -> json.\n\t"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the file at the specified path and returns the version contained in it.", "response": "def extract_version(path):\n    \"\"\"\n    Reads the file at the specified path and returns the version contained in it.\n\n    This is meant for reading the __init__.py file inside a package, and so it\n    expects a version field like:\n\n    __version__ = '1.0.0'\n\n    :param path: path to the Python file\n    :return: the version inside the file\n    \"\"\"\n\n    # Regular expression for the version\n    _version_re = re.compile(r'__version__\\s+=\\s+(.*)')\n\n    with open(path + '__init__.py', 'r', encoding='utf-8') as f:\n        version = f.read()\n\n    if version:\n        version = _version_re.search(version)\n        if version:\n            version = version.group(1)\n            version = str(ast.literal_eval(version.rstrip()))\n            extracted = version\n        else:\n            extracted = None\n    else:\n        extracted = None\n\n    return extracted"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a function capable of making connections with a particular driver given the supplied credentials.", "response": "def _make_connect(module, args, kwargs):\n    \"\"\"\n    Returns a function capable of making connections with a particular\n    driver given the supplied credentials.\n    \"\"\"\n    # pylint: disable-msg=W0142\n    return functools.partial(module.connect, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef connect(module, *args, **kwargs):\n    mdr = SingleConnectionMediator(\n        module, _make_connect(module, args, kwargs))\n    return Context(module, mdr)", "response": "Connect to a database using the given DB - API driver module."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a connection pool appropriate to the driver module s capabilities.", "response": "def create_pool(module, max_conns, *args, **kwargs):\n    \"\"\"\n    Create a connection pool appropriate to the driver module's capabilities.\n    \"\"\"\n    if not hasattr(module, 'threadsafety'):\n        raise NotSupported(\"Cannot determine driver threadsafety.\")\n    if max_conns < 1:\n        raise ValueError(\"Minimum number of connections is 1.\")\n    if module.threadsafety >= 2:\n        return Pool(module, max_conns, *args, **kwargs)\n    if module.threadsafety >= 1:\n        return DummyPool(module, *args, **kwargs)\n    raise ValueError(\"Bad threadsafety level: %d\" % module.threadsafety)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting an SQL statement and return the number of affected rows.", "response": "def execute(stmt, args=()):\n    \"\"\"\n    Execute an SQL statement. Returns the number of affected rows.\n    \"\"\"\n    ctx = Context.current()\n    with ctx.mdr:\n        cursor = ctx.execute(stmt, args)\n        row_count = cursor.rowcount\n        _safe_close(cursor)\n    return row_count"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a query. This returns an iterator of the result set.", "response": "def query(stmt, args=(), factory=None):\n    \"\"\"\n    Execute a query. This returns an iterator of the result set.\n    \"\"\"\n    ctx = Context.current()\n    factory = ctx.default_factory if factory is None else factory\n    with ctx.mdr:\n        return factory(ctx.execute(stmt, args), ctx.mdr)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a query and return the first row of the result set.", "response": "def query_row(stmt, args=(), factory=None):\n    \"\"\"\n    Execute a query. Returns the first row of the result set, or `None`.\n    \"\"\"\n    for row in query(stmt, args, factory):\n        return row\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a query returning the first value in the first row of the result set. If the query returns no result set a default value is returned.", "response": "def query_value(stmt, args=(), default=None):\n    \"\"\"\n    Execute a query, returning the first value in the first row of the\n    result set. If the query returns no result set, a default value is\n    returned, which is `None` by default.\n    \"\"\"\n    for row in query(stmt, args, TupleFactory):\n        return row[0]\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a stored procedure. Returns the number of affected rows.", "response": "def execute_proc(procname, args=()):\n    \"\"\"\n    Execute a stored procedure. Returns the number of affected rows.\n    \"\"\"\n    ctx = Context.current()\n    with ctx.mdr:\n        cursor = ctx.execute_proc(procname, args)\n        row_count = cursor.rowcount\n        _safe_close(cursor)\n    return row_count"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_proc(procname, args=(), factory=None):\n    ctx = Context.current()\n    factory = ctx.default_factory if factory is None else factory\n    with ctx.mdr:\n        return factory(ctx.execute_proc(procname, args), ctx.mdr)", "response": "Execute a stored procedure. This returns an iterator of the result set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef query_proc_row(procname, args=(), factory=None):\n    for row in query_proc(procname, args, factory):\n        return row\n    return None", "response": "Execute a stored procedure and return the first row of the result set."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_proc_value(procname, args=(), default=None):\n    for row in query_proc(procname, args, TupleFactory):\n        return row[0]\n    return default", "response": "Execute a stored procedure and return the first value in the first row\n   . If no result set is found or the default value is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_placeholders(seq, start=1):\n    if len(seq) == 0:\n        raise ValueError('Sequence must have at least one element.')\n    param_style = Context.current().param_style\n    placeholders = None\n    if isinstance(seq, dict):\n        if param_style in ('named', 'pyformat'):\n            template = ':%s' if param_style == 'named' else '%%(%s)s'\n            placeholders = (template % key\n                            for key in six.iterkeys(seq))\n    elif isinstance(seq, (list, tuple)):\n        if param_style == 'numeric':\n            placeholders = (':%d' % i\n                            for i in xrange(start, start + len(seq)))\n        elif param_style in ('qmark', 'format', 'pyformat'):\n            placeholders = itertools.repeat(\n                '?' if param_style == 'qmark' else '%s',\n                len(seq))\n    if placeholders is None:\n        raise NotSupported(\n            \"Param style '%s' does not support sequence type '%s'\" % (\n                param_style, seq.__class__.__name__))\n    return ', '.join(placeholders)", "response": "Generates a list of placeholders for the given sequence."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_file_object_logger(fh):\n    def logger_func(stmt, args, fh=fh):\n        \"\"\"\n        A logger that logs everything sent to a file object.\n        \"\"\"\n        now = datetime.datetime.now()\n        six.print_(\"Executing (%s):\" % now.isoformat(), file=fh)\n        six.print_(textwrap.dedent(stmt), file=fh)\n        six.print_(\"Arguments:\", file=fh)\n        pprint.pprint(args, fh)\n    return logger_func", "response": "Returns a logger function that logs everything sent to a file object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef current(cls, with_exception=True):\n        if with_exception and len(cls.stack) == 0:\n            raise NoContext()\n        return cls.stack.top()", "response": "Returns the current database context."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transaction(self):\n        # The idea here is to fake the nesting of transactions. Only when\n        # we've gotten back to the topmost transaction context do we actually\n        # commit or rollback.\n        with self.mdr:\n            try:\n                self._depth += 1\n                yield self\n                self._depth -= 1\n            except self.mdr.OperationalError:\n                # We've lost the connection, so there's no sense in\n                # attempting to roll back back the transaction.\n                self._depth -= 1\n                raise\n            except:\n                self._depth -= 1\n                if self._depth == 0:\n                    self.mdr.rollback()\n                raise\n            if self._depth == 0:\n                self.mdr.commit()", "response": "A context manager that commits and commits all the statements within it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a cursor for the current connection. For internal use only.", "response": "def cursor(self):\n        \"\"\"\n        Get a cursor for the current connection. For internal use only.\n        \"\"\"\n        cursor = self.mdr.cursor()\n        with self.transaction():\n            try:\n                yield cursor\n                if cursor.rowcount != -1:\n                    self.last_row_count = cursor.rowcount\n                self.last_row_id = getattr(cursor, 'lastrowid', None)\n            except:\n                self.last_row_count = None\n                self.last_row_id = None\n                _safe_close(cursor)\n                raise"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute(self, stmt, args):\n        self.logger(stmt, args)\n        with self.cursor() as cursor:\n            cursor.execute(stmt, args)\n            return cursor", "response": "Execute a statement returning a cursor. For internal use only."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef execute_proc(self, procname, args):\n        self.logger(procname, args)\n        with self.cursor() as cursor:\n            cursor.callproc(procname, args)\n            return cursor", "response": "Execute a stored procedure returning a cursor. For internal use only."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the connection this context wraps.", "response": "def close(self):\n        \"\"\"\n        Close the connection this context wraps.\n        \"\"\"\n        self.logger = None\n        for exc in _EXCEPTIONS:\n            setattr(self, exc, None)\n        try:\n            self.mdr.close()\n        finally:\n            self.mdr = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self):\n        ctx = Context(self.module, self.create_mediator())\n        ctx.logger = self.logger\n        ctx.default_factory = self.default_factory\n        return ctx", "response": "Returns a context that uses this pool as a connection source."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close(self):\n        if self.mdr is None:\n            return\n        exc = (None, None, None)\n        try:\n            self.cursor.close()\n        except:\n            exc = sys.exc_info()\n        try:\n            if self.mdr.__exit__(*exc):\n                exc = (None, None, None)\n        except:\n            exc = sys.exc_info()\n        self.mdr = None\n        self.cursor = None\n        if exc != (None, None, None):\n            six.reraise(*exc)", "response": "Closes the resource database and releases all resources associated with this factory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_item(cls, item, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._add_item_with_http_info(item, **kwargs)\n        else:\n            (data) = cls._add_item_with_http_info(item, **kwargs)\n            return data", "response": "Add new item to the shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_item(cls, item_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_item_with_http_info(item_id, **kwargs)\n        else:\n            (data) = cls._delete_item_with_http_info(item_id, **kwargs)\n            return data", "response": "Remove item from shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef empty(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._empty_with_http_info(**kwargs)\n        else:\n            (data) = cls._empty_with_http_info(**kwargs)\n            return data", "response": "Empty the shopping cart."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the shopping cart of the current session.", "response": "def get(cls, **kwargs):\n        \"\"\"Get cart.\n\n        Retrieve the shopping cart of the current session.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :return: ShoppingCart\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_with_http_info(**kwargs)\n        else:\n            (data) = cls._get_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_item(cls, item_id, item, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_item_with_http_info(item_id, item, **kwargs)\n        else:\n            (data) = cls._update_item_with_http_info(item_id, item, **kwargs)\n            return data", "response": "Update the item s metadata."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all permissions supported by the resource.", "response": "def get_perm_names(cls, resource):\n        \"\"\" Return all permissions supported by the resource.\n\n        This is used for auto-generating missing permissions rows into\n        database in syncdb.\n        \"\"\"\n\n        return [cls.get_perm_name(resource, method) for method in cls.METHODS]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomposes permission name for a resource and method.", "response": "def get_perm_name(cls, resource, method):\n        \"\"\" Compose permission name\n\n        @param resource the resource\n        @param method the request method (case doesn't matter).\n        \"\"\"\n\n        return '%s_%s_%s' % (\n            cls.PREFIX,\n            cls._get_resource_name(resource),\n            method.lower())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_perm(self, request, resource):\n\n        perm_name = self.get_perm_name(resource, request.method)\n        if not self._has_perm(request.user, perm_name):\n            raise errors.Forbidden()", "response": "Check permission for the requested resource and resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck whether the user has the given permission.", "response": "def _has_perm(self, user, permission):\n        \"\"\" Check whether the user has the given permission\n\n        @return True if user is granted with access, False if not.\n        \"\"\"\n\n        if user.is_superuser:\n            return True\n        if user.is_active:\n            perms = [perm.split('.')[1] for perm in user.get_all_permissions()]\n            return permission in perms\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef wash_url_argument(var, new_type):\n    out = []\n    if new_type == 'list':  # return lst\n        if isinstance(var, list):\n            out = var\n        else:\n            out = [var]\n    elif new_type == 'str':  # return str\n        if isinstance(var, list):\n            try:\n                out = \"%s\" % var[0]\n            except:\n                out = \"\"\n        elif isinstance(var, str):\n            out = var\n        else:\n            out = \"%s\" % var\n    elif new_type == 'int':  # return int\n        if isinstance(var, list):\n            try:\n                out = int(var[0])\n            except:\n                out = 0\n        elif isinstance(var, (int, long)):\n            out = var\n        elif isinstance(var, str):\n            try:\n                out = int(var)\n            except:\n                out = 0\n        else:\n            out = 0\n    elif new_type == 'tuple':  # return tuple\n        if isinstance(var, tuple):\n            out = var\n        else:\n            out = (var, )\n    elif new_type == 'dict':  # return dictionary\n        if isinstance(var, dict):\n            out = var\n        else:\n            out = {0: var}\n    return out", "response": "Wash argument into new_type that can be list str int tuple or dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_local_url(target):\n    ref_url = urlparse(cfg.get('CFG_SITE_SECURE_URL'))\n    test_url = urlparse(urljoin(cfg.get('CFG_SITE_SECURE_URL'), target))\n    return test_url.scheme in ('http', 'https') and \\\n        ref_url.netloc == test_url.netloc", "response": "Determine if URL is a local."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget URL to redirect to and ensure that it is local.", "response": "def get_safe_redirect_target(arg='next'):\n    \"\"\"Get URL to redirect to and ensure that it is local.\"\"\"\n    for target in request.args.get(arg), request.referrer:\n        if not target:\n            continue\n        if is_local_url(target):\n            return target\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nredirect current page to url.", "response": "def redirect_to_url(req, url, redirection_type=None, norobot=False):\n    \"\"\"\n    Redirect current page to url.\n    @param req: request as received from apache\n    @param url: url to redirect to\n    @param redirection_type: what kind of redirection is required:\n    e.g.: apache.HTTP_MULTIPLE_CHOICES             = 300\n          apache.HTTP_MOVED_PERMANENTLY            = 301\n          apache.HTTP_MOVED_TEMPORARILY            = 302\n          apache.HTTP_SEE_OTHER                    = 303\n          apache.HTTP_NOT_MODIFIED                 = 304\n          apache.HTTP_USE_PROXY                    = 305\n          apache.HTTP_TEMPORARY_REDIRECT           = 307\n    The default is apache.HTTP_MOVED_TEMPORARILY\n    @param norobot: wether to instruct crawlers and robots such as GoogleBot\n        not to index past this point.\n    @see: http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html#sec10.3\n    \"\"\"\n    url = url.strip()\n    if redirection_type is None:\n        redirection_type = apache.HTTP_MOVED_TEMPORARILY\n\n    from flask import redirect\n    r = redirect(url, code=redirection_type)\n    raise apache.SERVER_RETURN(r)\n    # FIXME enable code bellow\n\n    del req.headers_out[\"Cache-Control\"]\n    req.headers_out[\"Cache-Control\"] = \"no-cache, private, no-store, \" \\\n        \"must-revalidate, post-check=0, pre-check=0, max-age=0\"\n    req.headers_out[\"Pragma\"] = \"no-cache\"\n\n    if norobot:\n        req.headers_out[\n            \"X-Robots-Tag\"] = \"noarchive, nosnippet, noindex, nocache\"\n\n    user_agent = req.headers_in.get('User-Agent', '')\n    if 'Microsoft Office Existence Discovery' in user_agent or 'ms-office' in user_agent:\n        # HACK: this is to workaround Microsoft Office trying to be smart\n        # when users click on URLs in Office documents that require\n        # authentication. Office will check the validity of the URL\n        # but will pass the browser the redirected URL rather than\n        # the original one. This is incompatible with e.g. Shibboleth\n        # based SSO since the referer would be lost.\n        # See: http://support.microsoft.com/kb/899927\n        req.status = 200\n        req.content_type = 'text/html'\n        if req.method != 'HEAD':\n            req.write(\"\"\"\n<html>\n    <head>\n        <title>Intermediate page for URLs clicked on MS Office Documents</title>\n        <meta http-equiv=\"REFRESH\" content=\"5;url=%(url)s\"></meta>\n    </head>\n    <body>\n        <p>You are going to be redirected to the desired content within 5 seconds. If the redirection does not happen automatically please click on <a href=\"%(url)s\">%(url_ok)s</a>.</p>\n    </body>\n</html>\"\"\" % {\n                'url': escape(req.unparsed_uri, True),\n                'url_ok': escape(req.unparsed_uri)\n            })\n        raise apache.SERVER_RETURN(apache.DONE)\n\n    req.headers_out[\"Location\"] = url\n\n    if req.response_sent_p:\n        raise IOError(\"Cannot redirect after headers have already been sent.\")\n\n    req.status = redirection_type\n    req.write('<p>Please go to <a href=\"%s\">here</a></p>\\n' % url)\n\n    raise apache.SERVER_RETURN(apache.DONE)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrewrite URL to a Secure URL.", "response": "def rewrite_to_secure_url(url, secure_base=None):\n    \"\"\"\n    Rewrite URL to a Secure URL\n\n    @param url URL to be rewritten to a secure URL.\n    @param secure_base: Base URL of secure site (defaults to CFG_SITE_SECURE_URL).\n    \"\"\"\n    if secure_base is None:\n        secure_base = cfg.get('CFG_SITE_SECURE_URL')\n    url_parts = list(urlparse(url))\n    url_secure_parts = urlparse(secure_base)\n    url_parts[0] = url_secure_parts[0]\n    url_parts[1] = url_secure_parts[1]\n    return urlunparse(url_parts)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the referer of a request.", "response": "def get_referer(req, replace_ampersands=False):\n    \"\"\" Return the referring page of a request.\n    Referer (wikipedia): Referer is a common misspelling of the word\n    \"referrer\"; so common, in fact, that it made it into the official\n    specification of HTTP. When visiting a webpage, the referer or\n    referring page is the URL of the previous webpage from which a link was\n    followed.\n    @param req: request\n    @param replace_ampersands: if 1, replace & by &amp; in url\n                               (correct HTML cannot contain & characters alone)\n    \"\"\"\n    try:\n        referer = req.headers_in['Referer']\n        if replace_ampersands == 1:\n            return referer.replace('&', '&amp;')\n        return referer\n    except KeyError:\n        return ''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_canonical_urlargd(urlargd, default_urlargd):\n\n    canonical = drop_default_urlargd(urlargd, default_urlargd)\n\n    if canonical:\n        return '?' + urlencode(canonical, doseq=True)\n        # FIXME double escaping of '&'? .replace('&', '&amp;')\n\n    return ''", "response": "This function takes a dictionary of arguments and returns a canonical url query string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_html_link(urlbase, urlargd, link_label, linkattrd=None,\n                     escape_urlargd=True, escape_linkattrd=True,\n                     urlhash=None):\n    \"\"\"Creates a W3C compliant link.\n    @param urlbase: base url (e.g. config.CFG_SITE_URL/search)\n    @param urlargd: dictionary of parameters. (e.g. p={'recid':3, 'of'='hb'})\n    @param link_label: text displayed in a browser (has to be already escaped)\n    @param linkattrd: dictionary of attributes (e.g. a={'class': 'img'})\n    @param escape_urlargd: boolean indicating if the function should escape\n                           arguments (e.g. < becomes &lt; or \" becomes &quot;)\n    @param escape_linkattrd: boolean indicating if the function should escape\n                           attributes (e.g. < becomes &lt; or \" becomes &quot;)\n    @param urlhash: hash string to add at the end of the link\n    \"\"\"\n    attributes_separator = ' '\n    output = '<a href=\"' + \\\n             create_url(urlbase, urlargd, escape_urlargd, urlhash) + '\"'\n    if linkattrd:\n        output += ' '\n        if escape_linkattrd:\n            attributes = [escape(str(key), quote=True) + '=\"' +\n                          escape(str(linkattrd[key]), quote=True) + '\"'\n                          for key in linkattrd.keys()]\n        else:\n            attributes = [str(key) + '=\"' + str(linkattrd[key]) + '\"'\n                          for key in linkattrd.keys()]\n        output += attributes_separator.join(attributes)\n    output = wash_for_utf8(output)\n    output += '>' + wash_for_utf8(link_label) + '</a>'\n    return output", "response": "Creates a W3C compliant link."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_html_mailto(\n        email,\n        subject=None,\n        body=None,\n        cc=None,\n        bcc=None,\n        link_label=\"%(email)s\",\n        linkattrd=None,\n        escape_urlargd=True,\n        escape_linkattrd=True,\n        email_obfuscation_mode=None):\n    \"\"\"Creates a W3C compliant 'mailto' link.\n\n    Encode/encrypt given email to reduce undesired automated email\n    harvesting when embedded in a web page.\n\n    NOTE: there is no ultimate solution to protect against email\n    harvesting. All have drawbacks and can more or less be\n    circumvented. There are other techniques to protect email\n    addresses. We implement the less annoying one for users.\n\n    @param email: the recipient of the email\n    @param subject: a default subject for the email (must not contain\n                    line feeds)\n    @param body: a default body for the email\n    @param cc: the co-recipient(s) of the email\n    @param bcc: the hidden co-recpient(s) of the email\n    @param link_label: the label of this mailto link. String\n                       replacement is performed on key %(email)s with\n                       the email address if needed.\n    @param linkattrd: dictionary of attributes (e.g. a={'class': 'img'})\n    @param escape_urlargd: boolean indicating if the function should escape\n                           arguments (e.g. < becomes &lt; or \" becomes &quot;)\n    @param escape_linkattrd: boolean indicating if the function should escape\n                           attributes (e.g. < becomes &lt; or \" becomes &quot;)\n    @param email_obfuscation_mode: the protection mode. See below:\n\n    You can choose among several modes to protect emails. It is\n    advised to keep the default\n    CFG_MISCUTIL_EMAIL_HARVESTING_PROTECTION value, so that it is\n    possible for an admin to change the policy globally.\n\n    Available modes ([t] means \"transparent\" for the user):\n\n         -1: hide all emails, excepted CFG_SITE_ADMIN_EMAIL and\n             CFG_SITE_SUPPORT_EMAIL.\n\n      [t] 0 : no protection, email returned as is.\n                foo@example.com => foo@example.com\n\n          1 : basic email munging: replaces @ by [at] and . by [dot]\n                foo@example.com => foo [at] example [dot] com\n\n      [t] 2 : transparent name mangling: characters are replaced by\n              equivalent HTML entities.\n                foo@example.com => &#102;&#111;&#111;&#64;&#101;&#120;&#97;&#109;&#112;&#108;&#101;&#46;&#99;&#111;&#109;\n\n      [t] 3 : javascript insertion. Requires Javascript enabled on client side.\n\n          4 : replaces @ and . characters by gif equivalents.\n                foo@example.com => foo<img src=\"at.gif\" alt=\" [at] \">example<img src=\"dot.gif\" alt=\" [dot] \">com\n    \"\"\"\n    # TODO: implement other protection modes to encode/encript email:\n    #\n    # [t] 5 : form submission. User is redirected to a form that he can\n    # fills in to send the email (??Use webmessage??).\n    # Depending on WebAccess, ask to answer a question.\n    ##\n    # [t] 6 : if user can see (controlled by WebAccess), display. Else\n    # ask to login to see email. If user cannot see, display\n    # form submission.\n\n    if email_obfuscation_mode is None:\n        email_obfuscation_mode = cfg.get(\n            'CFG_WEBSTYLE_EMAIL_ADDRESSES_OBFUSCATION_MODE')\n\n    if linkattrd is None:\n        linkattrd = {}\n\n    parameters = {}\n    if subject:\n        parameters[\"subject\"] = subject\n    if body:\n        parameters[\"body\"] = body.replace('\\r\\n', '\\n').replace('\\n', '\\r\\n')\n    if cc:\n        parameters[\"cc\"] = cc\n    if bcc:\n        parameters[\"bcc\"] = bcc\n\n    # Preprocessing values for some modes\n    if email_obfuscation_mode == 1:\n        # Basic Munging\n        email = email.replace(\"@\", \" [at] \").replace(\".\", \" [dot] \")\n    elif email_obfuscation_mode == 2:\n        # Transparent name mangling\n        email = string_to_numeric_char_reference(email)\n\n    if '%(email)s' in link_label:\n        link_label = link_label % {'email': email}\n\n    mailto_link = create_html_link('mailto:' + email, parameters,\n                                   link_label, linkattrd,\n                                   escape_urlargd, escape_linkattrd)\n\n    if email_obfuscation_mode == 0:\n        # Return \"as is\"\n        return mailto_link\n    elif email_obfuscation_mode == 1:\n        # Basic Munging\n        return mailto_link\n    elif email_obfuscation_mode == 2:\n        # Transparent name mangling\n        return mailto_link\n    elif email_obfuscation_mode == 3:\n        # Javascript-based\n        return '''<script language=\"JavaScript\" ''' \\\n            '''type=\"text/javascript\">''' \\\n            '''document.write('%s'.split(\"\").reverse().join(\"\"))''' \\\n            '''</script>''' % \\\n               mailto_link[::-1].replace(\"'\", \"\\\\'\")\n    elif email_obfuscation_mode == 4:\n        # GIFs-based\n        email = email.replace(\n            '.', '<img src=\"%s/img/dot.gif\" alt=\" [dot] \" '\n            'style=\"vertical-align:bottom\"  />' %\n            cfg.get('CFG_SITE_URL'))\n        email = email.replace(\n            '@', '<img src=\"%s/img/at.gif\" alt=\" [at] \" '\n            'style=\"vertical-align:baseline\" />' %\n            cfg.get('CFG_SITE_URL'))\n        return email\n\n    # All other cases, including mode -1:\n    return \"\"", "response": "Creates an HTML mailto link."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding a string to HTML - compatible numeric character reference.", "response": "def string_to_numeric_char_reference(string):\n    \"\"\"\n    Encode a string to HTML-compatible numeric character reference.\n    Eg: encode_html_entities(\"abc\") == '&#97;&#98;&#99;'\n    \"\"\"\n    out = \"\"\n    for char in string:\n        out += \"&#\" + str(ord(char)) + \";\"\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a W3C compliant URL.", "response": "def create_url(urlbase, urlargd, escape_urlargd=True, urlhash=None):\n    \"\"\"Creates a W3C compliant URL. Output will look like this:\n    'urlbase?param1=value1&amp;param2=value2'\n    @param urlbase: base url (e.g. config.CFG_SITE_URL/search)\n    @param urlargd: dictionary of parameters. (e.g. p={'recid':3, 'of'='hb'}\n    @param escape_urlargd: boolean indicating if the function should escape\n                           arguments (e.g. < becomes &lt; or \" becomes &quot;)\n    @param urlhash: hash string to add at the end of the link\n    \"\"\"\n    separator = '&amp;'\n    output = urlbase\n    if urlargd:\n        output += '?'\n        if escape_urlargd:\n            arguments = [escape(quote(str(key)), quote=True) + '=' +\n                         escape(quote(str(urlargd[key])), quote=True)\n                         for key in urlargd.keys()]\n        else:\n            arguments = [str(key) + '=' + str(urlargd[key])\n                         for key in urlargd.keys()]\n        output += separator.join(arguments)\n    if urlhash:\n        output += \"#\" + escape(quote(str(urlhash)))\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef same_urls_p(a, b):\n\n    ua = list(urlparse(a))\n    ub = list(urlparse(b))\n\n    ua[4] = parse_qs(ua[4])\n    ub[4] = parse_qs(ub[4])\n\n    return ua == ub", "response": "Compare two URLs ignoring reorganizing of query arguments"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nanalyze urlargs and for each occurrence of argument matching regexp_argname replace every substring text_old by text_new. Return the resulting new URL.", "response": "def urlargs_replace_text_in_arg(urlargs, regexp_argname, text_old, text_new):\n    \"\"\"Analyze `urlargs' (URL CGI GET query arguments in string form)\n       and for each occurrence of argument matching `regexp_argname'\n       replace every substring `text_old' by `text_new'.  Return the\n       resulting new URL.\n\n       Used to be used for search engine's create_nearest_terms_box,\n       now it is not used there anymore.  It is left here in case it\n       will become possibly useful later.\n    \"\"\"\n    out = \"\"\n    # parse URL arguments into a dictionary:\n    urlargsdict = parse_qs(urlargs)\n    # construct new URL arguments:\n    urlargsdictnew = {}\n    for key in urlargsdict.keys():\n        if re.match(regexp_argname, key):  # replace `arg' by new values\n            urlargsdictnew[key] = []\n            for parg in urlargsdict[key]:\n                urlargsdictnew[key].append(parg.replace(text_old, text_new))\n        else:  # keep old values\n            urlargsdictnew[key] = urlargsdict[key]\n    # build new URL for this word:\n    for key in urlargsdictnew.keys():\n        for val in urlargsdictnew[key]:\n            out += \"&amp;\" + key + \"=\" + quote_plus(val, '')\n    if out.startswith(\"&amp;\"):\n        out = out[5:]\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a nice and uniform user - agent string to be used when Invenio is used when HTTP requests are made.", "response": "def make_user_agent_string(component=None):\n    \"\"\"\n    Return a nice and uniform user-agent string to be used when Invenio\n    act as a client in HTTP requests.\n    \"\"\"\n    ret = \"Invenio-%s (+%s; \\\"%s\\\")\" % (cfg.get('CFG_VERSION'),\n                                        cfg.get('CFG_SITE_URL'), cfg.get('CFG_SITE_NAME'))\n    if component:\n        ret += \" %s\" % component\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef make_invenio_opener(component=None):\n    opener = urllib2.build_opener()\n    opener.addheaders = [('User-agent', make_user_agent_string(component))]\n    return opener", "response": "Returns an urllib2 opener with the useragent already set in the appropriate\n    way."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_AWS_request_url(base_url, argd, _amazon_secret_access_key,\n                           _timestamp=None):\n    \"\"\"\n    Create a signed AWS (Amazon Web Service) request URL corresponding\n    to the given parameters.\n\n    Example:\n    >> create_AWS_request_url(\"http://ecs.amazon.com/onca/xml\",\n                             {'AWSAccessKeyID': '0000000000',\n                              'Service': 'AWSECommerceService',\n                              'Operation': 'ItemLookup',\n                              'ItemID': '0679722769',\n                              'ResponseGroup': 'ItemAttributes,Offers,Images,Review'},\n                             \"1234567890\")\n\n    @param base_url: Service URL of the Amazon store to query\n    @param argd: dictionary of arguments defining the query\n    @param _amazon_secret_access_key: your Amazon secret key\n    @param _timestamp: for testing purpose only (default: current timestamp)\n\n    @type base_url: string\n    @type argd: dict\n    @type _amazon_secret_access_key: string\n    @type _timestamp: string\n\n    @return signed URL of the request (string)\n    \"\"\"\n\n    # First define a few util functions\n\n    def get_AWS_signature(argd, _amazon_secret_access_key,\n                          method=\"GET\", request_host=\"webservices.amazon.com\",\n                          request_uri=\"/onca/xml\",\n                          _timestamp=None):\n        \"\"\"\n        Returns the signature of an Amazon request, based on the\n        arguments of the request.\n\n        @param argd: dictionary of arguments defining the query\n        @param _amazon_secret_access_key: your Amazon secret key\n        @param method: method of the request POST or GET\n        @param request_host: host contacted for the query. To embed in the signature.\n        @param request_uri: uri contacted at 'request_host'. To embed in the signature.\n        @param _timestamp: for testing purpose only (default: current timestamp)\n\n        @type argd: dict\n        @type _amazon_secret_access_key: string\n        @type method: string\n        @type host_header: string\n        @type http_request_uri: string\n        @type _timestamp: string\n\n        @return signature of the request (string)\n        \"\"\"\n\n        # Add timestamp\n        if not _timestamp:\n            argd[\"Timestamp\"] = time.strftime(\"%Y-%m-%dT%H:%M:%SZ\",\n                                              time.gmtime())\n        else:\n            argd[\"Timestamp\"] = _timestamp\n\n        # Order parameter keys by byte value\n        parameter_keys = sorted(argd.keys())\n\n        # Encode arguments, according to RFC 3986. Make sure we\n        # generate a list which is ordered by byte value of the keys\n        arguments = [quote(str(key), safe=\"~/\") + \"=\" +\n                     quote(str(argd[key]), safe=\"~/\")\n                     for key in parameter_keys]\n\n        # Join\n        parameters_string = \"&\".join(arguments)\n\n        # Prefix\n        parameters_string = method.upper() + \"\\n\" + \\\n            request_host.lower() + \"\\n\" + \\\n            (request_uri or \"/\") + \"\\n\" + \\\n            parameters_string\n\n        # Sign and return\n        return calculate_RFC2104_HMAC(parameters_string,\n                                      _amazon_secret_access_key)\n\n    def calculate_RFC2104_HMAC(data, _amazon_secret_access_key):\n        \"\"\"\n        Computes a RFC 2104 compliant HMAC Signature and then Base64\n        encodes it.\n\n        Module hashlib must be installed if Python < 2.5\n        <http://pypi.python.org/pypi/hashlib/20081119>\n\n        @param data: data to sign\n        @param _amazon_secret_access_key: your Amazon secret key\n\n        @type data: string\n        @type _amazon_secret_access_key: string. Empty if hashlib module not installed\n        \"\"\"\n        if not HASHLIB_IMPORTED:\n            current_app.logger.warning(\n                \"Module hashlib not installed. Please install it.\"\n            )\n            return \"\"\n        else:\n            if sys.version_info < (2, 5):\n                # compatibility mode for Python < 2.5 and hashlib\n                my_digest_algo = _MySHA256(sha256())\n            else:\n                my_digest_algo = sha256\n\n        return base64.encodestring(\n            hmac.new(\n                _amazon_secret_access_key,\n                data,\n                my_digest_algo).digest()).strip()\n    # End util functions\n\n    parsed_url = urlparse(base_url)\n    signature = get_AWS_signature(argd, _amazon_secret_access_key,\n                                  request_host=parsed_url[1],\n                                  request_uri=parsed_url[2],\n                                  _timestamp=_timestamp)\n    if signature:\n        argd[\"Signature\"] = signature\n    return base_url + \"?\" + urlencode(argd)", "response": "Create a signed AWS request URL corresponding to the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a signed Indico request URL to access Indico HTTP Export APIs.", "response": "def create_Indico_request_url(\n        base_url,\n        indico_what,\n        indico_loc,\n        indico_id,\n        indico_type,\n        indico_params,\n        indico_key,\n        indico_sig,\n        _timestamp=None):\n    \"\"\"\n    Create a signed Indico request URL to access Indico HTTP Export APIs.\n\n    See U{http://indico.cern.ch/ihelp/html/ExportAPI/index.html} for more\n    information.\n\n    Example:\n    >> create_Indico_request_url(\"https://indico.cern.ch\",\n                                 \"categ\",\n                                 \"\",\n                                 [1, 7],\n                                 \"xml\",\n                                 {'onlypublic': 'yes',\n                                  'order': 'title',\n                                  'from': 'today',\n                                  'to': 'tomorrow'},\n                                 '00000000-0000-0000-0000-000000000000',\n                                 '00000000-0000-0000-0000-000000000000')\n\n    @param base_url: Service base URL of the Indico instance to query\n    @param indico_what: element to export\n    @type indico_what: one of the strings: C{categ}, C{event}, C{room}, C{reservation}\n    @param indico_loc: location of the element(s) specified by ID (only used for some elements)\n    @param indico_id: ID of the element to be exported\n    @type indico_id: a string or a list/tuple of strings\n    @param indico_type: output format\n    @type indico_type: one of the strings: C{json}, C{jsonp}, C{xml}, C{html}, C{ics}, C{atom}\n    @param indico_params: parameters of the query. See U{http://indico.cern.ch/ihelp/html/ExportAPI/common.html}\n    @param indico_key: API key provided for the given Indico instance\n    @param indico_sig: API secret key (signature) provided for the given Indico instance\n    @param _timestamp: for testing purpose only (default: current timestamp)\n\n    @return signed URL of the request (string)\n    \"\"\"\n\n    url = '/export/' + indico_what + '/'\n    if indico_loc:\n        url += indico_loc + '/'\n    if type(indico_id) in (list, tuple):\n        # dash separated list of values\n        indico_id = '-'.join([str(x) for x in indico_id])\n    url += indico_id + '.' + str(indico_type)\n\n    if hasattr(indico_params, 'items'):\n        items = indico_params.items()\n    else:\n        items = list(indico_params)\n    if indico_key:\n        items.append(('apikey', indico_key))\n    if indico_sig and HASHLIB_IMPORTED:\n        if _timestamp:\n            items.append(('timestamp', str(_timestamp)))\n        else:\n            items.append(('timestamp', str(int(time.time()))))\n        items = sorted(items, key=lambda x: x[0].lower())\n        url_to_sign = '%s?%s' % (url, urlencode(items))\n        if sys.version_info < (2, 5):\n            # compatibility mode for Python < 2.5 and hashlib\n            my_digest_algo = _MySHA1(sha1())\n        else:\n            my_digest_algo = sha1\n        signature = hmac.new(indico_sig, url_to_sign,\n                             my_digest_algo).hexdigest()\n        items.append(('signature', signature))\n    elif not HASHLIB_IMPORTED:\n        current_app.logger.warning(\n            \"Module hashlib not installed. Please install it.\"\n        )\n    if not items:\n        return url\n\n    url = '%s%s?%s' % (base_url.strip('/'), url, urlencode(items))\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auto_version_url(file_path):\n    file_md5 = \"\"\n    try:\n        file_md5 = md5(open(cfg.get('CFG_WEBDIR') +\n                            os.sep + file_path).read()).hexdigest()\n    except IOError:\n        pass\n    return file_path + \"?%s\" % file_md5", "response": "Adds modification time of the file to the request URL in order for the browser to refresh the cache when the file changes the\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_relative_url(url):\n    # remove any protocol info before\n    stripped_site_url = url.replace(\"://\", \"\")\n    baseurl = \"/\" + \"/\".join(stripped_site_url.split(\"/\")[1:])\n\n    # remove any trailing slash (\"/\")\n    if baseurl[-1] == \"/\":\n        return baseurl[:-1]\n    else:\n        return baseurl", "response": "Returns the relative URL from a URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef function_arg_count(fn):\n    assert callable(fn), 'function_arg_count needed a callable function, not {0}'.format(repr(fn))\n    if hasattr(fn, '__code__') and hasattr(fn.__code__, 'co_argcount'):\n        return fn.__code__.co_argcount\n    else:\n        return 1", "response": "returns how many arguments a function has"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef map(*args):\n\n    functions_to_apply = [i for i in args if callable(i)]\n    iterables_to_run = [i for i in args if not callable(i)]\n    #print('functions_to_apply:',functions_to_apply)\n    #print('iterables_to_run:',iterables_to_run)\n\n    assert len(functions_to_apply)>0, 'at least one function needs to be given to map'\n    assert len(iterables_to_run)>0, 'no iterables were given to map'\n\n    # check for native map usage\n    if len(functions_to_apply) == 1 and len(iterables_to_run) >= 1 and function_arg_count(*functions_to_apply)==1:\n        if hasattr(iter([]), '__next__'): # if python 3\n            return __builtins__.map(functions_to_apply[0], *iterables_to_run)\n        else:\n            return iter(__builtins__.map(functions_to_apply[0], *iterables_to_run))\n    # ---------------------------- new logic below ----------------------------\n    # logic for a single function\n    elif len(functions_to_apply) == 1:\n        fn = functions_to_apply[0]\n        # if there is a single iterable, chop it up\n        if len(iterables_to_run) == 1:\n            return (fn(*i) for i in window(iterables_to_run[0], function_arg_count(functions_to_apply[0])))\n    # logic for more than 1 function\n    elif len(functions_to_apply) > 1 and len(iterables_to_run) == 1:\n        return multi_ops(*(iterables_to_run + functions_to_apply))\n    else:\n        raise ValueError('invalid usage of map()')", "response": "this function maps a function over a base - set of iterable objects and returns a new iterable object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef merge(left, right, how='inner', key=None, left_key=None, right_key=None,\n          left_as='left', right_as='right'):\n    \"\"\" Performs a join using the union join function. \"\"\"\n    return join(left, right, how, key, left_key, right_key,\n                join_fn=make_union_join(left_as, right_as))", "response": "Merges two items into a single item."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef join(left, right, how='inner', key=None, left_key=None, right_key=None,\n         join_fn=tuple_join):\n    \"\"\"\n    :param left: left iterable to be joined\n    :param right: right iterable to be joined\n    :param str | function key: either an attr name, dict key, or function that produces hashable value\n    :param how: 'inner', 'left', 'right', or 'outer'\n    :param join_fn: function called on joined left and right iterable items to complete join\n    :rtype: list\n    \"\"\"\n    if key is None and (left_key is None or right_key is None):\n        raise ValueError(\"Must provide either key param or both left_key and right_key\")\n\n    if key is not None:\n        lkey = rkey = key if callable(key) else make_key_fn(key)\n    else:\n        lkey = left_key if callable(left_key) else make_key_fn(left_key)\n        rkey = right_key if callable(right_key) else make_key_fn(right_key)\n\n    try:\n        join_impl = {\n            \"left\": _left_join,\n            \"right\": _right_join,\n            \"inner\": _inner_join,\n            \"outer\": _outer_join,\n        }[how]\n    except KeyError:\n        raise ValueError(\"Invalid value for how: {}, must be left, right, \"\n                         \"inner, or outer.\".format(str(how)))\n    else:\n        return join_impl(left, right, lkey, rkey, join_fn)", "response": "Returns a list of items from the given iterable left and right."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _right_join(left, right, left_key_fn, right_key_fn, join_fn=union_join):\n    def reversed_join_fn(left_ele, right_ele):\n        return join_fn(right_ele, left_ele)\n    return _left_join(right, left, right_key_fn, left_key_fn, reversed_join_fn)", "response": "A function that joins two iterable objects with the same key."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _outer_join(left, right, left_key_fn, right_key_fn, join_fn=union_join):\n    left_joiner = defaultdict(list)\n    for ele in left:\n        left_joiner[left_key_fn(ele)].append(ele)\n    right_joiner = defaultdict(list)\n    for ele in right:\n        right_joiner[right_key_fn(ele)].append(ele)\n    keys = set(left_joiner.keys()).union(set(right_joiner.keys()))\n\n    def iter_join(l, r, join_keys):\n        for join_key in join_keys:\n            for ele in l.get(join_key, [None]):\n                for other in r.get(join_key, [None]):\n                    yield join_fn(ele, other)\n\n    return list(iter_join(left_joiner, right_joiner, keys))", "response": "outer join of two lists of objects"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngroup an iterable by an attribute or a key - access function.", "response": "def group(iterable, key=lambda ele: ele):\n    \"\"\" Groups an iterable by a specified attribute, or using a specified key access function.  Returns tuples of grouped elements.\n\n    >>> dogs = [Dog('gatsby', 'Rruff!', 15), Dog('william', 'roof', 12), Dog('edward', 'hi', 15)]\n    >>> groupby(dogs, 'weight')\n    [(Dog('gatsby', 'Rruff!', 15), Dog('edward', 'hi', 15)), (Dog('william', 'roof', 12), )]\n\n    :param iterable: iterable to be grouped\n    :param key: a key-access function or attr name to be used as a group key\n    \"\"\"\n    if callable(key):\n        return _group(iterable, key)\n    else:\n        return _group(iterable, make_key_fn(key))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef trigger_keyphrases(\n    text                          = None,  # input text to parse\n    keyphrases                    = None,  # keyphrases for parsing input text\n    response                      = None,  # optional text response on trigger\n    function                      = None,  # optional function on trigger\n    kwargs                        = None,  # optional function keyword arguments\n    confirm                       = False, # optional return of confirmation\n    confirmation_prompt           = \"Do you want to continue? (y/n)\",\n    confirmation_feedback_confirm = \"confirm\",\n    confirmation_feedback_deny    = \"deny\"\n    ):\n    \"\"\"\n    Parse input text for keyphrases. If any keyphrases are found, respond with\n    text or by seeking confirmation or by engaging a function with optional\n    keyword arguments. Return text or True if triggered and return False if not\n    triggered. If confirmation is required, a confirmation object is returned,\n    encapsulating a function and its optional arguments.\n    \"\"\"\n    if any(pattern in text for pattern in keyphrases):\n        if confirm:\n            return confirmation(\n                prompt           = confirmation_prompt,\n                feedback_confirm = confirmation_feedback_confirm,\n                feedback_deny    = confirmation_feedback_deny,\n                function         = function,\n                kwargs           = kwargs\n            )\n        if function and not kwargs:\n            result = function()\n        elif function and kwargs:\n            result = function(**kwargs)\n        else:\n            result = None\n        if response:\n            return response\n        elif not response and result:\n            return str(result)\n        else:\n            return True\n    else:\n        return False", "response": "Trigger keyphrases on a key - syllables."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse input text using various keyphrases and return a list of the values returned by that trigger.", "response": "def parse(\n    text   = None,\n    humour = 75\n    ):\n    \"\"\"\n    Parse input text using various triggers, some returning text and some for\n    engaging functions. If triggered, a trigger returns text or True if and if\n    not triggered, returns False. If no triggers are triggered, return False, if\n    one trigger is triggered, return the value returned by that trigger, and if\n    multiple triggers are triggered, return a list of the values returned by\n    those triggers.\n\n    Options such as humour engage or disengage various triggers.\n    \"\"\"\n    triggers = []\n\n    # general\n\n    if humour >= 75:\n        triggers.extend([\n            trigger_keyphrases(\n                text       = text,\n                keyphrases = [\n                             \"image\"\n                             ],\n                response   = \"http://i.imgur.com/MiqrlTh.jpg\"\n            ),\n            trigger_keyphrases(\n                text       = text,\n                keyphrases = [\n                             \"sup\",\n                             \"hi\"\n                             ],\n                response   = \"sup home bean\"\n            ),\n            trigger_keyphrases(\n                text       = text,\n                keyphrases = [\n                             \"thanks\",\n                             \"thank you\"\n                             ],\n                response   = \"you're welcome, boo ;)\"\n            )\n        ])\n\n    # information\n\n    triggers.extend([\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"where are you\",\n                         \"IP\",\n                         \"I.P.\",\n                         \"IP address\",\n                         \"I.P. address\",\n                         \"ip address\"\n                         ],\n            function   = report_IP\n        ),\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"how are you\",\n                         \"are you well\",\n                         \"status\"\n                         ],\n            function   = report_system_status,\n            kwargs     = {\"humour\": humour}\n        ),\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"heartbeat\"\n                         ],\n            function   = heartbeat_message\n        ),\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"METAR\"\n                         ],\n            function   = report_METAR,\n            kwargs     = {\"text\": text}\n        ),\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"TAF\"\n                         ],\n            response   = report_TAF,\n            kwargs     = {\"text\": text}\n        ),\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"rain\"\n                         ],\n            response   = report_rain_times,\n            kwargs     = {\"text\": text}\n        )\n    ])\n\n    # actions\n\n    triggers.extend([\n        trigger_keyphrases(\n            text       = text,\n            keyphrases = [\n                         \"command\",\n                         \"run command\",\n                         \"engage command\",\n                         \"execute command\"\n                         ],\n            response   = command()\n        ),\n        trigger_keyphrases(\n            text                          = text,\n            keyphrases                    = [\n                                            \"restart\"\n                                            ],\n            function                      = restart,\n            confirm                       = True,\n            confirmation_prompt           = \"Do you want to restart this \"\n                                            \"program? (y/n)\",\n            confirmation_feedback_confirm = \"confirm restart\",\n            confirmation_feedback_deny    = \"deny restart\"\n        )\n    ])\n\n    if any(triggers):\n        responses = [response for response in triggers if response]\n        if len(responses) > 1:\n            return responses\n        else:\n            return responses[0]\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the networking text into a nonsense.", "response": "def parse_networking(\n    text    = None\n    ):\n    \"\"\"\n    Access address and port parameters via the builtins or __builtin__ module.\n    Relish the nonsense.\n    \"\"\"\n    try:\n        address = _builtins.address\n        port    = _builtins.port\n    except:\n        address = None\n        port    = None\n    triggers = []\n    if address and port:\n        triggers.extend([\n            trigger_keyphrases(\n                text                          = text,\n                keyphrases                    = [\n                                                \"reverse SSH\",\n                                                \"reverse ssh\"\n                                                ],\n                function                      = engage_command,\n                kwargs                        = {\"command\": \"ssh -R \" + str(port) + \":localhost:22 \" + address},\n                confirm                       = True,\n                confirmation_prompt           = \"Do you want to reverse SSH \"\n                                                \"connect? (y/n)\",\n                confirmation_feedback_confirm = \"confirm reverse SSH connect: \"\n                                                \"ssh localhost -p \" + str(port),\n                confirmation_feedback_deny    = \"deny reverse SSH connect\"\n            )\n        ])\n    if any(triggers):\n        responses = [response for response in triggers if response]\n        if len(responses) > 1:\n            return responses\n        else:\n            return responses[0]\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses input text by looping over a list of multiple parsers and returning the value returned by that trigger.", "response": "def multiparse(\n    text         = None,\n    parsers      = [parse],\n    help_message = None\n    ):\n    \"\"\"\n    Parse input text by looping over a list of multiple parsers. If one trigger\n    is triggered, return the value returned by that trigger, if multiple\n    triggers are triggered, return a list of the values returned by those\n    triggers. If no triggers are triggered, return False or an optional help\n    message.\n    \"\"\"\n    responses = []\n    for _parser in parsers:\n        response = _parser(text = text)\n        if response is not False:\n            responses.extend(response if response is list else [response])\n    if not any(responses):\n        if help_message:\n            return help_message\n        else:\n            return False\n    else:\n        if len(responses) > 1:\n            return responses\n        else:\n            return responses[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the function with optional keyword arguments.", "response": "def run(\n        self\n        ):\n        \"\"\"\n        Engage contained function with optional keyword arguments.\n        \"\"\"\n        if self._function and not self._kwargs:\n            return self._function()\n        if self._function and self._kwargs:\n            return self._function(**self._kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the tax_class_based_on of this TaxSettings.", "response": "def tax_class_based_on(self, tax_class_based_on):\n        \"\"\"Sets the tax_class_based_on of this TaxSettings.\n\n\n        :param tax_class_based_on: The tax_class_based_on of this TaxSettings.\n        :type: str\n        \"\"\"\n        allowed_values = [\"shippingAddress\", \"billingAddress\"]  # noqa: E501\n        if tax_class_based_on is not None and tax_class_based_on not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `tax_class_based_on` ({0}), must be one of {1}\"  # noqa: E501\n                .format(tax_class_based_on, allowed_values)\n            )\n\n        self._tax_class_based_on = tax_class_based_on"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef writequery(\n    log,\n    sqlQuery,\n    dbConn,\n    Force=False,\n    manyValueList=False\n):\n    \"\"\"*Execute a MySQL write command given a sql query*\n\n    **Key Arguments:**\n        - ``sqlQuery`` -- the MySQL command to execute\n        - ``dbConn`` -- the db connection\n        - ``Force`` -- do not exit code if error occurs, move onto the next command\n        - ``manyValueList`` -- a list of value tuples if executing more than one insert\n\n    **Return:**\n        - ``message`` -- error/warning message\n\n    **Usage:**\n\n        Here's an example of how to create a table using the database connection passed to the function:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import writequery\n            sqlQuery = \"CREATE TABLE `testing_table` (`id` INT NOT NULL, PRIMARY KEY (`id`))\"\n            message = writequery(\n                log=log,\n                sqlQuery=sqlQuery,\n                dbConn=dbConn,\n                Force=False,\n                manyValueList=False\n            )\n\n        Here's a many value insert example:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import writequery\n            sqlQuery = \"INSERT INTO testing_table (id) values (%s)\"\n            message = writequery(\n                log=log,\n                sqlQuery=sqlQuery,\n                dbConn=dbConn,\n                Force=False,\n                manyValueList=[(1,), (2,), (3,), (4,), (5,), (6,), (7,),\n                               (8,), (9,), (10,), (11,), (12,), ]\n            )\n\n    \"\"\"\n    log.debug('starting the ``writequery`` function')\n    import pymysql\n    import warnings\n    warnings.filterwarnings('error', category=pymysql.Warning)\n    message = \"\"\n    try:\n        cursor = dbConn.cursor(pymysql.cursors.DictCursor)\n    except Exception as e:\n        log.error('could not create the database cursor.')\n    # EXECUTE THE SQL COMMAND\n\n    try:\n        if manyValueList == False:\n            cursor.execute(sqlQuery)\n        else:\n            # cursor.executemany(sqlQuery, manyValueList)\n            # INSET LARGE LISTS IN BATCHES TO STOP MYSQL SERVER BARFING\n            batch = 100000\n            offset = 0\n            stop = 0\n\n            while stop == 0:\n                thisList = manyValueList[offset:offset + batch]\n                offset += batch\n                a = len(thisList)\n                cursor.executemany(sqlQuery, thisList)\n                dbConn.commit()\n                if len(thisList) < batch:\n                    stop = 1\n\n    except pymysql.Error as e:\n        if e[0] == 1050 and 'already exists' in e[1]:\n            log.info(str(e) + '\\n')\n        elif e[0] == 1062:\n                           # Duplicate Key error\n            log.debug('Duplicate Key error: %s\\n' % (str(e), ))\n            message = \"duplicate key error\"\n        elif e[0] == 1061:\n                           # Duplicate Key error\n            log.debug('index already exists: %s\\n' % (str(e), ))\n            message = \"index already exists\"\n        elif \"Duplicate entry\" in str(e):\n            log.debug('Duplicate Key error: %s\\n' % (str(e), ))\n            message = \"duplicate key error\"\n        elif \"Deadlock\" in str(e):\n            i = 0\n            while i < 10:\n                time.sleep(1)\n                i += 1\n                try:\n                    if manyValueList == False:\n                        cursor.execute(sqlQuery)\n                    else:\n                        # cursor.executemany(sqlQuery, manyValueList)\n                        # INSET LARGE LISTS IN BATCHES TO STOP MYSQL SERVER\n                        # BARFING\n                        batch = 100000\n                        offset = 0\n                        stop = 0\n\n                        while stop == 0:\n                            thisList = manyValueList[offset:offset + batch]\n                            offset += batch\n                            a = len(thisList)\n                            cursor.executemany(sqlQuery, thisList)\n                            dbConn.commit()\n                            if len(thisList) < batch:\n                                stop = 1\n                    i = 20\n                except:\n                    pass\n            if i == 10:\n                log.error('Deadlock: %s\\n' % (str(e), ))\n                message = \"Deadlock error\"\n                raise\n\n        else:\n            sqlQueryTrim = sqlQuery[:1000]\n            message = 'MySQL write command not executed for this query: << %s >>\\nThe error was: %s \\n' % (sqlQuery,\n                                                                                                           str(e))\n            if Force == False:\n                log.error(message)\n                raise\n            else:\n                log.info(message)\n                return -1\n    except pymysql.Warning as e:\n        log.info(str(e))\n    except Exception as e:\n        if \"truncated\" in str(e):\n            log.error('%s\\n Here is the sqlquery:\\n%s\\n' % (str(e), sqlQuery))\n            if manyValueList:\n                log.error('... and the values:\\n%s\\n' % (thisList, ))\n        elif \"Duplicate entry\" in str(e):\n            log.warning('Duplicate Key error: %s\\n' % (str(e), ))\n            message = \"duplicate key error\"\n        else:\n            sqlQuery = sqlQuery[:2000]\n            log.error(\n                'MySQL write command not executed for this query: << %s >>\\nThe error was: %s \\n' %\n                (sqlQuery, str(e)))\n            if Force == False:\n                sys.exit(0)\n            return -1\n    dbConn.commit()\n    # CLOSE THE CURSOR\n    cOpen = True\n    count = 0\n    while cOpen:\n        try:\n            cursor.close()\n            cOpen = False\n        except Exception as e:\n            time.sleep(1)\n            count += 1\n            if count == 10:\n                log.warning('could not close the db cursor ' + str(e) + '\\n')\n                raise e\n                count = 0\n\n    log.debug('completed the ``writequery`` function')\n    return message", "response": "Execute a MySQL write command given a sql query and return the result as a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_fixed_rate_shipping(cls, fixed_rate_shipping, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_fixed_rate_shipping_with_http_info(fixed_rate_shipping, **kwargs)\n        else:\n            (data) = cls._create_fixed_rate_shipping_with_http_info(fixed_rate_shipping, **kwargs)\n            return data", "response": "Create a new FixedRateShipping object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete a fixed rate shipping by its ID.", "response": "def delete_fixed_rate_shipping_by_id(cls, fixed_rate_shipping_id, **kwargs):\n        \"\"\"Delete FixedRateShipping\n\n        Delete an instance of FixedRateShipping by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_fixed_rate_shipping_by_id(fixed_rate_shipping_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str fixed_rate_shipping_id: ID of fixedRateShipping to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, **kwargs)\n        else:\n            (data) = cls._delete_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds FixedRateShipping by ID Return single instance of FixedRateShipping", "response": "def get_fixed_rate_shipping_by_id(cls, fixed_rate_shipping_id, **kwargs):\n        \"\"\"Find FixedRateShipping\n\n        Return single instance of FixedRateShipping by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_fixed_rate_shipping_by_id(fixed_rate_shipping_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str fixed_rate_shipping_id: ID of fixedRateShipping to return (required)\n        :return: FixedRateShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, **kwargs)\n        else:\n            (data) = cls._get_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting FixedRateShippings Return a list of FixedRateShippings", "response": "def list_all_fixed_rate_shippings(cls, **kwargs):\n        \"\"\"List FixedRateShippings\n\n        Return a list of FixedRateShippings\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_fixed_rate_shippings(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[FixedRateShipping]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_fixed_rate_shippings_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_fixed_rate_shippings_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces all attributes of FixedRateShipping by ID", "response": "def replace_fixed_rate_shipping_by_id(cls, fixed_rate_shipping_id, fixed_rate_shipping, **kwargs):\n        \"\"\"Replace FixedRateShipping\n\n        Replace all attributes of FixedRateShipping\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_fixed_rate_shipping_by_id(fixed_rate_shipping_id, fixed_rate_shipping, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str fixed_rate_shipping_id: ID of fixedRateShipping to replace (required)\n        :param FixedRateShipping fixed_rate_shipping: Attributes of fixedRateShipping to replace (required)\n        :return: FixedRateShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, fixed_rate_shipping, **kwargs)\n        else:\n            (data) = cls._replace_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, fixed_rate_shipping, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates attributes of FixedRateShipping by ID", "response": "def update_fixed_rate_shipping_by_id(cls, fixed_rate_shipping_id, fixed_rate_shipping, **kwargs):\n        \"\"\"Update FixedRateShipping\n\n        Update attributes of FixedRateShipping\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_fixed_rate_shipping_by_id(fixed_rate_shipping_id, fixed_rate_shipping, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str fixed_rate_shipping_id: ID of fixedRateShipping to update. (required)\n        :param FixedRateShipping fixed_rate_shipping: Attributes of fixedRateShipping to update. (required)\n        :return: FixedRateShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, fixed_rate_shipping, **kwargs)\n        else:\n            (data) = cls._update_fixed_rate_shipping_by_id_with_http_info(fixed_rate_shipping_id, fixed_rate_shipping, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_wish_list(cls, wish_list, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_wish_list_with_http_info(wish_list, **kwargs)\n        else:\n            (data) = cls._create_wish_list_with_http_info(wish_list, **kwargs)\n            return data", "response": "Create a new WishList\n        This method creates a new WishList\n        and returns it."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete a WishList by its ID. This method deletes an instance of WishList by its ID.", "response": "def delete_wish_list_by_id(cls, wish_list_id, **kwargs):\n        \"\"\"Delete WishList\n\n        Delete an instance of WishList by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_wish_list_by_id(wish_list_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str wish_list_id: ID of wishList to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_wish_list_by_id_with_http_info(wish_list_id, **kwargs)\n        else:\n            (data) = cls._delete_wish_list_by_id_with_http_info(wish_list_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_wish_list_by_id(cls, wish_list_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_wish_list_by_id_with_http_info(wish_list_id, **kwargs)\n        else:\n            (data) = cls._get_wish_list_by_id_with_http_info(wish_list_id, **kwargs)\n            return data", "response": "Find WishList by ID Return single instance of WishList with its ID. This method returns a single instance of WishList with the specified ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_wish_lists(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_wish_lists_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_wish_lists_with_http_info(**kwargs)\n            return data", "response": "List WishLists\n        Return a list of WishLists\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_wish_list_by_id(cls, wish_list_id, wish_list, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_wish_list_by_id_with_http_info(wish_list_id, wish_list, **kwargs)\n        else:\n            (data) = cls._replace_wish_list_by_id_with_http_info(wish_list_id, wish_list, **kwargs)\n            return data", "response": "Replace all attributes of WishList with the same attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_wish_list_by_id(cls, wish_list_id, wish_list, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_wish_list_by_id_with_http_info(wish_list_id, wish_list, **kwargs)\n        else:\n            (data) = cls._update_wish_list_by_id_with_http_info(wish_list_id, wish_list, **kwargs)\n            return data", "response": "Update attributes of WishList by ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef recurse_up(directory, filename):\n\n\tdirectory = osp.abspath(directory)\n\n\twhile True:\n\t\tsearchfile = osp.join(directory, filename)\n\n\t\tif osp.isfile(searchfile):\n\t\t\treturn directory\n\n\t\tif directory == '/': break\n\t\telse: directory = osp.dirname(directory)\n\treturn False", "response": "recurse_up - recursively walk a directory up to root until it contains filename"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntranslate etree into dictionary.", "response": "def etree_to_dict(tree):\n    \"\"\"Translate etree into dictionary.\n\n    :param tree: etree dictionary object\n    :type tree: <http://lxml.de/api/lxml.etree-module.html>\n\n    \"\"\"\n    d = {tree.tag.split('}')[1]: map(\n        etree_to_dict, tree.iterchildren()\n    ) or tree.text}\n\n    return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef csv(\n        self,\n        filepath=None\n    ):\n        \"\"\"*Render the data in CSV format*\n\n        **Key Arguments:**\n            - ``filepath`` -- path to the file to write the csv content to. Default *None*\n\n        **Return:**\n            - ``renderedData`` -- the data rendered in csv format\n\n        **Usage:**\n\n            To render the data set as csv:\n\n            .. code-block:: python\n\n                print dataSet.csv()\n\n            .. code-block:: text\n\n                owner,pet,address\n                daisy,dog,\"belfast, uk\"\n                john,snake,the moon\n                susan,crocodile,larne\n\n            and to save the csv rendering to file:\n\n            .. code-block:: python\n\n                dataSet.csv(\"/path/to/myfile.csv\")\n        \"\"\"\n        self.log.debug('starting the ``csv`` method')\n\n        renderedData = self._list_of_dictionaries_to_csv(\"machine\")\n\n        if filepath and renderedData != \"NO MATCH\":\n\n            # RECURSIVELY CREATE MISSING DIRECTORIES\n            if not os.path.exists(os.path.dirname(filepath)):\n                os.makedirs(os.path.dirname(filepath))\n\n            writeFile = codecs.open(filepath, encoding='utf-8', mode='w')\n            writeFile.write(renderedData)\n            writeFile.close()\n\n        self.log.debug('completed the ``csv`` method')\n        return renderedData", "response": "Returns the rendered data in csv format"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the data set as json format", "response": "def json(\n        self,\n        filepath=None\n    ):\n        \"\"\"*Render the data in json format*\n\n        **Key Arguments:**\n            - ``filepath`` -- path to the file to write the json content to. Default *None*\n\n        **Return:**\n            - ``renderedData`` -- the data rendered as json\n\n        **Usage:**\n\n            To render the data set as json:\n\n            .. code-block:: python\n\n                print dataSet.json()\n\n            .. code-block:: json\n\n                [\n                    {\n                        \"address\": \"belfast, uk\",\n                        \"owner\": \"daisy\",\n                        \"pet\": \"dog\"\n                    },\n                    {\n                        \"address\": \"the moon\",\n                        \"owner\": \"john\",\n                        \"pet\": \"snake\"\n                    },\n                    {\n                        \"address\": \"larne\",\n                        \"owner\": \"susan\",\n                        \"pet\": \"crocodile\"\n                    }\n                ]\n\n            and to save the json rendering to file:\n\n            .. code-block:: python\n\n                dataSet.json(\"/path/to/myfile.json\")\n        \"\"\"\n        self.log.debug('starting the ``json`` method')\n\n        dataCopy = copy.deepcopy(self.listOfDictionaries)\n        for d in dataCopy:\n            for k, v in d.iteritems():\n                if isinstance(v,  datetime):\n                    d[k] = v.strftime(\"%Y%m%dt%H%M%S\")\n\n        renderedData = json.dumps(\n            dataCopy,\n            separators=(',', ': '),\n            sort_keys=True,\n            indent=4\n        )\n\n        if filepath and len(self.listOfDictionaries):\n\n            # RECURSIVELY CREATE MISSING DIRECTORIES\n            if not os.path.exists(os.path.dirname(filepath)):\n                os.makedirs(os.path.dirname(filepath))\n\n            writeFile = codecs.open(filepath, encoding='utf-8', mode='w')\n            writeFile.write(renderedData)\n            writeFile.close()\n\n        self.log.debug('completed the ``json`` method')\n        return renderedData"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef yaml(\n        self,\n        filepath=None\n    ):\n        \"\"\"*Render the data in yaml format*\n\n        **Key Arguments:**\n            - ``filepath`` -- path to the file to write the yaml content to. Default *None*\n\n        **Return:**\n            - ``renderedData`` -- the data rendered as yaml\n\n        **Usage:**\n\n            To render the data set as yaml:\n\n            .. code-block:: python\n\n                print dataSet.yaml()\n\n            .. code-block:: yaml\n\n                - address: belfast, uk\n                  owner: daisy\n                  pet: dog\n                - address: the moon\n                  owner: john\n                  pet: snake\n                - address: larne\n                  owner: susan\n                  pet: crocodile\n\n            and to save the yaml rendering to file:\n\n            .. code-block:: python\n\n                dataSet.json(\"/path/to/myfile.yaml\")\n        \"\"\"\n        self.log.debug('starting the ``yaml`` method')\n\n        dataCopy = []\n        dataCopy[:] = [dict(l) for l in self.listOfDictionaries]\n        renderedData = yaml.dump(dataCopy, default_flow_style=False)\n\n        if filepath and len(self.listOfDictionaries):\n\n            # RECURSIVELY CREATE MISSING DIRECTORIES\n            if not os.path.exists(os.path.dirname(filepath)):\n                os.makedirs(os.path.dirname(filepath))\n\n            stream = file(filepath, 'w')\n            yaml.dump(dataCopy, stream, default_flow_style=False)\n            stream.close()\n\n        self.log.debug('completed the ``yaml`` method')\n        return renderedData", "response": "Render the data in yaml format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a python list of dictionaries to a pretty csv file", "response": "def _list_of_dictionaries_to_csv(\n            self,\n            csvType=\"human\"):\n        \"\"\"Convert a python list of dictionaries to pretty csv output\n\n        **Key Arguments:**\n            - ``csvType`` -- human, machine or reST\n\n        **Return:**\n            - ``output`` -- the contents of a CSV file\n        \"\"\"\n        self.log.debug(\n            'starting the ``_list_of_dictionaries_to_csv`` function')\n\n        if not len(self.listOfDictionaries):\n            return \"NO MATCH\"\n\n        dataCopy = copy.deepcopy(self.listOfDictionaries)\n\n        tableColumnNames = dataCopy[0].keys()\n        columnWidths = []\n        columnWidths[:] = [len(tableColumnNames[i])\n                           for i in range(len(tableColumnNames))]\n\n        output = io.BytesIO()\n        # setup csv styles\n        if csvType == \"machine\":\n            delimiter = \",\"\n        elif csvType in [\"human\", \"markdown\"]:\n            delimiter = \"|\"\n        elif csvType in [\"reST\"]:\n            delimiter = \"|\"\n        if csvType in [\"markdown\"]:\n            writer = csv.writer(output, delimiter=delimiter,\n                                quoting=csv.QUOTE_NONE, doublequote=False, quotechar='\"', escapechar=\"\\\\\", lineterminator=\"\\n\")\n        else:\n            writer = csv.writer(output, dialect='excel', delimiter=delimiter,\n                                quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator=\"\\n\")\n\n        if csvType in [\"markdown\"]:\n            dividerWriter = csv.writer(\n                output, delimiter=\"|\", quoting=csv.QUOTE_NONE, doublequote=False, quotechar='\"', escapechar=\"\\\\\", lineterminator=\"\\n\")\n        else:\n            dividerWriter = csv.writer(output, dialect='excel', delimiter=\"+\",\n                                       quotechar='\"', quoting=csv.QUOTE_MINIMAL, lineterminator=\"\\n\")\n        # add column names to csv\n        header = []\n        divider = []\n        rstDivider = []\n        allRows = []\n\n        # clean up data\n        for row in dataCopy:\n            for c in tableColumnNames:\n                if isinstance(row[c], float) or isinstance(row[c], Decimal):\n                    row[c] = \"%0.9g\" % row[c]\n                elif isinstance(row[c], datetime):\n                    thisDate = str(row[c])[:10]\n                    row[c] = \"%(thisDate)s\" % locals()\n\n        # set the column widths\n        for row in dataCopy:\n            for i, c in enumerate(tableColumnNames):\n                if len(unicode(row[c])) > columnWidths[i]:\n                    columnWidths[i] = len(unicode(row[c]))\n\n        # table borders for human readable\n        if csvType in [\"human\", \"markdown\", \"reST\"]:\n            header.append(\"\")\n            divider.append(\"\")\n            rstDivider.append(\"\")\n\n        for i, c in enumerate(tableColumnNames):\n            if csvType == \"machine\":\n                header.append(c)\n            elif csvType in [\"human\", \"markdown\", \"reST\"]:\n                header.append(\n                    c.ljust(columnWidths[i] + 2).rjust(columnWidths[i] + 3))\n                divider.append('-' * (columnWidths[i] + 3))\n                rstDivider.append('=' * (columnWidths[i] + 3))\n\n        # table border for human readable\n        if csvType in [\"human\", \"markdown\", \"reST\"]:\n            header.append(\"\")\n            divider.append(\"\")\n            rstDivider.append(\"\")\n\n        # fill in the data\n        for row in dataCopy:\n            thisRow = []\n            # table border for human readable\n            if csvType in [\"human\", \"markdown\", \"reST\"]:\n                thisRow.append(\"\")\n\n            for i, c in enumerate(tableColumnNames):\n                if csvType in [\"human\", \"markdown\", \"reST\"]:\n                    if row[c] == None:\n                        row[c] = \"\"\n                    row[c] = unicode(unicode(row[c]).ljust(columnWidths[i] + 2)\n                                     .rjust(columnWidths[i] + 3))\n                thisRow.append(row[c])\n            # table border for human readable\n            if csvType in [\"human\", \"markdown\", \"reST\"]:\n                thisRow.append(\"\")\n            allRows.append(thisRow)\n            if csvType in [\"reST\"]:\n                allRows.append(divider)\n\n        if csvType == \"machine\":\n            writer.writerow(header)\n        if csvType in [\"reST\"]:\n            dividerWriter.writerow(divider)\n            writer.writerow(header)\n            dividerWriter.writerow(rstDivider)\n        if csvType in [\"human\"]:\n            dividerWriter.writerow(divider)\n            writer.writerow(header)\n            dividerWriter.writerow(divider)\n        elif csvType in [\"markdown\"]:\n            writer.writerow(header)\n            dividerWriter.writerow(divider)\n\n        # write out the data\n        writer.writerows(allRows)\n        # table border for human readable\n        if csvType in [\"human\"]:\n            dividerWriter.writerow(divider)\n\n        output = output.getvalue()\n        output = output.strip()\n\n        if csvType in [\"markdown\"]:\n            output = output.replace(\"|--\", \"|:-\")\n        if csvType in [\"reST\"]:\n            output = output.replace(\"|--\", \"+--\").replace(\"--|\", \"--+\")\n\n        self.log.debug(\n            'completed the ``_list_of_dictionaries_to_csv`` function')\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _list_of_dictionaries_to_mysql_inserts(\n            self,\n            tableName,\n            createStatement=None):\n        \"\"\"Convert a python list of dictionaries to pretty csv output\n\n        **Key Arguments:**\n            - ``tableName`` -- the name of the table to create the insert statements for\n            - ``createStatement`` -- add this create statement to the top of the file. Will only be executed if no table of that name exists in database. Default *None*\n\n        **Return:**\n            - ``output`` -- the mysql insert statements (as a string)\n        \"\"\"\n        self.log.debug(\n            'completed the ````_list_of_dictionaries_to_mysql_inserts`` function')\n\n        if not len(self.listOfDictionaries):\n            return \"NO MATCH\"\n\n        dataCopy = copy.deepcopy(self.listOfDictionaries)\n\n        if createStatement:\n            output = createStatement + \"\\n\"\n        else:\n            output = \"\"\n\n        inserts = []\n\n        inserts = []\n        inserts[:] = [convert_dictionary_to_mysql_table(log=self.log, dictionary=d, dbTableName=tableName, uniqueKeyList=[\n        ], dateModified=False, returnInsertOnly=True, replace=True, batchInserts=False, reDatetime=self.reDatetime) for d in dataCopy]\n        output += \";\\n\".join(inserts) + \";\"\n\n        self.log.debug(\n            'completed the ``_list_of_dictionaries_to_mysql_inserts`` function')\n        return output", "response": "Convert a python list of dictionaries to a list of mysql insert statements"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new PaymentToken with the given paymentToken", "response": "def create_payment_token(cls, payment_token, **kwargs):\n        \"\"\"Create PaymentToken\n\n        Create a new PaymentToken\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_payment_token(payment_token, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param PaymentToken payment_token: Attributes of paymentToken to create (required)\n        :return: PaymentToken\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_payment_token_with_http_info(payment_token, **kwargs)\n        else:\n            (data) = cls._create_payment_token_with_http_info(payment_token, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_payment_token_by_id(cls, payment_token_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_payment_token_by_id_with_http_info(payment_token_id, **kwargs)\n        else:\n            (data) = cls._delete_payment_token_by_id_with_http_info(payment_token_id, **kwargs)\n            return data", "response": "Delete an instance of PaymentToken by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_payment_token_by_id(cls, payment_token_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_payment_token_by_id_with_http_info(payment_token_id, **kwargs)\n        else:\n            (data) = cls._get_payment_token_by_id_with_http_info(payment_token_id, **kwargs)\n            return data", "response": "Find PaymentToken by ID Return single instance of PaymentToken by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist PaymentTokens Return a list of PaymentTokens", "response": "def list_all_payment_tokens(cls, **kwargs):\n        \"\"\"List PaymentTokens\n\n        Return a list of PaymentTokens\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_payment_tokens(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[PaymentToken]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_payment_tokens_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_payment_tokens_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreplaces PaymentToken by ID", "response": "def replace_payment_token_by_id(cls, payment_token_id, payment_token, **kwargs):\n        \"\"\"Replace PaymentToken\n\n        Replace all attributes of PaymentToken\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_payment_token_by_id(payment_token_id, payment_token, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str payment_token_id: ID of paymentToken to replace (required)\n        :param PaymentToken payment_token: Attributes of paymentToken to replace (required)\n        :return: PaymentToken\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_payment_token_by_id_with_http_info(payment_token_id, payment_token, **kwargs)\n        else:\n            (data) = cls._replace_payment_token_by_id_with_http_info(payment_token_id, payment_token, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_payment_token_by_id(cls, payment_token_id, payment_token, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_payment_token_by_id_with_http_info(payment_token_id, payment_token, **kwargs)\n        else:\n            (data) = cls._update_payment_token_by_id_with_http_info(payment_token_id, payment_token, **kwargs)\n            return data", "response": "Update attributes of PaymentToken by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split_in_columns(filterform, fields_per_column=None):\n    '''\n    Return iterator that yields a column (iterator too).\n\n    By default, flat field list is divided in columns with\n    fields_per_column elements in each (fields_per_column is a\n    class attribute).\n    '''\n    nfields = len(filterform.fields)\n    if fields_per_column is None:\n        fields_per_column = filterform.fields_per_column\n\n    ncolumns, tail = divmod(nfields, fields_per_column)\n    if tail > 0:\n        ncolumns += 1\n\n    itr = iter(filterform)\n\n    for _i in range(ncolumns):\n        yield itertools.islice(itr, fields_per_column)", "response": "Return iterator that yields a column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndispatching the given event.", "response": "def dispatch_event(self, event: \"Event\") -> None:\r\n        \"\"\"\r\n        Dispatches the given event.\r\n\r\n        It is the duty of this method to set the target of the dispatched event by calling\r\n        `event.set_target(self)`.\r\n\r\n        Args:\r\n            event (Event): The event to dispatch. Must not be `None`.\r\n\r\n        Raises:\r\n            TypeError: If the event is `None` or its type is incorrect.\r\n        \"\"\"\r\n        # Set the target of the event if it doesn't have one already. It could happen that\r\n        # we are simply redispatching an event.\r\n        if event.target is None:\r\n            event.set_target(self)\r\n\r\n        listeners: dict[types.MethodType, bool] = self._registered_listeners.get(event.type)\r\n        if listeners is None:\r\n            return\r\n\r\n        for listener in listeners:\r\n            listener(event)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the given event listener from the dispatcher for the given event type and event handler.", "response": "def remove_event_listener(self, event_type: str, event_handler: types.MethodType) -> None:\r\n        \"\"\"\r\n        Removes the given event listener registered on the dispatcher for the given event type.\r\n\r\n        Args:\r\n            event_type (str): The type of the event to remove the event handler from.\r\n                              Must not be `None` or empty string.\r\n            event_handler (types.MethodType): The event handler to remove from the given event\r\n                                              type of the dispatcher. Must not be `None`.\r\n\r\n        Raises:\r\n            ValueError: If any of the parameters are invalid.\r\n        \"\"\"\r\n        # TODO: we should also accept types.FunctionType,\r\n        # don't forget the documentation here and in the interface.\r\n        if not isinstance(event_type, str) or event_type == \"\" or\\\r\n           not isinstance(event_handler, types.MethodType):\r\n            raise ValueError(\"Invalid arguments: {}, {}\".format(event_type, event_handler))\r\n\r\n        listeners: dict[types.MethodType, bool] = self._registered_listeners.get(event_type)\r\n        listener: types.MethodType = None if listeners is None else listeners.get(event_handler)\r\n        if listener is not None:\r\n            del listeners[event_handler]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the target property of the event.", "response": "def set_target(self, target: EventDispatcherBase) -> None:\r\n        \"\"\"\r\n        This method should be called by the event dispatcher that dispatches this event\r\n        to set its target property.\r\n\r\n        Args:\r\n            target (EventDispatcherBase): The event dispatcher that will dispatch this event.\r\n\r\n        Raises:\r\n            PermissionError: If the target property of the event has already been set.\r\n            TypeError: If `target` is not an `EventDispatcherBase` instance.\r\n        \"\"\"\r\n        if self._target is not None:\r\n            raise PermissionError(\"The target property already has a valid value.\")\r\n\r\n        if not isinstance(target, EventDispatcherBase):\r\n            raise TypeError(\"Invalid target type: {}\".format(target))\r\n\r\n        self._target = target"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_url(url, content_type=None, download_to_file=None,\n                 retry_count=10, timeout=10.0):\n    \"\"\"\n    Will download a file from given URL (either local or external) to the\n    desired path (or generate one if none is given). Local files are copied\n    directly.\n\n    The function will retry a number of times based on retry_count (default 10)\n    parameter and sleeps a number of seconds based on given timeout\n    (default 10.0 sec) after each failed request.\n\n    Returns the path to the downloaded file if successful.\n    Otherwise an exception is raised.\n\n    Given a content_type and an external URL, the function will make sure\n    that the desired content_type is equal to the content-type of returned\n    file.\n\n    @param url: where the file lives on the interwebs\n    @type url: string\n\n    @param content_type: desired content_type to check for in external URLs.\n                         (optional)\n    @type content_type: string\n\n    @param download_to_file: where the file should live after download.\n                             (optional)\n    @type download_to_file: string\n\n    @param retry_count: number of times to retry. Defaults to 10.\n                        (optional)\n    @type retry_count: int\n\n    @param timeout: number of seconds to sleep between attempts.\n                    Defaults to 10.0 seconds. (optional)\n    @type timeout: float\n\n    @return: the path of the downloaded/copied file\n    @raise InvenioFileDownloadError: raised upon URL/HTTP errors, file errors or wrong format\n    \"\"\"\n    if not download_to_file:\n        download_to_file = safe_mkstemp(suffix=\".tmp\",\n                                        prefix=\"filedownloadutils_\")\n\n    try:\n        if is_url_a_local_file(url):\n            downloaded_file = download_local_file(url,\n                                                  download_to_file)\n        else:\n            downloaded_file = download_external_url(url,\n                                                    download_to_file,\n                                                    content_type=content_type,\n                                                    retry_count=retry_count,\n                                                    timeout=timeout)\n    except InvenioFileDownloadError:\n        raise\n\n    return downloaded_file", "response": "Download a file from a given URL to the specified path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndownloads an external file from the url and return the path to the downloaded file.", "response": "def download_external_url(url, download_to_file, content_type=None,\n                          retry_count=10, timeout=10.0, verbose=False):\n    \"\"\"\n    Download a url (if it corresponds to a remote file) and return a\n    local url to it. If format is specified, a check will be performed\n    in order to make sure that the format of the downloaded file is equal\n    to the expected format.\n\n    @param url: the URL to download\n    @type url: string\n\n    @param download_to_file: the path to download the file to\n    @type download_to_file: string\n\n    @param content_type: the content_type of the file (optional)\n    @type content_type: string\n\n    @param retry_count: max number of retries for downloading the file\n    @type retry_count: int\n\n    @param timeout: time to sleep in between attemps\n    @type timeout: int\n\n    @return: the path to the download local file\n    @rtype: string\n    @raise StandardError: if the download failed\n    \"\"\"\n    error_str = \"\"\n    error_code = None\n    retry_attempt = 0\n\n    while retry_attempt < retry_count:\n        try:\n            # Attempt to download the external file\n            request = open_url(url)\n            if request.code == 200 and \"Refresh\" in request.headers:\n                # PDF is being generated, they ask us to wait for\n                # n seconds.\n                # New arxiv responses, we are not sure if the old ones are\n                # deactivated\n                try:\n                    retry_after = int(request.headers[\"Refresh\"])\n                    # We make sure that we do not retry too often even if\n                    # they tell us to retry after 1s\n                    retry_after = max(retry_after, timeout)\n                except ValueError:\n                    retry_after = timeout\n                if verbose:\n                    msg = \"retrying after %ss\" % (retry_after,)\n                    print >> sys.stderr, msg\n                time.sleep(retry_after)\n                retry_attempt += 1\n                continue\n        except urllib2.HTTPError as e:\n            error_code = e.code\n            error_str = str(e)\n            retry_after = timeout\n            # This handling is the same as OAI queries.\n            # We are getting 503 errors when PDFs are being generated\n            if e.code == 503 and \"Retry-After\" in e.headers:\n                # PDF is being generated, they ask us to wait for n seconds\n                try:\n                    retry_after = int(e.headers[\"Retry-After\"])\n                    # We make sure that we do not retry too often even if\n                    # they tell us to retry after 1s\n                    retry_after = max(retry_after, timeout)\n                except ValueError:\n                    pass\n            if verbose:\n                msg = \"retrying after %ss\" % (retry_after,)\n                print >> sys.stderr, msg\n            time.sleep(retry_after)\n            retry_attempt += 1\n        except (urllib2.URLError,\n                socket.timeout,\n                socket.gaierror,\n                socket.error) as e:\n            if verbose:\n                error_str = str(e)\n                msg = \"socket error, retrying after %ss\" % (timeout,)\n                print >> sys.stderr, msg\n            time.sleep(timeout)\n            retry_attempt += 1\n        else:\n            # When we get here, it means that the download was a success.\n            try:\n                finalize_download(url, download_to_file, content_type, request)\n            finally:\n                request.close()\n            return download_to_file\n\n    # All the attempts were used, but no successfull download - so raise error\n    msg = 'URL could not be opened: %s' % (error_str,)\n    raise InvenioFileDownloadError(msg, code=error_code)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinalizing the download operation by doing various checks and saving the file to the file system.", "response": "def finalize_download(url, download_to_file, content_type, request):\n    \"\"\"\n    Finalizes the download operation by doing various checks, such as format\n    type, size check etc.\n    \"\"\"\n    # If format is given, a format check is performed.\n    if content_type and content_type not in request.headers['content-type']:\n        msg = 'The downloaded file is not of the desired format'\n        raise InvenioFileDownloadError(msg)\n\n    # Save the downloaded file to desired or generated location.\n    to_file = open(download_to_file, 'w')\n    try:\n        try:\n            while True:\n                block = request.read(CFG_FILEUTILS_BLOCK_SIZE)\n                if not block:\n                    break\n                to_file.write(block)\n        except Exception as e:\n            msg = \"Error when downloading %s into %s: %s\" % \\\n                  (url, download_to_file, e)\n            raise InvenioFileDownloadError(msg)\n    finally:\n        to_file.close()\n\n    # Check Size\n    filesize = os.path.getsize(download_to_file)\n    if filesize == 0:\n        raise InvenioFileDownloadError(\"%s seems to be empty\" % (url,))\n\n    # download successful, return the new path\n    return download_to_file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading a local file to Invenio s temporary directory.", "response": "def download_local_file(filename, download_to_file):\n    \"\"\"\n    Copies a local file to Invenio's temporary directory.\n\n    @param filename: the name of the file to copy\n    @type filename: string\n\n    @param download_to_file: the path to save the file to\n    @type download_to_file: string\n\n    @return: the path of the temporary file created\n    @rtype: string\n    @raise StandardError: if something went wrong\n    \"\"\"\n    # Try to copy.\n    try:\n        path = urllib2.urlparse.urlsplit(urllib.unquote(filename))[2]\n        if os.path.abspath(path) != path:\n            msg = \"%s is not a normalized path (would be %s).\" \\\n                  % (path, os.path.normpath(path))\n            raise InvenioFileCopyError(msg)\n\n        allowed_path_list = current_app.config.get(\n            'CFG_BIBUPLOAD_FFT_ALLOWED_LOCAL_PATHS', []\n        )\n        allowed_path_list.append(current_app.config['CFG_TMPSHAREDDIR'])\n        for allowed_path in allowed_path_list:\n            if path.startswith(allowed_path):\n                shutil.copy(path, download_to_file)\n                if os.path.getsize(download_to_file) == 0:\n                    os.remove(download_to_file)\n                    msg = \"%s seems to be empty\" % (filename,)\n                    raise InvenioFileCopyError(msg)\n                break\n        else:\n            msg = \"%s is not in one of the allowed paths.\" % (path,)\n            raise InvenioFileCopyError()\n    except Exception as e:\n        msg = \"Impossible to copy the local file '%s' to %s: %s\" % \\\n              (filename, download_to_file, str(e))\n        raise InvenioFileCopyError(msg)\n\n    return download_to_file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef safe_mkstemp(suffix, prefix='filedownloadutils_'):\n    tmpfd, tmppath = tempfile.mkstemp(\n        suffix=suffix,\n        prefix=prefix,\n        dir=current_app.config['CFG_TMPSHAREDDIR']\n    )\n    # Close the file and leave the responsability to the client code to\n    # correctly open/close it.\n    os.close(tmpfd)\n\n    if '.' not in suffix:\n        # Just in case format is empty\n        return tmppath\n    while '.' in os.path.basename(tmppath)[:-len(suffix)]:\n        os.remove(tmppath)\n        tmpfd, tmppath = tempfile.mkstemp(\n            suffix=suffix,\n            prefix=prefix,\n            dir=current_app.config['CFG_TMPSHAREDDIR']\n        )\n        os.close(tmpfd)\n    return tmppath", "response": "Create a temporary filename that don t have any '.' inside a part\n    from the suffix."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open_url(url, headers=None):\n    request = urllib2.Request(url)\n    if headers:\n        for key, value in headers.items():\n            request.add_header(key, value)\n    return URL_OPENER.open(request)", "response": "Opens a URL and returns a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef db(self, db_alias, shard_key=None):\n        if shard_key is None:\n            shard_key = ''\n\n        db_key = db_alias + '__' + str(shard_key)\n        if db_key not in self.__db_list:\n            self.__db_list[db_key] = DbQueryService(self, self.__default_headers, {\"db_alias\": db_alias, \"dbAlias\": db_alias, \"shard_find_key\": shard_key, \"shardKey\": shard_key})\n        return self.__db_list[db_key]", "response": "returns a specific database entry"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads the developer settings.", "response": "def __read_developer_settings(self):\n        \"\"\"\n        \u0427\u0438\u0442\u0430\u0435\u0442 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430 \u0441 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0439 \u043c\u0430\u0448\u0438\u043d\u044b \u0438\u043b\u0438 \u0438\u0437 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f\n        \u041f\u0440\u0438 \u044d\u0442\u043e\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043e\u0440\u0438\u0442\u0435\u0442\u043d\u0435\u0435\n        :return:\n        \"\"\"\n        self.developer_settings = read_developer_settings()\n        if not self.developer_settings:\n            self.log.warning(\"\u041d\u0415 \u0423\u0421\u0422\u0410\u041d\u041e\u0412\u041b\u0415\u041d\u042b \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430, \u044d\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u0438\u0432\u043e\u0434\u0438\u0442\u044c \u043a \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0430\u043c \u0432 \u0434\u0430\u043b\u044c\u043d\u0435\u0439\u0448\u0435\u0439 \u0440\u0430\u0431\u043e\u0442\u0435!\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef api_call(self, service, method, data, options):\n        if 'self' in data:\n            # \u043c\u043e\u0436\u0435\u0442 \u043d\u0435 \u0431\u044b\u0442\u044c, \u0435\u0441\u043b\u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u0438\u0437 \u043a\u043e\u0434\u0430,\n            # \u0430 \u043d\u0435 \u0438\u0437 \u043f\u0440\u043e\u0441\u043b\u043e\u0435\u043a \u0442\u0438\u043f\u0430 DbQueryService\n            data.pop(\"self\")\n\n        if options:\n            data.update(options)\n\n        _headers = dict(self.__default_headers)\n\n        if self.auth_user_id:\n            _headers['X-META-AuthUserID'] = str(self.auth_user_id)\n\n        request = {\n            \"url\": self.meta_url + \"/api/v1/adptools/\" + service + \"/\" + method,\n            \"data\": json.dumps(data),\n            \"headers\": _headers,\n            \"timeout\": (60, 1800)\n        }\n\n        for _try_idx in range(20):\n            try:\n                resp = requests.post(**request)\n                if resp.status_code == 200:\n                    decoded_resp = json.loads(resp.text)\n                    if 'data' in decoded_resp:\n                        return decoded_resp['data'][method]\n                    if 'error' in decoded_resp:\n                        if 'details' in decoded_resp['error']:\n                            eprint(decoded_resp['error']['details'])\n                        raise DbQueryError(decoded_resp['error'])\n                    raise UnexpectedError()\n                else:\n                    process_meta_api_error_code(resp.status_code, request, resp.text)\n            except (requests.exceptions.ConnectionError, ConnectionError, TimeoutError) as e:\n                self.log.warning('META API Connection Error. Sleep...', {\"e\": e})\n                time.sleep(15)\n            except Exception as e:\n                if '\u0421\u043b\u0443\u0436\u0431\u0430 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e \u0438\u043b\u0438 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u0430' in str(e):\n                    self.log.warning('META API Connection Error. Sleep...', {\"e\": e})\n                    time.sleep(15)\n                else:\n                    raise e\n\n        raise ServerError(request)", "response": "This method is used to call the API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef native_api_call(self, service, method, data, options, multipart_form=False, multipart_form_data=None, stream=False, http_path=\"/api/meta/v1/\", http_method='POST',\n                        get_params=None, connect_timeout_sec=60):\n        \"\"\"\n        :type app: metasdk.MetaApp\n        :rtype: requests.Response\n        \"\"\"\n        if get_params is None:\n            get_params = {}\n        if 'self' in data:\n            # \u043c\u043e\u0436\u0435\u0442 \u043d\u0435 \u0431\u044b\u0442\u044c, \u0435\u0441\u043b\u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u0435\u0442\u0441\u044f \u043d\u0430\u043f\u0440\u044f\u043c\u0443\u044e \u0438\u0437 \u043a\u043e\u0434\u0430,\n            # \u0430 \u043d\u0435 \u0438\u0437 \u043f\u0440\u043e\u0441\u043b\u043e\u0435\u043a \u0442\u0438\u043f\u0430 DbQueryService\n            data.pop(\"self\")\n\n        if options:\n            data.update(options)\n\n        _headers = dict(self.__default_headers)\n\n        if self.auth_user_id:\n            _headers['X-META-AuthUserID'] = str(self.auth_user_id)\n\n        request = {\n            \"url\": self.meta_url + http_path + service + \"/\" + method,\n            \"timeout\": (connect_timeout_sec, 1800),\n            \"stream\": stream,\n            \"params\": get_params,\n        }\n\n        if multipart_form:\n            if multipart_form_data:\n                request['files'] = multipart_form_data\n            request['data'] = data\n            _headers.pop('content-type', None)\n        else:\n            request['data'] = json.dumps(data)\n        request['headers'] = _headers\n\n        for _try_idx in range(20):\n            try:\n                resp = requests.request(http_method, **request)\n                if resp.status_code == 200:\n                    return resp\n                else:\n                    process_meta_api_error_code(resp.status_code, request, resp.text)\n            except (requests.exceptions.ConnectionError, ConnectionError, TimeoutError) as e:\n                self.log.warning('META API Connection Error. Sleep...', {\"e\": e})\n                time.sleep(15)\n            except Exception as e:\n                if '\u0421\u043b\u0443\u0436\u0431\u0430 \u0447\u0430\u0441\u0442\u0438\u0447\u043d\u043e \u0438\u043b\u0438 \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043d\u0435\u0434\u043e\u0441\u0442\u0443\u043f\u043d\u0430' in str(e):\n                    self.log.warning('META API Service Temporarily Unavailable. Sleep...', {\"e\": e})\n                    time.sleep(15)\n                else:\n                    raise e\n\n        raise ServerError(request)", "response": ":type app: metasdk.MetaApp\n        :rtype: requests.Response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget URL and parse JSON from text.", "response": "async def get_json(self, url, timeout=30, astext=False, exceptions=False):\n        \"\"\"Get URL and parse JSON from text.\"\"\"\n        try:\n            with async_timeout.timeout(timeout):\n                res = await self._aio_session.get(url)\n                if res.status != 200:\n                    _LOGGER.error(\"QSUSB returned %s [%s]\", res.status, url)\n                    return None\n                res_text = await res.text()\n        except (aiohttp.client_exceptions.ClientError,\n                asyncio.TimeoutError) as exc:\n            if exceptions:\n                raise exc\n            return None\n\n        if astext:\n            return res_text\n\n        try:\n            return json.loads(res_text)\n        except json.decoder.JSONDecodeError:\n            if res_text.strip(\" \") == \"\":\n                return None\n            _LOGGER.error(\"Could not decode %s [%s]\", res_text, url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the QS Mobile version.", "response": "def version(self):\n        \"\"\"Get the QS Mobile version.\"\"\"\n        return self.get_json(URL_VERSION.format(self._url), astext=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts the &listen long poll and return immediately.", "response": "def listen(self, callback=None):\n        \"\"\"Start the &listen long poll and return immediately.\"\"\"\n        self._running = True\n        self.loop.create_task(self._async_listen(callback))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _async_listen(self, callback=None):\n        while True:\n            if not self._running:\n                return\n\n            try:\n                packet = await self.get_json(\n                    URL_LISTEN.format(self._url), timeout=30, exceptions=True)\n            except asyncio.TimeoutError:\n                continue\n            except aiohttp.client_exceptions.ClientError as exc:\n                _LOGGER.warning(\"ClientError: %s\", exc)\n                self._sleep_task = self.loop.create_task(asyncio.sleep(30))\n                try:\n                    await self._sleep_task\n                except asyncio.CancelledError:\n                    pass\n                self._sleep_task = None\n                continue\n\n            if isinstance(packet, dict) and QS_CMD in packet:\n                _LOGGER.debug(\"callback( %s )\", packet)\n                try:\n                    callback(packet)\n                except Exception as err:  # pylint: disable=broad-except\n                    _LOGGER.error(\"Exception in callback\\nType: %s: %s\",\n                                  type(err), err)\n            else:\n                _LOGGER.debug(\"unknown packet? %s\", packet)", "response": "A loop that waits for a QS_CMD packet and calls the callback function."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_qs_value(self, qsid, val, success_cb):\n        self.loop.create_task(self.async_set_qs_value(qsid, val, success_cb))", "response": "Push state to QSUSB"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def async_set_qs_value(self, qsid, val, success_cb=None):\n        set_url = URL_SET.format(self._url, qsid, val)\n        for _repeat in range(1, 6):\n            set_result = await self.get_json(set_url, 2)\n            if set_result and set_result.get('data', 'NO REPLY') != 'NO REPLY':\n                if success_cb:\n                    success_cb()\n                return True\n            await asyncio.sleep(0.01 * _repeat)\n        _LOGGER.error(\"Unable to set %s\", set_url)\n        return False", "response": "Push state to QSUSB retry with backoff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving a list of &devices and values.", "response": "async def update_from_devices(self):\n        \"\"\"Retrieve a list of &devices and values.\"\"\"\n        res = await self.get_json(URL_DEVICES.format(self._url))\n        if res:\n            self.devices.update_devices(res)\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef multi_ops(data_stream, *funcs):\n\n    assert all(callable(func) for func in funcs), 'multi_ops can only apply functions to the first argument'\n    assert len(funcs), 'multi_ops needs at least one function to apply to data_stream'\n\n    for i in data_stream:\n        if len(funcs) > 1:\n            yield tuple(func(i) for func in funcs)\n        elif len(funcs) == 1:\n            yield funcs[0](i)", "response": "fork a generator with multiple operations and functions\n\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef attowiki_distro_path():\n    attowiki_path = os.path.abspath(__file__)\n    if attowiki_path[-1] != '/':\n        attowiki_path = attowiki_path[:attowiki_path.rfind('/')]\n    else:\n        attowiki_path = attowiki_path[:attowiki_path[:-1].rfind('/')]\n    return attowiki_path", "response": "return the absolute complete path where attowiki is located\n   .. todo use pkg_resources?\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_command(self):\n        return cron_utils.cronify(\"crontab -l | {{ cat; echo \\\"{} {} {} {} {} CJOBID='{}' MAILTO='' {}\\\"; }} | crontab - > /dev/null\".format(self._minute, self._hour, self._day_of_month, self._month_of_year, self._day_of_week, self._jobid, self._command))", "response": "Build out the crontab command"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading a. env file into os. environ.", "response": "def read_environment_file(envfile=None):\n    \"\"\"\n    Read a .env file into os.environ.\n\n    If not given a path to a envfile path, does filthy magic stack backtracking\n    to find manage.py and then find the envfile.\n    \"\"\"\n    if envfile is None:\n        frame = sys._getframe()\n        envfile = os.path.join(os.path.dirname(frame.f_back.f_code.co_filename), '.env')\n        if not os.path.exists(envfile):\n            warnings.warn(\"not reading %s - it doesn't exist.\" % envfile)\n            return\n    for k, v in parse_environment_file(envfile):\n        os.environ.setdefault(k, v)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn extension identifying format of given filename", "response": "def infer_format(filename:str) -> str:\n    \"\"\"Return extension identifying format of given filename\"\"\"\n    _, ext = os.path.splitext(filename)\n    return ext"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reversed_graph(graph:dict) -> dict:\n    ret = defaultdict(set)\n    for node, succs in graph.items():\n        for succ in succs:\n            ret[succ].add(node)\n    return dict(ret)", "response": "Return given graph reversed"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walk(start:list, graphs:iter) -> iter:\n    walked = set([start])\n    stack = [start]\n    while len(stack) > 0:\n        *stack, curr = stack\n        yield curr\n        succs = it.chain.from_iterable(graph.get(curr, ()) for graph in graphs)\n        for succ in succs:\n            if succ not in walked:\n                walked.add(curr)\n                stack.append(succ)", "response": "walk on given graphs beginning on start."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef have_cycle(graph:dict) -> frozenset:\n    # topological sort\n    walked = set()  # walked nodes\n    nodes = frozenset(it.chain(it.chain.from_iterable(graph.values()), graph.keys()))  # all nodes of the graph\n    preds = reversed_graph(graph)  # succ: preds\n    last_walked_len = -1\n    while last_walked_len != len(walked):\n        last_walked_len = len(walked)\n        for node in nodes - walked:\n            if len(preds.get(node, set()) - walked) == 0:\n                walked.add(node)\n    return frozenset(nodes - walked)", "response": "Perform a topologic sort to detect any cycle in given graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield lines found in given file", "response": "def file_lines(bblfile:str) -> iter:\n    \"\"\"Yield lines found in given file\"\"\"\n    with open(bblfile) as fd:\n        yield from (line.rstrip() for line in fd if line.rstrip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef line_type(line:str) -> str:\n    for regex, ltype in LINE_TYPES.items():\n        if re.fullmatch(regex, line):\n            return ltype\n    raise ValueError(\"Input line \\\"{}\\\" is not bubble formatted\".format(line))", "response": "Give type of input line as defined in LINE_TYPES\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef line_data(line:str) -> tuple:\n    for regex, _ in LINE_TYPES.items():\n        match = re.fullmatch(regex, line)\n        if match:\n            return match.groups()\n    raise ValueError(\"Input line \\\"{}\\\" is not bubble formatted\".format(line))", "response": "Return a tuple of all the groups found in given line"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _catchCurrentViewContent(self):\n        viewContent = None\n        if self._buffer_color_mode != self._display_color_mode:\n            viewContent = self._buffer.crop( self.View.rectToArray() ) .convert( self._display_color_mode )\n        else:\n            viewContent = self._buffer.crop( self.View.rectToArray() )\n\n        # Rotate for display direction\n        if self._display_direction == 0:\n            return viewContent\n        else:\n            return viewContent.rotate( angle = self._display_direction, expand=True )", "response": "Catch the current view content and return the image that is the captured content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _initBuffer(self, bufferColorMode, bufferSize):\n        # super(SSScreenBase)._initBuffer(bufferColorMode, bufferSize)\n        self._buffer_color_mode = bufferColorMode\n\n        #create screen image buffer and canvas\n        if bufferSize==None:\n            self._buffer = Image.new( bufferColorMode , self._display_size )\n        else:\n            self._buffer = Image.new( bufferColorMode , bufferSize )        \n        self.Canvas = ImageDraw.Draw( self._buffer )\n\n        #creare screen view\n        self.View = SSRect( 0, 0, self._display_size[0], self._display_size[1] )", "response": "Initialize the buffer object instance"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clearCanvas(self, fillColor = 0 ):\n        self.Canvas.rectangle((0, 0, self._display_size[0], self._display_size[1]), outline=0, fill=fillColor)", "response": "Clear the canvas at the same time."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear the view with the specified color.", "response": "def clearView(self, fillColor = 0 ):\n        \"\"\"!\n        \\~english\n        Clear up canvas with view size\n        @param fillColor: a color value\n        @note \n            The fillColor value range depends on the setting of _buffer_color_mode.\n            * If it is SS_COLOR_MODE_MONO (\"1\") monochrome mode, it can only select 0: black and 1: white\n            * If it is SS_COLOR_MODE_RGB (\"RGB\") color mode, RGB color values can be used\n\n        \\~chinese\n        \u6e05\u9664\u753b\u5e03\u4e2d\u5f53\u524d\u89c6\u56fe\u5927\u5c0f\u7684\u533a\u57df\u540c\u65f6\u586b\u5145\u989c\u8272\n        @param fillColor: \u989c\u8272\u503c\n        @note \n            fillColor \u53d6\u503c\u8303\u56f4\u53d6\u51b3\u4e8e _buffer_color_mode \u7684\u8bbe\u5b9a\u3002\n            * \u5982\u679c\u662f SS_COLOR_MODE_MONO (\"1\") \u5355\u8272\u6a21\u5f0f\uff0c\u53ea\u80fd\u9009\u62e9 0:\u9ed1\u8272 \u548c 1:\u767d\u8272 \n            * \u5982\u679c\u662f SS_COLOR_MODE_RGB (\"RGB\") \u5f69\u8272\u6a21\u5f0f\uff0c\u53ef\u4ee5\u4f7f\u7528 RGB \u8272\u5f69\u503c\n        \"\"\"\n        self.Canvas.rectangle(self.View.rectToArray(), outline=0, fill=fillColor)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef redefineBuffer(self, newBuffer ):\n        # Redefine Frame from an image object\n        if type(self._buffer) == type(newBuffer):\n            self._buffer = newBuffer\n            self.Canvas = ImageDraw.Draw( self._buffer )\n#             self.View.resize(newBuffer.width, newBuffer.height)\n            return True\n\n        # Redefine Frame from an <PIL.ImageFile.ImageFile>\n        if type(newBuffer).__name__.find(PIL.ImageFile.ImageFile.__name__) != -1:        \n            self._buffer = self._buffer.resize((newBuffer.width, newBuffer.height))\n            self._buffer.paste( newBuffer, (0,0))\n#             self.View.resize(newBuffer.width, newBuffer.height)\n            return True\n\n        # Recreated a new frame from dict of frame\n        if isinstance(newBuffer, dict):\n            self._buffer = Image.new( newBuffer[\"color_mode\"] , newBuffer[\"size\"] )\n            self.Canvas = ImageDraw.Draw( self._buffer )\n            return True\n        pass", "response": "Redefine the frame of the screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write(self, text=\"\", xy=(0,0), align=\"left\", font=None, fontName=None, fontSize = 10, fill = 1, spacing = 0, screenCenter = False):\n        tx = xy[0]\n        \n        try:\n            dwFont = font if font != None else DEF_SCR_FRONT if fontName==None else ImageFont.truetype(fontName, fontSize)\n        except:\n            dwFont = DEF_SCR_FRONT\n\n        try:\n            if screenCenter == True:\n                (fw, fh) = self.Canvas.multiline_textsize( text, font )\n                tx = xy[0] + (self._display_size[0]-fw)/2\n            self.Canvas.multiline_text( (tx, xy[1]) , text, font = dwFont, align=align, fill=fill, spacing=spacing)\n        except:\n            print(\"ERROR: canvas write error\")", "response": "Print one line text or multi - line text on the screen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef resize(self, newWidth = 0, newHeight = 0):\n        self.height = newHeight\n        self.width = newWidth", "response": "Resize the size of the rectangles of the current instance."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef adjuestSize(self, offsetWidth = 0, offsetHeight = 0):\n        self.height += offsetHeight\n        self.width += offsetWidth", "response": "Adjusts the width and height of the rectangles."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef moveTo(self, newX=0, newY=0):\n        self.x = newX\n        self.y = newY", "response": "Move the vertex of rectangles to new point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove the offset vertex of rectangles to new point", "response": "def moveOffset(self, offsetX=0, offsetY=0):\n        \"\"\"!\n        \\~english \n        Offset vertex of rectangles to new point (x,y)\n        @param offsetX: offset X value\n        @param offsetY: offset Y value\n        @note The negative numbers are left or up move , positive number is right or down move\uff0c0 remains unchanged.\n        \\~chinese\n        \u5e73\u79fb\u77e9\u5f62\u6307\u5b9a\u7684\u8ddd\u79bb (x,y)\n        @param offsetX: \u5e73\u79fb X\n        @param offsetY: \u5e73\u79fb Y\n        @note \u8d1f\u6570\u662f\u5de6\u79fb( X )\u6216\u4e0a\u79fb( Y )\uff0c\u6b63\u6570\u662f\u53f3\u79fb( X )\u6216\u4e0b\u79fb( Y )\uff0c0 \u4fdd\u6301\u4e0d\u53d8\u3002\n        \"\"\"\n        self.x += offsetX\n        self.y += offsetY"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nswap width and height of rectangles.", "response": "def swapWH(self):\n        \"\"\"!\n        \\~english Swap width and height of rectangles\n        \\~chinese \u4ea4\u6362\u77e9\u5f62\u9ad8\u5bbd\u8fb9\u6570\u636e\n        \"\"\"\n        width = self.width\n        self.width = self.height\n        self.height = width"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _needSwapWH(self, oldDirection, newDirection ):\n        if abs(newDirection - oldDirection) == 0: return False\n        if abs(newDirection - oldDirection) % 180 == 0: return False\n        if abs(newDirection - oldDirection) % 90 == 0: return True\n        return False", "response": "return True if we need to swap the screen"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rotateDirection(self, displayDirection):\n        if self._needSwapWH(self._display_direction, displayDirection):\n            self._display_size = ( self._display_size[1], self._display_size[0] )\n            if self.redefineBuffer( { \"size\":self._display_size, \"color_mode\":self._buffer_color_mode } ):\n                self.View.resize(self._display_size[0], self._display_size[1])\n        self._display_direction = displayDirection", "response": "rotate the screen direction by the given display direction."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new TaxClass by tax_class", "response": "def create_tax_class(cls, tax_class, **kwargs):\n        \"\"\"Create TaxClass\n\n        Create a new TaxClass\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_tax_class(tax_class, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param TaxClass tax_class: Attributes of taxClass to create (required)\n        :return: TaxClass\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_tax_class_with_http_info(tax_class, **kwargs)\n        else:\n            (data) = cls._create_tax_class_with_http_info(tax_class, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete TaxClass by ID.", "response": "def delete_tax_class_by_id(cls, tax_class_id, **kwargs):\n        \"\"\"Delete TaxClass\n\n        Delete an instance of TaxClass by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_tax_class_by_id(tax_class_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str tax_class_id: ID of taxClass to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_tax_class_by_id_with_http_info(tax_class_id, **kwargs)\n        else:\n            (data) = cls._delete_tax_class_by_id_with_http_info(tax_class_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_tax_class_by_id(cls, tax_class_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_tax_class_by_id_with_http_info(tax_class_id, **kwargs)\n        else:\n            (data) = cls._get_tax_class_by_id_with_http_info(tax_class_id, **kwargs)\n            return data", "response": "Find TaxClass by ID Return single instance of TaxClass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist TaxClasses Return a list of TaxClasses", "response": "def list_all_tax_classes(cls, **kwargs):\n        \"\"\"List TaxClasses\n\n        Return a list of TaxClasses\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_tax_classes(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[TaxClass]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_tax_classes_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_tax_classes_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_tax_class_by_id(cls, tax_class_id, tax_class, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_tax_class_by_id_with_http_info(tax_class_id, tax_class, **kwargs)\n        else:\n            (data) = cls._replace_tax_class_by_id_with_http_info(tax_class_id, tax_class, **kwargs)\n            return data", "response": "Replace TaxClass by ID and attributes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update_tax_class_by_id(cls, tax_class_id, tax_class, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_tax_class_by_id_with_http_info(tax_class_id, tax_class, **kwargs)\n        else:\n            (data) = cls._update_tax_class_by_id_with_http_info(tax_class_id, tax_class, **kwargs)\n            return data", "response": "Update attributes of a TaxClass by ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding matching modules using a package and a module name pattern.", "response": "def find_related_modules(package, related_name_re='.+',\n                         ignore_exceptions=False):\n    \"\"\"Find matching modules using a package and a module name pattern.\"\"\"\n    warnings.warn('find_related_modules has been deprecated.',\n                  DeprecationWarning)\n    package_elements = package.rsplit(\".\", 1)\n    try:\n        if len(package_elements) == 2:\n            pkg = __import__(package_elements[0], globals(), locals(), [\n                             package_elements[1]])\n            pkg = getattr(pkg, package_elements[1])\n        else:\n            pkg = __import__(package_elements[0], globals(), locals(), [])\n        pkg_path = pkg.__path__\n    except AttributeError:\n        return []\n\n    # Find all modules named according to related_name\n    p = re.compile(related_name_re)\n    modules = []\n\n    for name in find_modules(package, include_packages=True):\n        if p.match(name.split('.')[-1]):\n            try:\n                modules.append(import_string(name, silent=ignore_exceptions))\n            except Exception as e:\n                if not ignore_exceptions:\n                    raise e\n\n    return modules"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef import_related_module(package, pkg_path, related_name,\n                          ignore_exceptions=False):\n    \"\"\"Import module from given path.\"\"\"\n    try:\n        imp.find_module(related_name, pkg_path)\n    except ImportError:\n        return\n\n    try:\n        return getattr(\n            __import__('%s' % (package), globals(), locals(), [related_name]),\n            related_name\n        )\n    except Exception as e:\n        if ignore_exceptions:\n            current_app.logger.exception(\n                'Can not import \"{}\" package'.format(package)\n            )\n        else:\n            raise e", "response": "Imports a module from given path."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting a string to the terminal.", "response": "def puts(*args, **kwargs):\n\t\"\"\"\n\tFull feature printing function featuring\n\ttrimming and padding for both files and ttys\n\t\"\"\"\n\n\t# parse kwargs\n\ttrim    = kwargs.pop('trim', False)\n\tpadding = kwargs.pop('padding', None)\n\tstream  = kwargs.pop('stream', sys.stdout)\n\n\t# HACK: check if stream is IndentedFile\n\tindent = getattr(stream, 'indent', 0)\n\n\t# stringify args\n\targs = [str(i) for i in args]\n\n\t# helpers\n\tdef trimstr(ansi, width):\n\t\tstring = ''; size = 0; i = 0\n\n\t\twhile i < len(ansi):\n\t\t\tmobj = re.match(ANSI_PATTERN, ansi[i:])\n\t\t\tif mobj:\n\t\t\t\t# append ansi code\n\t\t\t\tstring = string + mobj.group(0)\n\t\t\t\ti += len(mobj.group(0))\n\t\t\telse:\n\t\t\t\t# loop for more ansi codes even at max width\n\t\t\t\tsize += 1\n\t\t\t\tif size > width: break\n\n\t\t\t\t# append normal char\n\t\t\t\tstring = string + ansi[i]\n\t\t\t\ti += 1\n\t\treturn (string, size)\n\n\t# process strings\n\tif not stream.isatty():\n\t\t# remove ansi codes and print\n\t\tfor string in args:\n\t\t\tstream.write(re.sub(ANSI_PATTERN, '', string) + '\\n')\n\telse:\n\t\t# get terminal width\n\t\ttry: curses.setupterm()\n\t\texcept:\n\t\t\ttrim = False\n\t\t\tpadding = None\n\t\telse:\n\t\t\twidth = curses.tigetnum('cols') - indent\n\n\t\tfor string in args:\n\t\t\tif trim or padding:\n\t\t\t\ttrimmed, size = trimstr(string, width)\n\n\t\t\t# trim string\n\t\t\tif trim:\n\t\t\t\tif len(trimmed) < len(string):\n\t\t\t\t\ttrimmed = trimstr(string, width - 3)[0] + colorama.Style.RESET_ALL + '...'\n\t\t\t\tstring = trimmed\n\n\t\t\t# add padding\n\t\t\tif padding:\n\t\t\t\tstring += padding * (width - size)\n\n\t\t\t# print final string\n\t\t\tstream.write(string + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrestore the tree for the given root.", "response": "def _restore_tree_for(root, translate):\n    # type: (Any, Dict[Type[Nonterminal], Type[Rule]]) -> Union[Nonterminal, Terminal]\n    \"\"\"\n    Create part of AST that generate epsilon.\n    :param root: Symbol in the original rule that results in epsilon.\n    Can be Nonterminal or epsilon itself.\n    :param translate: Dictionary where key is nonterminal and value is rule which is next to generate epsilon.\n    :return: Nonterminal instance with part of AST generating epsilon.\n    \"\"\"\n    # the symbol is epsilon directly, just return Terminal.\n    if root is EPSILON:\n        return Terminal(EPSILON)\n    # create nonterminal\n    created_nonterm = root()  # type: Nonterminal\n    created_rule = translate[root]()  # type: Rule\n    created_nonterm._set_to_rule(created_rule)\n    created_rule._from_symbols.append(created_nonterm)\n    # all symbols from the right are rewritable to epsilon, so we need to restore them as well\n    for ch in created_rule.right:\n        p = _restore_tree_for(ch, translate)  # type: Nonterminal\n        p._set_from_rule(created_rule)\n        created_rule._to_symbols.append(p)\n    return created_nonterm"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef epsilon_rules_restore(root):\n    # type: (Nonterminal) -> Nonterminal\n    \"\"\"\n    Transform parsed tree to contain epsilon rules originally removed from the grammar.\n    :param root: Root of the parsed tree.\n    :return: Modified tree including epsilon rules.\n    \"\"\"\n    items = Traversing.post_order(root)\n    items = filter(lambda x: isinstance(x, EpsilonRemovedRule), items)\n    for rule in items:\n        # create original rule\n        created_rule = rule.from_rule()  # type: Rule\n        # attach parrents parents\n        for s in rule.from_symbols:  # type: Nonterminal\n            s._set_to_rule(created_rule)\n            created_rule._from_symbols.append(s)\n        # attach children up to replace index (that will contain epsilon)\n        for i in range(rule.replace_index):\n            ch = rule.to_symbols[i]  # type: Nonterminal\n            ch._set_from_rule(created_rule)\n            created_rule._to_symbols.append(ch)\n        # add symbols originally rewrote to epsilon\n        symb = _restore_tree_for(created_rule.right[rule.replace_index], rule.backtrack)  # type: Nonterminal\n        created_rule._to_symbols.append(symb)\n        symb._set_from_rule(created_rule)\n        # attach rest of children\n        for i in range(rule.replace_index, len(rule.to_symbols)):\n            ch = rule.to_symbols[i]  # type: Nonterminal\n            ch._set_from_rule(created_rule)\n            created_rule._to_symbols.append(ch)\n    return root", "response": "Transform parsed tree to contain epsilon rules originally removed from the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef char_on_predicate(compiler, cont, test):\r\n  '''return current char and step if @test succeed, where \r\n  @test: a python function with one argument, which tests on one char and return True or False\r\n         @test must be registered with register_function'''\r\n  test = test.interlang()\r\n  text = compiler.new_var(il.ConstLocalVar('text'))\r\n  pos = compiler.new_var(il.ConstLocalVar('pos'))\r\n  if not isinstance(test, il.PyFunction):\r\n    raise DaoCompileTypeError(test)\r\n  return il.Begin((\r\n    il.AssignFromList(text, pos, il.parse_state),\r\n    il.If(il.Ge(pos,il.Len(text)), \r\n      il.failcont(il.FALSE),\r\n      il.If(il.Call(test, il.GetItem(text, pos)),\r\n        il.begin(\r\n          il.SetParseState(il.Tuple(text, il.add(pos, il.Integer(1)))),\r\n          il.append_failcont(compiler, \r\n                             il.SetParseState(il.Tuple(text, pos))),\r\n          cont(il.GetItem(text, pos))),\r\n        il.failcont(il.FALSE)))))", "response": "return current char and step if @test succeed where both are False or False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef char_between(lower, upper, func_name): \r\n  '''return current char and step if char is between lower and upper, where \r\n   @test: a python function with one argument, which tests on one char and return True or False\r\n          @test must be registered with register_function'''\r\n  function = register_function(func_name, \r\n                      lambda char: lower<=char<=upper)\r\n  return char_on_predicate(function)", "response": "return current char and step if char is between lower and upper"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef char_in(string, func_name): \r\n  '''return current char and step if char is in string, where \r\n   @test: a python function with one argument, which tests on one char and return True or False\r\n          @test must be registered with register_function'''\r\n  function = register_function(func_name, \r\n                      lambda char: char in string)\r\n  return char_on_predicate(function)", "response": "return current char and step if char is in string where where"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef string_on_predicate0(compiler, cont, test):\r\n  '''return current char and step if @test succeed, where \r\n   @test: a python function with one argument, which tests on one char and return True or False\r\n          @test must be registered with register_function'''\r\n  test = test.interlang()\r\n  text = compiler.new_var(il.ConstLocalVar('text'))\r\n  pos = compiler.new_var(il.ConstLocalVar('pos'))\r\n  length = compiler.new_var(il.ConstLocalVar('length'))\r\n  p = compiler.new_var(il.LocalVar('p'))\r\n  if not isinstance(test, il.PyFunction):\r\n    raise DaoCompileTypeError(test)\r\n  return il.Begin((\r\n    il.AssignFromList(text, pos, il.parse_state),\r\n    il.Assign(length, il.Len(text)),\r\n    il.If(il.Ge(pos,il.Len(text)), \r\n      cont(il.String('')),\r\n      il.begin(\r\n        il.Assign(p, pos),\r\n        il.While(il.And(il.Lt(p, length), il.Call(test, il.GetItem(text, p))),\r\n               il.AddAssign(p, il.Integer(1))),\r\n        il.SetParseState(il.Tuple(text, p)),\r\n        il.append_failcont(compiler, \r\n                           il.SetParseState(il.Tuple(text, pos))),\r\n        cont(il.GetItem(text, il.Slice2(pos, p)))))))", "response": "return current char and step if @test succeed where \r\n   is True or False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute an new version and write it as a tag", "response": "def update_version(self, version, step=1):\n        \"Compute an new version and write it as a tag\"\n\n        # update the version based on the flags passed.\n        if self.config.patch:\n            version.patch += step\n        if self.config.minor:\n            version.minor += step\n        if self.config.major:\n            version.major += step\n        if self.config.build:\n            version.build_number += step\n        if self.config.build_number:\n            version.build_number = self.config.build_number\n\n        # create a new tag in the repo with the new version.\n        if self.config.dry_run:\n            log.info('Not updating repo to version {0}, because of --dry-run'.format(version))\n        else:\n            version = self.call_plugin_function('set_version', version)\n\n        return version"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current data row object", "response": "def row(self):\r\n        \"\"\"Returns current data row: MyDBRow object, or None\"\"\"\r\n        ret = None\r\n        i = self.tableWidget.currentRow()\r\n        if i >= 0:\r\n            ret = self._data[i]\r\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _find_id(self, id_):\r\n        for i, row in enumerate(self._data):\r\n            if row[\"id\"] == id_:\r\n                t = self.tableWidget\r\n                # idx = t.itemFromIndex()\r\n                t.setCurrentCell(i, 0)\r\n                break", "response": "Moves to the first row where the formula is found"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering intentions to emit the id_changed signal if id really changed", "response": "def _wanna_emit_id_changed(self):\r\n        \"\"\"Filters intentions to emit the id_changed signal (only does if id really changed)\"\"\"\r\n        if self._last_id != self._get_id():\r\n            self._last_id = self._get_id()\r\n            self.id_changed.emit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_id(self):\r\n        ret = None\r\n        row = self.row\r\n        if row:\r\n            ret = row[\"id\"]\r\n        return ret", "response": "Getter because using the id property from within was not working"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses this function as a profiler for both functions and generators to see how many iterations or cycles they can run per second Example usage for timing simple operations/functions: ``` print(runs_per_second(lambda:1+2)) # 2074558 print(runs_per_second(lambda:1-2)) # 2048523 print(runs_per_second(lambda:1/2)) # 2075186 print(runs_per_second(lambda:1*2)) # 2101722 print(runs_per_second(lambda:1**2)) # 2104572 ``` Example usage for timing iteration speed of generators: ``` def counter(): c = 0 while 1: yield c c+=1 print(runs_per_second(counter())) # 1697328 print(runs_per_second((i for i in range(2000)))) # 1591301 ```", "response": "def runs_per_second(generator, seconds=3):\n    ''' \nuse this function as a profiler for both functions and generators\nto see how many iterations or cycles they can run per second \n\nExample usage for timing simple operations/functions:\n\n``` \n    print(runs_per_second(lambda:1+2))\n    # 2074558\n    print(runs_per_second(lambda:1-2))\n    # 2048523\n    print(runs_per_second(lambda:1/2))\n    # 2075186\n    print(runs_per_second(lambda:1*2))\n    # 2101722\n    print(runs_per_second(lambda:1**2))\n    # 2104572\n```\n\nExample usage for timing iteration speed of generators:\n  \n``` \n    def counter():\n        c = 0\n        while 1:\n            yield c\n            c+=1\n\n    print(runs_per_second(counter()))\n    # 1697328\n    print(runs_per_second((i for i in range(2000))))\n    # 1591301\n``` \n'''\n    assert isinstance(seconds, int), 'runs_per_second needs seconds to be an int, not {}'.format(repr(seconds))\n    assert seconds>0, 'runs_per_second needs seconds to be positive, not {}'.format(repr(seconds))\n    # if generator is a function, turn it into a generator for testing\n    if callable(generator) and not any(i in ('next', '__next__', '__iter__') for i in dir(generator)):\n        try:\n            # get the output of the function\n            output = generator()\n        except:\n            # if the function crashes without any arguments\n            raise Exception('runs_per_second needs a working function that accepts no arguments')\n        else:\n            # this usage of iter infinitely calls a function until the second argument is the output\n            # so I set the second argument to something that isnt what output was.\n            generator = iter(generator, (1 if output is None else None))\n            del output\n    c=0  # run counter, keep this one short for performance reasons\n    entire_test_time_used = False\n    start = ts()\n    end = start+seconds\n    for _ in generator:\n        if ts()>end:\n            entire_test_time_used = True\n            break\n        else:\n            c += 1\n    duration = (ts())-start  # the ( ) around ts ensures that it will be the first thing calculated\n    return int(c/(seconds if entire_test_time_used else duration))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving unreachable symbols from the grammar.", "response": "def remove_unreachable_symbols(grammar, inplace=False):\n    # type: (Grammar, bool) -> Grammar\n    \"\"\"\n    Remove unreachable symbols from the gramar\n    :param grammar: Grammar where to symbols remove\n    :param inplace: True if transformation should be performed in place. False by default.\n    :return: Grammar without unreachable symbols.\n    \"\"\"\n    # copy if required\n    if inplace is False:\n        grammar = copy(grammar)\n    # check if start symbol is set\n    if grammar.start is None:\n        raise StartSymbolNotSetException()\n    # create process sets\n    reachable = {grammar.start}\n    rules = grammar.rules.copy()\n    # begin iterations\n    while True:\n        # create sets for current iteration\n        active = reachable.copy()\n        # loop the working rules\n        for rule in rules.copy():\n            # lf left part of rule already in reachable symbols\n            if rule.fromSymbol in reachable:\n                # set symbols on the right as reachable\n                for symbol in rule.right:\n                    active.add(symbol)\n                # remove rule from the next iteration\n                rules.remove(rule)\n            # end of rules loop\n        # if current and previous iterations are same, we are done\n        if active == reachable:\n            break\n        # otherwise swap the sets\n        reachable = active\n    # remove the symbols\n    nonterminals_to_remove = grammar.nonterminals.difference(reachable)\n    terminals_to_remove = grammar.terminals.difference(reachable)\n    grammar.nonterminals.remove(*nonterminals_to_remove)\n    grammar.terminals.remove(*terminals_to_remove)\n    # return grammar\n    return grammar"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate the interaction term of a spin flip and pair hopping", "response": "def spinflipandhop(slaves):\n    \"\"\"Calculates the interaction term of a spin flip and pair hopping\"\"\"\n\n    Sdw = [csr_matrix(spin_gen(slaves, i, 0)) for i in range(slaves)]\n    Sup = [mat.T for mat in Sdw]\n\n    sfh = np.zeros_like(Sup[0])\n    orbitals = slaves//2\n    for n in range(orbitals):\n        for m in range(n+1, orbitals):\n            sfh += Sup[2*n  ] * Sdw[2*n + 1] * Sup[2*m + 1] * Sdw[2*m  ]\n            sfh += Sup[2*n+1] * Sdw[2*n    ] * Sup[2*m    ] * Sdw[2*m+1]\n\n            sfh += Sup[2*n] * Sup[2*n + 1] * Sdw[2*m] * Sdw[2*m+1]\n            sfh += Sup[2*m] * Sup[2*m + 1] * Sdw[2*n] * Sdw[2*n+1]\n\n    return sfh"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef spin_z_op(param, oper):\n    slaves = param['slaves']\n    oper['Sz'] = np.array([spin_z(slaves, spin) for spin in range(slaves)])\n    oper['Sz+1/2'] = oper['Sz'] + 0.5*np.eye(2**slaves)\n    oper['sumSz2'] = oper['Sz'].sum(axis=0)**2  # because Sz is diagonal\n    Sz_mat_shape = oper['Sz'].reshape(param['orbitals'], 2, 2**slaves, 2**slaves)\n    oper['sumSz-sp2'] = (Sz_mat_shape.sum(axis=1)**2).sum(axis=0)\n    oper['sumSz-or2'] = (Sz_mat_shape.sum(axis=0)**2).sum(axis=0)", "response": "Generates the required Sz operators given the system parameter setup\n       and the operator dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates the generic spin matrices for the system", "response": "def spin_gen_op(oper, gauge):\n    \"\"\"Generates the generic spin matrices for the system\"\"\"\n    slaves = len(gauge)\n    oper['O'] = np.array([spin_gen(slaves, i, c) for i, c in enumerate(gauge)])\n    oper['O_d'] = np.transpose(oper['O'], (0, 2, 1))\n    oper['O_dO'] = np.einsum('...ij,...jk->...ik', oper['O_d'], oper['O'])\n    oper['Sfliphop'] = spinflipandhop(slaves)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the orbital enenergies for on the reference of the free case.", "response": "def set_filling(self, populations):\n        \"\"\"Sets the orbital enenergies for on the reference of the free case.\n          By setting the desired local populations on every orbital.\n          Then generate the necesary operators to respect such configuraion\"\"\"\n        populations = np.asarray(populations)\n#\n#        self.param['orbital_e'] -= bethe_findfill_zeroT( \\\n#                                        self.param['avg_particles'],\n#                                        self.param['orbital_e'],\n#                                        self.param['hopping'])\n        efermi = - bethe_find_crystalfield(\n                            populations, self.param['hopping'])\n        self.param['populations'] = populations\n#        fermion_avg(efermi, self.param['hopping'], 'ocupation')\n        self.param['ekin'] = fermion_avg(efermi, self.param['hopping'], 'ekin')\n\n        spin_gen_op(self.oper, estimate_gauge(populations))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self, populations, lag, mu, u_int, j_coup, mean_f):\n\n        self.set_filling(populations)\n        self.param['lambda'] = lag\n        self.param['orbital_e'] = mu\n        self.selfconsistency(u_int, j_coup, mean_f)", "response": "Resets the system to the last known state as given by the input\n           values"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_H(self, mean_field, l):\n\n        self.H_s = self.spin_hamiltonian(mean_field, l)\n        try:\n            self.eig_energies, self.eig_states = diagonalize(self.H_s)\n        except np.linalg.linalg.LinAlgError:\n            np.savez('errorhamil', H=self.H_s, fiel=mean_field, lamb=l)\n            raise\n        except ValueError:\n            np.savez('errorhamil', H=self.H_s, fiel=mean_field, lamb=l)\n            print(mean_field, l)\n            raise", "response": "Updates the spin hamiltonian and recalculates its eigenbasis"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef spin_hamiltonian(self, h, l):\n        h_spin  = np.einsum('i,ijk', h[1], self.oper['O'])\n        h_spin += np.einsum('i,ijk', h[0], self.oper['O_d'])\n        h_spin += np.einsum('i,ijk', l, self.oper['Sz+1/2'])\n\n        h_spin += self.oper['Hint']\n        return h_spin", "response": "Constructs the single site spin Hamiltonian"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalculating the interaction Hamiltonian.", "response": "def inter_spin_hamiltonian(self, u_int, J_coup):\n        \"\"\"Calculates the interaction Hamiltonian. The Hund coupling is a\n           fraction of the coulom interaction\"\"\"\n        J_coup *= u_int\n        h_int  = (u_int - 2*J_coup)/2.*self.oper['sumSz2']\n        h_int += J_coup*self.oper['sumSz-sp2']\n        h_int -= J_coup/2.*self.oper['sumSz-or2']\n        h_int -= J_coup*self.oper['Sfliphop']\n\n        return h_int"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef expected(self, observable, beta=1e5):\n        return expected_value(observable,\n                         self.eig_energies,\n                         self.eig_states,\n                         beta)", "response": "Wrapper to the expected_value function to fix the eigenbasis"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef quasiparticle_weight(self):\n        return np.array([self.expected(op)**2 for op in self.oper['O']])", "response": "Calculates the quasiparticle weight"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates mean field of the object", "response": "def mean_field(self):\n        \"\"\"Calculates mean field\"\"\"\n        mean_field = []\n        for sp_oper in [self.oper['O'], self.oper['O_d']]:\n            avgO = np.array([self.expected(op) for op in sp_oper])\n            avgO[abs(avgO) < 1e-10] = 0.\n            mean_field.append(avgO*self.param['ekin'])\n\n        return np.array(mean_field)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef selfconsistency(self, u_int, J_coup, mean_field_prev=None):\n        if mean_field_prev is None:\n            mean_field_prev = np.array([self.param['ekin']]*2)\n        hlog = [mean_field_prev]\n\n        self.oper['Hint'] = self.inter_spin_hamiltonian(u_int, J_coup)\n        converging = True\n        half_fill = (self.param['populations'] == 0.5).all()\n        while converging:\n            if half_fill:\n                self.update_H(hlog[-1], self.param['lambda'])\n            else:\n                res = root(self.restriction, self.param['lambda'], (hlog[-1]))#, method='lm')\n                if not res.success:\n                    res.x = res.x * 0.5 + 0.5*self.param['lambda']\n                    self.update_H(self.mean_field()*0.5 + 0.5*hlog[-1], res.x)\n                    print('fail', self.param['populations'][3:5])\n                if (self.quasiparticle_weight() < 0.001).all():\n                    return hlog\n                self.param['lambda'] = res.x\n\n            hlog.append(self.mean_field())\n            converging = (abs(hlog[-1] - hlog[-2]) > self.param['tol']).all() \\\n                    or (abs(self.restriction(self.param['lambda'], hlog[-1])) > self.param['tol']).all()\n\n        return hlog", "response": "Iterates over the hamiltonian to get the stable selfcosistent one"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the restriction of the slave spin", "response": "def restriction(self, lam, mean_field):\n        \"\"\"Lagrange multiplier in lattice slave spin\"\"\"\n        self.update_H(mean_field, lam)\n        restric = np.array([self.expected(op) - n for op, n in zip(self.oper['Sz+1/2'], self.param['populations'])])\n        return restric"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef others2db(file_path, file_type, is_copy, step_id, db_conn):\n    logging.info(\"Processing '%s'\" % file_path)\n\n    df = db_conn.db_session.query(db_conn.DataFile).filter_by(path=file_path).one_or_none()\n\n    if not df:\n        df = db_conn.DataFile(\n            path=file_path,\n            type=file_type,\n            is_copy=is_copy,\n            processing_step_id=step_id\n        )\n        db_conn.db_session.merge(df)\n        db_conn.db_session.commit()\n    else:\n        if file_type not in [None, '', df.type]:\n            df.type = file_type\n            db_conn.db_session.commit()\n        if is_copy not in [None, df.is_copy]:\n            df.is_copy = is_copy\n            db_conn.db_session.commit()\n        if step_id not in [None, df.processing_step_id]:\n            df.processing_step_id = step_id\n            db_conn.db_session.commit()", "response": "Extract some meta - data from files and store them in a DB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Currency object", "response": "def create_currency(cls, currency, **kwargs):\n        \"\"\"Create Currency\n\n        Create a new Currency\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_currency(currency, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Currency currency: Attributes of currency to create (required)\n        :return: Currency\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_currency_with_http_info(currency, **kwargs)\n        else:\n            (data) = cls._create_currency_with_http_info(currency, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_currency_by_id(cls, currency_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_currency_by_id_with_http_info(currency_id, **kwargs)\n        else:\n            (data) = cls._delete_currency_by_id_with_http_info(currency_id, **kwargs)\n            return data", "response": "Delete an instance of Currency by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding Currency by ID Return single instance of Currency with its ID.", "response": "def get_currency_by_id(cls, currency_id, **kwargs):\n        \"\"\"Find Currency\n\n        Return single instance of Currency by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_currency_by_id(currency_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str currency_id: ID of currency to return (required)\n        :return: Currency\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_currency_by_id_with_http_info(currency_id, **kwargs)\n        else:\n            (data) = cls._get_currency_by_id_with_http_info(currency_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_all_currencies(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_currencies_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_currencies_with_http_info(**kwargs)\n            return data", "response": "List Currencies\nAttributeNames Returns a list of Currencies\nAttributeNames"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_currency_by_id(cls, currency_id, currency, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_currency_by_id_with_http_info(currency_id, currency, **kwargs)\n        else:\n            (data) = cls._replace_currency_by_id_with_http_info(currency_id, currency, **kwargs)\n            return data", "response": "Replace all attributes of Currency with the specified ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating attributes of Currency by ID", "response": "def update_currency_by_id(cls, currency_id, currency, **kwargs):\n        \"\"\"Update Currency\n\n        Update attributes of Currency\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_currency_by_id(currency_id, currency, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str currency_id: ID of currency to update. (required)\n        :param Currency currency: Attributes of currency to update. (required)\n        :return: Currency\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_currency_by_id_with_http_info(currency_id, currency, **kwargs)\n        else:\n            (data) = cls._update_currency_by_id_with_http_info(currency_id, currency, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun an external command in order to get the base class information.", "response": "def run_cmd(cmd, out=os.path.devnull, err=os.path.devnull):\n    \"\"\"Runs an external command\n\n    :param list cmd: Command to run.\n    :param str out: Output file\n    :param str err: Error file\n    :raises: RuntimeError\n    \"\"\"\n\n    logger.debug(' '.join(cmd))\n    with open(out, 'w') as hout:\n        proc = subprocess.Popen(cmd, stdout=hout, stderr=subprocess.PIPE)\n        err_msg = proc.communicate()[1].decode()\n    with open(err, 'w') as herr:\n        herr.write(str(err_msg))\n    msg = '({}) {}'.format(' '.join(cmd), err_msg)\n    if proc.returncode != 0:\n        logger.error(msg)\n        raise RuntimeError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_cmd_if_file_missing(cmd, fname, out=os.path.devnull, err=os.path.devnull):\n\n    if fname is None or not os.path.exists(fname):\n        run_cmd(cmd, out, err)\n        return True\n    else:\n        return False", "response": "Runs an external command if file is absent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncopy content of multiple files into a single file.", "response": "def merge_files(sources, destination):\n    \"\"\"Copy content of multiple files into a single file.\n\n    :param list(str) sources: source file names (paths)\n    :param str destination: destination file name (path)\n    :return:\n    \"\"\"\n\n    with open(destination, 'w') as hout:\n        for f in sources:\n            if os.path.exists(f):\n                with open(f) as hin:\n                    shutil.copyfileobj(hin, hout)\n            else:\n                logger.warning('File is missing: {}'.format(f))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a new path to the list of searchable paths . Returns the new path if it exists.", "response": "def add_path(self, path):\n        \"\"\" Adds a new path to the list of searchable paths\n\n        :param path: new path\n        \"\"\"\n\n        if os.path.exists(path):\n            self.paths.add(path)\n            return path\n        else:\n            #logger.debug('Path {} doesn\\'t exist'.format(path))\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, name):\n\n        for d in self.paths:\n            if os.path.exists(d) and name in os.listdir(d):\n                return os.path.join(d, name)\n        logger.debug('File not found {}'.format(name))\n        return None", "response": "Looks for a name in the path."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverwrite a FITS file with the contents of the given HDUList.", "response": "def overwrite_fits(hdulist, filename):\n    \"\"\"\n    Saves a FITS file. Combined file rename, save new, delete renamed for FITS files\n    Why: HDUlist.writeto() does not overwrite existing files\n    Why(2): It is also a standardized way to save FITS files\n    \"\"\"\n\n    assert isinstance(hdulist, (fits.HDUList, fits.PrimaryHDU))\n    temp_name = None\n    flag_delete_temp = False\n    if os.path.isfile(filename):\n        # PyFITS does not overwrite file\n        temp_name = a99.rename_to_temp(filename)\n    try:\n        hdulist.writeto(filename, output_verify='warn')\n        flag_delete_temp = temp_name is not None\n    except:\n        # Writing failed, reverts renaming\n        os.rename(temp_name, filename)\n        raise\n\n    if flag_delete_temp:\n        os.unlink(temp_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_conf(yml_file, conf={}):\n    with open(yml_file) as f:\n        data = yaml.load(f)\n        if conf:\n            data.update(conf)\n        return dictdot(data)", "response": "Load the config file and return the config dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if a given table exists in a given mysql database.", "response": "def table_exists(\n        dbConn,\n        log,\n        dbTableName):\n    \"\"\"*Probe a database to determine if a given table exists*\n\n    **Key Arguments:**\n        - ``dbConn`` -- mysql database connection\n        - ``log`` -- logger\n        - ``dbTableName`` -- the database tablename\n\n    **Return:**\n        - ``tableExists`` -- True or False\n\n    **Usage:**\n\n        To test if a table exists in a database:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import table_exists\n            exists = table_exists(\n                dbConn=dbConn,\n                log=log,\n                dbTableName=\"stupid_named_table\"\n            )\n\n            print exists\n\n            # OUTPUT: False\n    \"\"\"\n    log.debug('starting the ``table_exists`` function')\n\n    sqlQuery = u\"\"\"\n        SELECT count(*)\n        FROM information_schema.tables\n        WHERE table_name = '%(dbTableName)s'\n    \"\"\" % locals()\n    tableExists = readquery(\n        log=log,\n        sqlQuery=sqlQuery,\n        dbConn=dbConn,\n        quiet=False\n    )\n\n    if tableExists[0][\"count(*)\"] == 0:\n        tableExists = False\n    else:\n        tableExists = True\n\n    log.debug('completed the ``table_exists`` function')\n    return tableExists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nintercept the request and response.", "response": "def __handle_request(self, request, *args, **kw):\n        \"\"\" Intercept the request and response.\n\n        This function lets `HttpStatusCodeError`s fall through. They\n        are caught and transformed into HTTP responses by the caller.\n\n        :return: ``HttpResponse``\n        \"\"\"\n\n        self._authenticate(request)\n        self._check_permission(request)\n        method = self._get_method(request)\n        data = self._get_input_data(request)\n        data = self._clean_input_data(data, request)\n        response = self._exec_method(method, request, data, *args, **kw)\n        return self._process_response(response, request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexecuting appropriate request handler.", "response": "def _exec_method(self, method, request, data, *args, **kw):\n        \"\"\" Execute appropriate request handler. \"\"\"\n        if self._is_data_method(request):\n            return method(data, request, *args, **kw)\n        else:\n            return method(request, *args, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _process_response(self, response, request):\n\n        def coerce_response():\n            \"\"\" Coerce the response object into devil structure. \"\"\"\n            if not isinstance(response, Response):\n                return Response(0, response)\n            return response\n\n        if isinstance(response, HttpResponse):\n            # we don't do anything if resource returns django's http response\n            return response\n\n        devil_res = coerce_response()\n        if devil_res.content and devil_res.get_code_num() in (0, 200, 201):\n            # serialize, format and validate\n            serialized_res = devil_res.content = self._serialize_object(devil_res.content, request)\n            formatted_res = self._format_response(request, devil_res)\n            self._validate_output_data(response, serialized_res, formatted_res, request)\n        else:\n            # no data -> format only\n            formatted_res = self._format_response(request, devil_res)\n        return formatted_res", "response": "Process the response.\n\n        If the response is ``HttpResponse``, does nothing. Otherwise,\n        serializes, formats and validates the response.\n\n        :param response: resource's response. This can be\n           - ``None``,\n           - django's ``HttpResponse``\n           - devil's ``Response``\n           - dictionary (or list of dictionaries)\n           - object (or list of objects) that are first serialized into dict\n             using ``self.factory``.\n           - plaintext\n        :returns: Django's ``HttpResponse``"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nformatting the response using appropriate datamapper.", "response": "def _format_response(self, request, response):\n        \"\"\" Format response using appropriate datamapper.\n\n        Take the devil response and turn it into django response, ready to\n        be returned to the client.\n        \"\"\"\n\n        res = datamapper.format(request, response, self)\n        # data is now formatted, let's check if the status_code is set\n        if res.status_code is 0:\n            res.status_code = 200\n        # apply headers\n        self._add_resposne_headers(res, response)\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding HTTP headers from devil s response to django s response.", "response": "def _add_resposne_headers(self, django_response, devil_response):\n        \"\"\" Add response headers.\n\n        Add HTTP headers from devil's response to django's response.\n        \"\"\"\n\n        try:\n            headers = devil_response.headers\n        except AttributeError:\n            # ok, there was no devil_response\n            pass\n        else:\n            for k, v in headers.items():\n                django_response[k] = v\n        return django_response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_input_data(self, request):\n        # only PUT and POST should provide data\n        if not self._is_data_method(request):\n            return None\n\n        content = [row for row in request.read()]\n        content = ''.join(content) if content else None\n        return self._parse_input_data(content, request) if content else None", "response": "Parse the input data and return the data object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn appropriate input validator.", "response": "def _get_input_validator(self, request):\n        \"\"\" Return appropriate input validator.\n\n        For POST requests, ``self.post_representation`` is returned\n        if it is present, ``self.representation`` otherwise.\n        \"\"\"\n\n        method = request.method.upper()\n        if method != 'POST':\n            return self.representation\n        elif self.post_representation:\n            return self.post_representation\n        else:\n            return self.representation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _validate_input_data(self, data, request):\n\n        validator = self._get_input_validator(request)\n        if isinstance(data, (list, tuple)):\n            return map(validator.validate, data)\n        else:\n            return validator.validate(data)", "response": "Validate input data.\n\n        :param request: the HTTP request\n        :param data: the parsed data\n        :return: if validation is performed and succeeds the data is converted\n                 into whatever format the validation uses (by default Django's\n                 Forms) If not, the data is returned unchanged.\n        :raises: HttpStatusCodeError if data is not valid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nvalidating the response data.", "response": "def _validate_output_data(\n        self, original_res, serialized_res, formatted_res, request):\n        \"\"\" Validate the response data.\n\n        :param response: ``HttpResponse``\n        :param data: payload data. This implementation assumes\n                     dict or list of dicts.\n        :raises: `HttpStatusCodeError` if data is not valid\n        \"\"\"\n\n        validator = self.representation\n\n        # when not to validate...\n        if not validator:\n            return\n\n        try:\n            if isinstance(serialized_res, (list, tuple)):\n                map(validator.validate, serialized_res)\n            else:\n                validator.validate(serialized_res)\n        except ValidationError, exc:\n            self._output_validation_failed(exc, serialized_res, request)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a python object from the given data.", "response": "def _create_object(self, data, request):\n        \"\"\" Create a python object from the given data.\n\n        This will use ``self.factory`` object's ``create()`` function to\n        create the data.\n\n        If no factory is defined, this will simply return the same data\n        that was given.\n        \"\"\"\n\n        if request.method.upper() == 'POST' and self.post_factory:\n            fac_func = self.post_factory.create\n        else:\n            fac_func = self.factory.create\n\n        if isinstance(data, (list, tuple)):\n            return map(fac_func, data)\n        else:\n            return fac_func(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _serialize_object(self, response_data, request):\n\n        if not self.factory:\n            return response_data\n        if isinstance(response_data, (list, tuple)):\n            return map(\n                lambda item: self.factory.serialize(item, request),\n                response_data)\n        else:\n            return self.factory.serialize(response_data, request)", "response": "This method will create a python datatype from the given python object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a HttpResponse for unknown exceptions.", "response": "def _get_unknown_error_response(self, request, exc):\n        \"\"\" Generate HttpResponse for unknown exceptions.\n\n        todo: this should be more informative..\n        \"\"\"\n\n        logging.getLogger('devil').error(\n            'while doing %s on %s with [%s], devil caught: %s' % (\n                request.method, request.path_info, str(request.GET), str(exc)), exc_info=True)\n\n        if settings.DEBUG:\n            raise\n        else:\n            return HttpResponse(status=codes.INTERNAL_SERVER_ERROR[1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating HttpResponse based on the HttpStatusCodeError.", "response": "def _get_error_response(self, exc):\n        \"\"\" Generate HttpResponse based on the HttpStatusCodeError. \"\"\"\n        if exc.has_code(codes.UNAUTHORIZED):\n            return self._get_auth_challenge(exc)\n        else:\n            if exc.has_code(codes.INTERNAL_SERVER_ERROR):\n                logging.getLogger('devil').error('devil caught http error: ' + str(exc), exc_info=True)\n            else:\n                logging.getLogger('devil').error('devil caught http error: ' + str(exc))\n            content = exc.content or ''\n            return HttpResponse(content=content, status=exc.get_code_num())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the challenge for the client.", "response": "def _get_auth_challenge(self, exc):\n        \"\"\" Returns HttpResponse for the client. \"\"\"\n        response = HttpResponse(content=exc.content, status=exc.get_code_num())\n        response['WWW-Authenticate'] = 'Basic realm=\"%s\"' % REALM\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfiguring out the requested method and return the callable.", "response": "def _get_method(self, request):\n        \"\"\" Figure out the requested method and return the callable. \"\"\"\n        methodname = request.method.lower()\n        method = getattr(self, methodname, None)\n        if not method or not callable(method):\n            raise errors.MethodNotAllowed()\n        return method"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck user permissions. :raises: Forbidden, if user doesn't have access to the resource.", "response": "def _check_permission(self, request):\n        \"\"\" Check user permissions.\n\n        :raises: Forbidden, if user doesn't have access to the resource.\n        \"\"\"\n\n        if self.access_controller:\n            self.access_controller.check_perm(request, self)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting the reply from &devices() and highlight errors.", "response": "def print_devices_change_callback(devices, key, new):\n    \"\"\"Print the reply from &devices() and highlight errors.\"\"\"\n    dev = devices[key]\n    print('- ', new, ' ', dev)\n    if dev['type'] == QSType.unknown:\n        print(\" ERR decoding\")\n    elif dev['value'] == -1:\n        dev(\" ERR decoding: -1?\")\n    qcord = pyqwikswitch.decode_qwikcord(dev['data'][pyqwikswitch.QS_VALUE])\n    if qcord is not None:\n        print(' qwikcord (CTAVG, CTsum) = ' + str(qcord))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint an item callback used by &listen.", "response": "def print_item_callback(item):\n    \"\"\"Print an item callback, used by &listen.\"\"\"\n    print('&listen [{}, {}={}]'.format(\n        item.get('cmd', ''),\n        item.get('id', ''),\n        item.get('data', '')))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self):\n        with self._lock:\n            now = datetime.now()\n            active = []\n            for i, vef in enumerate(self.futures):\n                # has expired\n                if (vef[1] or datetime.max) <= now:\n                    self.futures.pop(i)\n                    continue\n                # in future\n                elif (vef[2] or datetime.min) >= now:\n                    continue\n                else:\n                    active.append(i)\n\n            if active:\n                # this will evict values old values\n                # because new ones are \"more recent\" via future\n                value, _e, _f = self.futures[active[-1]]\n                for i in active[:-1]:\n                    self.futures.pop(i)\n                return value\n\n            raise ValueError(\"dicttime: no current value, however future has (%d) values\" % len(self.futures))", "response": "Called to get the asset values and return the current value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef retrieve(self, *args, **kwargs):\n\n        lookup, key = self._lookup(*args, **kwargs)\n\n        return lookup[key]", "response": "Retrieve the permsission function for the provided things."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __api_proxy_call(self, engine, payload, method, analyze_json_error_param, retry_request_substr_variants,\n                         stream=False):\n        \"\"\"\n        :param engine: \u0421\u0438\u0441\u0442\u0435\u043c\u0430\n        :param payload: \u0414\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n        :param method: string \u041c\u043e\u0436\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c native_call | tsv | json_newline\n        :param analyze_json_error_param: \u041d\u0443\u0436\u043d\u043e \u043b\u0438 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u0430\u043d\u0430\u043b\u0438\u0437 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 error \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u043f\u0440\u043e\u043a\u0441\u0438\n        :param retry_request_substr_variants: \u0421\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u0434\u0441\u0442\u0440\u043e\u043a, \u043f\u0440\u0438 \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u0437\u0430\u043f\u0440\u043e\u0441\n        :param stream:\n        :return:\n        \"\"\"\n        log_ctx = {\n            \"engine\": engine,\n            \"method\": payload.get('method'),\n            \"method_params\": payload.get('method_params')\n        }\n        self.__app.log.info(\"Call api proxy\", log_ctx)\n        body = {\n            \"engine\": engine,\n            \"payload\": payload\n        }\n        for _try_idx in range(20):\n            try:\n                # 1h \u0442\u0430\u0439\u043c\u0430\u0443\u0442, \u0442\u0430\u043a \u043a\u0430\u043a \u0431\u044b\u0432\u0430\u044e\u0442 \u0431\u043e\u043b\u044c\u0448\u0438\u0435 \u0434\u043e\u043b\u0433\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435, \u0430 \u043b\u0438\u043c\u0438\u0442 \u0445\u043e\u0442\u044c \u043a\u0430\u043a\u043e\u0439-\u0442\u043e \u043d\u0443\u0436\u0435\u043d\n                body_str = json.dumps(body)\n                headers = {\n                    \"User-Agent\": self.__app.user_agent,\n                    \"X-App\": \"META\",\n                    \"X-Worker\": self.__app.service_id,\n                    \"X-ObjectLocator\": LOGGER_ENTITY.get(\"objectLocator\")\n                }\n                resp = requests.post(self.__app.api_proxy_url + \"/\" + method, body_str, timeout=3600, stream=stream,\n                                     headers=headers)\n\n                self.check_err(resp, analyze_json_error_param=analyze_json_error_param,\n                               retry_request_substr_variants=retry_request_substr_variants)\n                return resp\n            except (RetryHttpRequestError, RateLimitError, ConnectionError) as e:\n                self.__app.log.warning(\"Sleep retry query: \" + str(e), log_ctx)\n                sleep_time = 20\n\n                if e.__class__.__name__ == \"RateLimitError\":\n                    sleep_time = e.waiting_time\n\n                time.sleep(sleep_time)\n\n        raise EndOfTriesError(\"Api of api proxy tries request\")", "response": "Internal method to call API proxy."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling proxy with paging", "response": "def call_proxy_with_paging(self, engine, payload, method, analyze_json_error_param, retry_request_substr_variants,\n                               max_pages=MAX_PAGES):\n        \"\"\"\n        \u041f\u043e\u0441\u0442\u0440\u0430\u043d\u0438\u0447\u043d\u044b\u0439 \u0437\u0430\u043f\u0440\u043e\u0441\n        :param engine: \u0421\u0438\u0441\u0442\u0435\u043c\u0430\n        :param payload: \u0414\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n        :param method: string \u041c\u043e\u0436\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c native_call | tsv | json_newline\n        :param analyze_json_error_param: \u041d\u0443\u0436\u043d\u043e \u043b\u0438 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u0430\u043d\u0430\u043b\u0438\u0437 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 error \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u043f\u0440\u043e\u043a\u0441\u0438\n        :param retry_request_substr_variants: \u0421\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u0434\u0441\u0442\u0440\u043e\u043a, \u043f\u0440\u0438 \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u0437\u0430\u043f\u0440\u043e\u0441\n        :param max_pages: \u041c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0441\u0442\u0440\u0430\u043d\u0438\u0446 \u0432 \u0437\u0430\u043f\u0440\u043e\u0441\u0435\n        :return: \u043e\u0431\u044a\u0435\u043a\u0442 \u0433\u0435\u043d\u0435\u0440\u0430\u0442\u043e\u0440\n        \"\"\"\n        copy_payload = copy.deepcopy(payload)\n\n        idx = 0\n        for idx in range(max_pages):\n            resp = self.__api_proxy_call(engine, copy_payload, method, analyze_json_error_param,\n                                         retry_request_substr_variants)\n            yield resp\n\n            paging_resp = resp.json().get(\"paging\")\n            if not paging_resp:\n                break\n            copy_payload[\"paging\"] = paging_resp\n\n        if idx >= max_pages:\n            self.__app.log.warning(\"\u0414\u043e\u0441\u0442\u0438\u0433\u043d\u0443\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u044b\u0439 \u043f\u0440\u0435\u0434\u0435\u043b \u0441\u0442\u0440\u0430\u043d\u0438\u0446\", {\"max_pages\": max_pages})"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls the API proxy.", "response": "def call_proxy(self, engine, payload, method, analyze_json_error_param, retry_request_substr_variants,\n                   stream=False):\n        \"\"\"\n        :param engine: \u0421\u0438\u0441\u0442\u0435\u043c\u0430\n        :param payload: \u0414\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u0437\u0430\u043f\u0440\u043e\u0441\u0430\n        :param method: string \u041c\u043e\u0436\u0435\u0442 \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c native_call | tsv | json_newline\n        :param analyze_json_error_param: \u041d\u0443\u0436\u043d\u043e \u043b\u0438 \u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u0442\u044c \u0430\u043d\u0430\u043b\u0438\u0437 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u0430 error \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u043f\u0440\u043e\u043a\u0441\u0438\n        :param retry_request_substr_variants: \u0421\u043f\u0438\u0441\u043e\u043a \u043f\u043e\u0434\u0441\u0442\u0440\u043e\u043a, \u043f\u0440\u0438 \u043d\u0430\u043b\u0438\u0447\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u043e\u0442\u0432\u0435\u0442\u0435 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0441\u0445\u043e\u0434\u0438\u0442\u044c \u043f\u0435\u0440\u0435\u0437\u0430\u043f\u0440\u043e\u0441\n        :param stream:\n        :return:\n        \"\"\"\n        return self.__api_proxy_call(engine, payload, method, analyze_json_error_param, retry_request_substr_variants,\n                                     stream)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if the HTTP response is an error.", "response": "def check_err(resp, analyze_json_error_param=False, retry_request_substr_variants=None):\n        \"\"\"\n        :type retry_request_substr_variants: list \u0421\u043f\u0438\u0441\u043e\u043a \u0432\u0445\u043e\u0436\u0434\u0435\u043d\u0438\u0439 \u0441\u0442\u0440\u043e\u043a, \u043f\u0440\u0438 \u043d\u0430\u043b\u0438\u0446\u0438\u0438 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u0432 \u043e\u0448\u0438\u0431\u043a\u0435 \u0430\u043f\u0438 \u0431\u0443\u0434\u0435\u0442 \u043f\u0440\u043e\u0438\u0437\u0432\u0435\u0434\u0435\u043d \u043f\u043e\u0432\u0442\u043e\u0440\u043d\u044b\u0439 \u0437\u0430\u043f\u0440\u043e\u0441 \u043a \u0430\u043f\u0438\n        \"\"\"\n        if retry_request_substr_variants is None:\n            retry_request_substr_variants = []\n\n        # \u0420\u041a\u041d \u0431\u043b\u043e\u043a\u0438\u0440\u043e\u0432\u043a\u0438 \u0432\u044b\u0437\u044b\u0432\u0430\u044e\u0442 \u043e\u0448\u0438\u0431\u043a\u0443 SSL\n        retry_request_substr_variants.append(\"TLSV1_ALERT_ACCESS_DENIED\")\n\n        if resp.status_code in [502, 503, 504]:\n            raise RetryHttpRequestError(resp.text)\n\n        if resp.status_code >= 400:\n            rtext = resp.text\n            for v_ in retry_request_substr_variants:\n                if v_ in rtext:\n                    raise RetryHttpRequestError(rtext)\n            raise UnexpectedError(\"HTTP request failed: {} {}\".format(resp.status_code, rtext))\n        if analyze_json_error_param:\n            data_ = resp.json()\n            if 'error' in data_ and data_.get('error'):\n                error = data_.get('error')\n                full_err_ = json.dumps(error)\n\n                if error.get(\"type\") == \"RateLimitError\":\n                    raise RateLimitError(error.get(\"message\"), waiting_time=error.get(\"waiting_time\"))\n\n                for v_ in retry_request_substr_variants:\n                    if v_ in full_err_:\n                        raise RetryHttpRequestError(full_err_)\n                raise ApiProxyError(full_err_)\n        return resp"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the sequence has enough RabF motifs within the G domain.", "response": "def has_rabf_motif(self):\n        \"\"\"Checks if the sequence has enough RabF motifs within the G domain\n\n        If there exists more than one G domain in the sequence enough RabF motifs is required in at least one\n        of those domains to classify the sequence as a Rab.\n        \"\"\"\n\n        if self.rabf_motifs:\n            for gdomain in self.gdomain_regions:\n                beg, end = map(int, gdomain.split('-'))\n                motifs = [x for x in self.rabf_motifs if x[1] >= beg and x[2] <= end]\n                if motifs:\n                    matches = int(pairwise2.align.globalxx('12345', ''.join(str(x[0]) for x in motifs))[0][2])\n                    if matches >= self.motif_number:\n                        return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef summarize(self):\n        data = [\n            ['Sequence ID', self.seqrecord.id],\n            ['G domain', ' '.join(self.gdomain_regions) if self.gdomain_regions else None],\n            ['E-value vs rab db', self.evalue_bh_rabs],\n            ['E-value vs non-rab db', self.evalue_bh_non_rabs],\n            ['RabF motifs', ' '.join(map(str, self.rabf_motifs)) if self.rabf_motifs else None],\n            ['Is Rab?', self.is_rab()]\n        ]\n        summary = ''\n        for name, value in data:\n            summary += '{:25s}{}\\n'.format(name, value)\n        if self.is_rab():\n            summary += '{:25s}{}\\n'.format('Top 5 subfamilies',\n                                           ', '.join('{:s} ({:.2g})'.format(name, score) for name, score\n                                                     in self.rab_subfamily_top5))\n        return summary", "response": "A method to summarize the G protein annotation summary in a text format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite sequences predicted to be Rabs as a fasta file.", "response": "def write(self):\n        \"\"\"Write sequences predicted to be Rabs as a fasta file.\n\n        :return: Number of written sequences\n        :rtype: int\n        \"\"\"\n\n        rabs = [x.seqrecord for x in self.gproteins.values() if x.is_rab()]\n        return SeqIO.write(rabs, self.tmpfname + '.phase2', 'fasta')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if data and third party tools necessary to run the classification are available.", "response": "def check(self):\n        \"\"\" Check if data and third party tools, necessary to run the classification, are available\n\n        :raises: RuntimeError\n        \"\"\"\n\n        pathfinder = Pathfinder(True)\n        if pathfinder.add_path(pathfinder['superfamily']) is None:\n            raise RuntimeError(\"'superfamily' data directory is missing\")\n\n        for tool in ('hmmscan', 'phmmer', 'mast', 'blastp', 'ass3.pl', 'hmmscan.pl'):\n            if not pathfinder.exists(tool):\n                raise RuntimeError('Dependency {} is missing'.format(tool))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new Brand AttributeNames", "response": "def create_brand(cls, brand, **kwargs):\n        \"\"\"Create Brand\n\n        Create a new Brand\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_brand(brand, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Brand brand: Attributes of brand to create (required)\n        :return: Brand\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_brand_with_http_info(brand, **kwargs)\n        else:\n            (data) = cls._create_brand_with_http_info(brand, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting an instance of Brand by its ID.", "response": "def delete_brand_by_id(cls, brand_id, **kwargs):\n        \"\"\"Delete Brand\n\n        Delete an instance of Brand by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_brand_by_id(brand_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str brand_id: ID of brand to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_brand_by_id_with_http_info(brand_id, **kwargs)\n        else:\n            (data) = cls._delete_brand_by_id_with_http_info(brand_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_brand_by_id(cls, brand_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_brand_by_id_with_http_info(brand_id, **kwargs)\n        else:\n            (data) = cls._get_brand_by_id_with_http_info(brand_id, **kwargs)\n            return data", "response": "Find Brand by ID Return single instance of Brand by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist Brands Return a list of Brands", "response": "def list_all_brands(cls, **kwargs):\n        \"\"\"List Brands\n\n        Return a list of Brands\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_brands(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Brand]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_brands_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_brands_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing all attributes of Brand AttributeNames with the given Brand.", "response": "def replace_brand_by_id(cls, brand_id, brand, **kwargs):\n        \"\"\"Replace Brand\n\n        Replace all attributes of Brand\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_brand_by_id(brand_id, brand, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str brand_id: ID of brand to replace (required)\n        :param Brand brand: Attributes of brand to replace (required)\n        :return: Brand\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_brand_by_id_with_http_info(brand_id, brand, **kwargs)\n        else:\n            (data) = cls._replace_brand_by_id_with_http_info(brand_id, brand, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate attributes of a brand.", "response": "def update_brand_by_id(cls, brand_id, brand, **kwargs):\n        \"\"\"Update Brand\n\n        Update attributes of Brand\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_brand_by_id(brand_id, brand, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str brand_id: ID of brand to update. (required)\n        :param Brand brand: Attributes of brand to update. (required)\n        :return: Brand\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_brand_by_id_with_http_info(brand_id, brand, **kwargs)\n        else:\n            (data) = cls._update_brand_by_id_with_http_info(brand_id, brand, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a clause to filter all bearers or targets for a given berarer or target.", "response": "def filter_(*permissions, **kwargs):\n    \"\"\"\n    Constructs a clause to filter all bearers or targets for a given\n    berarer or target.\n    \"\"\"\n    bearer = kwargs['bearer']\n    target = kwargs.get('target')\n    bearer_cls = type_for(bearer)\n\n    # We need a query object.  There are many ways to get one,  Either we can\n    # be passed one, or we can make one from the session.  We can either be\n    # passed the session, or we can grab the session from the bearer passed.\n\n    if 'query' in kwargs:\n        query = kwargs['query']\n    elif 'session' in kwargs:\n        query = kwargs['session'].query(target)\n    else:\n        query = object_session(bearer).query(target)\n\n    getter = functools.partial(\n        registry.retrieve,\n        bearer=bearer_cls,\n        target=target)\n\n    try:\n        # Generate a hash of {rulefn: permission} that we can use later\n        # to collect all of the rules.\n        if len(permissions):\n            rules = {getter(permission=x): x for x in permissions}\n        else:\n            rules = {getter(): None}\n    except KeyError:\n        # No rules defined.  Default to no permission.\n        return query.filter(sql.false())\n\n    # Invoke all the rules and collect the results\n\n    # Abusing reduce here to invoke each rule and send the return value (query)\n    # from one rule to the next one.  In this way the query becomes\n    # increasingly decorated as it marches through the system.\n\n    # q == query\n    # r = (rulefn, permission)\n    reducer = lambda q, r: r[0](permission=r[1], query=q, bearer=bearer)\n\n    return reduce(reducer, six.iteritems(rules), query)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if the passed bearer has the passed permissions.", "response": "def has(*permissions, **kwargs):\n    \"\"\"\n    Checks if the passed bearer has the passed permissions (optionally on\n    the passed target).\n    \"\"\"\n\n    target = kwargs['target']\n\n    kwargs['target'] = type_for(target)\n\n    # TODO: Predicate evaluation?\n    return target in filter_(*permissions, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_now_datetime_filestamp(longTime=False):\n    ## > IMPORTS ##\n    from datetime import datetime, date, time\n    now = datetime.now()\n    if longTime:\n        now = now.strftime(\"%Y%m%dt%H%M%S%f\")\n    else:\n        now = now.strftime(\"%Y%m%dt%H%M%S\")\n\n    return now", "response": "Returns a datetime stamp for the current file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_app(application, request_class=Request):\n\n    def wsgi(environ, start_response):\n        response = application.serve(\n            request=request_class(environ),\n            path=environ.get(\"PATH_INFO\", \"\"),\n        )\n        start_response(\n            response.status, [\n                (name, b\",\".join(values))\n                for name, values in response.headers.canonicalized()\n            ],\n        )\n        return [response.content]\n    return wsgi", "response": "Create a WSGI application out of the given Minion app."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_store_profile_by_id(cls, store_profile_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_store_profile_by_id_with_http_info(store_profile_id, **kwargs)\n        else:\n            (data) = cls._get_store_profile_by_id_with_http_info(store_profile_id, **kwargs)\n            return data", "response": "Find StoreProfile by ID Return single instance of StoreProfile with its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing all attributes of StoreProfile by ID", "response": "def replace_store_profile_by_id(cls, store_profile_id, store_profile, **kwargs):\n        \"\"\"Replace StoreProfile\n\n        Replace all attributes of StoreProfile\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_store_profile_by_id(store_profile_id, store_profile, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_profile_id: ID of storeProfile to replace (required)\n        :param StoreProfile store_profile: Attributes of storeProfile to replace (required)\n        :return: StoreProfile\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_store_profile_by_id_with_http_info(store_profile_id, store_profile, **kwargs)\n        else:\n            (data) = cls._replace_store_profile_by_id_with_http_info(store_profile_id, store_profile, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate attributes of StoreProfile by ID", "response": "def update_store_profile_by_id(cls, store_profile_id, store_profile, **kwargs):\n        \"\"\"Update StoreProfile\n\n        Update attributes of StoreProfile\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_store_profile_by_id(store_profile_id, store_profile, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_profile_id: ID of storeProfile to update. (required)\n        :param StoreProfile store_profile: Attributes of storeProfile to update. (required)\n        :return: StoreProfile\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_store_profile_by_id_with_http_info(store_profile_id, store_profile, **kwargs)\n        else:\n            (data) = cls._update_store_profile_by_id_with_http_info(store_profile_id, store_profile, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_documentation(self, request, *args, **kw):\n        ret = dict()\n        ret['resource'] = self.name()\n        ret['urls'] = self._get_url_doc()\n        ret['description'] = self.__doc__\n        ret['representation'] = self._get_representation_doc()\n        ret['methods'] = self._get_method_doc()\n        return ret", "response": "Generate the documentation for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _serialize_object(self, response_data, request):\n        if self._is_doc_request(request):\n            return response_data\n        else:\n            return super(DocumentedResource, self)._serialize_object(\n                response_data, request)", "response": "Override to not serialize doc responses."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride to not validate doc output.", "response": "def _validate_output_data(\n        self, original_res, serialized_res, formatted_res, request):\n        \"\"\" Override to not validate doc output. \"\"\"\n        if self._is_doc_request(request):\n            return\n        else:\n            return super(DocumentedResource, self)._validate_output_data(\n                original_res, serialized_res, formatted_res, request)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverriding to check if this is a documentation request.", "response": "def _get_method(self, request):\n        \"\"\" Override to check if this is a documentation request. \"\"\"\n        if self._is_doc_request(request):\n            return self.get_documentation\n        else:\n            return super(DocumentedResource, self)._get_method(request)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_representation_doc(self):\n        if not self.representation:\n            return 'N/A'\n        fields = {}\n        for name, field in self.representation.fields.items():\n            fields[name] = self._get_field_doc(field)\n        return fields", "response": "Return documentation for the representation of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns documentation for a field in the representation.", "response": "def _get_field_doc(self, field):\n        \"\"\" Return documentation for a field in the representation. \"\"\"\n        fieldspec = dict()\n        fieldspec['type'] = field.__class__.__name__\n        fieldspec['required'] = field.required\n        fieldspec['validators'] = [{validator.__class__.__name__: validator.__dict__} for validator in field.validators]\n        return fieldspec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_url_doc(self):\n        resolver = get_resolver(None)\n        possibilities = resolver.reverse_dict.getlist(self)\n        urls = [possibility[0] for possibility in possibilities]\n        return urls", "response": "Return a list of URLs that map to this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef clean(df,error_rate = 0):\n    df = df.copy()\n    \n    # Change colnames\n    basics.clean_colnames(df)\n    # Eventually use a more advanced function to clean colnames\n    print('Changed colnames to {}'.format(df.columns))\n    \n    # Remove extra whitespace\n    obj_col_list = df.select_dtypes(include = 'object').columns\n    for col_name in obj_col_list:\n        df[col_name] = basics.col_strip(df,col_name)\n        print(\"Stripped extra whitespace from '{}'\".format(col_name))\n    \n    # Coerce columns if possible\n    for col_name in obj_col_list:\n        new_dtype = coerce_col(df,col_name,error_rate)\n        if new_dtype is not None:\n            print(\"Coerced '{}' to datatype '{}'\".format(col_name, new_dtype))\n\n    # Scrub columns\n    obj_col_list = df.select_dtypes(include = 'object').columns\n    for col_name in obj_col_list:\n        scrubf, scrubb = smart_scrub(df,col_name,1-error_rate)\n        if scrubf is not None or scrubb is not None:\n            print(\"Scrubbed '{}' from the front and '{}' from the back of column '{}'\" \\\n                  .format(scrubf,scrubb,col_name))\n    \n    # Coerice columns if possible\n    for col_name in obj_col_list:\n        new_dtype = coerce_col(df,col_name,error_rate)\n        if new_dtype is not None:\n            print(\"Coerced '{}' to datatype '{}'\".format(col_name, new_dtype))  \n    return df", "response": "Clean the data of a single object tree tree"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a process using subprocess. Popen", "response": "def create_process(self, command, shell=True, stdout=None, stderr=None,\n                       env=None):\n        \"\"\"\n        Execute a process using subprocess.Popen, setting the backend's DISPLAY\n        \"\"\"\n        env = env if env is not None else dict(os.environ)\n        env['DISPLAY'] = self.display\n        return subprocess.Popen(command, shell=shell,\n                                stdout=stdout, stderr=stderr,\n                                env=env)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pause(self, instance_id, keep_provisioned=True):\n        try:\n            if self._paused:\n                log.debug(\"node %s is already paused\", instance_id)\n                return\n            self._paused = True\n            post_shutdown_action = 'Stopped' if keep_provisioned else \\\n                'StoppedDeallocated'\n            result = self._subscription._sms.shutdown_role(\n                service_name=self._cloud_service._name,\n                deployment_name=self._cloud_service._name,\n                role_name=self._qualified_name,\n                post_shutdown_action=post_shutdown_action)\n            self._subscription._wait_result(result)\n        except Exception as exc:\n            log.error(\"error pausing instance %s: %s\", instance_id, exc)\n            raise\n        log.debug('paused instance(instance_id=%s)', instance_id)", "response": "shuts down the instance without destroying it."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef restart(self, instance_id):\n        try:\n            if not self._paused:\n                log.debug(\"node %s is not paused, can't restart\", instance_id)\n                return\n            self._paused = False\n            result = self._subscription._sms.start_role(\n                service_name=self._cloud_service._name,\n                deployment_name=self._cloud_service._name,\n                role_name=instance_id)\n            self._subscription._wait_result(result)\n        except Exception as exc:\n            log.error('error restarting instance %s: %s', instance_id, exc)\n            raise\n        log.debug('restarted instance(instance_id=%s)', instance_id)", "response": "restart a paused instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart a new instance on the cloud using the given properties.", "response": "def start_instance(\n            self,\n            key_name,\n            public_key_path,\n            private_key_path,\n            security_group,\n            flavor,\n            image,\n            image_userdata,\n            location=None,\n            base_name=None,\n            username=None,\n            node_name=None,\n            host_name=None,\n            use_public_ips=None,\n            wait_timeout=None,\n            use_short_vm_names=None,\n            n_cloud_services=None,\n            n_storage_accounts=None,\n            **kwargs):\n        \"\"\"Starts a new instance on the cloud using the given properties.\n        Multiple instances might be started in different threads at the same\n        time. The implementation should handle any problems regarding this\n        itself.\n        :return: str - instance id of the started instance\n        \"\"\"\n\n        if self._start_failed:\n            raise Exception('start_instance for node %s: failing due to'\n                            ' previous errors.' % node_name)\n\n        index = None\n        with self._resource_lock:\n            # it'd be nice if elasticluster called something like\n            # init_cluster() with all the args that will be the\n            # same for every node created. But since it doesn't, handle that on\n            # first start_instance call.\n            if not self._cluster_prep_done:\n                self._times['CLUSTER_START'] = time.time()\n                self._config.setup(\n                    key_name,\n                    public_key_path,\n                    private_key_path,\n                    security_group,\n                    location,\n                    base_name=base_name,\n                    username=username,\n                    use_public_ips=use_public_ips,\n                    wait_timeout=wait_timeout,\n                    use_short_vm_names=use_short_vm_names,\n                    n_cloud_services=n_cloud_services,\n                    n_storage_accounts=n_storage_accounts,\n                    **kwargs)\n                # we know we're starting the first node, so create global\n                # requirements now\n                self._create_global_reqs()\n                if self._start_failed:\n                    return None\n                # this will allow vms to be created\n                self._times['SETUP_DONE'] = time.time()\n                self._cluster_prep_done = True\n\n            # absolute node index in cluster (0..n-1) determines what\n            # subscription, cloud service, storage\n            # account, etc. this VM will use. Create the vm and add it to\n            # its cloud service, then try to start it.\n            index = self._n_instances\n\n            v_m = AzureVM(\n                self._config,\n                index,\n                flavor=flavor,\n                image=image,\n                node_name=node_name,\n                host_name=host_name,\n                image_userdata=image_userdata)\n            v_m._cloud_service._instances[v_m._qualified_name] = v_m\n\n        try:\n            v_m._cloud_service._start_vm(v_m)\n        except Exception:\n            log.error(traceback.format_exc())\n            log.error(\"setting start_failed flag. Will not \"\n                      \"try to start further nodes.\")\n            self._start_failed = True\n            return None\n        log.debug('started instance %s', v_m._qualified_name)\n        if index == self._config._n_vms_requested - 1:\n            # all nodes started\n            self._times['NODES_STARTED'] = time.time()\n            self._times['SETUP_ELAPSED'] = self._times['SETUP_DONE'] - \\\n                self._times['CLUSTER_START']\n            self._times['NODE_START_ELAPSED'] = self._times['NODES_STARTED']\\\n                - self._times['SETUP_DONE']\n            self._times['CLUSTER_START_ELAPSED'] = \\\n                self._times['SETUP_ELAPSED'] + \\\n                self._times['NODE_START_ELAPSED']\n\n            log.debug(\"setup time: %.1f sec\", self._times['SETUP_ELAPSED'])\n            log.debug(\"node start time: %.1f sec (%.1f sec per vm)\",\n                      self._times['NODE_START_ELAPSED'],\n                      self._times['NODE_START_ELAPSED'] /\n                      self._config._n_vms_requested)\n            log.debug(\"total cluster start time: %.1f sec (%.1f sec per vm)\",\n                      self._times['CLUSTER_START_ELAPSED'],\n                      self._times['CLUSTER_START_ELAPSED'] /\n                      self._config._n_vms_requested)\n            # pause here to try to address the fact that Ansible setup fails\n            # more often on the first try than subsequent tries\n            time.sleep(_retry_sleep())\n        self._save_or_update()  # store our state\n        return v_m._qualified_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef stop_instance(self, instance_id):\n        self._restore_from_storage(instance_id)\n        if self._start_failed:\n            raise Exception('stop_instance for node %s: failing due to'\n                            ' previous errors.' % instance_id)\n\n        with self._resource_lock:\n            try:\n                v_m = self._qualified_name_to_vm(instance_id)\n                if not v_m:\n                    err = \"stop_instance: can't find instance %s\" % instance_id\n                    log.error(err)\n                    raise Exception(err)\n                v_m._cloud_service._stop_vm(v_m)\n                # note: self._n_instances is a derived property, doesn't need\n                # to be updated\n                if self._n_instances == 0:\n                    log.debug('last instance deleted, destroying '\n                              'global resources')\n                    self._delete_global_reqs()\n                    self._delete_cloud_provider_storage()\n            except Exception as exc:\n                log.error(traceback.format_exc())\n                log.error(\"error stopping instance %s: %s\", instance_id, exc)\n                raise\n        log.debug('stopped instance %s', instance_id)", "response": "Stops the instance gracefully."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the private and public ip addresses for a given instance.", "response": "def get_ips(self, instance_id):\n        \"\"\"Retrieves the private and public ip addresses for a given instance.\n        Note: Azure normally provides access to vms from a shared load\n        balancer IP and\n        mapping of ssh ports on the vms. So by default, the Azure provider\n        returns strings\n        of the form 'ip:port'. However, 'stock' elasticluster and ansible\n        don't support this,\n        so _use_public_ips uses Azure PublicIPs to expose each vm on the\n        internet with its own IP\n        and using the standard SSH port.\n\n        :return: list (IPs)\n        \"\"\"\n        self._restore_from_storage(instance_id)\n        if self._start_failed:\n            raise Exception('get_ips for node %s: failing due to'\n                            ' previous errors.' % instance_id)\n\n        ret = list()\n        v_m = self._qualified_name_to_vm(instance_id)\n        if not v_m:\n            raise Exception(\"Can't find instance_id %s\" % instance_id)\n        if self._config._use_public_ips:\n            ret.append(v_m._public_ip)\n        else:\n            ret.append(\"%s:%s\" % (v_m._public_ip, v_m._ssh_port))\n\n        log.debug('get_ips (instance %s) returning %s',\n                  instance_id, ', '.join(ret))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_instance_running(self, instance_id):\n        self._restore_from_storage(instance_id)\n        if self._start_failed:\n            raise Exception('is_instance_running for node %s: failing due to'\n                            ' previous errors.' % instance_id)\n        try:\n            v_m = self._qualified_name_to_vm(instance_id)\n            if not v_m:\n                raise Exception(\"Can't find instance_id %s\" % instance_id)\n        except Exception:\n            log.error(traceback.format_exc())\n            raise\n        return v_m._power_state == 'Started'", "response": "Checks if the instance is up and running."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _save_or_update(self):\n        with self._resource_lock:\n            if not self._config or not self._config._storage_path:\n                raise Exception(\"self._config._storage path is undefined\")\n            if not self._config._base_name:\n                raise Exception(\"self._config._base_name is undefined\")\n            if not os.path.exists(self._config._storage_path):\n                os.makedirs(self._config._storage_path)\n            path = self._get_cloud_provider_storage_path()\n            with open(path, 'wb') as storage:\n                pickle.dump(self._config, storage, pickle.HIGHEST_PROTOCOL)\n                pickle.dump(self._subscriptions, storage,\n                            pickle.HIGHEST_PROTOCOL)", "response": "Save or update the private state needed by the cloud provider."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_iter(src, sep=None, maxsplit=None):\n    if not is_iterable(src):\n        raise TypeError('expected an iterable')\n\n    if maxsplit is not None:\n        maxsplit = int(maxsplit)\n        if maxsplit == 0:\n            yield [src]\n            return\n\n    if callable(sep):\n        sep_func = sep\n    elif not is_scalar(sep):\n        sep = frozenset(sep)\n        sep_func = lambda x: x in sep\n    else:\n        sep_func = lambda x: x == sep\n\n    cur_group = []\n    split_count = 0\n    for s in src:\n        if maxsplit is not None and split_count >= maxsplit:\n            sep_func = lambda x: False\n        if sep_func(s):\n            if sep is None and not cur_group:\n                # If sep is none, str.split() \"groups\" separators\n                # check the str.split() docs for more info\n                continue\n            split_count += 1\n            yield cur_group\n            cur_group = []\n        else:\n            cur_group.append(s)\n\n    if cur_group or sep is not None:\n        yield cur_group\n    return", "response": "Splits an iterable into lists of lists."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef chunked(src, size, count=None, **kw):\n    chunk_iter = chunked_iter(src, size, **kw)\n    if count is None:\n        return list(chunk_iter)\n    else:\n        return list(itertools.islice(chunk_iter, count))", "response": "Returns a list of count chunks each with size elements generated from iterable src."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating size* - sized chunks from src iterable.", "response": "def chunked_iter(src, size, **kw):\n    \"\"\"Generates *size*-sized chunks from *src* iterable. Unless the\n    optional *fill* keyword argument is provided, iterables not even\n    divisible by *size* will have a final chunk that is smaller than\n    *size*.\n\n    >>> list(chunked_iter(range(10), 3))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n    >>> list(chunked_iter(range(10), 3, fill=None))\n    [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, None, None]]\n\n    Note that ``fill=None`` in fact uses ``None`` as the fill value.\n    \"\"\"\n    # TODO: add count kwarg?\n    if not is_iterable(src):\n        raise TypeError('expected an iterable')\n    size = int(size)\n    if size <= 0:\n        raise ValueError('expected a positive integer chunk size')\n    do_fill = True\n    try:\n        fill_val = kw.pop('fill')\n    except KeyError:\n        do_fill = False\n        fill_val = None\n    if kw:\n        raise ValueError('got unexpected keyword arguments: %r' % kw.keys())\n    if not src:\n        return\n    postprocess = lambda chk: chk\n    if isinstance(src, basestring):\n        postprocess = lambda chk, _sep=type(src)(): _sep.join(chk)\n    src_iter = iter(src)\n    while True:\n        cur_chunk = list(itertools.islice(src_iter, size))\n        if not cur_chunk:\n            break\n        lc = len(cur_chunk)\n        if lc < size and do_fill:\n            cur_chunk[lc:] = [fill_val] * (size - lc)\n        yield postprocess(cur_chunk)\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef windowed_iter(src, size):\n    # TODO: lists? (for consistency)\n    tees = itertools.tee(src, size)\n    try:\n        for i, t in enumerate(tees):\n            for _ in xrange(i):\n                next(t)\n    except StopIteration:\n        return izip([])\n    return izip(*tees)", "response": "Returns a generator that returns a sliding\n    window over iterable src."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xfrange(stop, start=None, step=1.0):\n    if not step:\n        raise ValueError('step must be non-zero')\n    if start is None:\n        start, stop = 0.0, stop * 1.0\n    else:\n        # swap when all args are used\n        stop, start = start * 1.0, stop * 1.0\n    cur = start\n    while cur < stop:\n        yield cur\n        cur += step", "response": "Generator - based version of xfrange."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef backoff(start, stop, count=None, factor=2.0, jitter=False):\n    if count == 'repeat':\n        raise ValueError(\"'repeat' supported in backoff_iter, not backoff\")\n    return list(backoff_iter(start, stop, count=count,\n                             factor=factor, jitter=jitter))", "response": "Returns a list of geometrically increasing floating - point numbers suitable for usage with exponential backoff."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backoff_iter(start, stop, count=None, factor=2.0, jitter=False):\n    start = float(start)\n    stop = float(stop)\n    factor = float(factor)\n    if start < 0.0:\n        raise ValueError('expected start >= 0, not %r' % start)\n    if factor < 1.0:\n        raise ValueError('expected factor >= 1.0, not %r' % factor)\n    if stop == 0.0:\n        raise ValueError('expected stop >= 0')\n    if stop < start:\n        raise ValueError('expected stop >= start, not %r' % stop)\n    if count is None:\n        denom = start if start else 1\n        count = 1 + math.ceil(math.log(stop/denom, factor))\n        count = count if start else count + 1\n    if count != 'repeat' and count < 0:\n        raise ValueError('count must be positive or \"repeat\", not %r' % count)\n    if jitter:\n        jitter = float(jitter)\n        if not (-1.0 <= jitter <= 1.0):\n            raise ValueError('expected jitter -1 <= j <= 1, not: %r' % jitter)\n\n    cur, i = start, 0\n    while count == 'repeat' or i < count:\n        if not jitter:\n            cur_ret = cur\n        elif jitter:\n            cur_ret = cur - (cur * jitter * random.random())\n        yield cur_ret\n        i += 1\n        if cur == 0:\n            cur = 1\n        elif cur < stop:\n            cur *= factor\n        if cur > stop:\n            cur = stop\n    return", "response": "A function that yields a sequence of geometrically increasing floats suitable for use with exponential backoff."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive an iterable of values in the source iterable by the value returned by key and a value_transform function and a key_filter function bucketize into a list of values.", "response": "def bucketize(src, key=None, value_transform=None, key_filter=None):\n    \"\"\"Group values in the *src* iterable by the value returned by *key*,\n    which defaults to :class:`bool`, grouping values by truthiness.\n\n    >>> bucketize(range(5))\n    {False: [0], True: [1, 2, 3, 4]}\n    >>> is_odd = lambda x: x % 2 == 1\n    >>> bucketize(range(5), is_odd)\n    {False: [0, 2, 4], True: [1, 3]}\n\n    Value lists are not deduplicated:\n\n    >>> bucketize([None, None, None, 'hello'])\n    {False: [None, None, None], True: ['hello']}\n\n    Bucketize into more than 3 groups\n\n    >>> bucketize(range(10), lambda x: x % 3)\n    {0: [0, 3, 6, 9], 1: [1, 4, 7], 2: [2, 5, 8]}\n\n    ``bucketize`` has a couple of advanced options useful in certain\n    cases.  *value_transform* can be used to modify values as they are\n    added to buckets, and *key_filter* will allow excluding certain\n    buckets from being collected.\n\n    >>> bucketize(range(5), value_transform=lambda x: x*x)\n    {False: [0], True: [1, 4, 9, 16]}\n\n    >>> bucketize(range(10), key=lambda x: x % 3, key_filter=lambda k: k % 3 != 1)\n    {0: [0, 3, 6, 9], 2: [2, 5, 8]}\n\n    Note in some of these examples there were at most two keys, ``True`` and\n    ``False``, and each key present has a list with at least one\n    item. See :func:`partition` for a version specialized for binary\n    use cases.\n\n    \"\"\"\n    if not is_iterable(src):\n        raise TypeError('expected an iterable')\n    if key is None:\n        key = bool\n    if not callable(key):\n        raise TypeError('expected callable key function')\n    if value_transform is None:\n        value_transform = lambda x: x\n    if not callable(value_transform):\n        raise TypeError('expected callable value transform function')\n\n    ret = {}\n    for val in src:\n        key_of_val = key(val)\n        if key_filter is None or key_filter(key_of_val):\n            ret.setdefault(key_of_val, []).append(value_transform(val))\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef partition(src, key=None):\n    bucketized = bucketize(src, key)\n    return bucketized.get(True, []), bucketized.get(False, [])", "response": "Return a tuple of the elements of src in order of their respective values."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nyielding unique elements from the iterable src based on key.", "response": "def unique_iter(src, key=None):\n    \"\"\"Yield unique elements from the iterable, *src*, based on *key*,\n    in the order in which they first appeared in *src*.\n\n    >>> repetitious = [1, 2, 3] * 10\n    >>> list(unique_iter(repetitious))\n    [1, 2, 3]\n\n    By default, *key* is the object itself, but *key* can either be a\n    callable or, for convenience, a string name of the attribute on\n    which to uniqueify objects, falling back on identity when the\n    attribute is not present.\n\n    >>> pleasantries = ['hi', 'hello', 'ok', 'bye', 'yes']\n    >>> list(unique_iter(pleasantries, key=lambda x: len(x)))\n    ['hi', 'hello', 'bye']\n    \"\"\"\n    if not is_iterable(src):\n        raise TypeError('expected an iterable, not %r' % type(src))\n    if key is None:\n        key_func = lambda x: x\n    elif callable(key):\n        key_func = key\n    elif isinstance(key, basestring):\n        key_func = lambda x: getattr(x, key, x)\n    else:\n        raise TypeError('\"key\" expected a string or callable, not %r' % key)\n    seen = set()\n    for i in src:\n        k = key_func(i)\n        if k not in seen:\n            seen.add(k)\n            yield i\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef one(src, default=None, key=None):\n    ones = list(itertools.islice(filter(key, src), 2))\n    return ones[0] if len(ones) == 1 else default", "response": "A function that returns the single object in src that evaluates to True as determined\n    by callable key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef same(iterable, ref=_UNSET):\n    iterator = iter(iterable)\n    if ref is _UNSET:\n        ref = next(iterator, ref)\n    return all(val == ref for val in iterator)", "response": "Returns a boolean value indicating whether all values in iterable are equal to one or more other values."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remap(root, visit=default_visit, enter=default_enter, exit=default_exit,\n          **kwargs):\n    \"\"\"The remap (\"recursive map\") function is used to traverse and\n    transform nested structures. Lists, tuples, sets, and dictionaries\n    are just a few of the data structures nested into heterogenous\n    tree-like structures that are so common in programming.\n    Unfortunately, Python's built-in ways to manipulate collections\n    are almost all flat. List comprehensions may be fast and succinct,\n    but they do not recurse, making it tedious to apply quick changes\n    or complex transforms to real-world data.\n\n    remap goes where list comprehensions cannot.\n\n    Here's an example of removing all Nones from some data:\n\n    >>> from pprint import pprint\n    >>> reviews = {'Star Trek': {'TNG': 10, 'DS9': 8.5, 'ENT': None},\n    ...            'Babylon 5': 6, 'Dr. Who': None}\n    >>> pprint(remap(reviews, lambda p, k, v: v is not None))\n    {'Babylon 5': 6, 'Star Trek': {'DS9': 8.5, 'TNG': 10}}\n\n    Notice how both Nones have been removed despite the nesting in the\n    dictionary. Not bad for a one-liner, and that's just the beginning.\n    See `this remap cookbook`_ for more delicious recipes.\n\n    .. _this remap cookbook: http://sedimental.org/remap.html\n\n    remap takes four main arguments: the object to traverse and three\n    optional callables which determine how the remapped object will be\n    created.\n\n    Args:\n\n        root: The target object to traverse. By default, remap\n            supports iterables like :class:`list`, :class:`tuple`,\n            :class:`dict`, and :class:`set`, but any object traversable by\n            *enter* will work.\n        visit (callable): This function is called on every item in\n            *root*. It must accept three positional arguments, *path*,\n            *key*, and *value*. *path* is simply a tuple of parents'\n            keys. *visit* should return the new key-value pair. It may\n            also return ``True`` as shorthand to keep the old item\n            unmodified, or ``False`` to drop the item from the new\n            structure. *visit* is called after *enter*, on the new parent.\n\n            The *visit* function is called for every item in root,\n            including duplicate items. For traversable values, it is\n            called on the new parent object, after all its children\n            have been visited. The default visit behavior simply\n            returns the key-value pair unmodified.\n        enter (callable): This function controls which items in *root*\n            are traversed. It accepts the same arguments as *visit*: the\n            path, the key, and the value of the current item. It returns a\n            pair of the blank new parent, and an iterator over the items\n            which should be visited. If ``False`` is returned instead of\n            an iterator, the value will not be traversed.\n\n            The *enter* function is only called once per unique value. The\n            default enter behavior support mappings, sequences, and\n            sets. Strings and all other iterables will not be traversed.\n        exit (callable): This function determines how to handle items\n            once they have been visited. It gets the same three\n            arguments as the other functions -- *path*, *key*, *value*\n            -- plus two more: the blank new parent object returned\n            from *enter*, and a list of the new items, as remapped by\n            *visit*.\n\n            Like *enter*, the *exit* function is only called once per\n            unique value. The default exit behavior is to simply add\n            all new items to the new parent, e.g., using\n            :meth:`list.extend` and :meth:`dict.update` to add to the\n            new parent. Immutable objects, such as a :class:`tuple` or\n            :class:`namedtuple`, must be recreated from scratch, but\n            use the same type as the new parent passed back from the\n            *enter* function.\n        reraise_visit (bool): A pragmatic convenience for the *visit*\n            callable. When set to ``False``, remap ignores any errors\n            raised by the *visit* callback. Items causing exceptions\n            are kept. See examples for more details.\n\n    remap is designed to cover the majority of cases with just the\n    *visit* callable. While passing in multiple callables is very\n    empowering, remap is designed so very few cases should require\n    passing more than one function.\n\n    When passing *enter* and *exit*, it's common and easiest to build\n    on the default behavior. Simply add ``from boltons.iterutils import\n    default_enter`` (or ``default_exit``), and have your enter/exit\n    function call the default behavior before or after your custom\n    logic. See `this example`_.\n\n    Duplicate and self-referential objects (aka reference loops) are\n    automatically handled internally, `as shown here`_.\n\n    .. _this example: http://sedimental.org/remap.html#sort_all_lists\n    .. _as shown here: http://sedimental.org/remap.html#corner_cases\n\n    \"\"\"\n    # TODO: improve argument formatting in sphinx doc\n    # TODO: enter() return (False, items) to continue traverse but cancel copy?\n    if not callable(visit):\n        raise TypeError('visit expected callable, not: %r' % visit)\n    if not callable(enter):\n        raise TypeError('enter expected callable, not: %r' % enter)\n    if not callable(exit):\n        raise TypeError('exit expected callable, not: %r' % exit)\n    reraise_visit = kwargs.pop('reraise_visit', True)\n    if kwargs:\n        raise TypeError('unexpected keyword arguments: %r' % kwargs.keys())\n\n    path, registry, stack = (), {}, [(None, root)]\n    new_items_stack = []\n    while stack:\n        key, value = stack.pop()\n        id_value = id(value)\n        if key is _REMAP_EXIT:\n            key, new_parent, old_parent = value\n            id_value = id(old_parent)\n            path, new_items = new_items_stack.pop()\n            value = exit(path, key, old_parent, new_parent, new_items)\n            registry[id_value] = value\n            if not new_items_stack:\n                continue\n        elif id_value in registry:\n            value = registry[id_value]\n        else:\n            res = enter(path, key, value)\n            try:\n                new_parent, new_items = res\n            except TypeError:\n                # TODO: handle False?\n                raise TypeError('enter should return a tuple of (new_parent,'\n                                ' items_iterator), not: %r' % res)\n            if new_items is not False:\n                # traverse unless False is explicitly passed\n                registry[id_value] = new_parent\n                new_items_stack.append((path, []))\n                if value is not root:\n                    path += (key,)\n                stack.append((_REMAP_EXIT, (key, new_parent, value)))\n                if new_items:\n                    stack.extend(reversed(list(new_items)))\n                continue\n        if visit is _orig_default_visit:\n            # avoid function call overhead by inlining identity operation\n            visited_item = (key, value)\n        else:\n            try:\n                visited_item = visit(path, key, value)\n            except Exception:\n                if reraise_visit:\n                    raise\n                visited_item = True\n            if visited_item is False:\n                continue  # drop\n            elif visited_item is True:\n                visited_item = (key, value)\n                # TODO: typecheck?\n                #    raise TypeError('expected (key, value) from visit(),'\n                #                    ' not: %r' % visited_item)\n        try:\n            new_items_stack[-1][1].append(visited_item)\n        except IndexError:\n            raise TypeError('expected remappable root, not: %r' % root)\n    return value", "response": "This function maps the object root to the object that is used by the remap function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a value from a nested object via a tuple representing the tree structure of the object.", "response": "def get_path(root, path, default=_UNSET):\n    \"\"\"Retrieve a value from a nested object via a tuple representing the\n    lookup path.\n\n    >>> root = {'a': {'b': {'c': [[1], [2], [3]]}}}\n    >>> get_path(root, ('a', 'b', 'c', 2, 0))\n    3\n\n    The path format is intentionally consistent with that of\n    :func:`remap`.\n\n    One of get_path's chief aims is improved error messaging. EAFP is\n    great, but the error messages are not.\n\n    For instance, ``root['a']['b']['c'][2][1]`` gives back\n    ``IndexError: list index out of range``\n\n    What went out of range where? get_path currently raises\n    ``PathAccessError: could not access 2 from path ('a', 'b', 'c', 2,\n    1), got error: IndexError('list index out of range',)``, a\n    subclass of IndexError and KeyError.\n\n    You can also pass a default that covers the entire operation,\n    should the lookup fail at any level.\n\n    Args:\n       root: The target nesting of dictionaries, lists, or other\n          objects supporting ``__getitem__``.\n       path (tuple): A list of strings and integers to be successively\n          looked up within *root*.\n       default: The value to be returned should any\n          ``PathAccessError`` exceptions be raised.\n    \"\"\"\n    if isinstance(path, basestring):\n        path = path.split('.')\n    cur = root\n    try:\n        for seg in path:\n            try:\n                cur = cur[seg]\n            except (KeyError, IndexError) as exc:\n                raise PathAccessError(exc, seg, path)\n            except TypeError as exc:\n                # either string index in a list, or a parent that\n                # doesn't support indexing\n                try:\n                    seg = int(seg)\n                    cur = cur[seg]\n                except (ValueError, KeyError, IndexError, TypeError):\n                    if not is_iterable(cur):\n                        exc = TypeError('%r object is not indexable'\n                                        % type(cur).__name__)\n                    raise PathAccessError(exc, seg, path)\n    except PathAccessError:\n        if default is _UNSET:\n            raise\n        return default\n    return cur"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef research(root, query=lambda p, k, v: True, reraise=False):\n    ret = []\n\n    if not callable(query):\n        raise TypeError('query expected callable, not: %r' % query)\n\n    def enter(path, key, value):\n        try:\n            if query(path, key, value):\n                ret.append((path + (key,), value))\n        except Exception:\n            if reraise:\n                raise\n        return default_enter(path, key, value)\n\n    remap(root, enter=enter)\n    return ret", "response": "This function recursively searches the given object for values which match a given criterion."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexpand all compound keys into nested dicts", "response": "def unflatten(data, separator='.', replace=True):\n    '''\n    Expand all compound keys (at any depth) into nested dicts\n\n        In [13]: d  = {'test.test2': {'k1.k2': 'val'}}\n        In [14]: flange.expand(d)\n        Out[14]: {'test.test2': {'k1': {'k2': 'val'}}}\n\n    :param data: input dict\n    :param separator: separator in compound keys\n    :param replace: if true, remove the compound key. Otherwise the value will\n    exist under the compound and expanded key\n    :return: copy of input dict with expanded keys\n    '''\n    if not separator:\n        return data\n    return remap({'temp':data}, visit=lambda p, k, v: __expand_keys(k, v, separator, replace))['temp']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __query(p, k, v, accepted_keys=None, required_values=None, path=None, exact=True):\n\n    # if not k:\n    #     print '__query p k:', p, k\n    # print p, k, accepted_keys, required_values, path, exact\n    def as_values_iterable(v):\n        if isinstance(v, dict):\n            return v.values()\n        elif isinstance(v, six.string_types):\n            return [v]\n        else:\n            # assume is already some iterable type\n            return v\n\n    if path and path != p:\n        return False\n\n    if accepted_keys:\n        if isinstance(accepted_keys, six.string_types):\n            accepted_keys = [accepted_keys]\n        if len([akey for akey in accepted_keys if akey == k or (not exact and akey in k)]) == 0:\n            return False\n\n    if required_values:\n        if isinstance(required_values, six.string_types):\n            required_values = [required_values]\n        # Find all terms in the vfilter that have a match somewhere in the values of the v dict. If the\n        # list is shorter than vfilter then some terms did not match and this v fails the test.\n        if len(required_values) > len([term for term in required_values for nv in as_values_iterable(v) if term == nv or (not exact and term in nv)]):\n            return False\n\n    return True", "response": "Query function given to visit method\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_customer_group(cls, customer_group, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_customer_group_with_http_info(customer_group, **kwargs)\n        else:\n            (data) = cls._create_customer_group_with_http_info(customer_group, **kwargs)\n            return data", "response": "Create a new CustomerGroup with the specified attributes. This method creates a new customerGroup with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an instance of CustomerGroup by its ID.", "response": "def delete_customer_group_by_id(cls, customer_group_id, **kwargs):\n        \"\"\"Delete CustomerGroup\n\n        Delete an instance of CustomerGroup by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_customer_group_by_id(customer_group_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str customer_group_id: ID of customerGroup to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_customer_group_by_id_with_http_info(customer_group_id, **kwargs)\n        else:\n            (data) = cls._delete_customer_group_by_id_with_http_info(customer_group_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_customer_group_by_id(cls, customer_group_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_customer_group_by_id_with_http_info(customer_group_id, **kwargs)\n        else:\n            (data) = cls._get_customer_group_by_id_with_http_info(customer_group_id, **kwargs)\n            return data", "response": "Find CustomerGroup by its ID Return single instance of CustomerGroup by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_customer_groups(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_customer_groups_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_customer_groups_with_http_info(**kwargs)\n            return data", "response": "List CustomerGroups\n        Return a list of CustomerGroups\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_customer_group_by_id(cls, customer_group_id, customer_group, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_customer_group_by_id_with_http_info(customer_group_id, customer_group, **kwargs)\n        else:\n            (data) = cls._replace_customer_group_by_id_with_http_info(customer_group_id, customer_group, **kwargs)\n            return data", "response": "Replace all attributes of CustomerGroup by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_customer_group_by_id(cls, customer_group_id, customer_group, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_customer_group_by_id_with_http_info(customer_group_id, customer_group, **kwargs)\n        else:\n            (data) = cls._update_customer_group_by_id_with_http_info(customer_group_id, customer_group, **kwargs)\n            return data", "response": "Update attributes of CustomerGroup by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect to the cloud web services.", "response": "def _connect(self):\n        \"\"\"Connects to the cloud web services. If this is the first\n        authentication, a web browser will be started to authenticate\n        against google and provide access to elasticluster.\n\n        :return: A Resource object with methods for interacting with the\n                 service.\n        \"\"\"\n        # check for existing connection\n        with GoogleCloudProvider.__gce_lock:\n            if self._gce:\n                return self._gce\n\n            flow = OAuth2WebServerFlow(self._client_id, self._client_secret,\n                                       GCE_SCOPE)\n            # The `Storage` object holds the credentials that your\n            # application needs to authorize access to the user's\n            # data. The name of the credentials file is provided. If the\n            # file does not exist, it is created. This object can only\n            # hold credentials for a single user. It stores the access\n            # priviledges for the application, so a user only has to grant\n            # access through the web interface once.\n            storage_path = os.path.join(self._storage_path,\n                                        self._client_id + '.oauth.dat')\n            storage = Storage(storage_path)\n\n            credentials = storage.get()\n            if credentials is None or credentials.invalid:\n                args = argparser.parse_args([])\n                args.noauth_local_webserver = self._noauth_local_webserver\n                # try to start a browser to have the user authenticate with Google\n                # TODO: what kind of exception is raised if the browser\n                #       cannot be started?\n                try:\n                    credentials = run_flow(flow, storage, flags=args)\n                except:\n                    import sys\n                    print \"Unexpected error:\", sys.exc_info()[0]\n                    raise\n\n            http = httplib2.Http()\n            self._auth_http = credentials.authorize(http)\n\n            self._gce = build(GCE_API_NAME, GCE_API_VERSION, http=http)\n\n            return self._gce"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstart a new instance with the given properties and returns the instance id.", "response": "def start_instance(self,\n                       # these are common to any\n                       # CloudProvider.start_instance() call\n                       key_name, public_key_path, private_key_path,\n                       security_group, flavor, image_id, image_userdata,\n                       username=None,\n                       # these params are specific to the\n                       # GoogleCloudProvider\n                       node_name=None,\n                       boot_disk_type='pd-standard',\n                       boot_disk_size=10,\n                       tags=None,\n                       scheduling=None,\n                       **kwargs):\n        \"\"\"Starts a new instance with the given properties and returns\n        the instance id.\n\n        :param str key_name: name of the ssh key to connect\n        :param str public_key_path: path to ssh public key\n        :param str private_key_path: path to ssh private key\n        :param str security_group: firewall rule definition to apply on the\n                                   instance\n        :param str flavor: machine type to use for the instance\n        :param str image_id: image type (os) to use for the instance\n        :param str image_userdata: command to execute after startup\n        :param str username: username for the given ssh key, default None\n        :param str node_name: name of the instance\n        :param str tags: comma-separated list of \"tags\" to label the instance\n        :param str scheduling: scheduling option to use for the instance (\"preemptible\")\n        :param str|Sequence tags: \"Tags\" to label the instance.\n\n        Can be either a single string (individual tags are comma-separated),\n        or a sequence of strings (each string being a single tag).\n\n        :return: str - instance id of the started instance\n        \"\"\"\n        # construct URLs\n        project_url = '%s%s' % (GCE_URL, self._project_id)\n        machine_type_url = '%s/zones/%s/machineTypes/%s' \\\n                           % (project_url, self._zone, flavor)\n        boot_disk_type_url = '%s/zones/%s/diskTypes/%s' \\\n                           % (project_url, self._zone, boot_disk_type)\n        # FIXME: `conf.py` should ensure that `boot_disk_size` has the right\n        # type, so there would be no need to convert here\n        boot_disk_size_gb = int(boot_disk_size)\n        network_url = '%s/global/networks/%s' % (project_url, self._network)\n        if image_id.startswith('http://') or image_id.startswith('https://'):\n            image_url = image_id\n        else:\n            # The image names and full resource URLs for several Google-\n            # provided images (debian, centos, etc.) follow a consistent\n            # pattern, and so elasticluster supports a short-hand of just\n            # an image name, such as\n            #   \"debian-7-wheezy-v20150526\".\n            # The cloud project in this case is then \"debian-cloud\".\n            #\n            # Several images do not follow this convention, and so are\n            # special-cased here:\n            #   backports-debian -> debian-cloud\n            #   ubuntu           -> ubuntu-os-cloud\n            #   containter-vm    -> google-containers\n            if image_id.startswith('container-vm-'):\n              os_cloud = 'google-containers'\n            elif image_id.startswith('backports-debian-'):\n              os_cloud = 'debian-cloud'\n            elif image_id.startswith('ubuntu-'):\n              os_cloud = 'ubuntu-os-cloud'\n            else:\n              os = image_id.split(\"-\")[0]\n              os_cloud = \"%s-cloud\" % os\n\n            image_url = '%s%s/global/images/%s' % (\n                GCE_URL, os_cloud, image_id)\n\n        if scheduling is None:\n            # use GCE's default\n            scheduling_option = {}\n        elif scheduling == 'preemptible':\n            scheduling_option = {\n              'preemptible': True\n            }\n        else:\n            raise InstanceError(\"Unknown scheduling option: '%s'\" % scheduling)\n\n        if isinstance(tags, types.StringTypes):\n            tags = tags.split(',')\n        elif isinstance(tags, collections.Sequence):\n            # ok, nothing to do\n            pass\n        elif tags is not None:\n            raise TypeError(\n                \"The `tags` argument to `gce.start_instance`\"\n                \" should be a string or a list, got {T} instead\"\n                .format(T=type(tags)))\n\n        # construct the request body\n        if node_name:\n            instance_id = node_name.lower().replace('_', '-')  # GCE doesn't allow \"_\"\n        else:\n            instance_id = 'elasticluster-%s' % uuid.uuid4()\n\n        with open(public_key_path, 'r') as f:\n            public_key_content = f.read()\n\n        instance = {\n            'name': instance_id,\n            'machineType': machine_type_url,\n            'tags': {\n              'items': tags,\n            },\n            'scheduling': scheduling_option,\n            'disks': [{\n                'autoDelete': 'true',\n                'boot': 'true',\n                'type': 'PERSISTENT',\n                'initializeParams' : {\n                    'diskName': \"%s-disk\" % instance_id,\n                    'diskType': boot_disk_type_url,\n                    'diskSizeGb': boot_disk_size_gb,\n                    'sourceImage': image_url\n                    }\n                }],\n            'networkInterfaces': [\n                {'accessConfigs': [\n                    {'type': 'ONE_TO_ONE_NAT',\n                     'name': 'External NAT'\n                    }],\n                 'network': network_url\n                }],\n            'serviceAccounts': [\n                {'email': self._email,\n                 'scopes': GCE_DEFAULT_SCOPES\n                }],\n            \"metadata\": {\n                \"kind\": \"compute#metadata\",\n                \"items\": [\n                    {\n                        \"key\": \"sshKeys\",\n                        \"value\": \"%s:%s\" % (username, public_key_content)\n                    }\n                ]\n            }\n        }\n\n        # create the instance\n        gce = self._connect()\n        request = gce.instances().insert(\n            project=self._project_id, body=instance, zone=self._zone)\n        try:\n            response = self._execute_request(request)\n            response = self._wait_until_done(response)\n            self._check_response(response)\n            return instance_id\n        except (HttpError, CloudProviderError) as e:\n            log.error(\"Error creating instance `%s`\" % e)\n            raise InstanceError(\"Error creating instance `%s`\" % e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_image_url(self, image_id):\n        gce = self._connect()\n        filter = \"name eq %s\" % image_id\n        request = gce.images().list(project=self._project_id, filter=filter)\n        response = self._execute_request(request)\n        response = self._wait_until_done(response)\n\n        image_url = None\n        if \"items\" in response:\n            image_url = response[\"items\"][0][\"selfLink\"]\n\n        if image_url:\n            return image_url\n        else:\n            raise ImageError(\"Could not find given image id `%s`\" % image_id)", "response": "Gets the url for the specified image."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef select_event(\n    event                             = None,\n    selection                         = \"all\",\n    required_variables                = None,\n    ensure_required_variables_present = False,\n    verbose                           = True\n    ):\n\n    \"\"\"\n    Select a HEP event.\n    \"\"\"\n\n    if required_variables is None:\n        required_variables = [\n            \"Aplan_bjets\",\n            \"Aplan_jets\",\n            \"Centrality_all\",\n            \"ClassifBDTOutput_6jsplit\",\n            \"ClassifBDTOutput_basic\",\n            \"ClassifBDTOutput_withReco_6jsplit\",\n            \"ClassifBDTOutput_withReco_basic\",\n            \"ClassifHPLUS_Semilep_HF_BDT200_Output\",\n            \"dEtajj_MaxdEta\",\n            \"dRbb_avg\",\n            \"dRbb_MaxM\",\n            \"dRbb_MaxPt\",\n            \"dRbb_min\",\n            \"dRbj_Wmass\",\n            \"dRHl_MaxdR\",\n            \"dRHl_MindR\",\n            \"dRjj_min\",\n            \"dRlepbb_MindR\",\n            \"dRlj_MindR\",\n            \"dRuu_MindR\",\n            \"H1_all\",\n            \"H4_all\",\n            \"HhadT_nJets\",\n            \"HiggsbbM\",\n            \"HiggsjjM\",\n            \"HT_all\",\n            \"HT_jets\",\n            \"Mbb_MaxM\",\n            \"Mbb_MaxPt\",\n            \"Mbb_MindR\",\n            \"Mbj_MaxPt\",\n            \"Mbj_MindR\",\n            \"Mbj_Wmass\",\n            \"met_met\",\n            \"met_phi\",\n            \"MHiggs\",\n            \"Mjj_HiggsMass\",\n            \"Mjjj_MaxPt\",\n            \"Mjj_MaxPt\",\n            \"Mjj_MindR\",\n            \"Mjj_MinM\",\n            \"mu\",\n            \"Muu_MindR\",\n            \"NBFricoNN_dil\",\n            \"nBTags\",\n            \"nBTags30\",\n            \"nBTags50\",\n            \"nBTags60\",\n            \"nBTags70\",\n            \"nBTags77\",\n            \"nBTags80\",\n            \"nBTags85\",\n            \"nBTags90\",\n            \"nBTagsFlatBEff_30\",\n            \"nBTagsFlatBEff_40\",\n            \"nBTagsFlatBEff_50\",\n            \"nBTagsFlatBEff_60\",\n            \"nBTagsFlatBEff_70\",\n            \"nBTagsFlatBEff_77\",\n            \"nBTagsFlatBEff_85\",\n            \"nElectrons\",\n            \"nHFJets\",\n            \"NHiggs_30\",\n            \"Njet_pt40\",\n            \"Njet_pt40\",\n            \"nJets\",\n            \"nMuons\",\n            \"nPrimaryVtx\",\n            \"pT_jet3\",\n            \"pT_jet5\",\n            \"pTuu_MindR\",\n            \"semilepMVAreco_b1higgsbhadtop_dR\",\n            \"semilepMVAreco_bbhiggs_dR\",\n            \"semilepMVAreco_BDT_output\",\n            \"semilepMVAreco_BDT_output_6jsplit\",\n            \"semilepMVAreco_BDT_output_truthMatchPattern\",\n            \"semilepMVAreco_BDT_withH_output\",\n            \"semilepMVAreco_BDT_withH_output_6jsplit\",\n            \"semilepMVAreco_BDT_withH_output_truthMatchPattern\",\n            \"semilepMVAreco_hadWb1Higgs_mass\",\n            \"semilepMVAreco_higgsbhadtop_withH_dR\",\n            \"semilepMVAreco_higgsbleptop_mass\",\n            \"semilepMVAreco_higgsbleptop_withH_dR\",\n            \"semilepMVAreco_higgslep_dR\",\n            \"semilepMVAreco_higgsleptop_dR\",\n            \"semilepMVAreco_higgs_mass\",\n            \"semilepMVAreco_higgsq1hadW_mass\",\n            \"semilepMVAreco_higgsttbar_withH_dR\",\n            \"semilepMVAreco_leptophadtop_dR\",\n            \"semilepMVAreco_leptophadtop_withH_dR\",\n            \"semilepMVAreco_Ncombinations\",\n            \"semilepMVAreco_nuApprox_recoBDT\",\n            \"semilepMVAreco_nuApprox_recoBDT_6jsplit\",\n            \"semilepMVAreco_nuApprox_recoBDT_withH\",\n            \"semilepMVAreco_nuApprox_recoBDT_withH_6jsplit\",\n            \"semilepMVAreco_ttH_Ht_withH\",\n            #\"ttHF_mva_discriminant\",\n            \"el_d0sig[0]\",\n            \"el_delta_z0_sintheta[0]\",\n            \"el_e[0]\",\n            \"el_eta[0]\",\n            \"el_phi[0]\",\n            \"el_pt[0]\",\n            \"el_topoetcone20[0]\",\n            #\"mu_d0sig[0]\",\n            #\"mu_delta_z0_sintheta[0]\",\n            #\"mu_e[0]\",\n            #\"mu_eta[0]\",\n            #\"mu_phi[0]\",\n            #\"mu_pt[0]\",\n            \"mu_topoetcone20[0]\",\n            \"jet_e[0]\",\n            \"jet_eta[0]\",\n            \"jet_jvt[0]\",\n            \"jet_mv2c10[0]\",\n            \"jet_mv2c20[0]\",\n            \"jet_phi[0]\",\n            \"jet_pt[0]\",\n            \"jet_semilepMVAreco_recoBDT_cand[0]\",\n            \"jet_semilepMVAreco_recoBDT_cand_6jsplit[0]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand[0]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand_6jsplit[0]\",\n            \"jet_e[1]\",\n            \"jet_eta[1]\",\n            \"jet_jvt[1]\",\n            \"jet_mv2c10[1]\",\n            \"jet_mv2c20[1]\",\n            \"jet_phi[1]\",\n            \"jet_pt[1]\",\n            \"jet_semilepMVAreco_recoBDT_cand[1]\",\n            \"jet_semilepMVAreco_recoBDT_cand_6jsplit[1]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand[1]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand_6jsplit[1]\",\n            \"jet_e[2]\",\n            \"jet_eta[2]\",\n            \"jet_jvt[2]\",\n            \"jet_mv2c10[2]\",\n            \"jet_mv2c20[2]\",\n            \"jet_phi[2]\",\n            \"jet_pt[2]\",\n            \"jet_semilepMVAreco_recoBDT_cand[2]\",\n            \"jet_semilepMVAreco_recoBDT_cand_6jsplit[2]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand[2]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand_6jsplit[2]\",\n            \"jet_e[3]\",\n            \"jet_eta[3]\",\n            \"jet_jvt[3]\",\n            \"jet_mv2c10[3]\",\n            \"jet_mv2c20[3]\",\n            \"jet_phi[3]\",\n            \"jet_pt[3]\",\n            \"jet_semilepMVAreco_recoBDT_cand[3]\",\n            \"jet_semilepMVAreco_recoBDT_cand_6jsplit[3]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand[3]\",\n            \"jet_semilepMVAreco_recoBDT_withH_cand_6jsplit[3]\"\n        ]\n\n    if ensure_required_variables_present and not all([hasattr(event, variable) for variable in required_variables]):\n\n        return False\n\n    #for variable in required_variables:\n    #    if not hasattr(event, variable):\n    #        print(\"missing {variable}\".format(variable = variable))\n\n    # By default, do not pass.\n    conditions = [False]\n\n    if selection == \"ejets\":\n\n        conditions = [\n            event.nElectrons == 1,                      # Require 1 electron.\n            event.nJets >= 4,                           # Require >= 4 jets.\n            #event.nLjets >= 1                          # Require a single large-R jet.\n        ]\n\n    elif selection == \"mujets\":\n\n        conditions = [\n            event.nMuons == 1,                          # Require 1 muon.\n            event.nJets >= 4,                           # Require >= 4 jets.\n            #event.nLjets >= 1                          # Require a single large-R jet.\n        ]\n\n    if selection == \"ejets_5JE4BI\":\n\n        conditions = [\n            event.nElectrons == 1,                      # Require 1 electron.\n            event.nJets == 5,                           # Require 5 jets.\n            event.nBTags >= 4                           # Require >= 4 b tags.\n            #event.nLjets >= 1                          # Require a single large-R jet.\n        ]\n\n    if selection == \"ejets_6JI4BI\":\n\n        conditions = [\n            event.nElectrons == 1,                      # Require 1 electron.\n            event.nJets >= 6,                           # Require >=6 jets.\n            event.nBTags >= 4                           # Require >= 4 b tags.\n            #event.nLjets >= 1                          # Require a single large-R jet.\n        ]\n\n    elif selection == \"all\":\n\n        conditions = [\n            event.nElectrons == 1 or event.nMuons == 1, # Require 1 electron or 1 muon.\n            event.nJets >= 4,                           # Require >= 4 jets.\n            #event.nLjets >= 1                          # Require a single large-R jet.\n        ]\n\n    if all(conditions):\n\n        if verbose:\n            log.info(\"event number {event_number} passed selection {selection}\".format(\n                event_number = event.eventNumber,\n                selection    = selection\n            ))\n\n        return True\n\n    else:\n\n        return False", "response": "Select a HEP event from the given set of variables."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_free_shipping(cls, free_shipping, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_free_shipping_with_http_info(free_shipping, **kwargs)\n        else:\n            (data) = cls._create_free_shipping_with_http_info(free_shipping, **kwargs)\n            return data", "response": "Create a new FreeShipping object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes FreeShipping by ID.", "response": "def delete_free_shipping_by_id(cls, free_shipping_id, **kwargs):\n        \"\"\"Delete FreeShipping\n\n        Delete an instance of FreeShipping by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_free_shipping_by_id(free_shipping_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_id: ID of freeShipping to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_free_shipping_by_id_with_http_info(free_shipping_id, **kwargs)\n        else:\n            (data) = cls._delete_free_shipping_by_id_with_http_info(free_shipping_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind FreeShipping by ID Return single instance of FreeShipping with the given ID.", "response": "def get_free_shipping_by_id(cls, free_shipping_id, **kwargs):\n        \"\"\"Find FreeShipping\n\n        Return single instance of FreeShipping by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_free_shipping_by_id(free_shipping_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_id: ID of freeShipping to return (required)\n        :return: FreeShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_free_shipping_by_id_with_http_info(free_shipping_id, **kwargs)\n        else:\n            (data) = cls._get_free_shipping_by_id_with_http_info(free_shipping_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist FreeShippings Return a list of FreeShippings", "response": "def list_all_free_shippings(cls, **kwargs):\n        \"\"\"List FreeShippings\n\n        Return a list of FreeShippings\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_free_shippings(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[FreeShipping]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_free_shippings_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_free_shippings_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_free_shipping_by_id(cls, free_shipping_id, free_shipping, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_free_shipping_by_id_with_http_info(free_shipping_id, free_shipping, **kwargs)\n        else:\n            (data) = cls._replace_free_shipping_by_id_with_http_info(free_shipping_id, free_shipping, **kwargs)\n            return data", "response": "Replace FreeShipping by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates attributes of FreeShipping objects by ID", "response": "def update_free_shipping_by_id(cls, free_shipping_id, free_shipping, **kwargs):\n        \"\"\"Update FreeShipping\n\n        Update attributes of FreeShipping\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_free_shipping_by_id(free_shipping_id, free_shipping, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_shipping_id: ID of freeShipping to update. (required)\n        :param FreeShipping free_shipping: Attributes of freeShipping to update. (required)\n        :return: FreeShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_free_shipping_by_id_with_http_info(free_shipping_id, free_shipping, **kwargs)\n        else:\n            (data) = cls._update_free_shipping_by_id_with_http_info(free_shipping_id, free_shipping, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the URL to HTTP enabled ( published ) dataset.", "response": "def publish(dataset_uri):\n    \"\"\"Return access URL to HTTP enabled (published) dataset.\n\n    Exits with error code 1 if the dataset_uri is not a dataset.\n    Exits with error code 2 if the dataset cannot be HTTP enabled.\n    \"\"\"\n\n    try:\n        dataset = dtoolcore.DataSet.from_uri(dataset_uri)\n    except dtoolcore.DtoolCoreTypeError:\n        print(\"Not a dataset: {}\".format(dataset_uri))\n        sys.exit(1)\n\n    try:\n        access_uri = dataset._storage_broker.http_enable()\n    except AttributeError:\n        print(\n            \"Datasets of type '{}' cannot be published using HTTP\".format(\n                dataset._storage_broker.key)\n        )\n        sys.exit(2)\n\n    return access_uri"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli():\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"dataset_uri\",\n        help=\"Dtool dataset URI\"\n    )\n    parser.add_argument(\n        \"-q\",\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"Only return the http URI\"\n    )\n    args = parser.parse_args()\n    access_uri = publish(args.dataset_uri)\n\n    if args.quiet:\n        print(access_uri)\n    else:\n        print(\"Dataset accessible at: {}\".format(access_uri))", "response": "Command line utility to HTTP enable a dataset."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the cluster and build a GC3Pie configuration snippet.", "response": "def execute(self):\n        \"\"\"\n        Load the cluster and build a GC3Pie configuration snippet.\n        \"\"\"\n        creator = make_creator(self.params.config,\n                               storage_path=self.params.storage)\n        cluster_name = self.params.cluster\n        try:\n            cluster = creator.load_cluster(cluster_name)\n        except (ClusterNotFound, ConfigurationError) as ex:\n            log.error(\"Listing nodes from cluster %s: %s\\n\" %\n                      (cluster_name, ex))\n            return\n\n        from elasticluster.gc3pie_config import create_gc3pie_config_snippet\n\n        if self.params.append:\n            path = os.path.expanduser(self.params.append)\n            try:\n                fd = open(path, 'a')\n                fd.write(create_gc3pie_config_snippet(cluster))\n                fd.close()\n            except IOError as ex:\n                log.error(\"Unable to write configuration to file %s: %s\",\n                          path, ex)\n        else:\n            print(create_gc3pie_config_snippet(cluster))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the Media RSS Feed s XML representation to the given file.", "response": "def write_xml(self, outfile, encoding=\"UTF-8\"):\n        \"\"\"Write the Media RSS Feed's XML representation to the given file.\"\"\"\n        # we add the media namespace if we see any media items\n        if any([key for item in self.items for key in vars(item) if\n                key.startswith('media_') and getattr(item, key)]):\n            self.rss_attrs[\"xmlns:media\"] = \"http://search.yahoo.com/mrss/\"\n        self.generator = _generator_name\n        super(MediaRSS2, self).write_xml(outfile, encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding an attribute to the MediaContent element.", "response": "def _add_attribute(self, name, value, allowed_values=None):\n        \"\"\"Add an attribute to the MediaContent element.\"\"\"\n        if value and value != 'none':\n\n            if isinstance(value, (int, bool)):\n                value = str(value)\n\n            if allowed_values and value not in allowed_values:\n                raise TypeError(\n                    \"Attribute '\" + name + \"' must be one of \" + str(\n                        allowed_values) + \" but is '\" + str(value) + \"'\")\n\n            self.element_attrs[name] = value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking compliance with Media RSS Specification Version 1. 5. 1.", "response": "def check_complicance(self):\n        \"\"\"Check compliance with Media RSS Specification, Version 1.5.1.\n\n        see http://www.rssboard.org/media-rss\n        Raises AttributeError on error.\n        \"\"\"\n        # check Media RSS requirement: one of the following elements is\n        # required: media_group | media_content | media_player | media_peerLink\n        # | media_location. We do the check only if any media_... element is\n        # set to allow non media feeds\n        if(any([ma for ma in vars(self)\n                if ma.startswith('media_') and getattr(self, ma)])\n           and not self.media_group\n           and not self.media_content\n           and not self.media_player\n           and not self.media_peerLink\n           and not self.media_location\n           ):\n            raise AttributeError(\n                \"Using media elements requires the specification of at least \"\n                \"one of the following elements: 'media_group', \"\n                \"'media_content', 'media_player', 'media_peerLink' or \"\n                \"'media_location'.\")\n\n        # check Media RSS requirement: if media:player is missing all\n        # media_content elements need to have url attributes.\n        if not self.media_player:\n            if self.media_content:\n                # check if all media_content elements have a URL set\n                if isinstance(self.media_content, list):\n                    if not all([False for mc in self.media_content if\n                                'url' not in mc.element_attrs]):\n                        raise AttributeError(\n                            \"MediaRSSItems require a media_player attribute \"\n                            \"if a media_content has no url set.\")\n                else:\n                    if not self.media_content.element_attrs['url']:\n                        raise AttributeError(\n                            \"MediaRSSItems require a media_player attribute \"\n                            \"if a media_content has no url set.\")\n                pass\n            elif self.media_group:\n                # check media groups without player if its media_content\n                # elements have a URL set\n                raise NotImplementedError(\n                    \"MediaRSSItem: media_group check not implemented yet.\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef publish_extensions(self, handler):\n        if isinstance(self.media_content, list):\n            [PyRSS2Gen._opt_element(handler, \"media:content\", mc_element) for\n             mc_element in self.media_content]\n        else:\n            PyRSS2Gen._opt_element(handler, \"media:content\",\n                                   self.media_content)\n\n        if hasattr(self, 'media_title'):\n            PyRSS2Gen._opt_element(handler, \"media:title\", self.media_title)\n\n        if hasattr(self, 'media_text'):\n            PyRSS2Gen._opt_element(handler, \"media:text\", self.media_text)", "response": "Publish the Media RSS Feed elements as XML."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conversations(self):\n        cs = self.data[\"data\"]\n        res = []\n        for c in cs:\n            res.append(Conversation(c))\n        return res", "response": "Returns list of Conversation objects representing the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _accumulate(iterable, func=(lambda a,b:a+b)): # this was from the itertools documentation\n    'Return running totals'\n    # accumulate([1,2,3,4,5]) --> 1 3 6 10 15\n    # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120\n    it = iter(iterable)\n    try:\n        total = next(it)\n    except StopIteration:\n        return\n    yield total\n    for element in it:\n        total = func(total, element)\n        yield total", "response": "A generator that accumulates the total value of the given iterable."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nuses this to bulk add new methods to Generator", "response": "def add_methods(methods_to_add):\n        ''' use this to bulk add new methods to Generator '''\n        for i in methods_to_add:\n            try:\n                Generator.add_method(*i)\n            except Exception as ex:\n                raise Exception('issue adding {} - {}'.format(repr(i), ex))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walklevel(path, depth = -1, **kwargs):\n        # if depth is negative, just walk\n        if depth < 0:\n            for root, dirs, files in os.walk(path, **kwargs):\n                yield root, dirs, files\n\n        # path.count works because is a file has a \"/\" it will show up in the list\n        # as a \":\"\n        path    = path.rstrip(os.path.sep)\n        num_sep = path.count(os.path.sep)\n        for root, dirs, files in os.walk(path, **kwargs):\n            yield root, dirs, files\n            num_sep_this = root.count(os.path.sep)\n            if num_sep + depth <= num_sep_this:\n                del dirs[:]", "response": "A recursive version of os. walk that returns a list of all the entries in the directory tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tree_probe(self, **kwargs):\n\n        str_topDir  = \".\"\n        l_dirs      = []\n        l_files     = []\n        b_status    = False\n        str_path    = ''\n        l_dirsHere  = []\n        l_filesHere = []\n\n        for k, v in kwargs.items():\n            if k == 'root':  str_topDir  = v\n\n        # for root, dirs, files in os.walk(str_topDir, followlinks = self.b_followLinks):\n        for root, dirs, files in pftree.walklevel(str_topDir,\n                                                  self.maxdepth, \n                                                  followlinks = self.b_followLinks):\n            b_status = True\n            str_path = root.split(os.sep)\n            if dirs:\n                l_dirsHere = [root + '/' + x for x in dirs]\n                l_dirs.append(l_dirsHere)\n                self.dp.qprint('Appending dirs to search space:\\n', level = 3)\n                self.dp.qprint(\"\\n\" + self.pp.pformat(l_dirsHere),  level = 3)\n            if files:\n                l_filesHere = [root + '/' + y for y in files]\n                if len(self.str_inputFile):\n                    l_hit = [s for s in l_filesHere if self.str_inputFile in s]\n                    if l_hit: \n                        l_filesHere = l_hit\n                    else:\n                        l_filesHere = []\n                if l_filesHere:\n                    l_files.append(l_filesHere)\n                self.dp.qprint('Appending files to search space:\\n', level = 3)\n                self.dp.qprint(\"\\n\" + self.pp.pformat(l_filesHere),  level = 3)\n        return {\n            'status':   b_status,\n            'l_dir':    l_dirs,\n            'l_files':  l_files\n        }", "response": "Perform an os walk down a file system tree and return lists of files and directories found."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses the <l_files> list of files from the tree_probe() and builds the input/output dictionary structures. Optionally execute a constructCallback function, and return results", "response": "def tree_construct(self, *args, **kwargs):\n        \"\"\"\n        Processes the <l_files> list of files from the tree_probe()\n        and builds the input/output dictionary structures.\n\n        Optionally execute a constructCallback function, and return\n        results\n        \"\"\"\n        l_files                 = []\n        d_constructCallback     = {}\n        fn_constructCallback    = None\n        for k, v in kwargs.items():\n            if k == 'l_files':           l_files                 = v\n            if k == 'constructCallback': fn_constructCallback    = v\n\n        index   = 1\n        total   = len(l_files)\n        for l_series in l_files:\n            str_path    = os.path.dirname(l_series[0])\n            l_series    = [ os.path.basename(i) for i in l_series]\n            self.simpleProgress_show(index, total)\n            self.d_inputTree[str_path]  = l_series\n            if fn_constructCallback:\n                kwargs['path']          = str_path\n                d_constructCallback     = fn_constructCallback(l_series, **kwargs)\n                self.d_inputTreeCallback[str_path]  = d_constructCallback\n            self.d_outputTree[str_path] = \"\"\n            index += 1\n        return {\n            'status':                   True,\n            'd_constructCalback':       d_constructCallback,   \n            'totalNumberOfAllSeries':   index\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dirsize_get(l_filesWithoutPath, **kwargs):\n\n        str_path    = \"\"\n        for k,v in kwargs.items():\n            if k == 'path': str_path = v\n\n        d_ret   = {}\n        l_size  = []\n        size    = 0\n        for f in l_filesWithoutPath:\n            str_f   = '%s/%s' % (str_path, f)\n            if not os.path.islink(str_f):\n                try:\n                    size += os.path.getsize(str_f)\n                except:\n                    pass\n        str_size    = pftree.sizeof_fmt(size)\n\n        return {\n            'status':           True,\n            'diskUsage_raw':    size,\n            'diskUsage_human':  str_size\n        }", "response": "Sample callback that determines a directory size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stats_compute(self, *args, **kwargs):\n        totalElements   = 0\n        totalKeys       = 0\n        totalSize       = 0\n        l_stats         = []\n        d_report        = {}\n\n        for k, v in sorted(self.d_inputTreeCallback.items(), \n                            key         = lambda kv: (kv[1]['diskUsage_raw']),\n                            reverse     = self.b_statsReverse):\n            str_report  = \"files: %5d; raw size: %12d; human size: %8s; %s\" % (\\\n                    len(self.d_inputTree[k]), \n                    self.d_inputTreeCallback[k]['diskUsage_raw'], \n                    self.d_inputTreeCallback[k]['diskUsage_human'], \n                    k)\n            d_report = {\n                'files':            len(self.d_inputTree[k]),\n                'diskUsage_raw':    self.d_inputTreeCallback[k]['diskUsage_raw'],\n                'diskUsage_human':  self.d_inputTreeCallback[k]['diskUsage_human'],\n                'path':             k\n            }\n            self.dp.qprint(str_report, level = 1)\n            l_stats.append(d_report)\n            totalElements   += len(v)\n            totalKeys       += 1\n            totalSize       += self.d_inputTreeCallback[k]['diskUsage_raw']\n        str_totalSize_human = self.sizeof_fmt(totalSize)\n        return {\n            'status':           True,\n            'dirs':             totalKeys,\n            'files':            totalElements,\n            'totalSize':        totalSize,\n            'totalSize_human':  str_totalSize_human,\n            'l_stats':          l_stats,\n            'runTime':          other.toc()\n        }", "response": "This method is used to compute the stats of the internal dictionary and return a dictionary with the stats of the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inputReadCallback(self, *args, **kwargs):\n        b_status    = True\n        filesRead   = 0\n\n        for k, v in kwargs.items():\n            if k == 'l_file':   l_file      = v\n            if k == 'path':     str_path    = v\n\n        if len(args):\n            at_data         = args[0]\n            str_path        = at_data[0]\n            l_file          = at_data[1]\n\n        self.dp.qprint(\"reading (in path %s):\\n%s\" % \n                            (str_path, \n                            self.pp.pformat(l_file)), \n                            level = 5)\n        filesRead   = len(l_file)\n\n        if not len(l_file): b_status = False\n\n        return {\n            'status':           b_status,\n            'l_file':           l_file,\n            'str_path':         str_path,\n            'filesRead':        filesRead\n        }", "response": "Test for inputReadCallback that checks if the input files are read and returns the passed file list back to \n        caller\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntesting method for inputAnalyzeCallback", "response": "def inputAnalyzeCallback(self, *args, **kwargs):\n        \"\"\"\n        Test method for inputAnalzeCallback\n\n        This method loops over the passed number of files, \n        and optionally \"delays\" in each loop to simulate\n        some analysis. The delay length is specified by\n        the '--test <delay>' flag.\n\n        \"\"\"\n        b_status            = False\n        filesRead           = 0\n        filesAnalyzed       = 0\n\n        for k, v in kwargs.items():\n            if k == 'filesRead':    d_DCMRead   = v\n            if k == 'path':         str_path    = v\n\n        if len(args):\n            at_data         = args[0]\n            str_path        = at_data[0]\n            d_read          = at_data[1]\n\n        b_status        = True\n        self.dp.qprint(\"analyzing:\\n%s\" % \n                                self.pp.pformat(d_read['l_file']), \n                                level = 5)\n        if int(self.f_sleepLength):\n            self.dp.qprint(\"sleeping for: %f\" % self.f_sleepLength, level = 5)\n            time.sleep(self.f_sleepLength)\n        filesAnalyzed   = len(d_read['l_file'])\n\n        return {\n            'status':           b_status,\n            'filesAnalyzed':    filesAnalyzed,\n            'l_file':           d_read['l_file']\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the tree and print the result.", "response": "def run(self, *args, **kwargs):\n        \"\"\"\n        Probe the input tree and print.\n        \"\"\"\n        b_status        = True\n        d_probe         = {}\n        d_tree          = {}\n        d_stats         = {}\n        str_error       = ''\n        b_timerStart    = False\n        d_test          = {}\n\n        for k, v in kwargs.items():\n            if k == 'timerStart':   b_timerStart    = bool(v)\n\n        if b_timerStart:\n            other.tic()\n\n        if not os.path.exists(self.str_inputDir):\n            b_status    = False\n            self.dp.qprint(\n                    \"input directory either not specified or does not exist.\", \n                    comms = 'error'\n            )\n            error.warn(self, 'inputDirFail', exitToOS = True, drawBox = True)\n            str_error   = 'error captured while accessing input directory'\n\n        if b_status:\n            str_origDir = os.getcwd()\n            if self.b_relativeDir:\n                os.chdir(self.str_inputDir)\n                str_rootDir     = '.'\n            else:\n                str_rootDir     = self.str_inputDir\n\n            d_probe     = self.tree_probe(      \n                root    = str_rootDir\n            )\n            b_status    = b_status and d_probe['status']\n            d_tree      = self.tree_construct(  \n                l_files             = d_probe['l_files'],\n                constructCallback   = self.dirsize_get\n            )\n            b_status    = b_status and d_tree['status']\n\n            if self.b_test:\n                d_test      = self.test_run(*args, **kwargs)\n                b_status    = b_status and d_test['status']\n            else:\n                if self.b_stats or self.b_statsReverse:\n                    d_stats     = self.stats_compute()\n                    self.dp.qprint('Total size (raw):   %d' % d_stats['totalSize'],         level = 1)\n                    self.dp.qprint('Total size (human): %s' % d_stats['totalSize_human'],   level = 1)\n                    self.dp.qprint('Total files:        %s' % d_stats['files'],             level = 1)\n                    self.dp.qprint('Total dirs:         %s' % d_stats['dirs'],              level = 1)\n                    b_status    = b_status and d_stats['status']\n\n            if self.b_jsonStats:\n                print(json.dumps(d_stats, indent = 4, sort_keys = True))\n\n            if self.b_relativeDir:\n                os.chdir(str_origDir)\n\n        d_ret = {\n            'status':       b_status,\n            'd_probe':      d_probe,\n            'd_tree':       d_tree,\n            'd_stats':      d_stats,\n            'd_test':       d_test,\n            'str_error':    str_error,\n            'runTime':      other.toc()\n        }\n\n        if self.b_json:\n            print(json.dumps(d_ret, indent = 4, sort_keys = True))\n\n        return d_ret"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if all required parameters are set", "response": "def check_required_params(self):\n        \"\"\" Check if all required parameters are set\"\"\"\n        for param in self.REQUIRED_FIELDS:\n            if param not in self.params:\n                raise ValidationError(\"Missing parameter: {} for {}\".format(\n                    param, self.__class__.path\n                ))\n\n        for child in self.TASKS:\n            for param in child.REQUIRED_FIELDS:\n                if param not in self.params:\n                    raise ValidationError(\n                        \"Missing parameter: {} for {}\".format(param, child.path)\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _set_status(self, status, result=None):\n        logger.info(\n            \"{}.SetStatus: {}[{}] status update '{}' -> '{}'\".format(\n                self.__class__.__name__, self.__class__.path, self.uuid,\n                self.status, status\n            ),\n            extra=dict(\n                kmsg=Message(\n                    self.uuid, entrypoint=self.__class__.path,\n                    params=self.params\n                ).dump()\n            )\n        )\n        return self.set_status(status, result)", "response": "update status of the object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _prerun(self):\n        self.check_required_params()\n        self._set_status(\"RUNNING\")\n        logger.debug(\n            \"{}.PreRun: {}[{}]: running...\".format(\n                self.__class__.__name__, self.__class__.path, self.uuid\n            ),\n            extra=dict(\n                kmsg=Message(\n                    self.uuid, entrypoint=self.__class__.path,\n                    params=self.params\n                ).dump()\n            )\n        )\n        return self.prerun()", "response": "To execute before running message\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _onerror(self, result):\n        self._set_status(\"FAILED\", result)\n        logger.error(\n            \"{}.Failed: {}[{}]: {}\".format(\n                self.__class__.__name__, self.__class__.path, self.uuid, result\n            ),\n            extra=dict(\n                kmsg=Message(\n                    self.uuid, entrypoint=self.__class__.path,\n                    params=self.params\n                ).dump(),\n                kresult=ResultSchema().dump(result) if result else dict()\n            )\n        )\n        return self.onerror(result)", "response": "To execute on execution failure\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump operation Arc Arc", "response": "def display(self):\n        \"\"\" dump operation\n\n        \"\"\"\n        print(\"{}\".format(self))\n        for task in self.tasks:\n            print(\"  - {}\".format(task))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next(self, task):\n        uuid = str(task.uuid)\n        for idx, otask in enumerate(self.tasks[:-1]):\n            if otask.uuid == uuid:\n                if self.tasks[idx + 1].status != 'SUCCESS':\n                    return self.tasks[idx + 1]\n                else:\n                    uuid = self.tasks[idx + 1].uuid", "response": "Find the next task in the list of available task tables."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef launch_next(self, task=None, result=None):\n        if task:\n            next_task = self.next(task)\n            if next_task:\n                return next_task.send(result=result)\n            else:\n                return self.set_status(task.status, result)\n        elif len(self.tasks) > 0:\n            return self.tasks[0].send(result=result)\n        else:\n            return Result(retcode=1, stderr=\"Nothing to do, empty operation !\")", "response": "Launch next task or finish operation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_tasks(self, **kwargs):\n        params = self._prebuild(**kwargs)\n        if not params:\n            params = dict(kwargs)\n\n        return self._build_tasks(**params)", "response": "perfrom checks and build tasks\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef build(self, **kwargs):\n        self.tasks += self.compute_tasks(**kwargs)\n        return self.finalize()", "response": "create the operation and associate tasks\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nserves the datasets in a directory over HTTP.", "response": "def serve_dtool_directory(directory, port):\n    \"\"\"Serve the datasets in a directory over HTTP.\"\"\"\n    os.chdir(directory)\n    server_address = (\"localhost\", port)\n    httpd = DtoolHTTPServer(server_address, DtoolHTTPRequestHandler)\n    httpd.serve_forever()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cli():\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\n        \"dataset_directory\",\n        help=\"Directory with datasets to be served\"\n    )\n    parser.add_argument(\n        \"-p\",\n        \"--port\",\n        type=int,\n        default=8081,\n        help=\"Port to serve datasets on (default 8081)\"\n    )\n    args = parser.parse_args()\n    if not os.path.isdir(args.dataset_directory):\n        parser.error(\"Not a directory: {}\".format(args.dataset_directory))\n\n    serve_dtool_directory(args.dataset_directory, args.port)", "response": "Command line utility for serving datasets in a directory over HTTP."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_url(self, suffix):\n        url_base_path = os.path.dirname(self.path)\n        netloc = \"{}:{}\".format(*self.server.server_address)\n        return urlunparse((\n            \"http\",\n            netloc,\n            url_base_path + \"/\" + suffix,\n            \"\", \"\", \"\"))", "response": "Return URL by combining server details with a path suffix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns dict with identifier and URL pairs for the dataset items.", "response": "def generate_item_urls(self):\n        \"\"\"Return dict with identifier/URL pairs for the dataset items.\"\"\"\n        item_urls = {}\n        for i in self.dataset.identifiers:\n            relpath = self.dataset.item_properties(i)[\"relpath\"]\n            url = self.generate_url(\"data/\" + relpath)\n            item_urls[i] = url\n        return item_urls"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_overlay_urls(self):\n        overlays = {}\n        for o in self.dataset.list_overlay_names():\n            url = self.generate_url(\".dtool/overlays/{}.json\".format(o))\n            overlays[o] = url\n        return overlays", "response": "Return dict with overlay and URL pairs for the dataset overlays."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating the http manifest.", "response": "def generate_http_manifest(self):\n        \"\"\"Return http manifest.\n\n        The http manifest is the resource that defines a dataset as HTTP\n        enabled (published).\n        \"\"\"\n        base_path = os.path.dirname(self.translate_path(self.path))\n        self.dataset = dtoolcore.DataSet.from_uri(base_path)\n\n        admin_metadata_fpath = os.path.join(base_path, \".dtool\", \"dtool\")\n        with open(admin_metadata_fpath) as fh:\n            admin_metadata = json.load(fh)\n\n        http_manifest = {\n            \"admin_metadata\": admin_metadata,\n            \"manifest_url\": self.generate_url(\".dtool/manifest.json\"),\n            \"readme_url\": self.generate_url(\"README.yml\"),\n            \"overlays\": self.generate_overlay_urls(),\n            \"item_urls\": self.generate_item_urls()\n        }\n        return bytes(json.dumps(http_manifest), \"utf-8\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\noverrides inherited do_GET method. Include logic for returning a http manifest when the URL ends with \"http_manifest.json\".", "response": "def do_GET(self):\n        \"\"\"Override inherited do_GET method.\n\n        Include logic for returning a http manifest when the URL ends with\n        \"http_manifest.json\".\n        \"\"\"\n        if self.path.endswith(\"http_manifest.json\"):\n            try:\n                manifest = self.generate_http_manifest()\n                self.send_response(200)\n                self.end_headers()\n                self.wfile.write(manifest)\n            except dtoolcore.DtoolCoreTypeError:\n                self.send_response(400)\n                self.end_headers()\n\n        else:\n            super(DtoolHTTPRequestHandler, self).do_GET()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nindents a python s famous indent.", "response": "def indent(self, code, level=1):\r\n    '''python's famous indent'''\r\n    lines = code.split('\\n')\r\n    lines = tuple(self.indent_space*level + line for line in lines)\r\n    return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_database_connection(\n        pathToYamlFile):\n    \"\"\"*Start a database connection using settings in yaml file* \n\n    Given the location of a YAML dictionary containing database credientials, this function will setup and return the connection*\n\n    **Key Arguments:**\n        - ``pathToYamlFile`` -- path to the YAML dictionary.\n\n    **Return:**\n        - ``dbConn`` -- connection to the MySQL database.\n\n    **Usage:**\n\n        The settings file should be in this form, with all keyword values set:\n\n        .. code-block:: yaml\n\n            db: dryx_unit_testing\n            host: localhost\n            user: unittesting\n            password: utpass\n\n        And here's how to generate the connection object:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import setup_database_connection\n            dbConn = setup_database_connection(\n                pathToYamlFile=pathToMyYamlFile\n            )\n    \"\"\"\n    import sys\n    import logging\n    import pymysql as ms\n\n    # IMPORT THE YAML CONNECTION DICTIONARY\n    try:\n        logging.info(\n            'importing the yaml database connection dictionary from ' + pathToYamlFile)\n        stream = file(pathToYamlFile, 'r')\n        connDict = yaml.load(stream)\n    except:\n        logging.critical(\n            'could not load the connect dictionary from ' + pathToYamlFile)\n        sys.exit(1)\n    # ESTABLISH A DB CONNECTION\n    try:\n        logging.info('connecting to the ' + connDict[\n                     'db'] + ' database on ' + connDict['host'])\n        dbConn = ms.connect(\n            host=connDict['host'],\n            user=connDict['user'],\n            passwd=connDict['password'],\n            db=connDict['db'],\n            use_unicode=True,\n            charset='utf8',\n            local_infile=1,\n            client_flag=ms.constants.CLIENT.MULTI_STATEMENTS,\n            connect_timeout=36000\n        )\n        dbConn.autocommit(True)\n    except Exception as e:\n        logging.critical('could not connect to the ' + connDict['db'] + ' database on ' + connDict['host'] + ' : '\n                         + str(e) + '\\n')\n    return dbConn", "response": "This function will setup a MySQL connection using the settings in the file containing database credientials."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new OrderLineItem with the specified attributes.", "response": "def create_order_line_item(cls, order_line_item, **kwargs):\n        \"\"\"Create OrderLineItem\n\n        Create a new OrderLineItem\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_order_line_item(order_line_item, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param OrderLineItem order_line_item: Attributes of orderLineItem to create (required)\n        :return: OrderLineItem\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_order_line_item_with_http_info(order_line_item, **kwargs)\n        else:\n            (data) = cls._create_order_line_item_with_http_info(order_line_item, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an order line item by its ID.", "response": "def delete_order_line_item_by_id(cls, order_line_item_id, **kwargs):\n        \"\"\"Delete OrderLineItem\n\n        Delete an instance of OrderLineItem by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_order_line_item_by_id(order_line_item_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_line_item_id: ID of orderLineItem to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_order_line_item_by_id_with_http_info(order_line_item_id, **kwargs)\n        else:\n            (data) = cls._delete_order_line_item_by_id_with_http_info(order_line_item_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind OrderLineItem by ID Return single instance of OrderLineItem", "response": "def get_order_line_item_by_id(cls, order_line_item_id, **kwargs):\n        \"\"\"Find OrderLineItem\n\n        Return single instance of OrderLineItem by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_order_line_item_by_id(order_line_item_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_line_item_id: ID of orderLineItem to return (required)\n        :return: OrderLineItem\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_order_line_item_by_id_with_http_info(order_line_item_id, **kwargs)\n        else:\n            (data) = cls._get_order_line_item_by_id_with_http_info(order_line_item_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_all_order_line_items(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_order_line_items_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_order_line_items_with_http_info(**kwargs)\n            return data", "response": "List OrderLineItems\n        Return a list of OrderLineItems\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreplace OrderLineItem by ID", "response": "def replace_order_line_item_by_id(cls, order_line_item_id, order_line_item, **kwargs):\n        \"\"\"Replace OrderLineItem\n\n        Replace all attributes of OrderLineItem\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_order_line_item_by_id(order_line_item_id, order_line_item, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_line_item_id: ID of orderLineItem to replace (required)\n        :param OrderLineItem order_line_item: Attributes of orderLineItem to replace (required)\n        :return: OrderLineItem\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_order_line_item_by_id_with_http_info(order_line_item_id, order_line_item, **kwargs)\n        else:\n            (data) = cls._replace_order_line_item_by_id_with_http_info(order_line_item_id, order_line_item, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_order_line_item_by_id(cls, order_line_item_id, order_line_item, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_order_line_item_by_id_with_http_info(order_line_item_id, order_line_item, **kwargs)\n        else:\n            (data) = cls._update_order_line_item_by_id_with_http_info(order_line_item_id, order_line_item, **kwargs)\n            return data", "response": "Update attributes of OrderLineItem by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_grammar_generating(grammar, remove=False):\n        # type: (Grammar, bool) -> bool\n        \"\"\"\n        Check if is grammar is generating.\n        Generating grammar generates at least one sentence.\n        :param grammar: Grammar to check.\n        :param remove: True to remove nongenerating symbols from the grammar.\n        :return: True if is grammar generating, false otherwise.\n        \"\"\"\n        g = ContextFree.remove_nongenerating_nonterminals(grammar, remove)\n        return g.start is not None", "response": "Checks if a grammar is generating at least one sentence."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_useless_symbols(grammar, inplace=False):\n        # type: (Grammar, bool) -> Grammar\n        \"\"\"\n        Remove useless symbols from the grammar.\n        Useless symbols are unreachable or nongenerating one.\n        :param grammar: Grammar where to symbols remove\n        :param inplace: True if transformation should be performed in place, false otherwise.\n        False by default.\n        :return: Grammar without useless symbols.\n        \"\"\"\n        grammar = ContextFree.remove_nongenerating_nonterminals(grammar, inplace)\n        grammar = ContextFree.remove_unreachable_symbols(grammar, True)\n        return grammar", "response": "Removes useless symbols from the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef prepare_for_cyk(grammar, inplace=False):\n        # type: (Grammar, bool) -> Grammar\n        \"\"\"\n        Take common context-free grammar and perform all the necessary steps to use it in the CYK algorithm.\n        Performs following steps:\n        - remove useless symbols\n        - remove rules with epsilon\n        - remove unit rules\n        - remove useless symbols once more (as previous steps could change the grammar)\n        - transform it to Chomsky Normal Form\n        :param grammar: Grammar to transform.\n        :param inplace: True if the operation should be done in place. False by default.\n        :return: Modified grammar.\n        \"\"\"\n        grammar = ContextFree.remove_useless_symbols(grammar, inplace)\n        grammar = ContextFree.remove_rules_with_epsilon(grammar, True)\n        grammar = ContextFree.remove_unit_rules(grammar, True)\n        grammar = ContextFree.remove_useless_symbols(grammar, True)\n        grammar = ContextFree.transform_to_chomsky_normal_form(grammar, True)\n        return grammar", "response": "Prepares a common context - free grammar for use in the CYK algorithm."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving authorization code to get access token", "response": "def retrieve_authorization_code(self, redirect_func=None):\n        \"\"\" retrieve authorization code to get access token\n        \"\"\"\n        \n        request_param = {\n            \"client_id\": self.client_id,\n            \"redirect_uri\": self.redirect_uri,\n            }\n\n        if self.scope:\n            request_param['scope'] = self.scope\n\n        if self._extra_auth_params:\n            request_param.update(self._extra_auth_params)\n\n        r = requests.get(self.auth_uri, params=request_param,\n                         allow_redirects=False)\n        url = r.headers.get('location') \n        if self.local:\n            webbrowser.open_new_tab(url)\n            authorization_code = raw_input(\"Code: \")\n            if self.validate_code(authorization_code):\n                self.authorization_code = authorization_code\n        else:\n            return redirect_func(url)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef retrieve_token(self):\n\n        if self.authorization_code:\n            request_param = {\n                \"client_id\": self.client_id,\n                \"client_secret\": self.client_secret,\n                \"redirect_uri\": self.redirect_uri,\n                \"code\": self.authorization_code\n                }\n\n            if self._extra_token_params:\n                request_param.update(self._extra_token_params)\n\n            content_length = len(urlencode(request_param))\n            headers = {\n                'Content-Length': str(content_length),\n                'Content-Type': 'application/x-www-form-urlencoded'\n                }\n        \n            r = requests.post(self.token_uri, data=request_param,\n                              headers=headers)\n            jsondata = json.loads(r.text)\n            self.access_token = jsondata\n            return self.access_token\n\n        else:\n            print(\"authorization code is required before getting accesss token\")\n            print(\"Please call retrieve_authorization_code() beforehand\")", "response": "retrieve access token with code fetched via \n        retrieve_authorization_code method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrepresenting the setup section in form of key - value pairs.", "response": "def to_dict(self):\n        '''Represents the setup section in form of key-value pairs.\n\n        Returns\n        -------\n        dict\n        '''\n        mapping = dict()\n        for attr in dir(self):\n            if attr.startswith('_'):\n                continue\n            if not isinstance(getattr(self.__class__, attr), property):\n                continue\n            try:\n                value = getattr(self, attr)\n            except AttributeError:\n                if attr in self._OPTIONAL_ATTRS:\n                    continue\n                else:\n                    raise AttributeError(\n                        'Required attribute \"{0}\" does not exist on '\n                        'instance of type \"{1}.'.format(\n                            attr, self.__class__.__name__\n                        )\n                    )\n            mapping[attr] = value\n        return mapping"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tm_group(self):\n        '''str: TissueMAPS system group (defaults to\n        :attr:`tm_user <tmdeploy.config.AnsibleHostVariableSection.tm_user>`)\n        '''\n        if self._tm_group is None:\n            self._tm_group = self.tm_user\n        return self._tm_group", "response": "str - TissueMAPS system group"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef db_group(self):\n        '''str: database system group (defaults to\n        :attr:`db_user <tmdeploy.config.AnsibleHostVariableSection.db_user>`)\n        '''\n        if self._db_group is None:\n            self._db_group = self.db_user\n        return self._db_group", "response": "str: database system group"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mtime(path):\n    if not os.path.exists(path):\n        return -1\n    stat = os.stat(path)\n    return stat.st_mtime", "response": "Get the modification time of a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrequest a resource form the API.", "response": "def get_cached(path, cache_name=None, **kwargs):\n    \"\"\"Request a resource form the API, first checking if there is a cached\n    response available. Returns the parsed JSON data.\n    \"\"\"\n    if gw2api.cache_dir and gw2api.cache_time and cache_name is not False:\n        if cache_name is None:\n            cache_name = path\n        cache_file = os.path.join(gw2api.cache_dir, cache_name)\n        if mtime(cache_file) >= time.time() - gw2api.cache_time:\n            with open(cache_file, \"r\") as fp:\n                return json.load(fp)\n    else:\n        cache_file = None\n\n    r = gw2api.session.get(gw2api.BASE_URL + path, **kwargs)\n\n    if not r.ok:\n        try:\n            response = r.json()\n        except ValueError:  # pragma: no cover\n            response = None\n        if isinstance(response, dict) and \"text\" in response:\n            r.reason = response[\"text\"]\n\n    r.raise_for_status()\n    data = r.json()\n\n    if cache_file:\n        with open(cache_file, \"w\") as fp:\n            json.dump(data, fp, indent=2)\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencoding a chat link for an item or a stack of items.", "response": "def encode_item_link(item_id, number=1, skin_id=None,\n                     upgrade1=None, upgrade2=None):\n    \"\"\"Encode a chat link for an item (or a stack of items).\n\n    :param item_id: the Id of the item\n    :param number: the number of items in the stack\n    :param skin_id: the id of the skin applied to the item\n    :param upgrade1: the id of the first upgrade component\n    :param upgrade2: the id of the second upgrade component\n    \"\"\"\n    return encode_chat_link(gw2api.TYPE_ITEM, id=item_id, number=number,\n                            skin_id=skin_id, upgrade1=upgrade1,\n                            upgrade2=upgrade2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_coin_link(copper, silver=0, gold=0):\n    return encode_chat_link(gw2api.TYPE_COIN, copper=copper, silver=silver,\n                            gold=gold)", "response": "Encode a chat link for an amount of coins."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the status of this StoreCreditPayment.", "response": "def status(self, status):\n        \"\"\"Sets the status of this StoreCreditPayment.\n\n\n        :param status: The status of this StoreCreditPayment.\n        :type: str\n        \"\"\"\n        allowed_values = [\"pending\", \"awaitingRetry\", \"successful\", \"failed\"]\n        if status is not None and status not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `status` ({0}), must be one of {1}\"\n                .format(status, allowed_values)\n            )\n\n        self._status = status"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_store_credit_payment(cls, store_credit_payment, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_store_credit_payment_with_http_info(store_credit_payment, **kwargs)\n        else:\n            (data) = cls._create_store_credit_payment_with_http_info(store_credit_payment, **kwargs)\n            return data", "response": "Create a new StoreCreditPayment object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_store_credit_payment_by_id(cls, store_credit_payment_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_store_credit_payment_by_id_with_http_info(store_credit_payment_id, **kwargs)\n        else:\n            (data) = cls._delete_store_credit_payment_by_id_with_http_info(store_credit_payment_id, **kwargs)\n            return data", "response": "Delete an instance of StoreCreditPayment by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds StoreCreditPayment by its ID Return single instance of StoreCreditPayment", "response": "def get_store_credit_payment_by_id(cls, store_credit_payment_id, **kwargs):\n        \"\"\"Find StoreCreditPayment\n\n        Return single instance of StoreCreditPayment by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_store_credit_payment_by_id(store_credit_payment_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_credit_payment_id: ID of storeCreditPayment to return (required)\n        :return: StoreCreditPayment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_store_credit_payment_by_id_with_http_info(store_credit_payment_id, **kwargs)\n        else:\n            (data) = cls._get_store_credit_payment_by_id_with_http_info(store_credit_payment_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists StoreCreditPayments This method returns a list of StoreCreditPayments", "response": "def list_all_store_credit_payments(cls, **kwargs):\n        \"\"\"List StoreCreditPayments\n\n        Return a list of StoreCreditPayments\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_store_credit_payments(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[StoreCreditPayment]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_store_credit_payments_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_store_credit_payments_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace all attributes of StoreCreditPayment with the specified ID.", "response": "def replace_store_credit_payment_by_id(cls, store_credit_payment_id, store_credit_payment, **kwargs):\n        \"\"\"Replace StoreCreditPayment\n\n        Replace all attributes of StoreCreditPayment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_store_credit_payment_by_id(store_credit_payment_id, store_credit_payment, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_credit_payment_id: ID of storeCreditPayment to replace (required)\n        :param StoreCreditPayment store_credit_payment: Attributes of storeCreditPayment to replace (required)\n        :return: StoreCreditPayment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_store_credit_payment_by_id_with_http_info(store_credit_payment_id, store_credit_payment, **kwargs)\n        else:\n            (data) = cls._replace_store_credit_payment_by_id_with_http_info(store_credit_payment_id, store_credit_payment, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates attributes of StoreCreditPayment by ID", "response": "def update_store_credit_payment_by_id(cls, store_credit_payment_id, store_credit_payment, **kwargs):\n        \"\"\"Update StoreCreditPayment\n\n        Update attributes of StoreCreditPayment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_store_credit_payment_by_id(store_credit_payment_id, store_credit_payment, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str store_credit_payment_id: ID of storeCreditPayment to update. (required)\n        :param StoreCreditPayment store_credit_payment: Attributes of storeCreditPayment to update. (required)\n        :return: StoreCreditPayment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_store_credit_payment_by_id_with_http_info(store_credit_payment_id, store_credit_payment, **kwargs)\n        else:\n            (data) = cls._update_store_credit_payment_by_id_with_http_info(store_credit_payment_id, store_credit_payment, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing an existing rule with another one.", "response": "def replaceRule(oldRule, newRule):\n        # type: (Rule, Rule) -> Rule\n        \"\"\"\n        Replace instance of Rule with another one.\n        :param oldRule: Instance in the tree.\n        :param newRule: Instance to replace with.\n        :return: New instance attached to the tree.\n        \"\"\"\n        for par in oldRule.from_symbols:\n            par._set_to_rule(newRule)\n            newRule._from_symbols.append(par)\n        for ch in oldRule.to_symbols:\n            ch._set_from_rule(newRule)\n            newRule._to_symbols.append(ch)\n        return newRule"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreplacing an instance of Nonterminal or Terminal with another one.", "response": "def replaceNode(oldNode, newNode):\n        # type: (_RuleConnectable, _RuleConnectable) -> _RuleConnectable\n        \"\"\"\n        Replace instance of Nonterminal or Terminal in the tree with another one.\n        :param oldNode: Old nonterminal or terminal already in the tree.\n        :param newNode: Instance of nonterminal or terminal to replace with.\n        :return: Instance `newNode` in the tree.\n        \"\"\"\n        if oldNode.from_rule is not None and len(oldNode.from_rule.to_symbols) > 0:\n            indexParent = oldNode.from_rule.to_symbols.index(oldNode)\n            oldNode.from_rule.to_symbols[indexParent] = newNode\n            newNode._set_from_rule(oldNode.from_rule)\n        if oldNode.to_rule is not None and len(oldNode.to_rule.from_symbols) > 0:\n            indexChild = oldNode.to_rule.from_symbols.index(oldNode)\n            oldNode.to_rule._from_symbols[indexChild] = newNode\n            newNode._set_to_rule(oldNode.to_rule)\n        return newNode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace(oldEl, newEl):\n        # type: (Union[Rule, _RuleConnectable], Union[Rule, _RuleConnectable]) -> Union[Rule, _RuleConnectable]\n        \"\"\"\n        Replace element in the parsed tree. Can be nonterminal, terminal or rule.\n        :param oldEl: Element already in the tree.\n        :param newEl: Element to replace with.\n        :return: New element attached to the tree.\n        \"\"\"\n        if isinstance(oldEl, Rule):\n            return Manipulations.replaceRule(oldEl, newEl)\n        if isinstance(oldEl, (Nonterminal, Terminal)):\n            return Manipulations.replaceNode(oldEl, newEl)", "response": "Replaces the old element with the new one."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef search_authors(self, query):\n        query = query.replace(\" \", \"+\")\n        \"\"\"\n        FIXME: Don't create a process to do this!\n        \"\"\"\n        p = subprocess.Popen(\"curl -H 'Accept: application/orcid+json' \\\n                             'http://pub.sandbox-1.orcid.org/search/orcid-bio?q=\" +\n                             query + \"&start=0&rows=10'\",\n                             shell=True,\n                             stdout=subprocess.PIPE,\n                             stderr=subprocess.STDOUT)\n        jsonResults = \"\"\n        for line in p.stdout.readlines():\n            jsonResults = line\n\n        self.authorsDict = json.loads(jsonResults)", "response": "Search for author names in the Orcid."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Nmtoken from a string.", "response": "def nmtoken_from_string(text):\n    \"\"\"\n    Returns a Nmtoken from a string.\n    It is useful to produce XHTML valid values for the 'name'\n    attribute of an anchor.\n\n    CAUTION: the function is surjective: 2 different texts might lead to\n    the same result. This is improbable on a single page.\n\n    Nmtoken is the type that is a mixture of characters supported in\n    attributes such as 'name' in HTML 'a' tag. For example,\n    <a name=\"Articles%20%26%20Preprints\"> should be tranformed to\n    <a name=\"Articles372037263720Preprints\"> using this function.\n    http://www.w3.org/TR/2000/REC-xml-20001006#NT-Nmtoken\n\n    Also note that this function filters more characters than\n    specified by the definition of Nmtoken ('CombiningChar' and\n    'Extender' charsets are filtered out).\n    \"\"\"\n    text = text.replace('-', '--')\n    return ''.join([(((not char.isalnum() and char not in [\n        '.', '-', '_', ':'\n    ]) and str(ord(char))) or char) for char in text])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nescaping all HTML tags in text.", "response": "def escape_html(text, escape_quotes=False):\n    \"\"\"Escape all HTML tags, avoiding XSS attacks.\n    < => &lt;\n    > => &gt;\n    & => &amp:\n    @param text: text to be escaped from HTML tags\n    @param escape_quotes: if True, escape any quote mark to its HTML entity:\n                          \" => &quot;\n                          ' => &#39;\n    \"\"\"\n    text = text.replace('&', '&amp;')\n    text = text.replace('<', '&lt;')\n    text = text.replace('>', '&gt;')\n    if escape_quotes:\n        text = text.replace('\"', '&quot;')\n        text = text.replace(\"'\", '&#39;')\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nescaping text in order to be used as Javascript string in various context. Examples:: >>> text = '''\"Are you a Munchkin?\" asked Dorothy. \"No, but I am their friend\"''' >>> escape_javascript_string(text) >>> \\\\\"&quot;Are you a Munchkin?\\\\\" asked Dorothy.\\\\n\\\\\"No, but I am their friend\\\\\"' The returned string can be enclosed either in single or double quotes delimiters. THE FUNCTION ASSUME THAT YOU HAVE ALREDADY WASHED THE STRING FROM UNSAFE CONTENT, according to the context you plan to use the string. The function will just make sure that the string will not break you Javascript/HTML code/markup. If you plan to include the string inside the body of an HTML page, you will probably want to set C{escape_for_html} to True, in order to produce XHTML-valid pages when the input string contain characters such as < , > and &. Furthermore if you plan to include the string as part of a tag attribute (for eg. <a href=\"#\" onclick=\"foo&quot;bar\"), you might want to set C{escape_quote_for_html} to True. If you plan to include the string inside the body of an HTML page, enclosed by CDATA delimiters, then you would *not* need to escape HTML tags. Using CDATA delimeters enables to include Javascript strings meant to refer to HTML tags (eg. in case you would like to manipulate the DOM tree to add new nodes to the page), which would not be possible when escaping the HTML. For eg.: /*<![CDATA[*/ document.getElementById('foo').innerHTML = '<p>bar</p>' /*]]>*/ In this case you will probably want to set C{escape_CDATA} to True in order to produce an XHTML-valid document, in case a closing CDATA delimeter is in your input string. Parameter C{escape_CDATA} is not considered when C{escape_for_html} is set to True. Note that CDATA delimiters might be automatically added by the browser, based on the content-type used to serve the page. When C{escape_for_html} is set to False, whatever option is chosen for C{escape_CDATA}, the string must not contain a '</script>' tag (apparently...). The only option to keep this '</script>' tag (if you need it) is to split it, which requires to know which quote delimiter your plan to use. For eg: Examples:: >>> text = '''foo</script>bar''' >>> val = escape_javascript_string(text, escape_for_html=False, escape_script_tag_with_quote='\"') >>> 'foo</scr\"+\"ipt>bar' >>> mycode = '''alert(\"%s\")''' % val C{escape_script_tag_with_quote} is not considered when C{escape_for_html} is set to True. If you are planning to return the string as part of a pure Javascript document, then you should in principle set both C{escape_for_html} and C{escape_CDATA} to False, and C{escape_script_tag_with_quote} to None. @param text: string to be escaped @param escape_for_html: if True, also escape input for HTML @param escape_CDATA: if True, escape closing CDATA tags (when C{escape_for_html} is False) @escape_script_tag_with_quote: which quote will be used to delimit your string, in case you must wash, but keep, C{</script>} tag (when C{escape_for_html} is False)", "response": "def escape_javascript_string(\n        text,\n        escape_for_html=True,\n        escape_quote_for_html=False,\n        escape_CDATA=True,\n        escape_script_tag_with_quote='\"'):\n    \"\"\"\n    Escape text in order to be used as Javascript string in various\n    context.\n\n    Examples::\n    >>> text = '''\"Are you a Munchkin?\" asked Dorothy.\n\"No, but I am their friend\"'''\n    >>> escape_javascript_string(text)\n    >>> \\\\\"&quot;Are you a Munchkin?\\\\\" asked Dorothy.\\\\n\\\\\"No, but I am their friend\\\\\"'\n\n    The returned string can be enclosed either in single or double\n    quotes delimiters.\n\n    THE FUNCTION ASSUME THAT YOU HAVE ALREDADY WASHED THE STRING FROM\n    UNSAFE CONTENT, according to the context you plan to use the\n    string. The function will just make sure that the string will not\n    break you Javascript/HTML code/markup.\n\n    If you plan to include the string inside the body of an HTML page,\n    you will probably want to set C{escape_for_html} to True, in order\n    to produce XHTML-valid pages when the input string contain\n    characters such as < , > and &.\n\n    Furthermore if you plan to include the string as part of a tag\n    attribute (for eg. <a href=\"#\" onclick=\"foo&quot;bar\"), you might\n    want to set C{escape_quote_for_html} to True.\n\n    If you plan to include the string inside the body of an HTML page,\n    enclosed by CDATA delimiters, then you would *not* need to escape\n    HTML tags. Using CDATA delimeters enables to include Javascript\n    strings meant to refer to HTML tags (eg. in case you would like to\n    manipulate the DOM tree to add new nodes to the page), which would\n    not be possible when escaping the HTML. For eg.:\n        /*<![CDATA[*/\n            document.getElementById('foo').innerHTML = '<p>bar</p>'\n        /*]]>*/\n    In this case you will probably want to set C{escape_CDATA} to True\n    in order to produce an XHTML-valid document, in case a closing\n    CDATA delimeter is in your input string. Parameter C{escape_CDATA}\n    is not considered when C{escape_for_html} is set to True.\n\n    Note that CDATA delimiters might be automatically added by the\n    browser, based on the content-type used to serve the page.\n\n    When C{escape_for_html} is set to False, whatever option is chosen\n    for C{escape_CDATA}, the string must not contain a '</script>' tag\n    (apparently...). The only option to keep this '</script>' tag (if\n    you need it) is to split it, which requires to know which quote\n    delimiter your plan to use. For eg:\n\n    Examples::\n    >>> text = '''foo</script>bar'''\n    >>> val = escape_javascript_string(text, escape_for_html=False, escape_script_tag_with_quote='\"')\n    >>> 'foo</scr\"+\"ipt>bar'\n    >>> mycode = '''alert(\"%s\")''' % val\n\n    C{escape_script_tag_with_quote} is not considered when\n    C{escape_for_html} is set to True.\n\n    If you are planning to return the string as part of a pure\n    Javascript document, then you should in principle set both\n    C{escape_for_html} and C{escape_CDATA} to False, and\n    C{escape_script_tag_with_quote} to None.\n\n    @param text: string to be escaped\n    @param escape_for_html: if True, also escape input for HTML\n    @param escape_CDATA: if True, escape closing CDATA tags (when C{escape_for_html} is False)\n    @escape_script_tag_with_quote: which quote will be used to delimit your string, in case you must wash, but keep, C{</script>} tag (when C{escape_for_html} is False)\n    \"\"\"\n    if escape_quote_for_html:\n        text = text.replace('\"', '&quot;')\n    if escape_for_html:\n        text = cgi.escape(text)\n    elif escape_CDATA:\n        text = text.replace(']]>', ']]]]><![CDATA[>')\n\n    text = json.dumps(text)[1:-1].replace(\"'\", \"\\\\'\")\n\n    if not escape_for_html and escape_script_tag_with_quote:\n        text = RE_CLOSING_SCRIPT_TAG.sub(\n            '''</scr%(q)s+%(q)sipt>''' % {'q': escape_script_tag_with_quote}, text)\n\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntidying up the input HTML using one of the installed clean libraries.", "response": "def tidy_html(html_buffer, cleaning_lib='utidylib'):\n    \"\"\"\n    Tidy up the input HTML using one of the installed cleaning\n    libraries.\n\n    @param html_buffer: the input HTML to clean up\n    @type html_buffer: string\n    @param cleaning_lib: chose the preferred library to clean the HTML. One of:\n                         - utidylib\n                         - beautifulsoup\n    @return: a cleaned version of the input HTML\n    @note: requires uTidylib or BeautifulSoup to be installed. If the chosen library is missing, the input X{html_buffer} is returned I{as is}.\n    \"\"\"\n\n    if CFG_TIDY_INSTALLED and cleaning_lib == 'utidylib':\n        options = dict(output_xhtml=1,\n                       show_body_only=1,\n                       merge_divs=0,\n                       wrap=0)\n        try:\n            output = str(tidy.parseString(html_buffer, **options))\n        except:\n            output = html_buffer\n    elif CFG_BEAUTIFULSOUP_INSTALLED and cleaning_lib == 'beautifulsoup':\n        try:\n            output = str(BeautifulSoup(html_buffer).prettify())\n        except:\n            output = html_buffer\n    else:\n        output = html_buffer\n\n    return output"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_mathjax_header(https=False):\n    if cfg['CFG_MATHJAX_HOSTING'].lower() == 'cdn':\n        if https:\n            mathjax_path = \"https://d3eoax9i5htok0.cloudfront.net/mathjax/2.1-latest\"\n        else:\n            mathjax_path = \"http://cdn.mathjax.org/mathjax/2.1-latest\"\n    else:\n        mathjax_path = \"/vendors/MathJax\"\n\n    if cfg['CFG_MATHJAX_RENDERS_MATHML']:\n        mathjax_config = \"TeX-AMS-MML_HTMLorMML\"\n    else:\n        mathjax_config = \"TeX-AMS_HTML\"\n\n    return \"\"\"<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n  tex2jax: {inlineMath: [['$','$']],\n            processEscapes: true},\n  showProcessingMessages: false,\n  messageStyle: \"none\"\n});\n</script>\n<script src=\"%(mathjax_path)s/MathJax.js?config=%(mathjax_config)s\" type=\"text/javascript\">\n</script>\"\"\" % {\n        'mathjax_path': mathjax_path,\n        'mathjax_config': mathjax_config,\n    }", "response": "Return the snippet of HTML code to put in HTML HEAD tag."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_html_text_editor(\n        name,\n        id=None,\n        content='',\n        textual_content=None,\n        width='300px',\n        height='200px',\n        enabled=True,\n        file_upload_url=None,\n        toolbar_set=\"Basic\",\n        custom_configurations_path='/js/ckeditor/invenio-ckeditor-config.js',\n        ln=None):\n    \"\"\"\n    Returns a wysiwyg editor (CKEditor) to embed in html pages.\n\n    Fall back to a simple textarea when the library is not installed,\n    or when the user's browser is not compatible with the editor, or\n    when 'enable' is False, or when javascript is not enabled.\n\n    NOTE that the output also contains a hidden field named\n    'editor_type' that contains the kind of editor used, 'textarea' or\n    'ckeditor'.\n\n    Based on 'editor_type' you might want to take different actions,\n    like replace CRLF with <br/> when editor_type equals to\n    'textarea', but not when editor_type equals to 'ckeditor'.\n\n    @param name: *str* the name attribute of the returned editor\n\n    @param id: *str* the id attribute of the returned editor (when\n        applicable)\n\n    @param content: *str* the default content of the editor.\n\n    @param textual_content: *str* a content formatted for the case where the\n        wysiwyg editor is not available for user. When not\n        specified, use value of 'content'\n\n    @param width: *str* width of the editor in an html compatible unit:\n        Eg: '400px', '50%'.\n\n    @param height: *str* height of the editor in an html compatible unit:\n        Eg: '400px', '50%'.\n\n    @param enabled: *bool* if the wysiwyg editor is return (True) or if a\n        simple texteara is returned (False)\n\n    @param file_upload_url: *str* the URL used to upload new files via the\n        editor upload panel. You have to implement the\n        handler for your own use. The URL handler will get\n        form variables 'File' as POST for the uploaded file,\n        and 'Type' as GET for the type of file ('file',\n        'image', 'flash', 'media')\n        When value is not given, the file upload is disabled.\n\n    @param toolbar_set: *str* the name of the toolbar layout to\n        use. CKeditor comes by default with 'Basic' and\n        'Default'. To define other sets, customize the\n        config file in\n        /opt/cds-invenio/var/www/ckeditor/invenio-ckconfig.js\n\n    @param custom_configurations_path: *str* value for the CKeditor config\n        variable 'CustomConfigurationsPath',\n        which allows to specify the path of a\n        file that contains a custom configuration\n        for the editor. The path is relative to\n        /opt/invenio/var/www/\n\n    @return: the HTML markup of the editor\n    \"\"\"\n    ln = default_ln(ln)\n\n    if textual_content is None:\n        textual_content = content\n\n    editor = ''\n\n    if enabled and ckeditor_available:\n        # Prepare upload path settings\n        file_upload_script = ''\n        if file_upload_url is not None:\n            file_upload_script = ''',\n            filebrowserLinkUploadUrl: '%(file_upload_url)s',\n            filebrowserImageUploadUrl: '%(file_upload_url)s?type=Image',\n            filebrowserFlashUploadUrl: '%(file_upload_url)s?type=Flash'\n            ''' % {'file_upload_url': file_upload_url}\n\n        # Prepare code to instantiate an editor\n        editor += '''\n        <script type=\"text/javascript\" language=\"javascript\">//<![CDATA[\n        /* Load the script only once, or else multiple instance of the editor on the same page will not work */\n        var INVENIO_CKEDITOR_ALREADY_LOADED\n            if (INVENIO_CKEDITOR_ALREADY_LOADED != 1) {\n                document.write('<script type=\"text/javascript\" src=\"%(CFG_SITE_URL)s/vendors/ckeditor/ckeditor.js\"><\\/script>');\n                INVENIO_CKEDITOR_ALREADY_LOADED = 1;\n            }\n        //]]></script>\n        <input type=\"hidden\" name=\"editor_type\" id=\"%(id)seditortype\" value=\"textarea\" />\n        <textarea rows=\"100\" cols=\"80\" id=\"%(id)s\" name=\"%(name)s\" style=\"width:%(width)s;height:%(height)s\">%(textual_content)s</textarea>\n        <textarea rows=\"100\" cols=\"80\" id=\"%(id)shtmlvalue\" name=\"%(name)shtmlvalue\" style=\"display:none;width:%(width)s;height:%(height)s\">%(html_content)s</textarea>\n        <script type=\"text/javascript\">//<![CDATA[\n          var CKEDITOR_BASEPATH = '/ckeditor/';\n\n          CKEDITOR.replace( '%(name)s',\n                            {customConfig: '%(custom_configurations_path)s',\n                            toolbar: '%(toolbar)s',\n                            width: '%(width)s',\n                            height:'%(height)s',\n                            language: '%(ln)s'\n                            %(file_upload_script)s\n                            });\n\n        CKEDITOR.on('instanceReady',\n          function( evt )\n          {\n            /* If CKeditor was correctly loaded, display the nice HTML representation */\n            var oEditor = evt.editor;\n            editor_id = oEditor.id\n            editor_name = oEditor.name\n            var html_editor = document.getElementById(editor_name + 'htmlvalue');\n            oEditor.setData(html_editor.value);\n            var editor_type_field = document.getElementById(editor_name + 'editortype');\n            editor_type_field.value = 'ckeditor';\n            var writer = oEditor.dataProcessor.writer;\n            writer.indentationChars = ''; /*Do not indent source code with tabs*/\n            oEditor.resetDirty();\n            /* Workaround: http://dev.ckeditor.com/ticket/3674 */\n             evt.editor.on( 'contentDom', function( ev )\n             {\n             ev.removeListener();\n             evt.editor.resetDirty();\n             } );\n            /* End workaround */\n          })\n\n        //]]></script>\n        ''' % \\\n            {'textual_content': cgi.escape(textual_content),\n             'html_content': content,\n             'width': width,\n             'height': height,\n             'name': name,\n             'id': id or name,\n             'custom_configurations_path': custom_configurations_path,\n             'toolbar': toolbar_set,\n             'file_upload_script': file_upload_script,\n             'CFG_SITE_URL': cfg['CFG_SITE_URL'],\n             'ln': ln}\n\n    else:\n        # CKedior is not installed\n        textarea = '<textarea rows=\"100\" cols=\"80\" %(id)s name=\"%(name)s\" style=\"width:%(width)s;height:%(height)s\">%(content)s</textarea>' \\\n            % {'content': cgi.escape(textual_content),\n               'width': width,\n               'height': height,\n               'name': name,\n               'id': id and ('id=\"%s\"' % id) or ''}\n        editor += textarea\n        editor += '<input type=\"hidden\" name=\"editor_type\" value=\"textarea\" />'\n\n    return editor", "response": "Returns a wysiwyg editor that can embed in html pages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove HTML markup from text.", "response": "def remove_html_markup(text, replacechar=' ', remove_escaped_chars_p=True):\n    \"\"\"\n    Remove HTML markup from text.\n\n    @param text: Input text.\n    @type text: string.\n    @param replacechar: By which character should we replace HTML markup.\n        Usually, a single space or an empty string are nice values.\n    @type replacechar: string\n    @param remove_escaped_chars_p: If True, also remove escaped characters\n        like '&amp;', '&lt;', '&gt;' and '&quot;'.\n    @type remove_escaped_chars_p: boolean\n    @return: Input text with HTML markup removed.\n    @rtype: string\n    \"\"\"\n    if not remove_escaped_chars_p:\n        return RE_HTML_WITHOUT_ESCAPED_CHARS.sub(replacechar, text)\n    return RE_HTML.sub(replacechar, text)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate an XML or HTML tag.", "response": "def create_tag(\n        tag,\n        escaper=EscapedHTMLString,\n        opening_only=False,\n        body=None,\n        escape_body=False,\n        escape_attr=True,\n        indent=0,\n        attrs=None,\n        **other_attrs):\n    \"\"\"\n    Create an XML/HTML tag.\n\n    This function create a full XML/HTML tag, putting toghether an\n    optional inner body and a dictionary of attributes.\n\n        >>> print create_html_tag (\"select\", create_html_tag(\"h1\",\n        ... \"hello\", other_attrs={'class': \"foo\"}))\n        <select>\n          <h1 class=\"foo\">\n            hello\n          </h1>\n        </select>\n\n    @param tag: the tag (e.g. \"select\", \"body\", \"h1\"...).\n    @type tag: string\n    @param body: some text/HTML to put in the body of the tag (this\n        body will be indented WRT the tag).\n    @type body: string\n    @param escape_body: wether the body (if any) must be escaped.\n    @type escape_body: boolean\n    @param escape_attr: wether the attribute values (if any) must be\n        escaped.\n    @type escape_attr: boolean\n    @param indent: number of level of indentation for the tag.\n    @type indent: integer\n    @param attrs: map of attributes to add to the tag.\n    @type attrs: dict\n    @return: the HTML tag.\n    @rtype: string\n    \"\"\"\n\n    if attrs is None:\n        attrs = {}\n    for key, value in iteritems(other_attrs):\n        if value is not None:\n            if key.endswith('_'):\n                attrs[key[:-1]] = value\n            else:\n                attrs[key] = value\n    out = \"<%s\" % tag\n    for key, value in iteritems(attrs):\n        if escape_attr:\n            value = escaper(value, escape_quotes=True)\n        out += ' %s=\"%s\"' % (key, value)\n    if body is not None:\n        if callable(body) and body.__name__ == 'handle_body':\n            body = body()\n        out += \">\"\n        if escape_body and not isinstance(body, EscapedString):\n            body = escaper(body)\n        out += body\n        if not opening_only:\n            out += \"</%s>\" % tag\n    elif not opening_only:\n        out += \" />\"\n    if indent:\n        out = indent_text(out, indent)[:-1]\n    from invenio_utils.text import wash_for_utf8\n    return EscapedString(wash_for_utf8(out))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_html_select(\n        options,\n        name=None,\n        selected=None,\n        disabled=None,\n        multiple=False,\n        attrs=None,\n        **other_attrs):\n    \"\"\"\n    Create an HTML select box.\n\n        >>> print create_html_select([\"foo\", \"bar\"], selected=\"bar\", name=\"baz\")\n        <select name=\"baz\">\n          <option selected=\"selected\" value=\"bar\">\n            bar\n          </option>\n          <option value=\"foo\">\n            foo\n          </option>\n        </select>\n        >>> print create_html_select([(\"foo\", \"oof\"), (\"bar\", \"rab\")], selected=\"bar\", name=\"baz\")\n        <select name=\"baz\">\n          <option value=\"foo\">\n            oof\n          </option>\n          <option selected=\"selected\" value=\"bar\">\n            rab\n          </option>\n        </select>\n\n    @param options: this can either be a sequence of strings, or a sequence\n        of couples or a map of C{key->value}. In the former case, the C{select}\n        tag will contain a list of C{option} tags (in alphabetical order),\n        where the C{value} attribute is not specified. In the latter case,\n        the C{value} attribute will be set to the C{key}, while the body\n        of the C{option} will be set to C{value}.\n    @type options: sequence or map\n    @param name: the name of the form element.\n    @type name: string\n    @param selected: optional key(s)/value(s) to select by default. In case\n        a map has been used for options.\n    @type selected: string (or list of string)\n    @param disabled: optional key(s)/value(s) to disable.\n    @type disabled: string (or list of string)\n    @param multiple: whether a multiple select box must be created.\n    @type mutable: bool\n    @param attrs: optional attributes to create the select tag.\n    @type attrs: dict\n    @param other_attrs: other optional attributes.\n    @return: the HTML output.\n    @rtype: string\n\n    @note: the values and keys will be escaped for HTML.\n\n    @note: it is important that parameter C{value} is always\n        specified, in case some browser plugin play with the\n        markup, for eg. when translating the page.\n    \"\"\"\n    body = []\n    if selected is None:\n        selected = []\n    elif isinstance(selected, (str, unicode)):\n        selected = [selected]\n    if disabled is None:\n        disabled = []\n    elif isinstance(disabled, (str, unicode)):\n        disabled = [disabled]\n    if name is not None and multiple and not name.endswith('[]'):\n        name += \"[]\"\n    if isinstance(options, dict):\n        items = options.items()\n        items.sort(lambda item1, item2: cmp(item1[1], item2[1]))\n    elif isinstance(options, (list, tuple)):\n        options = list(options)\n        items = []\n        for item in options:\n            if isinstance(item, (str, unicode)):\n                items.append((item, item))\n            elif isinstance(item, (tuple, list)) and len(item) == 2:\n                items.append(tuple(item))\n            else:\n                raise ValueError(\n                    'Item \"%s\" of incompatible type: %s' % (item, type(item)))\n    else:\n        raise ValueError('Options of incompatible type: %s' % type(options))\n    for key, value in items:\n        option_attrs = {}\n        if key in selected:\n            option_attrs['selected'] = 'selected'\n        if key in disabled:\n            option_attrs['disabled'] = 'disabled'\n        body.append(\n            create_tag(\n                \"option\",\n                body=value,\n                escape_body=True,\n                value=key,\n                attrs=option_attrs))\n    if attrs is None:\n        attrs = {}\n    if name is not None:\n        attrs['name'] = name\n    if multiple:\n        attrs['multiple'] = 'multiple'\n    return create_tag(\n        \"select\",\n        body='\\n'.join(body),\n        attrs=attrs,\n        **other_attrs)", "response": "Create an HTML select box."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef wash(\n            self,\n            html_buffer,\n            render_unallowed_tags=False,\n            allowed_tag_whitelist=CFG_HTML_BUFFER_ALLOWED_TAG_WHITELIST,\n            automatic_link_transformation=False,\n            allowed_attribute_whitelist=CFG_HTML_BUFFER_ALLOWED_ATTRIBUTE_WHITELIST):\n        \"\"\"\n        Wash HTML buffer, escaping XSS attacks.\n        @param html_buffer: text to escape\n        @param render_unallowed_tags: if True, print unallowed tags escaping\n            < and >.  Else, only print content of unallowed tags.\n        @param allowed_tag_whitelist: list of allowed tags\n        @param allowed_attribute_whitelist: list of allowed attributes\n        \"\"\"\n        self.reset()\n        self.result = ''\n        self.nb = 0\n        self.previous_nbs = []\n        self.previous_type_lists = []\n        self.url = ''\n        self.render_unallowed_tags = render_unallowed_tags\n        self.automatic_link_transformation = automatic_link_transformation\n        self.allowed_tag_whitelist = allowed_tag_whitelist\n        self.allowed_attribute_whitelist = allowed_attribute_whitelist\n        self.feed(html_buffer)\n        self.close()\n\n        return self.result", "response": "Wash HTML buffer, escaping XSS attacks.\n        @param html_buffer: text to escape\n        @param render_unallowed_tags: if True, print unallowed tags escaping\n            < and >.  Else, only print content of unallowed tags.\n        @param allowed_tag_whitelist: list of allowed tags\n        @param allowed_attribute_whitelist: list of allowed attributes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning called for text nodes", "response": "def handle_data(self, data):\n        \"\"\"Function called for text nodes\"\"\"\n        if not self.silent:\n            possible_urls = re.findall(\n                r'(https?://[\\w\\d:#%/;$()~_?\\-=\\\\\\.&]*)', data)\n            # validate possible urls\n            # we'll transform them just in case\n            # they are valid.\n            if possible_urls and self.automatic_link_transformation:\n                for url in possible_urls:\n                    if regex_url.search(url):\n                        transformed_url = '<a href=\"%s\">%s</a>' % (url, url)\n                        data = data.replace(url, transformed_url)\n                self.result += data\n            else:\n                self.result += cgi.escape(data, True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_endtag(self, tag):\n        if tag.lower() in self.allowed_tag_whitelist:\n            self.result += '</' + tag + '>'\n        else:\n            if self.render_unallowed_tags:\n                self.result += '&lt;/' + cgi.escape(tag) + '&gt;'\n\n        if tag == 'style' or tag == 'script':\n            self.silent = False", "response": "Function called for ending of tags"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfunction called for starttag and endtag", "response": "def handle_startendtag(self, tag, attrs):\n        \"\"\"Function called for empty tags (e.g. <br />)\"\"\"\n        if tag.lower() in self.allowed_tag_whitelist:\n            self.result += '<' + tag\n            for (attr, value) in attrs:\n                if attr.lower() in self.allowed_attribute_whitelist:\n                    self.result += ' %s=\"%s\"' % \\\n                        (attr, self.handle_attribute_value(value))\n            self.result += ' />'\n        else:\n            if self.render_unallowed_tags:\n                self.result += '&lt;' + cgi.escape(tag)\n                for (attr, value) in attrs:\n                    self.result += ' %s=\"%s\"' % \\\n                        (attr, cgi.escape(value, True))\n                self.result += ' /&gt;'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_attribute_value(self, value):\n        if self.re_js.match(value) or self.re_vb.match(value):\n            return ''\n        return value", "response": "Check attribute. Especially designed for avoiding URLs in the form:\n        javascript:myXSSFunction();"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the appropriate template name based on the given file name.", "response": "def template_from_filename(filename):\n    \"\"\"Returns the appropriate template name based on the given file name.\"\"\"\n    ext = filename.split(os.path.extsep)[-1]\n    if not ext in TEMPLATES_MAP:\n        raise ValueError(\"No template for file extension {}\".format(ext))\n    return TEMPLATES_MAP[ext]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dt2ts(dt):\r\n    # Note: no assertion to really keep this fast\r\n    assert isinstance(dt, (datetime.datetime, datetime.date))\r\n    ret = time.mktime(dt.timetuple())\r\n    if isinstance(dt, datetime.datetime):\r\n        ret += 1e-6 * dt.microsecond\r\n    return ret", "response": "Converts to float representing number of seconds since 1970 - 01 - 01 GMT."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting datetime object to str if not already an str.", "response": "def dt2str(dt, flagSeconds=True):\r\n    \"\"\"Converts datetime object to str if not yet an str.\"\"\"\r\n    if isinstance(dt, str):\r\n        return dt\r\n    return dt.strftime(_FMTS if flagSeconds else _FMT)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef str2dt(s):\r\n    return datetime.datetime.strptime(s, _FMTS if s.count(\":\") == 2 else _FMT if s.count(\":\") == 1 else _FMT0)", "response": "Works with time with seconds."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning seconds since 0h00.", "response": "def time2seconds(t):\r\n    \"\"\"Returns seconds since 0h00.\"\"\"\r\n    return t.hour * 3600 + t.minute * 60 + t.second + float(t.microsecond) / 1e6"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_datetime(arg):\r\n\r\n\r\n    if isinstance(arg, datetime.datetime):\r\n        return arg\r\n    elif arg == 0:\r\n        return datetime.datetime.now()\r\n    elif isinstance(arg, str):\r\n        if arg == \"now\":\r\n            arg = datetime.datetime.now()\r\n        elif arg == \"?\":\r\n            arg = datetime.datetime(1970, 1, 1)\r\n        else:\r\n            arg = str2dt(arg)\r\n    elif isinstance(arg, datetime.date):\r\n        arg = date2datetime(arg)\r\n    elif isinstance(arg, (int, float)):\r\n        # Suppose it is a timestamp\r\n        arg = ts2dt(arg)\r\n    else:\r\n        raise TypeError(\"Wrong type for argument 'arg': {}\".format(arg.__class__.__name__))\r\n\r\n    return arg", "response": "Tries to convert any type of argument to datetime"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_all_coupons(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_coupons_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_coupons_with_http_info(**kwargs)\n            return data", "response": "List Coupons\n        Return a list of Coupons\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntaking points z x Q and sort by increasing z", "response": "def sort_points(self, points):\n        \"\"\"Take points (z,x,q) and sort by increasing z\"\"\"\n        new_points = []\n        z_lookup = {}\n        for z, x, Q in points:\n            z_lookup[z] = (z, x, Q)\n\n        z_keys = z_lookup.keys()\n        z_keys.sort()\n\n        for key in z_keys:\n            new_points.append(z_lookup[key])\n\n        return new_points"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nperforming a 2D fit on the 2D points then return parameters", "response": "def Fit(self, zxq):\n        \"\"\"Perform a 2D fit on 2D points then return parameters\n\n   :param zxq: A list where each element is (z, transverse, charge)\n   \"\"\"\n        z, trans, Q = zip(*zxq)\n\n        assert len(trans) == len(z)\n        ndf = len(z) - 3\n\n        z = np.array(z)\n        trans = np.array(trans)\n\n        def dbexpl(t, p):\n            return(p[0] - p[1] * t + p[2] * t ** 2)\n\n        def residuals(p, data, t):\n            err = data - dbexpl(t, p)\n            return err\n\n        doc = {}\n\n        try:\n            assert ndf > 0\n\n            p0 = [1, 0, 0]  # initial guesses\n            pbest = leastsq(residuals, p0, args=(trans, z), full_output=1)\n            bestparams = pbest[0]\n            good_of_fit = sum(pbest[2]['fvec'] ** 2)\n            good_of_fit = float(good_of_fit / ndf)\n            doc['params'] = list(bestparams)\n            doc['gof'] = good_of_fit\n        except:\n            doc['gof'] = 'FAIL'\n            doc['params'] = [0, 0, 0]\n\n        return doc"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_last_transverse_over_list(self, zxq):\n        z_max = None\n        x_of_interest = None\n\n        for z, x, q in zxq:\n            if z == None or z > z_max:\n                x_of_interest = x\n\n        return x_of_interest", "response": "Get the last transverse coord at highest zxq."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new CancelOperation with the specified attributes.", "response": "def create_cancel_operation(cls, cancel_operation, **kwargs):\n        \"\"\"Create CancelOperation\n\n        Create a new CancelOperation\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_cancel_operation(cancel_operation, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param CancelOperation cancel_operation: Attributes of cancelOperation to create (required)\n        :return: CancelOperation\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_cancel_operation_with_http_info(cancel_operation, **kwargs)\n        else:\n            (data) = cls._create_cancel_operation_with_http_info(cancel_operation, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_cancel_operation_by_id(cls, cancel_operation_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_cancel_operation_by_id_with_http_info(cancel_operation_id, **kwargs)\n        else:\n            (data) = cls._delete_cancel_operation_by_id_with_http_info(cancel_operation_id, **kwargs)\n            return data", "response": "Delete an instance of CancelOperation by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_cancel_operation_by_id(cls, cancel_operation_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_cancel_operation_by_id_with_http_info(cancel_operation_id, **kwargs)\n        else:\n            (data) = cls._get_cancel_operation_by_id_with_http_info(cancel_operation_id, **kwargs)\n            return data", "response": "Find CancelOperation by its ID Return single instance of CancelOperation with its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_cancel_operations(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_cancel_operations_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_cancel_operations_with_http_info(**kwargs)\n            return data", "response": "List CancelOperations\n        This method returns a list of CancelOperations\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_cancel_operation_by_id(cls, cancel_operation_id, cancel_operation, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_cancel_operation_by_id_with_http_info(cancel_operation_id, cancel_operation, **kwargs)\n        else:\n            (data) = cls._replace_cancel_operation_by_id_with_http_info(cancel_operation_id, cancel_operation, **kwargs)\n            return data", "response": "Replace CancelOperation by ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nupdate the attributes of a CancelOperation by ID", "response": "def update_cancel_operation_by_id(cls, cancel_operation_id, cancel_operation, **kwargs):\n        \"\"\"Update CancelOperation\n\n        Update attributes of CancelOperation\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_cancel_operation_by_id(cancel_operation_id, cancel_operation, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str cancel_operation_id: ID of cancelOperation to update. (required)\n        :param CancelOperation cancel_operation: Attributes of cancelOperation to update. (required)\n        :return: CancelOperation\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_cancel_operation_by_id_with_http_info(cancel_operation_id, cancel_operation, **kwargs)\n        else:\n            (data) = cls._update_cancel_operation_by_id_with_http_info(cancel_operation_id, cancel_operation, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_geo_zones(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_geo_zones_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_geo_zones_with_http_info(**kwargs)\n            return data", "response": "List GeoZones\n        Return a list of GeoZones\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping a Flask handler to require a valid IndieAuth access token.", "response": "def requires_indieauth(f):\n    \"\"\"Wraps a Flask handler to require a valid IndieAuth access token.\n    \"\"\"\n    @wraps(f)\n    def decorated(*args, **kwargs):\n        access_token = get_access_token()\n        resp = check_auth(access_token)\n        if isinstance(resp, Response):\n          return resp\n        return f(*args, **kwargs)\n    return decorated"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_auth(access_token):\n    if not access_token:\n      current_app.logger.error('No access token.')\n      return deny('No access token found.')\n    request = Request(\n      current_app.config['TOKEN_ENDPOINT'],\n      headers={\"Authorization\" : (\"Bearer %s\" % access_token)}\n    )\n    contents = urlopen(request).read().decode('utf-8')\n    token_data = parse_qs(contents)\n    me = token_data['me'][0]\n    client_id = token_data['client_id'][0]\n    if me is None or client_id is None:\n        current_app.logger.error(\"Invalid token [%s]\" % contents)\n        return deny('Invalid token')\n\n    me, me_error = check_me(me)\n    if me is None:\n        current_app.logger.error(\"Invalid `me` value [%s]\" % me_error)\n        return deny(me_error)\n\n    scope = token_data['scope']\n    if not isinstance(scope, str):\n        scope = scope[0]\n    valid_scopes = ('post','create', )\n    scope_ = scope.split()\n    scope_valid = any((val in scope_) for val in valid_scopes)\n\n    if not scope_valid:\n        current_app.logger.error(\"Scope '%s' does not contain 'post' or 'create'.\" % scope)\n        return deny(\"Scope '%s' does not contain 'post' or 'create'.\" % scope)\n\n    g.user = {\n      'me': me,\n      'client_id': client_id,\n      'scope': scope,\n      'access_token': access_token\n    }", "response": "Checks if the given token is a valid token and if it is for whom."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconnect to the specific database.", "response": "def connect_db(config):\n    \"\"\"Connects to the specific database.\"\"\"\n    rv = sqlite3.connect(config[\"database\"][\"uri\"])\n    rv.row_factory = sqlite3.Row\n    return rv"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_db():\n    with closing(connect_db()) as db:\n        db.cursor().execute(\"DROP TABLE IF EXISTS entries\")\n        db.cursor().execute(\n            \"\"\"\n            CREATE TABLE entries (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                title TEXT NOT NULL,\n                text TEXT NOT NULL\n            )\n            \"\"\"\n        )\n        db.commit()", "response": "Creates the database tables."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef harvest_repo(root_url, archive_path, tag=None, archive_format='tar.gz'):\n\n    if not git_exists():\n        raise Exception(\"Git not found. It probably needs installing.\")\n\n    clone_path = mkdtemp(dir=cfg['CFG_TMPDIR'])\n\n    git = get_which_git()\n\n    call([git, 'clone', root_url, clone_path])\n    chdir(clone_path)\n\n    if tag:\n        call([git, 'archive', '--format=' + archive_format, '-o',\n              archive_path, tag])\n    else:\n        call([git, 'archive', '--format=' + archive_format, '-o',\n              archive_path, 'HEAD'])\n\n    try:\n        rmtree(clone_path)\n    except OSError as e:\n        # Reraise unless ENOENT: No such file or directory\n        # (ok if directory has already been deleted)\n        if e.errno != errno.ENOENT:\n            raise", "response": "This function clones a specific Git repository and archives it to a specific path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gregorian_to_julian(day):\n    before_march = 1 if day.month < MARCH else 0\n\n    #\n    # Number of months since March\n    #\n    month_index = day.month + MONTHS_PER_YEAR * before_march - MARCH\n\n    #\n    # Number of years (year starts on March) since 4800 BC\n    #\n    years_elapsed = day.year - JULIAN_START_YEAR - before_march\n\n    total_days_in_previous_months = (153 * month_index + 2) // 5\n    total_days_in_previous_years = 365 * years_elapsed\n    total_leap_days = (\n        (years_elapsed // 4) -\n        (years_elapsed // 100) +\n        (years_elapsed // 400)\n    )\n\n    return sum([\n        day.day,\n        total_days_in_previous_months,\n        total_days_in_previous_years,\n        total_leap_days,\n        -32045,      # Offset to get January 1, 4713 equal to 0\n    ])", "response": "Convert a datetime. date object to its corresponding Julian day."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sun_declination(day):\n    day_of_year = day.toordinal() - date(day.year, 1, 1).toordinal()\n    day_angle = 2 * pi * day_of_year / 365\n    declination_radians = sum([\n        0.006918,\n        0.001480*sin(3*day_angle),\n        0.070257*sin(day_angle),\n        0.000907*sin(2*day_angle),\n        -0.399912*cos(day_angle),\n        -0.006758*cos(2*day_angle),\n        -0.002697*cos(3*day_angle),\n    ])\n\n    return degrees(declination_radians)", "response": "Compute the declination angle of the sun for the given date."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef equation_of_time(day):\n    day_of_year = day.toordinal() - date(day.year, 1, 1).toordinal()\n\n    # pylint: disable=invalid-name\n\n    #\n    # Distance Earth moves from solstice to January 1 (so about 10 days)\n    #\n    A = EARTH_ORIBITAL_VELOCITY * (day_of_year + 10)\n\n    #\n    # Distance Earth moves from solstice to day_of_year\n    # 2 is the number of days from Jan 1 to periheleon\n    # This is the result of a lot of constants collapsing\n    #\n    B = A + 1.914 * sin(radians(EARTH_ORIBITAL_VELOCITY * (day_of_year - 2)))\n\n    #\n    # Compute \"the difference between the angles moved at mean speed, and at\n    # the corrected speed projected onto the equatorial plane, and [divide] by\n    # 180 to get the difference in 'half turns'\"\n    #\n    movement_on_equatorial_plane = degrees(\n        atan2(\n            tan(radians(B)),\n            cos(EARTH_AXIS_TILT)\n        )\n    )\n    eot_half_turns = (A - movement_on_equatorial_plane) / 180\n\n    result = 720 * (eot_half_turns - int(eot_half_turns + 0.5))\n\n    return radians(result)", "response": "Compute the equation of time for the given date."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compute_zuhr_utc(day, longitude):\n    eot = equation_of_time(day)\n\n    #\n    # Formula as described by PrayTime.org doesn't work in Eastern hemisphere\n    # because it expects to be subtracting a negative longitude. +abs() should\n    # do the trick\n    #\n\n    zuhr_time_utc = 12 + (abs(longitude) / 15) - eot\n    return abs(zuhr_time_utc) % 24", "response": "Compute the UTC floating point time for Zuhr given date and longitude."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the floating point time difference between mid - day and an angle.", "response": "def compute_time_at_sun_angle(day, latitude, angle):\n    \"\"\"Compute the floating point time difference between mid-day and an angle.\n\n    All the prayers are defined as certain angles from mid-day (Zuhr).\n    This formula is taken from praytimes.org/calculation\n\n    :param day: The day to which to compute for\n    :param longitude: Longitude of the place of interest\n    :angle: The angle at which to compute the time\n    :returns: The floating point time delta between Zuhr and the angle, the\n              sign of the result corresponds to the sign of the angle\n    \"\"\"\n    positive_angle_rad = radians(abs(angle))\n    angle_sign = abs(angle)/angle\n\n    latitude_rad = radians(latitude)\n\n    declination = radians(sun_declination(day))\n\n    numerator = -sin(positive_angle_rad) - sin(latitude_rad) * sin(declination)\n\n    denominator = cos(latitude_rad) * cos(declination)\n\n    time_diff = degrees(acos(numerator/denominator)) / 15\n\n    return time_diff * angle_sign"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the time at which an object s shadow is a multiple of its length.", "response": "def time_at_shadow_length(day, latitude, multiplier):\n    \"\"\"Compute the time at which an object's shadow is a multiple of its length.\n\n    Specifically, determine the time the length of the shadow is a multiple of\n    the object's length + the length of the object's shadow at noon\n\n    This is used in the calculation for Asr time. Hanafi uses a multiplier of\n    2, and everyone else uses a multiplier of 1\n\n    Algorithm taken almost directly from PrayTimes.org code\n\n    :param day: The day which to compute for\n    :param latitude: The latitude of the place of interest\n    :param: multiplier: The multiplier of the object's length\n    :returns: The floating point time delta between Zuhr and the time at which\n              the lenghth of the shadow is as defined\n    \"\"\"\n    latitude_rad = radians(latitude)\n    declination = radians(sun_declination(day))\n\n    angle = arccot(\n        multiplier +\n        tan(abs(latitude_rad - declination))\n    )\n\n    numerator = sin(angle) - sin(latitude_rad)*sin(declination)\n    denominator = cos(latitude_rad) * cos(declination)\n\n    return degrees(acos(numerator/denominator)) / 15"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nrounds the given value.", "response": "def round(self, x):\n        \"\"\"Round the given value.\n        \n        @param x: to round\n        @type x: numeric  \n        \"\"\"\n        fraction, scaled_x, scale = self._get_fraction(x)\n        rounddown = fraction < .5\n        if rounddown:\n            result = math.floor(scaled_x) / scale\n        else:\n            result = math.ceil(scaled_x) / scale\n        self._record_roundoff_error(x, result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a range header as used by the dojo Json Rest store.", "response": "def parse_range_header(range):\n    '''\n    Parse a range header as used by the dojo Json Rest store.\n\n    :param str range: The content of the range header to be parsed.\n        eg. `items=0-9`\n    :returns: A dict with keys start, finish and number or `False` if the\n        range is invalid.\n    '''\n    match = re.match('^items=([0-9]+)-([0-9]+)$', range)\n    if match:\n        start = int(match.group(1))\n        finish = int(match.group(2))\n        if finish < start:\n            finish = start\n        return {\n            'start': start,\n            'finish': finish,\n            'number': finish - start + 1\n        }\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on(self, event):\n        handler = self._handlers.get(event, None)\n        if not handler:\n            raise ValueError(\"Unknown event '{}'\".format(event))\n        return handler.register", "response": "Returns a wrapper for the given event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a new event with available keys.", "response": "def register(self, event, keys):\n        \"\"\"\n        Register a new event with available keys.\n        Raises ValueError when the event has already been registered.\n\n        Usage:\n\n            dispatch.register(\"my_event\", [\"foo\", \"bar\", \"baz\"])\n\n        \"\"\"\n        if self.running:\n            raise RuntimeError(\"Can't register while running\")\n        handler = self._handlers.get(event, None)\n        if handler is not None:\n            raise ValueError(\"Event {} already registered\".format(event))\n        self._handlers[event] = EventHandler(event, keys, loop=self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unregister(self, event):\n        if self.running:\n            raise RuntimeError(\"Can't unregister while running\")\n        self._handlers.pop(event, None)", "response": "Unregister all handlers for an event."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming a better initial guess of lambda no improvement", "response": "def pressision_try(orbitals, U, beta, step):\n    \"\"\"perform a better initial guess of lambda\n       no improvement\"\"\"\n    mu, lam = main(orbitals, U, beta, step)\n    mu2, lam2 = linspace(0, U*orbitals, step), zeros(step)\n    for i in range(99):\n        lam2[i+1] = fsolve(restriction, lam2[i], (mu2[i+1], orbitals, U, beta))\n    plot(mu2, 2*orbitals*fermi_dist(-(mu2+lam2), beta), label='Test guess')\n    legend(loc=0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_python_logger():\r\n    global _python_logger\r\n    if _python_logger is None:\r\n        fn = \"a99.log\"\r\n        l = logging.Logger(\"a99\", level=a99.logging_level)\r\n        if a99.flag_log_file:\r\n            add_file_handler(l, fn)\r\n        if a99.flag_log_console:\r\n            ch = logging.StreamHandler()\r\n            ch.setFormatter(_fmtr)\r\n            l.addHandler(ch)\r\n        _python_logger = l\r\n        for line in a99.format_box(\"a99 logging session started @ {}\".format(a99.now_str())):\r\n            l.info(line)\r\n        if a99.flag_log_file:\r\n            l.info(\"$ Logging to console $\")\r\n        if a99.flag_log_file:\r\n            l.info(\"$ Logging to file '{}' $\".format(fn))\r\n\r\n    return _python_logger", "response": "Returns a logger that will receive Python messages."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds file handler to logger.", "response": "def add_file_handler(logger, logFilename=None):\r\n    \"\"\"Adds file handler to logger.\r\n\r\n    File is opened in \"a\" mode (append)\r\n    \"\"\"\r\n    assert isinstance(logger, logging.Logger)\r\n    ch = logging.FileHandler(logFilename, \"a\")\r\n    # ch.setFormatter(logging._defaultFormatter) # todo may change to have same formatter as last handler of logger\r\n    ch.setFormatter(_fmtr)\r\n    logger.addHandler(ch)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating the TerminalSet. update the TerminalSet. Keep elements from self and other but discard elements that are in both.", "response": "def symmetric_difference_update(self, other):\n        # type: (Iterable[Any]) -> _BaseSet\n        \"\"\"\n        Update the TerminalSet.\n        Keep elements from self and other, but discard elements that are in both.\n        :param other: Iterable object with elements to compare with.\n        :return: Current instance with updated state.\n        \"\"\"\n        intersect = self.intersection(other)\n        self.remove(*intersect)\n        for elem in set(other).difference(intersect):\n            self.add(elem)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the spin_z projection operator for a system of nanos N = particles and index = index. where index = 0.. N - 1", "response": "def spin_z(particles, index):\n    \"\"\"Generates the spin_z projection operator for a system of\n        N=particles and for the selected spin index name. where index=0..N-1\"\"\"\n    mat = np.zeros((2**particles, 2**particles))\n\n    for i in range(2**particles):\n        ispin = btest(i, index)\n        if ispin == 1:\n            mat[i, i] = 1\n        else:\n            mat[i, i] = -1\n    return 1/2.*mat"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninserts a value into the specified key and returns a pair.", "response": "def insert(self, val, pipe=None):\n      \"\"\"\\\n      Inserts a value and returns a :class:`Pair <shorten.Pair>`.\n\n      .. admonition :: Key Safety\n\n         Keys and tokens are always inserted with a :class:`Pipeline`, so \n         irrevocable keys will never occur.\n      \n      If `pipe` is given, :class:`KeyInsertError <shorten.KeyInsertError>` and \n      :class:`TokenInsertError <shorten.TokenInsertError>` will not be thrown \n      if duplicate keys and tokens exist. Instead, the nth-from-last results \n      must be checked:\n      \n      ::\n      \n         pipe = redis.pipeline()\n         key, token = short.insert('value', pipe)\n         results = pipe.execute()\n         \n         if not results[-2]:\n            raise KeyInsertError(key)\n\n         if not results[-1]:\n            raise TokenInsertError(token)\n\n\n      :attr val:     a value to insert.\n      :attr pipe:    a Redis pipeline. If `None`, the pair will\n                     be returned immediately. Otherwise they must be\n                     extracted from the pipeline results (see above).\n      \"\"\"\n     \n      p = self.redis.pipeline() if pipe is None else pipe\n      \n      try:\n         key, token, formatted_key, formatted_token = self.next_formatted_pair()\n\n         p.watch(formatted_key, formatted_token)\n\n         # Make this atomic\n         p.multi()      \n\n         # Associate both the value and token with the key to\n         # allow `get_token(key)`\n         p.hsetnx(formatted_key, 'value', val)\n         p.hsetnx(formatted_key, 'token', token)\n         p.setnx(formatted_token, key)\n         \n         if pipe is None:\n            results = p.execute()\n\n            if not results[-2] or not results[-3]:\n               raise KeyInsertError(key, 'key exists')\n\n            if not results[-1]:\n               raise TokenInsertError(token, 'token exists')\n\n         return Pair(key, token)\n\n      except WatchError:\n         raise\n\n      finally:\n         if pipe is None:\n            p.reset()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef revoke(self, token, pipe=None):\n      \n      p = self.redis.pipeline() if pipe is None else pipe    \n      \n      formatted_token = self.format_token(token)\n\n      try:         \n         p.watch(formatted_token)\n\n         # Get the key immediately\n         key = p.get(formatted_token)\n         formatted_key = self.format_key(key)\n\n         # Make this atomic\n         p.multi()\n         p.delete(formatted_key, formatted_token)\n        \n         if pipe is None:\n            if not p.execute()[-1]:\n               raise RevokeError(token, 'token not found')         \n\n      except WatchError:\n         raise\n\n      finally:\n         if pipe is None:\n            p.reset()", "response": "Removes the key associated with the given token from the given pipeline."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse(representation):\n    representation = str(representation).upper().strip()\n\n    if '/' in representation:\n        return parse_interval(representation)\n\n    if representation[0] is 'P':\n        return parse_duration(representation)\n\n    return parse_date(representation)", "response": "Attempts to parse an ISO8601 formatted representation string into a tuple of datetime. datetime and timedelta objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BeginOfEventAction(self, event):\n        self.log.info(\"Simulating event %s\", event.GetEventID())\n        self.sd.setEventNumber(event.GetEventID())", "response": "Begin of event action"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef EndOfEventAction(self, event):\n        self.log.debug('Processesing simulated event %d', event.GetEventID())\n\n        docs = self.sd.getDocs()\n        self.sd.clearDocs()\n\n        for processor in self.processors:\n            docs = processor.process(docs)\n            if not docs:\n                self.log.warning('%s did not return documents in process()!',\n                    processor.__class__.__name__)", "response": "Called when the event is complete."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup(\n            self):\n        \"\"\"\n        **Summary:**\n            *setup the attributes and return*\n        \"\"\"\n\n        return self.arguments, self.settings, self.log, self.dbConn", "response": "setup the attributes and return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that the TCP Port we ve decided to use for tunnelling is available on the server.", "response": "def _checkServer(self, address, port):\n        \"\"\"\n        *Check that the TCP Port we've decided to use for tunnelling is available*\n        \"\"\"\n        # CREATE A TCP SOCKET\n        import socket\n        s = socket.socket()\n\n        try:\n            s.connect((address, port))\n            return True\n        except socket.error, e:\n            self.log.warning(\n                \"\"\"Connection to `%(address)s` on port `%(port)s` failed - try again: %(e)s\"\"\" % locals())\n            return False\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef generate_handler():\n    logger.debug(\"[#] Setting up user, group and permissions\")\n    client = boto3.client(\"iam\", region_name=PRIMARY_REGION)\n\n    # Create the user\n    try:\n        response = client.create_user(\n            UserName=BLOCKADE_USER\n        )\n    except client.exceptions.EntityAlreadyExistsException:\n        logger.debug(\"[!] Blockade user already exists\")\n    logger.info(\"[#] %s user successfully created\" % (BLOCKADE_USER))\n\n    # Create the role\n    try:\n        logger.debug(\"[#] Creating %s role\" % (BLOCKADE_ROLE))\n        response = client.create_role(\n            RoleName=BLOCKADE_ROLE,\n            AssumeRolePolicyDocument=BLOCKADE_ROLE_POLICY,\n            Description=\"Allow a user to manage the administration of Blockade.\"\n        )\n    except client.exceptions.EntityAlreadyExistsException:\n        logger.debug(\"[!] Blockade role already exists\")\n    logger.info(\"[#] %s role successfully created\" % (BLOCKADE_ROLE))\n\n    # Create the group\n    try:\n        logger.debug(\"[#] Creating %s group\" % (BLOCKADE_GROUP))\n        response = client.create_group(\n            GroupName=BLOCKADE_GROUP,\n        )\n    except client.exceptions.EntityAlreadyExistsException:\n        logger.debug(\"[!] Blockade group already exists\")\n    logger.info(\"[#] %s group successfully created\" % (BLOCKADE_GROUP))\n\n    # Generate all policy items\n    logger.debug(\"[#] Creating Blockade IAM policies\")\n    for label in BLOCKADE_POLICIES:\n        logger.debug(\"[#] Creating %s policy\" % (label))\n        try:\n            response = client.create_policy(\n                PolicyName=label,\n                PolicyDocument=POLICIES[label],\n                Description=\"Generated policy from Blockade bootstrap tool\"\n            )\n        except client.exceptions.EntityAlreadyExistsException:\n            logger.debug(\"[!] Blockade policy %s already exists\" % (label))\n        logger.info(\"[#] Blockade %s policy successfully created\" % (label))\n    logger.info(\"[#] Blockade policies successfully created\")\n\n    # Attach policies to all entity types\n    iam = boto3.resource('iam')\n    account_id = iam.CurrentUser().arn.split(':')[4]\n    for label in BLOCKADE_POLICIES + ['PushToCloud', 'APIGatewayAdmin']:\n        logger.debug(\"[#] Attaching %s policy\" % (label))\n        arn = 'arn:aws:iam::{id}:policy/{policy}'.format(id=account_id, policy=label)\n        if label == 'PushToCloud':\n            arn = \"arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs\"\n        if label == 'APIGatewayAdmin':\n            arn = \"arn:aws:iam::aws:policy/AmazonAPIGatewayAdministrator\"\n        client.attach_role_policy(RoleName=BLOCKADE_ROLE, PolicyArn=arn)\n        client.attach_group_policy(GroupName=BLOCKADE_GROUP, PolicyArn=arn)\n    logger.info(\"[#] Blockade policies successfully attached\")\n\n    logger.debug(\"[#] Adding %s to %s group\" % (BLOCKADE_USER, BLOCKADE_GROUP))\n    response = client.add_user_to_group(\n        GroupName=BLOCKADE_GROUP,\n        UserName=BLOCKADE_USER\n    )\n    logger.info(\"[#] %s user is part of %s group\" % (BLOCKADE_USER, BLOCKADE_GROUP))\n\n    return True", "response": "Create the Blockade user and give them permissions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the user group and policies for Blockade.", "response": "def remove_handler():\n    \"\"\"Remove the user, group and policies for Blockade.\"\"\"\n    logger.debug(\"[#] Removing user, group and permissions for Blockade\")\n    client = boto3.client(\"iam\", region_name=PRIMARY_REGION)\n\n    iam = boto3.resource('iam')\n    account_id = iam.CurrentUser().arn.split(':')[4]\n\n    try:\n        logger.debug(\"[#] Removing %s from %s group\" % (BLOCKADE_USER, BLOCKADE_GROUP))\n        response = client.remove_user_from_group(\n            GroupName=BLOCKADE_GROUP,\n            UserName=BLOCKADE_USER\n        )\n    except client.exceptions.NoSuchEntityException:\n        logger.debug(\"[!] Blockade user already removed from group\")\n\n    for label in BLOCKADE_POLICIES + ['PushToCloud', 'APIGatewayAdmin']:\n        logger.debug(\"[#] Removing %s policy\" % (label))\n        arn = 'arn:aws:iam::{id}:policy/{policy}'.format(id=account_id,\n                                                         policy=label)\n        if label == 'PushToCloud':\n            arn = \"arn:aws:iam::aws:policy/service-role/AmazonAPIGatewayPushToCloudWatchLogs\"\n        if label == 'APIGatewayAdmin':\n            arn = \"arn:aws:iam::aws:policy/AmazonAPIGatewayAdministrator\"\n\n        try:\n            response = client.detach_group_policy(\n                GroupName=BLOCKADE_GROUP, PolicyArn=arn)\n        except:\n            pass\n        try:\n            response = client.detach_role_policy(\n                RoleName=BLOCKADE_ROLE, PolicyArn=arn)\n        except:\n            pass\n        try:\n            response = client.delete_policy(PolicyArn=arn)\n        except Exception as e:\n            print(e)\n            pass\n    logger.debug(\"[#] Removed all policies\")\n\n    try:\n        logger.debug(\"[#] Deleting %s user\" % (BLOCKADE_USER))\n        response = client.delete_user(\n            UserName=BLOCKADE_USER\n        )\n    except client.exceptions.NoSuchEntityException:\n        logger.debug(\"[!] %s user already deleted\" % (BLOCKADE_USER))\n\n    try:\n        logger.debug(\"[#] Removing %s group\" % (BLOCKADE_GROUP))\n        response = client.delete_group(GroupName=BLOCKADE_GROUP)\n    except:\n        logger.debug(\"[!] Group already removed\")\n\n    try:\n        logger.debug(\"[#] Removing %s role\" % (BLOCKADE_ROLE))\n        response = client.delete_role(RoleName=BLOCKADE_ROLE)\n    except:\n        logger.debug(\"[!] Role already removed\")\n\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the blockade bucket if not already there.", "response": "def generate_s3_bucket():\n    \"\"\"Create the blockade bucket if not already there.\"\"\"\n    logger.debug(\"[#] Setting up S3 bucket\")\n    client = boto3.client(\"s3\", region_name=PRIMARY_REGION)\n    buckets = client.list_buckets()\n    matches = [x for x in buckets.get('Buckets', list())\n               if x['Name'].startswith(S3_BUCKET)]\n    if len(matches) > 0:\n        logger.debug(\"[*] Bucket already exists\")\n        return matches.pop()\n\n    response = client.create_bucket(\n        Bucket=S3_BUCKET,\n        CreateBucketConfiguration={\n            'LocationConstraint': PRIMARY_REGION\n        }\n    )\n    logger.info(\"[#] Successfully setup the S3 bucket\")\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_s3_bucket():\n    logger.debug(\"[#] Removing S3 bucket\")\n    client = boto3.client(\"s3\", region_name=PRIMARY_REGION)\n    buckets = client.list_buckets()\n    matches = [x for x in buckets.get('Buckets', list())\n               if x['Name'].startswith(S3_BUCKET_NAME)]\n    if len(matches) == 0:\n        return\n    match = matches.pop()['Name']\n    try:\n        response = client.list_objects_v2(\n            Bucket=match,\n        )\n    except client.exceptions.NoSuchBucket:\n        logger.info(\"[!] S3 bucket already deleted\")\n        return True\n\n    while response['KeyCount'] > 0:\n        logger.debug('[*] Deleting %d objects from bucket %s'\n                     % (len(response['Contents']), match))\n        response = client.delete_objects(\n            Bucket=match,\n            Delete={\n                'Objects': [{'Key': obj['Key']} for obj in response['Contents']]\n            }\n        )\n        response = client.list_objects_v2(\n            Bucket=match,\n        )\n\n    logger.debug('[#] Deleting bucket %s' % match)\n    response = client.delete_bucket(\n        Bucket=match\n    )\n    logger.info(\"[#] Successfully deleted the S3 bucket\")\n\n    return response", "response": "Remove the Blockade bucket."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_dynamodb_tables():\n    logger.debug(\"[#] Setting up DynamoDB tables\")\n    client = boto3.client('dynamodb', region_name=PRIMARY_REGION)\n    existing_tables = client.list_tables()['TableNames']\n\n    responses = list()\n    for label in DYNAMODB_TABLES:\n        if label in existing_tables:\n            logger.debug(\"[*] Table %s already exists\" % (label))\n            continue\n\n        kwargs = {\n            'TableName': label,\n            'ProvisionedThroughput': {\n                'ReadCapacityUnits': 5,\n                'WriteCapacityUnits': 5\n            }\n        }\n        kwargs.update(DYNAMODB_SCHEMAS[label])\n        response = client.create_table(**kwargs)\n        responses.append(response)\n        logger.debug(\"[#] Successfully setup DynamoDB table %s\" % (label))\n    logger.info(\"[#] Successfully setup DynamoDB tables\")\n\n    return responses", "response": "Create the Blockade DynamoDB tables."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the Blockade DynamoDB tables.", "response": "def remove_dynamodb_tables():\n    \"\"\"Remove the Blockade DynamoDB tables.\"\"\"\n    logger.debug(\"[#] Removing DynamoDB tables\")\n    client = boto3.client('dynamodb', region_name=PRIMARY_REGION)\n\n    responses = list()\n    for label in DYNAMODB_TABLES:\n        logger.debug(\"[*] Removing %s table\" % (label))\n        try:\n            response = client.delete_table(\n                TableName=label\n            )\n        except client.exceptions.ResourceNotFoundException:\n            logger.info(\"[!] Table %s already removed\" % (label))\n            continue\n        responses.append(response)\n        logger.debug(\"[*] Removed %s table\" % (label))\n    logger.info(\"[#] Successfully removed DynamoDB tables\")\n\n    return responses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_lambda_functions():\n    logger.debug(\"[#] Setting up the Lambda functions\")\n    aws_lambda = boto3.client('lambda', region_name=PRIMARY_REGION)\n    functions = aws_lambda.list_functions().get('Functions')\n    existing_funcs = [x['FunctionName'] for x in functions]\n\n    iam = boto3.resource('iam')\n    account_id = iam.CurrentUser().arn.split(':')[4]\n\n    responses = list()\n    for label in LAMBDA_FUNCTIONS:\n        if label in existing_funcs:\n            logger.debug(\"[*] Lambda function %s already exists\" % (label))\n            continue\n        dir_path = os.path.dirname(os.path.realpath(__file__))\n        dir_path = dir_path.replace('/cli', '/aws')\n\n        kwargs = {\n            'Runtime': 'python2.7',\n            'Role': 'arn:aws:iam::{0}:role/{1}'.format(account_id, BLOCKADE_ROLE),\n            'Timeout': 3,\n            'MemorySize': 128,\n            'Publish': True,\n            'Code': {\n                'ZipFile': open(\"{0}/lambda-zips/{1}.zip\".format(dir_path, label), 'rb').read()\n            }\n        }\n        kwargs.update(LAMBDA_SCHEMA[label])\n        logger.debug(\"[#] Setting up the %s Lambda function\" % (label))\n        response = aws_lambda.create_function(**kwargs)\n        responses.append(response)\n        logger.debug(\"[#] Successfully setup Lambda function %s\" % (label))\n    logger.info(\"[#] Successfully setup Lambda functions\")\n\n    return responses", "response": "Create the Blockade Lambda functions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the Lambda functions from the blockade.", "response": "def remove_lambda_functions():\n    \"\"\"Remove the Blockade Lambda functions.\"\"\"\n    logger.debug(\"[#] Removing the Lambda functions\")\n    client = boto3.client('lambda', region_name=PRIMARY_REGION)\n\n    responses = list()\n    for label in LAMBDA_FUNCTIONS:\n        try:\n            response = client.delete_function(\n                FunctionName=label,\n            )\n        except client.exceptions.ResourceNotFoundException:\n            logger.info(\"[!] Function %s already removed\" % (label))\n            continue\n        responses.append(response)\n        logger.debug(\"[*] Removed %s function\" % (label))\n    logger.info(\"[#] Successfully removed Lambda functions\")\n\n    return responses"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_api_gateway():\n    logger.debug(\"[#] Setting up the API Gateway\")\n    client = boto3.client('apigateway', region_name=PRIMARY_REGION)\n    matches = [x for x in client.get_rest_apis().get('items', list())\n               if x['name'] == API_GATEWAY]\n    if len(matches) > 0:\n        logger.debug(\"[#] API Gateway already setup\")\n        return matches.pop()\n\n    response = client.create_rest_api(\n        name=API_GATEWAY,\n        description='REST-API to power the Blockade service'\n    )\n    logger.info(\"[#] Successfully setup the API Gateway\")\n\n    return response", "response": "Create the Blockade API Gateway REST service."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef generate_admin_resource():\n    logger.debug(\"[#] Setting up the admin resource\")\n    client = boto3.client('apigateway', region_name=PRIMARY_REGION)\n    existing = get_api_gateway_resource(\"admin\")\n    if existing:\n        logger.debug(\"[#] API admin resource already created\")\n        return True\n    matches = [x for x in client.get_rest_apis().get('items', list())\n               if x['name'] == API_GATEWAY]\n    match = matches.pop()\n    resource_id = get_api_gateway_resource('/')\n    response = client.create_resource(\n        restApiId=match.get('id'),\n        parentId=resource_id,\n        pathPart='admin'\n    )\n    logger.info(\"[#] Successfully setup the admin resource\")\n\n    return response", "response": "Create the Blockade admin resource for the REST services."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the resource associated with our gateway.", "response": "def get_api_gateway_resource(name):\n    \"\"\"Get the resource associated with our gateway.\"\"\"\n    client = boto3.client('apigateway', region_name=PRIMARY_REGION)\n    matches = [x for x in client.get_rest_apis().get('items', list())\n               if x['name'] == API_GATEWAY]\n    match = matches.pop()\n    resources = client.get_resources(restApiId=match.get('id'))\n    resource_id = None\n    for item in resources.get('items', list()):\n        if item.get('pathPart', '/') != name:\n            continue\n        resource_id = item['id']\n    return resource_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef generate_api_resources():\n    client = boto3.client('apigateway', region_name=PRIMARY_REGION)\n    matches = [x for x in client.get_rest_apis().get('items', list())\n               if x['name'] == API_GATEWAY]\n    match = matches.pop()\n\n    iam = boto3.resource('iam')\n    account_id = iam.CurrentUser().arn.split(':')[4]\n\n    for label in API_GATEWAY_RESOURCES:\n        schema = API_GATEWAY_RESOURCE_SCHEMA[label]\n        existing = get_api_gateway_resource(schema['resource']['path'])\n        if existing:\n            logger.debug(\"[#] API resource %s already created\" % (label))\n            continue\n\n        resource_id = get_api_gateway_resource('/')\n        if schema['admin']:\n            resource_id = get_api_gateway_resource('admin')\n\n        logger.debug(\"[#] Adding %s endpoint\" % (label))\n        schema = API_GATEWAY_RESOURCE_SCHEMA[label]\n\n        logger.debug(\"[#] Creating %s resource\" % (schema['resource']['path']))\n        resource = client.create_resource(\n            restApiId=match.get('id'),\n            parentId=resource_id,\n            pathPart=schema['resource']['path']\n        )\n        logger.debug(\"[#] Created %s resource\" % (schema['resource']['path']))\n\n        logger.debug(\"[#] Creating %s method\" % (schema['resource']['method']))\n        method = client.put_method(\n            restApiId=match.get('id'),\n            resourceId=resource.get('id'),\n            httpMethod=schema['resource']['method'],\n            authorizationType='NONE'\n        )\n        logger.debug(\"[#] Created %s method\" % (schema['resource']['method']))\n\n        logger.debug(\"[#] Creating %s integration\" % (label))\n        uri = \"arn:aws:apigateway:{region}:lambda:path/2015-03-31/functions/\"\n        uri += \"arn:aws:lambda:{region}:{id}:function:{func}/invocations\"\n        integration = client.put_integration(\n            restApiId=match.get('id'),\n            resourceId=resource.get('id'),\n            httpMethod=schema['resource']['method'],\n            type='AWS',\n            integrationHttpMethod='POST',\n            uri=uri.format(id=account_id, region=PRIMARY_REGION, func=label),\n            requestTemplates=schema['request']['template'],\n            passthroughBehavior='WHEN_NO_TEMPLATES'\n        )\n        logger.debug(\"[#] Created %s integration\" % (label))\n\n        logger.debug(\"[#] Creating %s response method\" % (label))\n        method_reponse = client.put_method_response(\n            restApiId=match.get('id'),\n            resourceId=resource.get('id'),\n            httpMethod=schema['resource']['method'],\n            statusCode='200'\n        )\n        logger.debug(\"[#] Created %s response method\" % (label))\n\n        logger.debug(\"[#] Creating %s integration response\" % (label))\n        integration_response = client.put_integration_response(\n            restApiId=match.get('id'),\n            resourceId=resource.get('id'),\n            httpMethod=schema['resource']['method'],\n            statusCode='200',\n            responseTemplates=schema['response']['template']\n        )\n        logger.debug(\"[#] Created %s integration response\" % (label))\n\n        logger.debug(\"[#] Generating %s permissions\" % (label))\n        aws_lambda = boto3.client('lambda', region_name=PRIMARY_REGION)\n\n        if not schema['admin']:\n            arn = \"arn:aws:execute-api:{region}:{account_id}:{rest_id}/*/{method}/{path}\"\n        else:\n            arn = \"arn:aws:execute-api:{region}:{account_id}:{rest_id}/*/{method}/admin/{path}\"\n        aws_lambda.add_permission(\n            FunctionName=label,\n            StatementId='BlockadeBootstrap-%d' % (random.randint(0, 9999)),\n            Action='lambda:InvokeFunction',\n            Principal='apigateway.amazonaws.com',\n            SourceArn=arn.format(region=PRIMARY_REGION, account_id=account_id,\n                                 rest_id=match.get('id'),\n                                 method=schema['resource']['method'],\n                                 path=schema['resource']['path'])\n        )\n        logger.debug(\"[#] Generated %s permissions\" % (label))\n\n    logger.debug(\"[#] Creating production deployment\")\n    deployment = client.create_deployment(\n        restApiId=match.get('id'),\n        stageName='prod'\n    )\n    url = \"https://{rest_id}.execute-api.{region}.amazonaws.com/prod/\"\n    url = url.format(rest_id=match.get('id'), region=PRIMARY_REGION)\n    logger.debug(\"[#] Deployment is accessible: %s\" % (url))\n\n    return url", "response": "Generate the Blockade API resources."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_api_gateway():\n    logger.debug(\"[#] Removing API Gateway\")\n    client = boto3.client('apigateway', region_name=PRIMARY_REGION)\n    matches = [x for x in client.get_rest_apis().get('items', list())\n               if x['name'] == API_GATEWAY]\n    if len(matches) == 0:\n        logger.info(\"[!] API Gateway already removed\")\n        return True\n    match = matches.pop()\n    response = client.delete_rest_api(\n        restApiId=match.get('id')\n    )\n    logger.info(\"[#] Removed API Gateway\")\n\n    return response", "response": "Remove the Blockade REST API service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n    parser = ArgumentParser()\n    subs = parser.add_subparsers(dest='cmd')\n    setup_parser = subs.add_parser('setup')\n    setup_parser.add_argument('-r', '--region', default=PRIMARY_REGION,\n                              help='AWS region to install all services')\n    setup_parser.add_argument('-d', '--debug', action='store_true',\n                              help='Run in debug mode')\n    setup_parser.add_argument('--rollback', action='store_true',\n                              help='Rollback configuration on failure')\n    setup_parser.add_argument('--skip-node-setup', action='store_true',\n                              help='Rollback configuration on failure')\n    setup_parser = subs.add_parser('teardown')\n    setup_parser.add_argument('-r', '--region', default=PRIMARY_REGION,\n                              help='AWS region to delete all services')\n    setup_parser.add_argument('-d', '--debug', action='store_true',\n                              help='Run in debug mode')\n    args = parser.parse_args()\n\n    if args.region:\n        if args.region not in SUPPORTED_REGIONS:\n            raise Exception(\"INVALID_REGION: Region must be one of: %s\"\n                            % (', '.join(SUPPORTED_REGIONS)))\n        global PRIMARY_REGION\n        PRIMARY_REGION = args.region\n\n    if args.debug:\n        logger.setLevel(logging.DEBUG)\n\n    if args.cmd == 'setup':\n        try:\n            generate_handler()\n            time.sleep(7)\n            generate_s3_bucket()\n            generate_dynamodb_tables()\n            generate_lambda_functions()\n            generate_api_gateway()\n            generate_admin_resource()\n            api_node = generate_api_resources()\n        except Exception as e:\n            logger.error(str(e))\n            if args.rollback:\n                logger.info(\"[!] Rolling back deployed services\")\n                remove_s3_bucket()\n                remove_dynamodb_tables()\n                remove_lambda_functions()\n                remove_api_gateway()\n                remove_handler()\n\n        if not args.skip_node_setup:\n            email = input(\"[*] Blockade admin email: \")\n            if email.find('@') < 0:\n                logger.error(\"[!] %s does not appear to be an email\" % email)\n                email = input(\"[*] Blockade admin email: \")\n            name = input(\"[*] Blockade admin name: \")\n\n            url = api_node + \"admin/add-user\"\n            params = {'user_email': email, 'user_name': name,\n                      'user_role': 'admin'}\n            headers = {'Content-Type': 'application/json'}\n            response = requests.post(url, data=json.dumps(params),\n                                     headers=headers)\n            loaded = json.loads(response.content)\n            logger.info(\"[#] Successfully added Blockade admin\")\n            logger.debug(loaded)\n            print(\"---------------------------------------------------------------------------\")\n            print(\"Blockade Server: %s\" % api_node)\n            print(\"Blockade Admin: %s\" % loaded['email'])\n            print(\"Blockade API Key: %s\" % loaded['api_key'])\n            print(\"---------------------------------------------------------------------------\")\n            print(\"Quick Config: blockade-cfg setup %s %s --api-node=%s\"\n                  % (loaded['email'], loaded['api_key'], api_node))\n            print(\"Next steps: Add indicators to your node with our analyst toolbench: %s\" % (ANALYST_TOOLBENCH))\n            print(\"For more documentation on other cloud node actions, see %s.\" % (CLOUD_NODE_DOCS))\n\n    if args.cmd == 'teardown':\n        remove_s3_bucket()\n        remove_dynamodb_tables()\n        remove_lambda_functions()\n        remove_api_gateway()\n        remove_handler()", "response": "Run along little fella."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a function that delegates based on the request s HTTP method.", "response": "def method_delegate(**methods):\n    \"\"\"\n    Construct a renderer that delegates based on the request's HTTP method.\n\n    \"\"\"\n\n    methods = {k.upper(): v for k, v in iteritems(methods)}\n\n    if PY3:\n        methods = {k.encode(\"utf-8\"): v for k, v in iteritems(methods)}\n\n    def render(request):\n        renderer = methods.get(request.method)\n        if renderer is None:\n            return Response(code=405)\n        return renderer(request)\n    return render"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef traverse(path, request, resource):\n\n    path = path.lstrip(b\"/\")\n    for component in path and path.split(b\"/\"):\n        if getattr(resource, \"is_leaf\", False):\n            break\n        resource = resource.get_child(name=component, request=request)\n    return resource", "response": "Traverse a root resource retrieving the appropriate child for the request."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef every_other(pipe, how_many=1):\n    ''' feeding this function a pipe yields every other (or how ever many)\n        objects you want at a time.\n    '''\n    for i,x in zip(pipe, cycle(repeater([True,False], how_many))):\n        if x:\n            yield i", "response": "feeding this function a pipe yields every other object in the order that they appear. how_many is the number of items you want to iterate over."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new Address", "response": "def create_address(cls, address, **kwargs):\n        \"\"\"Create Address\n\n        Create a new Address\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_address(address, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Address address: Attributes of address to create (required)\n        :return: Address\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_address_with_http_info(address, **kwargs)\n        else:\n            (data) = cls._create_address_with_http_info(address, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting an instance of Address by its ID.", "response": "def delete_address_by_id(cls, address_id, **kwargs):\n        \"\"\"Delete Address\n\n        Delete an instance of Address by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_address_by_id(address_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str address_id: ID of address to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_address_by_id_with_http_info(address_id, **kwargs)\n        else:\n            (data) = cls._delete_address_by_id_with_http_info(address_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind Address by ID Return single instance of Address by its ID.", "response": "def get_address_by_id(cls, address_id, **kwargs):\n        \"\"\"Find Address\n\n        Return single instance of Address by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_address_by_id(address_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str address_id: ID of address to return (required)\n        :return: Address\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_address_by_id_with_http_info(address_id, **kwargs)\n        else:\n            (data) = cls._get_address_by_id_with_http_info(address_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_all_addresses(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_addresses_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_addresses_with_http_info(**kwargs)\n            return data", "response": "List Addresses\n        Return a list of Addresses\n       "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_address_by_id(cls, address_id, address, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_address_by_id_with_http_info(address_id, address, **kwargs)\n        else:\n            (data) = cls._replace_address_by_id_with_http_info(address_id, address, **kwargs)\n            return data", "response": "Replace all attributes of Address\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates attributes of Address", "response": "def update_address_by_id(cls, address_id, address, **kwargs):\n        \"\"\"Update Address\n\n        Update attributes of Address\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_address_by_id(address_id, address, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str address_id: ID of address to update. (required)\n        :param Address address: Attributes of address to update. (required)\n        :return: Address\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_address_by_id_with_http_info(address_id, address, **kwargs)\n        else:\n            (data) = cls._update_address_by_id_with_http_info(address_id, address, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command in a sub - shell and returns a tuple of stdout stderr info.", "response": "def run_shell_command(cmd, args=None, filename_out=None, filename_err=None):\n    \"\"\"Run operating system command cmd with arguments from the args\n    tuple in a sub-shell and return tuple (exit status code, stdout\n    info, stderr info).\n\n    @param cmd: Command to execute in a shell; may contain %s\n        placeholders for arguments that will be expanded from the args\n        tuple. Example: cmd='echo %s', args = ('hello',).\n    @type cmd: string\n\n    @param args: Arguments to be escaped and substituted for %s\n        placeholders in cmd.\n    @type args: tuple of strings\n\n    @param filename_out: Desired filename for stdout output\n        (optional; see below).\n    @type filename_out: string\n\n    @param filename_err: Desired filename for stderr output\n        (optional; see below).\n    @type filename_err: string\n\n    @return: Tuple (exit code, string containing stdout output buffer,\n        string containing stderr output buffer).\n\n        However, if either filename_out or filename_err are defined,\n        then the output buffers are not passed back but rather written\n        into filename_out/filename_err pathnames.  This is useful for\n        commands that produce big files, for which it is not practical\n        to pass results back to the callers in a Python text buffer.\n        Note that it is the client's responsibility to name these\n        files in the proper fashion (e.g. to be unique) and to close\n        these files after use.\n    @rtype: (number, string, string)\n\n    @raise TypeError: if the number of args does not correspond to the\n       number of placeholders in cmd.\n\n    @note: Uses temporary files to store out/err output, not pipes due\n        to potential pipe race condition on some systems.  If either\n        filename_out or filename_err are defined, then do not create\n        temporary files, but store stdout or stderr output directly in\n        these files instead, and do not delete them after execution.\n    \"\"\"\n    # wash args value:\n    if args:\n        args = tuple(args)\n    else:\n        args = ()\n    # construct command with argument substitution:\n    try:\n        cmd = cmd % tuple([escape_shell_arg(x) for x in args])\n    except TypeError:\n        # there were problems with %s and args substitution, so raise an error:\n        raise\n    cmd_out = ''\n    cmd_err = ''\n    # create files:\n    if filename_out:\n        cmd_out_fd = os.open(filename_out, os.O_CREAT, 0o644)\n        file_cmd_out = filename_out\n    else:\n        cmd_out_fd, file_cmd_out = \\\n            tempfile.mkstemp(\"invenio_utils.shell-cmd-out\")\n    if filename_err:\n        cmd_err_fd = os.open(filename_err, os.O_CREAT, 0o644)\n        file_cmd_err = filename_err\n    else:\n        cmd_err_fd, file_cmd_err = \\\n            tempfile.mkstemp(\"invenio_utils.shell-cmd-err\")\n    # run command:\n    cmd_exit_code = os.system(\"%s > %s 2> %s\" % (cmd,\n                                                 file_cmd_out,\n                                                 file_cmd_err))\n    # delete temporary files: (if applicable)\n    if not filename_out:\n        if os.path.exists(file_cmd_out):\n            cmd_out_fo = open(file_cmd_out)\n            cmd_out = cmd_out_fo.read()\n            cmd_out_fo.close()\n            os.remove(file_cmd_out)\n    if not filename_err:\n        if os.path.exists(file_cmd_err):\n            cmd_err_fo = open(file_cmd_err)\n            cmd_err = cmd_err_fo.read()\n            cmd_err_fo.close()\n            os.remove(file_cmd_err)\n    os.close(cmd_out_fd)\n    os.close(cmd_err_fd)\n    # return results:\n    return cmd_exit_code, cmd_out, cmd_err"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef run_process_with_timeout(\n        args,\n        filename_in=None,\n        filename_out=None,\n        filename_err=None,\n        cwd=None,\n        timeout=None,\n        sudo=None):\n    \"\"\"Execute the specified process but within a certain timeout.\n\n    @param args: the actuall process. This should be a list of string as in:\n         ['/usr/bin/foo', '--bar', 'baz']\n    @type args: list of string\n\n    @param filename_in: the path to a file that should be provided as standard\n        input to the process. If None this will default to /dev/null\n    @type filename_in: string\n\n    @param filename_out: Desired filename for stdout output\n        (optional; see below).\n    @type filename_out: string\n\n    @param filename_err: Desired filename for stderr output\n        (optional; see below).\n    @type filename_err: string\n\n    @param cwd: the path from where to execute the process\n    @type cwd: string\n\n    @param timeout: the timeout in seconds after which to consider the\n        process execution as failed. a Timeout exception will be raised\n    @type timeout: int\n\n    @param sudo: the optional name of the user under which to execute the\n        process (by using sudo, without prompting for a password)\n    @type sudo: string\n\n    @return: Tuple (exit code, string containing stdout output buffer,\n        string containing stderr output buffer).\n\n        However, if either filename_out or filename_err are defined,\n        then the output buffers are not passed back but rather written\n        into filename_out/filename_err pathnames.  This is useful for\n        commands that produce big files, for which it is not practical\n        to pass results back to the callers in a Python text buffer.\n        Note that it is the client's responsibility to name these\n        files in the proper fashion (e.g. to be unique) and to close\n        these files after use.\n    @rtype: (number, string, string)\n\n    @raise Timeout: if the process does not terminate within the timeout\n    \"\"\"\n    if timeout is None:\n        timeout = current_app.config['CFG_MISCUTIL_DEFAULT_PROCESS_TIMEOUT']\n    stdout = stderr = None\n    if filename_in is not None:\n        stdin = open(filename_in)\n    else:\n        # FIXME: should use NUL on Windows\n        stdin = open('/dev/null', 'r')\n    if filename_out:\n        stdout = open(filename_out, 'w')\n    if filename_err:\n        stderr = open(filename_err, 'w')\n    tmp_stdout = StringIO()\n    tmp_stderr = StringIO()\n    if sudo is not None:\n        args = ['sudo', '-u', sudo, '-S'] + list(args)\n    # See: <http://stackoverflow.com/questions/3876886/timeout-a-subprocess>\n    process = subprocess.Popen(\n        args,\n        stdin=stdin,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        close_fds=True,\n        cwd=cwd,\n        preexec_fn=os.setpgrp)\n\n    # See:\n    # <http://stackoverflow.com/questions/375427/non-blocking-read-on-a-stream-in-python>\n    fd = process.stdout.fileno()\n    fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n    fd = process.stderr.fileno()\n    fl = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)\n    fd_to_poll = [process.stdout, process.stderr]\n    select_timeout = 0.5\n    t1 = time.time()\n    try:\n        while process.poll() is None:\n            if time.time() - t1 >= timeout:\n                if process.stdin is not None:\n                    process.stdin.close()\n                time.sleep(1)\n                if process.poll() is None:\n                    # See:\n                    # <http://stackoverflow.com/questions/3876886/timeout-a-subprocess>\n                    os.killpg(process.pid, signal.SIGTERM)\n                    time.sleep(1)\n                if process.poll() is None:\n                    os.killpg(process.pid, signal.SIGKILL)\n                try:\n                    os.waitpid(process.pid, 0)\n                except OSError:\n                    pass\n                raise Timeout()\n            for fd in select.select(fd_to_poll, [], [], select_timeout)[0]:\n                if fd == process.stdout:\n                    buf = process.stdout.read(65536)\n                    if stdout is None:\n                        tmp_stdout.write(buf)\n                    else:\n                        stdout.write(buf)\n                elif fd == process.stderr:\n                    buf = process.stderr.read(65536)\n                    if stderr is None:\n                        tmp_stderr.write(buf)\n                    else:\n                        stderr.write(buf)\n                else:\n                    raise OSError(\"fd %s is not a valid file descriptor\" % fd)\n    finally:\n        while True:\n            # Let's just read what is remaining to read.\n            for fd in select.select(fd_to_poll, [], [], select_timeout)[0]:\n                if fd == process.stdout:\n                    buf = process.stdout.read(65536)\n                    tmp_stdout.write(buf)\n                    if stdout is not None:\n                        stdout.write(buf)\n                elif fd == process.stderr:\n                    buf = process.stderr.read(65536)\n                    tmp_stderr.write(buf)\n                    if stderr is not None:\n                        stderr.write(buf)\n                else:\n                    raise OSError(\"fd %s is not a valid file descriptor\" % fd)\n            else:\n                break\n    return process.poll(), tmp_stdout.getvalue(), tmp_stderr.getvalue()", "response": "Execute the specified process but within a certain timeout."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nescaping shell argument shell_arg by placing it within single - quotes.", "response": "def escape_shell_arg(shell_arg):\n    \"\"\"Escape shell argument shell_arg by placing it within\n    single-quotes.  Any single quotes found within the shell argument\n    string will be escaped.\n\n    @param shell_arg: The shell argument to be escaped.\n    @type shell_arg: string\n    @return: The single-quote-escaped value of the shell argument.\n    @rtype: string\n    @raise TypeError: if shell_arg is not a string.\n    @see: U{http://mail.python.org/pipermail/python-list/2005-October/346957.html}\n    \"\"\"\n\n    if isinstance(shell_arg, six.text_type):\n        msg = \"ERROR: escape_shell_arg() expected string argument but \" \\\n              \"got '%s' of type '%s'.\" % (repr(shell_arg), type(shell_arg))\n        raise TypeError(msg)\n\n    return \"'%s'\" % shell_arg.replace(\"'\", r\"'\\''\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake mkstemp more robust against AFS glitches.", "response": "def retry_mkstemp(suffix='', prefix='tmp', directory=None, max_retries=3):\n    \"\"\"\n    Make mkstemp more robust against AFS glitches.\n    \"\"\"\n    if directory is None:\n        directory = current_app.config['CFG_TMPSHAREDDIR']\n    for retry_count in range(1, max_retries + 1):\n        try:\n            tmp_file_fd, tmp_file_name = tempfile.mkstemp(suffix=suffix,\n                                                          prefix=prefix,\n                                                          dir=directory)\n        except OSError as e:\n            if e.errno == 19 and retry_count <= max_retries:\n                # AFS Glitch?\n                time.sleep(10)\n            else:\n                raise\n        else:\n            break\n    return tmp_file_fd, tmp_file_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsplitting the command line argument value into a set of integers.", "response": "def split_cli_ids_arg(value):\n    \"\"\"\n    Split ids given in the command line\n    Possible formats are:\n    * 1\n    * 1,2,3,4\n    * 1-5,20,30,40\n    Returns respectively\n    * set([1])\n    * set([1,2,3,4])\n    * set([1,2,3,4,5,20,30,40])\n    \"\"\"\n    def parse(el):\n        el = el.strip()\n        if not el:\n            ret = []\n        elif '-' in el:\n            start, end = el.split('-', 1)\n            ret = xrange(int(start), int(end) + 1)\n        else:\n            ret = [int(el)]\n        return ret\n    return set(chain(*(parse(c) for c in value.split(',') if c.strip())))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a sorted dictionary of form field instances from the passed in attrs plus anyother fields on the base classes.", "response": "def get_declared_fields(bases, attrs, cls_filter,\n        with_base_fields=True,\n        extra_attr_name='base_fields'):\n    \"\"\"\n    Create a list of form field instances from the passed in 'attrs', plus any\n    similar fields on the base classes (in 'bases'). This is used by both the\n    Form and ModelForm metclasses.\n\n    If 'with_base_fields' is True, all fields from the bases are used.\n    Otherwise, only fields in the 'declared_fields' attribute on the bases are\n    used. The distinction is useful in ModelForm subclassing.\n    Also integrates any additional media definitions\n    \"\"\"\n    fields = [(field_name, attrs.pop(field_name))\\\n            for field_name, obj in attrs.items()\\\n                if isinstance(obj, cls_filter)]\n\n    fields.sort(key=lambda x: x[1].creation_counter)\n\n    # If this class is subclassing another Form, add that Form's fields.\n    # Note that we loop over the bases in *reverse*. This is necessary in\n    # order to preserve the correct order of fields.\n    if with_base_fields:\n        for base in reversed(bases):\n            if hasattr(base, extra_attr_name):\n                fields = getattr(base, extra_attr_name).items() + fields\n    else:\n        for base in reversed(bases):\n            if hasattr(base, 'declared_fields'):\n                fields = base.declared_fields.items() + fields\n\n    return SortedDict(fields)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a generator when created", "response": "def started(generator_function):\n    \"\"\" starts a generator when created \"\"\"\n    @wraps(generator_function)\n    def wrapper(*args, **kwargs):\n        g = generator_function(*args, **kwargs)\n        next(g)\n        return g\n    return wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd text of labelError.", "response": "def add_log_error(self, x, flag_also_show=False, E=None):\r\n        \"\"\"Sets text of labelError.\"\"\"\r\n        if len(x) == 0:\r\n            x = \"(empty error)\"\r\n            tb.print_stack()\r\n        x_ = x\r\n        if E is not None:\r\n            a99.get_python_logger().exception(x_)\r\n        else:\r\n            a99.get_python_logger().info(\"ERROR: {}\".format(x_))\r\n\r\n        x = '<span style=\"color: {0!s}\">{1!s}</span>'.format(a99.COLOR_ERROR, x)\r\n        self._add_log_no_logger(x, False)\r\n        if flag_also_show:\r\n            a99.show_error(x_)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlog to 4 different outputs conditionally to 3 and certainly to get_python_logger", "response": "def add_log(self, x, flag_also_show=False):\r\n        \"\"\"Logs to 4 different outputs: conditionally to 3, and certainly to get_python_logger()\"\"\"\r\n\r\n        self._add_log_no_logger(x, flag_also_show)\r\n\r\n        a99.get_python_logger().info(x)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef parse_cache_url(url):\n    config = {}\n\n    url = urlparse.urlparse(url)\n    # Update with environment configuration.\n    config['BACKEND'] = CACHE_SCHEMES[url.scheme]\n    if url.scheme in ('file', 'uwsgi'):\n        config['LOCATION'] = url.path\n        return config\n    elif url.scheme in ('redis', 'hiredis'):\n        if url.netloc == 'unix':\n            location_index = None\n            bits = list(filter(None, url.path.split('/')))\n            # find the end of the socket path\n            for index, bit in enumerate(bits, 1):\n                if bit.endswith(('.sock', '.socket')):\n                    location_index = index\n                    break\n\n            if location_index is None:\n                # no socket file extension found, using the whole location\n                location = bits\n            else:\n                # splitting socket path from database and prefix\n                location = bits[:location_index]\n                rest = bits[location_index:]\n                if len(rest) > 0:\n                    try:\n                        # check if first item of the rest is a database\n                        database = int(rest[0])\n                        prefix = rest[1:]\n                    except ValueError:\n                        # or assume the rest is the prefix\n                        database = 0\n                        prefix = rest\n                else:\n                    database = prefix = None\n\n            full_location = (url.netloc, '/' + '/'.join(location))\n            if database is not None:\n                full_location += (str(database),)\n            config['LOCATION'] = ':'.join(full_location)\n            config['KEY_PREFIX'] = '/'.join(prefix)\n\n        else:\n            try:\n                userpass, hostport = url.netloc.split('@')\n            except ValueError:\n                userpass, hostport = '', url.netloc\n\n            try:\n                username, password = userpass.split(':')\n            except ValueError:\n                pass\n\n            path = list(filter(None, url.path.split('/')))\n            config['LOCATION'] = ':'.join((hostport, path[0]))\n            config['KEY_PREFIX'] = '/'.join(path[1:])\n\n        redis_options = {}\n\n        if url.scheme == 'hiredis':\n            redis_options['PARSER_CLASS'] = 'redis.connection.HiredisParser'\n\n        try:\n            if password:\n                redis_options['PASSWORD'] = password\n        except NameError:  # No password defined\n            pass\n\n        if redis_options:\n            config['OPTIONS'] = redis_options\n\n    else:\n        netloc_list = url.netloc.split(',')\n        if len(netloc_list) > 1:\n            config['LOCATION'] = netloc_list\n        else:\n            config['LOCATION'] = url.netloc\n        config['KEY_PREFIX'] = url.path[1:]\n\n    return config", "response": "Parses a cache URL and returns a dictionary of environment configuration."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config(name='CACHE_URL', default='locmem://'):\n    config = {}\n\n    s = env(name, default)\n\n    if s:\n        config = parse_cache_url(s)\n\n    return config", "response": "Returns configured CACHES dictionary from CACHE_URL"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new Country AttributeNames", "response": "def create_country(cls, country, **kwargs):\n        \"\"\"Create Country\n\n        Create a new Country\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_country(country, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Country country: Attributes of country to create (required)\n        :return: Country\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_country_with_http_info(country, **kwargs)\n        else:\n            (data) = cls._create_country_with_http_info(country, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete_country_by_id(cls, country_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_country_by_id_with_http_info(country_id, **kwargs)\n        else:\n            (data) = cls._delete_country_by_id_with_http_info(country_id, **kwargs)\n            return data", "response": "Delete an instance of Country by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_country_by_id(cls, country_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_country_by_id_with_http_info(country_id, **kwargs)\n        else:\n            (data) = cls._get_country_by_id_with_http_info(country_id, **kwargs)\n            return data", "response": "Find Country by ID Return single instance of Country by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist Countries Return a list of Countries", "response": "def list_all_countries(cls, **kwargs):\n        \"\"\"List Countries\n\n        Return a list of Countries\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_countries(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Country]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_countries_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_countries_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_country_by_id(cls, country_id, country, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_country_by_id_with_http_info(country_id, country, **kwargs)\n        else:\n            (data) = cls._replace_country_by_id_with_http_info(country_id, country, **kwargs)\n            return data", "response": "Replace all attributes of a country in a specific country."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_country_by_id(cls, country_id, country, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_country_by_id_with_http_info(country_id, country, **kwargs)\n        else:\n            (data) = cls._update_country_by_id_with_http_info(country_id, country, **kwargs)\n            return data", "response": "Update attributes of a country."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_user(user, password):\n    return ((user == attowiki.user or attowiki.user is None) and\n            (password == attowiki.password or attowiki.password is None))", "response": "check the auth for user and password"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all the available. rst files in the directory.", "response": "def view_meta_index():\n    \"\"\"List all the available .rst files in the directory.\n\n    view_meta_index is called by the 'meta' url : /__index__\n    \"\"\"\n    rst_files = [filename[2:-4] for filename in sorted(glob.glob(\"./*.rst\"))]\n    rst_files.reverse()\n    return template('index',\n                    type=\"view\",\n                    filelist=rst_files,\n                    name=\"__index__\",\n                    extended_name=None,\n                    history=[],\n                    gitref=None,\n                    is_repo=check_repo())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist all found meta files in the directory.", "response": "def view_meta_admonition(admonition_name, name=None):\n    \"\"\"List all found admonition from all the rst files found in directory.\n\n    view_meta_admonition is called by the 'meta' url: /__XXXXXXX__\n    where XXXXXXX represents and admonition name, like:\n\n    * todo\n    * warning\n    * danger\n    * ...\n\n    .. note:: this function may works for any docutils node, not only\n       admonition\n\n    Keyword Arguments:\n\n        :admonition_name: (str) -- name of the admonition\n    \"\"\"\n    print(\"meta admo: %s - %s\" % (admonition_name, name))\n    admonition = None\n\n    if admonition_name == 'todo':\n        admonition = todo\n    elif admonition_name == 'done':\n        admonition = done\n    elif hasattr(nodes, admonition_name):\n        admonition = getattr(nodes, admonition_name)\n    else:\n        return abort(404)\n\n    doc2_content = \"\"\n\n    doc2_output, doc2_pub = docutils.core.publish_programmatically(\n        source_class=io.StringInput,\n        source=doc2_content,\n        source_path=None,\n        destination_class=io.StringOutput,\n        destination=None, destination_path=None,\n        reader=None, reader_name='standalone',\n        parser=None, parser_name='restructuredtext',\n        writer=AttowikiWriter(), writer_name=None,\n        settings=None, settings_spec=None,\n        settings_overrides=None,\n        config_section=None,\n        enable_exit_status=False)\n\n    section1 = nodes.section(\"{0}_list_file\".format(admonition_name))\n    doc2_pub.reader.document.append(section1)\n    title1 = nodes.title(\"{0} LIST\".format(admonition_name.upper()),\n                         \"{0} LIST\".format(admonition_name.upper()))\n    doc2_pub.reader.document.append(title1)\n    if name is None:\n        rst_files = [filename[2:-4] for filename in sorted(\n            glob.glob(\"./*.rst\"))]\n        rst_files.reverse()\n    else:\n        rst_files = [filename[2:-4] for filename in\n                     sorted(glob.glob(\"./{0}.rst\".format(name)))]\n    for file in rst_files:\n        file_title = False\n        file_handle = open(file + '.rst', 'r')\n        file_content = file_handle.read()\n        file_handle.close()\n        file_content = file_content.decode('utf-8')\n\n        output, pub = docutils.core.publish_programmatically(\n            source_class=io.StringInput, source=file_content,\n            source_path=None,\n            destination_class=io.StringOutput,\n            destination=None, destination_path=None,\n            reader=None, reader_name='standalone',\n            parser=None, parser_name='restructuredtext',\n            writer=None, writer_name='html',\n            settings=None, settings_spec=None,\n            settings_overrides=None,\n            config_section=None,\n            enable_exit_status=False)\n\n        my_settings = pub.get_settings()\n        parser = docutils.parsers.rst.Parser()\n        document = docutils.utils.new_document('test', my_settings)\n        parser.parse(file_content, document)\n        for node in document.traverse(admonition):\n            if not file_title:\n                file_title = True\n                # new section\n                section2 = nodes.section(file)\n                doc2_pub.reader.document.append(section2)\n                # add link to the originating file\n                paragraph = nodes.paragraph()\n                file_target = nodes.target(ids=[file],\n                                           names=[file],\n                                           refuri=\"/\" + file)\n                file_ref = nodes.reference(file, file,\n                                           name=file,\n                                           refuri=\"/\" + file)\n                paragraph.append(nodes.Text(\"in \"))\n                paragraph.append(file_ref)\n                paragraph.append(file_target)\n                paragraph.append(nodes.Text(\":\"))\n                doc2_pub.reader.document.append(paragraph)\n                # doc2_pub.reader.document.append(file_target)\n\n            doc2_pub.reader.document.append(node)\n        doc2_pub.apply_transforms()\n\n    doc2_pub.writer.write(doc2_pub.document, doc2_pub.destination)\n    doc2_pub.writer.assemble_parts()\n    if name is None:\n        display_file_name = '__{0}__'.format(admonition_name)\n        extended_name = None\n    else:\n        display_file_name = '{0}'.format(name)\n        extended_name = '__{0}__'.format(admonition_name)\n    return template('page',\n                    type=\"view\",\n                    name=display_file_name,\n                    extended_name=extended_name,\n                    is_repo=check_repo(),\n                    history=[],\n                    gitref=None,\n                    content=doc2_pub.writer.parts['html_body'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncanceling the edition of an existing page.", "response": "def view_cancel_edit(name=None):\n    \"\"\"Cancel the edition of an existing page.\n\n    Then render the last modification status\n\n    .. note:: this is a bottle view\n\n    if no page name is given, do nothing (it may leave some .tmp. files in\n    the directory).\n\n    Keyword Arguments:\n        :name: (str) -- name of the page (OPTIONAL)\n\n    Returns:\n        bottle response object\n    \"\"\"\n    if name is None:\n        return redirect('/')\n    else:\n        files = glob.glob(\"{0}.rst\".format(name))\n        if len(files) > 0:\n            reset_to_last_commit()\n            return redirect('/' + name)\n        else:\n            return abort(404)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef view_edit(name=None):\n    response.set_header('Cache-control', 'no-cache')\n    response.set_header('Pragma', 'no-cache')\n    if name is None:\n        # new page\n        return template('edit',\n                        type=\"edit\",\n                        name=name,\n                        extended_name=None,\n                        is_repo=check_repo(),\n                        history=[],\n                        gitref=None,\n                        today=datetime.datetime.now().strftime(\"%Y%m%d\"),\n                        content=\"\")\n    else:\n        files = glob.glob(\"{0}.rst\".format(name))\n        if len(files) > 0:\n            file_handle = open(files[0], 'r')\n            return template('edit',\n                            type=\"edit\",\n                            name=name,\n                            extended_name=None,\n                            is_repo=check_repo(),\n                            history=[],\n                            gitref=None,\n                            today=datetime.datetime.now().strftime(\"%Y%m%d\"),\n                            content=file_handle.read())\n        else:\n            return abort(404)", "response": "Edit or creates a new page."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef view_pdf(name=None):\n    if name is None:\n        return view_meta_index()\n\n    files = glob.glob(\"{0}.rst\".format(name))\n    if len(files) > 0:\n        file_handle = open(files[0], 'r')\n        dest_filename = name + '.pdf'\n        doctree = publish_doctree(file_handle.read())\n        try:\n            produce_pdf(doctree_content=doctree,\n                        filename=dest_filename)\n        except:\n            raise\n        else:\n            return static_file(dest_filename,\n                               root='',\n                               download=True)\n    else:\n        return abort(404)", "response": "Render a pdf file based on the given page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nserve a page name. .. note:: this is a bottle view * if the view is called with the POST method, write the new page content to the file, commit the modification and then display the html rendering of the restructured text file * if the view is called with the GET method, directly display the html rendering of the restructured text file Keyword Arguments: :name: (str) -- name of the rest file (without the .rst extension) OPTIONAL if no filename is given, first try to find a \"index.rst\" file in the directory and serve it. If not found, serve the meta page __index__ Returns: bottle response object", "response": "def view_page(name=None):\n    \"\"\"Serve a page name.\n\n    .. note:: this is a bottle view\n\n    * if the view is called with the POST method, write the new page\n      content to the file, commit the modification and then display the\n      html rendering of the restructured text file\n\n    * if the view is called with the GET method, directly display the html\n      rendering of the restructured text file\n\n    Keyword Arguments:\n        :name: (str) -- name of the rest file (without the .rst extension)\n                        OPTIONAL\n\n    if no filename is given, first try to find a \"index.rst\" file in the\n    directory and serve it. If not found, serve the meta page __index__\n\n    Returns:\n        bottle response object\n    \"\"\"\n    if request.method == 'POST':\n        if name is None:\n            # new file\n            if len(request.forms.filename) > 0:\n                name = request.forms.filename\n\n        if name is not None:\n            filename = \"{0}.rst\".format(name)\n            file_handle = open(filename, 'w')\n            file_handle.write(request.forms.content.encode('utf-8'))\n            file_handle.close()\n            add_file_to_repo(filename)\n            commit(filename)\n\n    response.set_header('Cache-control', 'no-cache')\n    response.set_header('Pragma', 'no-cache')\n    if name is None:\n        # we try to find an index file\n        index_files = glob.glob(\"./[Ii][Nn][Dd][Ee][Xx].rst\")\n        if len(index_files) == 0:\n            # not found\n            # redirect to __index__\n            return view_meta_index()\n        else:\n            name = index_files[0][2:-4]\n    files = glob.glob(\"{0}.rst\".format(name))\n    if len(files) > 0:\n        file_handle = open(files[0], 'r')\n        html_body = publish_parts(file_handle.read(),\n                                  writer=AttowikiWriter(),\n                                  settings=None,\n                                  settings_overrides=None)['html_body']\n        history = commit_history(\"{0}.rst\".format(name))\n        return template('page',\n                        type=\"view\",\n                        name=name,\n                        extended_name=None,\n                        is_repo=check_repo(),\n                        history=history,\n                        gitref=None,\n                        content=html_body)\n    else:\n        return static_file(name, '')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nserves a page name from git repo", "response": "def view_history(name, gitref):\n    \"\"\"Serve a page name from git repo (an old version of a page).\n\n    .. note:: this is a bottle view\n\n    * this is a GET only method : you can not change a committed page\n\n    Keyword Arguments:\n        :name: (str) -- name of the rest file (without the .rst extension)\n        :gitref: (str) -- hexsha of the git commit to look into\n\n    Returns:\n        bottle response object or 404 error page\n    \"\"\"\n    response.set_header('Cache-control', 'no-cache')\n    response.set_header('Pragma', 'no-cache')\n    content = read_committed_file(gitref, name + '.rst')\n    if content:\n        html_body = publish_parts(content,\n                                  writer=AttowikiWriter(),\n                                  settings=None,\n                                  settings_overrides=None)['html_body']\n        history = commit_history(name + '.rst')\n        return template('page',\n                        type=\"history\",\n                        name=name,\n                        extended_name=None,\n                        is_repo=check_repo(),\n                        history=history,\n                        gitref=gitref,\n                        content=html_body)\n    else:\n        return abort(404)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef view_history_source(name, gitref=None):\n    response.set_header('Cache-control', 'no-cache')\n    response.set_header('Pragma', 'no-cache')\n    response.set_header('Content-Type', 'text/html; charset=utf-8')\n    if gitref is None:\n        files = glob.glob(\"{0}.rst\".format(name))\n        if len(files) > 0:\n            file_handle = open(files[0], 'r')\n            content = file_handle.read()\n        else:\n            return abort(404)\n    else:\n        content = read_committed_file(gitref, name + '.rst')\n    if content:\n        return template('source_view',\n                        type=\"history\",\n                        name=name,\n                        extended_name='__source__',\n                        is_repo=check_repo(),\n                        history=commit_history(\"{0}.rst\".format(name)),\n                        gitref=gitref,\n                        content=content.decode('utf-8'))\n    else:\n        return abort(404)", "response": "Serve a page name from git repo and return the reST source code"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef view_history_diff(name, gitref):\n    response.set_header('Cache-control', 'no-cache')\n    response.set_header('Pragma', 'no-cache')\n    response.set_header('Content-Type', 'text/html; charset=utf-8')\n    old_content = read_committed_file(gitref, name + '.rst')\n    if old_content:\n        old_content = old_content.decode('utf-8')\n        files = glob.glob(\"{0}.rst\".format(name))\n        if len(files) > 0:\n            file_handle = open(files[0], 'r')\n            current_content = file_handle.read().decode('utf-8')\n            differ = difflib.Differ()\n            result = list(differ.compare(old_content.splitlines(),\n                                         current_content.splitlines()))\n            return template('diff_view',\n                            type=\"history\",\n                            name=name,\n                            extended_name='__diff__',\n                            is_repo=check_repo(),\n                            history=commit_history(\"{0}.rst\".format(name)),\n                            gitref=gitref,\n                            content=result)\n        else:\n            return abort(404)\n    else:\n        return abort(404)", "response": "Serve a page name from git repo and return the diff between the current and the old commited source"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef describeTable(TableName):\n    print('-----------------------------------------')\n    print(TableName+' summary:')\n    try:\n       print('-----------------------------------------')\n       print('Comment: \\n'+LOCAL_TABLE_CACHE[TableName]['header']['comment'])\n    except:\n       pass\n    print('Number of rows: '+str(LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']))\n    print('Table type: '+str(LOCAL_TABLE_CACHE[TableName]['header']['table_type']))\n    print('-----------------------------------------')\n    print('            PAR_NAME           PAR_FORMAT')\n    print('')\n    for par_name in LOCAL_TABLE_CACHE[TableName]['header']['order']:\n        par_format = LOCAL_TABLE_CACHE[TableName]['header']['format'][par_name]\n        print('%20s %20s' % (par_name,par_format))\n    print('-----------------------------------------')", "response": "A simple wrapper for the describeTable function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of columns with a names in ParameterNames from the specified table TableName.", "response": "def getColumns(TableName,ParameterNames):\n    \"\"\"\n    INPUT PARAMETERS: \n        TableName:       source table name           (required)\n        ParameterNames:  list of column names to get (required)\n    OUTPUT PARAMETERS: \n        ListColumnData:   tuple of lists of values from specified column \n    ---\n    DESCRIPTION:\n        Returns columns with a names in ParameterNames from\n        table TableName. Columns are returned as a tuple of lists.\n    ---\n    EXAMPLE OF USAGE:\n        p1,p2,p3 = getColumns('sampletab',('p1','p2','p3'))\n    ---\n    \"\"\"\n    Columns = []\n    for par_name in ParameterNames:\n        Columns.append(LOCAL_TABLE_CACHE[TableName]['data'][par_name])\n    return Columns"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef select(TableName,DestinationTableName=QUERY_BUFFER,ParameterNames=None,Conditions=None,Output=True,File=None):\n    # TODO: Variables defined in ParameterNames ('LET') MUST BE VISIBLE IN Conditions !!\n    # check if table exists\n    if TableName not in LOCAL_TABLE_CACHE.keys():\n        raise Exception('%s: no such table. Check tableList() for more info.' % TableName)\n    if not ParameterNames: ParameterNames=LOCAL_TABLE_CACHE[TableName]['header']['order']\n    LOCAL_TABLE_CACHE[DestinationTableName] = {} # clear QUERY_BUFFER for the new result\n    RowObjectDefault = getDefaultRowObject(TableName)\n    VarDictionary = getVarDictionary(RowObjectDefault)\n    ContextFormat = getContextFormat(RowObjectDefault)\n    RowObjectDefaultNew = newRowObject(ParameterNames,RowObjectDefault,VarDictionary,ContextFormat)\n    dropTable(DestinationTableName) # redundant\n    createTable(DestinationTableName,RowObjectDefaultNew)\n    selectInto(DestinationTableName,TableName,ParameterNames,Conditions)\n    if DestinationTableName!=QUERY_BUFFER:\n        if File: outputTable(DestinationTableName,File=File)\n    elif Output:\n        outputTable(DestinationTableName,File=File)", "response": "Select the data in a table into a new table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sort(TableName,DestinationTableName=None,ParameterNames=None,Accending=True,Output=False,File=None):\n    number_of_rows = LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']\n    index = range(0,number_of_rows)\n    #print 'num = '+str(number_of_rows)\n    if not DestinationTableName:\n       DestinationTableName = TableName\n    # if names are not provided use all parameters in sorting\n    if not ParameterNames:\n       ParameterNames = LOCAL_TABLE_CACHE[TableName]['header']['order']\n    elif type(ParameterNames) not in set([list,tuple]):\n       ParameterNames = [ParameterNames] # fix of stupid bug where ('p1',) != ('p1')\n    #print 'SRT: ParameterNames = '+str(ParameterNames)\n    #print 'parnames: '+str(ParameterNames)\n    index_sorted = quickSort(index,TableName,ParameterNames,Accending)\n    arrangeTable(TableName,DestinationTableName,index_sorted)\n    if Output:\n       outputTable(DestinationTableName,File=File)", "response": "A quick sort function that sorts a single table by a list of parameters or expressions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninput PARAMETERS: TableName: name of source table (required) DestinationTableName: name of resulting table (optional) ParameterNames: list of parameters or expressions to take (optional) GroupParameterNames: list of parameters or expressions to group by (optional) Accending: sort in ascending (True) or descending (False) order (optional) Output: enable (True) or suppress (False) text output (optional) OUTPUT PARAMETERS: none --- DESCRIPTION: none --- EXAMPLE OF USAGE: group('sampletab',ParameterNames=('p1',('sum','p2')),GroupParameterNames=('p1')) ... makes grouping by p1,p2. For each group it calculates sum of p2 values. ---", "response": "def group(TableName,DestinationTableName=QUERY_BUFFER,ParameterNames=None,GroupParameterNames=None,Output=True):\n    \"\"\"\n    INPUT PARAMETERS: \n        TableName:                name of source table          (required)\n        DestinationTableName:     name of resulting table       (optional)\n        ParameterNames:       list of parameters or expressions to take       (optional)\n        GroupParameterNames:  list of parameters or expressions to group by   (optional)\n        Accending:       sort in ascending (True) or descending (False) order (optional)\n        Output:   enable (True) or suppress (False) text output (optional)\n    OUTPUT PARAMETERS: \n        none\n    ---\n    DESCRIPTION:\n        none\n    ---\n    EXAMPLE OF USAGE:\n        group('sampletab',ParameterNames=('p1',('sum','p2')),GroupParameterNames=('p1'))\n        ... makes grouping by p1,p2. For each group it calculates sum of p2 values.\n    ---\n    \"\"\"\n    # Implements such functions as:\n    # count,sum,avg,min,max,ssq etc...\n    # 1) ParameterNames can contain group functions\n    # 2) GroupParameterNames can't contain group functions\n    # 3) If ParameterNames contains parameters defined by LET directive,\n    #    it IS visible in the sub-context of GroupParameterNames\n    # 4) Parameters defined in GroupParameterNames are NOT visible in ParameterNames\n    # 5) ParameterNames variable represents the structure of the resulting table/collection\n    # 6) GroupParameterNames can contain either par_names or expressions with par_names\n    # Clear old GROUP_INDEX value\n    clearGroupIndex()\n    # Consistency check\n    if TableName == DestinationTableName:\n       raise Exception('TableName and DestinationTableName must be different')\n    #if not ParameterNames: ParameterNames=LOCAL_TABLE_CACHE[TableName]['header']['order']\n    # Prepare the new DestinationTable\n    RowObjectDefault = getDefaultRowObject(TableName)\n    VarDictionary = getVarDictionary(RowObjectDefault)\n    ContextFormat = getContextFormat(RowObjectDefault)\n    RowObjectDefaultNew = newRowObject(ParameterNames,RowObjectDefault,VarDictionary,ContextFormat)\n    dropTable(DestinationTableName) # redundant\n    createTable(DestinationTableName,RowObjectDefaultNew)\n    # Loop through rows of source Table\n    # On each iteration group functions update GROUP_INDEX (see description above)\n    number_of_rows = LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']   \n    # STAGE 1: CREATE GROUPS\n    print('LOOP:')\n    for RowID in range(0,number_of_rows):\n        print('--------------------------------')\n        print('RowID='+str(RowID))\n        RowObject = getRowObject(RowID,TableName) # RowObject from source table\n        VarDictionary = getVarDictionary(RowObject)\n        print('VarDictionary='+str(VarDictionary))\n        # This is a trick which makes evaluateExpression function\n        #   not consider first expression as an operation\n        GroupParameterNames_ = ['LIST'] + list(GroupParameterNames)\n        GroupIndexKey = evaluateExpression(GroupParameterNames_,VarDictionary)\n        # List is an unhashable type in Python!\n        GroupIndexKey = tuple(GroupIndexKey)       \n        initializeGroup(GroupIndexKey)\n        print('GROUP_INDEX='+str(GROUP_INDEX))\n        ContextFormat = getContextFormat(RowObject)\n        RowObjectNew = newRowObject(ParameterNames,RowObject,VarDictionary,ContextFormat,GroupIndexKey)\n        RowIDGroup = GROUP_INDEX[GroupIndexKey]['ROWID']\n        setRowObject(RowIDGroup,RowObjectNew,DestinationTableName)\n    # Output result if required\n    if Output and DestinationTableName==QUERY_BUFFER:\n       outputTable(DestinationTableName,File=File)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef extractColumns(TableName,SourceParameterName,ParameterFormats,ParameterNames=None,FixCol=False):\n    # ParameterNames = just the names without expressions\n    # ParFormats contains python formats for par extraction\n    # Example: ParameterNames=('v1','v2','v3')\n    #          ParameterFormats=('%1s','%1s','%1s')\n    # By default the format of parameters is column-fixed\n    if type(LOCAL_TABLE_CACHE[TableName]['header']['default'][SourceParameterName]) not in set([str,unicode]):\n       raise Exception('Source parameter must be a string')\n    i=-1\n    # bug when (a,) != (a)\n    if ParameterNames and type(ParameterNames) not in set([list,tuple]):\n       ParameterNames = [ParameterNames]\n    if ParameterFormats and type(ParameterFormats) not in set([list,tuple]):\n       ParameterFormats = [ParameterFormats]\n    # if ParameterNames is empty, fill it with #1-2-3-...\n    if not ParameterNames:\n       ParameterNames = []\n       # using naming convension #i, i=0,1,2,3...\n       for par_format in ParameterFormats:\n           while True:\n                 i+=1\n                 par_name = '#%d' % i\n                 fmt = LOCAL_TABLE_CACHE[TableName]['header']['format'].get(par_name,None)\n                 if not fmt: break\n           ParameterNames.append(par_name)\n    # check if ParameterNames are valid\n    Intersection = set(ParameterNames).intersection(LOCAL_TABLE_CACHE[TableName]['header']['order'])\n    if Intersection:\n       raise Exception('Parameters %s already exist' % str(list(Intersection)))\n    # loop over ParameterNames to prepare LOCAL_TABLE_CACHE\n    i=0\n    for par_name in ParameterNames:  \n        par_format = ParameterFormats[i]     \n        LOCAL_TABLE_CACHE[TableName]['header']['format'][par_name]=par_format\n        LOCAL_TABLE_CACHE[TableName]['data'][par_name]=[] \n        i+=1\n    # append new parameters in order list\n    LOCAL_TABLE_CACHE[TableName]['header']['order'] += ParameterNames\n    # cope with default values\n    i=0\n    format_regex = []\n    format_types = []\n    #print 'ParameterNames='+str(ParameterNames)\n    for par_format in ParameterFormats:\n        par_name = ParameterNames[i]\n        regex = FORMAT_PYTHON_REGEX\n        #print 'par_name: '+par_name\n        #print 'par_format: '+par_format\n        (lng,trail,lngpnt,ty) = re.search(regex,par_format).groups()\n        ty = ty.lower()\n        if ty == 'd':\n           par_type = int\n           if FixCol:\n              format_regex_part = REGEX_INTEGER_FIXCOL(lng)\n           else:\n              format_regex_part = REGEX_INTEGER\n        elif ty == 's':\n           par_type = str\n           if FixCol:\n              format_regex_part = REGEX_STRING_FIXCOL(lng)\n           else:\n              format_regex_part = REGEX_STRING\n        elif ty == 'f':\n           par_type = float\n           if FixCol:\n              format_regex_part = REGEX_FLOAT_F_FIXCOL(lng)\n           else:\n              format_regex_part = REGEX_FLOAT_F\n        elif ty == 'e':\n           par_type = float\n           if FixCol:\n              format_regex_part = REGEX_FLOAT_E_FIXCOL(lng)\n           else:\n              format_regex_part = REGEX_FLOAT_E\n        else:\n           raise Exception('Unknown data type')\n        format_regex.append('('+format_regex_part+')')\n        format_types.append(par_type)\n        def_val = getDefaultValue(par_type)\n        LOCAL_TABLE_CACHE[TableName]['header']['default'][par_name]=def_val\n        i+=1\n    format_regex = '\\s*'.join(format_regex)\n    #print 'format_regex='+str(format_regex)\n    #return format_regex\n    # loop through values of SourceParameter\n    for SourceParameterString in LOCAL_TABLE_CACHE[TableName]['data'][SourceParameterName]:\n        try:\n           ExtractedValues = list(re.search(format_regex,SourceParameterString).groups())\n        except:\n           raise Exception('Error with line \\\"%s\\\"' % SourceParameterString)\n        i=0\n        # loop through all parameters which are supposed to be extracted\n        for par_name in ParameterNames:\n            #print 'ExtractedValues[i]='+ExtractedValues[i]\n            #print 'par_name='+par_name\n            par_value = format_types[i](ExtractedValues[i])\n            LOCAL_TABLE_CACHE[TableName]['data'][par_name].append(par_value)\n            i+=1\n    # explicitly check that number of rows are equal\n    number_of_rows = LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']\n    number_of_rows2 = len(LOCAL_TABLE_CACHE[TableName]['data'][SourceParameterName])\n    number_of_rows3 = len(LOCAL_TABLE_CACHE[TableName]['data'][ParameterNames[0]])\n    if not (number_of_rows == number_of_rows2 == number_of_rows3):\n       raise Exception('Error while extracting parameters: check your regexp')", "response": "This function extracts the columns from the source table."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getHelp(arg=None):\n    if arg==None:\n        print('--------------------------------------------------------------')\n        print('Hello, this is an interactive help system of HITRANonline API.')\n        print('--------------------------------------------------------------')\n        print('Run getHelp(.) with one of the following arguments:')\n        print('    tutorial  -  interactive tutorials on HAPI')\n        print('    units     -  units used in calculations')\n        print('    index     -  index of available HAPI functions')\n    elif arg=='tutorial':\n        print('-----------------------------------')\n        print('This is a tutorial section of help.')\n        print('-----------------------------------')\n        print('Please choose the subject of tutorial:')\n        print('    data      -  downloading the data and working with it')\n        print('    spectra   -  calculating spectral functions')\n        print('    plotting  -  visualizing data with matplotlib')\n        print('    python    -  Python quick start guide')\n    elif arg=='python':\n        print_python_tutorial()\n    elif arg=='data':\n        print_data_tutorial()\n    elif arg=='spectra':\n        print_spectra_tutorial()\n    elif arg=='plotting':\n        print_plotting_tutorial()\n    elif arg=='index':\n        print('------------------------------')\n        print('FETCHING DATA:')\n        print('------------------------------')\n        print('  fetch')\n        print('  fetch_by_ids')\n        print('')\n        print('------------------------------')\n        print('WORKING WITH DATA:')\n        print('------------------------------')\n        print('  db_begin')\n        print('  db_commit')\n        print('  tableList')\n        print('  describe')\n        print('  select')\n        print('  sort')\n        print('  extractColumns')\n        print('  getColumn')\n        print('  getColumns')\n        print('  dropTable')\n        print('')\n        print('------------------------------')\n        print('CALCULATING SPECTRA:')\n        print('------------------------------')\n        print('  profiles')\n        print('  partitionSum')\n        print('  absorptionCoefficient_HT')\n        print('  absorptionCoefficient_Voigt')\n        print('  absorptionCoefficient_SDVoigt')\n        print('  absorptionCoefficient_Lorentz')\n        print('  absorptionCoefficient_Doppler')\n        print('  transmittanceSpectrum')\n        print('  absorptionSpectrum')\n        print('  radianceSpectrum')\n        print('')\n        print('------------------------------')\n        print('CONVOLVING SPECTRA:')\n        print('------------------------------')\n        print('  convolveSpectrum')\n        print('  slit_functions')\n        print('')\n        print('------------------------------')\n        print('INFO ON ISOTOPOLOGUES:')\n        print('------------------------------')\n        print('  ISO_ID')\n        print('  abundance')\n        print('  molecularMass')\n        print('  moleculeName')\n        print('  isotopologueName')\n        print('')\n        print('------------------------------')\n        print('MISCELLANEOUS:')\n        print('------------------------------')\n        print('  getStickXY')\n        print('  read_hotw')\n    elif arg == ISO:\n        print_iso()\n    elif arg == ISO_ID:\n        print_iso_id()\n    elif arg == profiles:\n        print_profiles()\n    elif arg == slit_functions:\n        print_slit_functions()\n    else:\n       help(arg)", "response": "This function provides interactive manuals and tutorials."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninputs PARAMETERS: TableName: local table name to fetch in (required) iso_id_list: list of isotopologue id's (required) numin: lower wavenumber bound (required) numax: upper wavenumber bound (required) OUTPUT PARAMETERS: none --- DESCRIPTION: Download line-by-line data from HITRANonline server and save it to local table. The input parameter iso_id_list contains list of \"global\" isotopologue Ids (see help on ISO_ID). Note: this function is required if user wants to download multiple species into single table. --- EXAMPLE OF USAGE: fetch_by_ids('water',[1,2,3,4],4000,4100) ---", "response": "def fetch_by_ids(TableName,iso_id_list,numin,numax,ParameterGroups=[],Parameters=[]):\n    \"\"\"\n    INPUT PARAMETERS: \n        TableName:   local table name to fetch in (required)\n        iso_id_list: list of isotopologue id's    (required)\n        numin:       lower wavenumber bound       (required)\n        numax:       upper wavenumber bound       (required)\n    OUTPUT PARAMETERS: \n        none\n    ---\n    DESCRIPTION:\n        Download line-by-line data from HITRANonline server\n        and save it to local table. The input parameter iso_id_list\n        contains list of \"global\" isotopologue Ids (see help on ISO_ID).\n        Note: this function is required if user wants to download\n        multiple species into single table.\n    ---\n    EXAMPLE OF USAGE:\n        fetch_by_ids('water',[1,2,3,4],4000,4100)\n    ---\n    \"\"\"\n    if type(iso_id_list) not in set([list,tuple]):\n       iso_id_list = [iso_id_list]\n    queryHITRAN(TableName,iso_id_list,numin,numax,\n                pargroups=ParameterGroups,params=Parameters)\n    iso_names = [ISO_ID[i][ISO_ID_INDEX['iso_name']] for i in iso_id_list]\n    Comment = 'Contains lines for '+','.join(iso_names)\n    Comment += ('\\n in %.3f-%.3f wavenumber range' % (numin,numax))\n    comment(TableName,Comment)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fetch(TableName,M,I,numin,numax,ParameterGroups=[],Parameters=[]):\n    queryHITRAN(TableName,[ISO[(M,I)][ISO_INDEX['id']]],numin,numax,\n                pargroups=ParameterGroups,params=Parameters)\n    iso_name = ISO[(M,I)][ISO_INDEX['iso_name']]\n    Comment = 'Contains lines for '+iso_name\n    Comment += ('\\n in %.3f-%.3f wavenumber range' % (numin,numax))\n    comment(TableName,Comment)", "response": "This function downloads line - by - line data from HITRAN online server and saves it to a local table."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninputs PARAMETERS: M: HITRAN molecule number (required) I: HITRAN isotopologue number (required) T: temperature conditions (required) step: step to calculate temperatures (optional) OUTPUT PARAMETERS: TT: list of temperatures (present only if T is a list) PartSum: partition sums calculated on a list of temperatures --- DESCRIPTION: Calculate range of partition sums at different temperatures. This function uses a python implementation of TIPS-2011 code: Reference: A. L. Laraia, R. R. Gamache, J. Lamouroux, I. E. Gordon, L. S. Rothman. Total internal partition sums to support planetary remote sensing. Icarus, Volume 215, Issue 1, September 2011, Pages 391\u2013400 http://dx.doi.org/10.1016/j.icarus.2011.06.004 Output depends on a structure of input parameter T so that: 1) If T is a scalar/list and step IS NOT provided, then calculate partition sums over each value of T. 2) If T is a list and step parameter IS provided, then calculate partition sums between T[0] and T[1] with a given step. --- EXAMPLE OF USAGE: PartSum = partitionSum(1,1,[296,1000]) TT,PartSum = partitionSum(1,1,[296,1000],step=0.1) ---", "response": "def partitionSum(M,I,T,step=None):\n    \"\"\"\n    INPUT PARAMETERS: \n        M: HITRAN molecule number              (required)\n        I: HITRAN isotopologue number          (required)\n        T: temperature conditions              (required)\n        step:  step to calculate temperatures  (optional)\n    OUTPUT PARAMETERS:\n        TT: list of temperatures (present only if T is a list)\n        PartSum: partition sums calculated on a list of temperatures\n    ---\n    DESCRIPTION:\n        Calculate range of partition sums at different temperatures.\n        This function uses a python implementation of TIPS-2011 code:\n\n        Reference:\n            A. L. Laraia, R. R. Gamache, J. Lamouroux, I. E. Gordon, L. S. Rothman.\n            Total internal partition sums to support planetary remote sensing.\n            Icarus, Volume 215, Issue 1, September 2011, Pages 391\u2013400\n            http://dx.doi.org/10.1016/j.icarus.2011.06.004\n\n        Output depends on a structure of input parameter T so that:\n            1) If T is a scalar/list and step IS NOT provided,\n                then calculate partition sums over each value of T.\n            2) If T is a list and step parameter IS provided,\n                then calculate partition sums between T[0] and T[1]\n                with a given step.\n    ---\n    EXAMPLE OF USAGE:\n        PartSum = partitionSum(1,1,[296,1000])\n        TT,PartSum = partitionSum(1,1,[296,1000],step=0.1)\n    ---\n    \"\"\"\n    # partitionSum\n    if not step:\n       if type(T) not in set([list,tuple]):\n          return BD_TIPS_2011_PYTHON(M,I,T)[1]\n       else:\n          return [BD_TIPS_2011_PYTHON(M,I,temp)[1] for temp in T]\n    else:\n       #n = (T[1]-T[0])/step\n       #TT = linspace(T[0],T[1],n)\n       TT = arange(T[0],T[1],step)\n       return TT,array([BD_TIPS_2011_PYTHON(M,I,temp)[1] for temp in TT])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef PROFILE_HT(sg0,GamD,Gam0,Gam2,Shift0,Shift2,anuVC,eta,sg):\n    return pcqsdhc(sg0,GamD,Gam0,Gam2,Shift0,Shift2,anuVC,eta,sg)", "response": "Returns the complex normalized spectral shape of an isolated line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef PROFILE_SDRAUTIAN(sg0,GamD,Gam0,Gam2,Shift0,Shift2,anuVC,sg):\n    return pcqsdhc(sg0,GamD,Gam0,Gam2,Shift0,Shift2,anuVC,cZero,sg)", "response": "Returns the Speed dependent Rautian profile for a given SG."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a Rautian profile based on HTP.", "response": "def PROFILE_RAUTIAN(sg0,GamD,Gam0,Shift0,anuVC,eta,sg):\n    \"\"\"\n    # Rautian profile based on HTP.\n    # Input parameters:\n    #      sg0     : Unperturbed line position in cm-1 (Input).\n    #      GamD    : Doppler HWHM in cm-1 (Input)\n    #      Gam0    : Speed-averaged line-width in cm-1 (Input).       \n    #      anuVC   : Velocity-changing frequency in cm-1 (Input).\n    #      Shift0  : Speed-averaged line-shift in cm-1 (Input).\n    #      sg      : Current WaveNumber of the Computation in cm-1 (Input).\n    \"\"\"\n    return pcqsdhc(sg0,GamD,Gam0,cZero,Shift0,cZero,anuVC,cZero,sg)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the Speed Dependence Profile for a given Speed Dependence Profile.", "response": "def PROFILE_SDVOIGT(sg0,GamD,Gam0,Gam2,Shift0,Shift2,sg):\n    \"\"\"\n    # Speed dependent Voigt profile based on HTP.\n    # Input parameters:\n    #      sg0     : Unperturbed line position in cm-1 (Input).\n    #      GamD    : Doppler HWHM in cm-1 (Input)\n    #      Gam0    : Speed-averaged line-width in cm-1 (Input).       \n    #      Gam2    : Speed dependence of the line-width in cm-1 (Input).\n    #      Shift0  : Speed-averaged line-shift in cm-1 (Input).\n    #      Shift2  : Speed dependence of the line-shift in cm-1 (Input)       \n    #      sg      : Current WaveNumber of the Computation in cm-1 (Input).\n    \"\"\"\n    return pcqsdhc(sg0,GamD,Gam0,Gam2,Shift0,Shift2,cZero,cZero,sg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the profile of a Voigt line.", "response": "def PROFILE_VOIGT(sg0,GamD,Gam0,sg):\n    \"\"\"\n    # Voigt profile based on HTP.\n    # Input parameters:\n    #   sg0: Unperturbed line position in cm-1 (Input).\n    #   GamD: Doppler HWHM in cm-1 (Input)\n    #   Gam0: Speed-averaged line-width in cm-1 (Input).       \n    #   sg: Current WaveNumber of the Computation in cm-1 (Input).\n    \"\"\"\n    return PROFILE_HTP(sg0,GamD,Gam0,cZero,cZero,cZero,cZero,cZero,sg)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfunctioning that computes the Doppler profile.", "response": "def PROFILE_DOPPLER(sg0,GamD,sg):\n    \"\"\"\n    # Doppler profile.\n    # Input parameters:\n    #   sg0: Unperturbed line position in cm-1 (Input).\n    #   GamD: Doppler HWHM in cm-1 (Input)\n    #   sg: Current WaveNumber of the Computation in cm-1 (Input).\n    \"\"\"\n    return cSqrtLn2divSqrtPi*exp(-cLn2*((sg-sg0)/GamD)**2)/GamD"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninputting PARAMETERS: Components: list of tuples [(M,I,D)], where M - HITRAN molecule number, I - HITRAN isotopologue number, D - relative abundance (optional) SourceTables: list of tables from which to calculate cross-section (optional) partitionFunction: pointer to partition function (default is PYTIPS) (optional) Environment: dictionary containing thermodynamic parameters. 'p' - pressure in atmospheres, 'T' - temperature in Kelvin Default={'p':1.,'T':296.} WavenumberRange: wavenumber range to consider. WavenumberStep: wavenumber step to consider. WavenumberWing: absolute wing for calculating a lineshape (in cm-1) WavenumberWingHW: relative wing for calculating a lineshape (in halfwidths) IntensityThreshold: threshold for intensities GammaL: specifies broadening parameter ('gamma_air' or 'gamma_self') HITRAN_units: use cm2/molecule (True) or cm-1 (False) for absorption coefficient File: write output to file (if specified) Format: c-format of file output (accounts for significant digits in WavenumberStep) OUTPUT PARAMETERS: Wavenum: wavenumber grid with respect to parameters WavenumberRange and WavenumberStep Xsect: absorption coefficient calculated on the grid --- DESCRIPTION: Calculate absorption coefficient using Voigt profile. Absorption coefficient is calculated at arbitrary temperature and pressure. User can vary a wide range of parameters to control a process of calculation. The choise of these parameters depends on properties of a particular linelist. Default values are a sort of guess which gives a decent precision (on average) for a reasonable amount of cpu time. To increase calculation accuracy, user should use a trial and error method. --- EXAMPLE OF USAGE: nu,coef = absorptionCoefficient_Voigt(((2,1),),'co2',WavenumberStep=0.01, HITRAN_units=False,GammaL='gamma_self') ---", "response": "def absorptionCoefficient_Voigt(Components=None,SourceTables=None,partitionFunction=PYTIPS,\n                                Environment=None,OmegaRange=None,OmegaStep=None,OmegaWing=None,\n                                IntensityThreshold=DefaultIntensityThreshold,\n                                OmegaWingHW=DefaultOmegaWingHW,\n                                GammaL='gamma_air', HITRAN_units=True, LineShift=True,\n                                File=None, Format=None, OmegaGrid=None,\n                                WavenumberRange=None,WavenumberStep=None,WavenumberWing=None,\n                                WavenumberWingHW=None,WavenumberGrid=None,\n                                Diluent={},EnvDependences=None):\n    \"\"\"\n    INPUT PARAMETERS: \n        Components:  list of tuples [(M,I,D)], where\n                        M - HITRAN molecule number,\n                        I - HITRAN isotopologue number,\n                        D - relative abundance (optional)\n        SourceTables:  list of tables from which to calculate cross-section   (optional)\n        partitionFunction:  pointer to partition function (default is PYTIPS) (optional)\n        Environment:  dictionary containing thermodynamic parameters.\n                        'p' - pressure in atmospheres,\n                        'T' - temperature in Kelvin\n                        Default={'p':1.,'T':296.}\n        WavenumberRange:  wavenumber range to consider.\n        WavenumberStep:   wavenumber step to consider. \n        WavenumberWing:   absolute wing for calculating a lineshape (in cm-1) \n        WavenumberWingHW:  relative wing for calculating a lineshape (in halfwidths)\n        IntensityThreshold:  threshold for intensities\n        GammaL:  specifies broadening parameter ('gamma_air' or 'gamma_self')\n        HITRAN_units:  use cm2/molecule (True) or cm-1 (False) for absorption coefficient\n        File:   write output to file (if specified)\n        Format:  c-format of file output (accounts for significant digits in WavenumberStep)\n    OUTPUT PARAMETERS: \n        Wavenum: wavenumber grid with respect to parameters WavenumberRange and WavenumberStep\n        Xsect: absorption coefficient calculated on the grid\n    ---\n    DESCRIPTION:\n        Calculate absorption coefficient using Voigt profile.\n        Absorption coefficient is calculated at arbitrary temperature and pressure.\n        User can vary a wide range of parameters to control a process of calculation.\n        The choise of these parameters depends on properties of a particular linelist.\n        Default values are a sort of guess which gives a decent precision (on average) \n        for a reasonable amount of cpu time. To increase calculation accuracy,\n        user should use a trial and error method.\n    ---\n    EXAMPLE OF USAGE:\n        nu,coef = absorptionCoefficient_Voigt(((2,1),),'co2',WavenumberStep=0.01,\n                                              HITRAN_units=False,GammaL='gamma_self')\n    ---\n    \"\"\"\n   \n    # Paremeters OmegaRange,OmegaStep,OmegaWing,OmegaWingHW, and OmegaGrid\n    # are deprecated and given for backward compatibility with the older versions.\n    if WavenumberRange:  OmegaRange=WavenumberRange\n    if WavenumberStep:   OmegaStep=WavenumberStep\n    if WavenumberWing:   OmegaWing=WavenumberWing\n    if WavenumberWingHW: OmegaWingHW=WavenumberWingHW\n    if WavenumberGrid:   OmegaGrid=WavenumberGrid\n\n    # \"bug\" with 1-element list\n    Components = listOfTuples(Components)\n    SourceTables = listOfTuples(SourceTables)\n    \n    # determine final input values\n    Components,SourceTables,Environment,OmegaRange,OmegaStep,OmegaWing,\\\n    IntensityThreshold,Format = \\\n       getDefaultValuesForXsect(Components,SourceTables,Environment,OmegaRange,\n                                OmegaStep,OmegaWing,IntensityThreshold,Format)\n    \n    # warn user about too large omega step\n    if OmegaStep>0.1: warn('Big wavenumber step: possible accuracy decline')\n\n    # get uniform linespace for cross-section\n    #number_of_points = (OmegaRange[1]-OmegaRange[0])/OmegaStep + 1\n    #Omegas = linspace(OmegaRange[0],OmegaRange[1],number_of_points)\n    if OmegaGrid is not None:\n        Omegas = npsort(OmegaGrid)\n    else:\n        #Omegas = arange(OmegaRange[0],OmegaRange[1],OmegaStep)\n        Omegas = arange_(OmegaRange[0],OmegaRange[1],OmegaStep) # fix\n    number_of_points = len(Omegas)\n    Xsect = zeros(number_of_points)\n       \n    # reference temperature and pressure\n    Tref = __FloatType__(296.) # K\n    pref = __FloatType__(1.) # atm\n    \n    # actual temperature and pressure\n    T = Environment['T'] # K\n    p = Environment['p'] # atm\n       \n    # create dictionary from Components\n    ABUNDANCES = {}\n    NATURAL_ABUNDANCES = {}\n    for Component in Components:\n        M = Component[0]\n        I = Component[1]\n        if len(Component) >= 3:\n            ni = Component[2]\n        else:\n            try:\n                ni = ISO[(M,I)][ISO_INDEX['abundance']]\n            except KeyError:\n                raise Exception('cannot find component M,I = %d,%d.' % (M,I))\n        ABUNDANCES[(M,I)] = ni\n        NATURAL_ABUNDANCES[(M,I)] = ISO[(M,I)][ISO_INDEX['abundance']]\n        \n    # precalculation of volume concentration\n    if HITRAN_units:\n        factor = __FloatType__(1.0)\n    else:\n        factor = volumeConcentration(p,T) \n        \n    # setup the default empty environment dependence function\n    if not EnvDependences:\n        EnvDependences = lambda ENV,LINE:{}\n    Env = Environment.copy()\n    Env['Tref'] = Tref\n    Env['pref'] = pref\n  \n    # setup the Diluent variable\n    GammaL = GammaL.lower()\n    if not Diluent:\n        if GammaL == 'gamma_air':\n            Diluent = {'air':1.}\n        elif GammaL == 'gamma_self':\n            Diluent = {'self':1.}\n        else:\n            raise Exception('Unknown GammaL value: %s' % GammaL)\n        \n    # Simple check\n    for key in Diluent:\n        val = Diluent[key]\n        if val < 0 and val > 1:\n            raise Exception('Diluent fraction must be in [0,1]')\n    \n    # SourceTables contain multiple tables\n    for TableName in SourceTables:\n\n        # get the number of rows\n        nline = LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']\n        \n        # get parameter names for each table\n        parnames = LOCAL_TABLE_CACHE[TableName]['data'].keys()\n        \n        # loop through line centers (single stream)\n        for RowID in range(nline):\n            \n            # Get the custom environment dependences\n            Line = {parname:LOCAL_TABLE_CACHE[TableName]['data'][parname][RowID] for parname in parnames}\n            CustomEnvDependences = EnvDependences(Env,Line)\n            \n            # get ftbasic line parameters (lower level)\n            LineCenterDB = LOCAL_TABLE_CACHE[TableName]['data']['nu'][RowID]\n            LineIntensityDB = LOCAL_TABLE_CACHE[TableName]['data']['sw'][RowID]\n            LowerStateEnergyDB = LOCAL_TABLE_CACHE[TableName]['data']['elower'][RowID]\n            MoleculeNumberDB = LOCAL_TABLE_CACHE[TableName]['data']['molec_id'][RowID]\n            IsoNumberDB = LOCAL_TABLE_CACHE[TableName]['data']['local_iso_id'][RowID]\n            \n            # filter by molecule and isotopologue\n            if (MoleculeNumberDB,IsoNumberDB) not in ABUNDANCES: continue\n            \n            # partition functions for T and Tref\n            SigmaT = partitionFunction(MoleculeNumberDB,IsoNumberDB,T)\n            SigmaTref = partitionFunction(MoleculeNumberDB,IsoNumberDB,Tref)\n            \n            # get all environment dependences from voigt parameters\n            \n            #   intensity\n            if 'sw' in CustomEnvDependences:\n                LineIntensity = CustomEnvDependences['sw']\n            else:\n                LineIntensity = EnvironmentDependency_Intensity(LineIntensityDB,T,Tref,SigmaT,SigmaTref,\n                                                                LowerStateEnergyDB,LineCenterDB)\n            \n            #   FILTER by LineIntensity: compare it with IntencityThreshold\n            if LineIntensity < IntensityThreshold: continue\n            \n            #   doppler broadening coefficient (GammaD)\n            cMassMol = 1.66053873e-27 # hapi\n            m = molecularMass(MoleculeNumberDB,IsoNumberDB) * cMassMol * 1000\n            GammaD = sqrt(2*cBolts*T*log(2)/m/cc**2)*LineCenterDB\n            \n            #   pressure broadening coefficient\n            Gamma0 = 0.; Shift0 = 0.;\n            for species in Diluent:\n                species_lower = species.lower()\n                \n                abun = Diluent[species]\n                \n                gamma_name = 'gamma_' + species_lower\n                try:\n                    Gamma0DB = LOCAL_TABLE_CACHE[TableName]['data'][gamma_name][RowID]\n                except:\n                    Gamma0DB = 0.0\n                \n                n_name = 'n_' + species_lower\n                try:\n                    TempRatioPowerDB = LOCAL_TABLE_CACHE[TableName]['data'][n_name][RowID]\n                    if species_lower == 'self' and TempRatioPowerDB == 0.:\n                        TempRatioPowerDB = LOCAL_TABLE_CACHE[TableName]['data']['n_air'][RowID] # same for self as for air\n                except:\n                    #TempRatioPowerDB = 0                    \n                    TempRatioPowerDB = LOCAL_TABLE_CACHE[TableName]['data']['n_air'][RowID]\n                \n                # Add to the final Gamma0\n                Gamma0 += abun*CustomEnvDependences.get(gamma_name, # default ->\n                          EnvironmentDependency_Gamma0(Gamma0DB,T,Tref,p,pref,TempRatioPowerDB))\n\n                delta_name = 'delta_' + species_lower\n                try:\n                    Shift0DB = LOCAL_TABLE_CACHE[TableName]['data'][delta_name][RowID]\n                except:\n                    Shift0DB = 0.0\n                \n                deltap_name = 'deltap_' + species_lower\n                try:\n                    deltap = LOCAL_TABLE_CACHE[TableName]['data'][deltap_name][RowID]\n                except:\n                    deltap = 0.0\n\n                Shift0 += abun*CustomEnvDependences.get(delta_name, # default ->\n                          ((Shift0DB + deltap*(T-Tref))*p/pref))\n            \n            #   get final wing of the line according to Gamma0, OmegaWingHW and OmegaWing\n            # XXX min or max?\n            OmegaWingF = max(OmegaWing,OmegaWingHW*Gamma0,OmegaWingHW*GammaD)\n\n            #   shift coefficient\n            #Shift0 = Shift0DB*p/pref\n            \n            # XXX other parameter (such as Delta0, Delta2, anuVC etc.) will be included in HTP version\n            \n            #PROFILE_VOIGT(sg0,GamD,Gam0,sg)\n            #      sg0           : Unperturbed line position in cm-1 (Input).\n            #      GamD          : Doppler HWHM in cm-1 (Input)\n            #      Gam0          : Speed-averaged line-width in cm-1 (Input).\n            #      sg            : Current WaveNumber of the Computation in cm-1 (Input).\n\n            # XXX time?\n            BoundIndexLower = bisect(Omegas,LineCenterDB-OmegaWingF)\n            BoundIndexUpper = bisect(Omegas,LineCenterDB+OmegaWingF)\n            lineshape_vals = PROFILE_VOIGT(LineCenterDB+Shift0,GammaD,Gamma0,Omegas[BoundIndexLower:BoundIndexUpper])[0]\n            Xsect[BoundIndexLower:BoundIndexUpper] += factor / NATURAL_ABUNDANCES[(MoleculeNumberDB,IsoNumberDB)] * \\\n                                                      ABUNDANCES[(MoleculeNumberDB,IsoNumberDB)] * \\\n                                                      LineIntensity * lineshape_vals\n    \n    if File: save_to_file(File,Format,Omegas,Xsect)\n    return Omegas,Xsect"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninput PARAMETERS: Components: list of tuples [(M,I,D)], where M - HITRAN molecule number, I - HITRAN isotopologue number, D - abundance (optional) SourceTables: list of tables from which to calculate cross-section (optional) partitionFunction: pointer to partition function (default is PYTIPS) (optional) Environment: dictionary containing thermodynamic parameters. 'p' - pressure in atmospheres, 'T' - temperature in Kelvin Default={'p':1.,'T':296.} WavenumberRange: wavenumber range to consider. WavenumberStep: wavenumber step to consider. WavenumberWing: absolute wing for calculating a lineshape (in cm-1) WavenumberWingHW: relative wing for calculating a lineshape (in halfwidths) IntensityThreshold: threshold for intensities GammaL: specifies broadening parameter ('gamma_air' or 'gamma_self') HITRAN_units: use cm2/molecule (True) or cm-1 (False) for absorption coefficient File: write output to file (if specified) Format: c-format of file output (accounts for significant digits in WavenumberStep) OUTPUT PARAMETERS: Wavenum: wavenumber grid with respect to parameters OmegaRange and OmegaStep Xsect: absorption coefficient calculated on the grid --- DESCRIPTION: Calculate absorption coefficient using Doppler (Gauss) profile. Absorption coefficient is calculated at arbitrary temperature and pressure. User can vary a wide range of parameters to control a process of calculation. The choise of these parameters depends on properties of a particular linelist. Default values are a sort of guess which give a decent precision (on average) for a reasonable amount of cpu time. To increase calculation accuracy, user should use a trial and error method. --- EXAMPLE OF USAGE: nu,coef = absorptionCoefficient_Doppler(((2,1),),'co2',WavenumberStep=0.01, HITRAN_units=False,GammaL='gamma_self') ---", "response": "def absorptionCoefficient_Doppler(Components=None,SourceTables=None,partitionFunction=PYTIPS,\n                                  Environment=None,OmegaRange=None,OmegaStep=None,OmegaWing=None,\n                                  IntensityThreshold=DefaultIntensityThreshold,\n                                  OmegaWingHW=DefaultOmegaWingHW,\n                                  ParameterBindings=DefaultParameterBindings,\n                                  EnvironmentDependencyBindings=DefaultEnvironmentDependencyBindings,\n                                  GammaL='dummy', HITRAN_units=True, LineShift=True,\n                                  File=None, Format=None, OmegaGrid=None,\n                                  WavenumberRange=None,WavenumberStep=None,WavenumberWing=None,\n                                  WavenumberWingHW=None,WavenumberGrid=None):   \n    \"\"\"\n    INPUT PARAMETERS: \n        Components:  list of tuples [(M,I,D)], where\n                        M - HITRAN molecule number,\n                        I - HITRAN isotopologue number,\n                        D - abundance (optional)\n        SourceTables:  list of tables from which to calculate cross-section   (optional)\n        partitionFunction:  pointer to partition function (default is PYTIPS) (optional)\n        Environment:  dictionary containing thermodynamic parameters.\n                        'p' - pressure in atmospheres,\n                        'T' - temperature in Kelvin\n                        Default={'p':1.,'T':296.}\n        WavenumberRange:  wavenumber range to consider.\n        WavenumberStep:   wavenumber step to consider. \n        WavenumberWing:   absolute wing for calculating a lineshape (in cm-1) \n        WavenumberWingHW:  relative wing for calculating a lineshape (in halfwidths)\n        IntensityThreshold:  threshold for intensities\n        GammaL:  specifies broadening parameter ('gamma_air' or 'gamma_self')\n        HITRAN_units:  use cm2/molecule (True) or cm-1 (False) for absorption coefficient\n        File:   write output to file (if specified)\n        Format:  c-format of file output (accounts for significant digits in WavenumberStep)\n    OUTPUT PARAMETERS: \n        Wavenum: wavenumber grid with respect to parameters OmegaRange and OmegaStep\n        Xsect: absorption coefficient calculated on the grid\n    ---\n    DESCRIPTION:\n        Calculate absorption coefficient using Doppler (Gauss) profile.\n        Absorption coefficient is calculated at arbitrary temperature and pressure.\n        User can vary a wide range of parameters to control a process of calculation.\n        The choise of these parameters depends on properties of a particular linelist.\n        Default values are a sort of guess which give a decent precision (on average) \n        for a reasonable amount of cpu time. To increase calculation accuracy,\n        user should use a trial and error method.\n    ---\n    EXAMPLE OF USAGE:\n        nu,coef = absorptionCoefficient_Doppler(((2,1),),'co2',WavenumberStep=0.01,\n                                              HITRAN_units=False,GammaL='gamma_self')\n    ---\n    \"\"\"\n\n    if WavenumberRange:  OmegaRange=WavenumberRange\n    if WavenumberStep:   OmegaStep=WavenumberStep\n    if WavenumberWing:   OmegaWing=WavenumberWing\n    if WavenumberWingHW: OmegaWingHW=WavenumberWingHW\n    if WavenumberGrid:   OmegaGrid=WavenumberGrid\n    \n    # \"bug\" with 1-element list\n    Components = listOfTuples(Components)\n    SourceTables = listOfTuples(SourceTables)\n    \n    # determine final input values\n    Components,SourceTables,Environment,OmegaRange,OmegaStep,OmegaWing,\\\n    IntensityThreshold,Format = \\\n       getDefaultValuesForXsect(Components,SourceTables,Environment,OmegaRange,\n                                OmegaStep,OmegaWing,IntensityThreshold,Format)\n    # special for Doppler case: set OmegaStep to a smaller value\n    if not OmegaStep: OmegaStep = 0.001\n                \n    # warn user about too large omega step\n    if OmegaStep>0.005: warn('Big wavenumber step: possible accuracy decline')\n\n    # get uniform linespace for cross-section\n    #number_of_points = (OmegaRange[1]-OmegaRange[0])/OmegaStep + 1\n    #Omegas = linspace(OmegaRange[0],OmegaRange[1],number_of_points)\n    if OmegaGrid is not None:\n        Omegas = npsort(OmegaGrid)\n    else:\n        #Omegas = arange(OmegaRange[0],OmegaRange[1],OmegaStep)\n        Omegas = arange_(OmegaRange[0],OmegaRange[1],OmegaStep) # fix\n    number_of_points = len(Omegas)\n    Xsect = zeros(number_of_points)\n       \n    # reference temperature and pressure\n    Tref = __FloatType__(296.) # K\n    pref = __FloatType__(1.) # atm\n    \n    # actual temperature and pressure\n    T = Environment['T'] # K\n    p = Environment['p'] # atm\n       \n    # create dictionary from Components\n    ABUNDANCES = {}\n    NATURAL_ABUNDANCES = {}\n    for Component in Components:\n        M = Component[0]\n        I = Component[1]\n        if len(Component) >= 3:\n            ni = Component[2]\n        else:\n            try:\n                ni = ISO[(M,I)][ISO_INDEX['abundance']]\n            except KeyError:\n                raise Exception('cannot find component M,I = %d,%d.' % (M,I))\n        ABUNDANCES[(M,I)] = ni\n        NATURAL_ABUNDANCES[(M,I)] = ISO[(M,I)][ISO_INDEX['abundance']]\n        \n    # precalculation of volume concentration\n    if HITRAN_units:\n        factor = __FloatType__(1.0)\n    else:\n        factor = volumeConcentration(p,T) \n        \n    # SourceTables contain multiple tables\n    for TableName in SourceTables:\n\n        # get line centers\n        nline = LOCAL_TABLE_CACHE[TableName]['header']['number_of_rows']\n        \n        # loop through line centers (single stream)\n        for RowID in range(nline):\n            \n            # get ftbasic line parameters (lower level)\n            LineCenterDB = LOCAL_TABLE_CACHE[TableName]['data']['nu'][RowID]\n            LineIntensityDB = LOCAL_TABLE_CACHE[TableName]['data']['sw'][RowID]\n            LowerStateEnergyDB = LOCAL_TABLE_CACHE[TableName]['data']['elower'][RowID]\n            MoleculeNumberDB = LOCAL_TABLE_CACHE[TableName]['data']['molec_id'][RowID]\n            IsoNumberDB = LOCAL_TABLE_CACHE[TableName]['data']['local_iso_id'][RowID]\n            if LineShift:\n                Shift0DB = LOCAL_TABLE_CACHE[TableName]['data']['delta_air'][RowID]\n            else:\n                Shift0DB = 0\n            \n            # filter by molecule and isotopologue\n            if (MoleculeNumberDB,IsoNumberDB) not in ABUNDANCES: continue\n            \n            # partition functions for T and Tref\n            # TODO: optimize\n            SigmaT = partitionFunction(MoleculeNumberDB,IsoNumberDB,T)\n            SigmaTref = partitionFunction(MoleculeNumberDB,IsoNumberDB,Tref)\n            \n            # get all environment dependences from voigt parameters\n            \n            #   intensity\n            LineIntensity = EnvironmentDependency_Intensity(LineIntensityDB,T,Tref,SigmaT,SigmaTref,\n                                                            LowerStateEnergyDB,LineCenterDB)\n            \n            #   FILTER by LineIntensity: compare it with IntencityThreshold\n            # TODO: apply wing narrowing instead of filtering, this would be more appropriate\n            if LineIntensity < IntensityThreshold: continue\n            \n            #   doppler broadening coefficient (GammaD)\n            #GammaDDB = cSqrtLn2*LineCenterDB/cc*sqrt(2*cBolts*T/molecularMass(MoleculeNumberDB,IsoNumberDB))\n            #GammaD = EnvironmentDependency_GammaD(GammaDDB,T,Tref)\n            #print(GammaD)\n\n            cMassMol = 1.66053873e-27\n            #cSqrt2Ln2 = 1.1774100225\n            fSqrtMass = sqrt(molecularMass(MoleculeNumberDB,IsoNumberDB))\n            #fSqrtMass = sqrt(32831.2508809)\n            cc_ = 2.99792458e8\n            cBolts_ = 1.3806503e-23\n            #cBolts_ = 1.3806488E-23\n            GammaD = (cSqrt2Ln2/cc_)*sqrt(cBolts_/cMassMol)*sqrt(T) * LineCenterDB/fSqrtMass\n            \n            #GammaD = 4.30140e-7*LineCenterDB*sqrt(T/molecularMass(MoleculeNumberDB,IsoNumberDB))\n\n            #cc_ = 2.99792458e8 # 2.99792458e10 # 2.99792458e8\n            #cBolts_ = 1.3806503e-23 #1.3806488E-16 # 1.380648813E-16 # 1.3806503e-23 # 1.3806488E-23\n            #GammaD = sqrt(log(2))*LineCenterDB*sqrt(2*cBolts_*T/(cMassMol*molecularMass(MoleculeNumberDB,IsoNumberDB)*cc_**2))\n            #print(GammaD)\n            \n            #   get final wing of the line according to GammaD, OmegaWingHW and OmegaWing\n            # XXX min or max?\n            OmegaWingF = max(OmegaWing,OmegaWingHW*GammaD)\n\n            #   shift coefficient\n            Shift0 = Shift0DB*p/pref\n\n            # XXX other parameter (such as Delta0, Delta2, anuVC etc.) will be included in HTP version\n            \n            #PROFILE_VOIGT(sg0,GamD,Gam0,sg)\n            #      sg0           : Unperturbed line position in cm-1 (Input).\n            #      GamD          : Doppler HWHM in cm-1 (Input)\n            #      Gam0          : Speed-averaged line-width in cm-1 (Input).\n            #      sg            : Current WaveNumber of the Computation in cm-1 (Input).\n                                              \n            # XXX time?\n            BoundIndexLower = bisect(Omegas,LineCenterDB-OmegaWingF)\n            BoundIndexUpper = bisect(Omegas,LineCenterDB+OmegaWingF)\n            lineshape_vals = PROFILE_DOPPLER(LineCenterDB+Shift0,GammaD,Omegas[BoundIndexLower:BoundIndexUpper])\n            #lineshape_vals = PROFILE_VOIGT(LineCenterDB,GammaD,cZero,Omegas[BoundIndexLower:BoundIndexUpper])[0]\n            #Xsect[BoundIndexLower:BoundIndexUpper] += lineshape_vals # DEBUG\n            Xsect[BoundIndexLower:BoundIndexUpper] += factor / NATURAL_ABUNDANCES[(MoleculeNumberDB,IsoNumberDB)] * \\\n                                                      ABUNDANCES[(MoleculeNumberDB,IsoNumberDB)] * \\\n                                                      LineIntensity * lineshape_vals\n\n    if File: save_to_file(File,Format,Omegas,Xsect)\n    return Omegas,Xsect"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transmittanceSpectrum(Omegas,AbsorptionCoefficient,Environment={'l':100.},\n                          File=None, Format='%e %e', Wavenumber=None):\n    \"\"\"\n    INPUT PARAMETERS: \n        Wavenumber/Omegas:   wavenumber grid                    (required)\n        AbsorptionCoefficient:  absorption coefficient on grid  (required)\n        Environment:  dictionary containing path length in cm.\n                      Default={'l':100.}\n        File:         name of the output file                 (optional) \n        Format: c format used in file output, default '%e %e' (optional)\n    OUTPUT PARAMETERS: \n        Wavenum: wavenumber grid\n        Xsect:  transmittance spectrum calculated on the grid\n    ---\n    DESCRIPTION:\n        Calculate a transmittance spectrum (dimensionless) based\n        on previously calculated absorption coefficient.\n        Transmittance spectrum is calculated at an arbitrary\n        optical path length 'l' (1 m by default)\n    ---\n    EXAMPLE OF USAGE:\n        nu,trans = transmittanceSpectrum(nu,coef)\n    ---\n    \"\"\"\n    # compatibility with older versions\n    if Wavenumber: Omegas=Wavenumber\n    l = Environment['l']\n    Xsect = exp(-AbsorptionCoefficient*l)\n    if File: save_to_file(File,Format,Omegas,Xsect)\n    return Omegas,Xsect", "response": "This function calculates the transmittance spectrum of a single set of items on a single grid and saves it to a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninputs PARAMETERS: Wavenumber/Omegas: wavenumber grid (required) AbsorptionCoefficient: absorption coefficient on grid (required) Environment: dictionary containing path length in cm. and temperature in Kelvin. Default={'l':100.,'T':296.} File: name of the output file (optional) Format: c format used in file output, default '%e %e' (optional) OUTPUT PARAMETERS: Wavenum: wavenumber grid Xsect: radiance spectrum calculated on the grid --- DESCRIPTION: Calculate a radiance spectrum (in W/sr/cm^2/cm-1) based on previously calculated absorption coefficient. Radiance spectrum is calculated at an arbitrary optical path length 'l' (1 m by default) and temperature 'T' (296 K by default). For obtaining a physically meaningful result 'T' must be the same as a temperature which was used in absorption coefficient. --- EXAMPLE OF USAGE: nu,radi = radianceSpectrum(nu,coef) ---", "response": "def radianceSpectrum(Omegas,AbsorptionCoefficient,Environment={'l':100.,'T':296.},\n                     File=None, Format='%e %e', Wavenumber=None):\n    \"\"\"\n    INPUT PARAMETERS: \n        Wavenumber/Omegas:   wavenumber grid                   (required)\n        AbsorptionCoefficient:  absorption coefficient on grid (required)\n        Environment:  dictionary containing path length in cm.\n                      and temperature in Kelvin.\n                      Default={'l':100.,'T':296.}\n        File:         name of the output file                 (optional) \n        Format: c format used in file output, default '%e %e' (optional)\n    OUTPUT PARAMETERS: \n        Wavenum: wavenumber grid\n        Xsect:  radiance spectrum calculated on the grid\n    ---\n    DESCRIPTION:\n        Calculate a radiance spectrum (in W/sr/cm^2/cm-1) based\n        on previously calculated absorption coefficient.\n        Radiance spectrum is calculated at an arbitrary\n        optical path length 'l' (1 m by default) and \n        temperature 'T' (296 K by default). For obtaining a\n        physically meaningful result 'T' must be the same \n        as a temperature which was used in absorption coefficient.\n    ---\n    EXAMPLE OF USAGE:\n        nu,radi = radianceSpectrum(nu,coef)\n    ---\n    \"\"\"\n    # compatibility with older versions\n    if Wavenumber: Omegas=Wavenumber\n    l = Environment['l']\n    T = Environment['T']\n    Alw = 1-exp(-AbsorptionCoefficient*l)\n    LBBTw = 2*hh*cc**2*Omegas**3 / (exp(hh*cc*Omegas/(cBolts*T)) - 1) * 1.0E-7\n    Xsect = Alw*LBBTw # W/sr/cm**2/cm**-1\n    if File: save_to_file(File,Format,Omegas,Xsect)\n    return Omegas,Xsect"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets X and Y for fine plotting of a stick spectrum.", "response": "def getStickXY(TableName):\n    \"\"\"\n    Get X and Y for fine plotting of a stick spectrum.\n    Usage: X,Y = getStickXY(TableName).\n    \"\"\"\n    cent,intens = getColumns(TableName,('nu','sw'))\n    n = len(cent)\n    cent_ = zeros(n*3)\n    intens_ = zeros(n*3)\n    for i in range(n):\n        intens_[3*i] = 0\n        intens_[3*i+1] = intens[i]\n        intens_[3*i+2] = 0\n        cent_[(3*i):(3*i+3)] = cent[i]\n    return cent_,intens_"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread cross - section file fetched from HITRAN - on - the - Web.", "response": "def read_hotw(filename):\n    \"\"\"\n    Read cross-section file fetched from HITRAN-on-the-Web.\n    The format of the file line must be as follows: \n      nu, coef\n    Other lines are omitted.\n    \"\"\"\n    import sys\n    f = open(filename,'r')\n    nu = []\n    coef = []\n    for line in f:\n        pars = line.split()\n        try:\n            nu.append(float(pars[0]))\n            coef.append(float(pars[1]))\n        except:\n            if False:\n                print(sys.exc_info())\n            else:\n                pass    \n    return array(nu),array(coef)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef SLIT_RECTANGULAR(x,g):\n    index_inner = abs(x) <= g/2\n    index_outer = ~index_inner\n    y = zeros(len(x))\n    y[index_inner] = 1/g\n    y[index_outer] = 0\n    return y", "response": "Instrumental (slit) function.\n    B(x) = 1/\u03b3 , if |x| \u2264 \u03b3/2 & B(x) = 0, if |x| > \u03b3/2,\n    where \u03b3 is a slit width or the instrumental resolution."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninputting PARAMETERS: Wavenumber/Omega: wavenumber grid (required) CrossSection: high-res cross section calculated on grid (required) Resolution: instrumental resolution \u03b3 (optional) AF_wing: instrumental function wing (optional) SlitFunction: instrumental function for low-res spectra calculation (optional) OUTPUT PARAMETERS: Wavenum: wavenumber grid CrossSection: low-res cross section calculated on grid i1: lower index in Omega input i2: higher index in Omega input slit: slit function calculated over grid [-AF_wing; AF_wing] with the step equal to instrumental resolution. --- DESCRIPTION: Produce a simulation of experimental spectrum via the convolution of a \u201cdry\u201d spectrum with an instrumental function. Instrumental function is provided as a parameter and is calculated in a grid with the width=AF_wing and step=Resolution. --- EXAMPLE OF USAGE: nu_,radi_,i,j,slit = convolveSpectrum(nu,radi,Resolution=2.0,AF_wing=10.0, SlitFunction=SLIT_MICHELSON) ---", "response": "def convolveSpectrum(Omega,CrossSection,Resolution=0.1,AF_wing=10.,\n                     SlitFunction=SLIT_RECTANGULAR,Wavenumber=None):\n    \"\"\"\n    INPUT PARAMETERS: \n        Wavenumber/Omega:    wavenumber grid                     (required)\n        CrossSection:  high-res cross section calculated on grid (required)\n        Resolution:    instrumental resolution \u03b3                 (optional)\n        AF_wing:       instrumental function wing                (optional)\n        SlitFunction:  instrumental function for low-res spectra calculation (optional)\n    OUTPUT PARAMETERS: \n        Wavenum: wavenumber grid\n        CrossSection: low-res cross section calculated on grid\n        i1: lower index in Omega input\n        i2: higher index in Omega input\n        slit: slit function calculated over grid [-AF_wing; AF_wing]\n                with the step equal to instrumental resolution. \n    ---\n    DESCRIPTION:\n        Produce a simulation of experimental spectrum via the convolution \n        of a \u201cdry\u201d spectrum with an instrumental function.\n        Instrumental function is provided as a parameter and\n        is calculated in a grid with the width=AF_wing and step=Resolution.\n    ---\n    EXAMPLE OF USAGE:\n        nu_,radi_,i,j,slit = convolveSpectrum(nu,radi,Resolution=2.0,AF_wing=10.0,\n                                                SlitFunction=SLIT_MICHELSON)\n    ---\n    \"\"\"    \n    # compatibility with older versions\n    if Wavenumber: Omega=Wavenumber\n    step = Omega[1]-Omega[0]\n    if step>=Resolution: raise Exception('step must be less than resolution')\n    #x = arange(-AF_wing,AF_wing+step,step)\n    x = arange_(-AF_wing,AF_wing+step,step) # fix\n    slit = SlitFunction(x,Resolution)\n    # FIXING THE BUG: normalize slit function\n    slit /= sum(slit)*step # simple normalization\n    left_bnd = len(slit)/2\n    right_bnd = len(Omega) - len(slit)/2\n    #CrossSectionLowRes = convolve(CrossSection,slit,mode='valid')*step\n    CrossSectionLowRes = convolve(CrossSection,slit,mode='same')*step\n    #return Omega[left_bnd:right_bnd],CrossSectionLowRes,left_bnd,right_bnd,slit\n    return Omega[left_bnd:right_bnd],CrossSectionLowRes[left_bnd:right_bnd],left_bnd,right_bnd,slit"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convolveSpectrumSame(Omega,CrossSection,Resolution=0.1,AF_wing=10.,\n                         SlitFunction=SLIT_RECTANGULAR):\n    \"\"\"\n    Convolves cross section with a slit function with given parameters.\n    \"\"\"\n    step = Omega[1]-Omega[0]\n    x = arange(-AF_wing,AF_wing+step,step)\n    slit = SlitFunction(x,Resolution)\n    print('step=')\n    print(step)\n    print('x=')\n    print(x)\n    print('slitfunc=')\n    print(SlitFunction)\n    CrossSectionLowRes = convolve(CrossSection,slit,mode='same')*step\n    return Omega,CrossSectionLowRes,None,None,slit", "response": "Convolves cross section with a slit function with given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_db(self, couch, dbname):\n\n        # Avoid race condition of two creating db\n        my_db = None\n\n        self.log.debug('Setting up DB: %s' % dbname)\n\n        if dbname not in couch:\n            self.log.info(\"DB doesn't exist so creating DB: %s\", dbname)\n            try:\n                my_db = couch.create(dbname)\n            except:\n                self.log.critical(\"Race condition caught\")\n                raise RuntimeError(\"Race condition caught when creating DB\")\n\n            try:\n                auth_doc = {}\n                auth_doc['_id'] = '_design/auth'\n                auth_doc['language'] = 'javascript'\n\n                auth_doc['validate_doc_update'] = \"\"\"\n                function(newDoc, oldDoc, userCtx) {\n                if (userCtx.roles.indexOf('_admin') !== -1) {\n                return;\n                } else {\n                throw({forbidden: 'Only admins may edit the database'});\n                }\n                }\n                \"\"\"\n\n                my_db.save(auth_doc)\n            except:\n                self.log.error('Could not set permissions of %s' % dbname)\n\n        else:\n            my_db = couch[dbname]\n\n        return my_db", "response": "Setup and configure DB"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncommits data to CouchDB", "response": "def commit(self, force=False):\n        \"\"\"Commit data to couchdb\n\n        Compared to threshold (unless forced) then sends data to couch\n        \"\"\"\n        self.log.debug('Bulk commit requested')\n        size = sys.getsizeof(self.docs)\n\n        self.log.debug('Size of docs in KB: %d', size)\n        if size > self.commit_threshold or force:\n            self.log.info('Commiting %d KB to CouchDB' % size)\n            self.my_db.update(self.docs)\n            self.docs = []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsave a doc to cache", "response": "def save(self, doc):\n        \"\"\"Save a doc to cache\n        \"\"\"\n        self.log.debug('save()')\n        self.docs.append(doc)\n        self.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\napplying a given function to the last item in a generator", "response": "def apply_to_last(stream, fn):\n    ''' applies a given function to the last item in a generator/stream '''\n    assert iterable(stream), 'apply_to_last needs stream to be iterable'\n    assert callable(fn), 'apply_to_last needs fn to be callable'\n\n    stream = iter(stream)\n    previous = next(stream)\n    for current in stream:\n        yield previous\n        previous = current\n    yield fn(previous)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef convert_dictionary_to_mysql_table(\n        log,\n        dictionary,\n        dbTableName,\n        uniqueKeyList=[],\n        dbConn=False,\n        createHelperTables=False,\n        dateModified=False,\n        returnInsertOnly=False,\n        replace=False,\n        batchInserts=True,\n        reDatetime=False,\n        skipChecks=False,\n        dateCreated=True):\n    \"\"\"convert dictionary to mysql table\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``dictionary`` -- python dictionary\n        - ``dbConn`` -- the db connection\n        - ``dbTableName`` -- name of the table you wish to add the data to (or create if it does not exist)\n        - ``uniqueKeyList`` - a lists column names that need combined to create the primary key\n        - ``createHelperTables`` -- create some helper tables with the main table, detailing original keywords etc\n        - ``returnInsertOnly`` -- returns only the insert command (does not execute it)\n        - ``dateModified`` -- add a modification date and updated flag to the mysql table\n        - ``replace`` -- use replace instead of mysql insert statements (useful when updates are required)\n        - ``batchInserts`` -- if returning insert statements return separate insert commands and value tuples\n        - ``reDatetime`` -- compiled regular expression matching datetime (passing this in cuts down on execution time as it doesn't have to be recompiled everytime during multiple iterations of ``convert_dictionary_to_mysql_table``)\n        - ``skipChecks`` -- skip reliability checks. Less robust but a little faster.\n        - ``dateCreated`` -- add a timestamp for dateCreated?\n\n    **Return:**\n        - ``returnInsertOnly`` -- the insert statement if requested\n\n    **Usage:**\n\n        To add a python dictionary to a database table, creating the table and/or columns if they don't yet exist:\n\n        .. code-block:: python\n\n            from fundamentals.mysql import convert_dictionary_to_mysql_table\n            dictionary = {\"a newKey\": \"cool\", \"and another\": \"super cool\",\n                      \"uniquekey1\": \"cheese\", \"uniqueKey2\": \"burgers\"}\n\n            convert_dictionary_to_mysql_table(\n                dbConn=dbConn,\n                log=log,\n                dictionary=dictionary,\n                dbTableName=\"testing_table\",\n                uniqueKeyList=[\"uniquekey1\", \"uniqueKey2\"],\n                dateModified=False,\n                returnInsertOnly=False,\n                replace=True\n            )\n\n        Or just return the insert statement with a list of value tuples, i.e. do not execute the command on the database:\n\n            insertCommand, valueTuple = convert_dictionary_to_mysql_table(\n                dbConn=dbConn,\n                log=log,\n                dictionary=dictionary,\n                dbTableName=\"testing_table\",\n                uniqueKeyList=[\"uniquekey1\", \"uniqueKey2\"],\n                dateModified=False,\n                returnInsertOnly=True,\n                replace=False,\n                batchInserts=True\n            )\n\n            print insertCommand, valueTuple\n\n            # OUT: 'INSERT IGNORE INTO `testing_table`\n            # (a_newKey,and_another,dateCreated,uniqueKey2,uniquekey1) VALUES\n            # (%s, %s, %s, %s, %s)', ('cool', 'super cool',\n            # '2016-06-21T12:08:59', 'burgers', 'cheese')\n\n        You can also return a list of single insert statements using ``batchInserts = False``. Using ``replace = True`` will also add instructions about how to replace duplicate entries in the database table if found:\n\n            inserts = convert_dictionary_to_mysql_table(\n                dbConn=dbConn,\n                log=log,\n                dictionary=dictionary,\n                dbTableName=\"testing_table\",\n                uniqueKeyList=[\"uniquekey1\", \"uniqueKey2\"],\n                dateModified=False,\n                returnInsertOnly=True,\n                replace=True,\n                batchInserts=False\n            )\n\n            print inserts\n\n            # OUT: INSERT INTO `testing_table` (a_newKey,and_another,dateCreated,uniqueKey2,uniquekey1)\n            # VALUES (\"cool\" ,\"super cool\" ,\"2016-09-14T13:12:08\" ,\"burgers\" ,\"cheese\")\n            # ON DUPLICATE KEY UPDATE  a_newKey=\"cool\", and_another=\"super\n            # cool\", dateCreated=\"2016-09-14T13:12:08\", uniqueKey2=\"burgers\",\n            # uniquekey1=\"cheese\"\n    \"\"\"\n\n    log.debug('starting the ``convert_dictionary_to_mysql_table`` function')\n\n    if not reDatetime:\n        reDatetime = re.compile('^[0-9]{4}-[0-9]{2}-[0-9]{2}T')\n\n    if not replace:\n        insertVerb = \"INSERT\"\n    else:\n        insertVerb = \"INSERT IGNORE\"\n\n    if returnInsertOnly == False:\n        # TEST THE ARGUMENTS\n        if str(type(dbConn).__name__) != \"Connection\":\n            message = 'Please use a valid MySQL DB connection.'\n            log.critical(message)\n            raise TypeError(message)\n\n        if not isinstance(dictionary, dict):\n            message = 'Please make sure \"dictionary\" argument is a dict type.'\n            log.critical(message)\n            raise TypeError(message)\n\n        if not isinstance(uniqueKeyList, list):\n            message = 'Please make sure \"uniqueKeyList\" is a list'\n            log.critical(message)\n            raise TypeError(message)\n\n        for i in uniqueKeyList:\n            if i not in dictionary.keys():\n                message = 'Please make sure values in \"uniqueKeyList\" are present in the \"dictionary\" you are tring to convert'\n                log.critical(message)\n                raise ValueError(message)\n\n        for k, v in dictionary.iteritems():\n            # log.debug('k: %s, v: %s' % (k, v,))\n            if isinstance(v, list) and len(v) != 2:\n                message = 'Please make sure the list values in \"dictionary\" 2 items in length'\n                log.critical(\"%s: in %s we have a %s (%s)\" %\n                             (message, k, v, type(v)))\n                raise ValueError(message)\n            if isinstance(v, list):\n                if not (isinstance(v[0], str) or isinstance(v[0], int) or isinstance(v[0], bool) or isinstance(v[0], float) or isinstance(v[0], long) or isinstance(v[0], datetime.date) or v[0] == None):\n                    message = 'Please make sure values in \"dictionary\" are of an appropriate value to add to the database, must be str, float, int or bool'\n                    log.critical(\"%s: in %s we have a %s (%s)\" %\n                                 (message, k, v, type(v)))\n                    raise ValueError(message)\n            else:\n                if not (isinstance(v, str) or isinstance(v, int) or isinstance(v, bool) or isinstance(v, float) or isinstance(v, long) or isinstance(v, unicode) or isinstance(v, datetime.date) or v == None):\n                    this = type(v)\n                    message = 'Please make sure values in \"dictionary\" are of an appropriate value to add to the database, must be str, float, int or bool : %(k)s is a %(this)s' % locals(\n                    )\n                    log.critical(\"%s: in %s we have a %s (%s)\" %\n                                 (message, k, v, type(v)))\n                    raise ValueError(message)\n\n        if not isinstance(createHelperTables, bool):\n            message = 'Please make sure \"createHelperTables\" is a True or False'\n            log.critical(message)\n            raise TypeError(message)\n\n        # TEST IF TABLE EXISTS\n        if not skipChecks:\n            tableExists = table_exists.table_exists(\n                dbConn=dbConn,\n                log=log,\n                dbTableName=dbTableName\n            )\n        else:\n            tableExists = False\n\n        # CREATE THE TABLE IF IT DOES NOT EXIST\n        if tableExists is False:\n            sqlQuery = \"\"\"\n                CREATE TABLE IF NOT EXISTS `%(dbTableName)s`\n                (`primaryId` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'An internal counter',\n                `dateCreated` DATETIME NULL DEFAULT CURRENT_TIMESTAMP,\n                `dateLastModified` DATETIME NULL DEFAULT CURRENT_TIMESTAMP,\n                `updated` tinyint(4) DEFAULT '0',\n                PRIMARY KEY (`primaryId`))\n                ENGINE=MyISAM AUTO_INCREMENT=0 DEFAULT CHARSET=latin1;\n            \"\"\" % locals()\n            writequery(\n                log=log,\n                sqlQuery=sqlQuery,\n                dbConn=dbConn,\n\n            )\n\n    qCreateColumn = ''\n    formattedKey = ''\n    formattedKeyList = []\n    myValues = []\n\n    # ADD EXTRA COLUMNS TO THE DICTIONARY todo: do I need this?\n    if dateModified:\n        dictionary['dateLastModified'] = [\n            str(times.get_now_sql_datetime()), \"date row was modified\"]\n        if replace == False:\n            dictionary['updated'] = [0, \"this row has been updated\"]\n        else:\n            dictionary['updated'] = [1, \"this row has been updated\"]\n\n    # ITERATE THROUGH THE DICTIONARY AND GENERATE THE TABLE COLUMN WITH THE\n    # NAME OF THE KEY, IF IT DOES NOT EXIST\n    count = len(dictionary)\n    i = 1\n    for (key, value) in dictionary.items():\n        if (isinstance(value, list) and value[0] is None):\n            del dictionary[key]\n    # SORT THE DICTIONARY BY KEY\n    odictionary = c.OrderedDict(sorted(dictionary.items()))\n    for (key, value) in odictionary.iteritems():\n\n        formattedKey = key.replace(\" \", \"_\").replace(\"-\", \"_\")\n        # DEC A KEYWORD IN MYSQL - NEED TO CHANGE BEFORE INGEST\n        if formattedKey == \"dec\":\n            formattedKey = \"decl\"\n        if formattedKey == \"DEC\":\n            formattedKey = \"DECL\"\n\n        formattedKeyList.extend([formattedKey])\n        if len(key) > 0:\n            # CONVERT LIST AND FEEDPARSER VALUES TO YAML (SO I CAN PASS IT AS A\n            # STRING TO MYSQL)\n            if isinstance(value, list) and (isinstance(value[0], list)):\n                value[0] = yaml.dump(value[0])\n                value[0] = str(value[0])\n            # REMOVE CHARACTERS THAT COLLIDE WITH MYSQL\n            # if type(value[0]) == str or type(value[0]) == unicode:\n            #     value[0] = value[0].replace('\"', \"\"\"'\"\"\")\n            # JOIN THE VALUES TOGETHER IN A LIST - EASIER TO GENERATE THE MYSQL\n            # COMMAND LATER\n            if isinstance(value, str):\n                value = value.replace('\\\\', '\\\\\\\\')\n                value = value.replace('\"', '\\\\\"')\n                try:\n                    udata = value.decode(\"utf-8\", \"ignore\")\n                    value = udata.encode(\"ascii\", \"ignore\")\n                except:\n                    log.error('cound not decode value %(value)s' % locals())\n\n                # log.debug('udata: %(udata)s' % locals())\n\n            if isinstance(value, unicode):\n                value = value.replace('\"', '\\\\\"')\n                value = value.encode(\"ascii\", \"ignore\")\n\n            if isinstance(value, list) and isinstance(value[0], unicode):\n                myValues.extend(['%s' % value[0].strip()])\n            elif isinstance(value, list):\n                myValues.extend(['%s' % (value[0], )])\n            else:\n                myValues.extend(['%s' % (value, )])\n\n            if returnInsertOnly == False:\n                # CHECK IF COLUMN EXISTS YET\n                colExists = \\\n                    \"SELECT * FROM information_schema.COLUMNS WHERE TABLE_SCHEMA=DATABASE() AND COLUMN_NAME='\" + \\\n                    formattedKey + \"'AND TABLE_NAME='\" + dbTableName + \"\"\"'\"\"\"\n                try:\n                    # log.debug('checking if the column '+formattedKey+' exists\n                    # in the '+dbTableName+' table')\n\n                    rows = readquery(\n                        log=log,\n                        sqlQuery=colExists,\n                        dbConn=dbConn,\n                    )\n                except Exception as e:\n                    log.error('something went wrong' + str(e) + '\\n')\n\n                # IF COLUMN DOESN'T EXIT - GENERATE IT\n                if len(rows) == 0:\n                    qCreateColumn = \"\"\"ALTER TABLE `%s` ADD `%s\"\"\" % (\n                        dbTableName, formattedKey)\n                    if not isinstance(value, list):\n                        value = [value]\n                    if reDatetime.search(str(value[0])):\n                        # log.debug('Ok - a datetime string was found')\n                        qCreateColumn += '` datetime DEFAULT NULL'\n                    elif formattedKey == 'updated_parsed' or formattedKey == 'published_parsed' or formattedKey \\\n                            == 'feedName' or formattedKey == 'title':\n                        qCreateColumn += '` varchar(100) DEFAULT NULL'\n                    elif (isinstance(value[0], str) or isinstance(value[0], unicode)) and len(value[0]) < 30:\n                        qCreateColumn += '` varchar(100) DEFAULT NULL'\n                    elif (isinstance(value[0], str) or isinstance(value[0], unicode)) and len(value[0]) >= 30 and len(value[0]) < 80:\n                        qCreateColumn += '` varchar(100) DEFAULT NULL'\n                    elif isinstance(value[0], str) or isinstance(value[0], unicode):\n                        columnLength = 450 + len(value[0]) * 2\n                        qCreateColumn += '` varchar(' + str(\n                            columnLength) + ') DEFAULT NULL'\n                    elif isinstance(value[0], int) and abs(value[0]) <= 9:\n                        qCreateColumn += '` tinyint DEFAULT NULL'\n                    elif isinstance(value[0], int):\n                        qCreateColumn += '` int DEFAULT NULL'\n                    elif isinstance(value[0], float) or isinstance(value[0], long):\n                        qCreateColumn += '` double DEFAULT NULL'\n                    elif isinstance(value[0], bool):\n                        qCreateColumn += '` tinyint DEFAULT NULL'\n                    elif isinstance(value[0], list):\n                        qCreateColumn += '` varchar(1024) DEFAULT NULL'\n                    else:\n                        # log.debug('Do not know what format to add this key in\n                        # MySQL - removing from dictionary: %s, %s'\n                                 # % (key, type(value[0])))\n                        formattedKeyList.pop()\n                        myValues.pop()\n                        qCreateColumn = None\n                    if qCreateColumn:\n                        # ADD COMMENT TO GIVE THE ORGINAL KEYWORD IF formatted FOR\n                        # MYSQL\n                        if key is not formattedKey:\n                            qCreateColumn += \" COMMENT 'original keyword: \" + \\\n                                key + \"\"\"'\"\"\"\n                        # CREATE THE COLUMN IF IT DOES NOT EXIST\n                        try:\n                            log.info('creating the ' +\n                                     formattedKey + ' column in the ' + dbTableName + ' table')\n                            writequery(\n                                log=log,\n                                sqlQuery=qCreateColumn,\n                                dbConn=dbConn\n                            )\n\n                        except Exception as e:\n                            # log.debug('qCreateColumn: %s' % (qCreateColumn,\n                            # ))\n                            log.error('could not create the ' + formattedKey + ' column in the ' + dbTableName\n                                      + ' table -- ' + str(e) + '\\n')\n\n    if returnInsertOnly == False:\n        # GENERATE THE INDEX NAME - THEN CREATE INDEX IF IT DOES NOT YET EXIST\n        if len(uniqueKeyList):\n            for i in range(len(uniqueKeyList)):\n                uniqueKeyList[i] = uniqueKeyList[\n                    i].replace(\" \", \"_\").replace(\"-\", \"_\")\n                if uniqueKeyList[i] == \"dec\":\n                    uniqueKeyList[i] = \"decl\"\n                if uniqueKeyList[i] == \"DEC\":\n                    uniqueKeyList[i] = \"DECL\"\n\n            indexName = uniqueKeyList[0].replace(\" \", \"_\").replace(\"-\", \"_\")\n            for i in range(len(uniqueKeyList) - 1):\n                indexName += '_' + uniqueKeyList[i + 1]\n\n            indexName = indexName.lower().replace(\"  \", \" \").replace(\" \", \"_\")\n\n            sqlQuery = u\"\"\"SELECT COUNT(*) FROM INFORMATION_SCHEMA.STATISTICS WHERE TABLE_SCHEMA = DATABASE() AND TABLE_NAME = '\"\"\" + \\\n                dbTableName + \"\"\"' AND INDEX_NAME = '\"\"\" + indexName + \"\"\"'\"\"\"\n            rows = readquery(\n                log=log,\n                sqlQuery=sqlQuery,\n                dbConn=dbConn,\n                quiet=False\n            )\n\n            exists = rows[0]['COUNT(*)']\n            # log.debug('uniqueKeyList: %s' % (uniqueKeyList,))\n            if exists == 0:\n                if isinstance(uniqueKeyList, list):\n                    uniqueKeyList = ','.join(uniqueKeyList)\n\n                addUniqueKey = 'ALTER TABLE `' + dbTableName + \\\n                    '` ADD unique ' + indexName + \\\n                    \"\"\" (\"\"\" + uniqueKeyList + ')'\n                # log.debug('HERE IS THE COMMAND:'+addUniqueKey)\n                writequery(\n                    log=log,\n                    sqlQuery=addUniqueKey,\n                    dbConn=dbConn\n                )\n\n    if returnInsertOnly == True and batchInserts == True:\n        myKeys = '`,`'.join(formattedKeyList)\n        valueString = (\"%s, \" * len(myValues))[:-2]\n        insertCommand = insertVerb + \"\"\" INTO `\"\"\" + dbTableName + \\\n            \"\"\"` (`\"\"\" + myKeys + \"\"\"`, dateCreated) VALUES (\"\"\" + \\\n            valueString + \"\"\", NOW())\"\"\"\n        mv = []\n        mv[:] = [None if m == \"None\" else m for m in myValues]\n        valueTuple = tuple(mv)\n\n        dup = \"\"\n        if replace:\n            dup = \" ON DUPLICATE KEY UPDATE \"\n            for k, v in zip(formattedKeyList, mv):\n                dup = \"\"\"%(dup)s %(k)s=values(%(k)s),\"\"\" % locals()\n\n        insertCommand = insertCommand + dup\n\n        insertCommand = insertCommand.replace('\\\\\"\"', '\\\\\" \"')\n        insertCommand = insertCommand.replace('\"\"', \"null\")\n        insertCommand = insertCommand.replace('!!python/unicode:', '')\n        insertCommand = insertCommand.replace('!!python/unicode', '')\n        insertCommand = insertCommand.replace('\"None\"', 'null')\n\n        if not dateCreated:\n            insertCommand = insertCommand.replace(\n                \", dateCreated)\", \")\").replace(\", NOW())\", \")\")\n\n        return insertCommand, valueTuple\n\n    # GENERATE THE INSERT COMMAND - IGNORE DUPLICATE ENTRIES\n    myKeys = '`,`'.join(formattedKeyList)\n    myValues = '\" ,\"'.join(myValues)\n    # log.debug(myValues+\" ------ PRESTRIP\")\n    # REMOVE SOME CONVERSION NOISE\n    myValues = myValues.replace('time.struct_time', '')\n    myValues = myValues.replace(\n        '- !!python/object/new:feedparser.FeedParserDict', '')\n    myValues = myValues.replace(\n        '!!python/object/new:feedparser.FeedParserDict', '')\n    myValues = myValues.replace('dictitems:', '')\n    myValues = myValues.replace('dictitems', '')\n    myValues = myValues.replace('!!python/unicode:', '')\n    myValues = myValues.replace('!!python/unicode', '')\n    myValues = myValues.replace('\"None\"', 'null')\n    # myValues = myValues.replace('\"None', 'null')\n\n    if myValues[-4:] != 'null':\n        myValues += '\"'\n\n    dup = \"\"\n    if replace:\n        dupValues = ('\"' + myValues).split(\" ,\")\n        dupKeys = formattedKeyList\n        dup = dup + \" ON DUPLICATE KEY UPDATE \"\n        for k, v in zip(dupKeys, dupValues):\n            dup = \"\"\"%(dup)s `%(k)s`=%(v)s,\"\"\" % locals()\n\n        if dateModified:\n            dup = \"\"\"%(dup)s updated=IF(\"\"\" % locals()\n            for k, v in zip(dupKeys, dupValues):\n                if v == \"null\":\n                    dup = \"\"\"%(dup)s `%(k)s` is %(v)s AND \"\"\" % locals()\n                else:\n                    dup = \"\"\"%(dup)s `%(k)s`=%(v)s AND \"\"\" % locals()\n            dup = dup[:-5] + \", 0, 1), dateLastModified=IF(\"\n            for k, v in zip(dupKeys, dupValues):\n                if v == \"null\":\n                    dup = \"\"\"%(dup)s `%(k)s` is %(v)s AND \"\"\" % locals()\n                else:\n                    dup = \"\"\"%(dup)s `%(k)s`=%(v)s AND \"\"\" % locals()\n            dup = dup[:-5] + \", dateLastModified, NOW())\"\n        else:\n            dup = dup[:-1]\n\n    # log.debug(myValues+\" ------ POSTSTRIP\")\n    addValue = insertVerb + \"\"\" INTO `\"\"\" + dbTableName + \\\n        \"\"\"` (`\"\"\" + myKeys + \"\"\"`, dateCreated) VALUES (\\\"\"\"\" + \\\n        myValues + \"\"\", NOW()) %(dup)s \"\"\" % locals()\n\n    if not dateCreated:\n        addValue = addValue.replace(\n            \", dateCreated)\", \")\").replace(\", NOW())\", \")\", 1)\n\n    addValue = addValue.replace('\\\\\"\"', '\\\\\" \"')\n    addValue = addValue.replace('\"\"', \"null\")\n    addValue = addValue.replace('!!python/unicode:', '')\n    addValue = addValue.replace('!!python/unicode', '')\n    addValue = addValue.replace('\"None\"', 'null')\n    # log.debug(addValue)\n\n    if returnInsertOnly == True:\n        return addValue\n\n    message = \"\"\n    try:\n        # log.debug('adding new data to the %s table; query: %s' %\n        # (dbTableName, addValue))\"\n        writequery(\n            log=log,\n            sqlQuery=addValue,\n            dbConn=dbConn\n        )\n\n    except Exception as e:\n        log.error(\"could not add new data added to the table '\" +\n                  dbTableName + \"' : \" + str(e) + '\\n')\n\n    log.debug('completed the ``convert_dictionary_to_mysql_table`` function')\n    return None, None", "response": "convert a python dictionary to a mysql table"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nstarting a new Interactive client.", "response": "def start(address, channel, key, loop=None):\n    \"\"\"Starts a new Interactive client.\n\n    Takes the remote address of the Tetris robot, as well as the\n    channel number and auth key to use. Additionally, it takes\n    a list of handler. This should be a dict of protobuf wire\n    IDs to handler functions (from the .proto package).\n    \"\"\"\n\n    if loop is None:\n        loop = asyncio.get_event_loop()\n\n    socket = yield from websockets.connect(address+\"/robot\", loop=loop)\n\n    conn = Connection(socket, loop)\n    yield from conn.send(_create_handshake(channel, key))\n\n    return conn"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_handshake(channel, key):\n    hsk = Handshake()\n    hsk.channel = channel\n    hsk.streamKey = key\n    return hsk", "response": "Creates and returns a Handshake packet that authenticates the given channel with the given stream key."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports a module from a file.", "response": "def import_module(filename):\r\n    \"\"\"\r\n    Returns module object\r\n\r\n    Source: https://www.blog.pythonlibrary.org/2016/05/27/python-201-an-intro-to-importlib/\r\n    \"\"\"\r\n    module_name = \"xyz\"\r\n\r\n    module_spec = importlib.util.spec_from_file_location(module_name, filename)\r\n\r\n    if module_spec is None:\r\n        raise RuntimeError(\"Python cannot import file '{}'\".format(filename))\r\n\r\n    module = importlib.util.module_from_spec(module_spec)\r\n    module_spec.loader.exec_module(module)\r\n    # print(dir(module))\r\n    #\r\n    # msg = 'The {module_name} module has the following methods:' \\\r\n    #       ' {methods}'\r\n    # print(msg.format(module_name=module_name,\r\n    #                  methods=dir(module)))\r\n\r\n    return module"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of ExeInfo objects which represent Python scripts within dir_", "response": "def get_exe_info(dir_, flag_protected=False):\r\n    \"\"\"\r\n    Returns a list of ExeInfo objects, which represent Python scripts within dir_\r\n\r\n    Args:\r\n        dir_: string, path to directory\r\n        flag_protected: whether or not to include files starting with a '_'\r\n\r\n    Returns:\r\n        list of ExeInfo objects\r\n\r\n    The ExeInfo objects represent the \".py\" files in directory dir_,\r\n    \"\"\"\r\n\r\n    ret = []\r\n    # gets all scripts in script directory\r\n    ff = glob.glob(os.path.join(dir_, \"*.py\"))\r\n    # discards scripts whose file name starts with a \"_\"\r\n    ff = [f for f in ff if flag_protected or not os.path.basename(f).startswith(\"_\")]\r\n    ff.sort()\r\n\r\n    for f in ff:\r\n        _, filename = os.path.split(f)\r\n        flag_error = False\r\n        flag_gui = None\r\n        descr = \"(no doc)\"\r\n        try:\r\n            # Checks if it is a graphical application\r\n\r\n            with open(f, \"r\") as h:\r\n                flag_gui = \"QApplication\" in h.read()\r\n\r\n            try:\r\n                script_ = None\r\n                script_ = import_module(f)  # imp.load_source('script_', f)  # module object\r\n            except SystemExit:\r\n                descr = \"? (called sys.exit())\"\r\n            else:\r\n                if script_.__doc__ is not None:\r\n                    descr = script_.__doc__.strip().split(\"\\n\")[0]  # first line of docstring\r\n\r\n        except Exception as e:\r\n            flag_error = True\r\n            descr = \"*{0!s}*: {1!s}\".format(e.__class__.__name__, str(e))\r\n\r\n        if len(descr) == 0:\r\n            descr = \"(no doc)\"\r\n\r\n        ret.append(ExeInfo(filename, descr, flag_error, flag_gui))\r\n\r\n    # Sorts command-line and graphical applications by name separately\r\n    sisi_gra = [si for si in ret if si.flag_gui]\r\n    sisi_cmd = [si for si in ret if not si.flag_gui]\r\n    sisi_gra = sorted(sisi_gra, key=lambda x: x.filename)\r\n    sisi_cmd = sorted(sisi_cmd, key=lambda x: x.filename)\r\n    ret = sisi_cmd+sisi_gra\r\n\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of tuples containing class names signature and docstring strings for all the classes starting with prefix.", "response": "def collect_doc(module, base_class=None, prefix=\"\", flag_exclude_prefix=False):\r\n    \"\"\"\r\n    Collects class names and docstrings in module for classes starting with prefix\r\n\r\n    Arguments:\r\n        module -- Python module\r\n        prefix -- argument for str.startswith(); if not passed, does not filter\r\n        base_class -- filters only descendants of this class\r\n        flag_exclude_prefix -- whether or not to exclude prefix from class name in result\r\n\r\n    Returns: [(classname0, signature, docstring0), ...]\r\n    \"\"\"\r\n\r\n    ret = []\r\n    for attrname in module.__all__:\r\n        if prefix and not attrname.startswith(prefix):\r\n            continue\r\n\r\n        attr = module.__getattribute__(attrname)\r\n\r\n        if base_class is not None and not issubclass(attr, base_class):\r\n            continue\r\n\r\n        spec = inspect.signature(attr)\r\n\r\n        ret.append((attrname if not flag_exclude_prefix else attrname[len(prefix):], spec, attr.__doc__))\r\n\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list with all classes in module that are a subclass of superclass.", "response": "def get_classes_in_module(module, superclass=object):\r\n    \"\"\"\r\n    Returns a list with all classes in module that descend from parent\r\n\r\n    Args:\r\n        module: builtins.module\r\n        superclass: a class\r\n\r\n    Returns: list\r\n    \"\"\"\r\n\r\n    ret = []\r\n    for classname in dir(module):\r\n        attr = module.__getattribute__(classname)\r\n        try:\r\n            if issubclass(attr, superclass) and (attr != superclass):\r\n                ret.append(attr)\r\n        except TypeError:\r\n            # \"issubclass() arg 1 must be a class\"\r\n            pass\r\n        except RuntimeError:\r\n            # a99.get_python_logger().exception(\"Failed probing attribute '{}'\".format(classname))\r\n            # raise\r\n            pass\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn first line of cls. __doc__ or alternative text", "response": "def get_obj_doc0(obj, alt=\"(no doc)\"):\r\n    \"\"\"Returns first line of cls.__doc__, or alternative text\"\"\"\r\n    ret = obj.__doc__.strip().split(\"\\n\")[0] if obj.__doc__ is not None else alt\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfigure out the names of the subpackages of a package", "response": "def get_subpackages_names(dir_):\r\n    \"\"\"Figures out the names of the subpackages of a package\r\n\r\n    Args:\r\n        dir_: (str) path to package directory\r\n\r\n    Source: http://stackoverflow.com/questions/832004/python-finding-all-packages-inside-a-package\r\n    \"\"\"\r\n\r\n    def is_package(d):\r\n        d = os.path.join(dir_, d)\r\n        return os.path.isdir(d) and glob.glob(os.path.join(d, '__init__.py*'))\r\n\r\n    ret = list(filter(is_package, os.listdir(dir_)))\r\n    ret.sort()\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_params(filepath):\n    # Read the file\n    with open(filepath) as file:\n        content = file.read()\n\n    # Detect all environment variables referenced (using %EXAMPLE%, use windows style since it is easier to match)\n    q = [m.start() for m in re.finditer(\"%\", content)]\n    env_vars = []\n    for i in range(0, len(q), 2):\n        env_var = content[q[i]+1:q[i+1]]\n        if env_var not in env_vars:\n            if env_var in os.environ:\n                env_vars.append(env_var)\n            else:\n                print(\"WARNING: Detected an environment variable which is not set.\")\n    \n    # Fill in environment variables\n    for env_var in env_vars:\n        s = \"%\" + env_var + \"%\"\n        # Use unix style path linebreaks, since windows style might break stuff (and linux is more common anyways.)\n        content = content.replace(s, os.environ[env_var].replace(\"\\\\\", \"/\"))\n\n    # Try to match linux path style with anything that matches\n    for env_var in list(os.environ.keys()):\n        s = \"$\" + env_var\n        content = content.replace(s, os.environ[env_var].replace(\"\\\\\", \"/\"))\n\n    # Finally load hyperparams\n    return HyperParams(json.loads(jsmin(content)))", "response": "Load your hyper parameters from a json file."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the value specified in the dictionary or a default.", "response": "def get(self, key, default=_sentinel):\n        \"\"\"\n        Get the value specified in the dictionary or a default.\n        :param key: The key which should be retrieved.\n        :param default: The default that is returned if the key is not set.\n        :return: The value from the dict or the default.\n        \"\"\"\n        if default is _sentinel:\n            default = HyperParams({})\n        return self.__dict__[key] if key in self.__dict__ else default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the negative log likelihood given data and a model", "response": "def nll(data, model):\n    \"\"\"\n    Negative log likelihood given data and a model\n\n    Parameters\n    ----------\n    {0}\n    {1}\n\n    Returns\n    -------\n    float\n        Negative log likelihood\n\n    Examples\n    ---------\n\n    >>> import macroeco.models as md\n    >>> import macroeco.compare as comp\n\n    >>> # Generate random data\n    >>> rand_samp = md.logser.rvs(p=0.9, size=100)\n\n    >>> # Get nll for p = 0.9\n    >>> comp.nll(rand_samp, md.logser(p=0.9))\n    237.6871819262054\n\n    >>> # Get the nll for the MLE for p\n    >>> mle_p = md.logser.fit_mle(rand_samp)\n    >>> comp.nll(rand_samp, md.logser(*mle_p))\n    235.2841347820297\n\n    \"\"\"\n\n    try:\n        log_lik_vals = model.logpmf(data)\n    except:\n        log_lik_vals = model.logpdf(data)\n    return -np.sum(log_lik_vals)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lrt(data, model_full, model_reduced, df=None):\n\n    # Calculate G^2 statistic\n    ll_full = nll(data, model_full) * -1\n    ll_reduced = nll(data, model_reduced) * -1\n    test_stat = 2 * (ll_full - ll_reduced)\n\n    # Set df if necessary\n    if not df:\n        df =  ( len(model_full.args) + len(model_full.kwds)\n              - len(model_reduced.args) - len(model_reduced.kwds) )\n\n    return test_stat, stats.chisqprob(test_stat, df)", "response": "Compare two nested models using a likelihood ratio test."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncalculate delta AIC and AIC weights from a list of AIC values.", "response": "def AIC_compare(aic_list):\n    \"\"\"\n    Calculates delta AIC and AIC weights from a list of AIC values\n\n    Parameters\n    -----------------\n    aic_list : iterable\n        AIC values from set of candidat models\n\n    Returns\n    -------------\n    tuple\n        First element contains the delta AIC values, second element contains\n        the relative AIC weights.\n\n    Notes\n    -----\n    AIC weights can be interpreted as the probability that a given model is the\n    best model in the set.\n\n    Examples\n    --------\n\n    >>> # Generate random data\n    >>> rand_samp = md.nbinom_ztrunc.rvs(20, 0.5, size=100)\n\n    >>> # Fit Zero-truncated NBD (Full model)\n    >>> mle_nbd = md.nbinom_ztrunc.fit_mle(rand_samp)\n\n    >>> # Fit a logseries (limiting case of Zero-truncated NBD, reduced model)\n    >>> mle_logser = md.logser.fit_mle(rand_samp)\n\n    >>> # Get AIC for ztrunc_nbinom\n    >>> nbd_aic = comp.AIC(rand_samp, md.nbinom_ztrunc(*mle_nbd))\n\n    >>> # Get AIC for logser\n    >>> logser_aic = comp.AIC(rand_samp, md.logser(*mle_logser))\n\n    >>> # Make AIC list and get weights\n    >>> aic_list = [nbd_aic, logser_aic]\n    >>> comp.AIC_compare(aic_list)\n    (array([  0.        ,  19.11806518]),\n    array([  9.99929444e-01,   7.05560486e-05]))\n\n    >>> # Zero-truncated NBD is a far superior model based on AIC weights\n\n    \"\"\"\n\n    aic_values = np.array(aic_list)\n    minimum = np.min(aic_values)\n    delta = aic_values - minimum\n    values = np.exp(-delta / 2)\n    weights = values / np.sum(values)\n\n    return delta, weights"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the sum of squares between observed and predicted data.", "response": "def sum_of_squares(obs, pred):\n    \"\"\"\n    Sum of squares between observed and predicted data\n\n    Parameters\n    ----------\n    obs : iterable\n        Observed data\n    pred : iterable\n        Predicted data\n\n    Returns\n    -------\n    float\n        Sum of squares\n\n    Notes\n    -----\n    The length of observed and predicted data must match.\n\n    \"\"\"\n\n    return np.sum((np.array(obs) - np.array(pred)) ** 2)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the R^2 value for a regression of observed and predicted data.", "response": "def r_squared(obs, pred, one_to_one=False, log_trans=False):\n    \"\"\"\n    R^2 value for a regression of observed and predicted data\n\n    Parameters\n    ----------\n    obs : iterable\n        Observed data\n    pred : iterable\n        Predicted data\n    one_to_one : bool\n        If True, calculates the R^2 based on the one-to-one line (see [#]_),\n        and if False, calculates the standard R^2 based on a linear regression.\n        Default False.\n    log_trans : bool\n        If True, log transforms obs and pred before R^2 calculation.\n\n    Returns\n    -------\n    float\n        R^2 value\n\n    Notes\n    -----\n    Using the traditional R^2 to compare the fit of observed and predicted\n    values may be misleading as the relationship may not be one-to-one but the\n    R^2 value may be quite high. The one-to-one option alleviates this problem.\n    Note that with the one-to-one option R^2 can be negative.\n\n    Examples\n    --------\n\n    >>> import numpy as np\n    >>> import macroeco.compare as comp\n\n    >>> # Generate some data\n    >>> x_vals = np.linspace(1, 20, num=100)\n    >>> y_vals = np.random.normal(4 + x_vals*2, 1)\n\n    >>> # Standard R^2\n    >>> comp.r_squared(x_vals, y_vals)\n    0.99336568326291697\n\n    >>> # R^2 about the 1:1 line, will be a poor fit (possibly negative)\n    >>> comp.r_squared(x_vals, y_vals, one_to_one=True)\n    -6.8621799432144988\n\n    >>> # Generate some other data\n    >>> y_vals = np.random.normal(x_vals, 1)\n\n    >>> # Normal R^2\n    >>> comp.r_squared(x_vals, y_vals)\n    0.97651897660174425\n\n    >>> # R^2 on to the one to one line\n    >>> comp.r_squared(x_vals, y_vals, one_to_one=True)\n    0.97591430200514639\n\n    References\n    ----------\n    .. [#]\n       White, E., Thibault, K., & Xiao, X. (2012). Characterizing the species\n       abundance distributions across taxa and ecosystems using a simple\n       maximum entropy model. Ecology, 93(8), 1772-8\n\n    \"\"\"\n\n    if log_trans:\n        obs = np.log(obs)\n        pred = np.log(pred)\n\n    if one_to_one:\n        r_sq = 1 - (sum_of_squares(obs, pred) /\n                    sum_of_squares(obs, np.mean(obs)))\n    else:\n        b0, b1, r, p_value, se = stats.linregress(obs, pred)\n        r_sq = r ** 2\n\n    return r_sq"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef preston_bin(data, max_num):\n\n    log_ub = np.ceil(np.log2(max_num))\n\n    # Make an exclusive lower bound in keeping with Preston\n    if log_ub == 0:\n        boundaries = np.array([0, 1])\n    elif log_ub == 1:\n        boundaries = np.arange(1, 4)\n    else:\n        boundaries = 2 ** np.arange(0, log_ub + 1)\n        boundaries = np.insert(boundaries, 2, 3)\n        boundaries[3:] = boundaries[3:] + 1\n\n    hist_data = np.histogram(data, bins=boundaries)\n    return hist_data", "response": "Bin data on base 2 using Preston s method of binning."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pueyo_bins(data):\n    log_ub = np.ceil(np.log2(np.max(data)))\n    bins = 2**np.arange(log_ub + 1)\n    binned_data = np.histogram(data, bins=bins)[0]\n    epdf = (1 / bins[:-1]) * binned_data / len(data)\n    return binned_data, epdf", "response": "Binning method based on Pueyo 2006"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the base url of the given url.", "response": "def get_base_url(url, include_path=False):\n    \"\"\" :return: the url without the query or fragment segments \"\"\"\n\n    if not url:\n        return None\n\n    parts = _urlsplit(url)\n    base_url = _urlunsplit((\n        parts.scheme, parts.netloc, (parts.path if include_path else ''), None, None\n    ))\n\n    return base_url if base_url.endswith('/') else base_url + '/'"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_url_params(url, replace_all=False, **url_params):\n\n    # Ensure 'replace_all' can be sent as a url param\n    if not (replace_all is True or replace_all is False):\n        url_params['replace_all'] = replace_all\n\n    if not url or not url_params:\n        return url or None\n\n    scheme, netloc, url_path, url_query, fragment = _urlsplit(url)\n\n    if replace_all is True:\n        url_query = url_params\n    else:\n        url_query = _parse_qs(url_query)\n        url_query.update(url_params)\n\n    return _urlunsplit((scheme, netloc, url_path, _unquote(_urlencode(url_query, doseq=True)), fragment))", "response": "Updates the url query with the given params."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef url_to_parts(url):\n\n    if not url:\n        return None\n\n    scheme, netloc, path, query, fragment = _urlsplit(url)\n\n    if not path or path == '/':\n        path = []\n    else:\n        path = path.strip('/').split('/')\n\n    if not query:\n        query = {}\n    else:\n        query = _parse_qs(query)\n\n    return _urllib_parse.SplitResult(scheme, netloc, path, query, fragment)", "response": "Split url into list of parts"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild urlunsplit style but optionally handle path as a list and / or query as a dict", "response": "def parts_to_url(parts=None, scheme=None, netloc=None, path=None, query=None, fragment=None):\n    \"\"\" Build url urlunsplit style, but optionally handle path as a list and/or query as a dict \"\"\"\n\n    if isinstance(parts, _urllib_parse.SplitResult):\n        scheme, netloc, path, query, fragment = parts\n    elif parts and isinstance(parts, dict):\n        scheme = parts.get('scheme', 'http')\n        netloc = parts.get('netloc', '')\n        path = parts.get('path', [])\n        query = parts.get('query', {})\n        fragment = parts.get('fragment', '')\n\n    if isinstance(path, (list, tuple)):\n        path = '/' + '/'.join(path).strip('/')\n    if isinstance(query, (dict, tuple)):\n        query = _unquote(_urlencode(query, doseq=True))\n\n    return _urlunsplit((scheme, netloc, path, query, fragment)) or None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search(self, path, values=None, unique=False, raise_absent=False, vfunc=lambda x: x):\n        path_and_value_list = iterutils.search(\n                self.data,\n                path=path,\n                required_values=values)\n\n        # print 'search found ', [x[0] for x in path_and_value_list]\n\n        return self.__return_value(path_and_value_list, unique, raise_absent, vfunc)", "response": "Search for a single model object instance matching a given criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns single model object instance matching given criteria", "response": "def obj(self, path=None, model=None, values=None, raise_absent=False):\n        \"\"\"\n       Return single model object instance matching given criteria\n       :param path: tuple or dpath expression representing the hierarchy/chain of parent keys\n       :param values: single value or list of values to match. If exact is False then .contains method is used as filter\n       :param raise_absent: if True then raise exception if no match is found\n       :return: matching object from cache if already created or new if not\n       \"\"\"\n        return self.search(path=path, unique=True, raise_absent=raise_absent, values=values,\n                            vfunc=lambda x: self.path_index[x[0]].instance(model=model) if x[0] in self.path_index else None)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef objs(self, path=None, model=None, values=None, raise_absent=False):\n        return self.search(path=path, unique=False, raise_absent=raise_absent, values=values,\n                       vfunc=lambda x: self.path_index[x[0]].instance(model=model, reraise=False) if x[0] in self.path_index else None)", "response": "Return list of model objects matching given criteria"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fobj(self, path=None, values=None, unique=True, raise_absent=False):\n        return self.path_index[self.search(path=path, unique=unique, values=values, raise_absent=raise_absent)[0]]", "response": "Returns the first model instance or registration object matching given criteria"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling during model research on merged data", "response": "def __visit_index_model_instance(self, models, p, k, v):\n        \"\"\"\n            Called during model research on merged data\n        \"\"\"\n            # print 'model visit {} on {}'.format(model, v)\n        cp = p + (k,)\n        for model in models:\n            try:\n                if model.validator(v):\n                    if cp in self.path_index:\n                        # if self.path_index[cp].val != v:\n                        #     raise ValueError('unexpected value change at path_index[{}]'.format(cp))\n                        self.path_index[cp].add_model(model, v)\n                    else:\n                        # The object should already be in the index but don't complain for now.\n                        self.path_index[cp] = PathCacheObject(val=v, path=cp, regs=[model])\n            except:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing the edge reduction. Costly computation", "response": "def compute_edge_reduction(self) -> float:\n        \"\"\"Compute the edge reduction. Costly computation\"\"\"\n        nb_init_edge = self.init_edge_number()\n        nb_poweredge = self.edge_number()\n        return (nb_init_edge - nb_poweredge) / (nb_init_edge)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef init_edge_number(self) -> int:\n        return len(frozenset(frozenset(edge) for edge in self.initial_edges()))", "response": "Return the number of edges present in the non - compressed graph"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef initial_edges(self) -> iter:\n        nodes_in = lambda n: ([n] if self.is_node(n) else self.nodes_in(n))\n        for node, succs in self.edges.items():\n            twos = tuple(two for succ in succs for two in nodes_in(succ))\n            for one in nodes_in(node):\n                for two in twos:\n                    yield one, two", "response": "Yields edges in the initial ( uncompressed ) graphs. Possible doublons."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns for one root of each connected component all the linked objects and the mapping linking a connected component containing the roots that it contains.", "response": "def connected_components(self) -> (dict, dict):\n        \"\"\"Return for one root of each connected component all\n        the linked objects, and the mapping linking a connected component\n        root with the roots that it contains.\"\"\"\n        inclusions = utils.completed_graph(self.inclusions)  # allow bottom-up movement\n        edges = utils.completed_graph(self.edges) if self.oriented else self.edges\n        cc = {}  # maps cc root with nodes in the cc\n        subroots = defaultdict(set)  # maps cc root with other roots of the cc\n        walked_roots = set()  # all roots that have been walked already\n        for root in self.roots:\n            if root in walked_roots: continue  # this cc have been done already\n            # walk in the graph starting at root\n            cc[root] = set([root])\n            walked = cc[root]\n            stack = list(edges.get(root, ())) + list(inclusions.get(root, ()))\n            while len(stack) > 0:\n                *stack, curr = stack\n                walked.add(curr)\n                if curr in self.roots:  # don't do the walk for already found roots\n                    walked_roots.add(curr)\n                    subroots[root].add(curr)\n                for succ in it.chain(edges.get(curr, ()), inclusions.get(curr, ())):\n                    if succ not in walked:\n                        stack.append(succ)\n        return cc, dict(subroots)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nraise a ValueError if given name refers to a powernode in given graph.", "response": "def assert_powernode(self, name:str) -> None or ValueError:\n        \"\"\"Do nothing if given name refers to a powernode in given graph.\n        Raise a ValueError in any other case.\n\n        \"\"\"\n        if name not in self.inclusions:\n            raise ValueError(\"Powernode '{}' does not exists.\".format(name))\n        if self.is_node(name):\n            raise ValueError(\"Given name '{}' is a node.\".format(name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Powernode object describing the given powernode name.", "response": "def powernode_data(self, name:str) -> Powernode:\n        \"\"\"Return a Powernode object describing the given powernode\"\"\"\n        self.assert_powernode(name)\n        contained_nodes = frozenset(self.nodes_in(name))\n        return Powernode(\n            size=len(contained_nodes),\n            contained=frozenset(self.all_in(name)),\n            contained_pnodes=frozenset(self.powernodes_in(name)),\n            contained_nodes=contained_nodes,\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef node_number(self, *, count_pnode=True) -> int:\n        return (sum(1 for n in self.nodes())\n                + (sum(1 for n in self.powernodes()) if count_pnode else 0))", "response": "Return the number of nodes in the hierarchy."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef edge_number(self) -> int:\n        edges = set()\n        for node, succs in self.edges.items():\n            for succ in succs:\n                edges.add(frozenset((node, succ)))\n        return len(edges)", "response": "Return the number of power edges"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nodes(self) -> iter:\n        yield from (elem for elem, subs in self.inclusions.items() if subs == ())", "response": "Yield all nodes in the graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield all powernodes in the graph.", "response": "def powernodes(self) -> iter:\n        \"\"\"Yield all powernodes in the graph (not the nodes)\"\"\"\n        yield from (elem for elem, subs in self.inclusions.items() if subs != ())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nodes_in(self, name) -> iter:\n        yield from (node for node in self.all_in(name) if self.is_node(node))", "response": "Yield all nodes contained in given power name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef powernodes_in(self, name) -> iter:\n        yield from (node for node in self.all_in(name) if self.is_powernode(node))", "response": "Yield all power nodes contained in given ( power ) node name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nyields all ( power ) nodes contained in given ( power ) node.", "response": "def all_in(self, name) -> iter:\n        \"\"\"Yield all (power) nodes contained in given (power) node\"\"\"\n        for elem in self.inclusions[name]:\n            yield elem\n            yield from self.all_in(elem)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef powernodes_containing(self, name, directly=False) -> iter:\n        if directly:\n            yield from (node for node in self.all_in(name)\n                        if name in self.inclusions[node])\n        else:\n            # This algorithm is very bad. Inverting the inclusion dict could\n            #  be far better.\n            @functools.lru_cache(maxsize=self.node_number(count_pnode=True))\n            def contains_target(node, target):\n                succs = self.inclusions[node]\n                if target in succs:\n                    return True\n                else:\n                    return any(contains_target(succ, target) for succ in succs)\n            # populate the cache\n            for root in self.roots:\n                contains_target(root, name)\n            # output all that contains target at some level\n            yield from (node for node in self.inclusions.keys()\n                        if contains_target(node, name))", "response": "Yield all power nodes containing given name."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite in given filename the lines of bubble describing this instance", "response": "def write_bubble(self, filename:str):\n        \"\"\"Write in given filename the lines of bubble describing this instance\"\"\"\n        from bubbletools import converter\n        converter.tree_to_bubble(self, filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_bubble_file(bblfile:str, oriented:bool=False,\n                          symmetric_edges:bool=True) -> 'BubbleTree':\n        \"\"\"Extract data from given bubble file,\n        then call from_bubble_data method\n        \"\"\"\n        return BubbleTree.from_bubble_data(utils.data_from_bubble(bblfile),\n                                           oriented=bool(oriented),\n                                           symmetric_edges=symmetric_edges)", "response": "Extract data from given bubble file and return a new BubbleTree object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a BubbleTree instance from a list of raw line strings.", "response": "def from_bubble_lines(bbllines:iter, oriented:bool=False,\n                          symmetric_edges:bool=True) -> 'BubbleTree':\n        \"\"\"Return a BubbleTree instance.\n\n        bbllines -- iterable of raw line, bubble-formatted\n        oriented -- True: returned BubbleTree is oriented\n\n        \"\"\"\n        return BubbleTree.from_bubble_data((utils.line_data(line)\n                                            for line in bbllines),\n                                           oriented=bool(oriented),\n                                           symmetric_edges=symmetric_edges)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef from_bubble_data(bbldata:iter, oriented:bool=False,\n                         symmetric_edges:bool=True) -> 'BubbleTree':\n        \"\"\"Return a BubbleTree instance.\n\n        bbldata -- lines in bubble bbltree\n        oriented -- True: returned BubbleTree is oriented\n\n        \"\"\"\n        # get structure as two dicts\n        edges, inclusions = defaultdict(set), defaultdict(set)\n        used_in_edges = set()\n        for line in bbldata:\n            if not line: continue\n            ltype, *payload = line\n            if ltype == 'EDGE':\n                source, target = payload\n                edges[source].add(target)\n                used_in_edges.add(source)\n                used_in_edges.add(target)\n            elif ltype == 'SET':\n                setname = payload[0]\n                inclusions[setname]  # create it if not already populated\n            elif ltype == 'NODE':\n                nodename = payload[0]\n                inclusions[nodename] = ()  # a node can't contain anything\n            elif ltype == 'IN':\n                contained, container = payload\n                inclusions[container].add(contained)\n            else:  # comment, empty or error\n                if ltype not in {'COMMENT', 'EMPTY', 'ERROR'}:\n                    raise ValueError(\"The following line is not a valid \"\n                                     \"type ({}): '{}'\".format(ltype, payload))\n                else:  # it's a comment, an empty line or an error\n                    pass\n\n\n        # all (power)nodes used in edges should be present in inclusions tree\n        for node in used_in_edges:\n            if node not in inclusions:  # contains nothing, so its a node\n                inclusions[node] = ()\n\n        # all pure nodes needs to be a key in inclusions\n        for node in set(it.chain.from_iterable(inclusions.values())):\n            # an element that is not in inclusion is either:\n            #  - a node not explicitely defined in a NODE line\n            #  - a powernode that contains nothing and not explicitely defined in a SET line\n            # the second case is meaningless : this is the case for any unused powernode name.\n            # Consequently, elements not in inclusions are nodes.\n            if node not in inclusions:\n                inclusions[node] = ()\n\n        # find the roots\n        not_root = set(it.chain.from_iterable(inclusions.values()))\n        roots = frozenset(frozenset(inclusions.keys()) - not_root)\n\n        # build the (oriented) bubble tree\n        symmetric_edges = symmetric_edges and not oriented\n        if symmetric_edges:\n            edges = utils.completed_graph(edges)\n        return BubbleTree(edges=edges, inclusions=dict(inclusions),\n                          roots=roots, oriented=oriented, symmetric_edges=symmetric_edges)", "response": "Return a BubbleTree instance from a list of lines in bubble data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef same_network(atree, btree) -> bool:\n    return same_hierarchy(atree, btree) and same_topology(atree, btree)", "response": "True if given trees share the same structure of powernodes and same topology between powernodes and powernodes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_from_tree(root:str, graph:dict) -> frozenset:\n    Node = namedtuple('Node', 'id succs')\n    succs = graph[root]\n    if succs:\n        return (len(succs), sorted(tuple(set_from_tree(succ, graph) for succ in succs)))\n    else:\n        return 0, ()", "response": "Return a recursive structure describing given tree"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_suitable_vis_list_classes(objs):\n\n    from f311 import explorer as ex\n\n    ret = []\n    for class_ in classes_vis():\n        if isinstance(class_, ex.VisList):\n            flag_can = True\n            for obj in objs:\n                if not isinstance(obj, class_.item_input_classes):\n                    flag_can = False\n                    break\n            if flag_can:\n                ret.append(class_)\n    return ret", "response": "Retuns a list of VisList classes that can handle a list of objects."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _collect_classes(m):\n    from f311 import filetypes as ft\n    from f311 import explorer as ex\n\n    def _extend(classes, newclasses):\n        \"\"\"Filters out classes already present in list.\n\n        This shouldn't be necessary, but collaborators may accidentally import already loaded\n        classes into the datatypes namespace\"\"\"\n        classes.extend([class_ for class_ in newclasses if class_ not in classes])\n        # classes.extend(newclasses)\n\n    file_classes = [class_ for class_ in a99.get_classes_in_module(m, ft.DataFile) if class_.flag_collect]\n\n    # Classes to consider when attempts to load a text file (see load_any_file())\n    _extend(_classes_txt, [class_ for class_ in file_classes if class_.flag_txt])\n\n    # Classes to consider when attempts to load a binary file (see load_any_file())\n    _extend(_classes_bin, [class_ for class_ in file_classes if not class_.flag_txt])\n    # Adds Classes to consider when attempts to load a spectrum file (see load_spectrum())\n    _extend(_classes_sp, [class_ for class_ in file_classes if issubclass(class_, ft.FileSpectrum)])\n    # All kwown File* classes\n    _extend(_classes_file, file_classes)\n    # All kwnown Vis* classes\n\n    _extend(_classes_vis, a99.get_classes_in_module(m, ex.Vis))\n\n    global _classes_file_superclass\n    _classes_file_superclass = [cls.__bases__[0] for cls in _classes_file]", "response": "Collect all classes in a module into a single base - class list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __setup():\n    global __collaborators, __flag_first\n\n    import f311\n\n    __flag_first = False\n    for pkgname in f311.COLLABORATORS_C:\n        try:\n            pkg = importlib.import_module(pkgname)\n            a99.get_python_logger().info(\"Imported collaborator package '{}'\".format(pkgname))\n\n            try:\n                if hasattr(pkg, \"_setup_filetypes\"):\n                    pkg._setup_filetypes()\n                else:\n                    _collect_classes(pkg)\n\n                __collaborators[pkgname] = pkg\n            except:\n                a99.get_python_logger().exception(\n                    \"Actually, package '{}' gave error\".format(pkgname))\n                raise\n        except:\n            a99.get_python_logger().warning(\"Failed to import package '{}\".format(pkgname))", "response": "Will be executed in the first time someone calls classes_*"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild and returns programs dictionary", "response": "def _get_programs_dict():\n    \"\"\"\n    Builds and returns programs dictionary\n\n    This will have to import the packages in COLLABORATORS_S in order to get their absolute path.\n\n    Returns:\n        dictionary: {\"packagename\": [ExeInfo0, ...], ...}\n\n    \"packagename\" examples: \"f311.explorer\", \"numpy\"\n    \"\"\"\n    global __programs_dict\n\n    if __programs_dict is not None:\n        return __programs_dict\n\n    d = __programs_dict = OrderedDict()\n\n    for pkgname in COLLABORATORS_S:\n        try:\n            package = importlib.import_module(pkgname)\n        except ImportError:\n            # I think it is better to be silent when a collaborator package is not installed\n            continue\n\n        path_ = os.path.join(os.path.split(package.__file__)[0], \"scripts\")\n        bulk = a99.get_exe_info(path_, flag_protected=True)\n        d[pkgname] = {\"description\": a99.get_obj_doc0(package), \"exeinfo\": bulk}\n\n    return __programs_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_programs_dict(pkgname_only=None, flag_protected=False):\n\n    ___ret = _get_programs_dict()\n    __ret = ___ret if pkgname_only is None else OrderedDict(((pkgname_only, ___ret[pkgname_only]),))\n    if flag_protected:\n        _ret = __ret\n    else:\n        _ret = copy.deepcopy(__ret)\n        for value in _ret.values():\n            value[\"exeinfo\"] = [exeinfo for exeinfo in value[\"exeinfo\"] if not exeinfo.filename.startswith(\"_\")]\n\n    # Removes packages that may have gone out of scripts after filtering\n    ret = _ret if pkgname_only is None and flag_protected is None else \\\n        OrderedDict(((key, value) for key, value in _ret.items() if len(value[\"exeinfo\"]) > 0))\n\n    return ret", "response": "Returns a dictionary of all the programs in the COLLABORATORS_S package."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntransforms a grammar to Chomsky Normal Form.", "response": "def transform_to_chomsky_normal_form(grammar, inplace=False):\n    # type: (Grammar, bool) -> Grammar\n    \"\"\"\n    Transform grammar to Chomsky Normal Form.\n    :param grammar: Grammar to transform.\n    :param inplace: True if transformation should be performed in place. False by default.\n    :return: Grammar in Chomsky Normal Form.\n    \"\"\"\n    # Copy if required\n    if inplace is False:\n        grammar = copy(grammar)\n    # Create nonterminals rewritable to the terminal.\n    # They will be inserted into the grammar as needed.\n    fill = TerminalsFilling(grammar)\n    to_process = Queue()\n    for r in grammar.rules:\n        to_process.put(r)\n    while not to_process.empty():\n        rule = to_process.get()  # type: Type[Rule]\n        # Check, if rule must be split\n        if len(rule.right) > 2:\n            grammar.rules.remove(rule)\n            # create nonterm that represent group on the right\n            created_nonterm = type(\"ChomskyGroup[\" + rule.__name__ + \"]\",\n                                   (ChomskyGroupNonterminal,),\n                                   ChomskyGroupNonterminal.__dict__.copy())  # type: Type[ChomskyGroupNonterminal]\n            created_nonterm.group = rule.right[1:]\n            # create rule that replace current\n            created_left_rule = type(\"ChomskySplit[\" + rule.__name__ + \"]\",\n                                     (ChomskySplitRule,),\n                                     ChomskySplitRule.__dict__.copy())  # type: Type[ChomskySplitRule]\n            created_left_rule.rule = ([rule.fromSymbol], [rule.right[0], created_nonterm])\n            created_left_rule.from_rule = rule\n            # create rule with symbols on the right\n            created_right_rule = type(\"ChomskyRest[\" + rule.__name__ + \"]\",\n                                      (ChomskyRestRule,),\n                                      ChomskyRestRule.__dict__.copy())  # type: Type[ChomskyRestRule]\n            created_right_rule.rule = ([created_nonterm], rule.right[1:])\n            created_right_rule.from_rule = rule\n            # add it to the grammar\n            grammar.nonterminals.add(created_nonterm)\n            grammar.rules.add(created_left_rule, created_right_rule)\n            to_process.put(created_left_rule)\n            to_process.put(created_right_rule)\n        # check, if must replace terminal\n        elif len(rule.right) == 2:\n            if rule.right[0] in grammar.terminals:\n                # first symbol is terminal\n                # remove rule from grammar\n                grammar.rules.remove(rule)\n                # get nonterminal rewritable to the terminal and add that rules into the grammar implicitly\n                symb = fill.get(rule.right[0])\n                # create rule replacing the original one\n                created = type(\"ChomskyLeft[\" + rule.__name__ + \"]\",\n                               (ChomskyTerminalReplaceRule,),\n                               ChomskyTerminalReplaceRule.__dict__.copy())  # type: Type[ChomskyTerminalReplaceRule]\n                created.rule = ([rule.fromSymbol], [symb, rule.right[1]])\n                created.from_rule = rule\n                created.replaced_index = 0\n                # add it into the grammar\n                grammar.rules.add(created)\n                to_process.put(created)\n            elif rule.right[1] in grammar.terminals:\n                # second symbol is terminal\n                # remove rule from grammar\n                grammar.rules.remove(rule)\n                # get nonterminal rewritable to the terminal and add that rules into the grammar implicitly\n                symb = fill.get(rule.right[1])\n                # create rule replacing the original one\n                created = type(\"ChomskyRight[\" + rule.__name__ + \"]\",\n                               (ChomskyTerminalReplaceRule,),\n                               ChomskyTerminalReplaceRule.__dict__.copy())\n                created.rule = ([rule.fromSymbol], [rule.right[0], symb])\n                created.from_rule = rule\n                created.replaced_index = 1\n                # add it into the grammar\n                grammar.rules.add(created)\n                to_process.put(created)\n    return grammar"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the ChomskyTermNonterminal class for the given term.", "response": "def get(self, term):\n        # type: (Any) -> Type[ChomskyTermNonterminal]\n        \"\"\"\n        Get nonterminal rewritable to term.\n        If the rules is not in the grammar, nonterminal and rule rewritable to terminal are add into grammar.\n        :param term: Term for which get the nonterminal.\n        :return: ChomskyTermNonterminal class for terminal.\n        \"\"\"\n        if self._items[term].used is False:\n            cont = self._items[term]\n            self._grammar.nonterminals.add(cont.nonterminal)\n            self._grammar.rules.add(cont.rule)\n            cont.used = True\n        return self._items[term].nonterminal"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_url(*args, **kwargs) -> str:\n    resource_url = API_RESOURCES_URLS\n    for key in args:\n        resource_url = resource_url[key]\n\n    if kwargs:\n        resource_url = resource_url.format(**kwargs)\n\n    return urljoin(URL, resource_url)", "response": "Build a valid url."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmake a GET call.", "response": "def _get(url:str, headers:dict) -> dict:\n    \"\"\"\n    Make a GET call.\n    \"\"\"\n    response = requests.get(url, headers=headers)\n\n    data = response.json()\n    if response.status_code != 200:\n        raise GoogleApiError({\"status_code\": response.status_code,\n                                  \"error\": data.get(\"error\", \"\")})\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a POST call.", "response": "def _post(url:str, params:dict, headers:dict) -> dict:\n    \"\"\"\n    Make a POST call.\n    \"\"\"\n    response = requests.post(url, params=params, headers=headers)\n    data = response.json()\n    if response.status_code != 200 or \"error\" in data:\n        raise GoogleApiError({\"status_code\": response.status_code,\n                                  \"error\": data.get(\"error\", \"\")})\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef login(access_code:str, client_id:str=CLIENT_ID, client_secret:str=CLIENT_SECRET,\n          headers:dict=HEADERS, redirect_uri:str=REDIRECT_URI):\n    \"\"\"\n    Get access_token fron an user authorized code, the client id and the client secret key.\n    (See https://developer.google.com/v3/oauth/#web-application-flow).\n    \"\"\"\n    if not CLIENT_ID or not CLIENT_SECRET:\n        raise GoogleApiError({\"error_message\": _(\"Login with google account is disabled. Contact \"\n                                                     \"with the sysadmins. Maybe they're snoozing in a \"\n                                                     \"secret hideout of the data center.\")})\n\n    url = _build_url(\"login\", \"access-token\")\n    params={\"code\": access_code,\n            \"client_id\": client_id,\n            \"client_secret\": client_secret,\n            \"grant_type\": \"authorization_code\",\n            \"redirect_uri\": redirect_uri}\n    data = _post(url, params=params, headers=headers)\n    return AuthInfo(access_token=data.get(\"access_token\", None))", "response": "Get access_token fron an user authorized code, the client id and the client secret key.\n    (See https://developer.google.com/v3/oauth/#web-application-flow)."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget authenticated user info.", "response": "def get_user_profile(headers:dict=HEADERS):\n    \"\"\"\n    Get authenticated user info.\n    (See https://developer.google.com/v3/users/#get-the-authenticated-user).\n    \"\"\"\n    url = _build_url(\"user\", \"profile\")\n    data = _get(url, headers=headers)\n    return User(id=data.get(\"id\", None),\n                username=data.get(\"name\", None).get(\"givenName\", None) + data.get(\"name\", None).get(\"familyName\", None),\n                full_name=(data.get(\"displayName\", None) or \"\"),\n                email=(data.get(\"emails\", None)[0].get(\"value\", None) or \"\"),\n\t\tbio=(data.get(\"bio\", None) or \"\"))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a list with all emails of the authenticated user.", "response": "def get_user_emails(headers:dict=HEADERS) -> list:\n    \"\"\"\n    Get a list with all emails of the authenticated user.\n    (See https://developer.google.com/v3/users/emails/#list-email-addresses-for-a-user).\n    \"\"\"\n    url = _build_url(\"user\", \"emails\")\n    data = _get(url, headers=headers)\n    return [Email(email=e.get(\"email\", None), is_primary=e.get(\"primary\", False))\n                    for e in data]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef me(access_code:str) -> tuple:\n    auth_info = login(access_code)\n\n    headers = HEADERS.copy()\n    headers[\"Authorization\"] = \"Bearer {}\".format(auth_info.access_token)\n\n    user = get_user_profile(headers=headers)\n    # emails = get_user_emails(headers=headers)\n\n    # primary_email = next(filter(lambda x: x.is_primary, emails))\n    # return primary_email.email, user\n    return user", "response": "Connect to Google account and get all personal info."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef controls(self, move):\n    '''Returns a set of attacked/defended squares'''\n    to_move = self.board.turn\n    analysis_board = chess.Board(self.board.fen())\n    analysis_board.push(move)\n    squares = 0\n    for square in chess.SQUARES:\n      if move.to_square in analysis_board.attackers(to_move, square):\n        squares |= chess.BB_SQUARES[square]\n    return SquareSet(squares)", "response": "Returns a set of attacked and defended squares that are in the board."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the rim is dim", "response": "def dims_knight(self, move):\n    '''Knight on the rim is dim'''\n    if self.board.piece_type_at(move.from_square) == chess.KNIGHT:\n      rim = SquareSet(\n          chess.BB_RANK_1 | \\\n          chess.BB_RANK_8 | \\\n          chess.BB_FILE_A | \\\n          chess.BB_FILE_H)\n      return move.to_square in rim"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate mapping between symbols and rules rewritable to these symbols.", "response": "def _create_mapping(grammar):\n    # type: (Grammar) -> (Dict[int, Set[Type[Rule]]], Dict[int, Set[Type[Rule]]])\n    \"\"\"\n    Create mapping between symbols and rules rewritable to these symbols.\n    :param grammar: Grammar to use.\n    :return: Tuple of two dictionaries.\n    First dictionary maps rule to terminal hash.\n    Second dictionary maps rule to nonterminals hash.\n    \"\"\"\n    termmap = dict()\n    rulemap = dict()\n    for r in grammar.rules:\n        if len(r.right) == 1:\n            # rule to terminal\n            h = hash(r.toSymbol)\n            if h not in termmap:\n                termmap[h] = set()\n            termmap[h].add(r)\n        else:\n            # rule to two nonterms\n            key = hash(tuple(r.right))\n            if key not in rulemap:\n                rulemap[key] = set()\n            rulemap[key].add(r)\n    return (termmap, rulemap)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a CYK algorithm on a Chomsky Normal Form.", "response": "def cyk(grammar, parse_sequence):\n    # type: (Grammar, Iterable[Any]) -> Nonterminal\n    \"\"\"\n    Perform CYK algorithm.\n    :param grammar: Grammar to use in Chomsky Normal Form.\n    :param parse_sequence: Input sequence to parse.\n    :return: Instance of root Nonterminal in parsed tree.\n    \"\"\"\n    # check start symbol\n    if grammar.start is None:\n        raise StartSymbolNotSetException()\n    # create variables\n    parse_sequence = list(parse_sequence)\n    input_length = len(parse_sequence)\n    index = input_length - 1\n    f = Field(input_length)\n    # creating mapping for speedup rules searching\n    (termmap, rulemap) = _create_mapping(grammar)\n    # fill first line with rules directly rewritable to terminal\n    f.fill(termmap, parse_sequence)\n    # fill rest of fields\n    for y in range(1, input_length):\n        for x in range(input_length - y):\n            positions = f.positions(x, y)\n            pairs_of_rules = [(f.rules(pos[0].x, pos[0].y),\n                      f.rules(pos[1].x, pos[1].y))\n                     for pos in positions]\n            rules = set()\n            for pair_of_rule in pairs_of_rules:\n                for (first_rule, second_rule) in _all_combinations(pair_of_rule):\n                    h = hash((first_rule.fromSymbol, second_rule.fromSymbol))\n                    if h in rulemap:\n                        for r in rulemap[h]: # list of rules\n                            rules.add(PlaceItem(r, first_rule, second_rule))\n            f.put(x, y, list(rules))\n    # Check if is start symol on the bottom of field\n    if grammar.start not in [r.fromSymbol for r in f.rules(0, input_length - 1)]:\n        raise NotParsedException()\n    # Find init symbol and rule\n    start = grammar.start()  # type: Nonterminal\n    start_rule = [r for r in f.rules(0, input_length - 1) if grammar.start == r.fromSymbol][0]\n    # Prepare buffer for proccess\n    to_process = list()\n    to_process.append({'n': start, 'r': start_rule})\n    # Prepare tree\n    while len(to_process) > 0:\n        working = to_process.pop()\n        rule_class = working['r']\n        working_nonterm = working['n']  # type: Nonterminal\n        # its middle rule - not rewritable to nonterminal\n        if isinstance(rule_class, PlaceItem):\n            created_rule = rule_class.rule()  # type: Rule\n            working_nonterm._set_to_rule(created_rule)\n            created_rule._from_symbols.append(working_nonterm)\n            for side in rule_class.to_rule:\n                symbol = side.fromSymbol()  # type: Nonterminal\n                symbol._set_from_rule(created_rule)\n                created_rule._to_symbols.append(symbol)\n                to_process.append({'n': symbol, 'r': side})\n        # it is rule rewritable to nonterminal\n        else:\n            created_rule = rule_class()  # type: Rule\n            working_nonterm._set_to_rule(created_rule)\n            created_rule._from_symbols.append(working_nonterm)\n            t = Terminal(parse_sequence[index])\n            index -= 1\n            created_rule._to_symbols.append(t)\n            t._set_from_rule(created_rule)\n    return start"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all the comments (reviews) of a specific internal record or external basket record. :param recID: record id where (internal record IDs > 0) or (external basket record IDs < -100) :param display_order: hh = highest helpful score, review only lh = lowest helpful score, review only hs = highest star score, review only ls = lowest star score, review only od = oldest date nd = newest date :param display_since: all= no filtering by date nd = n days ago nw = n weeks ago nm = n months ago ny = n years ago where n is a single digit integer between 0 and 9 :param nb_per_page: number of results per page :param page: results page :param voted: boolean, active if user voted for a review, see perform_request_vote function :param reported: boolean, active if user reported a certain comment/review, perform_request_report function :param subscribed: int, 1 if user just subscribed to discussion, -1 if unsubscribed :param reviews: boolean, enabled if reviews, disabled for comments :param uid: the id of the user who is reading comments :param can_send_comments: if user can send comment or not :param can_attach_files: if user can attach file to comment or not :param user_is_subscribed_to_discussion: True if user already receives new comments by email :param user_can_unsubscribe_from_discussion: True is user is allowed to unsubscribe from discussion :return html body.", "response": "def perform_request_display_comments_or_remarks(\n        req,\n        recID,\n        display_order='od',\n        display_since='all',\n        nb_per_page=100,\n        page=1,\n        ln=CFG_SITE_LANG,\n        voted=-1,\n        reported=-1,\n        subscribed=0,\n        reviews=0,\n        uid=-1,\n        can_send_comments=False,\n        can_attach_files=False,\n        user_is_subscribed_to_discussion=False,\n        user_can_unsubscribe_from_discussion=False,\n        display_comment_rounds=None):\n    \"\"\"\n    Returns all the comments (reviews) of a specific internal record or external basket record.\n    :param recID:  record id where (internal record IDs > 0) or (external basket record IDs < -100)\n    :param display_order:       hh = highest helpful score, review only\n                                lh = lowest helpful score, review only\n                                hs = highest star score, review only\n                                ls = lowest star score, review only\n                                od = oldest date\n                                nd = newest date\n    :param display_since:       all= no filtering by date\n                                nd = n days ago\n                                nw = n weeks ago\n                                nm = n months ago\n                                ny = n years ago\n                                where n is a single digit integer between 0 and 9\n    :param nb_per_page: number of results per page\n    :param page: results page\n    :param voted: boolean, active if user voted for a review, see perform_request_vote function\n    :param reported: boolean, active if user reported a certain comment/review, perform_request_report function\n    :param subscribed: int, 1 if user just subscribed to discussion, -1 if unsubscribed\n    :param reviews: boolean, enabled if reviews, disabled for comments\n    :param uid: the id of the user who is reading comments\n    :param can_send_comments: if user can send comment or not\n    :param can_attach_files: if user can attach file to comment or not\n    :param user_is_subscribed_to_discussion: True if user already receives new comments by email\n    :param user_can_unsubscribe_from_discussion: True is user is allowed to unsubscribe from discussion\n    :return html body.\n    \"\"\"\n    _ = gettext_set_language(ln)\n\n    warnings = []\n    nb_reviews = 0\n    nb_comments = 0\n\n    # wash arguments\n    recID = wash_url_argument(recID, 'int')\n    ln = wash_language(ln)\n    display_order = wash_url_argument(display_order, 'str')\n    display_since = wash_url_argument(display_since, 'str')\n    nb_per_page = wash_url_argument(nb_per_page, 'int')\n    page = wash_url_argument(page, 'int')\n    voted = wash_url_argument(voted, 'int')\n    reported = wash_url_argument(reported, 'int')\n    reviews = wash_url_argument(reviews, 'int')\n\n    # vital argument check\n    (valid, error_body) = check_recID_is_in_range(recID, warnings, ln)\n    if not(valid):\n        return error_body\n\n    # CERN hack begins: filter out ATLAS comments\n    from invenio.config import CFG_CERN_SITE\n    if CFG_CERN_SITE:\n        restricted_comments_p = False\n        for report_number in get_fieldvalues(recID, '088__a'):\n            if report_number.startswith(\"ATL-\"):\n                restricted_comments_p = True\n                break\n        if restricted_comments_p:\n            err_code, err_msg = acc_authorize_action(\n                uid, 'viewrestrcoll', collection='ATLAS Communications')\n            if err_code:\n                return err_msg\n    # CERN hack ends\n\n    # Query the database and filter results\n    user_info = UserInfo(uid)\n    res = query_retrieve_comments_or_remarks(\n        recID,\n        display_order,\n        display_since,\n        reviews,\n        user_info=user_info)\n    # res2 = query_retrieve_comments_or_remarks(recID, display_order, display_since, not reviews, user_info=user_info)\n    nb_res = len(res)\n\n    filters = [\n        CmtRECORDCOMMENT.id_bibrec == recID,\n        CmtRECORDCOMMENT.status.notin_(['dm', 'da'])\n    ]\n\n    nb_reviews = CmtRECORDCOMMENT.count(*(\n        filters + [\n            CmtRECORDCOMMENT.star_score > 0\n        ]\n    ))\n\n    nb_comments = CmtRECORDCOMMENT.count(*(\n        filters + [\n            CmtRECORDCOMMENT.star_score == 0\n        ]\n    ))\n\n    # checking non vital arguemnts - will be set to default if wrong\n    # if page <= 0 or page.lower() != 'all':\n    if page < 0:\n        page = 1\n        try:\n            raise InvenioWebCommentWarning(\n                _('Bad page number --> showing first page.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, ''))\n        # warnings.append(('WRN_WEBCOMMENT_INVALID_PAGE_NB',))\n    if nb_per_page < 0:\n        nb_per_page = 100\n        try:\n            raise InvenioWebCommentWarning(\n                _('Bad number of results per page --> showing 10 results per page.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, ''))\n        # warnings.append(('WRN_WEBCOMMENT_INVALID_NB_RESULTS_PER_PAGE',))\n    if CFG_WEBCOMMENT_ALLOW_REVIEWS and reviews:\n        if display_order not in ['od', 'nd', 'hh', 'lh', 'hs', 'ls']:\n            display_order = 'hh'\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Bad display order --> showing most helpful first.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, ''))\n            # warnings.append(('WRN_WEBCOMMENT_INVALID_REVIEW_DISPLAY_ORDER',))\n    else:\n        if display_order not in ['od', 'nd']:\n            display_order = 'od'\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Bad display order --> showing oldest first.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, ''))\n            # warnings.append(('WRN_WEBCOMMENT_INVALID_DISPLAY_ORDER',))\n\n    if not display_comment_rounds:\n        display_comment_rounds = []\n\n    # filter results according to page and number of reults per page\n    if nb_per_page > 0:\n        if nb_res > 0:\n            last_page = int(math.ceil(nb_res / float(nb_per_page)))\n        else:\n            last_page = 1\n        if page > last_page:\n            page = 1\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Bad page number --> showing first page.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, ''))\n            # warnings.append((\"WRN_WEBCOMMENT_INVALID_PAGE_NB\",))\n        if nb_res > nb_per_page:  # if more than one page of results\n            if page < last_page:\n                res = res[(page - 1) * (nb_per_page): (page * nb_per_page)]\n            else:\n                res = res[(page - 1) * (nb_per_page):]\n        else:  # one page of results\n            pass\n    else:\n        last_page = 1\n\n    # Add information regarding visibility of comment for user\n    user_collapsed_comments = get_user_collapsed_comments_for_record(\n        uid,\n        recID)\n    if reviews:\n        res = [row[:] + (row[10] in user_collapsed_comments,) for row in res]\n    else:\n        res = [row[:] + (row[6] in user_collapsed_comments,) for row in res]\n\n    # Send to template\n    avg_score = 0.0\n    # comments not allowed by admin\n    if not CFG_WEBCOMMENT_ALLOW_COMMENTS and not CFG_WEBCOMMENT_ALLOW_REVIEWS:\n        try:\n            raise InvenioWebCommentError(\n                _('Comments on records have been disallowed by the administrator.'))\n        except InvenioWebCommentError as exc:\n            register_exception(req=req)\n            body = webcomment_templates.tmpl_error(exc.message, ln)\n            return body\n       # errors.append(('ERR_WEBCOMMENT_COMMENTS_NOT_ALLOWED',))\n    if reported > 0:\n        try:\n            raise InvenioWebCommentWarning(\n                _('Your feedback has been recorded, many thanks.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, 'green'))\n        # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_RECORDED',))\n    elif reported == 0:\n        try:\n            raise InvenioWebCommentWarning(\n                _('You have already reported an abuse for this comment.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, ''))\n        # warnings.append(('WRN_WEBCOMMENT_ALREADY_REPORTED',))\n    elif reported == -2:\n        try:\n            raise InvenioWebCommentWarning(\n                _('The comment you have reported no longer exists.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, ''))\n        # warnings.append(('WRN_WEBCOMMENT_INVALID_REPORT',))\n    if CFG_WEBCOMMENT_ALLOW_REVIEWS and reviews:\n        avg_score = calculate_avg_score(res)\n        if voted > 0:\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Your feedback has been recorded, many thanks.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, 'green'))\n            # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_RECORDED',))\n        elif voted == 0:\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Sorry, you have already voted. This vote has not been recorded.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, ''))\n            # warnings.append(('WRN_WEBCOMMENT_ALREADY_VOTED',))\n    if subscribed == 1:\n        try:\n            raise InvenioWebCommentWarning(\n                _('You have been subscribed to this discussion. From now on, you will receive an email whenever a new comment is posted.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, 'green'))\n        # warnings.append(('WRN_WEBCOMMENT_SUBSCRIBED',))\n    elif subscribed == -1:\n        try:\n            raise InvenioWebCommentWarning(\n                _('You have been unsubscribed from this discussion.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, 'green'))\n        # warnings.append(('WRN_WEBCOMMENT_UNSUBSCRIBED',))\n\n    grouped_comments = group_comments_by_round(res, reviews)\n\n    # Clean list of comments round names\n    if not display_comment_rounds:\n        display_comment_rounds = []\n    elif 'all' in display_comment_rounds:\n        display_comment_rounds = [cmtgrp[0] for cmtgrp in grouped_comments]\n    elif 'latest' in display_comment_rounds:\n        if grouped_comments:\n            display_comment_rounds.append(grouped_comments[-1][0])\n        display_comment_rounds.remove('latest')\n\n    body = webcomment_templates.tmpl_get_comments(\n        req,\n        recID,\n        ln,\n        nb_per_page,\n        page,\n        last_page,\n        display_order,\n        display_since,\n        CFG_WEBCOMMENT_ALLOW_REVIEWS,\n        grouped_comments,\n        nb_comments,\n        avg_score,\n        warnings,\n        border=0,\n        reviews=reviews,\n        total_nb_reviews=nb_reviews,\n        uid=uid,\n        can_send_comments=can_send_comments,\n        can_attach_files=can_attach_files,\n        user_is_subscribed_to_discussion=user_is_subscribed_to_discussion,\n        user_can_unsubscribe_from_discussion=user_can_unsubscribe_from_discussion,\n        display_comment_rounds=display_comment_rounds)\n    return body"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef perform_request_vote(cmt_id, client_ip_address, value, uid=-1):\n    cmt_id = wash_url_argument(cmt_id, 'int')\n    client_ip_address = wash_url_argument(client_ip_address, 'str')\n    value = wash_url_argument(value, 'int')\n    uid = wash_url_argument(uid, 'int')\n    if cmt_id > 0 and value in [-1,\n                                1] and check_user_can_vote(cmt_id,\n                                                           client_ip_address,\n                                                           uid):\n        action_date = convert_datestruct_to_datetext(time.localtime())\n        action_code = CFG_WEBCOMMENT_ACTION_CODE['VOTE']\n        # FIXME compatibility with postgresql\n        query = \"\"\"INSERT INTO \"cmtACTIONHISTORY\" (\"id_cmtRECORDCOMMENT\",\n                    id_bibrec, id_user, client_host, action_time,\n                    action_code)\n                   VALUES (%s, NULL ,%s, inet_aton(%s), %s, %s)\"\"\"\n        params = (cmt_id, uid, client_ip_address, action_date, action_code)\n        run_sql(query, params)\n        return query_record_useful_review(cmt_id, value)\n    else:\n        return 0", "response": "Perform a request vote on a specific comment."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a user has already commented in the last seconds.", "response": "def check_user_can_comment(recID, client_ip_address, uid=-1):\n    \"\"\" Check if a user hasn't already commented within the last seconds\n    time limit: CFG_WEBCOMMENT_TIMELIMIT_PROCESSING_COMMENTS_IN_SECONDS\n    :param recID: record id\n    :param client_ip_address: IP => use: str(req.remote_ip)\n    :param uid: user id, as given by invenio.legacy.webuser.getUid(req)\n    \"\"\"\n    recID = wash_url_argument(recID, 'int')\n    client_ip_address = wash_url_argument(client_ip_address, 'str')\n    uid = wash_url_argument(uid, 'int')\n    max_action_time = time.time() - \\\n        CFG_WEBCOMMENT_TIMELIMIT_PROCESSING_COMMENTS_IN_SECONDS\n    max_action_time = convert_datestruct_to_datetext(\n        time.localtime(max_action_time))\n    action_code = CFG_WEBCOMMENT_ACTION_CODE['ADD_COMMENT']\n    query = \"\"\"SELECT id_bibrec\n               FROM \"cmtACTIONHISTORY\"\n               WHERE id_bibrec=%s AND\n                     action_code=%s AND\n                     action_time>%s\n            \"\"\"\n    params = (recID, action_code, max_action_time)\n    if uid < 0:\n        query += \" AND client_host=inet_aton(%s)\"\n        params += (client_ip_address,)\n    else:\n        query += \" AND id_user=%s\"\n        params += (uid,)\n    res = run_sql(query, params)\n    return len(res) == 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_user_can_review(recID, client_ip_address, uid=-1):\n    action_code = CFG_WEBCOMMENT_ACTION_CODE['ADD_REVIEW']\n    query = \"\"\"SELECT id_bibrec\n               FROM \"cmtACTIONHISTORY\"\n               WHERE id_bibrec=%s AND\n                     action_code=%s\n            \"\"\"\n    params = (recID, action_code)\n    if uid < 0:\n        query += \" AND client_host=inet_aton(%s)\"\n        params += (client_ip_address,)\n    else:\n        query += \" AND id_user=%s\"\n        params += (uid,)\n    res = run_sql(query, params)\n    return len(res) == 0", "response": "Check if a user can add a new comment to the record."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if a user has already voted a comment.", "response": "def check_user_can_vote(cmt_id, client_ip_address, uid=-1):\n    \"\"\" Checks if a user hasn't already voted\n    :param cmt_id: comment id\n    :param client_ip_address: IP => use: str(req.remote_ip)\n    :param uid: user id, as given by invenio.legacy.webuser.getUid(req)\n    \"\"\"\n    cmt_id = wash_url_argument(cmt_id, 'int')\n    client_ip_address = wash_url_argument(client_ip_address, 'str')\n    uid = wash_url_argument(uid, 'int')\n    query = \"\"\"SELECT \"id_cmtRECORDCOMMENT\"\n               FROM \"cmtACTIONHISTORY\"\n               WHERE \"id_cmtRECORDCOMMENT\"=%s\"\"\"\n    params = (cmt_id,)\n    if uid < 0:\n        query += \" AND client_host=inet_aton(%s)\"\n        params += (client_ip_address,)\n    else:\n        query += \" AND id_user=%s\"\n        params += (uid, )\n    res = run_sql(query, params)\n    return (len(res) == 0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract the collection where the comment is written", "response": "def get_comment_collection(cmt_id):\n    \"\"\"\n    Extract the collection where the comment is written\n    \"\"\"\n    query = \"\"\"SELECT id_bibrec FROM \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n    recid = run_sql(query, (cmt_id,))\n    record_primary_collection = guess_primary_collection_of_a_record(\n        recid[0][0])\n    return record_primary_collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_collection_moderators(collection):\n    from invenio_access.engine import acc_get_authorized_emails\n\n    res = list(\n        acc_get_authorized_emails(\n            'moderatecomments',\n            collection=collection))\n    if not res:\n        return [CFG_WEBCOMMENT_DEFAULT_MODERATOR, ]\n    return res", "response": "Return the list of comment moderators for the given collection."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a report request for a comment.", "response": "def perform_request_report(cmt_id, client_ip_address, uid=-1):\n    \"\"\"\n    Report a comment/review for inappropriate content.\n\n    Will send an email to the administrator if number of reports is a multiple\n    of CFG_WEBCOMMENT_NB_REPORTS_BEFORE_SEND_EMAIL_TO_ADMIN\n\n    :param cmt_id: comment id\n    :return: integer 1 if successful, integer 0 if not. -2 if comment does not exist\n    \"\"\"\n    cmt_id = wash_url_argument(cmt_id, 'int')\n    if cmt_id <= 0:\n        return 0\n    (query_res, nb_abuse_reports) = query_record_report_this(cmt_id)\n    if query_res == 0:\n        return 0\n    elif query_res == -2:\n        return -2\n    if not(check_user_can_report(cmt_id, client_ip_address, uid)):\n        return 0\n    action_date = convert_datestruct_to_datetext(time.localtime())\n    action_code = CFG_WEBCOMMENT_ACTION_CODE['REPORT_ABUSE']\n    query = \"\"\"INSERT INTO \"cmtACTIONHISTORY\" (\"id_cmtRECORDCOMMENT\", id_bibrec,\n                  id_user, client_host, action_time, action_code)\n               VALUES (%s, NULL, %s, inet_aton(%s), %s, %s)\"\"\"\n    params = (cmt_id, uid, client_ip_address, action_date, action_code)\n    run_sql(query, params)\n    if nb_abuse_reports % CFG_WEBCOMMENT_NB_REPORTS_BEFORE_SEND_EMAIL_TO_ADMIN == 0:\n        (cmt_id2,\n         id_bibrec,\n         id_user,\n         cmt_body,\n         cmt_date,\n         cmt_star,\n         cmt_vote, cmt_nb_votes_total,\n         cmt_title,\n         cmt_reported,\n         round_name,\n         restriction) = query_get_comment(cmt_id)\n        (user_nb_abuse_reports,\n         user_votes,\n         user_nb_votes_total) = query_get_user_reports_and_votes(int(id_user))\n        (nickname,\n         user_email,\n         last_login) = query_get_user_contact_info(id_user)\n        from_addr = '%s Alert Engine <%s>' % (\n            CFG_SITE_NAME, CFG_WEBALERT_ALERT_ENGINE_EMAIL)\n        comment_collection = get_comment_collection(cmt_id)\n        to_addrs = get_collection_moderators(comment_collection)\n        subject = \"A comment has been reported as inappropriate by a user\"\n        body = '''\nThe following comment has been reported a total of %(cmt_reported)s times.\n\nAuthor:     nickname    = %(nickname)s\n            email       = %(user_email)s\n            user_id     = %(uid)s\n            This user has:\n                total number of reports         = %(user_nb_abuse_reports)s\n                %(votes)s\nComment:    comment_id      = %(cmt_id)s\n            record_id       = %(id_bibrec)s\n            date written    = %(cmt_date)s\n            nb reports      = %(cmt_reported)s\n            %(review_stuff)s\n            body            =\n---start body---\n%(cmt_body)s\n---end body---\n\nPlease go to the record page %(comment_admin_link)s to delete this message if necessary. A warning will be sent to the user in question.''' % \\\n            {'cfg-report_max': CFG_WEBCOMMENT_NB_REPORTS_BEFORE_SEND_EMAIL_TO_ADMIN,\n             'nickname': nickname,\n             'user_email': user_email,\n             'uid': id_user,\n             'user_nb_abuse_reports': user_nb_abuse_reports,\n             'user_votes': user_votes,\n             'votes': CFG_WEBCOMMENT_ALLOW_REVIEWS and\n             \"total number of positive votes\\t= %s\\n\\t\\ttotal number of negative votes\\t= %s\" %\n             (user_votes,\n              (user_nb_votes_total - user_votes)) or \"\\n\",\n                'cmt_id': cmt_id,\n                'id_bibrec': id_bibrec,\n                'cmt_date': cmt_date,\n             'cmt_reported': cmt_reported,\n             'review_stuff': CFG_WEBCOMMENT_ALLOW_REVIEWS and\n             \"star score\\t= %s\\n\\treview title\\t= %s\" % (\n                 cmt_star,\n                 cmt_title) or \"\",\n                'cmt_body': cmt_body,\n             'comment_admin_link': CFG_SITE_URL + \"/\" + CFG_SITE_RECORD + \"/\" + str(id_bibrec) + '/comments#' + str(cmt_id),\n             'user_admin_link': \"user_admin_link\"  # ! FIXME\n             }\n\n        # FIXME to be added to email when websession module is over:\n        # If you wish to ban the user, you can do so via the User Admin Panel\n        # %(user_admin_link)s.\n\n        send_email(from_addr, to_addrs, subject, body)\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef query_get_user_contact_info(uid):\n    # FIXME compatibility with postgresql\n    query1 = \"\"\"SELECT nickname, email,\n                       \"\"\" + \\\n        datetime_format('last_login') + \\\n        \"\"\"\n                     FROM \"user\" WHERE id=%s\"\"\"\n    params1 = (uid,)\n    res1 = run_sql(query1, params1)\n    if res1:\n        return res1[0]\n    else:\n        return ()", "response": "Query the user contact information"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_get_user_reports_and_votes(uid):\n    query1 = \"\"\"SELECT nb_votes_yes,\n                       nb_votes_total,\n                       nb_abuse_reports\n                FROM \"cmtRECORDCOMMENT\"\n                WHERE id_user=%s\"\"\"\n    params1 = (uid,)\n    res1 = run_sql(query1, params1)\n    if len(res1) == 0:\n        return ()\n    nb_votes_yes = nb_votes_total = nb_abuse_reports = 0\n    for cmt_tuple in res1:\n        nb_votes_yes += int(cmt_tuple[0])\n        nb_votes_total += int(cmt_tuple[1])\n        nb_abuse_reports += int(cmt_tuple[2])\n    return (nb_abuse_reports, nb_votes_yes, nb_votes_total)", "response": "Query the user reports and votes of a particular user."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_get_comment(comID):\n    query1 = \"\"\"SELECT id,\n                       id_bibrec,\n                       id_user,\n                       body,\n                       \"\"\" + \\\n        datetime_format('date_creation') + ', ' \\\n        \"\"\"\n                       star_score,\n                       nb_votes_yes,\n                       nb_votes_total,\n                       title,\n                       nb_abuse_reports,\n                       round_name,\n                       restriction\n                FROM \"cmtRECORDCOMMENT\"\n                WHERE id=%s\"\"\"\n    params1 = (comID,)\n    res1 = run_sql(query1, params1)\n    if len(res1) > 0:\n        return res1[0]\n    else:\n        return ()", "response": "Query the comment record for a given comment id."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nquery the record_report_this function for a comment.", "response": "def query_record_report_this(comID):\n    \"\"\"\n    Increment the number of reports for a comment\n    :param comID: comment id\n    :return: tuple (success, new_total_nb_reports_for_this_comment) where\n    success is integer 1 if success, integer 0 if not, -2 if comment does not exist\n    \"\"\"\n    # retrieve nb_abuse_reports\n    query1 = \"\"\"SELECT nb_abuse_reports FROM \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n    params1 = (comID,)\n    res1 = run_sql(query1, params1)\n    if len(res1) == 0:\n        return (-2, 0)\n\n    #increment and update\n    nb_abuse_reports = int(res1[0][0]) + 1\n    query2 = \"\"\"UPDATE \"cmtRECORDCOMMENT\" SET nb_abuse_reports=%s WHERE id=%s\"\"\"\n    params2 = (nb_abuse_reports, comID)\n    res2 = run_sql(query2, params2)\n    return (int(res2), nb_abuse_reports)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_record_useful_review(comID, value):\n    # retrieve nb_useful votes\n    query1 = \"\"\"SELECT nb_votes_total, nb_votes_yes FROM \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n    params1 = (comID,)\n    res1 = run_sql(query1, params1)\n    if len(res1) == 0:\n        return 0\n\n    # modify and insert new nb_useful votes\n    nb_votes_yes = int(res1[0][1])\n    if value >= 1:\n        nb_votes_yes = int(res1[0][1]) + 1\n    nb_votes_total = int(res1[0][0]) + 1\n    query2 = \"\"\"UPDATE \"cmtRECORDCOMMENT\" SET nb_votes_total=%s, nb_votes_yes=%s WHERE id=%s\"\"\"\n    params2 = (nb_votes_total, nb_votes_yes, comID)\n    res2 = run_sql(query2, params2)\n    return int(res2)", "response": "query_record_useful_review - Query the record of a useful review for a comment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_retrieve_comments_or_remarks(\n        recID,\n        display_order='od',\n        display_since='0000-00-00 00:00:00',\n        ranking=0,\n        limit='all',\n        user_info=None):\n    \"\"\"\n    Private function\n    Retrieve tuple of comments or remarks from the database\n    :param recID: record id\n    :param display_order:   hh = highest helpful score\n                            lh = lowest helpful score\n                            hs = highest star score\n                            ls = lowest star score\n                            od = oldest date\n                            nd = newest date\n    :param display_since: datetime, e.g. 0000-00-00 00:00:00\n    :param ranking: boolean, enabled if reviews, disabled for comments\n    :param limit: number of comments/review to return\n    :return: tuple of comment where comment is\n            tuple (nickname, uid, date_creation, body, status, id) if ranking disabled or\n            tuple (nickname, uid, date_creation, body, status, nb_votes_yes, nb_votes_total, star_score, title, id)\n    Note: for the moment, if no nickname, will return email address up to ':'\n    \"\"\"\n    display_since = calculate_start_date(display_since)\n\n    order_dict = {\n        'hh': \"cmt.nb_votes_yes/(cmt.nb_votes_total+1) DESC, cmt.date_creation DESC \",\n        'lh': \"cmt.nb_votes_yes/(cmt.nb_votes_total+1) ASC, cmt.date_creation ASC \",\n        'ls': \"cmt.star_score ASC, cmt.date_creation DESC \",\n        'hs': \"cmt.star_score DESC, cmt.date_creation DESC \",\n        'nd': \"cmt.reply_order_cached_data DESC \",\n        'od': \"cmt.reply_order_cached_data ASC \"}\n\n    # Ranking only done for comments and when allowed\n    if ranking and recID > 0:\n        try:\n            display_order = order_dict[display_order]\n        except:\n            display_order = order_dict['od']\n    else:\n        # in case of recID > 0 => external record => no ranking!\n        ranking = 0\n    try:\n        if display_order[-1] == 'd':\n            display_order = order_dict[display_order]\n        else:\n            display_order = order_dict['od']\n    except:\n        display_order = order_dict['od']\n\n    #display_order = order_dict['nd']\n    query = \"\"\"SELECT user.nickname,\n                      cmt.id_user,\n                       \"\"\" + \\\n        datetime_format('cmt.date_creation', False, True) + ', ' \\\n        \"\"\"\n                      cmt.body,\n                      cmt.status,\n                      cmt.nb_abuse_reports,\n                      %(ranking)s cmt.id,\n                      cmt.round_name,\n                      cmt.restriction,\n                      %(reply_to_column)s\n               FROM   \"cmtRECORDCOMMENT\" cmt LEFT JOIN \"user\" ON\n                                              \"user\".id=cmt.id_user\n               WHERE cmt.id_bibrec=%%s\n               %(ranking_only)s\n               %(display_since)s\n               ORDER BY %(display_order)s\n               \"\"\" % {'ranking'       : ranking and ' cmt.nb_votes_yes, cmt.nb_votes_total, cmt.star_score, cmt.title, ' or '',\n                      'ranking_only': ranking and ' AND cmt.star_score>0 ' or ' AND cmt.star_score=0 ',\n                      #                      'id_bibrec'     : recID > 0 and 'cmt.id_bibrec' or 'cmt.id_bibrec_or_bskEXTREC',\n                      #                      'table'         : recID > 0 and 'cmtRECORDCOMMENT' or 'bskRECORDCOMMENT',\n                      'display_since': display_since == '0000-00-00 00:00:00' and ' ' or 'AND cmt.date_creation>=\\'%s\\' ' % display_since,\n                      'display_order': display_order,\n                      'reply_to_column': recID > 0 and 'cmt.\"in_reply_to_id_cmtRECORDCOMMENT\"' or 'cmt.\"in_reply_to_id_bskRECORDCOMMENT\"'}\n    params = (recID,)\n    res = run_sql(query, params)\n#    return res\n\n    new_limit = limit\n    comments_list = []\n    for row in res:\n        if ranking:\n            # when dealing with reviews, row[12] holds restriction info:\n            restriction = row[12]\n        else:\n            # when dealing with comments, row[8] holds restriction info:\n            restriction = row[8]\n        if user_info and check_user_can_view_comment(\n                user_info, None, restriction)[0] != 0:\n            # User cannot view comment. Look further\n            continue\n        comments_list.append(row)\n        if limit.isdigit():\n            new_limit -= 1\n            if limit < 1:\n                break\n\n    if comments_list:\n        if limit.isdigit():\n            return comments_list[:limit]\n        else:\n            return comments_list\n    return ()", "response": "Private function to retrieve comments or remarks from the database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the list of ancestors of the given comment.", "response": "def get_comment_ancestors(comID, depth=None):\n    \"\"\"\n    Returns the list of ancestors of the given comment, ordered from\n    oldest to newest (\"top-down\": direct parent of comID is at last position),\n    up to given depth\n\n    :param comID: the ID of the comment for which we want to retrieve ancestors\n    :type comID: int\n    :param depth: the maximum of levels up from the given comment we\n                  want to retrieve ancestors. None for no limit, 1 for\n                  direct parent only, etc.\n    :type depth: int\n    :return the list of ancestors\n    :rtype: list\n    \"\"\"\n    if depth == 0:\n        return []\n\n    res = run_sql(\n        \"\"\"SELECT \"in_reply_to_id_cmtRECORDCOMMENT\" FROM \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\",\n        (comID,\n         ))\n    if res:\n        parent_comID = res[0][0]\n        if parent_comID == 0:\n            return []\n        parent_ancestors = []\n        if depth:\n            depth -= 1\n        parent_ancestors = get_comment_ancestors(parent_comID, depth)\n        parent_ancestors.append(parent_comID)\n        return parent_ancestors\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares a representation of the comment ID given as parameter so that it is suitable for byte ordering in MySQL.", "response": "def get_reply_order_cache_data(comid):\n    \"\"\"\n    Prepare a representation of the comment ID given as parameter so\n    that it is suitable for byte ordering in MySQL.\n    \"\"\"\n    return \"%s%s%s%s\" % (chr((comid >> 24) % 256), chr((comid >> 16) % 256),\n                         chr((comid >> 8) % 256), chr(comid % 256))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef query_add_comment_or_remark(reviews=0, recID=0, uid=-1, msg=\"\",\n                                note=\"\", score=0, priority=0,\n                                client_ip_address='', editor_type='textarea',\n                                req=None, reply_to=None, attached_files=None):\n    \"\"\"\n    Private function\n    Insert a comment/review or remarkinto the database\n    :param recID: record id\n    :param uid: user id\n    :param msg: comment body\n    :param note: comment title\n    :param score: review star score\n    :param priority: remark priority #!FIXME\n    :param editor_type: the kind of editor used to submit the comment: 'textarea', 'ckeditor'\n    :param req: request object. If provided, email notification are sent after we reply to user request.\n    :param reply_to: the id of the comment we are replying to with this inserted comment.\n    :return: integer >0 representing id if successful, integer 0 if not\n    \"\"\"\n    current_date = calculate_start_date('0d')\n    # change utf-8 message into general unicode\n    msg = msg.decode('utf-8')\n    note = note.decode('utf-8')\n    # change general unicode back to utf-8\n    msg = msg.encode('utf-8')\n    note = note.encode('utf-8')\n    (restriction, round_name) = get_record_status(recID)\n    if attached_files is None:\n        attached_files = {}\n    if reply_to and CFG_WEBCOMMENT_MAX_COMMENT_THREAD_DEPTH >= 0:\n        # Check that we have not reached max depth\n        comment_ancestors = get_comment_ancestors(reply_to)\n        if len(comment_ancestors) >= CFG_WEBCOMMENT_MAX_COMMENT_THREAD_DEPTH:\n            if CFG_WEBCOMMENT_MAX_COMMENT_THREAD_DEPTH == 0:\n                reply_to = None\n            else:\n                reply_to = comment_ancestors[\n                    CFG_WEBCOMMENT_MAX_COMMENT_THREAD_DEPTH -\n                    1]\n        # Inherit restriction and group/round of 'parent'\n        comment = query_get_comment(reply_to)\n        if comment:\n            (round_name, restriction) = comment[10:12]\n    if editor_type == 'ckeditor':\n        # Here we remove the line feeds introduced by CKEditor (they\n        # have no meaning for the user) and replace the HTML line\n        # breaks by linefeeds, so that we are close to an input that\n        # would be done without the CKEditor. That's much better if a\n        # reply to a comment is made with a browser that does not\n        # support CKEditor.\n        msg = msg.replace('\\n', '').replace('\\r', '')\n\n        # We clean the quotes that could have been introduced by\n        # CKEditor when clicking the 'quote' button, as well as those\n        # that we have introduced when quoting the original message.\n        # We can however not use directly '>>' chars to quote, as it\n        # will be washed/fixed when calling tidy_html(): double-escape\n        # all &gt; first, and use &gt;&gt;\n        msg = msg.replace('&gt;', '&amp;gt;')\n        msg = re.sub('^\\s*<blockquote', '<br/> <blockquote', msg)\n        msg = re.sub('<blockquote.*?>\\s*<(p|div).*?>', '&gt;&gt;', msg)\n        msg = re.sub('</(p|div)>\\s*</blockquote>', '', msg)\n        # Then definitely remove any blockquote, whatever it is\n        msg = re.sub('<blockquote.*?>', '<div>', msg)\n        msg = re.sub('</blockquote>', '</div>', msg)\n        # Tidy up the HTML\n        msg = tidy_html(msg)\n        # We remove EOL that might have been introduced when tidying\n        msg = msg.replace('\\n', '').replace('\\r', '')\n        # Now that HTML has been cleaned, unescape &gt;\n        msg = msg.replace('&gt;', '>')\n        msg = msg.replace('&amp;gt;', '&gt;')\n        msg = re.sub('<br .*?(/>)', '\\n', msg)\n        msg = msg.replace('&nbsp;', ' ')\n        # In case additional <p> or <div> got inserted, interpret\n        # these as new lines (with a sad trick to do it only once)\n        # (note that it has been deactivated, as it is messing up\n        # indentation with >>)\n        #msg = msg.replace('</div><', '</div>\\n<')\n        #msg = msg.replace('</p><', '</p>\\n<')\n\n    query = \"\"\"INSERT INTO \"cmtRECORDCOMMENT\" (id_bibrec,\n                                           id_user,\n                                           body,\n                                           date_creation,\n                                           star_score,\n                                           nb_votes_total,\n                                           title,\n                                           round_name,\n                                           restriction,\n                                           \"in_reply_to_id_cmtRECORDCOMMENT\")\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\"\"\n    params = (\n        recID,\n        uid,\n        msg,\n        current_date,\n        score,\n        0,\n        note,\n        round_name,\n        restriction,\n        reply_to or 0)\n    res = run_sql(query, params)\n    if res:\n        new_comid = int(res)\n        move_attached_files_to_storage(attached_files, recID, new_comid)\n        parent_reply_order = run_sql(\n            \"\"\"SELECT reply_order_cached_data from \"cmtRECORDCOMMENT\" where id=%s\"\"\",\n            (reply_to,\n             ))\n        if not parent_reply_order or parent_reply_order[0][0] is None:\n            # This is not a reply, but a first 0-level comment\n            parent_reply_order = ''\n        else:\n            parent_reply_order = parent_reply_order[0][0]\n        run_sql(\n            \"\"\"UPDATE \"cmtRECORDCOMMENT\" SET reply_order_cached_data=%s WHERE id=%s\"\"\",\n            (parent_reply_order +\n             get_reply_order_cache_data(new_comid),\n             new_comid))\n        action_code = CFG_WEBCOMMENT_ACTION_CODE[\n            reviews and 'ADD_REVIEW' or 'ADD_COMMENT']\n        action_time = convert_datestruct_to_datetext(time.localtime())\n        query2 = \"\"\"INSERT INTO \"cmtACTIONHISTORY\"  (\"id_cmtRECORDCOMMENT\",\n                     id_bibrec, id_user, client_host, action_time, action_code)\n                    VALUES (%s, %s, %s, inet_aton(%s), %s, %s)\"\"\"\n        params2 = (\n            res,\n            recID,\n            uid,\n            client_ip_address,\n            action_time,\n            action_code)\n        run_sql(query2, params2)\n\n        def notify_subscribers_callback(data):\n            \"\"\"\n            Define a callback that retrieves subscribed users, and\n            notify them by email.\n\n            :param data: contains the necessary parameters in a tuple:\n                         (recid, uid, comid, msg, note, score, editor_type, reviews)\n            \"\"\"\n            recid, uid, comid, msg, note, score, editor_type, reviews = data\n            # Email this comment to 'subscribers'\n            (subscribers_emails1, subscribers_emails2) = \\\n                get_users_subscribed_to_discussion(recid)\n            email_subscribers_about_new_comment(\n                recid,\n                reviews=reviews,\n                emails1=subscribers_emails1,\n                emails2=subscribers_emails2,\n                comID=comid,\n                msg=msg,\n                note=note,\n                score=score,\n                editor_type=editor_type,\n                uid=uid)\n\n        # Register our callback to notify subscribed people after\n        # having replied to our current user.\n        data = (recID, uid, res, msg, note, score, editor_type, reviews)\n        if req:\n            req.register_cleanup(notify_subscribers_callback, data)\n        else:\n            notify_subscribers_callback(data)\n\n    return int(res)", "response": "Private function to insert a comment or remark into the database."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef move_attached_files_to_storage(attached_files, recID, comid):\n    for filename, filepath in iteritems(attached_files):\n        dest_dir = os.path.join(CFG_COMMENTSDIR, str(recID), str(comid))\n        try:\n            os.makedirs(dest_dir)\n        except:\n            # Dir most probably already existed\n            pass\n        shutil.move(filepath,\n                    os.path.join(dest_dir, filename))", "response": "Move the files that were just attached to a new comment to their respective location."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of tuples filename filepath fileurl", "response": "def get_attached_files(recid, comid):\n    \"\"\"\n    Returns a list with tuples (filename, filepath, fileurl)\n\n    :param recid: the recid to which the comment belong\n    :param comid: the commment id for which we want to retrieve files\n    \"\"\"\n    base_dir = os.path.join(CFG_COMMENTSDIR, str(recid), str(comid))\n    if os.path.isdir(base_dir):\n        filenames = os.listdir(base_dir)\n        return [\n            (\n                filename,\n                os.path.join(\n                    CFG_COMMENTSDIR,\n                    str(recid),\n                    str(comid),\n                    filename),\n                CFG_SITE_URL +\n                '/' +\n                CFG_SITE_RECORD +\n                '/' +\n                str(recid) +\n                '/comments/attachments/get/' +\n                str(comid) +\n                '/' +\n                filename) for filename in filenames]\n    else:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef subscribe_user_to_discussion(recID, uid):\n    query = \"\"\"INSERT INTO \"cmtSUBSCRIPTION\" (id_bibrec, id_user, creation_time)\n                    VALUES (%s, %s, %s)\"\"\"\n    params = (recID, uid, convert_datestruct_to_datetext(time.localtime()))\n    try:\n        run_sql(query, params)\n    except:\n        return 0\n    return 1", "response": "Subscribe a user to a discussion."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_user_subscription_to_discussion(recID, uid):\n    user_email = User.query.get(uid).email\n    (emails1, emails2) = get_users_subscribed_to_discussion(\n        recID, check_authorizations=False)\n    if user_email in emails1:\n        return 1\n    elif user_email in emails2:\n        return 2\n    else:\n        return 0", "response": "Returns the type of subscription for the given user to this\n    discussion."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_users_subscribed_to_discussion(recID, check_authorizations=True):\n    subscribers_emails = {}\n\n    # Get users that have subscribed to this discussion\n    query = \"\"\"SELECT id_user FROM \"cmtSUBSCRIPTION\" WHERE id_bibrec=%s\"\"\"\n    params = (recID,)\n    res = run_sql(query, params)\n    for row in res:\n        uid = row[0]\n        if check_authorizations:\n            user_info = UserInfo(uid)\n            (auth_code, auth_msg) = check_user_can_view_comments(\n                user_info, recID)\n        else:\n            # Don't check and grant access\n            auth_code = False\n        if auth_code:\n            # User is no longer authorized to view comments.\n            # Delete subscription\n            unsubscribe_user_from_discussion(recID, uid)\n        else:\n            email = User.query.get(uid).email\n            if '@' in email:\n                subscribers_emails[email] = True\n\n    # Get users automatically subscribed, based on the record metadata\n    collections_with_auto_replies = CFG_WEBCOMMENT_EMAIL_REPLIES_TO.keys()\n    for collection in collections_with_auto_replies:\n        if recID in get_collection_reclist(collection):\n            fields = CFG_WEBCOMMENT_EMAIL_REPLIES_TO[collection]\n            for field in fields:\n                emails = get_fieldvalues(recID, field)\n                for email in emails:\n                    if not '@' in email:\n                        # Is a group: add domain name\n                        subscribers_emails[\n                            email +\n                            '@' +\n                            CFG_SITE_SUPPORT_EMAIL.split('@')[1]] = False\n                    else:\n                        subscribers_emails[email] = False\n\n    return ([email for email, can_unsubscribe_p\n             in iteritems(subscribers_emails) if can_unsubscribe_p],\n            [email for email, can_unsubscribe_p\n             in iteritems(subscribers_emails) if not can_unsubscribe_p])", "response": "Returns the list of users subscribed to a given discussion."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef email_subscribers_about_new_comment(recID, reviews, emails1,\n                                        emails2, comID, msg=\"\",\n                                        note=\"\", score=0,\n                                        editor_type='textarea',\n                                        ln=CFG_SITE_LANG, uid=-1):\n    \"\"\"\n    Notify subscribers that a new comment was posted.\n    FIXME: consider recipient preference to send email in correct language.\n\n    :param recID: record id\n    :param emails1: list of emails for users who can unsubscribe from discussion\n    :param emails2: list of emails for users who cannot unsubscribe from discussion\n    :param comID: the comment id\n    :param msg: comment body\n    :param note: comment title\n    :param score: review star score\n    :param editor_type: the kind of editor used to submit the comment: 'textarea', 'ckeditor'\n    :rtype: bool\n    :return: True if email was sent okay, False if it was not.\n    \"\"\"\n    _ = gettext_set_language(ln)\n\n    if not emails1 and not emails2:\n        return 0\n\n    # Get title\n    titles = get_fieldvalues(recID, \"245__a\")\n    if not titles:\n        # usual title not found, try conference title:\n        titles = get_fieldvalues(recID, \"111__a\")\n\n    title = ''\n    if titles:\n        title = titles[0]\n    else:\n        title = _(\"Record %(x_rec)i\", x_rec=recID)\n\n    # Get report number\n    report_numbers = get_fieldvalues(recID, \"037__a\")\n    if not report_numbers:\n        report_numbers = get_fieldvalues(recID, \"088__a\")\n        if not report_numbers:\n            report_numbers = get_fieldvalues(recID, \"021__a\")\n\n    # Prepare email subject and body\n    if reviews:\n        email_subject = _('%(report_number)s\"%(title)s\" has been reviewed') % {\n            'report_number': report_numbers and (\n                '[' + report_numbers[0] + '] ') or '',\n            'title': title}\n    else:\n        email_subject = _('%(report_number)s\"%(title)s\" has been commented') % {\n            'report_number': report_numbers and (\n                '[' + report_numbers[0] + '] ') or '',\n            'title': title}\n\n    washer = EmailWasher()\n    msg = washer.wash(msg)\n    msg = msg.replace('&gt;&gt;', '>')\n    email_content = msg\n    if note:\n        email_content = note + email_content\n\n    # Send emails to people who can unsubscribe\n    email_header = webcomment_templates.tmpl_email_new_comment_header(\n        recID,\n        title,\n        reviews,\n        comID,\n        report_numbers,\n        can_unsubscribe=True,\n        ln=ln,\n        uid=uid)\n\n    email_footer = webcomment_templates.tmpl_email_new_comment_footer(\n        recID,\n        title,\n        reviews,\n        comID,\n        report_numbers,\n        can_unsubscribe=True,\n        ln=ln)\n    res1 = True\n    if emails1:\n        res1 = send_email(fromaddr=CFG_WEBCOMMENT_ALERT_ENGINE_EMAIL,\n                          toaddr=emails1,\n                          subject=email_subject,\n                          content=email_content,\n                          header=email_header,\n                          footer=email_footer,\n                          ln=ln)\n\n    # Then send email to people who have been automatically\n    # subscribed to the discussion (they cannot unsubscribe)\n    email_header = webcomment_templates.tmpl_email_new_comment_header(\n        recID,\n        title,\n        reviews,\n        comID,\n        report_numbers,\n        can_unsubscribe=False,\n        ln=ln,\n        uid=uid)\n\n    email_footer = webcomment_templates.tmpl_email_new_comment_footer(\n        recID,\n        title,\n        reviews,\n        comID,\n        report_numbers,\n        can_unsubscribe=False,\n        ln=ln)\n    res2 = True\n    if emails2:\n        res2 = send_email(fromaddr=CFG_WEBCOMMENT_ALERT_ENGINE_EMAIL,\n                          toaddr=emails2,\n                          subject=email_subject,\n                          content=email_content,\n                          header=email_header,\n                          footer=email_footer,\n                          ln=ln)\n\n    return res1 and res2", "response": "Send an email to subscribers about a new comment."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the current status of the record.", "response": "def get_record_status(recid):\n    \"\"\"\n    Returns the current status of the record, i.e. current restriction to apply for newly submitted\n    comments, and current commenting round.\n\n    The restriction to apply can be found in the record metadata, in\n    field(s) defined by config CFG_WEBCOMMENT_RESTRICTION_DATAFIELD. The restriction is empty string \"\"\n    in cases where the restriction has not explicitely been set, even\n    if the record itself is restricted.\n\n    :param recid: the record id\n    :type recid: int\n    :return tuple(restriction, round_name), where 'restriction' is empty string when no restriction applies\n    :rtype (string, int)\n    \"\"\"\n    collections_with_rounds = CFG_WEBCOMMENT_ROUND_DATAFIELD.keys()\n    commenting_round = \"\"\n    for collection in collections_with_rounds:\n        # Find the first collection defines rounds field for this\n        # record\n        if recid in get_collection_reclist(collection):\n            commenting_rounds = get_fieldvalues(\n                recid,\n                CFG_WEBCOMMENT_ROUND_DATAFIELD.get(\n                    collection,\n                    \"\"))\n            if commenting_rounds:\n                commenting_round = commenting_rounds[0]\n            break\n\n    collections_with_restrictions = CFG_WEBCOMMENT_RESTRICTION_DATAFIELD.keys()\n    restriction = \"\"\n    for collection in collections_with_restrictions:\n        # Find the first collection that defines restriction field for\n        # this record\n        if recid in get_collection_reclist(collection):\n            restrictions = get_fieldvalues(\n                recid,\n                CFG_WEBCOMMENT_RESTRICTION_DATAFIELD.get(\n                    collection,\n                    \"\"))\n            if restrictions:\n                restriction = restrictions[0]\n            break\n\n    return (restriction, commenting_round)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_start_date(display_since):\n    time_types = {'d': 0, 'w': 0, 'm': 0, 'y': 0}\n    today = datetime.today()\n    try:\n        nb = int(display_since[:-1])\n    except:\n        return datetext_default\n    if display_since in [None, 'all']:\n        return datetext_default\n    if str(display_since[-1]) in time_types:\n        time_type = str(display_since[-1])\n    else:\n        return datetext_default\n    # year\n    if time_type == 'y':\n        if (int(display_since[:-1]) > today.year -\n                1) or (int(display_since[:-1]) < 1):\n            #   1 < nb years < 2008\n            return datetext_default\n        else:\n            final_nb_year = today.year - nb\n            yesterday = today.replace(year=final_nb_year)\n    # month\n    elif time_type == 'm':\n        try:\n            from dateutil.relativedelta import relativedelta\n        except ImportError:\n            # The dateutil library is only recommended: if not\n            # available, then send warning about this.\n            register_exception(alert_admin=True)\n            return datetext_default\n        # obtain only the date: yyyy-mm-dd\n        date_today = datetime.now().date()\n        final_date = date_today - relativedelta(months=nb)\n        yesterday = today.replace(\n            year=final_date.year,\n            month=final_date.month,\n            day=final_date.day)\n    # week\n    elif time_type == 'w':\n        delta = timedelta(weeks=nb)\n        yesterday = today - delta\n    # day\n    elif time_type == 'd':\n        delta = timedelta(days=nb)\n        yesterday = today - delta\n    return yesterday.strftime(\"%Y-%m-%d %H:%M:%S\")", "response": "Private function to calculate the start date of the nth date in MySQL datetime format."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the first nb comments or remarks for a record.", "response": "def get_first_comments_or_remarks(recID=-1,\n                                  ln=CFG_SITE_LANG,\n                                  nb_comments='all',\n                                  nb_reviews='all',\n                                  voted=-1,\n                                  reported=-1,\n                                  user_info=None,\n                                  show_reviews=False):\n    \"\"\"\n    Gets nb number comments/reviews or remarks.\n    In the case of comments, will get both comments and reviews\n    Comments and remarks sorted by most recent date, reviews sorted by highest helpful score\n    :param recID: record id\n    :param ln: language\n    :param nb_comments: number of comment or remarks to get\n    :param nb_reviews: number of reviews or remarks to get\n    :param voted: 1 if user has voted for a remark\n    :param reported: 1 if user has reported a comment or review\n    :return: if comment, tuple (comments, reviews) both being html of first nb comments/reviews\n            if remark, tuple (remakrs, None)\n    \"\"\"\n    _ = gettext_set_language(ln)\n    warnings = []\n    voted = wash_url_argument(voted, 'int')\n    reported = wash_url_argument(reported, 'int')\n\n    # check recID argument\n    if not isinstance(recID, int):\n        return ()\n    # comment or review. NB: suppressed reference to basket (handled in\n    # webbasket)\n    if recID >= 1:\n        if CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            res_reviews = query_retrieve_comments_or_remarks(\n                recID=recID,\n                display_order=\"hh\",\n                ranking=1,\n                limit=nb_comments,\n                user_info=user_info)\n            nb_res_reviews = len(res_reviews)\n            # check nb argument\n            if isinstance(nb_reviews, int) and nb_reviews < len(res_reviews):\n                first_res_reviews = res_reviews[:nb_reviews]\n            else:\n                first_res_reviews = res_reviews\n        if CFG_WEBCOMMENT_ALLOW_COMMENTS:\n            res_comments = query_retrieve_comments_or_remarks(\n                recID=recID,\n                display_order=\"od\",\n                ranking=0,\n                limit=nb_reviews,\n                user_info=user_info)\n            nb_res_comments = len(res_comments)\n            # check nb argument\n            if isinstance(nb_comments, int) and nb_comments < len(\n                    res_comments):\n                first_res_comments = res_comments[:nb_comments]\n            else:\n                first_res_comments = res_comments\n    else:  # error\n        try:\n            raise InvenioWebCommentError(\n                _('%(recid)s is an invalid record ID', recid=recID))\n        except InvenioWebCommentError as exc:\n            register_exception()\n            body = webcomment_templates.tmpl_error(exc.message, ln)\n            return body\n        # errors.append(('ERR_WEBCOMMENT_RECID_INVALID', recID)) #!FIXME dont\n        # return error anywhere since search page\n\n    # comment\n    if recID >= 1:\n        comments = reviews = \"\"\n        if reported > 0:\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Your feedback has been recorded, many thanks.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning')\n                warnings.append((exc.message, 'green'))\n            # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_RECORDED_GREEN_TEXT',))\n        elif reported == 0:\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Your feedback could not be recorded, please try again.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning')\n                warnings.append((exc.message, ''))\n            # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_NOT_RECORDED_RED_TEXT',))\n        if CFG_WEBCOMMENT_ALLOW_COMMENTS:  # normal comments\n            grouped_comments = group_comments_by_round(\n                first_res_comments,\n                ranking=0)\n            comments = webcomment_templates.tmpl_get_first_comments_without_ranking(\n                recID,\n                ln,\n                grouped_comments,\n                nb_res_comments,\n                warnings)\n        if show_reviews:\n            if CFG_WEBCOMMENT_ALLOW_REVIEWS:  # ranked comments\n                # calculate average score\n                avg_score = calculate_avg_score(res_reviews)\n                if voted > 0:\n                    try:\n                        raise InvenioWebCommentWarning(\n                            _('Your feedback has been recorded, many thanks.'))\n                    except InvenioWebCommentWarning as exc:\n                        register_exception(stream='warning')\n                        warnings.append((exc.message, 'green'))\n                    # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_RECORDED_GREEN_TEXT',))\n                elif voted == 0:\n                    try:\n                        raise InvenioWebCommentWarning(\n                            _('Your feedback could not be recorded, please try again.'))\n                    except InvenioWebCommentWarning as exc:\n                        register_exception(stream='warning')\n                        warnings.append((exc.message, ''))\n                    # warnings.append(('WRN_WEBCOMMENT_FEEDBACK_NOT_RECORDED_RED_TEXT',))\n                grouped_reviews = group_comments_by_round(\n                    first_res_reviews,\n                    ranking=0)\n                reviews = webcomment_templates.tmpl_get_first_comments_with_ranking(\n                    recID,\n                    ln,\n                    grouped_reviews,\n                    nb_res_reviews,\n                    avg_score,\n                    warnings)\n        return (comments, reviews)\n    # remark\n    else:\n        return(webcomment_templates.tmpl_get_first_remarks(first_res_comments, ln, nb_res_comments), None)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef group_comments_by_round(comments, ranking=0):\n    comment_rounds = {}\n    ordered_comment_round_names = []\n    for comment in comments:\n        comment_round_name = ranking and comment[11] or comment[7]\n        if comment_round_name not in comment_rounds:\n            comment_rounds[comment_round_name] = []\n            ordered_comment_round_names.append(comment_round_name)\n        comment_rounds[comment_round_name].append(comment)\n    return [(comment_round_name, comment_rounds[comment_round_name])\n            for comment_round_name in ordered_comment_round_names]", "response": "Group comments by the round to which they belong"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_avg_score(res):\n    c_star_score = 6\n    avg_score = 0.0\n    nb_reviews = 0\n    for comment in res:\n        if comment[c_star_score] > 0:\n            avg_score += comment[c_star_score]\n            nb_reviews += 1\n    if nb_reviews == 0:\n        return 0.0\n    avg_score = avg_score / nb_reviews\n    avg_score_unit = avg_score - math.floor(avg_score)\n    if avg_score_unit < 0.25:\n        avg_score = math.floor(avg_score)\n    elif avg_score_unit > 0.75:\n        avg_score = math.floor(avg_score) + 1\n    else:\n        avg_score = math.floor(avg_score) + 0.5\n    if avg_score > 5:\n        avg_score = 5.0\n    return avg_score", "response": "Private function to calculate the average score of reviews present in the resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef perform_request_add_comment_or_remark(recID=0,\n                                          uid=-1,\n                                          action='DISPLAY',\n                                          ln=CFG_SITE_LANG,\n                                          msg=None,\n                                          score=None,\n                                          note=None,\n                                          priority=None,\n                                          reviews=0,\n                                          comID=0,\n                                          client_ip_address=None,\n                                          editor_type='textarea',\n                                          can_attach_files=False,\n                                          subscribe=False,\n                                          req=None,\n                                          attached_files=None,\n                                          warnings=None):\n    \"\"\"\n    Add a comment/review or remark\n    :param recID: record id\n    :param uid: user id\n    :param action:  'DISPLAY' to display add form\n                    'SUBMIT' to submit comment once form is filled\n                    'REPLY' to reply to an existing comment\n    :param ln: language\n    :param msg: the body of the comment/review or remark\n    :param score: star score of the review\n    :param note: title of the review\n    :param priority: priority of remark (int)\n    :param reviews: boolean, if enabled will add a review, if disabled will add a comment\n    :param comID: if replying, this is the comment id of the comment we are replying to\n    :param editor_type: the kind of editor/input used for the comment: 'textarea', 'ckeditor'\n    :param can_attach_files: if user can attach files to comments or not\n    :param subscribe: if True, subscribe user to receive new comments by email\n    :param req: request object. Used to register callback to send email notification\n    :param attached_files: newly attached files to this comment, mapping filename to filepath\n    :type attached_files: dict\n    :param warnings: list of warning tuples (warning_text, warning_color) that should be considered\n    :return:\n             - html add form if action is display or reply\n             - html successful added form if action is submit\n    \"\"\"\n    _ = gettext_set_language(ln)\n    if warnings is None:\n        warnings = []\n\n    _ = gettext_set_language(ln)\n\n    # check arguments\n    check_recID_is_in_range(recID, warnings, ln)\n    if uid <= 0:\n        try:\n            raise InvenioWebCommentError(\n                _('%(uid)s is an invalid user ID.', uid=uid))\n        except InvenioWebCommentError as exc:\n            register_exception()\n            body = webcomment_templates.tmpl_error(exc.message, ln)\n            return body\n        #errors.append(('ERR_WEBCOMMENT_UID_INVALID', uid))\n        return ''\n\n    if attached_files is None:\n        attached_files = {}\n\n    user_contact_info = query_get_user_contact_info(uid)\n    nickname = ''\n    if user_contact_info:\n        if user_contact_info[0]:\n            nickname = user_contact_info[0]\n    # show the form\n    if action == 'DISPLAY':\n        if reviews and CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            return webcomment_templates.tmpl_add_comment_form_with_ranking(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                score,\n                note,\n                warnings,\n                can_attach_files=can_attach_files)\n        elif not reviews and CFG_WEBCOMMENT_ALLOW_COMMENTS:\n            return webcomment_templates.tmpl_add_comment_form(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                warnings,\n                can_attach_files=can_attach_files)\n        else:\n            try:\n                raise InvenioWebCommentError(\n                    _('Comments on records have been disallowed by the administrator.'))\n            except InvenioWebCommentError as exc:\n                register_exception(req=req)\n                body = webcomment_templates.tmpl_error(exc.message, ln)\n                return body\n            # errors.append(('ERR_WEBCOMMENT_COMMENTS_NOT_ALLOWED',))\n\n    elif action == 'REPLY':\n        if reviews and CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            try:\n                raise InvenioWebCommentError(_('Cannot reply to a review.'))\n            except InvenioWebCommentError as exc:\n                register_exception(req=req)\n                body = webcomment_templates.tmpl_error(exc.message, ln)\n                return body\n            # errors.append(('ERR_WEBCOMMENT_REPLY_REVIEW',))\n            return webcomment_templates.tmpl_add_comment_form_with_ranking(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                score,\n                note,\n                warnings,\n                can_attach_files=can_attach_files)\n        elif not reviews and CFG_WEBCOMMENT_ALLOW_COMMENTS:\n            textual_msg = msg\n            if comID > 0:\n                comment = query_get_comment(comID)\n                if comment:\n                    user_info = UserInfo(comment[2])\n                    if user_info:\n                        date_creation = convert_datetext_to_dategui(\n                            str(comment[4]))\n                        # Build two msg: one mostly textual, the other one with\n                        # HTML markup, for the CkEditor.\n                        msg = _(\"%(x_name)s wrote on %(x_date)s:\") % {\n                            'x_name': user_info[2],\n                            'x_date': date_creation}\n                        textual_msg = msg\n                        # 1 For CkEditor input\n                        msg += '\\n\\n'\n                        msg += comment[3]\n                        msg = email_quote_txt(text=msg)\n                        # Now that we have a text-quoted version, transform into\n                        # something that CkEditor likes, using <blockquote> that\n                        # do still enable users to insert comments inline\n                        msg = email_quoted_txt2html(\n                            text=msg,\n                            indent_html=(\n                                '<blockquote><div>',\n                                '&nbsp;&nbsp;</div></blockquote>'),\n                            linebreak_html=\"&nbsp;<br/>\",\n                            indent_block=False)\n                        # Add some space for users to easily add text\n                        # around the quoted message\n                        msg = '<br/>' + msg + '<br/>'\n                        # Due to how things are done, we need to\n                        # escape the whole msg again for the editor\n                        msg = cgi.escape(msg)\n\n                        # 2 For textarea input\n                        textual_msg += \"\\n\\n\"\n                        textual_msg += comment[3]\n                        textual_msg = email_quote_txt(text=textual_msg)\n            return webcomment_templates.tmpl_add_comment_form(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                warnings,\n                textual_msg,\n                can_attach_files=can_attach_files,\n                reply_to=comID)\n        else:\n            try:\n                raise InvenioWebCommentError(\n                    _('Comments on records have been disallowed by the administrator.'))\n            except InvenioWebCommentError as exc:\n                register_exception(req=req)\n                body = webcomment_templates.tmpl_error(exc.message, ln)\n                return body\n            # errors.append(('ERR_WEBCOMMENT_COMMENTS_NOT_ALLOWED',))\n\n    # check before submitting form\n    elif action == 'SUBMIT':\n        if reviews and CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            if note.strip() in [\n                    \"\", \"None\"] and not CFG_WEBCOMMENT_ALLOW_SHORT_REVIEWS:\n                try:\n                    raise InvenioWebCommentWarning(\n                        _('You must enter a title.'))\n                except InvenioWebCommentWarning as exc:\n                    register_exception(stream='warning', req=req)\n                    warnings.append((exc.message, ''))\n                # warnings.append(('WRN_WEBCOMMENT_ADD_NO_TITLE',))\n            if score == 0 or score > 5:\n                try:\n                    raise InvenioWebCommentWarning(\n                        _('You must choose a score.'))\n                except InvenioWebCommentWarning as exc:\n                    register_exception(stream='warning', req=req)\n                    warnings.append((exc.message, ''))\n                # warnings.append((\"WRN_WEBCOMMENT_ADD_NO_SCORE\",))\n        if msg.strip() in [\n                \"\", \"None\"] and not CFG_WEBCOMMENT_ALLOW_SHORT_REVIEWS:\n            try:\n                raise InvenioWebCommentWarning(_('You must enter a text.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning', req=req)\n                warnings.append((exc.message, ''))\n            # warnings.append(('WRN_WEBCOMMENT_ADD_NO_BODY',))\n        # if no warnings, submit\n        if len(warnings) == 0:\n            if reviews:\n                if check_user_can_review(recID, client_ip_address, uid):\n                    success = query_add_comment_or_remark(\n                        reviews,\n                        recID=recID,\n                        uid=uid,\n                        msg=msg,\n                        note=note,\n                        score=score,\n                        priority=0,\n                        client_ip_address=client_ip_address,\n                        editor_type=editor_type,\n                        req=req,\n                        reply_to=comID)\n                else:\n                    try:\n                        raise InvenioWebCommentWarning(\n                            _('You already wrote a review for this record.'))\n                    except InvenioWebCommentWarning as exc:\n                        register_exception(stream='warning', req=req)\n                        warnings.append((exc.message, ''))\n                    # warnings.append('WRN_WEBCOMMENT_CANNOT_REVIEW_TWICE')\n                    success = 1\n            else:\n                if check_user_can_comment(recID, client_ip_address, uid):\n                    success = query_add_comment_or_remark(\n                        reviews,\n                        recID=recID,\n                        uid=uid,\n                        msg=msg,\n                        note=note,\n                        score=score,\n                        priority=0,\n                        client_ip_address=client_ip_address,\n                        editor_type=editor_type,\n                        req=req,\n                        reply_to=comID,\n                        attached_files=attached_files)\n                    if success > 0 and subscribe:\n                        subscribe_user_to_discussion(recID, uid)\n                else:\n                    try:\n                        raise InvenioWebCommentWarning(\n                            _('You already posted a comment short ago. Please retry later.'))\n                    except InvenioWebCommentWarning as exc:\n                        register_exception(stream='warning', req=req)\n                        warnings.append((exc.message, ''))\n                    # warnings.append('WRN_WEBCOMMENT_TIMELIMIT')\n                    success = 1\n            if success > 0:\n                if CFG_WEBCOMMENT_ADMIN_NOTIFICATION_LEVEL > 0:\n                    notify_admin_of_new_comment(comID=success)\n                return webcomment_templates.tmpl_add_comment_successful(\n                    recID, ln, reviews, warnings, success)\n            else:\n                try:\n                    raise InvenioWebCommentError(\n                        _('Failed to insert your comment to the database. Please try again.'))\n                except InvenioWebCommentError as exc:\n                    register_exception(req=req)\n                    body = webcomment_templates.tmpl_error(exc.message, ln)\n                    return body\n                # errors.append(('ERR_WEBCOMMENT_DB_INSERT_ERROR'))\n        # if are warnings or if inserting comment failed, show user where\n        # warnings are\n        if reviews and CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            return webcomment_templates.tmpl_add_comment_form_with_ranking(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                score,\n                note,\n                warnings,\n                can_attach_files=can_attach_files)\n        else:\n            return webcomment_templates.tmpl_add_comment_form(\n                recID,\n                uid,\n                nickname,\n                ln,\n                msg,\n                warnings,\n                can_attach_files=can_attach_files)\n    # unknown action send to display\n    else:\n        try:\n            raise InvenioWebCommentWarning(\n                _('Unknown action --> showing you the default add comment form.'))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning', req=req)\n            warnings.append((exc.message, ''))\n        # warnings.append(('WRN_WEBCOMMENT_ADD_UNKNOWN_ACTION',))\n        if reviews and CFG_WEBCOMMENT_ALLOW_REVIEWS:\n            return webcomment_templates.tmpl_add_comment_form_with_ranking(\n                recID,\n                uid,\n                ln,\n                msg,\n                score,\n                note,\n                warnings,\n                can_attach_files=can_attach_files)\n        else:\n            return webcomment_templates.tmpl_add_comment_form(\n                recID,\n                uid,\n                ln,\n                msg,\n                warnings,\n                can_attach_files=can_attach_files)\n\n    return ''", "response": "This function is used to add a comment or remark to a record."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef notify_admin_of_new_comment(comID):\n    comment = query_get_comment(comID)\n    if len(comment) > 0:\n        (comID2,\n         id_bibrec,\n         id_user,\n         body,\n         date_creation,\n         star_score, nb_votes_yes, nb_votes_total,\n         title,\n         nb_abuse_reports, round_name, restriction) = comment\n    else:\n        return\n    user_info = query_get_user_contact_info(id_user)\n    if len(user_info) > 0:\n        (nickname, email, last_login) = user_info\n        if not len(nickname) > 0:\n            nickname = email.split('@')[0]\n    else:\n        nickname = email = \"ERROR: Could not retrieve\"\n\n    review_stuff = '''\n    Star score  = %s\n    Title       = %s''' % (star_score, title)\n\n    washer = EmailWasher()\n    try:\n        body = washer.wash(body)\n    except:\n        body = cgi.escape(body)\n\n    record_info = webcomment_templates.tmpl_email_new_comment_admin(id_bibrec)\n    out = '''\nThe following %(comment_or_review)s has just been posted (%(date)s).\n\nAUTHOR:\n    Nickname    = %(nickname)s\n    Email       = %(email)s\n    User ID     = %(uid)s\n\nRECORD CONCERNED:\n    Record ID   = %(recID)s\n    URL         = <%(siteurl)s/%(CFG_SITE_RECORD)s/%(recID)s/%(comments_or_reviews)s/>\n%(record_details)s\n\n%(comment_or_review_caps)s:\n    %(comment_or_review)s ID    = %(comID)s %(review_stuff)s\n    Body        =\n<--------------->\n%(body)s\n\n<--------------->\nADMIN OPTIONS:\nTo moderate the %(comment_or_review)s go to %(siteurl)s/%(CFG_SITE_RECORD)s/%(recID)s/%(comments_or_reviews)s/display?%(arguments)s\n    ''' % \\\n        {'comment_or_review': star_score > 0 and 'review' or 'comment',\n            'comment_or_review_caps': star_score > 0 and 'REVIEW' or 'COMMENT',\n            'comments_or_reviews': star_score > 0 and 'reviews' or 'comments',\n            'date': date_creation,\n            'nickname': nickname,\n            'email': email,\n            'uid': id_user,\n            'recID': id_bibrec,\n            'record_details': record_info,\n            'comID': comID2,\n            'review_stuff': star_score > 0 and review_stuff or \"\",\n            'body': body.replace('<br />', '\\n'),\n            'siteurl': CFG_SITE_URL,\n            'CFG_SITE_RECORD': CFG_SITE_RECORD,\n            'arguments': 'ln=en&do=od#%s' % comID\n         }\n\n    from_addr = '%s WebComment <%s>' % (\n        CFG_SITE_NAME, CFG_WEBALERT_ALERT_ENGINE_EMAIL)\n    comment_collection = get_comment_collection(comID)\n    to_addrs = get_collection_moderators(comment_collection)\n\n    rec_collection = guess_primary_collection_of_a_record(id_bibrec)\n    report_nums = get_fieldvalues(id_bibrec, \"037__a\")\n    report_nums += get_fieldvalues(id_bibrec, \"088__a\")\n    report_nums = ', '.join(report_nums)\n    subject = \"A new comment/review has just been posted [%s|%s]\" % (\n        rec_collection, report_nums)\n\n    send_email(from_addr, to_addrs, subject, out)", "response": "Send an email to the admin of the new comment."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_recID_is_in_range(recID, warnings=[], ln=CFG_SITE_LANG):\n    _ = gettext_set_language(ln)\n\n    try:\n        recID = int(recID)\n    except:\n        pass\n\n    if isinstance(recID, int):\n        if recID > 0:\n            from invenio.legacy.search_engine import record_exists\n            success = record_exists(recID)\n            if success == 1:\n                return (1, \"\")\n            else:\n                try:\n                    if success == -1:\n                        status = 'deleted'\n                        raise InvenioWebCommentWarning(\n                            _('The record has been deleted.'))\n                    else:\n                        status = 'inexistant'\n                        raise InvenioWebCommentWarning(\n                            _('Record ID %(x_rec)s does not exist in the database.', x_rec=recID))\n                except InvenioWebCommentWarning as exc:\n                    register_exception(stream='warning')\n                    warnings.append((exc.message, ''))\n                #warnings.append(('ERR_WEBCOMMENT_RECID_INEXISTANT', recID))\n                return (0, webcomment_templates.tmpl_record_not_found(\n                    status=status, recID=recID, ln=ln))\n        elif recID == 0:\n            try:\n                raise InvenioWebCommentWarning(_('No record ID was given.'))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning')\n                warnings.append((exc.message, ''))\n            # warnings.append(('ERR_WEBCOMMENT_RECID_MISSING',))\n            return (0, webcomment_templates.tmpl_record_not_found(\n                status='missing', recID=recID, ln=ln))\n        else:\n            try:\n                raise InvenioWebCommentWarning(\n                    _('Record ID %(recid)s is an invalid ID.', recid=recID))\n            except InvenioWebCommentWarning as exc:\n                register_exception(stream='warning')\n                warnings.append((exc.message, ''))\n            #warnings.append(('ERR_WEBCOMMENT_RECID_INVALID', recID))\n            return (0, webcomment_templates.tmpl_record_not_found(\n                status='invalid', recID=recID, ln=ln))\n    else:\n        try:\n            raise InvenioWebCommentWarning(\n                _('Record ID %(recid)s is not a number.', recid=recID))\n        except InvenioWebCommentWarning as exc:\n            register_exception(stream='warning')\n            warnings.append((exc.message, ''))\n        #warnings.append(('ERR_WEBCOMMENT_RECID_NAN', recID))\n        return (0, webcomment_templates.tmpl_record_not_found(\n            status='nan', recID=recID, ln=ln))", "response": "Check that record ID is in the given range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks that the value of an integer argument is in the specified range.", "response": "def check_int_arg_is_in_range(value, name, gte_value, lte_value=None):\n    \"\"\"\n    Check that variable with name 'name' >= gte_value and optionally <= lte_value\n    :param value: variable value\n    :param name: variable name\n    :param errors: list of error tuples (error_id, value)\n    :param gte_value: greater than or equal to value\n    :param lte_value: less than or equal to value\n    :return: boolean (1=true, 0=false)\n    \"\"\"\n\n    if not isinstance(value, int):\n        try:\n            raise InvenioWebCommentError('%s is not a number.' % value)\n        except InvenioWebCommentError as exc:\n            register_exception()\n            body = webcomment_templates.tmpl_error(exc.message)\n            return body\n        #errors.append(('ERR_WEBCOMMENT_ARGUMENT_NAN', value))\n        return 0\n\n    if value < gte_value:\n        try:\n            raise InvenioWebCommentError('%s invalid argument.' % value)\n        except InvenioWebCommentError as exc:\n            register_exception()\n            body = webcomment_templates.tmpl_error(exc.message)\n            return body\n        #errors.append(('ERR_WEBCOMMENT_ARGUMENT_INVALID', value))\n        return 0\n    if lte_value:\n        if value > lte_value:\n            try:\n                raise InvenioWebCommentError('%s invalid argument.' % value)\n            except InvenioWebCommentError as exc:\n                register_exception()\n                body = webcomment_templates.tmpl_error(exc.message)\n                return body\n            #errors.append(('ERR_WEBCOMMENT_ARGUMENT_INVALID', value))\n            return 0\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_mini_reviews(recid, ln=CFG_SITE_LANG):\n    if CFG_WEBCOMMENT_ALLOW_SHORT_REVIEWS:\n        action = 'SUBMIT'\n    else:\n        action = 'DISPLAY'\n\n    reviews = query_retrieve_comments_or_remarks(recid, ranking=1)\n\n    return webcomment_templates.tmpl_mini_review(\n        recid,\n        ln,\n        action=action,\n        avg_score=calculate_avg_score(reviews),\n        nb_comments_total=len(reviews))", "response": "Returns the web controls to add reviews to a record from the mini - panel."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_user_can_view_comments(user_info, recid):\n    # Check user can view the record itself first\n    (auth_code, auth_msg) = check_user_can_view_record(user_info, recid)\n    if auth_code:\n        return (auth_code, auth_msg)\n\n    # Check if user can view the comments\n    # But first can we find an authorization for this case action,\n    # for this collection?\n    record_primary_collection = guess_primary_collection_of_a_record(recid)\n    return acc_authorize_action(\n        user_info,\n        'viewcomment',\n        authorized_if_no_roles=True,\n        collection=record_primary_collection)", "response": "Check if the user is authorized to view comments for given recid. Returns the same type as acc_authorize_action\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the user is authorized to view a particular comment.", "response": "def check_user_can_view_comment(user_info, comid, restriction=None):\n    \"\"\"Check if the user is authorized to view a particular comment,\n    given the comment restriction. Note that this function does not\n    check if the record itself is restricted to the user, which would\n    mean that the user should not see the comment.\n\n    You can omit 'comid' if you already know the 'restriction'\n\n    :param user_info: the user info object\n    :param comid: the comment id of that we want to check\n    :param restriction: the restriction applied to given comment (if known. Otherwise retrieved automatically)\n\n    :return: the same type as acc_authorize_action\n    \"\"\"\n    if restriction is None:\n        comment = query_get_comment(comid)\n        if comment:\n            restriction = comment[11]\n        else:\n            return (1, 'Comment %i does not exist' % comid)\n    if restriction == \"\":\n        return (0, '')\n    return acc_authorize_action(\n        user_info, 'viewrestrcomment', status=restriction)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_user_can_send_comments(user_info, recid):\n    # First can we find an authorization for this case, action + collection\n    record_primary_collection = guess_primary_collection_of_a_record(recid)\n    return acc_authorize_action(\n        user_info,\n        'sendcomment',\n        authorized_if_no_roles=True,\n        collection=record_primary_collection)", "response": "Check if the user is authorized to comment the given\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_comment_belongs_to_record(comid, recid):\n    query = \"\"\"SELECT id_bibrec from \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n    params = (comid,)\n    res = run_sql(query, params)\n    if res and res[0][0] == recid:\n        return True\n\n    return False", "response": "Check if comment belongs to record"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the user is authorized to attach a file to comments for given recid.", "response": "def check_user_can_attach_file_to_comments(user_info, recid):\n    \"\"\"Check if the user is authorized to attach a file to comments\n    for given recid. This function does not check that user can view\n    the comments or send comments.\n\n    Returns the same type as acc_authorize_action\n    \"\"\"\n    # First can we find an authorization for this case action, for\n    # this collection?\n    record_primary_collection = guess_primary_collection_of_a_record(recid)\n    return acc_authorize_action(\n        user_info,\n        'attachcommentfile',\n        authorized_if_no_roles=False,\n        collection=record_primary_collection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef toggle_comment_visibility(uid, comid, collapse, recid):\n    # We rely on the client to tell if comment should be collapsed or\n    # developed, to ensure consistency between our internal state and\n    # client state.  Even if not strictly necessary, we store the\n    # record ID for quicker retrieval of the collapsed comments of a\n    # given discussion page. To prevent unnecessary population of the\n    # table, only one distinct tuple (record ID, comment ID, user ID)\n    # can be inserted (due to table definition). For the same purpose\n    # we also check that comment to collapse exists, and corresponds\n    # to an existing record: we cannot rely on the recid found as part\n    # of the URL, as no former check is done. This rule is not applied\n    # when deleting an entry, as in the worst case no line would be\n    # removed. For optimized retrieval of row to delete, the id_bibrec\n    # column is used, though not strictly necessary.\n    if collapse:\n        query = \"\"\"SELECT id_bibrec from \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n        params = (comid,)\n        res = run_sql(query, params)\n        if res:\n            query = \"\"\"INSERT INTO \"cmtCOLLAPSED\" (id_bibrec, \"id_cmtRECORDCOMMENT\", id_user)\n                              VALUES (%s, %s, %s)\"\"\"\n            params = (res[0][0], comid, uid)\n            run_sql(query, params)\n        return True\n    else:\n        query = \"\"\"DELETE FROM \"cmtCOLLAPSED\" WHERE\n                      \"id_cmtRECORDCOMMENT\"=%s and\n                      id_user=%s and\n                      id_bibrec=%s\"\"\"\n        params = (comid, uid, recid)\n        run_sql(query, params)\n        return False", "response": "Toggle the visibility of the given comment for the given user."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the comments that have been collapsed for a given user on a given discussion page and record.", "response": "def get_user_collapsed_comments_for_record(uid, recid):\n    \"\"\"\n    Get the comments collapsed for given user on given recid page\n    \"\"\"\n    # Collapsed state is not an attribute of cmtRECORDCOMMENT table\n    # (vary per user) so it cannot be found when querying for the\n    # comment. We must therefore provide a efficient way to retrieve\n    # the collapsed state for a given discussion page and user.\n    query = \"\"\"SELECT \"id_cmtRECORDCOMMENT\" from \"cmtCOLLAPSED\" WHERE id_user=%s and id_bibrec=%s\"\"\"\n    params = (uid, recid)\n    return [res[0] for res in run_sql(query, params)]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_comment_deleted(comid):\n    query = \"\"\"SELECT status from \"cmtRECORDCOMMENT\" WHERE id=%s\"\"\"\n    params = (comid,)\n    res = run_sql(query, params)\n    if res and res[0][0] != 'ok':\n        return True\n\n    return False", "response": "Check if the comment is deleted."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef perform_display_your_comments(user_info,\n                                  page_number=1,\n                                  selected_order_by_option=\"lcf\",\n                                  selected_display_number_option=\"all\",\n                                  selected_display_format_option=\"rc\",\n                                  ln=CFG_SITE_LANG):\n    \"\"\"\n    Display all comments submitted by the user.\n\n    :TODO: support reviews too\n\n    :param user_info: standard user info object.\n    :param comments: ordered list of tuples (id_bibrec, comid, date_creation, body, status, in_reply_to_id_cmtRECORDCOMMENT)\n    :param page_number: page on which the user is.\n    :type page_number: integer\n    :param selected_order_by_option: seleccted ordering option. Can be one of:\n          - ocf: Oldest comment first\n          - lcf: Latest comment first\n          - grof: Group by record, oldest commented first\n          - grlf: Group by record, latest commented first\n    :type selected_order_by_option: string\n    :param selected_display_number_option: number of results to show per page. Can be a string-digit or 'all'.\n    :type selected_display_number_option: string\n    :param selected_display_format_option: how to show records. Can be one of:\n          - rc: Records and comments\n          - ro: Records only\n          - co: Comments only\n    :type selected_display_format_option: string\n    :ln: language\n    :type ln: string\n    \"\"\"\n    query_params = \"\"\n    nb_total_pages = 0\n\n    if selected_display_format_option in ('rc', 'co'):\n        nb_total_results = run_sql(\n            \"\"\"SELECT count(id) from \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0\"\"\",\n            (user_info['uid'],\n             ))[0][0]\n    else:\n        if selected_order_by_option in ('grlf', 'grof'):\n            nb_total_results = run_sql(\n                \"\"\"SELECT count(distinct(id_bibrec)) from \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0\"\"\",\n                (user_info['uid'],\n                 ))[0][0]\n        else:\n            nb_total_results = run_sql(\n                \"\"\"SELECT count(id_bibrec) from \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0\"\"\",\n                (user_info['uid'],\n                 ))[0][0]\n    if page_number < 1:\n        page_number = 1\n\n    if selected_display_number_option != 'all' and \\\n            not selected_display_number_option.isdigit():\n        # must be some garbage\n        selected_display_number_option = 'all'\n\n    query = ''\n    if selected_order_by_option == \"lcf\":\n        query_params += \" ORDER BY date_creation DESC\"\n    elif selected_order_by_option == \"ocf\":\n        query_params += \" ORDER BY date_creation ASC\"\n    elif selected_order_by_option == \"grlf\":\n        query = \"\"\"SELECT cmt.id_bibrec, cmt.id, cmt.date_creation, cmt.body, cmt.status, cmt.\"in_reply_to_id_cmtRECORDCOMMENT\" FROM \"cmtRECORDCOMMENT\" as cmt left join (SELECT max(date_creation) as maxdatecreation, id_bibrec FROM \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0 GROUP BY id_bibrec) as grp on cmt.id_bibrec = grp.id_bibrec WHERE id_user=%s AND star_score = 0 ORDER BY grp.maxdatecreation DESC, cmt.date_creation DESC\"\"\"\n    elif selected_order_by_option == \"grof\":\n        query = \"\"\"SELECT cmt.id_bibrec, cmt.id, cmt.date_creation, cmt.body, cmt.status, cmt.\"in_reply_to_id_cmtRECORDCOMMENT\" FROM \"cmtRECORDCOMMENT\" as cmt left join (SELECT min(date_creation) as mindatecreation, id_bibrec FROM \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0 GROUP BY id_bibrec) as grp on cmt.id_bibrec = grp.id_bibrec WHERE id_user=%s AND star_score = 0 ORDER BY grp.mindatecreation ASC\"\"\"\n\n    if selected_display_number_option.isdigit():\n        selected_display_number_option_as_int = int(\n            selected_display_number_option)\n        if selected_display_number_option_as_int < 5:\n            selected_display_number_option_as_int = 5\n            selected_display_number_option = str(\n                selected_display_number_option_as_int)\n        from_index = (page_number - 1) * int(selected_display_number_option)\n        query_params += ' LIMIT ' + \\\n                        str(from_index) + \\\n                        ',' + \\\n                        str(int(selected_display_number_option))\n        nb_total_pages = int(\n            math.ceil(\n                float(nb_total_results) /\n                selected_display_number_option_as_int))\n\n    if selected_order_by_option in (\"grlf\", \"grof\"):\n        res = run_sql(\n            query +\n            query_params,\n            (user_info['uid'],\n             user_info['uid']))\n    else:\n        res = run_sql(\n            \"\"\"SELECT id_bibrec, id, date_creation, body, status, \"in_reply_to_id_cmtRECORDCOMMENT\" FROM \"cmtRECORDCOMMENT\" WHERE id_user=%s AND star_score = 0\"\"\" +\n            query_params,\n            (user_info['uid'],\n             ))\n\n    return webcomment_templates.tmpl_your_comments(\n        user_info,\n        res,\n        page_number=page_number,\n        selected_order_by_option=selected_order_by_option,\n        selected_display_number_option=selected_display_number_option,\n        selected_display_format_option=selected_display_format_option,\n        nb_total_results=nb_total_results,\n        nb_total_pages=nb_total_pages,\n        ln=ln)", "response": "Display comments for the current user."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fix_time(self, dt):\n        if dt.tzinfo is not None:\n            dt = dt.replace(tzinfo=None)\n        return dt", "response": "Stackdistiller converts all times to utc."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstripping the leading whitespaces and % from the given text.", "response": "def strip_leading_comments(text):\n    \"\"\"Strips the leading whitespaces and % from the given text.\n\n    Adapted from textwrap.dedent\n    \"\"\"\n    # Look for the longest leading string of spaces and tabs common to\n    # all lines.\n    margin = None\n    text = _whitespace_only_re.sub('', text)\n    indents = _leading_whitespace_re.findall(text)\n    for indent in indents:\n        if margin is None:\n            margin = indent\n\n        # Current line more deeply indented than previous winner:\n        # no change (previous winner is still on top).\n        elif indent.startswith(margin):\n            pass\n\n        # Current line consistent with and no deeper than previous winner:\n        # it's the new winner.\n        elif margin.startswith(indent):\n            margin = indent\n\n        # Current line and previous winner have no common whitespace:\n        # there is no margin.\n        else:\n            margin = \"\"\n            break\n\n    # sanity check (testing/debugging only)\n    if 0 and margin:\n        for line in text.split(\"\\n\"):\n            assert not line or line.startswith(margin), \\\n                \"line = %r, margin = %r\" % (line, margin)\n\n    if margin:\n        text = re.sub(r'(?m)^' + margin, '', text)\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(target, trace=False, **kwargs):\n\n    # Beware! This function, that actually is the core of all the\n    # business, is written to minimize the responsibilities of each\n    # chunk of code, keeping things simple. Performance may degrade\n    # because of this, but without actual measurements the simplest\n    # choice is the best one.\n\n    if hasattr(target, 'read'):\n        # It's a file-like object\n        file_content = target.read()\n        return parse(file_content, trace, **kwargs)\n\n    if os.path.isfile(target):\n        if target.endswith(\".ily\") or target.endswith(\".ly\"):\n            console.display(\"Parsing\", target)\n            with io.open(target, \"r\", encoding=\"utf-8\") as fp:\n                return parse(fp, trace, filename=target, **kwargs)\n        else:\n            return []\n\n    if os.path.isdir(target):\n        docs = []\n        logging.info(\"Parsing directory {}\", target)\n        for root, _, files in os.walk(target):\n            for f in files:\n                fname = os.path.join(root, f)\n                file_docs = parse(fname, trace, **kwargs)\n                docs.extend(file_docs)\n        return docs\n\n    # We were given a text, so parse it directly\n    metrics = kwargs.get(\"metrics\", None)\n    if metrics is not None:\n        metrics.record_file(target)\n\n    docs = []\n    parser = LilyParser(parseinfo=True)\n    try:\n        parser.parse(target,\n                     'lilypond',\n                     semantics=DocumentationSemantics(docs),\n                     filename=kwargs.get(\"filename\", None),\n                     trace=trace)\n    except FailedParse as err:\n        logging.warn(err)\n        if metrics is not None:\n            metrics.record_error(err)\n    except RuntimeError as err:\n        logging.warn(err)\n        if metrics is not None:\n            metrics.record_error(err)\n\n    return docs", "response": "Parse the given target and return a list of the objects that are available in the system."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find(name, app=None, components=None, raw=False):\n\n    if components is None:\n        if app is None:\n            from flask import current_app as app\n\n        components = app.config.get('COMPONENTS', [])\n\n    items = []\n    for key in components:\n        # Attempt to import the component and access the specified name\n        # as an attribute.\n        module = import_module(key)\n        item = getattr(module, name, None)\n\n        if item is None:\n            # Attempt to import a module or package in the component\n            # with the specified name.\n            try:\n                item = import_module('.'.join((key, name)))\n\n            except ImportError:\n                # Assume this component has nothing under the specified name.\n                continue\n\n        if not raw:\n            if isinstance(item, types.ModuleType):\n                all_ = getattr(item, '__all__', None)\n                if all_:\n                    item = {n: getattr(item, n) for n in all_}\n\n                else:\n                    item = vars(item)\n\n        items.append(item)\n\n    return items", "response": "Find the items under the specified name in the COMPONENTS section of the application config."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unsafe_execute(self, result=None):\n        if result:\n            self.result += result\n\n        with opentracing.tracer.start_span(\n                obj=self, child_of=KserSpan.extract_span(self),\n                span_factory=KserSpan) as span:\n            self.result = self._onsuccess(self._postrun(self._run()))\n            span.obj = self\n            return self.result", "response": "un - wrapped execution can raise excepetion\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef auto_clear_shopping_cart(self, auto_clear_shopping_cart):\n        allowed_values = [\"never\", \"orderCreated\", \"orderCompleted\"]  # noqa: E501\n        if auto_clear_shopping_cart is not None and auto_clear_shopping_cart not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `auto_clear_shopping_cart` ({0}), must be one of {1}\"  # noqa: E501\n                .format(auto_clear_shopping_cart, allowed_values)\n            )\n\n        self._auto_clear_shopping_cart = auto_clear_shopping_cart", "response": "Sets the auto_clear_shopping_cart of this CartSettings."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getView(self, lv):\n        view = None\n        if str(lv.GetName())[-1] == 'X':\n            return 'X'\n        elif str(lv.GetName())[-1] == 'Y':\n            return 'Y'\n\n        self.log.error('Cannot determine view for %s', lv.GetName())\n        raise 'Cannot determine view for %s' % lv.GetName()\n        return view", "response": "Determine the detector view starting with a G4LogicalVolume"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncrossing product of two vectors.", "response": "def cross_product (x1, y1, x2, y2, x3, y3):\n    \"\"\" \u53c9\u4e58\n    vector 1: x1, y1, x2, y2\n    vector 2: x1, y1, x3, y3\n    \"\"\"\n    return (x2 - x1) * (y3 - y1) - (x3 - x1) * (y2 - y1)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collide(self, s2):\n        s1 = self\n        \n        s1.update_points()\n        s2.update_points()\n\n        if not (s1.points and s2.points):\n            return False\n\n        t1 = s1.transform\n        t2 = s2.transform\n\n        t1.update_points(s1.points)\n        t2.update_points(s2.points)\n\n        # \u66f4\u65b0\u5916\u63a5\u77e9\u5f62\n        t1.update_collision_rect()\n        t2.update_collision_rect()\n\n        # simple collide rect\n        if not (t1.min_x < t2.max_x and t1.max_x > t2.min_x \\\n                and t1.min_y < t2.max_y and t1.max_y > t2.min_y):\n            return False\n\n        return points_in_points(t1, t2) or \\\n               points_in_points(t2, t1) or \\\n               lines_cross(t1, t2)", "response": "return True if the two sets of points collide"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _FromSpecs(self, specs):\r\n\r\n        if isinstance(specs, dict):\r\n            specs_ = []\r\n            for name, value in specs.items():\r\n                specs_.append((name, {\"value\": value}))\r\n        else:\r\n            specs_ = specs\r\n        for spec in specs_:\r\n            self.params.append(Parameter(spec))", "response": "Populate self. params from a list of specification parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the parameters to the given QFormLayout.", "response": "def AddToLayout(self, layout):\r\n        \"\"\"\r\n        Arguments:\r\n          layout -- a QFormLayout instance\r\n        \"\"\"\r\n        for param in self.params:\r\n            widget = param.RenderWidget()\r\n            layout.addRow(param.caption, widget)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new instance of from a new instance of .", "response": "def FromSpec(self, spec):\r\n        \"\"\"\r\n        Args:\r\n          spec: (name, {...}), or Parameter object\r\n\r\n        Dict keys:\r\n          \"caption\" -- (optional) text for label in editor. Defaults to the\r\n                 keyword argument name\r\n          \"toolTip\" (optional)\r\n          \"type\" -- (optional, defaults to type(\"value\") or int if \"value\" is\r\n              not specified. Accepts:\r\n                - int\r\n                - float\r\n                - str\r\n                - bool\r\n                - list\r\n          \"value\" -- (optional) defaults to 1 if numeric, False if bool,\r\n               \"\" if str\r\n\r\n        \"\"\"\r\n        if isinstance(spec, Parameter):\r\n            self.name = spec.name\r\n            self.caption = spec.caption if spec.caption is not None else spec.name\r\n            self.toolTip = spec.toolTip if spec.toolTip is not None else \"\"\r\n            self.type = spec.type if spec.type is not None else type(spec.value) if spec.value is not None else int\r\n            self.value = spec.value\r\n        else:\r\n            self.name, d = spec\r\n            self.caption = d.get(\"caption\", self.name)\r\n            self.toolTip = d.get(\"toolTip\", \"\")\r\n            t = self.type = d.get(\"type\", type(d[\"value\"]) if \"value\" in d else int)\r\n            if not t in (int, float, bool, str, list):\r\n                raise TypeError(\"Invalid type: '{0!s}'\".format(t.__name__))\r\n            self.value = d.get(\"value\")\r\n\r\n        if self.value is None:\r\n            self.value = 0 if self.type == int else \\\r\n                0. if self.type == float else \\\r\n                False if self.type == bool else \"\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RenderWidget(self):\r\n        t = self.type\r\n        if t == int:\r\n            ret = QSpinBox()\r\n            ret.setMaximum(999999999)\r\n            ret.setValue(self.value)\r\n        elif t == float:\r\n            ret = QLineEdit()\r\n            ret.setText(str(self.value))\r\n        elif t == bool:\r\n            ret = QCheckBox()\r\n            ret.setChecked(self.value)\r\n        else:  # str, list left\r\n            ret = QLineEdit()\r\n            ret.setText(str(self.value))\r\n\r\n        if self.toolTip is not None:\r\n            ret.setToolTip(self.toolTip)\r\n\r\n        self.widget = ret\r\n        return ret", "response": "Returns a subclass of QWidget subclass. Exact class depends on self. type"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating an infinite series of rectangular phase screens", "response": "def ScreenGenerator(nfft, r0, nx, ny):\n    \"\"\"Generate an infinite series of rectangular phase screens\n    Uses an FFT screen generator to make a large screen and then\n    returns non-overlapping subsections of it\"\"\"\n    while 1:\n        layers = GenerateTwoScreens(nfft, r0)\n        for iLayer in range(2):\n            for iy in range(int(nfft/ny)):\n                for ix in range(int(nfft/nx)):\n                    yield layers[iLayer][iy*ny:iy*ny+ny, ix*nx:ix*nx+nx]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing one or more dates from d", "response": "def parse_dates(d, default='today'):\n    \"\"\" Parses one or more dates from d \"\"\"\n\n    if default == 'today':\n        default = datetime.datetime.today()\n\n    if d is None:\n        return default\n\n    elif isinstance(d, _parsed_date_types):\n        return d\n\n    elif is_number(d):\n        # Treat as milliseconds since 1970\n        d = d if isinstance(d, float) else float(d)\n        return datetime.datetime.utcfromtimestamp(d)\n\n    elif not isinstance(d, STRING_TYPES):\n        if hasattr(d, '__iter__'):\n            return [parse_dates(s, default) for s in d]\n        else:\n            return default\n\n    elif len(d) == 0:\n        # Behaves like dateutil.parser < version 2.5\n        return default\n\n    else:\n        try:\n            return parser.parse(d)\n        except (AttributeError, ValueError):\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef load_with_classes(filename, classes):\n\n    ok = False\n    for class_ in classes:\n        obj = class_()\n        try:\n            obj.load(filename)\n            ok = True\n        # # cannot let IOError through because pyfits raises IOError!!\n        # except IOError:\n        #     raise\n        # # also cannot let OSError through because astropy.io.fits raises OSError!!\n        # except OSError:\n        #     raise\n        except FileNotFoundError:\n            raise\n        except Exception as e:  # (ValueError, NotImplementedError):\n            # Note: for debugging, switch the below to True\n            if a99.logging_level == logging.DEBUG:\n                a99.get_python_logger().exception(\"Error trying with class \\\"{0!s}\\\"\".format(\n                                              class_.__name__))\n            pass\n        if ok:\n            break\n    if ok:\n        return obj\n    return None", "response": "Attempts to load a file by trial - and - error using a given list of classes."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_any_file(filename):\n    import f311\n\n    # Splits attempts using ((binary X text) file) criterion\n    if a99.is_text_file(filename):\n        return load_with_classes(filename, f311.classes_txt())\n    else:\n        return load_with_classes(filename, f311.classes_bin())", "response": "Attempts to load filename by trial - and - error\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a single spectrum from a file.", "response": "def load_spectrum(filename):\n    \"\"\"\n    Attempts to load spectrum as one of the supported types.\n\n    Returns:\n        a Spectrum, or None\n    \"\"\"\n    import f311\n\n    f = load_with_classes(filename, f311.classes_sp())\n    if f:\n        return f.spectrum\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a FITS file spectrum that does not have the proper headers. Returns a Spectrum object.", "response": "def load_spectrum_fits_messed_x(filename, sp_ref=None):\n    \"\"\"Loads FITS file spectrum that does not have the proper headers. Returns a Spectrum\"\"\"\n    import f311.filetypes as ft\n\n    # First tries to load as usual\n    f = load_with_classes(filename, (ft.FileSpectrumFits,))\n\n    if f is not None:\n        ret = f.spectrum\n    else:\n        hdul = fits.open(filename)\n\n        hdu = hdul[0]\n        if not hdu.header.get(\"CDELT1\"):\n            hdu.header[\"CDELT1\"] = 1 if sp_ref is None else sp_ref.delta_lambda\n        if not hdu.header.get(\"CRVAL1\"):\n            hdu.header[\"CRVAL1\"] = 0 if sp_ref is None else sp_ref.x[0]\n\n        ret = ft.Spectrum()\n        ret.from_hdu(hdu)\n        ret.filename = filename\n        original_shape = ret.y.shape  # Shape of data before squeeze\n        # Squeezes to make data of shape e.g. (1, 1, 122) into (122,)\n        ret.y = ret.y.squeeze()\n\n        if len(ret.y.shape) > 1:\n            raise RuntimeError(\n                \"Data contains more than 1 dimension (shape is {0!s}), \"\n                \"FITS file is not single spectrum\".format(original_shape))\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of FileTypeInfo objects for all available data types.", "response": "def get_filetypes_info(editor_quote=\"`\", flag_leaf=True):\n    \"\"\"\n    Reports available data types\n\n    Args:\n        editor_quote: character to enclose the name of the editor script between.\n        flag_leaf: see tabulate_filetypes_rest()\n\n    Returns:\n        list: list of FileTypeInfo\n    \"\"\"\n    NONE_REPL = \"\"\n    import f311\n    data = []  # [FileTypeInfo, ...]\n\n    for attr in f311.classes_file(flag_leaf):\n        description = a99.get_obj_doc0(attr)\n\n        def_ = NONE_REPL if attr.default_filename is None else attr.default_filename\n        ee = attr.editors\n        if ee is None:\n            ee = NONE_REPL\n        else:\n            # Example: \"``mained.py``, ``x.py``\"\n            ee = \", \".join([\"{0}{1}{0}\".format(editor_quote, x, editor_quote) for x in ee])\n\n        data.append({\"description\": description, \"default_filename\": def_, \"classname\": attr.__name__,\n                     \"editors\": ee, \"class\": attr, \"txtbin\": \"text\" if attr.flag_txt else \"binary\"})\n\n    data.sort(key=lambda x: x[\"description\"])\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts filetype information to a list of rows and header.", "response": "def filetypes_info_to_rows_header(infos, attrnames=None, header=None, flag_wrap_description=False,\n                                  description_width=40):\n    \"\"\"\n    Converts filetype information to a (multiline_rows, header) tuple that can be more easily be tabulated\n\n    **Attention** uses ReST syntax, using a \"|br|\" marker for line break. It requires the .rst source\n                  file to contain the following bit:\n\n        .. |br| raw:: html\n\n           <br />\n\n    Args:\n        infos: list of FileTypeInfo\n        attrnames: list of attribute names (keys of FILE_TYPE_INFO_ATTRS).\n                   Defaults to all attributes\n        header: list of strings containing headers. If not passed, uses default names\n        flag_wrap_description: whether to wrap the description text\n        description_width: width to wrap the description text (effective only if\n                           flag_wrap_description is True)\n\n    Returns:\n        tuple: (rows, header): rows is a list of lists\n    \"\"\"\n\n    if attrnames is None:\n        attrnames = FILE_TYPE_INFO_ATTRS.keys()\n    if header is None:\n        header = [FILE_TYPE_INFO_ATTRS[key] for key in attrnames]\n\n    if flag_wrap_description:\n        wr = textwrap.TextWrapper(width=description_width, subsequent_indent=\"|br| \")\n\n    data = []\n    for i, info in enumerate(infos):\n        row = []\n        for j, attrname in enumerate(attrnames):\n            if attrname != \"description\" or not flag_wrap_description:\n                row.append(info[attrname])\n            else:\n                row.append(wr.wrap(info[attrname]))\n        data.append(row)\n\n    return data, header"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tabulate_filetypes_rest(attrnames=None, header=None, flag_wrap_description=True,\n                            description_width=40, flag_leaf=True):\n    \"\"\"\n    Generates a reST multirow table\n\n    Args:\n        attrnames: list of attribute names (keys of FILE_TYPE_INFO_ATTRS).\n                   Defaults to all attributes\n        header: list of strings containing headers. If not passed, uses default names\n        flag_wrap_description: whether to wrap the description text\n        description_width: width to wrap the description text (effective only if\n                           flag_wrap_description is True)\n        flag_leaf: returns only classes that do not have subclasses\n                   (\"leaf\" nodes as in a class tree graph)\n    \"\"\"\n\n    infos = get_filetypes_info(editor_quote=\"``\", flag_leaf=flag_leaf)\n    rows, header = filetypes_info_to_rows_header(infos, attrnames, header, flag_wrap_description,\n                                                 description_width)\n    ret = a99.rest_table(rows, header)\n    return ret", "response": "Returns a reST multirow table of filetypes for a given resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_all_payment_sources(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_payment_sources_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_payment_sources_with_http_info(**kwargs)\n            return data", "response": "List PaymentSources with the specified attributes"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the return_action of this ReturnSettings.", "response": "def return_action(self, return_action):\n        \"\"\"Sets the return_action of this ReturnSettings.\n\n\n        :param return_action: The return_action of this ReturnSettings.\n        :type: str\n        \"\"\"\n        allowed_values = [\"refund\", \"storeCredit\"]  # noqa: E501\n        if return_action is not None and return_action not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `return_action` ({0}), must be one of {1}\"  # noqa: E501\n                .format(return_action, allowed_values)\n            )\n\n        self._return_action = return_action"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a reduced unit rule based on sequence of unit rules and end rules.", "response": "def _create_rule(path, rule):\n    # type: (List[Type[Rule]], Type[Rule]) -> Type[ReducedUnitRule]\n    \"\"\"\n    Create ReducedUnitRule based on sequence of unit rules and end, generating rule.\n    :param path: Sequence of unit rules.\n    :param rule: Rule that is attached after sequence of unit rules.\n    :return: ReducedUnitRule class.\n    \"\"\"\n    created = type('Reduced[' + rule.__name__ + ']',\n                   (ReducedUnitRule,),\n                   ReducedUnitRule.__dict__.copy())  # type: Type[ReducedUnitRule]\n    created.rule = ([path[0].fromSymbol], rule.right)\n    created.end_rule = rule\n    created.by_rules = path\n    return created"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_unit_rules(grammar, inplace=False):\n    # type: (Grammar, bool) -> Grammar\n    \"\"\"\n    Remove unit rules from the grammar.\n    :param grammar: Grammar where remove the rules.\n    :param inplace: True if transformation should be performed in place. False by default.\n    :return: Grammar without unit rules.\n    \"\"\"\n    # copy if needed\n    if inplace is False:\n        grammar = copy(grammar)\n    # get connections\n    res = find_nonterminals_reachable_by_unit_rules(grammar)\n    # iterate through rules\n    for rule in grammar.rules.copy():\n        # delete unit rules\n        if _is_unit(rule):\n            grammar.rules.remove(rule)\n            continue\n        for nonterm in grammar.nonterminals:\n            # find all nonterminals that can rewrite to current rule\n            path = res.path_rules(nonterm, rule.fromSymbol)\n            # get rid of cyclic paths\n            if len(path) > 0 and path[0].fromSymbol != path[-1].toSymbol:\n                created = _create_rule(path, rule)\n                grammar.rules.add(created)\n    return grammar", "response": "Removes unit rules from the grammar."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nshow the current configuration.", "response": "def show_config(config):\n    \"\"\"Show the current configuration.\"\"\"\n    print(\"\\nCurrent Configuration:\\n\")\n    for k, v in sorted(config.config.items()):\n        print(\"{0:15}: {1}\".format(k, v))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattempts to create the user on the cloud node.", "response": "def create_cloud_user(cfg, args):\n    \"\"\"Attempt to create the user on the cloud node.\"\"\"\n    url = cfg['api_server'] + \"admin/add-user\"\n    params = {'user_email': args.user_email, 'user_name': args.user_name,\n              'user_role': args.user_role, 'email': cfg['email'],\n              'api_key': cfg['api_key']}\n    headers = {'Content-Type': 'application/json'}\n    response = requests.post(url, data=json.dumps(params),\n                             headers=headers)\n    if response.status_code not in range(200, 299):\n        raise Exception(\"Errors contacting the cloud node: %s\" % (response.content))\n    loaded = json.loads(response.content)\n    return loaded"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngive a mysql query, read the data from the database and return the results as a list of dictionaries (database rows) **Key Arguments:** - ``log`` -- the logger. - ``sqlQuery`` -- the MySQL command to execute - ``dbConn`` -- the db connection - ``quiet`` -- ignore mysql warnings and errors and move on. Be careful when setting this to true - damaging errors can easily be missed. Default *False*. **Return:** - ``rows`` -- the rows returned by the sql query **Usage:** .. code-block:: python from fundamentals.mysql import readquery rows = readquery( log=log, sqlQuery=sqlQuery, dbConn=dbConn, quiet=False )", "response": "def readquery(\n        sqlQuery,\n        dbConn,\n        log,\n        quiet=False):\n    \"\"\"Given a mysql query, read the data from the database and return the results as a list of dictionaries (database rows)\n\n    **Key Arguments:**\n        - ``log`` -- the logger.\n        - ``sqlQuery`` -- the MySQL command to execute\n        - ``dbConn`` -- the db connection\n        - ``quiet`` -- ignore mysql warnings and errors and move on. Be careful when setting this to true - damaging errors can easily be missed. Default *False*.\n\n    **Return:**\n        - ``rows`` -- the rows returned by the sql query\n\n    **Usage:**\n\n        .. code-block:: python\n\n            from fundamentals.mysql import readquery\n            rows = readquery(\n                log=log,\n                sqlQuery=sqlQuery,\n                dbConn=dbConn,\n                quiet=False\n            )\n    \"\"\"\n    log.debug('starting the ``readquery`` function')\n    import pymysql\n    import warnings\n    warnings.filterwarnings('error', category=pymysql.Warning)\n\n    rows = []\n\n    try:\n        cursor = dbConn.cursor(pymysql.cursors.DictCursor)\n    except Exception as e:\n        log.error('could not create the database cursor: %s' % (e, ))\n        raise IOError('could not create the database cursor: %s' % (e, ))\n    # EXECUTE THE SQL COMMAND\n    cursor.execute(sqlQuery)\n    rows = cursor.fetchall()\n    try:\n        cursor.execute(sqlQuery)\n        rows = cursor.fetchall()\n    except Exception as e:\n        sqlQuery = sqlQuery[:1000]\n        if quiet == False:\n            log.warning(\n                'MySQL raised an error - read command not executed.\\n' + str(e) + '\\nHere is the sqlQuery\\n\\t%(sqlQuery)s' % locals())\n            raise e\n\n    # CLOSE THE CURSOR\n    try:\n        cursor.close()\n    except Exception as e:\n        log.warning('could not close the db cursor ' + str(e) + '\\n')\n\n    log.debug('completed the ``readquery`` function')\n    return rows"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the caption of the page", "response": "def update_caption(self, mouse):\n        \"\"\" \u6dfb\u52a0\u5750\u6807\u663e\u793a \"\"\"\n        caption = \"{}  x: {}, y: {}\".format(self._title, mouse.x, mouse.y)\n        super().set_caption(caption)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef make_store(name, min_length=4, **kwargs):\n  \n   if name not in stores:\n      raise ValueError('valid stores are {0}'.format(', '.join(stores)))\n\n   if name == 'memcache':\n      store = MemcacheStore\n   elif name == 'memory':\n      store = MemoryStore\n   elif name == 'redis':\n      store = RedisStore\n\n   return store(min_length=min_length, **kwargs)", "response": "\\ Returns a new store with a reasonable keygen."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies packages between reposCopy SOURCE DESTINATION where SOURCE can be either LOCAL - FILE REPO - PACKAGE - SPEC - DESTINATION or REPO - DIR - DESTINATION", "response": "def do_copy(self, line):\n        '''\n        Copy packages between repos\n\n          copy SOURCE DESTINATION\n\n        Where SOURCE can be either LOCAL-FILE or REPO:PACKAGE-SPEC\n        DESTINATION can be either a REPO: or a directory.\n        '''\n        words = line.split()\n        source, destination = words\n        destination_repo = self._get_destination_repo(destination)\n        local_file_source = ':' not in source\n\n        if local_file_source:\n            destination_repo.upload_packages([source])\n        else:\n            source_repo_name, _, package_spec = source.partition(':')\n            try:\n                source_repo = self.network.get_repo(source_repo_name)\n            except UnknownRepoError:\n                raise ShellError(\n                    'Unknown repository {}'.format(source_repo_name)\n                )\n\n            # copy between repos with the help of temporary storage\n            try:\n                source_repo.download_packages(package_spec, self.__temp_dir)\n                destination_repo.upload_packages(self.__temp_dir.files)\n            finally:\n                self.__temp_dir.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking repo the active one and set the active_repo property.", "response": "def do_work_on(self, repo):\n        '''\n        Make repo the active one.\n        Commands working on a repo will use it as default for repo parameter.\n        '''\n        self.abort_on_nonexisting_repo(repo, 'work_on')\n        self.network.active_repo = repo"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_http_repo(self, repo):\n        '''\n        [Re]define REPO as http package repository.\n\n        http_repo REPO\n        '''\n        self.abort_on_missing_effective_repo_name(repo, 'http_repo')\n        repo_name = self.get_effective_repo_name(repo)\n        try:\n            self.network.set(repo_name, REPO.TYPE, REPOTYPE.HTTP)\n        except UnknownRepoError:\n            self.network.define_http_repo(repo_name)\n        self.network.active_repo = repo_name", "response": "This method is used to set the HTTP repository for the current active class."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef do_directory_repo(self, repo):\n        '''\n        [Re]define REPO as directory package repository.\n\n        directory_repo REPO\n        '''\n        self.abort_on_missing_effective_repo_name(repo, 'directory_repo')\n        repo_name = self.get_effective_repo_name(repo)\n        try:\n            self.network.set(repo_name, REPO.TYPE, REPOTYPE.DIRECTORY)\n        except UnknownRepoError:\n            self.network.define_directory_repo(repo_name)\n        self.network.active_repo = repo_name", "response": "This method is used to set the REPO as directory package repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nshowing python packaging configuration status", "response": "def do_status(self, line):\n        '''\n        Show python packaging configuration status\n        '''\n        # Pyrene version\n        print('{} {}'.format(bold('Pyrene version'), green(get_version())))\n\n        # .pip/pip.conf - Pyrene repo name | exists or not\n        pip_conf = os.path.expanduser('~/.pip/pip.conf')\n        if os.path.exists(pip_conf):\n            conf = read_file(pip_conf)\n            repo = self._get_repo_for_pip_conf(conf)\n            if repo:\n                print(\n                    '{} is configured for repository \"{}\"'\n                    .format(bold(pip_conf), green(repo.name))\n                )\n            else:\n                print(\n                    '{} exists, but is a {}'\n                    .format(bold(pip_conf), red('custom configuration'))\n                )\n        else:\n            print('{} {}'.format(bold(pip_conf), red('does not exists')))\n\n        # existence of ~/.pypirc\n        if os.path.exists(self.pypirc):\n            template = green('exists')\n        else:\n            template = red('does not exists')\n        template = '{} ' + template\n        print(template.format(bold(self.pypirc)))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef do_forget(self, repo):\n        '''\n        Drop definition of a repo.\n\n        forget REPO\n        '''\n        self.abort_on_nonexisting_repo(repo, 'forget')\n        self.network.forget(repo)", "response": "Drop definition of a repo. forget REPO\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_set(self, line):\n        '''\n        Set repository attributes on the active repo.\n\n        set attribute=value\n\n        # intended use:\n\n        # directory repos:\n        work_on developer-repo\n        set type=directory\n        set directory=package-directory\n\n        # http repos:\n        work_on company-private-repo\n        set type=http\n        set download-url=http://...\n        set upload-url=http://...\n        set username=user\n        set password=pass\n        '''\n        self.abort_on_invalid_active_repo('set')\n        repo = self.network.active_repo\n        attribute, eq, value = line.partition('=')\n        if not attribute:\n            raise ShellError('command \"set\" requires a non-empty attribute')\n        if not eq:\n            raise ShellError('command \"set\" requires a value')\n        self.network.set(repo, attribute, value)", "response": "Set the active repo attributes on the active repo."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists the known repos", "response": "def do_list(self, line):\n        '''\n        List known repos\n        '''\n        repo_names = self.network.repo_names\n        print('Known repos:')\n        print('    ' + '\\n    '.join(repo_names))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nshow the attributes of the specified repository.", "response": "def do_show(self, repo):\n        '''\n        List repo attributes\n        '''\n        self.abort_on_nonexisting_effective_repo(repo, 'show')\n\n        repo = self.network.get_repo(repo)\n        repo.print_attributes()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures repo to point to the default package index https://pypi.python.org.", "response": "def do_setup_for_pypi_python_org(self, repo):\n        '''\n        Configure repo to point to the default package index\n        https://pypi.python.org.\n        '''\n        effective_repo_name = self.get_effective_repo_name(repo)\n        self.abort_on_nonexisting_repo(\n            effective_repo_name, 'setup_for_pypi_python_org'\n        )\n\n        self.network.setup_for_pypi_python_org(effective_repo_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_setup_for_pip_local(self, repo):\n        '''\n        Configure repo to be directory based with directory `~/.pip/local`.\n        Also makes that directory if needed.\n        '''\n        effective_repo_name = self.get_effective_repo_name(repo)\n        self.abort_on_nonexisting_repo(\n            effective_repo_name, 'setup_for_pip_local'\n        )\n\n        self.network.setup_for_pip_local(effective_repo_name)", "response": "Configure the repository to be directory based with directory ~. pip. local."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserving a local directory over http as a package index.", "response": "def do_serve(self, repo_name):\n        '''\n        Serve a local directory over http as a package index (like pypi).\n        Intended for quick package exchanges.\n        '''\n        self.abort_on_nonexisting_effective_repo(repo_name, 'serve')\n\n        repo = self.network.get_repo(repo_name)\n        repo.serve()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(filename,\n            num_questions=None,\n            solution=False,\n            pages_per_q=DEFAULT_PAGES_PER_Q,\n            folder='question_pdfs',\n            output='gradescope.pdf',\n            zoom=1):\n    \"\"\"\n    Public method that exports nb to PDF and pads all the questions.\n\n    If num_questions is specified, will also check the final PDF for missing\n    questions.\n\n    If the output font size is too small/large, increase or decrease the zoom\n    argument until the size looks correct.\n\n    If solution=True, we'll export solution cells instead of student cells. Use\n    this option to generate the solutions to upload to Gradescope.\n    \"\"\"\n    check_for_wkhtmltohtml()\n    save_notebook(filename)\n\n    nb = read_nb(filename, solution=solution)\n    pdf_names = create_question_pdfs(nb,\n                                     pages_per_q=pages_per_q,\n                                     folder=folder,\n                                     zoom=zoom)\n    merge_pdfs(pdf_names, output)\n\n    # The first pdf generated is the email PDF\n    n_questions_found = len(pdf_names) - 1\n    if num_questions is not None and n_questions_found != num_questions:\n        logging.warning(\n            'We expected there to be {} questions but there are only {} in '\n            'your final PDF. Gradescope will most likely not accept your '\n            'submission. Double check that you wrote your answers in the '\n            'cells that we provided.'\n            .format(num_questions, len(pdf_names))\n        )\n\n    try:\n        from IPython.display import display, HTML\n        display(HTML(DOWNLOAD_HTML.format(output)))\n    except ImportError:\n        print('Done! The resulting PDF is located in this directory and is '\n              'called {}. Upload that PDF to Gradescope for grading.'\n              .format(output))\n        print()\n\n    print('If the font size of your PDF is too small/large, change the value '\n          'of the zoom argument when calling convert. For example, setting '\n          'zoom=2 makes everything twice as big.')", "response": "Convert a notebook to a PDF."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if the wkhtmltohtml binary is installed. Raises error if not.", "response": "def check_for_wkhtmltohtml():\n    \"\"\"\n    Checks to see if the wkhtmltohtml binary is installed. Raises error if not.\n    \"\"\"\n    locator = 'where' if sys.platform == 'win32' else 'which'\n\n    wkhtmltopdf = (subprocess.Popen([locator, 'wkhtmltopdf'],\n                                    stdout=subprocess.PIPE)\n                   .communicate()[0].strip())\n\n    if not os.path.exists(wkhtmltopdf):\n        logging.error(\n            'No wkhtmltopdf executable found. Please install '\n            'wkhtmltopdf before trying again - {}'.format(WKHTMLTOPDF_URL))\n        raise ValueError(\n            'No wkhtmltopdf executable found. Please install '\n            'wkhtmltopdf before trying again - {}'.format(WKHTMLTOPDF_URL))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching for the OkPy - generated string that contains the email address of the student.", "response": "def find_student_email(nb) -> str:\n    '''\n    Looks for the OkPy-generated string:\n\n    \"Successfully logged in as <email>\"\n\n    and returns the email address.\n\n    Raises a ValueError if email not found.\n    '''\n    search = 'Successfully logged in as '\n\n    cells = [cell for cell in nb.cells if 'outputs' in cell]\n    for cell in cells:\n        for output in cell.outputs:\n            if 'text' in output and search in output.text:\n                return output.text.split(search)[1].strip()\n    raise ValueError('Error: was not able to get email from ok.auth() cell.'\n                     'Please run that cell and try again.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a notebook file and returns a notebook object containing only the cell outputs to export.", "response": "def read_nb(filename, solution) -> nbformat.NotebookNode:\n    \"\"\"\n    Takes in a filename of a notebook and returns a notebook object containing\n    only the cell outputs to export.\n    \"\"\"\n    with open(filename, 'r') as f:\n        nb = nbformat.read(f, as_version=4)\n\n    email = find_student_email(nb)\n    preamble = nbformat.v4.new_markdown_cell(\n        source='# ' + email, metadata={'tags': ['q_email']})\n\n    tags_to_check = TAGS if not solution else SOL_TAGS\n    cells = ([preamble] +\n             [remove_input(cell) for cell in nb['cells']\n              if cell_has_tags(cell, tags_to_check)])\n\n    nb['cells'] = cells\n    return nb"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef nb_to_html_cells(nb) -> list:\n    html_exporter = HTMLExporter()\n    html_exporter.template_file = 'basic'\n\n    (body, resources) = html_exporter.from_notebook_node(nb)\n    return BeautifulSoup(body, 'html.parser').findAll('div', class_='cell')", "response": "Converts a notebook to an iterable of BS4 HTML cells."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nb_to_q_nums(nb) -> list:\n    def q_num(cell):\n        assert cell.metadata.tags\n        return first(filter(lambda t: 'q' in t, cell.metadata.tags))\n\n    return [q_num(cell) for cell in nb['cells']]", "response": "Converts a notebook to a list of question numbers."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npadding the PDF file with blank pages if necessary.", "response": "def pad_pdf_pages(pdf_name, pages_per_q) -> None:\n    \"\"\"\n    Checks if PDF has the correct number of pages. If it has too many, warns\n    the user. If it has too few, adds blank pages until the right length is\n    reached.\n    \"\"\"\n    pdf = PyPDF2.PdfFileReader(pdf_name)\n    output = PyPDF2.PdfFileWriter()\n    num_pages = pdf.getNumPages()\n    if num_pages > pages_per_q:\n        logging.warning('{} has {} pages. Only the first '\n                        '{} pages will get output.'\n                        .format(pdf_name, num_pages, pages_per_q))\n\n    # Copy over up to pages_per_q pages\n    for page in range(min(num_pages, pages_per_q)):\n        output.addPage(pdf.getPage(page))\n\n    # Pad if necessary\n    if num_pages < pages_per_q:\n        for page in range(pages_per_q - num_pages):\n            output.addBlankPage()\n\n    # Output the PDF\n    with open(pdf_name, 'wb') as out_file:\n        output.write(out_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconvert each cell in tbe notebook to a PDF named something like q04c. pdf. Places PDFs in the specified folder and returns the list of PDFs created in the specified folder.", "response": "def create_question_pdfs(nb, pages_per_q, folder, zoom) -> list:\n    \"\"\"\n    Converts each cells in tbe notebook to a PDF named something like\n    'q04c.pdf'. Places PDFs in the specified folder and returns the list of\n    created PDF locations.\n    \"\"\"\n    html_cells = nb_to_html_cells(nb)\n    q_nums = nb_to_q_nums(nb)\n\n    os.makedirs(folder, exist_ok=True)\n\n    pdf_options = PDF_OPTS.copy()\n    pdf_options['zoom'] = ZOOM_FACTOR * zoom\n\n    pdf_names = []\n    for question, cell in zip(q_nums, html_cells):\n        # Create question PDFs\n        pdf_name = os.path.join(folder, '{}.pdf'.format(question))\n\n        pdfkit.from_string(cell.prettify(), pdf_name, options=pdf_options)\n\n        pad_pdf_pages(pdf_name, pages_per_q)\n\n        print('Created ' + pdf_name)\n        pdf_names.append(pdf_name)\n    return pdf_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge all pdfs together into a single long PDF.", "response": "def merge_pdfs(pdf_names, output) -> None:\n    \"\"\"\n    Merges all pdfs together into a single long PDF.\n    \"\"\"\n    merger = PyPDF2.PdfFileMerger()\n\n    for filename in pdf_names:\n        merger.append(filename)\n    merger.write(output)\n    merger.close()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_item_abspath(self, identifier):\n\n        dataset_cache_abspath = os.path.join(\n            self._cache_abspath,\n            self.uuid\n        )\n        mkdir_parents(dataset_cache_abspath)\n\n        manifest = self.get_manifest()\n        relpath = manifest['items'][identifier]['relpath']\n        _, ext = os.path.splitext(relpath)\n\n        local_item_abspath = os.path.join(\n            dataset_cache_abspath,\n            identifier + ext\n        )\n\n        if not os.path.isfile(local_item_abspath):\n\n            url = self.http_manifest[\"item_urls\"][identifier]\n\n            r = self._get_request(url, stream=True)\n            tmp_local_item_abspath = local_item_abspath + \".tmp\"\n            with open(tmp_local_item_abspath, 'wb') as f:\n                shutil.copyfileobj(r.raw, f)\n            os.rename(tmp_local_item_abspath, local_item_abspath)\n\n        return local_item_abspath", "response": "Return absolute path at which the item content can be accessed."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the overlay as a dictionary.", "response": "def get_overlay(self, overlay_name):\n        \"\"\"Return overlay as a dictionary.\n\n        :param overlay_name: name of the overlay\n        :returns: overlay as a dictionary\n        \"\"\"\n        url = self.http_manifest[\"overlays\"][overlay_name]\n        return self._get_json_from_url(url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SQLarray_fromfile(filename, **kwargs):\n\n    Table2array = {'rst': rest_table.Table2array,\n                   'txt': rest_table.Table2array,\n                   'csv': csv_table.Table2array,\n                   }\n    # see convert.Autoconverter for the kwargs; *active*/*autoconvert*\n    # is for the Table2array class\n    _kwnames = ('active', 'autoconvert', 'mode', 'mapping', 'sep')\n    kwargsT2a = dict((k,kwargs.pop(k))  for k in _kwnames if k in kwargs)\n    kwargsT2a.setdefault('mode', 'singlet')\n    # Note: sep=False is the only sane choice because we cannot deal  yet\n    #       with numpy list structures for import into the db\n    kwargsT2a['sep'] = False\n\n    root, ext = os.path.splitext(filename)\n    if ext.startswith('.'):\n        ext = ext[1:]\n    ext = ext.lower()\n    kwargsT2a['filename'] = filename\n    t = Table2array[ext](**kwargsT2a)\n    kwargs.setdefault('name', t.tablename)\n    kwargs['columns'] = t.names\n    kwargs['records'] = t.records    # use records to have sqlite do type conversion\n    return SQLarray(**kwargs)", "response": "Create a SQLarray from a file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the number of currently open connections to the database.", "response": "def connection_count(self):\n        \"\"\"Number of currently open connections to the database.\n\n        (Stored in table sqlarray_master.)\n        \"\"\"\n        return self.sql(\"SELECT value FROM %(master)s WHERE name = 'connection_counter'\" % vars(self),\n                        cache=False, asrecarray=False)[0][0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef merge(self,recarray,columns=None):\n        len_before = len(self)\n        #  CREATE TEMP TABLE in database\n        tmparray = SQLarray(self.tmp_table_name, records=recarray, columns=columns,\n                            connection=self.connection, is_tmp=True)\n        len_tmp = len(tmparray)\n        # insert into main table\n        SQL = \"\"\"INSERT OR ABORT INTO __self__ SELECT * FROM %s\"\"\" % self.tmp_table_name\n        self.sql(SQL)\n        len_after = len(self)\n        n_inserted = len_after - len_before\n        assert len_tmp == n_inserted\n        del tmparray          # also drops the tmp table (keep it at end for debugging)\n        return n_inserted", "response": "Merge another numpy record array into this table."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmerge an existing table in the database with the name name.", "response": "def merge_table(self,name):\n        \"\"\"Merge an existing table in the database with the __self__ table.\n\n        Executes as ``'INSERT INTO __self__ SELECT * FROM <name>'``.\n        However, this method is probably used less often than the simpler :meth:`merge`.\n\n        :Arguments:\n           name         name of the table in the database (must be compatible with __self__)\n\n        :Returns:\n           n            number of inserted rows\n        \"\"\"\n        l_before = len(self)\n        SQL = \"\"\"INSERT OR ABORT INTO __self__ SELECT * FROM %s\"\"\" % name\n        self.sql(SQL)\n        l_after = len(self)\n        return l_after - l_before"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sql_index(self,index_name,column_names,unique=True):\n        if type(column_names) == str:\n            column_names = [column_names]\n        try:\n            if len(column_names) == 0:\n                raise TypeError\n        except TypeError:\n            raise ValueError(\"Provide a list of column names for an index.\")\n        if unique:\n            UNIQUE = \"UNIQUE\"\n        else:\n            UNIQUE = \"\"\n        table_name = self.name\n        columns = \",\".join(column_names)\n        SQL = \"\"\"CREATE %(UNIQUE)s INDEX %(index_name)s ON %(table_name)s \"\"\"\\\n            \"\"\"(%(columns)s)\"\"\" % locals()\n        self.sql(SQL)", "response": "Add a named index on given columns to improve performance."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a simple SQL SELECT statement and returns values as numpy recarray.", "response": "def sql_select(self,fields,*args,**kwargs):\n        \"\"\"Execute a simple SQL ``SELECT`` statement and returns values as new numpy rec array.\n\n        The arguments *fields* and the additional optional arguments\n        are simply concatenated with additional SQL statements\n        according to the template::\n\n           SELECT <fields> FROM __self__ [args]\n\n        The simplest fields argument is ``\"*\"``.\n\n        Example:\n           Create a recarray in which students with average grade less than\n           3 are listed::\n\n             result = T.SELECT(\"surname, subject, year, avg(grade) AS avg_grade\",\n                            \"WHERE avg_grade < 3\", \"GROUP BY surname,subject\",\n                            \"ORDER BY avg_grade,surname\")\n\n           The resulting SQL would be::\n\n             SELECT surname, subject, year, avg(grade) AS avg_grade FROM __self__\n                  WHERE avg_grade < 3\n                  GROUP BY surname,subject\n                  ORDER BY avg_grade,surname\n\n           Note how one can use aggregate functions such avg().\n\n           The string *'__self__'* is automatically replaced with the table\n           name (``T.name``); this can be used for cartesian products such as ::\n\n              LEFT JOIN __self__ WHERE ...\n\n        .. Note:: See the documentation for :meth:`~SQLarray.sql` for more details on\n                  the available keyword arguments and the use of ``?`` parameter\n                  interpolation.\n        \"\"\"\n        SQL = \"SELECT \"+str(fields)+\" FROM __self__ \"+ \" \".join(args)\n        return self.sql(SQL,**kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexecute a SQL statement and return the result as a numpy. recarray.", "response": "def sql(self,SQL,parameters=None,asrecarray=True,cache=True):\n        \"\"\"Execute sql statement.\n\n        :Arguments:\n           SQL : string\n              Full SQL command; can contain the ``?`` place holder so that values\n              supplied with the ``parameters`` keyword can be interpolated using\n              the ``pysqlite`` interface.\n           parameters : tuple\n              Parameters for ``?`` interpolation.\n           asrecarray : boolean\n              ``True``: return a ``numpy.recarray`` if possible;\n              ``False``: return records as a list of tuples. [``True``]\n           cache : boolean\n              Should the results be cached? Set to ``False`` for large queries to\n              avoid memory issues. Queries with ``?`` place holders are never cached.\n              [``True``]\n\n        :Returns:\n           For *asrecarray* = ``True`` a :class:`numpy.recarray` is returned; otherwise\n           a simple list of tuples is returned.\n\n        :Raises:\n           :exc:`TypeError` if the conversion to :class:`~numpy.recarray` fails for\n           any reason.\n\n        .. warning::\n\n           There are **no sanity checks** applied to the SQL.\n\n        The last *cachesize* queries are cached (for *cache* = ``True``) and\n        are returned directly unless the table has been modified.\n\n        The string \"__self__\" in *SQL* is substituted with the table name. See\n        the :meth:`SELECT` method for more details.\n        \"\"\"\n        SQL = SQL.replace('__self__',self.name)\n\n        # Cache the last N (query,result) tuples using a 'FIFO-dict'\n        # of length N, where key = SQL; if we can use the cache\n        # (cache=True) and if query in dict (AND cache\n        # valid, ie it hasn't been emptied (??)) just return cache result.\n        #\n        # Never use the cache if place holders are used because then we\n        # would return the same result for differing input!\n        if not '?' in SQL and cache and SQL in self.__cache:\n            return self.__cache[SQL]\n\n        c = self.cursor\n\n        if parameters is None:\n            c.execute(SQL)              # no sanity checks!\n        else:\n            c.execute(SQL, parameters)  # no sanity checks; params should be tuple\n\n        if c.rowcount > 0 or SQL.upper().find('DELETE') > -1:\n            # table was (potentially) modified\n            # rowcount does not change for DELETE, see\n            # http://oss.itsystementwicklung.de/download/pysqlite/doc/sqlite3.html#cursor-objects\n            # so we catch this case manually and invalidate the whole cache\n            self.__cache.clear()\n        result = c.fetchall()\n        if not result:\n            return []    # leaving here keeps cache invalidated\n        if asrecarray:\n            try:\n                names = [x[0] for x in c.description]   # first elements are column names\n                result = numpy.rec.fromrecords(result,names=names)\n            except:\n                raise TypeError(\"SQLArray.sql(): failed to return recarray, try setting asrecarray=False to return tuples instead\")\n        else:\n            pass      # keep as tuples/data structure as requested\n        if cache:\n            self.__cache.append(SQL,result)\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef limits(self,variable):\n        (vmin,vmax), = self.SELECT('min(%(variable)s), max(%(variable)s)' % vars())\n        return vmin,vmax", "response": "Return minimum and maximum of variable across all rows of data."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef selection(self, SQL, parameters=None, **kwargs):\n        # TODO: under development\n        # - could use VIEW\n\n        force = kwargs.pop('force', False)\n\n        # pretty unsafe... I hope the user knows what they are doing\n        # - only read data to first semicolon\n        # - here should be input scrubbing...\n        safe_sql = re.match(r'(?P<SQL>[^;]*)',SQL).group('SQL')\n\n        if re.match(r'\\s*SELECT.*FROM',safe_sql,flags=re.IGNORECASE):\n            _sql = safe_sql\n        else:\n            # WHERE clause only\n            _sql = \"\"\"SELECT * FROM __self__ WHERE \"\"\"+str(safe_sql)\n        # (note: MUST replace __self__  before md5!)\n        _sql = _sql.replace('__self__', self.name)\n        # unique name for table (unless user supplied... which could be 'x;DROP TABLE...')\n        newname = kwargs.pop('name', 'selection_'+md5(_sql).hexdigest())\n\n        if newname in (\"__self__\", self.name):\n            raise ValueError(\"Table name %(newname)r cannot refer to the parent table itself.\" % vars())\n        has_newname = self.has_table(newname)\n\n        c = self.cursor\n\n        if has_newname and force:\n            c.execute(\"DROP TABLE %(newname)s\" % vars())\n            has_newname = False\n\n        if not has_newname:\n            # create table directly\n            # SECURITY: unsafe tablename !!!! (but cannot interpolate?)\n            _sql = \"CREATE TABLE %(newname)s AS \" % vars() + _sql\n            if parameters is None:\n                c.execute(_sql)              # no sanity checks!\n            else:\n                c.execute(_sql, parameters)  # no sanity checks; params should be tuple\n\n        # associate with new table in db\n        return SQLarray(newname, None, dbfile=self.dbfile, connection=self.connection)", "response": "Return a new SQLarray from a SELECT selection."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize SQL functions to the database", "response": "def _init_sqlite_functions(self):\n        \"\"\"additional SQL functions to the database\"\"\"\n\n        self.connection.create_function(\"sqrt\", 1,sqlfunctions._sqrt)\n        self.connection.create_function(\"sqr\", 1,sqlfunctions._sqr)\n        self.connection.create_function(\"periodic\", 1,sqlfunctions._periodic)\n        self.connection.create_function(\"pow\", 2,sqlfunctions._pow)\n        self.connection.create_function(\"match\",2,sqlfunctions._match)\n        self.connection.create_function(\"regexp\",2,sqlfunctions._regexp)\n        self.connection.create_function(\"fformat\",2,sqlfunctions._fformat)\n        self.connection.create_aggregate(\"std\",1,sqlfunctions._Stdev)\n        self.connection.create_aggregate(\"stdN\",1,sqlfunctions._StdevN)\n        self.connection.create_aggregate(\"median\",1,sqlfunctions._Median)\n        self.connection.create_aggregate(\"array\",1,sqlfunctions._NumpyArray)\n        self.connection.create_aggregate(\"histogram\",4,sqlfunctions._NumpyHistogram)\n        self.connection.create_aggregate(\"distribution\",4,sqlfunctions._NormedNumpyHistogram)\n        self.connection.create_aggregate(\"meanhistogram\",5,sqlfunctions._MeanHistogram)\n        self.connection.create_aggregate(\"stdhistogram\",5,sqlfunctions._StdHistogram)\n        self.connection.create_aggregate(\"minhistogram\",5,sqlfunctions._MinHistogram)\n        self.connection.create_aggregate(\"maxhistogram\",5,sqlfunctions._MaxHistogram)\n        self.connection.create_aggregate(\"medianhistogram\",5,sqlfunctions._MedianHistogram)\n        self.connection.create_aggregate(\"zscorehistogram\",5,sqlfunctions._ZscoreHistogram)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if the table name * name* exists in the database.", "response": "def has_table(self, name):\n        \"\"\"Return ``True`` if the table *name* exists in the database.\"\"\"\n        return len(self.sql(\"SELECT name FROM sqlite_master WHERE type='table' AND name=?\",\n                            parameters=(name,), asrecarray=False, cache=False)) > 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef close(self):\n\n        self.__decrement_connection_counter()\n        if self.connection_count == 0:\n            if self.dbfile == \":memory:\":\n                SQL = \"\"\"DROP TABLE IF EXISTS __self__\"\"\"\n                self.sql(SQL, asrecarray=False, cache=False)\n            else:\n                self.connection.commit()\n                self.connection.close()", "response": "Closes the database connection."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nappending a new entry to the end of the ringbuffer.", "response": "def append(self,k,v):\n        \"\"\"x.append(k,v)\"\"\"\n        self.__ringbuffer.append(k)\n        super(KRingbuffer,self).__setitem__(k,v)\n        self._prune()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _prune(self):\n        delkeys = [k for k in self.keys() if k not in self.__ringbuffer]\n        for k in delkeys:  # necessary because dict is changed during iterations\n            super(KRingbuffer,self).__delitem__(k)", "response": "Primitive way to keep dict in sync with RB."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a bbl file to a CMY file.", "response": "def bbl_to_cys(bblfile:str, oriented:bool=False, width_as_cover:bool=True,\n               show_cover:str='cover: {}', false_edge_on_hover:bool=True,\n               default_poweredge_width:int=5):\n    \"\"\"Yield lines of js to write in output file\"\"\"\n    # False edges in clique\n    with open(bblfile) as fd:\n        falsedges = tuple(\n            (src, trg) for _, src, trg in\n            (l.strip().split('\\t') for l in fd if l.startswith('FALSEDGE'))\n        )\n    if false_edge_on_hover:\n        nodes_in_false_edges = set(itertools.chain.from_iterable(falsedges))\n    # Detect incomplete power edges\n    with open(bblfile) as fd:\n        falsepoweredges = {}\n        for line in fd:\n            if line.startswith('FALSEPOWEREDGE'):\n                _, seta, setb, src, trg = line.strip().split('\\t')\n                falsepoweredges.setdefault(frozenset((seta, setb)), set()).add((src, trg))\n                if false_edge_on_hover:\n                    nodes_in_false_edges.add(src)\n                    nodes_in_false_edges.add(trg)\n\n    # Build node hierarchy\n    tree = BubbleTree.from_bubble_file(bblfile, symmetric_edges=False, oriented=oriented)\n    def isclique(node): return node in tree.edges.get(node, ())\n    def handle_node(node, parent=None):\n        clique = isclique(node)\n        if false_edge_on_hover and clique:\n            falsedges = ((src, trg) for src, trg in itertools.combinations(tuple(tree.nodes_in(node)), r=2)\n                         if src in nodes_in_false_edges and trg in nodes_in_false_edges)\n        else: falsedges = ()\n        return JS_NODE_LINE(node, parent, clique=clique, falsedges=falsedges)\n\n    yield from JS_HEADER\n\n    for node in tree.roots:\n        yield handle_node(node)\n        yield JS_NODE_LINE(node, clique=isclique(node))\n    parents = reversed_graph(tree.inclusions)  # (power)node -> direct parent\n    for node, parents in parents.items():\n        assert len(parents) == 1, {node: parents}\n        yield handle_node(node, parent=next(iter(parents)))\n\n    yield from JS_MIDDLE\n\n    use_cover = width_as_cover or show_cover\n    if use_cover:\n        def coverof(source, target) -> int:\n            source_cover = sum(1 for _ in tree.nodes_in(source))\n            target_cover = sum(1 for _ in tree.nodes_in(target))\n            return (source_cover or 1) * (target_cover or 1)\n        def labelof(cover:int) -> str or None:\n            if cover > 1:  # it's a power edge\n                return show_cover.format(cover)\n    # Now, (power) edges\n    powernodes = frozenset(tree.powernodes())\n    for source, targets in tree.edges.items():\n        for target in targets:\n            if target == source:  continue  # cliques are not handled this way\n            label, attrs, isreflexive = None, {}, False\n            ispower = source in powernodes or target in powernodes\n            if use_cover:\n                cover = coverof(source, target)\n                label, attrs = labelof(cover), {'width': 2+cover if width_as_cover else default_poweredge_width}\n            if ispower and frozenset((source, target)) in falsepoweredges:\n                attrs['falsedges'] = list(map(list, falsepoweredges[frozenset((source, target))]))\n            yield ' '*8 + JS_EDGE_LINE(source, target, ispower, label=label, attrs=attrs)\n\n    # If asked so, add false edges in the file as regular edges\n    if not false_edge_on_hover:\n        for source, target in falsedges:\n            yield ' '*8 + JS_FALSEDGE_LINE(source, target)\n        for edges in falsepoweredges.values():\n            for source, target in edges:\n                yield ' '*8 + JS_FALSEDGE_LINE(source, target)\n\n    yield from JS_FOOTER\n\n    if false_edge_on_hover:\n        yield from JS_MOUSEOVER_SHOW_CALLBACKS\n    else:\n        yield from JS_MOUSEOVER_WIDTH_CALLBACKS"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunk_on(pipeline, new_chunk_signal, output_type=tuple):\n    ''' split the stream into seperate chunks based on a new chunk signal '''\n    assert iterable(pipeline), 'chunks needs pipeline to be iterable'\n    assert callable(new_chunk_signal), 'chunks needs new_chunk_signal to be callable'\n    assert callable(output_type), 'chunks needs output_type to be callable'\n    \n    out = deque()\n    for i in pipeline:\n        if new_chunk_signal(i) and len(out): # if new chunk start detected\n            yield output_type(out)\n            out.clear()\n        out.append(i)\n    # after looping, if there is anything in out, yield that too\n    if len(out):\n        yield output_type(out)", "response": "split the pipeline into seperate chunks based on a new chunk signal"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef repeat(f, dt=1/60):\n    stop(f)\n    pyglet.clock.schedule_interval(f, dt)", "response": "repeat f in a given dt"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef center_image(self, img):\n        img.anchor_x = img.width // 2 # int\n        img.anchor_y = img.height // 2", "response": "Sets an image s anchor point to its center"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_persons(self):\n        cs = self.data[\"to\"][\"data\"]\n        res = [] \n        for c in cs:\n            res.append(c[\"name\"])\n        return res", "response": "Returns list of strings which represents persons being chated with \n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of Message objects which represents messages being transported.", "response": "def get_messages(self):\n        \"\"\"\n        Returns list of Message objects which represents messages being transported.\n        \"\"\"\n        cs = self.data[\"comments\"][\"data\"]\n        res = [] \n        for c in cs:\n            res.append(Message(c,self))\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef main():\n\n    opts = dict(\n        name=\"clamavmirror\",\n        version='0.0.4',\n        description=\"ClamAV Signature Mirroring Tool\",\n        long_description=get_readme(),\n        keywords=\"clamav mirror mirroring mirror-tool signatures\",\n        author=\"Andrew Colin Kissa\",\n        author_email=\"andrew@topdog.za.net\",\n        url=\"https://github.com/akissa/clamavmirror\",\n        license=\"MPL 2.0\",\n        packages=[],\n        entry_points={\n            'console_scripts': [\n                'clamavmirror=clamavmirror:main'\n            ],\n        },\n        include_package_data=True,\n        zip_safe=False,\n        install_requires=['urllib3', 'dnspython', 'certifi'],\n        classifiers=[\n            'Development Status :: 4 - Beta',\n            'Programming Language :: Python',\n            'Programming Language :: Python :: 2.6',\n            'Programming Language :: Python :: 2.7',\n            'Topic :: Software Development :: Libraries :: Python Modules',\n            'Intended Audience :: System Administrators',\n            'Environment :: Console',\n            'License :: OSI Approved :: Mozilla Public License 2.0 (MPL 2.0)',\n            'Natural Language :: English',\n            'Operating System :: OS Independent'],)\n    setup(**opts)", "response": "A function that sets up the clamavmirror module."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _subset_table(full_table, subset):\n    if not subset:\n        return full_table\n\n    # TODO: Figure out syntax for logical or\n    conditions = subset.replace(' ','').split(';')\n\n    valid = np.ones(len(full_table), dtype=bool)\n    for condition in conditions:\n        col = re.split(\"[<>=!]\", condition)[0]\n        comp = condition.replace(col, \"\")\n        try:\n            this_valid = eval(\"full_table['{0}']{1}\".format(col, comp))\n        except KeyError as e: # catch error and redisplay for twiggy\n            raise KeyError(\"Column '%s' not found\" % e.message)\n        valid = np.logical_and(valid, this_valid)\n\n    return full_table[valid]", "response": "Return a subset of the data table with records from the full table that meeting requirements in subset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _subset_meta(full_meta, subset, incremented=False):\n    if not subset:\n        return full_meta, False\n\n    meta = {}  # Make deepcopy of entire meta (all section dicts in meta dict)\n    for key, val in full_meta.iteritems():\n        meta[key] = copy.deepcopy(dict(val))\n\n    conditions = subset.replace(' ','').split(';')\n\n    inc = False\n    for condition in conditions:\n        condition_list = re.split('[<>=]', condition)\n        col = condition_list[0]\n        val = condition_list[-1]\n\n        try:\n            col_step = meta[col]['step']\n        except:  # If there's no metadata for this col, do nothing\n            continue\n\n        operator = re.sub('[^<>=]', '', condition)\n\n        if operator == '==':\n            meta[col]['min'] = val\n            meta[col]['max'] = val\n        elif operator == '>=':\n            meta[col]['min'] = val\n        elif operator == '>':\n            if incremented:\n                meta[col]['min'] = val\n            else:\n                meta[col]['min'] = str(eval(val) + eval(col_step))\n            inc = True\n        elif operator == '<=':\n            meta[col]['max'] = val\n        elif operator == '<':\n            if incremented:\n                meta[col]['max'] = val\n            else:\n                meta[col]['max'] = str(eval(val) - eval(col_step))\n            inc = True\n        else:\n            raise ValueError, \"Subset %s not valid\" % condition\n\n    return meta, inc", "response": "Returns a copy of full_meta with only the conditions in subset"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sad(patch, cols, splits, clean=True):\n\n    (spp_col, count_col), patch = \\\n        _get_cols(['spp_col', 'count_col'], cols, patch)\n\n    full_spp_list = np.unique(patch.table[spp_col])\n\n    # Loop through each split\n    result_list = []\n    for substring, subpatch in _yield_subpatches(patch, splits):\n\n        # Get abundance for each species\n        sad_list = []\n        for spp in full_spp_list:\n            this_spp = (subpatch.table[spp_col] == spp)\n            count = np.sum(subpatch.table[count_col][this_spp])\n            sad_list.append(count)\n\n        # Create dataframe of spp names and abundances\n        subdf = pd.DataFrame({'spp': full_spp_list, 'y': sad_list})\n\n        # Remove zero abundance rows if requested\n        if clean:\n            subdf = subdf[subdf['y'] > 0]\n\n        # Append subset result\n        result_list.append((substring, subdf))\n\n    # Return all results\n    return result_list", "response": "Get the SAD of the full plot and keep absent species."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ssad(patch, cols, splits):\n\n    # Get and check SAD\n    sad_results = sad(patch, cols, splits, clean=False)\n\n    # Create dataframe with col for spp name and numbered col for each split\n    for i, sad_result in enumerate(sad_results):\n        if i == 0:  # For first result, create dataframe\n            fulldf = sad_result[1]\n            fulldf.columns = ['spp', '0']  # Renames y col to 0\n        else:  # For other results, append col to dataframe, named by num\n            fulldf[str(i)] = sad_result[1]['y']\n\n    # Get each spp SSAD (row of fulldf) and append as tuple in result_list\n    result_list = []\n    for _, row in fulldf.iterrows():\n        row_values_array = np.array(row[1:], dtype=float)\n        result_list.append((row[0], pd.DataFrame({'y': row_values_array})))\n\n    # Return all results\n    return result_list", "response": "Calculates an empirical intra - specific spatial abundance distribution for each species in each cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates an empirical species area or endemics area relationship Parameters ---------- {0} divs : str Description of how to divide x_col and y_col. See notes. ear : bool If True, calculates an endemics area relationship Returns ------- {1} Result has 5 columns; div, x, and y; that give the ID for the division given as an argument, fractional area, and the mean species richness at that division. Notes ----- {2} For the SAR and EAR, cols must also contain x_col and y_col, giving the x and y dimensions along which to grid the patch. {3} {4} Examples -------- {5} >>> # Get the SAR at the full area (1,1), 1 x 2 division, >>> # 2 x 1 division, 2 x 2 division, 2 x 4 division, 4 x 2 division, and >>> # 4 x 4 division >>> sar = meco.empirical.sar(pat, cols='spp_col:spp; count_col:count; x_col:row; y_col:column', splits=\"\", divs=\"1,1; 1,2; 2,1; 2,2; 2,4; 4,2; 4,4\") >>> sar[0][1] div n_individs n_spp x y 0 1,1 2445.0000 24.0000 16 24.0000 1 1,2 1222.5000 18.5000 8 18.5000 2 2,1 1222.5000 17.0000 8 17.0000 3 2,2 611.2500 13.5000 4 13.5000 4 2,4 305.6250 10.1250 2 10.1250 5 4,2 305.6250 10.5000 2 10.5000 6 4,4 152.8125 7.5625 1 7.5625 The column div gives the divisions specified in the function call. The column n_individs specifies the average number of individuals across the cells made from the given division. n_spp gives the average species across the cells made from the given division. x gives the absolute area of a cell for the given division. y gives the same information as n_spp and is included for easy plotting. See http://www.macroeco.org/tutorial_macroeco.html for additional examples and explanation", "response": "def sar(patch, cols, splits, divs, ear=False):\n    \"\"\"\n    Calculates an empirical species area or endemics area relationship\n\n    Parameters\n    ----------\n    {0}\n    divs : str\n        Description of how to divide x_col and y_col. See notes.\n    ear : bool\n        If True, calculates an endemics area relationship\n\n    Returns\n    -------\n    {1} Result has 5 columns; div, x, and y; that give the ID for the\n    division given as an argument, fractional area, and the mean species\n    richness at that division.\n\n    Notes\n    -----\n    {2}\n\n    For the SAR and EAR, cols must also contain x_col and y_col, giving the x\n    and y dimensions along which to grid the patch.\n\n    {3}\n\n    {4}\n\n    Examples\n    --------\n\n    {5}\n\n    >>> # Get the SAR at the full area (1,1), 1 x 2 division,\n    >>> # 2 x 1 division, 2 x 2 division, 2 x 4 division, 4 x 2 division, and\n    >>> # 4 x 4 division\n    >>> sar = meco.empirical.sar(pat,\n                cols='spp_col:spp; count_col:count; x_col:row; y_col:column',\n                splits=\"\",\n                divs=\"1,1; 1,2; 2,1; 2,2; 2,4; 4,2; 4,4\")\n\n    >>> sar[0][1]\n       div  n_individs    n_spp   x        y\n    0  1,1   2445.0000  24.0000  16  24.0000\n    1  1,2   1222.5000  18.5000   8  18.5000\n    2  2,1   1222.5000  17.0000   8  17.0000\n    3  2,2    611.2500  13.5000   4  13.5000\n    4  2,4    305.6250  10.1250   2  10.1250\n    5  4,2    305.6250  10.5000   2  10.5000\n    6  4,4    152.8125   7.5625   1   7.5625\n\n    The column div gives the divisions specified in the function call. The\n    column n_individs specifies the average number of individuals across the\n    cells made from the given division. n_spp gives the average species across\n    the cells made from the given division. x gives the absolute area of a\n    cell for the given division. y gives the same information as n_spp and is\n    included for easy plotting.\n\n    See http://www.macroeco.org/tutorial_macroeco.html for additional\n    examples and explanation\n\n    \"\"\"\n\n    def sar_y_func(spatial_table, all_spp):\n        return np.mean(spatial_table['n_spp'])\n\n    def ear_y_func(spatial_table, all_spp):\n        endemic_counter = 0\n        for spp in all_spp:\n            spp_in_cell = [spp in x for x in spatial_table['spp_set']]\n            spp_n_cells = np.sum(spp_in_cell)\n            if spp_n_cells == 1:  # If a spp is in only 1 cell, endemic\n                endemic_counter += 1\n        n_cells = len(spatial_table)\n        return endemic_counter / n_cells # mean endemics / cell\n\n    if ear:\n        y_func = ear_y_func\n    else:\n        y_func = sar_y_func\n\n    return _sar_ear_inner(patch, cols, splits, divs, y_func)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sar_ear_inner(patch, cols, splits, divs, y_func):\n\n    (spp_col, count_col, x_col, y_col), patch = \\\n        _get_cols(['spp_col', 'count_col', 'x_col', 'y_col'], cols, patch)\n\n    # Loop through each split\n    result_list = []\n    for substring, subpatch in _yield_subpatches(patch, splits):\n\n        # Get A0\n        A0 = _patch_area(subpatch, x_col, y_col)\n\n        # Loop through all divisions within this split\n        all_spp = np.unique(subpatch.table[spp_col])\n        subresultx = []\n        subresulty = []\n        subresultnspp = []\n        subresultnindivids = []\n        subdivlist = _split_divs(divs)\n        for subdiv in subdivlist:\n            spatial_table = _yield_spatial_table(subpatch, subdiv, spp_col,\n                                        count_col, x_col, y_col)\n            subresulty.append(y_func(spatial_table, all_spp))\n            subresultx.append(A0 / eval(subdiv.replace(',', '*')))\n            subresultnspp.append(np.mean(spatial_table['n_spp']))\n            subresultnindivids.append(np.mean(spatial_table['n_individs']))\n\n        # Append subset result\n        subresult = pd.DataFrame({'div': subdivlist, 'x': subresultx,\n                                  'y': subresulty, 'n_spp': subresultnspp,\n                                  'n_individs': subresultnindivids})\n        result_list.append((substring, subresult))\n\n    return result_list", "response": "A function that computes the mean number of species or endemics for the SAR or EAR tree."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate commonality as a function of distance between two cells in a gridded patch.", "response": "def comm_grid(patch, cols, splits, divs, metric='Sorensen'):\n    \"\"\"\n    Calculates commonality as a function of distance for a gridded patch\n\n    Parameters\n    ----------\n    {0}\n    divs : str\n        Description of how to divide x_col and y_col. Unlike SAR and EAR, only\n        one division can be given at a time. See notes.\n    metric : str\n        One of Sorensen or Jaccard, giving the metric to use for commonality\n        calculation\n\n    Returns\n    -------\n    {1} Result has three columns, pair, x, and y, that give the locations of\n    the pair of patches for which commonality is calculated, the distance\n    between those cells, and the Sorensen or Jaccard result.\n\n    Notes\n    -----\n    {2}\n\n    For gridded commonality, cols must also contain x_col and y_col, giving the\n    x and y dimensions along which to grid the patch.\n\n    {3}\n\n    \"\"\"\n\n    (spp_col, count_col, x_col, y_col), patch = \\\n        _get_cols(['spp_col', 'count_col', 'x_col', 'y_col'], cols, patch)\n\n    # Loop through each split\n    result_list = []\n    for substring, subpatch in _yield_subpatches(patch, splits):\n\n        # Get spatial table and break out columns\n        spatial_table = _yield_spatial_table(subpatch, divs, spp_col,\n                                             count_col, x_col, y_col)\n        spp_set = spatial_table['spp_set']\n        cell_loc = spatial_table['cell_loc']\n        n_spp = spatial_table['n_spp']\n\n        # Get all possible pairwise combinations of cells\n        pair_list = []\n        dist_list = []\n        comm_list = []\n        for i in range(len(spatial_table)):\n            for j in range(i+1, len(spatial_table)):\n\n                iloc = np.round(cell_loc[i], 6)\n                jloc = np.round(cell_loc[j], 6)\n                pair_list.append('('+str(iloc[0])+' '+str(iloc[1])+') - '+\n                                 '('+str(jloc[0])+' '+str(jloc[1])+')')\n\n                dist_list.append(_distance(cell_loc[i], cell_loc[j]))\n\n                ij_intersect = spp_set[i] & spp_set[j]\n                if metric.lower() == 'sorensen':\n                    comm = 2*len(ij_intersect) / (n_spp[i] + n_spp[j])\n                elif metric.lower() == 'jaccard':\n                    comm = len(ij_intersect) / len(spp_set[i] | spp_set[j])\n                else:\n                    raise ValueError, (\"Only Sorensen and Jaccard metrics are \"\n                                      \"available for gridded commonality\")\n                comm_list.append(comm)\n\n        # Append subset result\n        subresult = pd.DataFrame({'pair': pair_list, 'x': dist_list,\n                                  'y': comm_list})\n        result_list.append((substring, subresult))\n\n    # Return all results\n    return result_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nyielding a DataFrame containing the spatial table for each cell in the given division.", "response": "def _yield_spatial_table(patch, div, spp_col, count_col, x_col, y_col):\n    \"\"\"\n    Calculates an empirical spatial table\n\n    Yields\n    -------\n    DataFrame\n        Spatial table for each division. See Notes.\n\n    Notes\n    -----\n    The spatial table is the precursor to the SAR, EAR, and grid-based\n    commonality metrics. Each row in the table corresponds to a cell created by\n    a given division. Columns are cell_loc (within the grid defined by the\n    division), spp_set, n_spp, and n_individs.\n\n    \"\"\"\n\n    # Catch error if you don't use ; after divs in comm_grid in MacroecoDesktop\n    try:\n        div_split_list = div.replace(';','').split(',')\n    except AttributeError:\n        div_split_list = str(div).strip(\"()\").split(',')\n\n    div_split = (x_col + ':' + div_split_list[0] + ';' +\n                 y_col + ':' + div_split_list[1])\n\n    # Get cell_locs\n    # Requires _parse_splits and _product functions to go y inside of x\n    x_starts, x_ends = _col_starts_ends(patch, x_col, div_split_list[0])\n    x_offset = (x_ends[0] - x_starts[0]) / 2\n    x_locs = x_starts + x_offset\n\n    y_starts, y_ends = _col_starts_ends(patch, y_col, div_split_list[1])\n    y_offset = (y_ends[0] - y_starts[0]) / 2\n    y_locs = y_starts + y_offset\n\n    cell_locs = _product(x_locs, y_locs)\n\n    # Get spp set and count for all cells\n    n_spp_list = [] # Number of species in cell\n    n_individs_list = []\n    spp_set_list = []   # Set object giving unique species IDs in cell\n    for cellstring, cellpatch in _yield_subpatches(patch,div_split,name='div'):\n        spp_set = set(np.unique(cellpatch.table[spp_col]))\n        spp_set_list.append(spp_set)\n        n_spp_list.append(len(spp_set))\n        n_individs_list.append(np.sum(cellpatch.table[count_col]))\n\n    # Create and return dataframe\n    df = pd.DataFrame({'cell_loc': cell_locs, 'spp_set': spp_set_list,\n                       'n_spp': n_spp_list, 'n_individs': n_individs_list})\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef o_ring(patch, cols, splits, spp, bin_edges, density=True, full=False):\n\n    try:\n        geo.box(0, 0, 1, 1)\n    except:\n        raise ImportError, \"O-ring analysis requires shapely package\"\n\n    (spp_col, count_col, x_col, y_col), patch = \\\n        _get_cols(['spp_col', 'count_col', 'x_col', 'y_col'], cols, patch)\n\n    # Loop through each split\n    result_list = []\n    for substring, subpatch in _yield_subpatches(patch, splits):\n\n        # Get table for just this species\n        spp_table = subpatch.table[subpatch.table[spp_col] == spp]\n\n        # If spp not present, continue\n        if (len(spp_table) == 0):\n            result_list.append((substring, pd.DataFrame(columns=['x','y'])))\n            continue\n\n        # Set up plot geometry\n        plot_poly, radii, torus_areas = \\\n            _get_plot_geometry(subpatch, bin_edges, x_col, y_col)\n\n        # Get lists of all points and counts in spp_table\n        x = spp_table[x_col]\n        y = spp_table[y_col]\n        points = zip(x,y)\n        counts = list(spp_table[count_col])\n\n        # Arrays to hold summed areas and distance histograms for all points\n\n        if full:\n            hists = []  # Vectors of len(radii) appended for each point\n            areas = []\n        else:\n            hists = np.zeros(len(radii))\n            areas = np.zeros(len(radii))\n\n        # Go through each point and associated count\n        for i, (point, count) in enumerate(zip(points, counts)):\n\n            # Create list of all other points and counts except this\n            other_points = points[0:i] + points[i+1:]\n            other_counts = counts[0:i] + counts[i+1:]\n\n            # Get dist from this point to all other points\n            if other_points:\n                other_dists = dist.cdist(np.array([point]),\n                                         np.array(other_points))\n            else:\n                other_dists = np.array(())\n\n            # Repeat other point distances to acccount for their counts\n            other_dists = np.repeat(other_dists, other_counts)\n\n            # Repeat entire other_dist array to account for count here\n            other_dists = np.tile(other_dists, count)\n\n            # Add 0's for count at this point to account for count here\n            if count > 1:\n                other_dists = np.concatenate((other_dists,\n                                              np.zeros(count*(count-1))))\n\n            # Calculate histogram of distances to other points\n            hist, _ = np.histogram(other_dists, bin_edges)\n\n            # Convert histogram to density if desired\n            corr_factor = np.ones(len(radii))  # Frac length in plot\n            for j, r in enumerate(radii):\n                circ = geo.Point(*point).buffer(r, resolution=64)\n                outside_len = circ.boundary.difference(plot_poly).length\n                corr_factor[j] = ((circ.boundary.length - outside_len) /\n                                   circ.boundary.length)\n\n            # Add hist and corrected area for this point to running totals\n            if full:\n                hists.append(hist)\n                areas.append(torus_areas * corr_factor * count)\n            else:\n                hists += hist\n                areas += torus_areas * corr_factor * count\n\n        # If density, divide summed torus counts by summed areas\n        if density:\n            hists = np.array(hists) / np.array(areas)\n\n        # Append subset result\n        subresult = pd.DataFrame({'x': radii})\n        if full:\n            for i in range(len(hists)):\n                subresult[i] = hists[i]\n        else:\n            subresult['y'] = hists\n        result_list.append((substring, subresult))\n\n    # Return all results\n    return result_list", "response": "Calculates univariate O - ring for a single species."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef comm_sep(self, plot_locs, criteria, loc_unit=None):\n    '''\n    Calculates commonality (Sorensen and Jaccard) between pairs of plots.\n\n    Parameters\n    ----------\n    plot_locs : dict\n        Dictionary with keys equal to each plot name, which must be\n        represented by a column in the data table, and values equal to a\n        tuple of the x and y coordinate of each plot\n    criteria : dict\n        See docstring for Patch.sad.\n    loc_unit : str\n        Unit of plot locations. Special cases include 'decdeg' (decimal\n        degrees), returns result in km. Otherwise ignored.\n\n    Returns\n    -------\n    result: structured array\n        Returns a structured array with fields plot-a and plot-b (names of\n        two plots), dist (distance between plots), and sorensen and jaccard\n        (similarity indices). Has row for each unique pair of plots.\n    '''\n\n    # Set up sad_dict with key=plot and val=clean sad for that plot\n    sad_dict = {}\n\n    # Loop through all plot cols, updating criteria, and getting spp_list\n    for plot in plot_locs.keys():\n\n        # Find current count col and remove it from criteria\n        for crit_key in criteria.keys():\n            if criteria[crit_key] == 'count':\n                criteria.pop(crit_key, None)\n\n        # Add this plot as col with counts\n        criteria[plot] = 'count'\n\n        # Get SAD for existing criteria with this plot as count col\n        sad_return = self.sad(criteria, clean=True)\n\n        # Check that sad_return only has one element, or throw error\n        if len(sad_return) > 1:\n            raise NotImplementedError('Too many criteria for comm_sep')\n\n        # Get unique species list for this plot and store in sad_dict\n        sad_dict[plot] = sad_return[0][2]\n\n    # Set up recarray to hold Sorensen index for all pairs of plots\n    n_pairs = np.sum(np.arange(len(plot_locs.keys())))\n    result = np.recarray((n_pairs,), dtype=[('plot-a','S32'),\n                                            ('plot-b', 'S32'),\n                                            ('spp-a', int),\n                                            ('spp-b', int),\n                                            ('dist', float),\n                                            ('sorensen', float),\n                                            ('jaccard', float)])\n\n    # Loop through all combinations of plots and fill in result table\n    row = 0\n    for pair in itertools.combinations(plot_locs.keys(), 2):\n\n        # Names of plots\n        plota = pair[0]\n        plotb = pair[1]\n\n        result[row]['plot-a'] = plota\n        result[row]['plot-b'] = plotb\n\n        # Calculate inter-plot distance\n        if loc_unit == 'decdeg':\n            result[row]['dist'] = _decdeg_distance(plot_locs[plota],\n                                                   plot_locs[plotb])\n        else:\n            result[row]['dist'] = _distance(plot_locs[plota],\n                                            plot_locs[plotb])\n\n        # Get similarity indices\n        spp_a = len(sad_dict[plota])\n        spp_b = len(sad_dict[plotb])\n\n        result[row]['spp-a'] = spp_a\n        result[row]['spp-b'] = spp_b\n\n        intersect = set(sad_dict[plota]).intersection(sad_dict[plotb])\n        union = set(sad_dict[plota]).union(sad_dict[plotb])\n\n        # Fill in zero if denom is zero\n        if spp_a + spp_b == 0:\n            result[row]['sorensen'] = 0\n        else:\n            result[row]['sorensen'] = (2*len(intersect)) / (spp_a+spp_b)\n\n        if len(union) == 0:\n            result[row]['jaccard'] = 0\n        else:\n            result[row]['jaccard'] = len(intersect) / len(union)\n\n        # Increment row counter\n        row += 1\n\n    return result", "response": "Calculates commonality between two pairs of plots."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_cols(special_col_names, cols, patch):\n\n    # If cols not given, try to fall back on cols from metadata\n    if not cols:\n        if 'cols' in patch.meta['Description'].keys():\n            cols = patch.meta['Description']['cols']\n        else:\n            raise NameError, (\"cols argument not given, spp_col at a minimum \"\n                              \"must be specified\")\n\n    # Parse cols string into dict\n    cols = cols.replace(' ', '')\n    col_list = cols.split(';')\n    col_dict = {x.split(':')[0]: x.split(':')[1] for x in col_list}\n\n    # Get special_col_names from dict\n    result = []\n    for special_col_name in special_col_names:\n        col_name = col_dict.get(special_col_name, None)\n\n        # Create a count col if its requested and doesn't exist\n        if special_col_name is 'count_col' and col_name is None:\n            col_name = 'count'\n            patch.table['count'] = np.ones(len(patch.table))\n\n        # All special cols must be specified (count must exist by now)\n        if col_name is None:\n            raise ValueError, (\"Required column %s not specified\" %\n                               special_col_name)\n\n        result.append(col_name)\n\n    return tuple(result), patch", "response": "Retrieve values of special_cols from cols string or patch metadata\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield all subtables defined by splits string", "response": "def _yield_subpatches(patch, splits, name='split'):\n    \"\"\"\n    Iterator for subtables defined by a splits string\n\n    Parameters\n    ----------\n    patch : obj\n        Patch object containing data to subset\n    splits : str\n        Specifies how a column of a dataset should be split. See Notes.\n\n    Yields\n    ------\n    tuple\n        First element is subset string, second is subtable dataframe\n\n    Notes\n    -----\n    {0}\n\n    \"\"\"\n\n    if splits:\n        subset_list = _parse_splits(patch, splits)\n        for subset in subset_list:\n            logging.info('Analyzing subset %s: %s' % (name, subset))\n            subpatch = copy.copy(patch)\n            subpatch.table = _subset_table(patch.table, subset)\n            subpatch.meta, subpatch.incremented = _subset_meta(patch.meta,\n                                                subset, incremented=True)\n\n            yield subset, subpatch\n    else:\n        yield '', patch"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse splits string to get list of all associated subset strings.", "response": "def _parse_splits(patch, splits):\n    \"\"\"\n    Parse splits string to get list of all associated subset strings.\n\n    Parameters\n    ----------\n    patch : obj\n        Patch object containing data to subset\n    splits : str\n        Specifies how a column of a dataset should be split. See Notes.\n\n    Returns\n    -------\n    list\n        List of subset strings derived from splits string\n\n    Notes\n    -----\n    {0}\n\n    \"\"\"\n\n    split_list = splits.replace(' ','').split(';')\n    subset_list = []  # List of all subset strings\n\n    for split in split_list:\n        col, val = split.split(':')\n\n        if val == 'split':\n            uniques = []\n            for level in patch.table[col]:\n                if level not in uniques:\n                    uniques.append(level)\n            level_list = [col + '==' + str(x) + '; ' for x in uniques]\n        else:\n            starts, ends = _col_starts_ends(patch, col, val)\n            level_list = [col + '>=' + str(x) + '; ' + col + '<' + str(y)+'; '\n                          for x, y in zip(starts, ends)]\n\n        subset_list.append(level_list)\n\n    # Get product of all string levels as list, conv to string, drop final ;\n    return [''.join(x)[:-2] for x in _product(*subset_list)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the decdeg distance between two decimal latlong points using the Haversine approximation.", "response": "def _decdeg_distance(pt1, pt2):\n    \"\"\"\n    Earth surface distance (in km) between decimal latlong points using\n    Haversine approximation.\n\n    http://stackoverflow.com/questions/15736995/\n    how-can-i-quickly-estimate-the-distance-between-two-latitude-longitude-\n    points\n    \"\"\"\n\n    lat1, lon1 = pt1\n    lat2, lon2 = pt2\n\n    # Convert decimal degrees to radians\n    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n\n    # haversine formula\n    dlon = lon2 - lon1\n    dlat = lat2 - lat1\n    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n    c = 2 * np.arcsin(np.sqrt(a))\n    km = 6367 * c\n\n    return km"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an empirical cdf from data", "response": "def empirical_cdf(data):\n    \"\"\"\n    Generates an empirical cdf from data\n\n    Parameters\n    ----------\n    data : iterable\n        Empirical data\n\n    Returns\n    --------\n    DataFrame\n        Columns 'data' and 'ecdf'. 'data' contains ordered data and 'ecdf'\n        contains the corresponding ecdf values for the data.\n\n    \"\"\"\n\n    vals = pd.Series(data).value_counts()\n    ecdf = pd.DataFrame(data).set_index(keys=0)\n    probs = pd.DataFrame(vals.sort_index().cumsum() / np.float(len(data)))\n    ecdf = ecdf.join(probs)\n    ecdf = ecdf.reset_index()\n    ecdf.columns = ['data', 'ecdf']\n\n    return ecdf"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _load_table(self, metadata_path, data_path):\n\n        metadata_dir = os.path.dirname(os.path.expanduser(metadata_path))\n        data_path = os.path.normpath(os.path.join(metadata_dir, data_path))\n\n        extension = data_path.split('.')[-1]\n\n        if extension == 'csv':\n            full_table = pd.read_csv(data_path, index_col=False)\n            table = _subset_table(full_table, self.subset)\n            self.meta, _ = _subset_meta(self.meta, self.subset)\n        elif extension in ['db', 'sql']:\n\n            # TODO: deal with incrementing in DB table\n            table = self._get_db_table(data_path, extension)\n        else:\n            raise TypeError('Cannot process file of type %s' % extension)\n\n        return table", "response": "Load data table taking subset if needed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery a database and return query result as a recarray", "response": "def _get_db_table(self, data_path, extension):\n        \"\"\"\n        Query a database and return query result as a recarray\n\n        Parameters\n        ----------\n        data_path : str\n            Path to the database file\n        extension : str\n            Type of database, either sql or db\n\n        Returns\n        -------\n        table : recarray\n            The database query as a recarray\n\n        \"\"\"\n        # TODO: This is probably broken\n        raise NotImplementedError, \"SQL and db file formats not yet supported\"\n\n        # Load table\n        if extension == 'sql':\n            con = lite.connect(':memory:')\n            con.row_factory = lite.Row\n            cur = con.cursor()\n\n            with open(data_path, 'r') as f:\n                sql = f.read()\n\n            cur.executescript(sql)\n\n        else:\n            con = lite.connect(data_path)\n            con.row_factory = lite.Row\n            cur = con.cursor()\n\n        cur.execute(self.subset)\n\n        # Check that table is not empty\n        db_info = cur.fetchall()\n        try:\n            col_names = db_info[0].keys()\n        except IndexError:\n            raise lite.OperationalError(\"Query %s to database %s is empty\" %\n                                        (query_str, data_path))\n\n        # Convert objects to tuples\n        converted_info = [tuple(x) for x in db_info]\n\n        # NOTE: Using default value for Unicode: Seems better than checking\n        # lengths.  Should we keep the type as unicode?\n        dtypes=[type(x) if type(x) != unicode else 'S150' for x in db_info[0]]\n\n        table = np.array(converted_info, dtype=zip(col_names, dtypes))\n        con.commit()\n        con.close()\n\n        # Return a recarray for consistency\n        # TODO: This should now be a pd.dataframe\n        return table.view(np.recarray)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _thread_excepthook():\n    init_old = thread.Thread.__init__\n    def init(self, *args, **kwargs):\n        init_old(self, *args, **kwargs)\n        run_old = self.run\n        def run_with_except_hook(*args, **kw):\n            try:\n                run_old(*args, **kw)\n            except (KeyboardInterrupt, SystemExit):\n\n                raise\n            except:\n                sys.excepthook(*sys.exc_info())\n        self.run = run_with_except_hook\n    thread.Thread.__init__ = init", "response": "Make threads use sys. excepthook from parent process\n    http://bugs. python. org / issue1230540\n    Make threads use sys. excepthook from parent process\n    http://bugs. python. org / issue1230540\n    http://bugs. python. org / issue1230540\n    http://bugs. python. org / issue1230540\n    http://bugs. python. org / issue1230540\n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef log_start_end(f):\n    def inner(f, *args, **kwargs):\n        logging.info('Starting %s' % f.__name__)\n        res = f(*args, **kwargs)\n        logging.info('Finished %s' % f.__name__)\n        return res\n    return decorator.decorator(inner, f)", "response": "Decorator to log start and end of function\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions does a rudimentary check whether the cols splits and divs columns in the parameter files are formatted properly.", "response": "def check_parameter_file(filename):\n    \"\"\"\n    Function does a rudimentary check whether the cols, splits and divs columns\n    in the parameter files are formatted properly.\n\n    Just provides a preliminary check. Will only catch basic mistakes\n\n    Parameters\n    ----------\n    filename : str\n        Path to parameters file\n\n    Returns\n    -------\n    : list\n        Contains the number of possible bad strings detected\n    \"\"\"\n\n    # Load file\n    with open(filename, \"r\") as fin:\n        content = fin.read()\n\n    # Check cols and splits strings\n\n    bad_names = []\n    line_numbers = []\n\n    strs = [\"cols\", \"splits\", \"divs\"]\n\n    for tstr in strs:\n\n        start = content.find(tstr)\n\n        while start != -1:\n\n            cols_str = \"\".join(content[start:].split(\"\\n\")[0].split(\"=\")[-1].split(\" \"))\n\n            semis = cols_str.count(\";\")\n\n            # Get line number\n            line_end = content.find(\"\\n\", start)\n            line_number = content[:line_end].count(\"\\n\") + 1\n\n            if tstr == \"divs\":\n                colons = cols_str.count(\",\")\n            else:\n                colons = cols_str.count(\":\")\n\n            if colons != (semis + 1):\n                bad_names.append(tstr)\n                line_numbers.append(line_number)\n\n            start = content.find(tstr, start + 1)\n\n    return bad_names, line_numbers"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the root logger for command line applications.", "response": "def configure_logging(level=logging.DEBUG):\n    '''Configures the root logger for command line applications.\n\n    A stream handler will be added to the logger that directs\n    messages to the standard error stream.\n\n    By default, *no* messages will be filtered out: set a higher\n    level on derived/child loggers to achieve filtering.\n\n    Warning\n    -------\n    Logging should only be configured once at the main entry point of the\n    application!\n    '''\n    fmt = '%(asctime)s | %(levelname)-8s | %(name)-40s | %(message)s'\n    datefmt = '%Y-%m-%d %H:%M:%S'\n    formatter = logging.Formatter(fmt=fmt, datefmt=datefmt)\n\n    logger = logging.getLogger()  # returns the root logger\n\n    stderr_handler = logging.StreamHandler(stream=sys.stderr)\n    stderr_handler.name = 'err'\n    stderr_handler.setLevel(level)\n    stderr_handler.setFormatter(formatter)\n    logger.addHandler(stderr_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_starttag(self, tag, attrs):\n        if tag.lower() in self.allowed_tag_whitelist:\n            if tag.lower() == 'ol':\n                # we need a list to store the last\n                # number used  in the previous ordered lists\n                self.previous_nbs.append(self.nb)\n                self.nb = 0\n                # we need to know which is the tag list\n                self.previous_type_lists.append(tag.lower())\n                # we must remove any non-relevant spacing and end of\n                # line before\n                self.result = self.result.rstrip()\n            elif tag.lower() == 'ul':\n                self.previous_type_lists.append(tag.lower())\n                # we must remove any non-relevant spacing and end of\n                # line before\n                self.result = self.result.rstrip()\n            elif tag.lower() == 'li':\n                # we must remove any non-relevant spacing and end of\n                # line before\n                self.result = self.result.rstrip()\n                if self.previous_type_lists[-1] == 'ol':\n                    self.nb += 1\n                    self.result += '\\n' + self.line_quotation + \\\n                                   '  ' * len(self.previous_type_lists) + \\\n                        str(self.nb) + '. '\n                else:\n                    self.result += '\\n' + self.line_quotation + \\\n                                   '  ' * len(self.previous_type_lists) + '* '\n            elif tag.lower() == 'a':\n                # self.previous_type_lists.append(tag.lower())\n                for (attr, value) in attrs:\n                    if attr.lower() == 'href':\n                        self.url = value\n                        self.result += '<' + value + '>'", "response": "Function called for new opening tags"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef handle_data(self, data):\n        if not self.silent:\n            if self.url:\n                if self.url == data:\n                    data = ''\n                else:\n                    data = '(' + data + ')'\n            self.url = ''\n            self.result += cgi.escape(data, True)\n        lines = data.splitlines()\n        if len(lines) > 1:\n            match_obj = RE_HTML_FIRST_NON_QUOTATION_CHAR_ON_LINE.search(\n                lines[-1])\n            if match_obj:\n                self.line_quotation = '&gt;' * match_obj.start()\n            else:\n                self.line_quotation = ''", "response": "Function called for text nodes"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions called for ending of tags", "response": "def handle_endtag(self, tag):\n        \"\"\"Function called for ending of tags\"\"\"\n        if tag.lower() in self.allowed_tag_whitelist:\n            if tag.lower() in ['ul', 'ol']:\n                self.previous_type_lists = self.previous_type_lists[:-1]\n                if tag.lower() == 'ol':\n                    self.nb = self.previous_nbs[-1]\n                    self.previous_nbs = self.previous_nbs[:-1]\n                # we must remove any non-relevant spacing and end of\n                # line before\n                self.result = self.result.rstrip()\n                self.result += '\\n' + self.line_quotation"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef handle_entityref(self, name):\n        char_code = html_entities.name2codepoint.get(name, None)\n        if char_code is not None:\n            try:\n                self.result += unichr(char_code).encode(\"utf-8\")\n            except:\n                return", "response": "Process a general entity reference of the form name ;."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_topic_sha3(event_block):\n    '''\n    takes an event block and returns a signature for sha3 hashing\n    :param event_block:\n    :return:\n    '''\n\n    sig = \"\"\n    sig += event_block[\"name\"]\n    if not event_block[\"inputs\"]:\n        sig += \"()\"\n        return sig\n\n    sig += \"(\"\n    for input in event_block[\"inputs\"]:\n        sig += input[\"type\"]\n        sig += \",\"\n    sig = sig[:-1]\n    sig += \")\"\n\n    return sig", "response": "returns a sha3 hash of the event block"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_variant(cls, variant, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_variant_with_http_info(variant, **kwargs)\n        else:\n            (data) = cls._create_variant_with_http_info(variant, **kwargs)\n            return data", "response": "Create a new Variant\n                "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete an instance of Variant by its ID.", "response": "def delete_variant_by_id(cls, variant_id, **kwargs):\n        \"\"\"Delete Variant\n\n        Delete an instance of Variant by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_variant_by_id(variant_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str variant_id: ID of variant to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_variant_by_id_with_http_info(variant_id, **kwargs)\n        else:\n            (data) = cls._delete_variant_by_id_with_http_info(variant_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_variant_by_id(cls, variant_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_variant_by_id_with_http_info(variant_id, **kwargs)\n        else:\n            (data) = cls._get_variant_by_id_with_http_info(variant_id, **kwargs)\n            return data", "response": "Find Variant\nAttributeNames Return single instance of Variant by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists Variants Return a list of Variants", "response": "def list_all_variants(cls, **kwargs):\n        \"\"\"List Variants\n\n        Return a list of Variants\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_variants(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Variant]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_variants_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_variants_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreplace all attributes of a variant in the specified base.", "response": "def replace_variant_by_id(cls, variant_id, variant, **kwargs):\n        \"\"\"Replace Variant\n\n        Replace all attributes of Variant\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_variant_by_id(variant_id, variant, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str variant_id: ID of variant to replace (required)\n        :param Variant variant: Attributes of variant to replace (required)\n        :return: Variant\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_variant_by_id_with_http_info(variant_id, variant, **kwargs)\n        else:\n            (data) = cls._replace_variant_by_id_with_http_info(variant_id, variant, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_variant_by_id(cls, variant_id, variant, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_variant_by_id_with_http_info(variant_id, variant, **kwargs)\n        else:\n            (data) = cls._update_variant_by_id_with_http_info(variant_id, variant, **kwargs)\n            return data", "response": "Update attributes of a Variant by ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bethe_fermi(energy, quasipart, shift, hopping, beta):\n    return fermi_dist(quasipart * energy - shift, beta) \\\n            * bethe_lattice(energy, hopping)", "response": "calculate the bethe fermi distribution"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nproduct of the bethe lattice dos fermi distribution an weighted by energy", "response": "def bethe_fermi_ene(energy, quasipart, shift, hopping, beta):\n    \"\"\"product of the bethe lattice dos, fermi distribution an weighted\n       by energy\"\"\"\n    return energy * bethe_fermi(energy, quasipart, shift, hopping, beta)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the particle average count given a certan fermi energy and hopping", "response": "def bethe_filling_zeroT(fermi_energy, hopping):\n    \"\"\"Returns the particle average count given a certan fermi energy, for the\n       semicircular density of states of the bethe lattice\"\"\"\n    fermi_energy = np.asarray(fermi_energy).clip(-2*hopping, 2*hopping)\n    return 1/2. + fermi_energy/2 * bethe_lattice(fermi_energy, hopping) \\\n                    + np.arcsin(fermi_energy/2/hopping)/np.pi"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfinds fill of zero T for a given set of particles in a multi - particle system.", "response": "def bethe_findfill_zeroT(particles, orbital_e, hopping):\n    \"\"\"Return the fermi energy that correspond to the given particle quantity\n       in a semicircular density of states of a bethe lattice in a multi\n       orbital case that can be non-degenerate\"\"\"\n\n    assert 0. <= particles <= len(orbital_e)\n\n    zero = lambda e: np.sum([bethe_filling_zeroT(e-e_m, t) \\\n                        for t, e_m in zip(hopping, orbital_e)]) - particles\n    return fsolve(zero, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bethe_find_crystalfield(populations, hopping):\n\n    zero = lambda orb: [bethe_filling_zeroT(-em, tz) - pop \\\n                        for em, tz, pop in zip(orb, hopping, populations)]\n\n    return fsolve(zero, np.zeros(len(populations)))", "response": "Return the orbital energies to have the system populates as\n       desired by the given individual populations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsplit module_name and class_name from given string.", "response": "def _split_mod_var_names(resource_name):\n    \"\"\" Return (module_name, class_name) pair from given string. \"\"\"\n    try:\n        dot_index = resource_name.rindex('.')\n    except ValueError:\n        # no dot found\n        return '', resource_name\n    return resource_name[:dot_index], resource_name[dot_index + 1:]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting resource variable from string.", "response": "def _get_var_from_string(item):\n    \"\"\" Get resource variable. \"\"\"\n    modname, varname = _split_mod_var_names(item)\n    if modname:\n        mod = __import__(modname, globals(), locals(), [varname], -1)\n        return getattr(mod, varname)\n    else:\n        return globals()[varname]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _handle_list(reclist):\n    ret = []\n    for item in reclist:\n        recs = _handle_resource_setting(item)\n        ret += [resource for resource in recs if resource.access_controller]\n    return ret", "response": "Return list of resources that have access_controller defined."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures the content type is present in the database.", "response": "def _ensure_content_type():\n    \"\"\" Add the bulldog content type to the database if it's missing. \"\"\"\n    from django.contrib.contenttypes.models import ContentType\n    try:\n        row = ContentType.objects.get(app_label=PERM_APP_NAME)\n    except ContentType.DoesNotExist:\n        row = ContentType(name=PERM_APP_NAME, app_label=PERM_APP_NAME, model=PERM_APP_NAME)\n        row.save()\n    return row.id"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_permission_description(permission_name):\n\n    parts = permission_name.split('_')\n    parts.pop(0)\n    method = parts.pop()\n    resource = ('_'.join(parts)).lower()\n    return 'Can %s %s' % (method.upper(), resource)", "response": "Generate a descriptive string based on the permission name."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _populate_permissions(resources, content_type_id):\n    from django.contrib.auth.models import Permission\n    # read the whole auth_permission table into memory\n    db_perms = [perm.codename for perm in Permission.objects.all()]\n\n    for resource in resources:\n        # get all resource's permissions that are not already in db\n        perms = [perm for perm in resource.access_controller.get_perm_names(resource) if perm not in db_perms]\n        for perm in perms:\n            _save_new_permission(perm, content_type_id)", "response": "Populate the database with all missing permissions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a string of the form 1234567b into a Python integer. The terminal letter indicates e. g. billions.", "response": "def parse_int(int_str):\n    \"\"\"Parse a string of the form 1,234,567b into a Python integer.\n       The terminal letter, if present, indicates e.g. billions.\"\"\"\n    int_str = int_str.replace(',', '')\n\n    factor = __get_factor(int_str)\n    if factor != 1:\n        int_str = int_str[:-1]\n\n    try:\n        return int(int_str.replace(',', '')) * factor\n    except ValueError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_float(float_str):\n    factor = __get_factor(float_str)\n    if factor != 1:\n        float_str = float_str[:-1]\n\n    try:\n        return float(float_str.replace(',', '')) * factor\n    except ValueError:\n        return None", "response": "Parse a string of the form 305. 48b into a Python float."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_nonterminals_rewritable_to_epsilon(grammar):\n    # type: (Grammar) -> Dict[Type[Nonterminal], Type[Rule]]\n    \"\"\"\n    Get nonterminals rewritable to epsilon.\n    :param grammar: Grammar where to search.\n    :return: Dictionary, where key is nonterminal rewritable to epsilon and value is rule that is responsible for it.\n    The rule doesn't need to rewrite to epsilon directly,\n    but the whole right side can be rewritable to epsilon using different rules.\n    \"\"\"\n    # start with empty dictionary (contains only epsilon)\n    rewritable = dict()  # type: Dict[Type[Nonterminal], Optional[Type[Rule]]]\n    rewritable[EPSILON] = None\n    # iterate until the dictionary change\n    while True:\n        working = rewritable.copy()\n        for rule in grammar.rules:\n            # no need to process rules we already know rewrite to epsilon\n            if rule.fromSymbol in working:\n                continue\n            # check if the whole right side rewrite to epsilon\n            right_side_rewrite = True\n            for symbol in rule.right:\n                if symbol not in rewritable:\n                    right_side_rewrite = False\n            # the whole right side can be reduce to epsilon, add left side to dictionary\n            if right_side_rewrite:\n                working[rule.fromSymbol] = rule\n        # Working set didn't change, we are done\n        if working == rewritable:\n            break\n        # Otherwise swap the sets and iterate\n        rewritable = working\n    # delete epsilon from the dictionary\n    del rewritable[EPSILON]\n    return rewritable", "response": "Finds nonterminals rewritable to epsilon."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef init_default(self):\n        import f311\n        if self.default_filename is None:\n            raise RuntimeError(\"Class '{}' has no default filename\".format(self.__class__.__name__))\n        fullpath = f311.get_default_data_path(self.default_filename, class_=self.__class__)\n        self.load(fullpath)\n        name, ext = os.path.splitext(self.default_filename)\n        new = a99.new_filename(os.path.join(\"./\", name), ext)\n        self.save_as(new)", "response": "Overriden to take default database and save locally"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsaving the current file as filename.", "response": "def _do_save_as(self, filename):\n        \"\"\"Closes connection, copies DB file, and opens again pointing to new file\n\n        **Note** if filename equals current filename, does nothing!\n        \"\"\"\n        if filename != self.filename:\n            self._ensure_filename()\n            self._close_if_open()\n            shutil.copyfile(self.filename, filename)\n            self.__get_conn(filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate file and schema if it does not exist yet.", "response": "def ensure_schema(self):\n        \"\"\"Create file and schema if it does not exist yet.\"\"\"\n        self._ensure_filename()\n        if not os.path.isfile(self.filename):\n            self.create_schema()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving the. sqlite file. **CAREFUL ** needless say", "response": "def delete(self):\n        \"\"\"Removes .sqlite file. **CAREFUL** needless say\"\"\"\n        self._ensure_filename()\n        self._close_if_open()\n        os.remove(self.filename)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn information about fields of a specific table", "response": "def get_table_info(self, tablename):\n        \"\"\"Returns information about fields of a specific table\n\n        Returns:  OrderedDict((\"fieldname\", MyDBRow), ...))\n\n        **Note** Fields \"caption\" and \"tooltip\" are added to rows using information in moldb.gui_info\n\n        \"\"\"\n        conn = self.__get_conn()\n        ret = a99.get_table_info(conn, tablename)\n\n        if len(ret) == 0:\n            raise RuntimeError(\"Cannot get info for table '{}'\".format(tablename))\n\n        more = self.gui_info.get(tablename)\n        for row in ret.values():\n            caption, tooltip = None, None\n            if more:\n                info = more.get(row[\"name\"])\n                if info:\n                    caption, tooltip = info\n            row[\"caption\"] = caption\n            row[\"tooltip\"] = tooltip\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __get_conn(self, flag_force_new=False, filename=None):\n        flag_open_new = flag_force_new or not self._conn_is_open()\n\n        if flag_open_new:\n            if filename is None:\n                filename = self.filename\n            # funny that __get_conn() calls _get_conn() but that's it\n            conn = self._get_conn(filename)\n            self._conn = conn\n        else:\n            conn = self._conn\n        return conn", "response": "Returns a connection to the database. Tries to return existing connection unless flag_force_new\n            is True."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef flatten_multidict(multidict):\n    return dict([(key, value if len(value) > 1 else value[0])\n                 for (key, value) in multidict.iterlists()])", "response": "Return flattened dictionary from MultiDict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __setitem(self, chunk, key, keys, value, extend=False):\n        def setitem(chunk):\n            if keys:\n                return self.__setitem(chunk, keys[0], keys[1:], value, extend)\n            else:\n                return value\n\n        if key in ['.', ']']:\n            chunk[key] = value\n        elif ']' in key:  # list\n            key = int(key[:-1].replace('n', '-1'))\n            if extend:\n                if chunk is None:\n                    chunk = [None, ]\n                else:\n                    if not isinstance(chunk, list):\n                        chunk = [chunk, ]\n                    if key != -1:\n                        chunk.insert(key, None)\n                    else:\n                        chunk.append(None)\n            else:\n                if chunk is None:\n                    chunk = [None, ]\n            chunk[key] = setitem(chunk[key])\n        else:  # dict\n            if extend:\n                if chunk is None:\n                    chunk = {}\n                    chunk[key] = None\n                    chunk[key] = setitem(chunk[key])\n                elif key not in chunk:\n                    chunk[key] = None\n                    chunk[key] = setitem(chunk[key])\n                else:\n                    if keys:\n                        chunk[key] = setitem(chunk[key])\n                    else:\n                        if not isinstance(chunk[key], list):\n                            chunk[key] = [chunk[key], ]\n                        chunk[key].append(None)\n                        chunk[key][-1] = setitem(chunk[key][-1])\n            else:\n                if chunk is None:\n                    chunk = {}\n                if key not in chunk:\n                    chunk[key] = None\n                chunk[key] = setitem(chunk[key])\n\n        return chunk", "response": "Helper function to fill up the dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextend standard set function.", "response": "def set(self, key, value, extend=False, **kwargs):\n        \"\"\"Extended standard set function.\"\"\"\n        self.__setitem__(key, value, extend, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate and returns a default SQLAlchemy database interface to use.", "response": "def create_default_database(reset: bool = False) -> GraphDatabaseInterface:\n        \"\"\"\n        Creates and returns a default SQLAlchemy database interface to use.\n\n        Arguments:\n            reset (bool): Whether to reset the database if it happens to exist already.\n        \"\"\"\n        import sqlalchemy\n        from sqlalchemy.ext.declarative import declarative_base\n        from sqlalchemy.orm import sessionmaker\n        from sqlalchemy.pool import StaticPool\n\n        Base = declarative_base()\n        engine = sqlalchemy.create_engine(\"sqlite:///SpotifyArtistGraph.db\", poolclass=StaticPool)\n        Session = sessionmaker(bind=engine)\n\n        dbi: GraphDatabaseInterface = create_graph_database_interface(\n            sqlalchemy, Session(), Base, sqlalchemy.orm.relationship\n        )\n\n        if reset:\n            Base.metadata.drop_all(engine)\n        Base.metadata.create_all(engine)\n\n        return dbi"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the exact authentic node name for the given node name.", "response": "def get_authentic_node_name(self, node_name: str) -> Optional[str]:\n        \"\"\"\n        Returns the exact, authentic node name for the given node name if a node corresponding to\n        the given name exists in the graph (maybe not locally yet) or `None` otherwise.\n\n        By default, this method checks whether a node with the given name exists locally in the\n        graph and return `node_name` if it does or `None` otherwise.\n\n        In `Graph` extensions that are used by applications where the user can enter potentially\n        incorrect node names, this method should be overridden to improve usability.\n\n        Arguments:\n            node_name (str): The node name to return the authentic node name for.\n\n        Returns:\n            The authentic name of the node corresponding to the given node name or\n            `None` if no such node exists.\n        \"\"\"\n        items: List[NameExternalIDPair] = self._client.search_artists_by_name(node_name)\n        return items[0].name if len(items) > 0 else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_neighbors_from_external_source(self) -> None:\n        graph: SpotifyArtistGraph = self._graph\n        items: List[NameExternalIDPair] = graph.client.similar_artists(self.external_id)\n\n        limit: int = graph.neighbor_count if graph.neighbor_count > 0 else self._NEIGHBORS_TO_LOAD\n        if len(items) > limit:\n            del items[limit:]\n\n        for item in items:\n            neighbor: SpotifyArtistNode = graph.nodes.get_node_by_name(item.name,\n                                                                       can_validate_and_load=True,\n                                                                       external_id=item.external_id)\n\n            # Strangely we need this guard because the Spofity API's search method doesn't\n            # recognise certain artist names.\n            # Actually it could also be a bug in SpotifyClient.search_artists_by_name(),\n            # the artist name sent as a request parameter may not be encoded 100% correctly...\n            # Anyway, this is a working hotfix.\n            if neighbor is not None:\n                graph.add_edge(self, neighbor)", "response": "Load neighbors of the node from the external source."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_node(self, index: int, name: str, external_id: Optional[str] = None) -> SpotifyArtistNode:\n        if external_id is None:\n            graph: SpotifyArtistGraph = self._graph\n            items: List[NameExternalIDPair] = graph.client.search_artists_by_name(name)\n            for item in items:\n                if item.name == name:\n                    external_id = item.external_id\n                    break\n\n        return SpotifyArtistNode(graph=self._graph, index=index, name=name, external_id=external_id)", "response": "Creates a new node with the given index and name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef access_token(self) -> str:\n        if self._token_expires_at < time.time() + self._REFRESH_THRESHOLD:\n            self.request_token()\n\n        return self._token[\"access_token\"]", "response": "Returns the access token stored within the request token."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef request_token(self) -> None:\n        response: requests.Response = requests.post(\n            self._TOKEN_URL,\n            auth=HTTPBasicAuth(self._client_id, self._client_key),\n            data={\"grant_type\": self._GRANT_TYPE},\n            verify=True\n        )\n        response.raise_for_status()\n        self._token = response.json()\n        self._token_expires_at = time.time() + self._token[\"expires_in\"]", "response": "Requests a new Client Credentials Flow authentication token from the Spotify API\n            and stores it in the self. _token property."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_artists_by_name(self, artist_name: str, limit: int = 5) -> List[NameExternalIDPair]:\n        response: requests.Response = requests.get(\n            self._API_URL_TEMPLATE.format(\"search\"),\n            params={\"q\": artist_name, \"type\": \"artist\", \"limit\": limit},\n            headers={\"Authorization\": \"Bearer {}\".format(self._token.access_token)}\n        )\n\n        # TODO: handle API rate limiting\n\n        response.raise_for_status()\n        if not response.text:\n            return []\n\n        result: List[NameExternalIDPair] = []\n        data: List[Dict] = response.json()[\"artists\"][\"items\"]\n        for artist in data:\n            artist = NameExternalIDPair(artist[\"name\"].strip(), artist[\"id\"].strip())\n            if not artist.name or not artist.external_id:\n                raise SpotifyClientError(\"Name or ID is missing\")\n            result.append(artist)\n\n        return result", "response": "Search for artists by name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning zero or more similar artists.", "response": "def similar_artists(self, artist_id: str) -> List[NameExternalIDPair]:\n        \"\"\"\n        Returns zero or more similar artists (in the form of artist name - external ID pairs)\n        to the one corresponding to the given artist ID.\n\n        Arguments:\n            artist_id ([str]): The Spotify ID of the artist for whom similar artists are requested.\n\n        Returns:\n            Zero or more artist name - external ID pairs.\n\n        Raises:\n            requests.HTTPError: If an HTTP error occurred during the request.\n            SpotifyClientError: If an invalid item is found.\n        \"\"\"\n        response: requests.Response = requests.get(\n            self._API_URL_TEMPLATE.format(\"artists/{}/related-artists\".format(artist_id)),\n            headers={\"Authorization\": \"Bearer {}\".format(self._token.access_token)}\n        )\n\n        # TODO: handle API rate limiting\n\n        response.raise_for_status()\n        if not response.text:\n            return []\n\n        result: List[NameExternalIDPair] = []\n        data: List[Dict] = response.json()[\"artists\"]\n        for artist in data:\n            artist = NameExternalIDPair(artist[\"name\"], artist[\"id\"])\n            if artist.name is None or artist.external_id is None:\n                raise SpotifyClientError(\"Name or ID is missing\")\n            result.append(artist)\n\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef event_details(event_id=None, lang=\"en\"):\n    if event_id:\n        cache_name = \"event_details.%s.%s.json\" % (event_id, lang)\n        params = {\"event_id\": event_id, \"lang\": lang}\n    else:\n        cache_name = \"event_details.%s.json\" % lang\n        params = {\"lang\": lang}\n\n    data = get_cached(\"event_details.json\", cache_name, params=params)\n    events = data[\"events\"]\n    return events.get(event_id) if event_id else events", "response": "This resource returns the static details about available events."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfits to a field map", "response": "def PhenomModel(self, r):\n        \"\"\"Fit to field map\n\n        A phenomenological fit by Ryan Bayes (Glasgow) to a field map\n        generated by Bob Wands (FNAL).  It assumes a 1 cm plate.  This is dated\n        January 30th, 2012.  Not defined for r <= 0\"\"\"\n        if r <= 0:\n            raise ValueError\n        field = self.B0 + self.B1 * G4.m / r + self.B2 * math.exp(-1 * self.H * r / G4.m)\n        return field"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_customer(cls, customer, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_customer_with_http_info(customer, **kwargs)\n        else:\n            (data) = cls._create_customer_with_http_info(customer, **kwargs)\n            return data", "response": "Create a new customer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting an instance of Customer by its ID.", "response": "def delete_customer_by_id(cls, customer_id, **kwargs):\n        \"\"\"Delete Customer\n\n        Delete an instance of Customer by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_customer_by_id(customer_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str customer_id: ID of customer to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_customer_by_id_with_http_info(customer_id, **kwargs)\n        else:\n            (data) = cls._delete_customer_by_id_with_http_info(customer_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding Customer by its ID Return single instance of Customer by its ID.", "response": "def get_customer_by_id(cls, customer_id, **kwargs):\n        \"\"\"Find Customer\n\n        Return single instance of Customer by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_customer_by_id(customer_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str customer_id: ID of customer to return (required)\n        :return: Customer\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_customer_by_id_with_http_info(customer_id, **kwargs)\n        else:\n            (data) = cls._get_customer_by_id_with_http_info(customer_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nlisting all customers in a specific language", "response": "def list_all_customers(cls, **kwargs):\n        \"\"\"List Customers\n\n        Return a list of Customers\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_customers(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[Customer]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_customers_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_customers_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces all attributes of a customer by ID", "response": "def replace_customer_by_id(cls, customer_id, customer, **kwargs):\n        \"\"\"Replace Customer\n\n        Replace all attributes of Customer\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_customer_by_id(customer_id, customer, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str customer_id: ID of customer to replace (required)\n        :param Customer customer: Attributes of customer to replace (required)\n        :return: Customer\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_customer_by_id_with_http_info(customer_id, customer, **kwargs)\n        else:\n            (data) = cls._replace_customer_by_id_with_http_info(customer_id, customer, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_customer_by_id(cls, customer_id, customer, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_customer_by_id_with_http_info(customer_id, customer, **kwargs)\n        else:\n            (data) = cls._update_customer_by_id_with_http_info(customer_id, customer, **kwargs)\n            return data", "response": "Update attributes of a customer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_class(rule, index):\n        # type: (Type[Rule], int) -> Type[SplitRule]\n        \"\"\"\n        Create subtype of SplitRule based on rule.\n        :param rule: Rule from which the SplitRule derive.\n        :param index: Index of the rule (in original Rule class) to use for SplitRule.\n        :return: Class inherited from SplitRule representing rule at index.\n        \"\"\"\n        name = 'SplitRule[' + rule.__name__ + ';' + str(index) + ']'\n        created = type(name, (SplitRule,), SplitRule.__dict__.copy())  # type: Type[SplitRule]\n        created.rule = rule.rules[index]\n        created.rule_index = index\n        created.from_rule = rule\n        return created", "response": "Create subclass of SplitRule based on rule and index."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset text making it a relative path", "response": "def _set_text_from_file_dialog(self, text):\r\n        \"\"\"Sets text making it a **relative path**\"\"\"\r\n\r\n        text = os.path.relpath(text, \".\")\r\n\r\n        self.edit.setText(text)\r\n        self.dialog_path = text\r\n        self._act_on_change()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef convert_sqlite_to_mysql(\n            self):\n        \"\"\"*copy the contents of the sqlite database into the mysql database*\n\n        See class docstring for usage\n        \"\"\"\n        from fundamentals.renderer import list_of_dictionaries\n        from fundamentals.mysql import directory_script_runner\n        self.log.debug('starting the ``convert_sqlite_to_mysql`` method')\n\n        con = lite.connect(self.pathToSqlite)\n        con.row_factory = lite.Row\n        cur = con.cursor()\n\n        # GET ALL TABLE NAMES\n        cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n        tables = cur.fetchall()\n\n        createStatements = []\n        inserts = []\n        for table in tables:\n            table = table['name']\n            if table == \"sqlite_sequence\":\n                continue\n\n            # CREATE TABLE collection_books (folder_id, fingerprint, primary key(folder_id, fingerprint));\n            # GENEREATE THE MYSQL CREATE STATEMENTS FOR EACH TABLE\n            cur.execute(\n                \"SELECT sql FROM sqlite_master WHERE name = '%(table)s';\" % locals())\n            createStatement = cur.fetchone()\n            createStatement = createStatement[0].replace('\"', '`') + \";\"\n            if \"DEFAULT\" not in createStatement:\n                if \"primary key(\" in createStatement:\n                    tmp = createStatement.split(\"primary key(\")\n                    tmp[0] = tmp[0].replace(\n                        \",\", \" varchar(150) DEFAULT NULL,\")\n                    createStatement = (\"primary key(\").join(tmp)\n                if \"primary key,\" in createStatement:\n                    tmp = createStatement.split(\"primary key,\")\n                    tmp[1] = tmp[1].replace(\n                        \",\", \" varchar(150) DEFAULT NULL,\")\n                    tmp[1] = tmp[1].replace(\n                        \");\", \" varchar(150) DEFAULT NULL);\")\n                    createStatement = (\"primary key,\").join(tmp)\n            createStatement = createStatement.replace(\n                \"INTEGER PRIMARY KEY\", \"INTEGER AUTO_INCREMENT PRIMARY KEY\")\n            createStatement = createStatement.replace(\n                \"AUTOINCREMENT\", \"AUTO_INCREMENT\")\n            createStatement = createStatement.replace(\n                \"DEFAULT 't'\", \"DEFAULT '1'\")\n            createStatement = createStatement.replace(\n                \"DEFAULT 'f'\", \"DEFAULT '0'\")\n            createStatement = createStatement.replace(\",'t'\", \",'1'\")\n            createStatement = createStatement.replace(\",'f'\", \",'0'\")\n            if \"CREATE TABLE `\" in createStatement:\n                createStatement = createStatement.replace(\n                    \"CREATE TABLE `\", \"CREATE TABLE IF NOT EXISTS `\" + self.tablePrefix)\n            else:\n                createStatement = createStatement.replace(\n                    \"CREATE TABLE \", \"CREATE TABLE IF NOT EXISTS \" + self.tablePrefix)\n            if \", primary key(\" in createStatement:\n                createStatement = createStatement.replace(\", primary key(\", \"\"\",\n`dateCreated` datetime DEFAULT CURRENT_TIMESTAMP,\n`dateLastModified` datetime DEFAULT CURRENT_TIMESTAMP,\n`updated` tinyint(4) DEFAULT '0',\nprimary key(\"\"\")\n            else:\n                createStatement = createStatement.replace(\");\", \"\"\",\n    `dateCreated` datetime DEFAULT CURRENT_TIMESTAMP,\n    `dateLastModified` datetime DEFAULT CURRENT_TIMESTAMP,\n    `updated` tinyint(4) DEFAULT '0');\n                \"\"\")\n            createStatement = createStatement.replace(\n                \" text primary key\", \" varchar(100) primary key\")\n            createStatement = createStatement.replace(\n                \"`EntryText` TEXT NOT NULL,\", \"`EntryText` TEXT,\")\n            createStatement = createStatement.replace(\n                \"`SelectionText` TEXT NOT NULL\", \"`SelectionText` TEXT\")\n            createStatement = createStatement.replace(\n                \"`Filename` INTEGER NOT NULL,\", \"`Filename` TEXT NOT NULL,\")\n            createStatement = createStatement.replace(\n                \"`SessionPartUUID` TEXT NOT NULL UNIQUE,\", \"`SessionPartUUID` VARCHAR(100) NOT NULL UNIQUE,\")\n            createStatement = createStatement.replace(\n                \"`Name` TEXT PRIMARY KEY NOT NULL\", \"`Name` VARCHAR(100) PRIMARY KEY NOT NULL\")\n            createStatement = createStatement.replace(\n                \" VARCHAR \", \" VARCHAR(100) \")\n            createStatement = createStatement.replace(\n                \" VARCHAR,\", \" VARCHAR(100),\")\n\n            # GRAB THE DATA TO ADD TO THE MYSQL DATABASE TABLES\n            cur.execute(\n                \"SELECT * from '%(table)s';\" % locals())\n            rows = cur.fetchall()\n\n            allRows = []\n            for row in rows:\n                allRows.append(dict(row))\n\n            # RECURSIVELY CREATE MISSING DIRECTORIES\n            if not os.path.exists(\"/tmp/headjack/\"):\n                os.makedirs(\"/tmp/headjack/\")\n\n            writequery(\n                log=self.log,\n                sqlQuery=createStatement,\n                dbConn=self.dbConn,\n            )\n\n            from fundamentals.mysql import insert_list_of_dictionaries_into_database_tables\n            # USE dbSettings TO ACTIVATE MULTIPROCESSING\n            insert_list_of_dictionaries_into_database_tables(\n                dbConn=self.dbConn,\n                log=self.log,\n                dictList=allRows,\n                dbTableName=self.tablePrefix + table,\n                uniqueKeyList=[],\n                dateModified=True,\n                dateCreated=True,\n                batchSize=10000,\n                replace=True,\n                dbSettings=self.settings[\"database settings\"]\n            )\n\n            # # DUMP THE DATA INTO A MYSQL DATABASE\n            # dataSet = list_of_dictionaries(\n            #     log=self.log,\n            #     listOfDictionaries=allRows\n            # )\n            # originalList = dataSet.list\n            # now = datetime.now()\n            # now = now.strftime(\"%Y%m%dt%H%M%S%f.sql\")\n            # mysqlData = dataSet.mysql(\n            # tableName=self.tablePrefix + table, filepath=\"/tmp/headjack/\" +\n            # now, createStatement=createStatement)\n\n            # directory_script_runner(\n            #     log=self.log,\n            #     pathToScriptDirectory=\"/tmp/headjack/\",\n            #     databaseName=self.settings[\"database settings\"][\"db\"],\n            #     loginPath=self.settings[\"database settings\"][\"loginPath\"],\n            #     successRule=\"delete\",\n            #     failureRule=\"failed\"\n            # )\n\n        con.close()\n\n        self.log.debug('completed the ``convert_sqlite_to_mysql`` method')\n        return None", "response": "converts the contents of the sqlite database into the mysql database"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_data(self, configuration, output_file):\n        params = configuration\n        response = self.__app.native_api_call('metaql', 'download-data', params, self.__options, False, None, True, http_path=\"/api/v1/meta/\")\n        with open(output_file, 'wb') as out_file:\n            shutil.copyfileobj(response.raw, out_file)\n        del response", "response": "Download data from the metaql server."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_schema(self, db_alias, entity):\n        response = self.__app.native_api_call('metaql', 'schema/' + db_alias + '/' + entity, {}, self.__options, False, None, False, http_path=\"/api/v1/meta/\", http_method=\"GET\")\n        return json.loads(response.text)", "response": "\u041f\u043e\u043b\u044c\u044f \u0411\u0414\n            - \u041f\u043e\u043b\u044c\u044f \u0411\u0414\n            - \u041f\u043e\u043b\u044c\u044f \u0411\u0414\n            - \u041f\u043e\u043b\u044c\u044f \u0411\u0414\n            - \u041f\u043e\u043b\u044c\u044f \u0411\u0414\n            - \u041f\ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_dir(self, dir_):\n\n        self.__lock_set_dir(dir_)\n        self.__lock_auto_load()\n        self.__lock_update_table()\n        self.__update_info()\n        self.__update_window_title()", "response": "Sets the directory auto - loads updates all GUI contents."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __update_info(self):\n\n        from f311 import explorer as ex\n        import f311\n\n        t = self.tableWidget\n        z = self.listWidgetVis\n        z.clear()\n        classes = self.__vis_classes = []\n        propss = self.__lock_get_current_propss()\n        npp = len(propss)\n        s0, s1 = \"\", \"\"\n        if npp == 1:\n            p = propss[0]\n            # Visualization options\n            if p.flag_scanned:\n                if isinstance(p.f, f311.DataFile):\n                    classes.extend(f311.get_suitable_vis_classes(p.f))\n                    if ex.VisPrint in classes:\n                        classes.remove(ex.VisPrint)\n                if p.flag_text:\n                    # This is an exception, since \"txt\" is not a Vis descendant.\n                    # This will be properly handled in __visualize()\n                    classes.append(\"txt\")\n\n                for x in classes:\n                    if x == \"txt\":\n                        text = \"View plain text\"\n                    else:\n                        text = x.action\n                        text += \" (\"+x.__name__+\")\"\n                    item = QListWidgetItem(text)\n                    z.addItem(item)\n\n            # File info\n            s0 = p.get_summary()\n            s1 = p.get_info()\n\n        elif npp >= 2:\n            s0 = \"{0:d} selected\".format(npp)\n            ff = [p.f for p in propss]\n            flag_spectra = all([isinstance(f, f311.FileSpectrum) for f in ff])\n\n            # gambiarra to visualize several PFANT .mod files\n            has_pyfant = False\n            try:\n                import pyfant\n                has_pyfant = True\n            except:\n                pass\n\n            flag_mod = False\n            if has_pyfant:\n                flag_mod = all([isinstance(f, pyfant.FileModBin) and len(f.records) > 1 for f in ff])\n\n            if flag_spectra:\n                z.addItem(QListWidgetItem(\"Plot spectra stacked\"))\n                classes.append(\"sta\")\n                z.addItem(QListWidgetItem(\"Plot spectra overlapped\"))\n                classes.append(\"ovl\")\n            elif flag_mod:\n\n                # TODO plugin-based way to handle visualization of multiple selection\n\n                z.addItem(QListWidgetItem(\"View model grid\"))\n                classes.append(\"modgrid\")\n                \n        # File info\n        self.labelSummary.setText(s0)\n        self.textEditInfo.setPlainText(s1)", "response": "Updates visualization options and file info areas."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate(self, value):\n        if value in self.empty_values and self.required:\n            raise ValidationError(self.error_messages['required'])", "response": "Validate that the value is valid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clean(self, value):\n\n        obj = self.factory.create(value)\n\n        # todo: what if the field defines properties that have any of\n        # these names:\n        if obj:\n            del obj.fields\n            del obj.alias\n            del obj.validators\n            del obj.required\n            del obj.factory\n\n        # do own cleaning first...\n        self._validate_existence(obj)\n        self._run_validators(obj)\n\n        # ret = {}\n        # for name in self.fields.keys():\n        #     ret[name] = getattr(obj, name)\n        # return ret\n        return obj", "response": "Clean the data and validate the nested spec."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef serialize(self, value, entity, request):\n\n        self._validate_existence(value)\n        self._run_validators(value)\n\n        if not value:\n            return value\n\n        return self.factory.serialize(value, request)", "response": "Serialize the value to a dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _run_validators(self, value):\n        errors = []\n        for v in self.validators:\n            try:\n                v(value)\n            except ValidationError, e:\n                errors.extend(e.messages)\n        if errors:\n            raise ValidationError(errors)", "response": "Execute all associated validators."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npropagates to list elements.", "response": "def clean(self, value):\n        \"\"\" Propagate to list elements. \"\"\"\n        value = super(ListField, self).clean(value)\n        if value is not None:\n            return map(self.itemspec.clean, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nserializes to list elements.", "response": "def serialize(self, value, entity, request):\n        \"\"\" Propagate to list elements. \"\"\"\n        value = super(ListField, self).serialize(value, entity, request)\n        if value is None:\n            return\n        ret = []\n        for v in value:\n            ret.append(self.itemspec.serialize(v, entity, request))\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef try_log_part(self, context=None, with_start_message=True):\n        if context is None:\n            context = {}\n        self.__counter += 1\n        if time.time() - self.__begin_time > self.__part_log_time_seconds:\n            self.__begin_time = time.time()\n            context['count'] = self.__counter\n            if self.__total:\n                self.__percent_done = int(self.__counter * 100 / self.__total)\n                context['percentDone'] = self.__percent_done\n                context['total'] = self.__total\n            self.__log.info(msg=self.__log_message, context=context)\n            return True\n        elif self.__counter == 1:\n            if with_start_message:\n                self.__log.info(u\"\u041d\u0430\u0447\u0430\u043b\u0438 \u0446\u0438\u043a\u043b: \" + self.__log_message)\n            return True\n        return False", "response": "Try to log a single instance of the class."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreplace SplittedRules in the parsed tree with the original one.", "response": "def splitted_rules(root):\n    # type: (Nonterminal) -> Nonterminal\n    \"\"\"\n    Replace SplittedRules in the parsed tree with the original one.\n    This method is mandatory if you insert Rule class with multiple rules into the grammar.\n    :param root: Root of the parsed tree.\n    :return: Modified tree.\n    \"\"\"\n    items = Traversing.post_order(root)\n    items = filter(lambda x: isinstance(x, SplitRule), items)\n    for i in items:\n        # create the original rule\n        newRule = i.from_rule()\n        # replace it with the node in the tree\n        Manipulations.replace(i, newRule)\n    return root"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new instance of UnitSymbolReachability.", "response": "def find_nonterminals_reachable_by_unit_rules(grammar):\n    # type: (Grammar) -> UnitSymbolReachability\n    \"\"\"\n    Get nonterminal for which exist unit rule\n    :param grammar: Grammar where to search\n    :return: Instance of UnitSymbolReachability.\n    \"\"\"\n    # get nonterminals\n    nonterminals = list(grammar.nonterminals)  # type: List[Type[Nonterminal]]\n    count_of_nonterms = len(nonterminals)\n    # create indexes for nonterminals\n    nonterm_to_index = dict()  # type: Dict[Type[Nonterminal], int]\n    for i in range(count_of_nonterms):\n        nonterm_to_index[nonterminals[i]] = i\n    # prepare matrix\n    field = [[None for _ in nonterminals] for _ in nonterminals]  # type: MATRIX_OF_UNIT_RULES\n    # fill existing unit rules\n    for rule in grammar.rules:\n        if _is_unit(rule):\n            field[nonterm_to_index[rule.fromSymbol]][nonterm_to_index[rule.toSymbol]] = [rule]\n    # run Floyd Warshall\n    f = field\n    for k in range(count_of_nonterms):\n        for i in range(count_of_nonterms):\n            for j in range(count_of_nonterms):\n                if f[i][k] is not None and f[k][j] is not None:\n                    if f[i][j] is None or len(f[i][j]) > len(f[i][k]) + len(f[k][j]):\n                        f[i][j] = f[i][k] + f[k][j]\n    # return results\n    return UnitSymbolReachability(f, nonterm_to_index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of nonterminals which are rewritable from from_symbol.", "response": "def reachables(self, from_symbol):\n        # type: (Type[Nonterminal]) -> List[Type[Nonterminal]]\n        \"\"\"\n        Get list of nonterminals, what are rewritable from nonterminal passed as parameter\n        using only unit rules.\n        :param from_symbol: For which symbols to search.\n        :return: List of nonterminals.\n        \"\"\"\n        if from_symbol not in self.t:\n            return []\n        reachable = []\n        index = self.t[from_symbol]\n        for n, i in self.t.items():\n            if len(self.f[index][i] or []) > 0:\n                reachable.append(n)\n        return reachable"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef path_rules(self, from_symbol, to_symbol):\n        # type: (Type[Nonterminal], Type[Nonterminal]) -> List[Type[Rule]]\n        \"\"\"\n        Get sequence of unit rules between first and second parameter.\n        :param from_symbol: From which symbol.\n        :param to_symbol: To which symbol.\n        :return: Sequence of unit rules. Empty sequence mean there is no way between them.\n        \"\"\"\n        if from_symbol not in self.t or to_symbol not in self.t:\n            return []\n        return self.f[self.t[from_symbol]][self.t[to_symbol]] or []", "response": "Returns the sequence of rules between first and second parameter."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all of the active messages ordered by the active_datetime.", "response": "def get_all_active(self):\n        \"\"\"\n        Get all of the active messages ordered by the active_datetime.\n        \"\"\"\n        now = timezone.now()\n        return self.select_related().filter(active_datetime__lte=now,\n                                              inactive_datetime__gte=now).order_by('active_datetime')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_word(self,word,size,color):\n        '''Creates a surface that contains a word.'''\n        pygame.font.init()\n        font = pygame.font.Font(None,size)\n        self.rendered_word = font.render(word,0,color)\n        self.word_size = font.size(word)", "response": "Creates a surface that contains a word."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef collides(self,position,size):\n        '''Returns True if the word collides with another plotted word.'''\n        word_rect = pygame.Rect(position,self.word_size)\n        if word_rect.collidelistall(self.used_pos) == []:\n            return False\n        else:\n            return True", "response": "Returns True if the word collides with another plotted word."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmaking the cloud surface bigger. Maintains all word positions.", "response": "def expand(self,delta_width,delta_height):\n        '''Makes the cloud surface bigger. Maintains all word positions.'''\n        temp_surface = pygame.Surface((self.width + delta_width,self.height + delta_height))\n        (self.width,self.height) = (self.width + delta_width, self.height + delta_height)\n        temp_surface.blit(self.cloud,(0,0))\n        self.cloud = temp_surface"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smart_cloud(self,input,max_text_size=72,min_text_size=12,exclude_words = True):\n        '''Creates a word cloud using the input.\n           Input can be a file, directory, or text.\n           Set exclude_words to true if you want to eliminate words that only occur once.'''\n        self.exclude_words = exclude_words\n        if isdir(input):\n            self.directory_cloud(input,max_text_size,min_text_size)\n        elif isfile(input):\n            text = read_file(input)\n            self.text_cloud(text,max_text_size,min_text_size)\n        elif isinstance(input, basestring):\n            self.text_cloud(input,max_text_size,min_text_size)\n        else:\n            print 'Input type not supported.'\n            print 'Supported types: String, Directory, .txt file'", "response": "Creates a word cloud using the input."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a word cloud using files from a directory.", "response": "def directory_cloud(self,directory,max_text_size=72,min_text_size=12,expand_width=50,expand_height=50,max_count=100000):\n        '''Creates a word cloud using files from a directory.\n        The color of the words correspond to the amount of documents the word occurs in.'''\n        worddict = assign_fonts(tuplecount(read_dir(directory)),max_text_size,min_text_size,self.exclude_words)\n        sorted_worddict = list(reversed(sorted(worddict.keys(), key=lambda x: worddict[x])))\n        colordict = assign_colors(dir_freq(directory))\n        num_words = 0\n        for word in sorted_worddict:\n            self.render_word(word,worddict[word],colordict[word])\n            if self.width < self.word_size[0]:\n                #If the word is bigger than the surface, expand the surface.\n                self.expand(self.word_size[0]-self.width,0)\n            elif self.height < self.word_size[1]:\n                self.expand(0,self.word_size[1]-self.height)\n            position = [randint(0,self.width-self.word_size[0]),randint(0,self.height-self.word_size[1])]\n            #the initial position is determined\n            loopcount = 0\n            while self.collides(position,self.word_size):\n                if loopcount > max_count:\n                #If it can't find a position for the word, create a bigger cloud.\n                    self.expand(expand_width,expand_height)      \n                    loopcount = 0\n                position = [randint(0,self.width-self.word_size[0]),randint(0,self.height-self.word_size[1])]\n                loopcount += 1\n            self.plot_word(position)\n            num_words += 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a word cloud using plain text.", "response": "def text_cloud(self,text,max_text_size=72,min_text_size=12,expand_width=50,expand_height=50,max_count=100000):\n        '''Creates a word cloud using plain text.'''\n        worddict = assign_fonts(tuplecount(text),max_text_size,min_text_size,self.exclude_words)\n        sorted_worddict = list(reversed(sorted(worddict.keys(), key=lambda x: worddict[x])))\n        for word in sorted_worddict:\n            self.render_word(word,worddict[word],(randint(0,255),randint(0,255),randint(0,255)))\n            if self.width < self.word_size[0]:\n                #If the word is bigger than the surface, expand the surface.\n                self.expand(self.word_size[0]-self.width,0)\n            elif self.height < self.word_size[1]:\n                self.expand(0,self.word_size[1]-self.height)\n            position = [randint(0,self.width-self.word_size[0]),randint(0,self.height-self.word_size[1])]\n            loopcount = 0\n            while self.collides(position,self.word_size):\n                if loopcount > max_count:\n                #If it can't find a position for the word, expand the cloud.\n                    self.expand(expand_width,expand_height)\n                    loopcount = 0\n                position = [randint(0,self.width-self.word_size[0]),randint(0,self.height-self.word_size[1])]\n                loopcount += 1\n            self.plot_word(position)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying the word cloud to the screen.", "response": "def display(self):\n        '''Displays the word cloud to the screen.'''\n        pygame.init()\n        self.display = pygame.display.set_mode((self.width,self.height))\n        self.display.blit(self.cloud,(0,0))\n        pygame.display.update()\n        while True:\n            for event in pygame.event.get():\n                if event.type == pygame.QUIT:\n                    pygame.quit()\n                    return"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef gf_lehmann(eig_e, eig_states, d_dag, beta, omega, d=None):\n\n    ew = np.exp(-beta*eig_e)\n    zet = ew.sum()\n    G = np.zeros_like(omega)\n    basis_create = np.dot(eig_states.T, d_dag.dot(eig_states))\n    if d is None:\n        tmat = np.square(basis_create)\n    else:\n        tmat = np.dot(eig_states.T, d.T.dot(eig_states))*basis_create\n\n    tmat *= np.add.outer(ew, ew)\n    gap = np.add.outer(-eig_e, eig_e)\n\n    N = eig_e.size\n    for i, j in product(range(N), range(N)):\n        G += tmat[i, j] / (omega + gap[i, j])\n    return G / zet", "response": "Outputs the lehmann representation of the greens function\n       omega has to be given as matsubara"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef expected_value(operator, eig_values, eig_states, beta):\n    aux = np.einsum('i,ji,ji', np.exp(-beta*eig_values),\n                    eig_states, operator.dot(eig_states))\n\n    return aux / partition_func(beta, eig_values)", "response": "Calculates the expected value of an observable\n       it requires that the states and operators have the same base"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new Category with the specified attributes.", "response": "def create_category(cls, category, **kwargs):\n        \"\"\"Create Category\n\n        Create a new Category\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_category(category, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param Category category: Attributes of category to create (required)\n        :return: Category\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_category_with_http_info(category, **kwargs)\n        else:\n            (data) = cls._create_category_with_http_info(category, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_category_by_id(cls, category_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_category_by_id_with_http_info(category_id, **kwargs)\n        else:\n            (data) = cls._delete_category_by_id_with_http_info(category_id, **kwargs)\n            return data", "response": "Delete an instance of Category by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding Category by ID Return single instance of Category by its ID.", "response": "def get_category_by_id(cls, category_id, **kwargs):\n        \"\"\"Find Category\n\n        Return single instance of Category by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_category_by_id(category_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str category_id: ID of category to return (required)\n        :return: Category\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_category_by_id_with_http_info(category_id, **kwargs)\n        else:\n            (data) = cls._get_category_by_id_with_http_info(category_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_categories(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_categories_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_categories_with_http_info(**kwargs)\n            return data", "response": "List Categories\n        Return a list of Categories\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace_category_by_id(cls, category_id, category, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_category_by_id_with_http_info(category_id, category, **kwargs)\n        else:\n            (data) = cls._replace_category_by_id_with_http_info(category_id, category, **kwargs)\n            return data", "response": "Replace all attributes of a Category by ID"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_category_by_id(cls, category_id, category, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_category_by_id_with_http_info(category_id, category, **kwargs)\n        else:\n            (data) = cls._update_category_by_id_with_http_info(category_id, category, **kwargs)\n            return data", "response": "Update attributes of a Category by ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of strings that can be used as plain text for the message.", "response": "def get_plain_text(self):\r\n        \"\"\"Returns a list\"\"\"\r\n        _msg = self.message if self.message is not None else [\"\"]\r\n        msg = _msg if isinstance(_msg, list) else [_msg]\r\n        line = \"\" if not self.line else \", line {}\".format(self.line)\r\n        ret = [\"{} found in file '{}'{}::\".format(self.type.capitalize(), self.filename, line),\r\n               \"  <<\"]+ \\\r\n              [\"    \"+x for x in msg]+ \\\r\n              [\"  >>\"]\r\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_plain_text(self):\r\n        ret = []\r\n        for occ in self.occurrences:\r\n            ret.extend(occ.get_plain_text())\r\n        return ret", "response": "Returns a list of strings that contains the most recent occurrence of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef slugify(string):\r\n    string = re.sub('[^\\w .-]', '', string)\r\n    string = string.replace(\" \", \"-\")\r\n    return string", "response": "Returns a slugified version of the given string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef crunch_dir(name, n=50):\r\n    if len(name) > n + 3:\r\n        name = \"...\" + name[-n:]\r\n    return name", "response": "Puts... in the middle of a directory name if lengh > n."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a prefix and suffix to a file name.", "response": "def add_bits_to_path(path_, filename_prefix=None, extension=None):\r\n    \"\"\"\r\n    Adds prefix/suffix to filename\r\n\r\n    Arguments:\r\n        path_ -- path to file\r\n        filename_prefix -- prefix to be added to file name\r\n        extension -- extension to be added to file name. The dot is automatically added, such as\r\n            \"ext\" and \".ext\" will have the same effect\r\n\r\n    Examples:\r\n        > add_bits_to_path(\"/home/user/file\", \"prefix-\")\r\n        /home/user/prefix-file\r\n\r\n        > add_bits_to_path(\"/home/user/file\", None, \".ext\")\r\n        /home/user/file.ext\r\n\r\n        > add_bits_to_path(\"/home/user/file\", None, \"ext\")  # dot in extension is optional\r\n        /home/user/file.ext\r\n\r\n        > add_bits_to_path(\"/home/user/\", None, \".ext\")\r\n        /home/user/.ext\r\n    \"\"\"\r\n\r\n    dir_, basename = os.path.split(path_)\r\n\r\n    if filename_prefix:\r\n        basename = filename_prefix+basename\r\n    if extension:\r\n        if not extension.startswith(\".\"):\r\n            extension = \".\"+extension\r\n        basename = basename+extension\r\n\r\n    return os.path.join(dir_, basename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of strings that spans several rows in a text file.", "response": "def multirow_str_vector(f, n, r=0):\r\n    \"\"\"\r\n    Assembles a vector that spans several rows in a text file.\r\n\r\n    Arguments:\r\n      f -- file-like object\r\n      n -- number of values expected\r\n      r (optional) -- Index of last row read in file (to tell which file row in\r\n                      case of error)\r\n\r\n    Returns:\r\n      (list-of-strings, number-of-rows-read-from-file)\r\n    \"\"\"\r\n\r\n    so_far = 0\r\n    n_rows = 0\r\n    v = []\r\n    while True:\r\n        temp = str_vector(f)\r\n        n_rows += 1\r\n        n_now = len(temp)\r\n\r\n        if n_now+so_far > n:\r\n            a99.get_python_logger().warning(('Reading multi-row vector: '\r\n                'row %d should have %d values (has %d)') %\r\n                (r+n_rows, n-so_far, n_now))\r\n\r\n            v.extend(temp[:n-so_far])\r\n            so_far = n\r\n\r\n        elif n_now+so_far <= n:\r\n            so_far += n_now\r\n            v.extend(temp)\r\n\r\n        if so_far == n:\r\n            break\r\n\r\n    return v, n_rows"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a new filename that does not exist yet", "response": "def new_filename(prefix, extension=None, flag_minimal=True):\r\n    \"\"\"returns a file name that does not exist yet, e.g. prefix.0001.extension\r\n\r\n    Args:\r\n        prefix:\r\n        extension: examples: \"dat\", \".dat\" (leading dot will be detected, does not repeat dot in name)\r\n        flag_minimal:\r\n\r\n          - True: will try to be as \"clean\" as possible\r\n          - False: will generate filenames in a simple, same-length pattern\r\n\r\n    Example: ``new_filename(\"molecules-\", \"dat\", True)``\r\n\r\n    In the example above, the first attempt will be \"molecules.dat\", then \"molecules-0000.dat\".\r\n    If flag_minimal were True, it would skip the first attempt.\r\n    \"\"\"\r\n\r\n    if extension is None:\r\n        extension = \"\"\r\n\r\n    if len(extension) > 0 and extension[0] == '.':\r\n        extension = extension[1:]\r\n\r\n    # extension-sensitive format for filename\r\n    fmt = '{0!s}-{1:04d}.{2!s}' if extension else '{0!s}-{1:04d}'\r\n\r\n    # Removes tailing dash because it would look funny (but will be re-added in format string)\r\n    prefix_ = prefix[:-1] if prefix.endswith(\"-\") else prefix\r\n\r\n    i = -1\r\n    while True:\r\n        if i == -1:\r\n            if flag_minimal:\r\n                ret = \"{}.{}\".format(prefix_, extension) if extension else prefix_\r\n        else:\r\n            ret = fmt.format(prefix_, i, extension)\r\n\r\n        if not os.path.exists(ret):\r\n            break\r\n        i += 1\r\n        if i > 9999:\r\n            raise RuntimeError(\"Could not make a new file name for (prefix='{0!s}', extension='{1!s}')\".format(prefix, extension))\r\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rename_to_temp(filename):\r\n    with _rename_to_temp_lock:\r\n        root, ext = os.path.splitext(filename)\r\n        if len(ext) > 0:\r\n            ext = ext[1:]  # the dot (\".\") is originally included\r\n        new_name = new_filename(root, ext)\r\n        os.rename(filename, new_name)\r\n        return new_name", "response": "Rename file to temporary filename. Returns new name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_symlink(source, link_name):\r\n    os_symlink = getattr(os, \"symlink\", None)\r\n    if isinstance(os_symlink, collections.Callable):\r\n        os_symlink(source, link_name)\r\n    else:\r\n        import ctypes\r\n        csl = ctypes.windll.kernel32.CreateSymbolicLinkW\r\n        csl.argtypes = (ctypes.c_wchar_p, ctypes.c_wchar_p, ctypes.c_uint32)\r\n        csl.restype = ctypes.c_ubyte\r\n        flags = 1 if os.path.isdir(source) else 0\r\n        if csl(link_name, source, flags) == 0:\r\n            raise ctypes.WinError()", "response": "Creates a symbolic link for the source directory."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_text_file(filepath, blocksize=2**14):\r\n    with open(filepath, \"rb\") as fileobj:\r\n        block = fileobj.read(blocksize)\r\n        if b'\\x00' in block:\r\n            # Files with null bytes are binary\r\n            return False\r\n        elif not block:\r\n            # an empty file is considered a valid text file\r\n            return True\r\n\r\n        # Use translate's 'deletechars' argument to efficiently remove all\r\n        # occurrences of _text_characters from the block\r\n        nontext = block.translate(None, _text_characters)\r\n        return float(len(nontext)) / len(block) <= 0.30", "response": "Returns True if the given file is a text file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning full path to specified module", "response": "def get_path(*args, module=a99):\r\n    \"\"\"Returns full path to specified module\r\n\r\n    Args:\r\n      *args: are added at the end of module path with os.path.join()\r\n      module: Python module, defaults to a99\r\n\r\n    Returns: path string\r\n\r\n    >>> get_path()\r\n    \"\"\"\r\n\r\n    p = os.path.abspath(os.path.join(os.path.split(module.__file__)[0], *args))\r\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef harvest_repo(root_url, archive_path, tag=None, archive_mode='w:gz'):\n\n    if not svn_exists():\n        raise Exception(\"SVN not found. It probably needs installing.\")\n\n    clone_path = mkdtemp(dir=cfg['CFG_TMPDIR'])\n\n    svn = get_which_svn()\n\n    if tag:\n        call([svn, 'co', root_url + '/tags/' + tag, clone_path])\n    else:\n        call([svn, 'co', root_url + '/trunk/', clone_path])\n\n    chdir(cfg['CFG_TMPDIR'])\n    tar = tarfile.open(name=archive_path, mode=archive_mode)\n    tar.add(clone_path, arcname=root_url.split('/').pop())\n    tar.close()\n\n    try:\n        rmtree(clone_path)\n    except OSError as e:\n        # Reraise unless ENOENT: No such file or directory\n        # (ok if directory has already been deleted)\n        if e.errno != errno.ENOENT:\n            raise", "response": "This function will harvest a specific tag in a specific SVN repository."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef send_recovery_notice(self, login, app_alias, state=None):\n        data = {\n            \"login\": login,\n            \"appAlias\": app_alias,\n            \"state\": state,\n        }\n        response = self.__app.native_api_call('user-management', 'sendRecoveryNotice', data, self.__options, False, None, False, http_path=\"/api/meta/v1/\", http_method=\"POST\")\n        return json.loads(response.text)", "response": "Send a recovery notice to the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_data_dir(appname=None, appauthor=None, version=None, roaming=False, as_path=False):\n    if system == \"win32\":\n        if appauthor is None:\n            appauthor = appname\n        const = roaming and \"CSIDL_APPDATA\" or \"CSIDL_LOCAL_APPDATA\"\n        path = os.path.normpath(_get_win_folder(const))\n        if appname:\n            if appauthor is not False:\n                path = os.path.join(path, appauthor, appname)\n            else:\n                path = os.path.join(path, appname)\n    elif system == 'darwin' and not os.getenv('XDG_DATA_HOME'):\n        path = os.path.expanduser('~/Library/Application Support/')\n        if appname:\n            path = os.path.join(path, appname)\n    else:\n        path = os.getenv('XDG_DATA_HOME') or os.path.expanduser(\"~/.local/share\")\n        if appname:\n            path = os.path.join(path, appname)\n    if appname and version:\n        path = os.path.join(path, version)\n    if as_path:\n        path = Path(path)\n    return path", "response": "r Returns full path to the user - specific data directory for this application."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads as many files as the number of pages is set to True.", "response": "def load_many(self, fobjs=None):\r\n        \"\"\"Loads as many files as the number of pages\r\n\r\n        Args:\r\n            fobjs: [filename or DataFile obj, ...]\"\"\"\r\n        if fobjs is not None:\r\n            # tolerance\r\n            if not hasattr(fobjs, \"__iter__\"):\r\n                fobjs = [fobjs]\r\n\r\n            for index, (fobj, page) in enumerate(zip(fobjs, self.pages)):\r\n                if fobj is None:\r\n                    continue\r\n                elif isinstance(fobj, ft.DataFile):\r\n                    self.load(fobj, index)\r\n                elif isinstance(fobj, str):\r\n                    self.load_filename(fobj, index)\r\n                else:\r\n                    raise TypeError(\"Invalid object of class '{}'\".format(fobj.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds element to pages and new tab", "response": "def _add_log_tab(self):\r\n        \"\"\"Adds element to pages and new tab\"\"\"\r\n\r\n        # text_tab = \"Log (Alt+&{})\".format(len(self.pages)+1)\r\n        text_tab = \"Log\"\r\n\r\n        self.pages.append(MyPage(text_tab=text_tab))\r\n\r\n        # ### Log tab\r\n        te = self.textEdit_log = self.keep_ref(QTextEdit())\r\n        te.setReadOnly(True)\r\n        self.tabWidget.addTab(te, text_tab)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, fobj, index=None):\r\n        if index is None:\r\n            index = self._get_tab_index()\r\n        page = self.pages[index]\r\n\r\n        if fobj is None:\r\n            return\r\n\r\n\r\n        if not isinstance(fobj, tuple(page.clss_load)):\r\n            raise RuntimeError('Object to load must be in {0!s} (not a {1!s})'.format(\r\n             [x.__name__ for x in page.clss_load], fobj.__class__.__name__))\r\n\r\n        page.editor.load(fobj)\r\n        self._update_gui_text_tabs()", "response": "Loads given object into current tab."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_filename(self, filename, index=None):\r\n        filename = str(filename)  # QString protection\r\n        if index is None:\r\n            index = self._get_tab_index()\r\n        page = self.pages[index]\r\n\r\n        # Maybe this is set on purpose before loading attempt to leave new load_dir set (?)\r\n        self.load_dir, _ = os.path.split(filename)\r\n\r\n        clss = page.clss_load\r\n        if len(clss) == 1:\r\n            # If there is only one class to handle the file, will load it in a way that eventual\r\n            # load errors will raise\r\n            f = clss[0]()\r\n            f.load(filename)\r\n        else:\r\n            # At the moment, the multi-class alternative will not display particular error information\r\n            # if the file does not load\r\n            f = f311.load_with_classes(filename, page.clss_load)\r\n            if f is None:\r\n                raise RuntimeError(\"Could not load '{0!s}'\".format(filename))\r\n\r\n        self.load(f, index)", "response": "Loads a file into the current tab with the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nslots for changed events", "response": "def _on_changed(self):\r\n        \"\"\"Slot for changed events\"\"\"\r\n        page = self._get_page()\r\n        if not page.flag_autosave:\r\n            page.flag_changed = True\r\n            self._update_gui_text_tabs()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning description of current tab.", "response": "def _get_tab_description(self):\r\n        \"\"\"Returns \"description\" of current tab (tab text without shortcut info).\"\"\"\r\n        text = self._get_page().text_tab\r\n        if \"(\" in text:\r\n            text = text[:text.index(\"(\") - 1]\r\n        text = text[0].lower() + text[1:]\r\n        return text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _update_gui_text_tabs(self):\r\n        for index, page in enumerate(self.pages):\r\n            self.tabWidget.setTabText(index, \"{} (Alt+&{}){}\".format(page.text_tab, index+1, (\" (changed)\" if page.flag_changed else \"\")))", "response": "Updates the tab texts of the GUI text tabs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn False if user has cancelled a save as operation otherwise True.", "response": "def __generic_save(self):\r\n        \"\"\"Returns False if user has cancelled a \"save as\" operation, otherwise True.\"\"\"\r\n        page = self._get_page()\r\n        f = page.editor.f\r\n        if not f:\r\n            return True\r\n        if not page.editor.flag_valid:\r\n            a99.show_error(\"Cannot save, {0!s} has error(s)!\".format(f.description))\r\n            return True\r\n        if f.filename:\r\n            f.save_as()\r\n\r\n            self.add_log(\"Saved '{}'\".format(f.filename))\r\n            page.flag_changed = False\r\n            self._update_gui_text_tabs()\r\n\r\n            if hasattr(page.editor, \"update_gui_label_fn\"):\r\n                page.editor.update_gui_label_fn()  # duck typing\r\n            return True\r\n        else:\r\n            return self.__generic_save_as()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn False if user has cancelled operation otherwise True.", "response": "def __generic_save_as(self):\r\n        \"\"\"Returns False if user has cancelled operation, otherwise True.\"\"\"\r\n        page = self._get_page()\r\n        if not page.editor.f:\r\n            return True\r\n        if page.editor.f.filename:\r\n            d = page.editor.f.filename\r\n        else:\r\n            d = os.path.join(self.save_dir if self.save_dir is not None \\\r\n                                 else self.load_dir if self.load_dir is not None \\\r\n                else \".\", page.editor.f.default_filename)\r\n        new_filename = QFileDialog.getSaveFileName(self, page.make_text_saveas(), d, page.wild)[0]\r\n        if new_filename:\r\n            self.save_dir, _ = os.path.split(str(new_filename))\r\n            page.editor.f.save_as(str(new_filename))\r\n            page.flag_changed = False\r\n            self._update_gui_text_tabs()\r\n            page.editor.update_gui_label_fn()\r\n            return True\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_config(self, cluster_config, login_config):\n\n        oldvalue = self.__update_option(cluster_config, 'ssh_to', 'ssh_to')\n        if oldvalue:\n            log.debug(\"Attribute 'ssh_to' updated: %s -> %s\", oldvalue, self.ssh_to)", "response": "Update the current configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a node from the known hosts of this cluster.", "response": "def remove_node(self, node, stop=False):\n        \"\"\"Removes a node from the cluster.\n\n        By default, it doesn't also stop the node, just remove from\n        the known hosts of this cluster.\n\n        :param node: node to remove\n        :type node: :py:class:`Node`\n\n        :param stop: Stop the node\n        :type stop: bool\n\n        \"\"\"\n        if node.kind not in self.nodes:\n            raise NodeNotFound(\"Unable to remove node %s: invalid node type `%s`.\",\n                               node.name, node.kind)\n        else:\n            try:\n                index = self.nodes[node.kind].index(node)\n                if self.nodes[node.kind][index]:\n                    del self.nodes[node.kind][index]\n                if stop:\n                    node.stop()\n                self._naming_policy.free(node.kind, node.name)\n                self.repository.save_or_update(self)\n            except ValueError:\n                raise NodeNotFound(\"Node %s not found in cluster\" % node.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start(self, min_nodes=None):\n\n        nodes = self.get_all_nodes()\n\n        log.info(\"Starting cluster nodes ...\")\n        if log.DO_NOT_FORK:\n            nodes = self._start_nodes_sequentially(nodes)\n        else:\n            nodes = self._start_nodes_parallel(nodes, self.thread_pool_max_size)\n\n        # checkpoint cluster state\n        self.repository.save_or_update(self)\n\n        not_started_nodes = self._check_starting_nodes(nodes, self.startup_timeout)\n\n        # now that all nodes are up, checkpoint cluster state again\n        self.repository.save_or_update(self)\n\n        # Try to connect to each node to gather IP addresses and SSH host keys\n        log.info(\"Checking SSH connection to nodes ...\")\n        pending_nodes = nodes - not_started_nodes\n        self._gather_node_ip_addresses(pending_nodes, self.startup_timeout)\n\n        # It might be possible that the node.connect() call updated\n        # the `preferred_ip` attribute, so, let's save the cluster\n        # again.\n        self.repository.save_or_update(self)\n\n        # A lot of things could go wrong when starting the cluster. To\n        # ensure a stable cluster fitting the needs of the user in terms of\n        # cluster size, we check the minimum nodes within the node groups to\n        # match the current setup.\n        min_nodes = self._compute_min_nodes(min_nodes)\n        self._check_cluster_size(min_nodes)", "response": "Starts up all the instances in the ElastiCluster."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _start_nodes_sequentially(self, nodes):\n        started_nodes = set()\n        for node in copy(nodes):\n            started = self._start_node(node)\n            if started:\n                started_nodes.add(node)\n            # checkpoint cluster state\n            self.repository.save_or_update(self)\n        return started_nodes", "response": "Start the nodes sequentially without forking."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstart the nodes in parallel using multiprocessing threads.", "response": "def _start_nodes_parallel(self, nodes, max_thread_pool_size):\n        \"\"\"\n        Start the nodes using a pool of multiprocessing threads for speed-up.\n\n        Return set of nodes that were actually started.\n        \"\"\"\n        # Create one thread for each node to start\n        thread_pool_size = min(len(nodes), max_thread_pool_size)\n        thread_pool = Pool(processes=thread_pool_size)\n        log.debug(\"Created pool of %d threads\", thread_pool_size)\n\n        # pressing Ctrl+C flips this flag, which in turn stops the main loop\n        # down below\n        keep_running = True\n\n        def sigint_handler(signal, frame):\n            \"\"\"\n            Makes sure the cluster is saved, before the sigint results in\n            exiting during node startup.\n            \"\"\"\n            log.error(\n                \"Interrupted: will save cluster state and exit\"\n                \" after all nodes have started.\")\n            keep_running = False\n\n        # intercept Ctrl+C\n        with sighandler(signal.SIGINT, sigint_handler):\n            result = thread_pool.map_async(self._start_node, nodes)\n            while not result.ready():\n                result.wait(1)\n                # check if Ctrl+C was pressed\n                if not keep_running:\n                    log.error(\"Aborting upon user interruption ...\")\n                    # FIXME: `.close()` will keep the pool running until all\n                    # nodes have been started; should we use `.terminate()`\n                    # instead to interrupt node creation as soon as possible?\n                    thread_pool.close()\n                    thread_pool.join()\n                    self.repository.save_or_update(self)\n                    # FIXME: should raise an exception instead!\n                    sys.exit(1)\n\n            # keep only nodes that were successfully started\n            return set(node for node, ok\n                       in itertools.izip(nodes, result.get()) if ok)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _start_node(node):\n        log.debug(\"_start_node: working on node `%s`\", node.name)\n        # FIXME: the following check is not optimal yet. When a node is still\n        # in a starting state, it will start another node here, since the\n        # `is_alive` method will only check for running nodes (see issue #13)\n        if node.is_alive():\n            log.info(\"Not starting node `%s` which is \"\n                     \"already up&running.\", node.name)\n            return True\n        else:\n            try:\n                node.start()\n                log.info(\"Node `%s` has been started.\", node.name)\n                return True\n            except Exception as err:\n                log.exception(\"Could not start node `%s`: %s -- %s\",\n                              node.name, err, err.__class__)\n                return False", "response": "Start the given node VM."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_cluster_size(self, min_nodes):\n        # check the total sizes before moving the nodes around\n        minimum_nodes = 0\n        for group, size in min_nodes.items():\n            minimum_nodes = minimum_nodes + size\n\n        if len(self.get_all_nodes()) < minimum_nodes:\n            raise ClusterError(\"The cluster does not provide the minimum \"\n                               \"amount of nodes specified in the \"\n                               \"configuration. The nodes are still running, \"\n                               \"but will not be setup yet. Please change the\"\n                               \" minimum amount of nodes in the \"\n                               \"configuration or try to start a new cluster \"\n                               \"after checking the cloud provider settings.\")\n\n        # finding all node groups with an unsatisfied amount of nodes\n        unsatisfied_groups = []\n        for group, size in min_nodes.items():\n            if len(self.nodes[group]) < size:\n                unsatisfied_groups.append(group)\n\n        # trying to move nodes around to fill the groups with missing nodes\n        for ugroup in unsatisfied_groups[:]:\n            missing = min_nodes[ugroup] - len(self.nodes[ugroup])\n            for group, nodes in self.nodes.items():\n                spare = len(self.nodes[group]) - min_nodes[group]\n                while spare > 0 and missing > 0:\n                    self.nodes[ugroup].append(self.nodes[group][-1])\n                    del self.nodes[group][-1]\n                    spare -= 1\n                    missing -= 1\n\n                    if missing == 0:\n                        unsatisfied_groups.remove(ugroup)\n\n        if unsatisfied_groups:\n            raise ClusterError(\"Could not find an optimal solution to \"\n                               \"distribute the started nodes into the node \"\n                               \"groups to satisfy the minimum amount of \"\n                               \"nodes. Please change the minimum amount of \"\n                               \"nodes in the configuration or try to start a\"\n                               \" new clouster after checking the cloud \"\n                               \"provider settings\")", "response": "Checks the size of the cluster to fit the minimum number of nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all nodes in this cluster as a mixed list of different node kinds.", "response": "def get_all_nodes(self):\n        \"\"\"Returns a list of all nodes in this cluster as a mixed list of\n        different node kinds.\n\n        :return: list of :py:class:`Node`\n        \"\"\"\n        nodes = self.nodes.values()\n        if nodes:\n            return reduce(operator.add, nodes, list())\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_node_by_name(self, nodename):\n        nodes = dict((n.name, n) for n in self.get_all_nodes())\n        try:\n            return nodes[nodename]\n        except KeyError:\n            raise NodeNotFound(\"Node %s not found\" % nodename)", "response": "Return the node corresponding with name nodename"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_frontend_node(self):\n        if self.ssh_to:\n            if self.ssh_to in self.nodes:\n                cls = self.nodes[self.ssh_to]\n                if cls:\n                    return cls[0]\n                else:\n                    log.warning(\n                        \"preferred `ssh_to` `%s` is empty: unable to \"\n                        \"get the choosen frontend node from that class.\",\n                        self.ssh_to)\n            else:\n                raise NodeNotFound(\n                    \"Invalid ssh_to `%s`. Please check your \"\n                    \"configuration file.\" % self.ssh_to)\n\n        # If we reach this point, the preferred class was empty. Pick\n        # one using the default logic.\n        for cls in sorted(self.nodes.keys()):\n            if self.nodes[cls]:\n                return self.nodes[cls][0]\n        # Uh-oh, no nodes in this cluster.\n        raise NodeNotFound(\"Unable to find a valid frontend: \"\n                           \"cluster has no nodes!\")", "response": "Returns the first node of the class specified in the the\n archive as ssh_to or the first node of the first class in alphabetic order."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a node name into a dictionary of parts forming name.", "response": "def _parse(name):\n        \"\"\"\n        Return dict of parts forming `name`.  Raise `ValueError` if string\n        `name` cannot be correctly parsed.\n\n        The default implementation uses\n        `NodeNamingPolicy._NODE_NAME_RE` to parse the name back into\n        constituent parts.\n\n        This is ideally the inverse of :meth:`_format` -- it should be\n        able to parse a node name string into the parameter values\n        that were used to form it.\n        \"\"\"\n        match = NodeNamingPolicy._NODE_NAME_RE.match(name)\n        if match:\n            return match.groupdict()\n        else:\n            raise ValueError(\n                \"Cannot parse node name `{name}`\"\n                    .format(name=name))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new node name for a given kind.", "response": "def new(self, kind, **extra):\n        \"\"\"\n        Return a host name for a new node of the given kind.\n\n        The new name is formed by interpolating ``{}``-format\n        specifiers in the string given as ``pattern`` argument to the\n        class constructor.  The following names can be used in the\n        ``{}``-format specifiers:\n\n        * ``kind`` -- the `kind` argument\n        * ``index`` -- a positive integer number, garanteed to be unique (per kind)\n        * any other keyword argument used in the call to :meth:`new`\n\n        Example::\n\n          >>> p = NodeNamingPolicy(pattern='node-{kind}-{index}{spec}')\n          >>> p.new('foo', spec='bar')\n          'node-foo-1bar'\n          >>> p.new('foo', spec='quux')\n          'node-foo-2quux'\n        \"\"\"\n        if self._free[kind]:\n            index = self._free[kind].pop()\n        else:\n            self._top[kind] += 1\n            index = self._top[kind]\n        return self._format(self.pattern, kind=kind, index=index, **extra)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef use(self, kind, name):\n        try:\n            params = self._parse(name)\n            index = int(params['index'], 10)\n            if index in self._free[kind]:\n                self._free[kind].remove(index)\n            top = self._top[kind]\n            if index > top:\n                self._free[kind].update(range(top + 1, index))\n                self._top[kind] = index\n        except ValueError:\n            log.warning(\n                \"Cannot extract numerical index\"\n                \" from node name `%s`!\", name)", "response": "Mark a node name as used."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef free(self, kind, name):\n        try:\n            params = self._parse(name)\n            index = int(params['index'], 10)\n            self._free[kind].add(index)\n            assert index <= self._top[kind]\n            if index == self._top[kind]:\n                self._top[kind] -= 1\n        except ValueError:\n            # ignore failures in self._parse()\n            pass", "response": "Mark a node name as no longer in use."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the current node is up and running in the cloud.", "response": "def is_alive(self):\n        \"\"\"Checks if the current node is up and running in the cloud. It\n        only checks the status provided by the cloud interface. Therefore a\n        node might be running, but not yet ready to ssh into it.\n        \"\"\"\n        running = False\n        if not self.instance_id:\n            return False\n\n        try:\n            log.debug(\"Getting information for instance %s\",\n                      self.instance_id)\n            running = self._cloud_provider.is_instance_running(\n                self.instance_id)\n        except Exception as ex:\n            log.debug(\"Ignoring error while looking for vm id %s: %s\",\n                      self.instance_id, str(ex))\n        if running:\n            log.debug(\"node `%s` (instance id %s) is up and running\",\n                      self.name, self.instance_id)\n            self.update_ips()\n        else:\n            log.debug(\"node `%s` (instance id `%s`) still building...\",\n                      self.name, self.instance_id)\n\n        return running"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconnect to the node via ssh using the paramiko library.", "response": "def connect(self, keyfile=None):\n        \"\"\"Connect to the node via ssh using the paramiko library.\n\n        :return: :py:class:`paramiko.SSHClient` - ssh connection or None on\n                 failure\n        \"\"\"\n        ssh = paramiko.SSHClient()\n        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        if keyfile and os.path.exists(keyfile):\n            ssh.load_host_keys(keyfile)\n\n        # Try connecting using the `preferred_ip`, if\n        # present. Otherwise, try all of them and set `preferred_ip`\n        # using the first that is working.\n        ips = self.ips[:]\n        # This is done in order to \"sort\" the IPs and put the preferred_ip first.\n        if self.preferred_ip:\n            if self.preferred_ip in ips:\n                ips.remove(self.preferred_ip)\n            else:\n                # Preferred is changed?\n                log.debug(\"IP %s does not seem to belong to %s anymore. Ignoring!\", self.preferred_ip, self.name)\n                self.preferred_ip = ips[0]\n\n        for ip in itertools.chain([self.preferred_ip], ips):\n            if not ip:\n                continue\n            try:\n                log.debug(\"Trying to connect to host %s (%s)\",\n                          self.name, ip)\n                addr, port = parse_ip_address_and_port(ip, SSH_PORT)\n                ssh.connect(str(addr),\n                            username=self.image_user,\n                            allow_agent=True,\n                            key_filename=self.user_key_private,\n                            timeout=Node.connection_timeout,\n                            port=port)\n                log.debug(\"Connection to %s succeeded on port %d!\", ip, port)\n                if ip != self.preferred_ip:\n                    log.debug(\"Setting `preferred_ip` to %s\", ip)\n                    self.preferred_ip = ip\n                # Connection successful.\n                return ssh\n            except socket.error as ex:\n                log.debug(\"Host %s (%s) not reachable: %s.\",\n                          self.name, ip, ex)\n            except paramiko.BadHostKeyException as ex:\n                log.error(\"Invalid host key: host %s (%s); check keyfile: %s\",\n                          self.name, ip, keyfile)\n            except paramiko.SSHException as ex:\n                log.debug(\"Ignoring error %s connecting to %s\",\n                          str(ex), self.name)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nretrieves the public and private ip of the instance by using the cloud provider.", "response": "def update_ips(self):\n        \"\"\"Retrieves the public and private ip of the instance by using the\n        cloud provider. In some cases the public ip assignment takes some\n        time, but this method is non blocking. To check for a public ip,\n        consider calling this method multiple times during a certain timeout.\n        \"\"\"\n        self.ips = self._cloud_provider.get_ips(self.instance_id)\n        return self.ips[:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a file at user home folder and returns a AAConfigObj object", "response": "def get_config_obj(filename):\r\n    \"\"\"Reads/creates filename at user **home** folder and returns a AAConfigObj object\"\"\"\r\n\r\n    if not filename.startswith(\".\"):\r\n        a99.get_python_logger().warning(\"Configuration filename '{}' does not start with a '.'\".format(filename))\r\n\r\n    path_ = os.path.join(os.path.expanduser(\"~\"), filename)\r\n    return AAConfigObj(path_, encoding=\"UTF8\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_section(self, path_):\r\n\r\n        if isinstance(path_, str):\r\n            path_ = path_.strip().split(\"/\")\r\n            if path_[0] == \"\":\r\n                path_ = path_[1:]\r\n\r\n        obj = self\r\n        for section_name in path_[:-1]:\r\n            try:\r\n                obj = obj[section_name]\r\n            except KeyError:\r\n                obj[section_name] = {}  # creates section\r\n                obj = obj[section_name]\r\n\r\n        return obj, path_", "response": "Auto - creates section structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the item or default if it is not found", "response": "def get_item(self, path_, default):\r\n        \"\"\"Return item or default. In the latter, change file to have default.\r\n\r\n        Arguments:\r\n            path_ -- path to item in section/subsection structure. May be either:\r\n                     [\"section\", \"subsection\", ...] or\r\n                     \"[/]section/subsection/...\"  (leading slash is tolerated)\r\n            default -- value to return if item is not found\r\n\r\n        Argument 'default' is also used to determine the type of the data to return:\r\n\r\n            - str and list: returned as retrieved\r\n            - int and float: eval'ed\r\n            - bool: parsed\r\n        \"\"\"\r\n        section, path_ = self._get_section(path_)\r\n\r\n\r\n        key = path_[-1]\r\n\r\n        if key not in section:\r\n            self.set_item(path_, default)\r\n            return default\r\n\r\n        xvalue = section[key]\r\n        type_ = type(default)\r\n        if type_ in (str, list):\r\n            return xvalue\r\n        elif type_ == bool:\r\n            value = True if xvalue == \"True\" else False if xvalue == \"False\" else eval(xvalue)\r\n        elif type_ in (int, float):\r\n            value = type_(xvalue)\r\n        elif default is None:\r\n            value = None if xvalue == \"None\" else eval(xvalue)\r\n        else:\r\n\r\n            raise TypeError(\"Type not supported: {}\".format(type_.__name__))\r\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the value of the item at the given path and automatically saves file", "response": "def set_item(self, path_, value):\r\n        \"\"\"Sets item and automatically saves file\"\"\"\r\n        section, path_ = self._get_section(path_)\r\n        section[path_[-1]] = value\r\n        self.write()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating every possible slice that can be generated from an iterable", "response": "def all_subslices(itr):\n    \"\"\" generates every possible slice that can be generated from an iterable \"\"\"\n    assert iterable(itr), 'generators.all_subslices only accepts iterable arguments, not {}'.format(itr)\n    if not hasattr(itr, '__len__'): # if itr isnt materialized, make it a deque\n        itr = deque(itr)\n    len_itr = len(itr)\n    for start,_ in enumerate(itr):\n        d = deque()\n        for i in islice(itr, start, len_itr): # how many slices for this round\n            d.append(i)\n            yield tuple(d)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef just(*args):\n    ''' this works as an infinite loop that yields\n        the given argument(s) over and over\n    '''\n    assert len(args) >= 1, 'generators.just needs at least one arg'\n\n    if len(args) == 1: # if only one arg is given\n        try:\n            # try to cycle in a set for iteration speedup\n            return cycle(set(args))\n        except:\n            # revert to cycling args as a tuple\n            return cycle(args)\n    else:\n        return cycle({args})", "response": "this works as an infinite loop that yields\nAttributeNames the given argument list over and over\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new CountriesGeoZone with the specified attributes.", "response": "def create_countries_geo_zone(cls, countries_geo_zone, **kwargs):\n        \"\"\"Create CountriesGeoZone\n\n        Create a new CountriesGeoZone\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_countries_geo_zone(countries_geo_zone, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param CountriesGeoZone countries_geo_zone: Attributes of countriesGeoZone to create (required)\n        :return: CountriesGeoZone\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_countries_geo_zone_with_http_info(countries_geo_zone, **kwargs)\n        else:\n            (data) = cls._create_countries_geo_zone_with_http_info(countries_geo_zone, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a countries geo zone by its ID.", "response": "def delete_countries_geo_zone_by_id(cls, countries_geo_zone_id, **kwargs):\n        \"\"\"Delete CountriesGeoZone\n\n        Delete an instance of CountriesGeoZone by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_countries_geo_zone_by_id(countries_geo_zone_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str countries_geo_zone_id: ID of countriesGeoZone to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._delete_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_countries_geo_zone_by_id(cls, countries_geo_zone_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, **kwargs)\n        else:\n            (data) = cls._get_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, **kwargs)\n            return data", "response": "Find CountriesGeoZone by ID Return single instance of CountriesGeoZone by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists all countries geo zones in the specified domain.", "response": "def list_all_countries_geo_zones(cls, **kwargs):\n        \"\"\"List CountriesGeoZones\n\n        Return a list of CountriesGeoZones\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_countries_geo_zones(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[CountriesGeoZone]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_countries_geo_zones_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_countries_geo_zones_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_countries_geo_zone_by_id(cls, countries_geo_zone_id, countries_geo_zone, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, countries_geo_zone, **kwargs)\n        else:\n            (data) = cls._replace_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, countries_geo_zone, **kwargs)\n            return data", "response": "Replace all attributes of CountriesGeoZone by ID"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_countries_geo_zone_by_id(cls, countries_geo_zone_id, countries_geo_zone, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, countries_geo_zone, **kwargs)\n        else:\n            (data) = cls._update_countries_geo_zone_by_id_with_http_info(countries_geo_zone_id, countries_geo_zone, **kwargs)\n            return data", "response": "Update attributes of CountriesGeoZone by ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef data_read_write(data_path_in, data_path_out, format_type, **kwargs):\n\n    if format_type == \"dense\":\n\n        # Set dense defaults\n        kwargs = _set_dense_defaults_and_eval(kwargs)\n\n        # Try to parse non label columns appropriately\n        try:\n            nlc = [nm.strip() for nm in kwargs['non_label_cols'].split(\",\")]\n            kwargs.pop('non_label_cols', None)\n        except KeyError:\n            raise KeyError(\"'non_label_cols' is a required keyword dense data\")\n\n        # Read data with dense specific keywords\n        arch_data = pd.read_csv(data_path_in, sep=kwargs['delimiter'],\n                                na_values=kwargs['na_values'])\n\n        form_data = format_dense(arch_data, nlc, **kwargs)\n\n    elif format_type == \"grid\":\n        pass\n    elif format_type == \"stacked\":\n        pass\n    elif format_type == \"transect\":\n        pass\n    else:\n        raise NameError(\"%s is not a supported data format\" % format_type)\n\n    form_data.to_csv(data_path_out, index=False)", "response": "Read and write data from a file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_dense(base_data, non_label_cols, **kwargs):\n\n    kwargs = _set_dense_defaults_and_eval(kwargs)\n\n    # Stack data in columnar form.\n    indexed_data = base_data.set_index(keys=non_label_cols)\n    columnar_data = indexed_data.stack(dropna=False)\n    columnar_data = columnar_data.reset_index()\n\n    # Rename columns\n    num = len(non_label_cols)\n    columnar_data.rename(columns={0: kwargs['count_col'], 'level_%i' % num:\n        kwargs['label_col']}, inplace=True)\n\n    # Set nans to zero?\n    if kwargs['nan_to_zero']:\n        ind = np.isnan(columnar_data[kwargs['count_col']])\n        columnar_data.loc[ind, kwargs['count_col']] = 0\n        columnar_data.reset_index(inplace=True, drop=True)\n\n    # Drop nans?\n    if kwargs['drop_na']:\n        columnar_data = columnar_data.dropna(how=\"any\")\n        columnar_data.reset_index(inplace=True, drop=True)\n\n    return columnar_data", "response": "Formats a dense data type into a stacked data type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset default values in kwargs if kwargs are not already given. Evaluates all values in kwargs if kwargs are not already given.", "response": "def _set_dense_defaults_and_eval(kwargs):\n    \"\"\"\n    Sets default values in kwargs if kwargs are not already given.\n\n    Evaluates all values using eval\n\n    Parameters\n    -----------\n    kwargs : dict\n        Dictionary of dense specific keyword args\n\n    Returns\n    -------\n    : dict\n        Default, evaluated dictionary\n\n    \"\"\"\n\n    kwargs['delimiter'] = kwargs.get('delimiter', ',')\n    kwargs['na_values'] = kwargs.get('na_values', '')\n    kwargs['nan_to_zero'] = kwargs.get('nan_to_zero', False)\n    kwargs['drop_na'] = kwargs.get('drop_na', False)\n    kwargs['label_col'] = kwargs.get('label_col', 'label')\n    kwargs['count_col'] = kwargs.get('count_col', 'count')\n\n    for key, val in kwargs.iteritems():\n        try:\n            kwargs[key] = eval(val)\n        except:\n            kwargs[key] = val\n\n    return kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_points(self):\n        n = max(8, min(72, int(2*sqrt(self.r_x+self.r_y))))\n        d = pi * 2 / n\n        x, y, r_x, r_y = self.x, self.y, self.r_x, self.r_y\n\n        ps = []\n        for i in range(n):\n            ps += [(x + r_x * sin(d * i)), (y + r_y * cos(d * i))]\n        self.points = tuple(ps)", "response": "Update the points attribute of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_spectra_stacked(ss, title=None, num_rows=None, setup=_default_setup):\n\n    draw_spectra_stacked(ss, title, num_rows, setup)\n    plt.show()", "response": "Plots one or more stacked in subplots sharing same x - axis."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_spectra_overlapped(ss, title=None, setup=_default_setup):\n\n    plt.figure()\n    draw_spectra_overlapped(ss, title, setup)\n    plt.show()", "response": "Plots one or more spectra in the same plot."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_spectra_pieces_pdf(ss, aint=10, pdf_filename='pieces.pdf', setup=_default_setup):\n\n    import f311.explorer as ex\n\n    xmin, xmax, ymin_, ymax, _, yspan = calc_max_min(ss)\n    ymin = ymin_ if setup.ymin is None else setup.ymin\n\n    num_pages = int(math.ceil((xmax-xmin)/aint)) # rightmost point may be left out...or not\n    # num_spectra = len(ss)\n\n    a99.format_BLB()\n    # pdf = matplotlib.backends.backend_pdf.PdfPages(pdf_filename)\n    pdf = matplotlib.backends.backend_pdf.PdfPages(pdf_filename)\n    logger = a99.get_python_logger()\n\n    for h in range(num_pages):\n        fig = plt.figure()\n        lambda0 = xmin+h*aint\n        lambda1 = lambda0+aint\n        logger.info(\"Printing page {0:d}/{1:d} ([{2:g}, {3:g}])\".format(h+1, num_pages, lambda0, lambda1))\n        for i, s in enumerate(ss):\n            s_cut = ex.cut_spectrum(s, lambda0, lambda1)\n            ax = plt.gca()\n            ax.plot(s_cut.x, s_cut.y, label=s.title)\n        if setup.flag_xlabel and setup.fmt_xlabel:\n            plt.xlabel('Wavelength (interval: [{0:g}, {1:g}])'.format(lambda0, lambda1))\n        xspan = lambda1-lambda0\n        ax.set_xlim([lambda0 - xspan * _T, lambda1 + xspan * _T])\n        ax.set_ylim([ymin - yspan * _T, ymax + yspan * _T])\n        if setup.flag_legend:\n            leg = plt.legend(loc=0)\n            a99.format_legend(leg)\n        plt.tight_layout()\n        pdf.savefig(fig)\n        plt.close()\n\n    # for fig in xrange(1, figure().number): ## will open an empty extra figure :(\n    #     pdf.savefig( fig )\n    pdf.close()\n    logger.info(\"File {0!s} successfully created.\".format(pdf_filename))", "response": "Plots spectra overlapped in small wavelength intervals into a PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_spectra_pages_pdf(ss, pdf_filename='pages.pdf', setup=_default_setup):\n    logger = a99.get_python_logger()\n    xmin, xmax, ymin_, ymax, xspan, yspan = calc_max_min(ss)\n    ymin = ymin_ if setup.ymin is None else setup.ymin\n    num_pages = len(ss)\n    a99.format_BLB()\n    pdf = matplotlib.backends.backend_pdf.PdfPages(pdf_filename)\n    for i, s in enumerate(ss):\n        title = s.title\n        fig = plt.figure()\n        plt.plot(s.x, s.y, c=_FAV_COLOR)\n        if setup.flag_xlabel and setup.fmt_xlabel:\n            _set_plot(plt.xlabel, setup.fmt_xlabel, s)\n        if setup.flag_ylabel and setup.fmt_ylabel:\n            _set_plot(plt.ylabel, setup.fmt_ylabel, s)\n        _set_plot(plt.title, setup.fmt_title, s)\n        plt.xlim([xmin-xspan*_T, xmax+xspan*_T])\n        plt.ylim([ymin-yspan*_T, ymax+yspan*_T])\n        plt.tight_layout()\n        plt.subplots_adjust(top=0.94) # workaround for cropped title\n        logger.info(\"Printing page {0:d}/{1:d} ('{2!s}')\".format(i+1, num_pages, title))\n        pdf.savefig(fig)\n        plt.close()\n    pdf.close()\n    logger.info(\"File {0!s} successfully created.\".format(pdf_filename))", "response": "Plots spectra into a PDF file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef calc_max_min(ss):\n    xmin, xmax, ymin, ymax = 1e38, -1e38, 1e38, -1e38\n    for s in ss:\n        assert isinstance(s, ft.Spectrum)\n        if len(s.x) > 0:\n            xmin, xmax = min(min(s.x), xmin), max(max(s.x), xmax)\n            ymin, ymax = min(min(s.y), ymin), max(max(s.y), ymax)\n    xspan = xmax-xmin\n    yspan = ymax - ymin\n    return xmin, xmax, ymin, ymax, xspan, yspan", "response": "Calculates ( x y ) ( max min ) for a list of Spectrum objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the target of the a if it exists.", "response": "def target(self):\n        \"\"\":class:`Nation`, :class:`Region`, or None: Target of a\n        Liberation, Commendation, or Condemnation.  ``None`` if the\n        resolution is not a Liberation, Commendation, or Condemnation.\n        \"\"\"\n        if self.council == 'Security Council' and self.category != 'Repeal':\n            # e.g. N:ever-wandering_souls\n            entity_type, entity_name = self.option.split(':')\n            entity_types = {\n                'R': aionationstates.Region,\n                'N': aionationstates.Nation\n            }\n            return entity_types[entity_type](entity_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repeal_target(self):\n        if not self.category == 'Repeal':\n            raise TypeError(\"This resolution doesn't repeal anything\")\n        return wa.resolution(int(self.option) + 1)", "response": "The target of the repealing of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new object containing the resolution with the given index.", "response": "def resolution(self, index):\n        \"\"\"Resolution with a given index.\n\n        Parameters\n        ----------\n        index : int\n            Resolution index.\n\n            Global if this is the ``aionationstates.wa`` object, local\n            if this is ``aionationstates.ga`` or ``aionationstates.sc``.\n\n        Returns\n        -------\n        :class:`ApiQuery` of :class:`Resolution`\n\n        Raises\n        ------\n        :class:`NotFound`\n            If a resolution with the requested index doesn't exist.\n        \"\"\"\n        @api_query('resolution', id=str(index))\n        async def result(_, root):\n            elem = root.find('RESOLUTION')\n            if not elem:\n                raise NotFound(f'No resolution found with index {index}')\n            return Resolution(elem)\n        return result(self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def resolution_at_vote(self, root):\n        elem = root.find('RESOLUTION')\n        if elem:\n            resolution = ResolutionAtVote(elem)\n            resolution._council_id = self._council_id\n            return resolution", "response": "Return the resolution at vote."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the software name and returns the path of the binary.", "response": "def get_binary_path(executable):\n    \"\"\"Gets the software name and returns the path of the binary.\"\"\"\n    if sys.platform == 'win32':\n        if executable == 'start':\n            return executable\n        executable = executable + '.exe'\n        if executable in os.listdir('.'):\n            binary = os.path.join(os.getcwd(), executable)\n        else:\n            binary = next((os.path.join(path, executable)\n                           for path in os.environ['PATH'].split(os.pathsep)\n                           if os.path.isfile(os.path.join(path, executable))), None)\n    else:\n        binary = Popen(['which', executable], stdout=PIPE).stdout.read().strip().decode('utf-8')\n    return binary if binary else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nincreasing indentation by levels levels.", "response": "def indent(self, levels, first_line=None):\n        \"\"\"Increase indentation by ``levels`` levels.\"\"\"\n        self._indentation_levels.append(levels)\n        self._indent_first_line.append(first_line)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wrap(self, text, width=None, indent=None):\n        width = width if width is not None else self.options.wrap_length\n        indent = indent if indent is not None else self.indentation\n        initial_indent = self.initial_indentation\n        return textwrap.fill(text, width=width,\n                             initial_indent=initial_indent,\n                             subsequent_indent=indent)", "response": "Return text wrapped to width and indented with indent."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Construct(self):  # pylint: disable-msg=C0103\n        # Parse the GDML\n        self.gdml_parser.Read(self.filename)\n        self.world = self.gdml_parser.GetWorldVolume()\n\n        self.log.info(\"Materials:\")\n        self.log.info(G4.G4Material.GetMaterialTable())\n\n        # Return pointer to world volume\n        return self.world", "response": "Construct a cuboid from a GDML file without sensitive detector"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef Construct(self):  # pylint: disable-msg=C0103\n        # Parse the GDML\n        self.world = self.gdml_parser.GetWorldVolume()\n\n        # Create sensitive detector\n        self.sensitive_detector = ScintSD()\n\n        # Get logical volume for X view, then attach SD\n        my_lv = G4.G4LogicalVolumeStore.GetInstance().GetVolumeID(1)\n        assert my_lv.GetName() == \"ScintillatorBarX\"\n        my_lv.SetSensitiveDetector(self.sensitive_detector)\n\n        # Get logical volume for Y view, then attach SD\n        my_lv = G4.G4LogicalVolumeStore.GetInstance().GetVolumeID(2)\n        assert my_lv.GetName() == \"ScintillatorBarY\"\n        my_lv.SetSensitiveDetector(self.sensitive_detector)\n\n        my_lv = G4.G4LogicalVolumeStore.GetInstance().GetVolumeID(0)\n        assert my_lv.GetName() == \"SteelPlane\"\n\n        # field\n        self.field_manager = G4.G4FieldManager()\n        self.my_field = MagneticField.WandsToroidField(self.field_polarity)\n        self.field_manager.SetDetectorField(self.my_field)\n        self.field_manager.CreateChordFinder(self.my_field)\n        my_lv.SetFieldManager(self.field_manager, False)\n\n        self.log.info(\"Materials:\")\n        self.log.info(G4.G4Material.GetMaterialTable())\n\n        # Return pointer to world volume\n        return self.world", "response": "Construct nuSTORM from a GDML file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield lines of warnings and errors about input bbl file.", "response": "def validate(bbllines:iter, *, profiling=False):\n    \"\"\"Yield lines of warnings and errors about input bbl lines.\n\n    profiling -- yield also info lines about input bbl file.\n\n    If bbllines is a valid file name, it will be read.\n    Else, it should be an iterable of bubble file lines.\n\n    \"\"\"\n    if isinstance(bbllines, str):\n        if os.path.exists(bbllines):  # filename containing bubble\n            bbllines = utils.file_lines(bbllines)\n        elif '\\n' not in bbllines or '\\t' not in bbllines:\n            # probably a bad file name: let's rise the proper error\n            bbllines = utils.file_lines(bbllines)\n        else:  # bubble itself\n            bbllines = bbllines.split('\\n')\n    bubble = tuple(bbllines)\n    data = tuple(utils.line_data(line) for line in bubble)\n    types = tuple(utils.line_type(line) for line in bubble)\n    # launch profiling\n    if profiling:\n        ltype_counts = Counter(types)\n        for ltype, count in ltype_counts.items():\n            yield 'INFO {} lines of type {}'.format(count, ltype)\n        yield 'INFO {} lines of payload'.format(\n            ltype_counts['EDGE'] + ltype_counts['IN'] +\n            ltype_counts['NODE'] + ltype_counts['SET'])\n    # launch validation\n    for errline in (l for l, t in zip(bubble, types) if t == 'ERROR'):\n        yield 'ERROR line is not bubble: \"{}\"'.format(errline)\n    tree = BubbleTree.from_bubble_data(data)\n    cc, subroots = tree.connected_components()\n    # print('cc:', cc)\n    # print('subroots:', subroots)\n    if profiling:\n        yield 'INFO {} top (power)nodes'.format(len(tree.roots))\n        yield 'INFO {} connected components'.format(len(cc))\n        yield 'INFO {} nodes are defined, {} are used'.format(\n            ltype_counts['NODE'], len(tuple(tree.nodes())))\n        yield 'INFO {} powernodes are defined, {} are used'.format(\n            ltype_counts['SET'], len(tuple(tree.powernodes())))\n\n    yield from inclusions_validation(tree)\n    yield from mergeability_validation(tree)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield message about inclusions inconsistancies", "response": "def inclusions_validation(tree:BubbleTree) -> iter:\n    \"\"\"Yield message about inclusions inconsistancies\"\"\"\n    # search for powernode overlapping\n    for one, two in it.combinations(tree.inclusions, 2):\n        assert len(one) == len(one.strip())\n        assert len(two) == len(two.strip())\n        one_inc = set(included(one, tree.inclusions))\n        two_inc = set(included(two, tree.inclusions))\n        common_inc = one_inc & two_inc\n        if len(common_inc) == one_inc:\n            if not two in one_inc:\n                yield (\"ERROR inconsistency in inclusions: {} is both\"\n                       \" included and not included in {}.\".format(two, one))\n        if len(common_inc) == two_inc:\n            if not one in two_inc:\n                yield (\"ERROR inconsistency in inclusions: {} is both\"\n                       \" included and not included in {}.\".format(one, two))\n        if len(common_inc) > 0:  # one and two are not disjoint\n            if len(common_inc) == len(one_inc) or len(common_inc) == len(two_inc):\n                # one is included in the other\n                pass\n            else:  # problem: some nodes are shared, but not all\n                yield (\"ERROR overlapping powernodes:\"\n                       \" {} nodes are shared by {} and {},\"\n                       \" which are not in inclusion.\"\n                       \" Shared nodes are {}\".format(\n                           len(common_inc), one, two, common_inc))\n    for pwn in tree.powernodes():\n        # search for empty powernodes\n        if len(tree.inclusions[pwn]) == 0:\n            yield (\"WARNING empty powernode: {} is defined,\"\n                   \" but contains nothing\".format(pwn))\n        # search for singleton powernodes\n        if len(tree.inclusions[pwn]) == 1:\n            yield (\"WARNING singleton powernode: {} is defined,\"\n                   \" but contains only {}\".format(pwn, tree.inclusions[pwn]))\n    # search for cycles\n    nodes_in_cycles = utils.have_cycle(tree.inclusions)\n    if nodes_in_cycles:\n        yield (\"ERROR inclusion cycle: the following {}\"\n               \" nodes are involved: {}\".format(\n                   len(nodes_in_cycles), set(nodes_in_cycles)))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef included(powernode:str, inclusions:dict, nodes_only=False) -> iter:\n    if nodes_only:\n        condition = lambda e: e != powernode and inclusions[e] == ()\n    else:\n        condition = lambda e: e != powernode\n    yield from (elem for elem in utils.walk(powernode, (inclusions,))\n                if condition(elem))", "response": "Yields the power nodes below given powernode."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mergeability_validation(tree:BubbleTree) -> iter:\n    def gen_warnings(one, two, inc_message:str) -> [str]:\n        \"Yield the warning for given (power)nodes if necessary\"\n        nodetype = ''\n        if tree.inclusions[one] and tree.inclusions[two]:\n            nodetype = 'power'\n        elif tree.inclusions[one] or tree.inclusions[two]:\n            nodetype = '(power)'\n        if one > two:  one, two = two, one\n        shared = set(tree.edges.get(one, ())) & set(tree.edges.get(two, ()))\n        if shared:\n            yield (f\"WARNING mergeable {nodetype}nodes: {one} and {two}\"\n                   f\" are {inc_message}, and share\"\n                   f\" {len(shared)} neigbor{'s' if len(shared) > 1 else ''}\")\n    for one, two in it.combinations(tree.roots, 2):\n        yield from gen_warnings(one, two, inc_message='both roots')\n    for parent, childs in tree.inclusions.items():\n        for one, two in it.combinations(childs, 2):\n            yield from gen_warnings(one, two, inc_message=f'in the same level (under {parent})')", "response": "Yields the message about mergables powernodes if necessary"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef guild_details(guild_id=None, name=None):\n    if guild_id and name:\n        warnings.warn(\"both guild_id and name are specified, \"\n                      \"name will be ignored\")\n\n    if guild_id:\n        params = {\"guild_id\": guild_id}\n        cache_name = \"guild_details.%s.json\" % guild_id\n    elif name:\n        params = {\"guild_name\": name}\n        cache_name = \"guild_details.%s.json\" % name\n    else:\n        raise Exception(\"specify either guild_id or name\")\n\n    return get_cached(\"guild_details.json\", cache_name, params=params)", "response": "This resource returns details about a guild."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chunks(stream, chunk_size, output_type=tuple):\n    ''' returns chunks of a stream '''\n    assert iterable(stream), 'chunks needs stream to be iterable'\n    assert (isinstance(chunk_size, int) and chunk_size > 0) or callable(chunk_size), 'chunks needs chunk_size to be a positive int or callable'\n    assert callable(output_type), 'chunks needs output_type to be callable'\n    if callable(chunk_size):\n        ''' chunk_size is acting as a separator function '''\n        for chunk in chunk_on(stream, chunk_size, output_type):\n            yield chunk\n    else:\n        it = iter(stream)\n        marker = object()\n        iters = [it] * chunk_size\n        pipeline = apply_to_last(\n           zip_longest(*iters, fillvalue=marker),\n           lambda last_chunk: tuple(i for i in last_chunk if i is not marker)\n        )\n        if output_type is not tuple:\n            pipeline = map(output_type, pipeline)\n        for chunk in pipeline:\n            yield chunk", "response": "returns a generator that yields a chunk of a sequence of items from a stream"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef camelcase_to_slash(name):\n\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1/\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1/\\2', s1).lower()", "response": "Converts CamelCase to CamelCase"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nextracting charset from the content type of the current page", "response": "def get_charset(request):\n    \"\"\" Extract charset from the content type\n    \"\"\"\n\n    content_type = request.META.get('CONTENT_TYPE', None)\n    if content_type:\n        return extract_charset(content_type) if content_type else None\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_accept_header(accept):\n\n    def parse_media_range(accept_item):\n        \"\"\" Parse media range and subtype \"\"\"\n\n        return accept_item.split('/', 1)\n\n    def comparator(a, b):\n        \"\"\" Compare accept items a and b \"\"\"\n\n        # first compare q values\n        result = -cmp(a[2], b[2])\n        if result is not 0:\n            # q values differ, no need to compare media types\n            return result\n\n        # parse media types and compare them (asterisks are lower in precedence)\n        mtype_a, subtype_a = parse_media_range(a[0])\n        mtype_b, subtype_b = parse_media_range(b[0])\n        if mtype_a == '*' and subtype_a == '*':\n            return 1\n        if mtype_b == '*' and subtype_b == '*':\n            return -1\n        if subtype_a == '*':\n            return 1\n        if subtype_b == '*':\n            return -1\n        return 0\n\n    if not accept:\n        return []\n\n    result = []\n    for media_range in accept.split(\",\"):\n        parts = media_range.split(\";\")\n        media_type = parts.pop(0).strip()\n        media_params = []\n        q = 1.0\n        for part in parts:\n            (key, value) = part.lstrip().split(\"=\", 1)\n            if key == \"q\":\n                q = float(value)\n            else:\n                media_params.append((key, value))\n        result.append((media_type, tuple(media_params), q))\n    result.sort(comparator)\n    return result", "response": "Parse the Accept header and return a list of tuples with media type and q value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nresolve django - like path eg. object2__object3. Description is a string.", "response": "def _resolve_path(obj, path=None):\n        \"\"\"Resolve django-like path eg. object2__object3 for object\n        Args:\n            obj: The object the view is displaying.\n            path (str, optional): Description\n        Returns:\n            A oject at end of resolved path\n        \"\"\"\n        if path:\n            for attr_name in path.split('__'):\n                obj = getattr(obj, attr_name)\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef in_session(self):\n        session = self.get_session()\n        try:\n            yield session\n            session.commit()\n        except IntegrityError:\n            session.rollback()\n            raise DuplicateError(\"Duplicate unique value detected!\")\n        except (OperationalError, DisconnectionError):\n            session.rollback()\n            self.close()\n            logger.warn(\"Database Connection Lost!\")\n            raise DatabaseConnectionError()\n        except Exception:\n            session.rollback()\n            raise\n        finally:\n            session.close()", "response": "Provide a session scope around a series of operations."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef info(self, req) -> ResponseInfo:\n        r = ResponseInfo()\n        r.version = \"1.0\"\n        r.last_block_height = 0\n        r.last_block_app_hash = b''\n        return r", "response": "Return the response info for the current app."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating the Tx before entry into the mempool and return a ResponseCheckTx object.", "response": "def check_tx(self, tx) -> ResponseCheckTx:\n        \"\"\"\n        Validate the Tx before entry into the mempool\n        Checks the txs are submitted in order 1,2,3...\n        If not an order, a non-zero code is returned and the tx\n        will be dropped.\n        \"\"\"\n        value = decode_number(tx)\n        if not value == (self.txCount + 1):\n            # respond with non-zero code\n            return ResponseCheckTx(code=1)\n        return ResponseCheckTx(code=CodeTypeOk)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the last tx count", "response": "def query(self, req) -> ResponseQuery:\n        \"\"\"Return the last tx count\"\"\"\n        v = encode_number(self.txCount)\n        return ResponseQuery(code=CodeTypeOk, value=v, height=self.last_block_height)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the current encode state value to tendermint", "response": "def commit(self) -> ResponseCommit:\n        \"\"\"Return the current encode state value to tendermint\"\"\"\n        hash = struct.pack('>Q', self.txCount)\n        return ResponseCommit(data=hash)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nkeeping track of each file in list file_names.", "response": "def track(context, file_names):\n    \"\"\"Keep track of each file in list file_names.\n\n    Tracking does not create or delete the actual file, it only tells the\n    version control system whether to maintain versions (to keep track) of\n    the file.\n    \"\"\"\n    context.obj.find_repo_type()\n    for fn in file_names:\n        context.obj.call([context.obj.vc_name, 'add', fn])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef untrack(context, file_names):\n    context.obj.find_repo_type()\n    for fn in file_names:\n        if context.obj.vc_name == 'git':\n            context.obj.call(['git', 'rm', '--cached', fn])\n        elif context.obj.vc_name == 'hg':\n            context.obj.call(['hg', 'forget', fn])", "response": "Forget about tracking each file in the list file_names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(context, message, name):\n    context.obj.find_repo_type()\n    if context.obj.vc_name == 'git':\n        context.obj.call(['git', 'commit', '-a', '-m', message])\n    elif context.obj.vc_name == 'hg':\n        context.obj.call(['hg', 'commit', '-m', message])\n    if name != '' and context.obj.vc_name == 'git':\n        context.obj.call(['git', 'tag', '-a', name, '-m', message])\n    elif name != '' and context.obj.vc_name == 'hg':\n        context.obj.call(['hg', 'tag', '-m', message, name])", "response": "Commit saved changes to the repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef revert(context, file_names):\n    context.obj.find_repo_type()\n    if len(file_names) == 0:\n        click.echo('No file names to checkout specified.')\n        click.echo('The following have changed since the last check in.')\n        context.invoke(status)\n    for fn in file_names:\n        if context.obj.vc_name == 'git':\n            context.obj.call(['git', 'checkout', '--', fn])\n        elif context.obj.vc_name == 'hg':\n            context.obj.call(['hg', 'revert', '--no-backup', fn])", "response": "Revert each file in the list file_names back to version in repo"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsynchronising local repo to remote repo", "response": "def up(context):\n    \"\"\"(upload) Synchronise local repo to remote repo\"\"\"\n    context.obj.find_repo_type()\n    if context.obj.vc_name == 'git':\n        context.obj.call(['git', 'push'])\n        context.obj.call(['git', 'push', '--tags'])\n    elif context.obj.vc_name == 'hg':\n        context.obj.call(['hg', 'push'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef down(context, repo_url):\n    if repo_url == '':\n        context.obj.find_repo_type()\n        if context.obj.vc_name == 'git':\n            context.obj.call(['git', 'pull'])\n        elif context.obj.vc_name == 'hg':\n            context.obj.call(['hg', 'pull', '-u'])\n    else:\n        context.obj.call([context.obj.vc_name, 'clone', repo_url])", "response": "Synchronise remote repo to local repo."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef status(context):\n    context.obj.find_repo_type()\n    context.obj.call([context.obj.vc_name, 'status'])", "response": "See which files have changed checked in and uploaded"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs the current state of the current repository.", "response": "def log(context):\n    \"\"\"See history\"\"\"\n    context.obj.find_repo_type()\n    if context.obj.vc_name == 'git':\n        format = (\"--pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset \"\n                  \"%s %Cgreen(%cr) %C(bold blue)<%an>%Creset'\")\n        context.obj.call(['git', 'log', '--graph', format,\n                          '--abbrev-commit', '--stat'])\n    elif context.obj.vc_name == 'hg':\n        template = (\n            '\"changeset:   {rev}:{node|short} {tags}\\n'\n            ' summary:     {desc|firstline|fill68|tabindent|tabindent}\"')\n        context.obj.call(['hg', 'log', '-G', '--template', template])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef diff(context, file_name):\n    context.obj.find_repo_type()\n    if context.obj.vc_name == 'git':\n        context.obj.call(['git', 'diff', '--color-words',\n                          '--ignore-space-change', file_name])\n    elif context.obj.vc_name == 'hg':\n        context.obj.call(['hg', 'diff', file_name])", "response": "See changes that occured since last check in"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef call(self, args, devnull=False):\n        if self.debug:\n            click.echo(subprocess.list2cmdline(args))\n            click.confirm('Continue?', default=True, abort=True)\n        try:\n            kwargs = {}\n            if devnull:\n                # Pipe to /dev/null (or equivalent).\n                kwargs['stderr'] = subprocess.STDOUT\n                kwargs['stdout'] = self.FNULL\n            ret_code = subprocess.call(args, **kwargs)\n        except subprocess.CalledProcessError:\n            return False\n        return ret_code", "response": "Call other processes.\n        args - list of command args\n        devnull - whether to pipe stdout to /dev/null (or equivalent)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_repo_type(self):\n        is_git = self.call(['git', 'rev-parse', '--is-inside-work-tree'],\n                           devnull=True)\n        if is_git != 0:\n            if self.debug:\n                click.echo('not git')\n            is_hg = self.call(['hg', '-q', 'stat'], devnull=True)\n            if is_hg != 0:\n                if self.debug:\n                    click.echo('not hg')\n                exit(1)\n            else:\n                self.vc_name = 'hg'", "response": "Check for git or hg repository"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef main():\n\n    # Parse command line arguments\n    argp = _cli_argument_parser()\n    args = argp.parse_args()\n\n    # setup logging\n    logging.basicConfig(\n        level=args.loglevel,\n        format=\"%(levelname)s %(message)s\")\n\n    console.display(\"Collecting documentation from files\")\n    collector_metrics = metrics.Metrics()\n    docs = collector.parse(args.path, args.trace_parser,\n                           metrics=collector_metrics)\n    collector_metrics.display()\n\n    console.display(\"Rendering documentation\")\n\n    try:\n        if args.output:\n            template = renderer.template_from_filename(args.output)\n        else:\n            template = \"json\"\n        out = renderer.render(docs, template)\n    except ValueError as err:\n        logging.error(err)\n        sys.exit(1)\n    except TemplateNotFound as err:\n        logging.error(\n            \"Template `{}` not found. Available templates are: {}\".format(\n                err.name, renderer.list_templates()))\n        sys.exit(1)\n\n    if not args.output:\n        print(out)\n    else:\n        console.display(\"Writing documentation to\", args.output)\n        with io.open(args.output, \"w\", encoding=\"utf-8\") as fp:\n            fp.write(out)", "response": "The main entry point of the program."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_ioc(args):\n    client = IndicatorClient.from_config()\n    client.set_debug(True)\n\n    if args.get:\n        response = client.get_indicators()\n    elif args.single:\n        response = client.add_indicators(indicators=[args.single],\n                                         private=args.private, tags=args.tags)\n    else:\n        if not os.path.isfile(args.file):\n            raise Exception(\"File path isn't valid!\")\n\n        indicators = list()\n        with open(args.file, 'r') as handle:\n            for line in handle:\n                line = line.strip()\n                if line == '':\n                    continue\n                indicators.append(line)\n\n        response = client.add_indicators(indicators=indicators,\n                                         private=args.private, tags=args.tags)\n\n    return response", "response": "Process actions related to the IOC switch."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprocessing actions related to events switch.", "response": "def process_events(args):\n    \"\"\"Process actions related to events switch.\"\"\"\n    client = EventsClient.from_config()\n    client.set_debug(True)\n    if args.get:\n        response = client.get_events()\n    elif args.flush:\n        response = client.flush_events()\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    parser = ArgumentParser(description=\"Blockade Analyst Bench\")\n    subs = parser.add_subparsers(dest='cmd')\n\n    ioc = subs.add_parser('ioc', help=\"Perform actions with IOCs\")\n    ioc.add_argument('--single', '-s', help=\"Send a single IOC\")\n    ioc.add_argument('--file', '-f', help=\"Parse a file of IOCs\")\n    ioc.add_argument('--private', '-p', action=\"store_true\",\n                     help=\"Submit the IOCs to the node hashed, \\\n                     instead of in clear\")\n    ioc.add_argument('--tags', '-t',\n                     help=\"Add a comma-separated list of tags to store \\\n                     with the indicators\")\n    ioc.add_argument('--get', '-g', action=\"store_true\",\n                     help=\"List indicators on the remote node\")\n\n    events = subs.add_parser('events', help=\"Perform actions with Events\")\n    events.add_argument('--get', '-g', action='store_true',\n                        help=\"Get recent events\")\n    events.add_argument('--flush', '-f', action='store_true',\n                        help=\"Flush all events from cloud node\")\n\n    args, unknown = parser.parse_known_args()\n\n    try:\n        if args.cmd == 'ioc':\n            if (args.single and args.file):\n                raise Exception(\"Can't use single and file together!\")\n            if (not args.single and not args.file and not args.get):\n                ioc.print_help()\n                sys.exit(1)\n            response = process_ioc(args)\n        elif args.cmd == 'events':\n            if (not args.get and not args.flush):\n                events.print_help()\n                sys.exit(1)\n            response = process_events(args)\n        else:\n            parser.print_usage()\n            sys.exit(1)\n    except ValueError as e:\n        parser.print_usage()\n        sys.stderr.write('{}\\n'.format(str(e)))\n        sys.exit(1)\n\n    print(response.get('message', ''))", "response": "Main function for the code."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_store_credit_transaction(cls, store_credit_transaction, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_store_credit_transaction_with_http_info(store_credit_transaction, **kwargs)\n        else:\n            (data) = cls._create_store_credit_transaction_with_http_info(store_credit_transaction, **kwargs)\n            return data", "response": "Create a new StoreCreditTransaction with the specified attributes"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_store_credit_transaction_by_id(cls, store_credit_transaction_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, **kwargs)\n        else:\n            (data) = cls._delete_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, **kwargs)\n            return data", "response": "Delete an existing StoreCreditTransaction by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_store_credit_transaction_by_id(cls, store_credit_transaction_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, **kwargs)\n        else:\n            (data) = cls._get_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, **kwargs)\n            return data", "response": "Find StoreCreditTransaction by its ID Return single instance of StoreCreditTransaction by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_store_credit_transactions(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_store_credit_transactions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_store_credit_transactions_with_http_info(**kwargs)\n            return data", "response": "List StoreCreditTransactions\n        This method returns a list of StoreCreditTransactions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef replace_store_credit_transaction_by_id(cls, store_credit_transaction_id, store_credit_transaction, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, store_credit_transaction, **kwargs)\n        else:\n            (data) = cls._replace_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, store_credit_transaction, **kwargs)\n            return data", "response": "Replace StoreCreditTransaction by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_store_credit_transaction_by_id(cls, store_credit_transaction_id, store_credit_transaction, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, store_credit_transaction, **kwargs)\n        else:\n            (data) = cls._update_store_credit_transaction_by_id_with_http_info(store_credit_transaction_id, store_credit_transaction, **kwargs)\n            return data", "response": "Update attributes of StoreCreditTransaction by ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef window(iterable, size=2):\n    ''' yields wondows of a given size '''\n    iterable = iter(iterable)\n    d = deque(islice(iterable, size-1), maxlen=size)\n    for _ in map(d.append, iterable):\n        yield tuple(d)", "response": "yields wondows of a given size"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef multiobject_download(\n    urlList,\n    downloadDirectory,\n    log,\n    timeStamp=True,\n    timeout=180,\n    concurrentDownloads=10,\n    resetFilename=False,\n    credentials=False,\n    longTime=False,\n    indexFilenames=False\n):\n    \"\"\"\n    *get multiple url documents and place them in specified download directory/directories*\n\n    **Key Arguments:**\n      - ``urlList`` -- list of document urls\n      - ``downloadDirectory`` -- directory(ies) to download the documents to - can be one directory path or a list of paths the same length as urlList\n      - ``log`` -- the logger\n      - ``timestamp`` -- append a timestamp the name of the URL (ensure unique filenames)\n      - ``longTime`` -- use a longer timestamp when appending to the filename (greater uniqueness)\n      - ``timeout`` -- the timeout limit for downloads (secs)\n      - ``concurrentDownloads`` -- the number of concurrent downloads allowed at any one time\n      - ``resetFilename`` -- a string to reset all filenames to\n      - ``credentials`` -- basic http credentials { 'username' : \"...\", \"password\", \"...\" }\n      - ``indexFilenames`` -- prepend filenames with index (where url appears in urllist)\n\n    **Return:**\n      - list of timestamped documents (same order as the input urlList)\n\n    **Usage:**\n        .. code-block:: python \n\n            # download the pages linked from the main list page\n            from fundamentals.download import multiobject_download\n            localUrls = multiobject_download(\n                urlList=[\"https://www.python.org/dev/peps/pep-0257/\",\"https://en.wikipedia.org/wiki/Docstring\"],\n                downloadDirectory=\"/tmp\",\n                log=\"log\",\n                timeStamp=True,\n                timeout=180,\n                concurrentDownloads=2,\n                resetFilename=False,\n                credentials=False,  # { 'username' : \"...\", \"password\", \"...\" }\n                longTime=True\n            )\n\n            print localUrls\n            # OUT: ['/tmp/untitled_20160316t160650610780.html', '/tmp/Docstring_20160316t160650611136.html']\n\n        .. image:: https://i.imgur.com/QYoMm24.png width=600px\n    \"\"\"\n    ## > IMPORTS ##\n    import sys\n    import os\n    import eventlet\n    from eventlet.green import urllib2\n    import socket\n    import re\n    import base64\n    from fundamentals.download import _fetch, _dump_files_to_local_drive, append_now_datestamp_to_filename, extract_filename_from_url\n\n    ## >SETTINGS ##\n    # TIMEOUT IN SECONDS\n    timeout = float(timeout)\n    socket.setdefaulttimeout(timeout)\n\n    ###########################################################\n    # >ACTION(S)                                              #\n    ###########################################################\n    # BUILD THE 2D ARRAY FOR MULTI_THREADED DOWNLOADS\n    thisArray = []\n    bodies = []\n    localUrls = []\n    theseUrls = []\n    requestList = []\n\n    totalCount = len(urlList)\n    # IF ONLY ONE DOWNLOAD DIRECORY\n    if isinstance(downloadDirectory, str):\n        for i, url in enumerate(urlList):\n            # EXTRACT THE FILENAME FROM THE URL\n            if resetFilename and len(resetFilename):\n                filename = resetFilename[i]\n            else:\n                filename = extract_filename_from_url(log, url)\n                if indexFilenames:\n                    filename = \"\"\"%(i)03d_%(filename)s\"\"\" % locals()\n\n            if not filename:\n                from datetime import datetime, date, time\n                now = datetime.now()\n                filename = now.strftime(\"%Y%m%dt%H%M%S%f\")\n\n            if(timeStamp):\n                # APPEND TIMESTAMP TO THE FILENAME\n                filename = append_now_datestamp_to_filename(\n                    log, filename, longTime=longTime)\n            # GENERATE THE LOCAL FILE URL\n            localFilepath = downloadDirectory + \"/\" + filename\n            thisArray.extend([[url, localFilepath]])\n\n            # GENERATE THE REQUESTS\n            request = urllib2.Request(url)\n            if credentials != False:\n                username = credentials[\"username\"]\n                password = credentials[\"password\"]\n                base64string = base64.encodestring(\n                    '%s:%s' % (username, password)).replace('\\n', '')\n                request.add_header(\"Authorization\", \"Basic %s\" % base64string)\n            requestList.append(request)\n\n    elif isinstance(downloadDirectory, list):\n        for u, d in zip(urlList, downloadDirectory):\n            # EXTRACT THE FILENAME FROM THE URL\n            if resetFilename:\n                filename = resetFilename\n            else:\n                filename = extract_filename_from_url(log, url)\n\n            if not filename:\n                continue\n\n            if(timeStamp):\n                # APPEND TIMESTAMP TO THE FILENAME\n                filename = append_now_datestamp_to_filename(\n                    log, filename)\n            # GENERATE THE LOCAL FILE URL\n            localFilepath = d + \"/\" + filename\n            thisArray.extend([[u, localFilepath]])\n            log.debug(\" about to download %s\" % (u,))\n\n            # GENERATE THE REQUESTS\n            request = urllib2.Request(u)\n            if credentials != False:\n                log.debug('adding the credentials')\n                username = credentials[\"username\"]\n                password = credentials[\"password\"]\n                base64string = base64.encodestring(\n                    '%s:%s' % (username, password)).replace('\\n', '')\n                request.add_header(\"Authorization\", \"Basic %s\" % base64string)\n            requestList.append(request)\n\n    pool = eventlet.GreenPool(concurrentDownloads)\n    i = 0\n    try:\n\n        log.debug(\n            \"starting mutli-threaded download batch - %s concurrent downloads\" %\n            (concurrentDownloads,))\n        log.debug('len(requestList): %s' % (len(requestList),))\n        for url, body in pool.imap(_fetch, requestList):\n            urlNum = i + 1\n            if urlNum > 1:\n                # CURSOR UP ONE LINE AND CLEAR LINE\n                sys.stdout.write(\"\\x1b[1A\\x1b[2K\")\n            percent = (float(urlNum) / float(totalCount)) * 100.\n            print \"  %(urlNum)s / %(totalCount)s (%(percent)1.1f%%) URLs downloaded\" % locals()\n\n            if(body):\n                bodies.extend([body])\n                theseUrls.extend([thisArray[i][1]])\n            else:\n                theseUrls.extend([None])\n                bodies.extend([None])\n\n            # DUMP THE FILES FROM MEMORY EVERY CONCURRENT DOWNLOAD CYCLE\n            if i % concurrentDownloads == 0:\n                _dump_files_to_local_drive(bodies, theseUrls, log)\n                localUrls.extend(theseUrls)\n                # RESET THE TMP ARRAYS\n                bodies = []\n                theseUrls = []\n            i += 1\n    except Exception, e:\n        log.error(\n            \"something went wrong with the mutli-threaded download : \" + str(e) + \"\\n\")\n\n    # DUMP REMAINING FILES TO THE LOCAL DRIVE\n    _dump_files_to_local_drive(bodies, theseUrls, log)\n    localUrls.extend(theseUrls)\n\n    return localUrls", "response": "Download multiple url documents and place them in specified download directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef payment_mode(self, payment_mode):\n        allowed_values = [\"authorize\", \"capture\"]\n        if payment_mode is not None and payment_mode not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `payment_mode` ({0}), must be one of {1}\"\n                .format(payment_mode, allowed_values)\n            )\n\n        self._payment_mode = payment_mode", "response": "Sets the payment_mode of this CreditCardPayment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_credit_card_payment(cls, credit_card_payment, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_credit_card_payment_with_http_info(credit_card_payment, **kwargs)\n        else:\n            (data) = cls._create_credit_card_payment_with_http_info(credit_card_payment, **kwargs)\n            return data", "response": "Create a new CreditCardPayment object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting CreditCardPayment by its ID.", "response": "def delete_credit_card_payment_by_id(cls, credit_card_payment_id, **kwargs):\n        \"\"\"Delete CreditCardPayment\n\n        Delete an instance of CreditCardPayment by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_credit_card_payment_by_id(credit_card_payment_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str credit_card_payment_id: ID of creditCardPayment to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_credit_card_payment_by_id_with_http_info(credit_card_payment_id, **kwargs)\n        else:\n            (data) = cls._delete_credit_card_payment_by_id_with_http_info(credit_card_payment_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_credit_card_payment_by_id(cls, credit_card_payment_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_credit_card_payment_by_id_with_http_info(credit_card_payment_id, **kwargs)\n        else:\n            (data) = cls._get_credit_card_payment_by_id_with_http_info(credit_card_payment_id, **kwargs)\n            return data", "response": "Find CreditCardPayment by its ID Return single instance of CreditCardPayment"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_credit_card_payments(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_credit_card_payments_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_credit_card_payments_with_http_info(**kwargs)\n            return data", "response": "List CreditCardPayments\n        This method returns a list of CreditCardPayments\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef replace_credit_card_payment_by_id(cls, credit_card_payment_id, credit_card_payment, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_credit_card_payment_by_id_with_http_info(credit_card_payment_id, credit_card_payment, **kwargs)\n        else:\n            (data) = cls._replace_credit_card_payment_by_id_with_http_info(credit_card_payment_id, credit_card_payment, **kwargs)\n            return data", "response": "Replace CreditCardPayment by ID and attributes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate attributes of CreditCardPayment by ID", "response": "def update_credit_card_payment_by_id(cls, credit_card_payment_id, credit_card_payment, **kwargs):\n        \"\"\"Update CreditCardPayment\n\n        Update attributes of CreditCardPayment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_credit_card_payment_by_id(credit_card_payment_id, credit_card_payment, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str credit_card_payment_id: ID of creditCardPayment to update. (required)\n        :param CreditCardPayment credit_card_payment: Attributes of creditCardPayment to update. (required)\n        :return: CreditCardPayment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_credit_card_payment_by_id_with_http_info(credit_card_payment_id, credit_card_payment, **kwargs)\n        else:\n            (data) = cls._update_credit_card_payment_by_id_with_http_info(credit_card_payment_id, credit_card_payment, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmatch the image using a cross correlation.", "response": "def match_via_correlation(image, template, raw_tolerance=1, normed_tolerance=0.9):\n    \"\"\" Matchihng algorithm based on normalised cross correlation.\n        Using this matching prevents false positives occuring for bright patches in the image\n    \"\"\"\n    h, w = image.shape\n    th, tw = template.shape\n    # fft based convolution enables fast matching of large images\n    correlation = fftconvolve(image, template[::-1,::-1])\n    # trim the returned image, fftconvolve returns an image of width: (Temp_w-1) + Im_w + (Temp_w -1), likewise height\n    correlation = correlation[th-1:h, tw-1:w]\n    # find images regions which are potentially matches\n    match_position_dict = get_tiles_at_potential_match_regions(image, template, correlation, raw_tolerance=raw_tolerance)\n    # bright spots in images can lead to false positivies- the normalisation carried out here eliminates those\n    results = normalise_correlation(match_position_dict, correlation, template, normed_tolerance=normed_tolerance)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmatches the image using square differences.", "response": "def match_via_squared_difference(image, template, raw_tolerance=1, sq_diff_tolerance=0.1):\n    \"\"\" Matchihng algorithm based on normalised cross correlation.\n        Using this matching prevents false positives occuring for bright patches in the image\n    \"\"\"\n    h, w = image.shape\n    th, tw = template.shape\n    # fft based convolution enables fast matching of large images\n    correlation = fftconvolve(image, template[::-1,::-1])\n    # trim the returned image, fftconvolve returns an image of width: (Temp_w-1) + Im_w + (Temp_w -1), likewise height\n    correlation = correlation[th-1:h, tw-1:w]\n    # find images regions which are potentially matches\n    match_position_dict = get_tiles_at_potential_match_regions(image, template, correlation, raw_tolerance=raw_tolerance)\n    # bright spots in images can lead to false positivies- the normalisation carried out here eliminates those\n    results = calculate_squared_differences(match_position_dict, correlation, template, sq_diff_tolerance=sq_diff_tolerance)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmatches image using correlation coefficient.", "response": "def match_via_correlation_coefficient(image, template, raw_tolerance=1, normed_tolerance=0.9):\n    \"\"\" Matching algorithm based on 2-dimensional version of Pearson product-moment correlation coefficient.\n\n        This is more robust in the case where the match might be scaled or slightly rotated.\n\n        From experimentation, this method is less prone to false positives than the correlation method.\n    \"\"\"\n    h, w = image.shape\n    th, tw = template.shape\n    temp_mean = np.mean(template)\n    temp_minus_mean = template - temp_mean\n    convolution = fftconvolve(image, temp_minus_mean[::-1,::-1])\n    convolution = convolution[th-1:h, tw-1:w]\n    match_position_dict = get_tiles_at_potential_match_regions(image, template, convolution, method='correlation coefficient', raw_tolerance=raw_tolerance)\n    # this is empty, so think condition is wrong\n    results = normalise_correlation_coefficient(match_position_dict, convolution, template, normed_tolerance=normed_tolerance)\n    return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndetermine if a fuzzy match is present in the given image and template.", "response": "def fuzzy_match(image, template, normed_tolerance=None, raw_tolerance=None, method='correlation'):\n    \"\"\"Determines, using one of two methods, whether a match(es) is present and returns the positions of\n       the bottom right corners of the matches.\n       Fuzzy matches returns regions, so the center of each region is returned as the final match location\n\n       USE THIS FUNCTION IF you need to match, e.g. the same image but rendered slightly different with respect to\n       anti aliasing; the same image on a number of different backgrounds.\n\n       The method is the name of the matching method used, the details of this do not matter. Use the default method\n       unless you have too many false positives, in this case, use the method 'correlation coefficient.' The\n       correlation coefficient method can also be more robust at matching when the match might not be exact.\n\n       The raw_tolerance is the proportion of the value at match positions (i.e. the value returned for an exact match)\n       that we count as a match. For fuzzy matching, this value will not be exactly the value returned for an exact match\n       N. B. Lowering raw_tolerance increases the number of potential match tiles requiring normalisation.\n       This DRAMATICALLY slows down matching as normalisation (a process which eliminates false positives)\n\n       The normed_tolerance is how far a potential match value can differ from one after normalisation.\n\n       The tolerance values indicated below are from a short investigation, looking to minimise missing items we wish to match,\n       as all as false positives which inevitably occur when performing fuzzy matching. To generate these values, we\n       tested maching letters with different type of antialiasing on a number of backgrounds.\n    \"\"\"\n    if method == 'correlation':\n        if not raw_tolerance:\n            raw_tolerance = 0.95\n        if not normed_tolerance:\n            normed_tolerance = 0.95\n        results = np.array(match_via_correlation(image, template, raw_tolerance=raw_tolerance, normed_tolerance=normed_tolerance))\n    elif method == 'correlation coefficient':\n        if not raw_tolerance:\n            raw_tolerance = 0.95\n        if not normed_tolerance:\n            normed_tolerance = 0.95\n        results = np.array(match_via_correlation_coefficient(image, template, raw_tolerance=raw_tolerance, normed_tolerance=normed_tolerance))\n    elif method == 'squared difference':\n        if not raw_tolerance:\n            raw_tolerance = 0.95\n        if not normed_tolerance:\n            normed_tolerance = 0.05\n        results = np.array(match_via_squared_difference(image, template, raw_tolerance=raw_tolerance, sq_diff_tolerance=normed_tolerance))\n    h, w = image.shape\n    th, tw = template.shape\n    results = np.array([(result[0], result[1]) for result in results])\n    #match_x, match_y = int(np.mean(results[:,1])), int(np.mean(results[:,0]))\n    results_aggregated_mean_match_position = match_positions((h,w), results)\n    return results_aggregated_mean_match_position"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_positions(shape, list_of_coords):\n    match_array = np.zeros(shape)\n    try:\n        # excpetion hit on this line if nothing in list_of_coords- i.e. no matches\n        match_array[list_of_coords[:,0],list_of_coords[:,1]] = 1\n        labelled = label(match_array)\n        objects = find_objects(labelled[0])\n        coords = [{'x':(slice_x.start, slice_x.stop),'y':(slice_y.start, slice_y.stop)} for (slice_y,slice_x) in objects]\n        final_positions = [(int(np.mean(coords[i]['x'])),int(np.mean(coords[i]['y']))) for i in range(len(coords))]\n        return final_positions\n    except IndexError:\n        print 'no matches found'\n        # this error occurs if no matches are found\n        return []", "response": "Given a list of coordinates return the positions of the matches that are found in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef md5_8_name(self, url):\n        m = hashlib.md5()\n        m.update(url.encode('utf-8'))\n        return m.hexdigest()[:8] + os.path.splitext(url)[1]", "response": "Return md5 - 8 name of url"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_transaction_by_id(cls, transaction_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_transaction_by_id_with_http_info(transaction_id, **kwargs)\n        else:\n            (data) = cls._delete_transaction_by_id_with_http_info(transaction_id, **kwargs)\n            return data", "response": "Delete an instance of Transaction by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_transaction_by_id(cls, transaction_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_transaction_by_id_with_http_info(transaction_id, **kwargs)\n        else:\n            (data) = cls._get_transaction_by_id_with_http_info(transaction_id, **kwargs)\n            return data", "response": "Find Transaction by its ID Return single instance of Transaction by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_transactions(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_transactions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_transactions_with_http_info(**kwargs)\n            return data", "response": "List Transactions\n        Return a list of Transactions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clean(self):\n        '''\n        Cleaning phase of `FilterForm` is aimed to collect arguments for\n        filtering (lookup parameters).\n\n        As a result we will get three new artefacts:\n          * return value: a mapping to use as keyword arguments in `filter`;\n          * `complex_conditions`: a `Q` object to use as a positional argument;\n          * `extra_conditions`: a mapping to use as keyword arguments in\n            `extra`.\n        '''\n        simple_lookups = []\n        complex_conditions = []\n        extra_conditions = []\n        for name, spec in self.filter_specs.iteritems():\n            raw_value = self.cleaned_data.get(name)\n            if isinstance(spec, RuntimeAwareFilterSpecMixin):\n                lookup_or_condition = spec.to_lookup(raw_value, runtime_context=self.runtime_context)\n            else:\n                lookup_or_condition = spec.to_lookup(raw_value)\n\n            if isinstance(lookup_or_condition, Q) and lookup_or_condition:\n                    complex_conditions.append(lookup_or_condition)\n            elif isinstance(lookup_or_condition, Extra):\n                extra_conditions.append(lookup_or_condition)\n            elif lookup_or_condition:\n                simple_lookups.append(lookup_or_condition)\n\n        self.simple_lookups = simple_lookups\n        self.complex_conditions = complex_conditions\n        self.extra_conditions = extra_conditions\n\n        return {}", "response": "Clean the data for the current filter."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if form is valid and contains an empty lookup.", "response": "def is_empty(self):\n        '''\n        Return `True` if form is valid and contains an empty lookup.\n        '''\n        return (self.is_valid() and\n            not self.simple_lookups and\n            not self.complex_conditions and\n            not self.extra_conditions)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef build_inventory(setup):\n    '''Builds an inventory for use as part of an\n    `dynamic Ansible inventory <http://docs.ansible.com/ansible/intro_dynamic_inventory.html>`_\n    according to the\n    `script conventions <http://docs.ansible.com/ansible/developing_inventory.html#script-conventions>`_::\n\n        {\n            \"_meta\" : {\n                \"hostvars\" : {\n                    \"host1\": {},\n                    \"host2\": {},\n                    \"host3\": {},\n                    ...\n            },\n            \"all\": {\n                \"vars\": {}\n            },\n            \"group1\": {\n                \"hosts\": [\"host1\", \"host2\"],\n                \"vars\": {}\n            },\n            \"group2\": {\n                \"hosts\": [\"host3\"],\n                \"vars\": {}\n            },\n            ...\n        }\n\n\n    Parameters\n    ----------\n    setup: tmdeploy.config.Setup\n        setup configuration\n\n    Returns\n    -------\n    dict\n        mapping of groups to hosts\n    '''\n    inventory = dict()\n    inventory['all'] = dict()\n    inventory['all']['vars'] = {\n        'provider': setup.cloud.provider,\n        'region': setup.cloud.region,\n        'key_name': setup.cloud.key_name,\n        'key_file': os.path.expandvars(\n            os.path.expanduser(\n                setup.cloud.key_file_public\n            )\n        ),\n        'network': setup.cloud.network,\n        'subnetwork': setup.cloud.subnetwork,\n        'ip_range': setup.cloud.ip_range,\n        'proxy_env': {\n            'http_proxy': setup.cloud.proxy,\n            'https_proxy': setup.cloud.proxy\n        }\n    }\n    inventory['_meta'] = dict()\n    inventory['_meta']['hostvars'] = dict()\n\n    if not isinstance(setup, Setup):\n        raise TypeError(\n            'Argument \"setup\" must have type {0}.'.format(\n                '.'.join([Setup.__module__, Setup.__name__])\n            )\n        )\n    for cluster in setup.architecture.clusters:\n        logger.info('configure cluster \"%s\"', cluster.name)\n        for node_type in cluster.node_types:\n            logger.info('configure node type \"%s\"', node_type.name)\n            for i in range(node_type.count):\n                host_name = HOSTNAME_FORMAT.format(\n                    name=setup.architecture.name, cluster=cluster.name,\n                    node_type=node_type.name, index=i+1\n                )\n                host_vars = dict()\n                for k, v in node_type.instance.to_dict().items():\n                    if k == 'tags':\n                        # Every server is part of the \"compute-storage\"\n                        # security group, which is important for servers to be\n                        # able to connect to each other when part of a cluster.\n                        security_groups = 'compute-storage'\n                        if 'web' in v:\n                            host_vars['assign_public_ip'] = 'yes'\n                            security_groups = ','.join([\n                                security_groups, 'web'\n                            ])\n                        else:\n                            host_vars['assign_public_ip'] = 'no'\n                        host_vars['security_groups'] = security_groups\n                    if isinstance(v, list):\n                        v = ','.join(v)\n                    host_vars[k] = v\n                inventory['_meta']['hostvars'][host_name] = host_vars\n                for group in node_type.groups:\n                    logger.info('add group \"%s\"', group.name)\n                    if group.name not in inventory:\n                        inventory[group.name] = {'hosts': list()}\n                    inventory[group.name]['hosts'].append(host_name)\n                    inventory[group.name]['vars'] = dict()\n                    if group.vars is not None:\n                        inventory[group.name]['vars'].update(group.vars)\n                    if node_type.vars is not None:\n                        inventory[group.name]['vars'].update(node_type.vars)\n\n    return inventory", "response": "Builds an ansible inventory for use as part of an anonymized set of hosts."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload Ansible inventory from file.", "response": "def load_inventory(hosts_file=HOSTS_FILE):\n    '''Loads Ansible inventory from file.\n\n    Parameters\n    ----------\n    hosts_file: str, optional\n        path to Ansible hosts file\n\n    Returns\n    -------\n    ConfigParser.SafeConfigParser\n        content of `hosts_file`\n    '''\n    inventory = SafeConfigParser(allow_no_value=True)\n    if os.path.exists(hosts_file):\n        inventory.read(hosts_file)\n    else:\n        logger.warn('inventory file doesn\\'t exist: %s', hosts_file)\n    return inventory"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_inventory(inventory, hosts_file=HOSTS_FILE):\n    '''Saves Ansible inventory to file.\n\n    Parameters\n    ----------\n    inventory: ConfigParser.SafeConfigParser\n        content of the `hosts_file`\n    hosts_file: str, optional\n        path to Ansible hosts file\n    '''\n    with open(hosts_file, 'w') as f:\n        inventory.write(f)", "response": "Saves Ansible inventory to file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the spy was called with the specified args and kwargs.", "response": "def called_with(self, *args, **kwargs):\n        \"\"\"Return True if the spy was called with the specified args/kwargs.\n\n        Otherwise raise VerificationError.\n\n        \"\"\"\n        expected_call = Call(*args, **kwargs)\n        if expected_call in calls(self.spy):\n            return True\n        raise VerificationError(\n            \"expected %s to be called with %s, but it wasn't\" % (\n                self.spy, expected_call.formatted_args))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning True if the spy was not called with the specified args or kwargs.", "response": "def not_called_with(self, *args, **kwargs):\n        \"\"\"Return True if spy was not called with the specified args/kwargs.\n\n        Otherwise raise VerificationError.\n\n        \"\"\"\n        call = Call(*args, **kwargs)\n        if call in calls(self.spy):\n            raise VerificationError(\n                'expected %s to not be called with %s, but it was' % (\n                    self.spy, call.formatted_args))\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the internal state of the object.", "response": "def _init_config(self, width, height, spi=None, spiMosi= None, spiDC=None, spiCS=None, spiReset=None, spiClk=None):\n        \"\"\"!\n        SPI hardware and display width, height initialization.\n        \"\"\"\n        self._spi = spi\n        self._spi_mosi = spiMosi\n        self._spi_dc = spiDC\n        self._spi_cs = spiCS\n        self._spi_reset = spiReset\n        self._spi_clk = spiClk\n\n        self.width = width\n        self.height = height"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the IOs in the SPI controller.", "response": "def _init_io(self):\n        \"\"\"!\n        GPIO initialization.\n        Set GPIO into BCM mode and init other IOs mode\n        \"\"\"\n        GPIO.setwarnings(False)\n        GPIO.setmode( GPIO.BCM )\n        pins = [ self._spi_dc ]\n        for pin in pins:\n            GPIO.setup( pin, GPIO.OUT )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear(self, fill = 0x00):\n        self._buffer = [ fill ] * ( self.width * self.height )", "response": "Clear the buffer data for this object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_users(\n    path,\n    resource_name=None,\n    send_email_to_user=None,\n    alternate_email=None,\n    verbose=None,\n    export_to_file=None,\n    **kwargs,\n):\n    \"\"\"Import users from a CSV file with columns:\n        username\n        first_name\n        last_name\n        email\n        sites: a comma-separated list of sites\n        groups: a comma-separated list of groups\n        job_title\n    \"\"\"\n    users = []\n    with open(path) as f:\n        reader = csv.DictReader(f)\n        for user_data in reader:\n            username = user_data.get(\"username\")\n            site_names = user_data.get(\"sites\").lower().split(\",\")\n            group_names = user_data.get(\"groups\").lower().split(\",\")\n            first_name = user_data.get(\"first_name\")\n            last_name = user_data.get(\"last_name\")\n            email = user_data.get(\"email\")\n            o = UserImporter(\n                username=username,\n                first_name=first_name,\n                last_name=last_name,\n                email=email,\n                site_names=site_names,\n                group_names=group_names,\n                resource_name=resource_name,\n                send_email_to_user=send_email_to_user,\n                alternate_email=alternate_email,\n                verbose=verbose,\n                **kwargs,\n            )\n            users.append(\n                {\n                    \"username\": o.user.username,\n                    \"password\": o.password,\n                    \"first_name\": o.user.first_name,\n                    \"last_name\": o.user.last_name,\n                    \"sites\": o.site_names,\n                    \"groups\": o.group_names,\n                }\n            )\n    if export_to_file:\n        fieldnames = [\n            \"username\",\n            \"password\",\n            \"first_name\",\n            \"last_name\",\n            \"sites\",\n            \"groups\",\n        ]\n        with open(path + \"new.csv\", \"w+\") as f:\n            writer = csv.DictWriter(f, fieldnames=fieldnames)\n            writer.writeheader()\n            for user in users:\n                writer.writerow(user)", "response": "Imports users from a CSV file with columns username first_name last_name email sites groups and job_title."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeclaring an exchange on RabbitMQ by invoking the Exchange. Declare RPC command.", "response": "def setup_exchange(self, exchange_name):\n        \"\"\"Setup the exchange on RabbitMQ by invoking the Exchange.Declare RPC\n        command. When it is complete, the on_exchange_declareok method will\n        be invoked by pika.\n\n        :param str|unicode exchange_name: The name of the exchange to declare\n\n        \"\"\"\n        logger.info('Declaring exchange', name=exchange_name)\n        self._channel.exchange_declare(self.on_exchange_declareok,\n                                       exchange_name,\n                                       self._exchange_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndeclare a queue on RabbitMQ by invoking the Queue. Declare RPC command.", "response": "def setup_queue(self, queue_name):\n        \"\"\"Setup the queue on RabbitMQ by invoking the Queue.Declare RPC\n        command. When it is complete, the on_queue_declareok method will\n        be invoked by pika.\n\n        :param str|unicode queue_name: The name of the queue to declare.\n\n        \"\"\"\n        logger.info('Declaring queue', name=queue_name)\n        self._channel.queue_declare(\n            self.on_queue_declareok, queue_name, durable=self._durable_queue\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_queue_declareok(self, method_frame):\n        logger.info('Binding to rabbit', exchange=self._exchange, queue=self._queue)\n        self._channel.queue_bind(self.on_bindok, self._queue, self._exchange)", "response": "Invoked by pika when the Queue. Declare RPC call made in\n        setup_queue has completed."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninvoking by pika when a Basic. Cancel frame is received.", "response": "def on_consumer_cancelled(self, method_frame):\n        \"\"\"Invoked by pika when RabbitMQ sends a Basic.Cancel for a consumer\n        receiving messages.\n\n        :param pika.frame.Method method_frame: The Basic.Cancel frame\n\n        \"\"\"\n        msg = 'Consumer was cancelled remotely, shutting down: {0!r}'\n        logger.info(msg.format(method_frame))\n        if self._channel:\n            self._channel.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef acknowledge_message(self, delivery_tag, **kwargs):\n        logger.info('Acknowledging message', delivery_tag=delivery_tag, **kwargs)\n        self._channel.basic_ack(delivery_tag)", "response": "Acknowledge the delivery from RabbitMQ by sending Basic. Ack RPC method for the delivery tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnegativing acknowledge a message from the broker", "response": "def nack_message(self, delivery_tag, **kwargs):\n        \"\"\"Negative acknowledge a message\n\n        :param int delivery_tag: The deliver tag from the Basic.Deliver frame\n\n        \"\"\"\n        logger.info('Nacking message', delivery_tag=delivery_tag, **kwargs)\n        self._channel.basic_nack(delivery_tag)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreject a message from RabbitMQ by sending Basic. Reject RPC method for the delivery tag.", "response": "def reject_message(self, delivery_tag, requeue=False, **kwargs):\n        \"\"\"Reject the message delivery from RabbitMQ by sending a\n        Basic.Reject RPC method for the delivery tag.\n        :param int delivery_tag: The delivery tag from the Basic.Deliver frame\n\n        \"\"\"\n        logger.info('Rejecting message', delivery_tag=delivery_tag, **kwargs)\n        self._channel.basic_reject(delivery_tag, requeue=requeue)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef on_message(self, unused_channel, basic_deliver, properties, body):\n        logger.info(\n            'Received message',\n            delivery_tag=basic_deliver.delivery_tag,\n            app_id=properties.app_id,\n            msg=body,\n        )\n        self.acknowledge_message(basic_deliver.delivery_tag)", "response": "Invoked by pika when a message is delivered from RabbitMQ."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntells RabbitMQ that you would like to stop consuming the items.", "response": "def stop_consuming(self):\n        \"\"\"Tell RabbitMQ that you would like to stop consuming by sending the\n        Basic.Cancel RPC command.\n\n        \"\"\"\n        if self._channel:\n            logger.info('Sending a Basic.Cancel RPC command to RabbitMQ')\n            self._channel.basic_cancel(self.on_cancelok, self._consumer_tag)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nopens a new channel with RabbitMQ by issuing the Channel. Open RPC command.", "response": "def open_channel(self):\n        \"\"\"Open a new channel with RabbitMQ by issuing the Channel.Open RPC\n        command. When RabbitMQ responds that the channel is open, the\n        on_channel_open callback will be invoked by pika.\n\n        \"\"\"\n        logger.info('Creating a new channel')\n        self._connection.channel(on_open_callback=self.on_channel_open)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun the example consumer by connecting to RabbitMQ and then starting the IOLoop to block and allow the SelectConnection to operate.", "response": "def run(self):\n        \"\"\"Run the example consumer by connecting to RabbitMQ and then\n        starting the IOLoop to block and allow the SelectConnection to operate.\n\n        \"\"\"\n        logger.debug('Running rabbit consumer')\n        self._connection = self.connect()\n        self._connection.ioloop.start()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the tx_id for a message from a rabbit queue using the message properties. Will raise KeyError if tx_id is missing from message properties.", "response": "def tx_id(properties):\n        \"\"\"\n        Gets the tx_id for a message from a rabbit queue, using the\n        message properties. Will raise KeyError if tx_id is missing from message\n        headers.\n\n        : param properties: Message properties\n\n        : returns: tx_id of survey response\n        : rtype: str\n        \"\"\"\n        tx_id = properties.headers['tx_id']\n        logger.info(\"Retrieved tx_id from message properties: tx_id={}\".format(tx_id))\n        return tx_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling by the server when a message is received from a queue.", "response": "def on_message(self, unused_channel, basic_deliver, properties, body):\n        \"\"\"Called on receipt of a message from a queue.\n\n        Processes the message using the self._process method or function and positively\n        acknowledges the queue if successful. If processing is not succesful,\n        the message can either be rejected, quarantined or negatively acknowledged,\n        depending on the failure mode.\n\n        : param basic_deliver: AMQP basic.deliver method\n        : param properties: Message properties\n        : param body: Message body\n\n        : returns: None\n\n        \"\"\"\n        if self.check_tx_id:\n            try:\n                tx_id = self.tx_id(properties)\n\n                logger.info('Received message',\n                            queue=self._queue,\n                            delivery_tag=basic_deliver.delivery_tag,\n                            app_id=properties.app_id,\n                            tx_id=tx_id)\n\n            except KeyError as e:\n                self.reject_message(basic_deliver.delivery_tag)\n                logger.error(\"Bad message properties - no tx_id\",\n                             action=\"rejected\",\n                             exception=str(e))\n                return None\n            except TypeError as e:\n                self.reject_message(basic_deliver.delivery_tag)\n                logger.error(\"Bad message properties - no headers\",\n                             action=\"rejected\",\n                             exception=str(e))\n                return None\n        else:\n            logger.debug(\"check_tx_id is False. Not checking tx_id for message.\",\n                         delivery_tag=basic_deliver.delivery_tag)\n            tx_id = None\n\n        try:\n            try:\n                self.process(body.decode(\"utf-8\"), tx_id)\n            except TypeError:\n                logger.error('Incorrect call to process method')\n                raise QuarantinableError\n\n            self.acknowledge_message(basic_deliver.delivery_tag,\n                                     tx_id=tx_id)\n\n        except (QuarantinableError, BadMessageError) as e:\n            # Throw it into the quarantine queue to be dealt with\n            try:\n                self.quarantine_publisher.publish_message(body, headers={'tx_id': tx_id})\n                self.reject_message(basic_deliver.delivery_tag, tx_id=tx_id)\n                logger.error(\"Quarantinable error occured\",\n                             action=\"quarantined\",\n                             exception=str(e),\n                             tx_id=tx_id)\n            except PublishMessageError:\n                logger.error(\"Unable to publish message to quarantine queue. Rejecting message and requeuing.\")\n                self.reject_message(basic_deliver.delivery_tag,\n                                    requeue=True,\n                                    tx_id=tx_id)\n\n        except RetryableError as e:\n            self.nack_message(basic_deliver.delivery_tag, tx_id=tx_id)\n            logger.error(\"Failed to process\",\n                         action=\"nack\",\n                         exception=str(e),\n                         tx_id=tx_id)\n\n        except Exception as e:\n            self.nack_message(basic_deliver.delivery_tag, tx_id=tx_id)\n            logger.exception(\"Unexpected exception occurred\")\n            logger.error(\"Failed to process\",\n                         action=\"nack\",\n                         exception=str(e),\n                         tx_id=tx_id)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nauthenticating against the ObjectRocket API.", "response": "def authenticate(self, username, password):\n        \"\"\"Authenticate against the ObjectRocket API.\n\n        :param str username: The username to perform basic authentication against the API with.\n        :param str password: The password to perform basic authentication against the API with.\n        :returns: A token used for authentication against token protected resources.\n        :rtype: str\n        \"\"\"\n        # Update the username and password bound to this instance for re-authentication needs.\n        self._username = username\n        self._password = password\n\n        # Attempt to authenticate.\n        resp = requests.get(\n            self._url,\n            auth=(username, password),\n            **self._default_request_kwargs\n        )\n\n        # Attempt to extract authentication data.\n        try:\n            if resp.status_code == 200:\n                json_data = resp.json()\n                token = json_data['data']['token']\n            elif resp.status_code == 401:\n                raise errors.AuthFailure(resp.json().get('message', 'Authentication Failure.'))\n            else:\n                raise errors.AuthFailure(\n                    \"Unknown exception while authenticating: '{}'\".format(resp.text)\n                )\n        except errors.AuthFailure:\n            raise\n        except Exception as ex:\n            logging.exception(ex)\n            raise errors.AuthFailure('{}: {}'.format(ex.__class__.__name__, ex))\n\n        # Update the token bound to this instance for use by other client operations layers.\n        self._token = token\n        logger.info('New API token received: \"{}\".'.format(token))\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _refresh(self):\n        # Request and set a new API token.\n        new_token = self.authenticate(self._username, self._password)\n        self._token = new_token\n        logger.info('New API token received: \"{}\".'.format(new_token))\n        return self._token", "response": "Refresh the API token using the currently bound credentials."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies that the given token is valid.", "response": "def _verify(self, token):\n        \"\"\"Verify that the given token is valid.\n\n        :param str token: The API token to verify.\n        :returns: The token's corresponding user model as a dict, or None if invalid.\n        :rtype: dict\n        \"\"\"\n        # Attempt to authenticate.\n        url = '{}{}/'.format(self._url, 'verify')\n        resp = requests.post(\n            url,\n            json={'token': token},\n            **self._default_request_kwargs\n        )\n        if resp.status_code == 200:\n            return resp.json().get('data', None)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preprocess(net, image):\n    '''\n    convert to Caffe input image layout\n    '''\n    return np.float32(np.rollaxis(image, 2)[::-1]) - net.transformer.mean[\"data\"]", "response": "convert to Caffe input image layout\n    convert to Caffe input image layout\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef make_step(\n    net,\n    step_size = 1.5,\n    end       = \"inception_4c/output\", \n    jitter    = 32,\n    clip      = True,\n    objective = objective_L2\n    ):\n    '''\n    basic gradient ascent step\n    '''\n\n    src = net.blobs[\"data\"]\n    dst = net.blobs[end]\n\n    ox, oy = np.random.randint(- jitter, jitter + 1, 2)\n    # Apply jitter shift.\n    src.data[0] = np.roll(np.roll(src.data[0], ox, -1), oy, -2)\n\n    # Specify the optimisation objective.\n    net.forward(end = end)\n    objective(dst)\n    net.backward(start = end)\n    g = src.diff[0]\n    # Apply normalised ascent step to the input image.\n    src.data[:] += step_size / np.abs(g).mean() * g\n    # Unshift the image.\n    src.data[0] = np.roll(np.roll(src.data[0], - ox, - 1), -oy, -2)\n            \n    if clip:\n        bias = net.transformer.mean[\"data\"]\n        src.data[:] = np.clip(src.data, -bias, 255-bias)", "response": "This function creates a step of the inception network."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef bx_encode(n, alphabet):\n \n   if not isinstance(n, int):\n      raise TypeError('an integer is required')\n\n   base = len(alphabet)\n\n   if n == 0:\n      return alphabet[0]\n\n   digits = []\n   \n   while n > 0:\n      digits.append(alphabet[n % base])\n      n = n // base\n   \n   digits.reverse()\n   return ''.join(digits)", "response": "\\ Returns a base - 8 encoded string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _do_analysis(options):\n\n    module = _function_location(options)\n    core_results = _call_analysis_function(options, module)\n\n    if module == 'emp' and ('models' in options.keys()):\n        fit_results = _fit_models(options, core_results)\n    else:\n        fit_results = None\n\n    _save_results(options, module, core_results, fit_results)", "response": "Do analysis for a single run."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncalls function from module and get result", "response": "def _call_analysis_function(options, module):\n    \"\"\"\n    Call function from module and get result, using inputs from options\n\n    Parameters\n    ----------\n    options : dict\n        Option names and values for analysis\n    module : str\n        Short name of module within macroeco containing analysis function\n\n    Returns\n    -------\n    dataframe, array, value, list of tuples\n        Functions from emp module return a list of tuples in which first\n        element of the tuple gives a string describing the result and the\n        second element giving the result of the analysis as a dataframe.\n        Functions in other modules return dataframe, array, or value.\n\n    \"\"\"\n\n    args, kwargs = _get_args_kwargs(options, module)\n    return eval(\"%s.%s(*args, **kwargs)\" % (module, options['analysis']))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngives an options and a module extract args and kwargs from the object tree.", "response": "def _get_args_kwargs(options, module):\n    \"\"\"\n    Given an options (including analysis), and module, extract args and kwargs\n    \"\"\"\n\n    if module == 'emp':\n        options = _emp_extra_options(options)\n    arg_names, kw_names = _arg_kwarg_lists(module, options['analysis'])\n\n    # Create list of values for arg_names\n    args = []\n    for arg_name in arg_names:\n\n        if arg_name == 'patch':  # For patch arg, append actual patch obj\n            args.append(options['patch'])\n            continue\n        if arg_name == 'self':  # Ignore self from class methods\n            continue\n        if arg_name == 'k':  # scipy dists use k and x, we always use x\n            arg_name = 'x'\n\n        try:\n            exec 'args.append(eval(\"%s\"))' % options[arg_name]\n        except SyntaxError: # eval failing because option is a string\n            args.append(options[arg_name])\n        except:\n            raise ValueError, (\"Value for required argument %s not provided\"\n                               % arg_name)\n\n    # Create dict with vals for kw_names\n    kwargs = {}\n    for kw_name in kw_names:\n        if kw_name in options.keys():  # If a value is given for this kwarg\n            try:\n                exec 'kwargs[kw_name] = eval(\"%s\")' % options[kw_name]\n            except SyntaxError:  # eval failing because value is a string\n                kwargs[kw_name] = options[kw_name]\n            except:\n                raise ValueError, (\"Value for optional argument %s is invalid\"\n                                   % kw_name)\n\n    return args, kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _emp_extra_options(options):\n\n    # Check that metadata is valid\n    metadata_path = os.path.normpath(os.path.join(options['param_dir'],\n                                                  options['metadata']))\n    if not os.path.isfile(metadata_path):\n        raise IOError, (\"Path to metadata file %s is invalid.\" %\n                        metadata_path)\n    options['metadata_path'] = metadata_path\n\n    # Using subset if given, create and store patch\n    subset = options.get('subset', '')\n    options['patch'] = emp.Patch(metadata_path, subset)\n\n    # If cols or splits not given in options, make empty strings\n    if 'cols' not in options.keys():\n        options['cols'] = ''\n    if 'splits' not in options.keys():\n        options['splits'] = ''\n\n    return options", "response": "Get special options patch cols and splits if analysis in emp module\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfitting models to empirical result from a function in emp module", "response": "def _fit_models(options, core_results):\n    \"\"\"\n    Fit models to empirical result from a function in emp module\n\n    Parameters\n    ----------\n    options : dict\n        Option names and values for analysis\n    core_results : list of tuples\n        Output of function in emp\n\n    Returns\n    -------\n    list of dicts\n        Each element in list corresponds to a subset. The dict has a key for\n        each model given in options, and the value is a list of fitted\n        parameters (tuple), values (array), comparison statistic names (list),\n        and comparison statistic values (list).\n\n    Notes\n    -----\n    To determine if the empirical result refers to a curve or a distribution,\n    the result dataframe is inspected for a column 'x', which indicates a\n    curve.\n\n    \"\"\"\n\n    logging.info(\"Fitting models\")\n    models = options['models'].replace(' ', '').split(';')\n\n    # TODO: Make work for 2D results, i.e., curves, comm_sep, o_ring\n    # TODO: Make work for curves in general (check if 'x' present in core_res)\n    fit_results = []\n    for core_result in core_results:  # Each subset\n        fit_result = {}\n        for model in models:\n            fits = _get_fits(core_result, model, options)\n            values = _get_values(core_result, model, fits)\n            stat_names, stats = _get_comparison_stat(core_result, values,\n                                                     model, fits)\n            fit_result[model] = [fits, values, stat_names, stats]\n        fit_results.append(fit_result)\n\n    return fit_results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _save_results(options, module, core_results, fit_results):\n\n    logging.info(\"Saving all results\")\n\n    # Use custom plot format\n    mpl.rcParams.update(misc.rcparams.ggplot_rc)\n\n    # Make run directory\n    os.makedirs(options['run_dir'])\n\n    # Write core results\n    _write_core_tables(options, module, core_results)\n\n    # Write additional results if analysis from emp\n    if module == 'emp':\n        _write_subset_index_file(options, core_results)\n\n    # Write model/data comparison if models were given\n    if fit_results:\n        models = options['models'].replace(' ','').split(';')\n        for i, core_result in enumerate(core_results):\n            _write_fitted_params(i, models, options, fit_results)\n            _write_test_statistics(i, models, options, fit_results)\n            _write_comparison_plot_table(i, models, options,\n                                         core_results, fit_results)", "response": "Save results of analysis from emp to emp base analysis."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_core_tables(options, module, core_results):\n\n    table_name = 'core_result.csv'\n    single_file_path = os.path.join(options['run_dir'], table_name)\n\n    if module == 'emp':  # List of tuples\n        for i, core_result in enumerate(core_results):\n            file_path = _get_file_path(i, options, table_name)\n            core_result[1].to_csv(file_path, index=False, float_format='%.4f')\n\n    elif type(core_results) == type(pd.DataFrame()):  # DataFrame\n        core_results.to_csv(single_file_path, index=False, float_format='%.4f')\n\n    else:  # Array or single value (atleast_1d corrects for unsized array)\n        df = pd.DataFrame({'y': np.atleast_1d(core_results)})\n        df.to_csv(single_file_path, index=False, float_format='%.4f')", "response": "Writes the core_result. csv files for the current module."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the index of subsets giving number and subset string", "response": "def _write_subset_index_file(options, core_results):\n    \"\"\"\n    Write table giving index of subsets, giving number and subset string\n    \"\"\"\n\n    f_path = os.path.join(options['run_dir'], '_subset_index.csv')\n    subset_strs = zip(*core_results)[0]\n    index = np.arange(len(subset_strs)) + 1\n    df = pd.DataFrame({'subsets': subset_strs}, index=index)\n    df.to_csv(f_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting comparison plot table for the current SAR and the models.", "response": "def _write_comparison_plot_table(spid, models, options, core_results,\n                                 fit_results):\n    \"\"\"\n    Notes\n    -----\n    Only applies to analysis using functions from empirical in which models are\n    also given.\n\n    \"\"\"\n    # TODO: Clean up sorting, may not work if SAR x out of order, e.g.\n\n    is_curve = 'x' in core_results[0][1]\n    df = core_results[spid][1]\n    df.rename(columns={'y': 'empirical'}, inplace=True)\n\n    # If distribution, need to sort values so will match sorted rank in fits\n    if not is_curve:\n        x = np.arange(len(df)) + 1\n        df = df.sort(columns='empirical')\n        df.insert(0, 'x', x[::-1])\n\n    # Add residual column for each model\n    for model in models:\n        fit_result = fit_results[spid][model]\n        df[model] = fit_result[1]\n        df[model + \"_residual\"] = df[model] - df['empirical']\n\n    # If curve, sort now for plotting purposes\n    if is_curve:\n        df = df.sort(columns='x')\n\n    # Set up file paths\n    f_path = _get_file_path(spid, options, 'data_models.csv')\n    p_path = _get_file_path(spid, options, 'data_models.pdf')\n\n    # Save table\n    df.to_csv(f_path, index=False, float_format='%.4f')  # Table\n\n    # Save plot\n    fig, (ax1, ax2) = plt.subplots(1, 2)\n\n    ax1.scatter(df['x'], df['empirical'], color='k')\n    ax1.plot(df['x'], df[models])\n    ax1.legend(models + ['empirical'], loc='best')\n    ax1.set_xlabel('x')\n    ax1.set_ylabel('value')\n\n    ax2.hlines(0, np.min(df['x']), np.max(df['x']))\n    ax2.plot(df['x'], df[[x + '_residual' for x in models]])\n    ax2.legend(models + ['empirical'], loc='best')\n    ax2.set_xlabel('x')\n    ax2.set_ylabel('residual')\n    ax2.set_xlim(ax1.get_xlim())\n    ax2.set_ylim(min(ax2.get_ylim()[0], -1), max(ax2.get_ylim()[1], 1))\n\n    if options.get('log_y', None):\n        ax1.set_yscale('log')\n        ax2.set_yscale('symlog', linthreshy=1)\n    if options.get('log_x', None):\n        ax1.set_xscale('log')\n        ax2.set_xscale('log')\n\n    if not options.get('log_x', None) and not options.get('log_y', None):\n        ax1.set_ylim(bottom=0)\n        ax1.set_xlim(left=0)\n        ax1 = _pad_plot_frame(ax1)\n        ax2 = _pad_plot_frame(ax2)\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        fig.tight_layout()\n    fig.savefig(p_path)\n\n    plt.close('all')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npads the axes of a single frame of a plot.", "response": "def _pad_plot_frame(ax, pad=0.01):\n    \"\"\"\n    Provides padding on sides of frame equal to pad fraction of plot\n    \"\"\"\n\n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_ylim()\n    xr = xmax - xmin\n    yr = ymax - ymin\n\n    ax.set_xlim(xmin - xr*pad, xmax + xr*pad)\n    ax.set_ylim(ymin - yr*pad, ymax + yr*pad)\n\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _output_cdf_plot(core_result, spid, models, options, fit_results):\n\n    # CDF\n    x = core_result['y'].values\n    df = emp.empirical_cdf(x)\n    df.columns = ['x', 'empirical']\n\n    def calc_func(model, df, shapes):\n        return eval(\"mod.%s.cdf(df['x'], *shapes)\" % model)\n\n    plot_exec_str = \"ax.step(df['x'], emp, color='k', lw=3);ax.set_ylim(top=1)\"\n\n    _save_table_and_plot(spid, models, options, fit_results, 'data_pred_cdf',\n                         df, calc_func, plot_exec_str)", "response": "Function for plotting cdf"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfunction for plotting pdf and PMF", "response": "def output_pdf_plot(core_result, spid, models, options, fit_results):\n    \"\"\" Function for plotting pdf/pmf \"\"\"\n    # PDF/PMF\n    hist_bins = 11\n    emp_hist, edges = np.histogram(core_result['y'].values, hist_bins,\n                                   normed=True)\n    x = (np.array(edges[:-1]) + np.array(edges[1:])) / 2\n    df = pd.DataFrame({'x': x, 'empirical': emp_hist})\n\n    def calc_func(model, df, shapes):\n        try:\n            return eval(\"mod.%s.pmf(np.floor(df['x']), *shapes)\" % model)\n        except:\n            return eval(\"mod.%s.pdf(df['x'], *shapes)\" % model)\n\n    plot_exec_str = \"ax.bar(df['x']-width/2, emp, width=width, color='gray')\"\n\n    _save_table_and_plot(spid, models, options, fit_results, 'data_pred_pdf',\n                         df, calc_func, plot_exec_str)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef openWith(self, accel = True, gyro = True, temp = True, cycle = False, cycleFreq = 0x00):\n        val_pwr_2 = 0x00\n        #disable Accel sensor\n        if accel == False:\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_XA\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_YA\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_ZA\n\n        #disable Gyro sensor\n        if gyro == False:\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_XG\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_YG\n            val_pwr_2 = val_pwr_2 | self.VAL_PWR_MGMT_2_STBY_ZG\n\n        val_pwr_1 = 0x00\n        #disable temp sensor\n        if temp == False:\n            val_pwr_1 = val_pwr_1 | self.VAL_PWR_MGMT_1_OFF_TEMP\n\n        #cycle mode\n        if cycle == True:\n            val_pwr_1 = val_pwr_1 | self.VAL_PWR_MGMT_1_ON_CYCLE\n            val_pwr_2 = val_pwr_2 | cycleFreq\n\n        self._sendCmd( self.REG_PWR_MGMT_2, val_pwr_2 )\n        self._sendCmd( self.REG_PWR_MGMT_1, val_pwr_1 )", "response": "Open with accel gyro and temp sensors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen only Accelerometer Only Low Power Mode Arc.", "response": "def openOnlyAccel(self, cycleFreq = 0x00 ):\n        \"\"\"!\n        Trun on device into Accelerometer Only Low Power Mode\n        @param cycleFreq can be choise: \n            @see VAL_PWR_MGMT_2_LP_WAKE_CTRL_1_25HZ is default\n            @see VAL_PWR_MGMT_2_LP_WAKE_CTRL_5HZ\n            @see VAL_PWR_MGMT_2_LP_WAKE_CTRL_20HZ\n            @see VAL_PWR_MGMT_2_LP_WAKE_CTRL_40HZ\n        \"\"\"\n        self.openWith(accel = True, gyro = False, temp = False, cycle = True, cycleFreq = cycleFreq)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset Motion Detection Interrupt and set the current state of the active high.", "response": "def setMotionInt(self, motDHPF = 0x01, motTHR = 0x14, motDUR = 0x30, motDeteDec = 0x15 ):\n        \"\"\"!\n        Set to enable Motion Detection Interrupt\n\n        @param motDHPF Set the Digital High Pass Filter. Default is 0x01 (5Hz)\n        @param motTHR  Desired motion threshold. Default is 20 (0x14)\n        @param motDUR  Desired motion duration. Default is 48ms (0x30)\n        @param motDeteDec Motion detection decrement. Default is 21 (0x15)\n        \n        @note <b>motDHPF</b> should be one of the following values:<br>\n            0x00: RESET,<br>\n            0x01: 5Hz,<br>\n            0x02: 2.5Hz,<br>\n            0x03: 1.25Hz,<br>\n            0x04: 0.63Hz,<br>\n            0x07: HOLD<br>\n        \"\"\"\n        #After power on (0x00 to register (decimal) 107), the Motion Detection Interrupt can be enabled as follows:\n        #self._sendCmd( self.REG_PWR_MGMT_1, 0x00 )\n        #(optionally?) Reset all internal signal paths in the MPU-6050 by writing 0x07 to register 0x68;\n        self._sendCmd( self.REG_SIGNAL_PATH_RESET, 0x07 )\n        #write register 0x37 to select how to use the interrupt pin. \n        #For an active high, push-pull signal that stays until register \n        #(decimal) 58 is read, write 0x20 (need read to clear INT state) or 0x00 (auto clear INT state).\n        self._sendCmd( self.REG_INT_PIN_CFG, 0x00 )\n        \n        orgAccelConf = self._readByte(self.REG_ACCEL_CONFIG)\n        newAccelConf = ( (orgAccelConf | 0xE7) ^ 0xE7 ) | motDHPF\n        # Write register 28 (==0x1C) to set the Digital High Pass Filter, \n        # bits 3:0. For example set it to 0x01 for 5Hz. \n        # (These 3 bits are grey in the data sheet, but they are used! \n        # Leaving them 0 means the filter always outputs 0.)\n        #\n        # 0x00: RESET,\n        # 0x01: 5Hz,\n        # 0x02: 2.5Hz,\n        # 0x03: 1.25Hz,\n        # 0x04: 0.63Hz,\n        # 0x07: hold\n        #\n        # \u9ad8\u901a\u6ee4\u6ce2\u5668\u7075\u654f\u5ea6\u8c03\u8282\n        #\n        self._sendCmd( self.REG_ACCEL_CONFIG, newAccelConf )\n        #Write the desired Motion threshold to register 0x1F (For example, write decimal 20).\n        self._sendCmd( self.REG_MOTION_DET, motTHR )\n        #To register 0x20 (hex), write the desired motion duration, for example 40ms (0x28).\n        # \u7075\u654f\u5ea6\u8c03\u8282\n        self._sendCmd( self.REG_MOTION_DET_DUR, motDUR )\n        \n        #to register 0x69, write the motion detection decrement and \n        #a few other settings (for example write 0x15 to set both \n        #free-fall and motion decrements to 1 and accelerome0x00ter \n        #start-up delay to 5ms total by adding 1ms. )\n        self._sendCmd( self.REG_MOTION_DET_CTRL, motDeteDec )\n\n        #write register 0x38, bit 6 (0x40), to enable motion detection interrupt.\n        self._sendCmd( self.REG_INT_ENABLE, self.VAL_INT_ENABLE_MOTION )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets to enabled Data Ready Interrupt", "response": "def setDataRdyInt(self, int_cfg = 0x20 ):\n        \"\"\"!\n        \\~english \n        Set to enabled Data Ready Interrupt\n        int_cfg : Register 55( 0x37 ) \u2013 INT Pin / Bypass Enable Configuration, page 26\n        \n        \\~chinese \n        \u542f\u7528\u6570\u636e\u5c31\u7eea\u4e2d\u65ad\n        @param int_cfg: \u5bc4\u5b58\u5668 55( 0x37 ) \u2013 INT Pin / Bypass Enable Configuration, page 26\n        \"\"\"\n        self._sendCmd( self.REG_INT_PIN_CFG, int_cfg )\n        self._sendCmd( self.REG_INT_ENABLE, self.VAL_INT_ENABLE_DATA_RDY)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the accelerometer setup.", "response": "def readAccelRange( self ):\n        \"\"\"!\n        Reads the range of accelerometer setup.\n        \n        @return an int value.\n          It should be one of the following values:\n              @see ACCEL_RANGE_2G\n              @see ACCEL_RANGE_4G\n              @see ACCEL_RANGE_8G\n              @see ACCEL_RANGE_16G\n        \"\"\"\n        raw_data = self._readByte(self.REG_ACCEL_CONFIG)\n        raw_data = (raw_data | 0xE7) ^ 0xE7\n        return raw_data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getAccelData( self,  raw = False ):\n        x = self._readWord(self.REG_ACCEL_XOUT_H)\n        y = self._readWord(self.REG_ACCEL_YOUT_H)\n        z = self._readWord(self.REG_ACCEL_ZOUT_H)\n\n        accel_scale_modifier = None\n        accel_range = self.readAccelRange()\n\n        if accel_range == self.ACCEL_RANGE_2G:\n            accel_scale_modifier = self.ACCEL_SCALE_MODIFIER_2G\n        elif accel_range == self.ACCEL_RANGE_4G:\n            accel_scale_modifier = self.ACCEL_SCALE_MODIFIER_4G\n        elif accel_range == self.ACCEL_RANGE_8G:\n            accel_scale_modifier = self.ACCEL_SCALE_MODIFIER_8G\n        elif accel_range == self.ACCEL_RANGE_16G:\n            accel_scale_modifier = self.ACCEL_SCALE_MODIFIER_16G\n        else:\n            print( \"ERROR: Unkown accel range!\" )\n            return False            \n            #accel_scale_modifier = self.ACCEL_SCALE_MODIFIER_2G\n\n        x = x / accel_scale_modifier\n        y = y / accel_scale_modifier\n        z = z / accel_scale_modifier\n\n        if raw == True:\n            return { 'x': x, 'y': y, 'z': z }\n        elif raw == False:\n            return { 'x': x * self._gravityFactor, 'y': y * self._gravityFactor, 'z': z * self._gravityFactor }", "response": "Gets and returns the X Y and Z values from the accelerometer."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads range of gyroscope.", "response": "def readGyroRange( self ):\n        \"\"\"!\n        Read range of gyroscope.\n\n        @return an int value. It should be one of the following values (GYRO_RANGE_250DEG)\n\n        @see GYRO_RANGE_250DEG\n        @see GYRO_RANGE_500DEG\n        @see GYRO_RANGE_1KDEG\n        @see GYRO_RANGE_2KDEG\n        \"\"\"\n        raw_data = self._readByte( self.REG_GYRO_CONFIG )\n        raw_data = (raw_data | 0xE7) ^ 0xE7\n        return raw_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getGyroData(self):\n        x = self._readWord(self.REG_GYRO_XOUT_H)\n        y = self._readWord(self.REG_GYRO_YOUT_H)\n        z = self._readWord(self.REG_GYRO_ZOUT_H)\n\n        gyro_scale_modifier = None\n        gyro_range = self.readGyroRange()\n\n        if gyro_range == self.GYRO_RANGE_250DEG:\n            gyro_scale_modifier = self.GYRO_SCALE_MODIFIER_250DEG\n        elif gyro_range == self.GYRO_RANGE_500DEG:\n            gyro_scale_modifier = self.GYRO_SCALE_MODIFIER_500DEG\n        elif gyro_range == self.GYRO_RANGE_1KDEG:\n            gyro_scale_modifier = self.GYRO_SCALE_MODIFIER_1KDEG\n        elif gyro_range == self.GYRO_RANGE_2KDEG:\n            gyro_scale_modifier = self.GYRO_SCALE_MODIFIER_2KDEG\n        else:\n            print(\"ERROR: Unkown gyroscope range!\")\n            return False\n            #gyro_scale_modifier = self.GYRO_SCALE_MODIFIER_250DEG\n\n        x = x / gyro_scale_modifier\n        y = y / gyro_scale_modifier\n        z = z / gyro_scale_modifier\n        return {'x': x, 'y': y, 'z': z}", "response": "Gets and returns the X Y and Z values from the gyroscope range and returns the X Y and Z values or Boolean."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting all the available data for a specific locale.", "response": "def getAllData(self, temp = True, accel = True, gyro = True):\n        \"\"\"!\n        Get all the available data.\n\n        @param temp: True - Allow to return Temperature data\n        @param accel: True - Allow to return Accelerometer data\n        @param gyro: True - Allow to return Gyroscope data\n\n        @return a dictionary data\n            @retval {} Did not read any data\n            @retval {\"temp\":32.3,\"accel\":{\"x\":0.45634,\"y\":0.2124,\"z\":1.334},\"gyro\":{\"x\":0.45634,\"y\":0.2124,\"z\":1.334}} Returned all data\n        \"\"\"\n        allData = {}\n        if temp:\n            allData[\"temp\"] = self.getTemp()\n\n        if accel:\n            allData[\"accel\"] = self.getAccelData( raw = False )\n\n        if gyro:\n            allData[\"gyro\"] = self.getGyroData()\n\n        return allData"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_neighbor_expression_vector(neighbors, gene_expression_dict):\r\n    expressions = []  # Expression vector.\r\n    for gene in neighbors:\r\n        try:\r\n            expression = gene_expression_dict[gene]\r\n        except KeyError:\r\n            continue\r\n\r\n        expressions.append(expression)\r\n    return expressions", "response": "Get an expression vector of neighboring genes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting an expression vector into a probability vector.", "response": "def exp2prob(expression_vector):\r\n    \"\"\"Convert an expression vector into a probability vector.\r\n    Attribute:\r\n        expression_vector (list): List of expression values.\r\n    \"\"\"\r\n    v = np.asarray(expression_vector)\r\n    if np.sum(v) == 0:\r\n        return np.zeros(len(expression_vector))\r\n    else:\r\n        return v / np.sum(v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kld(p1, p2):\r\n    return np.sum(np.where(p1 != 0, p1 * np.log(p1 / p2), 0))", "response": "Compute Kullback - Leibler divergence between p1 and p2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef jsd(p1, p2):\r\n    m = (p1 + p2) / 2\r\n    return (kld(p1, m) + kld(p2, m)) / 2", "response": "Compute Jensen - Shannon divergence between p1 and p2."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef njsd(network, ref_gene_expression_dict, query_gene_expression_dict, gene_set):\r\n    gene_jsd_dict = dict()\r\n    reference_genes = ref_gene_expression_dict.keys()\r\n    assert len(reference_genes) != 'Reference gene expression profile should have > 0 genes.'\r\n\r\n    for gene in gene_set:\r\n        if gene not in network.nodes:\r\n            continue\r\n\r\n        neighbors = find_neighbors(network, gene)\r\n\r\n        query_expression_vec = get_neighbor_expression_vector(neighbors, query_gene_expression_dict)\r\n        ref_expression_vec = get_neighbor_expression_vector(neighbors, ref_gene_expression_dict)\r\n        assert len(query_expression_vec) == len(ref_expression_vec), 'Topology of reference network and query network differs. Please check.'\r\n\r\n        # A gene which has non-expressed neighbors is ignored.\r\n        if np.sum(query_expression_vec) == 0 and np.sum(ref_expression_vec) == 0:\r\n            continue\r\n\r\n        query_p_vec = exp2prob(query_expression_vec)\r\n        ref_p_vec = exp2prob(ref_expression_vec)\r\n\r\n        gene_jsd_dict[gene] = jsd(query_p_vec, ref_p_vec)\r\n\r\n    return np.mean(list(gene_jsd_dict.values()))", "response": "Calculate Jensen - Shannon divergence between query and reference gene expression profiles."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef lookupProcessor(name):\n    if name in _proc_lookup:\n        return _proc_lookup[name]\n    else:\n        error_string = 'If you are creating a new processor, please read the\\\ndocumentation on creating a new processor'\n        raise LookupError(\"Unknown processor %s\\n%s\" % (name, error_string))", "response": "Lookup a processor class object by its name"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the developer settings.", "response": "def read_developer_settings():\n    \"\"\"\n    \u0427\u0438\u0442\u0430\u0435\u0442 \u043a\u043e\u043d\u0444\u0438\u0433\u0443\u0440\u0430\u0446\u0438\u0438 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u0447\u0438\u043a\u0430 \u0441 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e\u0439 \u043c\u0430\u0448\u0438\u043d\u044b \u0438\u043b\u0438 \u0438\u0437 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0445 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f\n    \u041f\u0440\u0438 \u044d\u0442\u043e\u043c \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u043f\u0440\u0438\u043e\u0440\u0438\u0442\u0435\u0442\u043d\u0435\u0435\n\n    :return: dict|None\n    \"\"\"\n    ret = read_cfg(\"/.rwmeta/developer_settings.json\")\n\n    env_developer_settings = os.environ.get('META_SERVICE_ACCOUNT_SECRET', None)\n    if not env_developer_settings:\n        env_developer_settings = os.environ.get('X-META-Developer-Settings', None)\n    if env_developer_settings:\n        ret = json.loads(env_developer_settings)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_cfg(path) -> dict:\n    ret = None\n    full_path = __build_path(path)\n    if os.path.isfile(full_path):\n        with open(full_path, 'r') as myfile:\n            ret = json.loads(myfile.read())\n    return ret", "response": "read the configuration file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting the configuration to a file.", "response": "def write_cfg(path, value) -> None:\n    \"\"\"\n    :param path:  example: \"/.rwmeta/developer_settings.json\"\n    :param value: dict\n    \"\"\"\n    full_path = __build_path(path)\n    with open(full_path, 'w') as myfile:\n        myfile.write(json.dumps(value))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef start(self, s):\n        # type: (Optional[Type[Nonterminal]]) -> None\n        \"\"\"\n        Set start symbol of the grammar.\n        :param s: Start symbol to set.\n        :raise NonterminalDoesNotExistsException: If the start symbol is not in nonterminals.\n        \"\"\"\n        if s is not None and s not in self.nonterminals:\n            raise NonterminalDoesNotExistsException(None, s, self)\n        self._start_symbol = s", "response": "Sets the start symbol of the grammar."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates and serialize the value.", "response": "def serialize(self, value, entity=None, request=None):\n    \"\"\" Validate and serialize the value.\n\n    This is the default implementation\n    \"\"\"\n\n    ret = self.from_python(value)\n    self.validate(ret)\n    self.run_validators(value)\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_composite_reflectivity(self, tower_id, background='#000000', include_legend=True, include_counties=True,\n                                   include_warnings=True, include_highways=True, include_cities=True,\n                                   include_rivers=True, include_topography=True):\n        \"\"\"\n        Get the composite reflectivity for a noaa radar site.\n        :param tower_id: The noaa tower id.  Ex Huntsville, Al -> 'HTX'.\n        :type tower_id: str\n        :param background: The hex background color.\n        :type background: str\n        :param include_legend: True - include legend.\n        :type include_legend: bool\n        :param include_counties: True - include county lines.\n        :type include_counties: bool\n        :param include_warnings: True - include warning lines.\n        :type include_warnings: bool\n        :param include_highways: True - include highways.\n        :type include_highways: bool\n        :param include_cities: True - include city labels.\n        :type include_cities: bool\n        :param include_rivers: True - include rivers\n        :type include_rivers: bool\n        :param include_topography: True - include topography\n        :type include_topography: bool\n        :rtype: PIL.Image\n        :return: A PIL.Image instance with the Radar composite reflectivity.\n        \"\"\"\n        return self._build_radar_image(tower_id, \"NCR\", background=background, include_legend=include_legend,\n                                       include_counties=include_counties, include_warnings=include_warnings,\n                                       include_highways=include_highways, include_cities=include_cities,\n                                       include_rivers=include_rivers, include_topography=include_topography)", "response": "Get the composite reflectivity image for a specific tower."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the given terminals into the set.", "response": "def add(self, *terminals):\n        # type: (Iterable[Any]) -> None\n        \"\"\"\n        Add terminals into the set.\n        :param terminals: Terminals to insert.\n        \"\"\"\n        for term in terminals:\n            if term in self:\n                continue\n            super().add(term)\n            self._assign_map[term] = set()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(self, *terminals):\n        # type: (Iterable[Any]) -> None\n        \"\"\"\n        Remove terminals from the set.\n        Removes also rules using this terminal.\n        :param terminals: Terminals to remove.\n        :raise KeyError if the object is not in the set.\n        \"\"\"\n        for term in set(terminals):\n            if term not in self:\n                raise KeyError('Terminal ' + str(term) + ' is not inside')\n            self._grammar.rules.remove(*self._assign_map[term], _validate=False)\n            del self._assign_map[term]\n            super().remove(term)", "response": "Removes the rules using this terminal."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_network(network_fp):\r\n    graph = nx.Graph()\r\n    gene_set = set()\r\n\r\n    with open(network_fp) as inFile:\r\n        inFile.readline()  # Skip header.\r\n        for line in inFile.readlines():\r\n            gene1, gene2 = line.strip().split()\r\n\r\n            graph.add_edge(gene1, gene2)\r\n            gene_set.add(gene1)\r\n            gene_set.add(gene2)\r\n\r\n    return graph, gene_set", "response": "Parses a network file and returns a network instance and a gene set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_gene_set(gene_set_fp):\r\n    group_gene_set_dict = OrderedDict()\r\n\r\n    with open(gene_set_fp) as inFile:\r\n        for line in inFile.readlines():\r\n            tokens = line.strip().split('\\t')\r\n            group = tokens[0]\r\n            gene_set = set(tokens[1:])\r\n\r\n            group_gene_set_dict[group] = gene_set\r\n\r\n    return group_gene_set_dict", "response": "Parses a gene set file and returns a group - > gene set dictionary."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_gene_expression(gene_expression_fp, mean=False):\r\n    gene_expression_dict = OrderedDict()\r\n    with open(gene_expression_fp) as inFile:\r\n        inFile.readline()  # Skip header.\r\n        for line in inFile.readlines():\r\n            tokens = line.strip().split('\\t')\r\n            gene_identifier = tokens[0]\r\n\r\n            if mean:\r\n                expression = np.log2(np.mean([float(t) for t in tokens[1:]]) + 1.0)\r\n            else:\r\n                expression = np.log2(float(tokens[1]) + 1.0)\r\n\r\n            gene_expression_dict[gene_identifier] = expression\r\n\r\n    return gene_expression_dict", "response": "Parses a gene expression file and returns a dictionary of gene identifier - > expression"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef side_task(pipe, *side_jobs):\n    ''' allows you to run a function in a pipeline without affecting the data '''\n    # validate the input\n    assert iterable(pipe), 'side_task needs the first argument to be iterable'\n    for sj in side_jobs:\n        assert callable(sj), 'all side_jobs need to be functions, not {}'.format(sj)\n    # add a pass through function to side_jobs\n    side_jobs = (lambda i:i ,) + side_jobs\n    # run the pipeline\n    for i in map(pipe, *side_jobs):\n        yield i[0]", "response": "allows you to run a function in a pipeline without affecting the data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the ec2 cloud provider and returns a new connection object.", "response": "def _connect(self):\n        \"\"\"Connects to the ec2 cloud provider\n\n        :return: :py:class:`boto.ec2.connection.EC2Connection`\n        :raises: Generic exception on error\n        \"\"\"\n        # check for existing connection\n        if self._ec2_connection:\n            return self._ec2_connection\n\n        if not self._vpc:\n            vpc_connection = None\n\n        try:\n            log.debug(\"Connecting to ec2 host %s\", self._ec2host)\n            region = ec2.regioninfo.RegionInfo(name=self._region_name,\n                                               endpoint=self._ec2host)\n\n            # connect to webservice\n            ec2_connection = boto.connect_ec2(\n                aws_access_key_id=self._access_key,\n                aws_secret_access_key=self._secret_key,\n                is_secure=self._secure,\n                host=self._ec2host, port=self._ec2port,\n                path=self._ec2path, region=region)\n            log.debug(\"EC2 connection has been successful.\")\n\n            if self._vpc:\n                vpc_connection = boto.connect_vpc(\n                    aws_access_key_id=self._access_key,\n                    aws_secret_access_key=self._secret_key,\n                    is_secure=self._secure,\n                    host=self._ec2host, port=self._ec2port,\n                    path=self._ec2path, region=region)\n                log.debug(\"VPC connection has been successful.\")\n\n                for vpc in vpc_connection.get_all_vpcs():\n                    log.debug(\"Checking whether %s matches %s/%s\" %\n                        (self._vpc, vpc.tags['Name'], vpc.id))\n                    if self._vpc in [vpc.tags['Name'], vpc.id]:\n                        self._vpc_id = vpc.id\n                        if self._vpc != self._vpc_id:\n                            log.debug(\"VPC %s matches %s\" %\n                                (self._vpc, self._vpc_id))\n                        break\n                else:\n                    raise VpcError('VPC %s does not exist.' % self._vpc)\n\n            # list images to see if the connection works\n            # images = self._ec2_connection.get_all_images()\n            # log.debug(\"%d images found on cloud %s\",\n            #           len(images), self._ec2host)\n\n        except Exception as e:\n            log.error(\"connection to ec2 could not be \"\n                      \"established: message=`%s`\", str(e))\n            raise\n\n        self._ec2_connection, self._vpc_connection = (\n            ec2_connection, vpc_connection)\n        return self._ec2_connection"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start_instance(self, key_name, public_key_path, private_key_path,\n                       security_group, flavor, image_id, image_userdata,\n                       username=None, node_name=None, network_ids=None,\n                       price=None, timeout=None,\n                       **kwargs):\n        \"\"\"Starts a new instance on the cloud using the given properties.\n        The following tasks are done to start an instance:\n\n        * establish a connection to the cloud web service\n        * check ssh keypair and upload it if it does not yet exist. This is\n          a locked process, since this function might be called in multiple\n          threads and we only want the key to be stored once.\n        * check if the security group exists\n        * run the instance with the given properties\n\n        :param str key_name: name of the ssh key to connect\n        :param str public_key_path: path to ssh public key\n        :param str private_key_path: path to ssh private key\n        :param str security_group: firewall rule definition to apply on the\n                                   instance\n        :param str flavor: machine type to use for the instance\n        :param str image_id: image type (os) to use for the instance\n        :param str image_userdata: command to execute after startup\n        :param str username: username for the given ssh key, default None\n        :param float price: Spot instance price (if 0, do not use spot instances).\n        :param int price: Timeout (in seconds) waiting for spot instances;\n                          only used if price > 0.\n\n        :return: str - instance id of the started instance\n        \"\"\"\n        connection = self._connect()\n\n        log.debug(\"Checking keypair `%s`.\", key_name)\n        # the `_check_keypair` method has to be called within a lock,\n        # since it will upload the key if it does not exist and if this\n        # happens for every node at the same time ec2 will throw an error\n        # message (see issue #79)\n        with BotoCloudProvider.__node_start_lock:\n            self._check_keypair(key_name, public_key_path, private_key_path)\n\n        log.debug(\"Checking security group `%s`.\", security_group)\n        security_group_id = self._check_security_group(security_group)\n        # image_id = self._find_image_id(image_id)\n\n        if network_ids:\n            interfaces = []\n            for subnet in network_ids.split(','):\n                subnet_id = self._check_subnet(subnet)\n\n                interfaces.append(ec2.networkinterface.NetworkInterfaceSpecification(\n                    subnet_id=subnet_id, groups=[security_group_id],\n                    associate_public_ip_address=self.request_floating_ip))\n            interfaces = ec2.networkinterface.NetworkInterfaceCollection(*interfaces)\n\n            security_groups = []\n        else:\n            interfaces = None\n            security_groups = [security_group]\n\n        # get defaults for `price` and `timeout` from class instance\n        if price is None:\n            price = self.price\n        if timeout is None:\n            timeout = self.timeout\n\n        try:\n            #start spot instance if bid is specified\n            if price:\n                log.info(\"Requesting spot instance with price `%s` ...\", price)\n                request = connection.request_spot_instances(\n                                price,image_id, key_name=key_name, security_groups=security_groups,\n                                instance_type=flavor, user_data=image_userdata,\n                                network_interfaces=interfaces,\n                                instance_profile_name=self._instance_profile)[-1]\n\n                # wait until spot request is fullfilled (will wait\n                # forever if no timeout is given)\n                start_time = time.time()\n                timeout = (float(timeout) if timeout else 0)\n                log.info(\"Waiting for spot instance (will time out in %d seconds) ...\", timeout)\n                while  request.status.code != 'fulfilled':\n                    if timeout and time.time()-start_time > timeout:\n                        request.cancel()\n                        raise RuntimeError('spot instance timed out')\n                    time.sleep(self.POLL_INTERVAL)\n                    # update request status\n                    request=connection.get_all_spot_instance_requests(request_ids=request.id)[-1]\n            else:\n                reservation = connection.run_instances(\n                    image_id, key_name=key_name, security_groups=security_groups,\n                    instance_type=flavor, user_data=image_userdata,\n                    network_interfaces=interfaces,\n                    instance_profile_name=self._instance_profile)\n        except Exception as ex:\n            log.error(\"Error starting instance: %s\", ex)\n            if \"TooManyInstances\" in ex:\n                raise ClusterError(ex)\n            else:\n                raise InstanceError(ex)\n        if price:\n            vm  = connection.get_only_instances(instance_ids=[request.instance_id])[-1]\n        else:\n            vm = reservation.instances[-1]\n        vm.add_tag(\"Name\", node_name)\n\n        # cache instance object locally for faster access later on\n        self._instances[vm.id] = vm\n\n        return vm.id", "response": "Starts a new instance on the cloud using the given properties."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _check_keypair(self, name, public_key_path, private_key_path):\n        connection = self._connect()\n        keypairs = connection.get_all_key_pairs()\n        keypairs = dict((k.name, k) for k in keypairs)\n\n        # decide if dsa or rsa key is provided\n        pkey = None\n        is_dsa_key = False\n        try:\n            pkey = DSSKey.from_private_key_file(private_key_path)\n            is_dsa_key = True\n        except PasswordRequiredException:\n            warn(\"Unable to check key file `{0}` because it is encrypted with a \"\n                 \"password. Please, ensure that you added it to the SSH agent \"\n                 \"with `ssh-add {1}`\"\n                 .format(private_key_path, private_key_path))\n        except SSHException:\n            try:\n                pkey = RSAKey.from_private_key_file(private_key_path)\n            except PasswordRequiredException:\n                warn(\"Unable to check key file `{0}` because it is encrypted with a \"\n                     \"password. Please, ensure that you added it to the SSH agent \"\n                     \"with `ssh-add {1}`\"\n                     .format(private_key_path, private_key_path))\n            except SSHException:\n                raise KeypairError('File `%s` is neither a valid DSA key '\n                                   'or RSA key.' % private_key_path)\n\n        # create keys that don't exist yet\n        if name not in keypairs:\n            log.warning(\n                \"Keypair `%s` not found on resource `%s`, Creating a new one\",\n                name, self._url)\n            with open(os.path.expanduser(public_key_path)) as f:\n                key_material = f.read()\n                try:\n                    # check for DSA on amazon\n                    if \"amazon\" in self._ec2host and is_dsa_key:\n                        log.error(\n                            \"Apparently, amazon does not support DSA keys. \"\n                            \"Please specify a valid RSA key.\")\n                        raise KeypairError(\n                            \"Apparently, amazon does not support DSA keys.\"\n                            \"Please specify a valid RSA key.\")\n\n                    connection.import_key_pair(name, key_material)\n                except Exception as ex:\n                    log.error(\n                        \"Could not import key `%s` with name `%s` to `%s`\",\n                        name, public_key_path, self._url)\n                    raise KeypairError(\n                        \"could not create keypair `%s`: %s\" % (name, ex))\n        else:\n            # check fingerprint\n            cloud_keypair = keypairs[name]\n\n            if pkey:\n                fingerprint = str.join(\n                    ':', (i.encode('hex') for i in pkey.get_fingerprint()))\n\n                if fingerprint != cloud_keypair.fingerprint:\n                    if \"amazon\" in self._ec2host:\n                        log.error(\n                            \"Apparently, Amazon does not compute the RSA key \"\n                            \"fingerprint as we do! We cannot check if the \"\n                            \"uploaded keypair is correct!\")\n                    else:\n                        raise KeypairError(\n                            \"Keypair `%s` is present but has \"\n                            \"different fingerprint. Aborting!\" % name)", "response": "Checks if the keypair is valid and creates the ssh keys if not"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits on given patterns and yield pieces of items in the given order.", "response": "def split(pipe, splitter, skip_empty=False):\n    ''' this function works a lot like groupby but splits on given patterns,\n        the same behavior as str.split provides. if skip_empty is True,\n        split only yields pieces that have contents\n\n        Example:\n\n            splitting 1011101010101\n            by        10\n            returns   ,11,,,,1\n\n        Or if skip_empty is True\n\n            splitting 1011101010101\n            by        10\n            returns   11,1\n    '''\n\n    splitter = tuple(splitter)\n    len_splitter = len(splitter)\n    pipe=iter(pipe)\n    current = deque()\n    tmp = []\n    windowed = window(pipe, len(splitter))\n    for i in windowed:\n        if i == splitter:\n            skip(windowed, len(splitter)-1)\n            yield list(current)\n            current.clear()\n            tmp = []\n        else:\n            current.append(i[0])\n            tmp = i\n    if len(current) or len(tmp):\n        yield list(chain(current,tmp))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new ReturnLineItem with the specified attributes.", "response": "def create_return_line_item(cls, return_line_item, **kwargs):\n        \"\"\"Create ReturnLineItem\n\n        Create a new ReturnLineItem\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_return_line_item(return_line_item, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param ReturnLineItem return_line_item: Attributes of returnLineItem to create (required)\n        :return: ReturnLineItem\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_return_line_item_with_http_info(return_line_item, **kwargs)\n        else:\n            (data) = cls._create_return_line_item_with_http_info(return_line_item, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting an instance of ReturnLineItem by its ID.", "response": "def delete_return_line_item_by_id(cls, return_line_item_id, **kwargs):\n        \"\"\"Delete ReturnLineItem\n\n        Delete an instance of ReturnLineItem by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_return_line_item_by_id(return_line_item_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str return_line_item_id: ID of returnLineItem to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_return_line_item_by_id_with_http_info(return_line_item_id, **kwargs)\n        else:\n            (data) = cls._delete_return_line_item_by_id_with_http_info(return_line_item_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_return_line_item_by_id(cls, return_line_item_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_return_line_item_by_id_with_http_info(return_line_item_id, **kwargs)\n        else:\n            (data) = cls._get_return_line_item_by_id_with_http_info(return_line_item_id, **kwargs)\n            return data", "response": "Find ReturnLineItem by its ID Return single instance of ReturnLineItem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef list_all_return_line_items(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_return_line_items_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_return_line_items_with_http_info(**kwargs)\n            return data", "response": "List ReturnLineItems\n        This method returns a list of ReturnLineItems\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace ReturnLineItem by ID", "response": "def replace_return_line_item_by_id(cls, return_line_item_id, return_line_item, **kwargs):\n        \"\"\"Replace ReturnLineItem\n\n        Replace all attributes of ReturnLineItem\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_return_line_item_by_id(return_line_item_id, return_line_item, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str return_line_item_id: ID of returnLineItem to replace (required)\n        :param ReturnLineItem return_line_item: Attributes of returnLineItem to replace (required)\n        :return: ReturnLineItem\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_return_line_item_by_id_with_http_info(return_line_item_id, return_line_item, **kwargs)\n        else:\n            (data) = cls._replace_return_line_item_by_id_with_http_info(return_line_item_id, return_line_item, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_return_line_item_by_id(cls, return_line_item_id, return_line_item, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_return_line_item_by_id_with_http_info(return_line_item_id, return_line_item, **kwargs)\n        else:\n            (data) = cls._update_return_line_item_by_id_with_http_info(return_line_item_id, return_line_item, **kwargs)\n            return data", "response": "Update ReturnLineItemAttributes by ID"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a tracking_code return a list of events related to that tracking code", "response": "def query_tracking_code(tracking_code, year=None):\n    \"\"\"\n    Given a tracking_code return a list of events related the tracking code\n    \"\"\"\n    payload = {\n        'Anio': year or datetime.now().year,\n        'Tracking': tracking_code,\n    }\n    response = _make_request(TRACKING_URL, payload)\n\n    if not response['d']:\n        return []\n\n    data = response['d'][0]\n\n    destination = data['RetornoCadena6']\n    payload.update({\n        'Destino': destination,\n    })\n\n    response = _make_request(TRACKING_DETAIL_URL, payload)\n    return _process_detail(response['d'])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef comments_nb_counts():\n    recid = request.view_args.get('recid')\n\n    if recid is None:\n        return\n    elif recid == 0:\n        return 0\n    else:\n        return CmtRECORDCOMMENT.count(*[\n            CmtRECORDCOMMENT.id_bibrec == recid,\n            CmtRECORDCOMMENT.star_score == 0,\n            CmtRECORDCOMMENT.status.notin_(['dm', 'da'])\n        ])", "response": "Return the number of comments for the record recid."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_date(datestring):\n    datestring = str(datestring).strip()\n\n    if not datestring[0].isdigit():\n        raise ParseError()\n\n    if 'W' in datestring.upper():\n        try:\n            datestring = datestring[:-1] + str(int(datestring[-1:]) -1)\n        except:\n            pass\n\n    for regex, pattern in DATE_FORMATS:\n        if regex.match(datestring):\n            found = regex.search(datestring).groupdict()\n            dt = datetime.utcnow().strptime(found['matched'], pattern)\n\n            if 'fraction' in found and found['fraction'] is not None:\n                dt = dt.replace(microsecond=int(found['fraction'][1:]))\n\n            if 'timezone' in found and found['timezone'] is not None:\n                dt = dt.replace(tzinfo=Timezone(found.get('timezone', '')))\n\n            return dt\n\n    return parse_time(datestring)", "response": "Parse an ISO8601 formatted date string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a config parameter.", "response": "def config_param(self, conf_alias, param):\n        \"\"\"\n        \u041f\u043e\u043b\u0443\u0447\u0430\u0435\u0442 \u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0441 \u0441\u0435\u0440\u0432\u0435\u0440\u0430, \u043a\u0435\u0448\u0438\u0440\u0443\u0435\u0442 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e \u0438 \u0434\u0430\u0435\u0442 \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0438\u043d\u0442\u0435\u0440\u0444\u0435\u0439\u0441 \u0438\u0445 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u0438\u044f\n        :param conf_alias:\n        :param param:\n        :return:\n        \"\"\"\n        data = self.data_get(conf_alias)\n        flat_cache = self.__data_get_flatten_cache.get(conf_alias)\n        if flat_cache is None:\n            flat_cache = self.__flatten_dict(data, '', '.')\n            self.__data_get_flatten_cache[conf_alias] = flat_cache\n        if param not in flat_cache:\n            raise KeyError(\"Key not found: \" + conf_alias)\n        return flat_cache.get(param)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconnects to the database and return the connection object", "response": "def connect(self):\n        \"\"\"connect to the database\n\n        **Return:**\n            - ``dbConn`` -- the database connection\n\n        See the class docstring for usage\n        \"\"\"\n        self.log.debug('starting the ``get`` method')\n\n        dbSettings = self.dbSettings\n\n        port = False\n        if \"tunnel\" in dbSettings and dbSettings[\"tunnel\"]:\n            port = self._setup_tunnel(\n                tunnelParameters=dbSettings[\"tunnel\"]\n            )\n\n        # SETUP A DATABASE CONNECTION\n        host = dbSettings[\"host\"]\n        user = dbSettings[\"user\"]\n        passwd = dbSettings[\"password\"]\n        dbName = dbSettings[\"db\"]\n        dbConn = ms.connect(\n            host=host,\n            user=user,\n            passwd=passwd,\n            db=dbName,\n            port=port,\n            use_unicode=True,\n            charset='utf8',\n            local_infile=1,\n            client_flag=ms.constants.CLIENT.MULTI_STATEMENTS,\n            connect_timeout=36000,\n            max_allowed_packet=51200000\n        )\n        if self.autocommit:\n            dbConn.autocommit(True)\n\n        self.log.debug('completed the ``get`` method')\n        return dbConn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map_(cache: Mapping[Domain, Range]) -> Operator[Map[Domain, Range]]:\n\n    def wrapper(function: Map[Domain, Range]) -> Map[Domain, Range]:\n        @wraps(function)\n        def wrapped(argument: Domain) -> Range:\n            try:\n                return cache[argument]\n            except KeyError:\n                return function(argument)\n\n        return wrapped\n\n    return wrapper", "response": "Returns a decorator that calls wrapped function if nothing was found in cache for its argument."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef updatable_map(cache: MutableMapping[Domain, Range]) -> Operator[Map]:\n\n    def wrapper(function: Map[Domain, Range]) -> Map[Domain, Range]:\n        @wraps(function)\n        def wrapped(argument: Domain) -> Range:\n            try:\n                return cache[argument]\n            except KeyError:\n                result = function(argument)\n                cache[argument] = result\n                return result\n\n        return wrapped\n\n    return wrapper", "response": "Returns a decorator that returns a function that returns the result of the function and sets it in cache if it is not already."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn property that calls given getter on the first access .", "response": "def property_(getter: Map[Domain, Range]) -> property:\n    \"\"\"\n    Returns property that calls given getter on the first access\n    and reuses result afterwards.\n\n    Class instances should be hashable and weak referenceable.\n    \"\"\"\n    return property(map_(WeakKeyDictionary())(getter))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntraverses the tree using a callback function.", "response": "def traverse(root, callback, *args, **kwargs):\n        # type: (Nonterminal, Callable[[Any, Callable, Any, Any], Generator], Any, Any) -> Generator\n        \"\"\"\n        Traverse AST based on callback.\n        :param root: Root element of the parsed tree.\n        :param callback: Function that accepts current node, callback `c_2` and parameters from the parent.\n        Function must yield individual values.\n        Its possible to yield callback c_2 **call** on any node to call the recursion.\n        The callback can accept parameters from the parent call.\n        The root will receive parameters from the `traverse` call.\n\n        Example of pre-order traversing:\n        def traverse_func(item, callback):\n            if isinstance(item, Rule):\n                yield item\n                for el in item.to_symbols:\n                    yield callback(el)\n            elif isinstance(item, Nonterminal):\n                yield item\n                yield callback(item.to_rule)\n            else:\n                yield item\n\n        :return: Sequence of nodes to traverse.\n        \"\"\"\n        class MyGenerator:\n            def __init__(self, gen):\n                self._gen = gen\n            def __next__(self):\n                return next(self._gen)\n\n        def inner_callback(item, *args, **kwargs):\n            return MyGenerator(callback(item, inner_callback, *args, **kwargs))\n\n        to_call = list()\n        to_call.append(inner_callback(root, *args, **kwargs))\n        while len(to_call) > 0:\n            current = to_call.pop()\n            try:\n                el = next(current)\n                to_call.append(current)\n                if isinstance(el, MyGenerator):\n                    to_call.append(el)\n                else:\n                    yield el\n            except StopIteration:\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef traverse_separated(root, callbackRules, callbackNonterminals, callbackTerminals, *args, **kwargs):\n        # type: (Nonterminal, Callable[[Rule, Callable, Any, Any], Generator], Callable[[Nonterminal, Callable, Any, Any], Generator], Callable[[Terminal, Callable, Any, Any], Generator], Any, Any) -> Generator\n        \"\"\"\n        Same as traverse method, but have different callbacks for rules, nonterminals and terminals.\n        Functions accepts current node, callback `c_2` and parameters from the parent.\n        Functions must yield individual values.\n        Its possible to yield callback c_2 **call** on any node to call the recursion.\n        The callback can accept parameters from the parent call.\n        The root will receive parameters from the `traverse_separated` call.\n        :param root: Root node of the parsed tree.\n        :param callbackRules: Function to call for every rule.\n        :param callbackNonterminals: Function to call for every nonterminal.\n        :param callbackTerminals: Function to call for every terminal.\n        :return: Sequence of nodes to traverse.\n        \"\"\"\n\n        def separate_traverse_callback(item, callback, *args, **kwargs):\n            if isinstance(item, Rule):\n                return callbackRules(item, callback, *args, **kwargs)\n            if isinstance(item, Nonterminal):\n                return callbackNonterminals(item, callback, *args, **kwargs)\n            if isinstance(item, Terminal):\n                return callbackTerminals(item, callback, *args, **kwargs)\n\n        return Traversing.traverse(root, separate_traverse_callback, *args, **kwargs)", "response": "A recursive method that traverses the tree and calls the callback function for each node."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pre_order(root):\n        # type: (Nonterminal) -> Generator\n        \"\"\"\n        Perform pre-order traversing. Expects tree like structure.\n        Traverse in DFS fashion.\n        :param root: Root tree of the parsed tree.\n        :return: Sequence of nodes to traverse.\n        \"\"\"\n\n        def traverse_rule(item, callback):\n            yield item\n            for el in item.to_symbols:\n                yield callback(el)\n\n        def traverse_nonterminal(item, callback):\n            yield item\n            yield callback(item.to_rule)\n\n        def traverse_terminal(item, callback):\n            yield item\n\n        return Traversing.traverse_separated(root, traverse_rule, traverse_nonterminal, traverse_terminal)", "response": "Perform a pre - order traversal of the tree like structure."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransform the parsed tree to the string.", "response": "def print(root):\n        # type: (Union[Nonterminal,Terminal,Rule])-> str\n        \"\"\"\n        Transform the parsed tree to the string. Expects tree like structure.\n        You can see example output below.\n\n        (R)SplitRules26\n        |--(N)Iterate\n        |  `--(R)SplitRules30\n        |     `--(N)Symb\n        |        `--(R)SplitRules4\n        |           `--(T)e\n        `--(N)Concat\n           `--(R)SplitRules27\n              `--(N)Iterate\n                 `--(R)SplitRules30\n                    `--(N)Symb\n                       `--(R)SplitRules5\n                          `--(T)f\n\n        :param root: Root node of the parsed tree.\n        :return: String representing the parsed tree (ends with newline).\n        \"\"\"\n        # print the part before the element\n        def print_before(previous=0, defined=None, is_last=False):\n            defined = defined or {}\n            ret = ''\n            if previous != 0:\n                for i in range(previous - 1):\n                    # if the column is still active write |\n                    if i in defined:\n                        ret += '|  '\n                    # otherwise just print space\n                    else:\n                        ret += '   '\n                # if is current element last child, don't print |-- but `-- instead\n                ret += '`--' if is_last else '|--'\n            return ret\n\n        # print the terminal\n        def terminal_traverse(term, callback, previous=0, defined=None, is_last=False):\n            before = print_before(previous, defined, is_last)\n            yield before + '(T)' + str(term.s) + '\\n'\n\n        # print the nonterminal\n        def nonterminal_traverse(nonterm, callback, previous=0, defined=None, is_last=False):\n            before = print_before(previous, defined, is_last)\n            yield before + '(N)' + nonterm.__class__.__name__ + '\\n'\n            yield callback(nonterm.to_rule, previous + 1, defined, True)\n\n        # print the rule\n        def rule_traverse(rule, callback, previous=0, defined=None, is_last=False):\n            # print the rule name\n            before = print_before(previous, defined, is_last)\n            yield before + '(R)' + rule.__class__.__name__ + '\\n'\n            # register new column\n            defined = defined or set()\n            defined.add(previous)\n            # print all childs except the last one\n            for i in range(len(rule.to_symbols) - 1):\n                yield callback(rule.to_symbols[i], previous + 1, defined, False)\n            # unregister the column as last child print it automatically\n            defined.remove(previous)\n            yield callback(rule.to_symbols[-1], previous + 1, defined, True)\n\n        res = Traversing.traverse_separated(root, rule_traverse, nonterminal_traverse, terminal_traverse)\n        return str.join(\"\", res)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_colours(color_group, color_name, reverse=False):\n    color_group = color_group.lower()\n    cmap = get_map(color_group, color_name, reverse=reverse)\n    return cmap.hex_colors\n    \"\"\"\n    if not reverse:\n        return cmap.hex_colors\n    else:\n        return cmap.hex_colors[::-1]\n    \"\"\"", "response": "Get the colors for a given color group and name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a new DiscountCoupon with the given attributes", "response": "def create_discount_coupon(cls, discount_coupon, **kwargs):\n        \"\"\"Create DiscountCoupon\n\n        Create a new DiscountCoupon\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_discount_coupon(discount_coupon, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param DiscountCoupon discount_coupon: Attributes of discountCoupon to create (required)\n        :return: DiscountCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_discount_coupon_with_http_info(discount_coupon, **kwargs)\n        else:\n            (data) = cls._create_discount_coupon_with_http_info(discount_coupon, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_discount_coupon_by_id(cls, discount_coupon_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_discount_coupon_by_id_with_http_info(discount_coupon_id, **kwargs)\n        else:\n            (data) = cls._delete_discount_coupon_by_id_with_http_info(discount_coupon_id, **kwargs)\n            return data", "response": "Delete an instance of DiscountCoupon by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind DiscountCoupon by ID Return single instance of DiscountCoupon with its ID.", "response": "def get_discount_coupon_by_id(cls, discount_coupon_id, **kwargs):\n        \"\"\"Find DiscountCoupon\n\n        Return single instance of DiscountCoupon by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_discount_coupon_by_id(discount_coupon_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str discount_coupon_id: ID of discountCoupon to return (required)\n        :return: DiscountCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_discount_coupon_by_id_with_http_info(discount_coupon_id, **kwargs)\n        else:\n            (data) = cls._get_discount_coupon_by_id_with_http_info(discount_coupon_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists DiscountCoupons Return a list of DiscountCoupons", "response": "def list_all_discount_coupons(cls, **kwargs):\n        \"\"\"List DiscountCoupons\n\n        Return a list of DiscountCoupons\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_discount_coupons(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[DiscountCoupon]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_discount_coupons_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_discount_coupons_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_discount_coupon_by_id(cls, discount_coupon_id, discount_coupon, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_discount_coupon_by_id_with_http_info(discount_coupon_id, discount_coupon, **kwargs)\n        else:\n            (data) = cls._replace_discount_coupon_by_id_with_http_info(discount_coupon_id, discount_coupon, **kwargs)\n            return data", "response": "Replace all attributes of discountCoupon with the given ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating attributes of a discountcoupon by ID", "response": "def update_discount_coupon_by_id(cls, discount_coupon_id, discount_coupon, **kwargs):\n        \"\"\"Update DiscountCoupon\n\n        Update attributes of DiscountCoupon\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_discount_coupon_by_id(discount_coupon_id, discount_coupon, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str discount_coupon_id: ID of discountCoupon to update. (required)\n        :param DiscountCoupon discount_coupon: Attributes of discountCoupon to update. (required)\n        :return: DiscountCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_discount_coupon_by_id_with_http_info(discount_coupon_id, discount_coupon, **kwargs)\n        else:\n            (data) = cls._update_discount_coupon_by_id_with_http_info(discount_coupon_id, discount_coupon, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_queryset(self):\n        qs = super(FilterFormMixin, self).get_queryset()\n        filter_form = self.get_filter()\n        if filter_form.is_valid():\n            qs = filter_form.filter(qs).distinct()\n        return qs", "response": "Returns queryset with filtering applied if filter form passes\n            validation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_context_data(self, **kwargs):\n        context = super(FilterFormMixin, self).get_context_data(**kwargs)\n        context[self.context_filterform_name] = self.get_filter()\n        return context", "response": "Add filter form to the context."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nassemble steps from dao expression to python code", "response": "def compile_to_python(exp, env, done=None): \r\n  '''assemble steps from dao expression to python code'''\r\n  original_exp = exp\r\n  compiler = Compiler()\r\n  if done is None:\r\n    done = il.Done(compiler.new_var(il.ConstLocalVar('v')))\r\n  compiler.exit_block_cont_map = {}\r\n  compiler.continue_block_cont_map = {}\r\n  compiler.protect_cont = done\r\n  if env is None: env = Environment()\r\n  exp = element(exp)\r\n  exp = exp.alpha(env, compiler)\r\n  exp = exp.cps(compiler, done)\r\n  exp.analyse(compiler)\r\n  env = Environment()\r\n  exp = exp.optimize(env, compiler)\r\n  #exp = exp.tail_recursive_convert()\r\n  function = compiler.new_var(il.ConstLocalVar('compiled_dao_function'))\r\n  exp = il.Function(function, (), exp)\r\n  exp = il.begin(*exp.pythonize(env, compiler)[0])\r\n  if isinstance(exp, il.Begin):\r\n    exp = exp.statements[0]\r\n  exp.body = exp.body.replace_return_with_yield()\r\n  compiler = Compiler()\r\n  result = exp.to_code(compiler)\r\n  return prelude + result"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef last(pipe, items=1):\n    ''' this function simply returns the last item in an iterable '''\n    if items == 1:\n        tmp=None\n        for i in pipe:\n            tmp=i\n        return tmp\n    else:\n        return tuple(deque(pipe, maxlen=items))", "response": "this function simply returns the last item in an iterable"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints help to the given destination file object.", "response": "def print_help(filename, table, dest=sys.stdout):\n    \"\"\"\n    Print help to the given destination file object.\n    \"\"\"\n    cmds = '|'.join(sorted(table.keys()))\n    print >> dest, \"Syntax: %s %s [args]\" % (path.basename(filename), cmds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndispatches to a function based on the contents of args.", "response": "def dispatch(table, args):\n    \"\"\"\n    Dispatches to a function based on the contents of `args`.\n    \"\"\"\n    # No arguments: print help.\n    if len(args) == 1:\n        print_help(args[0], table)\n        sys.exit(0)\n\n    # Bad command or incorrect number of arguments: print help to stderr.\n    if args[1] not in table or len(args) != len(table[args[1]]) + 1:\n        print_help(args[0], table, dest=sys.stderr)\n        sys.exit(1)\n\n    # Cast all the arguments to fit their function's signature to ensure\n    # they're correct and to make them safe for consumption.\n    sig = table[args[1]]\n    try:\n        fixed_args = [type_(arg) for arg, type_ in zip(args[2:], sig[1:])]\n    except TypeError:\n        # If any are wrong, complain to stderr.\n        print_help(args[0], table, dest=sys.stderr)\n        sys.exit(1)\n\n    # Dispatch the call to the correct function.\n    sig[0](*fixed_args)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncompute the gexf representation of given BubbleTree and push it into given file.", "response": "def tree_to_file(tree:'BubbleTree', outfile:str):\n    \"\"\"Compute the gexf representation of given power graph,\n    and push it into given file.\"\"\"\n    with open(outfile, 'w') as fd:\n        fd.write(tree_to_gexf(tree))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncomputing the gexf representation of given bubble tree and push it into given file.", "response": "def tree_to_gexf(tree:'BubbleTree') -> str:\n    \"\"\"Compute the gexf representation of given power graph,\n    and push it into given file.\n\n    See https://gephi.org/gexf/format/index.html\n    for format doc.\n\n    \"\"\"\n    output_nodes, output_edges = '', ''\n\n    def build_node(node:str) -> str:\n        \"\"\"Yield strings describing given node, recursively\"\"\"\n        if tree.inclusions[node]:  # it's a powernode\n            yield '<node id=\"{}\" label=\"{}\">'.format(node, node)\n            yield '<nodes>'\n            for sub in tree.inclusions[node]:\n                yield from build_node(sub)\n            yield '</nodes>'\n            yield '</node>'\n        else:  # it's a regular node\n            yield '<node id=\"{}\" label=\"{}\"/>'.format(node, node)\n        return\n\n    # build full hierarchy from the roots\n    output_nodes += '\\n'.join('\\n'.join(build_node(root)) for root in tree.roots)\n\n    # # add the edges to the final graph\n    for idx, (source, targets) in enumerate(tree.edges.items()):\n        for target in targets:\n            if source <= target:  # edges dict is complete. This avoid multiple edges.\n                output_edges += '<edge id=\"{}\" source=\"{}\" target=\"{}\" />\\n'.format(idx, source, target)\n\n    return GEXF_TEMPLATE.format(\n        'directed' if tree.oriented else 'undirected',\n        output_nodes,\n        output_edges\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding all occurrences of substring sub in string s.", "response": "def find_all(s, sub, start=0, end=0, limit=-1, reverse=False):\n    \"\"\"\n    Find all indexes of sub in s.\n\n    :param s: the string to search\n    :param sub: the string to search for\n    :param start: the index in s at which to begin the search (same as in ''.find)\n    :param end: the index in s at which to stop searching (same as in ''.find)\n    :param limit: the maximum number of matches to find\n    :param reverse: if False search s forwards; otherwise search backwards\n\n    :return: all occurrences of substring sub in string s\n    \"\"\"\n\n    indexes = []\n\n    if not bool(s and sub):\n        return indexes\n\n    lstr = len(s)\n    if lstr <= start:\n        return indexes\n\n    lsub = len(sub)\n    if lstr < lsub:\n        return indexes\n\n    if limit == 0:\n        return indexes\n    elif limit < 0:\n        limit = lstr\n\n    end = min(end, lstr) or lstr\n    idx = s.rfind(sub, start, end) if reverse else s.find(sub, start, end)\n\n    while idx != -1:\n        indexes.append(idx)\n        if reverse:\n            idx = s.rfind(sub, start, idx - lstr)\n        else:\n            idx = s.find(sub, idx + lsub, end)\n\n        if len(indexes) >= limit:\n            break\n\n    return indexes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef splitany(s, sep=None, maxsplit=-1):\n\n    if s is None:\n        return []\n    elif not isinstance(s, STRING_TYPES):\n        raise TypeError('Cannot split a {t}: {s}'.format(s=s, t=type(s).__name__))\n    elif sep is None:\n        return s.split(sep, maxsplit)\n    elif not isinstance(sep, _split_sep_types):\n        raise TypeError('Cannot split on a {t}: {s}'.format(s=sep, t=type(sep).__name__))\n    else:\n        split_on_any_char = isinstance(sep, STRING_TYPES)\n\n        if split_on_any_char:\n            # Python 3 compliance: sync and wrap to prevent issues with Binary: b'a'[0] == 97\n            seps = [_sync_string_to(s, sep)]\n        elif all(isinstance(sub, STRING_TYPES) for sub in sep):\n            # Python 3 compliance: sync, but also sort keys by length to do largest matches first\n            seps = [_sync_string_to(s, sub) for sub in sep]\n        else:\n            invalid_seps = [sub for sub in sep if not isinstance(sep, STRING_TYPES)]\n            raise TypeError('Cannot split on the following: {s}'.format(s=invalid_seps))\n\n    if len(s) == 0 or len(seps) == 0 or maxsplit == 0:\n        return [s]\n    elif len(seps) == 1:\n        # Reduce to single char or list item\n        # Call split if sep like: 'a', ['a'], ['ab']\n        # Otherwise, split on any if sep like: 'ab'\n\n        seps = seps[0]\n        if not split_on_any_char or len(seps) == 1:\n            return s.split(seps, maxsplit)\n\n    as_text = isinstance(seps, _split_txt_types)\n    parts = []\n    start = 0\n    rest = None\n\n    try:\n        while maxsplit < 0 or maxsplit >= len(parts):\n            rest = s if start == 0 else rest[start:]\n\n            # Sort based on (index_in_sep, negative_len_of_sep) to do largest matches first\n            if as_text:\n                stop = min((rest.index(sub), 0 - len(sub)) for sub in seps if sub in rest)\n            else:\n                # Python 3 compliance: iterating over bytes results in ints\n                stop = min((rest.index(sub), 0 - len(bytes([sub]))) for sub in seps if sub in rest)\n\n            parts.append(rest if maxsplit == len(parts) else rest[:stop[0]])\n            start = stop[0] - stop[1]  # Skip full index of last delim\n\n    except ValueError:\n        parts.append(rest)\n\n    return parts", "response": "Splits a string into a list of substrings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sync_string_to(bin_or_str, string):\n\n    if isinstance(string, type(bin_or_str)):\n        return string\n    elif isinstance(string, binary_type):\n        return string.decode(DEFAULT_ENCODING)\n    else:\n        return string.encode(DEFAULT_ENCODING)", "response": "Syncs a string to a binary or string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert any non - ASCII characters to their best - fit ASCII equivalents.", "response": "def to_ascii_equivalent(text):\n    \"\"\" Converts any non-ASCII characters (accents, etc.) to their best-fit ASCII equivalents \"\"\"\n\n    if text is None:\n        return None\n    elif isinstance(text, binary_type):\n        text = text.decode(DEFAULT_ENCODING)\n    elif not isinstance(text, text_type):\n        text = text_type(text)\n\n    text = EMPTY_STR.join(_ASCII_PUNCTUATION_MAP.get(c, c) for c in text)\n    return EMPTY_STR.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalidate rule. Valid rule must inherit from Rule and have valid syntax. :param rule: Rule to validate. :raise NotRuleException: If the parameter doesn't inherit from Rule.", "response": "def _validate_rule(self, rule):\n        # type: (Type[Rule]) -> None\n        \"\"\"\n        Validate rule. Valid rule must inherit from Rule and have valid syntax.\n        :param rule: Rule to validate.\n        :raise NotRuleException: If the parameter doesn't inherit from Rule.\n        \"\"\"\n        if not inspect.isclass(rule) or not issubclass(rule, Rule):\n            raise NotRuleException(rule)\n        rule.validate(self._grammar)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsplits a rule into multiple rules into separate classes each with only one rule defined.", "response": "def _split_rules(self, original_rule):\n        # type: (Type[Rule]) -> Iterable[Type[Rule]]\n        \"\"\"\n        Splits Rule class with multiple rules into separate classes, each with only one rule defined.\n        The created rules inherits from SplitRule.\n        If parameter define only one rule, its not split.\n        :param original_rule: Rule to split.\n        :return: Iterable of rules derived from the parameter.\n        \"\"\"\n        if original_rule.count == 1:\n            return [original_rule]\n\n        def yielding(original_rule):\n            for rule_index in range(original_rule.count):\n                yield SplitRule._create_class(original_rule, rule_index)\n\n        return yielding(original_rule)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds rules into the set.", "response": "def _add(self, *rules):\n        # type: (Iterable[Type[Rule]]) -> Generator[Type[Rule]]\n        \"\"\"\n        Add rules into the set. Each rule is validated and split if needed.\n        The method add the rules into dictionary, so the rule can be deleted with terminals or nonterminals.\n        :param rules: Rules to insert.\n        :return: Inserted rules.\n        :raise NotRuleException: If the parameter doesn't inherit from Rule.\n        :raise RuleException: If the syntax of the rule is invalid.\n        \"\"\"\n        for rule in rules:\n            if rule in self:\n                continue\n            self._validate_rule(rule)\n        for rule in rules:\n            for r in self._split_rules(rule):\n                for side in r.rule:\n                    for s in side:\n                        self._assign_map[s].add(r)\n                super().add(r)\n                yield r"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove(self, *rules, _validate=True):\n        # type: (Iterable[Type[Rule]], bool) -> None\n        \"\"\"\n        Remove rules from the set.\n        :param rules: Rules to remove.\n        :param _validate: True if the rule should be validated before deleting.\n        This parameter is only for internal use.\n        :raise NotRuleException: If the parameter doesn't inherit from Rule.\n        :raise RuleException: If the syntax of the rule is invalid.\n        :raise KeyError: If the rule is not in the grammar.\n        \"\"\"\n        all_rules = set()\n        for rule in rules:\n            if _validate:\n                self._validate_rule(rule)\n            for r in self._split_rules(rule):\n                if not self.__contains__(rule, _validate=False):\n                    raise KeyError('Rule ' + rule.__name__ + ' is not inside')\n                all_rules.add(r)\n        for rule in all_rules:\n            for side in rule.rule:\n                for s in side:\n                    self._assign_map[s].discard(rule)\n            super().remove(rule)", "response": "Removes the given set of rules from the set."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the rules representing parameters.", "response": "def _get(self, *rules):\n        # type: (Iterable[Type[Rule]]) -> Generator[Type[Rule]]\n        \"\"\"\n        Get rules representing parameters.\n        The return rules can be different from parameters, in case parameter define multiple rules in one class.\n        :param rules: For which rules get the representation.\n        :return: List of rules representing parameters.\n        :raise NotRuleException: If the parameter doesn't inherit from Rule.\n        :raise RuleException: If the syntax of the rule is invalid.\n        \"\"\"\n        for rule in rules:\n            if not inspect.isclass(rule) or not issubclass(rule, Rule):\n                raise NotRuleException(rule)\n            for r in self._split_rules(rule):\n                yield self._find_rule(r)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntrying to retrieve a sub - structure within some data within some path. Returns None if the path does not match any sub - structure.", "response": "def get_substructure(data, path):\n    \"\"\"\n    Tries to retrieve a sub-structure within some data. If the path does not\n    match any sub-structure, returns None.\n\n    >>> data = {'a': 5, 'b': {'c': [1, 2, [{'f': [57]}], 4], 'd': 'test'}}\n    >>> get_substructure(island, \"bc\")\n    [1, 2, [{'f': [57]}], 4]\n    >>> get_substructure(island, ['b', 'c'])\n    [1, 2, [{'f': [57]}], 4]\n    >>> get_substructure(island, ['b', 'c', 2, 0, 'f', 0])\n    57\n    >>> get_substructure(island, ['b', 'c', 2, 0, 'f', 'd'])\n    None\n\n    @param data: a container\n    @type data: str|dict|list|(an indexable container)\n\n    @param path: location of the data\n    @type path: list|str\n\n    @rtype: *\n    \"\"\"\n\n    if not len(path):\n        return data\n\n    try:\n        return get_substructure(data[path[0]], path[1:])\n    except (TypeError, IndexError, KeyError):\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn true if the given argument is iterable", "response": "def iterable(target):\n    ''' returns true if the given argument is iterable '''\n    if any(i in ('next', '__next__', '__iter__') for i in dir(target)):\n        return True\n    else:\n        try:\n            iter(target)\n            return True\n        except:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprocesses callbacks from the queue populated by &listen.", "response": "def _thread_worker(self):\n        \"\"\"Process callbacks from the queue populated by &listen.\"\"\"\n        while self._running:\n            # Retrieve next cmd, or block\n            packet = self._queue.get(True)\n            if isinstance(packet, dict) and QS_CMD in packet:\n                try:\n                    self._callback_listen(packet)\n                except Exception as err:  # pylint: disable=broad-except\n                    _LOGGER.error(\"Exception in callback\\nType: %s: %s\",\n                                  type(err), err)\n            self._queue.task_done()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef version(self):\n        # requests.get destroys the ?\n        import urllib\n        with urllib.request.urlopen(URL_VERSION.format(self._url)) as response:\n            return response.read().decode('utf-8')\n        return False", "response": "Get the QS Mobile version."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef listen(self, callback=None, timeout=(5, 300)):\n        if self._running:\n            return False\n        # if self.devices() is False:\n        #    return False\n        self._queue = Queue()\n        self._running = True\n        self._timeout = timeout\n        self._callback_listen = callback\n        threading.Thread(target=self._thread_listen, args=()).start()\n        threading.Thread(target=self._thread_worker, args=()).start()\n        return True", "response": "Start the &listen long poll and return immediately."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _callback_set_qs_value(self, key, val, success):\n        set_url = URL_SET.format(self._url, key, val)\n        with self._lock:\n            for _repeat in range(1, 6):\n                set_result = requests.get(set_url)\n                if set_result.status_code == 200:\n                    set_result = set_result.json()\n                    if set_result.get('data', 'NO REPLY') != 'NO REPLY':\n                        # self.devices._set_qs_value(key, set_result['data'])\n                        success()\n                        return True\n                sleep(0.01 * _repeat)\n        _LOGGER.error(\"Unable to set %s\", set_url)\n        return False", "response": "Push state to QSUSB retry with backoff."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving a list of &devices and values.", "response": "def update_from_devices(self):\n        \"\"\"Retrieve a list of &devices and values.\"\"\"\n        # _LOGGER.warning(\"update from devices\")\n        try:\n            rest = requests.get(URL_DEVICES.format(self._url))\n            if rest.status_code != 200:\n                _LOGGER.error(\"Devices returned %s\", rest.status_code)\n                return False\n            self.devices.update_devices(rest.json())\n            return True\n        except requests.exceptions.ConnectionError as conn_err:\n            _LOGGER.error(\"Could not connect: %s\", conn_err)\n        except Exception as err:  # pylint: disable=broad-except\n            _LOGGER.error(err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef color_to_tuple(color, opacity=1):\n    if(type(color) == str and color[0] == \"#\"):\n        color = hex_color_to_tuple(color)\n\n    elif type(color) == str:\n        if color in color_dict:\n            color = color_dict[color.lower()]\n        else:\n            print(\"\u65e0\u6cd5\u89e3\u6790\u989c\u8272:\" + color)\n            color = (255, 125, 0, int(255*opacity)) \n\n    while len(color) < 4:\n        color += (int(255*opacity),)\n\n    return color", "response": "convert any color to standard tuple"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef hsla_to_rgba(h, s, l, a):\n    h = h % 360\n    s = max(0, min(1, s))\n    l = max(0, min(1, l))\n    a = max(0, min(1, a))\n\n    c = (1 - abs(2*l - 1)) * s\n    x = c * (1 - abs(h/60%2 - 1))\n    m = l - c/2\n\n    if h<60:\n        r, g, b = c, x, 0\n    elif h<120:\n        r, g, b = x, c, 0\n    elif h<180:\n        r, g, b = 0, c, x\n    elif h<240:\n        r, g, b = 0, x, c\n    elif h<300:\n        r, g, b = x, 0, c\n    else:\n        r, g, b = c, 0, x\n\n\n    return (int((r+m)*255), int((g+m)*255), int((b+m)*255), int(a*255))", "response": "Convert from HSL color to RGBA color."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dir_freq(directory):\n    '''Returns a list of tuples of (word,# of directories it occurs)'''\n    content = dir_list(directory)\n    i = 0\n    freqdict = {}\n    for filename in content:\n        filewords = eliminate_repeats(read_file(directory + '/' + filename))\n        for word in filewords:\n            if freqdict.has_key(word):\n                freqdict[word] += 1\n            else:\n                freqdict[word] = 1\n    tupleize = []\n    for key in freqdict.keys():\n        wordtuple = (key,freqdict[key])\n        tupleize.append(wordtuple)\n    return tupleize", "response": "Returns a list of tuples of ( word count of directories it occurs )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dir_list(directory):\n    '''Returns the list of all files in the directory.'''\n    try:\n        content = listdir(directory)\n        return content\n    except WindowsError as winErr:\n        print(\"Directory error: \" + str((winErr)))", "response": "Returns the list of all files in the directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_dir(directory):\n    '''Returns the text of all files in a directory.'''\n    content = dir_list(directory)\n    text = ''\n    for filename in content:\n        text += read_file(directory + '/' + filename)\n        text += ' '\n    return text", "response": "Returns the text of all files in a directory."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef assign_colors(dir_counts):\n    '''Defines the color of a word in the cloud.\n    Counts is a list of tuples in the form (word,occurences)\n    The more files a word occurs in, the more red it appears in the cloud.'''\n    frequencies = map(lambda x: x[1],dir_counts)\n    words = map(lambda x: x[0],dir_counts)\n    maxoccur = max(frequencies)\n    minoccur = min(frequencies)\n    colors = map(lambda x: colorize(x,maxoccur,minoccur),frequencies)\n    color_dict = dict(zip(words,colors))\n    return color_dict", "response": "Defines the color of a word in the cloud."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assign_fonts(counts,maxsize,minsize,exclude_words):\n    '''Defines the font size of a word in the cloud.\n    Counts is a list of tuples in the form (word,count)'''\n    valid_counts = []\n    if exclude_words:\n        for i in counts:\n            if i[1] != 1:\n                valid_counts.append(i)\n    else:\n        valid_counts = counts\n    frequencies = map(lambda x: x[1],valid_counts)\n    words = map(lambda x: x[0],valid_counts)\n    maxcount = max(frequencies)\n    font_sizes = map(lambda x:fontsize(x,maxsize,minsize,maxcount),frequencies)\n    size_dict = dict(zip(words, font_sizes))\n    return size_dict", "response": "Defines the font size of a word in the cloud."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching the elastic database for the related items.", "response": "def search(self, query, index='default', **kwargs):\n        \"\"\"\n        kwargs supported are the parameters listed at:\n            http://www.elasticsearch.org/guide/reference/api/search/request-body/\n        Namely: timeout, from, size and search_type.\n        IMPORTANT: prepend ALL keys with \"es_\" as pyelasticsearch requires this\n        \"\"\"\n        # Looking up the index\n        if index not in self.conf.indexes:\n            self.raise_improperly_configured(index=index)\n\n        # Calling the backend search method\n        esurl = self.conf.connections[index]['URL']\n        esinst = pyelasticsearch.ElasticSearch(esurl)\n\n        query = isinstance(query, Query) and str(query) or query\n        self.raw_results = esinst.search(query, index=index, **kwargs)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend command to the NIC.", "response": "def _command(self, commands):\n        \"\"\"!\n        \\~english\n        Send command to ssd1306, DC pin need set to LOW\n        @param commands: an byte or array of bytes\n\n        \\~chinese \n        \u53d1\u9001\u547d\u4ee4\u7ed9 SSD1306\uff0cDC \u9700\u8981\u8bbe\u5b9a\u4e3a\u4f4e\u7535\u5e73 LOW\n        @param commands: \u4e00\u4e2a\u5b57\u8282\u6216\u5b57\u8282\u6570\u7ec4\n        \"\"\"\n        if self._spi == None: raise \"Do not setting SPI\"\n        GPIO.output( self._spi_dc, 0 )\n        self._spi.writebytes( commands )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending data to the chip of data.", "response": "def _data(self, data):\n        \"\"\"!\n        \\~english\n        Send data to ssd1306, DC pin need set to HIGH\n        @param data: sent to display chip of data. it can be an byte or array of bytes\n\n        \\~chinese\n        \u53d1\u9001\u6570\u636e\u7ed9 SSD1306, DC \u9700\u8981\u8bbe\u5b9a\u4e3a\u9ad8\u7535\u5e73 HIGH\n        @param data: \u9001\u5230\u663e\u793a\u82af\u7247\u7684\u6570\u636e\u3002 \u53ef\u4ee5\u662f\u4e00\u4e2a\u5b57\u8282\u6216\u5b57\u8282\u6570\u7ec4\n        \"\"\"\n        if self._spi == None: raise \"Do not setting SPI\"\n        GPIO.output( self._spi_dc, 1 )\n        self._spi.writebytes( data )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _display_buffer(self, buffer ):\n        self._command([\n            self.CMD_SSD1306_SET_COLUMN_ADDR,\n            0, self.width-1,\n            self.CMD_SSD1306_SET_PAGE_ADDR,\n            0, self._mem_pages - 1\n            ])\n        self._data( buffer )", "response": "!\n        \\~english\n        Send buffer data to physical display.\n        @param buffer: sent to display chip of data.\n\n        \\~chinese\n        \u5c06\u7f13\u51b2\u533a\u6570\u636e\u53d1\u9001\u5230\u7269\u7406\u663e\u793a\u3002\n        @param buffer: \u9001\u5230\u663e\u793a\u82af\u7247\u7684\u6570\u636e\u3002"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_display(self):\n        self._command([\n            # 0xAE\n            self.CMD_SSD1306_DISPLAY_OFF,\n            #Stop Scroll\n            self.CMD_SSD1306_SET_SCROLL_DEACTIVE,\n            # 0xA8 SET MULTIPLEX 0x3F\n            self.CMD_SSD1306_SET_MULTIPLEX_RATIO,\n            0x3F,\n            # 0xD3 SET DISPLAY OFFSET\n            self.CMD_SSD1306_SET_DISPLAY_OFFSET,\n            0x00,\n            # 0x40 Set Mapping RAM Display Start Line  (0x00~0x3F)\n            self.CMD_SSD1306_SET_DISPLAY_START_LINE,\n            # 0xDA Set COM Pins hardware configuration, (0x00/0x01/0x02)\n            self.CMD_SSD1306_SET_COM_PINS,\n            (0x02 | 0x10),\n            self.CMD_SSD1306_SET_CONTRAST,\n            0x7F,\n            # 0xA4 Disable Entire Display On\n            self.CMD_SSD1306_ENTIRE_DISPLAY_ON_0,\n            # 0xA6 Set normal display\n            self.CMD_SSD1306_NORMAL_DISPLAY,\n            # 0xA7 Set inverse display\n            # CMD_SSD1306_INVERSE_DISPLAY, \n            # 0xD5 Set osc frequency 0x80\n            self.CMD_SSD1306_SET_CLOCK_DIVIDE_RATIO,\n            0x80,\n            # 0x8D Enable DC/DC charge pump regulator 0x14\n            self.CMD_SSD1306_CHARGE_PUMP,\n            0x14,\n            # 0x20 Set Page Addressing Mode (0x00/0x01/0x02)\n            self.CMD_SSD1306_SET_MEM_ADDR_MODE,\n            0x01,\n  \n            # 0xC0 / 0xC8 Set COM Output Scan Direction\n            #CMD_SSD1306_SCAN_DIRECTION_INC,\n            #CMD_SSD1306_SCAN_DIRECTION_DEC,\n            self.CMD_SSD1306_SCAN_DIRECTION_INC if self._mirror_v else self.CMD_SSD1306_SCAN_DIRECTION_DEC,\n  \n            # 0xA0 / oxA1 Set Segment re-map\n            # 0xA0    left to right\n            # 0xA1    right to left\n            self.CMD_SSD1306_SET_SEGMENT_REMAP_0 if self._mirror_h else self.CMD_SSD1306_SET_SEGMENT_REMAP_1,\n        ])", "response": "Initialize the SSD1306 display."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nclear the buffer data and fill it with fill.", "response": "def clear(self, fill = 0x00):\n        \"\"\"!\n        \\~english\n        Clear buffer data and fill color into buffer\n        @param fill: a color value, it will fill into buffer.<br>\n                The SSD1306 only chosen two colors: <br>\n                   0 (0x0): black <br>\n                   1 (0x1): white <br>\n\n        \\~chinese\n        \u6e05\u9664\u7f13\u51b2\u533a\u6570\u636e\u5e76\u5728\u7f13\u51b2\u533a\u4e2d\u586b\u5145\u989c\u8272\n        @param fill: \u4e00\u4e2a\u989c\u8272\u503c\uff0c\u5b83\u4f1a\u586b\u5145\u5230\u7f13\u51b2\u533a\u4e2d <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 SSD1306\u53ea\u80fd\u9009\u62e9\u4e24\u79cd\u989c\u8272\uff1a <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\uff080x0\uff09\uff1a\u9ed1\u8272 <br>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1\uff080x1\uff09\uff1a\u767d\u8272 <br>\n        \"\"\"\n        self._buffer = [ fill ] * ( self.width * self._mem_pages )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset(self):\n        if self._spi_reset == None: return\n        GPIO.output( self._spi_reset, 1 )\n        time.sleep(0.002)\n        GPIO.output( self._spi_reset, 0 )\n        time.sleep(0.015)\n        GPIO.output( self._spi_reset, 1 )", "response": "!\n        \\~english Reset display\n        \\~chinese \u590d\u4f4d\u663e\u793a\u5c4f"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef display(self, buffer = None):\n        if buffer != None:\n            self._display_buffer( buffer )\n        else:\n            self._display_buffer( self._buffer )", "response": "Write buffer to physical display."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert an image to the buffer.", "response": "def setImage(self, image):\n        \"\"\"!\n        \\~english\n        Convert image to the buffer, The image mode must be 1 and image size \n        equal to the display size image type is Python Imaging Library image.\n        @param image: a PIL image object\n\n        \\~chinese\n        \u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u7f13\u51b2\u533a\uff0c\u8fd9\u4e2a\u56fe\u50cf\u7684\u8272\u5f69\u6a21\u5f0f\u5fc5\u987b\u4e3a 1 \u540c\u65f6\u56fe\u50cf\u5927\u5c0f\u5fc5\u987b\u7b49\u4e8e\u663e\u5b58\u5927\u5c0f\uff0c\n        \u56fe\u50cf\u7c7b\u578b\uff1a PIL Image (Python Imaging Library)\n        @param image: PIL\u56fe\u50cf\u5bf9\u8c61\n\n        \\n \\~\n        @note\n        <pre>\n        ssd1306.setImage( aPILImage )\n        ssd1306.display()\n        </pre>\n        \"\"\"\n        if image.mode != '1':\n            raise ValueError('The image color must be in mode \\\"1\\\".')\n\n        imgWidth, imgHeight = image.size\n        if imgWidth != self.width or imgHeight != self.height:\n            raise ValueError('The image must be same dimensions as display ( {0} x {1} ).' \\\n                .format(self.width, self.height))\n\n        # First then shift left \n        pixByte = [0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80]\n        bi = 0\n        pixs = image.load()\n        for x in range( 0, self.width ):\n            for y in range( 0, self.height, 8 ):\n                pixBits = 0x00\n                # first then range(8)\n                for py in [0,1,2,3,4,5,6,7]:\n                    pixBits |= (0x00 if pixs[x, y+py] == 0 else pixByte[py])\n                self._buffer[bi] = pixBits\n                bi += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscroll the screen with the specified parameters.", "response": "def scrollWith(self, hStart = 0x00, hEnd=0x00, vOffset = 0x00, vStart=0x00, vEnd=0x00, int = 0x00, dire = \"left\" ):\n        \"\"\"!\n        \\~english \n        Scroll screen\n        @param hStart: Set horizontal scroll PAGE start address, value can be chosen between 0 and 7\n        @param hEnd:  Set horizontal scroll PAGE end address, value can be chose between 0 and 7\n        @param vOffset: Vertical scroll offset row, if set to 0x00(0) means off vertical scroll\n        @param vStart: Vertical scroll start line, value can be chose between 0x00 and screen.height\n        @param vEnd: Vertical scroll end line, value can be chose between 0x00 and screen.height\n        @param int: Set time interval between each scroll step\n        @param dire: Set scroll direction, value can be \"left\" or \"right\"\n        \n        \\~chinese\n        \u5c4f\u5e55\u6eda\u52a8\n        @param hStart: \u8bbe\u7f6e\u6c34\u5e73\u6eda\u52a8PAGE\u8d77\u59cb\u5730\u5740\uff0c\u6570\u503c\u53ef\u4ee5\u57280\u52307\u4e4b\u95f4\u9009\u62e9\n        @param hEnd:  \u8bbe\u7f6e\u6c34\u5e73\u6eda\u52a8PAGE\u7ed3\u675f\u5730\u5740\uff0c\u503c\u53ef\u4ee5\u57280\u548c7\u4e4b\u95f4\u9009\u62e9\n        @param vOffset: \u5782\u76f4\u6eda\u52a8\u504f\u79fb\u884c\uff0c\u5982\u679c\u8bbe\u7f6e\u4e3a0x00\uff080\uff09\uff0c\u8868\u793a\u5173\u95ed\u5782\u76f4\u6eda\u52a8\n        @param vStart: \u5782\u76f4\u6eda\u52a8\u8d77\u59cb\u884c\uff0c\u503c\u53ef\u4ee5\u57280x00\u548cscreen.height\u4e4b\u95f4\u9009\u62e9\n        @param vEnd: \u5782\u76f4\u6eda\u52a8\u7ed3\u675f\u884c\uff0c\u503c\u53ef\u4ee5\u57280x00\u548cscreen.height\u4e4b\u95f4\u9009\u62e9\n        @param int: \u8bbe\u7f6e\u6bcf\u4e2a\u6eda\u52a8\u6b65\u9aa4\u4e4b\u95f4\u7684\u65f6\u95f4\u95f4\u9694\n        @param dire: \u8bbe\u7f6e\u6eda\u52a8\u65b9\u5411\uff0c\u6570\u503c\u53ef\u4ee5\u662f \"left\" \u6216 \"right\"\n        \"\"\"\n        self._command( [self.CMD_SSD1306_SET_SCROLL_DEACTIVE] )\n        if vOffset != 0:\n            self._command( [\n                    self.CMD_SSD1306_SET_SCROLL_VERTICAL_AREA,\n                    vStart,\n                    vEnd,\n                    0x00\n                ])\n\n        self._command( [\n            self.CMD_SSD1306_SET_SCROLL_HORIZONTAL_VERTICAL_LEFT if dire.upper()==\"LEFT\" else self.CMD_SSD1306_SET_SCROLL_HORIZONTAL_VERTICAL_RIGHT,\n            0x00, \n            hStart, \n            int, \n            hEnd, \n            vOffset, \n            0x00,\n            self.CMD_SSD1306_SET_SCROLL_ACTIVE\n            ])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self, schedule_id, auth_token, endpoint, payload, **kwargs):\n        log = self.get_logger(**kwargs)\n        log.info(\"Running instance of <%s>\" % (schedule_id,))\n        if self.request.retries > 0:\n            retry_delay = utils.calculate_retry_delay(self.request.retries)\n        else:\n            retry_delay = self.default_retry_delay\n\n        headers = {\"Content-Type\": \"application/json\"}\n        if auth_token is not None:\n            headers[\"Authorization\"] = \"Token %s\" % auth_token\n        try:\n            response = requests.post(\n                url=endpoint,\n                data=json.dumps(payload),\n                headers=headers,\n                timeout=settings.DEFAULT_REQUEST_TIMEOUT,\n            )\n            # Expecting a 201, raise for errors.\n            response.raise_for_status()\n        except requests_exceptions.ConnectionError as exc:\n            log.info(\"Connection Error to endpoint: %s\" % endpoint)\n            fire_metric.delay(\"scheduler.deliver_task.connection_error.sum\", 1)\n            self.retry(exc=exc, countdown=retry_delay)\n        except requests_exceptions.HTTPError as exc:\n            # Recoverable HTTP errors: 500, 401\n            log.info(\"Request failed due to status: %s\" % exc.response.status_code)\n            metric_name = (\n                \"scheduler.deliver_task.http_error.%s.sum\" % exc.response.status_code\n            )\n            fire_metric.delay(metric_name, 1)\n            self.retry(exc=exc, countdown=retry_delay)\n        except requests_exceptions.Timeout as exc:\n            log.info(\"Request failed due to timeout\")\n            fire_metric.delay(\"scheduler.deliver_task.timeout.sum\", 1)\n            self.retry(exc=exc, countdown=retry_delay)\n\n        return True", "response": "Runs an instance of a scheduled task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, schedule_type, lookup_id, **kwargs):\n        log = self.get_logger(**kwargs)\n        log.info(\"Queuing <%s> <%s>\" % (schedule_type, lookup_id))\n\n        task_run = QueueTaskRun()\n        task_run.task_id = self.request.id or uuid4()\n        task_run.started_at = now()\n        tr_qs = QueueTaskRun.objects\n\n        # Load the schedule active items\n        schedules = Schedule.objects.filter(enabled=True)\n        if schedule_type == \"crontab\":\n            schedules = schedules.filter(celery_cron_definition=lookup_id)\n            tr_qs = tr_qs.filter(celery_cron_definition=lookup_id)\n            scheduler_type = CrontabSchedule\n            task_run.celery_cron_definition_id = lookup_id\n        elif schedule_type == \"interval\":\n            schedules = schedules.filter(celery_interval_definition=lookup_id)\n            tr_qs = tr_qs.filter(celery_interval_definition=lookup_id)\n            scheduler_type = IntervalSchedule\n            task_run.celery_interval_definition_id = lookup_id\n\n        # Confirm that this task should run now based on last run time.\n        try:\n            last_task_run = tr_qs.latest(\"started_at\")\n        except QueueTaskRun.DoesNotExist:\n            # No previous run so it is safe to continue.\n            pass\n        else:\n            # This basicly replicates what celery beat is meant to do, but\n            # we can't trust celery beat and django-celery to always accurately\n            # update their own last run time.\n            sched = scheduler_type.objects.get(id=lookup_id)\n            due, due_next = sched.schedule.is_due(last_task_run.started_at)\n            if not due and due_next >= settings.DEFAULT_CLOCK_SKEW_SECONDS:\n                return (\n                    \"Aborted Queuing <%s> <%s> due to last task run (%s) \"\n                    \"at %s\"\n                    % (\n                        schedule_type,\n                        lookup_id,\n                        last_task_run.id,\n                        last_task_run.started_at,\n                    )\n                )\n\n        task_run.save()\n        # create tasks for each active schedule\n        queued = 0\n        schedules = schedules.values(\"id\", \"auth_token\", \"endpoint\", \"payload\")\n        for schedule in schedules.iterator():\n            schedule[\"schedule_id\"] = str(schedule.pop(\"id\"))\n            DeliverTask.apply_async(kwargs=schedule)\n            queued += 1\n\n        task_run.completed_at = now()\n        task_run.save()\n        return \"Queued <%s> Tasks\" % (queued,)", "response": "Runs the given schedule"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns an instance of a scheduled task", "response": "def run(self, **kwargs):\n        \"\"\"\n        Runs an instance of a scheduled task\n        \"\"\"\n        log = self.get_logger(**kwargs)\n        failures = ScheduleFailure.objects\n        log.info(\"Attempting to requeue <%s> failed schedules\" % failures.count())\n        for failure in failures.iterator():\n            schedule = Schedule.objects.values(\n                \"id\", \"auth_token\", \"endpoint\", \"payload\"\n            )\n            schedule = schedule.get(id=failure.schedule_id)\n            schedule[\"schedule_id\"] = str(schedule.pop(\"id\"))\n            # Cleanup the failure before requeueing it.\n            failure.delete()\n            DeliverTask.apply_async(kwargs=schedule)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the current time and date in MySQL format", "response": "def get_now_sql_datetime():\n    \"\"\"\n    *A datetime stamp in MySQL format: ``YYYY-MM-DDTHH:MM:SS``*\n\n    **Return:**\n        - ``now`` -- current time and date in MySQL format\n\n    **Usage:**\n        .. code-block:: python \n\n            from fundamentals import times\n            now = times.get_now_sql_datetime()\n            print now\n\n            # OUT: 2016-03-18T11:08:23 \n    \"\"\"\n    ## > IMPORTS ##\n    from datetime import datetime, date, time\n    now = datetime.now()\n    now = now.strftime(\"%Y-%m-%dT%H:%M:%S\")\n\n    return now"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calculate_time_difference(startDate, endDate):\n    ################ > IMPORTS ################\n    from datetime import datetime\n    from dateutil import relativedelta\n\n    ################ > VARIABLE SETTINGS ######\n\n    ################ >ACTION(S) ################\n    if \"T\" not in startDate:\n        startDate = startDate.strip().replace(\" \", \"T\")\n    if \"T\" not in endDate:\n        endDate = endDate.strip().replace(\" \", \"T\")\n    startDate = datetime.strptime(startDate, '%Y-%m-%dT%H:%M:%S')\n    endDate = datetime.strptime(endDate, '%Y-%m-%dT%H:%M:%S')\n    d = relativedelta.relativedelta(endDate, startDate)\n\n    relTime = \"\"\n    if d.years > 0:\n        relTime += str(d.years) + \"yrs \"\n    if d.months > 0:\n        relTime += str(d.months) + \"mths \"\n    if d.days > 0:\n        relTime += str(d.days) + \"dys \"\n    if d.hours > 0:\n        relTime += str(d.hours) + \"h \"\n    if d.minutes > 0:\n        relTime += str(d.minutes) + \"m \"\n    if d.seconds > 0:\n        relTime += str(d.seconds) + \"s\"\n    ###############################\n\n    if relTime == \"\":\n        relTime = \"0s\"\n\n    return relTime", "response": "Calculate the time difference between two dates"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef bind(renderer, to):\n\n    @wraps(to)\n    def view(request, **kwargs):\n        try:\n            returned = to(request, **kwargs)\n        except Exception as error:\n            view_error = getattr(renderer, \"view_error\", None)\n            if view_error is None:\n                raise\n            return view_error(request, error)\n\n        try:\n            return renderer.render(request, returned)\n        except Exception as error:\n            render_error = getattr(renderer, \"render_error\", None)\n            if render_error is None:\n                raise\n            return render_error(request, returned, error)\n\n    return view", "response": "Bind a renderer to a given callable by constructing a new rendering view."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_perm_model():\n    try:\n        return django_apps.get_model(settings.PERM_MODEL, require_ready=False)\n    except ValueError:\n        raise ImproperlyConfigured(\"PERM_MODEL must be of the form 'app_label.model_name'\")\n    except LookupError:\n        raise ImproperlyConfigured(\n            \"PERM_MODEL refers to model '{}' that has not been installed\".format(settings.PERM_MODEL)\n        )", "response": "Returns the Perm model that is active in this project."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a yaml config file.", "response": "def _load_yaml_config(cls, config_data, filename=\"(unknown)\"):\n        \"\"\"Load a yaml config file.\"\"\"\n\n        try:\n            config = yaml.safe_load(config_data)\n        except yaml.YAMLError as err:\n            if hasattr(err, 'problem_mark'):\n                mark = err.problem_mark\n                errmsg = (\"Invalid YAML syntax in Configuration file \"\n                          \"%(file)s at line: %(line)s, column: %(column)s.\"\n                          % dict(file=filename,\n                                 line=mark.line + 1,\n                                 column=mark.column + 1))\n            else:\n                errmsg = (\"YAML error reading Configuration file \"\n                          \"%(file)s\"\n                          % dict(file=filename))\n            logger.error(errmsg)\n            raise\n\n        logger.info(\"Configuration: %s\", config)\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new PaymentTransaction with the specified attributes.", "response": "def create_payment_transaction(cls, payment_transaction, **kwargs):\n        \"\"\"Create PaymentTransaction\n\n        Create a new PaymentTransaction\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_payment_transaction(payment_transaction, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param PaymentTransaction payment_transaction: Attributes of paymentTransaction to create (required)\n        :return: PaymentTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_payment_transaction_with_http_info(payment_transaction, **kwargs)\n        else:\n            (data) = cls._create_payment_transaction_with_http_info(payment_transaction, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndelete an instance of PaymentTransaction by its ID.", "response": "def delete_payment_transaction_by_id(cls, payment_transaction_id, **kwargs):\n        \"\"\"Delete PaymentTransaction\n\n        Delete an instance of PaymentTransaction by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_payment_transaction_by_id(payment_transaction_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str payment_transaction_id: ID of paymentTransaction to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_payment_transaction_by_id_with_http_info(payment_transaction_id, **kwargs)\n        else:\n            (data) = cls._delete_payment_transaction_by_id_with_http_info(payment_transaction_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind PaymentTransaction by ID Return single instance of PaymentTransaction by its ID.", "response": "def get_payment_transaction_by_id(cls, payment_transaction_id, **kwargs):\n        \"\"\"Find PaymentTransaction\n\n        Return single instance of PaymentTransaction by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_payment_transaction_by_id(payment_transaction_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str payment_transaction_id: ID of paymentTransaction to return (required)\n        :return: PaymentTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_payment_transaction_by_id_with_http_info(payment_transaction_id, **kwargs)\n        else:\n            (data) = cls._get_payment_transaction_by_id_with_http_info(payment_transaction_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_all_payment_transactions(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_payment_transactions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_payment_transactions_with_http_info(**kwargs)\n            return data", "response": "List PaymentTransactions\n        Return a list of PaymentTransactions\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreplaces PaymentTransaction by ID", "response": "def replace_payment_transaction_by_id(cls, payment_transaction_id, payment_transaction, **kwargs):\n        \"\"\"Replace PaymentTransaction\n\n        Replace all attributes of PaymentTransaction\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_payment_transaction_by_id(payment_transaction_id, payment_transaction, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str payment_transaction_id: ID of paymentTransaction to replace (required)\n        :param PaymentTransaction payment_transaction: Attributes of paymentTransaction to replace (required)\n        :return: PaymentTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_payment_transaction_by_id_with_http_info(payment_transaction_id, payment_transaction, **kwargs)\n        else:\n            (data) = cls._replace_payment_transaction_by_id_with_http_info(payment_transaction_id, payment_transaction, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_payment_transaction_by_id(cls, payment_transaction_id, payment_transaction, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_payment_transaction_by_id_with_http_info(payment_transaction_id, payment_transaction, **kwargs)\n        else:\n            (data) = cls._update_payment_transaction_by_id_with_http_info(payment_transaction_id, payment_transaction, **kwargs)\n            return data", "response": "Update attributes of PaymentTransaction by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nuses the input class to set the object as the current object.", "response": "def use(self, obj, parent_form=None):\n        \"\"\"Note: if title is None, will be replaced with obj.filename\n        \"\"\"\n\n        if not isinstance(obj, self.input_classes):\n            raise RuntimeError('{0!s} cannot handle a {1!s}'.format(self.__class__.__name__, obj.__class__.__name__))\n\n        self.parent_form = parent_form\n\n        if self.title is None:\n            self.title = 'file: '+obj.filename\n        self._do_use(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sround(x, precision=0):\n    sr = StochasticRound(precision=precision)\n    return sr.round(x)", "response": "Round a single number using default non - deterministic generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef round(self, x):\n        fraction, scaled_x, scale = self._get_fraction(x)\n\n        if fraction < self.minimum_stochastic_distance or 1-fraction <self.minimum_stochastic_distance:\n            result = round(x,self.precision)\n\n        else:\n            rounddown = fraction < self.random_generator.random()\n            if rounddown:\n                result = math.floor(scaled_x) / scale\n            else:\n                result = math.ceil(scaled_x) / scale\n\n        self._record_roundoff_error(x, result)\n        return result", "response": "Round the given value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef submit_mail(self, send_from, send_to, subject, body, unique_id=None):\n        self.__metadb.update(\"\"\"\n        INSERT INTO meta.mail(\"template\", \"from\", \"to\", \"subject\", \"body\", \"attachments\", \"unique_id\")\n        VALUES ('meta', :send_from, :send_to, :subject, :body, null, :unique_id)\n        ON CONFLICT (unique_id) DO NOTHING\n        \"\"\", {\n            \"send_from\": send_from,\n            \"send_to\": send_to,\n            \"subject\": subject,\n            \"body\": body,\n            \"unique_id\": unique_id\n        })", "response": "Submit a mail to the server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_chord_line(line):\n    ''' Parse a chord line into a `ChordLineData` object. '''\n    chords = [\n        TabChord(position=position, chord=chord)\n        for chord, position in Chord.extract_chordpos(line)\n    ]\n    return ChordLineData(chords=chords)", "response": "Parse a chord line into a ChordLineData object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_line_type(line):\n    ''' Decide the line type in function of its contents '''\n    stripped = line.strip()\n    if not stripped:\n        return 'empty'\n    remainder = re.sub(r\"\\s+\", \" \", re.sub(CHORD_RE, \"\", stripped))\n    if len(remainder) * 2 < len(re.sub(r\"\\s+\", \" \", stripped)):\n        return 'chord'\n    return 'lyric'", "response": "Decide the line type in function of its contents"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_line(line):\n    ''' Parse a line into a `TabLine` object. '''\n    line = line.rstrip()\n    line_type = _get_line_type(line)\n    return TabLine(\n        type=line_type,\n        data=_DATA_PARSERS[line_type](line),\n        original=line,\n    )", "response": "Parse a line into a TabLine object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing a list of lines into a Tablature.", "response": "def parse_tablature(lines):\n    ''' Parse a list of lines into a `Tablature`. '''\n    lines = [parse_line(l) for l in lines]\n    return Tablature(lines=lines)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef preview(df,preview_rows = 20):#,preview_max_cols = 0):\n    if preview_rows < 4:\n        preview_rows = 4\n    preview_rows = min(preview_rows,df.shape[0])\n    outer = math.floor(preview_rows / 4)\n    return pd.concat([df.head(outer),\n                      df[outer:-outer].sample(preview_rows-2*outer),\n                      df.tail(outer)])", "response": "Returns a dataframe which contains both header and tail rows and max_cols rows."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the. info output of a dataframe", "response": "def get_info(df, verbose = None,max_cols = None, memory_usage = None, null_counts = None):\n    \"\"\" Returns the .info() output of a dataframe\n    \"\"\"\n    assert type(df) is pd.DataFrame\n    buffer = io.StringIO()\n    df.info(verbose, buffer, max_cols, memory_usage, null_counts)\n    return buffer.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef title_line(text):\n    columns = shutil.get_terminal_size()[0]\n    start = columns // 2 - len(text) // 2\n    output = '='*columns + '\\n\\n' + \\\n            ' ' * start + str(text) + \"\\n\\n\" + \\\n            '='*columns + '\\n'\n    return output", "response": "Returns a string that represents the\n    text as a title blurb\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator for atmospheric wavefront perturbations across a set of telescopes.", "response": "def PhaseScreens(numTelescope,r0,pupilSize,screenSize=1024,numRealisation=-1):\n    \"\"\"Return a generator for atmospheric wavefront perturbations across\n    a set of *numTelescope* telescopes, each of size *pupilSize* and\n    with Fried parameter *r0*. The perturbations are modelled as being\n    uncorrelated between telescopes. The number of realisations is given\n    by *numRealisation*, but if *numRealisation* is negative then an \n    infinite sequence of realisations is generated.\n    \"\"\"\n    screenGenerators=[ScreenGenerator(screenSize,r0,pupilSize,pupilSize)\n                      for i in range(numTelescope)]\n    iter=0\n    while numRealisation<0 or iter<numRealisation:\n        iter+=1\n        yield np.array([next(screen) for screen in screenGenerators])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef RadiusGrid(gridSize):\n    x,y=np.mgrid[0:gridSize,0:gridSize]\n    x = x-(gridSize-1.0)/2.0\n    y = y-(gridSize-1.0)/2.0\n    return np.abs(x+1j*y)", "response": "Returns the radius of the grid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CircularMaskGrid(gridSize, diameter=None):\n    if diameter is None: diameter=gridSize\n    return np.less_equal(RadiusGrid(gridSize),diameter/2.0)", "response": "Return a square grid with ones inside and zeros outside a given \n    diameter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AdaptiveOpticsCorrect(pupils,diameter,maxRadial,numRemove=None):\n    gridSize=pupils.shape[-1]\n    pupilsVector=np.reshape(pupils,(-1,gridSize**2))\n    zernikes=np.reshape(ZernikeGrid(gridSize,maxRadial,diameter),(-1,gridSize**2))\n    if numRemove is None: numRemove=zernikes.shape[0]\n    numScreen=pupilsVector.shape[0]\n    normalisation=1.0/np.sum(zernikes[0])\n    # Note extra iteration to remove residual piston\n    for i in list(range(numRemove))+[0,]:\n        amplitudes=np.inner(zernikes[i],pupilsVector)*normalisation\n        pupilsVector=pupilsVector-zernikes[i]*amplitudes[:,np.newaxis]\n    return np.reshape(pupilsVector,pupils.shape)", "response": "Correct a wavefront using Zernike rejection up to some maximal order."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FibreMode(gridSize,modeDiameter):\n    rmode=modeDiameter/2\n    return np.exp(-(RadiusGrid(gridSize)/rmode)**2)/(np.sqrt(np.pi/2)*rmode)", "response": "Returns a pupil - plane Gaussian mode with 1 / e diameter given by \n    *modeDiameter * normalised so that integral power over the mode is unity\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef FibreCouple(pupils,modeDiameter):\n    gridSize=pupils.shape[-1]\n    pupilsVector=np.reshape(pupils,(-1,gridSize**2))\n    mode=np.reshape(FibreMode(gridSize,modeDiameter),(gridSize**2,))\n    return np.inner(pupilsVector,mode)", "response": "Return the complex amplitudes coupled into a set of fibers\n   "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncombine the coherent fluxes and photometric fluxes for a single - mode Fibre.", "response": "def SingleModeCombine(pupils,modeDiameter=None):\n    \"\"\"\n    Return the instantaneous coherent fluxes and photometric fluxes for a\n    multiway single-mode fibre combiner\n    \"\"\"\n    if modeDiameter is None:\n        modeDiameter=0.9*pupils.shape[-1]\n    amplitudes=FibreCouple(pupils,modeDiameter)\n    cc=np.conj(amplitudes)\n    fluxes=(amplitudes*cc).real\n    coherentFluxes=[amplitudes[i]*cc[j]\n                    for i in range(1,len(amplitudes))\n                    for j in range(i)]\n    return fluxes,coherentFluxes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncombining the coherent fluxes and photometric fluxes for a single - way multimode combiner.", "response": "def MultimodeCombine(pupils):\n    \"\"\"\n    Return the instantaneous coherent fluxes and photometric fluxes for a\n    multiway multimode combiner (no spatial filtering)\n    \"\"\"\n    fluxes=[np.vdot(pupils[i],pupils[i]).real for i in range(len(pupils))]\n    coherentFluxes=[np.vdot(pupils[i],pupils[j])\n                    for i in range(1,len(pupils))\n                    for j in range(i)]\n    return fluxes,coherentFluxes"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts unicode to unicode raise exception with instructive error message if s is not unicode ascii or utf - 8.", "response": "def to_unicode(s):\n    \"\"\" Convert to unicode, raise exception with instructive error\n    message if s is not unicode, ascii, or utf-8. \"\"\"\n    if not isinstance(s, TEXT):\n        if not isinstance(s, bytes):\n            raise TypeError('You are required to pass either unicode or '\n                            'bytes here, not: %r (%s)' % (type(s), s))\n        try:\n            s = s.decode('utf-8')\n        except UnicodeDecodeError as le:\n            raise TypeError('You are required to pass either a unicode '\n                            'object or a utf-8-encoded bytes string here. '\n                            'You passed a bytes object which contained '\n                            'non-utf-8: %r. The UnicodeDecodeError that '\n                            'resulted from attempting to interpret it as '\n                            'utf-8 was: %s'\n                            % (s, le,))\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_postdata(self):\n        items = []\n        for k, v in sorted(self.items()):  # predictable for testing\n            items.append((k.encode('utf-8'), to_utf8_optional_iterator(v)))\n\n        # tell urlencode to deal with sequence values and map them correctly\n        # to resulting querystring. for example self[\"k\"] = [\"v1\", \"v2\"] will\n        # result in 'k=v1&k=v2' and not k=%5B%27v1%27%2C+%27v2%27%5D\n        return urlencode(items, True).replace('+', '%20').encode('ascii')", "response": "Serialize as POST data for a POST request."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_url(self):\n        base_url = urlparse(self.url)\n\n        query = parse_qs(base_url.query)\n        for k, v in self.items():\n            query.setdefault(k, []).append(to_utf8_optional_iterator(v))\n        scheme = base_url.scheme\n        netloc = base_url.netloc\n        path = base_url.path\n        params = base_url.params\n        fragment = base_url.fragment\n\n        url = (scheme, netloc, path, params, urlencode(query, True), fragment)\n        return urlunparse(url)", "response": "Serialize as a URL for a GET request."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _split_header(header):\n        params = {}\n        parts = header.split(',')\n        for param in parts:\n            # Ignore realm parameter.\n            if param.lower().startswith('realm='):\n                continue\n            # Remove whitespace.\n            param = param.strip()\n            # Split key-value.\n            param_parts = param.split('=', 1)\n            # Remove quotes and unescape the value.\n            params[param_parts[0]] = unquote(param_parts[1].strip('\\\"'))\n        return params", "response": "Turn Authorization header into parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprocesses a request_token request and returns the request token on success.", "response": "def fetch_request_token(self, oauth_request):\n        \"\"\"Processes a request_token request and returns the\n        request token on success.\n        \"\"\"\n        try:\n            # Get the request token for authorization.\n            token = self._get_token(oauth_request, 'request')\n        except Error:\n            # No token required for the initial token request.\n            version = self._get_version(oauth_request)\n            consumer = self._get_consumer(oauth_request)\n            try:\n                callback = self.get_callback(oauth_request)\n            except Error:\n                callback = None # 1.0, no callback specified.\n            self._check_signature(oauth_request, consumer, None)\n            # Fetch a new token.\n            token = self.data_store.fetch_request_token(consumer, callback)\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing an access_token request and returns the access token on success.", "response": "def fetch_access_token(self, oauth_request):\n        \"\"\"Processes an access_token request and returns the\n        access token on success.\n        \"\"\"\n        version = self._get_version(oauth_request)\n        consumer = self._get_consumer(oauth_request)\n        try:\n            verifier = self._get_verifier(oauth_request)\n        except Error:\n            verifier = None\n        # Get the request token.\n        token = self._get_token(oauth_request, 'request')\n        self._check_signature(oauth_request, consumer, token)\n        new_token = self.data_store.fetch_access_token(consumer, token, verifier)\n        return new_token"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ntry to find the token for the provided request token key.", "response": "def _get_token(self, oauth_request, token_type='access'):\n        \"\"\"Try to find the token for the provided request token key.\"\"\"\n        token_field = oauth_request.get_parameter('oauth_token')\n        token = self.data_store.lookup_token(token_type, token_field)\n        if not token:\n            raise OAuthError('Invalid %s token: %s' % (token_type, token_field))\n        return token"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clean_chars(value):\n    \"Hack to remove non-ASCII data. Should convert to Unicode: code page 437?\"\n    value = value.replace('\\xb9', ' ')\n    value = value.replace('\\xf8', ' ')\n    value = value.replace('\\xab', ' ')\n    value = value.replace('\\xa7', ' ')\n    value = value.replace('\\xa8', ' ')\n    value = value.replace('\\xfb', ' ')\n    value = value.replace('\\xfc', ' ')\n    return value", "response": "Hack to remove non - ASCII data. Should convert to Unicode code page 437?"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit curve by method of least squares.", "response": "def fit_lsq(self, x, y_obs, params_start=None):\n        \"\"\"\n        Fit curve by method of least squares.\n\n        Parameters\n        ----------\n        x : iterable\n            Independent variable\n        y_obs : iterable\n            Dependent variable (values observed at x)\n        params_start : iterable\n            Optional start values for all parameters. Default 1.\n\n        Returns\n        -------\n        array\n            Best fit values of parameters\n\n        Notes\n        -----\n        If least squares fit does not converge, ValueError is raised with\n        convergence message.\n\n        \"\"\"\n\n        # Set up variables\n        x = np.atleast_1d(x)\n        y_obs = np.atleast_1d(y_obs)\n        if not params_start:\n            params_start = np.ones(self.n_parameters)\n\n        # Error checking\n        if len(x) != len(y_obs):\n            raise ValueError, \"x and y_obs must be the same length\"\n        if len(params_start) != self.n_parameters:\n            raise ValueError, \"Incorrect number of values in params_start\"\n\n        # Calculate fit\n        def residuals(params, x, y_obs):\n            y_pred = self.vals(x, *params)\n            return y_obs - y_pred\n\n        params_fit, _, _, msg, ier = optimize.leastsq(residuals, params_start,\n                                             args=(x, y_obs), full_output=True)\n\n        # Check for convergence\n        if ier > 4:\n            raise ValueError, (\"Least squares fit did not converge with \"\n                               \"message %s\" % msg)\n\n        return tuple(params_fit)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fit_lsq(self, df):\n        tdf = df.set_index('div')\n        return tdf.ix['1,1']['n_spp'], tdf.ix['1,1']['n_individs']", "response": "Fits the generic SAR curve from empirical data set set\n            to the data frame in df."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndraws all vertices and update the vertex list", "response": "def draw(self):\n        \"\"\" \u4f7f\u7528draw\u65b9\u6cd5\u5c06\u56fe\u5f62\u7ed8\u5236\u5728\u7a97\u53e3\u91cc \"\"\"\n        self.update_all()\n        self.vertex_list.draw(self.gl)\n        pyglet.gl.glLoadIdentity()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_all(self):\n        self.update_points()\n        self.update_vertex_list()\n        self.update_anchor()\n\n        pyglet.gl.glLoadIdentity()  # reset gl\n        pyglet.gl.glLineWidth(self.line_width)\n        pyglet.gl.glPointSize(self.point_size)\n        self.transform.update_gl()\n\n        # handle shapes click envets\n        all_shapes.discard(self)\n        if(self._press != None):\n            all_shapes.add(self)", "response": "update all vertices and vertices"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_vertex_list(self):\n        color = color_to_tuple(self.color, self.opacity)\n        length = len(self.points) // 2\n        self.vertex_list = pyglet.graphics.vertex_list(\n            length,\n            ('v2f', self.points),\n            ('c4B', color * length))", "response": "Update the vertex list of the image."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update_anchor(self):\n        t = self.transform\n        self.update_collision_rect()\n        if t.anchor_x_r and t.anchor_y_r:\n            t.anchor_x = self.min_x + (self.max_x - self.min_x) * t.anchor_x_r\n            t.anchor_y = self.min_y + (self.max_y - self.min_y) * t.anchor_y_r", "response": "Update anchor_x and anchor_y based on the current anchor_x and anchor_y values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending a batch of messages to a kafka topic", "response": "def bulk_send(self, topic, kmsgs):\n        \"\"\" Send a batch of messages\n\n        :param str topic: a kafka topic\n        :param ksr.transport.Message kmsgs: Messages to serialize\n        :return: Execution result\n        :rtype: kser.result.Result\n        \"\"\"\n\n        try:\n            self.client.do_request(\n                method=\"POST\", path=\"/topic/{}\".format(topic), data=[\n                    dict(Value=k.MARSHMALLOW_SCHEMA.dump(k)) for k in kmsgs\n                ]\n            )\n            return Result(stdout=\"{} message(s) sent\".format(len(kmsgs)))\n\n        except Exception as exc:\n            return Result.from_exception(exc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend the message into the given topic.", "response": "def send(self, topic, kmsg):\n        \"\"\" Send the message into the given topic\n\n        :param str topic: a kafka topic\n        :param ksr.transport.Message kmsg: Message to serialize\n        :return: Execution result\n        :rtype: kser.result.Result\n        \"\"\"\n        try:\n            self.client.do_request(\n                method=\"POST\", params=dict(format=\"raw\"),\n                path=\"/topic/{}\".format(topic),\n                data=kmsg.MARSHMALLOW_SCHEMA.dump(kmsg)\n            )\n            result = Result(\n                uuid=kmsg.uuid, stdout=\"Message sent: {} ({})\".format(\n                    kmsg.uuid, kmsg.entrypoint\n                )\n            )\n\n        except Exception as exc:\n            result = Result.from_exception(exc, kmsg.uuid)\n\n        finally:\n            # noinspection PyUnboundLocalVariable\n            if result.retcode < 300:\n                return self._onsuccess(kmsg=kmsg, result=result)\n            else:\n                return self._onerror(kmsg=kmsg, result=result)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef batch_update(self, command, rows):\n        request = {\n            \"database\": {\n                \"alias\": self.__options['dbAlias']\n            },\n            \"batchUpdate\": {\n                \"command\": command,\n                \"rows\": rows,\n                \"shardKey\": self.__options.get('shardKey'),\n            }\n        }\n        dr = self.__app.native_api_call('db', 'batch-update', request, self.__options, False)\n        return json.loads(dr.text)", "response": "Batch update a list of items in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef one(self, command, params=None):\n        dr = self.query(command, params)\n        if dr['rows']:\n            return dr['rows'][0]\n        else:\n            return None", "response": "\u041f\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0447\u0435\u0440\u0435\u0437 \u043e\u0442\u0432\u0435\u0442\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0447\u0435\u0440\ufffd"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef all(self, command, params=None):\n        dr = self.query(command, params)\n        return dr['rows']", "response": "\u041f\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u0441\u0442\u0440\u043e\u043a\u0438 \u043e\u0442\u0432\u0435\u0442\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0433\u043e \u0447\u0435\u0440\u0435\u0437 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0435\u0437"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef after_insert(mapper, connection, target):\n    record_after_update.send(CmtRECORDCOMMENT, recid=target.id_bibrec)\n\n    from .api import get_reply_order_cache_data\n    if target.in_reply_to_id_cmtRECORDCOMMENT > 0:\n        parent = CmtRECORDCOMMENT.query.get(\n            target.in_reply_to_id_cmtRECORDCOMMENT)\n        if parent:\n            trans = connection.begin()\n            parent_reply_order = parent.reply_order_cached_data \\\n                if parent.reply_order_cached_data else ''\n            parent_reply_order += get_reply_order_cache_data(target.id)\n            connection.execute(\n                db.update(CmtRECORDCOMMENT.__table__).\n                where(CmtRECORDCOMMENT.id == parent.id).\n                values(reply_order_cached_data=parent_reply_order))\n            trans.commit()", "response": "Update reply order cache and send record - after - update signal."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the comment is collapsed by user.", "response": "def is_collapsed(self, id_user):\n        \"\"\"Return true if the comment is collapsed by user.\"\"\"\n        return CmtCOLLAPSED.query.filter(db.and_(\n            CmtCOLLAPSED.id_bibrec == self.id_bibrec,\n            CmtCOLLAPSED.id_cmtRECORDCOMMENT == self.id,\n            CmtCOLLAPSED.id_user == id_user)).count() > 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef collapse(self, id_user):\n        c = CmtCOLLAPSED(id_bibrec=self.id_bibrec, id_cmtRECORDCOMMENT=self.id,\n                         id_user=id_user)\n        db.session.add(c)\n        db.session.commit()", "response": "Collapse comment beloging to user."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexpands comment beloging to user.", "response": "def expand(self, id_user):\n        \"\"\"Expand comment beloging to user.\"\"\"\n        CmtCOLLAPSED.query.filter(db.and_(\n            CmtCOLLAPSED.id_bibrec == self.id_bibrec,\n            CmtCOLLAPSED.id_cmtRECORDCOMMENT == self.id,\n            CmtCOLLAPSED.id_user == id_user)).delete(synchronize_session=False)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count(cls, *criteria, **filters):\n        return cls.query.filter(*criteria).filter_by(**filters).count()", "response": "Count how many comments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_version(version=None):\n\n    if version[4] > 0:  # 0.2.1-alpha.1\n        return \"%s.%s.%s-%s.%s\" % (version[0], version[1], version[2], version[3], version[4])\n    elif version[3] != '':  # 0.2.1-alpha\n        return \"%s.%s.%s-%s\" % (version[0], version[1], version[2], version[3])\n    elif version[2] > 0:  # 0.2.1\n        return \"%s.%s.%s\" % (version[0], version[1], version[2])\n    else:  # 0.2\n        return \"%s.%s\" % (version[0], version[1])", "response": "Returns a tuple of the django version."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef list_all_refund_operations(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_refund_operations_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_refund_operations_with_http_info(**kwargs)\n            return data", "response": "List RefundOperations\n        Return a list of RefundOperations\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\npush a packet onto the internal read queue and notifies the waiting listener that it just came in.", "response": "def _push_packet(self, packet):\n        \"\"\"\n        Appends a packet to the internal read queue, or notifies\n        a waiting listener that a packet just came in.\n        \"\"\"\n        self._read_queue.append((decode(packet), packet))\n\n        if self._read_waiter is not None:\n            w, self._read_waiter = self._read_waiter, None\n            w.set_result(None)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread data from the connection and adds it to _push_packet until the connection is closed or the task in cancelled.", "response": "def _read_data(self):\n        \"\"\"\n        Reads data from the connection and adds it to _push_packet,\n        until the connection is closed or the task in cancelled.\n        \"\"\"\n        while True:\n            try:\n                data = yield from self._socket.recv()\n            except asyncio.CancelledError:\n                break\n            except ConnectionClosed:\n                break\n\n            self._push_packet(data)\n\n        self._loop.call_soon(self.close)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwaits until a message is available on the wire.", "response": "def wait_message(self):\n        \"\"\"\n        Waits until a connection is available on the wire, or until\n        the connection is in a state that it can't accept messages.\n        It returns True if a message is available, False otherwise.\n        \"\"\"\n        if self._state != states['open']:\n            return False\n        if len(self._read_queue) > 0:\n            return True\n\n        assert self._read_waiter is None or self._read_waiter.cancelled(), \\\n            \"You may only use one wait_message() per connection.\"\n\n        self._read_waiter = asyncio.Future(loop=self._loop)\n        yield from self._read_waiter\n        return self.wait_message()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_reservation_ports(session, reservation_id, model_name='Generic Traffic Generator Port'):\n\n    reservation_ports = []\n    reservation = session.GetReservationDetails(reservation_id).ReservationDescription\n    for resource in reservation.Resources:\n        if resource.ResourceModelName == model_name:\n            reservation_ports.append(resource)\n    return reservation_ports", "response": "Get all Generic Traffic Generator Port in reservation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all resources of given models in reservation.", "response": "def get_reservation_resources(session, reservation_id, *models):\n    \"\"\" Get all resources of given models in reservation.\n\n    :param session: CloudShell session\n    :type session: cloudshell.api.cloudshell_api.CloudShellAPISession\n    :param reservation_id: active reservation ID\n    :param models: list of requested models\n    :return: list of all resources of models in reservation\n    \"\"\"\n\n    models_resources = []\n    reservation = session.GetReservationDetails(reservation_id).ReservationDescription\n    for resource in reservation.Resources:\n        if resource.ResourceModelName in models:\n            models_resources.append(resource)\n    return models_resources"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the ID of the current container.", "response": "def get_current_container_id(read_from='/proc/self/cgroup'):\n    \"\"\"\n    Get the ID of the container the application is currently running in,\n    otherwise return `None` if not running in a container.\n\n    This is a best-effort guess, based on cgroups.\n\n    :param read_from: the cgroups file to read from (default: `/proc/self/cgroup`)\n    \"\"\"\n\n    if not os.path.exists(read_from):\n        return\n\n    with open(read_from, 'r') as cgroup:\n        for line in cgroup:\n            if re.match('.*/[0-9a-f]{64}$', line.strip()):\n                return re.sub('.*/([0-9a-f]{64})$', '\\\\1', line.strip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a configuration from a file Docker config or secret or from environment variables.", "response": "def read_configuration(key, path=None, default=None, single_config=False, fallback_to_env=True):\n    \"\"\"\n    Read configuration from a file, Docker config or secret or from the environment variables.\n\n    :param key: the configuration key\n    :param path: the path of the configuration file (regular file or Docker config or secret)\n    :param default: the default value when not found elsewhere (default: `None`)\n    :param single_config: treat the configuration file as containing the full configuration,\n        otherwise the file is expected to be a '=' separated key-value list line by line\n        (default: `False`)\n    :param fallback_to_env: look for the configuration key in the environment variables\n        if not found elsewhere (default: `True`)\n    \"\"\"\n\n    if path and os.path.exists(path):\n        with open(path, 'r') as config_file:\n            if single_config:\n                return config_file.read()\n\n            for line in config_file:\n                if line.startswith('%s=' % key):\n                    return line.split('=', 1)[1].strip()\n\n    if fallback_to_env and key in os.environ:\n        return os.environ[key]\n\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef CleanString(s):\n    punc = (' ', '-', '\\'', '.', '&amp;', '&', '+', '@')\n    pieces = []\n    for part in s.split():\n        part = part.strip()\n        for p in punc:\n            part = part.replace(p, '_')\n        part = part.strip('_')\n        part = part.lower()\n        pieces.append(part)\n    return '_'.join(pieces)", "response": "Cleans up a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmakes sure every vCard in the dictionary has a unique filename.", "response": "def DedupVcardFilenames(vcard_dict):\n    \"\"\"Make sure every vCard in the dictionary has a unique filename.\"\"\"\n    remove_keys = []\n    add_pairs = []\n    for k, v in vcard_dict.items():\n        if not len(v) > 1:\n            continue\n        for idx, vcard in enumerate(v):\n            fname, ext = os.path.splitext(k)\n            fname = '{}-{}'.format(fname, idx + 1)\n            fname = fname + ext\n            assert fname not in vcard_dict\n            add_pairs.append((fname, vcard))\n        remove_keys.append(k)\n\n    for k, v in add_pairs:\n        vcard_dict[k].append(v)\n\n    for k in remove_keys:\n        vcard_dict.pop(k)\n\n    return vcard_dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef WriteVcard(filename, vcard, fopen=codecs.open):\n    if os.access(filename, os.F_OK):\n        logger.warning('File exists at \"{}\", skipping.'.format(filename))\n        return False\n    try:\n        with fopen(filename, 'w', encoding='utf-8') as f:\n            logger.debug('Writing {}:\\n{}'.format(filename, u(vcard.serialize())))\n            f.write(u(vcard.serialize()))\n    except OSError:\n        logger.error('Error writing to file \"{}\", skipping.'.format(filename))\n        return False\n    return True", "response": "Writes a vCard into the given filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_cash_on_delivery_payment(cls, cash_on_delivery_payment, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_cash_on_delivery_payment_with_http_info(cash_on_delivery_payment, **kwargs)\n        else:\n            (data) = cls._create_cash_on_delivery_payment_with_http_info(cash_on_delivery_payment, **kwargs)\n            return data", "response": "Create a new CashOnDeliveryPayment object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef delete_cash_on_delivery_payment_by_id(cls, cash_on_delivery_payment_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, **kwargs)\n        else:\n            (data) = cls._delete_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, **kwargs)\n            return data", "response": "Delete an instance of CashOnDeliveryPayment by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_cash_on_delivery_payment_by_id(cls, cash_on_delivery_payment_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, **kwargs)\n        else:\n            (data) = cls._get_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, **kwargs)\n            return data", "response": "Find CashOnDeliveryPayment by its ID Return single instance of CashOnDeliveryPayment"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing all attributes of CashOnDeliveryPayment by ID", "response": "def replace_cash_on_delivery_payment_by_id(cls, cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs):\n        \"\"\"Replace CashOnDeliveryPayment\n\n        Replace all attributes of CashOnDeliveryPayment\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_cash_on_delivery_payment_by_id(cash_on_delivery_payment_id, cash_on_delivery_payment, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str cash_on_delivery_payment_id: ID of cashOnDeliveryPayment to replace (required)\n        :param CashOnDeliveryPayment cash_on_delivery_payment: Attributes of cashOnDeliveryPayment to replace (required)\n        :return: CashOnDeliveryPayment\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs)\n        else:\n            (data) = cls._replace_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_cash_on_delivery_payment_by_id(cls, cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs)\n        else:\n            (data) = cls._update_cash_on_delivery_payment_by_id_with_http_info(cash_on_delivery_payment_id, cash_on_delivery_payment, **kwargs)\n            return data", "response": "Update attributes of CashOnDeliveryPayment by ID"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndial to a node", "response": "def dial(self, target):\n        '''\n        connects to a node\n\n        :param url: string (optional) - resource in which to connect.\n        if not provided, will use default for the stage\n        :returns: provider, error\n        '''\n\n        if not target:\n            return None, \"target network must be specified with -t or --target\"\n\n        url = get_url(self.config, target)\n\n        try:\n            if url.startswith('ws'):\n                self.w3 = Web3(WebsocketProvider(url))\n            elif url.startswith('http'):\n                self.w3 = Web3(HTTPProvider(url))\n            elif url.endswith('ipc'):\n                if url == 'ipc':\n                    url = None\n                self.w3 = Web3(Web3.IPCProvider(url))\n            else:\n                return None, \"Invalid Provider URL: {}\".format(url)\n\n        except Exception as e:\n            return None, e\n\n        return self.w3, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef start(self, contract_names, target):\n        '''\n        loads the contracts -- starts their event listeners\n        :param contract_names:\n        :return:\n        '''\n\n        if isinstance(contract_names, str):\n            contract_names = [contract_names]\n\n        if not isinstance(contract_names, list):\n            return None, \"error: expecting a string, or a list of contract names\"\n\n        contract_listeners = []\n\n        for name in contract_names:\n            c, err = Contract.get(name, self)\n            if err:\n                EZO.log.error(red(\"error loading contract {}\".format(name)))\n                EZO.log.error(red(err))\n                continue\n            if not c:\n                EZO.log.warn(blue(\"contract {} not found\".format(name)))\n                continue\n\n            address, err = Contract.get_address(name, c.hash, self.db, target=target)\n\n            if err:\n                EZO.log.error(red(\"error obtaining address for contract {}\").format(name))\n                EZO.log.error(red(err))\n                continue\n            if not address:\n                EZO.log.error(red(\"no address for contract {}\".format(name)))\n                continue\n\n            contract_listeners.append(c.listen(address, target))\n\n        if contract_listeners:\n            loop = asyncio.get_event_loop()\n            loop.run_until_complete(\n                asyncio.gather(*contract_listeners)\n            )\n        else:\n            return None, \"unable to start contract listeners\"", "response": "Loads the contracts and starts their event listeners"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new project and creates the initial skeleton and files", "response": "def create_project(name, include_examples=True):\n        '''\n        creates the initial project skeleton and files\n        :param name: the project name\n        :return:\n        '''\n\n        # from the start directory, create a project directory with the project name\n        path = \"{}/{}\".format(os.getcwd(), name)\n        if os.path.exists(path):\n            return None, \"path {} already exists\".format(path)\n\n        print(bright(\"creating new ezo project '{}\".format(name)))\n\n        # make project directory\n        os.mkdir(path)\n        print(bright(\"created project directory: '{}\".format(path)))\n\n        # create an empty contracts directory\n        contracts_dir = \"{}/{}\".format(path, \"contracts\")\n        os.mkdir(contracts_dir)\n        print(bright(\"created contract directory: '{}\".format(contracts_dir)))\n\n        if include_examples:\n            c = [(create_sample_contracts_1(), 'contract1.sol'), (create_sample_contracts_2(), 'contract2.sol')]\n            for s in c:\n                c, fn = s\n                file_path = \"{}/{}\".format(contracts_dir, fn)\n                try:\n                    with open(file_path, \"w+\") as outfile:\n                        outfile.write(c)\n                except Exception as e:\n                    print(bright(\"problem creating sample file: '{}\".format(path)))\n                    return None, e\n                print(bright(\"created sample contract: '{}\".format(fn)))\n\n        # create the handlers directory\n        handlers_dir = \"{}/{}\".format(path, \"handlers\")\n        os.mkdir(handlers_dir)\n        print(bright(\"created handlers directory: '{}\".format(handlers_dir)))\n\n        # leveldb directory (created by level)\n        leveldb = \"{}/{}\".format(path, \"ezodb\")\n\n        # create the initial config.json file\n        cfg = create_blank_config_obj()\n\n        cfg[\"ezo\"][\"contract-dir\"] = contracts_dir\n        cfg[\"ezo\"][\"handlers-dir\"] = handlers_dir\n        cfg[\"ezo\"][\"project-name\"] = name\n        cfg[\"ezo\"][\"leveldb\"] = leveldb\n        print(bright(\"creating configuration: '{}\".format(path)))\n\n        # write the file to the root project dir\n        config_file_path = \"{}/{}\".format(path, \"ezo.conf\")\n        try:\n            with open(config_file_path, \"w+\") as outfile:\n                json.dump(cfg, outfile, indent=2)\n        except Exception as e:\n            print(bright(\"problem creating configuration file: '{}\".format(path)))\n            return None, e\n\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef deploy(self, target, overwrite=False):\n        '''\n        deploy this contract\n        :param target:\n        :param account:  the account address to use\n        :return: address, err\n        '''\n\n        name = self.name.replace('<stdin>:', \"\")\n        key = DB.pkey([EZO.DEPLOYED, name, target, self.hash])\n\n        if not target:\n            return None, \"target network must be set with -t or --target\"\n\n        password = os.environ['EZO_PASSWORD'] if 'EZO_PASSWORD' in os.environ else None\n\n        # see if a deployment already exists for this contract on this target\n        if not overwrite:\n            res, err = self._ezo.db.get(key)\n            if err:\n                return None, \"ERROR: Contract.deployment() {}\".format(err)\n            if res:\n                return None, \"deployment on {} already exists for contract {} use '--overwrite' to force\".format(target, self.hash)\n\n        account = self._ezo.w3.toChecksumAddress(get_account(self._ezo.config, target))\n        self._ezo.w3.eth.accounts[0] = account\n\n        try:\n            u_state = self._ezo.w3.personal.unlockAccount(account, password)\n        except Exception as e:\n            return None, \"unable to unlock account for {} using password\".format(account)\n\n        try:\n            ct = self._ezo.w3.eth.contract(abi=self.abi, bytecode=self.bin)\n            gas_estimate = ct.constructor().estimateGas()\n            h = {'from': account, 'gas': gas_estimate + 1000}\n            tx_hash = ct.constructor().transact(h)\n            tx_receipt = self._ezo.w3.eth.waitForTransactionReceipt(tx_hash)\n            address = tx_receipt['contractAddress']\n\n        except Exception as e:\n            return None, e\n#        finally:\n#            self._ezo.w3.personal.lockAccount(account)\n\n        d = dict()\n        d[\"contract-name\"] = self.name\n        d[\"hash\"] = self.hash\n        d[\"tx-hash\"] = tx_hash\n        d[\"address\"] = address\n        d[\"gas-used\"] = tx_receipt[\"gasUsed\"]\n        d[\"target\"] = target\n        d[\"timestamp\"] = datetime.utcnow()\n\n        # save the deployment information\n        try:\n            _, err = self._ezo.db.save(key, d, overwrite=overwrite)\n            if err:\n                return None, err\n        except Exception as e:\n            return None, e\n\n        return address, None", "response": "deploy this contract on the specified target network"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlistens to a specific address and target", "response": "async def listen(self, address, target):\n        '''\n        starts event listener for the contract\n        :return:\n        '''\n\n        if not address:\n            return None, \"listening address not provided\"\n\n        EZO.log.info(bright(\"hello ezo::listening to address: {}\".format(blue(address))))\n        interval = self._ezo.config[\"poll-interval\"]\n\n        event_filter = self._ezo.w3.eth.filter({\"address\": address, \"toBlock\": \"latest\"})\n        loop = asyncio.new_event_loop()\n        try:\n            while True:\n                for event in event_filter.get_new_entries():\n                    if EZO.log:\n                        EZO.log.debug(bright(\"event received: {}\".format(event)))\n                    ContractEvent.handler(event, self, target)\n                await asyncio.sleep(interval)\n        except Exception as e:\n            return None, e\n        finally:\n            loop.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls by the event handler with the result data :param response_data: result data :return:", "response": "def response(self, response_data):\n        '''\n        called by the event handler with the result data\n        :param response_data: result data\n        :return:\n        '''\n\n        if \"address\" not in response_data:\n            return None, \"address missing from response_data payload\"\n        if \"function\" not in response_data:\n            return None, \"method missing from response_data payload\"\n        if \"params\" not in response_data:\n            return None, \"params missing from response_data payload\"\n        if \"target\" not in response_data:\n            return None, \"target missing from response_data payload\"\n\n\n        address = self._ezo.w3.toChecksumAddress(response_data[\"address\"])\n        account = self._ezo.w3.toChecksumAddress(get_account(self._ezo.config, response_data[\"target\"]))\n\n        self._ezo.w3.eth.accounts[0] = account\n\n        tx_dict = dict()\n        tx_dict[\"account\"] = account\n        tx_dict[\"from\"] = account\n\n        password = os.environ['EZO_PASSWORD'] if 'EZO_PASSWORD' in os.environ else None\n\n        u_state = self._ezo.w3.personal.unlockAccount(account, password)\n\n        if not self.contract_obj:\n            try:\n                self.contract_obj = self._ezo.w3.eth.contract(address=address, abi=self.abi)\n            except Exception as e:\n                return None, e\n\n        method = response_data[\"function\"]\n        params = response_data[\"params\"]\n        contract_func = self.contract_obj.functions[method]\n        try:\n            if not params:\n                tx_dict[\"gas\"] = contract_func().estimateGas() + 1000\n                tx_hash = contract_func().transact(tx_dict)\n            else:\n                tx_dict[\"gas\"] = contract_func(*params).estimateGas() + 1000\n                tx_hash = contract_func(*params).transact(tx_dict)\n\n            receipt = self._ezo.w3.eth.waitForTransactionReceipt(tx_hash)\n        except Exception as e:\n            return None, \"error executing transaction: {}\".format(e)\n  #      finally:\n#            self._ezo.w3.personal.lockAccount(account)\n\n        return receipt, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsend a message to a specific instance", "response": "def send(ezo, name, method, data, target):\n        '''\n        runs a transaction on a contract method\n        :param ezo:  ezo instance\n        :param name:  name of the Contract\n        :param method:  name of the contract method\n        :param data: formatted data to send to the contract method\n        :return:\n        '''\n\n        # load the contract by name\n        c, err = Contract.get(name, ezo)\n        if err:\n            return None, err\n\n        address, err = Contract.get_address(name, c.hash, ezo.db, target)\n        if err:\n            return None, err\n\n        d = dict()\n        d[\"address\"] = address\n        d[\"function\"] = method\n        d[\"params\"] = c.paramsForMethod(method, data)\n        d[\"target\"] = target\n\n\n        resp, err = c.response(d)\n        if err:\n            return None, err\n\n        return resp, None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(ezo, name, method, data, target):\n        '''\n        calls a method with data and returns a result without changing the chain state\n        :param ezo:  ezo instance\n        :param name:  name of the Contract\n        :param method:  name of the contract method\n        :param data: formatted data to send to the contract method\n        :param target: the target network\n        :return:\n        '''\n\n        # load the contract by name\n        c, err = Contract.get(name, ezo)\n        if err:\n            return None, err\n\n        address, err = Contract.get_address(name, c.hash, ezo.db, target)\n        if err:\n            return None, err\n\n        params = c.paramsForMethod(method, data)\n\n        address = ezo.w3.toChecksumAddress(address)\n        ezo.w3.eth.defaultAccount = ezo.w3.toChecksumAddress(get_account(ezo.config, target))\n\n        if not c.contract_obj:\n            try:\n                c.contract_obj = ezo.w3.eth.contract(address=address, abi=c.abi)\n            except Exception as e:\n                return None, e\n\n        contract_func = c.contract_obj.functions[method]\n        try:\n            if not params:\n                result = contract_func().call()\n            else:\n                result = contract_func(*params).call()\n\n        except Exception as e:\n            return None, \"error executing call: {}\".format(e)\n\n        return result, None", "response": "Calls a method with data and returns a result without changing the chain state"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the latest compiled contract instance by contract name", "response": "def get(name, ezo):\n        '''\n        get the latest compiled contract instance by contract name\n        :param name:\n        :param ezo:\n        :return:\n        '''\n\n        key = DB.pkey([EZO.CONTRACT, name])\n        cp, err = ezo.db.get(key)\n        if err:\n            return None, err\n\n        if not cp:\n            return None, None\n\n        # create a new Contract\n        c = Contract(cp[\"name\"], ezo)\n        c.abi = cp[\"abi\"]\n        c.bin = cp[\"bin\"]\n        c.hash = cp[\"hash\"]\n        c.source = cp[\"source\"]\n        c.timestamp = cp[\"timestamp\"]\n        c.te_map = cp['te-map']\n\n        return c, None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_from_hash(hash, ezo):\n        '''\n        given the hash of a contract, returns a contract  from the data store\n        :param hash: (string) hash of the contract source code\n        :param ezo: ezo instance\n        :return: contract instance, error\n        '''\n\n        cp, err = ezo.db.get(\"contracts\", hash)\n        if err:\n            return None, err\n\n        # create a new Contract\n        c = Contract(cp[\"name\"], ezo)\n        c.abi = cp[\"abi\"]\n        c.bin = cp[\"bin\"]\n        c.hash = cp[\"hash\"]\n        c.source = cp[\"source\"]\n        c.timestamp = cp[\"timestamp\"]\n        c.te_map = cp['te-map']\n\n        return c, None", "response": "create a new Contract object from a hash"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load(filepath):\n        '''\n        loads a contract file\n\n        :param filepath: (string) - contract filename\n        :return: source, err\n        '''\n\n        try:\n            with open(filepath, \"r\") as fh:\n                source = fh.read()\n        except Exception as e:\n            return None, e\n        return source, None", "response": "loads a contract file into a string"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compile(source, ezo):\n        '''\n        compiles the source code\n\n        :param source: (string) - contract source code\n        :param ezo: - ezo reference for Contract object creation\n        :return: (list) compiled source\n        '''\n        try:\n            compiled = compile_source(source)\n            compiled_list = []\n            for name in compiled:\n                c = Contract(name, ezo)\n                interface = compiled[name]\n                c.abi = interface['abi']\n                c.bin = interface['bin']\n                compiled_list.append(c)\n\n        except Exception as e:\n            return None, e\n        return compiled_list, None", "response": "compiles the source code\n            and returns a list of the compiled source code and the object creation\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_address(name, hash, db, target=None):\n        '''\n        fetches the contract address of deployment\n\n        :param hash: the contract file hash\n        :return: (string) address of the contract\n                 error, if any\n        '''\n\n        key = DB.pkey([EZO.DEPLOYED, name, target, hash])\n\n        d, err = db.get(key)\n        if err:\n            return None, err\n        if not d:\n            return None, None\n        return d['address'].lower(), None", "response": "Retrieves the contract address of the deployment with the given name and hash."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef put(contract_name, abi):\n        '''\n        save the contract's ABI\n\n        :param contract_name: string - name of the contract\n        :param abi: the contract's abi JSON file\n        :return: None, None if saved okay\n                 None, error is an error\n        '''\n\n        if not Catalog.path:\n            return None, \"path to catalog must be set before saving to it\"\n        if not contract_name:\n            return None, \"contract name must be provided before saving\"\n        if not abi:\n            return None, \"contract ABI missing\"\n\n        abi_file = \"{}/{}.abi\".format(Catalog.path, contract_name)\n\n        try:\n            with open(abi_file, \"w+\") as file:\n                file.write(abi)\n        except Exception as e:\n            return None, \"Catalog.put error: {}\".format(e)\n        return None, None", "response": "Save the contract s ABI to the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(contract_name):\n        '''\n        return the contract's ABI, marshaled into python dict\n        :param contract_name: string - name of the contract to load\n        :return: ABI, None - if successful\n                 None, error - if error\n        '''\n\n        if not Catalog.path:\n            return None, \"path to catalog must be set before searching it\"\n        if not contract_name:\n            return None, \"contract name missing\"\n\n        abi_file = \"{}/{}.abi\".format(Catalog.path, contract_name)\n\n        try:\n            with open(abi_file, \"r\") as file:\n                abi = file.read()\n        except Exception as e:\n            return None, \"Catalog.get error: {}\".format(e)\n        return abi, None", "response": "Returns the contract s ABI marshaled into python dict\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the database and return the ID and the error if it fails.", "response": "def open(self):\n        '''\n        attempts to open the database.  if it gets a locked message, it will wait one second and try\n        again.  if it is still locked, it will return an error\n        :return: None, None if successful\n                 None, error if error\n        '''\n        cycle = 2\n        count = 0\n\n        while(True):\n            try:\n                DB.db = plyvel.DB(DB.dbpath, create_if_missing=True).prefixed_db(bytes(DB.project, 'utf-8'))\n                if DB.db:\n                    break\n\n            except Exception as e:\n                # wait for other program to unlock the db\n                count+=1\n                time.sleep(1)\n                if count >= cycle:\n                    return None, \"DB error: {}\".format(e)\n\n        return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform_from_chomsky_normal_form(root):\n    # type: (Nonterminal) -> Nonterminal\n    \"\"\"\n    Transform the tree created by grammar in the Chomsky Normal Form to original rules.\n    :param root: Root of parsed tree.\n    :return: Modified tree.\n    \"\"\"\n    # Transforms leaves\n    items = Traversing.post_order(root)\n    items = filter(lambda x: isinstance(x, (ChomskyTermRule, ChomskyTerminalReplaceRule)), items)\n    de = deque(items)\n    while de:\n        rule = de.popleft()\n        if isinstance(rule, ChomskyTermRule):\n            upper_nonterm = rule.from_symbols[0]  # type: Nonterminal\n            term = rule.to_symbols[0]\n            Manipulations.replaceNode(upper_nonterm, term)\n        elif isinstance(rule, ChomskyTerminalReplaceRule):\n            created_rule = rule.from_rule()  # type: Rule\n            Manipulations.replaceRule(rule, created_rule)\n            de.append(created_rule)\n\n    # Transform inner nodes\n    items = Traversing.post_order(root)\n    items = filter(lambda x: isinstance(x, ChomskySplitRule), items)\n    de = deque(items)\n    while de:\n        rule = de.popleft()\n        if isinstance(rule, ChomskySplitRule):\n            created_rule = rule.from_rule()  # type: Rule\n            # parent nonterminals\n            for p in rule.from_symbols:  # type: Nonterminal\n                p._set_to_rule(created_rule)\n                created_rule._from_symbols.append(p)\n            # left child\n            left_child = rule.to_symbols[0]  # type: Nonterminal\n            left_child._set_from_rule(created_rule)\n            created_rule._to_symbols.append(left_child)\n            # right childs\n            for ch in rule.to_symbols[1].to_rule.to_symbols:  # type: Nonterminal\n                ch._set_from_rule(created_rule)\n                created_rule.to_symbols.append(ch)\n            # add back if the rules is ChomskySplitRule again\n            de.appendleft(created_rule)\n    return root", "response": "Transform the tree created by grammar in the Chomsky Normal Form to original rules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_return_operation(cls, return_operation, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_return_operation_with_http_info(return_operation, **kwargs)\n        else:\n            (data) = cls._create_return_operation_with_http_info(return_operation, **kwargs)\n            return data", "response": "Create a new ReturnOperation"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_return_operation_by_id(cls, return_operation_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_return_operation_by_id_with_http_info(return_operation_id, **kwargs)\n        else:\n            (data) = cls._delete_return_operation_by_id_with_http_info(return_operation_id, **kwargs)\n            return data", "response": "Delete an instance of ReturnOperation by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_return_operation_by_id(cls, return_operation_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_return_operation_by_id_with_http_info(return_operation_id, **kwargs)\n        else:\n            (data) = cls._get_return_operation_by_id_with_http_info(return_operation_id, **kwargs)\n            return data", "response": "Find ReturnOperation by its ID Return single instance of ReturnOperation"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists ReturnOperations Return a list of ReturnOperations", "response": "def list_all_return_operations(cls, **kwargs):\n        \"\"\"List ReturnOperations\n\n        Return a list of ReturnOperations\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_return_operations(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[ReturnOperation]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_return_operations_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_return_operations_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef replace_return_operation_by_id(cls, return_operation_id, return_operation, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_return_operation_by_id_with_http_info(return_operation_id, return_operation, **kwargs)\n        else:\n            (data) = cls._replace_return_operation_by_id_with_http_info(return_operation_id, return_operation, **kwargs)\n            return data", "response": "Replace ReturnOperation by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates attributes of ReturnOperation by ID", "response": "def update_return_operation_by_id(cls, return_operation_id, return_operation, **kwargs):\n        \"\"\"Update ReturnOperation\n\n        Update attributes of ReturnOperation\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_return_operation_by_id(return_operation_id, return_operation, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str return_operation_id: ID of returnOperation to update. (required)\n        :param ReturnOperation return_operation: Attributes of returnOperation to update. (required)\n        :return: ReturnOperation\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_return_operation_by_id_with_http_info(return_operation_id, return_operation, **kwargs)\n        else:\n            (data) = cls._update_return_operation_by_id_with_http_info(return_operation_id, return_operation, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a console logger for the given level", "response": "def console_logger(\n    level=\"WARNING\"\n):\n    \"\"\"\n    *Setup and return a console logger*\n\n    **Key Arguments:**\n        - ``level`` -- the level of logging required\n\n    **Return:**\n        - ``logger`` -- the console logger\n\n    **Usage:**\n        .. code-block:: python \n\n            from fundamentals import logs\n            log = logs.console_logger(\n                level=\"DEBUG\"\n            )\n            log.debug(\"Testing console logger\")\n    \"\"\"\n    ################ > IMPORTS ################\n    ## STANDARD LIB ##\n\n    import logging\n    import logging.config\n    ## THIRD PARTY ##\n    import yaml\n    try:\n        yaml.warnings({'YAMLLoadWarning': False})\n    except:\n        pass\n    ## LOCAL APPLICATION ##\n\n    # SETUP LOGGING\n    loggerConfig = \"\"\"\n  version: 1\n  formatters:\n      console_style:\n          format: '* %(asctime)s - %(levelname)s: %(pathname)s:%(funcName)s:%(lineno)d > %(message)s'\n          datefmt: '%H:%M:%S'\n  handlers:\n      console:\n          class: logging.StreamHandler\n          level: \"\"\" + level + \"\"\"\n          formatter: console_style\n          stream: ext://sys.stdout\n  root:\n      level: \"\"\" + level + \"\"\"\n      handlers: [console]\"\"\"\n\n    logging.config.dictConfig(yaml.load(loggerConfig))\n    logger = logging.getLogger(__name__)\n\n    return logger"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef itemgetter(iterable, indexes):\n    ''' same functionality as operator.itemgetter except, this one supports\n        both positive and negative indexing of generators as well '''\n    indexes = indexes if isinstance(indexes, tuple) else tuple(indexes)\n    assert all(isinstance(i, int) for i in indexes), 'indexes needs to be a tuple of ints'\n    positive_indexes=[i for i in indexes if i>=0]\n    negative_indexes=[i for i in indexes if i<0]\n    out = {}\n    if len(negative_indexes):\n        # if there are any negative indexes\n        negative_index_buffer = deque(maxlen=min(indexes)*-1)\n        for i,x in enumerate(iterable):\n            if i in positive_indexes:\n                out[i]=x\n            negative_index_buffer.append(x)\n        out.update({ni:negative_index_buffer[ni] for ni in negative_indexes})\n    else:\n        # if just positive results\n        out.update({i:x for i,x in enumerate(iterable) if i in positive_indexes})\n    return itemgetter(*indexes)(out)", "response": "same functionality as operator. itemgetter except this one supports both positive and negative indexing of generators as well as both positive and negative indexing of generators as well"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef refresh(self):\n        try:\n            # suport for RPiDisplay SSD1306 driver\n            self.Display.setImage( self._catchCurrentViewContent() )\n        except:\n            try:\n                # suport for Adafruit SSD1306 driver\n                self.Display.image( self._catchCurrentViewContent() )\n            except:\n                raise \"Can not update image to buffer.\"\n\n        self.Display.display()", "response": "Refresh the image and display of the current view content."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nregister a new user from google.", "response": "def google_register(username:str, email:str, full_name:str, google_id:int, bio:str, token:str=None):\n    \"\"\"\n    Register a new user from google.\n    This can raise `exc.IntegrityError` exceptions in\n    case of conflics found.\n    :returns: User\n    \"\"\"\n    auth_data_model = apps.get_model(\"users\", \"AuthData\")\n    user_model = apps.get_model(\"users\", \"User\")\n\n    try:\n        # Google user association exist?\n        auth_data = auth_data_model.objects.get(key=\"google\", value=google_id)\n        user = auth_data.user\n    except auth_data_model.DoesNotExist:\n        try:\n            # Is a user with the same email as the google user?\n            user = user_model.objects.get(email=email)\n            auth_data_model.objects.create(user=user, key=\"google\", value=google_id, extra={})\n        except user_model.DoesNotExist:\n            # Create a new user\n            username_unique = slugify_uniquely(username, user_model, slugfield=\"username\")\n            user = user_model.objects.create(email=email,\n                                             username=username_unique,\n                                             full_name=full_name,\n                                             bio=bio)\n            auth_data_model.objects.create(user=user, key=\"google\", value=google_id, extra={})\n\n            send_register_email(user)\n            user_registered_signal.send(sender=user.__class__, user=user)\n\n    if token:\n        membership = get_membership_by_token(token)\n        membership.user = user\n        membership.save(update_fields=[\"user\"])\n\n    return user"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef crystalfield(interaction=np.linspace(0, 20, 201), \\\n                 j_hund=np.linspace(0, 0.35, 71)):\n    \"\"\"Aimed at reproducing the figure in paper\n       L. de'Medici, PRB 83,205112 (2011)\n       showing the phase diagram of a 3 band hubbard with one lifted band\n       fixed population 1:1.5,1.5\"\"\"\n    slsp = Spinon(slaves=6, orbitals=3, hopping=[0.5]*6, \\\n               populations=[1, 1, 1.5, 1.5, 1.5, 1.5])\n\n    zet = []\n    for hund_cu in j_hund:\n        zet.append(ssplt.solve_loop(slsp, interaction, hund_cu)[0][0])\n    np.savez('PRB_83_205112', zeta=zet, u_int=interaction, j_hund=j_hund)", "response": "Aimed at reproducing the figure in paper\n       L. de Medici PRB 83 205112"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns True if the assigned feature can be displayed.", "response": "def show_feature(user, feature):\n    \"\"\"Return True/False whether the assigned feature can be displayed. This is\n    primarily used in the template tag to determine whether to render the\n    content inside itself.\n    \"\"\"\n    FeatureFlipper = get_feature_model()\n    return FeatureFlipper.objects.show_feature(user, feature)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a FlipperNode for the given user and feature.", "response": "def do_flipper(parser, token):\n    \"\"\"The flipper tag takes two arguments: the user to look up and the feature\n    to compare against.\n    \"\"\"\n    nodelist = parser.parse(('endflipper',))\n    tag_name, user_key, feature = token.split_contents()\n    parser.delete_first_token()\n    return FlipperNode(nodelist, user_key, feature)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef render(self, context):\n        user = self._get_value(self.user_key, context)\n        feature = self._get_value(self.feature, context)\n\n        if feature is None:\n            return ''\n\n        allowed = show_feature(user, feature)\n        return self.nodelist.render(context) if allowed else ''", "response": "Handle the actual rendering."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_value(self, key, context):\n        string_quotes = ('\"', \"'\")\n\n        if key[0] in string_quotes and key[-1] in string_quotes:\n            return key[1:-1]\n        if key in string.digits:\n            return int(key)\n        return context.get(key, None)", "response": "Works out whether the key is a value or if it s a variable referencing a\n        value and returns the correct value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing OAuth client from registry.", "response": "def client(self, client_name, **params):\n        \"\"\"Initialize OAuth client from registry.\"\"\"\n        if client_name not in self.cfg.clients:\n            raise OAuthException('Unconfigured client: %s' % client_name)\n\n        if client_name not in ClientRegistry.clients:\n            raise OAuthException('Unsupported services: %s' % client_name)\n\n        params = dict(self.cfg.clients[client_name], **params)\n        return ClientRegistry.clients[client_name](**params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nprocessing login with OAuth.", "response": "async def login(self, client_name, request, redirect_uri=None, **params):\n        \"\"\"Process login with OAuth.\n\n        :param client_name: A name one of configured clients\n        :param request: Web request\n        :param redirect_uri: An URI for authorization redirect\n        \"\"\"\n        client = self.client(client_name, logger=self.app.logger)\n\n        redirect_uri = redirect_uri or self.cfg.redirect_uri or '%s://%s%s' % (\n            request.scheme, request.host, request.path)\n        session = await self.app.ps.session(request)\n\n        if isinstance(client, OAuth1Client):\n            oauth_verifier = request.query.get('oauth_verifier')\n            if not oauth_verifier:\n\n                # Get request credentials\n                token, secret = await client.get_request_token(\n                    oauth_callback=redirect_uri)\n\n                # Save the credentials in current user session\n                session['oauth_token'] = token\n                session['oauth_token_secret'] = secret\n\n                url = client.get_authorize_url()\n                raise muffin.HTTPFound(url)\n\n            # Check request_token\n            oauth_token = request.query.get('oauth_token')\n            if session['oauth_token'] != oauth_token:\n                raise muffin.HTTPForbidden(reason='Invalid token.')\n\n            client.oauth_token = oauth_token\n            client.oauth_token_secret = session.get('oauth_token_secret')\n\n            # Get access tokens\n            return client, await client.get_access_token(oauth_verifier)\n\n        if isinstance(client, OAuth2Client):\n            code = request.query.get('code')\n            if not code:\n\n                # Authorize an user\n                state = sha1(str(random()).encode('ascii')).hexdigest()\n                session['oauth_secret'] = state\n                url = client.get_authorize_url(\n                    redirect_uri=redirect_uri, state=state, **params)\n                raise muffin.HTTPFound(url)\n\n            # Check state\n            state = request.query.get('state')\n            oauth_secret = session.pop('oauth_secret', '')\n            if oauth_secret != state:\n                raise muffin.HTTPForbidden(reason='Invalid token \"%s\".' % oauth_secret)\n\n            # Get access token\n            return client, await client.get_access_token(code, redirect_uri=redirect_uri)\n\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a new refresh token.", "response": "def refresh(self, client_name, refresh_token, **params):\n        \"\"\"Get refresh token.\n\n        :param client_name: A name one of configured clients\n        :param redirect_uri: An URI for authorization redirect\n        :returns: a coroutine\n        \"\"\"\n        client = self.client(client_name, logger=self.app.logger)\n        return client.get_access_token(refresh_token, grant_type='refresh_token', **params)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chain(*args):\n    has_iter = partial(hasattr, name='__iter__')\n    # check if a single iterable is being passed for\n    # the case that it's a generator of generators\n    if len(args) == 1 and hasattr(args[0], '__iter__'):\n        args = args[0]\n\n    for arg in args:\n        # if the arg is iterable\n        if hasattr(arg, '__iter__'):\n            # iterate through it\n            for i in arg:\n                yield i\n        # otherwise\n        else:\n            # yield the whole argument\n            yield arg", "response": "itertools. chain just better"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquery cron for all celcius commands", "response": "def get_all_celcius_commands():\n    \"\"\"Query cron for all celcius commands\"\"\"\n    p = subprocess.Popen([\"crontab\", \"-l\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n    out, err = p.communicate()\n    return [x for x in out.split('\\n') if 'CJOBID' in x]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new OptionSet with the specified attributes.", "response": "def create_option_set(cls, option_set, **kwargs):\n        \"\"\"Create OptionSet\n\n        Create a new OptionSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_option_set(option_set, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param OptionSet option_set: Attributes of optionSet to create (required)\n        :return: OptionSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_option_set_with_http_info(option_set, **kwargs)\n        else:\n            (data) = cls._create_option_set_with_http_info(option_set, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete an OptionSet by its ID.", "response": "def delete_option_set_by_id(cls, option_set_id, **kwargs):\n        \"\"\"Delete OptionSet\n\n        Delete an instance of OptionSet by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_option_set_by_id(option_set_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_set_id: ID of optionSet to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_option_set_by_id_with_http_info(option_set_id, **kwargs)\n        else:\n            (data) = cls._delete_option_set_by_id_with_http_info(option_set_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_option_set_by_id(cls, option_set_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_option_set_by_id_with_http_info(option_set_id, **kwargs)\n        else:\n            (data) = cls._get_option_set_by_id_with_http_info(option_set_id, **kwargs)\n            return data", "response": "Find OptionSet by its ID Return single instance of OptionSet by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist OptionSets with the same attributes. This method returns a list of OptionSets with the same attributes.", "response": "def list_all_option_sets(cls, **kwargs):\n        \"\"\"List OptionSets\n\n        Return a list of OptionSets\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_option_sets(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[OptionSet]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_option_sets_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_option_sets_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplace all attributes of OptionSet by ID", "response": "def replace_option_set_by_id(cls, option_set_id, option_set, **kwargs):\n        \"\"\"Replace OptionSet\n\n        Replace all attributes of OptionSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_option_set_by_id(option_set_id, option_set, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_set_id: ID of optionSet to replace (required)\n        :param OptionSet option_set: Attributes of optionSet to replace (required)\n        :return: OptionSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_option_set_by_id_with_http_info(option_set_id, option_set, **kwargs)\n        else:\n            (data) = cls._replace_option_set_by_id_with_http_info(option_set_id, option_set, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates attributes of OptionSet by ID", "response": "def update_option_set_by_id(cls, option_set_id, option_set, **kwargs):\n        \"\"\"Update OptionSet\n\n        Update attributes of OptionSet\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_option_set_by_id(option_set_id, option_set, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_set_id: ID of optionSet to update. (required)\n        :param OptionSet option_set: Attributes of optionSet to update. (required)\n        :return: OptionSet\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_option_set_by_id_with_http_info(option_set_id, option_set, **kwargs)\n        else:\n            (data) = cls._update_option_set_by_id_with_http_info(option_set_id, option_set, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling comparing vCard fields where inputs are lists of components.", "response": "def VcardFieldsEqual(field1, field2):\n    \"\"\"Handle comparing vCard fields where inputs are lists of components.\n\n    Handle parameters?  Are any used aside from 'TYPE'?\n    Note: force cast to string to compare sub-objects like Name and Address\n    \"\"\"\n    field1_vals = set([ str(f.value) for f in field1 ])\n    field2_vals = set([ str(f.value) for f in field2 ])\n    if field1_vals == field2_vals:\n        return True\n    else:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles merging list fields that may include some overlap.", "response": "def VcardMergeListFields(field1, field2):\n    \"\"\"Handle merging list fields that may include some overlap.\"\"\"\n    field_dict = {}\n    for f in field1 + field2:\n        field_dict[str(f)] = f\n    return list(field_dict.values())"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset vCard field values and parameters on a new vCard.", "response": "def SetVcardField(new_vcard, field_name, values):\n    \"\"\"Set vCard field values and parameters on a new vCard.\"\"\"\n    for val in values:\n        new_field = new_vcard.add(field_name)\n        new_field.value = val.value\n        if val.params:\n            new_field.params = val.params\n    return new_vcard"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncopying vCard fields from an authoritative vCard into a new vCard.", "response": "def CopyVcardFields(new_vcard, auth_vcard, field_names):\n    \"\"\"Copy vCard field values from an authoritative vCard into a new one.\"\"\"\n    for field in field_names:\n        value_list = auth_vcard.contents.get(field)\n        new_vcard = SetVcardField(new_vcard, field, value_list)\n    return new_vcard"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new vCard and populate it with the values from one vCard and another.", "response": "def MergeVcards(vcard1, vcard2):\n    \"\"\"Create a new vCard and populate it.\"\"\"\n    new_vcard = vobject.vCard()\n    vcard1_fields = set(vcard1.contents.keys())\n    vcard2_fields = set(vcard2.contents.keys())\n    mutual_fields = vcard1_fields.intersection(vcard2_fields)\n    logger.debug('Potentially conflicting fields: {}'.format(mutual_fields))\n    for field in mutual_fields:\n        val1 = vcard1.contents.get(field)\n        val2 = vcard2.contents.get(field)\n        new_values = []\n        if not VcardFieldsEqual(val1, val2):\n            # we have a conflict, if a list maybe append otherwise prompt user\n            if field not in MERGEABLE_FIELDS:\n                context_str = GetVcardContextString(vcard1, vcard2)\n                new_values.extend(SelectFieldPrompt(field,\n                                                    context_str,\n                                                    val1,\n                                                    val2))\n            else:\n                new_values.extend(VcardMergeListFields(val1, val2))\n        else:\n            new_values.extend(val1)\n\n        logger.debug('Merged values for field {}: {}'.format(\n            field.upper(),\n            u(str(new_values)))\n        )\n        new_vcard = SetVcardField(new_vcard, field, new_values)\n\n    new_vcard = CopyVcardFields(new_vcard,\n                                vcard1,\n                                vcard1_fields - vcard2_fields)\n    new_vcard = CopyVcardFields(new_vcard,\n                                vcard2,\n                                vcard2_fields - vcard1_fields)\n\n    return new_vcard"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef SelectFieldPrompt(field_name, context_str, *options):\n    option_format_str = '[ {} ] \"{}\"'\n    option_dict = {}\n    print(context_str)\n    print('Please select one of the following options for field \"{}\"'.format(\n        field_name)\n    )\n    for cnt, option in enumerate(options):\n        option_dict['{}'.format(cnt + 1)] = option\n        if not callable(option):\n            print(option_format_str.format(cnt + 1, u(str(option))))\n        else:\n            print(option_format_str.format(cnt + 1, option.__name__))\n    choice = None\n    while choice not in option_dict:\n        choice = input('option> ').strip()\n    new_value = option_dict[choice]\n    if callable(new_value):\n        return new_value()\n    else:\n        return new_value", "response": "Prompts user to select from provided options."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a fixture for the given model_klass.", "response": "def make_fixture(model_class, **kwargs):\n    \"\"\"\n    Take the model_klass and generate a fixure for it\n\n    Args:\n        model_class (MongoEngine Document): model for which a fixture\n            is needed\n        kwargs (dict): any overrides instead of random values\n\n    Returns:\n        dict for now, other fixture types are not implemented yet\n    \"\"\"\n    all_fields = get_fields(model_class)\n\n    fields_for_random_generation = map(\n        lambda x: getattr(model_class, x), all_fields\n    )\n\n    overrides = {}\n\n    for kwarg, value in kwargs.items():\n        if kwarg in all_fields:\n            kwarg_field = getattr(model_class, kwarg)\n            fields_for_random_generation.remove(kwarg_field)\n            overrides.update({kwarg_field: value})\n\n    random_values = get_random_values(fields_for_random_generation)\n\n    values = dict(overrides, **random_values)\n\n    assert len(all_fields) == len(values), (\n        \"Mismatch in values, {} != {}\".format(\n            len(all_fields), len(values)\n        )\n    )\n    data = {k.name: v for k, v in values.items()}\n    return model_class(**data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_random_values(fields):\n    values = {}\n\n    for field in fields:\n        try:\n            value = get_random_value(field)\n        except AttributeError:\n            # this can only really occur if the field is not implemented yet.\n            # Silencing the exception during the prototype phase\n            value = None\n\n        values.update({field: value})\n\n    return values", "response": "Returns a dict with the randomly generated values for the specified fields."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if a bucket exists in the S3.", "response": "def head_bucket(self, name):\n        \"\"\"\n        Check if a bucket exists\n        :param name:\n        :return:\n        \"\"\"\n        try:\n            self.s3.head_bucket(Bucket=name)\n            info = self.s3.get_bucket_website(Bucket=self.sitename)\n            if not info:\n                return False, 404, \"Configure improrperly\"\n            return True, None, None\n        except botocore.exceptions.ClientError as e:\n            if e.response[\"Error\"][\"Code\"] in [\"403\", \"404\"]:\n                return False, e.response[\"Error\"][\"Code\"], e.response[\"Error\"][\"Message\"]\n            else:\n                raise e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all files that are in the manifest", "response": "def purge_files(self, exclude_files=[\"index.html\", \"error.html\"]):\n        \"\"\"\n        To delete files that are in the manifest\n        :param excludes_files: list : files to not delete\n        :return:\n        \"\"\"\n        for chunk in utils.chunk_list(self._get_manifest_data(), 1000):\n            try:\n                self.s3.delete_objects(\n                    Bucket=self.sitename,\n                    Delete={\n                        'Objects': [{\"Key\": f} for f in chunk\n                                    if f not in exclude_files]\n                    }\n                )\n            except Exception as ex:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a manifest db from the list of S3 files in the site.", "response": "def create_manifest_from_s3_files(self):\n        \"\"\"\n        To create a manifest db for the current\n        :return:\n        \"\"\"\n        for k in self.s3.list_objects(Bucket=self.sitename)['Contents']:\n            key = k[\"Key\"]\n            files = []\n            if key not in [self.manifest_file]:\n                files.append(key)\n            self._set_manifest_data(files)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_manifest_data(self, files_list):\n        if files_list:\n            data = \",\".join(files_list)\n            self.s3.put_object(Bucket=self.sitename,\n                               Key=self.manifest_file,\n                               Body=data,\n                               ACL='private')", "response": "Write manifest files to S3"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_manifest_data(self):\n        with tempfile.NamedTemporaryFile(delete=True) as tmp:\n            try:\n                self.s3.download_fileobj(self.sitename, self.manifest_file, tmp)\n                tmp.seek(0)\n                data = tmp.read()\n                if data is not None:\n                    return data.split(\",\")\n            except Exception as ex:\n                pass\n        return []", "response": "Get the list of items in the manifest file"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _yass_vars(self):\n        utc = arrow.utcnow()\n        return {\n            \"NAME\": __title__,\n            \"VERSION\": __version__,\n            \"URL\": __uri__,\n            \"GENERATOR\": \"%s %s\" % (__title__, __version__),\n            \"YEAR\": utc.year\n        }", "response": "Return a dictionary of global variables."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_page_meta(self, page):\n        meta = self._pages_meta.get(page)\n        if not meta:\n            src_file = os.path.join(self.pages_dir, page)\n            with open(src_file) as f:\n                _, _ext = os.path.splitext(src_file)\n                markup = _ext.replace(\".\", \"\")\n                _meta, _ = frontmatter.parse(f.read())\n                meta = self.default_page_meta.copy()\n                meta[\"meta\"].update(self.config.get(\"site.meta\", {}))\n                meta.update(_meta)\n                dest_file, url = self._get_dest_file_and_url(page, meta)\n                meta[\"url\"] = url\n                meta[\"filepath\"] = dest_file\n                if meta.get(\"markup\") is None:\n                    meta[\"markup\"] = markup\n                self._pages_meta[page] = meta\n\n        return meta", "response": "Get the page meta from the frontmatter and assign new keys\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_page_content(self, page):\n        src_file = os.path.join(self.pages_dir, page)\n        with open(src_file) as f:\n            _meta, content = frontmatter.parse(f.read())\n            return content", "response": "Get the content of a page without the frontmatter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild the A HREF LINK To a page.", "response": "def _link_to(self, page, text=None, title=None, _class=\"\", id=\"\", alt=\"\", **kwargs):\n        \"\"\" Build the A HREF LINK To a page.\"\"\"\n        anchor = \"\"\n        if \"#\" in page:\n            page, anchor = page.split(\"#\")\n            anchor = \"#\" + anchor\n        meta = self._get_page_meta(page)\n        return \"<a href='{url}' class='{_class}' id='{id}'  title=\\\"{title}\\\">{text}</a>\".format(\n            url=meta.get(\"url\", \"/\") + anchor,\n            text=text or meta.get(\"title\") or title,\n            title=title or \"\",\n            _class=_class,\n            id=id\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _url_to(self, page):\n        anchor = \"\"\n        if \"#\" in page:\n            page, anchor = page.split(\"#\")\n            anchor = \"#\" + anchor\n        meta = self._get_page_meta(page)\n        return meta.get(\"url\")", "response": "Get the url of a page"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_dest_file_and_url(self, filepath, page_meta={}):\n\n        filename = filepath.split(\"/\")[-1]\n        filepath_base = filepath.replace(filename, \"\").rstrip(\"/\")\n        slug = page_meta.get(\"slug\")\n        fname = slugify(slug) if slug else filename \\\n            .replace(\".html\", \"\") \\\n            .replace(\".md\", \"\") \\\n            .replace(\".jade\", \"\")\n\n        if page_meta.get(\"pretty_url\") is False:\n            dest_file = os.path.join(filepath_base, \"%s.html\" % fname)\n        else:\n            dest_dir = filepath_base\n            if filename not in [\"index.html\", \"index.md\", \"index.jade\"]:\n                dest_dir = os.path.join(filepath_base, fname)\n            dest_file = os.path.join(dest_dir, \"index.html\")\n\n        url = \"/\" + dest_file.replace(\"index.html\", \"\")\n        return dest_file, url", "response": "Return tuple of the file destination and url"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over the pages_dir and build the pages", "response": "def build_pages(self):\n        \"\"\"Iterate over the pages_dir and build the pages \"\"\"\n        for root, _, files in os.walk(self.pages_dir):\n            base_dir = root.replace(self.pages_dir, \"\").lstrip(\"/\")\n            if not base_dir.startswith(\"_\"):\n                for f in files:\n                    src_file = os.path.join(base_dir, f)\n                    self._build_page(src_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a single page from a file.", "response": "def _build_page(self, filepath):\n        \"\"\" To build from filepath, relative to pages_dir \"\"\"\n        filename = filepath.split(\"/\")[-1]\n        # If filename starts with _ (underscore) or . (dot) do not build\n        if not filename.startswith((\"_\", \".\")) and (filename.endswith(PAGE_FORMAT)):\n            meta = self._get_page_meta(filepath)\n            content = self._get_page_content(filepath)\n\n            # The default context for the page\n            _default_page = {\n                \"build_dir\": self.build_dir,\n                \"filepath\": meta[\"filepath\"],\n                \"context\": {\"page\": meta},\n                \"content\": content,\n                \"markup\": meta.get(\"markup\"),\n                \"template\": meta.get(\"template\"),\n                \"layout\": meta.get(\"layout\") or self.default_layout\n            }\n\n            # GENERATOR\n            # Allows to generate\n            _generator = meta.get(\"_generator\")\n            if _generator:\n                data = self._data.get(_generator.get(\"data_source\"))\n\n                # We want these back in meta in they exists in the data\n                special_meta = [\"title\", \"slug\", \"description\"]\n\n                # SINGLE\n                if _generator.get(\"type\") == \"single\":\n                    for d in data:\n                        dmeta = copy.deepcopy(meta)\n                        page = copy.deepcopy(_default_page)\n                        for _ in special_meta:\n                            if _ in d:\n                                dmeta[_] = d.get(_)\n\n                        # If generator has the slug, it will substitute if\n                        # Slug in the generator must have token from the data\n                        # to generate the slug\n                        if \"slug\" in _generator:\n                            dmeta[\"slug\"] = _generator.get(\"slug\").format(**d)\n\n                        # Slug is required\n                        if \"slug\" not in dmeta:\n                            print(\"WARNING: Skipping page because it's missing `slug`\")\n                            continue\n                        slug = dmeta.get(\"slug\")\n                        dmeta[\"url\"] = slug\n                        dmeta[\"context\"] = d\n\n                        page.update({\n                            \"filepath\": slug,\n                            \"context\": {\"page\": dmeta}\n                        })\n                        self.create_page(**page)\n\n                if _generator.get(\"type\") == \"pagination\":\n\n                    per_page = int(_generator.get(\"per_page\", self.site_config.get(\"pagination.per_page\", 10)))\n                    left_edge = int(_generator.get(\"left_edge\", self.site_config.get(\"pagination.left_edge\", 2)))\n                    left_current = int(_generator.get(\"left_edge\", self.site_config.get(\"pagination.left_current\", 3)))\n                    right_current = int(_generator.get(\"right_current\", self.site_config.get(\"pagination.right_current\", 4)))\n                    right_edge = int(_generator.get(\"right_edge\", self.site_config.get(\"pagination.right_edge\", 2)))\n                    padding = _generator.get(\"padding\")\n                    slug = _generator.get(\"slug\")\n                    limit = _generator.get(\"limit\")\n\n                    if \"limit\" in _generator:\n                        data = data[:int(limit)]\n                    data_chunks = utils.chunk_list(data, per_page)\n                    len_data = len(data)\n\n                    for i, d in enumerate(data_chunks):\n                        dmeta = copy.deepcopy(meta)\n                        page = copy.deepcopy(_default_page)\n\n                        page_num = i + 1\n                        _paginator = Paginator([],\n                                               total=len_data,\n                                               page=page_num,\n                                               per_page=per_page,\n                                               padding=padding,\n                                               left_edge=left_edge,\n                                               right_edge=right_edge,\n                                               left_current=left_current,\n                                               right_current=right_current)\n                        _paginator.slug = slug\n                        _paginator.index_slug = _generator.get(\"index_slug\")\n\n                        _slug = slug.format(**{\"page_num\": page_num})\n                        dmeta[\"url\"] = _slug\n                        dmeta[\"context\"] = d\n                        dmeta[\"paginator\"] = _paginator\n                        page.update({\n                            \"filepath\": _slug,\n                            \"context\": {\"page\": dmeta}\n                        })\n                        self.create_page(**page)\n\n                        # First page need to generate the index\n                        if i == 0 and _generator.get(\"index_slug\"):\n                            page[\"filepath\"] = _generator.get(\"index_slug\")\n                            self.create_page(**page)\n\n            # NORMAL PAGE\n            else:\n                self.create_page(**_default_page)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef publish(self, target=\"S3\", sitename=None, purge_files=True):\n        self.build()\n\n        endpoint = self.config.get(\"hosting.%s\" % target)\n        if target.upper() == \"S3\":\n            p = publisher.S3Website(sitename=sitename or self.config.get(\"sitename\"),\n                                    aws_access_key_id=endpoint.get(\"aws_access_key_id\"),\n                                    aws_secret_access_key=endpoint.get(\"aws_secret_access_key\"),\n                                    region=endpoint.get(\"aws_region\"))\n            if not p.website_exists:\n                if p.create_website() is True:\n                    # Need to give it enough time to create it\n                    # Should be a one time thing\n                    time.sleep(10)\n                    p.create_www_website()\n\n            p.create_manifest_from_s3_files()\n\n            if purge_files:\n                exclude_files = endpoint.get(\"purge_exclude_files\", [])\n                p.purge_files(exclude_files=exclude_files)\n\n            p.upload(self.build_dir)\n            return p.website_endpoint_url", "response": "Publishes the site and returns the url of the website that is published to the site."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new RefundTransaction", "response": "def create_refund_transaction(cls, refund_transaction, **kwargs):\n        \"\"\"Create RefundTransaction\n\n        Create a new RefundTransaction\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_refund_transaction(refund_transaction, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param RefundTransaction refund_transaction: Attributes of refundTransaction to create (required)\n        :return: RefundTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_refund_transaction_with_http_info(refund_transaction, **kwargs)\n        else:\n            (data) = cls._create_refund_transaction_with_http_info(refund_transaction, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes an instance of RefundTransaction by its ID.", "response": "def delete_refund_transaction_by_id(cls, refund_transaction_id, **kwargs):\n        \"\"\"Delete RefundTransaction\n\n        Delete an instance of RefundTransaction by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_refund_transaction_by_id(refund_transaction_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str refund_transaction_id: ID of refundTransaction to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_refund_transaction_by_id_with_http_info(refund_transaction_id, **kwargs)\n        else:\n            (data) = cls._delete_refund_transaction_by_id_with_http_info(refund_transaction_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind RefundTransaction by ID Return single instance of RefundTransaction by its ID.", "response": "def get_refund_transaction_by_id(cls, refund_transaction_id, **kwargs):\n        \"\"\"Find RefundTransaction\n\n        Return single instance of RefundTransaction by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_refund_transaction_by_id(refund_transaction_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str refund_transaction_id: ID of refundTransaction to return (required)\n        :return: RefundTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_refund_transaction_by_id_with_http_info(refund_transaction_id, **kwargs)\n        else:\n            (data) = cls._get_refund_transaction_by_id_with_http_info(refund_transaction_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlists Refund Transactions of a specific resource. This method returns a list of RefundTransactions with the specified resource ID.", "response": "def list_all_refund_transactions(cls, **kwargs):\n        \"\"\"List RefundTransactions\n\n        Return a list of RefundTransactions\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_refund_transactions(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[RefundTransaction]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_refund_transactions_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_refund_transactions_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef replace_refund_transaction_by_id(cls, refund_transaction_id, refund_transaction, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_refund_transaction_by_id_with_http_info(refund_transaction_id, refund_transaction, **kwargs)\n        else:\n            (data) = cls._replace_refund_transaction_by_id_with_http_info(refund_transaction_id, refund_transaction, **kwargs)\n            return data", "response": "Replace all attributes of RefundTransaction by ID"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating attributes of RefundTransaction by ID", "response": "def update_refund_transaction_by_id(cls, refund_transaction_id, refund_transaction, **kwargs):\n        \"\"\"Update RefundTransaction\n\n        Update attributes of RefundTransaction\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.update_refund_transaction_by_id(refund_transaction_id, refund_transaction, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str refund_transaction_id: ID of refundTransaction to update. (required)\n        :param RefundTransaction refund_transaction: Attributes of refundTransaction to update. (required)\n        :return: RefundTransaction\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_refund_transaction_by_id_with_http_info(refund_transaction_id, refund_transaction, **kwargs)\n        else:\n            (data) = cls._update_refund_transaction_by_id_with_http_info(refund_transaction_id, refund_transaction, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nextracts some meta - data from NIFTI files and stores it in a DB.", "response": "def nifti2db(file_path, file_type, is_copy, step_id, db_conn, sid_by_patient=False, pid_in_vid=False):\n    \"\"\"Extract some meta-data from NIFTI files (actually mostly from their paths) and stores it in a DB.\n\n    Arguments:\n    :param file_path: File path.\n    :param file_type: File type.\n    :param is_copy: Indicate if this file is a copy.\n    :param step_id: Step ID.\n    :param db_conn: Database connection.\n    :param sid_by_patient: Rarely, a data set might use study IDs which are unique by patient\n    (not for the whole study).\n    E.g.: LREN data. In such a case, you have to enable this flag. This will use PatientID + StudyID as a session ID.\n    :param pid_in_vid: Rarely, a data set might mix patient IDs and visit IDs. E.g. : LREN data. In such a case, you\n    to enable this flag. This will try to split PatientID into VisitID and PatientID.\n    :return:\n    \"\"\"\n    logging.info(\"Processing '%s'\" % file_path)\n\n    df = db_conn.db_session.query(db_conn.DataFile).filter_by(path=file_path).one_or_none()\n\n    dataset = db_conn.get_dataset(step_id)\n    _extract_participant(db_conn, file_path, pid_in_vid, dataset)\n    visit_id = _extract_visit(db_conn, file_path, pid_in_vid, sid_by_patient, dataset)\n    session_id = _extract_session(db_conn, file_path, visit_id)\n    sequence_id = _extract_sequence(db_conn, file_path, session_id)\n    repetition_id = _extract_repetition(db_conn, file_path, sequence_id)\n\n    if not df:\n        df = db_conn.DataFile(\n            path=file_path,\n            type=file_type,\n            is_copy=is_copy,\n            processing_step_id=step_id,\n            repetition_id=repetition_id\n        )\n        db_conn.db_session.merge(df)\n        db_conn.db_session.commit()\n    else:\n        if file_type not in [None, '', df.type]:\n            df.type = file_type\n            db_conn.db_session.commit()\n        if is_copy not in [None, df.is_copy]:\n            df.is_copy = is_copy\n            db_conn.db_session.commit()\n        if step_id not in [None, df.processing_step_id]:\n            df.processing_step_id = step_id\n            db_conn.db_session.commit()\n        if repetition_id not in [None, df.repetition_id]:\n            df.repetition_id = repetition_id\n            db_conn.db_session.commit()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_skos_registry(registry):\n    '''\n    Get the :class:`skosprovider.registry.Registry` attached to this pyramid\n    application.\n\n    :rtype: :class:`skosprovider.registry.Registry`\n    '''\n    # Argument might be a config or request\n    regis = getattr(registry, 'registry', None)\n    if regis is None:\n        regis = registry\n    return regis.queryUtility(ISkosRegistry)", "response": "Get the skosprovider. registry. Registry attached to this pyramid\n    application."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsorts a list of matches best to worst", "response": "def sort_matches(matches):\n    '''Sorts a ``list`` of matches best to worst'''\n    multipliers = {'exact':10**5,'fname':10**4,'fuzzy':10**2,'fuzzy_fragment':1}\n    matches = [(multipliers[x.type]*(x.amount if x.amount else 1),x) for x in matches]\n    return [x[1] for x in sorted(matches,reverse=True)]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef matches(self,string,fuzzy=90,fname_match=True,fuzzy_fragment=None,guess=False):\n        '''Returns whether this :class:`Concept` matches ``string``'''\n        \n        matches = []\n        for item in self.examples:\n            m = best_match_from_list(string,self.examples[item],fuzzy,fname_match,fuzzy_fragment,guess)\n            if m:\n                match = ConceptMatch(self)\n                match.concept = self\n                match.string = string\n                match.item = item\n                match.examples = m[0]\n                match.type = m[2]\n                match.amount = m[3]\n                matches.append(match)\n        return sort_matches(matches)", "response": "Returns whether this Concept matches string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_action(self,concept_name,action_meth):\n        '''helper function to set the ``action`` attr of any :class:`Concept`s in ``self.vocab`` that match ``concept_name`` to ``action_meth``'''\n        for concept in self.vocab:\n            if concept.name == concept_name:\n                concept.action = action_meth", "response": "helper function to set the action attribute of any : class : Concepts in self. vocab that match concept_name to action_meth"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning sorted list of all concept s matching string", "response": "def match_all_concepts(self,string):\n        '''Returns sorted list of all :class:`Concept`s matching ``string``'''\n        multipliers = {'exact':10**5,'fname':10**4,'fuzzy':10**2,'fuzzy_fragment':1}\n        matches = []\n        for concept in self.vocab:\n            matches += concept.matches(string,self.fuzzy,self.fname_match,self.fuzzy_fragment,self.guess)\n        return sort_matches(matches)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef match_concept(self,string):\n        '''Find all matches in this :class:`Bottle` for ``string`` and return the best match'''\n        matches = self.match_all_concepts(string)\n        if len(matches)>0:\n            return matches[0]\n        return None", "response": "Find all matches in this : class : Bottle for string and return the best match"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a string and returns a list of concepts that match each word to a concept. If best is True will only return the top matches.", "response": "def parse_string(self,string,best=False):\n        '''Parses ``string`` trying to match each word to a :class:`Concept`. If ``best``, will only return the top matches'''\n        if isinstance(string,list):\n            items = string\n        else:\n            items = string.split()\n        item_list = []\n        not_next = False\n        for item in items:\n            if self.negative:\n                if item=='not':\n                    not_next = True\n                    continue\n                if item[0]=='-':\n                    not_next = True\n                    item = item[1:]\n            concepts = self.match_all_concepts(item)\n            if len(concepts)>0:\n                if not_next:\n                    for concept in concepts:\n                        concept.negative = True\n                if best:\n                    item_list.append(concepts[0])\n                else:\n                    item_list.append(concepts)\n            else:\n                item_list.append(item)\n            not_next = False\n        return item_list"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_string(self,string):\n        '''Searches the string (or list of strings) for an action word (a :class:`Concept` that has and ``action`` attached\n        to it), then calls the appropriate function with a dictionary of the identified words (according to ``vocab``).\n        \n        For examples, see ``demo.py``\n        '''\n        item_list = self.parse_string(string)\n        for item in item_list:\n            if len(item)>0 and 'concept' in dir(item[0]) and 'action' in dir(item[0].concept) and item[0].concept.action:\n                item[0].concept.action(item_list)", "response": "Searches the string and calls the appropriate function with a dictionary of the identified words."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef all(self):\n        response = requests.get(self._url, **self._default_request_kwargs)\n        data = self._get_response_data(response)\n        return self._concrete_instance_list(data)", "response": "Returns a list of all ObjectRocket instances that the current client has access to."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, name, plan, zone,\n               service_type='mongodb', instance_type='mongodb_sharded', version='2.4.6'):\n        \"\"\"Create an ObjectRocket instance.\n\n        :param str name: The name to give to the new instance.\n        :param int plan: The plan size of the new instance.\n        :param str zone: The zone that the new instance is to exist in.\n        :param str service_type: The type of service that the new instance is to provide.\n        :param str instance_type: The instance type to create.\n        :param str version: The version of the service the new instance is to provide.\n        \"\"\"\n        # Build up request data.\n        url = self._url\n        request_data = {\n            'name': name,\n            'service': service_type,\n            'plan': plan,\n            'type': instance_type,\n            'version': version,\n            'zone': zone\n        }\n\n        # Call to create an instance.\n        response = requests.post(\n            url,\n            data=json.dumps(request_data),\n            **self._default_request_kwargs\n        )\n\n        # Log outcome of instance creation request.\n        if response.status_code == 200:\n            logger.info('Successfully created a new instance with: {}'.format(request_data))\n        else:\n            logger.info('Failed to create instance with: {}'.format(request_data))\n            logger.info('Response: [{0}] {1}'.format(response.status_code, response.content))\n\n        data = self._get_response_data(response)\n        return self._concrete_instance(data)", "response": "Create an ObjectRocket instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves an object rocket instance by name.", "response": "def get(self, instance_name):\n        \"\"\"Get an ObjectRocket instance by name.\n\n        :param str instance_name: The name of the instance to retrieve.\n        :returns: A subclass of :py:class:`bases.BaseInstance`, or None if instance does not exist.\n        :rtype: :py:class:`bases.BaseInstance`\n        \"\"\"\n        url = self._url + instance_name + '/'\n        response = requests.get(url, **self._default_request_kwargs)\n        data = self._get_response_data(response)\n        return self._concrete_instance(data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _concrete_instance(self, instance_doc):\n        if not isinstance(instance_doc, dict):\n            return None\n\n        # Attempt to instantiate the appropriate class for the given instance document.\n        try:\n            service = instance_doc['service']\n            cls = self._service_class_map[service]\n            return cls(instance_document=instance_doc, instances=self)\n\n        # If construction fails, log the exception and return None.\n        except Exception as ex:\n            logger.exception(ex)\n            logger.error(\n                'Instance construction failed. You probably need to upgrade to a more '\n                'recent version of the client. Instance document which generated this '\n                'warning: {}'.format(instance_doc)\n            )\n            return None", "response": "Concretizes an instance document."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the plugin with the specified name.", "response": "def load_plugin_by_name(name):\n    \"\"\"\n    Load the plugin with the specified name.\n    \n    >>> plugin = load_plugin_by_name('default')\n    >>> api = dir(plugin)\n    >>> 'build_package' in api\n    True\n    >>> 'get_version' in api\n    True\n    >>> 'set_package_version' in api\n    True\n    >>> 'set_version' in api\n    True\n    \"\"\"\n    plugins = load(PLUGIN_NAMESPACE)\n    full_name = \"%s.%s\" % (PLUGIN_NAMESPACE, name)\n    try:\n        plugins = (plugin for plugin in plugins if plugin.__name__ == full_name)\n        plugin = next(plugins)\n        return plugin\n    except StopIteration:\n        raise UnknownPlugin([plugin.__name__.split('.').pop() for plugin in plugins])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, name):\n        path = self._get_cluster_storage_path(name)\n\n        try:\n            with open(path, 'r') as storage:\n                cluster = self.load(storage)\n                # Compatibility with previous version of Node\n                for node in sum(cluster.nodes.values(), []):\n                    if not hasattr(node, 'ips'):\n                        log.debug(\"Monkey patching old version of `Node` class: %s\", node.name)\n                        node.ips = [node.ip_public, node.ip_private]\n                        node.preferred_ip = None\n                cluster.storage_file = path\n                return cluster\n        except IOError as ex:\n            raise ClusterNotFound(\"Error accessing storage file %s: %s\" % (path, ex))", "response": "Retrieves the cluster with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_or_update(self, cluster):\n        if not os.path.exists(self.storage_path):\n            os.makedirs(self.storage_path)\n\n        path = self._get_cluster_storage_path(cluster.name)\n        cluster.storage_file = path\n        with open(path, 'wb') as storage:\n            self.dump(cluster, storage)", "response": "Save or update the cluster to persistent state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an instance of the correct DiskRepository based on the first file that matches the standard syntax for repository files", "response": "def _get_store_by_name(self, name):\n        \"\"\"Return an instance of the correct DiskRepository based on the *first* file that matches the standard syntax for repository files\"\"\"\n        for cls in self.storage_type_map.values():\n            cluster_files = glob.glob(\n                '%s/%s.%s' % (self.storage_path, name, cls.file_ending))\n            if cluster_files:\n                try:\n                    return cls(self.storage_path)\n                except:\n                    continue\n        raise ClusterNotFound(\"No cluster %s was found\" % name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a QTextCharFormat with the given attributes.", "response": "def _format(color, style=''):\r\n    \"\"\"Return a QTextCharFormat with the given attributes.\r\n    \"\"\"\r\n    _color = QColor()\r\n    _color.setNamedColor(color)\r\n\r\n    _format = QTextCharFormat()\r\n    _format.setForeground(_color)\r\n    if 'bold' in style:\r\n        _format.setFontWeight(QFont.Bold)\r\n    if 'italic' in style:\r\n        _format.setFontItalic(True)\r\n\r\n    return _format"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef highlightBlock(self, text):\r\n        # Do other syntax formatting\r\n        for expression, nth, format in self.rules:\r\n            index = expression.indexIn(text, 0)\r\n\r\n            while index >= 0:\r\n                # We actually want the index of the nth match\r\n                index = expression.pos(nth)\r\n                length = len(expression.cap(nth))\r\n                self.setFormat(index, length, format)\r\n                index = expression.indexIn(text, index + length)\r\n\r\n        self.setCurrentBlockState(0)\r\n\r\n        # Do multi-line strings\r\n        in_multiline = self.match_multiline(text, *self.tri_single)\r\n        if not in_multiline:\r\n            in_multiline = self.match_multiline(text, *self.tri_double)", "response": "Apply syntax highlighting to the given block of text."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef match_multiline(self, text, delimiter, in_state, style):\r\n        # If inside triple-single quotes, start at 0\r\n        if self.previousBlockState() == in_state:\r\n            start = 0\r\n            add = 0\r\n        # Otherwise, look for the delimiter on this line\r\n        else:\r\n            start = delimiter.indexIn(text)\r\n            # Move past this match\r\n            add = delimiter.matchedLength()\r\n\r\n        # As long as there's a delimiter match on this line...\r\n        while start >= 0:\r\n            # Look for the ending delimiter\r\n            end = delimiter.indexIn(text, start + add)\r\n            # Ending delimiter on this line?\r\n            if end >= add:\r\n                length = end - start + add + delimiter.matchedLength()\r\n                self.setCurrentBlockState(0)\r\n            # No; multi-line string\r\n            else:\r\n                self.setCurrentBlockState(in_state)\r\n                length = len(text) - start + add\r\n            # Apply formatting\r\n            self.setFormat(start, length, style)\r\n            # Look for the next match\r\n            start = delimiter.indexIn(text, start + length)\r\n\r\n        # Return True if still inside a multi-line string, False otherwise\r\n        if self.currentBlockState() == in_state:\r\n            return True\r\n        else:\r\n            return False", "response": "Match a multi - line string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __import_pem(self, key_name, pem_file_path, password):\n        key_import = self.__get_function_or_ex_function('import_key_pair_from_file')\n        pem_file = os.path.expandvars(os.path.expanduser(pem_file_path))\n        try:\n            pem = paramiko.RSAKey.from_private_key_file(pem_file, password)\n        except SSHException:\n            try:\n                pem = paramiko.DSSKey.from_private_key_file(pem_file, password)\n            except SSHException as e:\n                raise KeypairError('could not import {f}, neither as RSA key nor as DSA key: {e}'\n                                   .format(f=pem_file_path, e=e))\n        if not pem:\n            raise KeypairError('could not import {f}'.format(f=pem_file_path))\n        else:\n            with NamedTemporaryFile('w+t') as f:\n                f.write('{n} {p}'.format(n=pem.get_name(), p=pem.get_base64()))\n                key_import(name=key_name, key_file_path=f.name)", "response": "Import PEM certificate with provider"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_function_by_pattern(self, pattern):\n        function_names = [name for name in dir(self.driver) if pattern in name]\n        if function_names:\n            name = function_names[0]\n            if len(function_names) > 1:\n                log.warn(\n                    \"Several functions match pattern `%s`: %r -- using first one!\",\n                    pattern, function_names)\n            return getattr(self.driver, name)\n        else:\n            # no such function\n            raise AttributeError(\n                \"No function name contains `{0}` in class `{1}`\"\n                .format(pattern, self.__class__.__name__))", "response": "Return first function that contains the string pattern."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a function or extended function based on the given function name.", "response": "def __get_function_or_ex_function(self, func_name):\n        \"\"\"\n        Check if a function (or an 'extended' function) exists for a key on a driver, and if it does, return it.\n        :param func_name: name of the function\n        :return: a callable or none\n        \"\"\"\n        # try function name as given\n        try:\n            return getattr(self.driver, func_name)\n        except AttributeError:\n            pass\n        # try prefixing name with `ex_`\n        try:\n            return getattr(self.driver, 'ex_' + func_name)\n        except AttributeError:\n            pass\n        # no such function\n        raise AttributeError(\n            \"No function named `{0}` or `{1}` in class `{2}`\"\n            .format(func_name, 'ex_'+func_name, self.__class__.__name__))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __pop_driver_auth_args(**kwargs):\n        if 'username' in kwargs:\n            return [kwargs.pop('username'), kwargs.pop('password')]\n        elif 'access_token' in kwargs:\n            return kwargs.pop('access token')\n        elif 'access_id' in kwargs:\n            return kwargs.pop('access_id'), kwargs.pop('secret_key')\n        elif 'service_account_email' in kwargs:\n            return [kwargs.pop('service_account_email'), kwargs.pop('pem_file')]\n        elif 'client_id' in kwargs:\n            return [kwargs.pop('client_id'), kwargs.pop('client_secret')]\n        return None", "response": "Try to construct the arguments that should be passed as initialization of a driver s authentication class."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dict(cls, D, is_json=False):\n        '''This factory for :class:`Model`\n        takes either a native Python dictionary or a JSON dictionary/object\n        if ``is_json`` is ``True``. The dictionary passed does not need to\n        contain all of the values that the Model declares.\n\n        '''\n        instance = cls()\n        instance.set_data(D, is_json=is_json)\n        return instance", "response": "This factory for Model objects takes either a native Python dictionary or a JSON dictionary and returns a new instance of this class."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary representing the data of the class.", "response": "def to_dict(self, serial=False):\n        '''A dictionary representing the the data of the class is returned.\n        Native Python objects will still exist in this dictionary (for example,\n        a ``datetime`` object will be returned rather than a string)\n        unless ``serial`` is set to True.\n\n        '''\n        if serial:\n            return dict((key, self._fields[key].to_serial(getattr(self, key)))\n                        for key in list(self._fields.keys()) if hasattr(self, key))\n        else:\n            return dict((key, getattr(self, key)) for key in list(self._fields.keys())\n                       if hasattr(self, key))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports a single object from a string.", "response": "def import_from_string(path, slient=True):\n    \"\"\"\n    \u6839\u636e\u7ed9\u5b9a\u7684\u5bf9\u8c61\u8def\u5f84\uff0c\u52a8\u6001\u52a0\u8f7d\u5bf9\u8c61\u3002\n    \"\"\"\n    names = path.split(\".\")\n    for i in range(len(names), 0, -1):\n        p1 = \".\".join(names[0:i])\n        module = import_module(p1)\n        if module:\n            p2 = \".\".join(names[i:])\n            if p2:\n                return select(module, p2, slient=slient)\n            else:\n                return module\n    name = names[0]\n    names = names[1:]\n    module = get_caller_locals().get(name)\n    if module and names:\n        return select(module, \".\".join(names), slient=slient)\n    if module:\n        return module\n    module = get_caller_globals().get(name)\n    if module and names:\n        return select(module, \".\".join(names), slient=slient)\n    if module:\n        return module\n    if slient:\n        return None\n    else:\n        raise ImportError(\"Import {path} failed.\".format(path=path))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_search_url(url):\n\n    config = {}\n\n    url = urlparse.urlparse(url)\n\n    # Remove query strings.\n    path = url.path[1:]\n    path = path.split('?', 2)[0]\n\n    if url.scheme in SEARCH_SCHEMES:\n        config[\"ENGINE\"] = SEARCH_SCHEMES[url.scheme]\n\n    if url.scheme in USES_URL:\n        config[\"URL\"] = urlparse.urlunparse((\"http\",) + url[1:])\n\n    if url.scheme in USES_INDEX:\n        if path.endswith(\"/\"):\n            path = path[:-1]\n\n        split = path.rsplit(\"/\", 1)\n\n        if len(split) > 1:\n            path = split[:-1]\n            index = split[-1]\n        else:\n            path = \"\"\n            index = split[0]\n\n        config.update({\n            \"URL\": urlparse.urlunparse((\"http\",) + url[1:2] + (path,) + url[3:]),\n            \"INDEX_NAME\": index,\n        })\n\n    if url.scheme in USES_PATH:\n        config.update({\n            \"PATH\": path,\n        })\n\n    return config", "response": "Parses a search URL and returns a dictionary of configuration parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns configured SEARCH dictionary from SEARCH_URL", "response": "def config(name='SEARCH_URL', default='simple://'):\n    \"\"\"Returns configured SEARCH dictionary from SEARCH_URL\"\"\"\n    config = {}\n\n    s = env(name, default)\n\n    if s:\n        config = parse_search_url(s)\n\n    return config"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the given nonterm is valid.", "response": "def _control_nonterminal(nonterm):\n        # type: (Type[Nonterminal]) -> None\n        \"\"\"\n        Check if the nonterminal is valid.\n        :param nonterm: Nonterminal to check.\n        :raise NotNonterminalException: If the object doesn't inherit from Nonterminal class.\n        \"\"\"\n        if not inspect.isclass(nonterm) or not issubclass(nonterm, Nonterminal):\n            raise NotNonterminalException(nonterm)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd the given nonterminals into the set.", "response": "def add(self, *nonterminals):\n        # type: (Iterable[Type[Nonterminal]]) -> None\n        \"\"\"\n        Add nonterminals into the set.\n        :param nonterminals: Nonterminals to insert.\n        :raise NotNonterminalException: If the object doesn't inherit from Nonterminal class.\n        \"\"\"\n        for nonterm in nonterminals:\n            if nonterm in self:\n                continue\n            _NonterminalSet._control_nonterminal(nonterm)\n            super().add(nonterm)\n            self._assign_map[nonterm] = set()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the specified nonterminals from the set.", "response": "def remove(self, *nonterminals):\n        # type: (Iterable[Type[Nonterminal]]) -> None\n        \"\"\"\n        Remove nonterminals from the set.\n        Removes also rules using this nonterminal.\n        Set start symbol to None if deleting nonterminal is start symbol at the same time.\n        :param nonterminals: Nonterminals to remove.\n        \"\"\"\n        for nonterm in set(nonterminals):\n            _NonterminalSet._control_nonterminal(nonterm)\n            if nonterm not in self:\n                raise KeyError('Nonterminal ' + nonterm.__name__ + ' is not inside')\n            self._grammar.rules.remove(*self._assign_map[nonterm], _validate=False)\n            del self._assign_map[nonterm]\n            if self._grammar.start is nonterm:\n                del self._grammar.start\n            super().remove(nonterm)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwash the complete form based on the specification in content.", "response": "def wash_urlargd(form, content):\n    \"\"\"Wash the complete form based on the specification in content.\n\n    Content is a dictionary containing the field names as a\n    key, and a tuple (type, default) as value.\n\n    'type' can be list, unicode, legacy.wsgi.utils.StringField, int,\n    tuple, or legacy.wsgi.utils.Field (for file uploads).\n\n    The specification automatically includes the 'ln' field, which is\n    common to all queries.\n\n    Arguments that are not defined in 'content' are discarded.\n\n    .. note::\n\n        In case `list` or `tuple` were asked for, we assume that\n        `list` or `tuple` of strings is to be returned.  Therefore beware when\n        you want to use ``wash_urlargd()`` for multiple file upload forms.\n\n    :returns: argd dictionary that can be used for passing function\n        parameters by keywords.\n    \"\"\"\n    result = {}\n\n    for k, (dst_type, default) in content.items():\n        try:\n            value = form[k]\n        except KeyError:\n            result[k] = default\n            continue\n\n        src_type = type(value)\n\n        # First, handle the case where we want all the results. In\n        # this case, we need to ensure all the elements are strings,\n        # and not Field instances.\n        if src_type in (list, tuple):\n            if dst_type is list:\n                result[k] = [x for x in value]\n                continue\n\n            if dst_type is tuple:\n                result[k] = tuple([x for x in value])\n                continue\n\n            # in all the other cases, we are only interested in the\n            # first value.\n            value = value[0]\n\n        # Allow passing argument modyfing function.\n        if isinstance(dst_type, types.FunctionType):\n            result[k] = dst_type(value)\n            continue\n\n        # Maybe we already have what is expected? Then don't change\n        # anything.\n        if isinstance(value, dst_type):\n            result[k] = value\n            continue\n\n        # Since we got here, 'value' is sure to be a single symbol,\n        # not a list kind of structure anymore.\n        if dst_type in (int, float, long, bool):\n            try:\n                result[k] = dst_type(value)\n            except:\n                result[k] = default\n\n        elif dst_type is tuple:\n            result[k] = (value, )\n\n        elif dst_type is list:\n            result[k] = [value]\n\n        else:\n            raise ValueError(\n                'cannot cast form value %s of type %r into type %r' % (\n                    value, src_type, dst_type))\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstrips non - alphabetic or newline characters from a given string.", "response": "def wash_html_id(dirty):\n    \"\"\"Strip non-alphabetic or newline characters from a given string.\n\n    It can be used as a HTML element ID (also with jQuery and in all browsers).\n\n    :param dirty: the string to wash\n    :returns: the HTML ID ready string\n    \"\"\"\n    import re\n    if not dirty[0].isalpha():\n        # we make sure that the first character is a lowercase letter\n        dirty = 'i' + dirty\n    non_word = re.compile(r'[^\\w]+')\n    return non_word.sub('', dirty)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nquote this post. Parameters ---------- text : str Text to quote. Defaults to the whole text of the post. Returns ------- str A NationStates bbCode quote of the post.", "response": "def quote(self, text=None):\n        \"\"\"Quote this post.\n\n        Parameters\n        ----------\n        text : str\n            Text to quote.  Defaults to the whole text of the post.\n\n        Returns\n        -------\n        str\n            A NationStates bbCode quote of the post.\n        \"\"\"\n        text = text or re.sub(r'\\[quote=.+?\\[/quote\\]', '',\n                              self.text, flags=re.DOTALL\n                              ).strip('\\n')\n        return f'[quote={self.author.id};{self.id}]{text}[/quote]'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def factbook(self, root):\n        # This lib might have been a mistake, but the line below\n        # definitely isn't.\n        return html.unescape(html.unescape(root.find('FACTBOOK').text))", "response": "Region s World Factbook Entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def delegate(self, root):\n        nation = root.find('DELEGATE').text\n        if nation == '0':\n            return None\n        return aionationstates.Nation(nation)", "response": "Regional World Assembly Delegate."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def officers(self, root):\n        officers = sorted(\n            root.find('OFFICERS'),\n            # I struggle to say what else this tag would be useful for.\n            key=lambda elem: int(elem.find('ORDER').text)\n        )\n        return [Officer(elem) for elem in officers]", "response": "Returns a list of all officers in the Regional."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\niterate through the RMB posts from newest to oldest.", "response": "async def messages(self):\n        \"\"\"Iterate through RMB posts from newest to oldest.\n\n        Returns\n        -------\n        an asynchronous generator that yields :class:`Post`\n        \"\"\"\n        # Messages may be posted on the RMB while the generator is running.\n        oldest_id_seen = float('inf')\n        for offset in count(step=100):\n            posts_bunch = await self._get_messages(offset=offset)\n            for post in reversed(posts_bunch):\n                if post.id < oldest_id_seen:\n                    yield post\n            oldest_id_seen = posts_bunch[0].id\n            if len(posts_bunch) < 100:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef accumulate_items(items, reduce_each=False):\n\n    if not items:\n        return {}\n\n    accumulated = defaultdict(list)\n    for key, val in items:\n        accumulated[key].append(val)\n\n    if not reduce_each:\n        return accumulated\n    else:\n        return {k: reduce_value(v, v) for k, v in iteritems(accumulated)}", "response": "accumulates items under duplicate keys"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setdefaults(d, defaults):\n\n    if not isinstance(d, dict) or defaults is None:\n        return d\n    elif isinstance(defaults, _wrap_types):\n        return setdefaults(d, [defaults])  # Wrap in list for consistent behavior\n\n    use_none = not any(isinstance(s, dict) for s in defaults)\n\n    # Accumulate (current, remaining) pairs to be applied to d\n\n    accumulated = {}\n    for current, remaining in _to_key_val_pairs(defaults):\n        accumulated.setdefault(current, [])\n        if remaining is not None:\n            accumulated[current].append(remaining)\n\n    # Update d with accumulated pairs, handling further nested dot-notated keys\n\n    for current, remaining in iteritems(accumulated):\n        if use_none:\n\n            # Apply None value for what remains of the dot notated key\n            defaults = setdefaults(d.get(current, {}), remaining) if remaining else None\n            if defaults and isinstance(d.get(current), dict):\n                d[current].update(defaults)\n            else:\n                d.setdefault(current, defaults)\n\n        else:\n            next_up = remaining[0] if remaining else None\n\n            if '.' in current:\n                # Split on the dot and process next segment\n                k, s = current.split('.', 1)\n                d.setdefault(k, {})\n                setdefaults(d[k], [{s: next_up}])\n            elif isinstance(next_up, STRING_TYPES):\n                # Set a string value directly\n                d.setdefault(current, next_up)\n            else:\n                # Process a dict value or just set to the value in next_up\n                d.setdefault(current, setdefaults({}, remaining) or next_up)\n\n    return d", "response": "Set the value of the key - value pairs in a dict d to the values of the defaults."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of items that are empty.", "response": "def filter_empty(values, default=None):\n    \"\"\"\n    Eliminates None or empty items from lists, tuples or sets passed in.\n    If values is None or empty after filtering, the default is returned.\n    \"\"\"\n\n    if values is None:\n        return default\n    elif hasattr(values, '__len__') and len(values) == 0:\n        return default\n    elif hasattr(values, '__iter__') and not isinstance(values, _filtered_types):\n        filtered = type(values) if isinstance(values, _filter_types) else list\n        values = filtered(\n            v for v in values if not (v is None or (hasattr(v, '__len__') and len(v) == 0))\n        )\n        return default if len(values) == 0 else values\n\n    return values"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef flatten_items(items, recurse=False):\n\n    if not items:\n        return items\n    elif not hasattr(items, '__iter__'):\n        return items\n    elif isinstance(items, _flattened_types):\n        return items\n\n    flattened = []\n    for item in items:\n        if item and hasattr(item, '__iter__') and not isinstance(item, _flattened_types):\n            flattened.extend(flatten_items(item, True) if recurse else item)\n        else:\n            flattened.append(item)\n\n    return type(items)(flattened) if isinstance(items, _flatten_types) else flattened", "response": "Flatten nested lists of items so that each element extends its parent."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a unique ordered list tuple or string depending on the type of items.", "response": "def remove_duplicates(items, in_reverse=False, is_unhashable=False):\n    \"\"\"\n    With maximum performance, iterate over items and return unique ordered values.\n    :param items: an iterable of values: lists, tuples, strings, or generator\n    :param in_reverse: if True, iterate backwards to remove initial duplicates (less performant)\n    :param is_unhashable: if False, use a set to track duplicates; otherwise a list (less performant)\n    :return: a unique ordered list, tuple or string depending on the type of items\n    \"\"\"\n\n    if not items:\n        return items\n    elif isinstance(items, _removed_dup_types):\n        return items\n    elif not hasattr(items, '__iter__') and not hasattr(items, '__getitem__'):\n        return items\n\n    _items = items\n    if in_reverse:\n        subscriptable = hasattr(items, '__getitem__')\n        _items = items[::-1] if subscriptable else reversed([i for i in items])\n\n    is_unhashable &= not isinstance(items, STRING_TYPES)\n    buffer = list() if is_unhashable else set()\n    append = buffer.append if is_unhashable else buffer.add\n\n    if not isinstance(items, _remove_dup_types):\n        # The fastest case: handles lists (33% of other cases) and generators (25%)\n        unique = [i for i in _items if i not in buffer and not append(i)]\n    elif isinstance(items, tuple):\n        unique = tuple(i for i in _items if i not in buffer and not append(i))\n    elif isinstance(items, string_types):\n        unique = EMPTY_STR.join(i for i in _items if i not in buffer and not append(i))\n    else:\n        # Python 3 compliance: for bytearrays, convert integers back to bytes during iteration\n        unique = EMPTY_BIN.join(bytes([i]) for i in _items if i not in buffer and not append(i))\n\n    return unique if not in_reverse else unique[::-1]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the index in values where value is found or - 1 if no such index is found", "response": "def rfind(values, value):\n    \"\"\" :return: the highest index in values where value is found, or -1 \"\"\"\n\n    if isinstance(values, STRING_TYPES):\n        try:\n            return values.rfind(value)\n        except TypeError:\n            # Python 3 compliance: search for str values in bytearray\n            return values.rfind(type(values)(value, DEFAULT_ENCODING))\n    else:\n        try:\n            return len(values) - 1 - values[::-1].index(value)\n        except (TypeError, ValueError):\n            return -1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the index in values where value is found else raise ValueError", "response": "def rindex(values, value):\n    \"\"\" :return: the highest index in values where value is found, else raise ValueError \"\"\"\n\n    if isinstance(values, STRING_TYPES):\n        try:\n            return values.rindex(value)\n        except TypeError:\n            # Python 3 compliance: search for str values in bytearray\n            return values.rindex(type(values)(value, DEFAULT_ENCODING))\n    else:\n        return len(values) - 1 - values[::-1].index(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreduce a value to a single value from lists tuples or sets with one item ; return the default if it is empty.", "response": "def reduce_value(value, default=EMPTY_STR):\n    \"\"\"\n    :return: a single value from lists, tuples or sets with one item;\n    otherwise, the value itself if not empty or the default if it is.\n    \"\"\"\n\n    if hasattr(value, '__len__'):\n        vlen = len(value)\n\n        if vlen == 0:\n            return default\n        elif vlen == 1:\n            if isinstance(value, set):\n                return value.pop()\n            elif isinstance(value, _reduce_types):\n                return value[0]\n\n    return default if value is None else value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping a value in a list if it is already iterable.", "response": "def wrap_value(value, include_empty=False):\n    \"\"\"\n    :return: the value wrapped in a list unless it is already iterable (and not a dict);\n    if so, empty values will be filtered out by default, and an empty list is returned.\n    \"\"\"\n\n    if value is None:\n        return [None] if include_empty else []\n    elif hasattr(value, '__len__') and len(value) == 0:\n        return [value] if include_empty else []\n    elif isinstance(value, _wrap_types):\n        return [value]\n    elif not hasattr(value, '__iter__'):\n        return [value]\n\n    return value if include_empty else filter_empty(value, [])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef unit(self, unit):\n        allowed_values = [\"cm\", \"inch\", \"foot\"]  # noqa: E501\n        if unit is not None and unit not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `unit` ({0}), must be one of {1}\"  # noqa: E501\n                .format(unit, allowed_values)\n            )\n\n        self._unit = unit", "response": "Sets the unit of this Dimensions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef ZernikeSequence(x,y,maxRadial=5,epsilon=1e-10):\n    if maxRadial>5:\n        raise ValueError('Code for higher radial orders not implemented')\n    # Derive radius and exp(i*theta) \n    temp = x + 1j*y\n    r1 = np.abs(temp)\n    e1 = temp/(r1+epsilon)\n     # Generate powers of r recursively\n    r2 = r1*r1\n    r3 = r2*r1\n    r4 = r3*r1\n    r5 = r4*r1\n    # Generate cos and sin terms recursively from exp(i*theta)\n    e2 = e1*e1\n    e3 = e2*e1\n    e4 = e3*e1\n    e5 = e4*e1\n    ctheta = e1.real\n    stheta = e1.imag\n    c2theta = e2.real\n    s2theta = e2.imag\n    c3theta = e3.real\n    s3theta = e3.imag\n    c4theta = e4.real\n    s4theta = e4.imag\n    c5theta = e5.real\n    s5theta = e5.imag\n    # Generate all the zernikes\n    zernike = np.zeros((21,)+x.shape )\n    zernike[0] =  1.0\n    zernike[1] =  2.0*r1*ctheta\n    zernike[2] =  2.0*r1*stheta\n    zernike[3] =  sqrt(3.0)*(2.0*r2 - 1.0)\n    zernike[4] =  sqrt(6.0)*r2*s2theta\n    zernike[5] =  sqrt(6.0)*r2*c2theta\n    zernike[6] =  sqrt(8.0)*(3.0*r3 - 2.0*r1)*stheta\n    zernike[7] =  sqrt(8.0)*(3.0*r3 - 2.0*r1)*ctheta\n    zernike[8] =  sqrt(8.0)*r3*s3theta\n    zernike[9] = sqrt(8.0)*r3*c3theta\n    zernike[10] = sqrt(5.0)*(6.*r4 - 6.*r2 + 1.)\n    zernike[11] = sqrt(10.)*(4.*r4 - 3.*r2)*c2theta\n    zernike[12] = sqrt(10.)*(4.*r4 - 3.*r2)*s2theta\n    zernike[13] = sqrt(10.)*r4*c4theta\n    zernike[14] = sqrt(10.)*r4*s4theta\n    zernike[15] = sqrt(12.)*(10*r5-12*r3+3*r1)*ctheta\n    zernike[16] = sqrt(12.)*(10*r5-12*r3+3*r1)*stheta\n    zernike[17] = sqrt(12.)*(5*r5-4*r3)*c3theta\n    zernike[18] = sqrt(12.)*(5*r5-4*r3)*s3theta\n    zernike[19] = sqrt(12.)*r5*c5theta\n    zernike[20] = sqrt(12.)*r5*s5theta\n    # Make zernike zero outside unit circle (useful for dot product)\n    zernike = zernike*np.less_equal(r1, 1.0)\n    return(zernike[:NumZernike(maxRadial)])", "response": "Generate the Zernike values at a given set of x y coordinates up to some maximum \n    radial order"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef map_names(lang=\"en\"):\n    cache_name = \"map_names.%s.json\" % lang\n    data = get_cached(\"map_names.json\", cache_name, params=dict(lang=lang))\n    return dict([(item[\"id\"], item[\"name\"]) for item in data])", "response": "This resource returns the localized map names for the specified language."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef map_floor(continent_id, floor, lang=\"en\"):\n    cache_name = \"map_floor.%s-%s.%s.json\" % (continent_id, floor, lang)\n    params = {\"continent_id\": continent_id, \"floor\": floor, \"lang\": lang}\n    return get_cached(\"map_floor.json\", cache_name, params=params)", "response": "This resource returns details about a map floor."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_random_value(field):\n    func = get_factory_func(field)\n\n    if field.default is not None:\n        if callable(field.default):\n            return field.default()\n        return field.default\n\n    if field.choices:\n        return random.choice(field.choices)\n\n    return func(field)", "response": "Returns a random value depending on the field type and constraints."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_string_field_value(cls, field):\n        if field.regex is not None:\n            raise NotImplementedError\n\n        string_range = cls.get_range(field)\n\n        return cls.get_random_string(string_range)", "response": "Makes a random string value from a string field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef directory_script_runner(\n        log,\n        pathToScriptDirectory,\n        databaseName,\n        loginPath,\n        force=True,\n        waitForResult=True,\n        successRule=None,\n        failureRule=None):\n    \"\"\"A function to run all of the mysql scripts in a given directory (in a modified date order, oldest first) and then act on the script file in accordance with the succcess or failure of its execution\n\n    As it's insecure to pass in mysql database credentials via the command-line, run the following command from the terminal \n\n    .. code-block:: bash\n\n        mysql_config_editor set --login-path=<uniqueLoginName> --host=localhost --user=<myUsername> --password\n        > Enter password:\n\n    This will store your credentials in an encrypted file located at '~/.mylogin.cnf'. This function takes advantage of the `--login-path` so as not to compromise the user's credentials. Use `mysql_config_editor print --all` to see all of the login-paths set.\n\n    **Key Arguments:**\n        - ``log`` -- logger\n        - ``pathToScriptDirectory`` -- the path to the directory containing the sql script to be run\n        - ``databaseName`` -- the name of the database \n        - ``force`` -- force the script to run, skipping over lines with errors, Default *True*\n        - ``loginPath`` -- the local-path as set with `mysql_config_editor`\n        - ``waitForResult`` -- wait for the mysql script to finish execution? If 'False' the MySQL script will run in background (do not wait for completion), or if 'delete' the script will run then delete regardless of success status. Default *True*. [True|False|delete]\n        - ``successRule`` -- what to do if script succeeds. Default *None* [None|delete|subFolderName]\n        - ``failureRule`` -- what to do if script fails. Default *None* [None|delete|subFolderName]\n\n    **Return:**\n        - None\n\n    **Usage:**\n\n        To run the scripts in the directroy and not act on the script file use something similar to:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import directory_script_runner\n            directory_script_runner(\n                log=log,\n                pathToScriptDirectory=\"/path/to/mysql_scripts\",\n                databaseName=\"imports\",\n                loginPath=\"myLoginDetails\"\n            )\n\n        To delete successful scripts and archive failed scripts for later inspection:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import directory_script_runner\n            directory_script_runner(\n                log=log,\n                pathToScriptDirectory=\"/path/to/mysql_scripts\",\n                databaseName=\"imports\",\n                loginPath=\"myLoginDetails\",\n                successRule=\"delete\",\n                failureRule=\"failed\"\n            )\n\n        This creates a folder at `/path/to/mysql_scripts/failed` and moves the failed scripts into that folder.\n\n        Finally to execute the scripts within a directory but not wait for the results to return (much fast but you lose error checking in the MySQL scripts):\n\n        .. code-block:: python \n\n            from fundamentals.mysql import directory_script_runner\n            directory_script_runner(\n                log=log,\n                pathToScriptDirectory=\"/path/to/mysql_scripts\",\n                databaseName=\"imports\",\n                loginPath=\"myLoginDetails\",\n                waitForResults=False\n            )\n\n        Setting ``waitForResults`` = 'delete' will trash the script once it has run (or failed ... be very careful!)\n    \"\"\"\n    log.debug('starting the ``directory_script_runner`` function')\n\n    # COMPILE A DICTIONARY OF SCRIPTS / MODIFIED TIMES\n    scriptList = {}\n    for d in os.listdir(pathToScriptDirectory):\n        filePath = os.path.join(pathToScriptDirectory, d)\n        filename = os.path.basename(filePath)\n        extension = filePath.split(\".\")[-1]\n        if os.path.isfile(filePath) and extension == \"sql\":\n            modified = datetime.datetime.strptime(time.ctime(\n                os.path.getmtime(filePath)), \"%a %b %d %H:%M:%S %Y\")\n            scriptList[str(modified) + filename] = filePath\n\n    # FORCE MYSQL SCRIPT?\n    if force:\n        force = \"--force\"\n    else:\n        force = \"\"\n\n    # ORDER THE DICTIONARY BY MODIFIED TIME - OLDEST FIRST\n    scriptList = collections.OrderedDict(sorted(scriptList.items()))\n    for k, v in scriptList.iteritems():\n        scriptname = os.path.basename(v)\n        if waitForResult == True:\n            cmd =  \"\"\"mysql --login-path=%(loginPath)s %(force)s %(databaseName)s < \"%(v)s\" \"\"\" % locals(\n            )\n            p = Popen(cmd, stdout=PIPE, stderr=PIPE, close_fds=True,\n                      env={'PATH': os.getenv('PATH') + \":/usr/local/bin:/usr/bin:\", \"MYSQL_TEST_LOGIN_FILE\": os.getenv('HOME') + \"/.mylogin.cnf\"}, shell=True)\n            stdout, stderr = p.communicate()\n\n            if len(stderr):\n                log.error(\n                    \"MySQL Script `%(scriptname)s` Failed: '%(stderr)s'\" % locals())\n                if failureRule == None or failureRule == False:\n                    pass\n                elif failureRule == \"delete\":\n                    os.remove(v)\n                elif \"/\" not in failureRule:\n                    moveTo = pathToScriptDirectory + \"/\" + failureRule\n                    # Recursively create missing directories\n                    if not os.path.exists(moveTo):\n                        os.makedirs(moveTo)\n                    moveTo = moveTo + \"/\" + scriptname\n                    try:\n                        log.debug(\"attempting to rename file %s to %s\" %\n                                  (v, moveTo))\n                        os.rename(v, moveTo)\n                    except Exception, e:\n                        log.error(\n                            \"could not rename file %s to %s - failed with this error: %s \" % (v, moveTo, str(e),))\n            else:\n                if successRule == None or successRule == False:\n                    pass\n                elif successRule == \"delete\":\n                    os.remove(v)\n                elif \"/\" not in successRule:\n                    moveTo = pathToScriptDirectory + \"/\" + successRule\n                    # Recursively create missing directories\n                    if not os.path.exists(moveTo):\n                        os.makedirs(moveTo)\n                    moveTo = moveTo + \"/\" + scriptname\n                    try:\n                        log.debug(\"attempting to rename file %s to %s\" %\n                                  (v, moveTo))\n                        os.rename(v, moveTo)\n                    except Exception, e:\n                        log.error(\n                            \"could not rename file %s to %s - failed with this error: %s \" % (v, moveTo, str(e),))\n        else:\n            if waitForResult == \"delete\":\n                cmd =  \"\"\"mysql --login-path=%(loginPath)s %(force)s  %(databaseName)s < \"%(v)s\" > /dev/null 2>&1 & rm \"%(v)s\" \"\"\" % locals()\n            else:\n                cmd =  \"\"\"mysql --login-path=%(loginPath)s %(force)s  %(databaseName)s < \"%(v)s\" > /dev/null 2>&1 \"\"\" % locals()\n            p = Popen(cmd, close_fds=True,\n                      env={'PATH': os.getenv('PATH') + \":/usr/local/bin:/usr/bin:\", \"MYSQL_TEST_LOGIN_FILE\": os.getenv('HOME') + \"/.mylogin.cnf\"}, shell=True, stdin=None, stdout=None, stderr=None)\n\n    log.debug('completed the ``directory_script_runner`` function')\n    return None", "response": "This function runs all of the mysql scripts in a given directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(arguments=None):\n\n    # setup the command-line util settings\n    su = tools(\n        arguments=arguments,\n        docString=__doc__,\n        logLevel=\"WARNING\",\n        options_first=False,\n        projectName=\"fundmentals\"\n    )\n    arguments, settings, log, dbConn = su.setup()\n\n    # UNPACK REMAINING CL ARGUMENTS USING `EXEC` TO SETUP THE VARIABLE NAMES\n    # AUTOMATICALLY\n    for arg, val in arguments.iteritems():\n        if arg[0] == \"-\":\n            varname = arg.replace(\"-\", \"\") + \"Flag\"\n        else:\n            varname = arg.replace(\"<\", \"\").replace(\">\", \"\")\n        if isinstance(val, str) or isinstance(val, unicode):\n            exec(varname + \" = '%s'\" % (val,))\n        else:\n            exec(varname + \" = %s\" % (val,))\n        if arg == \"--dbConn\":\n            dbConn = val\n        log.debug('%s = %s' % (varname, val,))\n\n    if successFlag and successFlag.lower() == \"none\":\n        successFlag = None\n    if failureFlag and failureFlag.lower() == \"none\":\n        failureFlag = None\n\n    directory_script_runner(\n        log=log,\n        pathToScriptDirectory=pathToDirectory,\n        databaseName=databaseName,\n        loginPath=loginPath,\n        successRule=successFlag,\n        failureRule=failureFlag\n    )\n\n    return", "response": "This function is used when directory_script_runner. py is run as a single script from the cl command\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Eoi(compiler, cont):\r\n  '''end of parse_state'''\r\n  return il.If(il.Ge(il.GetItem(il.parse_state, il.Integer(1)), \r\n                     il.Len(il.GetItem(il.parse_state, il.Integer(0)))),\r\n          cont(TRUE),\r\n          il.failcont(FALSE))", "response": "Eoi is a non - empty condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if parse_state is at least 1.", "response": "def Boi(compiler, cont):\r\n  '''end of parse_state'''\r\n  return il.If(il.Le(il.GetItem(il.parse_state, il.Integer(1)),0),\r\n          cont(TRUE),\r\n          il.failcont(FALSE))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the column names of the database table", "response": "def get_database_table_column_names(\n    dbConn,\n    log,\n    dbTable\n):\n    \"\"\"get database table column names\n\n    **Key Arguments:**\n        - ``dbConn`` -- mysql database connection\n        - ``log`` -- logger\n        - ``dbTable`` -- database tablename\n\n    **Return:**\n        - ``columnNames`` -- table column names\n\n    **Usage:**\n\n        To get the column names of a table in a given database:\n\n        .. code-block:: python \n\n            from fundamentals.mysql import get_database_table_column_names\n            columnNames = get_database_table_column_names(\n                dbConn=dbConn,\n                log=log,\n                dbTable=\"test_table\"\n            )\n    \"\"\"\n    log.debug('starting the ``get_database_table_column_names`` function')\n\n    sqlQuery = \"\"\"SELECT * FROM %s LIMIT 1\"\"\" \\\n        % (dbTable, )\n    # ############### >ACTION(S) ################\n    try:\n        rows = readquery(\n            log=log,\n            sqlQuery=sqlQuery,\n            dbConn=dbConn,\n        )\n    except Exception as e:\n        log.error(\n            'could not find column names for dbTable %s - failed with this error: %s ' %\n            (dbTable, str(e)))\n        return -1\n    columnNames = rows[0].keys()\n\n    log.debug('completed the ``get_database_table_column_names`` function')\n    return columnNames"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing arguments returns options and args.", "response": "def parse_args(args=None):\n    '''Parses arguments, returns (options, args).'''\n    from argparse import ArgumentParser\n\n    if args is None:\n        args = sys.argv\n\n    parser = ArgumentParser(description='Example app for drawing shapes from '\n                            'dataframe, scaled to fit to GTK canvas while '\n                            'preserving aspect ratio (a.k.a., aspect fit).')\n    parser.add_argument('-p', '--padding-fraction', type=float, default=0)\n    parser.add_argument('--connections-color', default='#ffffff')\n    parser.add_argument('--connections-alpha', type=float, default=.5)\n    parser.add_argument('--connections-width', type=float, default=1)\n    parser.add_argument('-n', '--plugin-name', default=None)\n    parser.add_argument('-a', '--allocation', default=None,\n                        help='Window allocation: x, y, width, height (JSON'\n                        'object)')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='Include IPython button for debugging.')\n\n    subparsers = parser.add_subparsers(help='help for subcommand',\n                                       dest='command')\n\n    parser_fixed = subparsers.add_parser('fixed', help='Start view with fixed'\n                                         'name and hub URI.')\n    parser_fixed.add_argument('hub_uri')\n\n    parser_config = subparsers.add_parser('configurable', help='Start view '\n                                          'with configurable name and hub '\n                                          'URI.')\n    parser_config.add_argument('hub_uri', nargs='?')\n\n    args = parser.parse_args()\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(df, style = 'mean'):\n    if style == 'mean':\n        df_mean,df_std = df.mean(),df.std()\n        return (df-df_mean)/df_std\n    elif style == 'minmax':\n        col_min,col_max = df.min(),df.max()\n        return (df-col_min)/(col_max-col_min)\n    else:\n        return style(df)", "response": "Returns a normalized version of a DataFrame or Series"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize the dataframe of a cluster term tree structure.", "response": "def norms(df, col_names = None,row_names = None,style = 'mean', as_group = False, axis = 0):\n    \"\"\" Returns a normalized version of the input Dataframe\n    Parameters:\n    df - pandas DataFrame\n        The input data to normalize\n    col_names - list or string, default None\n        The column(s) to use when computing the norms\n    row_names - list or string, default None\n        The row(s) to use when computing the norms\n    style - function or string, default 'mean'\n        The style to use when computing the norms. Takes 'mean' or 'minmax' to\n        do mean or min-max normalization respectively. User-defined functions that take\n        a pandas Series as input and return a normalized pandas Series are also accepted\n    as_group - bool, default False\n        Whether to normalize accross the entire range or by row/column. If true, will normalize\n        by the entire DataFrame\n    axis - int or string, default 0\n        Which axis to perform the normalization on. Accepts 0 or 'columns' to do normalization by\n        columns, and 1 or 'rows' to do normalization by rows\n    \"\"\"\n    if col_names is None:\n        if row_names is not None:\n            df = df.loc[row_names,:]\n    else:\n        if row_names is None:\n            df = df.loc[:,col_names]\n        else:\n            df = df.loc[row_names,col_names]\n    if as_group:\n        return normalize(df,style)\n    if axis == 0 or str(axis).startswith('column'):\n        return _pd.concat([col_normalize(df,col_name,style) for col_name in df.columns],axis = 1)\n    elif axis == 1 or str(axis).startswith('row'):\n        return _pd.concat([row_normalize(df,row_name,style) for row_name in df.index])\n    else:\n        return normalize(df,style)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_finished(self):\n\n        component_name = self.get_component_name()\n\n        self.log(\n            logging.INFO,\n            \"Component [%s] is being marked as finished.\", \n            component_name)\n\n        existing_state = self.__get_state(component_name)\n\n        assert existing_state == fss.constants.PCS_RUNNING, \\\n               \"Can not change to 'finished' state from unsupported \" \\\n               \"state: (\" + str(existing_state) + \")\"\n\n        self.__set_data('count', self.__push_count)\n        self.__set_state(fss.constants.PCS_FINISHED)", "response": "Sets the state of this component to finished."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the weight_unit of this MeasurementSettings.", "response": "def weight_unit(self, weight_unit):\n        \"\"\"Sets the weight_unit of this MeasurementSettings.\n\n\n        :param weight_unit: The weight_unit of this MeasurementSettings.\n        :type: str\n        \"\"\"\n        allowed_values = [\"pound\", \"kilogram\"]  # noqa: E501\n        if weight_unit is not None and weight_unit not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `weight_unit` ({0}), must be one of {1}\"  # noqa: E501\n                .format(weight_unit, allowed_values)\n            )\n\n        self._weight_unit = weight_unit"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef dimensions_unit(self, dimensions_unit):\n        allowed_values = [\"inch\", \"cm\", \"foot\", \"meter\"]  # noqa: E501\n        if dimensions_unit is not None and dimensions_unit not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `dimensions_unit` ({0}), must be one of {1}\"  # noqa: E501\n                .format(dimensions_unit, allowed_values)\n            )\n\n        self._dimensions_unit = dimensions_unit", "response": "Sets the dimensions_unit of this MeasurementSettings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_result_hook(self, hook: Type[\"QueryResultHook\"]) -> Type[\"QueryResultHook\"]:\n        hook.next_hook = self._query_result_hook\n        self._query_result_hook = hook\n        return hook", "response": "Adds a query result hook to the chain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndetermine whether the pattern has already been loaded into the cache.", "response": "def already_resolved(self, pattern: QueryTriple) -> bool:\n        \"\"\" Determine whether pattern has already been loaded into the cache.\n\n        The \"wild card\" - `(None, None, None)` - always counts as resolved.\n\n        :param pattern: pattern to check\n        :return: True it is a subset of elements already loaded\n        \"\"\"\n        if self.sparql_locked or pattern == (None, None, None):\n            return True\n        for resolved_node in self.resolved_nodes:\n            if resolved_node != (None, None, None) and \\\n                    (pattern[0] == resolved_node[0] or resolved_node[0] is None) and \\\n                    (pattern[1] == resolved_node[1] or resolved_node[1] is None) and\\\n                    (pattern[2] == resolved_node[2] or resolved_node[2] is None):\n                return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef triples(self, pattern: QueryTriple):\n        self.total_calls += 1\n        if self.graph_name is not None:\n            gn = \"?g\" if not self.graph_name else self.graph_name\n            gquery = f\"graph {gn} {{\"\n            gqueryend = '}'\n        else:\n            gquery = gqueryend = ''\n        if not self.already_resolved(pattern):\n            subj = self._repr_element(pattern[0]) if pattern[0] is not None else '?s'\n            pred = self._repr_element(pattern[1]) if pattern[1] is not None else '?p'\n            obj = self._repr_element(pattern[2]) if pattern[2] is not None else '?o'\n            query = f\"SELECT ?s ?p ?o {{{gquery}{subj} {pred} {obj}{gqueryend}}}\"\n            start = time.time()\n            if self.debug_slurps:\n                print(f\"SPARQL: ({query})\", end=\"\")\n            self.sparql.setQuery(query)\n            resp = self.sparql.query().convert()\n            elapsed = time.time() - start\n            ntriples = len(resp['results']['bindings'])\n            self.total_slurptime += elapsed\n            self.total_triples += ntriples\n            self.total_queries += 1\n            if self.debug_slurps:\n                print(f\" ({round(elapsed, 2)} secs) - {ntriples} triples\")\n            query_result = self._query_result_hook(self) if self._query_result_hook is not None else None\n            for row in resp['results']['bindings']:\n                triple = RDFTriple(pattern[0] if pattern[0] is not None else self._map_type(row['s']),\n                                   pattern[1] if pattern[1] is not None else self._map_type(row['p']),\n                                   pattern[2] if pattern[2] is not None else self._map_type(row['o']))\n                self.add(triple)\n                if query_result:\n                    query_result.add(triple)\n            if query_result:\n                query_result.done()\n            self.resolved_nodes.append(pattern)\n        return super().triples(pattern)", "response": "Return the triples that match a pattern."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, t: RDFTriple) -> None:\n        if self.chained_hook is not None:\n            self.chained_hook.add(t)", "response": "Add a triple as a query result."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fix_base(fix_environ):\n    def _is_android():\n        import os\n\n        vm_path = os.sep+\"system\"+os.sep+\"bin\"+os.sep+\"dalvikvm\"\n        if os.path.exists(vm_path) or os.path.exists(os.sep+\"system\"+vm_path):\n            return True\n        try:\n            import android\n            del android  # Unused import (imported only for Android detection)\n            return True\n        except ImportError:\n            pass\n        return False\n\n    def _fix_android_environ():\n        import os\n\n        if \"LD_LIBRARY_PATH\" not in os.environ:\n            os.environ[\"LD_LIBRARY_PATH\"] = \"\"\n\n        lib_path = os.pathsep+\"/system/lib\"+os.pathsep+\"/vendor/lib\"\n        if sys.python_bits == 64:\n            lib_path = os.pathsep+\"/system/lib64\"+os.pathsep+\"/vendor/lib64\" + lib_path\n\n        os.environ[\"LD_LIBRARY_PATH\"] += lib_path\n\n    if sys.platform.startswith(\"linux\") and sys.platform != \"linux-android\":\n        if _is_android():\n            sys.platform = \"linux-android\"\n        elif \"-\" not in sys.platform:\n            sys.platform = \"linux\"\n\n    sys.platform_codename = sys.platform\n    if sys.platform_codename == \"win32\":\n        sys.platform_codename = \"win\"\n    elif sys.platform_codename == \"linux-android\":\n        sys.platform_codename = \"android\"\n\n    if 'maxsize' in sys.__dict__:\n        if sys.maxsize > 2**32:\n            sys.python_bits = 64\n        else:\n            sys.python_bits = 32\n    else:\n        import struct\n        sys.python_bits = 8 * struct.calcsize(\"P\")\n        if sys.python_bits == 32:\n            sys.maxsize = 2147483647\n        else:\n            sys.maxsize = int(\"9223372036854775807\")\n\n    if fix_environ and sys.platform == \"linux-android\":\n        _fix_android_environ()", "response": "Activate the base compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_builtins(override_debug=False):\n    override_dict = {}\n    orig_print = None\n    used_print = None\n\n    if(__builtins__.__class__ is dict):\n        builtins_dict = __builtins__\n    else:\n        try:\n            import builtins\n        except ImportError:\n            import __builtin__ as builtins\n        builtins_dict = builtins.__dict__\n\n    def _deprecated(*args, **kwargs):\n        \"\"\"Report the fact that the called function is deprecated.\"\"\"\n        import traceback\n        raise DeprecationWarning(\"the called function is deprecated => \" +\n                                 traceback.extract_stack(None, 2)[0][3])\n\n    def _print_wrapper(*args, **kwargs):\n        flush = kwargs.get(\"flush\", False)\n        if \"flush\" in kwargs:\n            del kwargs[\"flush\"]\n        orig_print(*args, **kwargs)\n        if flush:\n            kwargs.get(\"file\", sys.stdout).flush()\n\n    def _print_full(*args, **kwargs):\n        opt = {\"sep\": \" \", \"end\": \"\\n\", \"file\": sys.stdout, \"flush\": False}\n        for key in kwargs:\n            if(key in opt):\n                opt[key] = kwargs[key]\n            else:\n                raise TypeError(\"'\"+key+\"' is an invalid keyword argument \"\n                                \"for this function\")\n        opt[\"file\"].write(opt[\"sep\"].join(str(val) for val in args)+opt[\"end\"])\n        if opt[\"flush\"]:\n            opt[\"file\"].flush()\n\n    def _sorted(my_list):\n        my_list = list(my_list)\n        my_list.sort()\n        return my_list\n\n    def _format(value, format_spec):\n        return value.__format__(format_spec)\n\n    if builtins_dict.get(__name__, False):\n        raise RuntimeError(__name__+\" already loaded\")\n\n    # Exceptions\n    if builtins_dict.get(\"BaseException\") is None:\n        override_dict[\"BaseException\"] = Exception\n\n    # basestring\n    if builtins_dict.get(\"basestring\") is None:\n        if builtins_dict.get(\"bytes\") is None:\n            import types\n            override_dict[\"basestring\"] = types.StringType\n        else:\n            override_dict[\"basestring\"] = (str, bytes)  # It works only when used in isinstance\n    # IntType\n    if getattr(int, \"__str__\", None) is None:\n        import types\n        override_dict[\"IntType\"] = types.IntType\n    else:\n        override_dict[\"IntType\"] = int  # Python >= 2.2\n\n    if 'format' not in str.__dict__:\n        override_dict[\"str\"] = _Internal.ExtStr\n    # Function 'input'\n    if builtins_dict.get(\"raw_input\") is not None:\n        override_dict[\"input\"] = builtins_dict.get(\"raw_input\")\n    override_dict[\"raw_input\"] = _deprecated\n    # Function 'print' (also aliased as print_)\n    if sys.version_info >= (3, 3):\n        used_print = builtins_dict.get(\"print\")\n    else:\n        orig_print = builtins_dict.get(\"print\")\n        if orig_print is not None:\n            used_print = _print_wrapper\n        else:\n            used_print = _print_full\n        override_dict[\"print\"] = used_print\n    override_dict[\"print_\"] = used_print\n    # Function 'sorted'\n    if builtins_dict.get(\"sorted\") is None:\n        override_dict[\"sorted\"] = _sorted\n    # Function 'format'\n    if builtins_dict.get(\"format\") is None:\n        override_dict[\"format\"] = _format\n\n    override_dict[__name__] = True\n    builtins_dict.update(override_dict)\n    del override_dict", "response": "Activate the builtins compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fix_subprocess(override_debug=False, override_exception=False):\n    import subprocess\n\n    # Exceptions\n    if subprocess.__dict__.get(\"SubprocessError\") is None:\n        subprocess.SubprocessError = _Internal.SubprocessError\n    if _InternalReferences.UsedCalledProcessError is None:\n        if \"CalledProcessError\" in subprocess.__dict__:\n            _subprocess_called_process_error(True, subprocess)\n        else:\n            _subprocess_called_process_error(False, subprocess)\n            subprocess.CalledProcessError = _InternalReferences.UsedCalledProcessError\n\n    def _check_output(*args, **kwargs):\n        if \"stdout\" in kwargs:\n            raise ValueError(\"stdout argument not allowed, \"\n                             \"it will be overridden.\")\n        process = subprocess.Popen(stdout=subprocess.PIPE, *args, **kwargs)\n        stdout_data, __ = process.communicate()\n        ret_code = process.poll()\n        if ret_code is None:\n            raise RuntimeWarning(\"The process is not yet terminated.\")\n        if ret_code:\n            cmd = kwargs.get(\"args\")\n            if cmd is None:\n                cmd = args[0]\n            raise _InternalReferences.UsedCalledProcessError(returncode=ret_code, cmd=cmd, output=stdout_data)\n        return stdout_data\n\n    try:\n        subprocess.check_output\n    except AttributeError:\n        subprocess.check_output = _check_output", "response": "Activate the subprocess compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fix_all(override_debug=False, override_all=False):\n    fix_base(True)\n    fix_builtins(override_debug)\n    fix_subprocess(override_debug, override_all)\n    return True", "response": "Activate the full compatibility."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscrubbing from the front and back of an object column in a DataFrame df to the front and back of an object column in a DataFrame", "response": "def smart_scrub(df,col_name,error_rate = 0):\n    \"\"\" Scrubs from the front and back of an 'object' column in a DataFrame\n    until the scrub would semantically alter the contents of the column. If only a \n    subset of the elements in the column are scrubbed, then a boolean array indicating which\n    elements have been scrubbed is appended to the dataframe. Returns a tuple of the strings removed\n    from the front and back of the elements\n    df - DataFrame\n        DataFrame to scrub\n    col_name - string\n        Name of column to scrub\n    error_rate - number, default 0\n        The maximum amount of values this function can ignore while scrubbing, expressed as a\n        fraction of the total amount of rows in the dataframe. \n    \"\"\"\n    scrubf = smart_scrubf(df,col_name,error_rate)\n    scrubb = smart_scrubb(df,col_name,error_rate)\n    return (scrubf, scrubb)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscrub from the front of an object column in a DataFrame df until the scrub would semantically alter the contents of the column in df. Returns the string that was scrubbed.", "response": "def smart_scrubf(df,col_name,error_rate = 0):\n    \"\"\" Scrubs from the front of an 'object' column in a DataFrame\n    until the scrub would semantically alter the contents of the column. If only a \n    subset of the elements in the column are scrubbed, then a boolean array indicating which\n    elements have been scrubbed is appended to the dataframe. Returns the string that was scrubbed\n    df - DataFrame\n        DataFrame to scrub\n    col_name - string\n        Name of column to scrub\n    error_rate - number, default 0\n        The maximum amount of values this function can ignore while scrubbing, expressed as a\n        fraction of the total amount of rows in the dataframe. \n    \"\"\"\n    scrubbed = \"\"\n    while True:\n        valcounts = df[col_name].str[:len(scrubbed)+1].value_counts()\n        if not len(valcounts):\n            break\n        if not valcounts[0] >= (1-error_rate) * _utils.rows(df):\n            break\n        scrubbed=valcounts.index[0]\n    if scrubbed == '':\n        return None\n    which = df[col_name].str.startswith(scrubbed)\n    _basics.col_scrubf(df,col_name,which,len(scrubbed),True)\n    if not which.all():\n        new_col_name = _basics.colname_gen(df,\"{}_sf-{}\".format(col_name,scrubbed))\n        df[new_col_name] = which\n    return scrubbed"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscrubbing from the back of an object column in a DataFrame df until the scrub would semantically alter the contents of the column in df. Returns the string that was scrubbed.", "response": "def smart_scrubb(df,col_name,error_rate = 0):\n    \"\"\" Scrubs from the back of an 'object' column in a DataFrame\n    until the scrub would semantically alter the contents of the column. If only a \n    subset of the elements in the column are scrubbed, then a boolean array indicating which\n    elements have been scrubbed is appended to the dataframe. Returns the string that was scrubbed.\n    df - DataFrame\n        DataFrame to scrub\n    col_name - string\n        Name of column to scrub\n    error_rate - number, default 0\n        The maximum amount of values this function can ignore while scrubbing, expressed as a\n        fraction of the total amount of rows in the dataframe. \n    \"\"\"\n    scrubbed = \"\"\n    while True:\n        valcounts = df[col_name].str[-len(scrubbed)-1:].value_counts()\n        if not len(valcounts):\n            break\n        if not valcounts[0] >= (1-error_rate) * _utils.rows(df):\n            break\n        scrubbed=valcounts.index[0]\n    if scrubbed == '':\n        return None\n    which = df[col_name].str.endswith(scrubbed)\n    _basics.col_scrubb(df,col_name,which,len(scrubbed),True)\n    if not which.all():\n        new_col_name = _basics.colname_gen(df,\"{}_sb-{}\".format(col_name,scrubbed))\n        df[new_col_name] = which\n    return scrubbed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds all shipping methods for an order.", "response": "def find_all_for_order(cls, order_id, **kwargs):\n        \"\"\"Find shipping methods for order.\n\n        Find all shipping methods suitable for an order.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.find_all_for_order(order_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str order_id: Order ID to get shipping methods for. (required)\n        :return: page[ShippingMethod]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._find_all_for_order_with_http_info(order_id, **kwargs)\n        else:\n            (data) = cls._find_all_for_order_with_http_info(order_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list_all_shipping_methods(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_shipping_methods_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_shipping_methods_with_http_info(**kwargs)\n            return data", "response": "List ShippingMethods\n        Returns a list of ShippingMethods\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef extract(cls, obj):\n        span = cls.extract_span(obj)\n        if span:\n            return span.context", "response": "Extract a SpanContext instance from the given object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninject the span context into an object.", "response": "def inject(cls, span, obj):\n        \"\"\" Injects the span context into a `carrier` object.\n\n        :param opentracing.span.SpanContext span: the SpanContext instance\n        :param Any obj: Object to use as context\n        \"\"\"\n        obj.metadata['__parent-span__'] = dict()\n        cls.inject_span(span, obj.metadata['__parent-span__'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract tags from the given object", "response": "def extract_tags(cls, obj):\n        \"\"\" Extract tags from the given object\n\n        :param Any obj: Object to use as context\n        :return: Tags to add on span\n        :rtype: dict\n        \"\"\"\n        return dict(uuid=obj.uuid, entrypoint=obj.__class__.path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ntrigger to execute just before closing the span", "response": "def _postrun(cls, span, obj, **kwargs):\n        \"\"\" Trigger to execute just before closing the span\n\n        :param opentracing.span.Span  span: the SpanContext instance\n        :param Any obj: Object to use as context\n        :param dict kwargs: additional data\n        \"\"\"\n        for key, value in ResultSchema().dump(obj.result).items():\n            if isinstance(value, dict):\n                try:\n                    flat_data = cls.filter_keys(\n                        cls.fix_additional_fields(value)\n                    )\n                    span.set_tag(\"result.{}\".format(key), json.dumps(flat_data))\n                except Exception:\n                    span.set_tag(\"result.{}\".format(key), \"N/A\")\n            elif isinstance(value, (list, tuple)):\n                try:\n                    span.set_tag(\"result.{}\".format(key), json.dumps(value))\n                except Exception:\n                    try:\n                        span.set_tag(\"result.{}\".format(key), value)\n                    except Exception:\n                        span.set_tag(\"result.{}\".format(key), \"N/A\")\n            else:\n                span.set_tag(\"result.{}\".format(key), value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfilters GELF record keys using exclude_patterns", "response": "def filter_keys(cls, data):\n        \"\"\"Filter GELF record keys using exclude_patterns\n\n        :param dict data: Log record has dict\n        :return: the filtered log record\n        :rtype: dict\n        \"\"\"\n        keys = list(data.keys())\n        for pattern in cls.EXCLUDE_PATTERNS:\n            for key in keys:\n                if re.match(pattern, key):\n                    keys.remove(key)\n        return dict(filter(lambda x: x[0] in keys, data.items()))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the configuration to a local file.", "response": "def write_config(self):\n        \"\"\"Write the configuration to a local file.\n\n        :return: Boolean if successful\n        \"\"\"\n        json.dump(\n            self.config,\n            open(CONFIG_FILE, 'w'),\n            indent=4,\n            separators=(',', ': ')\n        )\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_config(self, **kwargs):\n        virgin_config = False\n        if not os.path.exists(CONFIG_PATH):\n            virgin_config = True\n            os.makedirs(CONFIG_PATH)\n        if not os.path.exists(CONFIG_FILE):\n            virgin_config = True\n        if not virgin_config:\n            self.config = json.load(open(CONFIG_FILE))\n        else:\n            self.logger.info('[!] Processing whitelists, this may take a few minutes...')\n            process_whitelists()\n        if kwargs:\n            self.config.update(kwargs)\n        if virgin_config or kwargs:\n            self.write_config()\n        if 'api_key' not in self.config:\n            sys.stderr.write('configuration missing API key\\n')\n        if 'email' not in self.config:\n            sys.stderr.write('configuration missing email\\n')\n        if not ('api_key' in self.config and 'email' in self.config):\n            sys.stderr.write('Errors have been reported. Run blockade-cfg '\n                             'to fix these warnings.\\n')\n        try:\n            last_update = datetime.strptime(self.config['whitelist_date'],\n                                            \"%Y-%m-%d\")\n            current = datetime.now()\n            delta = (current - last_update).days\n            if delta > 14:\n                self.logger.info('[!] Refreshing whitelists, this may take a few minutes...')\n                process_whitelists()\n                self.config['whitelist_date'] = datetime.now().strftime(\"%Y-%m-%d\")\n                self.write_config()\n        except Exception as e:\n            self.logger.error(str(e))\n            self.logger.info('[!] Processing whitelists, this may take a few minutes...')\n            process_whitelists()\n            self.config['whitelist_date'] = datetime.now().strftime(\"%Y-%m-%d\")\n            self.write_config()\n\n        return True", "response": "Load the configuration file and update the user s settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new TableRateRule with the given attributes.", "response": "def create_table_rate_rule(cls, table_rate_rule, **kwargs):\n        \"\"\"Create TableRateRule\n\n        Create a new TableRateRule\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_table_rate_rule(table_rate_rule, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param TableRateRule table_rate_rule: Attributes of tableRateRule to create (required)\n        :return: TableRateRule\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_table_rate_rule_with_http_info(table_rate_rule, **kwargs)\n        else:\n            (data) = cls._create_table_rate_rule_with_http_info(table_rate_rule, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_table_rate_rule_by_id(cls, table_rate_rule_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_table_rate_rule_by_id_with_http_info(table_rate_rule_id, **kwargs)\n        else:\n            (data) = cls._delete_table_rate_rule_by_id_with_http_info(table_rate_rule_id, **kwargs)\n            return data", "response": "Delete an instance of TableRateRule by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_table_rate_rule_by_id(cls, table_rate_rule_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_table_rate_rule_by_id_with_http_info(table_rate_rule_id, **kwargs)\n        else:\n            (data) = cls._get_table_rate_rule_by_id_with_http_info(table_rate_rule_id, **kwargs)\n            return data", "response": "Find TableRateRule by its ID Return single instance of TableRateRule by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nlisting TableRateRules Return a list of TableRateRules", "response": "def list_all_table_rate_rules(cls, **kwargs):\n        \"\"\"List TableRateRules\n\n        Return a list of TableRateRules\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_table_rate_rules(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[TableRateRule]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_table_rate_rules_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_table_rate_rules_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreplacing all attributes of TableRateRule with the given ID.", "response": "def replace_table_rate_rule_by_id(cls, table_rate_rule_id, table_rate_rule, **kwargs):\n        \"\"\"Replace TableRateRule\n\n        Replace all attributes of TableRateRule\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_table_rate_rule_by_id(table_rate_rule_id, table_rate_rule, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str table_rate_rule_id: ID of tableRateRule to replace (required)\n        :param TableRateRule table_rate_rule: Attributes of tableRateRule to replace (required)\n        :return: TableRateRule\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_table_rate_rule_by_id_with_http_info(table_rate_rule_id, table_rate_rule, **kwargs)\n        else:\n            (data) = cls._replace_table_rate_rule_by_id_with_http_info(table_rate_rule_id, table_rate_rule, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_table_rate_rule_by_id(cls, table_rate_rule_id, table_rate_rule, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_table_rate_rule_by_id_with_http_info(table_rate_rule_id, table_rate_rule, **kwargs)\n        else:\n            (data) = cls._update_table_rate_rule_by_id_with_http_info(table_rate_rule_id, table_rate_rule, **kwargs)\n            return data", "response": "Update attributes of TableRateRule by ID"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _update_fobj(self):\r\n\r\n        # print(\"PPPPPPPPPPPPPPPPPPPRINTANDO O STACK\")\r\n        # traceback.print_stack()\r\n\r\n        emsg, flag_error = \"\", False\r\n        fieldname = None\r\n        try:\r\n            \r\n            self._before_update_fobj()\r\n\r\n            for item in self._map:\r\n                self._f.obj[item.fieldname] = item.get_value()\r\n\r\n            self._after_update_fobj()\r\n\r\n        except Exception as E:\r\n            flag_error = True\r\n            if fieldname is not None:\r\n                emsg = \"Field '{}': {}\".format(fieldname, str(E))\r\n            else:\r\n                emsg = str(E)\r\n            self.add_log_error(emsg)\r\n\r\n        self._flag_valid = not flag_error\r\n        if not flag_error:\r\n            self.status(\"\")", "response": "Updates the object field with the current values from the GUI. Opposite of _update_gui."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef colname_gen(df,col_name = 'unnamed_col'):\n    if col_name not in df.keys():\n        yield col_name\n    id_number = 0\n    while True:\n        col_name = col_name + str(id_number)\n        if col_name in df.keys():\n            id_number+=1\n        else:\n            return col_name", "response": "Generates a column name that isn t in the specified DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_colnames(df):\n    col_list = []\n    for index in range(_dutils.cols(df)):\n        col_list.append(df.columns[index].strip().lower().replace(' ','_'))\n    df.columns = col_list", "response": "Cleans the column names on a DataFrame\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nperform str.strip() a column of a DataFrame Parameters: df - DataFrame DataFrame to operate on col_name - string Name of column to strip dest - bool, default False Whether to apply the result to the DataFrame or return it. True is apply, False is return.", "response": "def col_strip(df,col_name,dest = False):\n    \"\"\" Performs str.strip() a column of a DataFrame\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_name - string\n        Name of column to strip\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    if dest:\n        df[col_name] = df[col_name].str.strip()\n    else:\n        return df[col_name].str.strip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove characters from the front of the entries in a column in a DataFrame.", "response": "def col_scrubf(df,col_name,which,count = 1,dest = False):\n    \"\"\" Removes characters from the front of the entries in DataFrame for a column\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_name - string\n        Name of column to scrub\n    which - boolean array\n        Boolean array that determines which elements to scrub, where True means scrub\n    count - integer, default 1\n        amount of characters to scrub\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    if dest:\n        df.loc[which,col_name] = df.loc[which,col_name].str[count:]\n    else:\n        new_col = df[col_name].copy()\n        new_col[which] = df.loc[which,col_name].str[count:]\n        return new_col"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncoerces a column in a DataFrame to numeric", "response": "def col_to_numeric(df,col_name, dest = False):\n    \"\"\" Coerces a column in a DataFrame to numeric\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_name - string\n        Name of column to coerce\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    new_col = _pd.to_numeric(df[col_name], errors = 'coerce')\n    if dest:\n        set_col(df,col_name,new_col)\n    else:\n        return new_col"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef col_to_dt(df,col_name,set_format = None,infer_format = True, dest = False):\n    new_col = _pd.to_datetime(df[col_name],errors = 'coerce',\n                                    format = set_format,infer_datetime_format = infer_format)\n    if dest:\n        set_col(df,col_name,new_col)\n    else:\n        return new_col", "response": "Coerces a column in a DataFrame to datetime"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef col_to_cat(df,col_name, dest = False):\n    new_col = df[col_name].astype('category')\n    if dest:\n        set_col(df,col_name,new_col)\n    else:\n        return new_col", "response": "Coerces a column in a DataFrame to categorical\n   "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef col_rename(df,col_name,new_col_name):\n    col_list = list(df.columns)\n    for index,value in enumerate(col_list):\n        if value == col_name:\n            col_list[index] = new_col_name\n            break\n    df.columns = col_list", "response": "Changes a column name in a DataFrame\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmodifying a column of a DataFrame according to a given function", "response": "def col_mod(df,col_name,func,*args,**kwargs):\n    \"\"\" Changes a column of a DataFrame according to a given function\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_name - string\n        Name of column to modify\n    func - function\n        The function to use to modify the column\n    \"\"\"\n    backup = df[col_name].copy()\n    try:\n        return_val = func(df,col_name,*args,**kwargs)\n        if return_val is not None:\n            set_col(df,col_name,return_val)\n    except:\n        df[col_name] = backup"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nperform str.strip() a column of a DataFrame Parameters: df - DataFrame DataFrame to operate on col_list - list of strings names of columns to strip dest - bool, default False Whether to apply the result to the DataFrame or return it. True is apply, False is return.", "response": "def cols_strip(df,col_list, dest = False):\n    \"\"\" Performs str.strip() a column of a DataFrame\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_list - list of strings\n        names of columns to strip\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    if not dest:\n        return _pd.DataFrame({col_name:col_strip(df,col_name) for col_name in col_list})\n    for col_name in col_list:\n        col_strip(df,col_name,dest)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cols_to_numeric(df, col_list,dest = False):\n    if not dest:\n        return _pd.DataFrame({col_name:col_to_numeric(df,col_name) for col_name in col_list})\n    for col_name in col_list:\n        col_to_numeric(df,col_name,dest)", "response": "Coerces a list of columns to numeric DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncoerce a list of columns to datetime", "response": "def cols_to_dt(df, col_list,set_format = None,infer_format = True,dest = False):\n    \"\"\" Coerces a list of columns to datetime\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_list - list of strings\n        names of columns to coerce\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    if not dest:\n        return _pd.DataFrame({col_name:col_to_dt(df,col_name,set_format,infer_format) for col_name in col_list})\n    for col_name in col_list:\n        col_to_dt(df,col_name,set_format,infer_format,dest)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncoerce a list of columns to categorical DataFrame", "response": "def cols_to_cat(df, col_list,dest = False):\n    \"\"\" Coerces a list of columns to categorical\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_list - list of strings\n        names of columns to coerce\n    dest - bool, default False\n        Whether to apply the result to the DataFrame or return it.\n        True is apply, False is return.\n    \"\"\"\n    # Convert a list of columns to categorical\n    if not dest:\n        return _pd.DataFrame({col_name:col_to_cat(df,col_name) for col_name in col_list})\n    for col_name in col_list:\n        col_to_cat(df,col_name,dest)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cols_(df,col_list,func,*args,**kwargs):\n    return _pd.DataFrame({col_name:func(df,col_name,*args,**kwargs) for col_name in col_list})", "response": "Apply a function over a list of columns and return the result"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenames a set of columns in a DataFrame", "response": "def cols_rename(df,col_names, new_col_names):\n    \"\"\" Rename a set of columns in a DataFrame\n    Parameters:\n    df - DataFrame\n        DataFrame to operate on\n    col_names - list of strings\n        names of columns to change\n    new_col_names - list of strings\n        new names for old columns (order should be same as col_names)\n    \"\"\"\n    assert len(col_names) == len(new_col_names)\n    for old_name,new_name in zip(col_names,new_col_names):\n        col_rename(df,old_name,new_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary of datatypes in a DataFrame.", "response": "def col_dtypes(df): # Does some work to reduce possibility of errors and stuff\n    \"\"\" Returns dictionary of datatypes in a DataFrame (uses string representation)\n    Parameters:\n    df - DataFrame\n        The DataFrame to return the object types of\n    \n    Pandas datatypes are as follows:\n    object,number,bool,datetime,category,timedelta,datetimetz\n    This method uses queues and iterates over the columns in linear time.\n    It does extra steps to ensure that no further work with numpy datatypes needs\n    to be done.\n    \"\"\"\n    test_list = [col_isobj,col_isnum,col_isbool,col_isdt,col_iscat,col_istdelt,col_isdtz]\n    deque_list = [(deque(col_method(df)),name) \\\n                  for col_method,name in zip(test_list,_globals.__dtype_names) if len(col_method(df))]\n    type_dict = {}\n    for que, name in deque_list:\n        while len(que):\n            type_dict[que.popleft()] = name\n    return type_dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of columns that are of type object. col_name is optional and will return True if the column in the DataFrame is of type object.", "response": "def col_isobj(df, col_name = None):\n    \"\"\" Returns a list of columns that are of type object. If col_name is specified, returns \n    whether the column in the DataFrame is of type 'object' instead.\n    Parameters:\n    df - DataFrame\n        DataFrame to check\n    col_name - string, default None\n        If specified, this function will True if df[col_name] is of type 'object'\n    \"\"\"\n    col_list = df.select_dtypes(include = 'object').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef col_isnum(df,col_name = None):\n    col_list = df.select_dtypes(include = 'number').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list", "response": "Returns a list of columns that are of type number. col_name is optional and will return True if the column in the DataFrame is of type number otherwise returns False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef col_isbool(df,col_name = None):\n    col_list = df.select_dtypes(include = 'bool').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list", "response": "Returns a list of columns that are of type bool. col_name is optional and will return True if the column in the DataFrame is of type bool instead."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of columns that are of type datetime.", "response": "def col_isdt(df,col_name = None):\n    \"\"\" Returns a list of columns that are of type 'datetime'. If col_name is specified, returns \n    whether the column in the DataFrame is of type 'datetime' instead.\n    Parameters:\n    df - DataFrame\n        DataFrame to check\n    col_name - string, default None\n        If specified, this function will True if df[col_name] is of type 'datetime'\n    \"\"\"\n    col_list = df.select_dtypes(include = 'datetime').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of columns that are of type category. col_name is optional", "response": "def col_iscat(df,col_name = None):\n    \"\"\" Returns a list of columns that are of type 'category'. If col_name is specified, returns \n    whether the column in the DataFrame is of type 'category' instead.\n    Parameters:\n    df - DataFrame\n        DataFrame to check\n    col_name - string, default None\n        If specified, this function will True if df[col_name] is of type 'category'\n    \"\"\"\n    col_list = df.select_dtypes(include = 'category').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef col_istdelt(df,col_name = None):\n    col_list = df.select_dtypes(include = 'timedelta').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list", "response": "Returns a list of columns that are of type timedelta."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef col_isdtz(df,col_name = None):\n    col_list = df.select_dtypes(include = 'datetimetz').columns\n    if col_name is None:\n        return col_list\n    else:\n        return col_name in col_list", "response": "Returns a list of columns that are of type datetimetz"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new GraphDatabaseInterface instance for the given database.", "response": "def create_graph_database_interface(db: Engine,\r\n                                    session: Session,\r\n                                    declarative_meta: DeclarativeMeta,\r\n                                    relationship: RelationshipProperty) -> GraphDatabaseInterface:\r\n    \"\"\"\r\n    Creates a graph database interface to the database specified by the input arguments.\r\n\r\n    Note that the created database model assumes that the database enforces constraints such\r\n    as foreign key validity. This is _not true_ for SQLite databases for example, where\r\n    `PRAGMA foreign_key` is off by default. If you don't ensure that the database enforces\r\n    constraints, then some of the database tables might end up containing invalid records.\r\n\r\n    SQLAlchemy example:\r\n        >>> try:\r\n        >>>     import sqlalchemy\r\n        >>>     from sqlalchemy.ext.declarative import declarative_base\r\n        >>>     from sqlalchemy.orm import sessionmaker\r\n        >>> except ImportError:\r\n        >>>     raise ImportError(\"SQLAlchemy not found.\")\r\n        >>>\r\n        >>> # Import this method\r\n        >>> # import create_graph_database_interface\r\n        >>>\r\n        >>> # Database interface setup.\r\n        >>> Base = declarative_base()\r\n        >>> engine = sqlalchemy.create_engine(\"sqlite://\")\r\n        >>> Session = sessionmaker(bind=engine)\r\n        >>> dbi: GraphDatabaseInterface = create_graph_database_interface(\r\n        >>>     sqlalchemy,\r\n        >>>     Session(),\r\n        >>>     Base,\r\n        >>>     sqlalchemy.orm.relationship\r\n        >>> )\r\n        >>>\r\n        >>> # Complete database reset.\r\n        >>> Base.metadata.drop_all(engine)\r\n        >>> Base.metadata.create_all(engine)\r\n        >>>\r\n        >>> # Database interface test.\r\n        >>> node: DBNode = dbi.Node(\"Some vertex\")\r\n        >>> dbi.session.add(node)\r\n        >>> dbi.session.commit()\r\n        >>>\r\n        >>> node = dbi.Node.find_by_name(\"Some vertex\")\r\n        >>> if node is not None:\r\n        >>>     print(\"Got it!\")\r\n\r\n    Flask-SQLAlchemy example:\r\n        >>> try:\r\n        >>>     from flask import Flask\r\n        >>>     from flask_sqlalchemy import SQLAlchemy\r\n        >>> except ImportError:\r\n        >>>     raise ImportError(\"The flask and flask-sqlalchemy libraries are required in this example.\")\r\n        >>>\r\n        >>> # Import this method\r\n        >>> # import create_graph_database_interface\r\n        >>>\r\n        >>> # Set up the Flask application.\r\n        >>> app = Flask(__name__)\r\n        >>> app.config['SQLALCHEMY_DATABASE_URI'] = \"sqlite://\"\r\n        >>> flask_db = SQLAlchemy(app)\r\n        >>>\r\n        >>> # Create the database interface\r\n        >>> dbi: GraphDatabaseInterface = create_graph_database_interface(\r\n        >>>     flask_db,\r\n        >>>     flask_db.session,\r\n        >>>     flask_db.Model,\r\n        >>>     flask_db.relationship\r\n        >>> )\r\n        >>>\r\n        >>> # Complete database reset.\r\n        >>> flask_db.drop_all()\r\n        >>> flask_db.create_all()\r\n        >>>\r\n        >>> # Database interface test.\r\n        >>> node: DBNode = dbi.Node(\"Some vertex\")\r\n        >>> dbi.session.add(node)\r\n        >>> dbi.session.commit()\r\n        >>>\r\n        >>> node = dbi.Node.find_by_name(\"Some vertex\")\r\n        >>> if node is not None:\r\n        >>>     print(\"Got it!\")\r\n\r\n    Arguments:\r\n        db (Engine): The SQLAlchemy or Flask-SQLAlchemy database to use.\r\n        session (Session): The session database operations are executed on.\r\n        declarative_meta (DeclarativeMeta): The metaclass that should be the base class\r\n                                            of the database model classes.\r\n        relationship (RelationshipProperty): Relationship property generator.\r\n\r\n    Returns:\r\n        A graph database interface object the user can use to query and manipulate the database\r\n        that is specified by the input arguments of the method.\r\n    \"\"\"\r\n\r\n    class DBNode(declarative_meta):\r\n        \"\"\"\r\n        Declarative database object model representing a node.\r\n        \"\"\"\r\n\r\n        # Metaclass definition\r\n        # ------------------------------------------------------------\r\n\r\n        # __bind_key__ = bind_key  # Variable name must not be changed.\r\n        __tablename__ = \"nodes\"  # Variable name must not be changed.\r\n\r\n        _creation_date = db.Column(db.Date,\r\n                                   nullable=False,\r\n                                   default=datetime.date.today)\r\n\r\n        are_neighbors_cached = db.Column(db.Boolean,\r\n                                         default=False)\r\n        name = db.Column(db.String(100),\r\n                         primary_key=True)\r\n        external_id = db.Column(db.String(100))\r\n\r\n        edges_where_source = relationship(\"DBEdge\",\r\n                                          primaryjoin=\"DBNode.name==DBEdge.source_name\",\r\n                                          cascade=\"all, delete-orphan\",\r\n                                          backref=\"source\")\r\n        edges_where_target = relationship(\"DBEdge\",\r\n                                          primaryjoin=\"DBNode.name==DBEdge.target_name\",\r\n                                          cascade=\"all, delete-orphan\",\r\n                                          backref=\"target\")\r\n\r\n        # Initialization\r\n        # ------------------------------------------------------------\r\n\r\n        def __init__(self, node_name: str, external_id: str = None):\r\n            \"\"\"\r\n            Initialization.\r\n\r\n            Arguments:\r\n                node_name (str): The name of the node.\r\n                external_id (str): The external ID of the node.\r\n            \"\"\"\r\n            if node_name is None:\r\n                raise ValueError(\"Node name must not be None.\")\r\n\r\n            node_name = node_name.strip()\r\n            if len(node_name) == 0:\r\n                raise ValueError(\"Node name must contain non-whitespace characters.\")\r\n\r\n            self.name = node_name\r\n            self.external_id = external_id.strip() if external_id is not None else None\r\n\r\n        # Special methods\r\n        # ------------------------------------------------------------\r\n\r\n        def __repr__(self) -> str:\r\n            \"\"\"\r\n            The string representation of the object.\r\n            \"\"\"\r\n            return \"DBNode(name={}, external_id={})\".format(self.name, self.external_id)\r\n\r\n        # Properties\r\n        # ------------------------------------------------------------\r\n\r\n        @property\r\n        def creation_date(self) -> datetime.date:\r\n            \"\"\"\r\n            The date when the node was created.\r\n            \"\"\"\r\n            return self._creation_date\r\n\r\n        @property\r\n        def edges(self) -> List[\"DBEdge\"]:\r\n            \"\"\"\r\n            The edges where this node is one of the endpoints.\r\n            \"\"\"\r\n            result: List[\"DBEdge\"] = []\r\n            edges: List[\"DBEdge\"] = self.edges_where_target\r\n            if edges is not None:\r\n                result.extend(edges)\r\n\r\n            edges = self.edges_where_source\r\n            if edges is not None:\r\n                result.extend(edges)\r\n\r\n            return result\r\n\r\n        @property\r\n        def neighbor_names(self) -> List[str]:\r\n            \"\"\"\r\n            The names of the neighbors of the node that are currently in the database.\r\n            \"\"\"\r\n            result: List[str] = []\r\n            neighbors: List[str] = [edge.source_name\r\n                                    for edge in DBEdge.query.filter_by(target_name=self.name)]\r\n            if neighbors is not None:\r\n                result.extend(neighbors)\r\n\r\n            neighbors = [edge.target_name\r\n                         for edge in DBEdge.query.filter_by(source_name=self.name)]\r\n            if neighbors:\r\n                result.extend(neighbors)\r\n\r\n            return result\r\n\r\n        @property\r\n        def neighbors(self) -> List[\"DBNode\"]:\r\n            \"\"\"\r\n            The list of neighbors the node currently has in the database.\r\n            \"\"\"\r\n            result: List[DBNode] = []\r\n\r\n            neighbors: List[DBNode] = [edge.source for edge in DBEdge.query.filter_by(target_name=self.name)]\r\n            if neighbors is not None:\r\n                result.extend(neighbors)\r\n\r\n            neighbors = [edge.target for edge in DBEdge.query.filter_by(source_name=self.name)]\r\n            if neighbors is not None:\r\n                result.extend(neighbors)\r\n\r\n            return result\r\n\r\n        # Class methods\r\n        # ------------------------------------------------------------\r\n\r\n        @classmethod\r\n        def find_by_name(cls, node_name: str) -> Optional[\"DBNode\"]:\r\n            \"\"\"\r\n            Returns the `DBNode` with the given name if such a node exists in the database.\r\n\r\n            Arguments:\r\n                node_name (str): The queried node name.\r\n\r\n            Returns:\r\n                The node with the given name if it exists.\r\n            \"\"\"\r\n            return cls.query.filter_by(name=node_name).first()\r\n\r\n        @classmethod\r\n        def find_by_external_id(cls, external_id: str) -> Optional[\"DBNode\"]:\r\n            \"\"\"\r\n            Returns the `DBNode` with the given external ID if such a node exists in the database.\r\n\r\n            Arguments:\r\n                external_id (str): The queried external ID.\r\n\r\n            Returns:\r\n                The node with the given external ID if it exists.\r\n            \"\"\"\r\n            if external_id is None:\r\n                return None\r\n\r\n            nodes: Optional[List[DBNode]] = cls.query.filter_by(external_id=external_id)\r\n            return nodes.first() if len(nodes) == 1 else None\r\n\r\n    class DBEdge(declarative_meta):\r\n        \"\"\"\r\n        Declarative database object model representing an edge.\r\n        \"\"\"\r\n\r\n        # Metaclass definition\r\n        # ------------------------------------------------------------\r\n\r\n        # __bind_key__ = bind_key  # Variable name must not be changed.\r\n        __tablename__ = \"edges\"  # Variable name must not be changed.\r\n\r\n        _creation_date = db.Column(db.Date,\r\n                                   nullable=False,\r\n                                   default=datetime.date.today)\r\n\r\n        source_name = db.Column(db.String,\r\n                                db.ForeignKey(\"nodes.name\"),\r\n                                db.CheckConstraint(\"source_name < target_name\"),\r\n                                primary_key=True)\r\n        target_name = db.Column(db.String,\r\n                                db.ForeignKey(\"nodes.name\"),\r\n                                db.CheckConstraint(\"source_name < target_name\"),\r\n                                primary_key=True)\r\n        weight = db.Column(db.Float,\r\n                           db.CheckConstraint(\"weight > 0\"),\r\n                           default=1)\r\n\r\n        # Initialization\r\n        # ------------------------------------------------------------\r\n\r\n        def __init__(self, source_name: str, target_name: str, weight: float = 1):\r\n            \"\"\"\r\n            Initialization.\r\n\r\n            Arguments:\r\n                source_name (str): The name of the source node of the edge.\r\n                target_name (str): The name of the target node of the edge.\r\n                weight (float): The weight of the edge.\r\n            \"\"\"\r\n            if source_name is None or target_name is None or source_name == target_name:\r\n                raise ValueError(\"Invalid source and target name pair: {} - {}\".format(\r\n                    source_name, target_name)\r\n                )\r\n\r\n            # Make sure the order is right, we don't want the graph to be directed.\r\n            if source_name < target_name:\r\n                self.source_name = source_name\r\n                self.target_name = target_name\r\n            else:\r\n                self.source_name = target_name\r\n                self.target_name = source_name\r\n\r\n            self.weight = weight\r\n\r\n        # Special methods\r\n        # ------------------------------------------------------------\r\n\r\n        def __repr__(self):\r\n            \"\"\"\r\n            The string representation of the object.\r\n            \"\"\"\r\n            return \"DBEdge({} <> {})\".format(self.source_name, self.target_name)\r\n\r\n        # Properties\r\n        # ------------------------------------------------------------\r\n\r\n        @property\r\n        def creation_date(self) -> datetime.date:\r\n            \"\"\"\r\n            The date when the edge was created.\r\n            \"\"\"\r\n            return self._creation_date\r\n\r\n        # Class methods\r\n        # ------------------------------------------------------------\r\n\r\n        @classmethod\r\n        def find_by_name(cls, source_name: str, target_name: str) -> Optional[\"DBEdge\"]:\r\n            \"\"\"\r\n            Returns the `DBEdge` connecting the edges with the given names if such an edge\r\n            currently exists in the database.\r\n\r\n            Arguments:\r\n                source_name (str): The name of one of the endpoints of the queried edge.\r\n                target_name (str): The name of the other endpoint of the queried edge.\r\n\r\n            Returns:\r\n                The edge connecting the given nodes in the database if such an edge exists.\r\n            \"\"\"\r\n            if source_name < target_name:\r\n                return cls.query.filter_by(source_name=source_name, target_name=target_name).first()\r\n            else:\r\n                return cls.query.filter_by(source_name=target_name, target_name=source_name).first()\r\n\r\n    return GraphDatabaseInterface(session, DBNode, DBEdge)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the query property on the given model object.", "response": "def set_query_on_table_metaclass(model: object, session: Session):\r\n        \"\"\"\r\n        Ensures that the given database model (`DeclarativeMeta`) has a `query` property through\r\n        which the user can easily query the corresponding database table.\r\n\r\n        Database object models derived from Flask-SQLAlchemy's `database.Model` have this property\r\n        set up by default, but when using SQLAlchemy, this may not be the case. In this method this\r\n        problem we fix.\r\n\r\n        Argumentss:\r\n            model (DeclarativeMeta): The database model object whose `query` property should be\r\n                                     set up if it's not set up already.\r\n            session (Session): The session to use to set up the `query` property on `model`.\r\n        \"\"\"\r\n        if not hasattr(model, \"query\"):\r\n            model.query = session.query(model)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_feature_model():\n    try:\n        return apps.get_model(flipper_settings.FEATURE_FLIPPER_MODEL)\n    except ValueError:\n        raise ImproperlyConfigured(\n            \"FEATURE_FLIPPER_MODEL must be of the form 'app_label.model_name'\")\n    except LookupError:\n        raise ImproperlyConfigured(\n            \"FEATURE_FLIPPER_MODEL refers to model '{}' that has not been\"\n            \" installed\".format(flipper_settings.FEATURE_FLIPPER_MODEL))", "response": "Return the FeatureFlipper model defined in settings. py\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True or False for the given feature.", "response": "def show_feature(self, user, feature):\n        \"\"\"Return True or False for the given feature.\n        \"\"\"\n        user_filter = {\n            self.model.USER_FEATURE_FIELD: user,\n        }\n        return self.get_feature(feature).filter(\n            models.Q(**user_filter) | models.Q(everyone=True)).exists()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cbox(i, gray=False, spectrum=\"alternate\", reverse=False, **kwargs):\n\n    CD = {}\n    CD['dark blue'] = (0.0, 0.0, 0.55)  # 0\n    CD['greenish blue'] = (0.12, .8, .8)  # 10\n    CD['dark green'] = (0.15, 0.35, 0.0)  # 1\n    CD['yellow'] = (1.0, 1.0, 0.0)  # 6\n    CD['orangish yellow'] = (1.0, 0.9, 0.1)  # 6\n    CD['dark red'] = (0.73, 0.0, 0.0)  # 2\n    CD['dark purple'] = (0.8, 0.0, 0.8)  # 3\n    CD['light green'] = (0.49, 0.64, 0.0)  # 4\n    CD['orange'] = (1.0, 0.5, 0.0)  # 5\n    CD['light blue'] = (0.5, 0.85, 1.0)  # 6\n    CD['pink'] = (1.0, 0.8, 0.8)  # 7\n    CD['brown'] = (0.5, 0.3, 0.0)  # 8\n    CD['red'] = (0.9, 0.0, 0.0)  # 9\n\n    CD['bluey purple'] = (0.8, 0.85, 1.0)  # 12\n\n    CD['dark gray'] = (0.25, 0.25, 0.25)  #\n    CD['mid gray'] = (0.5, 0.5, 0.5)  #\n    CD['light gray'] = (0.75, 0.75, 0.75)  #\n    CD['dark grey'] = (0.25, 0.25, 0.25)  #\n    CD['mid grey'] = (0.5, 0.5, 0.5)  #\n    CD['light grey'] = (0.75, 0.75, 0.75)  #\n    CD['black5'] = (0.05, 0.05, 0.05)  #\n    CD['black'] = (0.0, 0.0, 0.0)  #\n    CD['white'] = (1.0, 1.0, 1.0)  #\n\n    if isinstance(i, int):\n        i = i\n    elif isinstance(i, float):\n        i = int(i)\n    elif isinstance(i, str):\n        dat = CD[i]\n        return dat\n    if spectrum == \"alternate\":\n        order = ['dark blue', 'orange', 'light blue', 'dark purple', 'dark green',\n                 'bluey purple', 'dark red', 'light green', 'pink', 'brown',\n                 'red', 'yellow', 'greenish blue', 'dark gray',\n                 'mid gray', 'light gray']\n    elif spectrum == \"lighten\":\n        order = ['dark blue', 'dark green', 'dark red', 'brown',\n                 'light green', 'orange', 'light blue', 'pink', 'dark purple',\n                 'red', 'greenish blue', 'bluey purple', 'yellow',\n                 'dark gray', 'mid gray', 'light gray']\n    elif spectrum == 'dots':\n        order = ['dark blue', 'yellow', 'light blue', 'dark purple', 'dark green', 'orange',\n                 'bluey purple', 'dark red', 'light green', 'pink', 'brown',\n                 'red', 'greenish blue', 'dark gray',\n                 'mid gray', 'light gray']\n    elif spectrum == \"traffic\":\n        order = ['dark green', 'orange', 'red']\n    else:  # warnings\n        order = ['light green', 'orangish yellow', 'orange', 'red', 'black', 'dark gray']\n\n    index = i % len(order)\n    if reverse:\n        index = len(order) - index - 1\n    rgb = CD[order[index]]\n\n    gray_value = 0.299 * rgb[0] + 0.587 * rgb[1] + 0.114 * rgb[2]  # calculate the gray scale value\n\n    if gray:\n        return gray_value, gray_value, gray_value\n\n    return rgb", "response": "Return a modular color box for plotting."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef spectra(i, **kwargs):\n    ordered = kwargs.get('ordered', False)\n    options = kwargs.get('options', 'best')\n    gray = kwargs.get('gray', False)\n    CD = {}\n    CD['dark blue'] = (1.0, 0.0, 0.55)  # 0\n    CD['dark green'] = (0.15, 0.35, 0.0)  # 1\n    CD['dark red'] = (0.73, 0.0, 0.0)  # 2\n    CD['dark purple'] = (0.8, 0.0, 0.8)  # 3\n    CD['light green'] = (0.49, 0.64, 0.0)  # 4\n    CD['orange'] = (1.0, 0.5, 0.0)  # 5\n    CD['light blue'] = (0.5, 0.85, 1.0)  # 6\n    CD['pink'] = (1.0, 0.8, 0.8)  # 7\n    CD['brown'] = (0.5, 0.3, 0.0)  # 8\n    CD['red'] = (0.9, 0.0, 0.0)  # 9\n    CD['greenish blue'] = (0.12, .8, .8)  # 10\n    CD['bluey purple'] = (0.8, 0.85, 1.0)  # 12\n    CD['yellow'] = (1.0, 1.0, 0.0)  # 6\n    CD['dark gray'] = (0.25, 0.25, 0.25)  #\n    CD['mid gray'] = (0.5, 0.5, 0.5)  #\n    CD['light gray'] = (0.75, 0.75, 0.75)  #\n    CD['black5'] = (0.05, 0.05, 0.05)  #\n    CD['black'] = (0.0, 0.0, 0.0)  #\n    CD['white'] = (1.0, 1.0, 1.0)  #\n\n    if isinstance(i, int):\n        i = i\n    elif isinstance(i, float):\n        i = int(i)\n    elif isinstance(i, str):\n        dat = CD[i]\n        return dat\n\n    DtoL = ['dark blue', 'dark green', 'dark red', 'brown',\n            'light green', 'orange', 'light blue', 'pink', 'dark purple',\n            'red', 'greenish blue', 'bluey purple', 'yellow',\n            'dark gray', 'mid gray', 'light gray']\n    Best = ['dark blue', 'orange', 'light blue', 'dark purple', 'dark green',\n            'bluey purple', 'dark red', 'light green', 'pink', 'brown',\n            'red', 'yellow', 'greenish blue', 'dark gray',\n            'mid gray', 'light gray']\n    Dots = ['dark blue', 'yellow', 'light blue', 'dark purple', 'dark green', 'orange',\n            'bluey purple', 'dark red', 'light green', 'pink', 'brown',\n            'red', 'greenish blue', 'dark gray',\n            'mid gray', 'light gray']\n    # ll = [0, 5, 2, 4, 1, 6, 3, 7, 8, 11, 9, 12, 10, 13, 14, 15]  # change 11 w 5\n\n    ind = i % len(Best)\n    dat = CD[Best[ind]]\n    col = Best[ind]\n    if ordered:  # if ordered is true then the colours are accessed from darkest to lightest\n        ind = i % len(DtoL)\n        dat = CD[DtoL[ind]]\n        col = DtoL[ind]\n    if options == \"dots\":\n        ind = i % len(Dots)\n        dat = CD[Dots[ind]]\n        col = Dots[ind]\n    if options == \"ordered\":\n        ind = i % len(DtoL)\n        dat = CD[DtoL[ind]]\n        col = DtoL[ind]\n\n    gray_value = 0.299 * dat[0] + 0.587 * dat[1] + 0.114 * dat[2]  # calculate the gray scale value\n\n    if gray:\n        return gray_value, gray_value, gray_value\n\n    return dat", "response": "Returns a list of spectra for the colour i in the order of gray scale or strong gray contrast for only three or four lines."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef solve_loop(slsp, u_span, j_coup):\n\n    zet, lam, eps, hlog, mean_f = [], [], [], [], [None]\n\n    for u in u_span:\n        print(u, j_coup)\n        hlog.append(slsp.selfconsistency(u, j_coup, mean_f[-1]))\n        mean_f.append(slsp.mean_field())\n        zet.append(slsp.quasiparticle_weight())\n        lam.append(slsp.param['lambda'])\n        eps.append(orbital_energies(slsp.param, zet[-1]))\n\n    return np.asarray([zet, lam, eps]), hlog, mean_f", "response": "Calculates the quasiparticle for the input loop of the given object store."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef calc_z(bands, filling, interaction, hund_cu, name):\n\n    while True:\n        try:\n            data = np.load(name+'.npz')\n            break\n        except IOError:\n            dopout = []\n            for dop in filling:\n                slsp = Spinon(slaves=2*bands, orbitals=bands, \\\n                             hopping=[0.5]*2*bands, populations=[dop]*2*bands)\n                dopout.append(solve_loop(slsp, interaction, hund_cu)[0][0])\n            np.savez(name, zeta=dopout, u_int=interaction, doping=filling, hund=hund_cu)\n\n    return data", "response": "Calculates the quasiparticle weight of degenerate system of N - bands at a given filling within an interaction range and saves the file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef label_saves(name):\n    plt.legend(loc=0)\n    plt.ylim([0, 1.025])\n    plt.xlabel('$U/D$', fontsize=20)\n    plt.ylabel('$Z$', fontsize=20)\n    plt.savefig(name, dpi=300, format='png',\n            transparent=False, bbox_inches='tight', pad_inches=0.05)", "response": "Labels plots and saves file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_curves_z(data, name, title=None):\n\n    plt.figure()\n    for zet, c in zip(data['zeta'], data['doping']):\n        plt.plot(data['u_int'], zet[:, 0], label='$n={}$'.format(str(c)))\n    if title != None:\n        plt.title(title)\n    label_saves(name+'.png')", "response": "Generates a simple plot of the quasiparticle weight decay curves given a data object with doping setup"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pick_flat_z(data):\n    zmes = []\n    for i in data['zeta']:\n        zmes.append(i[:, 0])\n    return np.asarray(zmes)", "response": "Generate a 2D array of the quasiparticle weight by only selecting the\n    first particle data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsurface plot of the quasiparticle weight as fuction of U / D and dop", "response": "def surf_z(data, name):\n    \"\"\"Surface plot of the quasiparticle weight as fuction of U/D and dop\"\"\"\n    from mpl_toolkits.mplot3d import Axes3D\n    from matplotlib import cm\n    from matplotlib.ticker import LinearLocator, FormatStrFormatter\n\n    fig = plt.figure()\n    ax = fig.gca(projection='3d')\n\n    dop, u_int = np.meshgrid(data['doping'], data['u_int'])\n    zmes = pick_flat_z(data)\n    ax.plot_surface(u_int, dop, zmes.T, rstride=1, cstride=1, cmap=cm.coolwarm,\n            linewidth=0, antialiased=False)\n    ax.contourf(u_int, dop, zmes.T, zdir='z', offset=0, cmap=cm.coolwarm)\n\n    ax.set_zlim(0, 1)\n    ax.view_init(elev=11, azim=-34)\n\n\n    ax.zaxis.set_major_locator(LinearLocator(10))\n    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n\n    ax.set_xlabel('$U/D$', fontsize=20)\n    ax.set_ylabel('$n$', fontsize=20)\n    ax.set_zlabel('$Z$', fontsize=20)\n\n    plt.savefig(name+'_surf.png', dpi=300, format='png',\n            transparent=False, bbox_inches='tight', pad_inches=0.05)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_mean_field_conv(N=1, n=0.5, Uspan=np.arange(0, 3.6, 0.5)):\n\n    sl = Spinon(slaves=2*N, orbitals=N, avg_particles=2*n,\n                       hopping=[0.5]*2*N, orbital_e=[0]*2*N)\n    hlog = solve_loop(sl, Uspan, [0.])[1]\n\n    f, (ax1, ax2) = plt.subplots(2, sharex=True)\n    for field in hlog:\n        field = np.asarray(field)\n        ax1.semilogy(abs(field[1:]-field[:-1]))\n        ax2.plot(field)#, label = 'h, U = {}'.format(Uint))\n\n    plt.title('Convergence of selfconsintent mean field')\n    ax1.set_ylabel('$\\\\Delta h$')\n    ax2.set_ylabel('mean field $h$')\n    plt.xlabel('iterations')\n\n    return hlog", "response": "Generates the plot on the convergenge of the mean field in single\n       site spin hamiltonian under with N degenerate half - filled orbitals"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assign(self, value, termenc):\n        if self._termenc != termenc:\n            self._decoder = codecs.getincrementaldecoder(termenc)(errors='replace')\n            self._termenc = termenc\n        self._data = self._decoder.decode(value)", "response": "Assign a value to the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dtypes_summary(df):\n    output_df = pd.DataFrame([])\n    row_count = df.shape[0]\n    row_indexes = ['rows_numerical','rows_string','rows_date_time','category_count','largest_category','rows_na','rows_total']\n    for colname in df:\n        data = df[colname] # data is the pandas series associated with this column\n        # number of numerical values in the column\n        rows_numerical = pd.to_numeric(data,errors = 'coerce').count()\n        # number of values that can't be coerced to a numerical\n        rows_string = row_count - rows_numerical\n        # number of values that can be coerced to a date-time object\n        rows_date_time = pd.to_datetime(data,errors = 'coerce',infer_datetime_format = True).count()\n        # categories in column\n        value_counts = data.value_counts().reset_index()\n        # number of different values in the dataframe\n        categories = len(value_counts)\n        # largest category\n        largest_category = value_counts.iloc[0,1]\n        # number of null/missing values\n        rows_na = data.isnull().sum()\n        # build the output list\n        output_data = [rows_numerical, rows_string, rows_date_time, categories, \n                       largest_category,rows_na,row_count]\n        # add to dataframe\n        output_df.loc[:,colname] = pd.Series(output_data)\n\n    # row names\n    output_df.index = row_indexes\n    return output_df", "response": "Takes in a dataframe and returns a dataframe with the data - types present in each column and the number of values that can be coerced to a date - time object and the number of null values that can be missing values that can be coerced to a date - time object and the number of values that can be coerced to a date - time object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind outliers in the dataframe.", "response": "def df_outliers(df,sensitivity = 1.5):\n    \"\"\" Finds outliers in the dataframe.\n    Parameters:\n    df - DataFrame\n        The DataFrame to analyze.\n    sensitivity - number, default 1.5\n        The value to multipy by the iter-quartile range when determining outliers. This number is used\n        for categorical data as well.\n    \"\"\"\n    outlier_df = df.copy()\n    dtypes = _basics.col_dtypes(df)\n    for col_name in df.columns:\n        outlier_df.loc[~outliers(df[col_name],'bool',dtypes[col_name],sensitivity),col_name] = np.nan\n    outlier_df = outlier_df.dropna(how = 'all')\n    return outlier_df"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef outliers(df,output_type = 'values',dtype = 'number',sensitivity = 1.5):# can output boolean array or values\n    if dtype in ('number','datetime','timedelt','datetimetz'):\n        if not dtype == 'number':\n            df = pd.to_numeric(df,errors = 'coerce')\n        quart25, quart75 = percentiles(df,q = [.25,.75]) \n        out_range= sensitivity * (quart75 - quart25)\n        lower_bound,upper_bound = quart25-out_range, quart75+out_range\n        bool_array = (df < lower_bound)|(df > upper_bound)\n    else:\n        value_counts = df.value_counts() # Trying to find categorical outliers.\n        quart25 = cum_percentile(value_counts,.25)\n        quart75 = cum_percentile(value_counts,.75)\n        out_values = int(sensitivity * (quart75 - quart25) + quart75 + 1)\n        if out_values >= len(value_counts):\n            bool_array = _utils.bc_vec(df,value = False)\n        else:\n            outlier_values = value_counts[value_counts <= value_counts.iloc[out_values]].index\n            bool_array = df.isin(outlier_values)\n        \n    if output_type == 'values':\n        return  df[bool_array]\n    return bool_array", "response": "Returns potential outliers as a boolean array or a subset of the original array."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ntake a series of ordered frequencies and returns the value at a specified quantile", "response": "def cum_percentile(series,q):\n    \"\"\" Takes a series of ordered frequencies and returns the value at a specified quantile\n    Parameters:\n    series - Series\n        The series to analyze\n    q - number\n        Quantile to get the value of\n    \"\"\"\n    total = series.sum()\n    cum_sum = series.cumsum()\n    return sum(cum_sum < total*q)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef to_dict(self):\n        result = {}\n\n        for attr, _ in six.iteritems(self.swagger_types):\n            value = getattr(self, attr)\n            if isinstance(value, list):\n                result[attr] = list(map(\n                    lambda x: x.to_dict() if hasattr(x, \"to_dict\") else x,\n                    value\n                ))\n            elif hasattr(value, \"to_dict\"):\n                result[attr] = value.to_dict()\n            elif isinstance(value, dict):\n                result[attr] = dict(map(\n                    lambda item: (item[0], item[1].to_dict())\n                    if hasattr(item[1], \"to_dict\") else item,\n                    value.items()\n                ))\n            else:\n                result[attr] = value\n        if issubclass(Payment, dict):\n            for key, value in self.items():\n                result[key] = value\n\n        return result", "response": "Returns the model properties as a dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef list_all_payments(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_payments_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_payments_with_http_info(**kwargs)\n            return data", "response": "List all payments in a specific language"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_debug(self, status):\n        if status:\n            self.logger.setLevel('DEBUG')\n        else:\n            self.logger.setLevel('INFO')", "response": "Control the logging state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the full URL for the action.", "response": "def _endpoint(self, endpoint, action, *url_args):\n        \"\"\"Return the URL for the action.\n\n        :param str endpoint: The controller\n        :param str action: The action provided by the controller\n        :param url_args: Additional endpoints(for endpoints that take part of\n                         the url as option)\n        :return: Full URL for the requested action\n        \"\"\"\n        args = (self.api_base, endpoint, action)\n        if action == '':\n            args = (self.api_base, endpoint)\n        api_url = \"/\".join(args)\n        if url_args:\n            if len(url_args) == 1:\n                api_url += \"/\" + url_args[0]\n            else:\n                api_url += \"/\".join(url_args)\n        return api_url"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _json(self, response):\n        if response.status_code == 204:\n            return None\n        try:\n            return response.json()\n        except ValueError as e:\n            raise ValueError(\n                'Exception: %s\\n'\n                'request: %s, response code: %s, response: %s' % (\n                    str(e), response.request.url, response.status_code,\n                    response.content,\n                )\n            )", "response": "JSON response from the server."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get(self, endpoint, action, *url_args, **url_params):\n        api_url = self._endpoint(endpoint, action, *url_args)\n        kwargs = {'headers': self.headers, 'params': url_params,\n                  'timeout': Client.TIMEOUT, 'verify': self.verify}\n        if self.proxies:\n            kwargs['proxies'] = self.proxies\n        self.logger.debug(\"Requesting: %s, %s\" % (api_url, str(kwargs)))\n        response = requests.get(api_url, **kwargs)\n        return self._json(response)", "response": "Request API Endpoint - for GET methods."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _send_data(self, method, endpoint, action,\n                   data, *url_args, **url_params):\n        \"\"\"Submit to API Endpoint - for DELETE, PUT, POST methods.\n\n        :param str method: Method to use for the request\n        :param str endpoint: Endpoint\n        :param str action: Endpoint Action\n        :param url_args: Additional endpoints(for endpoints that take part of\n                         the url as option)\n        :param url_params: Parameters to pass to url, typically query string\n        :return: response deserialized from JSON\n        \"\"\"\n        api_url = self._endpoint(endpoint, action, *url_args)\n        data.update({'email': self.email, 'api_key': self.api_key})\n        data = json.dumps(data)\n        kwargs = {'headers': self.headers, 'params': url_params,\n                  'verify': self.verify, 'data': data}\n        if self.proxies:\n            kwargs['proxies'] = self.proxies\n        self.logger.debug(\"Requesting: %s %s, %s\" % (method, api_url,\n                                                     str(kwargs)))\n        response = requests.request(method, api_url, **kwargs)\n        self.logger.debug(\"Response: %d, %s\" % (response.status_code,\n                                                response.content))\n        return self._json(response)", "response": "Send data to the API Endpoint"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a new Free Item Coupon", "response": "def create_free_item_coupon(cls, free_item_coupon, **kwargs):\n        \"\"\"Create FreeItemCoupon\n\n        Create a new FreeItemCoupon\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_free_item_coupon(free_item_coupon, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param FreeItemCoupon free_item_coupon: Attributes of freeItemCoupon to create (required)\n        :return: FreeItemCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_free_item_coupon_with_http_info(free_item_coupon, **kwargs)\n        else:\n            (data) = cls._create_free_item_coupon_with_http_info(free_item_coupon, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting Free Item Coupon by its ID.", "response": "def delete_free_item_coupon_by_id(cls, free_item_coupon_id, **kwargs):\n        \"\"\"Delete FreeItemCoupon\n\n        Delete an instance of FreeItemCoupon by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.delete_free_item_coupon_by_id(free_item_coupon_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_item_coupon_id: ID of freeItemCoupon to delete. (required)\n        :return: None\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_free_item_coupon_by_id_with_http_info(free_item_coupon_id, **kwargs)\n        else:\n            (data) = cls._delete_free_item_coupon_by_id_with_http_info(free_item_coupon_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds FreeItemCoupon by its ID Return single instance of FreeItemCoupon with the given ID.", "response": "def get_free_item_coupon_by_id(cls, free_item_coupon_id, **kwargs):\n        \"\"\"Find FreeItemCoupon\n\n        Return single instance of FreeItemCoupon by its ID.\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.get_free_item_coupon_by_id(free_item_coupon_id, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_item_coupon_id: ID of freeItemCoupon to return (required)\n        :return: FreeItemCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_free_item_coupon_by_id_with_http_info(free_item_coupon_id, **kwargs)\n        else:\n            (data) = cls._get_free_item_coupon_by_id_with_http_info(free_item_coupon_id, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef list_all_free_item_coupons(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_free_item_coupons_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_free_item_coupons_with_http_info(**kwargs)\n            return data", "response": "List Free Item Coupons by Free Item Cookie"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreplacing Free Item Coupon by ID and attributes.", "response": "def replace_free_item_coupon_by_id(cls, free_item_coupon_id, free_item_coupon, **kwargs):\n        \"\"\"Replace FreeItemCoupon\n\n        Replace all attributes of FreeItemCoupon\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_free_item_coupon_by_id(free_item_coupon_id, free_item_coupon, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str free_item_coupon_id: ID of freeItemCoupon to replace (required)\n        :param FreeItemCoupon free_item_coupon: Attributes of freeItemCoupon to replace (required)\n        :return: FreeItemCoupon\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_free_item_coupon_by_id_with_http_info(free_item_coupon_id, free_item_coupon, **kwargs)\n        else:\n            (data) = cls._replace_free_item_coupon_by_id_with_http_info(free_item_coupon_id, free_item_coupon, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_free_item_coupon_by_id(cls, free_item_coupon_id, free_item_coupon, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_free_item_coupon_by_id_with_http_info(free_item_coupon_id, free_item_coupon, **kwargs)\n        else:\n            (data) = cls._update_free_item_coupon_by_id_with_http_info(free_item_coupon_id, free_item_coupon, **kwargs)\n            return data", "response": "Update attributes of FreeItemCoupon by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprocesses all the events for logging and S3.", "response": "def process_events(events, source_ip):\n    \"\"\"Process all the events for logging and S3.\"\"\"\n    s3 = boto3.resource('s3')\n    table = boto3.resource(\"dynamodb\").Table(os.environ['database'])\n    with table.batch_writer() as batch:\n        for idx, event in enumerate(events):\n            event = convert_keys_to_string(event)\n            event['sourceIp'] = source_ip\n            event['event'] = hashlib.sha256(str(event)).hexdigest()\n            metadata = event['metadata']\n            timestamp = str(event['metadata']['timeStamp'])\n            event['metadata']['timeStamp'] = timestamp\n            kwargs = {'match': event['indicatorMatch'],\n                      'type': metadata['type'],\n                      'method': metadata['method'].lower(),\n                      'time': event['analysisTime'], 'ip': source_ip}\n            file_struct = '{match}_{type}_{method}_{ip}_{time}.json'\n            file_name = file_struct.format(**kwargs)\n            key_path = '/tmp/%s' % file_name\n            output = json.dumps(event, indent=4, sort_keys=True)\n            open(key_path, \"w\").write(output)\n            data = open(key_path, 'rb')\n            s3.Bucket(os.environ['s3_bucket']).put_object(Key=file_name,\n                                                          Body=data)\n            logger.info(\"EVENT: %s\" % str(event))\n            batch.put_item(Item=event)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset the cost_type of this TableRateShipping.", "response": "def cost_type(self, cost_type):\n        \"\"\"Sets the cost_type of this TableRateShipping.\n\n\n        :param cost_type: The cost_type of this TableRateShipping.\n        :type: str\n        \"\"\"\n        allowed_values = [\"orderSubtotal\", \"weight\"]\n        if cost_type is not None and cost_type not in allowed_values:\n            raise ValueError(\n                \"Invalid value for `cost_type` ({0}), must be one of {1}\"\n                .format(cost_type, allowed_values)\n            )\n\n        self._cost_type = cost_type"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new TableRateShipping with the given attributes.", "response": "def create_table_rate_shipping(cls, table_rate_shipping, **kwargs):\n        \"\"\"Create TableRateShipping\n\n        Create a new TableRateShipping\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.create_table_rate_shipping(table_rate_shipping, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param TableRateShipping table_rate_shipping: Attributes of tableRateShipping to create (required)\n        :return: TableRateShipping\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_table_rate_shipping_with_http_info(table_rate_shipping, **kwargs)\n        else:\n            (data) = cls._create_table_rate_shipping_with_http_info(table_rate_shipping, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete_table_rate_shipping_by_id(cls, table_rate_shipping_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, **kwargs)\n        else:\n            (data) = cls._delete_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, **kwargs)\n            return data", "response": "Delete an instance of TableRateShipping by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_table_rate_shipping_by_id(cls, table_rate_shipping_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, **kwargs)\n        else:\n            (data) = cls._get_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, **kwargs)\n            return data", "response": "Find TableRateShipping by ID Return single instance of TableRateShipping by its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef list_all_table_rate_shippings(cls, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_table_rate_shippings_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_table_rate_shippings_with_http_info(**kwargs)\n            return data", "response": "List TableRateShippings\n        Return a list of TableRateShippings\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_table_rate_shipping_by_id(cls, table_rate_shipping_id, table_rate_shipping, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, table_rate_shipping, **kwargs)\n        else:\n            (data) = cls._replace_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, table_rate_shipping, **kwargs)\n            return data", "response": "Replace all attributes of TableRateShipping by ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update_table_rate_shipping_by_id(cls, table_rate_shipping_id, table_rate_shipping, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, table_rate_shipping, **kwargs)\n        else:\n            (data) = cls._update_table_rate_shipping_by_id_with_http_info(table_rate_shipping_id, table_rate_shipping, **kwargs)\n            return data", "response": "Update attributes of TableRateShipping by ID"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a FormattedPair containing the next key and token.", "response": "def next_formatted_pair(self):\n      \"\"\"\\\n      Returns a :class:`FormattedPair <shorten.store.FormattedPair>` containing \n      attributes `key`, `token`, `formatted_key` and `formatted_token`. \n      Calling this method will always consume a key and token.\n      \"\"\"\n\n      key = self.key_gen.next()\n      token = self.token_gen.create_token(key)\n      fkey = self.formatter.format_key(key)\n      ftoken = self.formatter.format_token(token)\n\n      return FormattedPair(key, token, fkey, ftoken)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_source(path):\n    ''' yields all non-empty lines in a file '''\n    for line in read(path):\n        if 'import' in line or len(line.strip()) == 0 or line.startswith('#'):\n            continue\n        if '__name__' in line and '__main__' in line:\n            break\n        else:\n            yield line", "response": "yields all non - empty lines in a file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_option_value(cls, option_value, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._create_option_value_with_http_info(option_value, **kwargs)\n        else:\n            (data) = cls._create_option_value_with_http_info(option_value, **kwargs)\n            return data", "response": "Create an OptionValue by its attribute value."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete_option_value_by_id(cls, option_value_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._delete_option_value_by_id_with_http_info(option_value_id, **kwargs)\n        else:\n            (data) = cls._delete_option_value_by_id_with_http_info(option_value_id, **kwargs)\n            return data", "response": "Delete an option value by its ID."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_option_value_by_id(cls, option_value_id, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._get_option_value_by_id_with_http_info(option_value_id, **kwargs)\n        else:\n            (data) = cls._get_option_value_by_id_with_http_info(option_value_id, **kwargs)\n            return data", "response": "Find OptionValue by its ID Return single instance of OptionValue with its ID."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlists OptionValues Return a list of OptionValues", "response": "def list_all_option_values(cls, **kwargs):\n        \"\"\"List OptionValues\n\n        Return a list of OptionValues\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.list_all_option_values(async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param int page: page number\n        :param int size: page size\n        :param str sort: page order\n        :return: page[OptionValue]\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._list_all_option_values_with_http_info(**kwargs)\n        else:\n            (data) = cls._list_all_option_values_with_http_info(**kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreplace all attributes of OptionValue by ID", "response": "def replace_option_value_by_id(cls, option_value_id, option_value, **kwargs):\n        \"\"\"Replace OptionValue\n\n        Replace all attributes of OptionValue\n        This method makes a synchronous HTTP request by default. To make an\n        asynchronous HTTP request, please pass async=True\n        >>> thread = api.replace_option_value_by_id(option_value_id, option_value, async=True)\n        >>> result = thread.get()\n\n        :param async bool\n        :param str option_value_id: ID of optionValue to replace (required)\n        :param OptionValue option_value: Attributes of optionValue to replace (required)\n        :return: OptionValue\n                 If the method is called asynchronously,\n                 returns the request thread.\n        \"\"\"\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._replace_option_value_by_id_with_http_info(option_value_id, option_value, **kwargs)\n        else:\n            (data) = cls._replace_option_value_by_id_with_http_info(option_value_id, option_value, **kwargs)\n            return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_option_value_by_id(cls, option_value_id, option_value, **kwargs):\n        kwargs['_return_http_data_only'] = True\n        if kwargs.get('async'):\n            return cls._update_option_value_by_id_with_http_info(option_value_id, option_value, **kwargs)\n        else:\n            (data) = cls._update_option_value_by_id_with_http_info(option_value_id, option_value, **kwargs)\n            return data", "response": "Update attributes of OptionValue by ID"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bool_set(operation,*sets):\n    '''combine ``sets`` with ``operation``\n    \n    :and:       combine sets with AND\n    :or:        combine sets with OR\n    :not:       NOT sets versus the last given set'''\n    if len(sets)<=1:\n        return sets\n    if operation=='and':\n        return and_sets(*sets)\n    if operation=='or':\n        return or_sets(*sets)\n    if operation=='not':\n        return not_sets(*sets)", "response": "combine sets with operation and return the last set"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntransforming a datetime. datetime into a NationStates - style string.", "response": "def datetime_to_ns(then):\n    \"\"\"Transform a :any:`datetime.datetime` into a NationStates-style\n    string.\n\n    For example \"6 days ago\", \"105 minutes ago\", etc.\n    \"\"\"\n    if then == datetime(1970, 1, 1, 0, 0):\n        return 'Antiquity'\n\n    now = datetime.utcnow()\n    delta = now - then\n    seconds = delta.total_seconds()\n\n    # There's gotta be a better way to do this...\n    years,   seconds = divmod(seconds, 60*60*24*365)\n    days,    seconds = divmod(seconds, 60*60*24)\n    hours,   seconds = divmod(seconds, 60*60)\n    minutes, seconds = divmod(seconds, 60)\n    years   = int(years)\n    days    = int(days)\n    hours   = int(hours)\n    minutes = int(minutes)\n    seconds = round(seconds)\n\n    if years > 1:\n        if days > 1:\n            return f'{years} years {days} days ago'\n        elif days == 1:\n            return '{years} years 1 day ago'\n        return '{years} years ago'\n    if years == 1:\n        if days > 1:\n            return f'1 year {days} days ago'\n        elif days == 1:\n            return '1 year 1 day ago'\n        return '1 year ago'\n\n    if days > 3:\n        return f'{days} days ago'\n    if days > 1:\n        if hours > 1:\n            return f'{days} days {hours} hours ago'\n        elif hours == 1:\n            return f'{days} days 1 hour ago'\n        return f'{days} days ago'\n    if days == 1:\n        if hours > 1:\n            return f'1 day {hours} hours ago'\n        elif hours == 1:\n            return '1 day 1 hour ago'\n        return '1 day ago'\n\n    if hours > 1:\n        return f'{hours} hours ago'\n    if hours == 1:\n        return f'{minutes + 60} minutes ago'\n\n    if minutes > 1:\n        return f'{minutes} minutes ago'\n    if minutes == 1:\n        return '1 minute ago'\n\n    return 'Seconds ago'"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nauthenticates request using HTTP Basic authentication protocl.", "response": "def authenticate(self, request):\n        \"\"\" Authenticate request using HTTP Basic authentication protocl.\n\n        If the user is successfully identified, the corresponding user\n        object is stored in `request.user`. If the request has already\n        been authenticated (i.e. `request.user` has authenticated user\n        object), this function does nothing.\n\n        Raises Forbidden or Unauthorized if the user authentication\n        fails. If no exception is thrown, the `request.user` will\n        contain authenticated user object.\n        \"\"\"\n\n        # todo: can we trust that request.user variable is even defined?\n        if request.user and request.user.is_authenticated():\n            return request.user\n\n        if 'HTTP_AUTHORIZATION' in request.META:\n            auth = request.META['HTTP_AUTHORIZATION'].split()\n            if len(auth) == 2:\n                if auth[0].lower() == \"basic\":\n                    uname, passwd = base64.b64decode(auth[1]).split(':')\n                    user = authenticate(username=uname, password=passwd)\n                    if user is not None:\n                        if user.is_active:\n                            request.user = user\n                            return user\n                    else:\n                        raise Forbidden()\n\n        # either no auth header or using some other auth protocol,\n        # we'll return a challenge for the user anyway\n        raise Unauthorized()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncleans up previous garbage", "response": "def clean():\n    \"\"\"Clean up previous garbage\"\"\"\n    os.chdir(os.path.join(project_root, 'docs'))\n    sh(\"make clean\")\n    os.chdir(project_root)\n    sh(\"rm -rf pyoauth2.egg-info\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncheck if parameter is unit rule.", "response": "def _is_unit(rule):\n    # type: (Type[Rule]) -> bool\n    \"\"\"\n    Check if parameter is unit rule.\n    :param rule: Object to check.\n    :return: True if is parameter unit rule, false otherwise.\n    \"\"\"\n    return len(rule.left) == 1 and len(rule.right) == 1 and \\\n           isclass(rule.fromSymbol) and isclass(rule.toSymbol) and \\\n           issubclass(rule.fromSymbol, Nonterminal) and issubclass(rule.toSymbol, Nonterminal)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_rule(rule, index, backtrack):\n    # type: (Rule, int, Dict[Type[Nonterminal], Type[Rule]]) -> Type[EpsilonRemovedRule]\n    \"\"\"\n    Create EpsilonRemovedRule. This rule will skip symbol at the `index`.\n    :param rule: Original rule.\n    :param index: Index of symbol that is rewritable to epsilon.\n    :param backtrack: Dictionary where key is nonterminal and value is rule which is next to generate epsilon.\n    :return: EpsilonRemovedRule class without symbol rewritable to epsilon.\n    \"\"\"\n    # remove old rules from the dictionary\n    old_dict = rule.__dict__.copy()\n    if 'rules' in old_dict: del old_dict['rules']\n    if 'rule' in old_dict: del old_dict['rule']\n    if 'left' in old_dict: del old_dict['left']\n    if 'right' in old_dict: del old_dict['right']\n    if 'fromSymbol' in old_dict: del old_dict['fromSymbol']\n    if 'toSymbol' in old_dict: del old_dict['toSymbol']\n    # create type\n    created = type('NoEps[' + rule.__name__ + ']',\n                   (EpsilonRemovedRule,),\n                   old_dict)  # type: Type[EpsilonRemovedRule]\n    # add from_rule and index\n    created.from_rule = rule\n    created.replace_index = index\n    created.backtrack = backtrack\n    # attach rule\n    created.fromSymbol = rule.fromSymbol\n    created.right = [rule.right[i] for i in range(len(rule.right)) if i != index]\n    # ff the right side is empty\n    if len(created.right) == 0:\n        created.right = [EPSILON]\n    return created", "response": "Create a new rule with the given index and backtrack."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_rules_with_epsilon(grammar, inplace=False):\n    # type: (Grammar, bool) -> Grammar\n    \"\"\"\n    Remove epsilon rules.\n    :param grammar: Grammar where rules remove\n    :param inplace: True if transformation should be performed in place, false otherwise.\n    False by default.\n    :return: Grammar without epsilon rules.\n    \"\"\"\n    # copy if required\n    if inplace is False:\n        grammar = copy(grammar)\n    # find nonterminals rewritable to epsilon\n    rewritable = find_nonterminals_rewritable_to_epsilon(grammar)  # type: Dict[Type[Nonterminal], Type[Rule]]\n    # create queue from rules to iterate over\n    rules = Queue()\n    for r in grammar.rules:\n        rules.put(r)\n    # iterate thought rules\n    while not rules.empty():\n        rule = rules.get()\n        right = rule.right\n        # if the rule rewrite to epsilon we can safely delete it\n        if right == [EPSILON]:\n            # unless it rewrites from the start symbol\n            if rule.fromSymbol != grammar.start:\n                grammar.rules.discard(rule)\n            # continue IS executed, but due optimization line is marked as missed.\n            continue  # pragma: no cover\n        # iterate over the right side\n        for rule_index in range(len(right)):\n            symbol = right[rule_index]\n            # if symbol is rewritable, generate new rule without that symbol\n            if symbol in rewritable:\n                new_rule = _create_rule(rule, rule_index, rewritable)\n                grammar.rules.add(new_rule)\n                rules.put(new_rule)  # in case there are more rewritable symbols\n    return grammar", "response": "Removes epsilon rules from the grammar."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef args(self):\n        if self._args is None:\n            parser = self._build_parser()\n            self._args = parser.parse_args()\n        return self._args", "response": "Parsed command - line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nbuild the string representing the parsed package basename.", "response": "def build_pypackage_basename(self, pytree, base):\n        \"\"\"Build the string representing the parsed package basename.\n\n        :param str pytree: The pytree absolute path.\n        :param str pytree: The absolute path of the pytree sub-package of which determine the\n            parsed name.\n        :rtype: str\n        \"\"\"\n        dirname = os.path.dirname(pytree)\n        parsed_package_name = base.replace(dirname, '').strip('/')\n        return parsed_package_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds the needed command - line parser.", "response": "def _build_parser(self):\n        \"\"\"Build the needed command-line parser.\"\"\"\n        parser = argparse.ArgumentParser()\n\n        parser.add_argument('--pytree',\n                            required=True,\n                            type=self._valid_directory,\n                            help='This is the path, absolute or relative, of the Python package '\n                                 'that is to be parsed.')\n\n        parser.add_argument('--doctree',\n                            required=True,\n                            type=self._valid_directory,\n                            help='This is the path, absolute or relative, of the documentation '\n                                 'package that is to be parsed.')\n\n        parser.add_argument('--no-fail',\n                            action='store_true',\n                            help='Using this option will cause this program to return an exit '\n                                 'code of 0 even when the given trees do not match.')\n\n        parser.add_argument('--doc-ignores',\n                            action=AddDocIgnores,\n                            help='A comma separated list of additional doc files to ignore')\n\n        return parser"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_pyfile_path_from_docname(self, docfile):\n        name, ext = os.path.splitext(docfile)\n        expected_py_name = name.replace('.', '/') + '.py'\n        return expected_py_name", "response": "Builds the expected Python file name based on the given documentation file name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the differences between the given trees and the given documentation trees.", "response": "def calculate_tree_differences(self, pytree, doctree):\n        \"\"\"Calculate the differences between the given trees.\n\n        :param dict pytree: The dictionary of the parsed Python tree.\n        :param dict doctree: The dictionary of the parsed documentation tree.\n        :rtype: tuple\n        :returns: A two-tuple of sets, where the first is the missing Python files, and the second\n            is the missing documentation files.\n        \"\"\"\n        pykeys = set(pytree.keys())\n        dockeys = set(doctree.keys())\n\n        # Calculate the missing documentation files, if any.\n        missing_doc_keys = pykeys - dockeys\n        missing_docs = {pytree[pyfile] for pyfile in missing_doc_keys}\n\n        # Calculate the missing Python files, if any.\n        missing_py_keys = dockeys - pykeys\n        missing_pys = {docfile for docfile in missing_py_keys}\n\n        return missing_pys, missing_docs"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompares the given parsed trees.", "response": "def compare_trees(self, parsed_pytree, parsed_doctree):\n        \"\"\"Compare the given parsed trees.\n\n        :param dict parsed_pytree: A dictionary representing the parsed Python tree where each\n            key is a parsed Python file and its key is its expected rst file name.\n        \"\"\"\n        if parsed_pytree == parsed_doctree:\n            return 0\n\n        missing_pys, missing_docs = self.calculate_tree_differences(pytree=parsed_pytree,\n                                                                    doctree=parsed_doctree)\n        self.pprint_tree_differences(missing_pys=missing_pys, missing_docs=missing_docs)\n        return 0 if self.args.no_fail else 1"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse_doc_tree(self, doctree, pypackages):\n        parsed_doctree = {}\n        for filename in os.listdir(doctree):\n            if self._ignore_docfile(filename):\n                continue\n\n            expected_pyfile = self.build_pyfile_path_from_docname(filename)\n            parsed_doctree[expected_pyfile] = filename\n\n        pypackages = {name + '.py' for name in pypackages}\n        return {elem: parsed_doctree[elem] for elem in parsed_doctree if elem not in pypackages}", "response": "Parse the given documentation tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nparsing the given Python package tree.", "response": "def parse_py_tree(self, pytree):\n        \"\"\"Parse the given Python package tree.\n\n        :param str pytree: The absolute path to the Python tree which is to be parsed.\n        :rtype: dict\n        :returns: A two-tuple. The first element is a dict where each key is the path of a parsed\n            Python module (relative to the Python tree) and its value is the expected rst module\n            name. The second element is a set where each element is a Python package or\n            sub-package.\n        :rtype: tuple\n        \"\"\"\n        parsed_pytree = {}\n        pypackages = set()\n        for base, dirs, files in os.walk(pytree):\n            if self._ignore_pydir(os.path.basename(base)):\n                continue\n\n            # TODO(Anthony): If this is being run against a Python 3 package, this needs to be\n            # adapted to account for namespace packages.\n            elif '__init__.py' not in files:\n                continue\n\n            package_basename = self.build_pypackage_basename(pytree=pytree, base=base)\n            pypackages.add(package_basename)\n\n            for filename in files:\n                if self._ignore_pyfile(filename):\n                    continue\n\n                parsed_path = os.path.join(package_basename, filename)\n                parsed_pytree[parsed_path] = self.build_rst_name_from_pypath(parsed_path)\n\n        return parsed_pytree, pypackages"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the missing files of each given set.", "response": "def pprint_tree_differences(self, missing_pys, missing_docs):\n        \"\"\"Pprint the missing files of each given set.\n\n        :param set missing_pys: The set of missing Python files.\n        :param set missing_docs: The set of missing documentation files.\n        :rtype: None\n        \"\"\"\n        if missing_pys:\n            print('The following Python files appear to be missing:')\n            for pyfile in missing_pys:\n                print(pyfile)\n            print('\\n')\n\n        if missing_docs:\n            print('The following documentation files appear to be missing:')\n            for docfiile in missing_docs:\n                print(docfiile)\n            print('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _valid_directory(self, path):\n        abspath = os.path.abspath(path)\n        if not os.path.isdir(abspath):\n            raise argparse.ArgumentTypeError('Not a valid directory: {}'.format(abspath))\n        return abspath", "response": "Ensure that the given path is a valid directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main(self):\n        args = self.args\n        parsed_pytree, pypackages = self.parse_py_tree(pytree=args.pytree)\n        parsed_doctree = self.parse_doc_tree(doctree=args.doctree, pypackages=pypackages)\n        return self.compare_trees(parsed_pytree=parsed_pytree, parsed_doctree=parsed_doctree)", "response": "Parse package trees and report on any discrepancies."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the base class for a simulation run", "response": "def initialize(self, grid, num_of_paths, seed):\n        \"\"\" inits producer for a simulation run \"\"\"\n        for p in self.producers:\n            p.initialize(grid, num_of_paths, seed)\n        self.grid = grid\n        self.num_of_paths = num_of_paths\n        self.seed = seed"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef initialize_worker(self, process_num=None):\n        for p in self.producers:\n            p.initialize_worker(process_num)\n        # self.initial_state.process = process_num\n        self.random.seed(hash(self.seed) + hash(process_num))", "response": "Initializes the producer for a simulation run on a single process"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef initialize_path(self, path_num=None):\n        for p in self.producers:\n            p.initialize_path(path_num)\n        # self.state = copy(self.initial_state)\n        # self.state.path = path_num\n        self.random.seed(hash(self.seed) + hash(path_num))", "response": "Initializes the state of the current state for the next path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef evolve(self, new_date):\n        self.state = [p.evolve(new_date) for p in self.producers]\n        return self.state", "response": "evolve to the new process state at the next date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting db model by username", "response": "def where_unique(cls, ip, object_id, location):\r\n        \"\"\" Get db model by username \"\"\"\r\n        return cls.query.filter_by(\r\n            ip=ip,\r\n            object_id=object_id,\r\n            location=location).first()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes by ip and object id", "response": "def delete_where_unique(cls, ip, object_id, location):\r\n        \"\"\" delete by ip and object id \"\"\"\r\n        result = cls.where_unique(ip, object_id, location)\r\n        if result is None:\r\n            return None\r\n        result.delete()\r\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef do_req(self, method, url, body=None, headers=None, status=None):\n        if body is None:\n            body = ''\n        else:\n            body = json.dumps(body)\n        res = self.backend.dispatch_request(method=method,\n                                            url=url,\n                                            body=body,\n                                            headers=self.get_headers(headers),\n                                            auth=self.auth)\n        if not isinstance(res, MapiResponse):\n            res = MapiResponse(*res)\n        if status is None:\n            if res.status // 100 != 2:\n                raise MapiError(*res)\n        elif res.status != status:\n            raise MapiError(*res)\n\n        return res", "response": "This method is used internally to send a request to the API. It is used internally to send a request to the API left public\n        so it can be used to talk to the API more directly."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all the items that are returned while storing the data in a list.", "response": "def _depaginate_all(self, url):\n        \"\"\"GETs the url provided and traverses the 'next' url that's\n        returned while storing the data in a list. Returns a single list of all\n        items.\n        \"\"\"\n        items = []\n        for x in self._depagination_generator(url):\n            items += x\n        return items"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_user(self, user_id,\n                    roles=None, netmask=None,\n                    secret=None, pubkey=None):\n        u\"\"\"Create user for the Merchant given in the X-Mcash-Merchant header.\n\n        Arguments:\n            user_id:\n                Identifier for the user\n            roles:\n                Role\n            netmask:\n                Limit user connections by netmask, for example 192.168.1.0/24\n            secret:\n                Secret used when authenticating with mCASH\n            pubkey:\n                RSA key used for authenticating by signing\n        \"\"\"\n        arguments = {'id': user_id,\n                     'roles': roles,\n                     'netmask': netmask,\n                     'secret': secret,\n                     'pubkey': pubkey}\n        return self.do_req('POST', self.merchant_api_base_url + '/user/', arguments).json()", "response": "u Create a user for the Merchant given in the X - Mcash - Merchant header."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the user s properties. Returns the raw response object.", "response": "def update_user(self, user_id,\n                    roles=None, netmask=None,\n                    secret=None, pubkey=None):\n        \"\"\"Update user. Returns the raw response object.\n\n        Arguments:\n            user_id:\n                User id of user to update\n            roles:\n                Role\n            netmask:\n                Limit user connections by netmask, for example 192.168.1.0/24\n            secret:\n                Secret used when authenticating with mCASH\n            pubkey:\n                RSA key used for authenticating by signing\n        \"\"\"\n        arguments = {'roles': roles,\n                     'netmask': netmask,\n                     'secret': secret,\n                     'pubkey': pubkey}\n        return self.do_req('PUT',\n                           self.merchant_api_base_url + '/user/' +\n                           user_id + '/', arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new POS resource in the specified user and type", "response": "def create_pos(self, name, pos_type,\n                   pos_id, location=None):\n        \"\"\"Create POS resource\n\n        Arguments:\n            name:\n                Human-readable name of the POS, used for displaying payment\n                request origin to end user\n            pos_type:\n                POS type\n            location:\n                Merchant location\n            pos_id:\n                The ID of the POS that is to be created. Has to be unique for\n                the merchant\n        \"\"\"\n        arguments = {'name': name,\n                     'type': pos_type,\n                     'id': pos_id,\n                     'location': location}\n        return self.do_req('POST', self.merchant_api_base_url + '/pos/', arguments).json()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the details of a user s POS. Returns the raw response object.", "response": "def update_pos(self, pos_id, name, pos_type, location=None):\n        \"\"\"Update POS resource. Returns the raw response object.\n\n        Arguments:\n            pos_id:\n                POS id as chosen on registration\n            name:\n                Human-readable name of the POS, used for displaying payment\n                request origin to end user\n            pos_type:\n                POS type\n            location:\n                Merchant location\n        \"\"\"\n        arguments = {'name': name,\n                     'type': pos_type,\n                     'location': location}\n        return self.do_req('PUT',\n                           self.merchant_api_base_url + '/pos/' +\n                           pos_id + '/', arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a payment request for the specified customer and currency.", "response": "def create_payment_request(self, customer, currency, amount, allow_credit,\n                               pos_id, pos_tid, action, ledger=None,\n                               display_message_uri=None, callback_uri=None,\n                               additional_amount=None, additional_edit=None,\n                               text=None, expires_in=None, required_scope=None,\n                               required_scope_text=None, links=None, line_items=None):\n        \"\"\"Post payment request. The call is idempotent; that is, if one posts\n        the same pos_id and pos_tid twice, only one payment request is created.\n\n        Arguments:\n            ledger:\n                Log entries will be added to the open report on the specified\n                ledger\n            display_message_uri:\n                Messages that can be used to inform the POS operator about the\n                progress of the payment request will be POSTed to this URI if\n                provided\n            callback_uri:\n                If provided, mCASH will POST to this URI when the status of the\n                payment request changes, using the message mechanism described\n                in the introduction. The data in the \"object\" part of the\n                message is the same as what can be retrieved by calling GET on\n                the \"/payment_request/<tid>/outcome/\" resource URI.\n            customer:\n                Customer identifiers include msisdn, scan token or access token\n            currency:\n                3 chars https://en.wikipedia.org/wiki/ISO_4217\n            amount:\n                The base amount of the payment\n            additional_amount:\n                Typically cash withdrawal or gratuity\n            additional_edit:\n                Whether user is allowed to additional amount for gratuity or\n                similar\n            allow_credit:\n                Whether to allow credit payment for this payment request.\n                Credit incurs interchange\n            pos_id:\n                The POS this payment request originates from, used for\n                informing user about origin\n            pos_tid:\n                Local transaction id for POS. This must be unique for the POS\n            text:\n                Text that is shown to user when asked to pay. This can contain\n                linebreaks and the text has to fit on smartphones screens.\n            action:\n                Action to perform, the main difference is what it looks like in\n                App UI.\n            expires_in:\n                Expiration in seconds from when server received request\n            required_scope:\n                Scopes required to fulfill payment\n            required_scope_text:\n                Text that is shown to user when asked for permission.\n            links:\n                A list of links to be shown in app in various states\n                [{\"uri\": \"http://example.com/uri1\",\n                  \"caption\": \"This is always shown\",\n                  \"show_on\": [\"pending\", \"fail\", \"ok\"]}]\n            line_items:\n                A list of product lines in the payment request. Each item should\n                contain product_id, vat, description (optional), vat_rate, total,\n                item_cost, quantity and optionally tags, which is a list of tag\n                dicts containing tag_id and label. The sum of all\n                line item totals must be equal to the amount argument.\n                [{\"product_id\": \"product-1\", vat: \"0.50\",\n                description: \"An optional description\", vat_rate: \"0.25\",\n                total: \"5.00\", item_cost: \"2.50\", quantity: \"2\", \"tags\": [\n                    {\"tag_id\": \"product-info-5\", \"label\": \"Some product info\"}\n                ]}]\n        \"\"\"\n        arguments = {'customer': customer,\n                     'currency': currency,\n                     'amount': amount,\n                     'allow_credit': allow_credit,\n                     'pos_id': pos_id,\n                     'pos_tid': pos_tid,\n                     'action': action,\n                     'ledger': ledger,\n                     'display_message_uri': display_message_uri,\n                     'callback_uri': callback_uri,\n                     'additional_amount': additional_amount,\n                     'additional_edit': additional_edit,\n                     'text': text,\n                     'expires_in': expires_in}\n\n        if required_scope:\n            arguments['required_scope'] = required_scope\n            arguments['required_scope_text'] = required_scope_text\n        if links:\n            arguments['links'] = links\n\n        if line_items:\n            arguments['line_items'] = line_items\n\n        return self.do_req('POST', self.merchant_api_base_url + '/payment_request/',\n                           arguments).json()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates payment request, reauthorize, capture, release or abort It is possible to update ledger and the callback URIs for a payment request. Changes are always appended to the open report of a ledger, and notifications are sent to the callback registered at the time of notification. Capturing an authorized payment or reauthorizing is done with the action field. The call is idempotent; that is, if one posts the same amount, additional_amount and capture_id twice with action CAPTURE, only one capture is performed. Similarly, if one posts twice with action CAPTURE without any amount stated, to capture the full amount, only one full capture is performed. Arguments: ledger: Log entries will be added to the open report on the specified ledger display_message_uri: Messages that can be used to inform the POS operator about the progress of the payment request will be POSTed to this URI if provided callback_uri: If provided, mCASH will POST to this URI when the status of the payment request changes, using the message mechanism described in the introduction. The data in the \"object\" part of the message is the same as what can be retrieved by calling GET on the \"/payment_request/<tid>/outcome/\" resource URI. currency: 3 chars https://en.wikipedia.org/wiki/ISO_4217 amount: The base amount of the payment additional_amount: Typically cash withdrawal or gratuity capture_id: Local id for capture. Must be set if amount is set, otherwise capture_id must be unset. tid: Transaction id assigned by mCASH refund_id: Refund id needed when doing partial refund text: For example reason for refund. action: Action to perform. required_scope: Scopes required to fulfill payment line_items: An updated line_items. Will fail if line_items already set in the payment request or if the sum of the totals is different from the original amount. required_scope_text: Text that is shown to user when asked for permission.", "response": "def update_payment_request(self, tid, currency=None, amount=None,\n                               action=None, ledger=None, callback_uri=None,\n                               display_message_uri=None, capture_id=None,\n                               additional_amount=None, text=None, refund_id=None,\n                               required_scope=None, required_scope_text=None, line_items=None):\n        \"\"\"Update payment request, reauthorize, capture, release or abort\n\n        It is possible to update ledger and the callback URIs for a payment\n        request. Changes are always appended to the open report of a ledger,\n        and notifications are sent to the callback registered at the time of\n        notification.\n\n        Capturing an authorized payment or reauthorizing is done with the\n        action field.\n\n        The call is idempotent; that is, if one posts the same amount,\n        additional_amount and capture_id twice with action CAPTURE, only one\n        capture is performed. Similarly, if one posts twice with action CAPTURE\n        without any amount stated, to capture the full amount, only one full\n        capture is performed.\n\n        Arguments:\n            ledger:\n                Log entries will be added to the open report on the specified\n                ledger\n            display_message_uri:\n                Messages that can be used to inform the POS operator about the\n                progress of the payment request will be POSTed to this URI if\n                provided\n            callback_uri:\n                If provided, mCASH will POST to this URI when the status of the\n                payment request changes, using the message mechanism described\n                in the introduction. The data in the \"object\" part of the\n                message is the same as what can be retrieved by calling GET on\n                the \"/payment_request/<tid>/outcome/\" resource URI.\n            currency:\n                3 chars https://en.wikipedia.org/wiki/ISO_4217\n            amount:\n                The base amount of the payment\n            additional_amount:\n                Typically cash withdrawal or gratuity\n            capture_id:\n                Local id for capture. Must be set if amount is set, otherwise\n                capture_id must be unset.\n            tid:\n                Transaction id assigned by mCASH\n            refund_id:\n                Refund id needed when doing partial refund\n            text:\n                For example reason for refund.\n            action:\n                Action to perform.\n            required_scope:\n                Scopes required to fulfill payment\n            line_items:\n                An updated line_items. Will fail if line_items\n                already set in the payment request or if the sum of the totals\n                is different from the original amount.\n            required_scope_text:\n                Text that is shown to user when asked for permission.\n        \"\"\"\n        arguments = {'ledger': ledger,\n                     'display_message_uri': display_message_uri,\n                     'callback_uri': callback_uri,\n                     'currency': currency,\n                     'amount': amount,\n                     'additional_amount': additional_amount,\n                     'capture_id': capture_id,\n                     'action': action,\n                     'text': text,\n                     'refund_id': refund_id}\n\n        if required_scope:\n            arguments['required_scope'] = required_scope\n            arguments['required_scope_text'] = required_scope_text\n\n        if line_items:\n            arguments['line_items'] = line_items\n\n\n        arguments = {k: v for k, v in arguments.items() if v is not None}\n        return self.do_req('PUT',\n                           self.merchant_api_base_url + '/payment_request/' +\n                           tid + '/', arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef post_chat_message(self, merchant_id, channel_id, message):\n\n        return self.do_req('POST',\n                           self.base_url + '/chat/v1/merchant/%s/channel/%s/message/' % (merchant_id, channel_id),\n                           message)", "response": "Post a chat message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_shortlink(self, callback_uri=None,\n                         description=None, serial_number=None):\n        \"\"\"Register new shortlink\n\n        Arguments:\n            callback_uri:\n                URI called by mCASH when user scans shortlink\n            description:\n                Shortlink description displayed in confirmation dialogs\n            serial_number:\n                Serial number on printed QR codes. This field is only used when\n                registering printed stickers issued by mCASH\n        \"\"\"\n        arguments = {'callback_uri': callback_uri,\n                     'description': description,\n                     'serial_number': serial_number}\n        return self.do_req('POST', self.merchant_api_base_url + '/shortlink/',\n                           arguments).json()", "response": "Register new shortlink for a user"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update_shortlink(self, shortlink_id, callback_uri=None,\n                         description=None):\n        \"\"\"Update existing shortlink registration\n\n        Arguments:\n            shortlink_id:\n                Shortlink id assigned by mCASH\n        \"\"\"\n        arguments = {'callback_uri': callback_uri,\n                     'description': description}\n        return self.do_req('PUT',\n                           self.merchant_api_base_url + '/shortlink/' +\n                           shortlink_id + '/', arguments)", "response": "Update existing shortlink registration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_shortlink(self, shortlink_id_or_url):\n        if \"://\" not in shortlink_id_or_url:\n            shortlink_id_or_url = self.merchant_api_base_url + '/shortlink/' + shortlink_id_or_url + '/'\n\n        return self.do_req('GET', shortlink_id_or_url).json()", "response": "Retrieve registered shortlink info"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the info of a specific Ledger", "response": "def update_ledger(self, ledger_id, description=None):\n        \"\"\"Update ledger info\n\n        Arguments:\n            ledger_id:\n                Ledger id assigned by mCASH\n            description:\n                Description of the Ledger and it's usage\n        \"\"\"\n        arguments = {'description': description}\n        return self.do_req('PUT',\n                           self.merchant_api_base_url + '/ledger/' +\n                           ledger_id + '/', arguments)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_report(self, ledger_id, report_id):\n        return self.do_req('GET',\n                           self.merchant_api_base_url + '/ledger/' +\n                           ledger_id + '/report/' +\n                           report_id + '/').json()", "response": "Get report info\n\n        Arguments:\n            ledger_id:\n                Id for ledger for report\n            report_id:\n                Report id assigned by mCASH"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating permission request The call is idempotent; that is, if one posts the same pos_id and pos_tid twice, only one Permission request is created.", "response": "def create_permission_request(self, customer, pos_id, pos_tid, scope,\n                                  ledger=None, text=None, callback_uri=None,\n                                  expires_in=None):\n        \"\"\"Create permission request\n\n        The call is idempotent; that is, if one posts the same pos_id and\n        pos_tid twice, only one Permission request is created.\n        \"\"\"\n        arguments = {'customer': customer,\n                     'pos_id': pos_id,\n                     'pos_tid': pos_tid,\n                     'scope': scope,\n                     'ledger': ledger,\n                     'text': text,\n                     'callback_uri': callback_uri,\n                     'expires_in': expires_in}\n        return self.do_req('POST',\n                           self.merchant_api_base_url + '/permission_request/',\n                           arguments).json()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupload a receipt to the give url", "response": "def upload_receipt(self, url, data):\n        \"\"\"Upload a receipt to the give url\n\n        :param url:\n        :param data:\n        :return:\n        \"\"\"\n        return self.upload_attachment(url=url, data=data, mime_type='application/vnd.mcash.receipt.v1+json')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a new bundle and writes it to disk returning its hash version", "response": "def make_bundle(bundle, fixed_version=None):\n    \"\"\"\n    Does all of the processing required to create a bundle and write it to disk, returning its hash version\n    \"\"\"\n    tmp_output_file_name = '%s.%s.%s' % (os.path.join(bundle.bundle_file_root, bundle.bundle_filename), 'temp', bundle.bundle_type)\n\n    iter_input = iter_bundle_files(bundle)\n\n    output_pipeline = processor_pipeline(bundle.processors, iter_input)\n\n    m = md5()\n\n    with open(tmp_output_file_name, 'wb') as output_file:\n        for chunk in output_pipeline:\n            m.update(chunk)\n            output_file.write(chunk)\n\n    hash_version = fixed_version or m.hexdigest()\n\n    output_file_name = bundle.get_path(hash_version)\n\n    os.rename(tmp_output_file_name, output_file_name)\n\n    return hash_version"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the value of a field in the database.", "response": "def get_db_distinct(queryset, field, func, **params):\n    \"\"\"\n    Checks if a field / value pair exists in database\n    and continues generating values until it finds\n    a one that does not exist\n\n    func is the function that generates values and\n    params is the parameters that function takes\n    \"\"\"\n    while True:\n        try:\n            value = func(**params)\n            queryset.get(**{field: value})\n        except ObjectDoesNotExist:\n            break\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_model_class(name):\n    LOGGER.warning('Beware, function returns first match in the model registry.')\n    # iterate all registered models\n    for model in apps.get_models():\n        # return the app_label for first match\n        if name == model._meta.object_name:\n            app_label = model._meta.app_label\n    return apps.get_model(app_label, name)", "response": "Get the model class for the given name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a html string into a plain text string", "response": "def html_to_text(html_string):\n    \"\"\"\n    returns a plain text string when given a html string text\n    handles a, p, h1 to h6 and br, inserts newline chars to\n    create space in the string\n    @todo handle images\n    \"\"\"\n    # create a valid html document from string\n    # beware that it inserts <hmtl> <body> and <p> tags\n    # where needed\n    html_tree = html.document_fromstring(html_string)\n\n    # handle header tags\n    for h in html_tree.cssselect(\"h1, h2, h3, h4, h5, h6\"):\n        # add two newlines after a header tag\n        h.text = h.text + '\\n\\n'\n\n    # handle links\n    # find all a tags starting from the root of the document //\n    # and replace the link with (link)\n    for a in html_tree.xpath(\"//a\"):\n        href = a.attrib['href']\n        a.text = a.text + \" (\" + href + \")\"\n\n    # handle paragraphs\n    for p in html_tree.xpath(\"//p\"):\n        # keep the tail if there is one\n        # or add two newlines after the text if there is no tail\n        p.tail = p.tail if p.tail else \"\\n\\n\"\n\n    # handle breaks\n    for br in html_tree.xpath(\"//br\"):\n        # add a newline and then the tail (remaining text after the <br/> tag)\n        # or add a newline only if there is no tail\n        # http://stackoverflow.com/questions/18660382/how-can-i-preserve-br-as-newlines-with-lxml-html-text-content-or-equivalent?rq=1\n        br.tail = \"\\n\" + br.tail if br.tail else \"\\n\"\n\n    return html_tree.text_content()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef random_string(**kwargs):\n    n = kwargs.get('length', 10)\n    pool = kwargs.get('pool') or string.digits + string.ascii_lowercase\n    return ''.join(random.SystemRandom().choice(pool) for _ in range(n))", "response": "Generates a random string of the specified length and pool."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_worker(self, process_num=None):\n        self.initial_state.process = process_num\n        self.random.seed(hash(self.seed) + hash(process_num))", "response": "inits producer for a simulation run on a single process"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef evolve(self, new_date):\n        if self.state.date == new_date and not self.initial_state.date == new_date:\n            return self.state\n        self.state.value = self.func(self.state, new_date)\n        self.state.date = new_date\n        return self.state", "response": "evolve to the new process state at the next date"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef run(self, grid=None, num_of_paths=2000, seed=0, num_of_workers=CPU_COUNT, profiling=False):\n        self.grid = sorted(set(grid))\n        self.num_of_paths = num_of_paths\n        self.num_of_workers = num_of_workers\n        self.seed = seed\n\n        # pre processing\n        self.producer.initialize(self.grid, self.num_of_paths, self.seed)\n        self.consumer.initialize(self.grid, self.num_of_paths, self.seed)\n\n        if num_of_workers:\n            # processing\n            workers = list()\n            queue = Queue()\n            path_per_worker = int(num_of_paths // num_of_workers)\n            start_path, stop_path = 0, path_per_worker\n            for i in range(num_of_workers):\n                if i == num_of_workers - 1:\n                    stop_path = num_of_paths  # ensure exact num of path as required\n                name = 'worker-%d' % i\n                if profiling:\n                    # display profile with `snakeviz worker-0.prof`\n                    # if not installed `pip install snakeviz`\n                    workers.append(Process(target=self._run_parallel_process_with_profiling,\n                                           name=name,\n                                           args=(start_path, stop_path, queue, name + '.prof')))\n                else:\n                    workers.append(Process(target=self._run_parallel_process,\n                                           name=name,\n                                           args=(start_path, stop_path, queue)))\n                start_path, stop_path = stop_path, stop_path + path_per_worker\n            for worker in workers:\n                worker.start()\n\n            # post processing\n            for _ in range(num_of_workers):\n                self.consumer.get(queue.get())\n            for worker in workers:\n                worker.join()\n        else:\n            self._run_process(0, num_of_paths)\n\n        self.consumer.finalize()\n        return self.consumer.result", "response": "This method runs the consumer process and returns a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for usage of profiling", "response": "def _run_parallel_process_with_profiling(self, start_path, stop_path, queue, filename):\n        \"\"\"\n        wrapper for usage of profiling\n        \"\"\"\n        runctx('Engine._run_parallel_process(self,  start_path, stop_path, queue)', globals(), locals(), filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _run_process(self, start_path, stop_path, process_num=0):\n        # pre processing\n        self.producer.initialize_worker(process_num)\n        self.consumer.initialize_worker(process_num)\n\n        # processing\n        for path in range(start_path, stop_path):\n            self._run_path(path)\n\n        # post processing\n        self.consumer.finalize_worker(process_num)", "response": "This function calls _run_path for given set of paths and runs the process_num times."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing consumer for simulation", "response": "def initialize(self, grid=None, num_of_paths=None, seed=None):\n        \"\"\"\n        initialize consumer for simulation\n        :param num_of_paths: number of path\n        :type num_of_paths: int\n        :param grid: list of grid point\n        :type grid: list(date)\n        :param seed: simulation seed\n        :type seed: hashable\n        \"\"\"\n        self.num_of_paths = num_of_paths\n        self.grid = grid\n        self.seed = seed\n        self.result = list()\n        self.state = self.initial_state"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize consumer for next path", "response": "def initialize_path(self, path_num=None):\n        \"\"\"\n        initialize consumer for next path\n        \"\"\"\n        self.state = copy(self.initial_state)\n        return self.state"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef consume(self, state):\n        self.state.append(self.func(state))\n        return self.state", "response": "consume new producer state"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef finalize(self):\n        # todo sort self.result by path_num\n        if self.result:\n            self.result = sorted(self.result, key=lambda x: x[0])\n            p, r = map(list, zip(*self.result))\n            self.result = r", "response": "finalize simulation for consumer\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, queue_get):\n        if isinstance(queue_get, (tuple, list)):\n            self.result.extend(queue_get)", "response": "Get states from multiprocessing. queue\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate watchers for models defined in settings. py. Once created they will be passed over Activity. objects. follow_model.", "response": "def register_app_activity():\n    \"\"\"\n    Create watchers for models defined in settings.py.\n    Once created, they will be passed over\n    Activity.objects.follow_model(), which lives in managers.py\n    \"\"\"\n    from django.conf import settings\n    from django.contrib.contenttypes.models import ContentType\n\n    from .models import Activity\n\n    # TO-DO: Add check for existence of setting\n    if not hasattr(settings, 'ACTIVITY_MONITOR_MODELS'):\n        return\n\n    for item in settings.ACTIVITY_MONITOR_MODELS:\n        try:\n            app_label, model = item['model'].split('.', 1)\n            content_type = ContentType.objects.get(app_label=app_label, model=model)\n            model = content_type.model_class()\n            Activity.objects.follow_model(model)\n\n        except ContentType.DoesNotExist:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef relative_path(sub_directory='', function_index=1):\n    frm = inspect.currentframe()\n    for i in range(function_index):\n        frm = frm.f_back\n    if frm.f_code.co_name == 'run_code':\n        frm = frm.f_back\n\n    if not isinstance(sub_directory, list):\n        sub_directory = sub_directory.replace('\\\\','/').split('/')\n\n    path = os.path.split(frm.f_code.co_filename)[0]\n    if sub_directory:\n        path = os.path.abspath(os.path.join(path, *sub_directory))\n    return path", "response": "This will return the file relative to this python script\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncopies a file from source_file to destination_file.", "response": "def copy_file(source_file, destination_file, soft_link=False):\n    \"\"\"\n    :param source_file: str of the full path to the source file\n    :param destination_file: str of the full path to the destination file\n    :param soft_link: bool if True will soft link if possible\n    :return: None\n    \"\"\"\n    if not os.path.exists(source_file):\n        raise IOError(\"No such file: %s\" % source_file)\n    mkdir_for_file(destination_file)\n    if os.path.exists(destination_file):\n        os.remove(destination_file)\n\n    if os.name == 'posix' and soft_link:\n        try:\n            os.symlink(source_file, destination_file)\n        except:\n            shutil.copy(source_file, destination_file)\n    else:\n        try:\n            shutil.copy(source_file, destination_file)\n        except Exception:\n            raise"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_path(target, from_path=None, direction='both', depth_first=False):\n    from_path = from_path if from_path else relative_path('', 2)\n\n    if direction == 'up' or direction == 'both':\n        path = from_path\n        for i in range(100):\n            try:\n                file_path = os.path.abspath(os.path.join(path, target))\n                if os.path.exists(file_path):\n                    return file_path\n                path = os.path.split(path)[0]\n                if len(path) <= 1:\n                    break\n            except Exception:\n                break\n        if os.path.exists(os.path.join(path, target)):\n            return os.path.join(path, target)\n\n    if direction == 'down' or direction == 'both':\n        check = ['']\n        while len(check) != 0:\n            dir = check.pop(0)\n            try:\n                roster = os.listdir(os.path.join(from_path, dir))\n            except Exception:\n                continue    # ignore directories that are inaccessible\n            if target in roster:\n                return os.path.join(from_path, dir, target)\n            else:\n                stack = [os.path.join(from_path, dir, i)\n                         for i in roster if '.' not in i]\n                if depth_first:\n                    check = stack + check\n                else:\n                    check += stack\n\n    raise FileNotFoundError(\"Failed to find file: %s from %s\", file, from_path)", "response": "Find a file or subdirectory from the given path."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns files found by the file - finder ff.", "response": "def walk_revctrl(dirname='', ff=''):\n    \"\"\"Return files found by the file-finder 'ff'.\n    \"\"\"\n    file_finder = None\n    items = []\n\n    if not ff:\n        distutils.log.error('No file-finder passed to walk_revctrl')\n        sys.exit(1)\n\n    for ep in pkg_resources.iter_entry_points('setuptools.file_finders'):\n        if ff == ep.name:\n            distutils.log.info('using %s file-finder', ep.name)\n            file_finder = ep.load()\n            finder_items = []\n            with pythonpath_off():\n                for item in file_finder(dirname):\n                    if not basename(item).startswith(('.svn', '.hg', '.git')):\n                        finder_items.append(item)\n            distutils.log.info('%d files found', len(finder_items))\n            items.extend(finder_items)\n\n    if file_finder is None:\n        distutils.log.error('Failed to load %s file-finder; setuptools-%s extension missing?',\n            ff, 'subversion' if ff == 'svn' else ff)\n        sys.exit(1)\n\n    # Returning a non-empty list prevents egg_info from reading the\n    # existing SOURCES.txt\n    return items or ['']"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves all. pyc files we leave around because of import.", "response": "def cleanup_pycache():\n    \"\"\"Remove .pyc files we leave around because of import.\n    \"\"\"\n    try:\n        for file in glob.glob('setup.py[co]'):\n            os.remove(file)\n        if isdir('__pycache__'):\n            for file in glob.glob(join('__pycache__', 'setup.*.py[co]')):\n                os.remove(file)\n            if not glob.glob(join('__pycache__', '*')):\n                os.rmdir('__pycache__')\n    except (IOError, OSError):\n        pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run(args, ff=''):\n    import setuptools.command.egg_info\n    if ff == 'none':\n        setuptools.command.egg_info.walk_revctrl = no_walk_revctrl\n    else:\n        setuptools.command.egg_info.walk_revctrl = partial(walk_revctrl, ff=ff)\n\n    sys.argv = ['setup.py'] + args\n    import setup\n\n    cleanup_pycache()", "response": "Run setup. py with monkey patches applied."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the iterator over the sorted items.", "response": "def _get_sorted_iterator(self, iterator):\n        \"\"\"\n        Get the iterator over the sorted items.\n\n        This function decides whether the items can be sorted in memory or on disk.\n        :return:\n        \"\"\"\n        lines = list(next(iterator))\n        if len(lines) < self.max_lines:\n            return iter(sorted(lines, key=self.key))\n\n        import tempfile\n        tmp_dir = tempfile.mkdtemp()\n        fnames = self._split(chain([lines], iterator), tmp_dir)\n        return SortedIteratorMerger([unpickle_iter(open(fname, 'rb')) for fname in fnames], self.key)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _split(self, iterator, tmp_dir):\n        fnames = []\n        for i, lines in enumerate(iterator):\n            lines = list(lines)\n            out_fname = os.path.join(tmp_dir, self.TMP_FNAME.format(i + 1))\n            self._write(lines, out_fname)\n            fnames.append(out_fname)\n            if len(lines) < self.max_lines:\n                break\n        return fnames", "response": "Splits the file into several files."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a intermediate sorted file to fname.", "response": "def _write(self, lines, fname):\n        \"\"\"\n        Writes a intermediate temporary sorted file\n\n        :param lines: The lines to write.\n        :param fname: The name of the temporary file.\n        :return:\n        \"\"\"\n        with open(fname, 'wb') as out_fhndl:\n            for line in sorted(lines, key=self.key):\n                pickle.dump(line, out_fhndl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_iso_time(date_part, time_part):\r\n    str_date = datetime.datetime.strptime(\r\n        date_part, '%m/%d/%Y').strftime('%Y-%m-%d')\r\n    str_time = datetime.datetime.strptime(\r\n        time_part, '%I:%M %p').strftime('%H:%M:%S')\r\n\r\n    return str_date + \"T\" + str_time + \"-7:00\"", "response": "r Combign date and time into an iso datetime."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nvalidating user credentials. Returns True if valid False otherwise", "response": "def validate(self):\r\n        r\"\"\"Validate user credentials.\r\n\r\n        Returns\r\n        -------\r\n        bool\r\n\r\n        Examples\r\n        --------\r\n        Validate credentials.\r\n\r\n        >>> from srpenergy.client import SrpEnergyClient\r\n        >>>\r\n        >>> accountid = 'your account id'\r\n        >>> username = 'your username'\r\n        >>> password = 'your password'\r\n        >>> client = SrpEnergyClient(accountid, username, password)\r\n        >>>\r\n        >>> valid = client.validate()\r\n        >>> print(valid)\r\n        True\r\n\r\n        \"\"\"\r\n        try:\r\n\r\n            with requests.Session() as session:\r\n\r\n                result = session.get('https://www.srpnet.com/')\r\n                result = session.post(\r\n                    'https://myaccount.srpnet.com/sso/login/loginuser',\r\n                    data={'UserName': self.username, 'Password': self.password}\r\n                    )\r\n                result_string = result.content.decode(\"utf-8\")\r\n                soup = BeautifulSoup(result_string, \"html.parser\")\r\n                account_select = soup.find(\r\n                    'select', attrs={'name': 'accountNumber'}\r\n                    )\r\n\r\n                accounts = []\r\n                for option in account_select.find_all('option'):\r\n                    if option['value'] != 'newAccount':\r\n                        accounts.append(option['value'])\r\n\r\n                valid = len(accounts) > 0\r\n\r\n                return valid\r\n\r\n        except Exception:  # pylint: disable=W0703\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the energy usage for a given date range.", "response": "def usage(self, startdate, enddate):  # pylint: disable=R0914\r\n        r\"\"\"Get the energy usage for a given date range.\r\n\r\n        Parameters\r\n        ----------\r\n        startdate : datetime\r\n            the start date\r\n        enddate : datetime\r\n            the end date\r\n\r\n        Returns\r\n        -------\r\n        list of tuple\r\n            In the form of (datepart, timepart, isotime, kw, cost)\r\n\r\n        Raises\r\n        ------\r\n        ValueError\r\n            If ``startdate`` or ``enddate`` are not datetime,\r\n            or if ``startdate`` is greater than ``enddate``,\r\n            or if ``startdate`` is greater than now.\r\n\r\n        Examples\r\n        --------\r\n        Get the hourly usage for a given day.\r\n\r\n        >>> start_date = datetime(2018, 9, 19, 0, 0, 0)\r\n        >>> end_date = datetime(2018, 9, 19, 23, 0, 0)\r\n        >>> usage = client.usage(start_date, end_date)\r\n        >>> print(usage)\r\n        [\r\n        ('9/19/2018', '12:00 AM', '2018-09-19T00:00:00-7:00', '1.2', '0.17'),\r\n        ('9/19/2018', '1:00 AM', '2018-09-19T01:00:00-7:00', '2.1', '0.30'),\r\n        ('9/19/2018', '2:00 AM', '2018-09-19T02:00:00-7:00', '1.5', '0.23'),\r\n        ...\r\n        ('9/19/2018', '9:00 PM', '2018-09-19T21:00:00-7:00', '1.2', '0.19'),\r\n        ('9/19/2018', '10:00 PM', '2018-09-19T22:00:00-7:00', '1.1', '0.18'),\r\n        ('9/19/2018', '11:00 PM', '2018-09-19T23:00:00-7:00', '0.4', '0.09')\r\n        ]\r\n\r\n        \"\"\"\r\n        base_usage_url = \"https://myaccount.srpnet.com/MyAccount/Usage/\"\r\n\r\n        # Validate parameters\r\n        if not isinstance(startdate, datetime.datetime):\r\n            raise ValueError(\"Parameter startdate must be datetime.\")\r\n\r\n        if not isinstance(enddate, datetime.datetime):\r\n            raise ValueError(\"Parameter enddate must be datetime.\")\r\n\r\n        # Validate date ranges\r\n        if startdate > enddate:\r\n            raise ValueError(\r\n                \"Parameter startdate can not be greater than enddate.\")\r\n\r\n        # Validate date ranges\r\n        if startdate > datetime.datetime.now():\r\n            raise ValueError(\r\n                \"Parameter startdate can not be greater than now.\")\r\n\r\n        try:\r\n\r\n            # Convert datetime to strings\r\n            str_startdate = startdate.strftime('%m/%d/%Y')\r\n            str_enddate = enddate.strftime('%m/%d/%Y')\r\n\r\n            with requests.Session() as session:\r\n\r\n                result = session.get('https://www.srpnet.com/')\r\n                result = session.post(\r\n                    'https://myaccount.srpnet.com/sso/login/loginuser',\r\n                    data={'UserName': self.username, 'Password': self.password}\r\n                    )\r\n                result = session.get(base_usage_url)\r\n                result = session.get(\r\n                    base_usage_url + '/ExportToExcel?billAccount=' +\r\n                    self.accountid +\r\n                    '&viewDataType=KwhUsage&reportOption=Hourly&startDate=' +\r\n                    str_startdate + '&endDate=' + str_enddate +\r\n                    '&displayCost=false')\r\n\r\n                rows = result.content.decode('utf-8').split('\\r\\n')\r\n\r\n                if rows[0] == '<!DOCTYPE html>':\r\n                    raise TypeError(\"Expected csv but received html.\")\r\n\r\n                usage = []\r\n                for row in rows[1:-1]:\r\n                    s_date, s_time, s_kwh, s_cost, \\\r\n                        *peak = row.split(',')  # pylint: disable=W0612\r\n                    values = (\r\n                        s_date,\r\n                        s_time,\r\n                        get_iso_time(s_date, s_time),\r\n                        s_kwh,\r\n                        strip_currency(s_cost))\r\n                    usage.append(values)\r\n\r\n                return usage\r\n\r\n        except Exception as ex:\r\n            raise ex"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npull the list of users in a client. Inputs: - host_name: A string containing the address of the machine where the PServer instance is hosted. - client_name: The PServer client name. - client_pass: The PServer client's password. Output: - user_id_list: A python list of user ids.", "response": "def get_user_list(host_name, client_name, client_pass):\n    \"\"\"\n    Pulls the list of users in a client.\n\n    Inputs: - host_name: A string containing the address of the machine where the PServer instance is hosted.\n            - client_name: The PServer client name.\n            - client_pass: The PServer client's password.\n\n    Output: - user_id_list: A python list of user ids.\n    \"\"\"\n    # Construct request.\n    request = construct_request(model_type=\"pers\",\n                                client_name=client_name,\n                                client_pass=client_pass,\n                                command=\"getusrs\",\n                                values=\"whr=*\")\n\n    # Make request.\n    request_result = send_request(host_name, request)\n\n    # Extract a python list from xml object.\n    user_id_list = list()\n    append_user_id = user_id_list.append\n\n    if request_result is not None:\n        user_list_xml = request_result.text\n        tree = etree.parse(StringIO(user_list_xml))\n        root = tree.getroot()\n\n        xml_rows = root.findall(\"./result/row/usr\")\n        for xml_row in xml_rows:\n            append_user_id(xml_row.text)\n\n    return user_id_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_features(host_name, client_name, client_pass, feature_names):\n    init_feats = (\"&\".join([\"%s=0\"]*len(feature_names))) % tuple(feature_names)\n    features_req = construct_request(\"pers\",\n                                     client_name,\n                                     client_pass,\n                                     \"addftr\",\n                                     init_feats)\n    send_request(host_name,\n                 features_req)", "response": "Adds a number of numerical features to the client."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_features(host_name, client_name, client_pass, feature_names=None):\n    # Get all features.\n    if feature_names is None:\n        feature_names = get_feature_names(host_name,\n                                          client_name,\n                                          client_pass)\n\n    # Remove all features.\n    feature_to_be_removed = (\"&\".join([\"ftr=%s\"]*len(feature_names))) % tuple(feature_names)\n    features_req = construct_request(\"pers\",\n                                     client_name,\n                                     client_pass,\n                                     'remftr',\n                                     feature_to_be_removed)\n    send_request(host_name,\n                 features_req)", "response": "This function removes a number of numerical features in the client."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the names of all features in a PServer client.", "response": "def get_feature_names(host_name, client_name, client_pass):\n    \"\"\"\n    Get the names of all features in a PServer client.\n\n    Inputs: - host_name: A string containing the address of the machine where the PServer instance is hosted.\n            - client_name: The PServer client name.\n            - client_pass: The PServer client's password.\n\n    Output: - feature_names: A python list of feature names.\n    \"\"\"\n    # Construct request.\n    request = construct_request(model_type=\"pers\",\n                                client_name=client_name,\n                                client_pass=client_pass,\n                                command=\"getftrdef\",\n                                values=\"ftr=*\")\n\n    # Send request.\n    request_result = send_request(host_name,\n                                  request)\n\n    # Extract a python list from xml object.\n    feature_names = list()\n    append_feature_name = feature_names.append\n\n    if request_result is not None:\n        feature_names_xml = request_result.text\n        tree = etree.parse(StringIO(feature_names_xml))\n        root = tree.getroot()\n\n        xml_rows = root.findall(\"row/ftr\")\n        for xml_row in xml_rows:\n            append_feature_name(xml_row.text)\n\n    return feature_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert topic and score data for a user to a PServer client.", "response": "def insert_user_data(host_name, client_name, client_pass, user_twitter_id, topic_to_score):\n    \"\"\"\n    Inserts topic/score data for a user to a PServer client.\n\n    Inputs: - host_name: A string containing the address of the machine where the PServer instance is hosted.\n            - client_name: The PServer client name.\n            - client_pass: The PServer client's password.\n            - user_twitter_id: A Twitter user identifier.\n            - topic_to_score: A python dictionary that maps from topic to score.\n    \"\"\"\n\n    # Construct values.\n    values = \"usr=\" + str(user_twitter_id)\n\n    for topic, score in topic_to_score.items():\n        values += \"&type.\" + topic + \"=%.2f\" % score\n\n    # Construct request.\n    request = construct_request(model_type=\"pers\",\n                                client_name=client_name,\n                                client_pass=client_pass,\n                                command=\"setusr\",\n                                values=values)\n\n    # Send request.\n    send_request(host_name,\n                 request)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef construct_request(model_type, client_name, client_pass, command, values):\n    base_request = (\"{model_type}?\"\n                    \"clnt={client_name}|{client_pass}&\"\n                    \"com={command}&{values}\".format(model_type=model_type,\n                                                    client_name=client_name,\n                                                    client_pass=client_pass,\n                                                    command=command,\n                                                    values=values))\n    return base_request", "response": "Construct the base request url."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send_request(host_name, request):\n    request = \"%s%s\" % (host_name, request)\n    # print(request)\n    try:\n        result = requests.get(request)\n        if result.status_code == 200:\n            return result\n        else:\n            # print(result.status_code)\n            raise Exception\n    except Exception as e:\n        # print(e)\n        raise e", "response": "Sends a request to the NCBI server."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates a single topic score for a single user.", "response": "def update_feature_value(host_name, client_name, client_pass, user_twitter_id, feature_name, feature_score):\n    \"\"\"\n    Updates a single topic score, for a single user.\n\n    Inputs: - host_name: A string containing the address of the machine where the PServer instance is hosted.\n            - client_name: The PServer client name.\n            - client_pass: The PServer client's password.\n            - user_twitter_id: A Twitter user identifier.\n            - feature_name: A specific PServer feature name.\n            - feature_score: The corresponding score.\n    \"\"\"\n    username = str(user_twitter_id)\n    feature_value = \"{0:.2f}\".format(feature_score)\n    joined_ftr_value = \"ftr_\" + feature_name + \"=\" + str(feature_value)\n    values = \"usr=%s&%s\" % (username, joined_ftr_value)\n\n    # Construct request.\n    request = construct_request(model_type=\"pers\",\n                                client_name=client_name,\n                                client_pass=client_pass,\n                                command=\"setusr\",\n                                values=values)\n\n    # Send request.\n    send_request(host_name,\n                 request)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef init_app(self, app):\n        self.app = app\n        self.log = app.logger.getChild('compass')\n        self.log.debug(\"Initializing compass integration\")\n        self.compass_path = self.app.config.get('COMPASS_PATH', 'compass')\n        self.config_files = self.app.config.get('COMPASS_CONFIGS', None)\n        self.requestcheck_debug_only = self.app.config.get(\n                'COMPASS_REQUESTCHECK_DEBUG_ONLY', True)\n        self.skip_mtime_check = self.app.config.get(\n                'COMPASS_SKIP_MTIME_CHECK', False)\n        self.debug_only = self.app.config.get(\n                'COMPASS_DEBUG_ONLY', False)\n        self.disabled = self.app.config.get('COMPASS_DISABLED', False)\n\n        if not self.debug_only:\n            self.compile()\n        if (not self.debug_only) \\\n                and (not self.requestcheck_debug_only or self.app.debug):\n            self.app.after_request(self.after_request)", "response": "Initialize the application once the configuration has been loaded\n        there."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncompiles all the specified or found compasses.", "response": "def compile(self):\n        \"\"\"\n        Main entry point that compiles all the specified or found compass\n        projects.\n        \"\"\"\n        if self.disabled:\n            return\n        self._check_configs()\n        for _, cfg in self.configs.iteritems():\n            cfg.parse()\n            if cfg.changes_found() or self.skip_mtime_check:\n                self.log.debug(\"Changes found for \" + cfg.path \\\n                        + \" or checks disabled. Compiling...\")\n                cfg.compile(self)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef after_request(self, response):\n        if response is not None and request is not None:\n            # When used as response processor, only run if we are requesting\n            # anything but a static resource.\n            if request.endpoint in [None, \"static\"]:\n                return response\n        self.compile()\n        return response", "response": "This method is called after the request is complete."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_configs(self):\n        configs = set(self._find_configs())\n        known_configs = set(self.configs.keys())\n        new_configs = configs - known_configs\n        for cfg in (known_configs - configs):\n            self.log.debug(\"Compass configuration has been removed: \" + cfg)\n            del self.configs[cfg]\n        for cfg in new_configs:\n            self.log.debug(\"Found new compass configuration: \" + cfg)\n            self.configs[cfg] = CompassConfig(cfg)", "response": "Reloads the configuration files."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfinding all config files in the project directory and returns a list of files.", "response": "def _find_configs(self):\n        \"\"\"\n        Scans the project directory for config files or returns\n        the explicitly specified list of files.\n        \"\"\"\n        if self.config_files is not None:\n            return self.config_files\n\n        # Walk the whole project tree and look for \"config.rb\" files\n        result = []\n        for path, _, files in os.walk(self.app.root_path):\n            if \"config.rb\" in files:\n                result.append(os.path.join(path, \"config.rb\"))\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parse(self, replace=False):\n        if self.last_parsed is not None \\\n                and self.last_parsed > os.path.getmtime(self.path) \\\n                and not replace:\n            return\n        self.last_parsed = time.time()\n        with open(self.path, 'r') as file_:\n            for line in file_:\n                match = CONFIG_LINE_RE.match(line.rstrip())\n                if match:\n                    if match.group(1) == 'sass_dir':\n                        self.src = os.path.join(\n                                self.base_dir, match.group(2)[1:-1])\n                    elif match.group(1) == 'css_dir':\n                        self.dest = os.path.join(\n                                self.base_dir, match.group(2)[1:-1])", "response": "Parse the given compass config file and return the ID of the compass instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if the source folder is older than the destination folder.", "response": "def changes_found(self):\n        \"\"\"\n        Returns True if the target folder is older than the source folder.\n        \"\"\"\n        if self.dest is None:\n            warnings.warn(\"dest directory not found!\")\n        if self.src is None:\n            warnings.warn(\"src directory not found!\")\n        if self.src is None or self.dest is None:\n            return False\n        dest_mtime = -1\n        src_mtime = os.path.getmtime(self.src)\n        if os.path.exists(self.dest):\n            dest_mtime = os.path.getmtime(self.dest)\n\n        if src_mtime >= dest_mtime:\n            return True # changes found\n\n        for folder, _, files in os.walk(self.src):\n            for filename in fnmatch.filter(files, '*.scss'):\n                src_path = os.path.join(folder, filename)\n                if os.path.getmtime(src_path) >= dest_mtime:\n                    return True \n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall the compass script specified in the COMPASS_PATH setting and sets the destination directory to the current working directory.", "response": "def compile(self, compass):\n        \"\"\"\n        Calls the compass script specified in the compass extension\n        with the paths provided by the config.rb.\n        \"\"\"\n        try:\n            output = subprocess.check_output(\n                    [compass.compass_path, 'compile', '-q'],\n                    cwd=self.base_dir)\n            os.utime(self.dest, None)\n            compass.log.debug(output)\n        except OSError, e:\n            if e.errno == errno.ENOENT:\n                compass.log.error(\"Compass could not be found in the PATH \" +\n                    \"and/or in the COMPASS_PATH setting! \" +\n                    \"Disabling compilation.\")\n                compass.disabled = True\n            else:\n                raise e"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlifts deeply nested expressions out of redundant parentheses", "response": "def _remove_otiose(lst):\n    \"\"\"lift deeply nested expressions out of redundant parentheses\"\"\"\n    listtype = type([])\n    while type(lst) == listtype and len(lst) == 1:\n        lst = lst[0]\n\n    return lst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if a given date is a holiday.", "response": "def is_holiday(now=None, holidays=\"/etc/acct/holidays\"):\n    \"\"\"is_holiday({now}, {holidays=\"/etc/acct/holidays\"}\"\"\"\n    now = _Time(now)\n    # Now, parse holiday file.\n    if not os.path.exists(holidays):\n        raise Exception(\"There is no holidays file: %s\" % holidays)\n\n    f = open(holidays, \"r\")\n    # First, read all leading comments.\n    line = f.readline()\n    while line[0] == '*': line = f.readline()\n\n    # We just got the year line.\n    (year, primestart, primeend) = str.split(line)\n    # If not the right year, we have no idea for certain.  Skip.\n    if not year == now.year: return 0\n\n    # Now the dates.  Check each against now.\n    while line != '':\n        # Of course, ignore comments.\n        if line[0] == '*':\n            line = f.readline()\n            continue\n\n        try:\n            # Format: \"1/1\tNew Years Day\"\n            (month, day) = str.split(str.split(line)[0], \"/\")\n            # The _Time class has leading-zero padded day numbers.\n            if len(day) == 1: day = '0' + day\n            # Get month number from index map (compensate for zero indexing).\n            month = MONTH_MAP[int(month) - 1]\n\n            # Check the date.\n            #print month, now.month, day, now.day\n            if month == now.month and day == now.day:\n                return 1\n\n            line = f.readline()\n        except:\n            # Skip malformed lines.\n            line = f.readline()\n            continue\n\n    # If no match found, we must not be in a holiday.\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen one of the topic set resource files and returns a set of topics.", "response": "def get_topic_set(file_path):\n    \"\"\"\n    Opens one of the topic set resource files and returns a set of topics.\n\n    - Input:  - file_path: The path pointing to the topic set resource file.\n\n    - Output: - topic_set: A python set of strings.\n    \"\"\"\n    topic_set = set()\n    file_row_gen = get_file_row_generator(file_path, \",\")  # The separator here is irrelevant.\n    for file_row in file_row_gen:\n        topic_set.add(file_row[0])\n\n    return topic_set"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_reveal_set():\n    file_path = get_package_path() + \"/twitter/res/topics/story_set.txt\"\n    story_topics = get_topic_set(file_path)\n\n    file_path = get_package_path() + \"/twitter/res/topics/theme_set.txt\"\n    theme_topics = get_topic_set(file_path)\n\n    file_path = get_package_path() + \"/twitter/res/topics/attribute_set.txt\"\n    attribute_topics = get_topic_set(file_path)\n\n    file_path = get_package_path() + \"/twitter/res/topics/stance_set.txt\"\n    stance_topics = get_topic_set(file_path)\n\n    file_path = get_package_path() + \"/twitter/res/topics/geographical_set.txt\"\n    geographical_topics = get_topic_set(file_path)\n\n    topics = story_topics | theme_topics | attribute_topics | stance_topics | geographical_topics\n\n    return topics", "response": "Returns a set of all the topics that are interesting for REVEAL use - cases."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nopen the topic - keyword map resource file and returns the corresponding python dictionary.", "response": "def get_topic_keyword_dictionary():\n    \"\"\"\n    Opens the topic-keyword map resource file and returns the corresponding python dictionary.\n\n    - Input:  - file_path: The path pointing to the topic-keyword map resource file.\n\n    - Output: - topic_set: A topic to keyword python dictionary.\n    \"\"\"\n    topic_keyword_dictionary = dict()\n    file_row_gen = get_file_row_generator(get_package_path() + \"/twitter/res/topics/topic_keyword_mapping\" + \".txt\",\n                                          \",\",\n                                          \"utf-8\")\n    for file_row in file_row_gen:\n        topic_keyword_dictionary[file_row[0]] = set([keyword for keyword in file_row[1:]])\n\n    return topic_keyword_dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_surveys(self):\n        payload = { \n            'Request': 'getSurveys',\n            'Format': 'JSON'\n            }\n        r = self._session.get(QUALTRICS_URL, params=payload)\n        output = r.json()\n        return output['Result']['Surveys']", "response": "Gets all surveys in account\n        \nInterrupt or returns None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_input(self, name, ds):\n        columns = self.inputs.get(name)\n        df = ds.get_dataframe()\n\n        # set defaults\n        for column in columns:\n            if column not in df.columns:\n                df[column] = self.defaults.get(column)\n\n        return df[columns]", "response": "Retrieves the content of an input given a DataSource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef domain_relationship(self):\n        if self.__domain_relationship is None:\n            ent = self.relator.get_entity()\n            self.__domain_relationship = \\\n                    self.descriptor.make_relationship(ent)\n        return self.__domain_relationship", "response": "Returns a domain relationship equivalent with this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndates a proxy record.", "response": "def date(self, proxy, how='median', n=500):\n        \"\"\"Date a proxy record\n\n        Parameters\n        ----------\n        proxy : ProxyRecord\n        how : str\n            How to perform the dating. 'median' returns the average of the MCMC ensemble. 'ensemble' returns a 'n'\n            randomly selected members of the MCMC ensemble. Default is 'median'.\n        n : int\n            If 'how' is 'ensemble', the function will randomly select 'n' MCMC ensemble members, with replacement.\n\n        Returns\n        -------\n        DatedProxyRecord\n        \"\"\"\n        assert how in ['median', 'ensemble']\n        ens_members = self.mcmcfit.n_members()\n        if how == 'ensemble':\n            select_idx = np.random.choice(range(ens_members), size=n, replace=True)\n        out = []\n        for d in proxy.data.depth.values:\n            age = self.agedepth(d)\n            if how == 'median':\n                age = np.median(age)\n            elif how == 'ensemble':\n                age = age[select_idx]\n            out.append(age)\n        return DatedProxyRecord(proxy.data.copy(), out)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naging - depth plot", "response": "def plot(self, agebins=50, p=(2.5, 97.5), ax=None):\n        \"\"\"Age-depth plot\"\"\"\n        if ax is None:\n            ax = plt.gca()\n        ax.hist2d(np.repeat(self.depth, self.age_ensemble.shape[1]), self.age_ensemble.flatten(),\n                   (len(self.depth), agebins), cmin=1)\n        ax.step(self.depth, self.age_median(), where='mid', color='red')\n        ax.step(self.depth, self.age_percentile(p[0]), where='mid', color='red', linestyle=':')\n        ax.step(self.depth, self.age_percentile(p[1]), where='mid', color='red', linestyle=':')\n        ax.set_ylabel('Age (cal yr BP)')\n        ax.set_xlabel('Depth (cm)')\n        ax.grid(True)\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef agedepth(self, d):\n        # TODO(brews): Function cannot handle hiatus\n        # See lines 77 - 100 of hist2.cpp\n        x = self.mcmcfit.sediment_rate\n        theta0 = self.mcmcfit.headage  # Age abscissa (in yrs).  If array, dimension should be iterations or realizations of the sediment\n        deltac = self.thick\n        c0 = min(self.depth)  # Uniform depth segment abscissa (in cm).\n        assert d > c0 or np.isclose(c0, d, atol = 1e-4)\n        out = theta0.astype(float)\n        i = int(np.floor((d - c0) / deltac))\n        for j in range(i):\n            out += x[j] * deltac\n        ci = c0 + i * deltac\n        assert ci < d or np.isclose(ci, d, atol = 1e-4)\n        try:\n            next_x = x[i]\n        except IndexError:\n            # Extrapolating\n            next_x = x[i - 1]\n        out += next_x * (d - ci)\n        return out", "response": "Get calendar age for a depth segment."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef plot_prior_dates(self, dwidth=30, ax=None):\n        if ax is None:\n            ax = plt.gca()\n        depth, probs = self.prior_dates()\n        pat = []\n        for i, d in enumerate(depth):\n            p = probs[i]\n            z = np.array([p[:, 0], dwidth * p[:, 1] / np.sum(p[:, 1])])  # Normalize\n            z = z[:, z[0].argsort(kind='mergesort')]  # np.interp requires `xp` arg to be sorted\n            zy = np.linspace(np.min(z[0]), np.max(z[0]), num=200)\n            zp = np.interp(x=zy, xp=z[0], fp=z[1])\n            pol = np.vstack([np.concatenate([d + zp, d - zp[::-1]]),\n                             np.concatenate([zy, zy[::-1]])])\n            pat.append(Polygon(pol.T))\n        p = PatchCollection(pat)\n        p.set_label('Prior dates')\n        ax.add_collection(p)\n        ax.autoscale_view()\n        ax.set_ylabel('Age (cal yr BP)')\n        ax.set_xlabel('Depth (cm)')\n        ax.grid(True)\n        return ax", "response": "Plot prior chronology dates in age - depth plot"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots sediment accumulation rate prior and posterior distributions", "response": "def plot_sediment_rate(self, ax=None):\n        \"\"\"Plot sediment accumulation rate prior and posterior distributions\"\"\"\n        if ax is None:\n            ax = plt.gca()\n\n        y_prior, x_prior = self.prior_sediment_rate()\n        ax.plot(x_prior, y_prior, label='Prior')\n\n        y_posterior = self.mcmcfit.sediment_rate\n        density = scipy.stats.gaussian_kde(y_posterior.flat)\n        density.covariance_factor = lambda: 0.25\n        density._compute_covariance()\n        ax.plot(x_prior, density(x_prior), label='Posterior')\n\n        acc_shape = self.mcmcsetup.mcmc_kws['acc_shape']\n        acc_mean = self.mcmcsetup.mcmc_kws['acc_mean']\n        annotstr_template = 'acc_shape: {0}\\nacc_mean: {1}'\n        annotstr = annotstr_template.format(acc_shape, acc_mean)\n        ax.annotate(annotstr, xy=(0.9, 0.9), xycoords='axes fraction',\n                    horizontalalignment='right', verticalalignment='top')\n\n        ax.set_ylabel('Density')\n        ax.set_xlabel('Acc. rate (yr/cm)')\n        ax.grid(True)\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef plot_sediment_memory(self, ax=None):\n        if ax is None:\n            ax = plt.gca()\n\n        y_prior, x_prior = self.prior_sediment_memory()\n        ax.plot(x_prior, y_prior, label='Prior')\n\n        y_posterior = self.mcmcfit.sediment_memory\n        density = scipy.stats.gaussian_kde(y_posterior ** (1/self.thick))\n        density.covariance_factor = lambda: 0.25\n        density._compute_covariance()\n        ax.plot(x_prior, density(x_prior), label='Posterior')\n\n        mem_mean = self.mcmcsetup.mcmc_kws['mem_mean']\n        mem_strength = self.mcmcsetup.mcmc_kws['mem_strength']\n        annotstr_template = 'mem_strength: {0}\\nmem_mean: {1}\\nthick: {2} cm'\n        annotstr = annotstr_template.format(mem_strength, mem_mean, self.thick)\n        ax.annotate(annotstr, xy=(0.9, 0.9), xycoords='axes fraction',\n                    horizontalalignment='right', verticalalignment='top')\n\n        ax.set_ylabel('Density')\n        ax.set_xlabel('Memory (ratio)')\n        ax.grid(True)\n        return ax", "response": "Plot sediment memory prior and posterior distributions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint information of a quantitative phase imaging dataset", "response": "def qpinfo():\n    \"\"\"Print information of a quantitative phase imaging dataset\"\"\"\n    parser = qpinfo_parser()\n    args = parser.parse_args()\n\n    path = pathlib.Path(args.path).resolve()\n    try:\n        ds = load_data(path)\n    except UnknownFileFormatError:\n        print(\"Unknown file format: {}\".format(path))\n        return\n\n    print(\"{} ({})\".format(ds.__class__.__doc__, ds.__class__.__name__))\n    print(\"- number of images: {}\".format(len(ds)))\n    for key in ds.meta_data:\n        print(\"- {}: {}\".format(key, ds.meta_data[key]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_db_driver(uri, username=None, password=None, encrypted=True, max_pool_size=50, trust=0):\n    return GraphDatabase.driver(uri, auth=basic_auth(username, password), encrypted=encrypted,\n                                max_pool_size=max_pool_size, trust=trust)", "response": "Returns a neo4j driver for the given Bolt URI."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a node with the mandatory attributes name and handle_id also sets type label.", "response": "def create_node(manager, name, meta_type_label, type_label, handle_id, legacy=True):\n    \"\"\"\n    Creates a node with the mandatory attributes name and handle_id also sets type label.\n\n    :param manager: Manager to handle sessions and transactions\n    :param name: Node name\n    :param meta_type_label: Node meta type\n    :param type_label: Node label\n    :param handle_id: Unique id\n    :param legacy: Backwards compatibility\n\n    :type manager: norduniclient.contextmanager.Neo4jDBSessionManager\n    :type name: str|unicode\n    :type meta_type_label: str|unicode\n    :type type_label: str|unicode\n    :type handle_id: str|unicode\n    :type legacy: Boolean\n\n    :rtype: dict|neo4j.v1.types.Node\n    \"\"\"\n    if meta_type_label not in META_TYPES:\n        raise exceptions.MetaLabelNamingError(meta_type_label)\n    q = \"\"\"\n        CREATE (n:Node:%s:%s { name: { name }, handle_id: { handle_id }})\n        RETURN n\n        \"\"\" % (meta_type_label, type_label)\n    with manager.session as s:\n        if legacy:\n            return s.run(q, {'name': name, 'handle_id': handle_id}).single()['n'].properties\n        return s.run(q, {'name': name, 'handle_id': handle_id}).single()['n']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_node(manager, handle_id, legacy=True):\n    q = 'MATCH (n:Node { handle_id: {handle_id} }) RETURN n'\n\n    with manager.session as s:\n        result = s.run(q, {'handle_id': handle_id}).single()\n        if result:\n            if legacy:\n                return result['n'].properties\n            return result['n']\n    raise exceptions.NodeNotFound(manager, handle_id)", "response": "Get a node from the manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_node_bundle(manager, handle_id=None, node=None):\n    if not node:\n        node = get_node(manager, handle_id=handle_id, legacy=False)\n    d = {\n        'data': node.properties\n    }\n    labels = list(node.labels)\n    labels.remove('Node')  # All nodes have this label for indexing\n    for label in labels:\n        if label in META_TYPES:\n            d['meta_type'] = label\n            labels.remove(label)\n    d['labels'] = labels\n    return d", "response": "Get the node bundle"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndelete the node and all its relationships.", "response": "def delete_node(manager, handle_id):\n    \"\"\"\n    Deletes the node and all its relationships.\n\n    :param manager: Neo4jDBSessionManager\n    :param handle_id: Unique id\n\n    :rtype: bool\n    \"\"\"\n    q = \"\"\"\n        MATCH (n:Node {handle_id: {handle_id}})\n        OPTIONAL MATCH (n)-[r]-()\n        DELETE n,r\n        \"\"\"\n    with manager.session as s:\n        s.run(q, {'handle_id': handle_id})\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a specific relationship from a resource.", "response": "def get_relationship(manager, relationship_id, legacy=True):\n    \"\"\"\n    :param manager: Manager to handle sessions and transactions\n    :param relationship_id: Unique id\n    :param legacy: Backwards compatibility\n\n    :type manager: norduniclient.contextmanager.Neo4jDBSessionManager\n    :type relationship_id: int\n    :type legacy: Boolean\n\n    :rtype int|neo4j.v1.types.Relationship\n    \"\"\"\n    q = \"\"\"\n        MATCH ()-[r]->()\n        WHERE ID(r) = {relationship_id}\n        RETURN r\n        \"\"\"\n    with manager.session as s:\n        record = s.run(q, {'relationship_id': int(relationship_id)}).single()\n        if record:\n            if legacy:\n                return record['r'].properties\n            return record['r']\n    raise exceptions.RelationshipNotFound(manager, int(relationship_id))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a dictionary containing the metadata for a given relationship.", "response": "def get_relationship_bundle(manager, relationship_id=None, legacy=True):\n    \"\"\"\n    :param manager: Neo4jDBSessionManager\n    :param relationship_id: Internal Neo4j id\n    :param legacy: Backwards compatibility\n\n    :type relationship_id: int\n    :type legacy: bool\n\n    :rtype: dictionary\n    \"\"\"\n    q = \"\"\"\n        MATCH (start)-[r]->(end)\n        WHERE ID(r) = {relationship_id}\n        RETURN start, r, end\n        \"\"\"\n\n    with manager.session as s:\n        record = s.run(q, {'relationship_id': int(relationship_id)}).single()\n    if record is None:\n        raise exceptions.RelationshipNotFound(manager, int(relationship_id))\n\n    if legacy:\n        bundle = {\n            'type': record['r'].type,\n            'id': int(relationship_id),\n            'data': record['r'].properties,\n            'start': record['start'].properties['handle_id'],\n            'end': record['end'].properties['handle_id'],\n        }\n    else:\n        bundle = {\n            'type': record['r'].type,\n            'id': int(relationship_id),\n            'data': record['r'].properties,\n            'start': record['start'],\n            'end': record['end'],\n        }\n    return bundle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_relationship(manager, relationship_id):\n    q = \"\"\"\n        MATCH ()-[r]->()\n        WHERE ID(r) = {relationship_id}\n        DELETE r\n        \"\"\"\n    with manager.session as s:\n        s.run(q, {'relationship_id': int(relationship_id)})\n    return True", "response": "Deletes the relationship with the given id."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_node_meta_type(manager, handle_id):\n    node = get_node(manager=manager, handle_id=handle_id, legacy=False)\n    for label in node.labels:\n        if label in META_TYPES:\n            return label\n    raise exceptions.NoMetaLabelFound(handle_id)", "response": "Returns the meta type of the supplied node as a string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting nodes with the given value.", "response": "def get_nodes_by_value(manager, value, prop=None, node_type='Node'):\n    \"\"\"\n    Traverses all nodes or nodes of specified label and compares the property/properties of the node\n    with the supplied string.\n\n    :param manager: Neo4jDBSessionManager\n    :param value: Value to search for\n    :param prop: Which property to look for value in\n    :param node_type:\n\n    :type value: str|list|bool|int\n    :type prop: str\n    :type node_type: str\n    :return: dicts\n    \"\"\"\n    if prop:\n        q = \"\"\"\n            MATCH (n:{label})\n            USING SCAN n:{label}\n            WHERE n.{prop} = {{value}}\n            RETURN distinct n\n            \"\"\".format(label=node_type, prop=prop)\n\n        with manager.session as s:\n            for result in s.run(q, {'value': value}):\n                yield result['n']\n    else:\n        q = \"\"\"\n            MATCH (n:{label})\n            RETURN n\n            \"\"\".format(label=node_type)\n        pattern = re.compile(u'{0}'.format(value), re.IGNORECASE)\n        with manager.session as s:\n            for result in s.run(q):\n                for v in result['n'].properties.values():\n                    if pattern.search(text_type(v)):\n                        yield result['n']\n                        break"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsearch nodes or nodes of specified label and fuzzy compares the property and properties of the node with the supplied value.", "response": "def search_nodes_by_value(manager, value, prop=None, node_type='Node'):\n    \"\"\"\n    Traverses all nodes or nodes of specified label and fuzzy compares the property/properties of the node\n    with the supplied string.\n\n    :param manager: Neo4jDBSessionManager\n    :param value: Value to search for\n    :param prop: Which property to look for value in\n    :param node_type:\n\n    :type value: str\n    :type prop: str\n    :type node_type: str\n    :return: dicts\n    \"\"\"\n    if prop:\n        q = \"\"\"\n            MATCH (n:{label})\n            WHERE n.{prop} =~ \"(?i).*{value}.*\" OR any(x IN n.{prop} WHERE x =~ \"(?i).*{value}.*\")\n            RETURN distinct n\n            \"\"\".format(label=node_type, prop=prop, value=value)\n    else:\n        q = \"\"\"\n            MATCH (n:{label})\n            WITH n, keys(n) as props\n            WHERE any(prop in props WHERE n[prop] =~ \"(?i).*{value}.*\") OR\n              any(prop in props WHERE any(x IN n[prop] WHERE x =~ \"(?i).*{value}.*\"))\n            RETURN distinct n\n            \"\"\".format(label=node_type, value=value)\n\n    with manager.session as s:\n        for result in s.run(q):\n            yield result['n']"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_index(manager, prop, node_type='Node'):\n    with manager.session as s:\n        s.run('CREATE INDEX ON :{node_type}({prop})'.format(node_type=node_type, prop=prop))", "response": "Create an index on the Neo4j database."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the indexed node of a node in the Neo4j database.", "response": "def get_indexed_node(manager, prop, value, node_type='Node', lookup_func='CONTAINS', legacy=True):\n    \"\"\"\n    :param manager: Neo4jDBSessionManager\n    :param prop: Indexed property\n    :param value: Indexed value\n    :param node_type: Label used for index\n    :param lookup_func: STARTS WITH | CONTAINS | ENDS WITH\n    :param legacy: Backwards compatibility\n\n    :type manager: Neo4jDBSessionManager\n    :type prop: str\n    :type value: str\n    :type node_type: str\n    :type lookup_func: str\n    :type legacy: bool\n\n    :return: Dict or Node object\n    :rtype: dict|Node\n    \"\"\"\n    q = \"\"\"\n        MATCH (n:{label})\n        WHERE LOWER(n.{prop}) {lookup_func} LOWER({{value}})\n        RETURN n\n        \"\"\".format(label=node_type, prop=prop, lookup_func=lookup_func)\n    with manager.session as s:\n        for result in s.run(q, {'value': value}):\n            if legacy:\n                yield result['n'].properties\n            else:\n                yield result['n']"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the node model for a given node name and type.", "response": "def get_unique_node_by_name(manager, node_name, node_type):\n    \"\"\"\n    Returns the node if the node is unique for name and type or None.\n\n    :param manager: Neo4jDBSessionManager\n    :param node_name: string\n    :param node_type: str|unicode\n    :return: norduniclient node model or None\n    \"\"\"\n    q = \"\"\"\n        MATCH (n:Node { name: {name} })\n        WHERE {label} IN labels(n)\n        RETURN n.handle_id as handle_id\n        \"\"\"\n\n    with manager.session as s:\n        result = list(s.run(q, {'name': node_name, 'label': node_type}))\n\n    if result:\n        if len(result) == 1:\n            return get_node_model(manager, result[0]['handle_id'])\n        raise exceptions.MultipleNodesReturned(node_name, node_type)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a relationship between two nodes.", "response": "def _create_relationship(manager, handle_id, other_handle_id, rel_type, legacy=True):\n    \"\"\"\n    :param manager: Context manager to handle transactions\n    :param handle_id: Node handle id\n    :param other_handle_id: Other node handle id\n    :param rel_type: Relationship type\n    :param legacy: Backwards compatibility\n\n    :type manager: Neo4jDBSessionManager\n    :type handle_id: str|unicode\n    :type other_handle_id: str|unicode\n    :type rel_type: str|unicode\n    :type legacy: Boolean\n\n    :rtype: int|neo4j.v1.types.Relationship\n    \"\"\"\n\n    q = \"\"\"\n        MATCH (a:Node {handle_id: {start}}),(b:Node {handle_id: {end}})\n        CREATE (a)-[r:%s]->(b)\n        RETURN r\n        \"\"\" % rel_type\n\n    with manager.session as s:\n        if legacy:\n            return s.run(q, {'start': handle_id, 'end': other_handle_id}).single()['r'].id\n        return s.run(q, {'start': handle_id, 'end': other_handle_id}).single()['r']"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_location_relationship(manager, location_handle_id, other_handle_id, rel_type):\n    other_meta_type = get_node_meta_type(manager, other_handle_id)\n    if other_meta_type == 'Location' and rel_type == 'Has':\n        return _create_relationship(manager, location_handle_id, other_handle_id, rel_type)\n    raise exceptions.NoRelationshipPossible(location_handle_id, 'Location', other_handle_id, other_meta_type, rel_type)", "response": "Creates a relationship between two locations."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a relationship between two nodes and returns the relationship.", "response": "def create_logical_relationship(manager, logical_handle_id, other_handle_id, rel_type):\n    \"\"\"\n    Makes relationship between the two nodes and returns the relationship.\n    If a relationship is not possible NoRelationshipPossible exception is\n    raised.\n    \"\"\"\n    other_meta_type = get_node_meta_type(manager, other_handle_id)\n    if rel_type == 'Depends_on':\n        if other_meta_type == 'Logical' or other_meta_type == 'Physical':\n            return _create_relationship(manager, logical_handle_id, other_handle_id, rel_type)\n    elif rel_type == 'Part_of':\n        if other_meta_type == 'Physical':\n            return _create_relationship(manager, logical_handle_id, other_handle_id, rel_type)\n    raise exceptions.NoRelationshipPossible(logical_handle_id, 'Logical', other_handle_id, other_meta_type, rel_type)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_relation_relationship(manager, relation_handle_id, other_handle_id, rel_type):\n    other_meta_type = get_node_meta_type(manager, other_handle_id)\n    if other_meta_type == 'Logical':\n        if rel_type in ['Uses', 'Provides']:\n            return _create_relationship(manager, relation_handle_id, other_handle_id, rel_type)\n    elif other_meta_type == 'Location' and rel_type == 'Responsible_for':\n        return _create_relationship(manager, relation_handle_id, other_handle_id, rel_type)\n    elif other_meta_type == 'Physical':\n        if rel_type in ['Owns', 'Provides']:\n            return _create_relationship(manager, relation_handle_id, other_handle_id, rel_type)\n    raise exceptions.NoRelationshipPossible(relation_handle_id, 'Relation', other_handle_id, other_meta_type, rel_type)", "response": "Creates a relationship between two nodes and returns the relationship."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a relationship between two nodes.", "response": "def create_physical_relationship(manager, physical_handle_id, other_handle_id, rel_type):\n    \"\"\"\n    Makes relationship between the two nodes and returns the relationship.\n    If a relationship is not possible NoRelationshipPossible exception is\n    raised.\n    \"\"\"\n    other_meta_type = get_node_meta_type(manager, other_handle_id)\n    if other_meta_type == 'Physical':\n        if rel_type == 'Has' or rel_type == 'Connected_to':\n            return _create_relationship(manager, physical_handle_id, other_handle_id, rel_type)\n    elif other_meta_type == 'Location' and rel_type == 'Located_in':\n        return _create_relationship(manager, physical_handle_id, other_handle_id, rel_type)\n    raise exceptions.NoRelationshipPossible(physical_handle_id, 'Physical', other_handle_id, other_meta_type, rel_type)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a relationship from node to other_node depending on which meta_type the nodes are.", "response": "def create_relationship(manager, handle_id, other_handle_id, rel_type):\n    \"\"\"\n    Makes a relationship from node to other_node depending on which\n    meta_type the nodes are. Returns the relationship or raises\n    NoRelationshipPossible exception.\n    \"\"\"\n    meta_type = get_node_meta_type(manager, handle_id)\n    if meta_type == 'Location':\n        return create_location_relationship(manager, handle_id, other_handle_id, rel_type)\n    elif meta_type == 'Logical':\n        return create_logical_relationship(manager, handle_id, other_handle_id, rel_type)\n    elif meta_type == 'Relation':\n        return create_relation_relationship(manager, handle_id, other_handle_id, rel_type)\n    elif meta_type == 'Physical':\n        return create_physical_relationship(manager, handle_id, other_handle_id, rel_type)\n    other_meta_type = get_node_meta_type(manager, other_handle_id)\n    raise exceptions.NoRelationshipPossible(handle_id, meta_type, other_handle_id, other_meta_type, rel_type)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_relationships(manager, handle_id1, handle_id2, rel_type=None, legacy=True):\n    if rel_type:\n        q = \"\"\"\n        MATCH (a:Node {{handle_id: {{handle_id1}}}})-[r:{rel_type}]-(b:Node {{handle_id: {{handle_id2}}}})\n        RETURN collect(r) as relationships\n        \"\"\".format(rel_type=rel_type)\n    else:\n        q = \"\"\"\n            MATCH (a:Node {handle_id: {handle_id1}})-[r]-(b:Node {handle_id: {handle_id2}})\n            RETURN collect(r) as relationships\n            \"\"\"\n    with manager.session as s:\n        if legacy:\n            relationships = s.run(q, {'handle_id1': handle_id1, 'handle_id2': handle_id2}).single()['relationships']\n            return [relationship.id for relationship in relationships]\n        return s.run(q, {'handle_id1': handle_id1, 'handle_id2': handle_id2}).single()['relationships']", "response": "Get the relationships between two nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a Node model or sub class of models. BaseNodeModel.", "response": "def get_node_model(manager, handle_id=None, node=None):\n    \"\"\"\n    :param manager: Context manager to handle transactions\n    :type manager: Neo4jDBSessionManager\n    :param handle_id: Nodes handle id\n    :type handle_id: str|unicode\n    :param node: Node object\n    :type node: neo4j.v1.types.Node\n    :return: Node model\n    :rtype: models.BaseNodeModel or sub class of models.BaseNodeModel\n    \"\"\"\n    bundle = get_node_bundle(manager, handle_id, node)\n    for label in bundle.get('labels'):\n        try:\n            classname = '{meta_type}{base}Model'.format(meta_type=bundle.get('meta_type'), base=label).replace('_', '')\n            return getattr(models, classname)(manager).load(bundle)\n        except AttributeError:\n            pass\n    for label in bundle.get('labels'):\n        try:\n            classname = '{base}Model'.format(base=label).replace('_', '')\n            return getattr(models, classname)(manager).load(bundle)\n        except AttributeError:\n            pass\n    try:\n        classname = '{base}Model'.format(base=bundle.get('meta_type'))\n        return getattr(models, classname)(manager).load(bundle)\n    except AttributeError:\n        return models.BaseNodeModel(manager).load(bundle)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_relationship_model(manager, relationship_id):\n    bundle = get_relationship_bundle(manager, relationship_id)\n    return models.BaseRelationshipModel(manager).load(bundle)", "response": "Returns the relationship model for the given relationship id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_code(self, url, html):\n        soup = BeautifulSoup(html, 'html5lib', from_encoding='utf-8')\n\n        # -- main text\n        div = (soup\n               .find('div', id='content_false')\n               .find('div', attrs={'class': 'data'}))\n\n        code = Code(self.id_code,\n                    date_pub=self.date_pub,\n                    url_code=cleanup_url(url))\n\n        # -- Code title/subtitle\n        div_title = div.find('div', id='titreTexte')\n        span_subtitle = div_title.find('span',\n                                       attrs={'class': 'sousTitreTexte'})\n        if span_subtitle:\n            code.title = div_title.text.replace(span_subtitle.text, '')\n            code.subtitle = span_subtitle.text.strip()\n            regex = r'Version consolid\u00e9e au (\\d{1,2}(?:er)?\\s+[^\\s]+\\s+\\d{4})'\n            m = re.search(regex, code.subtitle)\n            if m:\n                code.date_pub = parse_date(m.group(1))\n\n        code.title = code.title.strip()\n\n        # -- TOC\n        code.children = [self.parse_code_ul(url, child)\n                         for child in div.find_all('ul', recursive=False)]\n\n        return code", "response": "Parse the code details and TOC from the given HTML content."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_code_ul(self, url, ul):\n        li_list = ul.find_all('li', recursive=False)\n        li = li_list[0]\n        span_title = li.find('span',\n                             attrs={'class': re.compile(r'TM\\d+Code')},\n                             recursive=False)\n\n        section = Section(span_title.attrs['id'], span_title.text.strip())\n        div_italic = li.find('div', attrs={'class': 'italic'}, recursive=False)\n        if div_italic:\n            section.content = div_italic.text.strip()\n        span_link = li.find('span',\n                            attrs={'class': 'codeLienArt'},\n                            recursive=False)\n        if span_link:\n            a_link = span_link.find('a', recursive=False)\n            if self.with_articles:\n                service = self.section_service\n                section.articles = service.articles(self.id_code,\n                                                    section.id_section,\n                                                    self.date_pub)\n            else:\n                section.articles = a_link.text.strip()\n            section.url_section = cleanup_url(\n                urljoin(url, a_link.attrs['href']))\n        section.children = [self.parse_code_ul(url, child)\n                            for child in li.find_all('ul', recursive=False)]\n        return section", "response": "Parses the code li and returns a new toc item"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd an interval to the internal list of entries in the internal list.", "response": "def add(self, interval, offset):\n        \"\"\"\n        The added interval must be overlapping or beyond the last stored interval ie. added in sorted order.\n\n        :param interval: interval to add\n        :param offset: full virtual offset to add\n        :return:\n        \"\"\"\n        start, stop = self.get_start_stop(interval)\n\n        if len(self.starts) > 0:\n            if start < self.starts[-1] or offset <= self.offsets[-1][1]:\n                raise ValueError('intervals and offsets must be added in-order')\n            self.offsets[-1][1] = offset\n            self.offsets[-1][2] += 1\n        else:\n            self.starts.append(start)\n            self.stops.append(stop)\n            self.offsets.append([offset, offset, 1])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting sum for queryset.", "response": "def get_sum(qs, field):\n    \"\"\"\n    get sum for queryset.\n\n    ``qs``: queryset\n    ``field``: The field name to sum.\n    \"\"\"\n    sum_field = '%s__sum' % field\n    qty = qs.aggregate(Sum(field))[sum_field]\n    return qty if qty else 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_max(qs, field):\n    max_field = '%s__max' % field\n    num = qs.aggregate(Max(field))[max_field]\n    return num if num else 0", "response": "get max for queryset.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread variable star data in GCVS format.", "response": "def read_gcvs(filename):\n    \"\"\"\n    Reads variable star data in `GCVS format`_.\n\n    :param filename: path to GCVS data file (usually ``iii.dat``)\n\n    .. _`GCVS format`: http://www.sai.msu.su/gcvs/gcvs/iii/html/\n    \"\"\"\n    with open(filename, 'r') as fp:\n        parser = GcvsParser(fp)\n        for star in parser:\n            yield star"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dict_to_body(star_dict):\n    if ephem is None:  # pragma: no cover\n        raise NotImplementedError(\"Please install PyEphem in order to use dict_to_body.\")\n    body = ephem.FixedBody()\n    body.name = star_dict['name']\n    body._ra = ephem.hours(str(star_dict['ra']))\n    body._dec = ephem.degrees(str(star_dict['dec']))\n    body._epoch = ephem.J2000\n    return body", "response": "Converts a dictionary of variable star data to a Body instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tempfile(self):\n        \"write the docx to a named tmpfile and return the tmpfile filename\"\n        tf = tempfile.NamedTemporaryFile()\n        tfn = tf.name\n        tf.close()\n        os.remove(tf.name)\n        shutil.copy(self.fn, tfn)\n        return tfn", "response": "write the docx to a named tmpfile and return the tmpfile filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sheets(self):\n        data = Dict()\n        for src in [src for src in self.zipfile.namelist() if 'xl/worksheets/' in src]:\n            name = os.path.splitext(os.path.basename(src))[0]\n            xml = self.xml(src)\n            data[name] = xml\n        return data", "response": "return the sheets of data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef workbook_data(self):\n        document = XML(\n            fn=os.path.splitext(self.fn)[0]+'.xml', \n            root=Element.workbook())\n        shared_strings = [\n            str(t.text) for t in \n            self.xml('xl/sharedStrings.xml')\n                .root.xpath(\".//xl:t\", namespaces=self.NS)]\n        for key in self.sheets.keys():\n            worksheet = self.sheets[key].transform(XT, shared_strings=shared_strings)\n            document.root.append(worksheet.root)\n        return document", "response": "return a readable XML form of the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nputs and process tasks in queue.", "response": "def process(self, event):\n        \"\"\"Put and process tasks in queue.\n        \"\"\"\n        logger.info(f\"{self}: put {event.src_path}\")\n        self.queue.put(os.path.basename(event.src_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n\tprint \"Downloading Holidays from Apple's server...\"\n\tr = requests.get('http://files.apple.com/calendars/Australian32Holidays.ics')\n\t\n\tcal = Calendar.from_ical(r.text)\n\t\n\tprint \"Processing calendar data...\"\n\t\n\tvalid_states = ['ACT', 'NSW', 'NT', 'QLD', 'SA', 'TAS', 'VIC', 'WA']\n\t\n\tstate_cal = {}\n\tall_cal = make_calendar()\n\t\n\tfor state in valid_states:\n\t\tstate_cal[state] = make_calendar()\n\t\n\tfor event in cal.walk('VEVENT'):\n\t\tevent_name = event.decoded('SUMMARY').lower()\n\t\tif filter(lambda x: x in event_name, IGNORED_EVENTS):\n\t\t\tcontinue\n\t\t\n\t\t# see if there is a state or if it is for all\n\t\tif '(' in event_name: # and not 'day in lieu' in event_name:\n\t\t\t# it is just for certain states.\n\t\t\t# eg:\n\t\t\t#  - Easter Tuesday (TAS)\n\t\t\t#  - Labour Day (ACT, NSW, SA, QLD)\n\t\t\tstates = event_name.split('(', 2)[1].split(')')[0].split(',')\n\t\t\t\n\t\t\tif states == ['day in lieu']:\n\t\t\t\t# only a day in lieu, switch to all-cal logic\n\t\t\t\tall_cal.add_component(event)\n\t\t\t\tcontinue\n\n\t\t\tfor state in states:\n\t\t\t\tstate = state.strip().upper()\n\t\t\t\tassert state in valid_states, 'state=%r' % state\n\t\t\t\tstate_cal[state].add_component(event)\n\t\telse:\n\t\t\t# for all states\n\t\t\tall_cal.add_component(event)\n\n\tprint \"Writing to disk...\"\n\t# done, write calendars.\n\twith open('au_holidays.ics', 'wb') as f:\n\t\tf.write(all_cal.to_ical())\n\n\tfor state in state_cal.keys():\n\t\twith open('%s_holidays.ics' % state.lower(), 'wb') as f:\n\t\t\tf.write(state_cal[state].to_ical())\n\t\n\tprint \"All done!\"", "response": "This function is used to generate the listings for the Australian public holidays. It will download the iCal feed and generate the listings for each state."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nfind matching line in line", "response": "def vi_pos_matching (line, index=0):\n    '''find matching <([{}])>'''\n    anchor = None\n    target = None\n    delta = 1\n    count = 0\n    try:\n        while 1:\n            if anchor is None:\n                # first find anchor\n                try:\n                    target, delta = _vi_dct_matching [line [index]]\n                    anchor = line [index]\n                    count = 1\n                except KeyError:\n                    index += 1\n                    continue\n            else:\n                # Here the anchor has been found\n                # Need to get corresponding target\n                if index < 0:\n                    return -1\n                if line [index] == anchor:\n                    count += 1\n                elif line [index] == target:\n                    count -= 1\n                    if count == 0:\n                        return index\n            index += delta\n    except IndexError:\n        return -1"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the vi editing mode.", "response": "def init_editing_mode(self, e): # (M-C-j)\n        '''Initialize vi editingmode'''\n        self.show_all_if_ambiguous = 'on'\n        self.key_dispatch = {}\n        self.__vi_insert_mode = None\n        self._vi_command = None\n        self._vi_command_edit = None\n        self._vi_key_find_char = None\n        self._vi_key_find_direction = True\n        self._vi_yank_buffer = None\n        self._vi_multiplier1 = ''\n        self._vi_multiplier2 = ''\n        self._vi_undo_stack = []\n        self._vi_undo_cursor = -1\n        self._vi_current = None\n        self._vi_search_text = ''\n        self.vi_save_line ()\n        self.vi_set_insert_mode (True)\n        # make ' ' to ~ self insert\n        for c in range(ord(' '), 127):\n            self._bind_key('%s' % chr(c), self.vi_key)\n        self._bind_key('BackSpace', self.vi_backspace)\n        self._bind_key('Escape', self.vi_escape)\n        self._bind_key('Return', self.vi_accept_line)\n\n        self._bind_key('Left', self.backward_char)\n        self._bind_key('Right', self.forward_char)\n        self._bind_key('Home', self.beginning_of_line)\n        self._bind_key('End', self.end_of_line)\n        self._bind_key('Delete', self.delete_char)\n\n        self._bind_key('Control-d', self.vi_eof)\n        self._bind_key('Control-z', self.vi_eof)\n        self._bind_key('Control-r', self.vi_redo)\n        self._bind_key('Up', self.vi_arrow_up)\n        self._bind_key('Control-p', self.vi_up)\n        self._bind_key('Down', self.vi_arrow_down)\n        self._bind_key('Control-n', self.vi_down)\n        self._bind_key('Tab', self.vi_complete)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfind matching < [ 0 - 9 ] >", "response": "def key_percent (self, char):\n        '''find matching <([{}])>'''\n        self.motion = self.motion_matching\n        self.delete_right = 1\n        self.state = _VI_MOTION\n        self.apply ()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef store_user_documents(user_document_gen, client, mongo_database_name, mongo_collection_name):\n    mongo_database = client[mongo_database_name]\n    mongo_collection = mongo_database[mongo_collection_name]\n\n    # Iterate over all users to be annotated and store the Twitter lists in mongo.\n    for user_twitter_id, user_document_list in user_document_gen:\n        document = user_document_list\n        document[\"_id\"] = int(user_twitter_id)\n        mongo_collection.update({\"_id\": user_twitter_id}, document, upsert=True)", "response": "Stores all Twitter lists in a single MongoDB collection."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads Twitter lists for a single user in a different mongo collection.", "response": "def read_user_documents_for_single_user_generator(user_twitter_id, mongo_database):\n    \"\"\"\n    Stores Twitter list objects that a Twitter user is a member of in different mongo collections.\n\n    Inputs: - user_twitter_id: A Twitter user id.\n            - mongo_database: A mongo database.\n\n    Yields: - twitter_list: A tuple containing: * A Twitter user id.\n                                                * A python list containing Twitter lists in dictionary (json) format.\n    \"\"\"\n    collection_name = str(user_twitter_id)\n    collection = mongo_database[collection_name]\n    cursor = collection.find()\n\n    for twitter_list in cursor:\n        yield twitter_list"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading Twitter lists from a list of Twitter users.", "response": "def read_user_documents_generator(user_twitter_id_list, client, mongo_database_name, mongo_collection_name):\n    \"\"\"\n    Stores Twitter list objects that a Twitter user is a member of in different mongo collections.\n\n    Inputs: - user_twitter_id_list: A python list of Twitter user ids.\n            - client: A pymongo MongoClient object.\n            - mongo_database_name: The name of a Mongo database as a string.\n            - mongo_collection_name: The name of the mongo collection as a string.\n\n    Yields: - user_twitter_id: A Twitter user id.\n            - twitter_list_gen: A python generator that yields Twitter lists in dictionary (json) format.\n    \"\"\"\n    mongo_database = client[mongo_database_name]\n    mongo_collection = mongo_database[mongo_collection_name]\n\n    # cursor = mongo_collection.find({\"_id\": {\"$in\": [int(user_twitter_id) for user_twitter_id in user_twitter_id_list]}})\n    cursor = mongo_collection.find()\n\n    user_twitter_id_list = [int(user_twitter_id) for user_twitter_id in user_twitter_id_list]\n    user_twitter_id_list = set(user_twitter_id_list)\n\n    for documents in cursor:\n        if documents[\"_id\"] in user_twitter_id_list:\n            yield documents[\"_id\"], documents"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_collection_documents_generator(client, database_name, collection_name, spec, latest_n, sort_key):\n    mongo_database = client[database_name]\n    collection = mongo_database[collection_name]\n    collection.create_index(sort_key)\n\n    if latest_n is not None:\n        skip_n = collection.count() - latest_n\n        if collection.count() - latest_n < 0:\n            skip_n = 0\n        cursor = collection.find(filter=spec).sort([(sort_key, ASCENDING), ])\n        cursor = cursor[skip_n:]\n    else:\n        cursor = collection.find(filter=spec).sort([(sort_key, ASCENDING), ])\n\n    for document in cursor:\n        yield document", "response": "This function returns a generator that yields tweets stored in a mongodb collection."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a tweet python generator, we encode the information into mention and retweet graphs and a lemma matrix. We assume that the tweets are given in increasing timestamp. Inputs: - tweet_generator: A python generator of tweets in python dictionary (json) format. Outputs: - mention_graph: The mention graph as a SciPy sparse matrix. - retweet_graph: The retweet graph as a SciPy sparse matrix. - user_lemma_matrix: The user lemma vector representation matrix as a SciPy sparse matrix. - tweet_id_set: A python set containing the Twitter ids for all the dataset tweets. - user_id_set: A python set containing the Twitter ids for all the dataset users. - lemma_to_attribute: A map from lemmas to numbers in python dictionary format.", "response": "def extract_graphs_and_lemmas_from_tweets(tweet_generator):\n    \"\"\"\n    Given a tweet python generator, we encode the information into mention and retweet graphs and a lemma matrix.\n\n    We assume that the tweets are given in increasing timestamp.\n\n    Inputs:  - tweet_generator: A python generator of tweets in python dictionary (json) format.\n\n    Outputs: - mention_graph: The mention graph as a SciPy sparse matrix.\n             - retweet_graph: The retweet graph as a SciPy sparse matrix.\n             - user_lemma_matrix: The user lemma vector representation matrix as a SciPy sparse matrix.\n             - tweet_id_set: A python set containing the Twitter ids for all the dataset tweets.\n             - user_id_set: A python set containing the Twitter ids for all the dataset users.\n             - lemma_to_attribute: A map from lemmas to numbers in python dictionary format.\n    \"\"\"\n    ####################################################################################################################\n    # Prepare for iterating over tweets.\n    ####################################################################################################################\n    # These are initialized as lists for incremental extension.\n    tweet_id_set = set()\n    user_id_set = list()\n\n    add_tweet_id = tweet_id_set.add\n    append_user_id = user_id_set.append\n\n    # Initialize sparse matrix arrays.\n    mention_graph_row = list()\n    mention_graph_col = list()\n\n    retweet_graph_row = list()\n    retweet_graph_col = list()\n\n    user_lemma_matrix_row = list()\n    user_lemma_matrix_col = list()\n    user_lemma_matrix_data = list()\n\n    append_mention_graph_row = mention_graph_row.append\n    append_mention_graph_col = mention_graph_col.append\n\n    append_retweet_graph_row = retweet_graph_row.append\n    append_retweet_graph_col = retweet_graph_col.append\n\n    extend_user_lemma_matrix_row = user_lemma_matrix_row.extend\n    extend_user_lemma_matrix_col = user_lemma_matrix_col.extend\n    extend_user_lemma_matrix_data = user_lemma_matrix_data.extend\n\n    # Initialize dictionaries.\n    id_to_node = dict()\n    id_to_name = dict()\n    id_to_username = dict()\n    id_to_listedcount = dict()\n    lemma_to_attribute = dict()\n\n    sent_tokenize, _treebank_word_tokenize = get_tokenizer()\n    # tagger = HunposTagger('hunpos-1.0-linux/english.model', 'hunpos-1.0-linux/hunpos-tag')\n    # tagger = PerceptronTagger()\n    tagger = get_braupt_tagger()\n    lemmatizer, lemmatize = get_lemmatizer(\"wordnet\")\n    stopset = get_stopset()\n    first_cap_re, all_cap_re = get_camel_case_regexes()\n    digits_punctuation_whitespace_re = get_digits_punctuation_whitespace_regex()\n    pos_set = get_pos_set()\n\n    ####################################################################################################################\n    # Iterate over tweets.\n    ####################################################################################################################\n    counter = 0\n    for tweet in tweet_generator:\n        # print(tweet)\n        # Increment tweet counter.\n        counter += 1\n        # if counter % 10000 == 0:\n        #     print(counter)\n        # print(counter)\n\n        # Extract base tweet's values.\n        try:\n            tweet_id = tweet[\"id\"]\n            user_id = tweet[\"user\"][\"id\"]\n            user_name = tweet[\"user\"][\"name\"]\n            user_screen_name = tweet[\"user\"][\"screen_name\"]\n\n            listed_count_raw = tweet[\"user\"][\"listed_count\"]\n\n            tweet_text = tweet[\"text\"]\n\n            tweet_in_reply_to_user_id = tweet[\"in_reply_to_user_id\"]\n            tweet_in_reply_to_screen_name = tweet[\"in_reply_to_screen_name\"]\n            tweet_entities_user_mentions = tweet[\"entities\"][\"user_mentions\"]\n\n            if \"retweeted_status\" not in tweet.keys():\n                user_mention_id_list = list()\n                user_mention_screen_name_list = list()\n                for user_mention in tweet_entities_user_mentions:\n                    user_mention_id_list.append(user_mention[\"id\"])\n                    user_mention_screen_name_list.append(user_mention[\"screen_name\"])\n            else:\n                # Extract base tweet's values.\n                original_tweet = tweet[\"retweeted_status\"]\n\n                original_tweet_id = original_tweet[\"id\"]\n                original_tweet_user_id = original_tweet[\"user\"][\"id\"]\n                original_tweet_user_name = original_tweet[\"user\"][\"name\"]\n                original_tweet_user_screen_name = original_tweet[\"user\"][\"screen_name\"]\n\n                listed_count_raw = original_tweet[\"user\"][\"listed_count\"]\n\n                original_tweet_text = original_tweet[\"text\"]\n\n                original_tweet_in_reply_to_user_id = original_tweet[\"in_reply_to_user_id\"]\n                original_tweet_in_reply_to_screen_name = original_tweet[\"in_reply_to_screen_name\"]\n                original_tweet_entities_user_mentions = original_tweet[\"entities\"][\"user_mentions\"]\n\n                original_tweet_user_mention_id_list = list()\n                original_tweet_user_mention_screen_name_list = list()\n                for user_mention in original_tweet_entities_user_mentions:\n                    original_tweet_user_mention_id_list.append(user_mention[\"id\"])\n                    original_tweet_user_mention_screen_name_list.append(user_mention[\"screen_name\"])\n        except KeyError:\n            continue\n        # Map users to distinct integer numbers.\n        graph_size = len(id_to_node)\n        source_node = id_to_node.setdefault(user_id, graph_size)\n\n        if listed_count_raw is None:\n            id_to_listedcount[user_id] = 0\n        else:\n            id_to_listedcount[user_id] = int(listed_count_raw)\n\n        # Update sets, lists and dictionaries.\n        add_tweet_id(tweet_id)\n        id_to_name[user_id] = user_screen_name\n        id_to_username[user_id] = user_name\n        append_user_id(user_id)\n\n        ################################################################################################################\n        # We are dealing with an original tweet.\n        ################################################################################################################\n        if \"retweeted_status\" not in tweet.keys():\n            ############################################################################################################\n            # Update user-lemma frequency matrix.\n            ############################################################################################################\n            # Extract lemmas from the text.\n            tweet_lemmas, lemma_to_keywordbag = clean_document(tweet_text, sent_tokenize, _treebank_word_tokenize,\n                                                               tagger, lemmatizer, lemmatize, stopset,\n                                                               first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                               pos_set)\n\n            number_of_lemmas = len(tweet_lemmas)\n\n            # Update the user-lemma frequency matrix one-by-one.\n            attribute_list = list()\n            append_attribute = attribute_list.append\n            for lemma in tweet_lemmas:\n                # Map lemmas to distinct integer numbers.\n                vocabulary_size = len(lemma_to_attribute)\n                attribute = lemma_to_attribute.setdefault(lemma, vocabulary_size)\n                append_attribute(attribute)\n\n            # Add values to the sparse matrix arrays.\n            extend_user_lemma_matrix_row(number_of_lemmas*[source_node])\n            extend_user_lemma_matrix_col(attribute_list)\n            extend_user_lemma_matrix_data(number_of_lemmas*[1.0])\n\n            ############################################################################################################\n            # Update mention matrix.\n            ############################################################################################################\n            # Get mentioned user ids.\n            mentioned_user_id_set = list()\n            if tweet_in_reply_to_user_id is not None:\n                mentioned_user_id_set.append(tweet_in_reply_to_user_id)\n\n                id_to_name[tweet_in_reply_to_user_id] = tweet_in_reply_to_screen_name\n            for user_mention, mentioned_user_id, mentioned_user_screen_name in zip(tweet_entities_user_mentions,\n                                                                                   user_mention_id_list,\n                                                                                   user_mention_screen_name_list):\n                mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = mentioned_user_screen_name\n\n            # We remove duplicates.\n            mentioned_user_id_set = set(mentioned_user_id_set)\n\n            # Update the mention graph one-by-one.\n            for mentioned_user_id in mentioned_user_id_set:\n                # Map users to distinct integer numbers.\n                graph_size = len(id_to_node)\n                mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                append_user_id(mentioned_user_id)\n\n                # Add values to the sparse matrix arrays.\n                append_mention_graph_row(source_node)\n                append_mention_graph_col(mention_target_node)\n\n        ################################################################################################################\n        # We are dealing with a retweet.\n        ################################################################################################################\n        else:\n            # Map users to distinct integer numbers.\n            graph_size = len(id_to_node)\n            original_tweet_node = id_to_node.setdefault(original_tweet_user_id, graph_size)\n\n            if listed_count_raw is None:\n                id_to_listedcount[user_id] = 0\n            else:\n                id_to_listedcount[user_id] = int(listed_count_raw)\n\n            # Update retweet graph.\n            append_retweet_graph_row(source_node)\n            append_retweet_graph_col(original_tweet_node)\n\n            # Extract lemmas from the text.\n            tweet_lemmas, lemma_to_keywordbag = clean_document(original_tweet_text, sent_tokenize, _treebank_word_tokenize,\n                                                               tagger, lemmatizer, lemmatize, stopset,\n                                                               first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                               pos_set)\n\n            number_of_lemmas = len(tweet_lemmas)\n\n            # Update the user-lemma frequency matrix one-by-one.\n            attribute_list = list()\n            append_attribute = attribute_list.append\n            for lemma in tweet_lemmas:\n                # Map lemmas to distinct integer numbers.\n                vocabulary_size = len(lemma_to_attribute)\n                attribute = lemma_to_attribute.setdefault(lemma, vocabulary_size)\n                append_attribute(attribute)\n\n            # Add values to the sparse matrix arrays.\n            extend_user_lemma_matrix_row(number_of_lemmas*[source_node])\n            extend_user_lemma_matrix_col(attribute_list)\n            extend_user_lemma_matrix_data(number_of_lemmas*[1.0])\n\n            # Get mentioned user ids.\n            mentioned_user_id_set = list()\n            if original_tweet_in_reply_to_user_id is not None:\n                mentioned_user_id_set.append(original_tweet_in_reply_to_user_id)\n\n                id_to_name[original_tweet_in_reply_to_user_id] = original_tweet_in_reply_to_screen_name\n            for user_mention, mentioned_user_id, mentioned_user_screen_name in zip(original_tweet_entities_user_mentions,\n                                                                                   original_tweet_user_mention_id_list,\n                                                                                   original_tweet_user_mention_screen_name_list):\n                mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = mentioned_user_screen_name\n\n            # We remove duplicates.\n            mentioned_user_id_set = set(mentioned_user_id_set)\n\n            # Get mentioned user ids.\n            retweet_mentioned_user_id_set = list()\n            if original_tweet_in_reply_to_user_id is not None:\n                retweet_mentioned_user_id_set.append(original_tweet_in_reply_to_user_id)\n\n                id_to_name[original_tweet_in_reply_to_user_id] = original_tweet_in_reply_to_screen_name\n            for user_mention, mentioned_user_id, mentioned_user_screen_name in zip(original_tweet_entities_user_mentions,\n                                                                                   original_tweet_user_mention_id_list,\n                                                                                   original_tweet_user_mention_screen_name_list):\n                retweet_mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = mentioned_user_screen_name\n\n            # We remove duplicates.\n            retweet_mentioned_user_id_set = set(retweet_mentioned_user_id_set)\n\n            mentioned_user_id_set.update(retweet_mentioned_user_id_set)\n\n            # Update the mention graph one-by-one.\n            for mentioned_user_id in mentioned_user_id_set:\n                # Map users to distinct integer numbers.\n                graph_size = len(id_to_node)\n                mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                append_user_id(mentioned_user_id)\n\n                # Add values to the sparse matrix arrays.\n                append_mention_graph_row(source_node)\n                append_mention_graph_col(mention_target_node)\n\n            # This is the first time we deal with this tweet.\n            if original_tweet_id not in tweet_id_set:\n                # Update sets, lists and dictionaries.\n                add_tweet_id(original_tweet_id)\n                id_to_name[original_tweet_user_id] = original_tweet_user_screen_name\n                id_to_username[original_tweet_user_id] = original_tweet_user_name\n                append_user_id(original_tweet_user_id)\n\n                ########################################################################################################\n                # Update user-lemma frequency matrix.\n                ########################################################################################################\n                # Update the user-lemma frequency matrix one-by-one.\n                attribute_list = list()\n                append_attribute = attribute_list.append\n                for lemma in tweet_lemmas:\n                    # Map lemmas to distinct integer numbers.\n                    vocabulary_size = len(lemma_to_attribute)\n                    attribute = lemma_to_attribute.setdefault(lemma, vocabulary_size)\n                    append_attribute(attribute)\n\n                # Add values to the sparse matrix arrays.\n                extend_user_lemma_matrix_row(number_of_lemmas*[source_node])\n                extend_user_lemma_matrix_col(attribute_list)\n                extend_user_lemma_matrix_data(number_of_lemmas*[1.0])\n\n                ########################################################################################################\n                # Update mention matrix.\n                ########################################################################################################\n                # Update the mention graph one-by-one.\n                for mentioned_user_id in retweet_mentioned_user_id_set:\n                    # Map users to distinct integer numbers.\n                    graph_size = len(id_to_node)\n                    mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                    append_user_id(mentioned_user_id)\n\n                    # Add values to the sparse matrix arrays.\n                    append_mention_graph_row(original_tweet_node)\n                    append_mention_graph_col(mention_target_node)\n            else:\n                pass\n\n    ####################################################################################################################\n    # Final steps of preprocessing tweets.\n    ####################################################################################################################\n    # Discard any duplicates.\n    user_id_set = set(user_id_set)\n    number_of_users = len(user_id_set)\n    # min_number_of_users = max(user_id_set) + 1\n\n    # Form mention graph adjacency matrix.\n    mention_graph_row = np.array(mention_graph_row, dtype=np.int64)\n    mention_graph_col = np.array(mention_graph_col, dtype=np.int64)\n    mention_graph_data = np.ones_like(mention_graph_row, dtype=np.float64)\n\n    mention_graph = spsp.coo_matrix((mention_graph_data, (mention_graph_row, mention_graph_col)),\n                                    shape=(number_of_users, number_of_users))\n    mention_graph = spsp.coo_matrix(spsp.csr_matrix(mention_graph))\n\n    # Form retweet graph adjacency matrix.\n    retweet_graph_row = np.array(retweet_graph_row, dtype=np.int64)\n    retweet_graph_col = np.array(retweet_graph_col, dtype=np.int64)\n    retweet_graph_data = np.ones_like(retweet_graph_row, dtype=np.float64)\n\n    retweet_graph = spsp.coo_matrix((retweet_graph_data, (retweet_graph_row, retweet_graph_col)),\n                                    shape=(number_of_users, number_of_users))\n    retweet_graph = spsp.coo_matrix(spsp.csr_matrix(retweet_graph))\n\n    # Form user-lemma matrix.\n    number_of_lemmas = len(lemma_to_attribute)\n\n    user_lemma_matrix_row = np.array(user_lemma_matrix_row, dtype=np.int64)\n    user_lemma_matrix_col = np.array(user_lemma_matrix_col, dtype=np.int64)\n    user_lemma_matrix_data = np.array(user_lemma_matrix_data, dtype=np.float64)\n\n    user_lemma_matrix = spsp.coo_matrix((user_lemma_matrix_data, (user_lemma_matrix_row, user_lemma_matrix_col)),\n                                        shape=(number_of_users, number_of_lemmas))\n    user_lemma_matrix = spsp.coo_matrix(spsp.csr_matrix(user_lemma_matrix))\n\n    node_to_id = dict(zip(id_to_node.values(), id_to_node.keys()))\n\n    # tagger.close()\n\n    return mention_graph, retweet_graph, user_lemma_matrix, tweet_id_set, user_id_set, node_to_id, lemma_to_attribute, id_to_name, id_to_username, id_to_listedcount"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a tweet python generator, we encode the information into mention and retweet graphs. We assume that the tweets are given in increasing timestamp. Inputs: - tweet_generator: A python generator of tweets in python dictionary (json) format. Outputs: - mention_graph: The mention graph as a SciPy sparse matrix. - user_id_set: A python set containing the Twitter ids for all the dataset users. - node_to_id: A python dictionary that maps from node anonymized ids, to twitter user ids.", "response": "def extract_graphs_from_tweets(tweet_generator):\n    \"\"\"\n    Given a tweet python generator, we encode the information into mention and retweet graphs.\n\n    We assume that the tweets are given in increasing timestamp.\n\n    Inputs:  - tweet_generator: A python generator of tweets in python dictionary (json) format.\n\n    Outputs: - mention_graph: The mention graph as a SciPy sparse matrix.\n             - user_id_set: A python set containing the Twitter ids for all the dataset users.\n             - node_to_id: A python dictionary that maps from node anonymized ids, to twitter user ids.\n    \"\"\"\n    ####################################################################################################################\n    # Prepare for iterating over tweets.\n    ####################################################################################################################\n    # These are initialized as lists for incremental extension.\n    tweet_id_set = set()\n    user_id_set = list()\n    twitter_to_reveal_user_id = dict()\n\n    add_tweet_id = tweet_id_set.add\n    append_user_id = user_id_set.append\n\n    # Initialize sparse matrix arrays.\n    mention_graph_row = list()\n    mention_graph_col = list()\n\n    retweet_graph_row = list()\n    retweet_graph_col = list()\n\n    append_mention_graph_row = mention_graph_row.append\n    append_mention_graph_col = mention_graph_col.append\n\n    append_retweet_graph_row = retweet_graph_row.append\n    append_retweet_graph_col = retweet_graph_col.append\n\n    # Initialize dictionaries.\n    id_to_node = dict()\n    id_to_name = dict()\n    id_to_username = dict()\n    id_to_listedcount = dict()\n\n    ####################################################################################################################\n    # Iterate over tweets.\n    ####################################################################################################################\n    counter = 0\n    for tweet in tweet_generator:\n        # Increment tweet counter.\n        counter += 1\n        if counter % 10000 == 0:\n            print(counter)\n        # print(counter)\n\n        # Extract base tweet's values.\n        try:\n            tweet_id = tweet[\"id\"]\n            user_id = tweet[\"user\"][\"id\"]\n            user_screen_name = tweet[\"user\"][\"screen_name\"]\n            user_name = tweet[\"user\"][\"name\"]\n\n            listed_count_raw = tweet[\"user\"][\"listed_count\"]\n\n            tweet_in_reply_to_user_id = tweet[\"in_reply_to_user_id\"]\n            tweet_in_reply_to_screen_name = tweet[\"in_reply_to_screen_name\"]\n            tweet_entities_user_mentions = tweet[\"entities\"][\"user_mentions\"]\n        except KeyError:\n            continue\n\n        # Map users to distinct integer numbers.\n        graph_size = len(id_to_node)\n        source_node = id_to_node.setdefault(user_id, graph_size)\n\n        if listed_count_raw is None:\n            id_to_listedcount[user_id] = 0\n        else:\n            id_to_listedcount[user_id] = int(listed_count_raw)\n\n        # Update sets, lists and dictionaries.\n        add_tweet_id(tweet_id)\n        id_to_name[user_id] = user_screen_name\n        id_to_username[user_id] = user_name\n        append_user_id(user_id)\n\n        # twitter_to_user_id\n\n        ################################################################################################################\n        # We are dealing with an original tweet.\n        ################################################################################################################\n        if \"retweeted_status\" not in tweet.keys():\n            ############################################################################################################\n            # Update mention matrix.\n            ############################################################################################################\n            # Get mentioned user ids.\n            mentioned_user_id_set = list()\n            if tweet_in_reply_to_user_id is not None:\n                mentioned_user_id_set.append(tweet_in_reply_to_user_id)\n\n                id_to_name[tweet_in_reply_to_user_id] = tweet_in_reply_to_screen_name\n            for user_mention in tweet_entities_user_mentions:\n                mentioned_user_id = user_mention[\"id\"]  # TODO: Perhaps safe extract as well.\n                mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = user_mention[\"screen_name\"]  # TODO: Perhaps safe extract as well.\n\n            # We remove duplicates.\n            mentioned_user_id_set = set(mentioned_user_id_set)\n\n            # Update the mention graph one-by-one.\n            for mentioned_user_id in mentioned_user_id_set:\n                # Map users to distinct integer numbers.\n                graph_size = len(id_to_node)\n                mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                append_user_id(mentioned_user_id)\n\n                # Add values to the sparse matrix arrays.\n                append_mention_graph_row(source_node)\n                append_mention_graph_col(mention_target_node)\n\n        ################################################################################################################\n        # We are dealing with a retweet.\n        ################################################################################################################\n        else:\n            # Extract base tweet's values.\n            original_tweet = tweet[\"retweeted_status\"]\n\n            try:\n                original_tweet_id = original_tweet[\"id\"]\n                original_tweet_user_id = original_tweet[\"user\"][\"id\"]\n                original_tweet_user_screen_name = original_tweet[\"user\"][\"screen_name\"]\n                original_tweet_user_name = original_tweet[\"user\"][\"name\"]\n\n                listed_count_raw = original_tweet[\"user\"][\"listed_count\"]\n\n                original_tweet_in_reply_to_user_id = original_tweet[\"in_reply_to_user_id\"]\n                original_tweet_in_reply_to_screen_name = original_tweet[\"in_reply_to_screen_name\"]\n                original_tweet_entities_user_mentions = original_tweet[\"entities\"][\"user_mentions\"]\n            except KeyError:\n                continue\n\n            # Map users to distinct integer numbers.\n            graph_size = len(id_to_node)\n            original_tweet_node = id_to_node.setdefault(original_tweet_user_id, graph_size)\n\n            if listed_count_raw is None:\n                id_to_listedcount[original_tweet_user_id] = 0\n            else:\n                id_to_listedcount[original_tweet_user_id] = int(listed_count_raw)\n\n            # Update retweet graph.\n            append_retweet_graph_row(source_node)\n            append_retweet_graph_col(original_tweet_node)\n\n            # Get mentioned user ids.\n            mentioned_user_id_set = list()\n            if original_tweet_in_reply_to_user_id is not None:\n                mentioned_user_id_set.append(original_tweet_in_reply_to_user_id)\n\n                id_to_name[original_tweet_in_reply_to_user_id] = original_tweet_in_reply_to_screen_name\n            for user_mention in original_tweet_entities_user_mentions:\n                mentioned_user_id = user_mention[\"id\"]  # TODO: Perhaps safe extract as well.\n                mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = user_mention[\"screen_name\"]  # TODO: Perhaps safe extract as well.\n\n            # We remove duplicates.\n            mentioned_user_id_set = set(mentioned_user_id_set)\n\n            # Get mentioned user ids.\n            retweet_mentioned_user_id_set = list()\n            if original_tweet_in_reply_to_user_id is not None:\n                retweet_mentioned_user_id_set.append(original_tweet_in_reply_to_user_id)\n\n                id_to_name[original_tweet_in_reply_to_user_id] = original_tweet_in_reply_to_screen_name\n            for user_mention in original_tweet_entities_user_mentions:\n                mentioned_user_id = user_mention[\"id\"]  # TODO: Perhaps safe extract as well.\n                retweet_mentioned_user_id_set.append(mentioned_user_id)\n\n                id_to_name[mentioned_user_id] = user_mention[\"screen_name\"]  # TODO: Perhaps safe extract as well.\n\n            # We remove duplicates.\n            retweet_mentioned_user_id_set = set(retweet_mentioned_user_id_set)\n\n            mentioned_user_id_set.update(retweet_mentioned_user_id_set)\n\n            # Update the mention graph one-by-one.\n            for mentioned_user_id in mentioned_user_id_set:\n                # Map users to distinct integer numbers.\n                graph_size = len(id_to_node)\n                mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                append_user_id(mentioned_user_id)\n\n                # Add values to the sparse matrix arrays.\n                append_mention_graph_row(source_node)\n                append_mention_graph_col(mention_target_node)\n\n            # This is the first time we deal with this tweet.\n            if original_tweet_id not in tweet_id_set:\n                # Update sets, lists and dictionaries.\n                add_tweet_id(original_tweet_id)\n                id_to_name[original_tweet_user_id] = original_tweet_user_screen_name\n                id_to_username[original_tweet_user_id] = original_tweet_user_name\n                append_user_id(original_tweet_user_id)\n\n                ########################################################################################################\n                # Update mention matrix.\n                ########################################################################################################\n                # Update the mention graph one-by-one.\n                for mentioned_user_id in retweet_mentioned_user_id_set:\n                    # Map users to distinct integer numbers.\n                    graph_size = len(id_to_node)\n                    mention_target_node = id_to_node.setdefault(mentioned_user_id, graph_size)\n\n                    append_user_id(mentioned_user_id)\n\n                    # Add values to the sparse matrix arrays.\n                    append_mention_graph_row(original_tweet_node)\n                    append_mention_graph_col(mention_target_node)\n            else:\n                pass\n\n    ####################################################################################################################\n    # Final steps of preprocessing tweets.\n    ####################################################################################################################\n    # Discard any duplicates.\n    user_id_set = set(user_id_set)\n    number_of_users = len(user_id_set)\n    # min_number_of_users = max(user_id_set) + 1\n\n    # Form mention graph adjacency matrix.\n    mention_graph_row = np.array(mention_graph_row, dtype=np.int64)\n    mention_graph_col = np.array(mention_graph_col, dtype=np.int64)\n    mention_graph_data = np.ones_like(mention_graph_row, dtype=np.float64)\n\n    mention_graph = spsp.coo_matrix((mention_graph_data, (mention_graph_row, mention_graph_col)),\n                                    shape=(number_of_users, number_of_users))\n    mention_graph = spsp.coo_matrix(spsp.csr_matrix(mention_graph))\n\n    # Form retweet graph adjacency matrix.\n    retweet_graph_row = np.array(retweet_graph_row, dtype=np.int64)\n    retweet_graph_col = np.array(retweet_graph_col, dtype=np.int64)\n    retweet_graph_data = np.ones_like(retweet_graph_row, dtype=np.float64)\n\n    retweet_graph = spsp.coo_matrix((retweet_graph_data, (retweet_graph_row, retweet_graph_col)),\n                                    shape=(number_of_users, number_of_users))\n    retweet_graph = spsp.coo_matrix(spsp.csr_matrix(retweet_graph))\n\n    node_to_id = dict(zip(id_to_node.values(), id_to_node.keys()))\n\n    return mention_graph, retweet_graph, tweet_id_set, user_id_set, node_to_id, id_to_name, id_to_username, id_to_listedcount"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts the largest connected component from a graph. Inputs: - graph: An adjacency matrix in scipy sparse matrix format. - connectivity_type: A string that can be either: \"strong\" or \"weak\". - node_to_id: A map from graph node id to Twitter id, in python dictionary format. Outputs: - largest_connected_component: An adjacency matrix in scipy sparse matrix format. - new_node_to_id: A map from graph node id to Twitter id, in python dictionary format. - old_node_list: List of nodes from the possibly disconnected original graph. Raises: - RuntimeError: If there the input graph is empty.", "response": "def extract_connected_components(graph, connectivity_type, node_to_id):\n    \"\"\"\n    Extract the largest connected component from a graph.\n\n    Inputs:  - graph: An adjacency matrix in scipy sparse matrix format.\n             - connectivity_type: A string that can be either: \"strong\" or \"weak\".\n             - node_to_id: A map from graph node id to Twitter id, in python dictionary format.\n\n    Outputs: - largest_connected_component: An adjacency matrix in scipy sparse matrix format.\n             - new_node_to_id: A map from graph node id to Twitter id, in python dictionary format.\n             - old_node_list: List of nodes from the possibly disconnected original graph.\n\n    Raises:  - RuntimeError: If there the input graph is empty.\n    \"\"\"\n    # Get a networkx graph.\n    nx_graph = nx.from_scipy_sparse_matrix(graph, create_using=nx.DiGraph())\n\n    # Calculate all connected components in graph.\n    if connectivity_type == \"weak\":\n        largest_connected_component_list = nxalgcom.weakly_connected_component_subgraphs(nx_graph)\n    elif connectivity_type == \"strong\":\n        largest_connected_component_list = nxalgcom.strongly_connected_component_subgraphs(nx_graph)\n    else:\n        print(\"Invalid connectivity type input.\")\n        raise RuntimeError\n\n    # Handle empty graph.\n    try:\n        largest_connected_component = max(largest_connected_component_list, key=len)\n    except ValueError:\n        print(\"Error: Empty graph.\")\n        raise RuntimeError\n\n    old_node_list = largest_connected_component.nodes()\n    node_to_node = dict(zip(np.arange(len(old_node_list)), old_node_list))\n    largest_connected_component = nx.to_scipy_sparse_matrix(largest_connected_component, dtype=np.float64, format=\"csr\")\n\n    # Make node_to_id.\n    new_node_to_id = {k: node_to_id[v] for k, v in node_to_node.items()}\n\n    return largest_connected_component, new_node_to_id, old_node_list"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef sendEmail(self, subject, body, toAddress=False):\n\n        if not toAddress:\n            toAddress = self.toAddress\n        toAddress = toAddress.split(';')\n\n        message = MIMEText(body)\n        message['Subject'] = subject\n        message['From'] = self.fromAddress\n        message['To'] = ','.join(toAddress)\n\n        if not self.testing:\n            s = SMTP(self.server, self.port)\n\n            s.sendmail(self.fromAddress, toAddress, message.as_string())\n            s.quit()\n\n            print('email sent')\n        else:\n            print('***Begin Test Email Message***')\n            print(message)\n            print('***End Test Email Message***')", "response": "Sends an email using the agrcpythonemailer@gmail. com account"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _bind_key(self, key, func):\r\n        if not callable(func):\r\n            print u\"Trying to bind non method to keystroke:%s,%s\"%(key,func)\r\n            raise ReadlineError(u\"Trying to bind non method to keystroke:%s,%s,%s,%s\"%(key,func,type(func),type(self._bind_key)))\r\n        keyinfo = make_KeyPress_from_keydescr(key.lower()).tuple()\r\n        log(u\">>>%s -> %s<<<\"%(keyinfo,func.__name__))\r\n        self.key_dispatch[keyinfo] = func", "response": "bind a function to a key"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of possible completions for the string ending at the point. Also set begidx and endidx in the process.", "response": "def _get_completions(self):\r\n        \"\"\"Return a list of possible completions for the string ending at the point.\r\n        Also set begidx and endidx in the process.\"\"\"\r\n        completions = []\r\n        self.begidx = self.l_buffer.point\r\n        self.endidx = self.l_buffer.point\r\n        buf=self.l_buffer.line_buffer\r\n        if self.completer:\r\n            # get the string to complete\r\n            while self.begidx > 0:\r\n                self.begidx -= 1\r\n                if buf[self.begidx] in self.completer_delims:\r\n                    self.begidx += 1\r\n                    break\r\n            text = ensure_str(u''.join(buf[self.begidx:self.endidx]))\r\n            log(u'complete text=\"%s\"' % ensure_unicode(text))\r\n            i = 0\r\n            while 1:\r\n                try:\r\n                    r = ensure_unicode(self.completer(text, i))\r\n                except IndexError:\r\n                    break\r\n                i += 1\r\n                if r is None:\r\n                    break\r\n                elif r and r not in completions:\r\n                    completions.append(r)\r\n                else:\r\n                    pass\r\n            log(u'text completions=<%s>' % map(ensure_unicode, completions))\r\n        if (self.complete_filesystem == \"on\") and not completions:\r\n            # get the filename to complete\r\n            while self.begidx > 0:\r\n                self.begidx -= 1\r\n                if buf[self.begidx] in u' \\t\\n':\r\n                    self.begidx += 1\r\n                    break\r\n            text = ensure_str(u''.join(buf[self.begidx:self.endidx]))\r\n            log(u'file complete text=\"%s\"' % ensure_unicode(text))\r\n            completions = map(ensure_unicode, glob.glob(os.path.expanduser(text) + '*'))\r\n            if self.mark_directories == u'on':\r\n                mc = []\r\n                for f in completions:\r\n                    if os.path.isdir(f):\r\n                        mc.append(f + os.sep)\r\n                    else:\r\n                        mc.append(f)\r\n                completions = mc\r\n            log(u'fnames=<%s>' % map(ensure_unicode, completions))\r\n        return completions"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef complete(self, e): # (TAB)\r\n        completions = self._get_completions()\r\n        if completions:\r\n            cprefix = commonprefix(completions)\r\n            if len(cprefix) > 0:\r\n                rep = [ c for c in cprefix ]\r\n                point=self.l_buffer.point\r\n                self.l_buffer[self.begidx:self.endidx] = rep\r\n                self.l_buffer.point = point + len(rep) - (self.endidx - self.begidx)\r\n            if len(completions) > 1:\r\n                if self.show_all_if_ambiguous == u'on':\r\n                    self._display_completions(completions)\r\n                else:\r\n                    self._bell()\r\n        else:\r\n            self._bell()\r\n        self.finalize()", "response": "This method is called by the user when a new entry is added to the list of completions."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef possible_completions(self, e): # (M-?)\r\n        completions = self._get_completions()\r\n        self._display_completions(completions)\r\n        self.finalize()", "response": "List the possible completions of the text before point."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts all possible completions of the text before point that would have been generated by possible - completions.", "response": "def insert_completions(self, e): # (M-*)\r\n        u\"\"\"Insert all completions of the text before point that would have\r\n        been generated by possible-completions.\"\"\"\r\n        completions = self._get_completions()\r\n        b = self.begidx\r\n        e = self.endidx\r\n        for comp in completions:\r\n            rep = [ c for c in comp ]\r\n            rep.append(' ')\r\n            self.l_buffer[b:e] = rep\r\n            b += len(rep)\r\n            e = b\r\n        self.line_cursor = b    \r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef insert_text(self, string):\r\n        self.l_buffer.insert_text(string, self.argument_reset)\r\n        self.finalize()", "response": "Insert text into the command line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmove forward a character.", "response": "def forward_char(self, e): # (C-f)\r\n        u\"\"\"Move forward a character. \"\"\"\r\n        self.l_buffer.forward_char(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef backward_char(self, e): # (C-b)\r\n        self.l_buffer.backward_char(self.argument_reset)\r\n        self.finalize()", "response": "u\"\"\"Move back a character."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef forward_word(self, e): # (M-f)\r\n        self.l_buffer.forward_word(self.argument_reset)\r\n        self.finalize()", "response": "Move forward to the end of the next word."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving backward word in the current or previous word.", "response": "def backward_word(self, e): # (M-b)\r\n        u\"\"\"Move back to the start of the current or previous word. Words are\r\n        composed of letters and digits.\"\"\"\r\n        self.l_buffer.backward_word(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove forward to the end of the next word.", "response": "def forward_word_end(self, e): # ()\r\n        u\"\"\"Move forward to the end of the next word. Words are composed of\r\n        letters and digits.\"\"\"\r\n        self.l_buffer.forward_word_end(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving forward to the end of the next word.", "response": "def backward_word_end(self, e): # ()\r\n        u\"\"\"Move forward to the end of the next word. Words are composed of\r\n        letters and digits.\"\"\"\r\n        self.l_buffer.backward_word_end(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef forward_char_extend_selection(self, e): # \r\n        self.l_buffer.forward_char_extend_selection(self.argument_reset)\r\n        self.finalize()", "response": "Move forward a character to the end of the current character."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef backward_char_extend_selection(self, e): #\r\n        self.l_buffer.backward_char_extend_selection(self.argument_reset)\r\n        self.finalize()", "response": "Move back a character."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef forward_word_extend_selection(self, e): # \r\n        self.l_buffer.forward_word_extend_selection(self.argument_reset)\r\n        self.finalize()", "response": "Move forward to the end of the next word."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backward_word_extend_selection(self, e): # \r\n        self.l_buffer.backward_word_extend_selection(self.argument_reset)\r\n        self.finalize()", "response": "Move backward to the start of the current or previous word. Words are composed of letters and digits."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmoves forward to the end of the next word.", "response": "def forward_word_end_extend_selection(self, e): # \r\n        u\"\"\"Move forward to the end of the next word. Words are composed of\r\n        letters and digits.\"\"\"\r\n        self.l_buffer.forward_word_end_extend_selection(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the character at point. Return EOF if no characters in the line are deleted.", "response": "def delete_char(self, e): # (C-d)\r\n        u\"\"\"Delete the character at point. If point is at the beginning of\r\n        the line, there are no characters in the line, and the last\r\n        character typed was not bound to delete-char, then return EOF.\"\"\"\r\n        self.l_buffer.delete_char(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndeleting the character behind the cursor.", "response": "def backward_delete_char(self, e): # (Rubout)\r\n        u\"\"\"Delete the character behind the cursor. A numeric argument means\r\n        to kill the characters instead of deleting them.\"\"\"\r\n        self.l_buffer.backward_delete_char(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef backward_delete_word(self, e): # (Control-Rubout)\r\n        self.l_buffer.backward_delete_word(self.argument_reset)\r\n        self.finalize()", "response": "Delete the character behind the cursor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nforward the delete word to the cursor.", "response": "def forward_delete_word(self, e): # (Control-Delete)\r\n        u\"\"\"Delete the character behind the cursor. A numeric argument means\r\n        to kill the characters instead of deleting them.\"\"\"\r\n        self.l_buffer.forward_delete_word(self.argument_reset)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a new entry into the buffer.", "response": "def self_insert(self, e): # (a, b, A, 1, !, ...)\r\n        u\"\"\"Insert yourself. \"\"\"\r\n        if e.char and ord(e.char)!=0: #don't insert null character in buffer, can happen with dead keys.\r\n            self.insert_text(e.char)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paste(self,e):\r\n        if self.enable_win32_clipboard:\r\n                txt=clipboard.get_clipboard_text_and_convert(False)\r\n                txt=txt.split(\"\\n\")[0].strip(\"\\r\").strip(\"\\n\")\r\n                log(\"paste: >%s<\"%map(ord,txt))\r\n                self.insert_text(txt)\r\n        self.finalize()", "response": "Paste windows clipboard.\r\n        Assume single line strip other lines and end of line markers and trailing spaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npastes the contents of the current page into the ipython clipboard.", "response": "def ipython_paste(self,e):\r\n        u\"\"\"Paste windows clipboard. If enable_ipython_paste_list_of_lists is \r\n        True then try to convert tabseparated data to repr of list of lists or \r\n        repr of array.\r\n        If enable_ipython_paste_for_paths==True then change \\\\ to / and spaces to \\space\"\"\"\r\n        if self.enable_win32_clipboard:\r\n                txt=clipboard.get_clipboard_text_and_convert(\r\n                                                self.enable_ipython_paste_list_of_lists)\r\n                if self.enable_ipython_paste_for_paths:\r\n                        if len(txt)<300 and (\"\\t\" not in txt) and (\"\\n\" not in txt):\r\n                                txt=txt.replace(\"\\\\\",\"/\").replace(\" \",r\"\\ \")\r\n                self.insert_text(txt)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump_functions(self, e): # ()\r\n        print\r\n        txt=\"\\n\".join(self.rl_settings_to_string())\r\n        print txt\r\n        self._print_prompt()\r\n        self.finalize()", "response": "Dump all of the functions and their key bindings to the Readline\r\n        output stream."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfit the ctmc. ctmc function with the data X and returns self. transmat self. genmat self. numstates self. toltime self. debug", "response": "def fit(self, X, y=None):\n        \"\"\"Calls the ctmc.ctmc function\n\n        Parameters\n        ----------\n        X : list of lists\n            (see ctmc function 'data')\n\n        y\n            not used, present for API consistence purpose.\n        \"\"\"\n        self.transmat, self.genmat, self.transcount, self.statetime = ctmc(\n            X, self.numstates, self.transintv, self.toltime, self.debug)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef RV_1(self):\n        return self.orbpop_long.RV * (self.orbpop_long.M2 / (self.orbpop_long.M1 + self.orbpop_long.M2))", "response": "Instantaneous RV of star 1 with respect to system center - of - mass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef RV_3(self):\n        return -self.orbpop_long.RV * (self.orbpop_long.M1 / (self.orbpop_long.M1 + self.orbpop_long.M2)) +\\\n            self.orbpop_short.RV_com2", "response": "Instantaneous RV of star 3 with respect to system center - of - mass\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dRV_2(self,dt):\n        return -self.orbpop_long.dRV(dt) * (self.orbpop_long.M1/(self.orbpop_long.M1 + self.orbpop_long.M2)) +\\\n            self.orbpop_short.dRV(dt,com=True)", "response": "Returns difference in RVs separated by time dt of star 2."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn difference in RVs separated by time dt of star 3.", "response": "def dRV_3(self,dt):\n        \"\"\"Returns difference in RVs (separated by time dt) of star 3.\n        \"\"\"\n        return -self.orbpop_long.dRV(dt) * (self.orbpop_long.M1/(self.orbpop_long.M1 + self.orbpop_long.M2)) -\\\n            self.orbpop_short.dRV(dt) * (self.orbpop_short.M1/(self.orbpop_short.M1 + self.orbpop_short.M2))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef save_hdf(self,filename,path=''):\n        self.orbpop_long.save_hdf(filename,'{}/long'.format(path))\n        self.orbpop_short.save_hdf(filename,'{}/short'.format(path))", "response": "Save to. h5 file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef Rsky(self):\n        return np.sqrt(self.position.x**2 + self.position.y**2)", "response": "Projected sky separation of stars\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef RV_com1(self):\n        return self.RV * (self.M2 / (self.M1 + self.M2))", "response": "RVs of star 1 relative to center - of - mass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef RV_com2(self):\n        return -self.RV * (self.M1 / (self.M1 + self.M2))", "response": "RVs of star 2 relative to center - of - mass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_hdf(self,filename,path=''):\n        self.dataframe.to_hdf(filename,'{}/df'.format(path))", "response": "Saves all relevant data to. h5 file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds PII model permissions to a group.", "response": "def add_pii_permissions(self, group, view_only=None):\n        \"\"\"Adds PII model permissions.\n        \"\"\"\n        pii_model_names = [m.split(\".\")[1] for m in self.pii_models]\n        if view_only:\n            permissions = Permission.objects.filter(\n                (Q(codename__startswith=\"view\") | Q(codename__startswith=\"display\")),\n                content_type__model__in=pii_model_names,\n            )\n        else:\n            permissions = Permission.objects.filter(\n                content_type__model__in=pii_model_names\n            )\n        for permission in permissions:\n            group.permissions.add(permission)\n\n        for model in self.pii_models:\n            permissions = Permission.objects.filter(\n                codename__startswith=\"view\",\n                content_type__app_label=model.split(\".\")[0],\n                content_type__model=f\"historical{model.split('.')[1]}\",\n            )\n            for permission in permissions:\n                group.permissions.add(permission)\n\n        for permission in Permission.objects.filter(\n            content_type__app_label=\"edc_registration\",\n            codename__in=[\n                \"add_registeredsubject\",\n                \"delete_registeredsubject\",\n                \"change_registeredsubject\",\n            ],\n        ):\n            group.permissions.remove(permission)\n        permission = Permission.objects.get(\n            content_type__app_label=\"edc_registration\",\n            codename=\"view_historicalregisteredsubject\",\n        )\n        group.permissions.add(permission)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict containing the connection information.", "response": "def get_connect_message(self, transport, http_version, method, url,\n                            headers):\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#connection\n        '''\n        url_obj = parse_url(url)\n        if url_obj.schema is None:\n            if transport.get_extra_info('sslcontext'):\n                scheme = 'wss'\n            else:\n                scheme = 'ws'\n        else:\n            scheme = url_obj.schema.decode()\n        self.path = ('' if url_obj.path is None\n                     else url_obj.path.decode('utf-8'))\n        query = b'' if url_obj.query is None else url_obj.query\n        self.order = 0\n        return {\n            'channel': 'websocket.connect',\n            'reply_channel': None,\n            'http_version': http_version,\n            'method': method.decode(),\n            'scheme': scheme,\n            'path': self.path,\n            'query_string': query,\n            'root_path': '',\n            'headers': headers,\n            'client': transport.get_extra_info('peername'),\n            'server': transport.get_extra_info('sockname'),\n            'order': self.order,\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_receive_message(self, data):\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#receive\n        '''\n        self.order += 1\n        message = {\n            'channel': 'websocket.receive',\n            'reply_channel': None,\n            'path': self.path,\n            'order': self.order,\n            'text': None,\n            'bytes': None,\n        }\n        if isinstance(data, str):\n            message['text'] = data\n        elif isinstance(data, bytes):\n            message['bytes'] = data\n        return message", "response": "Returns a dict with the message data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_disconnect_message(self, code: int):\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#disconnection\n        '''\n        self.order += 1\n        return {\n            'channel': 'websocket.disconnect',\n            'reply_channel': None,\n            'path': self.path,\n            'order': self.order,\n            'code': code,\n        }", "response": "Returns a dict with the message for a DISCONNECT message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_attribute_cardinality(attribute):\n    if attribute.kind == RESOURCE_ATTRIBUTE_KINDS.MEMBER:\n        card = CARDINALITY_CONSTANTS.ONE\n    elif attribute.kind == RESOURCE_ATTRIBUTE_KINDS.COLLECTION:\n        card = CARDINALITY_CONSTANTS.MANY\n    else:\n        raise ValueError('Can not determine cardinality for non-terminal '\n                         'attributes.')\n    return card", "response": "Returns the cardinality of the given resource attribute."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads a Bioquali - like graph description from a file and returns a TermSet object.", "response": "def readSIFGraph(filename):\n  p = sif_parser.Parser(filename)\n  \"\"\"\n  input: string, name of a file containing a Bioquali-like graph description\n  output: asp.TermSet, with atoms matching the contents of the input file\n  \n  Parses a Bioquali-like graph description, and returns\n  a TermSet object.\n  Written using original Bioquali\n  \"\"\"\n\n  accu = TermSet()\n  file = open(filename,'r')\n  s = file.readline()\n  while s!=\"\":\n    try: accu = p.parse(s)\n    except EOFError: break\n    s = file.readline()\n  return accu"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup(path_config=\"~/.config/scalar/config.yaml\", configuration_name=None):\n    global config\n    global client\n    global token\n    global room\n    # config file\n    path_config = Path(path_config).expanduser()\n    log.debug(\"load config {path}\".format(path = path_config))\n    if not path_config.exists():\n        log.error(\"no config {path} found\".format(path = path_config))\n        sys.exit()\n    else:\n        with open(str(path_config), \"r\") as _file:\n            config = yaml.load(_file)\n    if not configuration_name:\n        for configuration in list(config[\"configurations\"].items()):\n            if configuration[1][\"default\"]:\n                config = configuration[1]\n    else:\n        config[\"configurations\"][configuration_name]\n    # connect to homeserver and room\n    log.debug(\"Matrix username: \" + config[\"username\"])\n    log.debug(\"connect to homeserver \" + config[\"homeserver\"])\n    client = MatrixClient(config[\"homeserver\"])\n    token = client.login_with_password(username = config[\"username\"], password = config[\"passcode\"])\n    log.debug(\"connect to room \" + config[\"room_alias\"])\n    room = client.join_room(config[\"room_alias\"])", "response": "Setup the ACS A"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef worker_wrapper(worker_instance, pid_path):\n    def exit_handler(*args):\n        \"\"\"\n        Remove pid file on exit\n        \"\"\"\n        if len(args) > 0:\n            print(\"Exit py signal {signal}\".format(signal=args[0]))\n        remove(pid_path)\n\n    atexit.register(exit_handler)\n    signal.signal(signal.SIGINT, exit_handler)\n    signal.signal(signal.SIGTERM, exit_handler)\n\n    worker_instance.work()\n\n    # Remove pid file if the process can not catch signals\n    exit_handler(2)", "response": "A wrapper to start RQ worker as a new process."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the redis - collection instance.", "response": "def collection(self):\n        \"\"\"Return the redis-collection instance.\"\"\"\n        if not self.include_collections:\n            return None\n        ctx = stack.top\n        if ctx is not None:\n            if not hasattr(ctx, 'redislite_collection'):\n                ctx.redislite_collection = Collection(redis=self.connection)\n            return ctx.redislite_collection"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef queue(self):\n        if not self.include_rq:\n            return None\n        ctx = stack.top\n        if ctx is not None:\n            if not hasattr(ctx, 'redislite_queue'):\n                ctx.redislite_queue = {}\n\n                for queue_name in self.queues:\n                    ctx.redislite_queue[queue_name] = \\\n                        Queue(queue_name, connection=self.connection)\n\n            return ctx.redislite_queue", "response": "The queue property. Return rq. Queue instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntrigger new process as a RQ worker.", "response": "def start_worker(self):\n        \"\"\"Trigger new process as a RQ worker.\"\"\"\n        if not self.include_rq:\n            return None\n\n        worker = Worker(queues=self.queues,\n                        connection=self.connection)\n        worker_pid_path = current_app.config.get(\n            \"{}_WORKER_PID\".format(self.config_prefix), 'rl_worker.pid'\n        )\n\n        try:\n            worker_pid_file = open(worker_pid_path, 'r')\n            worker_pid = int(worker_pid_file.read())\n            print(\"Worker already started with PID=%d\" % worker_pid)\n            worker_pid_file.close()\n\n            return worker_pid\n\n        except (IOError, TypeError):\n            self.worker_process = Process(target=worker_wrapper, kwargs={\n                'worker_instance': worker,\n                'pid_path': worker_pid_path\n            })\n            self.worker_process.start()\n            worker_pid_file = open(worker_pid_path, 'w')\n            worker_pid_file.write(\"%d\" % self.worker_process.pid)\n            worker_pid_file.close()\n\n            print(\"Start a worker process with PID=%d\" %\n                  self.worker_process.pid)\n\n            return self.worker_process.pid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef image_get_format(f):\n    f.seek(0)\n    try:\n        img = Image.open(f)\n        t = img.format.lower()\n    except IOError:\n        t = None\n    return t", "response": "Get image format for file - object f."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if file f is image and set its correct content_type and filename extension.", "response": "def is_image(f, types=('png', 'jpeg', 'gif'), set_content_type=True):\n    \"\"\"\n    Return True if file f is image (types type) and set its correct content_type and filename extension.\n    Example:\n        if is_image(request.FILES['file']):\n            print 'File is image'\n\n        if is_image(open('/tmp/image.jpeg', 'rb')):\n            print 'File is image'\n    \"\"\"\n    assert isinstance(types, (list, tuple))\n    t = image_get_format(f)\n    if t not in [t.lower() for t in types]:\n        return False\n    if set_content_type:\n        set_uploaded_file_content_type_and_file_ext(f, t)\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuses pngquant for optimize PNG - image.", "response": "def optimize_png_file(f, o=None):\n    \"\"\"\n    Use pngquant for optimize PNG-image.\n    f - path to input image file or file-object.\n    o - path to output image file or file-object for save result.\n    NOTICE: f and o can not be of different type\n    \"\"\"\n    if isinstance(f, basestring):\n        if o is None:\n            o = f\n        else:\n            assert isinstance(o, basestring)\n        try:\n            subprocess.check_call(['pngquant', '--force', '--output', o, f])\n        except subprocess.CalledProcessError:\n            return False\n        return True\n    if not hasattr(f, 'read'):\n        raise RuntimeError\n    if o is None:\n        o = f\n    else:\n        if not hasattr(f, 'write'):\n            raise RuntimeError\n    f.seek(0)\n    try:\n        p = subprocess.Popen(['pngquant', '-'], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n        r = p.communicate(f.read())[0]\n    except IOError:\n        r = None\n    if r:\n        truncate_file(o)\n        o.write(r)\n        return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response(data={}, status=200, message='OK'):\n    response_data = {\n        'data': data,\n        'status': status,\n        'message': message,\n    }\n    content = json.dumps(response_data, ensure_ascii=False,\n                               cls=DjangoJSONEncoder)\n    return HttpResponse(content, status=status, content_type='application/json')", "response": "Returns a HttpResponse object with the HTTP status set to status 200 and message set to message."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef upgrade_many(upgrade=True, create_examples_all=True):\n    urls = set()\n\n    def inst(url):\n        print('upgrading %s' % url)\n        assert url not in urls\n        urls.add(url)\n        try:\n            lib = install_lib(url, upgrade)\n            print(' -> %s' % lib)\n        except Exception as e:\n            print(e)\n\n    ############################\n    # github.com\n    ############################\n    inst('https://github.com/sensorium/Mozzi/zipball/master')\n    inst('https://github.com/madsci1016/Arduino-EasyTransfer/zipball/master')\n    inst('https://github.com/sparkfun/SevSeg/zipball/master')\n    inst(\n        'https://github.com/madsci1016/Arduino-SoftEasyTransfer/zipball/master')\n    inst('https://github.com/madsci1016/Arduino-PS2X/zipball/master')\n# inst('http://github.com/wimleers/flexitimer2/zipball/v1.0')# can't install\n    inst('https://github.com/kerinin/arduino-splines/zipball/master')\n    inst('https://github.com/asynclabs/WiShield/zipball/master')\n    inst('https://github.com/asynclabs/dataflash/zipball/master')\n    inst('https://github.com/slugmobile/AtTouch/zipball/master')\n    inst(\n        'https://github.com/carlynorama/Arduino-Library-Button/zipball/master')\n    inst(\n        'https://github.com/carlynorama/Arduino-Library-FancyLED/zipball/master')\n    inst('https://github.com/markfickett/arduinomorse/zipball/master')\n    inst('https://github.com/rocketscream/Low-Power/zipball/master')\n    inst(\n        'https://github.com/arduino-libraries/CapacitiveSensor/zipball/master')\n\n    ############################\n    # arduiniana.org\n    ############################\n    # TODO: how to get latest version??\n    inst('http://arduiniana.org/PString/PString2.zip')\n    inst('http://arduiniana.org/Flash/Flash3.zip')\n    inst('http://arduiniana.org/NewSoftSerial/NewSoftSerial10c.zip')\n    inst('http://arduiniana.org/Streaming/Streaming4.zip')\n    inst('http://arduiniana.org/PWMServo/PWMServo.zip')\n    inst('http://arduiniana.org/TinyGPS/TinyGPS10.zip')\n\n    ############################\n    # google\n    ############################\n    # TODO: how to get latest version??\n    # parse http://code.google.com/p/arduino-pinchangeint/downloads/list\n\n    # simplified version in core\n    inst('http://rogue-code.googlecode.com/files/Arduino-Library-Tone.zip')\n\n    inst('http://arduino-playground.googlecode.com/files/LedDisplay03.zip')\n    inst('http://sserial2mobile.googlecode.com/files/SSerial2Mobile-1.1.0.zip')\n    inst('http://webduino.googlecode.com/files/webduino-1.4.1.zip')\n    inst('http://arduino-pid-library.googlecode.com/files/PID_v1.0.1.zip')\n    inst('http://ideoarduinolibraries.googlecode.com/files/Qtouch1Wire.zip')\n    inst('http://arduino-timerone.googlecode.com/files/TimerOne-v8.zip')\n    inst('http://arduinounit.googlecode.com/files/arduinounit-1.4.2.zip')\n    inst('http://arduinode.googlecode.com/files/arduinode_0.1.zip')\n    inst('http://arduino-edb.googlecode.com/files/EDB_r7.zip')\n    inst('http://arduino-dblib.googlecode.com/files/DB.zip')\n    inst(\n        'http://morse-endecoder.googlecode.com/files/Morse_EnDecoder_2010.12.06.tar.gz')\n    inst('http://arduino-pinchangeint.googlecode.com/files/PinChangeInt.zip')\n    inst('http://arduino-tvout.googlecode.com/files/TVout_R5.91.zip')\n    inst('http://narcoleptic.googlecode.com/files/Narcoleptic_v1a.zip')\n\n    ############################\n    # teensy\n    ############################\n    inst('http://www.pjrc.com/teensy/arduino_libraries/OneWire.zip')\n    inst('http://www.pjrc.com/teensy/arduino_libraries/VirtualWire.zip')\n    inst('http://www.pjrc.com/teensy/arduino_libraries/FrequencyTimer2.zip')\n    inst('http://www.pjrc.com/teensy/arduino_libraries/FreqCount.zip')\n    inst('http://www.pjrc.com/teensy/arduino_libraries/FreqMeasure.zip')\n\n    ############################\n    # others\n    ############################\n\n# too big\n#    inst('http://www.state-machine.com/arduino/qp_arduino.zip')\n\n# The owner of this website (download.milesburton.com) has banned your access based on your browser's signature\n#     inst('http://download.milesburton.com/Arduino/MaximTemperature/DallasTemperature_370Beta.zip')\n\n    inst('http://www.shikadi.net/files/arduino/SerialIP-1.0.zip')\n    inst(\n        'http://siggiorn.com/wp-content/uploads/libraries/ArduinoByteBuffer.zip')\n    inst(\n        'http://siggiorn.com/wp-content/uploads/libraries/ArduinoSerialManager.zip')\n    inst('http://arduino-tweet.appspot.com/Library-Twitter-1.2.2.zip')\n\n# can't install\n# inst('http://gkaindl.com/php/download.php?key=ArduinoEthernet')\n\n    inst(\n        'http://sebastian.setz.name/wp-content/uploads/2011/01/multiCameraIrControl_1-5.zip')\n    inst('http://alexandre.quessy.net/static/avr/Tween_01.zip')\n    inst(\n        'http://www.lpelettronica.it/images/stories/LPM11162_images/Arduino/LPM11162_ArduinoLib_v1.zip')\n    # inst('http://nootropicdesign.com/hackvision/downloads/Controllers.zip')\n    inst(\n        'http://interface.khm.de/wp-content/uploads/2009/01/FreqCounter_1_12.zip')\n    inst(\n        'http://interface.khm.de/wp-content/uploads/2010/06/FreqPeriod_1_12.zip')\n\n    ############################\n    # arduino.cc\n    ############################\n    inst('http://arduino.cc/playground/uploads/Main/PS2Keyboard002.zip')\n    inst('http://arduino.cc/playground/uploads/Code/Metro.zip')\n    inst('http://www.arduino.cc/playground/uploads/Main/MsTimer2.zip')\n\n# can't install\n# inst('http://www.arduino.cc/playground/uploads/Code/Time.zip')\n\n    inst('http://arduino.cc/playground/uploads/Main/LedControl.zip')\n\n# can't install\n# inst('http://www.arduino.cc/playground/uploads/Code/ks0108GLCD.zip')#\n\n    inst('http://arduino.cc/playground/uploads/Code/Bounce.zip')\n    inst('http://arduino.cc/playground/uploads/Main/CapacitiveSense003.zip')\n    inst('http://arduino.cc/playground/uploads/Main/PinChangeInt.zip')\n\n# can't install\n# inst('http://arduino.cc/playground/uploads/Code/TimerThree.zip')\n\n    inst('http://arduino.cc/playground/uploads/Code/TimedAction-1_6.zip')\n\n# can't install\n# inst('http://www.arduino.cc/playground/uploads/Code/Time.zip')\n\n    inst('http://arduino.cc/playground/uploads/Code/EventFuse.zip')\n    inst('http://arduino.cc/playground/uploads/Code/Charlieplex.zip')\n    inst('http://arduino.cc/playground/uploads/Code/DigitalToggle.zip')\n    inst('http://arduino.cc/playground/uploads/Code/Enerlib.zip')\n\n    inst('http://arduino.cc/playground/uploads/Code/AdvButton_11.zip')\n\n    # old version\n    # inst('http://arduino.cc/playground/uploads/Code/AdvButton.zip')\n\n# can't install\n# inst('http://arduino.cc/playground/uploads/Code/SerialDebugger.zip') #\n\n    inst('http://arduino.cc/playground/uploads/Code/MatrixMath.zip')\n    inst('http://arduino.cc/playground/uploads/Code/StackArray.zip')\n    inst('http://arduino.cc/playground/uploads/Code/StackList.zip')\n    inst('http://arduino.cc/playground/uploads/Code/QueueArray.zip')\n    inst('http://arduino.cc/playground/uploads/Code/QueueList.zip')\n    inst('http://arduino.cc/playground/uploads/Code/Ping-1_3.zip')\n    inst('http://www.arduino.cc/playground/uploads/Code/LED.zip')\n\n#    inst('')\n\n    if create_examples_all:\n        print('create \"all\" menu item')\n        exampallcreate.create_examples_all()\n    print('install finished')", "response": "upgrade many libs.\n\n    source: http://arduino.cc/playground/Main/LibraryList\n\n    you can set your arduino path if it is not default\n    os.environ['ARDUINO_HOME'] = '/home/...'"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nflags the batch as confirmed by updating confirmation_datetime on the history model for this batch.", "response": "def confirm(self, batch_id=None, filename=None):\n        \"\"\"Flags the batch as confirmed by updating\n        confirmation_datetime on the history model for this batch.\n        \"\"\"\n        if batch_id or filename:\n            export_history = self.history_model.objects.using(self.using).filter(\n                Q(batch_id=batch_id) | Q(filename=filename),\n                sent=True,\n                confirmation_code__isnull=True,\n            )\n        else:\n            export_history = self.history_model.objects.using(self.using).filter(\n                sent=True, confirmation_code__isnull=True\n            )\n        if export_history.count() == 0:\n            raise ConfirmationError(\n                \"Nothing to do. No history of sent and unconfirmed files\"\n            )\n        else:\n            confirmation_code = ConfirmationCode()\n            export_history.update(\n                confirmation_code=confirmation_code.identifier,\n                confirmation_datetime=get_utcnow(),\n            )\n        return confirmation_code.identifier"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming stemming or lemmatizing on a single word. If we are to search for a word in a clean bag-of-words, we need to search it after the same kind of preprocessing. Inputs: - word: A string containing the source word. - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\". Output: - lemma: The resulting clean lemma or stem.", "response": "def clean_single_word(word, lemmatizing=\"wordnet\"):\n    \"\"\"\n    Performs stemming or lemmatizing on a single word.\n\n    If we are to search for a word in a clean bag-of-words, we need to search it after the same kind of preprocessing.\n\n    Inputs: - word: A string containing the source word.\n            - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\".\n\n    Output: - lemma: The resulting clean lemma or stem.\n    \"\"\"\n    if lemmatizing == \"porter\":\n        porter = PorterStemmer()\n        lemma = porter.stem(word)\n    elif lemmatizing == \"snowball\":\n        snowball = SnowballStemmer('english')\n        lemma = snowball.stem(word)\n    elif lemmatizing == \"wordnet\":\n        wordnet = WordNetLemmatizer()\n        lemma = wordnet.lemmatize(word)\n    else:\n        print(\"Invalid lemmatizer argument.\")\n        raise RuntimeError\n\n    return lemma"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nextracts a clean bag-of-words from a document. Inputs: - document: A string containing some text. Output: - lemma_list: A python list of lemmas or stems. - lemma_to_keywordbag: A python dictionary that maps stems/lemmas to original topic keywords.", "response": "def clean_document(document,\n                   sent_tokenize, _treebank_word_tokenize,\n                   tagger,\n                   lemmatizer,\n                   lemmatize,\n                   stopset,\n                   first_cap_re, all_cap_re,\n                   digits_punctuation_whitespace_re,\n                   pos_set):\n    \"\"\"\n    Extracts a clean bag-of-words from a document.\n\n    Inputs: - document: A string containing some text.\n\n    Output: - lemma_list: A python list of lemmas or stems.\n            - lemma_to_keywordbag: A python dictionary that maps stems/lemmas to original topic keywords.\n    \"\"\"\n    ####################################################################################################################\n    # Tokenizing text\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    try:\n        tokenized_document = fast_word_tokenize(document, sent_tokenize, _treebank_word_tokenize)\n    except LookupError:\n        print(\"Warning: Could not tokenize document. If these warnings are commonplace, there is a problem with the nltk resources.\")\n        lemma_list = list()\n        lemma_to_keywordbag = defaultdict(lambda: defaultdict(int))\n        return lemma_list, lemma_to_keywordbag\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"Tokenize\", elapsed_time)\n\n    ####################################################################################################################\n    # Separate [\"camelCase\"] into [\"camel\", \"case\"] and make every letter lower case\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    tokenized_document = [separate_camel_case(token, first_cap_re, all_cap_re).lower() for token in tokenized_document]\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"camelCase\", elapsed_time)\n\n    ####################################################################################################################\n    # Parts of speech tagger\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    tokenized_document = tagger.tag(tokenized_document)\n    tokenized_document = [token[0] for token in tokenized_document if (token[1] in pos_set)]\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"POS\", elapsed_time)\n\n    ####################################################################################################################\n    # Removing digits, punctuation and whitespace\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    tokenized_document_no_punctuation = list()\n    append_token = tokenized_document_no_punctuation.append\n    for token in tokenized_document:\n        new_token = remove_digits_punctuation_whitespace(token, digits_punctuation_whitespace_re)\n        if not new_token == u'':\n            append_token(new_token)\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"digits etc\", elapsed_time)\n\n    ####################################################################################################################\n    # Removing stopwords\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    tokenized_document_no_stopwords = list()\n    append_word = tokenized_document_no_stopwords.append\n    for word in tokenized_document_no_punctuation:\n        if word not in stopset:\n            append_word(word)\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"stopwords 1\", elapsed_time)\n\n    ####################################################################################################################\n    # Stemming and Lemmatizing\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    lemma_to_keywordbag = defaultdict(lambda: defaultdict(int))\n\n    final_doc = list()\n    append_lemma = final_doc.append\n    for word in tokenized_document_no_stopwords:\n        lemma = lemmatize(word)\n        append_lemma(lemma)\n        lemma_to_keywordbag[lemma][word] += 1\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"lemmatize\", elapsed_time)\n\n    ####################################################################################################################\n    # One more stopword removal\n    ####################################################################################################################\n    # start_time = time.perf_counter()\n    lemma_list = list()\n    append_word = lemma_list.append\n    for word in final_doc:\n        if word not in stopset:\n            append_word(word)\n    # elapsed_time = time.perf_counter() - start_time\n    # print(\"stopwords 2\", elapsed_time)\n\n    return lemma_list, lemma_to_keywordbag"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean_corpus_serial(corpus, lemmatizing=\"wordnet\"):\n    list_of_bags_of_words = list()\n    append_bag_of_words = list_of_bags_of_words.append\n\n    lemma_to_keywordbag_total = defaultdict(lambda: defaultdict(int))\n\n    for document in corpus:\n        word_list, lemma_to_keywordbag = clean_document(document=document, lemmatizing=lemmatizing)  # TODO: Alter this.\n        bag_of_words = combine_word_list(word_list)\n        append_bag_of_words(bag_of_words)\n\n        for lemma, keywordbag in lemma_to_keywordbag.items():\n            for keyword, multiplicity in keywordbag.items():\n                lemma_to_keywordbag_total[lemma][keyword] += multiplicity\n\n    return list_of_bags_of_words, lemma_to_keywordbag_total", "response": "This function extracts a bag - of - words from each document in a corpus and returns a list of python dictionaries that maps each lemma to original topic keywords."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef middleware(func):\r\n    @wraps(func)\r\n    def parse(*args, **kwargs):\r\n        \"\"\" get middleware from route, execute middleware in order \"\"\"\r\n        middleware = copy.deepcopy(kwargs['middleware'])\r\n        kwargs.pop('middleware')\r\n        if request.method == \"OPTIONS\":\r\n            # return 200 json response for CORS\r\n            return JsonResponse(200)\r\n        if middleware is None:\r\n            return func(*args, **kwargs)\r\n        for mware in middleware:\r\n            ware = mware()\r\n            if ware.status is False:\r\n                return ware.response\r\n            return func(*args, **kwargs)\r\n    return parse", "response": "Executes routes. py route middleware"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef send(MESSAGE, SOCKET, MESSAGE_ID=None,\n         CODE_FILE=None, CODE_LINE=None, CODE_FUNC=None,\n         **kwargs):\n    r\"\"\"Send a message to the journal.\n\n    >>> journal.send('Hello world')\n    >>> journal.send('Hello, again, world', FIELD2='Greetings!')\n    >>> journal.send('Binary message', BINARY=b'\\xde\\xad\\xbe\\xef')\n\n    Value of the MESSAGE argument will be used for the MESSAGE=\n    field. MESSAGE must be a string and will be sent as UTF-8 to\n    the journal.\n\n    MESSAGE_ID can be given to uniquely identify the type of\n    message. It must be a string or a uuid.UUID object.\n\n    CODE_LINE, CODE_FILE, and CODE_FUNC can be specified to\n    identify the caller. Unless at least on of the three is given,\n    values are extracted from the stack frame of the caller of\n    send(). CODE_FILE and CODE_FUNC must be strings, CODE_LINE\n    must be an integer.\n\n    Additional fields for the journal entry can only be specified\n    as keyword arguments. The payload can be either a string or\n    bytes. A string will be sent as UTF-8, and bytes will be sent\n    as-is to the journal.\n\n    Other useful fields include PRIORITY, SYSLOG_FACILITY,\n    SYSLOG_IDENTIFIER, SYSLOG_PID.\n    \"\"\"\n\n    args = ['MESSAGE=' + MESSAGE]\n\n    if MESSAGE_ID is not None:\n        id = getattr(MESSAGE_ID, 'hex', MESSAGE_ID)\n        args.append('MESSAGE_ID=' + id)\n\n    if CODE_LINE == CODE_FILE == CODE_FUNC == None:\n        CODE_FILE, CODE_LINE, CODE_FUNC = \\\n            _traceback.extract_stack(limit=2)[0][:3]\n    if CODE_FILE is not None:\n        args.append('CODE_FILE=' + CODE_FILE)\n    if CODE_LINE is not None:\n        args.append('CODE_LINE={:d}'.format(CODE_LINE))\n    if CODE_FUNC is not None:\n        args.append('CODE_FUNC=' + CODE_FUNC)\n\n    args.extend(_make_line(key.upper(), val) for key, val in kwargs.items())\n    return sendv(SOCKET, *args)", "response": "r Sends a message to the specified journal."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef exists(self):\r\n        self_object = self.query.filter_by(id=self.id).first()\r\n        if self_object is None:\r\n            return False\r\n        return True", "response": "Checks if the item already exists in the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete(self):\r\n        try:\r\n            if self.exists() is False:\r\n                return None\r\n            self.db.session.delete(self)\r\n            self.db.session.commit()\r\n        except (Exception, BaseException) as error:\r\n            # fail silently\r\n            return None", "response": "Delete the object from the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef row_to_dict(self, row):\n        constellation = self.parse_constellation(row[0])\n        name = self.parse_name(row[1])\n        ra, dec = self.parse_coordinates(row[2])\n        variable_type = row[3].strip()\n        max_magnitude, symbol = self.parse_magnitude(row[4])\n        min_magnitude, symbol = self.parse_magnitude(row[5])\n        if symbol == '(' and max_magnitude is not None:\n            # this is actually amplitude\n            min_magnitude = max_magnitude + min_magnitude\n        epoch = self.parse_epoch(row[8])\n        period = self.parse_period(row[10])\n        return {\n            'constellation': constellation,\n            'name': name,\n            'ra': ra,\n            'dec': dec,\n            'variable_type': variable_type,\n            'max_magnitude': max_magnitude,\n            'min_magnitude': min_magnitude,\n            'epoch': epoch,\n            'period': period,\n        }", "response": "Converts a raw GCVS record to a dictionary of star data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_coordinates(self, coords_str):\n        if coords_str.strip() == '':\n            return (None, None)\n        ra = '%s:%s:%s' % (coords_str[0:2], coords_str[2:4], coords_str[4:8])\n        dec = '%s:%s:%s' % (coords_str[8:11], coords_str[11:13], coords_str[13:15])\n        return (ra, dec)", "response": "Parses a string containing the RA and Dec coordinates in the GCVS file."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a magnitude field into a tuple of magnitude and symbol.", "response": "def parse_magnitude(self, magnitude_str):\n        \"\"\"\n        Converts magnitude field to a float value, or ``None`` if GCVS does\n        not list the magnitude.\n\n        Returns a tuple (magnitude, symbol), where symbol can be either an\n        empty string or a single character - one of '<', '>', '('.\n        \"\"\"\n        symbol = magnitude_str[0].strip()\n        magnitude = magnitude_str[1:6].strip()\n        return float(magnitude) if magnitude else None, symbol"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts an epoch field to a float value", "response": "def parse_epoch(self, epoch_str):\n        \"\"\"\n        Converts epoch field to a float value (adding 24... prefix), or\n        ``None`` if there is no epoch in GCVS record.\n        \"\"\"\n        epoch = epoch_str.translate(TRANSLATION_MAP)[:10].strip()\n        return 2400000.0 + float(epoch) if epoch else None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting period field to a float value or None.", "response": "def parse_period(self, period_str):\n        \"\"\"\n        Converts period field to a float value or ``None`` if there is\n        no period in GCVS record.\n        \"\"\"\n        period = period_str.translate(TRANSLATION_MAP)[3:14].strip()\n        return float(period) if period else None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_hwpack_dir(root):\n    root = path(root)\n    log.debug('files in dir: %s', root)\n    for x in root.walkfiles():\n        log.debug('  %s', x)\n\n    hwpack_dir = None\n    for h in (root.walkfiles('boards.txt')):\n        assert not hwpack_dir\n        hwpack_dir = h.parent\n        log.debug('found hwpack: %s', hwpack_dir)\n\n    assert hwpack_dir\n    return hwpack_dir", "response": "search for hwpack dir under root."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninstalling hwpackrary from web or local files system.", "response": "def install_hwpack(url, replace_existing=False):\n    \"\"\"install hwpackrary from web or local files system.\n\n    :param url: web address or file path\n    :param replace_existing: bool\n    :rtype: None\n\n    \"\"\"\n    d = tmpdir(tmpdir())\n    f = download(url)\n    Archive(f).extractall(d)\n\n    clean_dir(d)\n    src_dhwpack = find_hwpack_dir(d)\n\n    targ_dhwpack = hwpack_dir() / src_dhwpack.name\n    doaction = 0\n    if targ_dhwpack.exists():\n        log.debug('hwpack already exists: %s', targ_dhwpack)\n        if replace_existing:\n            log.debug('remove %s', targ_dhwpack)\n            targ_dhwpack.rmtree()\n            doaction = 1\n    else:\n        doaction = 1\n\n    if doaction:\n        log.debug('move %s -> %s', src_dhwpack, targ_dhwpack)\n        src_dhwpack.move(targ_dhwpack)\n\n        hwpack_dir().copymode(targ_dhwpack)\n        for x in targ_dhwpack.walk():\n            hwpack_dir().copymode(x)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create(self, volume_id, vtype, size, affinity):\n        volume_id = volume_id or str(uuid.uuid4())\n        params = {'volume_type_name': vtype,\n                  'size': size,\n                  'affinity': affinity}\n        return self.http_put('/volumes/%s' % volume_id,\n                             params=self.unused(params))", "response": "create a new entry in the cache"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrestore a volume from a backup", "response": "def restore(self, volume_id, **kwargs):\n        \"\"\"\n        restore a volume from a backup\n        \"\"\"\n        # These arguments are required\n        self.required('create', kwargs, ['backup', 'size'])\n        # Optional Arguments\n        volume_id = volume_id or str(uuid.uuid4())\n        kwargs['volume_type_name'] = kwargs['volume_type_name'] or 'vtype'\n        kwargs['size'] = kwargs['size'] or 1\n        # Make the request\n        return self.http_put('/volumes/%s' % volume_id,\n                             params=self.unused(kwargs))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create(self, name, **kwargs):\n        # These arguments are required\n        self.required('create', kwargs, ['hostname', 'port',\n                      'storage_hostname', 'volume_type_name', 'size'])\n        kwargs['name'] = name\n        return self.http_post('/nodes', params=kwargs)", "response": "Create a new node in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a node s metadata", "response": "def update(self, name, **kwargs):\n        \"\"\"\n        Create a new node\n        \"\"\"\n        # These arguments are allowed\n        self.allowed('update', kwargs, ['hostname', 'port', 'status',\n                     'storage_hostname', 'volume_type_name', 'size'])\n        # Remove parameters that are None\n        kwargs = self.unused(kwargs)\n        return self.http_post('/nodes/%s' % name, params=kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an export for a volume", "response": "def create(self, volume_id, ip, initiator):\n        \"\"\"\n        create an export for a volume\n        \"\"\"\n        return self.http_put('/volumes/%s/export' % volume_id, params={\n                             'ip': ip,\n                             'initiator': initiator\n                             })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, volume_id, **kwargs):\n        # These arguments are allowed\n        self.allowed('update', kwargs,\n                     ['status', 'instance_id',\n                      'mountpoint', 'ip', 'initiator', 'session_ip',\n                      'session_initiator'])\n        # Remove parameters that are None\n        params = self.unused(kwargs)\n        return self.http_post('/volumes/%s/export' % volume_id, params=params)", "response": "update an exportable resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proto_refactor(proto_filename, namespace, namespace_path):\n    with open(proto_filename) as f:\n        data = f.read()\n        if not re.search('syntax = \"proto2\"', data):\n            insert_syntax = 'syntax = \"proto2\";\\n'\n            data = insert_syntax + data\n        substitution = 'import \"{}/\\\\1\";'.format(namespace_path)\n        data = re.sub('import\\s+\"([^\"]+\\.proto)\"\\s*;', substitution, data)\n        return data", "response": "This method refactors a Protobuf file to import from a namespace\nEClassifier that maps to the desired python package structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef proto_refactor_files(dest_dir, namespace, namespace_path):\n    for dn, dns, fns in os.walk(dest_dir):\n        for fn in fns:\n            fn = os.path.join(dn, fn)\n            if fnmatch.fnmatch(fn, '*.proto'):\n                data = proto_refactor(fn, namespace, namespace_path)\n                with open(fn, 'w') as f:\n                    f.write(data)", "response": "This method runs the refactoring on all the Protobuf files in the base directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clone_source_dir(source_dir, dest_dir):\n    if os.path.isdir(dest_dir):\n        print('removing', dest_dir)\n        shutil.rmtree(dest_dir)\n    shutil.copytree(source_dir, dest_dir)", "response": "Copies the source Protobuf files into a build directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef protoc_command(lang, output_dir, proto_path, refactored_dir):\n    proto_files = glob.glob(os.path.join(refactored_dir, '*.proto'))\n    cmd = ['protoc', '-I', proto_path, '--{}_out'.format(lang), output_dir]\n    cmd.extend(proto_files)\n    print(' '.join(cmd))\n    p = subprocess.Popen(\n        cmd, stdout=sys.stdout, stderr=sys.stderr, stdin=sys.stdin,\n        cwd=proto_path)\n    p.communicate()", "response": "Runs the protoc command on the refactored Protobuf files to generate\n    the source python files for the current language."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure(self, config):\n\n        specification = config.get(\n            'ckan.budgets.specification',\n            os.path.join(os.path.dirname(__file__),\n                         'data', 'bdp', 'schema.json'))\n        self.data = BudgetDataPackage(specification)\n\n        countries_json = config.get(\n            'ckan.budgets.countries',\n            os.path.join(os.path.dirname(__file__),\n                         'data', 'countries.json'))\n        with open(countries_json) as country_list:\n            self.countries = json.load(country_list)\n\n        country = config.get('ckan.budgets.default.country', None)\n        if country is not None:\n            self.default_country = country.upper()\n            if self.default_country not in self.countries:\n                raise ValueError('Uknown country code \"{code}\"'.format(\n                    code=country))\n        else:\n            self.default_currency = None\n\n        currencies_json = config.get(\n            'ckan.budget.currencies',\n            os.path.join(os.path.dirname(__file__),\n                         'data', 'currencies.json'))\n        with open(currencies_json) as currency_list:\n            self.currencies = json.load(currency_list)\n\n        currency = config.get('ckan.budgets.default.currency', None)\n        if currency is not None:\n            self.default_currency = currency.upper()\n            if self.default_currency not in self.currencies:\n                raise ValueError('Unknown currency code \"{code}\"'.format(\n                    code=currency))\n        else:\n            self.default_currency = None\n\n        statuses_json = config.get(\n            'ckan.budget.statuses',\n            os.path.join(os.path.dirname(__file__),\n                         'data', 'bdp', 'statuses.json'))\n        with open(statuses_json) as statuses_list:\n            self.statuses = json.load(statuses_list)", "response": "Initialize the plugin. This creates a data object which holds a\n        BudgetDataPackage parser which operates based on a specification\n        which is either provided in the config via:\n        ``ckan.budgets.specification`` or the included version."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef in_resource(self, field, resource):\n        resource_field = resource.get(field, None)\n        return resource_field is not None and resource_field != ''", "response": "Return True if the resource contains a valid value for the field\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef are_budget_data_package_fields_filled_in(self, resource):\n        fields = ['country', 'currency', 'year', 'status']\n        return all([self.in_resource(f, resource) for f in fields])", "response": "Check if the budget data package fields are all filled in because\n        is not a budget data package"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating a budget data package for the resource.", "response": "def generate_budget_data_package(self, resource):\n        \"\"\"\n        Try to grab a budget data package schema from the resource.\n        The schema only allows fields which are defined in the budget\n        data package specification. If a field is found that is not in\n        the specification this will return a NotABudgetDataPackageException\n        and in that case we can just return and ignore the resource\n        \"\"\"\n\n        # Return if the budget data package fields have not been filled in\n        if not self.are_budget_data_package_fields_filled_in(resource):\n            return\n\n        try:\n            resource['schema'] = self.data.schema\n        except exceptions.NotABudgetDataPackageException:\n            log.debug('Resource is not a Budget Data Package')\n            resource['schema'] = []\n            return\n\n        # If the schema fits, this can be exported as a budget data package\n        # so we add the missing metadata fields to the resource.\n        resource['BudgetDataPackage'] = True\n        resource['standard'] = self.data.version\n        resource['granularity'] = self.data.granularity\n        resource['type'] = self.data.budget_type"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the data for the budget data package.", "response": "def before_create(self, context, resource):\n        \"\"\"\n        When triggered the resource which can either be uploaded or linked\n        to will be parsed and analysed to see if it possibly is a budget\n        data package resource (checking if all required headers and any of\n        the recommended headers exist in the csv).\n\n        The budget data package specific fields are then appended to the\n        resource which makes it useful for export the dataset as a budget\n        data package.\n        \"\"\"\n\n        # If the resource is being uploaded we load the uploaded file\n        # If not we load the provided url\n        if resource.get('upload', '') == '':\n            self.data.load(resource['url'])\n        else:\n            self.data.load(resource['upload'].file)\n\n        self.generate_budget_data_package(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting entry by index.", "response": "def get_entry(self, entry_id):\n        \"\"\"Get mft entry by index. If entry is not already loaded it will load \\\n        it from file specified during :class:`MftTable` initialization.\n\n        Returns:\n            MftEntry: initialized :class:`~.mft_entry.MftEntry`.\n        \"\"\"\n\n        if entry_id in self._entries:\n            return self._entries[entry_id]\n        else:\n            entry_offset = entry_id * self.entry_size\n\n            # load entry\n            entry = MftEntry(\n                filename=self.filename,\n                offset=self.offset + entry_offset,\n                length=self.entry_size,\n                index=entry_id\n            )\n\n            # cache entry\n            self._entries[entry_id] = entry\n\n            return entry"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize():\r\n  \r\n  # Global 'factoids' list will be used to store factoids, fetched from a file.\r\n  global factoids\r\n  \r\n  # Path to \"factoid.txt\" file is created.\r\n  try:\r\n    current_path = os.getcwd()\r\n    file_path = os.path.join(current_path, \"modules\", \"factoids\", \"factoid.txt\")\r\n  except OSError, error:\r\n    raise seash_exceptions.InitializeError(\"Error during initializing factoids module: '\" + str(error) + \"'.\")\r\n\r\n  # We have to fatch list of factoids from \"factoid.txt\" file.\r\n  try:\r\n    file_object = open(file_path, 'r')\r\n    factoids_temp = file_object.readlines()\r\n    file_object.close()\r\n  except IOError, error:\r\n    raise seash_exceptions.InitializeError(\"Error during initializing factoids module: '\" + str(error) + \"'.\")\r\n  \r\n  # Newline characters in a list, read from a file are removed.\r\n  for factoid in factoids_temp:\r\n    factoids.append(factoid.strip('\\n'))\r\n  \r\n  # A random factoid is printed every time user runs seash.\r\n  print random.choice(factoids)+\"\\n\"", "response": "Initializes the factoids list."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprints the factoids in the seash dictionary.", "response": "def print_factoids(input_dict, environment_dict):\r\n  \"\"\"\r\n  <Purpose>\r\n    Used to print seash factoids when user uses 'show factoids'\r\n    command.\r\n    \r\n  <Arguments>\r\n    input_dict: Input dictionary generated by seash_dictionary.parse_command().\r\n    environment_dict: Dictionary describing the current seash environment.\r\n    \r\n    For more information, see command_callbacks.py's module docstring.\r\n    \r\n  <Side Effects>\r\n    Prints factoids onto the screen.\r\n    \r\n  <Exceptions>\r\n    UserError: If user does not type appropriate command.\r\n    ValueError: If user does not provide valid input (integer).\r\n    \r\n  <Return>\r\n    None\r\n  \"\"\"\r\n  \r\n  # User will insert an argument regarding how many factoids should be printed.\r\n  # We have to find what is user argument.\r\n  # User can type any positive number or he can type 'all' to see all factoids.\r\n  dict_mark = input_dict\r\n  try:\r\n    command = dict_mark.keys()[0]\r\n    while dict_mark[command]['name'] != 'args':\r\n      dict_mark = dict_mark[command]['children']\r\n      command = dict_mark.keys()[0]\r\n    args = command\r\n  except IndexError:\r\n    raise seash_exceptions.UserError(\"\\nError, Syntax of the command is: show factoids [number of factoids]/all \\n\")\r\n  \r\n  # User decided to print all factoids\r\n  if args == 'all':\r\n    print\r\n    for factoid in factoids:\r\n      print factoid\r\n    print\r\n    return\r\n  \r\n  # User can not insert other than integer number.\r\n  try:\r\n    no_of_factoids = int(args)\r\n  except ValueError:\r\n    raise seash_exceptions.UserError(\"\\nYou have to enter number only.\\n\")\r\n  \r\n  # If number of factoids decided by user is greater than total number of\r\n  # available factoids than whole factoids list is printed.\r\n  if (no_of_factoids > (len(factoids))):\r\n    print \"\\nWe have only %d factoids. Here is the list of factoids:\" % (len(factoids))\r\n    no_of_factoids = len(factoids)\r\n  elif (no_of_factoids <= 0):\r\n    raise seash_exceptions.UserError(\"\\nYou have to enter positive number only.\\n\")\r\n  \r\n  # 'factoids' list will be shuffled every time for printing random factoids.\r\n  random.shuffle(factoids)\r\n  \r\n  # Factoids will be printed.\r\n  for factoid in factoids[:no_of_factoids]:\r\n    print factoid\r\n  print"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the current language of the given key", "response": "def trans(self, key) -> str:\r\n        \"\"\"\r\n        Root Example:\r\n        Translator()\r\n        Translator.trans('messages.hello')\r\n        resources/lang/en/messages.lang will be opened\r\n        and parsed for { 'hello': 'Some english text' }\r\n        If language is fr,\r\n        resources/lang/fr/messages.lang will be opened\r\n        and parsed for { 'hello': 'Some french text' }\r\n        Module Example:\r\n        Translator('[module-name]')\r\n        Translator.trans('messages.hello')\r\n        \"\"\"\r\n\r\n        key_list = self.__list_key(key)\r\n        try:\r\n            current_selection = \\\r\n                current_app.config['LANGUAGE_PACKS'][\r\n                    self.module_name][self.app_language]\r\n        except KeyError as error:\r\n            if current_app.config['DEBUG']:\r\n                raise error\r\n            return None\r\n        for parsed_dot_key in key_list:\r\n            try:\r\n                current_selection = current_selection[parsed_dot_key]\r\n            except (Exception, BaseException) as error:\r\n                if current_app.config['DEBUG']:\r\n                    raise error\r\n                return None\r\n        return current_selection"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a translation file", "response": "def __load_file(self, key_list) -> str:\r\n        \"\"\" Load a translator file \"\"\"\r\n        file = str(key_list[0]) + self.extension\r\n        key_list.pop(0)\r\n        file_path = os.path.join(self.path, file)\r\n        if os.path.exists(file_path):\r\n            return Json.from_file(file_path)\r\n        else:\r\n            raise FileNotFoundError(file_path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving a programmer from the sequence", "response": "def remove_programmer(programmer_id):\n    \"\"\"remove programmer.\n\n    :param programmer_id: programmer id (e.g. 'avrisp')\n    :rtype: None\n\n    \"\"\"\n\n    log.debug('remove %s', programmer_id)\n    lines = programmers_txt().lines()\n    lines = filter(\n        lambda x: not x.strip().startswith(programmer_id + '.'), lines)\n    programmers_txt().write_lines(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads the given repository entity into the session and return it.", "response": "def load(self, entity_class, entity):\n        \"\"\"\n        Load the given repository entity into the session and return a\n        clone. If it was already loaded before, look up the loaded entity\n        and return it.\n\n        All entities referenced by the loaded entity will also be loaded\n        (and cloned) recursively.\n\n        :raises ValueError: When an attempt is made to load an entity that\n          has no ID\n        \"\"\"\n        if self.__needs_flushing:\n            self.flush()\n        if entity.id is None:\n            raise ValueError('Can not load entity without an ID.')\n        cache = self.__get_cache(entity_class)\n        sess_ent = cache.get_by_id(entity.id)\n        if sess_ent is None:\n            if self.__clone_on_load:\n                sess_ent = self.__clone(entity, cache)\n            else: # Only needed by the nosql backend pragma: no cover\n                cache.add(entity)\n                sess_ent = entity\n            self.__unit_of_work.register_clean(entity_class, sess_ent)\n        return sess_ent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisplaying the environment of a started container", "response": "def onStart(self, event):\n        \"\"\"\n        Display the environment of a started container\n        \"\"\"\n        c = event.container\n        print '+' * 5, 'started:', c\n        kv = lambda s: s.split('=', 1)\n        env = {k: v for (k, v) in (kv(s) for s in c.attrs['Config']['Env'])}\n        print env"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a list of file names that are cropped to be used in the cache.", "response": "def _get_cropped_file_names(self):\n        \"\"\"self.files with common path prefix/suffix removed\"\"\"\n        files = [ff.name for ff in self.files]\n        prefix = commonprefix(files)\n        suffix = commonprefix([f[::-1] for f in files])[::-1]\n        cropped = [f[len(prefix):-len(suffix)] for f in files]\n        return cropped"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _identifier_data(self):\n        # Use only file names\n        data = [ff.name for ff in self.files]\n        data.sort()\n        # also use the folder name\n        data.append(self.path.name)\n        # add meta data\n        data += self._identifier_meta()\n        return hash_obj(data)", "response": "Return a unique identifier for the folder data"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsearches a folder for data files and return a list of tuples.", "response": "def _search_files(path):\n        \"\"\"Search a folder for data files\n\n        .. versionchanged:: 0.6.0\n            `path` is not searched recursively anymore\n        \"\"\"\n        path = pathlib.Path(path)\n        fifo = []\n\n        for fp in path.glob(\"*\"):\n            if fp.is_dir():\n                continue\n            for fmt in formats:\n                # series data is not supported in SeriesFolder\n                if not fmt.is_series and fmt.verify(fp):\n                    fifo.append((fp, fmt.__name__))\n                    break\n\n        # ignore qpimage formats if multiple formats were\n        # detected.\n        theformats = [ff[1] for ff in fifo]\n        formset = set(theformats)\n        if len(formset) > 1:\n            fmts_qpimage = [\"SingleHdf5Qpimage\", \"SeriesHdf5Qpimage\"]\n            fifo = [ff for ff in fifo if ff[1] not in fmts_qpimage]\n        # ignore raw tif files if single_tif_phasics is detected\n        if len(formset) > 1 and \"SingleTifPhasics\" in theformats:\n            fmts_badtif = \"SingleTifHolo\"\n            fifo = [ff for ff in fifo if ff[1] not in fmts_badtif]\n        # otherwise, prevent multiple file formats\n        theformats2 = [ff[1] for ff in fifo]\n        formset2 = set(theformats2)\n        if len(formset2) > 1:\n            msg = \"Qpformat does not support multiple different file \" \\\n                  + \"formats within one directory: {}\".format(formset2)\n            raise MultipleFormatsNotSupportedError(msg)\n        # sort the lists\n        fifo = sorted(fifo)\n        return fifo"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlist of files in the SeriesFolder", "response": "def files(self):\n        \"\"\"List of files (only supported file formats)\"\"\"\n        if self._files is None:\n            fifo = SeriesFolder._search_files(self.path)\n            self._files = [ff[0] for ff in fifo]\n            self._formats = [ff[1] for ff in fifo]\n        return self._files"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_identifier(self, idx):\n        name = self._get_cropped_file_names()[idx]\n        return \"{}:{}:{}\".format(self.identifier, name, idx + 1)", "response": "Return an identifier for the data at index idx."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning QPImage with background correction", "response": "def get_qpimage_raw(self, idx):\n        \"\"\"Return QPImage without background correction\"\"\"\n        ds = self._get_dataset(idx)\n        qpi = ds.get_qpimage_raw()\n        qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nverify folder file format and return True if it is valid False otherwise.", "response": "def verify(path):\n        \"\"\"Verify folder file format\n\n        The folder file format is only valid when\n        there is only one file format present.\n        \"\"\"\n        valid = True\n        fifo = SeriesFolder._search_files(path)\n        # dataset size\n        if len(fifo) == 0:\n            valid = False\n        # number of different file formats\n        fifmts = [ff[1] for ff in fifo]\n        if len(set(fifmts)) != 1:\n            valid = False\n        return valid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a list of all paths in folder", "response": "def get_paths(folder):\n    '''Return *_phase.txt files in `folder`'''\n    folder = pathlib.Path(folder).resolve()\n    files = folder.rglob(\"*_phase.txt\")\n    return sorted(files)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads a txt data file", "response": "def load_file(path):\n    '''Load a txt data file'''\n    path = pathlib.Path(path)\n    data = path.open().readlines()\n    # remove comments and empty lines\n    data = [l for l in data if len(l.strip()) and not l.startswith(\"#\")]\n    # determine data shape\n    n = len(data)\n    m = len(data[0].strip().split())\n    res = np.zeros((n, m), dtype=np.dtype(float))\n    # write data to array, replacing comma with point decimal separator\n    for ii in range(n):\n        res[ii] = np.array(data[ii].strip().replace(\",\", \".\").split(),\n                           dtype=float)\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload QPI data using _intensity. txt files", "response": "def load_field(path):\n    '''Load QPI data using *_phase.txt files'''\n    path = pathlib.Path(path)\n    phase = load_file(path)\n    inten = load_file(path.parent / (path.name[:-10] + \"_intensity.txt\"))\n    ampli = np.sqrt(inten)\n    return ampli * np.exp(1j * phase)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_pyfiles(path):\n    n = 0\n    for pyfile in glob.glob(os.path.join(path, '*.py')):\n        m = import_file(pyfile)\n        IMPORTED_BUILD_SOURCES.append(m)\n        n += 1\n    return n", "response": "Import all. py files in specified directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite record as journal event.", "response": "def emit(self, record):\n        \"\"\"Write record as journal event.\n\n        MESSAGE is taken from the message provided by the\n        user, and PRIORITY, LOGGER, THREAD_NAME,\n        CODE_{FILE,LINE,FUNC} fields are appended\n        automatically. In addition, record.MESSAGE_ID will be\n        used if present.\n        \"\"\"\n        if record.args and isinstance(record.args, collections.Mapping):\n            extra = dict(self._extra, **record.args)  # Merge metadata from handler and record\n        else:\n            extra = self._extra\n        try:\n            msg = self.format(record)\n            pri = self.mapPriority(record.levelno)\n            mid = getattr(record, 'MESSAGE_ID', None)\n            send(msg,\n                 SOCKET=self.socket,\n                 MESSAGE_ID=mid,\n                 PRIORITY=format(pri),\n                 LOGGER=record.name,\n                 THREAD_NAME=record.threadName,\n                 CODE_FILE=record.pathname,\n                 CODE_LINE=record.lineno,\n                 CODE_FUNC=record.funcName,\n                 **extra)\n        except Exception:\n            self.handleError(record)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmap logging levels to journald priorities.", "response": "def mapPriority(levelno):\n        \"\"\"Map logging levels to journald priorities.\n\n        Since Python log level numbers are \"sparse\", we have\n        to map numbers in between the standard levels too.\n        \"\"\"\n        if levelno <= _logging.DEBUG:\n            return LOG_DEBUG\n        elif levelno <= _logging.INFO:\n            return LOG_INFO\n        elif levelno <= _logging.WARNING:\n            return LOG_WARNING\n        elif levelno <= _logging.ERROR:\n            return LOG_ERR\n        elif levelno <= _logging.CRITICAL:\n            return LOG_CRIT\n        else:\n            return LOG_ALERT"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_args(self, func):\n        def reverse(iterable):\n            if iterable:\n                iterable = list(iterable)\n                while len(iterable):\n                    yield iterable.pop()\n\n        args, varargs, varkw, defaults = inspect.getargspec(func)\n        result = {}\n        for default in reverse(defaults):\n            result[args.pop()] = default\n\n        for arg in reverse(args):\n            if arg == 'self':\n                continue\n            result[arg] = None\n\n        return result", "response": "Get the arguments of a method and return it as a dictionary with the passed defaults and method arguments with no default are assigned None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef guess_format(path):\n    for fmt in formats:\n        if fmt.verify(path):\n            return fmt.__name__\n    else:\n        msg = \"Undefined file format: '{}'\".format(path)\n        raise UnknownFileFormatError(msg)", "response": "Determine the file format of a folder or a file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load_data(path, fmt=None, bg_data=None, bg_fmt=None,\n              meta_data={}, holo_kw={}, as_type=\"float32\"):\n    \"\"\"Load experimental data\n\n    Parameters\n    ----------\n    path: str\n        Path to experimental data file or folder\n    fmt: str\n        The file format to use (see `file_formats.formats`).\n        If set to `None`, the file format is guessed.\n    bg_data: str\n        Path to background data file or `qpimage.QPImage`\n    bg_fmt: str\n        The file format to use (see `file_formats.formats`)\n        for the background. If set to `None`, the file format\n        is be guessed.\n    meta_data: dict\n        Meta data (see `qpimage.meta.DATA_KEYS`)\n    as_type: str\n        Defines the data type that the input data is casted to.\n        The default is \"float32\" which saves memory. If high\n        numerical accuracy is required (does not apply for a\n        simple 2D phase analysis), set this to double precision\n        (\"float64\").\n\n    Returns\n    -------\n    dataobj: SeriesData or SingleData\n        Object that gives lazy access to the experimental data.\n    \"\"\"\n    path = pathlib.Path(path).resolve()\n    # sanity checks\n    for kk in meta_data:\n        if kk not in qpimage.meta.DATA_KEYS:\n            msg = \"Meta data key not allowed: {}\".format(kk)\n            raise ValueError(msg)\n\n    # ignore None or nan values in meta_data\n    for kk in list(meta_data.keys()):\n        if meta_data[kk] in [np.nan, None]:\n            meta_data.pop(kk)\n\n    if fmt is None:\n        fmt = guess_format(path)\n    else:\n        if not formats_dict[fmt].verify(path):\n            msg = \"Wrong file format '{}' for '{}'!\".format(fmt, path)\n            raise WrongFileFormatError(msg)\n\n    dataobj = formats_dict[fmt](path=path,\n                                meta_data=meta_data,\n                                holo_kw=holo_kw,\n                                as_type=as_type)\n\n    if bg_data is not None:\n        if isinstance(bg_data, qpimage.QPImage):\n            # qpimage instance\n            dataobj.set_bg(bg_data)\n        else:\n            # actual data on disk\n            bg_path = pathlib.Path(bg_data).resolve()\n            if bg_fmt is None:\n                bg_fmt = guess_format(bg_path)\n                bgobj = formats_dict[bg_fmt](path=bg_path,\n                                             meta_data=meta_data,\n                                             holo_kw=holo_kw,\n                                             as_type=as_type)\n                dataobj.set_bg(bgobj)\n\n    return dataobj", "response": "Load the data from file or folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string of the form 1 hr 2 min 3 sec representing the given number of seconds.", "response": "def duration(seconds):\n    \"\"\"Return a string of the form \"1 hr 2 min 3 sec\" representing the\n    given number of seconds.\"\"\"\n    if seconds < 1:\n        return 'less than 1 sec'\n    seconds = int(round(seconds))\n    components = []\n    for magnitude, label in ((3600, 'hr'), (60, 'min'), (1, 'sec')):\n        if seconds >= magnitude:\n            components.append('{} {}'.format(seconds // magnitude, label))\n            seconds %= magnitude\n    return ' '.join(components)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filesize(num_bytes):\n    for prefix in '-KMGTEPZY':\n        if num_bytes < 999.9:\n            break\n        num_bytes /= 1000.0\n    if prefix == '-':\n        return '{} B'.format(num_bytes)\n    return '{:.3n} {}B'.format(num_bytes, prefix)", "response": "Return a string containing an approximate representation of num_bytes using a small number and decimal SI prefix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nevolve to the new process state at the next date", "response": "def evolve(self, new_date):\n        \"\"\"\n        evolve to the new process state at the next date\n\n        :param date new_date: date or point in time of the new state\n        :return State:\n        \"\"\"\n        if self.state.date == new_date and not self.initial_state.date == new_date:\n            return self.state\n        if self._len:\n            q = [self.random.gauss(0., 1.) for _ in range(int(self._len))]\n        else:\n            q = self.random.gauss(0., 1.)\n        self.state.value = self.func(self.state.value, self.state.date, new_date, q)\n        self.state.date = new_date\n        return self.state"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef evolve(self, new_date):\n        if all(p.state.date == new_date for p in self.producers):\n            return [p.state for p in self.producers]\n\n        if self._cholesky is not None:\n            q = [self.random.gauss(0., 1.) for _ in range(len(self._cholesky))]\n            q = list(self._cholesky.dot(q))\n        else:\n            q = list()\n\n        state = list()\n        for p in self.producers:\n            if len(self._driver_index[p]) == len(p.diffusion_driver):\n                qq = [q[i] for i in self._driver_index[p]]\n            elif len(self._driver_index[p]) < len(p.diffusion_driver):\n                qq = list()\n                for d in p.diffusion_driver:\n                    qqq = q[self._diffusion_driver.index(d)] if d in self._diffusion_driver else self.random.gauss(0., 1.)\n                    qq.append(qqq)\n            else:\n                qq = [self.random.gauss(0., 1.) for _ in p.diffusion_driver]\n\n            p.random.extend(qq)\n            state.append(p.evolve(new_date))\n\n        return state", "response": "evolve to the new process state at the next date"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the shortcut prefix of the user agent.", "response": "def _get_shortcut_prefix(self, user_agent, standart_prefix):\n        \"\"\"\n        Returns the shortcut prefix of browser.\n\n        :param user_agent: The user agent of browser.\n        :type user_agent: str\n        :param standart_prefix: The default prefix.\n        :type standart_prefix: str\n        :return: The shortcut prefix of browser.\n        :rtype: str\n        \"\"\"\n        # pylint: disable=no-self-use\n\n        if user_agent is not None:\n            user_agent = user_agent.lower()\n            opera = 'opera' in user_agent\n            mac = 'mac' in user_agent\n            konqueror = 'konqueror' in user_agent\n            spoofer = 'spoofer' in user_agent\n            safari = 'applewebkit' in user_agent\n            windows = 'windows' in user_agent\n            chrome = 'chrome' in user_agent\n            firefox = (\n                ('firefox' in user_agent)\n                or ('minefield' in user_agent)\n            )\n            internet_explorer = (\n                ('msie' in user_agent)\n                or ('trident' in user_agent)\n            )\n\n            if opera:\n                return 'SHIFT + ESC'\n            elif chrome and mac and (not spoofer):\n                return 'CTRL + OPTION'\n            elif safari and (not windows) and (not spoofer):\n                return 'CTRL + ALT'\n            elif (not windows) and (safari or mac or konqueror):\n                return 'CTRL'\n            elif firefox:\n                return 'ALT + SHIFT'\n            elif chrome or internet_explorer:\n                return 'ALT'\n            return standart_prefix\n        return standart_prefix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the description of a role.", "response": "def _get_role_description(self, role):\n        \"\"\"\n        Returns the description of role.\n\n        :param role: The role.\n        :type role: str\n        :return: The description of role.\n        :rtype: str\n        \"\"\"\n\n        parameter = 'role-' + role.lower()\n        if self.configure.has_parameter(parameter):\n            return self.configure.get_parameter(parameter)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the description of the language.", "response": "def _get_language_description(self, language_code):\n        \"\"\"\n        Returns the description of language.\n\n        :param language_code: The BCP 47 code language.\n        :type language_code: str\n        :return: The description of language.\n        :rtype: str\n        \"\"\"\n\n        language = language_code.lower()\n        parameter = 'language-' + language\n        if self.configure.has_parameter(parameter):\n            return self.configure.get_parameter(parameter)\n        elif '-' in language:\n            codes = re.split(r'\\-', language)\n            parameter = 'language-' + codes[0]\n            if self.configure.has_parameter(parameter):\n                return self.configure.get_parameter(parameter)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_description(self, element):\n\n        description = None\n        if element.has_attribute('title'):\n            description = element.get_attribute('title')\n        elif element.has_attribute('aria-label'):\n            description = element.get_attribute('aria-label')\n        elif element.has_attribute('alt'):\n            description = element.get_attribute('alt')\n        elif element.has_attribute('label'):\n            description = element.get_attribute('label')\n        elif (\n            (element.has_attribute('aria-labelledby'))\n            or (element.has_attribute('aria-describedby'))\n        ):\n            if element.has_attribute('aria-labelledby'):\n                description_ids = re.split(\n                    '[ \\n\\r\\t]+',\n                    element.get_attribute('aria-labelledby').strip()\n                )\n            else:\n                description_ids = re.split(\n                    '[ \\n\\r\\t]+',\n                    element.get_attribute('aria-describedby').strip()\n                )\n            for description_id in description_ids:\n                element_description = self.parser.find(\n                    '#' + description_id\n                ).first_result()\n                if element_description is not None:\n                    description = element_description.get_text_content()\n                    break\n        elif (\n            (element.get_tag_name() == 'INPUT')\n            and (element.has_attribute('type'))\n        ):\n            type_attribute = element.get_attribute('type').lower()\n            if (\n                (\n                    (type_attribute == 'button')\n                    or (type_attribute == 'submit')\n                    or (type_attribute == 'reset')\n                )\n                and (element.has_attribute('value'))\n            ):\n                description = element.get_attribute('value')\n        if not bool(description):\n            description = element.get_text_content()\n        return re.sub('[ \\n\\r\\t]+', ' ', description.strip())", "response": "Returns the description of the element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the list of shortcuts of page.", "response": "def _generate_list_shortcuts(self):\n        \"\"\"\n        Generate the list of shortcuts of page.\n        \"\"\"\n\n        id_container_shortcuts_before = (\n            AccessibleDisplayImplementation.ID_CONTAINER_SHORTCUTS_BEFORE\n        )\n        id_container_shortcuts_after = (\n            AccessibleDisplayImplementation.ID_CONTAINER_SHORTCUTS_AFTER\n        )\n        local = self.parser.find('body').first_result()\n        if local is not None:\n            container_before = self.parser.find(\n                '#'\n                + id_container_shortcuts_before\n            ).first_result()\n            if (\n                (container_before is None)\n                and (self.attribute_accesskey_before)\n            ):\n                container_before = self.parser.create_element('div')\n                container_before.set_attribute(\n                    'id',\n                    id_container_shortcuts_before\n                )\n\n                text_container_before = self.parser.create_element('span')\n                text_container_before.set_attribute(\n                    'class',\n                    AccessibleDisplayImplementation.CLASS_TEXT_SHORTCUTS\n                )\n                text_container_before.append_text(\n                    self.attribute_accesskey_before\n                )\n\n                container_before.append_element(text_container_before)\n                local.prepend_element(container_before)\n            if container_before is not None:\n                self.list_shortcuts_before = self.parser.find(\n                    container_before\n                ).find_children('ul').first_result()\n                if self.list_shortcuts_before is None:\n                    self.list_shortcuts_before = self.parser.create_element(\n                        'ul'\n                    )\n                    container_before.append_element(self.list_shortcuts_before)\n\n            container_after = self.parser.find(\n                '#'\n                + id_container_shortcuts_after\n            ).first_result()\n            if (\n                (container_after is None)\n                and (self.attribute_accesskey_after)\n            ):\n                container_after = self.parser.create_element('div')\n                container_after.set_attribute(\n                    'id',\n                    id_container_shortcuts_after\n                )\n\n                text_container_after = self.parser.create_element('span')\n                text_container_after.set_attribute(\n                    'class',\n                    AccessibleDisplayImplementation.CLASS_TEXT_SHORTCUTS\n                )\n                text_container_after.append_text(\n                    self.attribute_accesskey_after\n                )\n\n                container_after.append_element(text_container_after)\n                local.append_element(container_after)\n            if container_after is not None:\n                self.list_shortcuts_after = self.parser.find(\n                    container_after\n                ).find_children('ul').first_result()\n                if self.list_shortcuts_after is None:\n                    self.list_shortcuts_after = self.parser.create_element(\n                        'ul'\n                    )\n                    container_after.append_element(self.list_shortcuts_after)\n        self.list_shortcuts_added = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninsert a new element before or after another element.", "response": "def _insert(self, element, new_element, before):\n        \"\"\"\n        Insert a element before or after other element.\n\n        :param element: The reference element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param new_element: The element that be inserted.\n        :type new_element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param before: To insert the element before the other element.\n        :type before: bool\n        \"\"\"\n\n        tag_name = element.get_tag_name()\n        append_tags = [\n            'BODY',\n            'A',\n            'FIGCAPTION',\n            'LI',\n            'DT',\n            'DD',\n            'LABEL',\n            'OPTION',\n            'TD',\n            'TH'\n        ]\n        controls = ['INPUT', 'SELECT', 'TEXTAREA']\n        if tag_name == 'HTML':\n            body = self.parser.find('body').first_result()\n            if body is not None:\n                self._insert(body, new_element, before)\n        elif tag_name in append_tags:\n            if before:\n                element.prepend_element(new_element)\n            else:\n                element.append_element(new_element)\n        elif tag_name in controls:\n            labels = []\n            if element.has_attribute('id'):\n                labels = self.parser.find(\n                    'label[for=\"'\n                    + element.get_attribute('id')\n                    + '\"]'\n                ).list_results()\n            if not labels:\n                labels = self.parser.find(element).find_ancestors(\n                    'label'\n                ).list_results()\n            for label in labels:\n                self._insert(label, new_element, before)\n        elif before:\n            element.insert_before(new_element)\n        else:\n            element.insert_after(new_element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nforce the screen reader display an information of the element.", "response": "def _force_read_simple(self, element, text_before, text_after, data_of):\n        \"\"\"\n        Force the screen reader display an information of element.\n\n        :param element: The reference element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param text_before: The text content to show before the element.\n        :type text_before: str\n        :param text_after: The text content to show after the element.\n        :type text_after: str\n        :param data_of: The name of attribute that links the content with\n                        element.\n        :type data_of: str\n        \"\"\"\n\n        self.id_generator.generate_id(element)\n        identifier = element.get_attribute('id')\n        selector = '[' + data_of + '=\"' + identifier + '\"]'\n\n        reference_before = self.parser.find(\n            '.'\n            + AccessibleDisplayImplementation.CLASS_FORCE_READ_BEFORE\n            + selector\n        ).first_result()\n        reference_after = self.parser.find(\n            '.'\n            + AccessibleDisplayImplementation.CLASS_FORCE_READ_AFTER\n            + selector\n        ).first_result()\n        references = self.parser.find(selector).list_results()\n        if reference_before in references:\n            references.remove(reference_before)\n        if reference_after in references:\n            references.remove(reference_after)\n\n        if not references:\n            if text_before:\n                if reference_before is not None:\n                    reference_before.remove_node()\n\n                span = self.parser.create_element('span')\n                span.set_attribute(\n                    'class',\n                    AccessibleDisplayImplementation.CLASS_FORCE_READ_BEFORE\n                )\n                span.set_attribute(data_of, identifier)\n                span.append_text(text_before)\n                self._insert(element, span, True)\n            if text_after:\n                if reference_after is not None:\n                    reference_after.remove_node()\n\n                span = self.parser.create_element('span')\n                span.set_attribute(\n                    'class',\n                    AccessibleDisplayImplementation.CLASS_FORCE_READ_AFTER\n                )\n                span.set_attribute(data_of, identifier)\n                span.append_text(text_after)\n                self._insert(element, span, False)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _force_read(\n        self,\n        element,\n        value,\n        text_prefix_before,\n        text_suffix_before,\n        text_prefix_after,\n        text_suffix_after,\n        data_of\n    ):\n        \"\"\"\n        Force the screen reader display an information of element with prefixes\n        or suffixes.\n\n        :param element: The reference element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param value: The value to be show.\n        :type value: str\n        :param text_prefix_before: The prefix of value to show before the\n                                   element.\n        :type text_prefix_before: str\n        :param text_suffix_before: The suffix of value to show before the\n                                   element.\n        :type text_suffix_before: str\n        :param text_prefix_after: The prefix of value to show after the\n                                  element.\n        :type text_prefix_after: str\n        :param text_suffix_after: The suffix of value to show after the\n                                  element.\n        :type text_suffix_after: str\n        :param data_of: The name of attribute that links the content with\n                        element.\n        :type data_of: str\n        \"\"\"\n\n        if (text_prefix_before) or (text_suffix_before):\n            text_before = text_prefix_before + value + text_suffix_before\n        else:\n            text_before = ''\n        if (text_prefix_after) or (text_suffix_after):\n            text_after = text_prefix_after + value + text_suffix_after\n        else:\n            text_after = ''\n        self._force_read_simple(element, text_before, text_after, data_of)", "response": "Force the screen reader display an information of the content with the specified attributes."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_vessel_errors(retdict):\n  ERROR_RESPONSES = {\n    \"Node Manager error 'Insufficient Permissions'\": {\n      'error': \"You lack sufficient permissions to perform this action.\",\n      'reason': \"Did you release the resource(s) by accident?\"},\n    'timed out': {\n      'error':'Connection timed out.'},\n    \"file not found\": {\n      'error': \"The specified file(s) could not be found.\",\n      'reason': \"Please check the filename.\"},\n    \"Node Manager error 'Programming language platform is not supported.'\": {\n      'error': \"Requested platform is not supported by the target vessel.\"},\n    }\n\n  # A dictionary mapping error identifiers to a list of vessels that share\n  # that error.\n  error_longnames = {}\n\n  for longname in retdict:\n    # if the first item is true, then there is no error.\n    if not retdict[longname][0]:\n      matches = []\n      # Loop until we find the response\n      for error_string in ERROR_RESPONSES:\n        if error_string.lower() in retdict[longname][1].lower():\n          # This is the first match\n          if not matches:\n            matches = [error_string]\n          else:\n            # This is a better match, forget about the previous matches\n            if len(error_string) > len(matches[0]):\n              matches = [error_string]\n\n            elif len(error_string) == len(matches[0]):\n              matches.append(error_string)\n\n      # If there isn't a match, use the error string as an error identifier\n      if not matches:\n        errorid = retdict[longname][1]\n\n      else:\n        # There should not be more than 1 match for any error.\n        # If there is, log the error to a file.\n        if len(matches) != 1:\n          errfile = open('seasherrors.txt', 'a')\n          errorstring = \"Multiple matches with same priority:\" + '\\n'.join(matches)\n          errfile.write(errorstring)\n          errfile.close()\n          raise Exception(errorstring)\n        errorid = matches[0]\n\n      # Create the longname list if it doesn't already exist\n      if errorid not in error_longnames:\n        error_longnames[errorid] = []\n      error_longnames[errorid].append(longname)\n\n\n  # Print the errors out\n  for errorid in error_longnames:\n    # Represent the list of nodes in a human readable way.\n    nodestring = ''\n    for node in error_longnames[errorid]:\n      # This is the first node\n      if node == error_longnames[errorid][0]:\n        divider = ''\n      # This is a node in the middle\n      elif node != error_longnames[errorid][-1]:\n        divider = ', '\n      # This is the last node\n      else:\n        # We will always have at least 2 nodes at this point, since if there\n        # is only one node, it will be treated as the first node. Therefore,\n        # we only have two cases, where there are exactly 2 nodes, or more than\n        # 2 nodes.\n        # If we have two nodes, we want: \"node_1 and node_2\".\n        # Otherwise, we want: \"node_1, node_2, ..., and node_n\".\n        divider = \" and \"\n        if len(error_longnames[errorid]) > 2:\n          divider = ',' + divider\n      nodestring += divider + node\n\n    if errorid in ERROR_RESPONSES:\n      print ERROR_RESPONSES[errorid]['error'],\n      if 'reason' in ERROR_RESPONSES[errorid]:\n        print ERROR_RESPONSES[errorid]['reason']\n      else:\n        # Caret is still on the same line as the list of nodes\n        print\n    else:\n      # Unknown error.\n      print \"An error occurred: \" + errorid\n    print \"Affected vessels:\", nodestring + '.'", "response": "Print out any errors that occurred while performing an action on a node manager vessel."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_commands_from_commanddict(commanddict):\n  if not commanddict:\n    return []\n\n  commands = []\n  for command in commanddict:\n    has_user_argument = False\n    subcommands = get_commands_from_commanddict(commanddict[command]['children'])\n    if subcommands:\n      for subcommand in subcommands:\n        commands.append(command + \" \" + subcommand)\n    else:\n      commands.append(command)\n  return commands", "response": "Returns a list of all commands contained in commanddict."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef inject(*args, **kwargs):\n    def wrapper(obj):\n        if inspect.isclass(obj) or callable(obj):\n            _inject_object(obj, *args, **kwargs)\n            return obj\n        raise DiayException(\"Don't know how to inject into %r\" % obj)\n    return wrapper", "response": "Decorator for injecting properties into a class or function."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters a provider function.", "response": "def register_provider(self, func):\n        \"\"\"\n        Register a provider function.\n        \"\"\"\n        if 'provides' not in getattr(func, '__di__', {}):\n            raise DiayException('function %r is not a provider' % func)\n\n        self.factories[func.__di__['provides']] = func"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering a method lazily as a provider.", "response": "def register_lazy_provider_method(self, cls, method):\n        \"\"\"\n        Register a class method lazily as a provider.\n        \"\"\"\n        if 'provides' not in getattr(method, '__di__', {}):\n            raise DiayException('method %r is not a provider' % method)\n\n        @functools.wraps(method)\n        def wrapper(*args, **kwargs):\n            return getattr(self.get(cls), method.__name__)(*args, **kwargs)\n\n        self.factories[method.__di__['provides']] = wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_factory(self, thing: type, value, overwrite=False):\n        if thing in self.factories and not overwrite:\n            raise DiayException('factory for %r already exists' % thing)\n        self.factories[thing] = value", "response": "Set the factory for something."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets an instance of a thing.", "response": "def set_instance(self, thing: type, value, overwrite=False):\n        \"\"\"\n        Set an instance of a thing.\n        \"\"\"\n        if thing in self.instances and not overwrite:\n            raise DiayException('instance for %r already exists' % thing)\n        self.instances[thing] = value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, thing: type):\n        if thing in self.instances:\n            return self.instances[thing]\n\n        if thing in self.factories:\n            fact = self.factories[thing]\n            ret = self.get(fact)\n            if hasattr(fact, '__di__') and fact.__di__['singleton']:\n                self.instances[thing] = ret\n            return ret\n\n        if inspect.isclass(thing):\n            return self._call_class_init(thing)\n        elif callable(thing):\n            return self.call(thing)\n\n        raise DiayException('cannot resolve: %r' % thing)", "response": "Get an instance of some type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef call(self, func, *args, **kwargs):\n        guessed_kwargs = self._guess_kwargs(func)\n        for key, val in guessed_kwargs.items():\n            kwargs.setdefault(key, val)\n        try:\n            return func(*args, **kwargs)\n        except TypeError as exc:\n            msg = (\n                \"tried calling function %r but failed, probably \"\n                \"because it takes arguments that cannot be resolved\"\n            ) % func\n            raise DiayException(msg) from exc", "response": "Call a function resolving any type - hinted arguments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_dict(self):\r\n\r\n        # add in the raw data into the dict\r\n        result = {\r\n            key[1:]: getattr(self, key)\r\n            for key in self.__slots__\r\n            if key[0] == '_' and hasattr(self, key)\r\n        }\r\n\r\n        # deal with basic convenience wrappers\r\n\r\n        try:\r\n            colour = result.pop('colour')\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            if colour:\r\n                result['color'] = colour.value\r\n\r\n        try:\r\n            timestamp = result.pop('timestamp')\r\n        except KeyError:\r\n            pass\r\n        else:\r\n            if timestamp:\r\n                result['timestamp'] = timestamp.isoformat()\r\n\r\n        # add in the non raw attribute ones\r\n        if self.type:\r\n            result['type'] = self.type\r\n\r\n        if self.description:\r\n            result['description'] = self.description\r\n\r\n        if self.url:\r\n            result['url'] = self.url\r\n\r\n        if self.title:\r\n            result['title'] = self.title\r\n\r\n        return result", "response": "Converts this embed object into a dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef do_list(self, resource):\n        if resource == 'plugins':\n            self.__list_plugins()\n        elif resource == 'volumes':\n            self.__list_volumes()\n        else:\n            self.logger.error(\"Unknown resource: '{}', type 'help list' \"\n                              \"to get more information\".format(resource))", "response": "List the available resources"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload disk image for analysis", "response": "def do_load(self, filename):\n        \"\"\"Load disk image for analysis\"\"\"\n        try:\n            self.__session.load(filename)\n        except IOError as e:\n            self.logger.error(e.strerror)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nprinting current session information", "response": "def do_session(self, args):\n        \"\"\"Print current session information\"\"\"\n        filename = 'Not specified' if self.__session.filename is None \\\n            else self.__session.filename\n\n        print('{0: <30}: {1}'.format('Filename', filename))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _convert_iterable(self, iterable):\n        # Return original if _wrapper isn't callable\n        if not callable(self._wrapper):\n            return iterable\n\n        return [self._wrapper(x) for x in iterable]", "response": "Converts elements returned by an iterable into instances of\n        self. _wrapper\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _check_element(self, lookup_strings, instance):\n        for q, val in lookup_strings.items():\n            if not field_lookup(instance, q, val, True):\n                return False\n\n        return True", "response": "Return True if the lookup string value pairs match against the passed object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the first object encountered that matches the specified kwargs.", "response": "def get(self, **kwargs):\n        \"\"\"Returns the first object encountered that matches the specified\n        lookup parameters.\n\n        >>> site_list.get(id=1)\n        {'url': 'http://site1.tld/', 'published': False, 'id': 1}\n        >>> site_list.get(published=True, id__lt=3)\n        {'url': 'http://site1.tld/', 'published': True, 'id': 2}\n        >>> site_list.filter(published=True).get(id__lt=3)\n        {'url': 'http://site1.tld/', 'published': True, 'id': 2}\n\n        If the QueryList contains multiple elements that match the criteria,\n        only the first match will be returned. Use ``filter()`` to retrieve\n        the entire set.\n\n        If no match is found in the QueryList, the method will raise a\n        ``NotFound`` exception.\n\n        >>> site_list.get(id=None)\n        Traceback (most recent call last):\n          File \"<stdin>\", line 1, in <module>\n          File \"querylist/list.py\", line 113, in get\n            \"Element not found with attributes: %s\" % kv_str)\n        querylist.list.NotFound: Element not found with attributes: id=None\n\n        \"\"\"\n        for x in self:\n            if self._check_element(kwargs, x):\n                return x\n\n        kv_str = self._stringify_kwargs(kwargs)\n        raise QueryList.NotFound(\n            \"Element not found with attributes: %s\" % kv_str)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef exclude(self, **kwargs):\n        return QueryList(\n            data=(x for x in self if not self._check_element(kwargs, x)),\n            wrapper=self._wrapper, wrap=False)", "response": "Generates a new QueryList containing the subset of objects from this QueryList that do not match the provided field lookups."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate the APIHandler settings from the given configuration.", "response": "def __create_handler_settings(config):\n    \"\"\" :type config: dict \"\"\"\n    server_config = config['conf']['server']\n    plugins_conf = config['conf']['plugins_enabled']\n\n    api_handler_settings = {\n        'auth_required': server_config.get('auth_required', True),\n        'upstream_timeout': server_config.get('upstream_timeout', None),\n        'registry': PluginBuilder.build_plugins(plugins_conf),\n    }\n    if api_handler_settings['auth_required']:\n        api_handler_settings['auth_tokens'] = server_config['auth_tokens']\n\n    return {\n        APIHandler: api_handler_settings\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the fnExchange server", "response": "def runserver(ctx, conf, port, foreground):\n    \"\"\"Run the fnExchange server\"\"\"\n    config = read_config(conf)\n\n    debug = config['conf'].get('debug', False)\n    click.echo('Debug mode {0}.'.format('on' if debug else 'off'))\n\n    port = port or config['conf']['server']['port']\n\n    app_settings = {\n        'debug': debug,\n        'auto_reload': config['conf']['server'].get('auto_reload', False),\n    }\n    handlers_settings = __create_handler_settings(config)\n\n    if foreground:\n        click.echo('Requested mode: foreground')\n        start_app(port, app_settings, handlers_settings)\n    else:\n        click.echo('Requested mode: background')\n        # subprocess.call([sys.executable, 'yourscript.py'], env=os.environ.copy())\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the given registered resource as a repository.", "response": "def as_repository(resource):\n    \"\"\"\n    Adapts the given registered resource to its configured repository.\n\n    :return: object implementing\n      :class:`everest.repositories.interfaces.IRepository`.\n    \"\"\"\n    reg = get_current_registry()\n    if IInterface in provided_by(resource):\n        resource = reg.getUtility(resource, name='collection-class')\n    return reg.getAdapter(resource, IRepository)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the transaction manager should veto all commits for the current request.", "response": "def commit_veto(request, response): # unused request arg pylint: disable=W0613\n    \"\"\"\n    Strict commit veto to use with the transaction manager.\n\n    Unlike the default commit veto supplied with the transaction manager,\n    this will veto all commits for HTTP status codes other than 2xx unless\n    a commit is explicitly requested by setting the \"x-tm\" response header to\n    \"commit\". As with the default commit veto, the commit is always vetoed if\n    the \"x-tm\" response header is set to anything other than \"commit\".\n    \"\"\"\n    tm_header = response.headers.get('x-tm')\n    if not tm_header is None:\n        result = tm_header != 'commit'\n    else:\n        result = not response.status.startswith('2') \\\n                 and not tm_header == 'commit'\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set(cls, key, obj):\n        with cls._lock:\n            if not cls._globs.get(key) is None:\n                raise ValueError('Duplicate key \"%s\".' % key)\n            cls._globs[key] = obj\n        return cls._globs[key]", "response": "Sets the given object as global object for the given key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef as_representer(resource, content_type):\n    reg = get_current_registry()\n    rpr_reg = reg.queryUtility(IRepresenterRegistry)\n    return rpr_reg.create(type(resource), content_type)", "response": "Returns a representer for the given resource and content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_mapping_registry(content_type):\n    reg = get_current_registry()\n    rpr_reg = reg.queryUtility(IRepresenterRegistry)\n    return rpr_reg.get_mapping_registry(content_type)", "response": "Returns the mapping registry for the given content type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a data element tree to a string representation of the given data element tree.", "response": "def data_element_tree_to_string(data_element):\n    \"\"\"\n    Creates a string representation of the given data element tree.\n    \"\"\"\n    # FIXME: rewrite this as a visitor to use the data element tree traverser.\n    def __dump(data_el, stream, offset):\n        name = data_el.__class__.__name__\n        stream.write(\"%s%s\" % (' ' * offset, name))\n        offset += 2\n        ifcs = provided_by(data_el)\n        if ICollectionDataElement in ifcs:\n            stream.write(\"[\")\n            first_member = True\n            for member_data_el in data_el.get_members():\n                if first_member:\n                    stream.write('%s' % os.linesep + ' ' * offset)\n                    first_member = False\n                else:\n                    stream.write(',%s' % os.linesep + ' ' * offset)\n                __dump(member_data_el, stream, offset)\n            stream.write(\"]\")\n        else:\n            stream.write(\"(\")\n            if ILinkedDataElement in ifcs:\n                stream.write(\"url=%s, kind=%s, relation=%s\" %\n                             (data_el.get_url(), data_el.get_kind(),\n                              data_el.get_relation()))\n            else:\n                first_attr = True\n                for attr_name, attr_value in iteritems_(data_el.data):\n                    if first_attr:\n                        first_attr = False\n                    else:\n                        stream.write(',%s' % os.linesep\n                                     + ' ' * (offset + len(name) + 1))\n                    if attr_value is None:\n                        continue\n                    if not IResourceDataElement in provided_by(attr_value):\n                        stream.write(\"%s=%s\" % (attr_name, attr_value))\n                    else:\n                        stream.write(\"%s=\" % attr_name)\n                        __dump(attr_value, stream, offset)\n            stream.write(')')\n    stream = NativeIO()\n    __dump(data_element, stream, 0)\n    return stream.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinalizing simulation for consumer", "response": "def finalize(self):\n        \"\"\"\n        finalize simulation for consumer\n        \"\"\"\n        super(StringWriterConsumer, self).finalize()\n        self.result = self.decoder(self.result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninitializing the state of the consumer_state ready for the next MC path_num", "response": "def initialize_path(self, path_num=None):\n        \"\"\"\n        make the consumer_state ready for the next MC path\n\n        :param int path_num:\n        \"\"\"\n        for c in self.consumers:\n            c.initialize_path(path_num)\n        self.state = [c.state for c in self.consumers]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef finalize_path(self, path_num=None):\n        for c in self.consumers:\n            c.finalize_path(path_num)\n        self.result = [c.result for c in self.consumers]", "response": "finalize path and populate result for ConsumerConsumer"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets to given consumer states. This function is used for merging of results of parallelized MC. The first state is used for merging in place. The states must be disjoint. :param object queue_get: second consumer state", "response": "def get(self, queue_get):\n        \"\"\"\n        get to given consumer states.\n        This function is used for merging of results of parallelized MC.\n        The first state is used for merging in place. The states must be disjoint.\n\n        :param object queue_get: second consumer state\n        \"\"\"\n        for (c, cs) in izip(self.consumers, queue_get):\n            c.get(cs)\n        self.result = [c.result for c in self.consumers]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining attribute type at the offset and returns the MftAttr object.", "response": "def _get_attribute(self, offset):\n        \"\"\"Determines attribute type at the offset and returns \\\n        initialized attribute object.\n\n        Returns:\n            MftAttr: One of the attribute objects \\\n            (eg. :class:`~.mft_attribute.MftAttrFilename`).\n            None: If atttribute type does not mach any one of the supported \\\n            attribute types.\n        \"\"\"\n        attr_type = self.get_uint_le(offset)\n        # Attribute length is in header @ offset 0x4\n        length = self.get_uint_le(offset + 0x04)\n        data = self.get_chunk(offset, length)\n\n        return MftAttr.factory(attr_type, data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a tuple representing the index of an item in a 2D matrix.", "response": "def find_in_matrix_2d(val, matrix):\n    '''\n    Returns a tuple representing the index of an item in a 2D matrix.\n\n    Arguments:\n        - val (str) Value to look for\n        - matrix (list) 2D matrix to search for val in\n\n    Returns:\n        - (tuple) Ordered pair representing location of val\n    '''\n\n    dim = len(matrix[0])\n    item_index = 0\n\n    for row in matrix:\n        for i in row:\n            if i == val:\n                break\n            item_index += 1\n        if i == val:\n            break\n\n    loc = (int(item_index / dim), item_index % dim)\n\n    return loc"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef compute_qwerty_distance(c1, c2):\n    '''\n    Provides a score representing the distance between two characters on a\n    QWERTY keyboard, utilizing a simple matrix to represent the keyboard:\n\n        | 0   1   2   3   4   5   6   7   8   9   10  11  12  13\n      --+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n      0 | ` | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0 | - | = |   |\n      1 |   | q | w | e | r | t | y | u | i | o | p | [ | ] | \\ |\n      2 |   | a | s | d | f | g | h | j | k | l | ; | ' |   |   |\n      3 |   |   | z | x | c | v | b | n | m | , | . | / |   |   |\n      --+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n\n    For example, a score of 0 means the characters are the same, while a score\n    of 5 means that it takes 5 position changes to get from c1 to c2. However,\n    for characters that are 1 diagonal move away (such as q to s), the score is\n    reduced from 2 to 1 to prevent any horizontal / vertical bias.\n\n    Arguments:\n        - c1 (str) Character to compare to 'c2'\n        - c2 (str) Character to compare to 'c1'\n\n    Returns:\n        - (int) Number representing distance between two characters\n\n    Raises:\n        - ValueError: If the length of c1 or c2 is greater than 1\n    '''\n\n    # build table\n    keyboard = [\n        ['`', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '-', '=', ''],\n        ['', 'q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', '[', ']', '\\\\'],\n        ['', 'a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', ';', '\\'', '', ''],\n        ['', '', 'z', 'x', 'c', 'v', 'b', 'n', 'm', ',', '.', '/', '', '']\n    ]\n\n    loc_c1 = find_in_matrix_2d(c1, keyboard)\n    loc_c2 = find_in_matrix_2d(c2, keyboard)\n\n    # euclidean distance\n    distance = ((loc_c2[0] - loc_c1[0])**2 + (loc_c2[1] - loc_c1[1])**2)**0.5\n\n    return distance", "response": "Compute the QWERTY distance between two characters on a base - keyboard table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncomputing a modified Levenshtein distance between two strings comparing the lowercase versions of each string and accounting for QWERTY distance.", "response": "def compute_distance(a, b):\n    '''\n    Computes a modified Levenshtein distance between two strings, comparing the\n    lowercase versions of each string and accounting for QWERTY distance.\n\n    Arguments:\n        - a (str) String to compare to 'b'\n        - b (str) String to compare to 'a'\n\n    Returns:\n        - (int) Number representing closeness of 'a' and 'b' (lower is better)\n    '''\n\n    # check simple cases first\n    if not a:\n        return len(b)\n    if not b:\n        return len(a)\n    if a == b or str.lower(a) == str.lower(b):\n        return 0\n\n    # lowercase each string\n    a = str.lower(a)\n    b = str.lower(b)\n\n    # create empty vectors to store costs\n    vector_1 = [-1] * (len(b) + 1)\n    vector_2 = [-1] * (len(b) + 1)\n\n    # set default values\n    for i in range(len(vector_1)):\n        vector_1[i] = i\n\n    # compute distance\n    for i in range(len(a)):\n        vector_2[0] = i + 1\n\n        for j in range(len(b)):\n            penalty = 0 if a[i] == b[j] else compute_qwerty_distance(a[i], b[j])\n            vector_2[j + 1] = min(vector_2[j] + 1, vector_1[j + 1] + 1, vector_1[j] + penalty)\n\n        for j in range(len(vector_1)):\n            vector_1[j] = vector_2[j]\n\n    return vector_2[len(b)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread file for configuration defaults.", "response": "def get_defaults(path):\n    '''\n    Reads file for configuration defaults.\n\n    Arguments:\n        - path (str) Absolute filepath (usually ~/.licenser)\n\n    Returns:\n        - (dict) Defaults for name, email, license, .txt extension\n    '''\n\n    defaults = {}\n\n    if os.path.isfile(path):\n        with open(path) as f:\n\n            for line in f:\n                line = line.strip()\n                if '=' not in line or line.startswith('#'):\n                    continue\n\n                k, v = line.split('=', 1)\n                v = v.strip('\"').strip(\"'\")\n\n                defaults[k] = v\n        return defaults\n    else:\n        return {}"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_license(name):\n    '''\n    Returns the closest match to the requested license.\n\n    Arguments:\n        - name (str) License to use\n\n    Returns:\n        - (str) License that most closely matches the 'name' parameter\n    '''\n\n    filenames = os.listdir(cwd + licenses_loc)\n    licenses = dict(zip(filenames, [-1] * len(filenames)))\n\n    for l in licenses:\n        licenses[l] = compute_distance(name, l)\n\n    return min(licenses, key=(lambda k: licenses[k]))", "response": "Returns the closest match to the requested license."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse command line args & override defaults.", "response": "def get_args(path):\n    '''\n    Parse command line args & override defaults.\n\n    Arguments:\n        - path (str) Absolute filepath\n\n    Returns:\n        - (tuple) Name, email, license, project, ext, year\n    '''\n\n    defaults = get_defaults(path)\n    licenses = ', '.join(os.listdir(cwd + licenses_loc))\n    p = parser(description='tool for adding open source licenses to your projects. available licenses: %s' % licenses)\n\n    _name = False if defaults.get('name') else True\n    _email = False if defaults.get('email') else True\n    _license = False if defaults.get('license') else True\n\n    p.add_argument('-n', dest='name', required=_name, help='name')\n    p.add_argument('-e', dest='email', required=_email, help='email')\n    p.add_argument('-l', dest='license', required=_license, help='license')\n    p.add_argument('-p', dest='project', required=False, help='project')\n    p.add_argument('-v', '--version', action='version', version='%(prog)s {version}'.format(version=version))\n    p.add_argument('--txt', action='store_true', required=False, help='add .txt to filename')\n\n    args = p.parse_args()\n\n    name = args.name if args.name else defaults.get('name')\n    email = args.email if args.email else defaults.get('email')\n    license = get_license(args.license) if args.license else defaults.get('license')\n    project = args.project if args.project else os.getcwd().split('/')[-1]\n    ext = '.txt' if args.txt else ''\n    year = str(date.today().year)\n\n    return (name, email, license, project, ext, year)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a LICENSE file in the current directory.", "response": "def generate_license(args):\n    '''\n    Creates a LICENSE or LICENSE.txt file in the current directory. Reads from\n    the 'assets' folder and looks for placeholders enclosed in curly braces.\n\n    Arguments:\n        - (tuple) Name, email, license, project, ext, year\n    '''\n\n    with open(cwd + licenses_loc + args[2]) as f:\n        license = f.read()\n\n    license = license.format(name=args[0],\n                             email=args[1],\n                             license=args[2],\n                             project=args[3],\n                             year=args[5])\n\n    with open('LICENSE' + args[4], 'w') as f:\n        f.write(license)\n        print('licenser: license file added to current directory')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconstructing the message object", "response": "def construct_message(self, email=None):\r\n        \"\"\" construct the email message \"\"\"\r\n        # add subject, from and to\r\n        self.multipart['Subject'] = self.subject\r\n        self.multipart['From'] = self.config['EMAIL']\r\n        self.multipart['Date'] = formatdate(localtime=True)\r\n        if email is None and self.send_as_one:\r\n            self.multipart['To'] = \", \".join(self.addresses)\r\n        elif email is not None and self.send_as_one is False:\r\n            self.multipart['To'] = email\r\n        # add ccs\r\n        if self.ccs is not None and self.ccs:\r\n            self.multipart['Cc'] = \", \".join(self.ccs)\r\n        # add html and text body\r\n        html = MIMEText(self.html, 'html')\r\n        alt_text = MIMEText(self.text, 'plain')\r\n        self.multipart.attach(html)\r\n        self.multipart.attach(alt_text)\r\n        for file in self.files:\r\n            self.multipart.attach(file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_definition(query):\n    try:\n        return get_definition_api(query)\n    except:\n        raise\n\n    # http://api.wordnik.com:80/v4/word.json/discrimination/definitions?limit=200&includeRelated=true&sourceDictionaries=all&useCanonical=false&includeTags=false&api_key=a2a73e7b926c924fad7001ca3111acd55af2ffabf50eb4ae5\n    import json\n    payload = {'q': query, 'limit': 200, 'includeRelated': 'true', 'sourceDictionaries': 'all',\n               'useCanonical': 'false', 'includeTags': 'false',\n               'api_key': 'a2a73e7b926c924fad7001ca3111acd55af2ffabf50eb4ae5'}\n    url = 'http://api.wordnik.com:80/v4/word.json/%s/definitions' % query\n    r = requests.get(url, params=payload)\n    result = json.loads(r.text)\n    return result", "response": "Returns dictionary of id first names of people who posted on my wall\n    between start and end time"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef intversion(text=None):\n    try:\n        s = text\n\n        if not s:\n            s = version()\n\n        s = s.split('ubuntu')[0]\n        s = s.split(':')[-1]\n        s = s.split('+')[0]\n\n        # <100\n        if s.startswith('00'):\n            i = int(s[0:4])\n        # >=100\n        elif '.' in s:\n            ls = s.split('.')\n            ls += [0, 0, 0]\n            i = int(ls[0]) * 100 + int(ls[1]) * 10 + int(ls[2])\n    except ValueError:\n        print ('Can not parse version: %s' % text)\n        raise\n    return i", "response": "return version as int."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset current session id to flask globals", "response": "def set_current_session(session_id) -> bool:\r\n        \"\"\" Add session_id to flask globals for current request \"\"\"\r\n        try:\r\n            g.session_id = session_id\r\n            return True\r\n        except (Exception, BaseException) as error:\r\n            # catch all on config update\r\n            if current_app.config['DEBUG']:\r\n                print(error)\r\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_session(cls, session_id, user_id):\r\n        count = SessionModel.count(user_id)\r\n        if count < current_app.config['AUTH']['MAX_SESSIONS']:\r\n            cls.__save_session(session_id, user_id)\r\n            return\r\n        elif count >= current_app.config['AUTH']['MAX_SESSIONS']:\r\n            earliest_session = SessionModel.where_earliest(user_id)\r\n            earliest_session.delete()\r\n            cls.__save_session(session_id, user_id)\r\n            return", "response": "Create a new session."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef visit_member(self, attribute_key, attribute, member_node, member_data,\n                     is_link_node, parent_data, index=None):\n        \"\"\"\n        Visits a member node in a resource data tree.\n\n        :param tuple attribute_key: tuple containing the attribute tokens\n          identifying the member node's position in the resource data tree.\n        :param attribute: mapped attribute holding information about the\n          member node's name (in the parent) and type etc.\n        :type attribute:\n          :class:`everest.representers.attributes.MappedAttribute`\n        :param member_node: the node holding resource data. This is either a\n          resource instance (when using a :class:`ResourceTreeTraverser` on\n          a tree of resources) or a data element instance (when using a\n          :class:`DataElementTreeTraverser` on a data element tree.\n        :param dict member_data: dictionary holding all member data\n          extracted during traversal (with mapped attributes as keys).\n        :param bool is_link_node: indicates if the given member node is a link.\n        :param dict parent_data: dictionary holding all parent data extracted\n          during traversal (with mapped attributes as keys).\n        :param int index: this indicates a member node's index in a collection\n          parent node. If the parent node is a member node, it will be `None`.\n        \"\"\"\n        raise NotImplementedError('Abstract method.')", "response": "Visit a member node in a resource data tree."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_relationship(self, attribute):\n        rel = self.__relationships.get(attribute.entity_attr)\n        if rel is None:\n            rel = LazyDomainRelationship(self, attribute,\n                                         direction=\n                                            self.relationship_direction)\n            self.__relationships[attribute.entity_attr] = rel\n        return rel", "response": "Returns the domain relationship object for the given resource and attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef establish_rabbitmq_connection(rabbitmq_uri):\n    userid, password, host, port, virtual_host, ssl = translate_rabbitmq_url(rabbitmq_uri)\n\n    connection = Connection(userid=userid,\n                            password=password,\n                            host=host,\n                            port=port,\n                            virtual_host=virtual_host,\n                            ssl=False)\n\n    return connection", "response": "Establish a connection to a RabbitMQ server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npublishing a simple notification.", "response": "def simple_notification(connection, queue_name, exchange_name, routing_key, text_body):\n    \"\"\"\n    Publishes a simple notification.\n\n    Inputs: - connection: A rabbitmq connection object.\n            - queue_name: The name of the queue to be checked or created.\n            - exchange_name: The name of the notification exchange.\n            - routing_key: The routing key for the exchange-queue binding.\n            - text_body: The text to be published.\n    \"\"\"\n    channel = connection.channel()\n    try:\n        channel.queue_declare(queue_name, durable=True, exclusive=False, auto_delete=False)\n    except PreconditionFailed:\n        pass\n    try:\n        channel.exchange_declare(exchange_name, type=\"fanout\", durable=True, auto_delete=False)\n    except PreconditionFailed:\n        pass\n    channel.queue_bind(queue_name, exchange_name, routing_key=routing_key)\n\n    message = Message(text_body)\n    channel.basic_publish(message, exchange_name, routing_key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fmt_datetime(d, fmt='', local=True):\n    if not d:\n        return ''\n    if local:\n        from django.templatetags.tz import localtime\n        d = localtime(d)\n    if not fmt:\n        fmt = '%Y-%m-%d %H-%M'\n    return d.strftime(fmt)", "response": "format datetime to format"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_url(self, url_or_dict):\n        if isinstance(url_or_dict, basestring):\n            url_or_dict = {'viewname': url_or_dict}\n        try:\n            return reverse(**url_or_dict)\n        except NoReverseMatch:\n            if MENU_DEBUG:\n                print >>stderr,'Unable to reverse URL with kwargs %s' % url_or_dict", "response": "Returns the reverse url given a string or dict and prints errors if MENU_DEBUG is enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_time(self):\n        if isinstance(self.path, pathlib.Path):\n            thetime = self.path.stat().st_mtime\n        else:\n            thetime = np.nan\n        return thetime", "response": "Return the modification time of the TIFF file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning QPImage with background correction", "response": "def get_qpimage_raw(self, idx=0):\n        \"\"\"Return QPImage without background correction\"\"\"\n        # Load experimental data\n        with SingleTifHolo._get_tif(self.path) as tf:\n            holo = tf.pages[0].asarray()\n        meta_data = copy.copy(self.meta_data)\n        qpi = qpimage.QPImage(data=(holo),\n                              which_data=\"hologram\",\n                              meta_data=meta_data,\n                              holo_kw=self.holo_kw,\n                              h5dtype=self.as_type)\n        # set identifier\n        qpi[\"identifier\"] = self.get_identifier()\n        qpi[\"time\"] = self.get_time()\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef verify(path):\n        valid = False\n        try:\n            tf = SingleTifHolo._get_tif(path)\n        except (ValueError, IsADirectoryError):\n            pass\n        else:\n            if len(tf) == 1:\n                valid = True\n        return valid", "response": "Verify that path is a valid TIFF file"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add(entry_point, all_entry_points, auto_write, scripts_path):\n    '''Add Scrim scripts for a python project'''\n\n    click.echo()\n    if not entry_point and not all_entry_points:\n        raise click.UsageError(\n            'Missing required option: --entry_point or --all_entry_points'\n        )\n    if not os.path.exists('setup.py'):\n        raise click.UsageError('No setup.py found.')\n\n    setup_data = parse_setup('setup.py')\n    console_scripts = get_console_scripts(setup_data)\n\n    scripts = []\n    if all_entry_points and console_scripts:\n\n        # Make sure our entry points start with py\n        for entry in console_scripts:\n            if not entry.startswith('py'):\n                click.echo('Your python entry_points must start with py.')\n                click.echo('Found: ' + entry)\n                raise click.Abort()\n\n        for entry in console_scripts:\n            click.echo('Found entry_point: ' + entry)\n            py_entry_point = entry\n            entry_point = entry[2:]\n            more_scripts = copy_templates(\n                entry_point,\n                py_entry_point,\n                auto_write,\n                scripts_path\n            )\n\n            for script in more_scripts:\n                click.echo('    Created ' + script)\n\n            scripts.extend(more_scripts)\n\n    elif entry_point:\n        if not entry_point.startswith('py'):\n            click.echo('Your python entry_points must start with py.')\n            raise click.Abort()\n        if entry_point not in console_scripts:\n            click.echo(entry_point + ' not found in your setups entry_points')\n            click.echo('You will need to add it afterward if you continue...')\n            click.echo('')\n            click.confirm('Do you want to continue?', abort=True)\n\n        click.echo('\\nCreating scripts for: ' + entry_point)\n        py_entry_point = entry_point\n        entry_point = entry_point[2:]\n        more_scripts = copy_templates(\n            entry_point,\n            py_entry_point,\n            auto_write,\n            scripts_path\n        )\n\n        for script in more_scripts:\n            click.echo('    Created ' + script)\n\n        scripts.extend(more_scripts)\n\n    click.echo('\\n\\nAdd the following section to your package setup:\\n')\n    click.echo('scripts=[')\n    for script in scripts:\n        click.echo(\"    '{}',\".format(script))\n    click.echo('],')", "response": "Add Scrim scripts for a python project."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists of songs in the playlist", "response": "async def songs(self):\n    '''list of songs in the playlist\n\n    |force|\n\n    |coro|\n\n    Returns\n    -------\n    list\n      of type :class:`embypy.objects.Audio`\n    '''\n    items = []\n    for i in await self.items:\n      if i.type == 'Audio':\n        items.append(i)\n      elif hasattr(i, 'songs'):\n        items.extend(await i.songs)\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd items to the playlist |coro|", "response": "async def add_items(self, *items):\n    '''append items to the playlist\n\n    |coro|\n\n    Parameters\n    ----------\n    items : array_like\n      list of items to add(or their ids)\n\n    See Also\n    --------\n      remove_items :\n    '''\n    items = [item.id for item in await self.process(items)]\n    if not items:\n      return\n\n    await self.connector.post('Playlists/{Id}/Items'.format(Id=self.id),\n      data={'Ids': ','.join(items)}, remote=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving items from the playlist |coro|", "response": "async def remove_items(self, *items):\n    '''remove items from the playlist\n\n    |coro|\n\n    Parameters\n    ----------\n    items : array_like\n      list of items to remove(or their ids)\n\n    See Also\n    --------\n      add_items :\n    '''\n    items = [i.id for i in (await self.process(items)) if i in self.items]\n    if not items:\n      return\n\n    await self.connector.delete(\n      'Playlists/{Id}/Items'.format(Id=self.id),\n      EntryIds=','.join(items),\n      remote=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nlist of movies in the collection |force| |coro| Returns ------- list of movies in the collection |force| |coro| Returns ------- list of movies in the collection |force| |", "response": "async def movies(self):\n    '''list of movies in the collection\n\n    |force|\n\n    |coro|\n\n    Returns\n    -------\n    list\n      of type :class:`embypy.objects.Movie`\n    '''\n    items = []\n    for i in await self.items:\n      if i.type == 'Movie':\n        items.append(i)\n      elif hasattr(i, 'movies'):\n        items.extend(await i.movies)\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nlists of series in the collection |force| |coro| Returns ------- list of series in the collection |force| |coro|", "response": "async def series(self):\n    '''list of series in the collection\n\n    |force|\n\n    |coro|\n\n    Returns\n    -------\n    list\n      of type :class:`embypy.objects.Series`\n    '''\n    items = []\n    for i in await self.items:\n      if i.type == 'Series':\n        items.append(i)\n      elif hasattr(i, 'series'):\n        items.extend(await i.series)\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef save(self, *args, **kwargs):\n        if not self.target:\n            self.target = str(self.content_object)\n        if not self.actor_name:\n            self.actor_name = str(self.actor)\n        super(Activity, self).save()", "response": "Store a string representation of content_object as target\n            and actor name for fast retrieval and sorting."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning string with actor and verb allowing target and object to be filled in manually.", "response": "def short_action_string(self):\n        \"\"\"\n        Returns string with actor and verb, allowing target/object\n        to be filled in manually.\n\n        Example:\n        [actor] [verb] or\n        \"Joe cool posted a comment\"\n        \"\"\"\n        output = \"{0} \".format(self.actor)\n        if self.override_string:\n            output += self.override_string\n        else:\n            output += self.verb\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nattempts to provide a representative image from a content object based on the content object s get_image method.", "response": "def image(self):\n        \"\"\"\n        Attempts to provide a representative image from a content_object based on\n        the content object's get_image() method.\n\n        If there is a another content.object, as in the case of comments and other GFKs,\n        then it will follow to that content_object and then get the image.\n\n        Requires get_image() to be defined on the related model even if it just\n        returns object.image, to avoid bringing back images you may not want.\n\n        Note that this expects the image only. Anything related (caption, etc) should be stripped.\n\n        \"\"\"\n        obj = self.content_object\n        # First, try to get from a get_image() helper method\n        try:\n            image = obj.get_image()\n        except AttributeError:\n            try:\n                image = obj.content_object.get_image()\n            except:\n                image = None\n\n        # if we didn't find one, try to get it from foo.image\n        # This allows get_image to take precedence for greater control.\n        if not image:\n            try:\n                image = obj.image\n            except AttributeError:\n                try:\n                    image = obj.content_object.image\n                except:\n                    return None\n\n        # Finally, ensure we're getting an image, not an image object\n        # with caption and byline and other things.\n        try:\n            return image.image\n        except AttributeError:\n            return image"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the version of the package.", "response": "def getversion(package):\n    \"\"\"\n    Obtain the ``__version__`` for ``package``, looking at the egg information\n    or the source repository's version control if necessary.\n    \"\"\"\n    distribution = get_distribution(package)\n    if distribution is None:\n        raise RuntimeError(\"Can't find distribution {0}\".format(package))\n    repo_type = get_repo_type(distribution.location)\n    if repo_type is None:\n        return distribution.version\n\n    return repo_type.get_version(distribution.location)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef version_from_frame(frame):\n\n    module = getmodule(frame)\n    if module is None:\n        s = \"<unknown from {0}:{1}>\"\n        return s.format(frame.f_code.co_filename, frame.f_lineno)\n\n    module_name = module.__name__\n\n    variable = \"AUTOVERSION_{}\".format(module_name.upper())\n    override = os.environ.get(variable, None)\n    if override is not None:\n        return override\n\n    while True:\n        try:\n            get_distribution(module_name)\n        except DistributionNotFound:\n            # Look at what's to the left of \".\"\n            module_name, dot, _ = module_name.partition(\".\")\n            if dot == \"\":\n                # There is no dot, nothing more we can do.\n                break\n        else:\n            return getversion(module_name)\n\n    return None", "response": "Given a frame obtain the version number of the module running there."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef try_fix_num(n):\n    if not n.isdigit():\n        return n\n    if n.startswith(\"0\"):\n        n = n.lstrip(\"0\")\n    if not n:\n        n = \"0\"\n    return int(n)", "response": "Try to convert n to an integer if it is numeric otherwise return the input\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits version into a lexicographically comparable tuple.", "response": "def tupleize_version(version):\n    \"\"\"\n    Split ``version`` into a lexicographically comparable tuple.\n\n    \"1.0.3\" -> ((1, 0, 3),)\n    \"1.0.3-dev\" -> ((1, 0, 3), (\"dev\",))\n    \"1.0.3-rc-5\" -> ((1, 0, 3), (\"rc\",), (5,))\n    \"\"\"\n\n    if version is None:\n        return ((\"unknown\",),)\n\n    if version.startswith(\"<unknown\"):\n        return ((\"unknown\",),)\n\n    split = re.split(\"(?:\\.|(-))\", version)\n    parsed = tuple(try_fix_num(x) for x in split if x)\n\n    # Put the tuples in groups by \"-\"\n    def is_dash(s):\n        return s == \"-\"\n    grouped = groupby(parsed, is_dash)\n\n    return tuple(tuple(group) for dash, group in grouped if not dash)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a string describing the version of the repository at path.", "response": "def get_version(cls, path, memo={}):\n        \"\"\"\n        Return a string describing the version of the repository at ``path`` if\n        possible, otherwise throws ``subprocess.CalledProcessError``.\n\n        (Note: memoizes the result in the ``memo`` parameter)\n        \"\"\"\n        if path not in memo:\n            memo[path] = subprocess.check_output(\n                \"git describe --tags --dirty 2> /dev/null\",\n                shell=True, cwd=path).strip().decode(\"utf-8\")\n\n            v = re.search(\"-[0-9]+-\", memo[path])\n            if v is not None:\n                # Replace -n- with -branchname-n-\n                branch = r\"-{0}-\\1-\".format(cls.get_branch(path))\n                (memo[path], _) = re.subn(\"-([0-9]+)-\", branch, memo[path], 1)\n\n        return memo[path]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_repo_instance(cls, path):\n        try:\n            cls.get_version(path)\n            return True\n        except subprocess.CalledProcessError:\n            # Git returns non-zero status\n            return False\n        except OSError:\n            # Git unavailable?\n            return False", "response": "Return True if path is a source controlled repository."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the line number for something.", "response": "def get_line(thing):\n    \"\"\"\n    Get the line number for something.\n    Parameters\n    ----------\n    thing : function, class, module\n\n    Returns\n    -------\n    int\n        Line number in the source file\n    \"\"\"\n    try:\n        return inspect.getsourcelines(thing)[1]\n    except TypeError:\n        # Might be a property\n        return inspect.getsourcelines(thing.fget)[1]\n    except Exception as e:\n        # print(thing)\n        raise e"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsort modules in order of name.", "response": "def _sort_modules(mods):\n    \"\"\" Always sort `index` or `README` as first filename in list. \"\"\"\n\n    def compare(x, y):\n        x = x[1]\n        y = y[1]\n        if x == y:\n            return 0\n        if y.stem == \"__init__.py\":\n            return 1\n        if x.stem == \"__init__.py\" or x < y:\n            return -1\n        return 1\n\n    return sorted(mods, key=cmp_to_key(compare))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a References section from a dictionary produced by numpydoc", "response": "def refs_section(doc):\n    \"\"\"\n    Generate a References section.\n\n    Parameters\n    ----------\n    doc : dict\n        Dictionary produced by numpydoc\n\n    Returns\n    -------\n    list of str\n        Markdown for references section\n    \"\"\"\n    lines = []\n    if \"References\" in doc and len(doc[\"References\"]) > 0:\n        # print(\"Found refs\")\n        for ref in doc[\"References\"]:\n            # print(ref)\n            ref_num = re.findall(\"\\[([0-9]+)\\]\", ref)[0]\n            # print(ref_num)\n            ref_body = \" \".join(ref.split(\" \")[2:])\n            # print(f\"[^{ref_num}] {ref_body}\" + \"\\n\")\n            lines.append(f\"[^{ref_num}]: {ref_body}\" + \"\\n\\n\")\n            # print(lines)\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating markdown for examples section.", "response": "def examples_section(doc, header_level):\n    \"\"\"\n    Generate markdown for Examples section.\n\n    Parameters\n    ----------\n    doc : dict\n        Dict from numpydoc\n    header_level : int\n        Number of `#`s to use for header\n\n    Returns\n    -------\n    list of str\n        Markdown for examples section\n    \"\"\"\n    lines = []\n    if \"Examples\" in doc and len(doc[\"Examples\"]) > 0:\n        lines.append(f\"{'#'*(header_level+1)} Examples \\n\")\n        egs = \"\\n\".join(doc[\"Examples\"])\n        lines += mangle_examples(doc[\"Examples\"])\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef returns_section(thing, doc, header_level):\n    lines = []\n    return_type = None\n    try:\n        return_type = thing.__annotations__[\"return\"]\n    except AttributeError:\n        try:\n            return_type = thing.fget.__annotations__[\"return\"]\n        except:\n            pass\n    except KeyError:\n        pass\n    if return_type is None:\n        return_type = \"\"\n    else:\n        # print(f\"{thing} has annotated return type {return_type}\")\n        try:\n            return_type = (\n                f\"{return_type.__name__}\"\n                if return_type.__module__ == \"builtins\"\n                else f\"{return_type.__module__}.{return_type.__name__}\"\n            )\n        except AttributeError:\n            return_type = str(return_type)\n        # print(return_type)\n\n    try:\n        if \"Returns\" in doc and len(doc[\"Returns\"]) > 0 or return_type != \"\":\n            lines.append(f\"{'#'*(header_level+1)} Returns\\n\")\n            if return_type != \"\" and len(doc[\"Returns\"]) == 1:\n                name, typ, desc = doc[\"Returns\"][0]\n                if typ != \"\":\n                    lines.append(f\"- `{name}`: ``{return_type}``\")\n                else:\n                    lines.append(f\"- ``{return_type}``\")\n                lines.append(\"\\n\\n\")\n                if desc != \"\":\n                    lines.append(f\"    {' '.join(desc)}\\n\\n\")\n            elif return_type != \"\":\n                lines.append(f\"- ``{return_type}``\")\n                lines.append(\"\\n\\n\")\n            else:\n                for name, typ, desc in doc[\"Returns\"]:\n                    if \":\" in name:\n                        name, typ = name.split(\":\")\n\n                    if typ != \"\":\n                        line = f\"- `{name}`: {mangle_types(typ)}\"\n                    else:\n                        line = f\"- {mangle_types(name)}\"\n                    line += \"\\n\\n\"\n                    lines.append(line)\n                    lines.append(f\"    {' '.join(desc)}\\n\\n\")\n    except Exception as e:\n        # print(e)\n        # print(doc)\n        pass\n    return lines", "response": "Generates markdown for returns section for a given function and doc."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef summary(doc):\n    lines = []\n    if \"Summary\" in doc and len(doc[\"Summary\"]) > 0:\n        lines.append(fix_footnotes(\" \".join(doc[\"Summary\"])))\n        lines.append(\"\\n\")\n    if \"Extended Summary\" in doc and len(doc[\"Extended Summary\"]) > 0:\n        lines.append(fix_footnotes(\" \".join(doc[\"Extended Summary\"])))\n        lines.append(\"\\n\")\n    return lines", "response": "Generate markdown for summary section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef params_section(thing, doc, header_level):\n    lines = []\n\n    class_doc = doc[\"Parameters\"]\n    return type_list(\n        inspect.signature(thing),\n        class_doc,\n        \"#\" * (header_level + 1) + \" Parameters\\n\\n\",\n    )", "response": "Generate markdown for Parameters section."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_source_link(thing, source_location):\n    try:\n        lineno = get_line(thing)\n        try:\n            owner_module = inspect.getmodule(thing)\n            assert owner_module is not None\n        except (TypeError, AssertionError):\n            owner_module = inspect.getmodule(thing.fget)\n\n        thing_file = \"/\".join(owner_module.__name__.split(\".\"))\n        if owner_module.__file__.endswith(\"__init__.py\"):\n            thing_file += \"/__init__.py\"\n        else:\n            thing_file += \".py\"\n        return (\n            f\"Source: [{escape(thing_file)}]({source_location}/{thing_file}#L{lineno})\"\n            + \"\\n\\n\"\n        )\n    except Exception as e:\n        # print(\"Failed to find source file.\")\n        # print(e)\n        # print(lineno)\n        # print(thing)\n        # print(owner_module)\n        # print(thing_file)\n        # print(source_location)\n        pass\n    return \"\"", "response": "Get a link to the line number a module or class or function is defined at."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_signature(name, thing):\n    if inspect.ismodule(thing):\n        return \"\"\n    if isinstance(thing, property):\n        func_sig = name\n    else:\n        try:\n            sig = inspect.signature(thing)\n        except TypeError:\n            sig = inspect.signature(thing.fget)\n        except ValueError:\n            return \"\"\n        func_sig = f\"{name}{sig}\"\n        try:\n            mode = black.FileMode(line_length=80)\n            func_sig = black.format_str(func_sig, mode=mode).strip()\n        except (ValueError, TypeError):\n            pass\n    return f\"```python\\n{func_sig}\\n```\\n\"", "response": "Get the signature for a function or class or class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_names(names, types):\n    if types == \"\":\n        try:\n            names, types = names.split(\":\")\n        except:\n            pass\n    return names.split(\",\"), types", "response": "Get names and types from a list of names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef string_annotation(typ, default):\n    try:\n        type_string = (\n            f\"`{typ.__name__}`\"\n            if typ.__module__ == \"builtins\"\n            else f\"`{typ.__module__}.{typ.__name__}`\"\n        )\n    except AttributeError:\n        type_string = f\"`{str(typ)}`\"\n    if default is None:\n        type_string = f\"{type_string}, default ``None``\"\n    elif default == inspect._empty:\n        pass\n    else:\n        type_string = f\"{type_string}, default ``{default}``\"\n    return type_string", "response": "Construct a string representation of a type annotation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef type_list(signature, doc, header):\n\n    lines = []\n    docced = set()\n    lines.append(header)\n    try:\n        for names, types, description in doc:\n            names, types = _get_names(names, types)\n            unannotated = []\n            for name in names:\n                docced.add(name)\n                try:\n                    typ = signature.parameters[name].annotation\n                    if typ == inspect._empty:\n                        raise AttributeError\n                    default = signature.parameters[name].default\n                    type_string = string_annotation(typ, default)\n                    lines.append(f\"- `{name}`: {type_string}\")\n                    lines.append(\"\\n\\n\")\n                except (AttributeError, KeyError):\n                    unannotated.append(name)  # No annotation\n\n            if len(unannotated) > 0:\n                lines.append(\"- \")\n                lines.append(\", \".join(f\"`{name}`\" for name in unannotated))\n                if types != \"\" and len(unannotated) > 0:\n                    lines.append(f\": {mangle_types(types)}\")\n            lines.append(\"\\n\\n\")\n            lines.append(f\"    {' '.join(description)}\\n\\n\")\n        for names, types, description in doc:\n            names, types = _get_names(names, types)\n            for name in names:\n                if name not in docced:\n                    try:\n                        typ = signature.parameters[name].annotation\n                        default = signature.parameters[name].default\n                        type_string = string_annotation(typ, default)\n                        lines.append(f\"- `{name}`: {type_string}\")\n                        lines.append(\"\\n\\n\")\n                    except (AttributeError, KeyError):\n                        lines.append(f\"- `{name}`\")\n                        lines.append(\"\\n\\n\")\n    except Exception as e:\n        print(e)\n    return lines if len(lines) > 1 else []", "response": "Construct a list of types preferring type annotations to the list of docstrings if they are available."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nseparate properties from other kinds of member.", "response": "def _split_props(thing, doc):\n    \"\"\"\n    Separate properties from other kinds of member.\n    \"\"\"\n    props = inspect.getmembers(thing, lambda o: isinstance(o, property))\n    ps = []\n    docs = [\n        (*_get_names(names, types), names, types, desc) for names, types, desc in doc\n    ]\n    for prop_name, prop in props:\n        in_doc = [d for d in enumerate(docs) if prop_name in d[0]]\n        for d in in_doc:\n            docs.remove(d)\n        ps.append(prop_name)\n    if len(docs) > 0:\n        _, _, names, types, descs = zip(*docs)\n        return ps, zip(names, types, descs)\n    return ps, []"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attributes_section(thing, doc, header_level):\n    # Get Attributes\n\n    if not inspect.isclass(thing):\n        return []\n\n    props, class_doc = _split_props(thing, doc[\"Attributes\"])\n    tl = type_list(inspect.signature(thing), class_doc, \"\\n### Attributes\\n\\n\")\n    if len(tl) == 0 and len(props) > 0:\n        tl.append(\"\\n### Attributes\\n\\n\")\n    for prop in props:\n        tl.append(f\"- [`{prop}`](#{prop})\\n\\n\")\n    return tl", "response": "Generates an attributes section for classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a markdown for an enum", "response": "def enum_doc(name, enum, header_level, source_location):\n    \"\"\"\n    Generate markdown for an enum\n\n    Parameters\n    ----------\n    name : str\n        Name of the thing being documented\n    enum : EnumMeta\n        Enum to document\n    header_level : int\n        Heading level\n    source_location : str\n        URL of repo containing source code\n    \"\"\"\n\n    lines = [f\"{'#'*header_level} Enum **{name}**\\n\\n\"]\n    lines.append(f\"```python\\n{name}\\n```\\n\")\n    lines.append(get_source_link(enum, source_location))\n    try:\n        doc = NumpyDocString(inspect.getdoc(thing))._parsed_data\n        lines += summary(doc)\n    except:\n        pass\n    lines.append(f\"{'#'*(header_level + 1)} Members\\n\\n\")\n    lines += [f\"- `{str(v).split('.').pop()}`: `{v.value}` \\n\\n\" for v in enum]\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating markdown for a class or function or function.", "response": "def to_doc(name, thing, header_level, source_location):\n    \"\"\"\n    Generate markdown for a class or function\n\n    Parameters\n    ----------\n    name : str\n        Name of the thing being documented\n    thing : class or function\n        Class or function to document\n    header_level : int\n        Heading level\n    source_location : str\n        URL of repo containing source code\n    \"\"\"\n\n    if type(thing) is enum.EnumMeta:\n        return enum_doc(name, thing, header_level, source_location)\n    if inspect.isclass(thing):\n        header = f\"{'#'*header_level} Class **{name}**\\n\\n\"\n    else:\n        header = f\"{'#'*header_level} {name}\\n\\n\"\n    lines = [\n        header,\n        get_signature(name, thing),\n        get_source_link(thing, source_location),\n    ]\n\n    try:\n        doc = NumpyDocString(inspect.getdoc(thing))._parsed_data\n        lines += summary(doc)\n        lines += attributes_section(thing, doc, header_level)\n        lines += params_section(thing, doc, header_level)\n        lines += returns_section(thing, doc, header_level)\n        lines += examples_section(doc, header_level)\n        lines += notes_section(doc)\n        lines += refs_section(doc)\n    except Exception as e:\n        # print(f\"No docstring for {name}, src {source_location}: {e}\")\n        pass\n    return lines"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doc_module(module_name, module, output_dir, source_location, leaf):\n    path = pathlib.Path(output_dir).joinpath(*module.__name__.split(\".\"))\n    available_classes = get_available_classes(module)\n    deffed_classes = get_classes(module)\n    deffed_funcs = get_funcs(module)\n    deffed_enums = get_enums(module)\n    alias_funcs = available_classes - deffed_classes\n    if leaf:\n        doc_path = path.with_suffix(\".md\")\n    else:\n        doc_path = path / \"index.md\"\n    doc_path.parent.mkdir(parents=True, exist_ok=True)\n    module_path = \"/\".join(module.__name__.split(\".\"))\n    doc = [f\"title: {module_name.split('.')[-1]}\" + \"\\n\"]\n    module_doc = module.__doc__\n\n    # Module overview documentation\n    if module_doc is not None:\n        doc += to_doc(module.__name__, module, 1, source_location)\n    else:\n        doc.append(f\"# {module.__name__}\\n\\n\")\n    doc.append(\"\\n\\n\")\n    for cls_name, cls in sorted(deffed_enums) + sorted(deffed_classes):\n        doc += to_doc(cls_name, cls, 2, source_location)\n\n        class_methods = [\n            x\n            for x in inspect.getmembers(cls, inspect.isfunction)\n            if (not x[0].startswith(\"_\")) and deffed_here(x[1], cls)\n        ]\n        class_methods += inspect.getmembers(cls, lambda o: isinstance(o, property))\n        if len(class_methods) > 0:\n            doc.append(\"### Methods \\n\\n\")\n            for method_name, method in class_methods:\n                doc += to_doc(method_name, method, 4, source_location)\n    for fname, func in sorted(deffed_funcs):\n        doc += to_doc(fname, func, 2, source_location)\n    return doc_path.absolute(), \"\".join(doc)", "response": "Generates a module s documentation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_color(fg=None, bg=None):\n    if fg or bg:\n        _color_manager.set_color(fg, bg)\n    else:\n        _color_manager.set_defaults()", "response": "Set the current colors."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cprint(string, fg=None, bg=None, end='\\n', target=sys.stdout):\n    _color_manager.set_color(fg, bg)\n    target.write(string + end)\n    target.flush()  # Needed for Python 3.x\n    _color_manager.set_defaults()", "response": "Print a string to the target handle."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse and print a colored and perhaps formatted string.", "response": "def fprint(fmt, *args, **kwargs):\n    \"\"\"Parse and print a colored and perhaps formatted string.\n\n    The remaining keyword arguments are the same as for Python's built-in print\n    function. Colors are returning to their defaults before the function\n    returns.\n\n    \"\"\"\n    if not fmt:\n        return\n\n    hascolor = False\n    target = kwargs.get(\"target\", sys.stdout)\n\n    # Format the string before feeding it to the parser\n    fmt = fmt.format(*args, **kwargs)\n\n    for txt, markups in _color_format_parser.parse(fmt):\n        if markups != (None, None):\n            _color_manager.set_color(*markups)\n            hascolor = True\n        else:\n            if hascolor:\n                _color_manager.set_defaults()\n                hascolor = False\n\n        target.write(txt)\n        target.flush()  # Needed for Python 3.x\n\n    _color_manager.set_defaults()\n    target.write(kwargs.get('end', '\\n'))\n    _color_manager.set_defaults()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef formatcolor(string, fg=None, bg=None):\n    if fg is bg is None:\n        return string\n\n    temp = (['fg='+fg] if fg else []) +\\\n           (['bg='+bg] if bg else [])\n    fmt = _color_format_parser._COLOR_DELIM.join(temp)\n\n    return _color_format_parser._START_TOKEN + fmt +\\\n        _color_format_parser._FMT_TOKEN + string +\\\n        _color_format_parser._STOP_TOKEN", "response": "Wrap color syntax around a string and return it."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef formatbyindex(string, fg=None, bg=None, indices=[]):\n    if not string or not indices or (fg is bg is None):\n        return string\n\n    result, p = '', 0\n\n    # The lambda syntax is necessary to support both Python 2 and 3\n    for k, g in itertools.groupby(enumerate(sorted(indices)),\n                                  lambda x: x[0]-x[1]):\n        tmp = list(map(operator.itemgetter(1), g))\n        s, e = tmp[0], tmp[-1]+1\n\n        if s < len(string):\n            result += string[p:s]\n            result += formatcolor(string[s:e], fg, bg)\n            p = e\n\n    if p < len(string):\n        result += string[p:]\n\n    return result", "response": "Wrap color syntax around characters using indices and return it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhighlights characters using indices and print it to the target handle.", "response": "def highlight(string, fg=None, bg=None, indices=[], end='\\n',\n              target=sys.stdout):\n    \"\"\"Highlight characters using indices and print it to the target handle.\n\n    fg and bg specify foreground- and background colors, respectively. The\n    remaining keyword arguments are the same as for Python's built-in print\n    function.\n\n    \"\"\"\n    if not string or not indices or (fg is bg is None):\n        return\n\n    p = 0\n\n    # The lambda syntax is necessary to support both Python 2 and 3\n    for k, g in itertools.groupby(enumerate(sorted(indices)),\n                                  lambda x: x[0]-x[1]):\n        tmp = list(map(operator.itemgetter(1), g))\n        s, e = tmp[0], tmp[-1]+1\n        target.write(string[p:s])\n        target.flush()  # Needed for Python 3.x\n        _color_manager.set_color(fg, bg)\n        target.write(string[s:e])\n        target.flush()  # Needed for Python 3.x\n        _color_manager.set_defaults()\n        p = e\n\n    if p < len(string):\n        target.write(string[p:])\n\n    target.write(end)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_param_info(task_params, parameter_map):\n    gp_params = []\n    gp_param_list = []\n    gp_param_idx_list = []\n    gp_param_idx = 0\n    for task_param in task_params:\n        # Setup to gp_param dictionary used to substitute against the parameter info template.\n        gp_param = {}\n\n        # Convert DataType\n        data_type = task_param['type'].upper()\n        if 'dimensions' in task_param:\n            if len(task_param['dimensions'].split(',')) > 1:\n                raise UnknownDataTypeError('Only one-dimensional arrays are supported.')\n            data_type += 'ARRAY'\n\n        if data_type in parameter_map:\n            gp_param['dataType'] = parameter_map[data_type].data_type\n        else:\n            # No Mapping exists for this data type!\n            raise UnknownDataTypeError('Unable to map task datatype: ' +\n                                       data_type +\n                                       '.  A template must be created.')\n\n        gp_param['name'] = task_param['name']\n        gp_param['displayName'] = task_param['display_name']\n        gp_param['direction'] = _DIRECTION_MAP[task_param['direction']]\n        gp_param['paramType'] = 'Required' if task_param['required'] else 'Optional'\n        # ENVI/IDL output type translates to a derived output type in Arc\n        if gp_param['direction'] is 'Output':\n            gp_param['paramType'] = 'Derived'\n\n        gp_param['multiValue'] = True if 'dimensions' in task_param else False\n\n        # Substitute values into the template\n        gp_params.append(parameter_map[data_type].get_parameter(task_param).substitute(gp_param))\n\n        # Convert the default value\n        if 'default_value' in task_param:\n            gp_param['defaultValue'] = task_param['default_value']\n            gp_params.append(parameter_map[data_type].default_value().substitute(gp_param))\n\n        # Convert any choicelist\n        if 'choice_list' in task_param:\n            gp_param['choiceList'] = task_param['choice_list']\n            gp_params.append(_CHOICELIST_TEMPLATE.substitute(gp_param))\n\n        # Construct the parameter list and indicies for future reference\n        for param_name in parameter_map[data_type].parameter_names(task_param):\n            gp_param_list.append(param_name.substitute(gp_param))\n            gp_param_idx_list.append(_PARAM_INDEX_TEMPLATE.substitute(\n                {'name': param_name.substitute(gp_param),\n                 'idx': gp_param_idx}))\n            gp_param_idx += 1\n\n    # Construct the final parameter string\n    gp_params.append(_PARAM_RETURN_TEMPLATE.substitute({'paramList': convert_list(gp_param_list)}))\n    return ''.join((''.join(gp_params), ''.join(gp_param_idx_list)))", "response": "Creates the code block for the GPTool GetParameterInfo method based on the input task_params and returns the code block for the GPTool GetParameterInfo method."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the code block for the GPTool UpdateParameter method based on the input task_params.", "response": "def create_update_parameter(task_params, parameter_map):\n    \"\"\"\n    Builds the code block for the GPTool UpdateParameter method based on the input task_params.\n\n    :param task_params: A list of task parameters from the task info structure.\n    :return: A string representing the code block to the GPTool UpdateParameter method.\n    \"\"\"\n    gp_params = []\n    for param in task_params:\n        if param['direction'].upper() == 'OUTPUT':\n            continue\n\n        # Convert DataType\n        data_type = param['type'].upper()\n        if 'dimensions' in param:\n            data_type += 'ARRAY'\n\n        if data_type in parameter_map:\n            gp_params.append(parameter_map[data_type].update_parameter().substitute(param))\n\n    return ''.join(gp_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding the code block for the GPTool Execute method before the job isis submitted based on the input task_params.", "response": "def create_pre_execute(task_params, parameter_map):\n    \"\"\"\n    Builds the code block for the GPTool Execute method before the job is\n    submitted based on the input task_params.\n\n    :param task_params: A list of task parameters from the task info structure.\n    :return: A string representing the code block to the GPTool Execute method.\n    \"\"\"\n    gp_params = [_PRE_EXECUTE_INIT_TEMPLATE]\n    for task_param in task_params:\n        if task_param['direction'].upper() == 'OUTPUT':\n            continue\n\n        # Convert DataType\n        data_type = task_param['type'].upper()\n        if 'dimensions' in task_param:\n            data_type += 'ARRAY'\n\n        if data_type in parameter_map:\n            gp_params.append(parameter_map[data_type].pre_execute().substitute(task_param))\n\n    gp_params.append(_PRE_EXECUTE_CLEANUP_TEMPLATE)\n    return ''.join(gp_params)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild the code block for the GPTool Execute method after the job isisomeday submitted based on the input task_params.", "response": "def create_post_execute(task_params, parameter_map):\n    \"\"\"\n    Builds the code block for the GPTool Execute method after the job is\n    submitted based on the input task_params.\n\n    :param task_params: A list of task parameters from the task info structure.\n    :return: A string representing the code block to the GPTool Execute method.\n    \"\"\"\n\n    gp_params = []\n    for task_param in task_params:\n        if task_param['direction'].upper() == 'INPUT':\n            continue\n\n        # Convert DataType\n        data_type = task_param['type'].upper()\n        if 'dimensions' in task_param:\n            data_type += 'ARRAY'\n\n        if data_type in parameter_map:\n            gp_params.append(parameter_map[data_type].post_execute().substitute(task_param))\n\n    return ''.join(gp_params)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_default_templates(self):\n        for importer, modname, is_pkg in pkgutil.iter_modules(templates.__path__):\n            self.register_template('.'.join((templates.__name__, modname)))", "response": "Load the default templates"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a non - default template with the given module.", "response": "def register_template(self, module):\n        \"\"\"\n        Register a non-default template\n   \n        :param module: The full package path including the module name\n                    of the template to load.\n        \"\"\"\n        parameter_module = importlib.import_module(module)\n        parameter_template = parameter_module.template()\n        self.parameter_map[parameter_template.__class__.__name__.upper()] = \\\n            parameter_template"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    args = parser.parse_args()\n\n    scheduler = Scheduler()\n\n    print 'Start %s' % scheduler.scheduler_id\n    scheduler.interval = args.interval\n    if args.keepalive:\n        scheduler.run(once=True)\n        keepalive = Job('simplescheduler.keepalive',\n                        args=[0,\n                              scheduler.get_running_scheduler_id(),\n                              args.interval * 2])\n        scheduler.schedule(keepalive, long(time.time() * 1000000))\n    scheduler._run()", "response": "Simple scheduler main function"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_hwpack(name):\n    targ_dlib = hwpack_dir() / name\n    log.debug('remove %s', targ_dlib)\n    targ_dlib.rmtree()", "response": "remove hardware package.\n\n    :param name: hardware package name (e.g. 'Sanguino')\n    :rtype: None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_keyword(dist, _, value):\n    # type: (setuptools.dist.Distribution, str, bool) -> None\n    \"\"\"Add autodetected commands as entry points.\n\n    Args:\n        dist: The distutils Distribution object for the project being\n            installed.\n        _: The keyword used in the setup function. Unused.\n        value: The value set to the keyword in the setup function. If the value\n            is not True, this function will do nothing.\n    \"\"\"\n    if value is not True:\n        return\n    dist.entry_points = _ensure_entry_points_is_dict(dist.entry_points)\n\n    for command, subcommands in six.iteritems(_get_commands(dist)):\n        entry_point = '{command} = rcli.dispatcher:main'.format(\n            command=command)\n        entry_points = dist.entry_points.setdefault('console_scripts', [])\n        if entry_point not in entry_points:\n            entry_points.append(entry_point)\n        dist.entry_points.setdefault('rcli', []).extend(subcommands)", "response": "Add autodetected commands as entry points."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef egg_info_writer(cmd, basename, filename):\n    # type: (setuptools.command.egg_info.egg_info, str, str) -> None\n    \"\"\"Read rcli configuration and write it out to the egg info.\n\n    Args:\n        cmd: An egg info command instance to use for writing.\n        basename: The basename of the file to write.\n        filename: The full path of the file to write into the egg info.\n    \"\"\"\n    setupcfg = next((f for f in setuptools.findall()\n                     if os.path.basename(f) == 'setup.cfg'), None)\n    if not setupcfg:\n        return\n    parser = six.moves.configparser.ConfigParser()  # type: ignore\n    parser.read(setupcfg)\n    if not parser.has_section('rcli') or not parser.items('rcli'):\n        return\n    config = dict(parser.items('rcli'))  # type: typing.Dict[str, typing.Any]\n    for k, v in six.iteritems(config):\n        if v.lower() in ('y', 'yes', 'true'):\n            config[k] = True\n        elif v.lower() in ('n', 'no', 'false'):\n            config[k] = False\n        else:\n            try:\n                config[k] = json.loads(v)\n            except ValueError:\n                pass\n    cmd.write_file(basename, filename, json.dumps(config))", "response": "Writes out the rcli configuration and rcli. json file."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_commands(dist  # type: setuptools.dist.Distribution\n                  ):\n    # type: (...) -> typing.Dict[str, typing.Set[str]]\n    \"\"\"Find all commands belonging to the given distribution.\n\n    Args:\n        dist: The Distribution to search for docopt-compatible docstrings that\n            can be used to generate command entry points.\n\n    Returns:\n        A dictionary containing a mapping of primary commands to sets of\n        subcommands.\n    \"\"\"\n    py_files = (f for f in setuptools.findall()\n                if os.path.splitext(f)[1].lower() == '.py')\n    pkg_files = (f for f in py_files if _get_package_name(f) in dist.packages)\n    commands = {}  # type: typing.Dict[str, typing.Set[str]]\n    for file_name in pkg_files:\n        with open(file_name) as py_file:\n            module = typing.cast(ast.Module, ast.parse(py_file.read()))\n        module_name = _get_module_name(file_name)\n        _append_commands(commands, module_name, _get_module_commands(module))\n        _append_commands(commands, module_name, _get_class_commands(module))\n        _append_commands(commands, module_name, _get_function_commands(module))\n    return commands", "response": "Find all commands belonging to the given distribution."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _append_commands(dct,  # type: typing.Dict[str, typing.Set[str]]\n                     module_name,  # type: str\n                     commands  # type:typing.Iterable[_EntryPoint]\n                     ):\n    # type: (...) -> None\n    \"\"\"Append entry point strings representing the given Command objects.\n\n    Args:\n        dct: The dictionary to append with entry point strings. Each key will\n            be a primary command with a value containing a list of entry point\n            strings representing a Command.\n        module_name: The name of the module in which the command object\n            resides.\n        commands: A list of Command objects to convert to entry point strings.\n    \"\"\"\n    for command in commands:\n        entry_point = '{command}{subcommand} = {module}{callable}'.format(\n            command=command.command,\n            subcommand=(':{}'.format(command.subcommand)\n                        if command.subcommand else ''),\n            module=module_name,\n            callable=(':{}'.format(command.callable)\n                      if command.callable else ''),\n        )\n        dct.setdefault(command.command, set()).add(entry_point)", "response": "Appends the given list of commands to the given dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_module_commands(module):\n    # type: (ast.Module) -> typing.Generator[_EntryPoint, None, None]\n    \"\"\"Yield all Command objects represented by the python module.\n\n    Module commands consist of a docopt-style module docstring and a callable\n    Command class.\n\n    Args:\n        module: An ast.Module object used to retrieve docopt-style commands.\n\n    Yields:\n        Command objects that represent entry points to append to setup.py.\n    \"\"\"\n    cls = next((n for n in module.body\n                if isinstance(n, ast.ClassDef) and n.name == 'Command'), None)\n    if not cls:\n        return\n    methods = (n.name for n in cls.body if isinstance(n, ast.FunctionDef))\n    if '__call__' not in methods:\n        return\n    docstring = ast.get_docstring(module)\n    for commands, _ in usage.parse_commands(docstring):\n        yield _EntryPoint(commands[0], next(iter(commands[1:]), None), None)", "response": "Returns all Command objects represented by the python module."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all top - level functions that contain docopt - style docstrings.", "response": "def _get_function_commands(module):\n    # type: (ast.Module) -> typing.Generator[_EntryPoint, None, None]\n    \"\"\"Yield all Command objects represented by python functions in the module.\n\n    Function commands consist of all top-level functions that contain\n    docopt-style docstrings.\n\n    Args:\n        module: An ast.Module object used to retrieve docopt-style commands.\n\n    Yields:\n        Command objects that represent entry points to append to setup.py.\n    \"\"\"\n    nodes = (n for n in module.body if isinstance(n, ast.FunctionDef))\n    for func in nodes:\n        docstring = ast.get_docstring(func)\n        for commands, _ in usage.parse_commands(docstring):\n            yield _EntryPoint(commands[0], next(iter(commands[1:]), None),\n                              func.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a number of bytes into a human readable unit.", "response": "def convert(b):\n    '''\n    takes a number of bytes as an argument and returns the most suitable human\n    readable unit conversion.\n    '''\n    if b > 1024**3:\n        hr = round(b/1024**3)\n        unit = \"GB\"\n    elif b > 1024**2:\n        hr = round(b/1024**2)\n        unit = \"MB\"\n    else:\n        hr = round(b/1024)\n        unit = \"KB\"\n    return hr, unit"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncalculate the total size in bytes of the file or directory.", "response": "def calc(path):\n    '''\n    Takes a path as an argument and returns the total size in bytes of the file\n    or directory. If the path is a directory the size will be calculated\n    recursively.\n    '''\n    total = 0\n    err = None\n    if os.path.isdir(path):\n        try:\n            for entry in os.scandir(path):\n                try:\n                    is_dir = entry.is_dir(follow_symlinks=False)\n                except (PermissionError, FileNotFoundError):\n                    err = \"!\"\n                    return total, err\n                if is_dir:\n                    result = calc(entry.path)\n                    total += result[0]\n                    err = result[1]\n                    if err:\n                        return total, err\n                else:\n                    try:\n                        total += entry.stat(follow_symlinks=False).st_size\n                    except (PermissionError, FileNotFoundError):\n                        err = \"!\"\n                        return total, err\n        except (PermissionError, FileNotFoundError):\n            err = \"!\"\n            return total, err\n    else:\n        total += os.path.getsize(path)\n    return total, err"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nputs it all together!", "response": "def du(path):\n    '''\n    Put it all together!\n    '''\n    size, err = calc(path)\n    if err:\n        return err\n    else:\n        hr, unit = convert(size)\n        hr = str(hr)\n        result = hr + \" \" + unit\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsaves all objects from the activity monitor models listed in settings. TIMELINE_MODELS.", "response": "def handle(self, **kwargs):\n      \"\"\"\n      Simply re-saves all objects from models listed in settings.TIMELINE_MODELS. Since the timeline\n      app is now following these models, it will register each item as it is re-saved. The purpose of this\n      script is to register content in your database that existed prior to installing the timeline app.\n      \"\"\"\n      for item in settings.ACTIVITY_MONITOR_MODELS:\n        app_label, model = item['model'].split('.', 1)\n        content_type = ContentType.objects.get(app_label=app_label, model=model)\n        model = content_type.model_class()\n\n        objects = model.objects.all()\n\n        for object in objects:\n          try:\n            object.save()\n          except Exception as e:\n            print(\"Error saving: {}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef album_primary_image_url(self):\n    '''The image of the album'''\n    path = '/Items/{}/Images/Primary'.format(self.album_id)\n    return self.connector.get_url(path, attach_api_key=False)", "response": "The image of the album primary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstream for this song - not re - encoded", "response": "def stream_url(self):\n    '''stream for this song - not re-encoded'''\n    path = '/Audio/{}/universal'.format(self.id)\n    return self.connector.get_url(path,\n              userId=self.connector.userid,\n              MaxStreamingBitrate=140000000,\n              Container='opus',\n              TranscodingContainer='opus',\n              AudioCodec='opus',\n              MaxSampleRate=48000,\n              PlaySessionId=1496213367201 #TODO no hard code\n    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data(self):\n        if self._data is None:\n            request = urllib.Request(self._url, headers={'User-Agent': USER_AGENT})\n            with contextlib.closing(self._connection.urlopen(request)) as response:\n                self._data = response.read()\n        return self._data", "response": "Returns the raw image data of the current resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts the given filter specification to a CQL filter expression.", "response": "def make_filter_string(cls, filter_specification):\n        \"\"\"\n        Converts the given filter specification to a CQL filter expression.\n        \"\"\"\n        registry = get_current_registry()\n        visitor_cls = registry.getUtility(IFilterSpecificationVisitor,\n                                          name=EXPRESSION_KINDS.CQL)\n        visitor = visitor_cls()\n        filter_specification.accept(visitor)\n        return str(visitor.expression)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert the given order specification to a CQL order expression.", "response": "def make_order_string(cls, order_specification):\n        \"\"\"\n        Converts the given order specification to a CQL order expression.\n        \"\"\"\n        registry = get_current_registry()\n        visitor_cls = registry.getUtility(IOrderSpecificationVisitor,\n                                          name=EXPRESSION_KINDS.CQL)\n        visitor = visitor_cls()\n        order_specification.accept(visitor)\n        return str(visitor.expression)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef make_slice_key(cls, start_string, size_string):\n        try:\n            start = int(start_string)\n        except ValueError:\n            raise ValueError('Query parameter \"start\" must be a number.')\n        if start < 0:\n            raise ValueError('Query parameter \"start\" must be zero or '\n                             'a positive number.')\n        try:\n            size = int(size_string)\n        except ValueError:\n            raise ValueError('Query parameter \"size\" must be a number.')\n        if size < 1:\n            raise ValueError('Query parameter \"size\" must be a positive '\n                             'number.')\n        return slice(start, start + size)", "response": "Converts the given start and size query parts to a slice key."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the given slice key to start and size query parts.", "response": "def make_slice_strings(cls, slice_key):\n        \"\"\"\n        Converts the given slice key to start and size query parts.\n        \"\"\"\n        start = slice_key.start\n        size = slice_key.stop - start\n        return (str(start), str(size))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_match(self, elem):\n        for m in self.matches:\n            if (m.expression is not None and eval(m.expression)==True) \\\n            or (m.xpath is not None and len(elem.xpath(m.xpath, namespaces=m.namespaces)) > 0):\n                LOG.debug(\"=> match: %r\" % m.expression)\n                return m", "response": "return the match function that will be applied to the given elem"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef Element(self, elem, **params):\n        res = self.__call__(deepcopy(elem), **params)\n        if len(res) > 0: \n            return res[0]\n        else:\n            return None", "response": "Ensure that the input element is immutable by the transformation. Returns a single element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads properties file into bunch", "response": "def read_properties(filename):\n    \"\"\"read properties file into bunch.\n\n    :param filename: string\n    :rtype: bunch (dict like and object like)\n\n    \"\"\"\n    s = path(filename).text()\n    dummy_section = 'xxx'\n    cfgparser = configparser.RawConfigParser()\n\n    # avoid converting options to lower case\n    cfgparser.optionxform = str\n\n    cfgparser.readfp(StringIO('[%s]\\n' % dummy_section + s))\n    bunch = AutoBunch()\n    for x in cfgparser.options(dummy_section):\n        setattr(bunch, x, cfgparser.get(dummy_section, str(x)))\n    return bunch"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all files and directories under root", "response": "def clean_dir(root):\n    '''remove .* and _* files and directories under root'''\n    for x in root.walkdirs('.*', errors='ignore'):\n        x.rmtree()\n    for x in root.walkdirs('_*', errors='ignore'):\n        x.rmtree()\n\n    for x in root.walkfiles('.*', errors='ignore'):\n        x.remove()\n    for x in root.walkfiles('_*', errors='ignore'):\n        x.remove()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating the URL to submit to the Steam Web API.", "response": "def create_request_url(self, interface, method, version, parameters):\n        \"\"\"Create the URL to submit to the Steam Web API\n\n        interface: Steam Web API interface containing methods.\n        method: The method to call.\n        version: The version of the method.\n        paramters: Parameters to supply to the method.\n\n        \"\"\"\n        if 'format' in parameters:\n            parameters['key'] = self.apikey\n        else:\n            parameters.update({'key' : self.apikey, 'format' : self.format})\n        version = \"v%04d\" % (version)\n        url = \"http://api.steampowered.com/%s/%s/%s/?%s\" % (interface, method,\n            version, urlencode(parameters))\n        return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef retrieve_request(self, url):\n        try:\n            data = urlopen(url)\n        except:\n            print(\"Error Retrieving Data from Steam\")\n            sys.exit(2)\n        return data.read().decode('utf-8')", "response": "Open the given url and decode and return the response"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef return_data(self, data, format=None):\n        if format is None:\n            format = self.format\n        if format == \"json\":\n            formatted_data = json.loads(data)\n        else:\n            formatted_data = data\n        return formatted_data", "response": "Format and return data appropriate to the requested API format."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_friends_list(self, steamID, relationship='all', format=None):\n        parameters = {'steamid' : steamID, 'relationship' : relationship}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetFriendsList', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request the friends list of a given steam ID filtered by role."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_player_bans(self, steamIDS, format=None):\n        parameters = {'steamids' : steamIDS}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetPlayerBans', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request the communities a steam id is banned in."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_group_list(self, steamID, format=None):\n        parameters = {'steamid' : steamID}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetUserGroupList', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request a list of groups a user is subscribed to."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nrequests the steam id associated with a vanity url.", "response": "def resolve_vanity_url(self, vanityURL, url_type=1, format=None):\n        \"\"\"Request the steam id associated with a vanity url.\n\n        vanityURL: The users vanity URL\n        url_type: The type of vanity URL. 1 (default): Individual profile,\n                    2: Group, 3: Official game group\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {'vanityurl' : vanityURL, \"url_type\" : url_type}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'ResolveVanityUrl', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_global_achievement_percentages_for_app(self, gameID, format=None):\n        parameters = {'gameid' : gameID}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface,\n            'GetGlobalAchievementPercentagesForApp', 2, parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request statistics showing global achievements that have been unlocked."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_global_stats_for_game(self, appID, count, names, startdate,\n            enddate, format=None):\n        \"\"\"Request global stats for a give game.\n\n        appID: The app ID\n        count: Number of stats to get.\n        names: A list of names of stats to get.\n        startdate: The start time to gather stats. Unix timestamp\n        enddate: The end time to gather stats. Unix timestamp\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {\n            'appid' : appID,\n            'count' : count,\n            'startdate' : startdate,\n            'enddate' : enddate\n            }\n        count = 0\n        for name in names:\n            param = \"name[\" + str(count) + \"]\"\n            parameters[param] = name\n            count += 1\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetGlobalStatsForGame', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request global stats for a give game."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_number_of_current_players(self, appID, format=None):\n        parameters = {'appid' : appID}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface,\n            'GetNumberOfCurrentPlayers', 1, parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request the current number of players for a given app."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrequesting the achievements for a given app and steam id.", "response": "def get_player_achievements(self, steamID, appID, language=None,\n            format=None):\n        \"\"\"Request the achievements for a given app and steam id.\n\n        steamID: Users steam ID\n        appID: The app id\n        language: The language to return the results in. None uses default.\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {'steamid' : steamID, 'appid' : appID}\n        if format is not None:\n            parameters['format'] = format\n        if language is not None:\n            parameters['l'] = language\n        else:\n            parameters['l'] = self.language\n        url = self.create_request_url(self.interface, 'GetPlayerAchievements', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_schema_for_game(self, appID, language=None, format=None):\n        parameters = {'appid' : appID}\n        if format is not None:\n            parameters['format'] = format\n        if language is not None:\n            parameters['l'] = language\n        else:\n            parameters['l'] = self.language\n        url = self.create_request_url(self.interface, 'GetSchemaForGame', 2,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request the available achievements and stats for a game."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest the user stats for a given game.", "response": "def get_user_stats_for_game(self, steamID, appID, format=None):\n        \"\"\"Request the user stats for a given game.\n\n        steamID: The users ID\n        appID: The app id\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {'steamid' : steamID, 'appid' : appID}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetUserStatsForGame', 2,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_recently_played_games(self, steamID, count=0, format=None):\n        parameters = {'steamid' : steamID, 'count' : count}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetRecentlyPlayedGames', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request a list of recently played games by a given steam id."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrequests a list of games owned by a given steam id.", "response": "def get_owned_games(self, steamID, include_appinfo=1,\n            include_played_free_games=0, appids_filter=None, format=None):\n        \"\"\"Request a list of games owned by a given steam id.\n\n        steamID: The users id\n        include_appinfo: boolean.\n        include_played_free_games: boolean.\n        appids_filter: a json encoded list of app ids.\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {\n                    'steamid' : steamID,\n                    'include_appinfo' : include_appinfo,\n                    'include_played_free_games' : include_played_free_games\n                    }\n        if format is not None:\n            parameters['format'] = format\n        if appids_filter is not None:\n            parameters['appids_filter'] = appids_filter\n        url = self.create_request_url(self.interface, 'GetOwnedGames', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all the quests needed to get the specified badge, and which are completed. steamID: The users ID badgeID: The badge we're asking about format: Return format. None defaults to json. (json, xml, vdf)", "response": "def get_community_badge_progress(self, steamID, badgeID, format=None):\n        \"\"\"Gets all the quests needed to get the specified badge, and which are completed.\n\n        steamID: The users ID\n        badgeID: The badge we're asking about\n        format: Return format. None defaults to json. (json, xml, vdf)\n\n        \"\"\"\n        parameters = {'steamid' : steamID, 'badgeid' : badgeID}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetCommunityBadgeProgress', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_playing_shared_game(self, steamID, appid_playing, format=None):\n        parameters = {'steamid' : steamID, 'appid_playing' : appid_playing}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'IsPlayingSharedGame', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Returns valid lender SteamID if game currently played is borrowed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_server_info(self, format=None):\n        parameters = {}\n        if format is not None:\n            parameters['format'] = format\n        url = self.create_request_url(self.interface, 'GetServerInfo', 1,\n            parameters)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format=format)", "response": "Request the Steam Web API status and time."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_request_url(self, profile_type, steamID):\n        regex = re.compile('^\\d{17,}$')\n        if regex.match(steamID):\n            if profile_type == self.USER:\n                url = \"http://steamcommunity.com/profiles/%s/?xml=1\" % (steamID)\n            if profile_type == self.GROUP:\n                url = \"http://steamcommunity.com/gid/%s/memberslistxml/?xml=1\" % (steamID)\n        else:\n            if profile_type == self.USER:\n                url = \"http://steamcommunity.com/id/%s/?xml=1\" % (steamID)\n            if profile_type == self.GROUP:\n                url = \"http://steamcommunity.com/groups/%s/memberslistxml/?xml=1\" % (steamID)\n        return url", "response": "Create the url to submit to the Steam Community XML feed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_user_info(self, steamID):\n        url = self.create_request_url(self.USER, steamID)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format='xml')", "response": "Request the Steam Community XML feed for a specific user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_group_info(self, steamID):\n        url = self.create_request_url(self.GROUP, steamID)\n        data = self.retrieve_request(url)\n        return self.return_data(data, format='xml')", "response": "Request the Steam Community XML feed for a specific group."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef Deserializer(stream_or_string, **options):\n    if isinstance(stream_or_string, (bytes, six.string_types)):\n        stream_or_string = BytesIO(stream_or_string)\n    try:\n        def line_generator():\n            for line in stream_or_string:\n                yield json.loads(line.strip())\n        for obj in PythonDeserializer(line_generator(), **options):\n            yield obj\n    except GeneratorExit:\n        raise\n    except Exception as e:\n        # Map to deserializer error\n        six.reraise(DeserializationError, DeserializationError(e), sys.exc_info()[2])", "response": "Deserializes a stream or string of JSON data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmakes a request to the API.", "response": "def request(self, method, url, data=None, files=None, query=None, headers=None, timeout=60):\n        \"\"\"\n        Mechanism for issuing an API call\n        \"\"\"\n        headers = headers or {}\n\n        if self.token:\n            my_token = self.token\n        else:\n            from figure import token\n            my_token = token\n\n        if my_token:\n            self.__set_authorization(headers, my_token)\n\n        METHODS = {\n            'get': self.__get,\n            'post': self.__post,\n            'put': self.__put,\n            'head': self.__head,\n            'patch': self.__patch\n        }\n        request_method = METHODS[method.lower()]\n\n        abs_url = urlparse.urljoin(self.api_base, url)\n\n        encoded_query = urllib.urlencode(query or {})\n\n        abs_url = _build_api_url(abs_url, encoded_query)\n\n        try:\n            response = request_method(abs_url, data=data, files=files, headers=headers, timeout=timeout)\n            response.encoding = 'utf-8'\n        except RequestException:\n            raise error.APIConnectionError()\n\n        return self._interpret_response(response.text, response.status_code)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_color_old( text, attr=None):\r\n    u'''write text at current cursor position and interpret color escapes.\r\n\r\n    return the number of characters written.\r\n    '''\r\n    res = []\r\n    chunks = terminal_escape.split(text)\r\n    n = 0 # count the characters we actually write, omitting the escapes\r\n    if attr is None:#use attribute from initial console\r\n        attr = 15\r\n    for chunk in chunks:\r\n        m = escape_parts.match(chunk)\r\n        if m:\r\n            for part in m.group(1).split(u\";\"):\r\n                if part == u\"0\": # No text attribute\r\n                    attr = 0\r\n                elif part == u\"7\": # switch on reverse\r\n                    attr |= 0x4000\r\n                if part == u\"1\": # switch on bold (i.e. intensify foreground color)\r\n                    attr |= 0x08\r\n                elif len(part) == 2 and u\"30\" <= part <= u\"37\": # set foreground color\r\n                    part = int(part)-30\r\n                    # we have to mirror bits\r\n                    attr = (attr & ~0x07) | ((part & 0x1) << 2) | (part & 0x2) | ((part & 0x4) >> 2)\r\n                elif len(part) == 2 and u\"40\" <= part <= u\"47\": # set background color\r\n                    part = int(part) - 40\r\n                    # we have to mirror bits\r\n                    attr = (attr & ~0x70) | ((part & 0x1) << 6) | ((part & 0x2) << 4) | ((part & 0x4) << 2)\r\n                # ignore blink, underline and anything we don't understand\r\n            continue\r\n        n += len(chunk)\r\n        if chunk:\r\n            res.append((u\"0x%x\"%attr, chunk))\r\n    return res", "response": "u'''write text at current cursor position and interpret color escapes.\r\n    return the number of characters written."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef export(cls, folder, particles, datetimes):\n        normalized_locations = [particle.normalized_locations(datetimes) for particle in particles]\n\n        track_coords = []\n        for x in xrange(0, len(datetimes)):\n            points = MultiPoint([loc[x].point.coords[0] for loc in normalized_locations])\n            track_coords.append(points.centroid.coords[0])\n\n        ls = LineString(track_coords)\n\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n        filepath = os.path.join(folder, \"trackline.geojson\")\n        f = open(filepath, \"wb\")\n        f.write(json.dumps(mapping(ls)))\n        f.close()\n        return filepath", "response": "Export trackline data to GeoJSON file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexport particle data to CF trajectory convention", "response": "def export(cls, folder, particles, datetimes, summary, **kwargs):\n        \"\"\"\n            Export particle data to CF trajectory convention\n            netcdf file\n        \"\"\"\n        time_units = 'seconds since 1990-01-01 00:00:00'\n\n        # Create netcdf file, overwrite existing\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n\n        filepath = os.path.join(folder, 'trajectories.nc')\n        nc = netCDF4.Dataset(filepath, 'w')\n        # Create netcdf dimensions\n        nc.createDimension('time', None)\n        nc.createDimension('particle', None)\n\n        fillvalue = -9999.9\n\n        # Create netcdf variables\n        time = nc.createVariable('time', 'i', ('time',))\n        part = nc.createVariable('particle', 'i', ('particle',))\n        depth = nc.createVariable('depth', 'f', ('time', 'particle'))\n        lat = nc.createVariable('lat', 'f', ('time', 'particle'), fill_value=fillvalue)\n        lon = nc.createVariable('lon', 'f', ('time', 'particle'), fill_value=fillvalue)\n        salt = nc.createVariable('salt', 'f', ('time', 'particle'), fill_value=fillvalue)\n        temp = nc.createVariable('temp', 'f', ('time', 'particle'), fill_value=fillvalue)\n        u = nc.createVariable('u', 'f', ('time', 'particle'), fill_value=fillvalue)\n        v = nc.createVariable('v', 'f', ('time', 'particle'), fill_value=fillvalue)\n        w = nc.createVariable('w', 'f', ('time', 'particle'), fill_value=fillvalue)\n        settled = nc.createVariable('settled', 'f', ('time', 'particle'), fill_value=fillvalue)\n        dead = nc.createVariable('dead', 'f', ('time', 'particle'), fill_value=fillvalue)\n        halted = nc.createVariable('halted', 'f', ('time', 'particle'), fill_value=fillvalue)\n\n        # Loop through locations in each particle,\n        # add to netcdf file\n        for j, particle in enumerate(particles):\n            part[j] = particle.uid\n            i = 0\n\n            normalized_locations = particle.normalized_locations(datetimes)\n            normalized_temps = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.temps]\n            normalized_salts = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.salts]\n            normalized_u = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.u_vectors]\n            normalized_v = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.v_vectors]\n            normalized_w = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.w_vectors]\n            normalized_settled = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.settles]\n            normalized_dead = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.deads]\n            normalized_halted = [x if x is not None and not math.isnan(x) else fillvalue for x in particle.halts]\n\n            if len(normalized_locations) != len(normalized_temps):\n                logger.info(\"No temperature being added to netcdf.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_temps = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_salts):\n                logger.info(\"No salinity being added to netcdf.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_salts = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_u):\n                logger.info(\"No U being added to netcdf.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_u = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_v):\n                logger.info(\"No V being added to netcdf.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_v = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_w):\n                logger.info(\"No W being added to netcdf.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_w = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_settled):\n                logger.info(\"No Settled being added to shapefile.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_settled = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_dead):\n                logger.info(\"No Dead being added to shapefile.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_dead = [fillvalue] * len(normalized_locations)\n\n            if len(normalized_locations) != len(normalized_halted):\n                logger.info(\"No Halted being added to shapefile.\")\n                # Create list of 'fillvalue' equal to the length of locations\n                normalized_halted = [fillvalue] * len(normalized_locations)\n\n            for loc, _temp, _salt, _u, _v, _w, _settled, _dead, _halted in zip(normalized_locations, normalized_temps, normalized_salts, normalized_u, normalized_v, normalized_w, normalized_settled, normalized_dead, normalized_halted):\n\n                if j == 0:\n                    time[i] = int(round(netCDF4.date2num(loc.time, time_units)))\n                depth[i, j] = loc.depth\n                lat[i, j] = loc.latitude\n                lon[i, j] = loc.longitude\n                salt[i, j] = _salt\n                temp[i, j] = _temp\n                u[i, j] = _u\n                v[i, j] = _v\n                w[i, j] = _w\n                settled[i, j] = _settled\n                dead[i, j] = _dead\n                halted[i, j] = _halted\n                i += 1\n\n        # Variable attributes\n        depth.coordinates = \"time particle lat lon\"\n        depth.standard_name = \"depth_below_sea_surface\"\n        depth.units = \"m\"\n        depth.POSITIVE = \"up\"\n        depth.positive = \"up\"\n\n        salt.coordinates = \"time particle lat lon\"\n        salt.standard_name = \"sea_water_salinity\"\n        salt.units = \"psu\"\n\n        temp.coordinates = \"time particle lat lon\"\n        temp.standard_name = \"sea_water_temperature\"\n        temp.units = \"degrees_C\"\n\n        u.coordinates = \"time particle lat lon\"\n        u.standard_name = \"eastward_sea_water_velocity\"\n        u.units = \"m/s\"\n\n        v.coordinates = \"time particle lat lon\"\n        v.standard_name = \"northward_sea_water_velocity\"\n        v.units = \"m/s\"\n\n        w.coordinates = \"time particle lat lon\"\n        w.standard_name = \"upward_sea_water_velocity\"\n        w.units = \"m/s\"\n\n        settled.coordinates = \"time particle lat lon\"\n        settled.description = \"Is the particle settled\"\n        settled.standard_name = \"particle_settled\"\n\n        dead.coordinates = \"time particle lat lon\"\n        dead.description = \"Is the particle dead\"\n        dead.standard_name = \"particle_dead\"\n\n        halted.coordinates = \"time particle lat lon\"\n        halted.description = \"Is the particle prevented from being forced by currents\"\n        halted.standard_name = \"particle_halted\"\n\n        time.units = time_units\n        time.standard_name = \"time\"\n\n        lat.units = \"degrees_north\"\n\n        lon.units = \"degrees_east\"\n\n        part.cf_role = \"trajectory_id\"\n\n        # Global attributes\n        nc.featureType = \"trajectory\"\n        nc.summary = str(summary)\n        for key in kwargs:\n            nc.__setattr__(key, kwargs.get(key))\n\n        nc.sync()\n        nc.close()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef export(cls, folder, particles, datetimes):\n        if not os.path.exists(folder):\n            os.makedirs(folder)\n\n        particle_path = os.path.join(folder, 'particles.pickle')\n        f = open(particle_path, \"wb\")\n        pickle.dump(particles, f)\n        f.close()\n\n        datetimes_path = os.path.join(folder, 'datetimes.pickle')\n        f = open(datetimes_path, \"wb\")\n        pickle.dump(datetimes, f)\n        f.close()", "response": "Export particle and datetime data to Pickled objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_settings_class(setting_name):\n    config_value = getattr(settings, setting_name)\n    if config_value is None:\n        raise ImproperlyConfigured(\"Required setting not found: {0}\".format(setting_name))\n\n    return import_class(config_value, setting_name)", "response": "Imports a class from the settings variable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nimport a class by name.", "response": "def import_class(import_path, setting_name=None):\n    \"\"\"\n    Import a class by name.\n    \"\"\"\n    mod_name, class_name = import_path.rsplit('.', 1)\n\n    # import module\n    mod = import_module_or_none(mod_name)\n    if mod is not None:\n        # Loaded module, get attribute\n        try:\n            return getattr(mod, class_name)\n        except AttributeError:\n            pass\n\n    # For ImportError and AttributeError, raise the same exception.\n    if setting_name:\n        raise ImproperlyConfigured(\"{0} does not point to an existing class: {1}\".format(setting_name, import_path))\n    else:\n        raise ImproperlyConfigured(\"Class not found: {0}\".format(import_path))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef import_apps_submodule(submodule):\n    found_apps = []\n    for appconfig in apps.get_app_configs():\n        app = appconfig.name\n        if import_module_or_none('{0}.{1}'.format(app, submodule)) is not None:\n            found_apps.append(app)\n\n    return found_apps", "response": "Import a submodule of the INSTALLED_APPS."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef import_module_or_none(module_label):\n    try:\n        # On Python 3, importlib has much more functionality compared to Python 2.\n        return importlib.import_module(module_label)\n    except ImportError:\n        # Based on code from django-oscar:\n        # There are 2 reasons why there could be an ImportError:\n        #\n        #  1. Module does not exist. In that case, we ignore the import and return None\n        #  2. Module exists but another ImportError occurred when trying to import the module.\n        #     In that case, it is important to propagate the error.\n        #\n        # ImportError does not provide easy way to distinguish those two cases.\n        # Fortunately, the traceback of the ImportError starts at __import__\n        # statement. If the traceback has more than one frame, it means that\n        # application was found and ImportError originates within the local app\n        __, __, exc_traceback = sys.exc_info()\n        frames = traceback.extract_tb(exc_traceback)\n        frames = [f for f in frames\n                  if f[0] != \"<frozen importlib._bootstrap>\" and  # Python 3.6\n                  f[0] != IMPORT_PATH_IMPORTLIB and\n                  not f[0].endswith(IMPORT_PATH_GEVENT) and\n                  not IMPORT_PATH_PYDEV in f[0]]\n        if len(frames) > 1:\n            raise\n    return None", "response": "Imports the module with the given name. Returns None if the module does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_logger(name):\n    logger = logging.getLogger(name)\n    logger.addHandler(logging.NullHandler())\n    return logger", "response": "Gets a logger for the given name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of all the loader options that can be used to load the representer s entity attributes.", "response": "def loader_options(self):\n        \"\"\"\n        Dictionary mapping each entity class to configure a loader for to a\n        list of (possibly nested) entity attribute names.\n        \"\"\"\n        all_keys = set(self.__attr_map.keys())\n        # Go through the collected keys and through out all keys which are\n        # subkeys of others to eliminate redundancy.\n        for key in sorted(self.__attr_map):\n            for idx in range(1, len(key)):\n                sub_key = key[:-idx]\n                if sub_key in all_keys:\n                    all_keys.remove(sub_key)\n        if provides_member_resource(self._context):\n            # If the context is a member, we need to configure the loaders\n            # for the entity class belonging to each of its resource\n            # attributes. Only nested keys collected from the representer\n            # configuration need to be configured (and the corresponding\n            # nested entity attribute needs to be shortened).\n            loader_option_map = defaultdict(list)\n            for key in all_keys:\n                entity_attr_names = self.__attr_map[key]\n                if len(entity_attr_names) > 1:\n                    ent_attr_name = entity_attr_names[0]\n                    nested_attr_name = '.'.join(entity_attr_names[1:])\n                    opts = loader_option_map[ent_attr_name]\n                    opts.append(nested_attr_name)\n            # Translate to entity classes as keys. This is tricky as the\n            # keys in the loader option map can itself be nested attributes.\n            for ent_attr_name, nested_attr_names in loader_option_map.items():\n                ent_attr_name_tokens = ent_attr_name.split('.')\n                ent_cls = get_entity_class(self._context)\n                ent_cls_attr = getattr(ent_cls, ent_attr_name_tokens[0])\n                ent_cls = ent_cls_attr.property.mapper.entity\n                if len(ent_attr_name_tokens) > 1:\n                    prefix = '.'.join(ent_attr_name_tokens[1:])\n                    loader_option_map[ent_cls] = \\\n                            [\"%s.%s\" % (prefix, token)\n                             for token in nested_attr_names]\n                else:\n                    loader_option_map[ent_cls] = nested_attr_names\n                del loader_option_map[ent_attr_name]\n        else:\n            # If the context is a collection, we need to configure the\n            # loader for its entity class.\n            loader_option_map = {get_entity_class(self._context) :\n                                 ['.'.join(self.__attr_map[key])\n                                  for key in all_keys]}\n        return loader_option_map"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlooks up a list of user ids and checks whether they are currently suspended. Input: - user_twitter_id_list: A python list of Twitter user ids in integer format to be looked-up. Outputs: - suspended_user_twitter_id_list: A python list of suspended Twitter user ids in integer format. - non_suspended_user_twitter_id_list: A python list of non suspended Twitter user ids in integer format. - unknown_status_user_twitter_id_list: A python list of unknown status Twitter user ids in integer format.", "response": "def check_suspension(user_twitter_id_list):\n    \"\"\"\n    Looks up a list of user ids and checks whether they are currently suspended.\n\n    Input: - user_twitter_id_list: A python list of Twitter user ids in integer format to be looked-up.\n\n    Outputs: - suspended_user_twitter_id_list: A python list of suspended Twitter user ids in integer format.\n             - non_suspended_user_twitter_id_list: A python list of non suspended Twitter user ids in integer format.\n             - unknown_status_user_twitter_id_list: A python list of unknown status Twitter user ids in integer format.\n    \"\"\"\n    ####################################################################################################################\n    # Log into my application.\n    ####################################################################################################################\n    twitter = login()\n\n    ####################################################################################################################\n    # Lookup users\n    ####################################################################################################################\n    # Initialize look-up lists\n    suspended_user_twitter_id_list = list()\n    non_suspended_user_twitter_id_list = list()\n    unknown_status_user_twitter_id_list = list()\n\n    append_suspended_twitter_user = suspended_user_twitter_id_list.append\n    append_non_suspended_twitter_user = non_suspended_user_twitter_id_list.append\n    extend_unknown_status_twitter_user = unknown_status_user_twitter_id_list.extend\n\n    # Split twitter user id list into sub-lists of length 100 (This is the Twitter API function limit).\n    user_lookup_counter = 0\n    user_lookup_time_window_start = time.perf_counter()\n    for hundred_length_sub_list in chunks(list(user_twitter_id_list), 100):\n        # Make safe twitter request.\n        try:\n            api_result, user_lookup_counter, user_lookup_time_window_start\\\n                = safe_twitter_request_handler(twitter_api_func=twitter.lookup_user,\n                                               call_rate_limit=60,\n                                               call_counter=user_lookup_counter,\n                                               time_window_start=user_lookup_time_window_start,\n                                               max_retries=10,\n                                               wait_period=2,\n                                               parameters=hundred_length_sub_list)\n            # If the call is succesful, turn hundred sub-list to a set for faster search.\n            hundred_length_sub_list = set(hundred_length_sub_list)\n\n            # Check who is suspended and who is not.\n            for hydrated_user_object in api_result:\n                hydrated_twitter_user_id = hydrated_user_object[\"id\"]\n\n                if hydrated_twitter_user_id in hundred_length_sub_list:\n                    append_non_suspended_twitter_user(hydrated_twitter_user_id)\n                else:\n                    append_suspended_twitter_user(hydrated_twitter_user_id)\n        except twython.TwythonError:\n            # If the call is unsuccesful, we do not know about the status of the users.\n            extend_unknown_status_twitter_user(hundred_length_sub_list)\n        except URLError:\n            # If the call is unsuccesful, we do not know about the status of the users.\n            extend_unknown_status_twitter_user(hundred_length_sub_list)\n        except BadStatusLine:\n            # If the call is unsuccesful, we do not know about the status of the users.\n            extend_unknown_status_twitter_user(hundred_length_sub_list)\n\n    return suspended_user_twitter_id_list, non_suspended_user_twitter_id_list, unknown_status_user_twitter_id_list"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the experiments that are best found for the given network and the experiment variables.", "response": "def get_best_experiment_sets(nets,expvars,num):\n  '''\n  given the network and the experimental variables, and the bound on the size of an experiment set\n  returns the experiments as a``TermSet`` object [instance].\n  '''\n\n  netsf    = nets.to_file()\n  expvarsf = expvars.to_file()\n\n  best           = -1\n  best_solutions = []\n  best_found     = False\n\n  i = 0\n  while i < num and not best_found :\n    i += 1\n\n    num_exp   = String2TermSet('pexperiment('+str(i)+')')\n    num_expf  = num_exp.to_file()\n    prg       = [ netsf, expvarsf, num_expf, find_best_exp_sets_prg,\n                  elem_path_prg ]\n    coptions  = '--project --opt-mode=optN --opt-strategy=0 --opt-heuristic'\n    solver    = GringoClasp(clasp_options=coptions)\n    solutions = solver.run(prg,collapseTerms=True,collapseAtoms=False)\n\n    #print(solutions[0].score[0],solutions[0].score[1],solutions[0].score[2],solutions[0].score[3])\n\n    os.unlink(num_expf)\n    if solutions == []: best_found = True\n    else:\n      opt=(solutions[0].score[0]+solutions[0].score[1]+solutions[0].score[2])\n      if best == opt:\n        best_found = True\n      else:\n        best           = opt\n        best_solutions = solutions\n\n\n  os.unlink(netsf)\n  os.unlink(expvarsf)\n\n  return best_solutions"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def handler(self):\n    '''Handle loop, get and process messages'''\n    self.ws = await websockets.connect(self.url, ssl=self.ssl)\n    while self.ws:\n      message = await self.ws.recv()\n      for handle in self.on_message:\n        if asyncio.iscoroutinefunction(handle):\n          await handle(self, message)\n        else:\n          handle(self, message)", "response": "Handle loop get and process messages"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing a url for an emby request", "response": "def get_url(self, path='/', websocket=False, remote=True,\n              attach_api_key=True, userId=None, pass_uid=False, **query):\n    '''construct a url for an emby request\n\n    Parameters\n    ----------\n    path : str\n      uri path(excluding domain and port) of get request for emby\n    websocket : bool, optional\n      if true, then `ws(s)` are used instead of `http(s)`\n    remote : bool, optional\n      if true, remote-address is used (default True)\n    attach_api_key : bool, optional\n      if true, apikey is added to the query (default True)\n    userId : str, optional\n      uid to use, if none, default is used\n    pass_uid : bool, optional\n      if true, uid is added to the query (default False)\n    query : karg dict\n      additional parameters to set (part of url after the `?`)\n\n    Also See\n    --------\n      get :\n      getJson :\n      post :\n      delete :\n\n    Returns\n    -------\n    full url\n    '''\n    userId = userId or self.userid\n    if attach_api_key and self.api_key:\n      query.update({'api_key':self.api_key, 'deviceId': self.device_id})\n    if pass_uid:\n      query['userId'] = userId\n\n    if remote:\n      url = self.urlremote or self.url\n    else:\n      url = self.url\n\n    if websocket:\n      scheme = {'http':'ws', 'https':'wss'}[url.scheme]\n    else:\n      scheme = url.scheme\n    netloc = url.netloc + '/emby'\n\n    url = urlunparse((scheme, netloc, path, '', '{params}', '')).format(\n      UserId   = userId,\n      ApiKey   = self.api_key,\n      DeviceId = self.device_id,\n      params   = urlencode(query)\n    )\n\n    return url[:-1] if url[-1] == '?' else url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a get request Parameters ---------- path : str same as get_url query : kargs dict additional info to pass to get_url See Also -------- get_url : getJson : Returns ------- requests.models.Response the response that was given", "response": "async def get(self, path, **query):\n    '''return a get request\n\n    Parameters\n    ----------\n    path : str\n      same as get_url\n    query : kargs dict\n      additional info to pass to get_url\n\n    See Also\n    --------\n      get_url :\n      getJson :\n\n    Returns\n    -------\n    requests.models.Response\n      the response that was given\n    '''\n    url = self.get_url(path, **query)\n\n    for i in range(self.tries+1):\n      try:\n        resp = await self.session.get(url, timeout=self.timeout)\n        if await self._process_resp(resp):\n          return resp\n        else:\n          continue\n      except aiohttp.ClientConnectionError:\n        if i >= self.tries:\n          raise aiohttp.ClientConnectionError(\n                        'Emby server is probably down'\n          )"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend post request to get_url", "response": "async def post(self, path, data={}, send_raw=False, **params):\n    '''sends post request\n\n    Parameters\n    ----------\n    path : str\n      same as get_url\n    query : kargs dict\n      additional info to pass to get_url\n\n    See Also\n    --------\n      get_url :\n\n    Returns\n    -------\n    requests.models.Response\n      the response that was given\n    '''\n    url  = self.get_url(path, **params)\n    jstr = json.dumps(data)\n\n    for i in range(self.tries+1):\n      try:\n        if send_raw:\n          resp = await self.session.post(url, data=data, timeout=self.timeout)\n        else:\n          resp = await self.session.post(url, data=jstr, timeout=self.timeout)\n        if await self._process_resp(resp):\n          return resp\n        else:\n          continue\n      except aiohttp.ClientConnectionError:\n        if i >= self.tries:\n          raise aiohttp.ClientConnectionError(\n                        'Emby server is probably down'\n          )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap for get parses response as json", "response": "async def getJson(self, path, **query):\n    '''wrapper for get, parses response as json\n\n    Parameters\n    ----------\n    path : str\n      same as get_url\n    query : kargs dict\n      additional info to pass to get_url\n\n    See Also\n    --------\n      get_url :\n      get :\n\n    Returns\n    -------\n    dict\n      the response content as a dict\n    '''\n    for i in range(self.tries+1):\n      try:\n        return await (await self.get(path, **query)).json()\n      except:\n        if i >= self.tries:\n          raise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_by_missing(max_miss=0.01):\r\n\r\n    def f(G, bim):\r\n        Isnp = sp.isnan(G).mean(0) < max_miss\r\n        G_out = G[:, Isnp]\r\n        bim_out = bim[Isnp]\r\n        return G_out, bim_out\r\n\r\n    return f", "response": "Returns a function that filters by missing values"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_by_maf(min_maf=0.01):\r\n\r\n    def f(G, bim):\r\n        maf = 0.5 * G.mean(0)\r\n        maf[maf > 0.5] = 1.0 - maf[maf > 0.5]\r\n        Isnp = maf > min_maf\r\n        G_out = G[:, Isnp]\r\n        bim_out = bim[Isnp]\r\n        return G_out, bim_out\r\n\r\n    return f", "response": "Returns a function that filters by MAF"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef standardize():\r\n\r\n    def f(G, bim):\r\n        G_out = standardize_snps(G)\r\n        return G_out, bim\r\n\r\n    return f", "response": "Returns a function that returns a sequence of standardized variants."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef impute(imputer):\r\n\r\n    def f(G, bim):\r\n        return imputer.fit_transform(G), bim\r\n\r\n    return f", "response": "Returns a function that transforms a set of objects into a single object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compose(func_list):\r\n\r\n    def f(G, bim):\r\n        for func in func_list:\r\n            G, bim = func(G, bim)\r\n        return G, bim\r\n\r\n    return f", "response": "compose function that returns G bim"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the data back out of here and into a dict.", "response": "def asdict(self):\n    \"\"\"\n    Copy the data back out of here and into a dict.  Then return it.\n    Some libraries may check specifically for dict objects, such\n    as the json library; so, this makes it convenient to get the data\n    back out.\n\n    >>> import dictobj\n    >>> d = {'a':1, 'b':2}\n    >>> dictobj.DictionaryObject(d).asdict() == d\n    True\n    >>> d['c'] = {1:2, 3:4}\n    >>> dictobj.DictionaryObject(d).asdict() == d\n    True\n    \"\"\"\n    items = {}\n    for name in self._items:\n      value = self._items[name]\n      if isinstance(value, DictionaryObject):\n        items[name] = value.asdict()\n      else:\n        items[name] = value\n    return items"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_joke():\n    joke = None\n\n    while joke is None:\n        service_num = randint(1, NUM_SERVICES)\n        joke = load_joke(service_num)\n    return joke", "response": "Return a jokes from one of the random services."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nloads the joke from the service based on the argument.", "response": "def load_joke(service_num=1):\n    \"\"\"Pulls the joke from the service based on the argument.\n    \n    It is expected that all services used will return a string\n    when successful or None otherwise.\n    \"\"\"\n    result = {\n      1 : ronswanson.get_joke(),\n      2 : chucknorris.get_joke(),\n      3 : catfacts.get_joke(),\n      4 : dadjokes.get_joke(),\n    }.get(service_num)\n\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_14c(fl):\n    indata = pd.read_csv(fl, index_col=None, skiprows=11, header=None,\n                         names=['calbp', 'c14age', 'error', 'delta14c', 'sigma'])\n    outcurve = CalibCurve(calbp=indata['calbp'],\n                          c14age=indata['c14age'],\n                          error=indata['error'],\n                          delta14c=indata['delta14c'],\n                          sigma=indata['sigma'])\n    return outcurve", "response": "Read in a 14C file and return a CalibCurve instance"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading a Bacon file into a ChronRecord instance", "response": "def read_chron(fl):\n    \"\"\"Create ChronRecord instance from Bacon file\n    \"\"\"\n    indata = pd.read_csv(fl, sep=r'\\s*\\,\\s*', index_col=None, engine='python')\n    outcore = ChronRecord(age=indata['age'],\n                          error=indata['error'],\n                          depth=indata['depth'],\n                          labid=indata['labID'])\n    return outcore"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreads a file to create a proxy record instance", "response": "def read_proxy(fl):\n    \"\"\"Read a file to create a proxy record instance\n    \"\"\"\n    outcore = ProxyRecord(data=pd.read_csv(fl, sep=r'\\s*\\,\\s*', index_col=None, engine='python'))\n    return outcore"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_pandas(self):\n        agedepthdf = pd.DataFrame(self.age, index=self.data.depth)\n        agedepthdf.columns = list(range(self.n_members()))\n        out = (agedepthdf.join(self.data.set_index('depth'))\n               .reset_index()\n               .melt(id_vars=self.data.columns.values, var_name='mciter', value_name='age'))\n        out['mciter'] = pd.to_numeric(out.loc[:, 'mciter'])\n        if self.n_members() == 1:\n            out = out.drop('mciter', axis=1)\n        return out", "response": "Convert record to pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_token_type(self, char):\n        if char in '()':\n            return self.SPLIT, 0\n        elif char == ',':\n            return self.SPLIT, 1\n        elif char in '<>':\n            return self.IGNORE, 2\n        elif char == '.':\n            return self.JOIN, 3\n        elif char.isdigit():\n            return self.JOIN, 4\n        elif char.isalpha():\n            return self.JOIN, 5\n        elif char == '^':\n            return self.JOIN, 6\n        elif char.isspace():\n            return self.IGNORE, 7\n        else:\n            raise ValueError('TokeniserException: \"{}\" can not be tokenised'.format(char))", "response": "Returns a 2 - tuple of the behaviour and type of the token."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request(method, url, **kwargs):\n    auth = kwargs.get('auth')\n    headers = kwargs.get('headers', {})\n    # headers = headers.copy() # ? We do modify the dict in place here...\n    if isinstance(auth, TreqKerberosAuth):\n        del kwargs['auth']\n        if auth.force_preemptive:\n            # Save a round-trip and set the Negotiate header on the first req.\n            headers['Authorization'] = yield negotiate_header(url)\n    response = yield treq.request(method=method, url=url, headers=headers,\n                                  **kwargs)\n    # Retry if we got a 401 / Negotiate response.\n    if response.code == 401 and isinstance(auth, TreqKerberosAuth):\n        auth_mechs = response.headers.getRawHeaders('WWW-Authenticate')\n        if 'Negotiate' in auth_mechs:\n            headers['Authorization'] = yield negotiate_header(url)\n            response = yield treq.request(method=method, url=url,\n                                          headers=headers, **kwargs)\n    defer.returnValue(response)", "response": "A request that returns a response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the \"Authorization\" HTTP header value to use for this URL.", "response": "def negotiate_header(url):\n    \"\"\"\n    Return the \"Authorization\" HTTP header value to use for this URL.\n    \"\"\"\n    hostname = urlparse(url).hostname\n    _, krb_context = kerberos.authGSSClientInit('HTTP@%s' % hostname)\n    # authGSSClientStep goes over the network to the KDC (ie blocking).\n    yield threads.deferToThread(kerberos.authGSSClientStep,\n                                krb_context, '')\n    negotiate_details = kerberos.authGSSClientResponse(krb_context)\n    defer.returnValue('Negotiate ' + negotiate_details)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreads the specification provided.", "response": "def _get_specification(self, specification):\n        \"\"\"\n        Read the specification provided. It can either be a url or a file\n        location.\n        \"\"\"\n        result = six.moves.urllib.parse.urlparse(specification)\n\n        # If the specification has an http or an https scheme we can\n        # retrieve it via an HTTP get request, else we try to open it\n        # as a file.\n        if result.scheme in ['http', 'https']:\n            response = requests.get(specification)\n            spec_json = response.json()\n        else:\n            with open(specification, 'r') as spec_file:\n                spec_json = json.load(spec_file)\n\n        return spec_json"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the CSV file headers from the provided resource.", "response": "def _get_headers(self, resource):\n        \"\"\"\n        Get CSV file headers from the provided resource.\n        \"\"\"\n\n        # If the resource is a file we just open it up with the csv\n        # reader (after being sure we're reading from the beginning\n        # of the file\n        if type(resource) == file:\n            resource.seek(0)\n            reader = csv.reader(resource)\n        # If the resource is a basestring it is either a url or a file\n        # location, so similarly to the specification mechanism we either\n        # access it with an HTTP get request or by opening the file.\n        elif isinstance(resource, basestring):\n            result = six.moves.urllib.parse.urlparse(resource)\n            if result.scheme in ['http', 'https']:\n                with closing(requests.get(resource, stream=True)) as response:\n                    # Headers are alway the first row of a CSV file\n                    # so it's enought to just get the first line and\n                    # hopefully save bandwidth\n                    header_row = response.iter_lines().next()\n            else:\n                # It may seem weird to open up a csv file, read its header row\n                # and then StringIO that into a new csv reader but this file\n                # we want to close and we want the same interface for all\n                with open(resource) as resource_file:\n                    reader = csv.reader(resource_file)\n                    header_row = reader.next()\n\n            reader = csv.reader(cStringIO.StringIO(header_row))\n        else:\n            raise IOError('Resource type not supported')\n        return reader.next()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef schema(self):\n\n        if self.headers is None:\n            raise exceptions.NoResourceLoadedException(\n                'Resource must be loaded to find schema')\n        try:\n            fields = self.specification.get('fields', {})\n            parsed = {\n                'primaryKey': 'id',\n                'fields': [{\n                        'name': header,\n                        'type': fields[header]['type'],\n                        'description': fields[header]['description']\n                        } for header in self.headers]\n                }\n        except KeyError:\n            raise exceptions.NotABudgetDataPackageException(\n                'Includes other fields than the Budget Data Package fields')\n        return parsed", "response": "Returns the generated budget data package schema for this resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the time of the tif data since the epoch.", "response": "def get_time(self, idx=0):\n        \"\"\"Return the time of the tif data since the epoch\n\n        The time is stored in the \"61238\" tag.\n        \"\"\"\n        timestr = SingleTifPhasics._get_meta_data(path=self.path,\n                                                  section=\"acquisition info\",\n                                                  name=\"date & heure\")\n        if timestr is not None:\n            timestr = timestr.split(\".\")\n            # '2016-04-29_17h31m35s.00827'\n            structtime = time.strptime(timestr[0],\n                                       \"%Y-%m-%d_%Hh%Mm%Ss\")\n            fracsec = float(timestr[1]) * 1e-5\n            # use calendar, because we need UTC\n            thetime = calendar.timegm(structtime) + fracsec\n        else:\n            thetime = np.nan\n        return thetime"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns QPImage with background correction applied.", "response": "def get_qpimage_raw(self, idx=0):\n        \"\"\"Return QPImage without background correction\"\"\"\n        # Load experimental data\n        with SingleTifPhasics._get_tif(self.path) as tf:\n            # page 0 contains intensity\n            # page 1 contains phase in nm\n            # page 2 contains phase in wavelengths\n            # Intensity:\n            inttags = tf.pages[0].tags\n            imin = inttags[\"61243\"].value\n            imax = inttags[\"61242\"].value\n            isamp = inttags[\"max_sample_value\"].value\n            blc = INTENSITY_BASELINE_CLAMP\n            inten = tf.pages[0].asarray() * (imax - imin) / isamp + imin - blc\n            inten[inten < 0] = 0\n            # Phase\n            # The SID4Bio records two phase images, one in wavelengths and\n            # one in nanometers. Surprisingly, these two phase images are\n            # not derived from the same recording. The first image (pages[1])\n            # (in wavelengths) matches the intensity image (pages[0]). The\n            # second image (pages[2]) is recorded at a different time point.\n            # Initially, I thought it would be best to compute the phase\n            # directly from the measured value in nanometers (pages[2]) using\n            # the known wavelength given by the qpformat user. However, since\n            # phase and amplitude won't match up in that case, the wavelength\n            # phase image (pages[1]) has to be used. Since phasics uses its own\n            # wavelength (set by the user in the acquisition/extraction\n            # software) which might be wrong, I decided to first compute\n            # the phase in nanometers from tf.pages[1] using the phasics\n            # wavelength and then proceed as before, computing the phase\n            # in radians using the correct, user-given wavelength.\n            wl_phasics = self._get_wavelength(self.path)\n            if not np.isnan(wl_phasics):\n                # proceed with phase in wavelengths\n                phaid = 1\n            else:\n                # proceed with phase in nanometers\n                phaid = 2\n            phatags = tf.pages[phaid].tags\n            pmin = phatags[\"61243\"].value\n            pmax = phatags[\"61242\"].value\n            psamp = phatags[\"max_sample_value\"].value\n            if psamp == 0 or pmin == pmax:\n                # no phase data\n                pha = np.zeros_like(inten)\n            else:\n                # optical path difference\n                opd = tf.pages[phaid].asarray() * (pmax - pmin) / psamp + pmin\n                if phaid == 1:  # convert [wavelengths] to [nm]\n                    assert not np.isnan(wl_phasics)\n                    opd *= wl_phasics * 1e9\n                # convert from [nm] to [rad]\n                pha = opd / (self.meta_data[\"wavelength\"] * 1e9) * 2 * np.pi\n\n        meta_data = copy.copy(self.meta_data)\n        if \"time\" not in meta_data:\n            meta_data[\"time\"] = self.get_time()\n        qpi = qpimage.QPImage(data=(pha, inten),\n                              which_data=\"phase,intensity\",\n                              meta_data=meta_data,\n                              h5dtype=self.as_type)\n        # set identifier\n        qpi[\"identifier\"] = self.get_identifier()\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify(path):\n        valid = False\n        try:\n            tf = SingleTifPhasics._get_tif(path)\n        except (ValueError, IsADirectoryError):\n            pass\n        else:\n            if (len(tf) == 3 and\n                \"61243\" in tf.pages[0].tags and\n                \"61242\" in tf.pages[0].tags and\n                \"61238\" in tf.pages[0].tags and\n                \"61243\" in tf.pages[1].tags and\n                \"61242\" in tf.pages[1].tags and\n                \"max_sample_value\" in tf.pages[0].tags and\n                (tf.pages[0].tags[\"61242\"].value !=\n                 tf.pages[1].tags[\"61242\"].value)):\n                valid = True\n        return valid", "response": "Verify that path is a phasics phase or intensity TIFF file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _init(\n            self, default_prefix='_',\n            fext=TMPL_FN_EXT, req_tmpl_name=REQ_TMPL_NAME,\n            text_prefix=REQUIREJS_TEXT_PREFIX,\n            auto_reload=False,\n            *a, **kw):\n        \"\"\"\n        Arguments:\n\n        registry_name\n            The name of this registry.\n        \"\"\"\n\n        self.default_prefix = default_prefix\n        self.molds = {}\n        self.tracked_entry_points = {}\n        self.fext = fext\n        self.req_tmpl_name = req_tmpl_name\n        self.text_prefix = text_prefix\n        self.auto_reload = auto_reload", "response": "Initialize the object properties of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a list of all valid mold_ids from the input template_map and stores them into the molds dictionary.", "response": "def _generate_and_store_mold_id_map(self, template_map, molds):\n        \"\"\"\n        Not a pure generator expression as this has the side effect of\n        storing the resulting id and map it into a local dict.  Produces\n        a list of all valid mold_ids from the input template_keys.\n\n        Internal function; NOT meant to be used outside of this class.\n        \"\"\"\n\n        name = self.req_tmpl_name\n        for key in sorted(template_map.keys(), reverse=True):\n            if len(key.split('/')) == 3 and key.endswith(name):\n                mold_id = key[len(self.text_prefix):-len(name) - 1]\n                molds[mold_id] = template_map[key][:-len(name) - 1]\n                yield mold_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlook up the mold_id and translate it to its filesystem equivalent.", "response": "def lookup_path(self, mold_id_path, default=_marker):\n        \"\"\"\n        For the given mold_id_path, look up the mold_id and translate\n        that path to its filesystem equivalent.\n        \"\"\"\n\n        fragments = mold_id_path.split('/')\n        mold_id = '/'.join(fragments[:2])\n        try:\n            subpath = []\n            for piece in fragments[2:]:\n                if (sep in piece or (altsep and altsep in piece) or\n                        piece == pardir):\n                    raise KeyError\n                elif piece and piece != '.':\n                    subpath.append(piece)\n            path = self.mold_id_to_path(mold_id)\n        except KeyError:\n            if default is _marker:\n                raise\n            return default\n\n        return join(path, *subpath)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify_path(self, mold_id_path):\n\n        try:\n            path = self.lookup_path(mold_id_path)\n            if not exists(path):\n                raise KeyError\n        except KeyError:\n            raise_os_error(ENOENT)\n        return path", "response": "Verify that the path is correct."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the skippers of the configuration.", "response": "def _get_skippers(configure, file_name=None):\n        \"\"\"\n        Returns the skippers of configuration.\n\n        :param configure: The configuration of HaTeMiLe.\n        :type configure: hatemile.util.configure.Configure\n        :param file_name: The file path of skippers configuration.\n        :type file_name: str\n        :return: The skippers of configuration.\n        :rtype: list(dict(str, str))\n        \"\"\"\n\n        skippers = []\n        if file_name is None:\n            file_name = os.path.join(os.path.dirname(os.path.dirname(\n                os.path.dirname(os.path.realpath(__file__))\n            )), 'skippers.xml')\n        xmldoc = minidom.parse(file_name)\n        skippers_xml = xmldoc.getElementsByTagName(\n            'skippers'\n        )[0].getElementsByTagName('skipper')\n        for skipper_xml in skippers_xml:\n            skippers.append({\n                'selector': skipper_xml.attributes['selector'].value,\n                'description': configure.get_parameter(\n                    skipper_xml.attributes['description'].value\n                ),\n                'shortcut': skipper_xml.attributes['shortcut'].value\n            })\n        return skippers"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the list of skippers of page.", "response": "def _generate_list_skippers(self):\n        \"\"\"\n        Generate the list of skippers of page.\n\n        :return: The list of skippers of page.\n        :rtype: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        container = self.parser.find(\n            '#'\n            + AccessibleNavigationImplementation.ID_CONTAINER_SKIPPERS\n        ).first_result()\n        html_list = None\n        if container is None:\n            local = self.parser.find('body').first_result()\n            if local is not None:\n                container = self.parser.create_element('div')\n                container.set_attribute(\n                    'id',\n                    AccessibleNavigationImplementation.ID_CONTAINER_SKIPPERS\n                )\n                local.prepend_element(container)\n        if container is not None:\n            html_list = self.parser.find(container).find_children(\n                'ul'\n            ).first_result()\n            if html_list is None:\n                html_list = self.parser.create_element('ul')\n                container.append_element(html_list)\n        self.list_skippers_added = True\n\n        return html_list"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _generate_list_heading(self):\n\n        local = self.parser.find('body').first_result()\n        id_container_heading_before = (\n            AccessibleNavigationImplementation.ID_CONTAINER_HEADING_BEFORE\n        )\n        id_container_heading_after = (\n            AccessibleNavigationImplementation.ID_CONTAINER_HEADING_AFTER\n        )\n        if local is not None:\n            container_before = self.parser.find(\n                '#'\n                + id_container_heading_before\n            ).first_result()\n            if (container_before is None) and (self.elements_heading_before):\n                container_before = self.parser.create_element('div')\n                container_before.set_attribute(\n                    'id',\n                    id_container_heading_before\n                )\n\n                text_container_before = self.parser.create_element('span')\n                text_container_before.set_attribute(\n                    'class',\n                    AccessibleNavigationImplementation.CLASS_TEXT_HEADING\n                )\n                text_container_before.append_text(self.elements_heading_before)\n\n                container_before.append_element(text_container_before)\n                local.prepend_element(container_before)\n            if container_before is not None:\n                self.list_heading_before = self.parser.find(\n                    container_before\n                ).find_children('ol').first_result()\n                if self.list_heading_before is None:\n                    self.list_heading_before = self.parser.create_element('ol')\n                    container_before.append_element(self.list_heading_before)\n\n            container_after = self.parser.find(\n                '#'\n                + id_container_heading_after\n            ).first_result()\n            if (container_after is None) and (self.elements_heading_after):\n                container_after = self.parser.create_element('div')\n                container_after.set_attribute('id', id_container_heading_after)\n\n                text_container_after = self.parser.create_element('span')\n                text_container_after.set_attribute(\n                    'class',\n                    AccessibleNavigationImplementation.CLASS_TEXT_HEADING\n                )\n                text_container_after.append_text(self.elements_heading_after)\n\n                container_after.append_element(text_container_after)\n                local.append_element(container_after)\n            if container_after is not None:\n                self.list_heading_after = self.parser.find(\n                    container_after\n                ).find_children('ol').first_result()\n                if self.list_heading_after is None:\n                    self.list_heading_after = self.parser.create_element('ol')\n                    container_after.append_element(self.list_heading_after)\n        self.list_heading_added = True", "response": "Generate the list of heading links of page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_heading_level(self, element):\n        # pylint: disable=no-self-use\n\n        tag = element.get_tag_name()\n        if tag == 'H1':\n            return 1\n        elif tag == 'H2':\n            return 2\n        elif tag == 'H3':\n            return 3\n        elif tag == 'H4':\n            return 4\n        elif tag == 'H5':\n            return 5\n        elif tag == 'H6':\n            return 6\n        return -1", "response": "Returns the level of heading."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck that the headings of page are sintatic correct.", "response": "def _is_valid_heading(self):\n        \"\"\"\n        Check that the headings of page are sintatic correct.\n\n        :return: True if the headings of page are sintatic correct or False if\n                 not.\n        :rtype: bool\n        \"\"\"\n\n        elements = self.parser.find('h1,h2,h3,h4,h5,h6').list_results()\n        last_level = 0\n        count_main_heading = 0\n        self.validate_heading = True\n        for element in elements:\n            level = self._get_heading_level(element)\n            if level == 1:\n                if count_main_heading == 1:\n                    return False\n                else:\n                    count_main_heading = 1\n            if (level - last_level) > 1:\n                return False\n            last_level = level\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate an anchor for the element.", "response": "def _generate_anchor_for(self, element, data_attribute, anchor_class):\n        \"\"\"\n        Generate an anchor for the element.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param data_attribute: The name of attribute that links the element\n                               with the anchor.\n        :type data_attribute: str\n        :param anchor_class: The HTML class of anchor.\n        :type anchor_class: str\n        :return: The anchor.\n        :rtype: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        self.id_generator.generate_id(element)\n        if self.parser.find(\n            '[' + data_attribute + '=\"' + element.get_attribute('id') + '\"]'\n        ).first_result() is None:\n            if element.get_tag_name() == 'A':\n                anchor = element\n            else:\n                anchor = self.parser.create_element('a')\n                self.id_generator.generate_id(anchor)\n                anchor.set_attribute('class', anchor_class)\n                element.insert_before(anchor)\n            if not anchor.has_attribute('name'):\n                anchor.set_attribute('name', anchor.get_attribute('id'))\n            anchor.set_attribute(data_attribute, element.get_attribute('id'))\n            return anchor\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _free_shortcut(self, shortcut):\n\n        alpha_numbers = '1234567890abcdefghijklmnopqrstuvwxyz'\n        elements = self.parser.find('[accesskey]').list_results()\n        found = False\n        for element in elements:\n            shortcuts = element.get_attribute('accesskey').lower()\n            if CommonFunctions.in_list(shortcuts, shortcut):\n                for key in alpha_numbers:\n                    found = True\n                    for element_with_shortcuts in elements:\n                        shortcuts = element_with_shortcuts.get_attribute(\n                            'accesskey'\n                        ).lower()\n                        if CommonFunctions.in_list(shortcuts, key):\n                            found = False\n                            break\n                    if found:\n                        element.set_attribute('accesskey', key)\n                        break\n                if found:\n                    break", "response": "Replace the shortcut of elements that have the shortcut passed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a Scrim instance.", "response": "def get_scrim(path=None, auto_write=None, shell=None, script=None, cache={}):\n    '''Get a :class:`Scrim` instance. Each instance is cached so if you call\n    get_scrim again with the same arguments you get the same instance.\n\n    See also:\n        :class:`Scrim`\n    '''\n\n    args = (path, auto_write, shell, script)\n    if args not in cache:\n        cache[args] = Scrim(*args)\n    return cache[args]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add(self, name, *args, **kwargs):\n        '''Appends a command to the scrims list of commands. You should not\n        need to use this.'''\n\n        self.commands.append(Command(name, args, kwargs))", "response": "Appends a command to the scrims list of commands. You should not\n        need to use this."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raw(self, command, required_shell):\n        '''Append a raw command to the scrim. This text will be appeneded to\n        the output of :meth:`scrim.to_string` verbatim. Use required_shell to\n        specify the shell which this raw command is applicable to.\n\n        Examples:\n            >>> scrim = Scrim()\n            >>> scrim.raw('cat text.txt', 'bash')\n            >>> scrim.raw('type text.txt', 'cmd.exe')\n            >>> scrim.raw('Get-Content text.txt', 'powershell.exe')\n            >>> scrim.to_bash()\n            'cat text.txt'\n            >>> scrim.to_cmd()\n            'type text.txt'\n            >>> scrim.to_powershell()\n            'Get-Content text.txt'\n        '''\n\n        if not isinstance(command, basestring):\n            raise TypeError(f('{command} must be a string'))\n\n        if required_shell not in SHELLS:\n            raise ValueError(f('{required_shell} must be one of {SHELLS}'))\n\n        self.commands.append(RawCommand(command, required_shell))", "response": "Append a raw command to the scrim."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nusing the command executor to retrieve the text of the scrim script compatible with the provided shell.", "response": "def to_string(self, shell=None):\n        '''Use the command executor to retrieve the text of the scrim script\n        compatible with the provided shell. If no shell is provided, use\n        :attr:`scrim.shell`.\n\n        Attributes:\n            shell (str): Which shell should we return a script for\n                cmd.exe, powershell.exe, bash...\n\n        Returns:\n            str\n        '''\n\n        shell = shell or self.shell\n        lines = []\n        for c in self.commands:\n            text = self.command_executor(c, shell)\n            if text is not None:\n                lines.append(text)\n\n        return '\\n'.join(lines)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite this Scrims commands to its path", "response": "def write(self):\n        '''Write this Scrims commands to its path'''\n\n        if self.path is None:\n            raise Exception('Scrim.path is None')\n\n        dirname = os.path.dirname(os.path.abspath(self.path))\n        if not os.path.exists(dirname):\n            try:\n                os.makedirs(dirname)\n            except:\n                raise OSError('Failed to create root for scrim output.')\n\n        with open(self.path, 'w') as f:\n            f.write(self.to_string())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef on_exit(self):\n        '''atexit callback. If :attr:`Scrim.auto_write` is True write the\n        scrim to :attr:`Scrim.path` as :attr:`Scrim.shell`'''\n\n        if not all([self.auto_write, self.commands, self.script, self.path]):\n            return\n\n        self.write()", "response": "atexit callback. Write the scraper to the path as the shell."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves any Orphan objects that have been created by the given instance.", "response": "def remove_orphans(self, instance, **kwargs):\n      \"\"\"\n      When an item is deleted, first delete any Activity object that has been created\n      on its behalf.\n      \"\"\"\n      from activity_monitor.models import Activity\n      try:\n        instance_content_type = ContentType.objects.get_for_model(instance)\n        timeline_item = Activity.objects.get(content_type=instance_content_type, object_id=instance.pk)\n        timeline_item.delete()\n      except Activity.DoesNotExist:\n        return"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfollow a particular model class updating associated Activity objects automatically.", "response": "def follow_model(self, model):\n        \"\"\"\n        Follow a particular model class, updating associated Activity objects automatically.\n        \"\"\"\n        if model:\n          self.models_by_name[model.__name__.lower()] = model\n          signals.post_save.connect(create_or_update, sender=model)\n          signals.post_delete.connect(self.remove_orphans, sender=model)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a QuerySet of only items of a certain type.", "response": "def get_for_model(self, model):\n        \"\"\"\n        Return a QuerySet of only items of a certain type.\n        \"\"\"\n        return self.filter(content_type=ContentType.objects.get_for_model(model))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_last_update_of_model(self, model, **kwargs):\n        qs = self.get_for_model(model)\n        if kwargs:\n            qs = qs.filter(**kwargs)\n        try:\n            return qs.order_by('-timestamp')[0].timestamp\n        except IndexError:\n            return datetime.datetime.fromtimestamp(0)", "response": "Returns the last time a given model s items were updated. Returns the\n        epoch if the items were never updated."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef for_each(self, operation, limit=0, verbose=False):\n        if limit != 0:\n            count = 0\n            while self.has_next():\n                operation.perform(self.next())\n                count += 1\n                if verbose:\n                    print count\n                if count >= limit:\n                    break\n        else:\n            while self.has_next():\n                operation.perform(self.next())", "response": "Applies the given Operation to each item in the stream."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_lookup_string(self, lookup_chain):\n        lookup_chain = lookup_chain.split('__')\n        comparator = self.default_comparator\n\n        # Only look for a lookup method if the lookup chain is larger than 1\n        if len(lookup_chain) <= 1:\n            return lookup_chain, comparator\n\n        # Get the correct lookup_method if the last value in the lookup\n        # chain is a lookup method specifier\n        if lookup_chain[-1] in self.comparators:\n            comparator = self.comparators.get(lookup_chain.pop(-1))\n\n        return lookup_chain, comparator", "response": "Convert a lookup string to a ( lookup_chain comparator ) tuple."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _resolve_lookup_chain(self, chain, instance):\n        value = instance\n\n        for link in chain:\n            value = getattr(value, link)\n\n        return value", "response": "Return the value of the instance s attribute in the chain."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iregex(value, iregex):\n        return re.match(iregex, value, flags=re.I)", "response": "Returns true if the value case insentively matches agains the\n        regex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all subdirectories of a directory.", "response": "def get_subdirectories(directory):\r\n    \"\"\" Get subdirectories without pycache \"\"\"\r\n    return [name for name in os.listdir(directory)\r\n            if name != '__pycache__'\r\n            if os.path.isdir(os.path.join(directory, name))]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing field values from config. json and collect from request", "response": "def __collect_fields(self):\r\n        \"\"\" Use field values from config.json and collect from request \"\"\"\r\n        form = FormData()\r\n        form.add_field(self.__username_field, required=True,\r\n                       error=self.__username_error)\r\n        form.add_field(self.__password_field, required=True,\r\n                       error=self.__password_error)\r\n        form.parse()\r\n        self.username = form.values[self.__username_field]\r\n        self.password = form.values[self.__password_field]\r\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a session token", "response": "def session(self) -> str:\r\n        \"\"\" Generate a session(authorization Bearer) JWT token \"\"\"\r\n        session_jwt = None\r\n        self.user = self.user_model.where_username(self.username)\r\n        if self.user is None:\r\n            return None\r\n        self.user.updated()  # update timestamp on user access\r\n        if self.verify_password(self.user.password):\r\n            session_id = Session.create_session_id()\r\n            data = {\r\n                'session_id': session_id,\r\n                'user_id': self.user.id,\r\n                'user_email': self.user.email,\r\n            }\r\n            token_valid_for = \\\r\n                current_app.config['AUTH']['JWT']['TOKENS']['VALID_FOR'] if \\\r\n                'VALID_FOR' in \\\r\n                current_app.config['AUTH']['JWT']['TOKENS'] else 180\r\n            if current_app.config['AUTH']['JWT']['REFRESH_TOKENS']['ENABLED']:\r\n                refresh_token_valid_for = \\\r\n                    current_app \\\r\n                    .config['AUTH']['JWT']['REFRESH_TOKENS']['VALID_FOR'] if \\\r\n                    'VALID_FOR' in \\\r\n                    current_app.config['AUTH']['JWT']['REFRESH_TOKENS'] else \\\r\n                    86400\r\n                session_jwt = JWT().create_token_with_refresh_token(\r\n                    data,\r\n                    token_valid_for,\r\n                    refresh_token_valid_for)\r\n            else:\r\n                session_jwt = JWT().create_token(data, token_valid_for)\r\n            Session.create_session(session_id, self.user.id)\r\n            return session_jwt\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_board(board_id, board_options, hwpack='arduino', replace_existing=False):\n    doaction = 0\n    if board_id in boards(hwpack).keys():\n        log.debug('board already exists: %s', board_id)\n        if replace_existing:\n            log.debug('remove board: %s' , board_id)\n            remove_board(board_id)\n            doaction = 1\n    else:\n        doaction = 1\n\n    if doaction:\n        lines = bunch2properties(board_id, board_options)\n        boards_txt().write_lines([''] + lines, append=1)", "response": "install board in boards. txt."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a nested interval.", "response": "def _parse_nested_interval(self, tokens):\n        \"\"\" Parses a super range.\n         SuperRange ::= Range | Join | Complement\n        \"\"\"\n        if tokens[0].isdigit():\n            return self._parse_interval(tokens)\n        elif tokens[0] in ['join', 'order']:\n            return self._parse_join(tokens)\n        elif tokens[0] == 'complement':\n            return self._parse_complement(tokens)\n        raise ValueError('interval {} does not fit pattern.'.format(tokens))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_interval(self, tokens):\n        fr = int(tokens.pop(0)) - 1\n        if len(tokens) > 1 and tokens[0] in ['..', '^']:\n            tokens.pop(0)  # Pop '..' | '^'\n            to = int(tokens.pop(0))\n            return GenomicInterval(fr, to, chromosome=self.hdr['ACCESSION']['value'])\n        return GenomicInterval(fr, fr + 1, chromosome=self.hdr['ACCESSION']['value'])", "response": "Parses a range\n         and returns a GenomicInterval object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses a join. nanoset.", "response": "def _parse_join(self, tokens):\n        \"\"\" Parses a join.\n         Join ::= 'join' '(' SuperRange [',' SuperRange] ')'\n        \"\"\"\n        children = []\n        tokens.pop(0)  # Pop 'join'\n        tokens.pop(0)  # Pop '('\n        children.append(self._parse_nested_interval(tokens))\n        while tokens[0] == ',':\n            tokens.pop(0)\n            children.append(self._parse_nested_interval(tokens))\n        tokens.pop(0)  # Pop ')'\n\n        chromosome, strand = next((child.chromosome, child.strand) for child in children)\n        start = min(child.start.position for child in children)\n        stop = max(child.stop.position for child in children)\n        parent = NestedGenomicInterval(start, stop, chromosome=chromosome, strand=strand)\n        parent.children = children\n        return parent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse a complement Complement ::= 'complement' '(' SuperRange ')'", "response": "def _parse_complement(self, tokens):\n        \"\"\" Parses a complement\n         Complement ::= 'complement' '(' SuperRange ')'\n        \"\"\"\n        tokens.pop(0)  # Pop 'complement'\n        tokens.pop(0)  # Pop '('\n        res = self._parse_nested_interval(tokens)\n        tokens.pop(0)  # Pop ')'\n        res.switch_strand()\n        return res"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cycles(cls, **kwargs):\n        if \"loc\" not in kwargs:\n            if \"point\" not in kwargs:\n                if \"lat\" not in kwargs or \"lon\" not in kwargs:\n                    raise ValueError(\"You must supply some form of lat/lon coordinates\")\n                else:\n                    lat = kwargs.get(\"lat\")\n                    lon = kwargs.get(\"lon\")\n            else:\n                lat = kwargs.get(\"point\").y\n                lon = kwargs.get(\"point\").x\n            if \"time\" not in kwargs:\n                raise ValueError(\"You must supply a datetime object\")\n            else:\n                time = kwargs.get(\"time\")\n        else:\n            lat = kwargs.get(\"loc\").latitude\n            lon = kwargs.get(\"loc\").longitude\n            time = kwargs.get(\"loc\").time\n\n        # Convert time to UTC.  Save passed in timezone to return later.\n        if time.tzinfo is None:\n            time = time.replace(tzinfo=pytz.utc)\n            original_zone = pytz.utc\n        else:\n            original_zone = time.tzinfo\n\n        local_jd = time.timetuple().tm_yday\n        utc_jd = time.astimezone(pytz.utc).timetuple().tm_yday\n\n        # We ALWAYS want to return the sunrise/sunset for the day that was passed\n        # in (with timezone accounted for), regardless of what the UTC day is.  Modify\n        # the UTC julian day here if need be.\n        comp = cmp(utc_jd, local_jd)\n        if comp == 1:\n            utc_jd -= 1\n        elif comp == -1:\n            utc_jd += 1\n\n        time = time.replace(hour=0, minute=0, second=0, microsecond=0)\n\n        rising_h, rising_m = cls._calc(jd=utc_jd, lat=lat, lon=lon, stage=cls.RISING)\n        setting_h, setting_m = cls._calc(jd=utc_jd, lat=lat, lon=lon, stage=cls.SETTING)\n\n        # _calc returns UTC hours and minutes, so assume time is in UTC for a few lines...\n        rising = time.replace(tzinfo=pytz.utc) + timedelta(hours=rising_h, minutes=rising_m)\n        setting = time.replace(tzinfo=pytz.utc) + timedelta(hours=setting_h, minutes=setting_m)\n        # LOOK: We may be adding 24 hours to the setting time.  Why?\n        if setting < rising:\n            setting = setting + timedelta(hours=24)\n\n        rising = rising.astimezone(original_zone)\n        setting = setting.astimezone(original_zone)\n\n        return { cls.RISING : rising, cls.SETTING : setting}", "response": "This method returns the sunrise and sunset for the specified date and time."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _calc(cls, **kwargs):\n        zenith = 90.833333 # offical value\n\n        jd = kwargs.get(\"jd\", None)\n        lat = kwargs.get(\"lat\", None)\n        lon = kwargs.get(\"lon\", None)\n        stage = kwargs.get(\"stage\", None)\n        if jd is None or stage is None or lat is None or lon is None:\n            raise ValueError(\"Must supply an 'jd', 'lat, 'lon', and 'stage' parameter\")\n\n        if stage != SunCycles.RISING and stage != SunCycles.SETTING:\n            raise ValueError(\"'stage' parameter must be %s or %s\" % (SunCycles.RISING, SunCycles.SETTING))\n\n        longhr = lon / 15.\n        if stage == SunCycles.RISING:\n            apx = jd + ( (6 - longhr) / 24 )\n        elif stage == SunCycles.SETTING:\n            apx = jd + ( (18 - longhr) / 24 )\n\n        sun_mean_anom = ( 0.9856 * apx ) - 3.289 # sun's mean anomaly\n        #sun's longitude\n        sun_lon = sun_mean_anom + (1.916 * np.sin( np.radians(sun_mean_anom) )) \\\n                + (0.02 * np.sin( np.radians(2 * sun_mean_anom) )) + 282.634\n\n        if sun_lon > 360:\n            sun_lon = sun_lon - 360\n        elif sun_lon < 0:\n            sun_lon = sun_lon + 360\n\n        right_ascension = np.degrees(np.arctan( 0.91764 * np.tan( np.radians(sun_lon) ) )) # sun's right ascension\n\n        if right_ascension > 360:\n            right_ascension = right_ascension - 360\n        elif right_ascension < 0:\n            right_ascension = right_ascension + 360\n\n        # put sun's right ascension value in the same quadrant as the sun's\n        # true longitude\n        lQuad = 90. * np.floor(sun_lon / 90.)\n        raQuad = 90. * np.floor(right_ascension / 90.)\n        right_ascension = right_ascension + ( lQuad - raQuad)\n        right_ascension = right_ascension / 15. # Convert to hours\n\n        # Sun's declination\n        sinDecl = 0.39782 * np.sin( np.radians(sun_lon) )\n        cosDecl = np.cos( np.arcsin( sinDecl ) )\n\n        # Sun's local hour angle\n        cosHr = (np.cos( np.radians(zenith) ) - ( sinDecl * np.sin(np.radians(lat)) )) \\\n                / ( cosDecl * np.cos( np.radians(lat) ) )\n\n        if cosHr > 1: # Sun doesnt rise on this loc on this date\n            return -1, -1\n        elif cosHr < -1: # Sun doesnt set on this location on this date\n            return -1, -1\n        elif stage == SunCycles.RISING: # Sunrise\n            hr = 360 - np.degrees(np.arccos(cosHr))\n        elif stage == SunCycles.SETTING:  # Sunset\n            hr = np.degrees(np.arccos(cosHr))\n\n        hr = hr / 15. # Convert angle to hours\n\n        localTime = hr + right_ascension - ( 0.06571 * apx ) - 6.622# local meantime of rise/set\n\n        UTtime = localTime - longhr # adjust to UTC\n\n        if UTtime < 0:\n            UTtime = UTtime + 24\n        elif UTtime > 24:\n            UTtime = UTtime - 24\n\n        hour = np.floor(UTtime)\n\n        minute = (UTtime - hour) * 60\n        if minute == 60:\n            hour = hour + 1\n            minute = 0\n\n        return hour, minute", "response": "Calculate sunrise or sunset based on the given parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a data structure containing all indels in the read.", "response": "def get_indels( self, one_based=True ):\n        \"\"\"Return a data structure containing all indels in the read.\n        Returns the tuple (insertions, deletions)\n        insertions = [(pos1,ins1), (pos2,ins2)]\n        posN = start position (preceding base, VCF-style)\n        insN = length of inserted sequence (not including preceding base)\n        deletions = [(pos1,del1), (pos2,del2)]\n        posN = start position (preceding base, VCF-style)\n        delN = length of deleted sequence (not including preceding base)\n        \"\"\"\n        cigar = self.get_cigar() #CIGAR_OP = list( 'MIDNSHP=X' )\n        insertions = []\n        deletions = []\n        position_offset = 0\n        position_start = self.get_position( one_based=one_based )\n        while cigar:\n            cigar_size, cigar_op = cigar.pop( 0 )\n            if cigar_op in [ 0, 7, 8 ]: #M alignment match (can be a sequence match or mismatch); = sequence match; x sequence mismatch\n                position_offset += cigar_size\n            elif cigar_op == 1: #I insertion\n                insertions.append((position_start + position_offset - 1, cigar_size))\n            elif cigar_op == 2: #D deletion from the reference\n                deletions.append((position_start + position_offset - 1, cigar_size))\n                position_offset += cigar_size\n            elif cigar_op == 3: #N skipped region from the reference\n                position_offset += cigar_size\n            elif cigar_op == 4: #S soft clipping (clipped sequences present in SEQ)\n                pass\n            elif cigar_op == 5: #H hard clipping (clipped sequences NOT present in SEQ)\n                position_offset += cigar_size\n            elif cigar_op == 6: #P padding (silent deletion from padded reference)\n                pass\n            else: #unknown cigar_op\n                print >>sys.stderr, 'unknown cigar_op', cigar_op, cigar_size\n        return (insertions, deletions)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload the symbols from the file.", "response": "def _set_symbols(self, file_name, configure):\n        \"\"\"\n        Load the symbols with configuration.\n\n        :param file_name: The file path of symbol configuration.\n        :type file_name: str\n        :param configure: The configuration of HaTeMiLe.\n        :type configure: hatemile.util.configure.Configure\n        \"\"\"\n\n        self.symbols = []\n        if file_name is None:\n            file_name = os.path.join(os.path.dirname(os.path.dirname(\n                os.path.dirname(os.path.realpath(__file__))\n            )), 'symbols.xml')\n        xmldoc = minidom.parse(file_name)\n        symbols_xml = xmldoc.getElementsByTagName(\n            'symbols'\n        )[0].getElementsByTagName('symbol')\n        for symbol_xml in symbols_xml:\n            self.symbols.append({\n                'symbol': symbol_xml.attributes['symbol'].value,\n                'description': configure.get_parameter(\n                    symbol_xml.attributes['description'].value\n                )\n            })"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the symbol formated to be searched by regular expression.", "response": "def _get_formated_symbol(self, symbol):\n        \"\"\"\n        Returns the symbol formated to be searched by regular expression.\n\n        :param symbol: The symbol.\n        :type symbol: str\n        :return: The symbol formated.\n        :rtype: str\n        \"\"\"\n        # pylint: disable=no-self-use\n\n        old_symbols = [\n            '\\\\',\n            '.',\n            '+',\n            '*',\n            '?',\n            '^',\n            '$',\n            '[',\n            ']',\n            '{',\n            '}',\n            '(',\n            ')',\n            '|',\n            '/',\n            ',',\n            '!',\n            '=',\n            ':',\n            '-'\n        ]\n        replace_dict = {\n            '\\\\': '\\\\\\\\',\n            '.': r'\\.',\n            '+': r'\\+',\n            '*': r'\\*',\n            '?': r'\\?',\n            '^': r'\\^',\n            '$': r'\\$',\n            '[': r'\\[',\n            ']': r'\\]',\n            '{': r'\\{',\n            '}': r'\\}',\n            '(': r'\\(',\n            ')': r'\\)',\n            '|': r'\\|',\n            '/': r'\\/',\n            ',': r'\\,',\n            '!': r'\\!',\n            '=': r'\\=',\n            ':': r'\\:',\n            '-': r'\\-'\n        }\n        for old in old_symbols:\n            symbol = symbol.replace(old, replace_dict[old])\n        return symbol"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the regular expression to search all symbols.", "response": "def _get_regular_expression_of_symbols(self):\n        \"\"\"\n        Returns the regular expression to search all symbols.\n\n        :return: The regular expression to search all symbols.\n        :rtype: str\n        \"\"\"\n\n        regular_expression = None\n        for symbol in self.symbols:\n            formated_symbol = self._get_formated_symbol(symbol['symbol'])\n            if regular_expression is None:\n                regular_expression = '(' + formated_symbol + ')'\n            else:\n                regular_expression = (\n                    regular_expression +\n                    '|(' +\n                    formated_symbol +\n                    ')'\n                )\n        return regular_expression"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the children of element can be manipulated to apply the CSS the CSS properties.", "response": "def _is_valid_inherit_element(self, element):\n        \"\"\"\n        Check that the children of element can be manipulated to apply the CSS\n        properties.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :return: True if the children of element can be manipulated to apply\n                 the CSS properties or False if the children of element cannot\n                 be manipulated to apply the CSS properties.\n        :rtype: bool\n        \"\"\"\n        # pylint: disable=no-self-use\n\n        tag_name = element.get_tag_name()\n        return (\n            (tag_name in AccessibleCSSImplementation.VALID_INHERIT_TAGS)\n            and (not element.has_attribute(CommonFunctions.DATA_IGNORE))\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nisolates text nodes of element nodes. :param element: The element. :type element: hatemile.util.html.htmldomelement.HTMLDOMElement", "response": "def _isolate_text_node(self, element):\n        \"\"\"\n        Isolate text nodes of element nodes.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        if (\n            (element.has_children_elements())\n            and (self._is_valid_element(element))\n        ):\n            if self._is_valid_element(element):\n                child_nodes = element.get_children()\n                for child_node in child_nodes:\n                    if isinstance(child_node, HTMLDOMTextNode):\n                        span = self.html_parser.create_element('span')\n                        span.set_attribute(\n                            AccessibleCSSImplementation.DATA_ISOLATOR_ELEMENT,\n                            'true'\n                        )\n                        span.append_text(child_node.get_text_content())\n\n                        child_node.replace_node(span)\n            children = element.get_children_elements()\n            for child in children:\n                self._isolate_text_node(child)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _replace_element_by_own_content(self, element):\n        # pylint: disable=no-self-use\n\n        if element.has_children_elements():\n            children = element.get_children_elements()\n            for child in children:\n                element.insert_before(child)\n            element.remove_node()\n        elif element.has_children():\n            element.replace_node(element.get_first_node_child())", "response": "Replace the element by own text content."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvisit and execute a operation in element and descendants.", "response": "def _visit(self, element, operation):\n        \"\"\"\n        Visit and execute a operation in element and descendants.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param operation: The operation to be executed.\n        :type operation: function\n        \"\"\"\n\n        if self._is_valid_inherit_element(element):\n            if element.has_children_elements():\n                children = element.get_children_elements()\n                for child in children:\n                    self._visit(child, operation)\n            elif self._is_valid_element(element):\n                operation(element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a element to show the content.", "response": "def _create_content_element(self, content, data_property_value):\n        \"\"\"\n        Create a element to show the content.\n\n        :param content: The text content of element.\n        :type content: str\n        :param data_property_value: The value of custom attribute used to\n                                    identify the fix.\n        :type data_property_value: str\n        :return: The element to show the content.\n        :rtype: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        content_element = self.html_parser.create_element('span')\n        content_element.set_attribute(\n            AccessibleCSSImplementation.DATA_ISOLATOR_ELEMENT,\n            'true'\n        )\n        content_element.set_attribute(\n            AccessibleCSSImplementation.DATA_SPEAK_AS,\n            data_property_value\n        )\n        content_element.append_text(content)\n        return content_element"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates an element to show the content only to aural displays.", "response": "def _create_aural_content_element(self, content, data_property_value):\n        \"\"\"\n        Create a element to show the content, only to aural displays.\n\n        :param content: The text content of element.\n        :type content: str\n        :param data_property_value: The value of custom attribute used to\n                                    identify the fix.\n        :type data_property_value: str\n        :return: The element to show the content.\n        :rtype: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        content_element = self._create_content_element(\n            content,\n            data_property_value\n        )\n        content_element.set_attribute('unselectable', 'on')\n        content_element.set_attribute('class', 'screen-reader-only')\n        return content_element"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_visual_content_element(self, content, data_property_value):\n\n        content_element = self._create_content_element(\n            content,\n            data_property_value\n        )\n        content_element.set_attribute('aria-hidden', 'true')\n        content_element.set_attribute('role', 'presentation')\n        return content_element", "response": "Create a visual content element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _speak_normal(self, element):\n\n        if element.has_attribute(AccessibleCSSImplementation.DATA_SPEAK):\n            if (\n                (element.get_attribute(\n                    AccessibleCSSImplementation.DATA_SPEAK\n                ) == 'none')\n                and (not element.has_attribute(\n                    AccessibleCSSImplementation.DATA_ISOLATOR_ELEMENT\n                ))\n            ):\n                element.remove_attribute('role')\n                element.remove_attribute('aria-hidden')\n                element.remove_attribute(\n                    AccessibleCSSImplementation.DATA_SPEAK\n                )\n            else:\n                self._replace_element_by_own_content(element)", "response": "Speak the content of element only."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nspeaks the content of element and descendants.", "response": "def _speak_normal_inherit(self, element):\n        \"\"\"\n        Speak the content of element and descendants.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        self._visit(element, self._speak_normal)\n\n        element.normalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _speak_none(self, element):\n        # pylint: disable=no-self-use\n\n        element.set_attribute('role', 'presentation')\n        element.set_attribute('aria-hidden', 'true')\n        element.set_attribute(AccessibleCSSImplementation.DATA_SPEAK, 'none')", "response": "No speak any content of element only."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _speak_as(\n        self,\n        element,\n        regular_expression,\n        data_property_value,\n        operation\n    ):\n        \"\"\"\n        Execute a operation by regular expression for element only.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param regular_expression: The regular expression.\n        :type regular_expression: str\n        :param data_property_value: The value of custom attribute used to\n                                    identify the fix.\n        :type data_property_value: str\n        :param operation: The operation to be executed.\n        :type operation: function\n        \"\"\"\n\n        children = []\n        pattern = re.compile(regular_expression)\n        content = element.get_text_content()\n        while content:\n            matches = pattern.search(content)\n            if matches is not None:\n                index = matches.start()\n                children = operation(content, index, children)\n\n                new_index = index + 1\n                content = content[new_index:]\n            else:\n                break\n        if children:\n            if content:\n                children.append(self._create_content_element(\n                    content,\n                    data_property_value\n                ))\n            while element.has_children():\n                element.get_first_node_child().remove_node()\n            for child in children:\n                element.append_element(child)", "response": "Execute a operation by regular expression for element only."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrevert changes of a speak_as method for element and descendants.", "response": "def _reverse_speak_as(self, element, data_property_value):\n        \"\"\"\n        Revert changes of a speak_as method for element and descendants.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param data_property_value: The value of custom attribute used to\n                                    identify the fix.\n        :type data_property_value: str\n        \"\"\"\n\n        data_property = (\n            '['\n            + AccessibleCSSImplementation.DATA_SPEAK_AS\n            + '=\"'\n            + data_property_value\n            + '\"]'\n        )\n\n        auxiliar_elements = self.html_parser.find(element).find_descendants(\n            data_property\n        ).list_results()\n        for auxiliar_element in auxiliar_elements:\n            auxiliar_element.remove_node()\n\n        content_elements = self.html_parser.find(element).find_descendants(\n            data_property\n        ).list_results()\n        for content_element in content_elements:\n            if (\n                (element.has_attribute(\n                    AccessibleCSSImplementation.DATA_ISOLATOR_ELEMENT\n                ))\n                and (element.has_attribute(\n                    AccessibleCSSImplementation.DATA_ISOLATOR_ELEMENT\n                ) == 'true')\n            ):\n                self._replace_element_by_own_content(content_element)\n\n        element.normalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _speak_as_normal(self, element):\n\n        self._reverse_speak_as(element, 'spell-out')\n        self._reverse_speak_as(element, 'literal-punctuation')\n        self._reverse_speak_as(element, 'no-punctuation')\n        self._reverse_speak_as(element, 'digits')", "response": "Use the default speak configuration of user agent for element and\n        descendants."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _speak_as_spell_out_inherit(self, element):\n\n        self._reverse_speak_as(element, 'spell-out')\n\n        self._isolate_text_node(element)\n\n        self._visit(element, self._speak_as_spell_out)", "response": "Speak one letter at a time for each word for elements and descendants."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _speak_as_literal_punctuation(self, element):\n\n        self._speak_as(\n            element,\n            self._get_regular_expression_of_symbols(),\n            'literal-punctuation',\n            self._operation_speak_as_literal_punctuation\n        )", "response": "Speak the punctuation for elements only."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nspeak the punctuation for elements and descendants.", "response": "def _speak_as_literal_punctuation_inherit(self, element):\n        \"\"\"\n        Speak the punctuation for elements and descendants.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        self._reverse_speak_as(element, 'literal-punctuation')\n        self._reverse_speak_as(element, 'no-punctuation')\n\n        self._isolate_text_node(element)\n\n        self._visit(element, self._speak_as_literal_punctuation)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _speak_as_digits_inherit(self, element):\n\n        self._reverse_speak_as(element, 'digits')\n\n        self._isolate_text_node(element)\n\n        self._visit(element, self._speak_as_digits)", "response": "Speak the digit at a time for each number for element and descendants."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _speak_header_always_inherit(self, element):\n\n        self._speak_header_once_inherit(element)\n\n        cell_elements = self.html_parser.find(element).find_descendants(\n            'td[headers],th[headers]'\n        ).list_results()\n        accessible_display = AccessibleDisplayImplementation(\n            self.html_parser,\n            self.configure\n        )\n        for cell_element in cell_elements:\n            accessible_display.display_cell_header(cell_element)", "response": "The cells headers will be spoken for every data cell for element and their descendants."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _speak_header_once_inherit(self, element):\n\n        header_elements = self.html_parser.find(element).find_descendants(\n            '['\n            + AccessibleDisplayImplementation.DATA_ATTRIBUTE_HEADERS_OF\n            + ']'\n        ).list_results()\n        for header_element in header_elements:\n            header_element.remove_node()", "response": "Speak header once inheriting the element and descendants."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _provide_speak_properties_with_rule(self, element, rule):\n\n        if rule.has_property('speak'):\n            declarations = rule.get_declarations('speak')\n            for declaration in declarations:\n                property_value = declaration.get_value()\n                if property_value == 'none':\n                    self._speak_none_inherit(element)\n                elif property_value == 'normal':\n                    self._speak_normal_inherit(element)\n                elif property_value == 'spell-out':\n                    self._speak_as_spell_out_inherit(element)\n        if rule.has_property('speak-as'):\n            declarations = rule.get_declarations('speak-as')\n            for declaration in declarations:\n                speak_as_values = declaration.get_values()\n                self._speak_as_normal(element)\n                for speak_as_value in speak_as_values:\n                    if speak_as_value == 'spell-out':\n                        self._speak_as_spell_out_inherit(element)\n                    elif speak_as_value == 'literal-punctuation':\n                        self._speak_as_literal_punctuation_inherit(element)\n                    elif speak_as_value == 'no-punctuation':\n                        self._speak_as_no_punctuation_inherit(element)\n                    elif speak_as_value == 'digits':\n                        self._speak_as_digits_inherit(element)\n        if rule.has_property('speak-punctuation'):\n            declarations = rule.get_declarations('speak-punctuation')\n            for declaration in declarations:\n                property_value = declaration.get_value()\n                if property_value == 'code':\n                    self._speak_as_literal_punctuation_inherit(element)\n                elif property_value == 'none':\n                    self._speak_as_no_punctuation_inherit(element)\n        if rule.has_property('speak-numeral'):\n            declarations = rule.get_declarations('speak-numeral')\n            for declaration in declarations:\n                property_value = declaration.get_value()\n                if property_value == 'digits':\n                    self._speak_as_digits_inherit(element)\n                elif property_value == 'continuous':\n                    self._speak_as_continuous_inherit(element)\n        if rule.has_property('speak-header'):\n            declarations = rule.get_declarations('speak-header')\n            for declaration in declarations:\n                property_value = declaration.get_value()\n                if property_value == 'always':\n                    self._speak_header_always_inherit(element)\n                elif property_value == 'once':\n                    self._speak_header_once_inherit(element)", "response": "Provides the CSS features of speaking and speech properties in element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef commonprefix(m):\r\n    u\"Given a list of pathnames, returns the longest common leading component\"\r\n    if not m:\r\n        return ''\r\n    prefix = m[0]\r\n    for item in m:\r\n        for i in range(len(prefix)):\r\n            if prefix[:i + 1].lower() != item[:i + 1].lower():\r\n                prefix = prefix[:i]\r\n                if i == 0:\r\n                    return u''\r\n                break\r\n    return prefix", "response": "u Given a list of pathnames returns the longest common leading component"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninitialize search prompt self. argument = keyinfo. char", "response": "def _init_digit_argument(self, keyinfo):\r\n        \"\"\"Initialize search prompt\r\n        \"\"\"\r\n        c = self.console\r\n        line = self.l_buffer.get_line_text()\r\n        self._digit_argument_oldprompt = self.prompt\r\n        queue = self.process_keyevent_queue\r\n        queue = self.process_keyevent_queue\r\n        queue.append(self._process_digit_argument_keyevent)\r\n\r\n        if keyinfo.char == \"-\":\r\n            self.argument = -1\r\n        elif keyinfo.char in u\"0123456789\":\r\n            self.argument = int(keyinfo.char)\r\n        log(u\"<%s> %s\"%(self.argument, type(self.argument)))\r\n        self.prompt = u\"(arg: %s) \"%self.argument\r\n        log(u\"arg-init %s %s\"%(self.argument, keyinfo.char))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _process_keyevent(self, keyinfo):\r\n        #Process exit keys. Only exit on empty line\r\n        log(u\"_process_keyevent <%s>\"%keyinfo)\r\n\r\n        def nop(e):\r\n            pass\r\n        if self.next_meta:\r\n            self.next_meta = False\r\n            keyinfo.meta = True\r\n        keytuple = keyinfo.tuple()\r\n\r\n        if self._insert_verbatim:\r\n            self.insert_text(keyinfo)\r\n            self._insert_verbatim = False\r\n            self.argument = 0\r\n            return False\r\n\r\n        if keytuple in self.exit_dispatch:\r\n            pars = (self.l_buffer, lineobj.EndOfLine(self.l_buffer))\r\n            log(u\"exit_dispatch:<%s, %s>\"%pars)\r\n            if lineobj.EndOfLine(self.l_buffer) == 0:\r\n                raise EOFError\r\n        if keyinfo.keyname or keyinfo.control or keyinfo.meta:\r\n            default = nop\r\n        else:\r\n            default = self.self_insert\r\n        dispatch_func = self.key_dispatch.get(keytuple, default)\r\n\r\n        log(u\"readline from keyboard:<%s,%s>\"%(keytuple, dispatch_func))\r\n\r\n        r = None\r\n        if dispatch_func:\r\n            r = dispatch_func(keyinfo)\r\n            self._keylog(dispatch_func, self.l_buffer)\r\n            self.l_buffer.push_undo()\r\n\r\n        self.previous_func = dispatch_func\r\n        return r", "response": "uProcess a keyevent and return True when line is final\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef previous_history(self, e):  # (C-p)\r\n        u'''Move back through the history list, fetching the previous\r\n        command. '''\r\n        self._history.previous_history(self.l_buffer)\r\n        self.l_buffer.point = lineobj.EndOfLine\r\n        self.finalize()", "response": "Move back through the history list fetching the previous command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove forward through the history list fetching the next command.", "response": "def next_history(self, e):  # (C-n)\r\n        u'''Move forward through the history list, fetching the next\r\n        command. '''\r\n        self._history.next_history(self.l_buffer)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmove to the end of the history i. e. the line currently being entered.", "response": "def end_of_history(self, e):  # (M->)\r\n        u'''Move to the end of the input history, i.e., the line currently\r\n        being entered.'''\r\n        self._history.end_of_history(self.l_buffer)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reverse_search_history(self, e):  # (C-r)\r\n        u'''Search backward starting at the current line and moving up\r\n        through the history as necessary. This is an incremental search.'''\r\n        log(\"rev_search_history\")\r\n        self._init_incremental_search(self._history.reverse_search_history, e)\r\n        self.finalize()", "response": "Reverse the history of the entries in the current line."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nforwards search through the history.", "response": "def forward_search_history(self, e):  # (C-s)\r\n        u'''Search forward starting at the current line and moving down\r\n        through the the history as necessary. This is an incremental\r\n        search.'''\r\n        log(\"fwd_search_history\")\r\n        self._init_incremental_search(self._history.forward_search_history, e)\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch forward through the history for the string of characters between the start of the current line and the point.", "response": "def history_search_forward(self, e):  # ()\r\n        u'''Search forward through the history for the string of characters\r\n        between the start of the current line and the point. This is a\r\n        non-incremental search. By default, this command is unbound.'''\r\n        if (self.previous_func and\r\n            hasattr(self._history, self.previous_func.__name__)):\r\n            self._history.lastcommand = getattr(self._history,\r\n                                                self.previous_func.__name__)\r\n        else:\r\n            self._history.lastcommand = None\r\n        q = self._history.history_search_forward(self.l_buffer)\r\n        self.l_buffer = q\r\n        self.l_buffer.point = q.point\r\n        self.finalize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tab_insert(self, e):  # (M-TAB)\r\n        u'''Insert a tab character. '''\r\n        cursor = min(self.l_buffer.point, len(self.l_buffer.line_buffer))\r\n        ws = ' ' * (self.tabstop - (cursor % self.tabstop))\r\n        self.insert_text(ws)\r\n        self.finalize()", "response": "Insert a tab character."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ninitializing the command mode.", "response": "def init_editing_mode(self, e):  # (C-e)\r\n        u'''When in vi command mode, this causes a switch to emacs editing\r\n        mode.'''\r\n        self._bind_exit_key(u'Control-d')\r\n        self._bind_exit_key(u'Control-z')\r\n\r\n        # I often accidentally hold the shift or control while typing space\r\n        self._bind_key(u'space',       self.self_insert)\r\n        self._bind_key(u'Shift-space',       self.self_insert)\r\n        self._bind_key(u'Control-space',     self.self_insert)\r\n        self._bind_key(u'Return',            self.accept_line)\r\n        self._bind_key(u'Left',              self.backward_char)\r\n        self._bind_key(u'Control-b',         self.backward_char)\r\n        self._bind_key(u'Right',             self.forward_char)\r\n        self._bind_key(u'Control-f',         self.forward_char)\r\n        self._bind_key(u'Control-h',         self.backward_delete_char)\r\n        self._bind_key(u'BackSpace',         self.backward_delete_char)\r\n        self._bind_key(u'Control-BackSpace', self.backward_delete_word)\r\n\r\n        self._bind_key(u'Home',              self.beginning_of_line)\r\n        self._bind_key(u'End',               self.end_of_line)\r\n        self._bind_key(u'Delete',            self.delete_char)\r\n        self._bind_key(u'Control-d',         self.delete_char)\r\n        self._bind_key(u'Clear',             self.clear_screen)\r\n        self._bind_key(u'Alt-f',             self.forward_word)\r\n        self._bind_key(u'Alt-b',             self.backward_word)\r\n        self._bind_key(u'Control-l',         self.clear_screen)\r\n        self._bind_key(u'Control-p',         self.previous_history)\r\n        self._bind_key(u'Up',                self.history_search_backward)\r\n        self._bind_key(u'Control-n',         self.next_history)\r\n        self._bind_key(u'Down',              self.history_search_forward)\r\n        self._bind_key(u'Control-a',         self.beginning_of_line)\r\n        self._bind_key(u'Control-e',         self.end_of_line)\r\n        self._bind_key(u'Alt-<',             self.beginning_of_history)\r\n        self._bind_key(u'Alt->',             self.end_of_history)\r\n        self._bind_key(u'Control-r',         self.reverse_search_history)\r\n        self._bind_key(u'Control-s',         self.forward_search_history)\r\n        self._bind_key(u'Control-Shift-r',         self.forward_search_history)\r\n        self._bind_key(u'Alt-p',\r\n                       self.non_incremental_reverse_search_history)\r\n        self._bind_key(u'Alt-n',\r\n                       self.non_incremental_forward_search_history)\r\n        self._bind_key(u'Control-z',         self.undo)\r\n        self._bind_key(u'Control-_',         self.undo)\r\n        self._bind_key(u'Escape',            self.kill_whole_line)\r\n        self._bind_key(u'Meta-d',            self.kill_word)\r\n        self._bind_key(u'Control-Delete',       self.forward_delete_word)\r\n        self._bind_key(u'Control-w',         self.unix_word_rubout)\r\n        #self._bind_key('Control-Shift-v',   self.quoted_insert)\r\n        self._bind_key(u'Control-v',         self.paste)\r\n        self._bind_key(u'Alt-v',             self.ipython_paste)\r\n        self._bind_key(u'Control-y',         self.yank)\r\n        self._bind_key(u'Control-k',         self.kill_line)\r\n        self._bind_key(u'Control-m',         self.set_mark)\r\n        self._bind_key(u'Control-q',         self.copy_region_to_clipboard)\r\n#        self._bind_key('Control-shift-k',  self.kill_whole_line)\r\n        self._bind_key(u'Control-Shift-v',   self.paste_mulitline_code)\r\n        self._bind_key(u\"Control-Right\",     self.forward_word_end)\r\n        self._bind_key(u\"Control-Left\",      self.backward_word)\r\n        self._bind_key(u\"Shift-Right\",\r\n                       self.forward_char_extend_selection)\r\n        self._bind_key(u\"Shift-Left\",\r\n                       self.backward_char_extend_selection)\r\n        self._bind_key(u\"Shift-Control-Right\",\r\n                       self.forward_word_end_extend_selection)\r\n        self._bind_key(u\"Shift-Control-Left\",\r\n                       self.backward_word_extend_selection)\r\n        self._bind_key(u\"Shift-Home\",\r\n                       self.beginning_of_line_extend_selection)\r\n        self._bind_key(u\"Shift-End\",\r\n                       self.end_of_line_extend_selection)\r\n        self._bind_key(u\"numpad0\",           self.self_insert)\r\n        self._bind_key(u\"numpad1\",           self.self_insert)\r\n        self._bind_key(u\"numpad2\",           self.self_insert)\r\n        self._bind_key(u\"numpad3\",           self.self_insert)\r\n        self._bind_key(u\"numpad4\",           self.self_insert)\r\n        self._bind_key(u\"numpad5\",           self.self_insert)\r\n        self._bind_key(u\"numpad6\",           self.self_insert)\r\n        self._bind_key(u\"numpad7\",           self.self_insert)\r\n        self._bind_key(u\"numpad8\",           self.self_insert)\r\n        self._bind_key(u\"numpad9\",           self.self_insert)\r\n        self._bind_key(u\"add\",               self.self_insert)\r\n        self._bind_key(u\"subtract\",          self.self_insert)\r\n        self._bind_key(u\"multiply\",          self.self_insert)\r\n        self._bind_key(u\"divide\",            self.self_insert)\r\n        self._bind_key(u\"vk_decimal\",        self.self_insert)\r\n        log(u\"RUNNING INIT EMACS\")\r\n        for i in range(0, 10):\r\n            self._bind_key(u\"alt-%d\"%i,      self.digit_argument)\r\n        self._bind_key(u\"alt--\",             self.digit_argument)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a gptool help xml file.", "response": "def create(filename, task, alias):\n    \"\"\"Creates a gptool help xml file.\"\"\"\n\n    metadata = ET.Element('metadata', {'xml:lang': 'en'})\n    tool = ET.SubElement(metadata, 'tool', name=task.name,\n                         displayname=task.display_name,\n                         toolboxalias=alias)\n\n    summary = ET.SubElement(tool, 'summary')\n    summary.text = ''.join((HTML_BEGIN, task.description, HTML_END))\n\n    parameters = ET.SubElement(tool, 'parameters')\n    for task_param in task.parameters:\n        param = ET.SubElement(parameters, 'param',\n                              name=task_param['name'],\n                              displayname=task_param['display_name']\n                             )\n        dialog_ref = ET.SubElement(param, 'dialogReference')\n        dialog_ref.text = ''.join((HTML_BEGIN, task_param['description'], HTML_END))\n        python_ref = ET.SubElement(param, 'pythonReference')\n        python_ref.text = ''.join((HTML_BEGIN, task_param['description'], HTML_END))\n\n    dataIdInfo = ET.SubElement(metadata, 'dataIdInfo')\n    searchKeys = ET.SubElement(dataIdInfo, 'searchKeys')\n    keyword1 = ET.SubElement(searchKeys, 'keyword')\n    keyword1.text = 'ENVI'\n    keyword2 = ET.SubElement(searchKeys, 'keyword')\n    keyword2.text = task.name\n    idCitation = ET.SubElement(dataIdInfo, 'idCitation')\n    resTitle = ET.SubElement(idCitation, 'resTitle')\n    resTitle.text = task.name\n    idAbs = ET.SubElement(dataIdInfo, 'idAbs')\n    idAbs.text = ''.join((HTML_BEGIN, task.description, HTML_END))\n    idCredit = ET.SubElement(dataIdInfo, 'idCredit')\n    idCredit.text = '(c) 2017 Exelis Visual Information Solutions, Inc.'\n    resTitle.text = task.name\n    tree = ET.ElementTree(metadata)\n    tree.write(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the filesystem plugins and returns a list of VersionedPluginInfo objects.", "response": "def load_filesystem_plugins(self):\n        \"\"\"Looks for *.yapsy-plugin files, loads them and returns a list\n            of :class:`VersionedPluginInfo \\\n            <yapsy.VersionedPluginManager.VersionedPluginInfo>` objects\n\n                Note:\n                    Plugin search locations:\n                       * $(rawdisk package location)/plugins/filesystems\n                       * $(home dir)/.local/share/rawdisk/plugins/filesystems\n                       * /usr/local/share/rawdisk/plugins/filesystems\n                       * /usr/share/rawdisk/plugins/filesystems\n                \"\"\"\n        self.logger.info('Loading filesystem plugins')\n        search_path = self.__get_fs_plugin_search_path()\n        fs_plugins = []\n\n        PluginManagerSingleton.setBehaviour([\n            VersionedPluginManager,\n        ])\n\n        # Load the plugins from the plugin directory.\n        plugin_manager = PluginManagerSingleton.get()\n        plugin_manager.setPluginPlaces(search_path)\n        plugin_manager.setCategoriesFilter({\n            \"Filesystem\": IFilesystemPlugin,\n        })\n\n        # Load plugins\n        plugin_manager.collectPlugins()\n\n        for pluginInfo in plugin_manager.getPluginsOfCategory(\"Filesystem\"):\n            fs_plugins.append(pluginInfo)\n\n        return fs_plugins"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the params dictionary and returns a dict with the keys as keys and the values as values.", "response": "def parse_params(self, params):\n        \"\"\"\n        Parsing params, params is a dict\n        and the dict value can be a string\n        or an iterable, namely a list, we\n        need to process those iterables\n        \"\"\"\n        for (key, value) in params.items():\n            if not isinstance(value, str):\n                string_params = self.to_string(value)\n                params[key] = string_params\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts an object into a string.", "response": "def to_string(self, obj):\n        \"\"\"\n        Picks up an object and transforms it\n        into a string, by coercing each element\n        in an iterable to a string and then joining\n        them, or by trying to coerce the object directly\n        \"\"\"\n        try:\n            converted = [str(element) for element in obj]\n            string = ','.join(converted)\n        except TypeError:\n            # for now this is ok for booleans\n            string = str(obj)\n        return string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filter(self, endpoint, params):\n        params = self.parse_params(params)\n        params = urlencode(params)\n        path = '{0}?{1}'.format(endpoint, params)\n        return self.get(path)", "response": "Makes a get request by construction\n        the path from an endpoint and a dict of parameters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_domain_class_terminal_attribute(ent, attr_name):\n    attr = get_domain_class_attribute(ent, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.TERMINAL", "response": "Checks if the given attribute name is a terminal attribute of the given registered resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck if the given attribute name is a member attribute of the given registered resource.", "response": "def is_domain_class_member_attribute(ent, attr_name):\n    \"\"\"\n    Checks if the given attribute name is a entity attribute of the given\n    registered resource.\n    \"\"\"\n    attr = get_domain_class_attribute(ent, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.MEMBER"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_domain_class_collection_attribute(ent, attr_name):\n    attr = get_domain_class_attribute(ent, attr_name)\n    return attr.kind == RESOURCE_ATTRIBUTE_KINDS.COLLECTION", "response": "Checks if the given attribute name is a aggregate attribute of the given registered resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_domain_class_domain_attribute(ent, attr_name):\n    attr = get_domain_class_attribute(ent, attr_name)\n    return attr != RESOURCE_ATTRIBUTE_KINDS.TERMINAL", "response": "Checks if the given attribute name is a resource attribute of the given registered resource."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns an iterator over all terminal attributes in the given registered resource.", "response": "def get_domain_class_terminal_attribute_iterator(ent):\n    \"\"\"\n    Returns an iterator over all terminal attributes in the given registered\n    resource.\n    \"\"\"\n    for attr in itervalues_(ent.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.TERMINAL:\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_domain_class_relationship_attribute_iterator(ent):\n    for attr in itervalues_(ent.__everest_attributes__):\n        if attr.kind != RESOURCE_ATTRIBUTE_KINDS.TERMINAL:\n            yield attr", "response": "Returns an iterator over all terminal attributes in the given resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator over all terminal attributes in the given registered crawler resource.", "response": "def get_domain_class_member_attribute_iterator(ent):\n    \"\"\"\n    Returns an iterator over all terminal attributes in the given registered\n    resource.\n    \"\"\"\n    for attr in itervalues_(ent.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.MEMBER:\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_domain_class_collection_attribute_iterator(ent):\n    for attr in itervalues_(ent.__everest_attributes__):\n        if attr.kind == RESOURCE_ATTRIBUTE_KINDS.COLLECTION:\n            yield attr", "response": "Returns an iterator over all terminal attributes in the given registered crawler resource."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset user password with hash", "response": "def set_password(self, password):\r\n        \"\"\" Set user password with hash \"\"\"\r\n        self.password = Security.hash(password)\r\n        self.save()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_password_reset(cls, email, valid_for=3600) -> str:\r\n        user = cls.where_email(email)\r\n        if user is None:\r\n            return None\r\n        PasswordResetModel.delete_where_user_id(user.id)\r\n        token = JWT().create_token({\r\n            'code': Security.random_string(5),  # make unique\r\n            'user_id': user.id},\r\n            token_valid_for=valid_for)\r\n        code = Security.generate_uuid(1) + \"-\" + Security.random_string(5)\r\n        password_reset_model = PasswordResetModel()\r\n        password_reset_model.token = token\r\n        password_reset_model.code = code\r\n        password_reset_model.user_id = user.id\r\n        password_reset_model.save()\r\n        return code", "response": "Create a password reset request in the user_password_resets database table. Hashed code gets stored in the database."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nvalidating a password reset code against a hashed code and replaces the old password with the new password. Returns None if the code is not valid or the new password is invalid.", "response": "def validate_password_reset(cls, code, new_password):\r\n        \"\"\"\r\n        Validates an unhashed code against a hashed code.\r\n        Once the code has been validated and confirmed\r\n        new_password will replace the old users password\r\n        \"\"\"\r\n        password_reset_model = \\\r\n            PasswordResetModel.where_code(code)\r\n        if password_reset_model is None:\r\n            return None\r\n        jwt = JWT()\r\n        if jwt.verify_token(password_reset_model.token):\r\n            user = cls.where_id(jwt.data['data']['user_id'])\r\n            if user is not None:\r\n                user.set_password(new_password)\r\n                PasswordResetModel.delete_where_user_id(user.id)\r\n                return user\r\n        password_reset_model.delete()  # delete expired/invalid token\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef by_current_session(cls):\r\n        session = Session.current_session()\r\n        if session is None:\r\n            return None\r\n        return cls.where_id(session.user_id)", "response": "Returns a new instance of the class based on the current user session"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef AdvancedJsonify(data, status_code):\n        response = jsonify(data)\n        response.status_code = status_code\n        return response", "response": "Advanced Jsonify Response Maker\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef response(self, callback=None):\n        if not callback:\n            callback = type(self).AdvancedJsonify\n        resp = {\n            \"status\": \"error\",\n            \"message\": self.message\n        }\n        if self.step:\n            resp[\"step\"] = self.step\n\n        self.LOGGER.error(self.message, extra={\"step\": self.step, \"context\": self.context})\n        return callback(resp, status_code=self.code)", "response": "Return the object in view format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a dictionary representation of the object", "response": "def dict(self):\n        \"\"\" Builds a dictionary representation of the object (eg: for JSON)\n\n        :return: Dictionary representation of the object\n        \"\"\"\n        params = {\n            prop: getattr(self, prop)\n            for prop in [\n                \"logs\", \"date\", \"author\", \"sha\", \"path\"\n            ]\n        }\n        params[\"author\"] = params[\"author\"].dict()\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __json(self):\r\n        if self.exclude_list is None:\r\n            self.exclude_list = []\r\n        fields = {}\r\n        for key, item in vars(self).items():\r\n            if hasattr(self, '_sa_instance_state'):\r\n                # load only deferred objects\r\n                if len(orm.attributes.instance_state(self).unloaded) > 0:\r\n                    mapper = inspect(self)\r\n                    for column in mapper.attrs:\r\n                        column.key\r\n                        column.value\r\n            if str(key).startswith('_') or key in self.exclude_list:\r\n                continue\r\n            fields[key] = item\r\n        obj = Json.safe_object(fields)\r\n        return str(obj)", "response": "Convert fields to a string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef manage(cls, entity, unit_of_work):\n        if hasattr(entity, '__everest__'):\n            if not unit_of_work is entity.__everest__.unit_of_work:\n                raise ValueError('Trying to register an entity that has been '\n                                 'registered with another session!')\n        else:\n            entity.__everest__ = cls(entity, unit_of_work)", "response": "Manages the given entity under the given Unit Of Work."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef release(cls, entity, unit_of_work):\n        if not hasattr(entity, '__everest__'):\n            raise ValueError('Trying to unregister an entity that has not '\n                             'been registered yet!')\n        elif not unit_of_work is entity.__everest__.unit_of_work:\n            raise ValueError('Trying to unregister an entity that has been '\n                             'registered with another session!')\n        delattr(entity, '__everest__')", "response": "Removes the given entity from management under the given Unit Of Work."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_state_data(cls, entity):\n        attrs = get_domain_class_attribute_iterator(type(entity))\n        return dict([(attr,\n                      get_nested_attribute(entity, attr.entity_attr))\n                     for attr in attrs\n                     if not attr.entity_attr is None])", "response": "Returns the state data for the given entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the state data for the given entity.", "response": "def set_state_data(cls, entity, data):\n        \"\"\"\n        Sets the state data for the given entity to the given data.\n\n        This also works for unmanaged entities.\n        \"\"\"\n        attr_names = get_domain_class_attribute_names(type(entity))\n        nested_items = []\n        for attr, new_attr_value in iteritems_(data):\n            if not attr.entity_attr in attr_names:\n                raise ValueError('Can not set attribute \"%s\" for entity '\n                                 '\"%s\".' % (attr.entity_attr, entity))\n            if '.' in attr.entity_attr:\n                nested_items.append((attr, new_attr_value))\n                continue\n            else:\n                setattr(entity, attr.entity_attr, new_attr_value)\n        for attr, new_attr_value in nested_items:\n            try:\n                set_nested_attribute(entity, attr.entity_attr, new_attr_value)\n            except AttributeError as exc:\n                if not new_attr_value is None:\n                    raise exc"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef transfer_state_data(cls, source_entity, target_entity):\n        state_data = cls.get_state_data(source_entity)\n        cls.set_state_data(target_entity, state_data)", "response": "Transfer instance state data from the given source entity to the given target entity."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the given state data on the given entity.", "response": "def __set_data(self, data):\n        \"\"\"\n        Sets the given state data on the given entity of the given class.\n\n        :param data: State data to set.\n        :type data: Dictionary mapping attributes to attribute values.\n        :param entity: Entity to receive the state data.\n        \"\"\"\n        ent = self.__entity_ref()\n        self.set_state_data(ent, data)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pretty_print(self, carrot=True):\n        output = ['\\n']\n        output.extend([line.pretty_print() for line in\n                       self.partpyobj.get_surrounding_lines(1, 0)])\n\n        if carrot:\n            output.append('\\n' +\n                          (' ' * (self.partpyobj.col + 5)) + '^' + '\\n')\n        if self.partpymsg:\n            output.append(self.partpymsg)\n\n        return ''.join(output)", "response": "Print the previous and current line with line numbers and the current character position and the exception message."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef serialise_to_rsh(params: dict) -> str:\n    out = \"// Generated at %s\\n\\n\" % (datetime.now())\n\n    def add_val(field, value):\n        \"\"\"Add value to multiple line in rsh format.\"\"\"\n        if isinstance(value, bytes):\n            value = value.decode(\"cp1251\")\n        val = ''.join('%s, ' % (v) for v in value) if isinstance(value, list) \\\n              else value\n        if isinstance(val, str) and val.endswith(', '):\n            val = val[:-2]\n        return '%s -- %s\\n' % (val, field)\n\n    for param in params:\n        if param == \"channel\":\n            for i, channel in enumerate(params[param]):\n                for ch_par in channel:\n                    val = \"%s_%s[%s]\" % (param, ch_par, i)\n                    if ch_par == \"params\":\n                        val = \"%ss_%s[%s]\" % (param, ch_par, i)\n\n                    out += add_val(val, channel[ch_par])\n        elif param == \"synchro_channel\":\n            for sync_ch_par in params[param]:\n                if sync_ch_par == \"type\":\n                    out += add_val(param, params[param][sync_ch_par])\n                else:\n                    out += add_val(\"%s_%s\" % (param, sync_ch_par),\n                                   params[param][sync_ch_par])\n        else:\n            out += add_val(param, params[param])\n\n    return out", "response": "Serialise a dictionary of parameters into a RSH file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_from_rsb(header: bytearray) -> dict:\n    params = {}\n\n    params[\"text_header_size\"] = struct.unpack('I', header[0:4])[0]\n\n    params[\"events_num\"] = struct.unpack('i', header[8:12])[0]\n\n    start_time = struct.unpack('Q', header[16:24])[0]\n    params[\"start_time\"] = datetime.fromtimestamp(start_time).isoformat()\n    end_time = struct.unpack('Q', header[24:32])[0]\n    params[\"end_time\"] = datetime.fromtimestamp(end_time).isoformat()\n\n    params[\"filepath\"] = header[32: 32 + 255].rstrip(b'\\0').decode(\"cp1251\")\n\n    params[\"num_blocks\"] = struct.unpack('i', header[288:292])[0]\n\n    params[\"aquisition_time\"] = struct.unpack('i', header[292:296])[0]\n\n    params[\"blocks_in_file\"] = struct.unpack('i', header[296:300])[0]\n\n    params[\"waitTime\"] = struct.unpack('i', header[300:304])[0]\n\n    params[\"threshold\"] = struct.unpack('d', header[312:320])[0]\n\n    sync_params_num = struct.unpack('I', header[336:340])[0]\n    sync_params = np.unique(np.frombuffer(header[320:336], np.uint32)\n                            [:sync_params_num])\n    params[\"synchro_control\"] = []\n    for param in sync_params:\n        if param == 0:\n            params[\"synchro_control\"].append(\"Default\")\n        else:\n            params[\"synchro_control\"].append(list(synchro_control.keys())\n                                             [list(synchro_control.values())\n                                              .index(param)])\n\n    params[\"sample_freq\"] = struct.unpack('d', header[344:352])[0]\n    params[\"pre_history\"] = struct.unpack('I', header[352:356])[0]\n\n    params[\"packet_number\"] = struct.unpack('i', header[356:360])[0]\n\n    params[\"b_size\"] = struct.unpack('I', header[360:364])[0]\n\n    params[\"hysteresis\"] = struct.unpack('I', header[364:368])[0]\n\n    params[\"channel_number\"] = struct.unpack('I', header[368:372])[0]\n\n    ch_params = []\n\n    for i in range(params[\"channel_number\"]):\n        ch_data = header[372 + 56 * i: 372 + 56 * (i + 1)]\n        ch_param = {}\n\n        param_num = struct.unpack('I', ch_data[36:40])[0]\n        ch_params_raw = np.unique(np.frombuffer(ch_data[4:36],\n                                                np.uint32)[:param_num])\n        ch_param[\"params\"] = []\n        for param in ch_params_raw:\n            if param == 0:\n                ch_param[\"params\"].append(\"Default\")\n            else:\n                ch_param[\"params\"].append(list(channel_control.keys())\n                                          [list(channel_control.values())\n                                           .index(param)])\n\n        ch_param[\"adjustment\"] = struct.unpack('d', ch_data[44:52])[0]\n        ch_param[\"gain\"] = struct.unpack('I', ch_data[52:56])[0]\n        ch_params.append(ch_param)\n\n    params[\"channel\"] = ch_params\n\n    synchro_channel = {}\n    sync_ch_par_num = struct.unpack('I', header[632:636])[0]\n    sync_ch_params_raw = np.unique(np.frombuffer(header[600:632],\n                                                 np.uint32)[:sync_ch_par_num])\n\n    synchro_channel[\"params\"] = []\n    for param in sync_ch_params_raw:\n        if param == 0:\n            synchro_channel[\"params\"].append(\"Default\")\n        else:\n            synchro_channel[\"params\"] \\\n                .append(list(synchro_channel_control.keys())\n                        [list(synchro_channel_control.values()).index(param)])\n\n    synchro_channel_type = struct.unpack('I', header[304:308])[0]\n    synchro_channel[\"type\"] = list(synchro_channel_types.keys())[\n        list(synchro_channel_types.values()).index(synchro_channel_type)]\n\n    synchro_channel[\"gain\"] = struct.unpack('I', header[636:640])[0]\n\n    params[\"synchro_channel\"] = synchro_channel\n\n    params[\"err_lang\"] = struct.unpack('I', header[640:644])[0]\n    params[\"board_name\"] = header[644:644 + 255].rstrip(b'\\0').decode(\"cp1251\")\n\n    params[\"board_id\"] = struct.unpack('I', header[900:904])[0]\n\n    return params", "response": "Parse a block - wise header from a RSB file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nserializing a dictionary to a byte array.", "response": "def serialize_to_rsb(params: dict) -> bytes:\n    \"\"\"\u0421\u0435\u0440\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f JSON \u0445\u0435\u0434\u0435\u0440\u0430 rsb.\n\n    @params -- \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u0432 \u0444\u043e\u0440\u043c\u0430\u0442\u0435 JSON (dfparser.def_values.DEF_RSH_PARAMS)\n    @return -- \u0431\u0438\u043d\u0430\u0440\u043d\u044b\u0439 \u0445\u0435\u0434\u0435\u0440 (2048 bytes)\n\n    \"\"\"\n    header = bytearray(np.zeros(2048, np.byte).tostring())\n\n    if \"text_header_size\" in params:\n        header[0:4] = struct.pack('I', params[\"text_header_size\"])\n\n    if \"events_num\" in params:\n        header[8:12] = struct.pack('i', params[\"events_num\"])\n\n    if \"start_time\" in params:\n        start_time = dateutil.parser.parse(params[\"start_time\"]).timestamp()\n        header[16:24] = struct.pack('Q', int(start_time))\n\n    if \"end_time\" in params:\n        end_time = dateutil.parser.parse(params[\"end_time\"]).timestamp()\n        header[24:32] = struct.pack('Q', int(end_time))\n\n    header[32:32 + len(params[\"filepath\"])\n           ] = params['filepath'].encode('cp1251')\n\n    header[288:292] = struct.pack('i', params[\"num_blocks\"])\n\n    header[292:296] = struct.pack('i', int(params[\"aquisition_time\"]))\n\n    header[296:300] = struct.pack('i', params[\"blocks_in_file\"])\n\n    header[300:304] = struct.pack('i', int(params[\"waitTime\"]))\n\n    header[312:320] = struct.pack('d', params[\"threshold\"])\n\n    sync_params = params[\"synchro_control\"]\n    sync_params_num = len(sync_params)\n\n    header[336:340] = struct.pack('I', sync_params_num)\n\n    for i in range(sync_params_num):\n        if sync_params[i] == 'Default':\n            code = 0\n        else:\n            code = synchro_control[sync_params[i]]\n\n        header[320 + i * 4:320 + (i + 1) * 4] = struct.pack('I', code)\n\n    header[344:352] = struct.pack('d', params[\"sample_freq\"])\n    header[352:356] = struct.pack('I', params[\"pre_history\"])\n\n    header[356:360] = struct.pack('i', params[\"packet_number\"])\n\n    header[360:364] = struct.pack('I', params[\"b_size\"])\n\n    header[364:368] = struct.pack('I', params[\"hysteresis\"])\n\n    header[368:372] = struct.pack('I', params[\"channel_number\"])\n\n    for i in range(params[\"channel_number\"]):\n        off = 372 + 56 * i\n\n        ch_param = params['channel'][i]\n\n        header[off + 44: off + 52] = struct.pack('d', ch_param[\"adjustment\"])\n        header[off + 52: off + 56] = struct.pack('I', ch_param[\"gain\"])\n        header[off + 36: off + 40] = struct.pack('I', len(ch_param['params']))\n\n        for j, param in enumerate(ch_param['params']):\n            if param == 'Default':\n                code = 0\n            else:\n                code = channel_control[param]\n                header[off + 4 + j * 4:\n                       off + 4 + (j + 1) * 4] = struct.pack('I', code)\n\n    synchro_channel = params['synchro_channel']\n    header[632:636] = struct.pack('I', len(synchro_channel['params']))\n\n    for i, param in enumerate(synchro_channel['params']):\n        if param == 'Default':\n            code = 0\n        else:\n            code = synchro_channel_control[param]\n            header[600 + i * 4: 600 + (i + 1) * 4] = struct.pack('I', code)\n\n    sync_type = synchro_channel_types[synchro_channel['type']]\n    header[304:308] = struct.pack('I', sync_type)\n\n    header[636:640] = struct.pack('I', synchro_channel[\"gain\"])\n\n    if \"err_lang\" in params:\n        header[640:644] = struct.pack('I', params[\"err_lang\"])\n\n    if \"board_name\" in params:\n        header[644:644 + len(params[\"board_name\"])] = \\\n            params['board_name'].encode('cp1251')\n\n    if \"board_id\" in params:\n        header[900: 904] = struct.pack('I', params[\"board_id\"])\n\n    return bytes(header)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump_to_rsb(params: dict, times: np.ndarray, data: np.ndarray) -> bytes:\n    assert isinstance(times, np.ndarray)\n    assert times.ndim == 1\n    assert isinstance(data, np.ndarray)\n    assert data.ndim == 2\n    assert len(data) == len(times)\n\n    params['b_size'] = data.shape[1]\n    params['events_num'] = data.shape[0]\n\n    start = int(times.min() * 1e-9)\n    end = int(times.max() * 1e-9)\n\n    if 'start_time' not in params:\n        params['start_time'] = datetime.fromtimestamp(start).isoformat()\n\n    if 'end_time' not in params:\n        params['end_time'] = datetime.fromtimestamp(end).isoformat()\n\n    text_header = bytearray(5120)\n    text = serialise_to_rsh(params).encode('cp1251')\n    text_header[:len(text)] = text\n\n    params['text_header_size'] = len(text)\n\n    binary_header = serialize_to_rsb(params)\n\n    bin_data = b''\n\n    ch_num = params['channel_number']\n    ev_size = params['b_size']\n    for i, event_data in enumerate(data):\n        event = bytearray(\n            np.zeros(96 + 2 * ch_num * ev_size, np.byte).tostring())\n        text_hdr = datetime.fromtimestamp(int(times[i] * 10e-9)).isoformat()\n\n        event[:len(text_hdr)] = text_hdr.encode('cp1251')\n        event[64:68] = struct.pack('I', i)\n        event[72:80] = struct.pack('Q', int(times[i] * 10e-9))\n        event[80:88] = struct.pack('Q', int(times[i]))\n\n        event[96:] = event_data.astype(np.int16).tostring()\n        bin_data += event\n\n    return bytes(text_header + binary_header + bin_data)", "response": "Dump a single block of data to a single RSB file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nextract an event from the dataset.", "response": "def get_event(self, num):\n        \"\"\"Extract event from dataset.\"\"\"\n        if num < 0 or num >= self.params[\"events_num\"]:\n            raise IndexError(\"Index out of range [0:%s]\" %\n                             (self.params[\"events_num\"]))\n\n        ch_num = self.params['channel_number']\n        ev_size = self.params['b_size']\n\n        event = {}\n\n        self.file.seek(7168 + num * (96 + 2 * ch_num * ev_size))\n\n        event[\"text_hdr\"] = self.file.read(64)\n        event[\"ev_num\"] = struct.unpack('I', self.file.read(4))[0]\n        self.file.read(4)\n\n        start_time = struct.unpack('Q', self.file.read(8))[0]\n        event[\"start_time\"] = datetime.fromtimestamp(start_time)\n        ns_since_epoch = struct.unpack('Q', self.file.read(8))[0]\n        if ns_since_epoch:\n            event['ns_since_epoch'] = ns_since_epoch\n        self.file.read(8)\n\n        event_data = self.file.read(2 * ev_size * ch_num)\n\n        event[\"data\"] = np.fromstring(event_data, np.short)\n\n        return event"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update_event_data(self, num, data):\n        if num < 0 or num >= self.params[\"events_num\"]:\n            raise IndexError(\"Index out of range [0:%s]\" %\n                             (self.params[\"events_num\"]))\n\n        if isinstance(data, np.ndarray):\n            raise TypeError(\"data should be np.ndarray\")\n\n        if data.dtype != np.short:\n            raise TypeError(\"data array dtype should be dtype('int16')\")\n\n        ch_num = self.params['channel_number']\n        ev_size = self.params['b_size']\n\n        if data.shape != (ch_num * ev_size,):\n            raise Exception(\"data should contain same number of elements \"\n                            \"(%s)\" % (ch_num * ev_size))\n\n        self.file.seek(7168 + num * (96 + 2 * ch_num * ev_size) + 96)\n        self.file.write(data.tostring())\n        self.file.flush()", "response": "Update event data in dataset."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating arduino examples directory.", "response": "def create_examples_all():\n    \"\"\"create arduino/examples/all directory.\n\n    :rtype: None\n\n    \"\"\"\n    remove_examples_all()\n    examples_all_dir().mkdir()\n\n    for lib in libraries():\n        maindir = examples_all_dir() / lib.upper()[0:1] / lib\n#        libraries_dir() /\n        maindir.makedirs_p()\n\n        for ex in lib_examples(lib):\n            d = lib_example_dir(lib, ex)\n            if hasattr(os, 'symlink'):\n                d.symlink(maindir / ex)\n            else:\n                d.copytree(maindir / ex)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngiving a string containing an nginx upstream section return the pool name and list of nodes.", "response": "def str_to_pool(upstream):\n    \"\"\"\n    Given a string containing an nginx upstream section, return the pool name\n    and list of nodes.\n    \"\"\"\n    name = re.search('upstream +(.*?) +{', upstream).group(1)\n    nodes = re.findall('server +(.*?);', upstream)\n    return name, nodes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef calculate_vss(self, method=None):\n        if self.variance == float(0):\n            return self.vss\n        else:\n            # Calculate gausian distribution and return\n            if method == \"gaussian\" or method is None:\n                return gauss(self.vss, self.variance)\n            elif method == \"random\":\n                return uniform(self.vss - self.variance, self.vss + self.variance)\n            else:\n                raise ValueError(\"Method of vss calculation not recognized, please use 'gaussian' or 'random'\")", "response": "Calculates the vertical swimming speed of this behavior."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _check_experiment(self, name):\n        with h5py.File(name=self.path, mode=\"r\") as h5:\n            sigpath = \"/Experiments/{}/metadata/Signal\".format(name)\n            signal_type = h5[sigpath].attrs[\"signal_type\"]\n        if signal_type != \"hologram\":\n            msg = \"Signal type '{}' not supported: {}[{}]\".format(signal_type,\n                                                                  self.path,\n                                                                  name)\n            warnings.warn(msg, WrongSignalTypeWarnging)\n        return signal_type == \"hologram\"", "response": "Check the signal type of the experiment and return True if the signal type is supported False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_experiments(self):\n        explist = []\n        with h5py.File(name=self.path, mode=\"r\") as h5:\n            if \"Experiments\" not in h5:\n                msg = \"Group 'Experiments' not found in {}.\".format(self.path)\n                raise HyperSpyNoDataFoundError(msg)\n            for name in h5[\"Experiments\"]:\n                # check experiment\n                if self._check_experiment(name):\n                    explist.append(name)\n        explist.sort()\n        if not explist:\n            # if this error is raised, the signal_type is probably not\n            # set to \"hologram\".\n            msg = \"No supported data found: {}\".format(self.path)\n            raise HyperSpyNoDataFoundError(msg)\n        return explist", "response": "Get all experiments from the hdf5 file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns QPImage with background correction", "response": "def get_qpimage_raw(self, idx=0):\n        \"\"\"Return QPImage without background correction\"\"\"\n        name = self._get_experiments()[idx]\n        with h5py.File(name=self.path, mode=\"r\") as h5:\n            exp = h5[\"Experiments\"][name]\n            # hologram data\n            data = exp[\"data\"][:]\n            # resolution\n            rx = exp[\"axis-0\"].attrs[\"scale\"]\n            ry = exp[\"axis-1\"].attrs[\"scale\"]\n            if rx != ry:\n                raise NotImplementedError(\"Only square pixels supported!\")\n            runit = exp[\"axis-0\"].attrs[\"units\"]\n            if runit == \"nm\":\n                pixel_size = rx * 1e-9\n            else:\n                raise NotImplementedError(\"Units '{}' not implemented!\")\n\n        meta_data = {\"pixel size\": pixel_size}\n        meta_data.update(self.meta_data)\n\n        qpi = qpimage.QPImage(data=data,\n                              which_data=\"hologram\",\n                              meta_data=meta_data,\n                              holo_kw=self.holo_kw,\n                              h5dtype=self.as_type)\n        # set identifier\n        qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef verify(path):\n        valid = False\n        try:\n            h5 = h5py.File(path, mode=\"r\")\n        except (OSError, IsADirectoryError):\n            pass\n        else:\n            if (\"file_format\" in h5.attrs and\n                h5.attrs[\"file_format\"].lower() == \"hyperspy\" and\n                    \"Experiments\" in h5):\n                valid = True\n        return valid", "response": "Verify that path has the HyperSpy file format"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, df):\n        for name, function in self.outputs:\n            df[name] = function(df)", "response": "Transforms a DataFrame in place. Computes all outputs of the DataFrame."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a pandas. DataFrame with the contents of the current context.", "response": "def get_dataframe(self, force_computation=False):\n        \"\"\"\n        Preprocesses then transforms the return of fetch().\n\n        Args:\n            force_computation (bool, optional) : Defaults to False. If set to True, forces the computation of DataFrame at each call.\n\n        Returns:\n            pandas.DataFrame: Preprocessed and transformed DataFrame.\n        \"\"\"\n        # returns df if it was already computed\n        if self.df is not None and not force_computation: return self.df\n\n        self.df = self.fetch(self.context)\n\n        # compute df = transform(preprocess(df)\n        self.df = self.preprocess(self.df)\n        self.transform(self.df)\n\n        return self.df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a new node to the traversal path.", "response": "def push(self, proxy, key, attribute, relation_operation):\n        \"\"\"\n        Adds a new :class:`TraversalPathNode` constructed from the given\n        arguments to this traversal path.\n        \"\"\"\n        node = TraversalPathNode(proxy, key, attribute, relation_operation)\n        self.nodes.append(node)\n        self.__keys.add(key)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pop(self):\n        node = self.nodes.pop()\n        self.__keys.remove(node.key)", "response": "Removes the last node from this traversal path."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parent(self):\n        if len(self.nodes) > 0:\n            parent = self.nodes[-1].proxy\n        else:\n            parent = None\n        return parent", "response": "Returns the proxy from the last node visited on the path or None if no node has been visited."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef relation_operation(self):\n        if len(self.nodes) > 0:\n            rel_op = self.nodes[-1].relation_operation\n        else:\n            rel_op = None\n        return rel_op", "response": "Returns the relation operation from the last node visited on the\n            path or None if no node has been visited yet."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef score_meaning(text):\n    #all_characters = re.findall('[ -~]', text)  # match 32-126 in ASCII table\n    all_characters = re.findall('[a-zA-Z ]', text)  # match 32-126 in ASCII table\n    if len(all_characters) == 0:\n        return 0\n    repetition_count = Counter(all_characters)\n    score = (len(all_characters)) ** 2 / (len(repetition_count) + len(text) / 26)\n    return score", "response": "Returns a score in [ 0 1 ) if the text makes any sense in English."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_top_n_meanings(strings, n):\n    scored_strings = [(s, score_meaning(s)) for s in strings]\n    scored_strings.sort(key=lambda tup: -tup[1])\n    return scored_strings[:n]", "response": "Returns score for top n strings\n    Returns ( text score ) for top n strings\n   "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef ensure_unicode(text):\r\n    if isinstance(text, str):\r\n        try:\r\n            return text.decode(pyreadline_codepage, u\"replace\")\r\n        except (LookupError, TypeError):\r\n            return text.decode(u\"ascii\", u\"replace\")\r\n    return text", "response": "u helper to ensure that text passed to WriteConsoleW is unicode"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reload(self, regexes=None, **kwargs):\n        combined = re.compile(\"(\" + \")|(\".join(regexes) + \")\", re.I)\n        pending_files = os.listdir(self.src_path) or []\n        pending_files.sort()\n        for filename in pending_files:\n            if re.match(combined, filename):\n                self.put(os.path.join(self.src_path, filename))", "response": "Reloads the contents of the source directory into the queue\n        that match the regexes."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nunwraps the callback and returns the raw content", "response": "def unwrap_raw(content):\n    \"\"\" unwraps the callback and returns the raw content\n    \"\"\"\n    starting_symbol = get_start_symbol(content)\n    ending_symbol = ']' if starting_symbol == '[' else '}'\n    start = content.find(starting_symbol, 0)\n    end = content.rfind(ending_symbol)\n    return content[start:end+1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef combine_word_list(word_list):\n    bag_of_words = collections.defaultdict(int)\n\n    for word in word_list:\n        bag_of_words[word] += 1\n\n    return bag_of_words", "response": "Combine word list into a bag - of - words dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreduces a number of keyword sets to a bag - of - words.", "response": "def reduce_list_of_bags_of_words(list_of_keyword_sets):\n    \"\"\"\n    Reduces a number of keyword sets to a bag-of-words.\n\n    Input:  - list_of_keyword_sets: This is a python list of sets of strings.\n\n    Output: - bag_of_words: This is the corresponding multi-set or bag-of-words, in the form of a python dictionary.\n    \"\"\"\n    bag_of_words = dict()\n    get_bag_of_words_keys = bag_of_words.keys\n    for keyword_set in list_of_keyword_sets:\n        for keyword in keyword_set:\n            if keyword in get_bag_of_words_keys():\n                bag_of_words[keyword] += 1\n            else:\n                bag_of_words[keyword] = 1\n\n    return bag_of_words"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef query_list_of_words(target_word, list_of_words, edit_distance=1):\n    # Initialize lists\n    new_list_of_words = list()\n    found_list_of_words = list()\n\n    append_left_keyword = new_list_of_words.append\n    append_found_keyword = found_list_of_words.append\n\n    # Iterate over the list of words\n    for word in list_of_words:\n        if len(word) > 6:\n            effective_edit_distance = edit_distance\n        else:\n            effective_edit_distance = 0  # No edit distance for small words.\n        if abs(len(word)-len(target_word)) <= effective_edit_distance:\n            if nltk.edit_distance(word, target_word) <= effective_edit_distance:\n                append_found_keyword(word)\n            else:\n                append_left_keyword(word)\n        else:\n            append_left_keyword(word)\n\n    return new_list_of_words, found_list_of_words", "response": "This function checks whether a target word is within edit distance of any one in a list of keywords."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef fixup_instance(sender, **kwargs):\n    instance = kwargs['instance']\n    for model_field in instance._meta.fields:\n\n        if not isinstance(model_field, JSONAttributeField):\n            continue\n\n        if hasattr(instance, '_attr_field'):\n            raise FieldError('multiple JSONAttributeField fields: '\n                             'only one is allowed per model!')\n\n        field_name = model_field.name\n        attrs = getattr(instance, field_name)\n\n        # ensure JSONAttributeField's data is of JSONAttributes type\n        if not isinstance(attrs, JSONAttributes):\n            setattr(instance, field_name, JSONAttributes(attrs))\n            attrs = getattr(instance, field_name)\n\n        # Cache model instance on JSONAttributes instance and vice-versa\n        attrs._instance = instance\n        attrs._get_from_instance = functools.partial(\n            getattr, instance, field_name)\n        instance._attr_field = attrs\n\n    if not hasattr(instance, '_attr_field'):\n        raise FieldError('missing JSONAttributeField field in '\n                         'fixup_instance decorator')", "response": "Cache JSONAttributes data on instance and vice - versa for convenience."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget val form settings and set to context", "response": "def get_setting(context, key, default_val=\"\", as_key=None):\n    \"\"\"\n    get val form settings and set to context\n      {% load lbutils %}\n      {% get_setting \"key\" default_val \"as_key\" %}\n      {{ as_key }}\n      if as_key is None, this tag will return val\n    \"\"\"\n    if (\"%s\" % default_val).startswith('$.'):\n        default_val = getattr(settings, default_val[2:])\n    val = getattr(settings, key, default_val)\n    if not as_key:\n        return val\n    context[as_key] = val\n    return ''"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves the data from the Volkszaehler API.", "response": "async def get_data(self):\n        \"\"\"Retrieve the data.\"\"\"\n        try:\n            with async_timeout.timeout(5, loop=self._loop):\n                response = await self._session.get(self.url)\n\n            _LOGGER.debug(\n                \"Response from Volkszaehler API: %s\", response.status)\n            self.data = await response.json()\n            _LOGGER.debug(self.data)\n        except (asyncio.TimeoutError, aiohttp.ClientError):\n            _LOGGER.error(\"Can not load data from Volkszaehler API\")\n            self.data = None\n            raise exceptions.VolkszaehlerApiConnectionError()\n\n        self.average = self.data['data']['average']\n        self.max = self.data['data']['max'][1]\n        self.min = self.data['data']['min'][1]\n        self.consumption = self.data['data']['consumption']\n        self.tuples = self.data['data']['tuples']"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_clipboard_text_and_convert(paste_list=False):\r\n    txt = GetClipboardText()\r\n    if txt:\r\n        if paste_list and u\"\\t\" in txt:\r\n            array, flag = make_list_of_list(txt)\r\n            if flag:\r\n                txt = repr(array)\r\n            else:\r\n                txt = u\"array(%s)\"%repr(array)\r\n            txt = u\"\".join([c for c in txt if c not in u\" \\t\\r\\n\"])\r\n    return txt", "response": "Get txt from clipboard and convert tab separated \r\n    data to list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hdfFromKwargs(hdf=None, **kwargs):\n    if not hdf:\n        hdf = HDF()\n    for key, value in kwargs.iteritems():\n        if isinstance(value, dict):\n            #print \"dict:\",value\n            for k,v in value.iteritems():\n                dkey = \"%s.%s\"%(key,k)\n                #print \"k,v,dkey:\",k,v,dkey\n                args = {dkey:v}\n                hdfFromKwargs(hdf=hdf, **args)\n        elif isinstance(value, (list, tuple)):\n            #print \"list:\",value\n            for i, item in enumerate(value):\n                ikey = \"%s.%s\"%(key,i)\n                #print \"i,item:\",i,item, ikey\n                if isinstance(item, (list, tuple)):\n                    args = {ikey:item}\n                    hdfFromKwargs(hdf=hdf, **args)\n                elif isinstance(item, dict):\n                    args = {ikey:item}\n                    hdfFromKwargs(hdf=hdf, **args)\n                elif getattr(item, \"HDF_ATTRIBUTES\", False):\n                    attrs = {}\n                    for attr in item.HDF_ATTRIBUTES:\n                        attrs[attr] = getattr(item, attr, \"\")\n                    hdfFromKwargs(hdf=hdf, **{ikey:attrs})\n                else:\n                    hdf.setValue(ikey, str(item))\n        elif getattr(value, \"HDF_ATTRIBUTES\", False):\n            attrs = {}\n            for attr in value.HDF_ATTRIBUTES:\n                attrs[attr] = getattr(value, attr, \"\")\n            hdfFromKwargs(hdf=hdf, **{key:attrs})\n        else:\n            hdf.setValue(key, str(value))\n    #print \"HDF:\",hdf.dump()\n    return hdf", "response": "This function takes a dictionary of kwargs and returns an HDF object that contains the contents of the object that has toHDF() method that is invoked to get that object s HDF representation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef size(self):\n\n        if self is NULL:\n            return 0\n        return 1 + self.left.size() + self.right.size()", "response": "Return the size of the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfinds a value in a node using a key function.", "response": "def find_prekeyed(self, value, key):\n        \"\"\"\n        Find a value in a node, using a key function. The value is already a\n        key.\n        \"\"\"\n\n        while self is not NULL:\n            direction = cmp(value, key(self.value))\n            if direction < 0:\n                self = self.left\n            elif direction > 0:\n                self = self.right\n            elif direction == 0:\n                return self.value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nrotating the node to the left.", "response": "def rotate_left(self):\n        \"\"\"\n        Rotate the node to the left.\n        \"\"\"\n\n        right = self.right\n        new = self._replace(right=self.right.left, red=True)\n        top = right._replace(left=new, red=self.red)\n        return top"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nflipping colors of a node and its children.", "response": "def flip(self):\n        \"\"\"\n        Flip colors of a node and its children.\n        \"\"\"\n\n        left = self.left._replace(red=not self.left.red)\n        right = self.right._replace(red=not self.right.red)\n        top = self._replace(left=left, right=right, red=not self.red)\n        return top"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef balance(self):\n\n        # Always lean left with red nodes.\n        if self.right.red:\n            self = self.rotate_left()\n\n        # Never permit red nodes to have red children. Note that if the left-hand\n        # node is NULL, it will short-circuit and fail this test, so we don't have\n        # to worry about a dereference here.\n        if self.left.red and self.left.left.red:\n            self = self.rotate_right()\n\n        # Finally, move red children on both sides up to the next level, reducing\n        # the total redness.\n        if self.left.red and self.right.red:\n            self = self.flip()\n\n        return self", "response": "Balance a node.\n\n        The balance is inductive and relies on all subtrees being balanced\n        recursively or by construction. If the subtrees are not balanced, then\n        this will not fix them."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert(self, value, key):\n\n        # Base case: Insertion into the empty tree is just creating a new node\n        # with no children.\n        if self is NULL:\n            return Node(value, NULL, NULL, True), True\n\n        # Recursive case: Insertion into a non-empty tree is insertion into\n        # whichever of the two sides is correctly compared.\n        direction = cmp(key(value), key(self.value))\n        if direction < 0:\n            left, insertion = self.left.insert(value, key)\n            self = self._replace(left=left)\n        elif direction > 0:\n            right, insertion = self.right.insert(value, key)\n            self = self._replace(right=right)\n        elif direction == 0:\n            # Exact hit on an existing node (this node, in fact). In this\n            # case, perform an update.\n            self = self._replace(value=value)\n            insertion = False\n\n        # And balance on the way back up.\n        return self.balance(), insertion", "response": "Insert a value into a tree rooted at the given node and return whether this was an insertion or update."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef move_red_left(self):\n\n        self = self.flip()\n        if self.right is not NULL and self.right.left.red:\n            self = self._replace(right=self.right.rotate_right())\n            self = self.rotate_left().flip()\n\n        return self", "response": "Move the set of red elements to the left of a tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef move_red_right(self):\n\n        self = self.flip()\n        if self.left is not NULL and self.left.left.red:\n            self = self.rotate_right().flip()\n\n        return self", "response": "Move the red to the right of a tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete the minimum value from a tree.", "response": "def delete_min(self):\n        \"\"\"\n        Delete the left-most value from a tree.\n        \"\"\"\n\n        # Base case: If there are no nodes lesser than this node, then this is the\n        # node to delete.\n        if self.left is NULL:\n            return NULL, self.value\n\n        # Acquire more reds if necessary to continue the traversal. The\n        # double-deep check is fine because NULL is red.\n        if not self.left.red and not self.left.left.red:\n            self = self.move_red_left()\n\n        # Recursive case: Delete the minimum node of all nodes lesser than this\n        # node.\n        left, value = self.left.delete_min()\n        self = self._replace(left=left)\n\n        return self.balance(), value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef delete_max(self):\n\n        # Attempt to rotate left-leaning reds to the right.\n        if self.left.red:\n            self = self.rotate_right()\n\n        # Base case: If there are no selfs greater than this self, then this is\n        # the self to delete.\n        if self.right is NULL:\n            return NULL, self.value\n\n        # Acquire more reds if necessary to continue the traversal. NULL is\n        # red so this check doesn't need to check for NULL.\n        if not self.right.red and not self.right.left.red:\n            self = self.move_red_right()\n\n        # Recursive case: Delete the maximum self of all selfs greater than this\n        # self.\n        right, value = self.right.delete_max()\n        self = self._replace(right=right)\n\n        return self.balance(), value", "response": "Delete the maximum value from a tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a value from a tree.", "response": "def delete(self, value, key):\n        \"\"\"\n        Delete a value from a tree.\n        \"\"\"\n\n        # Base case: The empty tree cannot possibly have the desired value.\n        if self is NULL:\n            raise KeyError(value)\n\n        direction = cmp(key(value), key(self.value))\n\n        # Because we lean to the left, the left case stands alone.\n        if direction < 0:\n            if (not self.left.red and\n                self.left is not NULL and\n                not self.left.left.red):\n                self = self.move_red_left()\n            # Delete towards the left.\n            left = self.left.delete(value, key)\n            self = self._replace(left=left)\n        else:\n            # If we currently lean to the left, lean to the right for now.\n            if self.left.red:\n                self = self.rotate_right()\n\n            # Best case: The node on our right (which we just rotated there) is a\n            # red link and also we were just holding the node to delete. In that\n            # case, we just rotated NULL into our current node, and the node to\n            # the right is the lone matching node to delete.\n            if direction == 0 and self.right is NULL:\n                return NULL\n\n            # No? Okay. Move more reds to the right so that we can continue to\n            # traverse in that direction. At *this* spot, we do have to confirm\n            # that node.right is not NULL...\n            if (not self.right.red and\n                self.right is not NULL and\n                not self.right.left.red):\n                self = self.move_red_right()\n\n            if direction > 0:\n                # Delete towards the right.\n                right = self.right.delete(value, key)\n                self = self._replace(right=right)\n            else:\n                # Annoying case: The current node was the node to delete all\n                # along! Use a right-handed minimum deletion. First find the\n                # replacement value to rebuild the current node with, then delete\n                # the replacement value from the right-side tree. Finally, create\n                # the new node with the old value replaced and the replaced value\n                # deleted.\n                rnode = self.right\n                while rnode is not NULL:\n                    rnode = rnode.left\n\n                right, replacement = self.right.delete_min()\n                self = self._replace(value=replacement, right=right)\n\n        return self.balance()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pop_max(self):\n\n        if self.root is NULL:\n            raise KeyError(\"pop from an empty blackjack\")\n\n        self.root, value = self.root.delete_max()\n        self._len -= 1\n        return value", "response": "Remove the maximum value and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the minimum value from the blackjack and return it.", "response": "def pop_min(self):\n        \"\"\"\n        Remove the minimum value and return it.\n        \"\"\"\n\n        if self.root is NULL:\n            raise KeyError(\"pop from an empty blackjack\")\n\n        self.root, value = self.root.delete_min()\n        self._len -= 1\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwrapping for GNU readline.", "response": "def hook_wrapper_23(stdin, stdout, prompt):\r\n    u'''Wrap a Python readline so it behaves like GNU readline.'''\r\n    try:\r\n        # call the Python hook\r\n        res = ensure_str(readline_hook(prompt))\r\n        # make sure it returned the right sort of thing\r\n        if res and not isinstance(res, str):\r\n            raise TypeError, u'readline must return a string.'\r\n    except KeyboardInterrupt:\r\n        # GNU readline returns 0 on keyboard interrupt\r\n        return 0\r\n    except EOFError:\r\n        # It returns an empty string on EOF\r\n        res = u''\r\n    except:\r\n        print >>sys.stderr, u'Readline internal error'\r\n        traceback.print_exc()\r\n        res = u'\\n'\r\n    # we have to make a copy because the caller expects to free the result\r\n    n = len(res)\r\n    p = Console.PyMem_Malloc(n + 1)\r\n    _strncpy(cast(p, c_char_p), res, n + 1)\r\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hook_wrapper(prompt):\r\n    u'''Wrap a Python readline so it behaves like GNU readline.'''\r\n    try:\r\n        # call the Python hook\r\n        res = ensure_str(readline_hook(prompt))\r\n        # make sure it returned the right sort of thing\r\n        if res and not isinstance(res, str):\r\n            raise TypeError, u'readline must return a string.'\r\n    except KeyboardInterrupt:\r\n        # GNU readline returns 0 on keyboard interrupt\r\n        return 0\r\n    except EOFError:\r\n        # It returns an empty string on EOF\r\n        res = u''\r\n    except:\r\n        print >>sys.stderr, u'Readline internal error'\r\n        traceback.print_exc()\r\n        res = u'\\n'\r\n    # we have to make a copy because the caller expects to free the result\r\n    p = _strdup(res)\r\n    return p", "response": "Wrap a Python readline so it behaves like GNU readline."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef install_readline(hook):\r\n    '''Set up things for the interpreter to call \r\n    our function like GNU readline.'''\r\n    global readline_hook, readline_ref\r\n    # save the hook so the wrapper can call it\r\n    readline_hook = hook\r\n    # get the address of PyOS_ReadlineFunctionPointer so we can update it\r\n    PyOS_RFP = c_void_p.from_address(Console.GetProcAddress(sys.dllhandle,\r\n                                            \"PyOS_ReadlineFunctionPointer\"))\r\n    # save a reference to the generated C-callable so it doesn't go away\r\n    if sys.version < '2.3':\r\n        readline_ref = HOOKFUNC22(hook_wrapper)\r\n    else:\r\n        readline_ref = HOOKFUNC23(hook_wrapper_23)\r\n    # get the address of the function\r\n    func_start = c_void_p.from_address(addressof(readline_ref)).value\r\n    # write the function address into PyOS_ReadlineFunctionPointer\r\n    PyOS_RFP.value = func_start", "response": "Installs the interpreter to call \r\n    our function like GNU readline."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a long with x and y packed inside also handle negative x and y.", "response": "def fixcoord(self, x, y):\r\n        u'''Return a long with x and y packed inside, \r\n        also handle negative x and y.'''\r\n        if x < 0 or y < 0:\r\n            info = CONSOLE_SCREEN_BUFFER_INFO()\r\n            self.GetConsoleScreenBufferInfo(self.hout, byref(info))\r\n            if x < 0:\r\n                x = info.srWindow.Right - x\r\n                y = info.srWindow.Bottom + y\r\n\r\n        # this is a hack! ctypes won't pass structures but COORD is \r\n        # just like a long, so this works.\r\n        return c_int(y << 16 | x)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving or query the window cursor.", "response": "def pos(self, x=None, y=None):\r\n        u'''Move or query the window cursor.'''\r\n        if x is None:\r\n            info = CONSOLE_SCREEN_BUFFER_INFO()\r\n            self.GetConsoleScreenBufferInfo(self.hout, byref(info))\r\n            return (info.dwCursorPosition.X, info.dwCursorPosition.Y)\r\n        else:\r\n            return self.SetConsoleCursorPosition(self.hout, \r\n                                                 self.fixcoord(x, y))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite text at current cursor position while watching for scrolling.", "response": "def write_scrolling(self, text, attr=None):\r\n        u'''write text at current cursor position while watching for scrolling.\r\n\r\n        If the window scrolls because you are at the bottom of the screen\r\n        buffer, all positions that you are storing will be shifted by the\r\n        scroll amount. For example, I remember the cursor position of the\r\n        prompt so that I can redraw the line but if the window scrolls,\r\n        the remembered position is off.\r\n\r\n        This variant of write tries to keep track of the cursor position\r\n        so that it will know when the screen buffer is scrolled. It\r\n        returns the number of lines that the buffer scrolled.\r\n\r\n        '''\r\n        x, y = self.pos()\r\n        w, h = self.size()\r\n        scroll = 0 # the result\r\n        # split the string into ordinary characters and funny characters\r\n        chunks = self.motion_char_re.split(text)\r\n        for chunk in chunks:\r\n            n = self.write_color(chunk, attr)\r\n            if len(chunk) == 1: # the funny characters will be alone\r\n                if chunk[0] == u'\\n': # newline\r\n                    x = 0\r\n                    y += 1\r\n                elif chunk[0] == u'\\r': # carriage return\r\n                    x = 0\r\n                elif chunk[0] == u'\\t': # tab\r\n                    x = 8 * (int(x / 8) + 1)\r\n                    if x > w: # newline\r\n                        x -= w\r\n                        y += 1\r\n                elif chunk[0] == u'\\007': # bell\r\n                    pass\r\n                elif chunk[0] == u'\\010':\r\n                    x -= 1\r\n                    if x < 0:\r\n                        y -= 1 # backed up 1 line\r\n                else: # ordinary character\r\n                    x += 1\r\n                if x == w: # wrap\r\n                    x = 0\r\n                    y += 1\r\n                if y == h: # scroll\r\n                    scroll += 1\r\n                    y = h - 1\r\n            else: # chunk of ordinary characters\r\n                x += n\r\n                l = int(x / w) # lines we advanced\r\n                x = x % w # new x value\r\n                y += l\r\n                if y >= h: # scroll\r\n                    scroll += y - h + 1\r\n                    y = h - 1\r\n        return scroll"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn next key press event from the queue ignoring others.", "response": "def getkeypress(self):\r\n        u'''Return next key press event from the queue, ignoring others.'''\r\n        while 1:\r\n            e = self.get()\r\n            if e.type == u'KeyPress' and e.keycode not in key_modifiers:\r\n                log(u\"console.getkeypress %s\"%e)\r\n                if e.keyinfo.keyname == u'next':\r\n                    self.scroll_window(12)\r\n                elif e.keyinfo.keyname == u'prior':\r\n                    self.scroll_window(-12)\r\n                else:\r\n                    return e\r\n            elif ((e.type == u'KeyRelease') and \r\n                  (e.keyinfo == KeyPress('S', False, True, False, 'S'))):\r\n                log(u\"getKeypress:%s,%s,%s\"%(e.keyinfo, e.keycode, e.type))\r\n                return e"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nclasses decorator for inheriting docstrings.", "response": "def inherit_docstrings(cls):\n    \"\"\"Class decorator for inheriting docstrings.\n\n    Automatically inherits base class doc-strings if not present in the\n    derived class.\n\n    \"\"\"\n    @functools.wraps(cls)\n    def _inherit_docstrings(cls):\n        if not isinstance(cls, (type, colorise.compat.ClassType)):\n            raise RuntimeError(\"Type is not a class\")\n\n        for name, value in colorise.compat.iteritems(vars(cls)):\n            if isinstance(getattr(cls, name), types.MethodType):\n                if not getattr(value, '__doc__', None):\n                    for base in cls.__bases__:\n                        basemethod = getattr(base, name, None)\n\n                        if basemethod and getattr(base, '__doc__', None):\n                            value.__doc__ = basemethod.__doc__\n\n        return cls\n\n    return _inherit_docstrings(cls)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nuploading the build site to LSST the Docs.", "response": "def upload(config):\n    \"\"\"Upload the build documentation site to LSST the Docs.\n\n    Parameters\n    ----------\n    config : `lander.config.Configuration`\n        Site configuration, which includes upload information and credentials.\n    \"\"\"\n    token = get_keeper_token(config['keeper_url'],\n                             config['keeper_user'],\n                             config['keeper_password'])\n    build_resource = register_build(config, token)\n\n    ltdconveyor.upload_dir(\n        build_resource['bucket_name'],\n        build_resource['bucket_root_dir'],\n        config['build_dir'],\n        aws_access_key_id=config['aws_id'],\n        aws_secret_access_key=config['aws_secret'],\n        surrogate_key=build_resource['surrogate_key'],\n        cache_control='max-age=31536000',\n        surrogate_control=None,\n        upload_dir_redirect_objects=True)\n\n    confirm_build(config, token, build_resource)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a temporary auth token from LTD Keeper.", "response": "def get_keeper_token(base_url, username, password):\n    \"\"\"Get a temporary auth token from LTD Keeper.\"\"\"\n    token_endpoint = base_url + '/token'\n    r = requests.get(token_endpoint, auth=(username, password))\n    if r.status_code != 200:\n        raise RuntimeError('Could not authenticate to {0}: error {1:d}\\n{2}'.\n                           format(base_url, r.status_code, r.json()))\n    return r.json()['token']"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_product(config):\n    product_url = config['keeper_url'] + '/products/{p}'.format(\n        p=config['ltd_product'])\n    r = requests.get(product_url)\n    if r.status_code != 200:\n        raise RuntimeError(r.json())\n    product_info = r.json()\n    return product_info", "response": "Get the product resource from LTD Keeper."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncompute a unique identifier for the background data", "response": "def _compute_bgid(self, bg=None):\n        \"\"\"Return a unique identifier for the background data\"\"\"\n        if bg is None:\n            bg = self._bgdata\n        if isinstance(bg, qpimage.QPImage):\n            # Single QPImage\n            if \"identifier\" in bg:\n                return bg[\"identifier\"]\n            else:\n                data = [bg.amp, bg.pha]\n                for key in sorted(list(bg.meta.keys())):\n                    val = bg.meta[key]\n                    data.append(\"{}={}\".format(key, val))\n                return hash_obj(data)\n        elif (isinstance(bg, list) and\n              isinstance(bg[0], qpimage.QPImage)):\n            # List of QPImage\n            data = []\n            for bgii in bg:\n                data.append(self._compute_bgid(bgii))\n            return hash_obj(data)\n        elif (isinstance(bg, SeriesData) and\n              (len(bg) == 1 or\n               len(bg) == len(self))):\n            # DataSet\n            return bg.identifier\n        else:\n            raise ValueError(\"Unknown background data type: {}\".format(bg))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a unique identifier for the given data set", "response": "def identifier(self):\n        \"\"\"Return a unique identifier for the given data set\"\"\"\n        if self.background_identifier is None:\n            idsum = self._identifier_data()\n        else:\n            idsum = hash_obj([self._identifier_data(),\n                              self.background_identifier])\n        return idsum"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning time of data at index idx Returns nan if the time is not defined", "response": "def get_time(self, idx):\n        \"\"\"Return time of data at index `idx`\n\n        Returns nan if the time is not defined\"\"\"\n        # raw data\n        qpi = self.get_qpimage_raw(idx)\n        if \"time\" in qpi.meta:\n            thetime = qpi.meta[\"time\"]\n        else:\n            thetime = np.nan\n        return thetime"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_qpimage(self, idx):\n        # raw data\n        qpi = self.get_qpimage_raw(idx)\n        if \"identifier\" not in qpi:\n            msg = \"`get_qpimage_raw` does not set 'identifier' \" \\\n                  + \"in class '{}'!\".format(self.__class__)\n            raise KeyError(msg)\n        # bg data\n        if self._bgdata:\n            if len(self._bgdata) == 1:\n                # One background for all\n                bgidx = 0\n            else:\n                bgidx = idx\n\n            if isinstance(self._bgdata, SeriesData):\n                # `get_qpimage` does take `idx`\n                bg = self._bgdata.get_qpimage_raw(bgidx)\n            else:\n                # `self._bgdata` is a QPImage\n                bg = self._bgdata[bgidx]\n            qpi.set_bg_data(bg_data=bg)\n        return qpi", "response": "Return background - corrected QPImage of data at index idx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef saveh5(self, h5file, qpi_slice=None, series_slice=None,\n               time_interval=None, count=None, max_count=None):\n        \"\"\"Save the data set as an hdf5 file (qpimage.QPSeries format)\n\n        Parameters\n        ----------\n        h5file: str, pathlib.Path, or h5py.Group\n            Where to store the series data\n        qpi_slice: tuple of (slice, slice)\n            If not None, only store a slice of each QPImage\n            in `h5file`. A value of None is equivalent to\n            ``(slice(0, -1), slice(0, -1))``.\n        series_slice: slice\n            If None, save the entire series, otherwise only save\n            the images specified by this slice.\n        time_interval: tuple of (float, float)\n            If not None, only stores QPImages that were recorded\n            within the given time interval.\n        count, max_count: multiprocessing.Value\n            Can be used to monitor the progress of the algorithm.\n            Initially, the value of `max_count.value` is incremented\n            by the total number of steps. At each step, the value\n            of `count.value` is incremented.\n\n        Notes\n        -----\n        The series \"identifier\" meta data is only set when all\n        of `qpi_slice`, `series_slice`, and `time_interval`\n        are None.\n        \"\"\"\n        # set up slice to export\n        if series_slice is None:\n            sl = range(len(self))\n        else:\n            sl = range(series_slice.start, series_slice.stop)\n        # set up time interval\n        if time_interval is None:\n            ta = -np.inf\n            tb = np.inf\n        else:\n            ta, tb = time_interval\n        # set max_count according to slice\n        if max_count is not None:\n            max_count.value += len(sl)\n\n        qpskw = {\"h5file\": h5file,\n                 \"h5mode\": \"w\",\n                 }\n\n        if (qpi_slice is None and\n            series_slice is None and\n                time_interval is None):\n            # Only add series identifier if series complete.\n            # (We assume that if any of the above kwargs is set,\n            # the series data is somehow modified)\n            qpskw[\"identifier\"] = self.identifier\n\n        with qpimage.QPSeries(**qpskw) as qps:\n            increment = 0\n            for ii in sl:\n                ti = self.get_time(ii)\n                if ti < ta or ti > tb:\n                    # Not part of the series\n                    pass\n                else:\n                    increment += 1\n                    if increment == 1 or len(self._bgdata) != 1:\n                        # initial image or series data where each image\n                        # has a unique background image\n                        qpi = self.get_qpimage(ii)\n                        if qpi_slice is not None:\n                            qpi = qpi[qpi_slice]\n                        qps.add_qpimage(qpi)\n                    else:\n                        # hard-link the background data\n                        qpiraw = self.get_qpimage_raw(ii)\n                        if qpi_slice is not None:\n                            qpiraw = qpiraw[qpi_slice]\n                        qps.add_qpimage(qpiraw, bg_from_idx=0)\n                if count is not None:\n                    count.value += 1", "response": "Save the data set as an hdf5 file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the background data for the current object.", "response": "def set_bg(self, dataset):\n        \"\"\"Set background data\n\n        Parameters\n        ----------\n        dataset: `DataSet`, `qpimage.QPImage`, or int\n            If the ``len(dataset)`` matches ``len(self)``,\n            then background correction is performed\n            element-wise. Otherwise, ``len(dataset)``\n            must be one and is used for all data of ``self``.\n\n        See Also\n        --------\n        get_qpimage: obtain the background corrected QPImage\n        \"\"\"\n        if isinstance(dataset, qpimage.QPImage):\n            # Single QPImage\n            self._bgdata = [dataset]\n        elif (isinstance(dataset, list) and\n              len(dataset) == len(self) and\n              isinstance(dataset[0], qpimage.QPImage)):\n            # List of QPImage\n            self._bgdata = dataset\n        elif (isinstance(dataset, SeriesData) and\n              (len(dataset) == 1 or\n               len(dataset) == len(self))):\n            # DataSet\n            self._bgdata = dataset\n        else:\n            raise ValueError(\"Bad length or type for bg: {}\".format(dataset))\n\n        self.background_identifier = self._compute_bgid()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the time of the data set at the given index", "response": "def get_time(self, idx=0):\n        \"\"\"Time of the data\n\n        Returns nan if the time is not defined\n        \"\"\"\n        thetime = super(SingleData, self).get_time(idx=0)\n        return thetime"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef do(self, fn, message=None, *args, **kwargs):\n        self.items.put(ChainItem(fn, self.do, message, *args, **kwargs))\n        return self", "response": "Add a do action to the steps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding an assertion action to the steps and expect the value passed in.", "response": "def expect(self, value, message='Failed: \"{actual} {operator} {expected}\" after step \"{step}\"', operator='=='):\n        \"\"\"Add an 'assertion' action to the steps. This will evaluate the return value of the last 'do' step and\n        compare it to the value passed here using the specified operator.\n\n        Checks that the first function will return 2\n        >>> AssertionChain().do(lambda: 1 + 1, 'add 1 + 1').expect(2)\n\n        This will check that your function does not return None\n        >>> AssertionChain().do(lambda: myfunction(), 'call my function').expect(None, operator='is not')\n\n        :param value: The expected value\n        :param message: The error message to raise if the assertion fails. You can access the variables:\n\n            {actual} -- The actual value\n            {expected} -- The expected value\n            {step} -- The step just performed, which did not meet the expectation\n            {operator} -- The operator used to make the comparison\n\n        \"\"\"\n        if operator not in self.valid_operators:\n            raise ValueError('Illegal operator specified for ')\n        self.items.put(ChainItem(value, self.expect, message, operator=operator))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrun through all of the steps in the chain and runs each of them in sequence.", "response": "def perform(self):\n        \"\"\"Runs through all of the steps in the chain and runs each of them in sequence.\n\n        :return: The value from the lat \"do\" step performed\n        \"\"\"\n        last_value = None\n        last_step = None\n\n        while self.items.qsize():\n\n            item = self.items.get()\n\n            if item.flag == self.do:\n                last_value = item.item(*item.args, **item.kwargs)\n                last_step = item.message\n            elif item.flag == self.expect:\n                message = item.message\n                local = {'value': last_value, 'expectation': item.item}\n                expression = 'value {operator} expectation'.format(operator=item.operator)\n                result = eval(expression, local)\n\n                # Format the error message\n                format_vars = {\n                    'actual': last_value,\n                    'expected': item.item,\n                    'step': last_step,\n                    'operator': item.operator\n                }\n\n                for var, val in format_vars.iteritems():\n                    message = message.replace('{' + str(var) + '}', str(val))\n\n                assert result, message\n\n        return last_value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_volumes(self):\n        vols = [self.find_volume(name) for name in self.virsp.listVolumes()]\n        return vols", "response": "Return a list of all Volumes in this Storage Pool"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_backed_vol(self, name, backer, _format='qcow2'):\n        vol_xml = ElementTree.Element('volume')\n        vol_name = ElementTree.SubElement(vol_xml, 'name')\n        name = '{0}.{1}'.format(name, _format)\n        vol_name.text = name\n\n        target = ElementTree.SubElement(vol_xml, 'target')\n        target_format = ElementTree.SubElement(target, 'format')\n        target_format.set('type', _format)\n\n        vol_cap = ElementTree.SubElement(vol_xml, 'capacity')\n        vol_cap.set('unit', 'bytes')  # @TODO(rdelinger) this should be dynamic\n        vol_cap.text = backer.capacity\n\n        backing_store = ElementTree.SubElement(vol_xml, 'backingStore')\n        bs_path = ElementTree.SubElement(backing_store, 'path')\n        bs_path.text = backer.path\n\n        bs_format = ElementTree.SubElement(backing_store, 'format')\n        bs_format.set('type', backer.format)\n\n        XMLString = ElementTree.tostring(vol_xml)\n        self.virsp.createXML(XMLString, 0)\n\n        return self.find_volume(name)", "response": "This function creates a backed version of the libvirt volume with the given name and format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a storage volume by its name", "response": "def find_volume(self, name):\n        \"\"\"\n        Find a storage volume by its name\n        :param name: The name of the volume\n        :type name: str\n        \"\"\"\n        try:\n            return Volume(self.virsp.storageVolLookupByName(name), self)\n        except libvirtError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the value of the specified attribute converted to a representation value.", "response": "def get_terminal_converted(self, attr):\n        \"\"\"\n        Returns the value of the specified attribute converted to a\n        representation value.\n\n        :param attr: Attribute to retrieve.\n        :type attr: :class:`everest.representers.attributes.MappedAttribute`\n        :returns: Representation string.\n        \"\"\"\n        value = self.data.get(attr.repr_name)\n        return self.converter_registry.convert_to_representation(\n                                                            value,\n                                                            attr.value_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_terminal_converted(self, attr, repr_value):\n        value = self.converter_registry.convert_from_representation(\n                                                            repr_value,\n                                                            attr.value_type)\n        self.data[attr.repr_name] = value", "response": "Converts the given representation value and sets the specified\n        attribute value to the converted value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(self, filename, offset):\n        try:\n            self.offset = offset\n            # self.fd = open(filename, 'rb')\n            # self.fd.close()\n        except IOError:\n            self.logger.error('Unable to load EfiSystem volume')", "response": "Will eventually load information for Apple_Boot volume."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsend the file to the remote host and archives the sent file locally.", "response": "def send(self, filenames=None):\n        \"\"\"Sends the file to the remote host and archives\n        the sent file locally.\n        \"\"\"\n        try:\n            with self.ssh_client.connect() as ssh_conn:\n                with self.sftp_client.connect(ssh_conn) as sftp_conn:\n                    for filename in filenames:\n                        sftp_conn.copy(filename=filename)\n                        self.archive(filename=filename)\n                        if self.update_history_model:\n                            self.update_history(filename=filename)\n        except SSHClientError as e:\n            raise TransactionFileSenderError(e) from e\n        except SFTPClientError as e:\n            raise TransactionFileSenderError(e) from e\n        return filenames"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef compile(self, name, folder=None, data=None):\r\n        template_name = name.replace(os.sep, \"\")\r\n        if folder is None:\r\n            folder = \"\"\r\n        full_name = os.path.join(\r\n            folder.strip(os.sep), template_name)\r\n        if data is None:\r\n            data = {}\r\n        try:\r\n            self.templates[template_name] = \\\r\n                self.jinja.get_template(full_name).render(data)\r\n        except TemplateNotFound as template_error:\r\n            if current_app.config['DEBUG']:\r\n                raise template_error", "response": "Compile a template file with the given data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef run_process(cmd, stdin=None, iterate_stdin=True, output_chunk_size=1024, shell=True, to_close=None, cwd=None):\n    try:\n        p = subprocess.Popen(cmd, shell=shell, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, cwd=cwd)\n\n        if stdin:\n            if iterate_stdin:\n                stdin_iter = iter(stdin)\n                stdin_buffer = ''\n                stdin_available = True\n            else:\n                stdin_buffer = stdin\n                stdin_available = False\n\n        write_set = []\n        read_set = []\n        output_buffer = ''\n\n        if p.stdin and stdin:\n            write_set.append(p.stdin)\n        if p.stdout:\n            read_set.append(p.stdout)\n        if p.stderr:\n            read_set.append(p.stderr)\n\n        while read_set or write_set:\n            try:\n                rlist, wlist, xlist = select.select(read_set, write_set, [])\n            except select.error as e:\n                if e.args[0] == errno.EINTR:\n                    continue\n                raise\n\n            if p.stdin in wlist:\n                while len(stdin_buffer) < _PIPE_BUF and stdin_available:\n                    try:\n                        stdin_buffer += stdin_iter.next()\n                    except StopIteration:\n                        stdin_available = False\n                chunk = stdin_buffer[:_PIPE_BUF]\n                bytes_written = os.write(p.stdin.fileno(), chunk)\n                stdin_buffer = stdin_buffer[bytes_written:]\n\n                if not (stdin_buffer or stdin_available):\n                    p.stdin.close()\n                    write_set.remove(p.stdin)\n\n            if p.stdout in rlist:\n                data = os.read(p.stdout.fileno(), output_chunk_size)\n                if data == '':\n                    p.stdout.close()\n                    read_set.remove(p.stdout)\n                if data:\n                    output_buffer += data\n                    yield data\n\n            if p.stderr in rlist:\n                data = os.read(p.stderr.fileno(), output_chunk_size)\n                if data == '':\n                    p.stderr.close()\n                    read_set.remove(p.stderr)\n                if data:\n                    output_buffer += data\n\n            if len(output_buffer) > output_chunk_size:\n                output_buffer = output_buffer[-output_chunk_size:]\n\n        return_code = p.poll()\n        if return_code:\n            e = subprocess.CalledProcessError(return_code, cmd)\n            e.output = output_buffer\n            raise e\n    finally:\n        if to_close:\n            to_close.close()", "response": "Runs a process and returns a dictionary of the result."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nverifies the HTTP authorization token.", "response": "def verify_http_auth_token(self) -> bool:\r\n        \"\"\" Use request information to validate JWT \"\"\"\r\n        authorization_token = self.get_http_token()\r\n        if authorization_token is not None:\r\n            if self.verify_token(authorization_token):\r\n                if self.data is not None:\r\n                    self.data = self.data['data']\r\n                    return True\r\n                return False\r\n            else:\r\n                return False\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_token_with_refresh_token(self, data, token_valid_for=180,\r\n                                        refresh_token_valid_for=86400):\r\n        \"\"\" Create an encrypted JWT with a refresh_token \"\"\"\r\n        refresh_token = None\r\n        refresh_token = jwt.encode({\r\n            'exp':\r\n                datetime.utcnow() +\r\n                timedelta(seconds=refresh_token_valid_for)},\r\n            self.app_secret).decode(\"utf-8\")\r\n        jwt_token = jwt.encode({\r\n            'data': data,\r\n            'refresh_token': refresh_token,\r\n            'exp': datetime.utcnow() + timedelta(seconds=token_valid_for)},\r\n            self.app_secret)\r\n        return Security.encrypt(jwt_token)", "response": "Create an encrypted JWT with a refresh token"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef verify_refresh_token(self, expired_token) -> bool:\r\n        try:\r\n            decoded_token = jwt.decode(\r\n                Security.decrypt(expired_token),\r\n                self.app_secret,\r\n                options={'verify_exp': False})\r\n            if 'refresh_token' in decoded_token and \\\r\n                    decoded_token['refresh_token'] is not None:\r\n                try:\r\n                    jwt.decode(decoded_token['refresh_token'], self.app_secret)\r\n                    self.data = decoded_token\r\n                    return True\r\n                except (Exception, BaseException) as error:\r\n                    self.errors.append(error)\r\n                    return False\r\n        except (Exception, BaseException) as error:\r\n            self.errors.append(error)\r\n            return False\r\n        return False", "response": "Verify that the refresh token is valid"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nuse expired token to check refresh token information", "response": "def verify_http_auth_refresh_token(self) -> bool:\r\n        \"\"\" Use expired token to check refresh token information \"\"\"\r\n        authorization_token = self.get_http_token()\r\n        if authorization_token is not None:\r\n            if self.verify_refresh_token(authorization_token):\r\n                if self.data is not None:\r\n                    self.data = self.data['data']\r\n                    return True\r\n                return False\r\n            else:\r\n                return False\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef autocomplete(input_list):\r\n  if input_list[0] in ['modulehelp', 'enable', 'disable']:\r\n    commands = []\r\n    for modulename in seash_modules.module_data.keys():\r\n      commands.append(input_list[0] + ' ' + modulename)\r\n    return commands\r\n  return []", "response": "A convenience method that returns a list of valid input completions for the specified command line input."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting status or get status", "response": "def status(self, status_code=None):\r\n        \"\"\" Set status or Get Status \"\"\"\r\n        if status_code is not None:\r\n            self.response_model.status = status_code\r\n        # return string for response support\r\n        return str(self.response_model.status)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn preferred encoding for text I / O.", "response": "def getpreferredencoding():\n    \"\"\"Return preferred encoding for text I/O.\"\"\"\n    encoding = locale.getpreferredencoding(False)\n    if sys.platform == 'darwin' and encoding.startswith('mac-'):\n        # Upgrade ancient MacOS encodings in Python < 2.7\n        encoding = 'utf-8'\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getinputencoding(stream=None):\n    if stream is None:\n        stream = sys.stdin\n    encoding = stream.encoding\n    if not encoding:\n        encoding = getpreferredencoding()\n    return encoding", "response": "Return preferred encoding for reading from stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning preferred encoding for writing to stream.", "response": "def getoutputencoding(stream=None):\n    \"\"\"Return preferred encoding for writing to ``stream``.\n\n    ``stream`` defaults to sys.stdout.\n    \"\"\"\n    if stream is None:\n        stream = sys.stdout\n    encoding = stream.encoding\n    if not encoding:\n        encoding = getpreferredencoding()\n    return encoding"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndecoding from specified encoding.", "response": "def decode(string, encoding=None, errors=None):\n    \"\"\"Decode from specified encoding.\n\n    ``encoding`` defaults to the preferred encoding.\n    ``errors`` defaults to the preferred error handler.\n    \"\"\"\n    if encoding is None:\n        encoding = getpreferredencoding()\n    if errors is None:\n        errors = getpreferrederrors()\n    return string.decode(encoding, errors)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef encode(string, encoding=None, errors=None):\n    if encoding is None:\n        encoding = getpreferredencoding()\n    if errors is None:\n        errors = getpreferrederrors()\n    return string.encode(encoding, errors)", "response": "Encode a string to the specified encoding."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the response MIME type for this view.", "response": "def _get_response_mime_type(self):\n        \"\"\"\n        Returns the reponse MIME type for this view.\n\n        :raises: :class:`pyramid.httpexceptions.HTTPNotAcceptable` if the\n          MIME content type(s) the client specified can not be handled by\n          the view.\n        \"\"\"\n        view_name = self.request.view_name\n        if view_name != '':\n            mime_type = get_registered_mime_type_for_name(view_name)\n        else:\n            mime_type = None\n            acc = None\n            for acc in self.request.accept:\n                if acc == '*/*':\n                    # The client does not care; use the default.\n                    mime_type = self.__get_default_response_mime_type()\n                    break\n                try:\n                    mime_type = \\\n                            get_registered_mime_type_for_string(acc.lower())\n                except KeyError:\n                    pass\n                else:\n                    break\n            if mime_type is None:\n                if not acc is None:\n                    # The client specified a MIME type we can not handle; this\n                    # is a 406 exception. We supply allowed MIME content\n                    # types in the body of the response.\n                    headers = \\\n                        [('Location', self.request.path_url),\n                         ('Content-Type', TextPlainMime.mime_type_string),\n                         ]\n                    mime_strings = get_registered_mime_strings()\n                    exc = HTTPNotAcceptable('Requested MIME content type(s) '\n                                            'not acceptable.',\n                                            body=','.join(mime_strings),\n                                            headers=headers)\n                    raise exc\n                mime_type = self.__get_default_response_mime_type()\n        return mime_type"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_response_body_mime_type(self):\n        mime_type = self._get_response_mime_type()\n        if mime_type is AtomMime:\n            # FIXME: This cements using XML as the representation to use in\n            #        ATOM bodies (which is perhaps not too worrisome).\n            mime_type = XmlMime\n        return mime_type", "response": "Returns the response body MIME type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_result(self, resource):\n        if self._convert_response:\n            self._update_response_body(resource)\n            result = self.request.response\n        else:\n            result = dict(context=resource)\n        return result", "response": "Converts the given resource to a result to be returned from the view."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _update_response_body(self, resource):\n        rpr = self._get_response_representer(resource)\n        # Set content type and body of the response.\n        self.request.response.content_type = \\\n                                rpr.content_type.mime_type_string\n        rpr_body = rpr.to_bytes(resource)\n        self.request.response.body = rpr_body", "response": "Updates the response body with the byte representation created for the given resource."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nupdates the response location header for the given resource.", "response": "def _update_response_location_header(self, resource):\n        \"\"\"\n        Adds a new or replaces an existing Location header to the response\n        headers pointing to the URL of the given resource.\n        \"\"\"\n        location = resource_to_url(resource, request=self.request)\n        loc_hdr = ('Location', location)\n        hdr_names = [hdr[0].upper() for hdr in self.request.response.headerlist]\n        try:\n            idx = hdr_names.index('LOCATION')\n        except ValueError:\n            self.request.response.headerlist.append(loc_hdr)\n        else:\n            # Replace existing location header.\n            # FIXME: It is not clear under which conditions this happens, so\n            #        we do not have a test for it yet.\n            self.request.response.headerlist[idx] = loc_hdr"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a representer for the content type specified in the request.", "response": "def _get_request_representer(self):\n        \"\"\"\n        Returns a representer for the content type specified in the request.\n\n        :raises HTTPUnsupportedMediaType: If the specified content type is\n          not supported.\n        \"\"\"\n        try:\n            mime_type = \\\n              get_registered_mime_type_for_string(self.request.content_type)\n        except KeyError:\n            # The client sent a content type we do not support (415).\n            raise HTTPUnsupportedMediaType()\n        return as_representer(self.context, mime_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nextracting the data from the representation submitted in the request body and returns it.", "response": "def _extract_request_data(self):\n        \"\"\"\n        Extracts the data from the representation submitted in the request\n        body and returns it.\n\n        This default implementation uses a representer for the content type\n        specified by the request to perform the extraction and returns an\n        object implementing the\n        :class:`everest.representers.interfaces.IResourceDataElement`\n        interface.\n\n        :raises HTTPError: To indicate problems with the request data\n          extraction in terms of HTTP codes.\n        \"\"\"\n        rpr = self._get_request_representer()\n        return rpr.data_from_bytes(self.request.body)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nhandles a conflict request.", "response": "def _handle_conflict(self, name):\n        \"\"\"\n        Handles requests that triggered a conflict.\n\n        Respond with a 409 \"Conflict\"\n        \"\"\"\n        err = HTTPConflict('Member \"%s\" already exists!' % name).exception\n        return self.request.get_response(err)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check(self):\n        request = get_current_request()\n        ignore_guid = request.params.get('ignore-message')\n        coll = request.root['_messages']\n        vote = False\n        if ignore_guid:\n            ignore_mb = coll.get(ignore_guid)\n            if not ignore_mb is None and ignore_mb.text == self.message.text:\n                vote = True\n        return vote", "response": "Implements user message checking for views."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a 307 Temporary Redirect response.", "response": "def create_307_response(self):\n        \"\"\"\n        Creates a 307 \"Temporary Redirect\" response including a HTTP Warning\n        header with code 299 that contains the user message received during\n        processing the request.\n        \"\"\"\n        request = get_current_request()\n        msg_mb = UserMessageMember(self.message)\n        coll = request.root['_messages']\n        coll.add(msg_mb)\n        # Figure out the new location URL.\n        qs = self.__get_new_query_string(request.query_string,\n                                         self.message.slug)\n        resubmit_url = \"%s?%s\" % (request.path_url, qs)\n        headers = [('Warning', '299 %s' % self.message.text),\n#                       ('Content-Type', cnt_type),\n                   ]\n        http_exc = HttpWarningResubmit(location=resubmit_url,\n                                       detail=self.message.text,\n                                       headers=headers)\n        return request.get_response(http_exc)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef mkdir(*args):\n    path = ''\n    for chunk in args:\n        path = os.path.join(path, chunk)\n        if not os.path.isdir(path):\n            os.mkdir(path)\n    return path", "response": "Create a directory specified by a sequence of subdirectories."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shell(cmd, *args, **kwargs):\n    # type: (Union[str, unicode], *Union[str, unicode], **Any) ->Tuple[int, str]\n    \"\"\" Execute shell command and return output\n\n    Args:\n        cmd (str): the command itself, i.e. part until the first space\n        *args: positional arguments, i.e. other space-separated parts\n        rel_path (bool): execute relative to the path (default: `False`)\n        raise_on_status(bool): bool, raise exception if command\n            exited with non-zero status (default: `True`)\n        stderr (file-like): file-like object to collect stderr output,\n            None by default\n\n    Returns:\n        Tuple[int, str]: status, shell output\n\n    \"\"\"\n    if kwargs.get('rel_path') and not cmd.startswith(\"/\"):\n        cmd = os.path.join(kwargs['rel_path'], cmd)\n    status = 0\n    try:\n        output = subprocess.check_output(\n            (cmd,) + args, stderr=kwargs.get('stderr'))\n    except subprocess.CalledProcessError as e:\n        if kwargs.get('raise_on_status', True):\n            raise e\n        output = e.output\n        status = e.returncode\n    except OSError as e:  # command not found\n        if kwargs.get('raise_on_status', True):\n            raise e\n        if 'stderr' in kwargs:\n            kwargs['stderr'].write(e.message)\n        return -1, \"\"\n\n    if six.PY3:\n        output = output.decode('utf8')\n    return status, output", "response": "Execute a shell command and return the output of the command."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef raw_filesize(path):\n    # type: (str) -> Optional[int]\n    \"\"\" Get size of a file/directory in bytes.\n\n    Will return None if path does not exist or cannot be accessed.\n    \"\"\"\n    with open('/dev/null', 'w') as devnull:\n        status, output = shell(\"du\", \"-bs\", path, raise_on_status=False,\n                               stderr=devnull)\n    if status != 0:\n        return None\n    # output is: <size>\\t<path>\\n\n    return int(output.split(\"\\t\", 1)[0])", "response": "Get the size of a file or directory in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listen_for_events():\n    import_event_modules()\n    conn = redis_connection.get_connection()\n    pubsub = conn.pubsub()\n    pubsub.subscribe(\"eventlib\")\n    for message in pubsub.listen():\n        if message['type'] != 'message':\n            continue\n        data = loads(message[\"data\"])\n        if 'name' in data:\n            event_name = data.pop('name')\n            process_external(event_name, data)", "response": "Pubsub event listener\n\n    Listen for events in the pubsub bus and calls the process function\n    when somebody comes to play."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sendrequest(self, request):\n        '''\n            Recieves a request xml as a string and posts it\n            to the health service url specified in the\n            settings.py\n        '''\n        url = urlparse.urlparse(self.connection.healthserviceurl)\n        conn = None\n        if url.scheme == 'https':\n            conn = httplib.HTTPSConnection(url.netloc)\n        else:\n            conn = httplib.HTTPConnection(url.netloc)\n        conn.putrequest('POST', url.path)\n        conn.putheader('Content-Type', 'text/xml')\n        conn.putheader('Content-Length', '%d' % len(request))\n        conn.endheaders()\n        try:\n            conn.send(request)\n        except socket.error, v:\n            if v[0] == 32:      # Broken pipe\n                conn.close()\n            raise\n        response = conn.getresponse().read()\n        return etree.fromstring(response)", "response": "Send a request to the health service url specified in the settings. py\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(self, unit_of_work):\n        MemoryRepository.commit(self, unit_of_work)\n        if self.is_initialized:\n            entity_classes_to_dump = set()\n            for state in unit_of_work.iterator():\n                entity_classes_to_dump.add(type(state.entity))\n            for entity_cls in entity_classes_to_dump:\n                self.__dump_entities(entity_cls)", "response": "Commits all resources that were modified by the given session back into the repository."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_pdf_file(self):\n        if self['pdf_path'] is None:\n            self._logger.error('--pdf argument must be set')\n            sys.exit(1)\n        if not os.path.exists(self['pdf_path']):\n            self._logger.error('Cannot find PDF ' + self['pdf_path'])\n            sys.exit(1)", "response": "Validate that the pdf_path configuration is set and the referenced\n        file exists."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_docushare_url(handle, validate=True):\n        logger = structlog.get_logger(__name__)\n        logger.debug('Using Configuration._get_docushare_url')\n\n        # Make a short link to the DocuShare version page since\n        # a) It doesn't immediately trigger a PDF download,\n        # b) It gives the user extra information about the document before\n        #    downloading it.\n        url = 'https://ls.st/{handle}*'.format(handle=handle.lower())\n\n        if validate:\n            # Test that the short link successfully resolves to DocuShare\n            logger.debug('Validating {0}'.format(url))\n            try:\n                response = requests.head(url, allow_redirects=True, timeout=30)\n            except requests.exceptions.RequestException as e:\n                raise DocuShareError(str(e))\n\n            error_message = 'URL {0} does not resolve to DocuShare'.format(url)\n            if response.status_code != 200:\n                logger.warning('HEAD {0} status: {1:d}'.format(\n                    url, response.status_code))\n                raise DocuShareError(error_message)\n            redirect_url_parts = urllib.parse.urlsplit(response.url)\n            if redirect_url_parts.netloc != 'docushare.lsst.org':\n                logger.warning('{0} resolved to {1}'.format(url, response.url))\n                raise DocuShareError(error_message)\n\n        return url", "response": "Get a short link to the DocuShare version page corresponding to the given document s handle."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a dict of default configurations.", "response": "def _init_defaults(self):\n        \"\"\"Create a `dict` of default configurations.\"\"\"\n        defaults = {\n            'build_dir': None,\n            'build_datetime': datetime.datetime.now(dateutil.tz.tzutc()),\n            'pdf_path': None,\n            'extra_downloads': list(),\n            'environment': None,\n            'lsstdoc_tex_path': None,\n            'title': None,\n            'title_plain': \"\",\n            'authors': None,\n            'authors_json': list(),\n            'doc_handle': None,\n            'series': None,\n            'series_name': None,\n            'abstract': None,\n            'abstract_plain': \"\",\n            'ltd_product': None,\n            'docushare_url': None,\n            'github_slug': None,\n            'git_branch': 'master',  # so we default to the main LTD edition\n            'git_commit': None,\n            'git_tag': None,\n            'travis_job_number': None,\n            'is_travis_pull_request': False,  # If not on Travis, not a PR\n            'is_draft_branch': True,\n            'aws_id': None,\n            'aws_secret': None,\n            'keeper_url': 'https://keeper.lsst.codes',\n            'keeper_user': None,\n            'keeper_password': None,\n            'upload': False\n        }\n        return defaults"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating custom permissions on model model.", "response": "def create_permissions_from_tuples(model, codename_tpls):\n    \"\"\"Creates custom permissions on model \"model\".\n    \"\"\"\n    if codename_tpls:\n        model_cls = django_apps.get_model(model)\n        content_type = ContentType.objects.get_for_model(model_cls)\n        for codename_tpl in codename_tpls:\n            app_label, codename, name = get_from_codename_tuple(\n                codename_tpl, model_cls._meta.app_label\n            )\n            try:\n                Permission.objects.get(codename=codename, content_type=content_type)\n            except ObjectDoesNotExist:\n                Permission.objects.create(\n                    name=name, codename=codename, content_type=content_type\n                )\n            verify_codename_exists(f\"{app_label}.{codename}\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving group permissions for historical models except those whose prefix is in allowed_historical_permissions.", "response": "def remove_historical_group_permissions(group=None, allowed_permissions=None):\n    \"\"\"Removes group permissions for historical models\n    except those whose prefix is in `allowed_historical_permissions`.\n\n    Default removes all except `view`.\n    \"\"\"\n    allowed_permissions = allowed_permissions or [\"view\"]\n\n    for action in allowed_permissions:\n        for permission in group.permissions.filter(\n            codename__contains=\"historical\"\n        ).exclude(codename__startswith=action):\n            group.permissions.remove(permission)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef traversal(root):\n    '''Tree traversal function that generates nodes. For each subtree, the \n    deepest node is evaluated first. Then, the next-deepest nodes are \n    evaluated until all the nodes in the subtree are generated.'''\n    stack = [root]\n    while len(stack) > 0:\n        node = stack.pop()\n        if hasattr(node,'children'):\n            if node.children == set():\n                try:\n                    stack[-1].children.remove(node)\n                except:\n                    pass\n                yield (node,stack)\n            else:\n                childnode = node.children.pop()\n                stack += [node,childnode]\n        else: \n            children = [x for x in ast.iter_child_nodes(node)]\n            node.children = set(children)\n            stack.append(node)", "response": "A tree traversal function that generates nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef firstPass(ASTs,verbose):\n    '''Return a dictionary of function definition nodes, a dictionary of  \n    imported object names and a dictionary of imported module names. All three \n    dictionaries use source file paths as keys.'''\n    fdefs=dict()\n    cdefs=dict()\n    imp_obj_strs=dict()\n    imp_mods=dict()\n    for (root,path) in ASTs:\n        fdefs[path] = []\n        fdefs[path].append(formatBodyNode(root,path))\n        imp_obj_strs[path] = []\n        imp_mods[path] = []\n        cdefs[path] = []\n        for (node,stack) in traversal(root):\n            if isinstance(node,ast.FunctionDef):\n                fdefs[path].append(formatFunctionNode(node,path,stack))\n            elif isinstance(node,ast.ImportFrom):\n                module = ia.getImportFromModule(node,path,verbose)\n                if module:\n                    fn_names = ia.getImportFromObjects(node)\n                    for fn_name in fn_names:\n                        imp_obj_strs[path].append((module,fn_name))\n                else:\n                    if verbose:\n                        print(\"No module found \"+ast.dump(node))\n            elif isinstance(node,ast.Import):\n                module = ia.getImportModule(node,path,verbose)\n                imp_mods[path].append(module)\n            elif isinstance(node,ast.ClassDef):\n                node.path=path\n                cdefs[path].append(node)\n    return fdefs,imp_obj_strs,imp_mods,cdefs", "response": "Return a dictionary of function definition nodes a dictionary of imported object names and a dictionary of imported module names. All three \n    dictionaries use source file paths as keys."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef formatBodyNode(root,path):\n    '''Format the root node for use as the body node.'''\n    body        = root\n    body.name   = \"body\"\n    body.weight = calcFnWeight(body)\n    body.path   = path\n    body.pclass = None\n    return body", "response": "Format the root node for use as the body node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef formatFunctionNode(node,path,stack):\n    '''Add some helpful attributes to node.'''\n    #node.name is already defined by AST module\n    node.weight = calcFnWeight(node)\n    node.path   = path\n    node.pclass = getCurrentClass(stack)\n    return node", "response": "Add some helpful attributes to node."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calcFnWeight(node):\n    '''Calculates the weight of a function definition by recursively counting \n    its child nodes in the AST. Note that the tree traversal will become \n    O(n^2) instead of O(n) if this feature is enabled.'''\n    stack = [node]\n    count = 0\n    while len(stack) > 0:\n        node = stack.pop()\n        children = [x for x in ast.iter_child_nodes(node)]\n        count += len(children)\n        stack = stack + children\n    return count", "response": "Calculates the weight of a function definition by recursively counting its child nodes in the AST."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the source function definition", "response": "def getSourceFnDef(stack,fdefs,path):\n    '''VERY VERY SLOW'''\n    found = False\n    for x in stack:\n        if isinstance(x, ast.FunctionDef):\n            for y in fdefs[path]:\n                if ast.dump(x)==ast.dump(y): #probably causing the slowness\n                    found = True\n                    return y\n            raise\n    if not found:\n        for y in fdefs[path]:\n            if y.name=='body':\n                return y\n    raise"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the function node that the input call node targets.", "response": "def getTargetFnDef(node,path,fdefs,cdefs,imp_funcs,imp_mods,imp_classes):\n    ''' Return the function node that the input call node targets. \n    \n    Note that cases 2b and 2c might make false matches. If two classes are\n    imported by the same program and they both have a method with an identical\n    name, then class.method() will be associated with the first class in \n    imp_classes.'''\n    \n    #CASE 1: calling function inside namespace, like foo(x) or randint(x,y)\n    if isinstance(node.func,ast.Name):\n        # CASE 1A: calling an infile function\n        if path in fdefs:\n            for x in fdefs[path]:\n                if node.func.id == x.name:\n                    return x\n        # CASE 1B: calling an imported function\n        if path in imp_funcs:\n            for x in imp_funcs[path]:\n                if node.func.id == x.name: \n                    return x\n        # CASE 1C: infile object instantiation, i.e. a=Car()\n        if path in cdefs:\n            for x in cdefs[path]:\n                if node.func.id == x.name:\n                    classfuncs = [y for y in fdefs[path] if y.pclass==x]\n                    initfuncs = [z for z in classfuncs if z.name=='__init__']\n                    if initfuncs:\n                        return initfuncs[0]\n                        \n        # CASE 1D: imported object instantiation, from exe import car; a=Car()\n        if path in imp_classes:\n            for x in imp_classes[path]:\n                if node.func.id == x.name:\n                    classfuncs = [y for y in fdefs[x.path] if y.pclass==x]\n                    initfuncs = [z for z in classfuncs if z.name=='__init__']\n                    if initfuncs:\n                        return initfuncs[0]\n        return None # builtin functions\n        \n    # CASE 2: calling function outside namespace, like random.randint(x,y)\n    elif isinstance(node.func,ast.Attribute):\n        try:\n            obj    = node.func.value.id\n            method = node.func.attr\n        except AttributeError:\n            return None #weird string thingies\n        if obj == 'self':\n            return None #setting attrs in class def.\n        # CASE 2A: calling imported module.function\n        for modpath in imp_mods[path]:\n            if not modpath:\n                continue\n            elif obj+'.py' in modpath:\n                if modpath in fdefs:\n                    matches = [x for x in fdefs[modpath] if x.name==method]\n                    if matches:\n                        if len(matches)>1:\n                            pass\n                            #print(\"multiple matches found for \"+method)\n                        return matches[0]\n                    \n            # CASE 2B: object instantiation with an imported module\n            if modpath not in cdefs:\n                continue\n            for clss in cdefs[modpath]:\n                if clss.name==method:\n                    classfuncs = [y for y in fdefs[clss.path] if y.pclass==clss]\n                    initfuncs = [z for z in classfuncs if z.name=='__init__']\n                    if initfuncs:\n                        return initfuncs[0]\n                    \n        # CASE 2C: calling infile class.method \n        if path in cdefs:\n            for clss in cdefs[path]:\n                for x in fdefs[clss.path]:\n                    if x.pclass==clss:\n                        return x\n                    \n        # CASE 2D: calling imported class.method         \n        if path in imp_classes:\n            for clss in imp_classes[path]:\n                for x in fdefs[clss.path]:\n                    if x.pclass==clss:\n                        if x.name==method:\n                            return x\n                            \n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef matchImpObjStrs(fdefs,imp_obj_strs,cdefs):\n    '''returns imp_funcs, a dictionary with filepath keys that contains \n    lists of function definition nodes that were imported using\n     from __ import __ style syntax. also returns imp_classes, which \n    is the same for class definition nodes.'''\n    imp_funcs=dict()\n    imp_classes=dict()\n    for source in imp_obj_strs:\n        if not imp_obj_strs[source]:\n            continue\n        imp_funcs[source]=[]\n        imp_classes[source]=[]\n        for (mod,func) in imp_obj_strs[source]:\n            if mod not in fdefs:\n                #print(mod+\" is not part of the project.\")\n                continue\n            if func=='*':\n                all_fns = [x for x in fdefs[mod] if x.name!='body']\n                imp_funcs[source] += all_fns\n                all_cls = [x for x in cdefs[mod]]\n                imp_classes[source] += all_cls\n            else:\n                fn_node = [x for x in fdefs[mod] if x.name==func]\n                cls_node = [x for x in cdefs[mod] if x.name==func]\n                #assert len(fn_node) in [1,0]\n                #assert len(cls_node) in [1,0]\n                if cls_node:\n                    imp_classes[source] += cls_node\n                if fn_node:\n                    imp_funcs[source] += fn_node\n                if not fn_node and not cls_node:\n                    pass\n                    #print(func+' not found in function and class definitions.')\n    return imp_funcs,imp_classes", "response": "returns imp_funcs imp_classes which \n    is the same for function definition nodes that were imported using\n     from __ import __ style syntax. also returns imp_classes which \n    is the same for class definition nodes."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete_database(mongo_uri, database_name):\n    client = pymongo.MongoClient(mongo_uri)\n\n    client.drop_database(database_name)", "response": "Delete a mongo database using pymongo."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete_collection(mongo_uri, database_name, collection_name):\n    client = pymongo.MongoClient(mongo_uri)\n\n    db = client[database_name]\n\n    db.drop_collection(collection_name)", "response": "Delete a mongo document collection using pymongo."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_xml(self, xml):\n        '''\n            :param xml: lxml.etree.Element representing a single VocabularyItem\n        '''\n        xmlutils = XmlUtils(xml)\n        self.code_value = xmlutils.get_string_by_xpath('code-value')\n        self.display_text = xmlutils.get_string_by_xpath('display-text')\n        self.abbreviation_text = xmlutils.get_string_by_xpath('abbreviation-text')\n        info_xml = xml.xpath('info-xml')\n        if info_xml != []:\n            self.info_xml = info_xml[0]", "response": "Parses the VocabularyItem object from an xml."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def main():\n    async with aiohttp.ClientSession() as session:\n        zaehler = Volkszaehler(loop, session, UUID, host=HOST)\n\n        # Get the data\n        await zaehler.get_data()\n\n        print(\"Average:\", zaehler.average)\n        print(\"Max:\", zaehler.max)\n        print(\"Min:\", zaehler.min)\n        print(\"Consumption:\", zaehler.consumption)\n        print(\"Data tuples:\", zaehler.tuples)", "response": "The main part of the example script."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nrunning the parser over the entire sourestring and return the results.", "response": "def parse(self):\n        \"\"\"Run the parser over the entire sourestring and return the results.\"\"\"\n        try:\n            return self.parse_top_level()\n        except PartpyError as ex:\n            self.error = True\n            print(ex.pretty_print())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_contact(self):\n        self.parse_whitespace()\n        name = self.parse_name()  # parse a name expression and get the string.\n        if not name:  # No name was found so shout it out.\n            raise PartpyError(self, 'Expecting a name')\n\n        self.parse_whitespace()\n        # allow name and email to be delimited by either a ':' or '-'\n        if not self.match_any_char(':-'):\n            raise PartpyError(self, 'Expecting : or -')\n        self.eat_length(1)\n        self.parse_whitespace()\n\n        email = self.parse_email()  # parse an email and store its string.\n        if not email:\n            raise PartpyError(self, 'Expecting an email address')\n        return (name, email)", "response": "Parse a top level contact expression."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_name(self):\n        name = []\n        while True:\n            # Match the current char until it doesnt match the given pattern:\n            # first char must be an uppercase alpha and the rest must be lower\n            # cased alphas.\n            part = self.match_string_pattern(spat.alphau, spat.alphal)\n            if part == '':\n                break  # There is no more matchable strings.\n            self.eat_string(part)  # Eat the found string\n            name.append(part)  # Store this name part\n            if self.get_char() == ' ':  # if the current char is a single space\n                # eat it. This allows one space between parts\n                self.eat_length(1)\n\n        if not len(name):  # if no name parts where detected raise an expection.\n            raise PartpyError(self, 'Expecting a title cased name')\n        return ' '.join(name)", "response": "This function uses string patterns to match a title cased name. This function uses string patterns to match a title cased name. This function uses string patterns to match a title cased name. This function uses string patterns to match a title cased name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_email(self):\n        email = []\n        # Match from current char until a non lower cased alpha\n        name = self.match_string_pattern(spat.alphal)\n        if not name:\n            raise PartpyError(self, 'Expected a valid name')\n\n        email.append(name)  # Store the name\n        self.eat_string(name)  # Eat the name\n\n        nextchar = self.get_char()\n        if not nextchar == '@':\n            raise PartpyError(self, 'Expecting @, found: ' + nextchar)\n\n        email.append(nextchar)\n        self.eat_length(1)  # Eat the '@' symbol\n\n        # Use string pattern matching to match all lower cased alphas or '.'s.\n        site = self.match_string_pattern(spat.alphal + '.')\n        if not site:\n            raise PartpyError(self, 'Expecting a site, found: ' + site)\n\n        email.append(site)\n        self.eat_string(site)  # Eat the site\n        return ''.join(email)", "response": "Parses an email address from the internal buffer."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck that the specified object reference is instance of classes and throws a : py : class : TypeError if it is not.", "response": "def require_valid_type(value, *classes):\n    \"\"\"\n    Checks that the specified object reference is instance of classes and\n    throws a :py:class:`TypeError` if it is not.\n\n    :param value: The object.\n    :type value: object\n    :param classes: The classes.\n    :type classes: list(class)\n    \"\"\"\n\n    if value is not None:\n        valid = False\n        for auxiliar_class in classes:\n            if isinstance(value, auxiliar_class):\n                valid = True\n                break\n        if not valid:\n            raise TypeError()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_development_container_name(self):\n        if self.__prefix:\n            return \"{0}:{1}-{2}-dev\".format(\n                self.__repository,\n                self.__prefix,\n                self.__branch)\n        else:\n            return \"{0}:{1}-dev\".format(\n                self.__repository,\n                self.__branch)", "response": "Returns the development container name."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the build container tag", "response": "def get_build_container_tag(self):\n        \"\"\"\n        Return the build container tag\n        \"\"\"\n        if self.__prefix:\n            return \"{0}-{1}-{2}\".format(\n                self.__prefix,\n                self.__branch,\n                self.__version)\n        else:\n            return \"{0}-{1}\".format(\n                self.__branch,\n                self.__version)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_branch_container_tag(self):\n        if self.__prefix:\n            return \"{0}-{1}\".format(\n                self.__prefix,\n                self.__branch)\n        else:\n            return \"{0}\".format(self.__branch)", "response": "Returns the branch container tag"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef custom_server_error(request, template_name='500.html', admin_template_name='500A.html'):\n    trace = None\n    if request.user.is_authenticated() and (request.user.is_staff or request.user.is_superuser):\n        try:\n            import traceback, sys\n            trace = traceback.format_exception(*(sys.exc_info()))\n            if not request.user.is_superuser and trace:\n                trace = trace[-1:]\n            trace = '\\n'.join(trace)\n        except:\n            pass\n    \n    # if url is part of the admin site, use the 500A.html template\n    if request.path.startswith('/%s' % admin.site.name):\n        template_name = admin_template_name\n         \n    t = loader.get_template(template_name) # You need to create a 500.html and 500A.html template.\n    return http.HttpResponseServerError(t.render(Context({'trace': trace})))", "response": "Custom server error handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_n_jobs(s):\n\n    n_jobs = None\n    N = cpu_count()\n\n    if isinstance(s, int): n_jobs = s\n\n    elif isinstance(s, float): n_jobs = int(s)\n\n    elif isinstance(s, str):\n        m = re.match(r'(\\d*(?:\\.\\d*)?)?(\\s*\\*?\\s*n)?$', s.strip())\n        if m is None: raise ValueError('Unable to parse n_jobs=\"{}\"'.format(s))\n\n        k = float(m.group(1)) if m.group(1) else 1\n        if m.group(2): n_jobs = k * N\n        elif k < 1: n_jobs = k * N\n        else: n_jobs = int(k)\n\n    else: raise TypeError('n_jobs argument must be of type str, int, or float.')\n\n    n_jobs = int(n_jobs)\n    if n_jobs <= 0:\n        warnings.warn('n_jobs={} is invalid. Setting n_jobs=1.'.format(n_jobs))\n        n_jobs = 1\n    #end if\n\n    return int(n_jobs)", "response": "Parses a string - like string of number of jobs."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_settings_from_source(self, source):\n        if not source:\n            pass\n        elif source == 'env_settings_uri':\n            for env_settings_uri_key in self.env_settings_uri_keys:\n                env_settings_uri = self._search_environ(env_settings_uri_key)\n                if env_settings_uri:\n                    logger.debug('Found {} in the environment.'.format(env_settings_uri_key))\n                    yield env_settings_uri, self._load_settings_from_uri(env_settings_uri)\n                #end if\n            #end for\n\n        elif source == 'env':\n            logger.debug('Loaded {} settings from the environment.'.format(len(os.environ)))\n            yield source, dict(os.environ.items())\n\n        elif isinstance(source, ParseResult):\n            settings = self._load_settings_from_uri(source)\n            yield source, settings\n\n        elif isinstance(source, str):\n            try: spec = importlib.util.find_spec(source)\n            except (AttributeError, ImportError): spec = None\n\n            settings = self._load_settings_from_spec(spec, name=source)\n            if settings is None:\n                _, ext = os.path.splitext(source)\n                with uri_open(source, 'rb') as f:\n                    yield source, self._load_settings_from_file(f, ext=ext)\n            else:\n                yield source, settings\n            #end if\n\n        elif hasattr(source, 'read'):\n            yield source.name, self._load_settings_from_file(source)\n\n        elif hasattr(source, 'items'):\n            source_type = type(source).__name__\n            for dict_settings_uri_key in self.dict_settings_uri_keys:\n                if dict_settings_uri_key and dict_settings_uri_key in source and source[dict_settings_uri_key]:\n                    logger.debug('Found {} in the dict-like object <{}>.'.format(dict_settings_uri_key, source_type))\n                    yield from self._load_settings_from_source(source[dict_settings_uri_key])\n                #end if\n            #end for\n\n            logger.debug('Loaded {} settings from dict-like object <{}>.'.format(len(source), source_type))\n            yield self._get_unique_name(source_type), source\n\n        else:\n            source_type = type(source).__name__\n            for object_settings_uri_key in self.object_settings_uri_keys:\n                if object_settings_uri_key and hasattr(source, object_settings_uri_key) and getattr(source, object_settings_uri_key):\n                    logger.debug('Found {} in the object <{}>.'.format(object_settings_uri_key, source_type))\n                    yield from self._load_settings_from_source(getattr(source, object_settings_uri_key))\n                #end if\n            #end for\n\n            settings = dict((k, v) for k, v in source.__dict__.items() if not k.startswith('__'))\n            logger.debug('Loaded {} settings from object <{}>.'.format(len(settings), source_type))\n            yield self._get_unique_name(source_type), settings", "response": "Loads the relevant settings from the specified source."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nretrieves the value of a setting specified by key.", "response": "def get(self, key, *, default=None, cast_func=None, case_sensitive=None, raise_exception=None, warn_missing=None, use_cache=True, additional_sources=[]):\n        \"\"\"\n        Gets the setting specified by ``key``. For efficiency, we cache the retrieval of settings to avoid multiple searches through the sources list.\n\n        :param str key: settings key to retrieve\n        :param str default: use this as default value when the setting key is not found\n        :param func cast_func: cast the value of the settings using this function\n        :param bool case_sensitive: whether to make case sensitive comparisons for settings key\n        :param bool raise_exception: whether to raise a :exc:`MissingSettingException` exception when the setting is not found\n        :param bool warn_missing: whether to display a warning when the setting is not found\n        :param list additional_sources: additional sources to search for the key; note that the values obtained here could be cached in a future call\n\n        :returns: the setting value\n        :rtype: str\n        \"\"\"\n\n        case_sensitive = self.case_sensitive if case_sensitive is None else case_sensitive\n        raise_exception = self.raise_exception if raise_exception is None else raise_exception\n        warn_missing = self.warn_missing if warn_missing is None else warn_missing\n\n        if not case_sensitive: key = key.lower()\n\n        if use_cache and key in self._cache:\n            return cast_func(self._cache[key]) if cast_func else self._cache[key]\n\n        found, value = False, None\n\n        for source, settings in chain(self._settings.items(), map(self._load_settings_from_source, additional_sources)):\n            if case_sensitive:\n                if key in settings:\n                    found = True\n                    value = settings[key]\n                else: continue\n\n            else:\n                possible_keys = [k for k in settings.keys() if k.lower() == key]\n                if not possible_keys: continue\n                else:\n                    if len(possible_keys) > 1:\n                        warnings.warn('There are more than one possible value for \"{}\" in <{}> settings due to case insensitivity.'.format(key, source))\n\n                    found = True\n                    value = settings[possible_keys[0]]\n                #end if\n            #end if\n\n            if found: break\n        #end for\n\n        if not found:\n            if raise_exception: raise MissingSettingException('The \"{}\" setting is missing.'.format(key))\n            if warn_missing: warnings.warn('The \"{}\" setting is missing.'.format(key))\n\n            return default\n        #end if\n\n        if use_cache: self._cache[key] = value\n        if cast_func: value = cast_func(value)\n\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the setting value as a bool by cleverly recognizing true values.", "response": "def getbool(self, key, **kwargs):\n        \"\"\"\n        Gets the setting value as a :func:`bool` by cleverly recognizing true values.\n\n        :rtype: bool\n        \"\"\"\n\n        def _string_to_bool(s):\n            if isinstance(s, str):\n                if s.strip().lower() in ('true', 't', '1'): return True\n                elif s.strip().lower() in ('false', 'f', '0', 'None', 'null', ''): return False\n\n                raise ValueError('Unable to get boolean value of \"{}\".'.format(s))\n            #end if\n\n            return bool(s)\n        #end def\n\n        return self.get(key, cast_func=_string_to_bool, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getint(self, key, **kwargs):\n\n        return self.get(key, cast_func=int, **kwargs)", "response": "Gets the setting value as an int."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the setting value as a float.", "response": "def getfloat(self, key, **kwargs):\n        \"\"\"\n        Gets the setting value as a :obj:`float`.\n\n        :rtype: float\n        \"\"\"\n\n        return self.get(key, cast_func=float, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the setting value as a dict or yaml.", "response": "def getserialized(self, key, decoder_func=None, **kwargs):\n        \"\"\"\n        Gets the setting value as a :obj:`dict` or :obj:`list` trying :meth:`json.loads`, followed by :meth:`yaml.load`.\n\n        :rtype: dict, list\n        \"\"\"\n\n        value = self.get(key, cast_func=None, **kwargs)\n\n        if isinstance(value, (dict, list, tuple)) or value is None:\n            return value\n\n        if decoder_func: return decoder_func(value)\n\n        try:\n            o = json.loads(value)\n            return o\n        except json.decoder.JSONDecodeError: pass\n\n        try:\n            o = yaml.load(value)\n            return o\n        except yaml.parser.ParserError: pass\n\n        raise ValueError('Unable to parse {} setting using JSON or YAML.'.format(key))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef geturi(self, key, **kwargs):\n\n        return self.get(key, cast_func=urlparse, **kwargs)", "response": "Get the setting value as a url. ParseResult."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getlist(self, key, delimiter=',', **kwargs):\n\n        value = self.get(key, **kwargs)\n        if value is None: return value\n        if isinstance(value, str):\n            value = value.strip()\n            if value.startswith('[') and value.endswith(']'):\n                return self.getserialized(key)\n\n            return [p.strip(' ') for p in value.split(delimiter)]\n        #end if\n\n        return list(value)", "response": "Gets the setting value as a list ; it splits the string using this delimiter."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getnjobs(self, key, **kwargs):\n\n        return self.get(key, cast_func=parse_n_jobs, **kwargs)", "response": "Get the setting value as an integer relative to the number of CPU."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _in_list(self, original_list, item):\n        # pylint: disable=no-self-use\n\n        for item_list in original_list:\n            if item is item_list:\n                return True\n        return False", "response": "Check that an item as contained in a list."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _sort_results(self, results):\n\n        parents = []\n        groups = []\n        for result in results:\n            if not self._in_list(parents, result.parent):\n                parents.append(result.parent)\n                groups.append([])\n                groups[len(groups) - 1].append(result)\n            else:\n                groups[parents.index(result.parent)].append(result)\n        array = []\n        for group in groups:\n            array += sorted(\n                group,\n                key=lambda element: element.parent.contents.index(element)\n            )\n        return array", "response": "Order the results.\n\n        :param results: The disordened results.\n        :type results: array.bs4.element.Tag\n        :return: The ordened results.\n        :rtype: array.bs4.element.Tag"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfix all hyphens of data attributes for aaaaa to avoid error in the search.", "response": "def _fix_data_select(self):\n        \"\"\"\n        Replace all hyphens of data attributes for 'aaaaa', to avoid error in\n        search.\n        \"\"\"\n\n        elements = self.document.select('*')\n        for element in elements:\n            attributes = element.attrs.keys()\n            data_attributes = list()\n            for attribute in attributes:\n                if bool(re.findall('^data-', attribute)):\n                    data_attributes.append({\n                        'original': attribute,\n                        'modified': re.sub('data-', 'dataaaaaa', attribute),\n                        'value': element[attribute]\n                    })\n            if data_attributes:\n                auxiliar_element = BeautifulSoupHTMLDOMElement(element)\n                for data_attribute in data_attributes:\n                    auxiliar_element.remove_attribute(\n                        data_attribute['original']\n                    )\n                    auxiliar_element.set_attribute(\n                        data_attribute['modified'],\n                        data_attribute['value']\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a list of strings format them with commas and spaces but with and at the end.", "response": "def join_and(value):\n    \"\"\"Given a list of strings, format them with commas and spaces, but\n    with 'and' at the end.\n\n    >>> join_and(['apples', 'oranges', 'pears'])\n    \"apples, oranges, and pears\"\n\n    There is surely a better home for this\n\n    \"\"\"\n    # convert numbers to strings\n    value = [str(item) for item in value]\n\n    if len(value) == 1:\n        return value[0]\n    if len(value) == 2:\n        return \"%s and %s\" % (value[0], value[1])\n\n    # join all but the last element\n    all_but_last = \", \".join(value[:-1])\n    return \"%s and %s\" % (all_but_last, value[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive an activity will attempt to render the matching template snippet for that activity s content object and return a simple representation of the activity.", "response": "def render_activity(activity, grouped_activity=None, *args, **kwargs):\n    \"\"\"\n    Given an activity, will attempt to render the matching template snippet\n    for that activity's content object\n    or will return a simple representation of the activity.\n\n    Also takes an optional 'grouped_activity' argument that would match up with\n    what is produced by utils.group_activity\n    \"\"\"\n    template_name = 'activity_monitor/includes/models/{0.app_label}_{0.model}.html'.format(activity.content_type)\n    try:\n        tmpl = loader.get_template(template_name)\n    except template.TemplateDoesNotExist:\n        return None\n    # we know we have a template, so render it\n    content_object = activity.content_object\n    return tmpl.render(Context({\n        'activity': activity,\n        'obj': content_object,\n        'grouped_activity': grouped_activity\n    }))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef show_activity_count(date=None):\n    if not date:\n        today = datetime.datetime.now() - datetime.timedelta(hours = 24)\n        return Activity.objects.filter(timestamp__gte=today).count()\n    return Activity.objects.filter(timestamp__gte=date).count()", "response": "Simple filter to get activity count for a given day."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a pagination for activities.", "response": "def paginate_activity(visible_date=None):\n    \"\"\"\n    Creates \"get previous day\" / \"get next day\" pagination for activities.\n\n    Visible date is the date of the activities currently being shown,\n    represented by a date object.\n\n    If not provided, it will default to today.\n\n    #Expects date as default \"Aug. 25, 2014\" format.\n    \"\"\"\n    #if visible_date:\n    #    visible_date = datetime.datetime.strptime(visible_date, \"%b %d \")\n\n    if not visible_date:\n        visible_date = datetime.date.today()\n    previous_day = visible_date - datetime.timedelta(days=1)\n    if visible_date == datetime.date.today():\n        next_day = None\n    else:\n        next_day = visible_date + datetime.timedelta(days=1)\n    return {'previous_day': previous_day, 'next_day': next_day}"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_files(self):\r\n        modules = self.evernode_app.get_modules()\r\n        root_path = sys.path[0] if self.evernode_app.root_path is None \\\r\n            else self.evernode_app.root_path\r\n        dirs = [dict(\r\n            dir=os.path.join(root_path, 'resources', 'lang'), module=\"root\")]\r\n        for module_name in modules:\r\n            modules_folder = 'modules{}%s'.format(os.sep)\r\n            if module_name is not None:\r\n                modules_folder = modules_folder % (module_name.strip(os.sep))\r\n            else:\r\n                continue\r\n            path = os.path.join(\r\n                root_path, modules_folder, 'resources', 'lang')\r\n            if os.path.isdir(path):\r\n                dirs.append(dict(dir=path, module=module_name))\r\n        for dir in dirs:\r\n            module_pack = {\r\n                'name': dir['module'],\r\n                'languages': [],\r\n                'file_packs': []\r\n            }\r\n            for path, subdirs, files in os.walk(dir['dir']):\r\n                for subdir in subdirs:\r\n                    module_pack['languages'].append(subdir)\r\n                for name in files:\r\n                    module_pack['file_packs'].append(dict(\r\n                        file=os.path.join(path, name),\r\n                        name=name.rsplit('.', 1)[0].lower(),\r\n                        language=path.split(\"lang%s\" % (os.sep), 1)[1].strip()\r\n                    ))\r\n            self.module_packs.append(module_pack)\r\n        for module_pack in self.module_packs:\r\n            module_pack['file_packs'] = \\\r\n                list({v['file']: v for v in module_pack['file_packs']}\r\n                     .values())\r\n        if self.app.config['DEBUG']:\r\n            print('--- Loaded Language Files ---')\r\n            print(\"Loaded Dirs: \" + str(dirs))\r\n            print(\"Loaded Language Packs: \" + str(self.module_packs))", "response": "Gets modules routes. py and converts to module imports"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks the root path of the EverNode.", "response": "def __root_path(self):\r\n        \"\"\" Just checks the root path if set \"\"\"\r\n        if self.root_path is not None:\r\n            if os.path.isdir(self.root_path):\r\n                sys.path.append(self.root_path)\r\n                return\r\n            raise RuntimeError('EverNode requires a valid root path.'\r\n                               ' Directory: %s does not exist'\r\n                               % (self.root_path))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites the metadata. jsonld file for LSST Projectmeta.", "response": "def write_metadata(self, output_path):\n        \"\"\"Build a JSON-LD dataset for LSST Projectmeta.\n\n        Parameters\n        ----------\n        output_path : `str`\n            File path where the ``metadata.jsonld`` should be written for the\n            build.\n        \"\"\"\n        if self._config.lsstdoc is None:\n            self._logger.info('No known LSST LaTeX source (--tex argument). '\n                              'Not writing a metadata.jsonld file.')\n            return\n\n        # Build a JSON-LD dataset for the report+source repository.\n        product_data = ltdclient.get_product(self._config)\n        metadata = self._config.lsstdoc.build_jsonld(\n            url=product_data['published_url'],\n            code_url=product_data['doc_repo'],\n            ci_url='https://travis-ci.org/' + self._config['github_slug'],\n            readme_url=None,\n            license_id=None)\n\n        json_text = encode_jsonld(\n            metadata,\n            separators=(',', ':'),  # compact\n            ensure_ascii=False)  # unicode output\n        with open(output_path, 'w') as f:\n            f.write(json_text)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef upload_site(self):\n        if not os.path.isdir(self._config['build_dir']):\n            message = 'Site not built at {0}'.format(self._config['build_dir'])\n            self._logger.error(message)\n            raise RuntimeError(message)\n\n        ltdclient.upload(self._config)", "response": "Upload a previously - built site to LSST the Docs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn installed library names.", "response": "def libraries():\n    \"\"\"return installed library names.\"\"\"\n    ls = libraries_dir().dirs()\n    ls = [str(x.name) for x in ls]\n    ls.sort()\n    return ls"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of all examples in lib", "response": "def lib_examples(lib):\n    \"\"\"return library examples.\n\n    EXAMPLE1,EXAMPLE2,..\n\n    \"\"\"\n    d = lib_examples_dir(lib)\n    if not d.exists():\n        return []\n    ls = d.dirs()\n    ls = [x.name for x in ls]\n    ls.sort()\n    return ls"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fmt_num(num, zero_num=None):\n    if zero_num is not None:\n        num = floatformat(num, zero_num)\n    return intcomma(num, False)", "response": "format a number to a human readable format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nintersecting a Line or Point Collection and the Shoreline returning the point of intersection along the coastline.", "response": "def intersect(self, **kwargs):\n        \"\"\"\n            Intersect a Line or Point Collection and the Shoreline\n\n            Returns the point of intersection along the coastline\n            Should also return a linestring buffer around the interseciton point\n            so we can calculate the direction to bounce a particle.\n        \"\"\"\n        ls = None\n\n        if \"linestring\" in kwargs:\n            ls = kwargs.pop('linestring')\n            spoint = Point(ls.coords[0])\n            epoint = Point(ls.coords[-1])\n        elif \"start_point\" and \"end_point\" in kwargs:\n            spoint = kwargs.get('start_point')\n            epoint = kwargs.get('end_point')\n            ls = LineString(list(spoint.coords) + list(epoint.coords))\n        elif \"single_point\" in kwargs:\n            spoint = kwargs.get('single_point')\n            epoint = None\n            ls = LineString(list(spoint.coords) + list(spoint.coords))\n        else:\n            raise TypeError( \"must provide a LineString geometry object, (2) Point geometry objects, or (1) Point geometry object\" )\n\n        inter = False\n\n        # If the current point lies outside of our current shapefile index,\n        # re-query the shapefile in a buffer around this point\n        if self._spatial_query_object is None or (self._spatial_query_object and not ls.within(self._spatial_query_object)):\n            self.index(point=spoint)\n\n        for element in self._geoms:\n            prepped_element = prep(element)\n\n            # Test if starting on land\n            if prepped_element.contains(spoint):\n                if epoint is None:\n                    # If we only passed in one point, return the intersection is true.\n                    return {'point': spoint, 'feature': None}\n                else:\n                    # If we are testing a linestring, raise an exception that we started on land.\n                    raise Exception('Starting point on land: %s %s %s' % (spoint.envelope, epoint.envelope, element.envelope))\n            else:\n                # If we are just checking a single point, continue looping.\n                if epoint is None:\n                    continue\n\n            inter = ls.intersection(element)\n            if inter:\n                # Return the first point in the linestring, and the linestring that it hit\n                if isinstance(inter, MultiLineString):\n                    inter = inter.geoms[0]\n\n                inter = Point(inter.coords[0])\n                smaller_int = inter.buffer(self._spatialbuffer)\n                shorelines = element.exterior.intersection(smaller_int)\n                if isinstance(shorelines, LineString):\n                    shorelines = [shorelines]\n                else:\n                    shorelines = list(shorelines)\n\n                for shore_segment in shorelines:\n                    # Once we find the linestring in the Polygon that was\n                    # intersected, break out and return\n                    if ls.touches(shore_segment):\n                        break\n\n                return {'point': Point(inter.x, inter.y, 0), 'feature': shore_segment or None}\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef react(self, **kwargs):\n        if self._type == \"bounce\":\n            print \"This shoreline type is NOT SUPPORTED and is broken\"\n            return self.__bounce(**kwargs)\n        elif self._type == \"reverse\":\n            return self.__reverse(**kwargs)\n        else:\n            return kwargs.get('hit_point')\n            print \"Not reacting to shoreline (sticky with inifinite concentration)\"", "response": "Returns the shoreline entry point for the hit_point."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbouncing a specific particle from the shoreline to the start point and end point.", "response": "def __bounce(self, **kwargs):\n        \"\"\"\n            Bounce off of the shoreline.\n\n            NOTE: This does not work, but left here for future implementation\n\n            feature = Linestring of two points, being the line segment the particle hit.\n            angle = decimal degrees from 0 (x-axis), couter-clockwise (math style)\n        \"\"\"\n        start_point = kwargs.pop('start_point')\n        hit_point = kwargs.pop('hit_point')\n        end_point = kwargs.pop('end_point')\n        feature = kwargs.pop('feature')\n        distance = kwargs.pop('distance')\n        angle = kwargs.pop('angle')\n\n        # Figure out the angle of the shoreline here (beta)\n        points_in_shore = map(lambda x: Point(x), list(feature.coords))\n        points_in_shore = sorted(points_in_shore, key=lambda x: x.x)\n\n        # The point on the left (least longitude is always the first Point)\n        first_shore = points_in_shore[0]\n        last_shore = points_in_shore[-1]\n\n        shoreline_x = abs(abs(first_shore.x) - abs(last_shore.x))\n        shoreline_y = abs(abs(first_shore.y) - abs(last_shore.y))\n        beta = math.degrees(math.atan(shoreline_x / shoreline_y))\n\n        theta = 90 - angle - beta\n        bounce_azimuth = AsaMath.math_angle_to_azimuth(angle=2 * theta + angle)\n\n        print \"Beta:           \" + str(beta)\n        print \"Incoming Angle: \" + str(angle)\n        print \"ShorelineAngle: \" + str(theta + angle)\n        print \"Bounce Azimuth: \" + str(bounce_azimuth)\n        print \"Bounce Angle:   \" + str(AsaMath.azimuth_to_math_angle(azimuth=bounce_azimuth))\n\n        after_distance = distance - AsaGreatCircle.great_distance(start_point=start_point, end_point=hit_point)['distance']\n        \n        new_point = AsaGreatCircle.great_circle(distance=after_distance, azimuth=bounce_azimuth, start_point=hit_point)\n        return Location4D(latitude=new_point['latitude'], longitude=new_point['longitude'], depth=start_point.depth)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __reverse(self, **kwargs):\n        start_point = kwargs.pop('start_point')\n        hit_point = kwargs.pop('hit_point')\n        distance = kwargs.pop('distance')\n        azimuth = kwargs.pop('azimuth')\n        reverse_azimuth = kwargs.pop('reverse_azimuth')\n        reverse_distance = kwargs.get('reverse_distance', None)\n        if reverse_distance is None:\n            reverse_distance = 100\n\n        # Randomize the reverse angle slightly (+/- 5 degrees)\n        random_azimuth = reverse_azimuth + AsaRandom.random() * 5\n\n        count = 0\n        nudge_distance = 0.01\n        nudge_point = AsaGreatCircle.great_circle(distance=nudge_distance, azimuth=reverse_azimuth, start_point=hit_point)\n        nudge_loc = Location4D(latitude=nudge_point['latitude'], longitude=nudge_point['longitude'], depth=start_point.depth)\n\n        # Find point just offshore to do testing with.  Try 15 times (~350m).  This makes sure the start_point is in the water\n        # for the next call to intersect (next while loop).\n        while self.intersect(single_point=nudge_loc.point) and count < 16:\n            nudge_distance *= 2\n            nudge_point = AsaGreatCircle.great_circle(distance=nudge_distance, azimuth=reverse_azimuth, start_point=hit_point)\n            nudge_loc = Location4D(latitude=nudge_point['latitude'], longitude=nudge_point['longitude'], depth=start_point.depth)\n            count += 1\n\n        # We tried 16 times and couldn't find a point.  This should totally never happen.\n        if count == 16:\n            logger.debug(\"WOW. Could not find location in water to do shoreline calculation with.  Assuming particle did not move from original location\")\n            return start_point\n\n        # Keep trying to throw particle back, halfing the distance each time until it is in water.\n        # Only half it 12 times before giving up and returning the point which the particle came from.\n        count = 0\n        # Distance amount to half each iteration\n        changing_distance = reverse_distance\n        new_point = AsaGreatCircle.great_circle(distance=reverse_distance, azimuth=random_azimuth, start_point=hit_point)\n        new_loc = Location4D(latitude=new_point['latitude'], longitude=new_point['longitude'], depth=start_point.depth)\n        while self.intersect(start_point=nudge_loc.point, end_point=new_loc.point) and count < 12:\n            changing_distance /= 2\n            new_point = AsaGreatCircle.great_circle(distance=changing_distance, azimuth=random_azimuth, start_point=hit_point)\n            new_loc = Location4D(latitude=new_point['latitude'], longitude=new_point['longitude'], depth=start_point.depth)\n            count += 1\n\n        # We tried 10 times and the particle was still on shore, return the point the particle started from.\n        # No randomization.\n        if count == 12:\n            logger.debug(\"Could not react particle with shoreline.  Assuming particle did not move from original location\")\n            return start_point\n\n        return new_loc", "response": "This method is used to reverse the particle just off of the shoreline."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting capabilities. This is a simulation of a GetCapabilities WFS request. Returns a python dict with LatLongBoundingBox and Name keys defined.", "response": "def get_capabilities(self):\n        \"\"\"\n        Gets capabilities.\n\n        This is a simulation of a GetCapabilities WFS request. Returns a python dict\n        with LatLongBoundingBox and Name keys defined.\n        \"\"\"\n        d = {}\n\n        ext = self._layer.GetExtent()       # @TODO if a filter is on this may give different results\n        llbb = [round(float(v), 4) for v in ext]\n\n        d['LatLongBoundingBox'] = box(llbb[0], llbb[2], llbb[1], llbb[3])\n        d['Name']               = self._file.split('/')[-1].split('.')[0]\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of GeoJSON geometries within a certain bounds.", "response": "def get_geoms_for_bounds(self, bounds):\n        \"\"\"\n        Helper method to get geometries within a certain bounds (as WKT).\n\n        Returns GeoJSON (loaded as a list of python dictionaries).\n        \"\"\"\n        poly = ogr.CreateGeometryFromWkt(bounds)\n        self._layer.SetSpatialFilter(poly)\n        poly.Destroy()\n\n        return [json.loads(e.GetGeometryRef().ExportToJson()) for e in self._layer]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting capabilities. Queries WFS server for its capabilities. Internally used by get_feature_type_info.", "response": "def get_capabilities(self):\n        \"\"\"\n        Gets capabilities.\n\n        Queries WFS server for its capabilities. Internally used by get_feature_type_info.\n        \"\"\"\n        params = {'service'      : 'WFS',\n                  'request'      : 'GetCapabilities',\n                  'version'      : '1.0.0'}\n\n        caps_response = requests.get(self._wfs_server, params=params)\n        caps_response.raise_for_status()\n\n        return ET.fromstring(caps_response.content)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_feature_type_info(self):\n        caps = self.get_capabilities()\n        if caps is None:\n            return None\n\n        el = caps.find('{http://www.opengis.net/wfs}FeatureTypeList')\n        for e in el.findall('{http://www.opengis.net/wfs}FeatureType'):\n            if e.find('{http://www.opengis.net/wfs}Name').text == self._feature_name:\n                # transform into python dict\n                # <Name>sample</Name>\n                # <Abstract/>\n                # <LatLongBoundingBox maxx=\"1\" maxy=\"5\" ... />\n                #\n                # becomes:\n                #\n                # {'Name'               :'sample',\n                #  'Abtract'            : None,\n                #  'LatLongBoundingBox' : {'maxx':1, 'maxy':5 ... }}\n                #\n                d = {sube.tag[28:]:sube.text or sube.attrib or None for sube in e.getchildren()}\n\n                # transform LatLongBoundingBox into a Shapely box\n                llbb = {k:round(float(v), 4) for k,v in d['LatLongBoundingBox'].iteritems()}\n                d['LatLongBoundingBox'] = box(llbb['minx'], llbb['miny'], llbb['maxx'], llbb['maxy'])\n                return d\n\n        return None", "response": "Gets FeatureType as a python dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_geoms_for_bounds(self, bounds):\n\n        params = {'service'      : 'WFS',\n                  'request'      : 'GetFeature',\n                  'typeName'     : self._feature_name,\n                  'outputFormat' : 'json',\n                  'version'      : '1.0.0',\n                  'bbox'         : ','.join((str(b) for b in wkt.loads(bounds).bounds))}\n\n        raw_geojson_response = requests.get(self._wfs_server, params=params)\n        raw_geojson_response.raise_for_status()\n        geojson = raw_geojson_response.json()\n\n        return [g['geometry'] for g in geojson['features']]", "response": "Helper method to get geometries within a certain bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_and_bind(self, string):\n        u'''Parse and execute single line of a readline init file.'''\n        try:\n            log(u'parse_and_bind(\"%s\")' % string)\n            if string.startswith(u'#'):\n                return\n            if string.startswith(u'set'):\n                m = re.compile(ur'set\\s+([-a-zA-Z0-9]+)\\s+(.+)\\s*$').match(string)\n                if m:\n                    var_name = m.group(1)\n                    val = m.group(2)\n                    try:\n                        setattr(self.mode, var_name.replace(u'-',u'_'), val)\n                    except AttributeError:\n                        log(u'unknown var=\"%s\" val=\"%s\"' % (var_name, val))\n                else:\n                    log(u'bad set \"%s\"' % string)\n                return\n            m = re.compile(ur'\\s*(.+)\\s*:\\s*([-a-zA-Z]+)\\s*$').match(string)\n            if m:\n                key = m.group(1)\n                func_name = m.group(2)\n                py_name = func_name.replace(u'-', u'_')\n                try:\n                    func = getattr(self.mode, py_name)\n                except AttributeError:\n                    log(u'unknown func key=\"%s\" func=\"%s\"' % (key, func_name))\n                    if self.debug:\n                        print u'pyreadline parse_and_bind error, unknown function to bind: \"%s\"' % func_name\n                    return\n                self.mode._bind_key(key, func)\n        except:\n            log(u'error')\n            raise", "response": "Parse and execute single line of a readline init file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a readline history file. The default filename is ~. history.", "response": "def read_history_file(self, filename=None): \n        u'''Load a readline history file. The default filename is ~/.history.'''\n        if filename is None:\n            filename = self.mode._history.history_filename\n        log(u\"read_history_file from %s\"%ensure_unicode(filename))\n        self.mode._history.read_history_file(filename)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading a character and informs the readline callback interface when a line is received.", "response": "def callback_read_char(self):\n        u'''Reads a character and informs the readline callback interface when a line is received'''\n        if self.keyboard_poll():\n            line = self.get_line_buffer() + u'\\n'\n            # however there is another newline added by\n            # self.mode.readline_setup(prompt) which is called by callback_handler_install\n            # this differs from GNU readline\n            self.add_history(self.mode.l_buffer)\n            # TADA:\n            self.callback(line)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nring the bell if requested.", "response": "def _bell(self):\n        u'''ring the bell if requested.'''\n        if self.bell_style == u'none':\n            pass\n        elif self.bell_style == u'visible':\n            raise NotImplementedError(u\"Bellstyle visible is not implemented yet.\")\n        elif self.bell_style == u'audible':\n            self.console.bell()\n        else:\n            raise ReadlineError(u\"Bellstyle %s unknown.\"%self.bell_style)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a character and informs the readline callback interface when a line is received.", "response": "def callback_read_char(self):\n        #Override base to get automatic newline\n        u'''Reads a character and informs the readline callback interface when a line is received'''\n        if self.keyboard_poll():\n            line = self.get_line_buffer() + u'\\n'\n            self.console.write(u\"\\r\\n\")\n            # however there is another newline added by\n            # self.mode.readline_setup(prompt) which is called by callback_handler_install\n            # this differs from GNU readline\n            self.add_history(self.mode.l_buffer)\n            # TADA:\n            self.callback(line)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __get_param(self, param):\n        try:\n            return self.request_json[param]\n        except KeyError:\n            raise FnexchangeError(400, 'Bad request: {0} is required'.format(param))", "response": "Get a parameter from the request body"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies a list of attributes of a element for another element.", "response": "def set_list_attributes(element1, element2, attributes):\n        \"\"\"\n        Copy a list of attributes of a element for other element.\n\n        :param element1: The element that have attributes copied.\n        :type element1: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param element2: The element that copy the attributes.\n        :type element2: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param attributes: The list of attributes that will be copied.\n        :type attributes: list(str)\n        \"\"\"\n\n        for attribute in attributes:\n            if element1.has_attribute(attribute):\n                element2.set_attribute(\n                    attribute,\n                    element1.get_attribute(attribute)\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nincreases the value of a item in a HTML list.", "response": "def increase_in_list(list_to_increase, string_to_increase):\n        \"\"\"\n        Increase a item in a HTML list.\n\n        :param list_to_increase: The list.\n        :type list_to_increase: str\n        :param string_to_increase: The value of item.\n        :type string_to_increase: str\n        :return: The HTML list with the item added, if the item not was\n                 contained in list.\n        :rtype: str\n        \"\"\"\n\n        if (bool(list_to_increase)) and (bool(string_to_increase)):\n            if CommonFunctions.in_list(list_to_increase, string_to_increase):\n                return list_to_increase\n            return list_to_increase + ' ' + string_to_increase\n        elif bool(list_to_increase):\n            return list_to_increase\n        return string_to_increase"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef in_list(list_to_search, string_to_search):\n\n        if (bool(list_to_search)) and (bool(string_to_search)):\n            elements = re.split('[ \\n\\t\\r]+', list_to_search)\n            for element in elements:\n                if element == string_to_search:\n                    return True\n        return False", "response": "Verify if the list contains the item."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nchecking if the element can be manipulated by HaTeMiLe.", "response": "def is_valid_element(element):\n        \"\"\"\n        Check that the element can be manipulated by HaTeMiLe.\n\n        :param element: The element\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :return: True if element can be manipulated or False if element cannot\n                 be manipulated.\n        :rtype: bool\n        \"\"\"\n\n        if element.has_attribute(CommonFunctions.DATA_IGNORE):\n            return False\n        else:\n            parent_element = element.get_parent_element()\n            if parent_element is not None:\n                tag_name = parent_element.get_tag_name()\n                if (tag_name != 'BODY') and (tag_name != 'HTML'):\n                    return CommonFunctions.is_valid_element(parent_element)\n                return True\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a joke from the WebKnox one liner API.", "response": "def get_joke():\n    \"\"\"Returns a joke from the WebKnox one liner API.\n    \n    Returns None if unable to retrieve a joke.\n    \"\"\"\n\n\n    page = requests.get(\"https://api.chucknorris.io/jokes/random\")\n\n    if page.status_code == 200:\n       joke = json.loads(page.content.decode(\"UTF-8\"))\n       return joke[\"value\"]\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the earliest n ensemble members from the MCMC output", "response": "def burnin(self, n):\n        \"\"\"Remove the earliest n ensemble members from the MCMC output\"\"\"\n        self.sediment_rate = self.sediment_rate[:, n:]\n        self.headage = self.headage[n:]\n        self.sediment_memory = self.sediment_memory[n:]\n        self.objective = self.objective[n:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef update_current_time(loop):\n    global current_time\n    current_time = time()\n    loop.call_later(1, partial(update_current_time, loop))", "response": "Cache the current time since it is needed at the end of every\n    keep - alive request to update the request timeout"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding command - line options for this plugin.", "response": "def options(self, parser, env=None):\n        \"\"\"\n        Adds command-line options for this plugin.\n        \"\"\"\n        if env is None:\n            env = os.environ\n        env_opt_name = 'NOSE_%s' % self.__dest_opt_name.upper()\n        parser.add_option(\"--%s\" % self.__opt_name,\n                          dest=self.__dest_opt_name,\n                          type=\"string\",\n                          default=env.get(env_opt_name),\n                          help=\".ini file providing the environment for the \"\n                               \"test web application.\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the application URL as defined in the INI section server : main. Defaults to http://0. 0. 0", "response": "def get_app_url(self):\n        \"\"\"\n        Returns the application URL as defined in the INI section\n        `server:main`. Defaults to `http://0.0.0.0/6543`.\n        \"\"\"\n        section = 'server:main'\n        if self.has_setting(section, 'host'):\n            host = self.get_setting(section, 'host')\n        else:\n            host = '0.0.0.0'\n        if self.has_setting(section, 'port'):\n            port = int(self.get_setting(section, 'port'))\n        else:\n            port = 6543\n        return 'http://%s:%d' % (host, port)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreleasing an EIP or AID.", "response": "def destroy(self, eip_or_aid, disassociate=False):\n        \"\"\"Release an EIP. If the EIP was allocated for a VPC instance, an\n        AllocationId(aid) must be provided instead of a PublicIp. Setting\n        disassociate to True will attempt to disassociate the IP before\n        releasing it (required for associated nondefault VPC instances).\n        \"\"\"\n        if \".\" in eip_or_aid:               # If an IP is given (Classic)\n            # NOTE: EIPs are automatically disassociated for Classic instances.\n            return \"true\" == self.call(\"ReleaseAddress\",\n                                       response_data_key=\"return\",\n                                       PublicIp=eip_or_aid)\n        else:                               # If an AID is given (VPC)\n            if disassociate:\n                self.disassociate(eip_or_aid)\n            return \"true\" == self.call(\"ReleaseAddress\",\n                                       response_data_key=\"return\",\n                                       AllocationId=eip_or_aid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nassociates an EIP with a given instance or network interface.", "response": "def associate(self, eip_or_aid,\n                  instance_id='', network_interface_id='', private_ip=''):\n        \"\"\"Associate an EIP with a given instance or network interface. If\n        the EIP was allocated for a VPC instance, an AllocationId(aid) must\n        be provided instead of a PublicIp.\n        \"\"\"\n        if \".\" in eip_or_aid:               # If an IP is given (Classic)\n            return self.call(\"AssociateAddress\",\n                             PublicIp=eip_or_aid,\n                             InstanceId=instance_id,\n                             NetworkInterfaceId=network_interface_id,\n                             PrivateIpAddress=private_ip)\n        else:                               # If an AID is given (VPC)\n            return self.call(\"AssociateAddress\",\n                             AllocationId=eip_or_aid,\n                             InstanceId=instance_id,\n                             NetworkInterfaceId=network_interface_id,\n                             PrivateIpAddress=private_ip)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef disassociate(self, eip_or_aid):\n        if \".\" in eip_or_aid:               # If an IP is given (Classic)\n            return \"true\" == self.call(\"DisassociateAddress\",\n                                       response_data_key=\"return\",\n                                       PublicIp=eip_or_aid)\n        else:                               # If an AID is given (VPC)\n            return \"true\" == self.call(\"DisassociateAddress\",\n                                       response_data_key=\"return\",\n                                       AllocationId=eip_or_aid)", "response": "Disassociates an EIP. If the EIP was allocated for a VPC instance,\n        an AllocationId(aid) must be provided instead of a PublicIp."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an instance using the launcher.", "response": "def create(self, ami, count, config=None):\n        \"\"\"Create an instance using the launcher.\"\"\"\n        return self.Launcher(config=config).launch(ami, count)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef control(self, instances, action):\n        if not isinstance(instances, list) and\\\n           not isinstance(instances, tuple):\n            instances = [instances]\n        actions = {'start': {'operation': \"StartInstances\",\n                             'response_data_key': \"StartingInstances\",\n                             'InstanceIds': instances},\n                   'stop': {'operation': \"StopInstances\",\n                            'response_data_key': \"StoppingInstances\",\n                            'InstanceIds': instances},\n                   'reboot': {'operation': \"RebootInstances\",\n                              'response_data_key': \"return\",\n                              'InstanceIds': instances},\n                   'terminate': {'operation': \"TerminateInstances\",\n                                 'response_data_key': \"TerminatingInstances\",\n                                 'InstanceIds': instances},\n                   'protect': {'operation': \"ModifyInstanceAttribute\",\n                               'response_data_key': \"return\",\n                               'Attribute': 'disableApiTermination',\n                               'Value': 'true'},\n                   'unprotect': {'operation': \"ModifyInstanceAttribute\",\n                                 'response_data_key': \"return\",\n                                 'Attribute': 'disableApiTermination',\n                                 'Value': 'false'}}\n        if (action in ('protect', 'unprotect')):\n            for instance in instances:\n                self.call(InstanceId=instance, **actions[action])\n            return \"true\"\n        else:\n            return self.call(**actions[action])", "response": "This method is used to control the state of the instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprovides a configurable launcher for EC2 instances.", "response": "def Launcher(self, config=None):\n        \"\"\"Provides a configurable launcher for EC2 instances.\"\"\"\n        class _launcher(EC2ApiClient):\n            \"\"\"Configurable launcher for EC2 instances. Create the Launcher\n            (passing an optional dict of its attributes), set its attributes\n            (as described in the RunInstances API docs), then launch().\n            \"\"\"\n            def __init__(self, aws, config):\n                super(_launcher, self).__init__(aws)\n                self.config = config\n                self._attr = list(self.__dict__.keys()) + ['_attr']\n\n            def launch(self, ami, min_count, max_count=0):\n                \"\"\"Use given AMI to launch min_count instances with the\n                current configuration. Returns instance info list.\n                \"\"\"\n                params = config.copy()\n                params.update(dict([i for i in self.__dict__.items()\n                                    if i[0] not in self._attr]))\n                return self.call(\"RunInstances\",\n                                 ImageId=ami,\n                                 MinCount=min_count,\n                                 MaxCount=max_count or min_count,\n                                 response_data_key=\"Instances\",\n                                 **params)\n\n        if not config:\n            config = {}\n        return _launcher(self._aws, config)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef events(self, all_instances=None, instance_ids=None, filters=None):\n        params = {}\n        if filters:\n            params[\"filters\"] = make_filters(filters)\n        if instance_ids:\n            params['InstanceIds'] = instance_ids\n        statuses = self.status(all_instances, **params)\n        event_list = []\n        for status in statuses:\n            if status.get(\"Events\"):\n                for event in status.get(\"Events\"):\n                    event[u\"InstanceId\"] = status.get('InstanceId')\n                    event_list.append(event)\n        return event_list", "response": "a list of tuples containing instance Id s and event information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmaking a change to a security group.", "response": "def modify(self, api_action, sgid, other, proto_spec):\n        \"\"\"Make a change to a security group. api_action is an EC2 API name.\n           Other is one of:\n            - a group (sg-nnnnnnnn)\n            - a group with account (<user id>/sg-nnnnnnnn)\n            - a CIDR block (n.n.n.n/n)\n           Proto spec is a triplet (<proto>, low_port, high_port).\"\"\"\n        params = {'group_id': sgid, 'ip_permissions': []}\n        perm = {}\n        params['ip_permissions'].append(perm)\n\n        proto, from_port, to_port = proto_spec\n        perm['IpProtocol'] = proto\n        perm['FromPort'] = from_port or 0\n        perm['ToPort'] = to_port or from_port or 65535\n\n        if other.startswith(\"sg-\"):\n            perm['UserIdGroupPairs'] = [{'GroupId': other}]\n        elif \"/sg-\" in other:\n            account, group_id = other.split(\"/\", 1)\n            perm['UserIdGroupPairs'] = [{\n                'UserId': account,\n                'GroupId': group_id,\n            }]\n        else:\n            perm['IpRanges'] = [{'CidrIp': other}]\n\n        return self.call(api_action, **params)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add(self, sgid, other, proto_spec, direction=\"in\"):\n        # returns bool\n        # AuthorizeSecurityGroupIngress, AuthorizeSecurityGroupEgress\n        if direction == \"in\":\n            api = \"AuthorizeSecurityGroupIngress\"\n        elif direction == \"out\":\n            api = \"AuthorizeSecurityGroupEgress\"\n        else:\n            raise ValueError(\"direction must be one of ('in', 'out')\")\n        return self.modify(api, sgid, other, proto_spec)", "response": "Add a security group rule to group <sgid >."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlist EBS Volume info.", "response": "def get(self, volume_ids=None, filters=None):\n        \"\"\"List EBS Volume info.\"\"\"\n        params = {}\n        if filters:\n            params[\"filters\"] = make_filters(filters)\n        if isinstance(volume_ids, str):\n            volume_ids = [volume_ids]\n        return self.call(\"DescribeVolumes\",\n                         VolumeIds=volume_ids,\n                         response_data_key=\"Volumes\",\n                         **params)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an EBS Volume using an availability - zone and size_or_snap parameter.", "response": "def create(self, az, size_or_snap, volume_type=None, iops=None,\n               encrypted=True):\n        \"\"\"Create an EBS Volume using an availability-zone and size_or_snap\n        parameter, encrypted by default.\n        If the volume is crated from a snapshot, (str)size_or_snap denotes\n        the snapshot id. Otherwise, (int)size_or_snap denotes the amount of\n        GiB's to allocate. iops must be set if the volume type is io1.\n        \"\"\"\n        kwargs = {}\n        kwargs['encrypted'] = encrypted\n        if volume_type:\n            kwargs['VolumeType'] = volume_type\n        if iops:\n            kwargs['Iops'] = iops\n        is_snapshot_id = False\n        try:\n            size_or_snap = int(size_or_snap)\n        except ValueError:\n            is_snapshot_id = True\n        if is_snapshot_id:\n            return self.call(\"CreateVolume\", AvailabilityZone=az,\n                             SnapshotId=size_or_snap, **kwargs)\n        return self.call(\"CreateVolume\", AvailabilityZone=az,\n                         Size=size_or_snap, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef attach(self, volume_id, instance_id, device_path):\n        return self.call(\"AttachVolume\",\n                         VolumeId=volume_id, InstanceId=instance_id,\n                         Device=device_path)", "response": "Attach a volume to an instance."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndetaching a volume from an instance.", "response": "def detach(self, volume_id, instance_id='', device_path='', force=False):\n        \"\"\"Detach a volume from an instance.\"\"\"\n        return self.call(\"DetachVolume\",\n                         VolumeId=volume_id, InstanceId=instance_id,\n                         Device=device_path, force=force)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\noverrides the save method to create a new slug and save it", "response": "def save(self, *args, **kwargs):\n        \"\"\"\n        Overrides the save method\n        \"\"\"\n        self.slug = self.create_slug()\n        super(Slugable, self).save(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create_slug(self):\n        name = self.slug_source\n        counter = 0\n        # loops until slug is unique\n        while True:\n            if counter == 0:\n                slug = slugify(name)\n            else:\n                # using the counter var to bump the slug name\n                slug = slugify('{0} {1}'.format(name, str(counter)))\n            try:\n                # does the slug already exist, excluding the current object\n                self.__class__.objects.exclude(pk=self.pk).get(slug=slug)\n                # if slug exists increment counter and loop\n                counter += 1\n            except ObjectDoesNotExist:\n                # the slug does not exist\n                # we can break from the loop\n                break\n        return slug", "response": "Creates slug checks if slug is unique and loop if not unique"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_html(url,\n             headers=None,\n             timeout=None,\n             errors=\"strict\",\n             wait_time=None,\n             driver=None,\n             zillow_only=False,\n             cache_only=False,\n             zillow_first=False,\n             cache_first=False,\n             random=False,\n             **kwargs):\n    \"\"\"\n    Use Google Cached Url.\n\n    :param cache_only: if True, then real zillow site will never be used.\n    :param driver: selenium browser driver\u3002\n    \"\"\"\n    if wait_time is None:\n        wait_time = Config.Crawler.wait_time\n\n    # prepare url\n    cache_url1 = prefix + url + \"/\"\n    cache_url2 = prefix + url\n    zillow_url = url\n\n    only_flags = [zillow_only, cache_only]\n    if sum(only_flags) == 0:\n        first_flags = [zillow_first, cache_first]\n        if sum(first_flags) == 0:\n            if random:\n                if randint(0, 1):\n                    all_url = [zillow_url, cache_url1, cache_url2]\n                else:\n                    all_url = [cache_url1, cache_url2, zillow_url]\n            else:\n                all_url = [zillow_url, cache_url1, cache_url2]\n        elif sum(first_flags) == 1:\n            if zillow_first:\n                all_url = [zillow_url, cache_url1, cache_url2]\n            elif cache_first:\n                all_url = [cache_url1, cache_url2, zillow_url]\n        else:\n            raise ValueError(\n                \"Only zero or one `xxx_first` argument could be `True`!\")\n\n    elif sum(only_flags) == 1:\n        if zillow_only:\n            all_url = [zillow_url, ]\n        elif cache_only:\n            all_url = [cache_url1, cache_url2]\n\n    else:\n        raise ValueError(\n            \"Only zero or one `xxx_only` argument could be `True`!\")\n\n    for url in all_url:\n        try:\n            html = _get_html(url, headers, timeout, errors,\n                             wait_time, driver, **kwargs)\n            return html\n        except Exception as e:\n            pass\n    raise e", "response": "Get HTML from a URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns list of paths in folder", "response": "def get_paths(folder, ignore_endswith=ignore_endswith):\n    '''Return hologram file paths\n\n    Parameters\n    ----------\n    folder: str or pathlib.Path\n        Path to search folder\n    ignore_endswith: list\n        List of filename ending strings indicating which\n        files should be ignored.\n    '''\n    folder = pathlib.Path(folder).resolve()\n    files = folder.rglob(\"*\")\n    for ie in ignore_endswith:\n        files = [ff for ff in files if not ff.name.endswith(ie)]\n    return sorted(files)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef call(func, args):\n    assert hasattr(func, '__call__'), 'Cannot call func: {}'.format(\n        func.__name__)\n    raw_func = (\n        func if isinstance(func, FunctionType) else func.__class__.__call__)\n    hints = collections.defaultdict(lambda: Any, get_type_hints(raw_func))\n    argspec = _getargspec(raw_func)\n    named_args = {}\n    varargs = ()\n    for k, nk, v in _normalize(args):\n        if nk == argspec.varargs:\n            hints[nk] = Tuple[hints[nk], ...]\n        elif nk not in argspec.args and argspec.varkw in hints:\n            hints[nk] = hints[argspec.varkw]\n        try:\n            value = cast(hints[nk], v)\n        except TypeError as e:\n            _LOGGER.exception(e)\n            six.raise_from(exc.InvalidCliValueError(k, v), e)\n        if nk == argspec.varargs:\n            varargs = value\n        elif (nk in argspec.args or argspec.varkw) and (\n                nk not in named_args or named_args[nk] is None):\n            named_args[nk] = value\n    return func(*varargs, **named_args)", "response": "Call the function with args normalized and cast to the correct types."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_callable(subcommand):\n    # type: (config.RcliEntryPoint) -> Union[FunctionType, MethodType]\n    \"\"\"Return a callable object from the subcommand.\n\n    Args:\n        subcommand: A object loaded from an entry point. May be a module,\n            class, or function.\n\n    Returns:\n        The callable entry point for the subcommand. If the subcommand is a\n        function, it will be returned unchanged. If the subcommand is a module\n        or a class, an instance of the command class will be returned.\n\n    Raises:\n        AssertionError: Raised when a module entry point does not have a\n            callable class named Command.\n    \"\"\"\n    _LOGGER.debug(\n        'Creating callable from subcommand \"%s\".', subcommand.__name__)\n    if isinstance(subcommand, ModuleType):\n        _LOGGER.debug('Subcommand is a module.')\n        assert hasattr(subcommand, 'Command'), (\n            'Module subcommand must have callable \"Command\" class definition.')\n        callable_ = subcommand.Command  # type: ignore\n    else:\n        callable_ = subcommand\n    if any(isinstance(callable_, t) for t in six.class_types):\n        return callable_()\n    return callable_", "response": "Returns a callable object from the subcommand."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getargspec(func):\n    argspec = _getspec(func)\n    args = list(argspec.args)\n    if argspec.varargs:\n        args += [argspec.varargs]\n    if argspec[2]:  # \"keywords\" in PY2 and \"varkw\" in PY3\n        args += [argspec[2]]\n    return _ArgSpec(args, argspec.varargs, argspec[2])", "response": "Return a Python 3 - like argspec object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _normalize(args):\n    # type: (Dict[str, Any]) -> Generator[Tuple[str, str, Any], None, None]\n    \"\"\"Yield a 3-tuple containing the key, a normalized key, and the value.\n\n    Args:\n        args:  The arguments parsed by docopt.\n\n    Yields:\n        A 3-tuple that contains the docopt parameter name, the parameter name\n        normalized to be a valid python identifier, and the value assigned to\n        the parameter.\n    \"\"\"\n    for k, v in six.iteritems(args):\n        nk = re.sub(r'\\W|^(?=\\d)', '_', k).strip('_').lower()\n        do_not_shadow = dir(six.moves.builtins)  # type: ignore\n        if keyword.iskeyword(nk) or nk in do_not_shadow:\n            nk += '_'\n        _LOGGER.debug('Normalized \"%s\" to \"%s\".', k, nk)\n        yield k, nk, v", "response": "Normalizes the arguments to be a valid python identifier."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy the current object to the destination.", "response": "def copy(self, filename=None):\n        \"\"\"Puts on destination as a temp file, renames on\n        the destination.\n        \"\"\"\n        dst = os.path.join(self.dst_path, filename)\n        src = os.path.join(self.src_path, filename)\n        dst_tmp = os.path.join(self.dst_tmp, filename)\n        self.put(src=src, dst=dst_tmp, callback=self.update_progress, confirm=True)\n        self.rename(src=dst_tmp, dst=dst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send(self):\r\n        self.__create()\r\n        email_script = \\\r\n            os.path.join(Path(__file__).parents[1], 'scripts', 'sendemail.py')\r\n        if os.path.exists(email_script):\r\n            subprocess.Popen(\r\n                [get_python_path(), email_script, self.__data],\r\n                stdin=None, stdout=None, stderr=None, close_fds=True)", "response": "Send the message to the user."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the contents of the file.", "response": "def load(self, filename, bs=512):\n        \"\"\"Starts filesystem analysis. Detects supported filesystems and \\\n        loads :attr:`partitions` array.\n\n        Args:\n            filename - Path to file or device for reading.\n\n        Raises:\n            IOError - File/device does not exist or is not readable.\n        \"\"\"\n        self.__filename = filename\n        self.__volumes = []\n\n        # Detect partitioning scheme\n        self.__partition_scheme = rawdisk.scheme.common.detect_scheme(filename)\n\n        plugin_objects = [plugin.plugin_object for plugin in self.__fs_plugins]\n        fs_detector = FilesystemDetector(fs_plugins=plugin_objects)\n\n        if self.__partition_scheme == PartitionScheme.SCHEME_MBR:\n            self.__load_mbr_volumes(filename, fs_detector, bs)\n        elif self.__partition_scheme == PartitionScheme.SCHEME_GPT:\n            self.__load_gpt_volumes(filename, fs_detector, bs)\n        else:\n            self.logger.warning('Partitioning scheme could not be determined.')\n            # try detecting standalone volume\n            volume = fs_detector.detect_standalone(filename, offset=0)\n            if volume is not None:\n                volume.load(filename, offset=0)\n                self.__volumes.append(volume)\n            else:\n                self.logger.warning(\n                    'Were not able to detect standalone volume type')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def async_get_camera_image(self, image_name, username=None, password=None):\n\n        try:\n            data = await self.async_fetch_image_data(\n                image_name, username, password)\n            if data is None:\n                raise XeomaError('Unable to authenticate with Xeoma web '\n                                 'server')\n            return data\n        except asyncio.TimeoutError:\n            raise XeomaError('Connection timeout while fetching camera image.')\n        except aiohttp.ClientError as e:\n            raise XeomaError('Unable to fetch image: {}'.format(e))", "response": "Get a single image from the Xeoma web server."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def async_fetch_image_data(self, image_name, username, password):\n        params = {}\n        cookies = self.get_session_cookie()\n        if username is not None and password is not None:\n            params['user'] = self.encode_user(username, password)\n        else:\n            params['user'] = ''\n        async with aiohttp.ClientSession(cookies=cookies) as session:\n            resp = await session.get(\n                '{}/{}.jpg'.format(self._base_url, image_name),\n                params=params\n            )\n            if resp.headers['Content-Type'] == 'image/jpeg':\n                data = await resp.read()\n            else:\n                data = None\n        return data", "response": "Fetch image data from the Xeoma web server."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse web server camera view for camera image names", "response": "async def async_get_image_names(self):\n        \"\"\"\n            Parse web server camera view for camera image names\n        \"\"\"\n\n        cookies = self.get_session_cookie()\n        try:\n            async with aiohttp.ClientSession(cookies=cookies) as session:\n                resp = await session.get(\n                    self._base_url\n                )\n                t = await resp.text()\n                match = re.findall('(?:\\w|\\d|\")/(.*?).(?:mjpg|jpg)', t)\n                if len(match) == 0:\n                    raise XeomaError('Unable to find any camera image names')\n                image_names = set(match)\n                results = []\n                for image_name in image_names:\n                    match = re.search(\n                        image_name + '\\.(?:mjpg|jpg).*?user=(.*?)&', t\n                    )\n                    if match and len(match.group(1)) > 0:\n                        d = base64.b64decode(unquote(match.group(1))) \\\n                            .decode('ASCII')\n                        creds = d.split(':')\n                        if len(creds) < 2:\n                            raise XeomaError('Error parsing image credentials')\n                        results.append((image_name, creds[0], creds[1]))\n                    else:\n                        results.append((image_name, None, None))\n                return results\n        except asyncio.TimeoutError as e:\n            raise XeomaError(\"Unable to connect to Xeoma web server\")"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate a session cookie object for use by aiohttp", "response": "def get_session_cookie(self):\n        \"\"\"\n            Create a session cookie object for use by aiohttp\n        \"\"\"\n\n        if self._login is not None and self._password is not None:\n            session_key = self.encode_user(self._login, self._password)\n            return {'sessionkey': session_key}\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_sha256_digest(self, content):\n        content_sha256 = base64.b64encode(SHA256.new(content).digest())\n        return 'SHA256=' + content_sha256", "response": "Return the sha256 digest of the content in the Merchant API expects."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsigning the request with SHA256.", "response": "def _sha256_sign(self, method, url, headers, body):\n        \"\"\"Sign the request with SHA256.\n        \"\"\"\n        d = ''\n        sign_headers = method.upper() + '|' + url + '|'\n        for key, value in sorted(headers.items()):\n            if key.startswith('X-Mcash-'):\n                sign_headers += d + key.upper() + '=' + value\n                d = '&'\n\n        rsa_signature = base64.b64encode(\n            self.signer.sign(SHA256.new(sign_headers)))\n\n        return 'RSA-SHA256 ' + rsa_signature"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating or update the group model instances to match the list of group names.", "response": "def create_or_update_groups(self):\n        \"\"\"Add/Deletes group model instances to match the\n        the given list of group names.\n        \"\"\"\n\n        for name in self.group_names:\n            try:\n                Group.objects.get(name=name)\n            except ObjectDoesNotExist:\n                Group.objects.create(name=name)\n        Group.objects.exclude(name__in=self.group_names).delete()\n\n        if self.verbose:\n            names = [obj.name for obj in Group.objects.all().order_by(\"name\")]\n            sys.stdout.write(f\"  Groups are: {', '.join(names)}\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_multipart_form(body, boundary):\n    '''Parse a request body and returns fields and files\n\n    :param body: bytes request body\n    :param boundary: bytes multipart boundary\n    :return: fields (RequestParameters), files (RequestParameters)\n    '''\n    files = RequestParameters()\n    fields = RequestParameters()\n\n    form_parts = body.split(boundary)\n    for form_part in form_parts[1:-1]:\n        file_name = None\n        file_type = None\n        field_name = None\n        line_index = 2\n        line_end_index = 0\n        while not line_end_index == -1:\n            line_end_index = form_part.find(b'\\r\\n', line_index)\n            form_line = form_part[line_index:line_end_index].decode('utf-8')\n            line_index = line_end_index + 2\n\n            if not form_line:\n                break\n\n            colon_index = form_line.index(':')\n            form_header_field = form_line[0:colon_index].lower()\n            form_header_value, form_parameters = parse_header(\n                form_line[colon_index + 2:])\n\n            if form_header_field == 'content-disposition':\n                if 'filename' in form_parameters:\n                    file_name = form_parameters['filename']\n                field_name = form_parameters.get('name')\n            elif form_header_field == 'content-type':\n                file_type = form_header_value\n\n        post_data = form_part[line_index:-4]\n        if file_name or file_type:\n            file = File(type=file_type, name=file_name, body=post_data)\n            if field_name in files:\n                files[field_name].append(file)\n            else:\n                files[field_name] = [file]\n        else:\n            value = post_data.decode('utf-8')\n            if field_name in fields:\n                fields[field_name].append(value)\n            else:\n                fields[field_name] = [value]\n\n    return fields, files", "response": "Parse a multipart request body and returns fields and files."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nattempt to return the auth header token.", "response": "def token(self):\n        '''Attempt to return the auth header token.\n\n        :return: token related to request\n        '''\n        auth_header = self.headers.get('Authorization', '')\n        if 'Token ' in auth_header:\n            return auth_header.partition('Token ')[-1]\n        else:\n            return auth_header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a new Python toolbox containing the tasks from the service.", "response": "def create_toolbox(self, filename):\n        \"\"\"\n        Creates a new Python toolbox where each task name is a GPTool in the toolbox.\n\n        :param filename: the filename of the generated toolbox\n        :param service_name: The name of the ESE service containing the tasks.  Only tasks from\n                             one service may be used.\n        :param tasks: The list of tasks from the service to build as GPTools.\n        \"\"\"\n        filename = os.path.splitext(filename)[0]\n        label = os.path.basename(filename)\n\n        # Get task information first so we can build the tool list\n        tool_list = []\n        for task in self.tasks:\n            tool_list.append(task.name)\n\n        file_descriptor = os.open(filename + '.pyt',\n                                  os.O_WRONLY | os.O_CREAT | os.O_EXCL)\n        with os.fdopen(file_descriptor, 'w') as self.toolbox_file:\n            self.toolbox_file.write(self._imports_template.substitute({}))\n            toolbox_class = self._toolbox_class_template.substitute(\n                {'label': label,\n                 'alias': self.alias,\n                 'toolList': param_builder.convert_list(tool_list)\n                }\n            )\n            self.toolbox_file.write(toolbox_class)\n\n            for task in self.tasks:\n                gp_tool = self.create_tool(task)\n                self.toolbox_file.write(gp_tool)\n                toolbox_help_filename = '.'.join((filename, task.name, 'pyt', 'xml'))\n                help_builder.create(toolbox_help_filename, task, self.alias)\n\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a GPTool object for the current version of the task.", "response": "def create_tool(self, task):\n        \"\"\"\n        Creates a new GPTool for the toolbox.\n\n\n        \"\"\"\n        gp_tool = dict(taskName=task.name,\n                       taskDisplayName=task.display_name,\n                       taskDescription=task.description,\n                       canRunInBackground=True,\n                       taskUri=task.uri)\n\n        gp_tool['execute'] = self._execute_template.substitute(gp_tool)\n        gp_tool['parameterInfo'] = param_builder.create_param_info(task.parameters,\n                                                                   self.parameter_map)\n        gp_tool['updateParameter'] = param_builder.create_update_parameter(task.parameters,\n                                                                           self.parameter_map)\n        gp_tool['preExecute'] = param_builder.create_pre_execute(task.parameters,\n                                                                 self.parameter_map)\n        gp_tool['postExecute'] = param_builder.create_post_execute(task.parameters,\n                                                                   self.parameter_map)\n        return self._tool_template.substitute(gp_tool)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_script(self, script_name):\n        filename = os.path.abspath(script_name)\n        with open(filename, 'r') as script_file:\n            self.toolbox_file.write(script_file.read())", "response": "Finds the script file and copies it into the toolbox"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a relationship object for this attribute from the given relator and direction.", "response": "def make_relationship(self, relator,\n                          direction=\n                            RELATIONSHIP_DIRECTIONS.BIDIRECTIONAL):\n        \"\"\"\n        Create a relationship object for this attribute from the given\n        relator and relationship direction.\n        \"\"\"\n        if IEntity.providedBy(relator): # pylint:disable=E1101\n            rel = DomainRelationship(relator, self,\n                                     direction=direction)\n        elif IResource.providedBy(relator): # pylint:disable=E1101\n            rel = ResourceRelationship(relator, self,\n                                       direction=direction)\n        else:\n            raise ValueError('Invalid relator argument \"%s\" for '\n                             'relationship; must provide IEntity or '\n                             'IResource.' % relator)\n        return rel"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ntransforming version string into comparable list", "response": "def parse(version):\n    # type: (Union[str, unicode]) -> list\n    \"\"\" Transform version string into comparable list\n    :param version: version string, e.g. 0.11.23rc1\n    :return: list of version chunks, e.g. [0, 11, 23, 'rc1']\n\n    >>> parse(\"1\")\n    [1]\n    >>> parse(\"0.0.1\")\n    [0, 0, 1]\n    >>> parse(\"0.11.23rc1\")\n    [0, 11, 23, 'rc1']\n    \"\"\"\n    chunks = []\n    for chunk in re.findall(r\"(\\d+|[A-Za-z]\\w*)\", version):\n        try:\n            chunk = int(chunk)\n        except ValueError:\n            pass\n        chunks.append(chunk)\n    return chunks"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister the blueprint to the mach9 app.", "response": "def register(self, app, options):\n        \"\"\"Register the blueprint to the mach9 app.\"\"\"\n\n        url_prefix = options.get('url_prefix', self.url_prefix)\n\n        # Routes\n        for future in self.routes:\n            # attach the blueprint name to the handler so that it can be\n            # prefixed properly in the router\n            future.handler.__blueprintname__ = self.name\n            # Prepend the blueprint URI prefix if available\n            uri = url_prefix + future.uri if url_prefix else future.uri\n            app.route(\n                uri=uri[1:] if uri.startswith('//') else uri,\n                methods=future.methods,\n                host=future.host or self.host,\n                strict_slashes=future.strict_slashes,\n                stream=future.stream\n                )(future.handler)\n\n        # Middleware\n        for future in self.middlewares:\n            if future.args or future.kwargs:\n                app.middleware(*future.args,\n                               **future.kwargs)(future.middleware)\n            else:\n                app.middleware(future.middleware)\n\n        # Exceptions\n        for future in self.exceptions:\n            app.exception(*future.args, **future.kwargs)(future.handler)\n\n        # Static Files\n        for future in self.statics:\n            # Prepend the blueprint URI prefix if available\n            uri = url_prefix + future.uri if url_prefix else future.uri\n            app.static(uri, future.file_or_directory,\n                       *future.args, **future.kwargs)\n\n        # Event listeners\n        for event, listeners in self.listeners.items():\n            for listener in listeners:\n                app.listener(event)(listener)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_route(self, handler, uri, methods=frozenset({'GET'}), host=None,\n                  strict_slashes=False):\n        \"\"\"Create a blueprint route from a function.\n\n        :param handler: function for handling uri requests. Accepts function,\n                        or class instance with a view_class method.\n        :param uri: endpoint at which the route will be accessible.\n        :param methods: list of acceptable HTTP methods.\n        :return: function or class instance\n        \"\"\"\n        # Handle HTTPMethodView differently\n        if hasattr(handler, 'view_class'):\n            http_methods = (\n                'GET', 'POST', 'PUT', 'HEAD', 'OPTIONS', 'PATCH', 'DELETE')\n            methods = set()\n            for method in http_methods:\n                if getattr(handler.view_class, method.lower(), None):\n                    methods.add(method)\n\n        # handle composition view differently\n        if isinstance(handler, self._composition_view_class):\n            methods = handler.handlers.keys()\n\n        self.route(uri=uri, methods=methods, host=host,\n                   strict_slashes=strict_slashes)(handler)\n        return handler", "response": "Create a blueprint route from a function."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef static(self, uri, file_or_directory, *args, **kwargs):\n        static = FutureStatic(uri, file_or_directory, args, kwargs)\n        self.statics.append(static)", "response": "Create a blueprint static route from a decorated function."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove_boards_gui(hwpack=''):\n    if not hwpack:\n        if len(hwpack_names()) > 1:\n            hwpack = psidialogs.choice(hwpack_names(),\n                                       'select hardware package to select board from!',\n                                       title='select')\n        else:\n            hwpack = hwpack_names()[0]\n    print('%s selected' % hwpack)\n\n    if hwpack:\n        sel = psidialogs.multi_choice(board_names(hwpack),\n                                      'select boards to remove from %s!' % boards_txt(\n                                          hwpack),\n                                      title='remove boards')\n        print('%s selected' % sel)\n\n        if sel:\n            for x in sel:\n                remove_board(x)\n                print('%s was removed' % x)", "response": "remove boards by GUI."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a queryset of activity objects will group them by actors and return an OrderedDict including the items that are not already in the queryset.", "response": "def group_activities(queryset):\n    \"\"\"\n    Given a queryset of activity objects, will group them by actors and return an OrderedDict including:\n\n    item: The original target item being acted upon (activity.content_object)\n    actors: a list of all actors who have acted upon the target.\n    actor_count: zero-indexed count of actors. Useful for \"Joe and {{ actor_count }} others have...\"\n    verb: the item's verb string, to avoid extra lookups\n    last_modified: the time the target was last acted upon.\n\n    The string version of the target is also available as the dict key.\n    \"\"\"\n    actions = OrderedDict()\n    for item in queryset:\n        # current is defined as within the past day.\n        if item.timestamp >= datetime.datetime.now() - datetime.timedelta(days=1):\n            current_item = True\n        else:\n            current_item = False\n        if item.target not in actions.keys():\n            actions[item.target] = {\n                'item': item,\n                'actors': [item.actor_name],\n                'actor_count': 0,\n                'verb': item.override_string if item.override_string else item.verb,\n                'last_modified': item.timestamp,\n                'current_item': current_item\n            }\n        else: # item was previously added, but we need to update attributes\n            if item.actor_name not in actions[item.target]['actors']:\n                actions[item.target]['actors'].append(item.actor_name)\n                actions[item.target]['actor_count'] += 1\n            if actions[item.target]['last_modified'] < item.timestamp:\n                actions[item.target]['last_modified'] = item.timestamp\n\n    return actions"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef single(C, namespace=None):\n        if namespace is None:\n            B = C()._\n        else:\n            B = C(default=namespace, _=namespace)._\n        return B", "response": "An element maker with a single namespace that uses that namespace as the default"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intersect(self, **kwargs):\n        end_point = kwargs.pop('end_point')\n        depth = self.get_depth(location=end_point)\n        # Bathymetry and a particle's depth are both negative down\n        if depth < 0 and depth > end_point.depth:\n            inter = True\n        else:\n            inter = False\n        return inter", "response": "Intersects two Bathymetry and Intersect Point and Bathymetry returns bool"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef react(self, **kwargs):\n        react_type = kwargs.get(\"type\", self._type)\n\n        if react_type == 'hover':\n            return self.__hover(**kwargs)\n        elif react_type == 'stick':\n            pass\n        elif react_type == 'reverse':\n            return self.__reverse(**kwargs)\n        else:\n            raise ValueError(\"Bathymetry interaction type not supported\")", "response": "Returns the reactance of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef __hover(self, **kwargs):\n        end_point = kwargs.pop('end_point')\n        # The location argument here should be the point that intersected the bathymetry,\n        # not the end_point that is \"through\" the bathymetry.\n        depth = self.get_depth(location=end_point)\n        return Location4D(latitude=end_point.latitude, longitude=end_point.longitude, depth=(depth + 1.))", "response": "This is the function that is called when the user hits the bathymetry and hovers the particle. It is only called when the user hits the bathymetry and the particle is hit."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __reverse(self, **kwargs):\n        start_point = kwargs.pop('start_point')\n        return Location4D(latitude=start_point.latitude, longitude=start_point.longitude, depth=start_point.depth)", "response": "Reverse the location of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    # type: () -> typing.Any\n    \"\"\"Parse the command line options and launch the requested command.\n\n    If the command is 'help' then print the help message for the subcommand; if\n    no subcommand is given, print the standard help message.\n    \"\"\"\n    colorama.init(wrap=six.PY3)\n    doc = usage.get_primary_command_usage()\n    allow_subcommands = '<command>' in doc\n    args = docopt(doc, version=settings.version,\n                  options_first=allow_subcommands)\n    if sys.excepthook is sys.__excepthook__:\n        sys.excepthook = log.excepthook\n    try:\n        log.enable_logging(log.get_log_level(args))\n        default_args = sys.argv[2 if args.get('<command>') else 1:]\n        if (args.get('<command>') == 'help' and\n                None not in settings.subcommands):\n            subcommand = next(iter(args.get('<args>', default_args)), None)\n            return usage.get_help_usage(subcommand)\n        argv = [args.get('<command>')] + args.get('<args>', default_args)\n        return _run_command(argv)\n    except exc.InvalidCliValueError as e:\n        return str(e)", "response": "Parse the command line options and launch the requested command."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the function for the specified subcommand.", "response": "def _get_subcommand(name):\n    # type: (str) -> config.RcliEntryPoint\n    \"\"\"Return the function for the specified subcommand.\n\n    Args:\n        name: The name of a subcommand.\n\n    Returns:\n        The loadable object from the entry point represented by the subcommand.\n    \"\"\"\n    _LOGGER.debug('Accessing subcommand \"%s\".', name)\n    if name not in settings.subcommands:\n        raise ValueError(\n            '\"{subcommand}\" is not a {command} command. \\'{command} help -a\\' '\n            'lists all available subcommands.'.format(\n                command=settings.command, subcommand=name)\n        )\n    return settings.subcommands[name]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _run_command(argv):\n    # type: (typing.List[str]) -> typing.Any\n    \"\"\"Run the command with the given CLI options and exit.\n\n    Command functions are expected to have a __doc__ string that is parseable\n    by docopt.\n\n    Args:\n        argv: The list of command line arguments supplied for a command. The\n            first argument is expected to be the name of the command to be run.\n            Note that this is different than the full arguments parsed by\n            docopt for the entire program.\n\n    Raises:\n        ValueError: Raised if the user attempted to run an invalid command.\n    \"\"\"\n    command_name, argv = _get_command_and_argv(argv)\n    _LOGGER.info('Running command \"%s %s\" with args: %s', settings.command,\n                 command_name, argv)\n    subcommand = _get_subcommand(command_name)\n    func = call.get_callable(subcommand)\n    doc = usage.format_usage(subcommand.__doc__)\n    args = _get_parsed_args(command_name, doc, argv)\n    return call.call(func, args) or 0", "response": "Runs the command with the given CLI options and exits."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_command_and_argv(argv):\n    # type: (typing.List[str]) -> typing.Tuple[str, typing.List[str]]\n    \"\"\"Extract the command name and arguments to pass to docopt.\n\n    Args:\n        argv: The argument list being used to run the command.\n\n    Returns:\n        A tuple containing the name of the command and the arguments to pass\n        to docopt.\n    \"\"\"\n    command_name = argv[0]\n    if not command_name:\n        argv = argv[1:]\n    elif command_name == settings.command:\n        argv.remove(command_name)\n    return command_name, argv", "response": "Extracts the command name and argument list from the docopt command line."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the docstring with docopt.", "response": "def _get_parsed_args(command_name, doc, argv):\n    # type: (str, str, typing.List[str]) -> typing.Dict[str, typing.Any]\n    \"\"\"Parse the docstring with docopt.\n\n    Args:\n        command_name: The name of the subcommand to parse.\n        doc: A docopt-parseable string.\n        argv: The list of arguments to pass to docopt during parsing.\n\n    Returns:\n        The docopt results dictionary. If the subcommand has the same name as\n        the primary command, the subcommand value will be added to the\n        dictionary.\n    \"\"\"\n    _LOGGER.debug('Parsing docstring: \"\"\"%s\"\"\" with arguments %s.', doc, argv)\n    args = docopt(doc, argv=argv)\n    if command_name == settings.command:\n        args[command_name] = True\n    return args"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef trace(msg):\n    if os.environ.get('JARN_TRACE') == '1':\n        print('TRACE:', msg, file=sys.stderr)", "response": "Print a trace message to stderr if JARN_TRACE is set."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Efn(Ms,eccs):\n    Ms = np.atleast_1d(Ms)\n    eccs = np.atleast_1d(eccs)\n    unit = np.floor(Ms / (2*np.pi))\n    Es = EFN((Ms % (2*np.pi)),eccs)\n    Es += unit*(2*np.pi)\n    return Es", "response": "works for - 2pi < Ms < 2pi < e < 0. 97"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_module(modulefn):\n  # We can't import python modules by specifying the full path to the module\n  # Temporarily add the module path to the pythonpath\n  sys.path = [MODULES_FOLDER_PATH] + sys.path\n  moduleobj = __import__(modulefn)\n  try:\n    _attach_module_identifier(moduleobj.moduledata['command_dict'], modulefn)\n    return moduleobj.moduledata\n  except (NameError, KeyError):\n    raise seash_exceptions.ModuleImportError(\"Module '\" + modulefn + \"' is not well defined\")\n  finally:\n    # Remove the module path from the pythonpath because we don't need it anymore\n    sys.path = sys.path[1:]", "response": "Imports a module with the specified modulename and returns a dictionary containing the command_dict and helptext."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nimports all modules within the modules folder.", "response": "def import_all_modules():\n  \"\"\"\n  <Purpose>\n    Imports all modules within the modules folder.  This should only be called once \n    throughout the entire execution of seash.\n      \n  <Side Effects>\n    Modules that don't have collisions will have their commanddicts and \n    helptexts loaded and returned.\n    \n  <Exceptions>\n    ImportError: There is an existing module with the same name already imported.\n      \n  <Return>\n    The seashcommanddict that contains the imported commands on top of the \n    passed in commanddict.\n\n  \"\"\"\n  for module_folder in get_installed_modules(): \n    try:\n      if module_folder in module_data:\n        raise seash_exceptions.ModuleImportError(\"Module already imported\")\n      module_data[module_folder] = import_module(module_folder)\n    except seash_exceptions.ModuleImportError, e:\n      print str(e)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensure_no_conflicts_in_commanddicts(originaldict, comparedict):\n  \n  \"\"\"\n  Child nodes are identical if they all of the following are identical: \n    helptext/callback/summary.\n     \n  There are 3 cases we have to worry about.\n  > Shared child node.\n    > Child nodes are identical.  Check grandchildren.\n    > Only one is defined.  Check grandchildren.\n    > Both child nodes are defined and are not identical.  Reject.\n  > Node is not shared.  Accept. \n  \"\"\"\n  \n  for child in comparedict.keys():\n    # Node not shared.\n    if child not in originaldict:\n      continue\n    \n    # Shared node\n    comparechild_defined = is_commanddictnode_defined(comparedict[child])\n    originalchild_defined = is_commanddictnode_defined(originaldict[child])\n    \n    # Only one is defined, or;\n    # both are defined and they are identical\n    if ((comparechild_defined ^ originalchild_defined) or\n        (comparechild_defined and originalchild_defined and \n         _are_cmd_nodes_same(originaldict[child], comparedict[child]))):\n      try:\n        ensure_no_conflicts_in_commanddicts(comparedict[child]['children'], originaldict[child]['children'])\n      except seash_exceptions.ModuleConflictError, e:\n        # Reconstruct the full command recursively\n        raise seash_exceptions.ModuleConflictError(child + \" \" + str(e) + \" (\"+module_name+\")\")\n      continue\n    \n    # Not identical.  Conflict found.\n    # Also include which module the conflicting module was found from.\n    if 'module' in originaldict[child]:\n        module_name = originaldict['module'][child]      \n    else:\n      module_name = \"default\"\n    raise seash_exceptions.ModuleConflictError(child + ' ('+module_name+')')", "response": "Ensures that two commanddicts are identical."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncheck to see if two cmddnodes are the same.", "response": "def _are_cmd_nodes_same(node1, node2):\n  \"\"\" \n  Checks to see if two cmddnodes are the same.\n  Two cmdnodes are defined to be the same if they have the same callbacks/\n  helptexts/summaries. \n  \"\"\"\n\n  # Everything in node1 should be in node2\n  for propertytype in node1:\n    if (not propertytype in node2 or\n        node1[propertytype] != node2[propertytype]):\n      return False\n  return True"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef are_cmddicts_same(dict1, dict2):\n  \n  # If the set of all keys are not the same, they must not be the same.\n  if set(dict1.keys()) != set(dict2.keys()):\n    return False\n  \n  # Everything in dict1 should be in dict2\n  for key in dict1:\n    # Check everything except children;  Check for children recursively\n    for propertytype in dict1[key]:\n      if (not propertytype in dict2[key] or\n          dict1[key][propertytype] != dict2[key][propertytype]):\n        return False\n      \n    # Check children\n    if not are_cmddicts_same(dict1[key]['children'], dict2[key]['children']):\n      return False\n      \n  return True", "response": "Checks to see if two cmddicts are the same."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef merge_commanddict_recursive(originaldict, mergedict):\n  \n  \"\"\"\n  Every command in the mergedict should be placed into the original.  \n  We do not handle the case where a shared node is defined on both sides.\n  That check is done by ensure_no_conflicts_in_commanddict().\n  We make a deep copy of mergedict to make the deletion case easier.\n  \"\"\"\n  for commandnode in mergedict:\n    # Trivial case\n    if commandnode not in originaldict:\n      originaldict[commandnode] = deepcopy(mergedict[commandnode])\n    \n    else:\n      # Shared node exists in original but is not defined\n      # Replace properties if they exist, and then merge over the children.\n      if not is_commanddictnode_defined(originaldict[commandnode]):\n        for entry in mergedict[commandnode]:\n          if not entry in ['children', 'module']:\n            originaldict[commandnode][entry] = mergedict[commandnode][entry]\n      \n      merge_commanddict_recursive(originaldict[commandnode]['children'], mergedict[commandnode]['children'])", "response": "Recursively merges the commanddict into the originaldict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_commanddict(originaldict, removedict):\n  \n  for child in removedict:\n    if child in originaldict:\n      # Recursively remove all children specified\n      remove_commanddict(originaldict[child]['children'], removedict[child]['children'])\n      # Remove the definition as well if it is defined in removedict\n      if is_commanddictnode_defined(removedict[child]):\n        # Remove everything except for children.  We remove those recursively.\n        for propertytype in removedict[child]:\n          # Not all properties (i.e. module) will be defined in the original \n          # dictionary.  We may raise an exception when trying to delete one\n          # such property.\n          if (propertytype != 'children' and\n              propertytype in originaldict[child]):\n            del originaldict[child][propertytype]\n      # Remove this node if this node is no longer defined, and if there are no \n      # remaining child nodes.\n      if not (is_commanddictnode_defined(originaldict[child]) or originaldict[child]['children']):\n        del originaldict[child]", "response": "Removes all commands found in a commanddict from another command dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nenable a module and imports its commands into the seash commanddict.", "response": "def enable(commanddict, modulename):\n  \"\"\"\n  <Purpose>\n    Enables a module and imports its commands into the seash commanddict.\n\n  <Arguments>\n    modulename: The module to import.\n\n  <Side Effects>\n    All commands inside the specified module will be inserted into the seash\n    commanddict if possible.\n\n    The file modulename.disabled will be removed from /modules/ indicating that\n    this module has been enabled.\n\n  <Exceptions>\n    Exceptions raised by merge_commanddict()\n\n  <Returns>\n    None\n  \"\"\"\n  # Is this an installed module?\n  if not modulename in module_data:\n    raise seash_exceptions.UserError(\"Error, module '\"+modulename+\"' is not installed\")\n\n  if _is_module_enabled(modulename):\n    raise seash_exceptions.UserError(\"Module is already enabled.\")\n\n  merge_commanddict(commanddict, module_data[modulename]['command_dict'])\n\n  try:\n    # We mark this module as enabled by deleting the modulename.disabled file\n    os.remove(MODULES_FOLDER_PATH + os.sep + modulename + \".disabled\") \n  except OSError, e:\n    # If the file was deleted before we were able to delete it, it should not\n    # be a problem.\n    if not \"cannot find the file\" in str(e):\n      raise\n  \n  try:\n    initialize(modulename)\n  except seash_exceptions.InitializeError, e:\n    raise seash_exceptions.InitializeError(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndisables a module and removes its commands from the seash commanddict.", "response": "def disable(commanddict, modulename):\n  \"\"\"\n  <Purpose>\n    Disables a module and removes its commands from the seash commanddict.\n\n  <Arguments>\n    modulename: The module to disable.\n\n  <Side Effects>\n    All commands inside the specified module will be removed from the seash\n    commanddict.\n\n    A file (modulename.disabled) will be created under /modules/ indicating that\n    this module has been disabled.\n\n  <Exceptions>\n    Exceptions raised by merge_commanddict()\n\n  <Returns>\n    None\n  \"\"\"\n  # Is this an installed module?\n  if not modulename in module_data:\n    raise seash_exceptions.UserError(\"Error, module '\"+modulename+\"' is not installed\")\n  \n  # Is this module enabled?\n  if not _is_module_enabled(modulename):\n    raise seash_exceptions.UserError(\"Module is not enabled.\")\n\n  remove_commanddict(commanddict, module_data[modulename]['command_dict'])\n  cleanup(modulename)\n\n  # We mark this module as disabled by adding a modulename.disabled file.\n  open(MODULES_FOLDER_PATH + os.sep + modulename + \".disabled\", 'w')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of all enabled modules.", "response": "def get_enabled_modules():\n  \"\"\"\n  <Purpose>\n    Returns all enabled modules.\n  <Arguments>\n    None\n  <Side Effects>\n    None\n  <Exceptions>\n    None\n  <Return>\n    The list of all enabled modules.\n  \"\"\"\n  enabled = []\n  directory_contents = os.listdir(MODULES_FOLDER_PATH)\n  for fname in get_installed_modules():\n    if not fname+'.disabled' in directory_contents:\n      enabled.append(fname)\n  return enabled"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef enable_modules_from_last_session(seashcommanddict):\n  successfully_enabled_modules = []\n  modules_to_enable = get_enabled_modules()\n  for modulename in modules_to_enable:\n    # There are no bad side effects to seash's state when we do this\n    # The only thing that should happen is that the modulename.disabled file\n    # gets created (temporarily)\n    disable(seashcommanddict, modulename)\n    try:\n      enable(seashcommanddict, modulename)\n      successfully_enabled_modules.append(modulename)\n    except seash_exceptions.ModuleConflictError, e:\n      print \"Failed to enable the '\"+modulename+\"' module due to the following conflicting command:\"\n      print str(e)\n\n      # We mark this module as disabled by adding a modulename.disabled file.\n      open(MODULES_FOLDER_PATH + os.sep + modulename + \".disabled\", 'w')\n    except seash_exceptions.InitializeError, e:\n      print \"Failed to enable the '\"+modulename+\"' module.\"\n      disable(seashcommanddict, modulename)\n  successfully_enabled_modules.sort()\n  \n  print 'Enabled modules:', ', '.join(successfully_enabled_modules), '\\n'", "response": "Enable all modules that are not in the modules folder."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of valid tab - complete strings from all enabled modules.", "response": "def tab_complete(input_list):\n  \"\"\"\n  <Purpose>\n    Gets the list of all valid tab-complete strings from all enabled modules.\n  <Arguments>\n    input_list: The list of words the user entered.\n  <Side Effects>\n    None\n  <Exceptions>\n    None\n  <Returns>\n    A list of valid tab-complete strings\n  \"\"\"\n  commands = []\n  for module in get_enabled_modules():\n    if 'tab_completer' in module_data[module]:\n      commands += module_data[module]['tab_completer'](input_list)\n  return commands"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef preprocess_input(userinput):\n  for module in get_enabled_modules():\n    # Not every module has a preprocessor...\n    if 'input_preprocessor' in module_data[module]:\n      userinput = module_data[module]['input_preprocessor'](userinput)\n  return userinput", "response": "Preprocesses the input string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _attach_module_identifier(command_dict, modulefn):\n  for command in command_dict:\n    command_dict[command]['module'] = modulefn\n    _attach_module_identifier(command_dict[command]['children'], modulefn)", "response": "Attaches a module to each node in the command dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if the module folder exists. If it does not create it.", "response": "def _ensure_module_folder_exists():\n  \"\"\" \n  Checks to see if the module folder exists. If it does not, create it.\n  If there is an existing file with the same name, we raise a RuntimeError.\n  \"\"\"\n  if not os.path.isdir(MODULES_FOLDER_PATH):\n    try:\n      os.mkdir(MODULES_FOLDER_PATH)\n    except OSError, e:\n      if \"file already exists\" in str(e):\n        raise RuntimeError(\"Could not create modules folder: file exists with the same name\")"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_vm(self, name):\n        try:\n            domain = self.hyper.lookupByName(name)\n            VM = VirtualMachine(domain, self)\n        except libvirtError:\n            VM = None\n        return VM", "response": "Try and find a VM by name"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a fast clone of a VM.", "response": "def fast_clone(self, VM, clone_name, mem=None):\n        \"\"\"\n        Create a 'fast' clone of a VM. This means we make\n        a snapshot of the disk and copy some of the settings\n        and then create a new VM based on the snapshot and settings\n        The VM is transient so when it is shutdown it deletes itself\n        :param VM: The VM to base this clone on\n        :type VM: sham.machine.VirtualMachine\n\n        :param clone_name: The name for this clone\n        :type clone_name: str\n        \"\"\"\n        disks = VM.get_disks()\n        ints = VM.get_interfaces()\n        count = 0\n        new_disks = []\n        for disk in disks:\n            pool = disk.pool\n            new_disk_name = '{0}-disk{1}'.format(clone_name, count)\n            count += 1\n            new_disk = pool.create_backed_vol(new_disk_name, disk)\n            new_disks.append(new_disk)\n\n        for inter in ints:\n            inter.mac = None\n            # if the mac is set to None we don't include it in the xml\n            # and libvirt will autogen one for us\n        return self.create_vm(\n            VM.domain_type,\n            clone_name,\n            VM.num_cpus,\n            mem or VM.current_memory,\n            mem or VM.max_memory,\n            new_disks,\n            ints)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_configuration_from_settings(self, setting_info):\n        settings = self.get_settings()\n        return dict([(name, settings.get(key))\n                     for (name, key) in setting_info\n                     if not settings.get(key, None) is None])", "response": "Returns a dictionary with configuration names as keys and setting names as values extracted from this configurator s settings as values."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_repository(self, name, repository_type, repository_class,\n                       aggregate_class, make_default, configuration):\n        \"\"\"\n        Generic method for adding a repository.\n        \"\"\"\n        repo_mgr = self.get_registered_utility(IRepositoryManager)\n        if name is None:\n            # If no name was given, this is assumed to be the ROOT repository\n            # for the given repository type.\n            name = REPOSITORY_DOMAINS.ROOT\n        repo = repo_mgr.new(repository_type, name=name,\n                            make_default=make_default,\n                            repository_class=repository_class,\n                            aggregate_class=aggregate_class,\n                            configuration=configuration)\n        repo_mgr.set(repo)", "response": "Add a repository to the registry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt_email(email):\n    aes = SimpleAES(flask.current_app.config[\"AES_KEY\"])\n    return aes.encrypt(email)", "response": "This is the default encryption function for storing emails in the database."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt_email(enc_email):\n    aes = SimpleAES(flask.current_app.config[\"AES_KEY\"])\n    return aes.decrypt(enc_email)", "response": "Decrypt an email address."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shortlink_scanned(self, data):\n        # Inform log that we received an event\n        self.logger.info(\"Received shortlink_scanned event\")\n\n        data = json.loads(data)\n        customer_token = str(data['object']['id'])\n        response = self.mapiclient.create_payment_request(\n            customer=customer_token,\n            currency=\"NOK\",\n            amount=\"20.00\",\n            allow_credit=True,\n            pos_id=self._pos_id,\n            pos_tid=str(uuid.uuid4()),\n            action='auth',\n            expires_in=90,\n            callback_uri=\"pusher:m-winterwarming-pos_callback_chan\",\n            text='Have some hot chocolate!')\n        self._tid = response['id']\n        print(str(self._tid))", "response": "Called when a shortlink_scanned event is received."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef pusher_connected(self, data):\n        # Inform user that pusher is done connecting\n        self.logger.info(\"Pusherclient connected\")\n\n        # Bind the events we want to listen to\n        self.callback_client.bind(\"payment_authorized\",\n                                  self.payment_authorized)\n        self.callback_client.bind(\"shortlink_scanned\",\n                                  self.shortlink_scanned)", "response": "Called when the pusher client is connected"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the object for the given pk and returns it if it exists.", "response": "def get(self, *args, **kwargs):\n        \"\"\"\n        Checks the cache to see if there's a cached entry for this pk. If not, fetches \n        using super then stores the result in cache.\n \n        Most of the logic here was gathered from a careful reading of \n        ``django.db.models.sql.query.add_filter``\n        \"\"\"\n        if self.query.where:\n            # If there is any other ``where`` filter on this QuerySet just call\n            # super. There will be a where clause if this QuerySet has already\n            # been filtered/cloned.\n            return super(CachingQuerySet, self).get(*args, **kwargs)\n \n        # Punt on anything more complicated than get by pk/id only...\n        if len(kwargs) == 1:\n            k = kwargs.keys()[0]\n            if k in ('pk', 'pk__exact', '%s' % self.model._meta.pk.attname, \n                     '%s__exact' % self.model._meta.pk.attname):\n                obj = cache.get(self.model._cache_key(pk=kwargs.values()[0]))\n                if obj is not None:\n                    obj.from_cache = True\n                    return obj\n \n        # Calls self.iterator to fetch objects, storing object in cache.\n        return super(CachingQuerySet, self).get(*args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add(self, uri, methods, handler, host=None):\n        if host is not None:\n            if isinstance(host, str):\n                uri = host + uri\n                self.hosts.add(host)\n\n            else:\n                if not isinstance(host, Iterable):\n                    raise ValueError(\"Expected either string or Iterable of \"\n                                     \"host strings, not {!r}\".format(host))\n\n                for host_ in host:\n                    self.add(uri, methods, handler, host_)\n                return\n\n        # Dict for faster lookups of if method allowed\n        if methods:\n            methods = frozenset(methods)\n\n        parameters = []\n        properties = {\"unhashable\": None}\n\n        def add_parameter(match):\n            name = match.group(1)\n            name, _type, pattern = self.parse_parameter_string(name)\n\n            parameter = Parameter(\n                name=name, cast=_type)\n            parameters.append(parameter)\n\n            # Mark the whole route as unhashable if it has the hash key in it\n            if re.search(r'(^|[^^]){1}/', pattern):\n                properties['unhashable'] = True\n            # Mark the route as unhashable if it matches the hash key\n            elif re.search(r'/', pattern):\n                properties['unhashable'] = True\n\n            return '({})'.format(pattern)\n\n        pattern_string = re.sub(self.parameter_pattern, add_parameter, uri)\n        pattern = re.compile(r'^{}$'.format(pattern_string))\n\n        def merge_route(route, methods, handler):\n            # merge to the existing route when possible.\n            if not route.methods or not methods:\n                # method-unspecified routes are not mergeable.\n                raise RouteExists(\n                    \"Route already registered: {}\".format(uri))\n            elif route.methods.intersection(methods):\n                # already existing method is not overloadable.\n                duplicated = methods.intersection(route.methods)\n                raise RouteExists(\n                    \"Route already registered: {} [{}]\".format(\n                        uri, ','.join(list(duplicated))))\n            if isinstance(route.handler, self._composition_view_class):\n                view = route.handler\n            else:\n                view = self._composition_view_class()\n                view.add(route.methods, route.handler)\n            view.add(methods, handler)\n            route = route._replace(\n                handler=view, methods=methods.union(route.methods))\n            return route\n\n        if parameters:\n            # TODO: This is too complex, we need to reduce the complexity\n            if properties['unhashable']:\n                routes_to_check = self.routes_always_check\n                ndx, route = self.check_dynamic_route_exists(\n                    pattern, routes_to_check)\n            else:\n                routes_to_check = self.routes_dynamic[url_hash(uri)]\n                ndx, route = self.check_dynamic_route_exists(\n                    pattern, routes_to_check)\n            if ndx != -1:\n                # Pop the ndx of the route, no dups of the same route\n                routes_to_check.pop(ndx)\n        else:\n            route = self.routes_all.get(uri)\n\n        if route:\n            route = merge_route(route, methods, handler)\n        else:\n            # prefix the handler name with the blueprint name\n            # if available\n            if hasattr(handler, '__blueprintname__'):\n                handler_name = '{}.{}'.format(\n                    handler.__blueprintname__, handler.__name__)\n            else:\n                handler_name = getattr(handler, '__name__', None)\n\n            route = Route(\n                handler=handler, methods=methods, pattern=pattern,\n                parameters=parameters, name=handler_name, uri=uri)\n\n        self.routes_all[uri] = route\n        if properties['unhashable']:\n            self.routes_always_check.append(route)\n        elif parameters:\n            self.routes_dynamic[url_hash(uri)].append(route)\n        else:\n            self.routes_static[uri] = route", "response": "Add a handler function to the route list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_route_by_view_name(self, view_name):\n        if not view_name:\n            return (None, None)\n\n        for uri, route in self.routes_all.items():\n            if route.name == view_name:\n                return uri, route\n\n        return (None, None)", "response": "Search the router based on the specified view name."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get(self, url, method, host):\n        url = host + url\n        # Check against known static routes\n        route = self.routes_static.get(url)\n        method_not_supported = self._invalid_usage(\n            'Method {} not allowed for URL {}'.format(\n                method, url), status_code=405)\n        if route:\n            if route.methods and method not in route.methods:\n                raise method_not_supported\n            match = route.pattern.match(url)\n        else:\n            route_found = False\n            # Move on to testing all regex routes\n            for route in self.routes_dynamic[url_hash(url)]:\n                match = route.pattern.match(url)\n                route_found |= match is not None\n                # Do early method checking\n                if match and method in route.methods:\n                    break\n            else:\n                # Lastly, check against all regex routes that cannot be hashed\n                for route in self.routes_always_check:\n                    match = route.pattern.match(url)\n                    route_found |= match is not None\n                    # Do early method checking\n                    if match and method in route.methods:\n                        break\n                else:\n                    # Route was found but the methods didn't match\n                    if route_found:\n                        raise method_not_supported\n                    raise self._not_found(\n                        'Requested URL {} not found'.format(url))\n\n        kwargs = {p.name: p.cast(value)\n                  for value, p\n                  in zip(match.groups(1), route.parameters)}\n        route_handler = route.handler\n        if hasattr(route_handler, 'handlers'):\n            route_handler = route_handler.handlers[method]\n        return route_handler, [], kwargs, route.uri", "response": "Internal method for caching."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_stream_handler(self, request):\n        handler = self.get(request)[0]\n        if (hasattr(handler, 'view_class') and\n                hasattr(handler.view_class, request.method.lower())):\n            handler = getattr(handler.view_class, request.method.lower())\n        return hasattr(handler, 'is_stream')", "response": "Returns True if the request is a stream handler."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_vertex(self, v):\n        self.graph.add_vertex(v)\n        self.vs.add(v)", "response": "Add a vertex to the graph"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_outward_edge(self, v, e):\n        self.add_vertex(v)\n        self.graph.add_vertex(e)\n        self.es.add(e)\n        self.graph.add_edge(e, v)", "response": "Add an outward edge to a source vertex."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfetches contents from the path specified by name.", "response": "def fetch_path(self, name):\n        \"\"\"\n        Fetch contents from the path retrieved via lookup_path.\n\n        No caching will be done.\n        \"\"\"\n\n        with codecs.open(self.lookup_path(name), encoding='utf-8') as fd:\n            return fd.read()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef execute(self, mold_id, data, wrapper_tag='div'):\n\n        template = self.load_mold(mold_id)\n\n        kwargs = {}\n        kwargs.update(data)\n        kwargs['_nunja_data_'] = 'data-nunja=\"%s\"' % mold_id\n        kwargs['_template_'] = template\n        kwargs['_wrapper_tag_'] = wrapper_tag\n\n        return self._core_template_.render(**kwargs)", "response": "Execute a mold_id by rendering through env."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenders a mold `mold_id`. No wrappers are applied as only the default template defined for the mold is rendered.", "response": "def render(self, mold_id, data):\n        \"\"\"\n        Render a mold `mold_id`.  No wrappers are applied as only the\n        default template defined for the mold is rendered.\n        \"\"\"\n\n        template = self.load_mold(mold_id)\n        return template.render(**data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a list that represents the table.", "response": "def _get_model_table(self, part):\n        \"\"\"\n        Returns a list that represents the table.\n\n        :param part: The table header, table footer or table body.\n        :type part: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :return: The list that represents the table.\n        :rtype: list(list(hatemile.util.html.htmldomelement.HTMLDOMElement))\n        \"\"\"\n\n        rows = self.parser.find(part).find_children('tr').list_results()\n        table = []\n        for row in rows:\n            table.append(self._get_model_row(self.parser.find(\n                row\n            ).find_children('td,th').list_results()))\n        return self._get_valid_model_table(table)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_valid_model_table(self, ros):\n        # pylint: disable=no-self-use\n\n        new_table = []\n        if bool(ros):\n            length_table = len(ros)\n            for row_index in range(0, length_table):\n                cells_added = 0\n                original_row = [] + ros[row_index]\n                if len(new_table) <= row_index:\n                    new_table.append([])\n                length_row = len(original_row)\n                for cell_index in range(0, length_row):\n                    cell = original_row[cell_index]\n                    new_cell_index = cell_index + cells_added\n                    new_row = new_table[row_index]\n                    while True:\n                        if len(new_row) <= new_cell_index:\n                            new_row.append(None)\n                            break\n                        elif new_row[new_cell_index] is None:\n                            break\n                        else:\n                            cells_added += 1\n                            new_cell_index = cell_index + cells_added\n                    new_row[new_cell_index] = cell\n                    if cell.has_attribute('rowspan'):\n                        rowspan = int(cell.get_attribute('rowspan'))\n                        if rowspan > 1:\n                            for rowspan_index in range(1, rowspan):\n                                new_row_index = row_index + rowspan_index\n                                if len(new_table) <= new_row_index:\n                                    new_table.append([])\n                                while (\n                                    len(new_table[new_row_index])\n                                    < new_cell_index\n                                ):\n                                    new_table[new_row_index].append(None)\n                                new_table[new_row_index].append(cell)\n        return new_table", "response": "Returns a list of valid model tables."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list that represents the line of table with the colspans.", "response": "def _get_model_row(self, row):\n        \"\"\"\n        Returns a list that represents the line of table with the colspans.\n\n        :param row: The list that represents the line of table without the\n                    colspans.\n        :type row: list(hatemile.util.html.htmldomelement.HTMLDOMElement)\n        :return: The list that represents the line of table with the colspans.\n        :rtype: list(hatemile.util.html.htmldomelement.HTMLDOMElement)\n        \"\"\"\n        # pylint: disable=no-self-use\n\n        new_row = [] + row\n        size = len(row)\n        for i in range(0, size):\n            cell = row[i]\n            if cell.has_attribute('colspan'):\n                colspan = int(cell.get_attribute('colspan'))\n                if colspan > 1:\n                    for j in range(1, colspan):\n                        new_row.insert(i + j, cell)\n        return new_row"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nvalidates the list that represents the table header.", "response": "def _validate_header(self, hed):\n        \"\"\"\n        Validate the list that represents the table header.\n\n        :param hed: The list that represents the table header.\n        :type hed: list(list(hatemile.util.html.htmldomelement.HTMLDOMElement))\n        :return: True if the table header is valid or False if the table header\n                 is not valid.\n        :rtype: bool\n        \"\"\"\n        # pylint: disable=no-self-use\n\n        if not bool(hed):\n            return False\n        length = -1\n        for row in hed:\n            if not bool(row):\n                return False\n            elif length == -1:\n                length = len(row)\n            elif len(row) != length:\n                return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_cells_headers_ids(self, hed, index):\n        # pylint: disable=no-self-use\n\n        ids = []\n        for row in hed:\n            if row[index].get_tag_name() == 'TH':\n                ids.append(row[index].get_attribute('id'))\n        return ids", "response": "Returns a list with ids of rows of same column."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nassociating the data cell with header cell of row.", "response": "def _associate_data_cells_with_header_cells_of_row(self, element):\n        \"\"\"\n        Associate the data cell with header cell of row.\n\n        :param element: The table body or table footer.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        table = self._get_model_table(element)\n        for row in table:\n            headers_ids = []\n            for cell in row:\n                if cell.get_tag_name() == 'TH':\n                    self.id_generator.generate_id(cell)\n                    headers_ids.append(cell.get_attribute('id'))\n\n                    cell.set_attribute('scope', 'row')\n            if bool(headers_ids):\n                for cell in row:\n                    if cell.get_tag_name() == 'TD':\n                        headers = cell.get_attribute('headers')\n                        for header_id in headers_ids:\n                            headers = CommonFunctions.increase_in_list(\n                                headers,\n                                header_id\n                            )\n                        cell.set_attribute('headers', headers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the scope of header cells of table header.", "response": "def _prepare_header_cells(self, table_header):\n        \"\"\"\n        Set the scope of header cells of table header.\n\n        :param table_header: The table header.\n        :type table_header: hatemile.util.html.htmldomelement.HTMLDOMElement\n        \"\"\"\n\n        cells = self.parser.find(table_header).find_children(\n            'tr'\n        ).find_children('th').list_results()\n        for cell in cells:\n            self.id_generator.generate_id(cell)\n\n            cell.set_attribute('scope', 'col')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the kelvin to white.", "response": "def white(self, kelvin):\n    \"\"\"Supports between 2700K and 6500K white\n    :type kelvin int:\n    \"\"\"\n    whiteness = int(((kelvin - MIN_KELVIN) * 255)/(MAX_KELVIN-MIN_KELVIN))\n    whiteness = max(min(whiteness,255),0)\n    data = [CODE_COLOUR, self._id, 255 - whiteness, whiteness]\n    self._mode = MODE_WHITE\n    self._white = kelvin\n    self._effect = ''\n    self._send(data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encrypt(clear_text) -> str:\r\n        if not isinstance(clear_text, bytes):\r\n            clear_text = str.encode(clear_text)\r\n        cipher = Fernet(current_app.config['KEY'])\r\n        return cipher.encrypt(clear_text).decode(\"utf-8\")", "response": "Encrypt the given clear_text using the config. json key to generate a new key."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef decrypt(crypt_text) -> str:\r\n        cipher = Fernet(current_app.config['KEY'])\r\n        if not isinstance(crypt_text, bytes):\r\n            crypt_text = str.encode(crypt_text)\r\n        return cipher.decrypt(crypt_text).decode(\"utf-8\")", "response": "Use config. json key to decrypt"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the volume information for the given id or path.", "response": "def get_volume(self, id):\n        \"\"\"\n        return volume information if the argument is an id or a path\n        \"\"\"\n        # If the id is actually a path\n        if exists(id):\n            with open(id) as file:\n                size = os.lseek(file.fileno(), 0, os.SEEK_END)\n            return {'path': id, 'size': size}\n        return self.volume.get(id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef randomize(self, device=None, percent=100, silent=False):\n        volume = self.get_volume(device)\n        # The number of blocks in the volume\n        blocks = int(volume['size'] / BLOCK_SIZE)\n        # How many writes should be to the device\n        # (based on the percentage requested)\n        num_writes = int(blocks * percent * 0.01)\n        # Build a list of offsets we write to\n        offsets = sorted(random.sample(range(blocks), num_writes))\n        total = 0\n\n        if not silent:\n            print('Writing urandom to %s bytes in %s' % (volume['size'],\n                                                         volume['path']))\n\n        with open(volume['path'], 'w') as file:\n            for offset in offsets:\n                if not silent:\n                    self.dot()\n                file.seek(offset * BLOCK_SIZE)\n                # Create a random string 32k long then duplicate\n                # the randomized string 128 times (32768 * 128 = 4MB)\n                data = os.urandom(32768) * 128\n                total += len(data)\n                # write out the 4MB block of randomized data\n                file.write(data)\n        print(\"\\nWrote: %s\" % total)", "response": "Writes random data to the beginning of each 32k block on a device and then duplicate the data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nread the entries from the file system", "response": "def read(self, device=None, offset=0, bs=None, count=1):\n        \"\"\"\n        Using DIRECT_O read from the block device specified to stdout\n        (Without any optional arguments will read the first 4k from the device)\n        \"\"\"\n        volume = self.get_volume(device)\n        block_size = bs or BLOCK_SIZE\n\n        offset = int(offset) * block_size\n        count = int(count)\n        print(\"Offset: \", offset)\n\n        total = 0\n        with directio.open(volume['path'], buffered=block_size) as file:\n            file.seek(offset)\n            for i in range(0, count):\n                total += os.write(sys.stdout.fileno(), file.read(block_size))\n        os.write(sys.stdout.fileno(), \"\\nRead: %d Bytes\\n\" % total)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a character to a specified block in 4k chunks to a specified device.", "response": "def write(self, device=None, char=0, bs=None, count=None):\n        \"\"\"\n        Using DIRECT_O write a character in 4k chunks to a specified block\n        device (Without any optional arguments will write NULL's to the\n        entire device)\n        \"\"\"\n        volume = self.get_volume(device)\n        block_size = bs or BLOCK_SIZE\n\n        # Calculate the number of blocks that are in the volume\n        count = count or (volume['size'] / block_size)\n\n        data = \"\".join([chr(int(char)) for i in range(0, block_size)])\n\n        print(\"Writing: '%c'\" % data[0])\n        total = 0\n        with directio.open(volume['path'], buffered=block_size) as file:\n            for i in range(0, count):\n                self.dot()\n                total += file.write(data)\n        print(\"\\nWrote: \", total)\n        return 0"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef backup(self, id=None, src=None, timestamp=None):\n        # Set basic Logging\n        logging.basicConfig()\n        # Get the lunr logger\n        log = logger.get_logger()\n        # Output Debug level info\n        log.logger.setLevel(logging.DEBUG)\n        # Load the local storage configuration\n        conf = LunrConfig.from_storage_conf()\n        # If no time provided, use current time\n        timestamp = timestamp or time()\n        # Init our helpers\n        volume = VolumeHelper(conf)\n        backup = BackupHelper(conf)\n\n        try:\n            # Create the snapshot\n            snapshot = volume.create_snapshot(src, id, timestamp)\n\n            # For testing non-snapshot speeds\n            # snapshot = volume.get(src)\n            # snapshot['backup_id'] = id\n            # snapshot['origin'] = src\n            # snapshot['timestamp'] = 1338410885.0\n            # del snapshot['volume']\n\n            print(\"Created snap-shot: \", pprint(snapshot))\n\n            with self.timeit(snapshot['size']):\n                # Backup the snapshot\n                print(\"Starting Backup\")\n                backup.save(snapshot, id)\n\n        finally:\n            # Delete the snapshot if it was created\n            if 'snapshot' in locals():\n                self._remove_volume(snapshot['path'])", "response": "This runs a backup job outside of the storage api. This runs a backup job outside of the storage api."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clone(self, id=None, src=None, backup=None, size=None):\n        # Set basic Logging\n        logging.basicConfig()\n        # Get the lunr logger\n        log = logger.get_logger()\n        # Output Debug level info\n        log.logger.setLevel(logging.DEBUG)\n        # Load the local storage configuration\n        conf = LunrConfig.from_storage_conf()\n        # Init the volume helper\n        volume = VolumeHelper(conf)\n\n        # Attempt to figure out the original volume size\n        size = size or str(volume.get(src)['size'] / 1073741824)\n        # Size is in gigs\n        if not re.match('G', size):\n            size = size + 'G'\n        # Create a tag to apply to the lvm volume\n        tag = encode_tag(source_volume_id=src, backup_id=backup)\n        # Create the volume\n        execute('lvcreate', volume.volume_group,\n                name=id, size=size, addtag=tag)\n        # Get info for the newly created volume\n        new = volume.get(id)\n\n        with self.timeit():\n            print(\"Starting Backup\")\n            # Restore volume from the backup\n            volume.clone(new, src, backup)", "response": "This runs a clone job that creates a new volume and restores it"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the IP address inside the HTTP_X_FORWARDED_FOR var inside the request object.", "response": "def get_ip(request):\n    \"\"\"Return the IP address inside the HTTP_X_FORWARDED_FOR var inside\n    the `request` object.\n\n    The return of this function can be overrided by the\n    `LOCAL_GEOLOCATION_IP` variable in the `conf` module.\n\n    This function will skip local IPs (starting with 10. and equals to\n    127.0.0.1).\n    \"\"\"\n    if getsetting('LOCAL_GEOLOCATION_IP'):\n        return getsetting('LOCAL_GEOLOCATION_IP')\n\n    forwarded_for = request.META.get('HTTP_X_FORWARDED_FOR')\n\n    if not forwarded_for:\n        return UNKNOWN_IP\n\n    for ip in forwarded_for.split(','):\n        ip = ip.strip()\n        if not ip.startswith('10.') and not ip == '127.0.0.1':\n            return ip\n\n    return UNKNOWN_IP"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_connection(self):\n\n        if self.conn:\n            return self.conn\n\n        redis_configs = getsetting('REDIS_CONNECTIONS')\n        if redis_configs:\n            config_name = getsetting('EVENTLIB_REDIS_CONFIG_NAME', 'default')\n            config = redis_configs[config_name]\n            host = config['HOST']\n            port = config['PORT']\n            self.conn = redis.StrictRedis(host=host, port=port)\n        else:\n            self.conn = None\n        return self.conn", "response": "Return a valid redis connection based on the settings in the EVENTLIB_REDIS_CONNECTIONS and EVENTLIB_REDIS_CONFIG_NAME settings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _run_setup_py(self, args, echo=True, echo2=True, ff=''):\n        python = self.python\n\n        if ff:\n            setup_py = '-c\"%s\"' % (RUN_SETUP % locals())\n        else:\n            setup_py = 'setup.py %s' % ' '.join(args)\n\n        rc, lines = self.process.popen(\n            '\"%(python)s\" %(setup_py)s' % locals(), echo=echo, echo2=echo2)\n\n        return rc, lines", "response": "Run setup. py with monkey - patched setuptools."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndefaults factory for creating a WSGI application using the everest configurator and root factory.", "response": "def app_factory(global_settings, **local_settings): # pylint: disable=W0613\n    \"\"\"\n    Default factory for creating a WSGI application using the everest\n    configurator and root factory.\n\n    :param dict global_settings: Global settings extracted from an ini file.\n        Not used in this default app factory.\n    :param dict local_settings: App settings extracted from an ini file.\n    \"\"\"\n    config = Configurator()\n    config.setup_registry(settings=local_settings,\n                          root_factory=RootFactory())\n    if 'configure_zcml' in local_settings:\n        config.load_zcml(local_settings['configure_zcml'])\n    app = config.make_wsgi_app()\n    # In the absence of an application name in the settings, we have to\n    # extract the main app's name from the ini file, which unfortunately\n    # means parsing it again.\n    app_name = app_name_from_ini_file(global_settings['__file__'])\n    ep_group = \"%s.plugins\" % app_name\n    plugin_mgr = config.get_registered_utility(IPluginManager)\n    plugin_mgr.load_all(ep_group)\n    return app"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef factory(attr_type, data):\n\n        constructors = {\n            MFT_ATTR_STANDARD_INFORMATION: MftAttrStandardInformation,\n            MFT_ATTR_ATTRIBUTE_LIST: MftAttrAttributeList,\n            MFT_ATTR_FILENAME: MftAttrFilename,\n            MFT_ATTR_OBJECT_ID: MftAttrObjectId,\n            MFT_ATTR_SECURITY_DESCRIPTOR: MftAttrSecurityDescriptor,\n            MFT_ATTR_VOLUME_NAME: MftAttrVolumeName,\n            MFT_ATTR_VOLUME_INFO: MftAttrVolumeInfo,\n            MFT_ATTR_DATA: MftAttrData,\n            MFT_ATTR_INDEX_ROOT: MftAttrIndexRoot,\n            MFT_ATTR_INDEX_ALLOCATION: MftAttrIndexAllocation,\n            MFT_ATTR_BITMAP: MftAttrBitmap,\n            MFT_ATTR_REPARSE_POINT: MftAttrReparsePoint,\n            MFT_ATTR_LOGGED_TOOLSTREAM: MftAttrLoggedToolstream,\n        }\n\n        if attr_type not in constructors:\n            return None\n\n        return constructors[attr_type](data)", "response": "Returns an initialized attribute object based on attr_type and data."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def fetch_page(session, host):\n    await asyncio.sleep(random.randint(0, 25) * 0.1)\n    start = time.time()\n    logger.info('Fetch from {}'.format(host))\n\n    try:\n        response = await session.get(host, allow_redirects=False)\n    except aiohttp.ClientResponseError as err:\n        # likely a 404 implying HTTP but no page\n        # likely a 401 implying HTTP but no access\n        # FIXME: for instance, a gateway\n        # headers are available via err.headers()\n        # https://multidict.readthedocs.io/en/stable/multidict.html#multidict.CIMultiDict\n        results_tuple = (host, 'no page', err)\n    except aiohttp.ClientConnectorError as err:\n        # likely device at IP but no HTTP server\n        results_tuple = (host, 'no http', err)\n    except aiohttp.ServerConnectionError as err:\n        # likely ServerTimeoutError implying no device at IP\n        results_tuple = (host, 'no dev', err)\n    except aiohttp.InvalidURL as err:\n        # likely a malformed URL\n        results_tuple = (host, 'no URL', err)\n    # except Exception as err:\n    #     # Generic trap for debug\n    #     results_tuple = (host, 'unknown', err)\n    else:\n        try:\n            text_response = await response.text()\n        except aiohttp.ClientPayloadError as err:\n            # trouble reading page TODO: anyway to recover?\n            results_tuple = (host, 'no read', err)\n        else:\n            results_tuple = (host, 'found', text_response)\n        response.close()\n\n    logger.info('Recvd from {} after {:.2f}s'.format(host, time.time() - start))\n    return results_tuple", "response": "Perform the page fetch from an individual host."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def asynchronous(urls=None, re_filter=None):\n    class _URLBase(str):\n        \"\"\" Convenient access to hostname (ip) portion of the URL \"\"\"\n        @property\n        def hostname(self):\n            return urlsplit(self).hostname\n\n    http_devices = {}\n    qualified_devices = []\n    connection = aiohttp.TCPConnector(limit=0)\n    async with aiohttp.ClientSession(connector=connection, \n        conn_timeout=5, raise_for_status=True) as session:\n        \n        futures = [fetch_page(session, url) for url in urls]\n\n        for future in asyncio.as_completed(futures):\n            response = await future\n            if 'found' in response[1]:\n                http_devices[response[0]] = response[2]\n                logger.debug('Processed %s', response[0])\n                if re_filter.search(response[2]):\n                    qualified_devices.append(_URLBase(response[0]))\n\n    # print('The following responded to HTTP:')\n    # for x in http_devices.keys():\n    #     print(x)\n\n    return qualified_devices", "response": "Asynchronous request manager for session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngenerating a tuple of URLs with path one for each host on network", "response": "def url_generator(network=None, path=''):\n    \"\"\" Return a tuple of URLs with path, one for each host on network\n\n    `network` - IP address and subnet mask compatible with \n    [ipaddress library](https://docs.python.org/3/library/ipaddress.html#ipaddress.ip_network)  \n    `path` - Path portion of a URL as defined by \n    [url(un)split](https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlsplit)  \n    \"\"\"\n    network_object = ipaddress.ip_network(network)\n    if network_object.num_addresses > 256:\n        # will need to batch process this case otherwise we run out of selectors\n        logger.error('Scan limited to 256 addresses, requested %d.', network_object.num_addresses)\n        raise NotImplementedError\n    elif network_object.num_addresses > 1:\n        # async request upto 256 hosts\n        network_hosts = network_object.hosts()\n    else:\n        # assume user intent was a single IP address\n        network_hosts = [network_object.network_address]\n    return (urlunsplit(('http',str(ip),path,'','')) for ip in network_hosts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches network for hosts with a response to path that matches pattern", "response": "def survey(network=None, path='', pattern='', log=False):\n    \"\"\" Search network for hosts with a response to path that matches pattern\n\n    `network` - IP address and subnet mask compatible with \n    [ipaddress library](https://docs.python.org/3/library/ipaddress.html#ipaddress.ip_network)  \n    `path` - Path portion of a URL as defined by \n    [url(un)split](https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlsplit)  \n    `pattern` - A regular expression pattern compatible with\n    [re.compile](https://docs.python.org/3/library/re.html#re.compile)  \n    `log` -  boolean to control logging level\n    \"\"\"\n    if log:\n        logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.CRITICAL)\n\n    network_scan = asyncio.ensure_future(asynchronous(\n        urls=url_generator(network=network, path=path),\n        re_filter=re.compile(pattern))\n        )\n    ioloop = asyncio.get_event_loop()\n    ioloop.run_until_complete(network_scan)\n    # Zero-sleep to allow underlying connections to close\n    # http://aiohttp.readthedocs.io/en/stable/client_advanced.html#graceful-shutdown\n    ioloop.run_until_complete(asyncio.sleep(0))\n    # ioloop.close()  # don't close the loop, so it's available for re-use \n    # https://stackoverflow.com/questions/45010178/how-to-use-asyncio-event-loop-in-library-function\n    return sorted(network_scan.result(), key=lambda x: ipaddress.ip_address(x.hostname))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cli():\n    ch = logging.StreamHandler()\n    ch.setFormatter(logging.Formatter(\n        '%(asctime)s.%(msecs)03d %(levelname)s: %(message)s',\n        datefmt=\"%Y-%m-%d %H:%M:%S\"\n    ))\n    logger.addHandler(ch)\n\n    import argparse\n    parser = argparse.ArgumentParser(description=\"Search 'network' for hosts with a \\\n    response to 'path' that matches 'filter'\")\n    parser.add_argument('network', help='IP address with optional mask, e.g. 192.168.0.0/24')\n    parser.add_argument('-p', '--path', help='URL path at host, e.g. index.html',\n        default='')\n    parser.add_argument('-f', '--filter', help='Regular expression pattern for filter',\n        dest='pattern', default='')\n    parser.add_argument('-l', '--log', help='Enable logging', action='store_true')\n    args = parser.parse_args()\n    print('Scanning, please wait ...')\n    result = survey(**vars(args))\n    print('Found {} match{}{}{} on {}'.format(len(result), 'es' if len(result)!=1 else '',\n        ' for ' if args.pattern else '', args.pattern, args.network))\n    for x in result:\n        print(x.hostname)", "response": "Command line interface for the\n    search command"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hidden_cursor():\n    if sys.stdout.isatty():\n        _LOGGER.debug('Hiding cursor.')\n        print('\\x1B[?25l', end='')\n        sys.stdout.flush()\n    try:\n        yield\n    finally:\n        if sys.stdout.isatty():\n            _LOGGER.debug('Showing cursor.')\n            print('\\n\\x1B[?25h', end='')\n            sys.stdout.flush()", "response": "Temporarily hide the terminal cursor."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef display_status():\n    def print_status(msg, color):\n        \"\"\"Print the status message.\n\n        Args:\n            msg: The message to display (e.g. OK or FAILED).\n            color: The ANSI color code to use in displaying the message.\n        \"\"\"\n        print('\\r' if sys.stdout.isatty() else '\\t', end='')\n        print('{}{}[{color}{msg}{}]{}'.format(\n            Cursor.FORWARD(_ncols() - 8),\n            Style.BRIGHT,\n            Fore.RESET,\n            Style.RESET_ALL,\n            color=color,\n            msg=msg[:6].upper().center(6)\n        ))\n        sys.stdout.flush()\n\n    try:\n        yield\n    except Status as e:\n        _LOGGER.debug(e)\n        print_status(e.msg, e.color)\n        if e.exc:\n            raise e.exc  # pylint: disable=raising-bad-type\n    except (KeyboardInterrupt, EOFError):\n        raise\n    except Exception:\n        print_status('FAILED', Fore.RED)\n        raise\n    else:\n        print_status('OK', Fore.GREEN)", "response": "Display an OK or FAILED message for the context block."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nrun a group of tasks with a header footer and success or failure messages.", "response": "def run_tasks(header, tasks):\n    \"\"\"Run a group of tasks with a header, footer and success/failure messages.\n\n    Args:\n        header: A message to print in the header bar before the tasks are run.\n        tasks: A list of tuples containing a task title, a task, and a weight.\n            If the tuple only contains two values, the weight is assumed to be\n            one.\n    \"\"\"\n    tasks = list(tasks)\n    with timed_display(header) as print_message:\n        with tqdm(tasks, position=1, desc='Progress', disable=None,\n                  bar_format='{desc}{percentage:3.0f}% |{bar}|',\n                  total=sum(t[2] if len(t) > 2 else 1 for t in tasks),\n                  dynamic_ncols=True) as pbar:\n            for task in tasks:\n                print_message(task[0])\n                with display_status():\n                    try:\n                        task[1]()\n                    finally:\n                        pbar.update(task[2] if len(task) > 2 else 1)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _pusher_connect_handler(self, data):\n        self.channel = self.pusher.subscribe(self.pos_callback_chan)\n        for listener in self.pusher_connected_listeners:\n            listener(data)", "response": "Binds the channel to the pusher_connected_listeners"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _runForever(self, stop_event):\n        while(not stop_event.is_set()):\n            state = self.pusher.connection.state\n\n            if (state is not \"connecting\" and\n                    state is not \"connected\"):\n                self.logger.warning(\n                    \"Pusher seems to be disconnected, trying to reconnect\")\n                self.pusher.connect()\n\n            stop_event.wait(0.5)", "response": "Runs the main loop for the current node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop(self):\n        self.pusherthread_stop.set()\n        self.pusher.disconnect()\n\n        # wait until pusher is down\n        while self.pusher.connection.state is \"connected\":\n            sleep(0.1)\n        logging.info(\"shutting down pusher connector thread\")", "response": "Stops the pusherclient cleanly\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads GPT partition table.", "response": "def load(self, filename, bs=512):\n        \"\"\"Loads GPT partition table.\n\n        Args:\n            filename (str): path to file or device to open for reading\n            bs (uint): Block size of the volume, default: 512\n\n        Raises:\n            IOError: If file does not exist or not readable\n        \"\"\"\n        with open(filename, 'rb') as f:\n            f.seek(GPT_HEADER_OFFSET + 0x0C)\n            header_size = struct.unpack(\"<I\", f.read(4))[0]\n            f.seek(GPT_HEADER_OFFSET)\n\n            header_data = f.read(header_size)\n            self.header = GPT_HEADER(header_data)\n\n            if (self.header.signature != GPT_SIGNATURE):\n                raise Exception(\"Invalid GPT signature\")\n\n            self.__load_partition_entries(f, bs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __load_partition_entries(self, fd, bs):\n\n        fd.seek(self.header.part_lba * bs)\n        for p in range(0, self.header.num_partitions):\n            data = fd.read(self.header.part_size)\n            entry = GptPartitionEntry(data)\n            if entry.type_guid != uuid.UUID(\n                '{00000000-0000-0000-0000-000000000000}'\n            ):\n                self.__partition_entries.append(entry)\n            else:\n                # stop loading on empty partition entry\n                break", "response": "Loads the list of GptPartition entries from the file descriptor fd."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a slice object for mapping local index to global index", "response": "def slice_local_to_global(self, index_slice, axis=0):\n        \"\"\" Calculate start and stop index for mapping sliced index\n\n        :param index_slice: sliced index?\n        :param axis: current axis to calculate\n        :return: slice object as calculated\n        \"\"\"\n\n        local_start = self.int_local_to_global_start(index_slice.start, axis)\n        local_stop = self.int_local_to_global_stop(index_slice.stop, axis)\n\n        return slice(local_start,local_stop,index_slice.step)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef local_to_global(self, index):\n\n        if (type(index) is int) or (type(index) is slice):\n            if len(self.__mask) > 1:\n                raise IndexError('check length of parameter index')\n            # 1D array\n            if type(index) is int:\n                return self.int_local_to_global(index)\n\n            elif type(index) is slice:\n                return self.slice_local_to_global(index)\n\n            else:\n                raise IndexError('check data type of index to be integer or slice')\n\n        elif type(index) is tuple:\n\n            local_index = []\n\n            for k, item in enumerate(index):\n                if k < len(self.__mask):\n\n                    if type(item) is slice:\n                        temp_index = self.slice_local_to_global(item, k)\n\n                    elif type(item) in [int, np.int64, np.int32]:\n                        temp_index = self.int_local_to_global(item, k)\n\n                    if temp_index is None:\n                        return temp_index\n\n                else:\n                    temp_index = item\n\n                local_index.append(temp_index)\n\n            return tuple(local_index)\n        else:\n            raise IndexError('check index for correct length and type')", "response": "Calculate local index from global index."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a slice object for mapping global index to local index", "response": "def slice_global_to_local(self, index_slice, axis=0):\n        \"\"\" Calculate start and stop index for mapping sliced index\n\n        :param index_slice: sliced index?\n        :param axis: current axis to calculate\n        :return: slice object as calculated\n        \"\"\"\n        if index_slice.stop < self.__mask[axis].start+self.__halos[0][axis]:\n            return None\n\n        if index_slice.start > self.__mask[axis].stop-self.__halos[1][axis]:\n            return None\n\n        local_start = self.int_global_to_local_start(index_slice.start, axis)\n        local_stop = self.int_global_to_local_stop(index_slice.stop, axis)\n\n        return slice(local_start,local_stop,index_slice.step)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate local index from global index.", "response": "def global_to_local(self, index):\n        \"\"\" Calculate local index from global index\n\n        :param index: input index\n        :return: local index for data\n        \"\"\"\n        if (type(index) is int) or (type(index) is slice):\n            if len(self.__mask) > 1:\n                raise IndexError('check length of parameter index')\n            # 1D array\n            if type(index) is int:\n                return self.int_global_to_local(index)\n\n            elif type(index) is slice:\n                return self.slice_global_to_local(index)\n\n            else:\n                raise IndexError('check data type of index to be integer or slice')\n\n        elif type(index) is tuple:\n            #if len(index) is not len(self.__mask):\n            #    raise IndexError('check length of parameter index')\n\n            local_index = []\n\n            for k, item in enumerate(index):\n                if k < len(self.__mask):\n\n                    if type(item) is slice:\n                        temp_index = self.slice_global_to_local(item, k)\n\n                    elif type(item) in [int, np.int64, np.int32]:\n                        temp_index = self.int_global_to_local(item, k)\n\n                    if temp_index is None:\n                        return temp_index\n\n                else:\n                    temp_index = item\n\n                local_index.append(temp_index)\n\n            return tuple(local_index)\n        else:\n            raise IndexError('check index for correct length and type')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef int_global_to_local_start(self, index, axis=0):\n        if index >= self.__mask[axis].stop-self.__halos[1][axis]:\n            return None\n\n        if index < self.__mask[axis].start:\n            return 0\n\n        return index-self.__mask[axis].start", "response": "Calculate local index from global index from start_index\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating local index from global index from stop_index", "response": "def int_global_to_local_stop(self, index, axis=0):\n        \"\"\" Calculate local index from global index from stop_index\n\n        :param index: global index as integer\n        :param axis: current axis to process\n        :return:\n        \"\"\"\n        if index < self.__mask[axis].start+self.__halos[0][axis]:\n            return None\n\n        if index > self.__mask[axis].stop:\n            return self.__mask[axis].stop-self.__mask[axis].start\n\n        return index-self.__mask[axis].start"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncalculate local index from global index for integer input :param index: global index as integer :param axis: current axis to process :return:", "response": "def int_global_to_local(self, index, axis=0):\n        \"\"\" Calculate local index from global index for integer input\n\n        :param index: global index as integer\n        :param axis: current axis to process\n        :return:\n        \"\"\"\n\n        # Warum >= an dieser Stelle. Eigentlich sollte > ausreichend sein! Test!\n        if index >= self.__mask[axis].stop-self.__halos[1][axis]:\n            return None\n\n        if index < self.__mask[axis].start+self.__halos[0][axis]:\n            return None\n\n        return index-self.__mask[axis].start"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef int_out_of_bounds(self, index, axis=0):\n        #if index >= self._global_shape[axis]:\n        if index > self._global_shape[axis]:\n            raise IndexError('index is larger than the upper bound')\n\n        # wrap around index if negative like in python\n        if index < 0:\n            index += self._global_shape[axis]\n            #warnings.warn('warp around may occur')\n\n        # check for invalid wrap around\n        if index < 0:\n            raise IndexError('index is smaller than the lower bound')\n\n        return index", "response": "examples if index is out of local processing bounds\n        function is used to perform examples for index of type integer\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks index for out of bounds.", "response": "def out_of_bounds(self, index):\n        \"\"\" Check index for out of bounds\n\n        :param index: index as integer, tuple or slice\n        :return: local index as tuple\n        \"\"\"\n        if type(index) is int:\n            return self.int_out_of_bounds(index)\n\n        elif type(index) is slice:\n            return self.slice_out_of_bounds(index)\n\n        elif type(index) is tuple:\n\n            local_index = []\n\n            for k, item in enumerate(index):\n\n                if type(item) is slice:\n                    temp_index = self.slice_out_of_bounds(item, k)\n\n                elif type(item) is int:\n                    temp_index = self.int_out_of_bounds(item, k)\n                # FIXME: will fail if item is no int or slice!\n                if temp_index is None:\n                    return temp_index\n\n                local_index.append(temp_index)\n\n            return tuple(local_index)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef reservoir(iterator, k):\n    sample = list(itertools.islice(iterator, 0, k))\n    for i, item in enumerate(iterator):\n        replace = random.randint(0, i + k)\n        if replace < k:\n            sample[replace] = item\n    return sample", "response": "Performs reservoir sampling of k items from the iterator."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_server_setting(self, protocol, host='127.0.0.1', port=8000,\n                           debug=False, ssl=None, sock=None, workers=1,\n                           loop=None, backlog=100, has_log=True):\n        '''Helper function used by `run`.'''\n\n        if isinstance(ssl, dict):\n            # try common aliaseses\n            cert = ssl.get('cert') or ssl.get('certificate')\n            key = ssl.get('key') or ssl.get('keyfile')\n            if cert is None or key is None:\n                raise ValueError('SSLContext or certificate and key required.')\n            context = create_default_context(purpose=Purpose.CLIENT_AUTH)\n            context.load_cert_chain(cert, keyfile=key)\n            ssl = context\n\n        server_settings = {\n            'protocol': protocol,\n            'request_handler': self.request_handler,\n            'log': self.log,\n            'netlog': self.netlog,\n            'host': host,\n            'port': port,\n            'sock': sock,\n            'ssl': ssl,\n            'signal': self.signal,\n            'debug': debug,\n            'request_timeout': self.request_timeout,\n            'request_max_size': self.request_max_size,\n            'keep_alive': self.keep_alive,\n            'loop': loop,\n            'backlog': backlog,\n            'has_log': has_log\n        }\n        for event_name, settings_name, reverse in (\n                ('before_server_start', 'before_start', False),\n                ('after_server_start', 'after_start', False),\n                ('before_server_stop', 'before_stop', True),\n                ('after_server_stop', 'after_stop', True),\n        ):\n            listeners = self.listeners[event_name].copy()\n            if reverse:\n                listeners.reverse()\n            # Prepend mach9 to the arguments when listeners are triggered\n            listeners = [partial(listener, self.app) for listener in listeners]\n            server_settings[settings_name] = listeners\n\n        if debug:\n            self.log.setLevel(logging.DEBUG)\n\n        # Serve\n        if host and port:\n            proto = 'http'\n            if ssl is not None:\n                proto = 'https'\n            self.log.info('Goin\\' Fast @ {}://{}:{}'.format(proto, host, port))\n        return server_settings", "response": "Helper function used by run."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_qpimage(self, idx):\n        if self._bgdata:\n            # The user has explicitly chosen different background data\n            # using `get_qpimage_raw`.\n            qpi = super(SeriesHdf5Qpimage, self).get_qpimage(idx)\n        else:\n            # We can use the background data stored in the qpimage hdf5 file\n            with self._qpseries() as qps:\n                qpi = qps.get_qpimage(index=idx).copy()\n            # Force meta data\n            for key in self.meta_data:\n                qpi[key] = self.meta_data[key]\n            # set identifier\n            qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi", "response": "Return background - corrected QPImage of data at index idx"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a copy of the QPImage with background correction", "response": "def get_qpimage_raw(self, idx):\n        \"\"\"Return QPImage without background correction\"\"\"\n        with self._qpseries() as qps:\n            qpi = qps.get_qpimage(index=idx).copy()\n        # Remove previously performed background correction\n        qpi.set_bg_data(None)\n        # Force meta data\n        for key in self.meta_data:\n            qpi[key] = self.meta_data[key]\n        # set identifier\n        qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef verify(path):\n        valid = False\n        try:\n            h5 = h5py.File(path, mode=\"r\")\n            qpi0 = h5[\"qpi_0\"]\n        except (OSError, KeyError):\n            pass\n        else:\n            if (\"qpimage version\" in qpi0.attrs and\n                \"phase\" in qpi0 and\n                \"amplitude\" in qpi0 and\n                \"bg_data\" in qpi0[\"phase\"] and\n                    \"bg_data\" in qpi0[\"amplitude\"]):\n                valid = True\n        return valid", "response": "Verify that path has the qpimage series file format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a set of requirements for pip.", "response": "def generate_requirements(output_path=None):\n    \"\"\"\n    Loop through the INSTALLED_APPS and create a set of requirements for pip.\n    \n    if output_path is ``None`` then write to standard out, otherwise write\n    to the path.\n    \"\"\"\n    from django.conf import settings\n    reqs = set()\n    \n    for app in settings.INSTALLED_APPS:\n        if app in mapping.keys():\n            reqs |= set(mapping[app])\n    if output_path is None:\n        print \"--extra-index-url=http://opensource.washingtontimes.com/pypi/simple/\"\n        for item in reqs:\n            print item\n    else:\n        try:\n            out_file = open(output_path, 'w')\n            out_file.write(\"--extra-index-url=http://opensource.washingtontimes.com/pypi/simple/\\n\")\n            for item in reqs:\n                out_file.write(\"%s\\n\" % item)\n        finally:\n            out_file.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nuse in plugin s registration routine to associate it s detection method with given filesystem id", "response": "def register_mbr_plugin(self, fs_id, plugin):\n        \"\"\"Used in plugin's registration routine,\n        to associate it's detection method with given filesystem id\n\n        Args:\n            fs_id: filesystem id that is read from MBR partition entry\n            plugin: plugin that supports this filesystem\n        \"\"\"\n        self.logger.debug('MBR: {}, FS ID: {}'\n                          .format(self.__get_plugin_name(plugin), fs_id))\n        self.__mbr_plugins[fs_id].append(plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nusing in plugin s registration routine to associate it s detection method with given filesystem guid", "response": "def register_gpt_plugin(self, fs_guid, plugin):\n        \"\"\"Used in plugin's registration routine,\n        to associate it's detection method with given filesystem guid\n\n        Args:\n            fs_guid: filesystem guid that is read from GPT partition entry\n            plugin: plugin that supports this filesystem\n        \"\"\"\n        key = uuid.UUID(fs_guid.lower())\n\n        self.logger.debug('GPT: {}, GUID: {}'\n                          .format(self.__get_plugin_name(plugin), fs_guid))\n        self.__gpt_plugins[key].append(plugin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndetects the partition type of the MBR file.", "response": "def detect_mbr(self, filename, offset, fs_id):\n        \"\"\"Used by rawdisk.session.Session to match mbr partitions against\n        filesystem plugins.\n\n        Args:\n            filename: device or file that it will read in order to detect\n            the filesystem fs_id: filesystem id to match (ex. 0x07)\n            offset: offset for the filesystem that is being matched\n\n        Returns:\n            Volume object supplied by matched plugin.\n            If there is no match, None is returned\n        \"\"\"\n        self.logger.debug('Detecting MBR partition type')\n\n        if fs_id not in self.__mbr_plugins:\n            return None\n        else:\n            plugins = self.__mbr_plugins.get(fs_id)\n            for plugin in plugins:\n                if plugin.detect(filename, offset):\n                    return plugin.get_volume_object()\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndetects the partition type of a file on the filesystem.", "response": "def detect_gpt(self, filename, offset, fs_guid):\n        \"\"\"Used by rawdisk.session.Session to match gpt partitions agains\n        filesystem plugins.\n\n        Args:\n            filename: device or file that it will read in order to detect the\n            filesystem\n            fs_id: filesystem guid to match\n            (ex. {EBD0A0A2-B9E5-4433-87C0-68B6B72699C7})\n            offset: offset for the filesystem that is being matched\n\n        Returns:\n            Volume object supplied by matched plugin.\n            If there is no match, None is returned\n        \"\"\"\n        self.logger.debug('Detecting GPT partition type')\n\n        if fs_guid not in self.__gpt_plugins:\n            return None\n        else:\n            plugins = self.__gpt_plugins.get(fs_guid)\n            for plugin in plugins:\n                if plugin.detect(filename, offset):\n                    return plugin.get_volume_object()\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef inject_documentation(**options):\n    import cog\n    loader = ConfigLoader(**options)\n    cog.out(\"\\n\" + loader.documentation + \"\\n\\n\")", "response": "Generate configuration documentation in reStructuredText_ syntax."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_checksum(self):\n        if self.context.is_file(self.filename):\n            friendly_name = format_path(self.filename)\n            logger.debug(\"Calculating SHA1 of %s ..\", friendly_name)\n            context = hashlib.sha1()\n            context.update(self.context.read_file(self.filename))\n            checksum = context.hexdigest()\n            logger.debug(\"The SHA1 digest of %s is %s.\", friendly_name, checksum)\n            return checksum", "response": "Get the SHA1 digest of the contents of the file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef old_checksum(self):\n        if self.context.is_file(self.checksum_file):\n            logger.debug(\"Reading saved checksum from %s ..\", format_path(self.checksum_file))\n            checksum = self.context.read_file(self.checksum_file).decode('ascii')\n            logger.debug(\"Saved checksum is %s.\", checksum)\n            return checksum", "response": "Get the checksum stored in the checksum_file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_file(self, force=None):\n        if force is None:\n            force = self.force\n        if not self.context.is_directory(self.directory):\n            # Create the .d directory.\n            logger.info(\"Creating directory %s ..\", format_path(self.directory))\n            self.context.execute('mkdir', '-p', self.directory, tty=False)\n            # Move the original file into the .d directory.\n            local_file = os.path.join(self.directory, 'local')\n            logger.info(\"Moving %s to %s ..\", format_path(self.filename), format_path(local_file))\n            self.context.execute('mv', self.filename, local_file, tty=False)\n        # Read the modular configuration file(s).\n        blocks = []\n        for entry in natsort(self.context.list_entries(self.directory)):\n            if not entry.startswith('.'):\n                filename = os.path.join(self.directory, entry)\n                if self.context.is_executable(filename):\n                    blocks.append(self.execute_file(filename))\n                else:\n                    blocks.append(self.read_file(filename))\n        contents = b\"\\n\\n\".join(blocks)\n        # Make sure the generated file was not modified? We skip this on the\n        # first run, when the original file was just moved into the newly\n        # created directory (see above).\n        if all(map(self.context.is_file, (self.filename, self.checksum_file))):\n            logger.info(\"Checking for local changes to %s ..\", format_path(self.filename))\n            if self.new_checksum != self.old_checksum:\n                if force:\n                    logger.warning(compact(\n                        \"\"\"\n                        The contents of the file to generate ({filename})\n                        were modified but --force was used so overwriting\n                        anyway!\n                        \"\"\",\n                        filename=format_path(self.filename),\n                    ))\n                else:\n                    raise RefuseToOverwrite(compact(\n                        \"\"\"\n                        The contents of the file to generate ({filename})\n                        were modified and I'm refusing to overwrite it! If\n                        you're sure you want to proceed, use the --force\n                        option or delete the file {checksum_file} and\n                        retry.\n                        \"\"\",\n                        filename=format_path(self.filename),\n                        checksum_file=format_path(self.checksum_file),\n                    ))\n        # Update the generated configuration file.\n        self.write_file(self.filename, contents)\n        # Update the checksum file.\n        self.context.write_file(self.checksum_file, self.new_checksum)", "response": "Update the file with the contents of the files in the. d directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read_file(self, filename):\n        logger.info(\"Reading file: %s\", format_path(filename))\n        contents = self.context.read_file(filename)\n        num_lines = len(contents.splitlines())\n        logger.debug(\"Read %s from %s.\",\n                     pluralize(num_lines, 'line'),\n                     format_path(filename))\n        return contents.rstrip()", "response": "Read a text file and provide feedback to the user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a file and provide feedback to the user.", "response": "def execute_file(self, filename):\n        \"\"\"\n        Execute a file and provide feedback to the user.\n\n        :param filename: The pathname of the file to execute (a string).\n        :returns: Whatever the executed file returns on stdout (a string).\n        \"\"\"\n        logger.info(\"Executing file: %s\", format_path(filename))\n        contents = self.context.execute(filename, capture=True).stdout\n        num_lines = len(contents.splitlines())\n        logger.debug(\"Execution of %s yielded % of output.\",\n                     format_path(filename),\n                     pluralize(num_lines, 'line'))\n        return contents.rstrip()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites a text file and provide feedback to the user.", "response": "def write_file(self, filename, contents):\n        \"\"\"\n        Write a text file and provide feedback to the user.\n\n        :param filename: The pathname of the file to write (a string).\n        :param contents: The new contents of the file (a string).\n        \"\"\"\n        logger.info(\"Writing file: %s\", format_path(filename))\n        contents = contents.rstrip() + b\"\\n\"\n        self.context.write_file(filename, contents)\n        logger.debug(\"Wrote %s to %s.\",\n                     pluralize(len(contents.splitlines()), \"line\"),\n                     format_path(filename))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef available_files(self):\n        matches = []\n        for pattern in self.filename_patterns:\n            logger.debug(\"Matching filename pattern: %s\", pattern)\n            matches.extend(natsort(glob.glob(parse_path(pattern))))\n        return matches", "response": "Returns a list of filenames that are available for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef documentation(self):\n        from humanfriendly.tables import format_rst_table\n        formatted_table = format_rst_table([\n            (directory,\n             self.get_main_pattern(directory).replace('*', r'\\*'),\n             self.get_modular_pattern(directory).replace('*', r'\\*'))\n            for directory in self.base_directories\n        ], [\n            \"Directory\",\n            \"Main configuration file\",\n            \"Modular configuration files\",\n        ])\n        return format(DOCUMENTATION_TEMPLATE, table=formatted_table).strip()", "response": "r Returns a string that contains the documentation for the current configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filename_patterns(self):\n        patterns = []\n        for directory in self.base_directories:\n            patterns.append(self.get_main_pattern(directory))\n            patterns.append(self.get_modular_pattern(directory))\n        return patterns", "response": "Returns a list of filename patterns to search for available configuration files."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parser(self):\n        parser = configparser.RawConfigParser()\n        for filename in self.available_files:\n            friendly_name = format_path(filename)\n            logger.debug(\"Loading configuration file: %s\", friendly_name)\n            loaded_files = parser.read(filename)\n            if len(loaded_files) == 0:\n                self.report_issue(\"Failed to load configuration file! (%s)\", friendly_name)\n        logger.debug(\"Loaded %s from %s.\",\n                     pluralize(len(parser.sections()), \"section\"),\n                     pluralize(len(self.available_files), \"configuration file\"))\n        return parser", "response": "A : class : configparser. RawConfigParser object with available_files loaded."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_main_pattern(self, directory):\n        return os.path.join(directory, format(\n            '{prefix}{program_name}.{extension}',\n            extension=self.filename_extension.lstrip('.'),\n            program_name=self.program_name,\n            prefix=self.get_prefix(directory),\n        ))", "response": "Get the pattern to find the main configuration file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef report_issue(self, message, *args, **kw):\n        if self.strict:\n            raise ValueError(format(message, *args, **kw))\n        else:\n            logger.warning(format(message, *args, **kw))", "response": "Handle a problem by raising an exception or logging a warning."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getModulePath(project_path,module_name,verbose):\n    '''Searches for module_name in searchpath and returns the filepath.\n    If no filepath was found, returns None.'''\n    if not module_name:\n        return None\n    sys.path.append(project_path)\n    try:\n        package = pkgutil.get_loader(module_name)\n    except ImportError:\n        if verbose:\n            print(\"Parent module for \"+module_name+\" not found.\")\n        return None\n    except:\n        if verbose:\n            print(module_name+\" not loaded for bizarre reasons\")\n    try:\n        if package: \n                if package.get_code(module_name):\n                    filename = package.get_code(module_name).co_filename\n                    return filename\n                elif package.find_spec(module_name).has_location==False:\n                    return None #built-in module such as itertools\n                else:\n                    pass #perhaps filename is in package.find_spec(module_name).origin?\n                    pass #a good reference is https://www.python.org/dev/peps/pep-0302/\n    except ImportError:\n        if verbose:\n            print(\"Code object unavailable for \"+module_name)\n        return None\n    except AttributeError:\n        if verbose:\n            print(module_name+\" is an ExtensionFileLoader object\")\n        return None\n    except:\n        if verbose:\n            print(module_name+\" not loaded for bizarre reasons\")\n        return None\n    else:\n        if verbose:\n            print (\"Module \"+module_name+\" not found.\")\n        return None", "response": "Searches for module_name in searchpath and returns the filepath."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of objects referenced by import from node", "response": "def getImportFromObjects(node):\n    '''Returns a list of objects referenced by import from node'''\n    somenames = [x.asname for x in node.names if x.asname]\n    othernames = [x.name for x in node.names if not x.asname]\n    return somenames+othernames"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef mft_record_size(self):\n        if self.extended_bpb.clusters_per_mft < 0:\n            return 2 ** abs(self.extended_bpb.clusters_per_mft)\n        else:\n            return self.clusters_per_mft * self.sectors_per_cluster * \\\n                self.bytes_per_sector", "response": "Returns the size of the MFT record in bytes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the MFT Table offset from the beginning of the partition in bytes.", "response": "def mft_offset(self):\n        \"\"\"\n        Returns:\n            int: MFT Table offset from the beginning of the partition in bytes\n        \"\"\"\n        return self.bpb.bytes_per_sector * \\\n            self.bpb.sectors_per_cluster * self.extended_bpb.mft_cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef mft_mirror_offset(self):\n        return self.bpb.bytes_per_sector * \\\n            self.bpb.sectors_per_cluster * self.extended_bpb.mft_mirror_cluster", "response": "Returns the Mirror MFT Table offset from the beginning of the partition"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clear_mappers():\n    # Remove our hybrid property constructs.\n    for mpr, is_primary in _mapper_registry.items():\n        if is_primary:\n            for attr_name in ('id', 'slug'):\n                try:\n                    attr = object.__getattribute__(mpr.class_, attr_name)\n                    if isinstance(attr, hybrid_property):\n                        if attr_name == 'id':\n                            delattr(mpr.class_, attr_name)\n                        else:\n                            setattr(mpr.class_, attr_name, attr.descriptor)\n                except AttributeError:\n                    pass\n    sa_clear_mappers()", "response": "Clears all mappers set up by SA and also clears all custom id and slug attributes inserted by the SA."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef as_slug_expression(attr):\n    slug_expr = sa_func.replace(attr, ' ', '-')\n    slug_expr = sa_func.replace(slug_expr, '_', '-')\n    slug_expr = sa_func.lower(slug_expr)\n    return slug_expr", "response": "Converts the given instrumented string attribute into an SQL expression that can be used as a slug."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef mapper(class_, local_table=None, id_attribute='id', slug_expression=None,\n           *args, **kwargs):\n    \"\"\"\n    Convenience wrapper around the SA mapper which will set up the hybrid\n    \"id\" and \"slug\" attributes required by everest after calling the SA\n    mapper.\n\n    If you (e.g., for testing purposes) want to clear mappers created with\n    this function, use the :func:`clear_mappers` function in this module.\n\n    :param str id_attribute: the name of the column in the table to use as\n      ID column (will be aliased to a new \"id\" attribute in the mapped class)\n    :param slug_expression: function to generate a slug SQL expression given\n      the mapped class as argument.\n    \"\"\"\n    mpr = sa_mapper(class_, local_table=local_table, *args, **kwargs)\n    # Set up the ID attribute as a hybrid property, if necessary.\n    if id_attribute != 'id':\n        # Make sure we are not overwriting an already mapped or customized\n        # 'id' attribute.\n        if 'id' in mpr.columns:\n            mpr.dispose()\n            raise ValueError('Attempting to overwrite the mapped \"id\" '\n                             'attribute.')\n        elif isdatadescriptor(getattr(class_, 'id', None)):\n            mpr.dispose()\n            raise ValueError('Attempting to overwrite the custom data '\n                             'descriptor defined for the \"id\" attribute.')\n        class_.id = synonym(id_attribute)\n    # If this is a polymorphic class, a base class may already have a\n    # hybrid descriptor set as slug attribute.\n    slug_descr = None\n    for base_cls in class_.__mro__:\n        try:\n            slug_descr = object.__getattribute__(base_cls, 'slug')\n        except AttributeError:\n            pass\n        else:\n            break\n    if isinstance(slug_descr, hybrid_descriptor):\n        if not slug_expression is None:\n            raise ValueError('Attempting to overwrite the expression for '\n                             'an inherited slug hybrid descriptor.')\n        hyb_descr = slug_descr\n    else:\n        # Set up the slug attribute as a hybrid property.\n        if slug_expression is None:\n            cls_expr = lambda cls: cast(getattr(cls, 'id'), String)\n        else:\n            cls_expr = slug_expression\n        hyb_descr = hybrid_descriptor(slug_descr, expr=cls_expr)\n    class_.slug = hyb_descr\n    return mpr", "response": "A simple SA mapper that creates a new SA object that maps to the given class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef synonym(name):\n    return hybrid_property(lambda inst: getattr(inst, name),\n                           lambda inst, value: setattr(inst, name, value),\n                           expr=lambda cls: getattr(cls, name))", "response": "Utility function mimicking the behavior of the old SA synonym function\n    with the new SA synonym semantics."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmaps all system entities to the user message system entity.", "response": "def map_system_entities(engine, metadata, reset):\n    \"\"\"\n    Maps all system entities.\n    \"\"\"\n    # Map the user message system entity.\n    msg_tbl = Table('_user_messages', metadata,\n                    Column('guid', String, nullable=False, primary_key=True),\n                    Column('text', String, nullable=False),\n                    Column('time_stamp', DateTime(timezone=True),\n                           nullable=False, default=sa_func.now()),\n                    )\n    mapper(UserMessage, msg_tbl, id_attribute='guid')\n    if reset:\n        metadata.drop_all(bind=engine, tables=[msg_tbl])\n    metadata.create_all(bind=engine, tables=[msg_tbl])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef inspect(orm_class, attribute_name):\n        key = (orm_class, attribute_name)\n        elems = OrmAttributeInspector.__cache.get(key)\n        if elems is None:\n            elems = OrmAttributeInspector.__inspect(key)\n            OrmAttributeInspector.__cache[key] = elems\n        return elems", "response": "inspects the mapped attribute"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nusing trang to convert the Schema to the given output filename or to the given extension", "response": "def trang(self, outfn=None, ext='.rng'):\n        \"\"\"use trang to convert the Schema to the given output filename or to the given extension\n        SIDE EFFECT: creates a new file on the filesystem.\n        \"\"\"\n        from . import JARS\n        java = os.environ.get('java') or 'java'\n        trang_jar = os.path.join(JARS, 'trang.jar')\n        outfn = outfn or os.path.splitext(self.fn)[0] + ext\n        stderr = tempfile.NamedTemporaryFile()\n        try:\n            result = subprocess.check_call(\n                [java, \"-jar\", trang_jar, self.fn, outfn],\n                universal_newlines=True,\n                stderr=stderr)\n        except subprocess.CalledProcessError as e:\n            f = open(stderr.name, 'r+b')\n            output = f.read(); f.close()\n            raise RuntimeError(str(output, 'utf-8')).with_traceback(sys.exc_info()[2]) from None\n        if result==0:\n            return outfn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the Schema to schematron and save at the given output filename or with the given extension.", "response": "def schematron(self, fn=None, outfn=None, ext='.sch'):\n        \"\"\"convert the Schema to schematron and save at the given output filename or with the given extension.\"\"\"\n        from .xslt import XSLT\n        from . import PATH, XML, etree\n        fn = fn or self.fn\n        if os.path.splitext(fn)[-1].lower()==ext:\n            return fn\n        elif os.path.splitext(fn)[-1].lower()!='.rng':\n            fn = Schema(fn=fn).trang(ext='.rng')\n        rng2sch = XSLT(fn=os.path.join(PATH, 'xslts', 'rng2sch.xslt'))\n        rng = XML(fn=fn)\n        outfn = outfn or os.path.splitext(fn)[0]+ext\n        sch = XML(fn=outfn, root=rng2sch.saxon9(rng.root).getroot())\n        sch.write()\n        return sch.fn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef xhtml(self, outfn=None, ext='.xhtml', css=None, **params):\n        from markdown import markdown\n        from copy import deepcopy\n        from bl.file import File\n        from .xslt import XSLT\n        from .rng import RNG\n        from . import XML, PATH, etree\n        rncfn = os.path.splitext(self.fn)[0] + '.rnc'\n        rngfn = os.path.splitext(self.fn)[0] + '.rng'\n        htmlfn = os.path.splitext(self.fn)[0] + '.html'\n        if self.fn==rncfn or os.path.exists(rncfn):\n            rngfn = Schema(rncfn).trang(ext='.rng')\n        assert os.path.exists(rngfn)\n\n        # convert all <r:define> elements into a <a:definition> blocks containing a compact syntax alternative\n        rng = RNG(fn=rngfn)\n        for define in rng.xpath(rng.root, \"//r:define\"):\n            log.debug(\"%s %r\" % (rng.tag_name(define), define.attrib))\n            tempdefine = deepcopy(define)\n            tempgrammar = deepcopy(rng.root); tempgrammar.text = '\\n'\n            for ch in tempgrammar.getchildren(): rng.remove(ch)\n            tempgrammar.insert(0, tempdefine)\n            for adoc in rng.xpath(tempdefine, \".//a:documentation | .//a:definition\"):\n                rng.remove(adoc)\n            with tempfile.TemporaryDirectory() as tempdir:\n                x = XML(fn=os.path.join(tempdir, 'define.rng'), root=tempgrammar)\n                x.write()\n                newfn = Schema(x.fn).trang(ext='.rnc')\n                txt = open(newfn, 'rb').read().decode('utf-8')\n                if '\\n\\n' in txt:\n                    txt = txt[txt.index('\\n\\n')+1:].strip()\n            adef = etree.Element(\"{%(a)s}definition\" % RNG.NS)\n            adef.text = txt\n            adef.tail = '\\n\\t\\t'\n            log.debug(adef.text)\n            annotations = rng.xpath(define, \"a:*\")\n            if len(annotations) > 0:\n                index = define.index(annotations[-1])+1\n            else:\n                index = 0\n            define.insert(index, adef)\n        rng.write()\n\n        xslt = XSLT(fn=os.path.join(PATH, 'xslts', 'rng2md.xslt'))\n        md = xslt.saxon9(rng.root, **params).strip()\n        html_body = markdown(md, \n            output_format=\"xhtml5\", \n            extensions=[                            # see https://python-markdown.github.io/extensions/\n                'markdown.extensions.extra',    \n                'markdown.extensions.admonition', \n                'markdown.extensions.headerid', \n                'markdown.extensions.sane_lists', \n                'markdown.extensions.toc']).strip()\n        html_text = \"\"\"<html><head><meta charset=\"UTF-8\"/><style type=\"text/css\">\n            body {font-family:sans-serif;line-height:1.3}\n            h1,h2,h3 {margin:1em 0 .25em 0}\n            h1 {font-size:2rem;font-weight:normal;}\n            h2 {font-size:1.2rem;font-weight:bold;}\n            h3 {font-size:1.15rem;font-weight:normal;font-style:italic;}\n            p {margin:0 0 .5rem 0;}\n            p.subtitle {font-size:1.2rem;font-family:sans-serif;margin-bottom:1em}\n            p.code {font-family:monospace;font-size:.6rem;color:#666;line-height:1.1}\n            pre {font-family:monospace;font-size:.6rem;color:#666;line-height:1.1;margin-left:1.5rem;}\n            hr {border:0;border-top:1px solid #999;margin:1rem 0;}\n            </style></head><body>\\n\"\"\" + html_body + \"\"\"\\n</body></html>\"\"\"\n        html = XML(fn=htmlfn, root=html_text)\n        return html", "response": "convert the Schema to XHTML with the given output filename or with the given extension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a schema using an element s tag. schemas can be a string or a list of strings", "response": "def from_tag(cls, tag, schemas, ext='.rnc'):\n        \"\"\"load a schema using an element's tag. schemas can be a string or a list of strings\"\"\"\n        return cls(fn=cls.filename(tag, schemas, ext=ext))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef filename(cls, tag, schemas, ext='.rnc'):\n        if type(schemas)==str: \n            schemas = re.split(\"\\s*,\\s*\", schemas)\n        for schema in schemas:\n            fn = os.path.join(schema, cls.dirname(tag), cls.basename(tag, ext=ext))\n            if os.path.exists(fn):\n                return fn", "response": "given a tag and a list of schemas return the filename of the schema."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a namespace url to a directory name. Also accepts an Element tag with namespace prepended in brackets. Also accepts an Element tag with namespace prepended in brackets.", "response": "def dirname(cls, namespace):\n        \"\"\"convert a namespace url to a directory name. \n            Also accepts an Element 'tag' with namespace prepended in {braces}.\"\"\"\n        md = re.match(\"^\\{?(?:[^:]+:/{0,2})?([^\\}]+)\\}?\", namespace)\n        if md is not None:\n            dirname = re.sub(\"[/:]\", '_', md.group(1))\n        else:\n            dirname = ''\n        return dirname"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a string containing the errors of the current object.", "response": "def errors_as_text(self):\n        \"\"\"\n        only available to Django 1.7+\n        \"\"\"\n        errors = []\n        errors.append(self.non_field_errors().as_text())\n        errors_data = self.errors.as_data()\n        for key, value in errors_data.items():\n            field_label = self.fields[key].label\n            err_descn = ''.join([force_text(e.message) for e in value])\n            error = \"%s %s\" % (field_label, err_descn)\n            errors.append(error)\n        return ','.join(errors)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_attr2fields(self, attr_name, attr_val, fields=[], exclude=[], include_all_if_empty=True):\n        for f in self.filter_fields(fields, exclude, include_all_if_empty):\n            f = self.fields[f.name]\n            org_val = f.widget.attrs.get(attr_name, '')\n            f.widget.attrs[attr_name] = '%s %s' % (org_val, attr_val) if org_val else attr_val", "response": "add attr to fields"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_class2fields(self, html_class, fields=[], exclude=[], include_all_if_empty=True):\n        self.add_attr2fields('class', html_class, fields, exclude)", "response": "add class to html widgets."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filter_fields(self, fields=[], exclude=[], include_all_if_empty=True):\n        if not include_all_if_empty and not fields:\n            return []\n        ret = []\n        for f in self.visible_fields():\n            if fields and f.name not in fields:\n                continue\n            if exclude and f.name in exclude:\n                continue\n            ret.append(f)\n        return ret", "response": "filter_fields - Filter the fields of the fileds based on the fields in the list fields - a list of fields to filter exclude - a list of fields to exclude"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting required to True", "response": "def as_required_fields(self, fields=[]):\n        \"\"\" set required to True \"\"\"\n        fields = self.filter_fields(fields)\n        for f in fields:\n            f = self.fields[f.name]\n            f.required = True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef check_uniqe(self, obj_class, error_msg=_('Must be unique'), **kwargs):\n        if obj_class.objects.filter(**kwargs).exclude(pk=self.instance.pk):\n            raise forms.ValidationError(error_msg)", "response": "check if this object is unique"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve dunder values from a pyfile", "response": "def get_info(pyfile):\n    '''Retrieve dunder values from a pyfile'''\n    info = {}\n    info_re = re.compile(r\"^__(\\w+)__ = ['\\\"](.*)['\\\"]\")\n    with open(pyfile, 'r') as f:\n        for line in f.readlines():\n            match = info_re.search(line)\n            if match:\n                info[match.group(1)] = match.group(2)\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an argument parser and parse command line arguments.", "response": "def parse_args():\n    \"\"\"Create an `argparse.ArgumentParser` and parse command line arguments.\n    \"\"\"\n    parser = ArgumentParser(\n        description=\"Create a landing website for for PDF documentation.\",\n        epilog=\"lander is a product of LSST Data Management. Code is \"\n               \"available at https://github.com/lsst-sqre/lander.\")\n\n    parser.add_argument(\n        '--version',\n        dest='show_version',\n        default=False,\n        action='store_true',\n        help=\"Show version information and exit.\")\n\n    parser.add_argument(\n        '--verbose',\n        default=False,\n        action='store_true',\n        help='Show debugging information.')\n\n    parser.add_argument(\n        '--build-dir',\n        dest='build_dir',\n        default=os.path.abspath('_build'),\n        help='Build directory (scratch space).')\n\n    parser.add_argument(\n        '--pdf',\n        dest='pdf_path',\n        help='Filepath of PDF document.'\n    )\n\n    parser.add_argument(\n        '--lsstdoc',\n        dest='lsstdoc_tex_path',\n        help='File path of a lsstdoc LaTeX file (for metadata).'\n    )\n\n    parser.add_argument(\n        '--env',\n        dest='environment',\n        choices=['travis'],\n        default=None,\n        help='Environment for auto-configuration'\n    )\n\n    parser.add_argument(\n        '--title',\n        dest='title',\n        help='Document title (metadata override)'\n    )\n\n    parser.add_argument(\n        '--authors',\n        dest='authors_json',\n        help='Author list, as a JSON array of strings (metadata override).'\n    )\n\n    parser.add_argument(\n        '--abstract',\n        dest='abstract',\n        help='Document abstract (metadata override).'\n    )\n\n    parser.add_argument(\n        '--handle',\n        dest='doc_handle',\n        help='Document handle, such as LDM-000 (metadata override).'\n    )\n\n    parser.add_argument(\n        '--repo-url',\n        dest='repo_url',\n        help='Git repository URL (metadata override).'\n    )\n\n    parser.add_argument(\n        '--repo-branch',\n        dest='repo_branch',\n        help='Git repository branch name (metadata override).'\n    )\n\n    parser.add_argument(\n        '--date',\n        dest='build_datetime',\n        help='Datetime string describing when the document was authored '\n             '(metadata override; the current datetime is used by default).'\n    )\n\n    parser.add_argument(\n        '--extra-downloads',\n        dest='extra_downloads',\n        nargs='*',\n        help='Paths of additional files to provide '\n             'download links for from the landing page. '\n             'These files will be copied into the root deployment directory. '\n             'The main PDF (--pdf) should not be included in this list.'\n    )\n\n    parser.add_argument(\n        '--docushare-url',\n        dest='docushare_url',\n        help='Docushare URL. Prefer the landing page URL in docushare rather '\n             'than the direct PDF link so that users can see metadata about '\n             'the accepted version. Using ls.st, this is the '\n             'https://ls.st/ldm-nnn* URL.'\n    )\n\n    parser.add_argument(\n        '--ltd-product',\n        dest='ltd_product',\n        help='Product name on LSST the Docs, such as `ldm-000` '\n             '(metadata override).'\n    )\n\n    parser.add_argument(\n        '--keeper-url',\n        dest='keeper_url',\n        help='LTD Keeper API URL (or $LTD_KEEPER_URL)'\n    )\n\n    parser.add_argument(\n        '--keeper-user',\n        dest='keeper_user',\n        help='LTD Keeper API username (or $LTD_KEEPER_USER)'\n    )\n\n    parser.add_argument(\n        '--keeper-password',\n        dest='keeper_password',\n        help='LTD Keeper API password (or $LTD_KEEPER_PASSWORD)'\n    )\n\n    parser.add_argument(\n        '--aws-id',\n        dest='aws_id',\n        help='AWS key ID (or $LTD_AWS_ID)'\n    )\n\n    parser.add_argument(\n        '--aws-secret',\n        dest='aws_secret',\n        help='AWS secret key (or $LTD_AWS_SECRET)'\n    )\n\n    parser.add_argument(\n        '--upload',\n        dest='upload',\n        default=False,\n        action='store_true',\n        help='Upload built documentation to LSST the Docs'\n    )\n\n    return parser.parse_args()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main():\n    args = parse_args()\n    config_logger(args)\n    logger = structlog.get_logger(__name__)\n\n    if args.show_version:\n        # only print the version\n        print_version()\n        sys.exit(0)\n\n    version = pkg_resources.get_distribution('lander').version\n    logger.info('Lander version {0}'.format(version))\n\n    config = Configuration(args=args)\n\n    # disable any build confirmed to be a PR with Travis\n    if config['is_travis_pull_request']:\n        logger.info('Skipping build from PR.')\n        sys.exit(0)\n\n    lander = Lander(config)\n    lander.build_site()\n    logger.info('Build complete')\n\n    if config['upload']:\n        lander.upload_site()\n        logger.info('Upload complete')\n\n    logger.info('Lander complete')", "response": "Entrypoint for lander executable."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a node into the node_map if it is not already there. Returns True if added otherwise returns False", "response": "def insert_node(self, node):\n        \"\"\"\n        Adds node if name is available or pre-existing node\n        returns True if added\n        returns False if not added\n        \"\"\"\n        if self._is_node_reserved(node):\n            return False\n\n        # Put node in map\n        self._node_map[node.get_id()] = node\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmerges rules: 00 + 00 == 00 00 + 0B == 0B 0A + 00 == 0A 0A + 0B == 0A A0 + 00 == A0 A0 + 0B == AB AA + 00 == AA AA + 0B == AB 00 + B0 == B0 00 + BB == BB 0A + B0 == BA 0A + BB == BA A0 + B0 == A0 A0 + BB == AB AA + B0 == AA AA + BB == AA", "response": "def merge(self, subordinate_graph):\n        \"\"\"\n        merge rules:\n        00 + 00 == 00    00 + 0B == 0B\n        0A + 00 == 0A    0A + 0B == 0A\n        A0 + 00 == A0    A0 + 0B == AB\n        AA + 00 == AA    AA + 0B == AB\n\n        00 + B0 == B0    00 + BB == BB\n        0A + B0 == BA    0A + BB == BA\n        A0 + B0 == A0    A0 + BB == AB\n        AA + B0 == AA    AA + BB == AA\n        \"\"\"\n        if not isinstance(subordinate_graph, Graph):\n            raise Exception(\"Graph is expected to only merge with a Graph.\")\n\n        subordinate_nodes = subordinate_graph.get_nodes()\n\n        merge_results = []\n        for node_id in subordinate_nodes:\n            node = subordinate_nodes[node_id]\n            merge_results.append((\n                node.get_id(),\n                self.insert_node(node)\n            ))\n\n        # TODO perhaps throw exception if merge was unsuccessful\n        return merge_results"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef join(self, distbase, location):\n        sep = ''\n        if distbase and distbase[-1] not in (':', '/'):\n            sep = '/'\n        return distbase + sep + location", "response": "Join distbase and location in such way that the result is a valid scp destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_location(self, location, depth=0):\n        if not location:\n            return []\n        if location in self.aliases:\n            res = []\n            if depth > MAXALIASDEPTH:\n                err_exit('Maximum alias depth exceeded: %(location)s' % locals())\n            for loc in self.aliases[location]:\n                res.extend(self.get_location(loc, depth+1))\n            return res\n        if self.is_server(location):\n            return [location]\n        if location == 'pypi':\n            err_exit('No configuration found for server: pypi\\n'\n                     'Please create a ~/.pypirc file')\n        if self.urlparser.is_url(location):\n            return [location]\n        if not self.has_host(location) and self.distbase:\n            return [self.join(self.distbase, location)]\n        return [location]", "response": "Resolve aliases and apply distbase."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_default_location(self):\n        res = []\n        for location in self.distdefault:\n            res.extend(self.get_location(location))\n        return res", "response": "Return the default location."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef check_empty_locations(self, locations=None):\n        if locations is None:\n            locations = self.locations\n        if not locations:\n            err_exit('mkrelease: option -d is required\\n%s' % USAGE)", "response": "Fail if locations is empty."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef check_valid_locations(self, locations=None):\n        if locations is None:\n            locations = self.locations\n        for location in locations:\n            if (not self.is_server(location) and\n                not self.is_ssh_url(location) and\n                not self.has_host(location)):\n                err_exit('Unknown location: %(location)s' % locals())", "response": "Fail if locations contains bad destinations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state of the internal state.", "response": "def set_defaults(self, config_file):\n        \"\"\"Set defaults.\n        \"\"\"\n        self.defaults = Defaults(config_file)\n        self.locations = Locations(self.defaults)\n        self.python = Python()\n        self.setuptools = Setuptools()\n        self.scp = SCP()\n        self.scms = SCMFactory()\n        self.urlparser = URLParser()\n        self.skipcommit = not self.defaults.commit\n        self.skiptag = not self.defaults.tag\n        self.skipregister = False   # per server\n        self.skipupload = False     # special\n        self.push = self.defaults.push\n        self.develop = False        # special\n        self.quiet = self.defaults.quiet\n        self.sign = False           # per server\n        self.list = False\n        self.manifest = self.defaults.manifest\n        self.identity = ''          # per server\n        self.branch = ''\n        self.scmtype = ''\n        self.infoflags = []\n        self.formats = []\n        self.distributions = []\n        self.directory = os.curdir\n        self.scm = None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_options(self, args, depth=0):\n        try:\n            options, remaining_args = getopt.gnu_getopt(args,\n                'CPRSTbc:d:eghi:lmnpqsvwz',\n                ('no-commit', 'no-tag', 'no-register', 'no-upload', 'dry-run',\n                 'sign', 'identity=', 'dist-location=', 'version', 'help',\n                 'push', 'quiet', 'svn', 'hg', 'git', 'develop', 'binary',\n                 'list-locations', 'config-file=', 'wheel', 'zip', 'gztar',\n                 'manifest-only', 'trace', 'egg', 'no-push'))\n        except getopt.GetoptError as e:\n            err_exit('mkrelease: %s\\n%s' % (e.msg, USAGE))\n\n        for name, value in options:\n            if name in ('-C', '--no-commit'):\n                self.skipcommit = True\n            elif name in ('-T', '--no-tag'):\n                self.skiptag = True\n            elif name in ('-R', '--no-register'):\n                self.skipregister = True\n            elif name in ('-S', '--no-upload'):\n                self.skipupload = True\n            elif name in ('-n', '--dry-run'):\n                self.skipcommit = self.skiptag = self.skipregister = self.skipupload = True\n            elif name in ('-p', '--push'):\n                self.push = True\n            elif name in ('-P', '--no-push'):   # undocumented\n                self.push = False\n            elif name in ('-q', '--quiet'):\n                self.quiet = True\n            elif name in ('-s', '--sign'):\n                self.sign = True\n            elif name in ('-i', '--identity'):\n                self.identity = value\n            elif name in ('-d', '--dist-location'):\n                self.locations.extend(self.locations.get_location(value))\n            elif name in ('-l', '--list-locations'):\n                self.list = True\n            elif name in ('-m', '--manifest-only'):\n                self.manifest = True\n            elif name in ('-h', '--help'):\n                msg_exit(HELP)\n            elif name in ('-v', '--version'):\n                msg_exit(VERSION)\n            elif name in ('--svn', '--hg', '--git'):\n                self.scmtype = name[2:]\n            elif name in ('-e', '--develop'):\n                self.develop = True\n            elif name in ('-z', '--zip'):\n                self.formats.append('zip')\n            elif name in ('-g', '--gztar'):\n                self.formats.append('gztar')\n            elif name in ('-b', '--binary', '--egg'):\n                self.formats.append('egg')\n            elif name in ('-w', '--wheel'):\n                self.formats.append('wheel')\n            elif name in ('--trace',):          # undocumented\n                os.environ['JARN_TRACE'] = '1'\n            elif name in ('-c', '--config-file') and depth == 0:\n                self.reset_defaults(expanduser(value))\n                return self.parse_options(args, depth+1)\n\n        return remaining_args", "response": "Parse command line options."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprint known dist - locations and exit.", "response": "def list_locations(self):\n        \"\"\"Print known dist-locations and exit.\n        \"\"\"\n        known = self.defaults.get_known_locations()\n        for default in self.defaults.distdefault:\n            if default not in known:\n                known.add(default)\n        if not known:\n            err_exit('No locations', 0)\n        for location in sorted(known):\n            if location in self.defaults.distdefault:\n                print(location, '(default)')\n            else:\n                print(location)\n        sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns True if the register command is disabled for the given server.", "response": "def get_skipregister(self, location=None):\n        \"\"\"Return true if the register command is disabled (for the given server.)\n        \"\"\"\n        if location is None:\n            return self.skipregister or not self.defaults.register\n        else:\n            server = self.defaults.servers[location]\n            if self.skipregister:\n                return True\n            elif server.register is not None:\n                if not self.defaults.register and self.get_skipupload():\n                    return True # prevent override\n                return not server.register\n            elif not self.defaults.register:\n                return True\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the list of uploadflags for the given location.", "response": "def get_uploadflags(self, location):\n        \"\"\"Return uploadflags for the given server.\n        \"\"\"\n        uploadflags = []\n        server = self.defaults.servers[location]\n\n        if self.sign:\n            uploadflags.append('--sign')\n        elif server.sign is not None:\n            if server.sign:\n                uploadflags.append('--sign')\n        elif self.defaults.sign:\n            uploadflags.append('--sign')\n\n        if self.identity:\n            if '--sign' not in uploadflags:\n                uploadflags.append('--sign')\n            uploadflags.append('--identity=\"%s\"' % self.identity)\n        elif '--sign' in uploadflags:\n            if server.identity is not None:\n                if server.identity:\n                    uploadflags.append('--identity=\"%s\"' % server.identity)\n            elif self.defaults.identity:\n                uploadflags.append('--identity=\"%s\"' % self.defaults.identity)\n\n        return uploadflags"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_options(self):\n        args = self.parse_options(self.args)\n\n        if args:\n            self.directory = args[0]\n\n        if self.develop:\n            self.skiptag = True\n        if not self.develop:\n            self.develop = self.defaults.develop\n        if not self.develop:\n            self.infoflags = self.setuptools.infoflags\n\n        if not self.formats:\n            self.formats = self.defaults.formats\n\n        for format in self.formats:\n            if format == 'zip':\n                self.distributions.append(('sdist', ['--formats=\"zip\"']))\n            elif format == 'gztar':\n                self.distributions.append(('sdist', ['--formats=\"gztar\"']))\n            elif format == 'egg':\n                self.distributions.append(('bdist', ['--formats=\"egg\"']))\n            elif format == 'wheel':\n                self.distributions.append(('bdist_wheel', []))\n\n        if not self.distributions:\n            self.distributions.append(('sdist', ['--formats=\"zip\"']))\n\n        if self.list:\n            self.list_locations()\n\n        if not self.locations:\n            self.locations.extend(self.locations.get_default_location())\n\n        if not (self.skipregister and self.skipupload):\n            if not (self.get_skipregister() and self.get_skipupload()):\n                self.locations.check_empty_locations()\n            self.locations.check_valid_locations()\n\n        if len(args) > 1:\n            if self.urlparser.is_url(self.directory):\n                self.branch = args[1]\n            elif self.urlparser.is_ssh_url(self.directory):\n                self.branch = args[1]\n            else:\n                err_exit('mkrelease: invalid arguments\\n%s' % USAGE)\n\n        if len(args) > 2:\n            err_exit('mkrelease: too many arguments\\n%s' % USAGE)", "response": "Process the command line."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the URL or sandbox to release.", "response": "def get_package(self):\n        \"\"\"Get the URL or sandbox to release.\n        \"\"\"\n        directory = self.directory\n        develop = self.develop\n        scmtype = self.scmtype\n\n        self.scm = self.scms.get_scm(scmtype, directory)\n\n        if self.scm.is_valid_url(directory):\n            directory = self.urlparser.abspath(directory)\n\n            self.remoteurl = directory\n            self.isremote = self.push = True\n        else:\n            directory = abspath(expanduser(directory))\n            self.isremote = False\n\n            self.scm.check_valid_sandbox(directory)\n            self.setuptools.check_valid_package(directory)\n\n            name, version = self.setuptools.get_package_info(directory, develop)\n            print('Releasing', name, version)\n\n            if not self.skipcommit:\n                if self.scm.is_dirty_sandbox(directory):\n                    self.scm.commit_sandbox(directory, name, version, self.push)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds and distribute the package.", "response": "def make_release(self):\n        \"\"\"Build and distribute the package.\n        \"\"\"\n        directory = self.directory\n        infoflags = self.infoflags\n        branch = self.branch\n        develop = self.develop\n        scmtype = self.scm.name\n\n        tempdir = abspath(tempfile.mkdtemp(prefix='mkrelease-'))\n        try:\n            if self.isremote:\n                directory = join(tempdir, 'build')\n                self.scm.clone_url(self.remoteurl, directory)\n            else:\n                directory = abspath(expanduser(directory))\n\n            self.scm.check_valid_sandbox(directory)\n\n            if self.isremote:\n                branch = self.scm.make_branchid(directory, branch)\n                if branch:\n                    self.scm.switch_branch(directory, branch)\n                if scmtype != 'svn':\n                    branch = self.scm.get_branch_from_sandbox(directory)\n                    print('Releasing branch', branch)\n\n            self.setuptools.check_valid_package(directory)\n\n            if not (self.skipcommit and self.skiptag):\n                self.scm.check_dirty_sandbox(directory)\n                self.scm.check_unclean_sandbox(directory)\n\n            name, version = self.setuptools.get_package_info(directory, develop)\n            if self.isremote:\n                print('Releasing', name, version)\n\n            if not self.skiptag:\n                print('Tagging', name, version)\n                tagid = self.scm.make_tagid(directory, version)\n                self.scm.check_tag_exists(directory, tagid)\n                self.scm.create_tag(directory, tagid, name, version, self.push)\n\n            if self.manifest:\n                scmtype = 'none'\n\n            for distcmd, distflags in self.distributions:\n                manifest = self.setuptools.run_egg_info(\n                    directory, infoflags, scmtype, self.quiet)\n                distfile = self.setuptools.run_dist(\n                    directory, infoflags, distcmd, distflags, scmtype, self.quiet)\n\n                for location in self.locations:\n                    if self.locations.is_server(location):\n                        if not self.get_skipregister(location):\n                            self.setuptools.run_register(\n                                directory, infoflags, location, scmtype, self.quiet)\n                        if not self.get_skipupload():\n                            uploadflags = self.get_uploadflags(location)\n                            if '--sign' in uploadflags and isfile(distfile+'.asc'):\n                                os.remove(distfile+'.asc')\n                            self.setuptools.run_upload(\n                                directory, infoflags, distcmd, distflags, location, uploadflags,\n                                scmtype, self.quiet)\n                    else:\n                        if not self.skipupload:\n                            if self.locations.is_ssh_url(location):\n                                scheme, location = self.urlparser.to_ssh_url(location)\n                                self.scp.run_upload(scheme, distfile, location)\n                            else:\n                                self.scp.run_upload('scp', distfile, location)\n        finally:\n            shutil.rmtree(tempdir)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure a Py4J JVM Virtual Machine.", "response": "def configure_gateway(\n            cls, launch_jvm: bool = True,\n            gateway: Union[GatewayParameters, Dict[str, Any]] = None,\n            callback_server: Union[CallbackServerParameters, Dict[str, Any]] = False,\n            javaopts: Iterable[str] = (), classpath: Iterable[str] = ''):\n        \"\"\"\n        Configure a Py4J gateway.\n\n        :param launch_jvm: ``True`` to spawn a Java Virtual Machine in a subprocess and connect to\n            it, ``False`` to connect to an existing Py4J enabled JVM\n        :param gateway: either a :class:`~py4j.java_gateway.GatewayParameters` object or a\n            dictionary of keyword arguments for it\n        :param callback_server: callback server parameters or a boolean indicating if a\n            callback server is wanted\n        :param javaopts: options passed to Java itself\n        :param classpath: path or iterable of paths to pass to the JVM launcher as the class path\n\n        \"\"\"\n        assert check_argument_types()\n        classpath = classpath if isinstance(classpath, str) else os.pathsep.join(classpath)\n        javaopts = list(javaopts)\n\n        # Substitute package names with their absolute directory paths\n        for match in package_re.finditer(classpath):\n            pkgname = match.group(1)\n            module = import_module(pkgname)\n            module_dir = os.path.dirname(module.__file__)\n            classpath = classpath.replace(match.group(0), module_dir)\n\n        if gateway is None:\n            gateway = {}\n        if isinstance(gateway, dict):\n            gateway.setdefault('eager_load', True)\n            gateway.setdefault('auto_convert', True)\n            gateway = GatewayParameters(**gateway)\n\n        if isinstance(callback_server, dict):\n            callback_server = CallbackServerParameters(**callback_server)\n        elif callback_server is True:\n            callback_server = CallbackServerParameters()\n\n        return launch_jvm, gateway, callback_server, classpath, javaopts"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self, filename, offset):\n        self.offset = offset\n        self.filename = filename\n\n        self.bootsector = BootSector(\n            filename=filename,\n            length=NTFS_BOOTSECTOR_SIZE,\n            offset=self.offset)\n\n        self.mft_table = MftTable(\n            mft_entry_size=self.bootsector.mft_record_size,\n            filename=self.filename,\n            offset=self.mft_table_offset\n        )\n\n        self.mft_table.preload_entries(NUM_SYSTEM_ENTRIES)\n\n        self._load_volume_information()", "response": "Loads the NTFS volume information from a file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the mft zone size in clusters.", "response": "def _get_mft_zone_size(self, num_clusters, mft_zone_multiplier=1):\n        \"\"\"Returns mft zone size in clusters.\n        From ntfs_progs.1.22.\"\"\"\n\n        sizes = {\n            4: num_clusters >> 1,           # 50%\n            3: (num_clusters * 3) >> 3,     # 37,5%\n            2: num_clusters >> 2,           # 25%\n        }\n\n        return sizes.get(mft_zone_multiplier, num_clusters >> 3)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef artist(self):\n        if not self._artist:\n            self._artist = Artist(self._artist_id, self._artist_name, self._connection)\n        return self._artist", "response": "Return an artist object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cover(self):\n        if not self._cover:\n            self._cover = Picture(self._cover_url, self._connection)\n        return self._cover", "response": "get album cover as Picture object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary with all album information.", "response": "def export(self):\n        \"\"\"\n        Returns a dictionary with all album information.\n        Use the :meth:`from_export` method to recreate the\n        :class:`Album` object.\n        \"\"\"\n        return {'id' : self.id, 'name' : self.name, 'artist' : self._artist_name, 'artist_id' : self._artist_id, 'cover' : self._cover_url}"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncloses all the iterators.", "response": "def close(self):\n        \"\"\"\n        Closes all the iterators.\n\n        This is particularly important if the iterators are files.\n        \"\"\"\n        if hasattr(self, 'iterators'):\n            for it in self.iterators:\n                if hasattr(it, 'close'):\n                    it.close()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _update_sorting(self):\n        key = self.key\n        sorted_tops = self.sorted_tops\n        tops = self.tops\n        iterators = self.iterators\n        for idx in self.idxs:\n            try:\n                tops[idx] = next(iterators[idx])\n                top_key = key(tops[idx])\n                if top_key not in sorted_tops:\n                    sorted_tops[top_key] = []\n                sorted_tops[top_key].append(idx)\n            except StopIteration:\n                pass\n        if len(sorted_tops) == 0:\n            raise StopIteration\n        key, self.idxs = sorted_tops.popitem(last=False)\n        self.c_idx = 0", "response": "Update the sorting of the entries in the merged iterator."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse(raw_email):\n    # type: (six.string_types) -> Tuple[six.string_types, six.string_types]\n    \"\"\"Extract email from a full address. Example:\n      'John Doe <jdoe+github@foo.com>' -> jdoe@foo.com\n\n    >>> parse(\"John Doe <me+github.com@someorg.com\")\n    ('me', 'someorg.com')\n    >>> parse(42)  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    InvalidEmail: 'Invalid email: 42'\n    >>> parse(None)  # doctest: +IGNORE_EXCEPTION_DETAIL\n    Traceback (most recent call last):\n        ...\n    InvalidEmail: 'None or NaN is not a valid email address'\n    \"\"\"\n    if not isinstance(raw_email, six.string_types):\n        raise InvalidEmail(\"Invalid email: %s\" % raw_email)\n    if not raw_email or pd.isnull(raw_email):\n        raise InvalidEmail(\"None or NaN is not a valid email address\")\n    email = raw_email.split(\"<\", 1)[-1].split(\">\", 1)[0]\n    chunks = email.split(\"@\", 3)\n    # git-svn generates emails with several @, e.g.:\n    # <rossberg@chromium.org@ce2b1a6d-e550-0410-aec6-3dcde31c8c00>\n    if len(chunks) < 2:\n        raise InvalidEmail(\"Invalid email\")\n    uname = chunks[0].rsplit(\" \", 1)[-1]\n    addr_domain = chunks[1].split(\" \", 1)[0]\n\n    return uname.split(\"+\", 1)[0], addr_domain", "response": "Parses a full email address into a tuple of the name and domain of the email."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef university_domains():\n    # type: () -> set\n    \"\"\" Return list of university domains outside of .edu TLD\n    NOTE: only 2nd level domain is returned, i.e. for aaa.bbb.uk only bbbl.uk\n          will be returned. This is necessary since many universities use\n          departmenntal domains, like cs.cmu.edu or andrew.cmu.edu\n    NOTE2: .edu domains are not included into this list as they're considered\n          belonging to universities by default.\n\n    How to get the original CSV:\n    ```python\n    x = requests.get(\n         \"https://raw.githubusercontent.com/Hipo/university-domains-list/\"\n         \"master/world_universities_and_domains.json\").json()\n    domains = set(ds for u in x\n                  for ds in u['domains'] if not \"edu\" in ds.rsplit(\".\", 2)[-2:])\n    domains = list(domains)\n    pd.Series(domains, index=domains, name=\"domain\"\n    ).drop(\n        [\"chat.ru\"]\n    ).to_csv(\"email_university_domains.csv\", index=False)\n    ```\n    \"\"\"\n    fpath = os.path.join(\n        os.path.dirname(__file__), \"email_university_domains.csv\")\n    with open(fpath) as fh:\n        return set(addr_domain.strip() for addr_domain in fh)", "response": "Return list of university domains outside of. edu TLD\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget number of distinct email addresses in observed domains", "response": "def domain_user_stats():\n    # type: () -> pd.Series\n    \"\"\" Get number of distinct email addresses in observed domains\n\n    TODO: get up to date with new projects layout\n    How to build email_domain_users.csv:\n\n    from collections import defaultdict\n    import logging\n    from common import utils as common\n    import stscraper as scraper\n\n    log = logging.getLogger(\"domain_user_stats\")\n    stats = defaultdict(set)\n    for ecosystem in common.ECOSYSTEMS:\n        urls = common.package_urls(ecosystem)\n        for package_name, url in urls.items():\n            log.info(package_name)\n            try:\n                cs = scraper.commits(url)\n            except scraper.RepoDoesNotExist:\n                continue\n            for email_addr in cs[\"author_email\"].dropna().unique():\n                if not email_addr or pd.isnull(email_addr):\n                    continue\n                try:\n                    user, email_domain = clean(email_addr).split(\"@\")\n                except InvalidEmail:\n                    continue\n                stats[email_domain].add(user)\n    s = pd.Series({dm: len(users) for dm, users in stats.items()})\n    s = s.rename(\"users\").sort_values(ascending=False)\n    s.to_csv(\"common/email_domain_users.csv\", encoding=\"utf8\", header=True)\n    return s\n    \"\"\"\n    fname = os.path.join(os.path.dirname(__file__), \"email_domain_users.csv\")\n    stats = pd.read_csv(fname, header=0, squeeze=True, index_col=0)\n    return stats[pd.notnull(stats.index)]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef commercial_domains():\n    # type: () -> set\n    \"\"\" Return list of commercial email domains, which means:\n    - domain is not public\n    - domain is not university\n    - it is not personal (more than 1 person using this domain)\n    >>> \"google.com\" in commercial_domains()\n    True\n    >>> \"microsoft.com\" in commercial_domains()\n    True\n    >>> \"isri.cs.cmu.edu\" in commercial_domains()  # university department\n    False\n    >>> \"jaraco.com\" in commercial_domains()  # personal\n    False\n    \"\"\"\n    dus = domain_user_stats()\n    es = \"test@\" + pd.Series(dus.index, index=dus.index)\n    return set(\n        dus[~is_public_bulk(es) & ~is_university_bulk(es) & (dus > 1)].index)", "response": "Return list of commercial email domains which means public university personal or more than one person using this domain"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef is_university(addr):\n    # type: (Union[str, unicode]) -> bool\n    \"\"\" Check if provided email has a university domain\n\n    - either in .edu domain\n        (except public sercices like england.edu or australia.edu)\n    - or in .edu.TLD (non-US based institutions, like edu.au)\n    - or listed in a public list of universities\n        since universities often have department addresses as well, only the end\n        is matched. E.g. cs.cmu.edu will match cmu.edu\n\n    :param addr: email address\n    :return: bool\n    >>> is_university(\"john@cmu.edu\")\n    True\n    >>> is_university(\"john@gmail.com\")\n    False\n    \"\"\"\n    addr_domain = domain(addr)\n    if not addr_domain:  # invalid email\n        return False\n    chunks = addr_domain.split(\".\")\n    if len(chunks) < 2:  # local or invalid address\n        return False\n\n    domains = university_domains()\n    # many universitites have departmental emails, such as cs.cmu.edu. However,\n    # the original dataset only has top level domain (cmu.edu). So, what we need\n    # to do is to strip leading subdomains until match or nothing to strip:\n    # isri.cs.cmu.edu (no match) -> cs.cmu.edu (no match) -> cmu.edu (match)\n    return (chunks[-1] == \"edu\" and chunks[-2] not in (\"england\", \"australia\"))\\\n        or chunks[-2] == \"edu\" \\\n        or any(\".\".join(chunks[i:]) in domains for i in range(len(chunks)-1))", "response": "Checks if given email address is a university domain."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_public(addr):\n    # type: (Union[str, unicode]) -> bool\n    \"\"\" Check if the passed email registered at a free pubic mail server\n\n    :param addr: email address to check\n    :return: bool\n    >>> is_public(\"john@cmu.edu\")\n    False\n    >>> is_public(\"john@gmail.com\")\n    True\n    \"\"\"\n    addr_domain = domain(addr)\n    if not addr_domain:\n        # anybody can use invalid email\n        return True\n    chunks = addr_domain.rsplit(\".\", 1)\n\n    return len(chunks) < 2 \\\n        or addr_domain.endswith(\"local\") \\\n        or addr_domain in public_domains()", "response": "Checks if the passed email address is a public one."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove or query the window cursor.", "response": "def pos(self, x=None, y=None):\r\n        u'''Move or query the window cursor.'''\r\n        if x is not None:\r\n            System.Console.CursorLeft=x\r\n        else:\r\n            x = System.Console.CursorLeft\r\n        if y is not None:\r\n            System.Console.CursorTop=y\r\n        else:\r\n            y = System.Console.CursorTop\r\n        return x, y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_color(self, text, attr=None):\r\n        '''write text at current cursor position and interpret color escapes.\r\n\r\n        return the number of characters written.\r\n        '''\r\n        log(u'write_color(\"%s\", %s)' % (text, attr))\r\n        chunks = self.terminal_escape.split(text)\r\n        log(u'chunks=%s' % repr(chunks))\r\n        bg = self.savebg\r\n        n = 0 # count the characters we actually write, omitting the escapes\r\n        if attr is None:#use attribute from initial console\r\n            attr = self.attr\r\n        try:\r\n            fg = self.trtable[(0x000f&attr)]\r\n            bg = self.trtable[(0x00f0&attr)>>4]\r\n        except TypeError:\r\n            fg = attr\r\n            \r\n        for chunk in chunks:\r\n            m = self.escape_parts.match(chunk)\r\n            if m:\r\n                log(m.group(1))\r\n                attr = ansicolor.get(m.group(1), self.attr)\r\n            n += len(chunk)\r\n            System.Console.ForegroundColor = fg\r\n            System.Console.BackgroundColor = bg\r\n            System.Console.Write(chunk)\r\n        return n", "response": "write text at current cursor position and interpret color escapes. Returns the number of characters written."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_plain(self, text, attr=None):\r\n        u'''write text at current cursor position.'''\r\n        log(u'write(\"%s\", %s)' %(text, attr))\r\n        if attr is None:\r\n            attr = self.attr\r\n        n = c_int(0)\r\n        self.SetConsoleTextAttribute(self.hout, attr)\r\n        self.WriteConsoleA(self.hout, text, len(text), byref(n), None)\r\n        return len(text)", "response": "write text at current cursor position."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite text at the given position.", "response": "def text(self, x, y, text, attr=None):\r\n        u'''Write text at the given position.'''\r\n        self.pos(x, y)\r\n        self.write_color(text, attr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfills the screen with the specified rectangle.", "response": "def rectangle(self, rect, attr=None, fill=u' '):\r\n        u'''Fill Rectangle.'''\r\n        oldtop = self.WindowTop\r\n        oldpos = self.pos()\r\n        #raise NotImplementedError\r\n        x0, y0, x1, y1 = rect\r\n        if attr is None:\r\n            attr = self.attr\r\n        if fill:\r\n            rowfill = fill[:1] * abs(x1 - x0)\r\n        else:\r\n            rowfill = u' ' * abs(x1 - x0)\r\n        for y in range(y0, y1):\r\n                System.Console.SetCursorPosition(x0, y)\r\n                self.write_color(rowfill, attr)\r\n        self.pos(*oldpos)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scroll_window(self, lines):\r\n        u'''Scroll the window by the indicated number of lines.'''\r\n        top = self.WindowTop + lines\r\n        if top < 0:\r\n            top = 0\r\n        if top + System.Console.WindowHeight > System.Console.BufferHeight:\r\n            top = System.Console.BufferHeight\r\n        self.WindowTop = top", "response": "Scroll the window by the indicated number of lines."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getkeypress(self):\r\n        u'''Return next key press event from the queue, ignoring others.'''\r\n        ck = System.ConsoleKey\r\n        while 1:\r\n            e = System.Console.ReadKey(True)\r\n            if e.Key == System.ConsoleKey.PageDown: #PageDown\r\n                self.scroll_window(12)\r\n            elif e.Key == System.ConsoleKey.PageUp:#PageUp\r\n                self.scroll_window(-12)\r\n            elif str(e.KeyChar) == u\"\\000\":#Drop deadkeys\r\n                log(u\"Deadkey: %s\"%e)\r\n                return event(self, e)\r\n            else:\r\n                return event(self, e)", "response": "Return next key press event from the queue ignoring others."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the title of the user.", "response": "def title(self, txt=None):\r\n        u'''Set/get title.'''\r\n        if txt:\r\n            System.Console.Title = txt\r\n        else:\r\n            return System.Console.Title"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef size(self, width=None, height=None):\r\n        u'''Set/get window size.'''\r\n        sc = System.Console\r\n        if width is not None and height is not None:\r\n            sc.BufferWidth, sc.BufferHeight = width,height\r\n        else:\r\n            return sc.BufferWidth, sc.BufferHeight\r\n\r\n        if width is not None and height is not None:\r\n            sc.WindowWidth, sc.WindowHeight = width,height\r\n        else:\r\n            return sc.WindowWidth - 1, sc.WindowHeight - 1", "response": "u'''Set / get window size. u'''Set / get buffer size. u'''Set / get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''Set/get window size. u'''"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef files(self):\n        if self._files is None:\n            self._files = SeriesZipTifHolo._index_files(self.path)\n        return self._files", "response": "List of hologram data file names in the input zip file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_time(self, idx):\n        # first try to get the time from the TIFF file\n        # (possible meta data keywords)\n        ds = self._get_dataset(idx)\n        thetime = ds.get_time()\n        if np.isnan(thetime):\n            # use zipfile date_time\n            zf = zipfile.ZipFile(self.path)\n            info = zf.getinfo(self.files[idx])\n            timetuple = tuple(list(info.date_time) + [0, 0, 0])\n            thetime = time.mktime(timetuple)\n        return thetime", "response": "Time for each TIFF file in the archive"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_user_variable(input_dict, environment_dict):\n  # Iterates through the dictionary to retrieve the variable name\n  command_key = input_dict.keys()[0]\n  while input_dict[command_key]['name'] is not 'variable_name':\n    input_dict = input_dict[command_key]['children']\n    variable_name = command_key = input_dict.keys()[0]\n\n  # User may accidentally omit this value, we must catch the exception and\n  # return something readable...\n  try:\n    # Iterates through the dictionary to retrieve the variable value\n    while input_dict[command_key]['name'] is not 'variable_value':\n      input_dict = input_dict[command_key]['children']\n      variable_value = command_key = input_dict.keys()[0]\n  except IndexError, e:\n    raise seash_exceptions.UserError(\"Error, expected a value to assign to variable\")\n\n  uservariables[variable_name] = variable_value.strip()", "response": "This function is used to set a user variable in the Seash dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nprint the user defined variables.", "response": "def show_user_variables(input_dict, environment_dict):\n  \"\"\"\n  <Purpose>\n    Seash callback to allow user to check all variables that they defined.\n  <Arguments>\n    input_dict: Input dictionary generated by seash_dictionary.parse_command().\n    environment_dict: Dictionary describing the current seash environment.\n    \n    For more information, see command_callbacks.py's module docstring.\n  <Side Effects>\n    All the variables currently defined will be printed alongside their values.\n  <Exceptions>\n    None\n  <Return>\n    None\n  \"\"\"\n  for variable, value in uservariables.iteritems():\n    print variable+\": '\"+value+\"'\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef autocomplete(input_list):\n  # We are only interested if the last token starts with a single '$'\n  # Double $$'s indicate that it is meant to be a '$', so we don't do anything.\n  if input_list[-1].startswith('$') and not input_list[-1].startswith('$$'):\n    # Omit the '$'\n    partial_variable = input_list[-1][1:]\n    commands = []\n\n    for variable in uservariables:\n      # No need to include variables that don't match...\n      if variable.startswith(partial_variable):\n        # Reconstruct the string\n        tokens = input_list[:-1] + ['$'+variable]\n        commands.append(' '.join(tokens))\n    return commands\n  return []", "response": "A function that returns all valid input completions for the specified command line input."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_remote_data(self, localvars, remotevars, inds, shape):\n        # If user specifies 'all' then entire xy domain is\n        # grabbed, default is 4, specified in the model_controller\n        if self.horiz_size == 'all':\n            y, y_1 = 0, shape[-2]\n            x, x_1 = 0, shape[-1]\n        else:\n            r = self.horiz_size\n            x, x_1 = self.point_get.value[2]-r, self.point_get.value[2]+r+1\n            y, y_1 = self.point_get.value[1]-r, self.point_get.value[1]+r+1\n            x, x_1 = x[0], x_1[0]\n            y, y_1 = y[0], y_1[0]\n            if y < 0:\n                y = 0\n            if x < 0:\n                x = 0\n            if y_1 > shape[-2]:\n                y_1 = shape[-2]\n            if x_1 > shape[-1]:\n                x_1 = shape[-1]\n\n        # Update domain variable for where we will add data\n        domain = self.local.variables['domain']\n\n        if len(shape) == 4:\n            domain[inds[0]:inds[-1]+1, 0:shape[1], y:y_1, x:x_1] = np.ones((inds[-1]+1-inds[0], shape[1], y_1-y, x_1-x))\n        elif len(shape) == 3:\n            domain[inds[0]:inds[-1]+1, y:y_1, x:x_1] = np.ones((inds[-1]+1-inds[0], y_1-y, x_1-x))\n\n        # Update the local variables with remote data\n        logger.debug(\"Filling cache with: Time - %s:%s, Lat - %s:%s, Lon - %s:%s\" % (str(inds[0]), str(inds[-1]+1), str(y), str(y_1), str(x), str(x_1)))\n        for local, remote in zip(localvars, remotevars):\n            if len(shape) == 4:\n                local[inds[0]:inds[-1]+1, 0:shape[1], y:y_1, x:x_1] = remote[inds[0]:inds[-1]+1,  0:shape[1], y:y_1, x:x_1]\n            else:\n                local[inds[0]:inds[-1]+1, y:y_1, x:x_1] = remote[inds[0]:inds[-1]+1, y:y_1, x:x_1]", "response": "Method that will update local netcdf cache with remote data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef need_data(self, i):\n\n        # If we are not caching, we always grab data from the raw source\n        if self.caching is False:\n            return False\n\n        logger.debug(\"Checking cache for data availability at %s.\" % self.part.location.logstring())\n\n        try:\n            # Tell the DataController that we are going to be reading from the file\n            with self.read_lock:\n                self.read_count.value += 1\n                self.has_read_lock.append(os.getpid())\n\n            self.dataset.opennc()\n            # Test if the cache has the data we need\n            # If the point we request contains fill values,\n            # we need data\n            cached_lookup = self.dataset.get_values('domain', timeinds=[np.asarray([i])], point=self.part.location)\n            logger.debug(\"Type of result: %s\" % type(cached_lookup))\n            logger.debug(\"Double mean of result: %s\" % np.mean(np.mean(cached_lookup)))\n            logger.debug(\"Type of Double mean of result: %s\" % type(np.mean(np.mean(cached_lookup))))\n            if type(np.mean(np.mean(cached_lookup))) == np.ma.core.MaskedConstant:\n                need = True\n                logger.debug(\"I NEED data.  Got back: %s\" % cached_lookup)\n            else:\n                need = False\n                logger.debug(\"I DO NOT NEED data\")\n        except StandardError:\n            # If the time index doesnt even exist, we need\n            need = True\n            logger.debug(\"I NEED data (no time index exists in cache)\")\n        finally:\n            self.dataset.closenc()\n            with self.read_lock:\n                self.read_count.value -= 1\n                self.has_read_lock.remove(os.getpid())\n\n        return need", "response": "Test if the data that we need for the given time index is in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef data_interp(self, i, currenttime):\n        if self.active.value is True:\n            while self.get_data.value is True:\n                logger.debug(\"Waiting for DataController to release cache file so I can read from it...\")\n                timer.sleep(2)\n                pass\n\n        if self.need_data(i+1):\n            # Acquire lock for asking for data\n            self.data_request_lock.acquire()\n            self.has_data_request_lock.value = os.getpid()\n            try:\n                # Do I still need data?\n                if self.need_data(i+1):\n\n                    # Tell the DataController that we are going to be reading from the file\n                    with self.read_lock:\n                        self.read_count.value += 1\n                        self.has_read_lock.append(os.getpid())\n\n                    # Open netcdf file on disk from commondataset\n                    self.dataset.opennc()\n                    # Get the indices for the current particle location\n                    indices = self.dataset.get_indices('u', timeinds=[np.asarray([i-1])], point=self.part.location )\n                    self.dataset.closenc()\n\n                    with self.read_lock:\n                        self.read_count.value -= 1\n                        self.has_read_lock.remove(os.getpid())\n\n                    # Override the time\n                    # get the current time index data\n                    self.point_get.value = [indices[0] + 1, indices[-2], indices[-1]]\n                    # Request that the data controller update the cache\n                    self.get_data.value = True\n                    # Wait until the data controller is done\n                    if self.active.value is True:\n                        while self.get_data.value is True:\n                            logger.debug(\"Waiting for DataController to update cache with the CURRENT time index\")\n                            timer.sleep(2)\n                            pass\n\n                    # Do we still need to get the next timestep?\n                    if self.need_data(i+1):\n                        # get the next time index data\n                        self.point_get.value = [indices[0] + 2, indices[-2], indices[-1]]\n                        # Request that the data controller update the cache\n                        self.get_data.value = True\n                        # Wait until the data controller is done\n                        if self.active.value is True:\n                            while self.get_data.value is True:\n                                logger.debug(\"Waiting for DataController to update cache with the NEXT time index\")\n                                timer.sleep(2)\n                                pass\n            except StandardError:\n                logger.warn(\"Particle failed to request data correctly\")\n                raise\n            finally:\n                # Release lock for asking for data\n                self.has_data_request_lock.value = -1\n                self.data_request_lock.release()\n\n        if self.caching is True:\n            # Tell the DataController that we are going to be reading from the file\n            with self.read_lock:\n                self.read_count.value += 1\n                self.has_read_lock.append(os.getpid())\n\n        try:\n            # Open the Cache netCDF file on disk\n            self.dataset.opennc()\n\n            # Grab data at time index closest to particle location\n            u = [np.mean(np.mean(self.dataset.get_values('u', timeinds=[np.asarray([i])], point=self.part.location ))),\n                 np.mean(np.mean(self.dataset.get_values('u', timeinds=[np.asarray([i+1])], point=self.part.location )))]\n            v = [np.mean(np.mean(self.dataset.get_values('v', timeinds=[np.asarray([i])], point=self.part.location ))),\n                 np.mean(np.mean(self.dataset.get_values('v', timeinds=[np.asarray([i+1])], point=self.part.location )))]\n            # if there is vertical velocity inthe dataset, get it\n            if 'w' in self.dataset.nc.variables:\n                w = [np.mean(np.mean(self.dataset.get_values('w', timeinds=[np.asarray([i])], point=self.part.location ))),\n                     np.mean(np.mean(self.dataset.get_values('w', timeinds=[np.asarray([i+1])], point=self.part.location )))]\n            else:\n                w = [0.0, 0.0]\n            # If there is salt and temp in the dataset, get it\n            if self.temp_name is not None and self.salt_name is not None:\n                temp = [np.mean(np.mean(self.dataset.get_values('temp', timeinds=[np.asarray([i])], point=self.part.location ))),\n                        np.mean(np.mean(self.dataset.get_values('temp', timeinds=[np.asarray([i+1])], point=self.part.location )))]\n                salt = [np.mean(np.mean(self.dataset.get_values('salt', timeinds=[np.asarray([i])], point=self.part.location ))),\n                        np.mean(np.mean(self.dataset.get_values('salt', timeinds=[np.asarray([i+1])], point=self.part.location )))]\n\n            # Check for nans that occur in the ocean (happens because\n            # of model and coastline resolution mismatches)\n            if np.isnan(u).any() or np.isnan(v).any() or np.isnan(w).any():\n                # Take the mean of the closest 4 points\n                # If this includes nan which it will, result is nan\n                uarray1 = self.dataset.get_values('u', timeinds=[np.asarray([i])], point=self.part.location, num=2)\n                varray1 = self.dataset.get_values('v', timeinds=[np.asarray([i])], point=self.part.location, num=2)\n                uarray2 = self.dataset.get_values('u', timeinds=[np.asarray([i+1])], point=self.part.location, num=2)\n                varray2 = self.dataset.get_values('v', timeinds=[np.asarray([i+1])], point=self.part.location, num=2)\n                if 'w' in self.dataset.nc.variables:\n                    warray1 = self.dataset.get_values('w', timeinds=[np.asarray([i])], point=self.part.location, num=2)\n                    warray2 = self.dataset.get_values('w', timeinds=[np.asarray([i+1])], point=self.part.location, num=2)\n                    w = [warray1.mean(), warray2.mean()]\n                else:\n                    w = [0.0, 0.0]\n\n                if self.temp_name is not None and self.salt_name is not None:\n                    temparray1 = self.dataset.get_values('temp', timeinds=[np.asarray([i])], point=self.part.location, num=2)\n                    saltarray1 = self.dataset.get_values('salt', timeinds=[np.asarray([i])], point=self.part.location, num=2)\n                    temparray2 = self.dataset.get_values('temp', timeinds=[np.asarray([i+1])], point=self.part.location, num=2)\n                    saltarray2 = self.dataset.get_values('salt', timeinds=[np.asarray([i+1])], point=self.part.location, num=2)\n                    temp = [temparray1.mean(), temparray2.mean()]\n                    salt = [saltarray1.mean(), saltarray2.mean()]\n                u = [uarray1.mean(), uarray2.mean()]\n                v = [varray1.mean(), varray2.mean()]\n\n            # Linear interp of data between timesteps\n            currenttime = date2num(currenttime)\n            timevar = self.timevar.datenum\n            u = self.linterp(timevar[i:i+2], u, currenttime)\n            v = self.linterp(timevar[i:i+2], v, currenttime)\n            w = self.linterp(timevar[i:i+2], w, currenttime)\n            if self.temp_name is not None and self.salt_name is not None:\n                temp = self.linterp(timevar[i:i+2], temp, currenttime)\n                salt = self.linterp(timevar[i:i+2], salt, currenttime)\n\n            if self.temp_name is None:\n                temp = np.nan\n            if self.salt_name is None:\n                salt = np.nan\n\n        except StandardError:\n            logger.error(\"Error in data_interp method on ForceParticle\")\n            raise\n        finally:\n            # If caching is False, we don't have to close the dataset.  We can stay in read-only mode.\n            if self.caching is True:\n                self.dataset.closenc()\n                with self.read_lock:\n                    self.read_count.value -= 1\n                    self.has_read_lock.remove(os.getpid())\n\n        return u, v, w, temp, salt", "response": "This method is used to streamline data from a specific particle in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef boundary_interaction(self, **kwargs):\n        particle = kwargs.pop('particle')\n        starting = kwargs.pop('starting')\n        ending = kwargs.pop('ending')\n\n        # shoreline\n        if self.useshore:\n            intersection_point = self._shoreline.intersect(start_point=starting.point, end_point=ending.point)\n            if intersection_point:\n                # Set the intersection point.\n                hitpoint = Location4D(point=intersection_point['point'], time=starting.time + (ending.time - starting.time))\n                particle.location = hitpoint\n\n                # This relies on the shoreline to put the particle in water and not on shore.\n                resulting_point = self._shoreline.react(start_point=starting,\n                                                        end_point=ending,\n                                                        hit_point=hitpoint,\n                                                        reverse_distance=self.reverse_distance,\n                                                        feature=intersection_point['feature'],\n                                                        distance=kwargs.get('distance'),\n                                                        angle=kwargs.get('angle'),\n                                                        azimuth=kwargs.get('azimuth'),\n                                                        reverse_azimuth=kwargs.get('reverse_azimuth'))\n                ending.latitude = resulting_point.latitude\n                ending.longitude = resulting_point.longitude\n                ending.depth = resulting_point.depth\n                logger.debug(\"%s - hit the shoreline at %s.  Setting location to %s.\" % (particle.logstring(), hitpoint.logstring(),  ending.logstring()))\n\n        # bathymetry\n        if self.usebathy:\n            if not particle.settled:\n                bintersect = self._bathymetry.intersect(start_point=starting, end_point=ending)\n                if bintersect:\n                    pt = self._bathymetry.react(type='reverse', start_point=starting, end_point=ending)\n                    logger.debug(\"%s - hit the bottom at %s.  Setting location to %s.\" % (particle.logstring(), ending.logstring(), pt.logstring()))\n                    ending.latitude = pt.latitude\n                    ending.longitude = pt.longitude\n                    ending.depth = pt.depth\n\n        # sea-surface\n        if self.usesurface:\n            if ending.depth > 0:\n                logger.debug(\"%s - rose out of the water.  Setting depth to 0.\" % particle.logstring())\n                ending.depth = 0\n\n        particle.location = ending\n        return", "response": "Returns a list of Location4D objects representing the boundary of the given particle."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the path to the build file that should be downloaded.", "response": "def get_buildfile_path(settings):\n    \"\"\"\n    Path to which a build tarball should be downloaded.\n    \"\"\"\n    base = os.path.basename(settings.build_url)\n    return os.path.join(BUILDS_ROOT, base)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef prior_dates(*args, **kwargs):\n        try:\n            chron = args[0]\n        except IndexError:\n            chron = kwargs['coredates']\n\n        d_r = np.array(kwargs['d_r'])\n        d_std = np.array(kwargs['d_std'])\n        t_a = np.array(kwargs['t_a'])\n        t_b = np.array(kwargs['t_b'])\n\n        try:\n            normal_distr = kwargs['normal_distr']\n        except KeyError:\n            normal_distr = None\n\n        cc_int = kwargs['cc']\n\n        ccdict = {0: 'ConstCal', 1: 'IntCal3', 2: 'Marine13',\n                  3: 'SHCal13', 4: 'ConstCal'}\n        # There is a better way to do this.\n        if 'cc1' in kwargs:\n            ccdict[1] = str(kwargs['cc1'])\n        if 'cc2' in kwargs:\n            ccdict[2] = str(kwargs['cc2'])\n        if 'cc3' in kwargs:\n            ccdict[3] = str(kwargs['cc3'])\n        if 'cc4' in kwargs:\n            ccdict[4] = str(kwargs['cc4'])\n\n        cc = []\n        for i in cc_int:\n            i = int(i)\n            cc.append(fetch_calibcurve(ccdict[i]))\n\n        d, p = calibrate_dates(chron, calib_curve=cc, d_r=d_r, d_std=d_std,\n                               t_a=t_a, t_b=t_b, normal_distr=normal_distr)\n        return d, p", "response": "Get the prior distribution of calibrated radiocarbon dates"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prior_sediment_rate(*args, **kwargs):\n        # PlotAccPrior @ Bacon.R ln 113 -> ln 1097-1115\n        # alpha = acc_shape, beta = acc_shape / acc_mean\n        # TODO(brews): Check that these stats are correctly translated to scipy.stats distribs.\n        acc_mean = kwargs['acc_mean']\n        acc_shape = kwargs['acc_shape']\n        x = np.linspace(0, 6 * np.max(acc_mean), 100)\n        y = stats.gamma.pdf(x, a=acc_shape,\n                            scale=1 / (acc_shape/acc_mean))\n        return y, x", "response": "Get the prior density of sediment rates for a specific set of sediment products."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prior_sediment_memory(*args, **kwargs):\n        # \"plot the prior for the memory (= accumulation rate varibility between neighbouring depths)\"\n        # PlotMemPrior @ Bacon.R ln 114 -> ln 1119 - 1141\n        # w_a = mem_strength * mem_mean, w_b = mem_strength * (1 - mem_mean)\n        # TODO(brews): Check that these stats are correctly translated to scipy.stats distribs.\n        mem_shape = kwargs['mem_strength']  # aka. `mem_shape`\n        mem_mean = kwargs['mem_mean']\n        x = np.linspace(0, 1, 100)\n        y = stats.beta.pdf(x, a=mem_shape * mem_mean,\n                           b=mem_shape * (1 - mem_mean))\n        return y, x", "response": "Get the prior density of sediment memory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _init_browser(self):\n        self.browser = splinter.Browser('phantomjs')\n        self.browser.visit(self.server_url)\n        self.browser.find_link_by_partial_text(\"Sign in\").click()\n        self.browser.fill(\n            'ctl00$ctl00$NICEMasterPageBodyContent$SiteContentPlaceholder$'\n            'txtFormsLogin', self.user)\n        self.browser.fill(\n            'ctl00$ctl00$NICEMasterPageBodyContent$SiteContentPlaceholder$'\n            'txtFormsPassword', self.password)\n        self.browser.find_by_css('input[type=submit]').click()\n        self.browser.find_by_css('input[type=submit]').click()", "response": "Update this everytime the CERN SSO login form is refactored."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef album(self):\n        if not self._album:\n            self._album = Album(self._album_id, self._album_name,\n                                self._artist_id, self._artist_name,\n                                self._cover_url, self._connection)\n        return self._album", "response": "get the Album object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new Stream object for this song.", "response": "def stream(self):\n        \"\"\"\n        :class:`Stream` object for playing\n        \"\"\"\n        # Add song to queue\n        self._connection.request(\n            'addSongsToQueue',\n            {'songIDsArtistIDs': [{'artistID': self.artist.id,\n                                   'source': 'user',\n                                   'songID': self.id,\n                                   'songQueueSongID': 1}],\n             'songQueueID': self._connection.session.queue},\n            self._connection.header('addSongsToQueue', 'jsqueue'))\n\n        stream_info = self._connection.request(\n            'getStreamKeyFromSongIDEx',\n            {'songID': self.id, 'country': self._connection.session.country,\n             'prefetch': False, 'mobile': False},\n            self._connection.header('getStreamKeyFromSongIDEx', 'jsqueue'))[1]\n        return Stream(stream_info['ip'], stream_info['streamKey'],\n                      self._connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef export(self):\n        return {'id': self.id, 'name': self.name, 'artist': self._artist_name,\n                'artist_id': self._artist_id, 'album': self._album_name,\n                'album_id': self._album_id, 'track': self.track,\n                'duration': self.duration, 'popularity': self.popularity,\n                'cover': self._cover_url}", "response": "Returns a dictionary with all song information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nformat the song according to certain patterns", "response": "def format(self, pattern):\n        \"\"\"\n        Format the song according to certain patterns:\n\n        %a: artist title\n        %s: song title\n        %A: album title\n        \"\"\"\n        pattern = pattern.replace('%a', self.artist.name)\n        pattern = pattern.replace('%s', self.name)\n        pattern = pattern.replace('%A', self.album.name)\n        return pattern.replace('/', '') \\\n                      .replace('\\\\', '') \\\n                      .replace(\":\", \"\") \\\n                      .replace(\"*\", \"\") \\\n                      .replace(\"?\", \"\") \\\n                      .replace('\"', \"\") \\\n                      .replace(\"|\", \"\") \\\n                      .replace(\"<\", \"\") \\\n                      .replace(\">\", \"\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef download(self, directory='~/Music', song_name='%a - %s - %A'):\n        formatted = self.format(song_name)\n        path = os.path.expanduser(directory) + os.path.sep + formatted + '.mp3'\n        try:\n            raw = self.safe_download()\n            with open(path, 'wb') as f:\n                f.write(raw)\n        except:\n            raise\n        return formatted", "response": "Download a song to a directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_download(self):\n        def _markStreamKeyOver30Seconds(stream):\n            self._connection.request(\n                'markStreamKeyOver30Seconds',\n                {'streamServerID': stream.ip,\n                 'artistID': self.artist.id,\n                 'songQueueID': self._connection.session.queue,\n                 'songID': self.id,\n                 'songQueueSongID': 1,\n                 'streamKey': stream.key},\n                self._connection.header('markStreamKeyOver30Seconds', 'jsqueue'))\n\n        stream = self.stream\n        timer = threading.Timer(30, _markStreamKeyOver30Seconds, [stream])\n        timer.start()\n        raw = stream.data.read()\n        if len(raw) == stream.size:\n            timer.cancel()\n            self._connection.request(\n                'markSongDownloadedEx',\n                {'streamServerID': stream.ip,\n                 'songID': self.id,\n                 'streamKey': stream.key},\n                self._connection.header('markSongDownloadedEx', 'jsqueue'))\n            self._connection.request(\n                'removeSongsFromQueue',\n                {'userRemoved': True,\n                 'songQueueID': self._connection.session.queue,\n                 'songQueueSongIDs': [1]},\n                self._connection.header('removeSongsFromQueue', 'jsqueue'))\n            return raw\n        else:\n            raise ValueError(\"Content-Length {}, but read {}\"\n                             .format(stream.size, len(raw)))", "response": "Download a song respecting Grooveshark s API."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a copy of this configuration.", "response": "def copy(self):\n        \"\"\"\n        Return a copy of this configuration.\n        \"\"\"\n        return self.__class__(options=self.__options,\n                              attribute_options=self.__attribute_options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_option(self, name):\n        self.__validate_option_name(name)\n        return self.__options.get(name, None)", "response": "Returns the value for the specified generic configuration option."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_option(self, name, value):\n        self.__validate_option_name(name)\n        self.__options[name] = value", "response": "Sets the specified generic configuration option to the given value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_attribute_option(self, attribute, option_name, option_value):\n        self.__validate_attribute_option_name(option_name)\n        attribute_key = self.__make_key(attribute)\n        mp_options = self.__attribute_options.setdefault(attribute_key, {})\n        mp_options[option_name] = option_value", "response": "Sets the given attribute option to the given value for the specified attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value of the given attribute option for the specified attribute.", "response": "def get_attribute_option(self, attribute, option_name):\n        \"\"\"\n        Returns the value of the given attribute option for the specified\n        attribute.\n        \"\"\"\n        self.__validate_attribute_option_name(option_name)\n        attribute_key = self.__make_key(attribute)\n        return self.__attribute_options[attribute_key].get(option_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dictionary of mapping options for the given attribute name.", "response": "def get_attribute_options(self, attribute=None):\n        \"\"\"\n        Returns a copy of the mapping options for the given attribute name\n        or a copy of all mapping options, if no attribute name is provided.\n        All options that were not explicitly configured are given a default\n        value of `None`.\n\n        :param tuple attribute_key: attribute name or tuple specifying an\n          attribute path.\n        :returns: mapping options dictionary (including default `None` values)\n        \"\"\"\n        attribute_key = self.__make_key(attribute)\n        if attribute_key is None:\n            opts = defaultdict(self._default_attributes_options.copy)\n            for attr, mp_options in iteritems_(self.__attribute_options):\n                opts[attr].update(mp_options)\n        else:\n            opts = self._default_attributes_options.copy()\n            attr_opts = self.__attribute_options[attribute_key]\n            opts.update(attr_opts)\n        return opts"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef run(self, visitor):\n        attr_option_map = self.__config.get_attribute_options()\n        # Sorting the keys results in a depth-first traversal, which is just\n        # what we want.\n        for (key, key_attr_option_map) in sorted(iteritems_(attr_option_map)):\n            if not self.__max_depth is None and len(key) > self.__max_depth:\n                continue\n            visitor.visit(key, key_attr_option_map)", "response": "Traverses this representer configuration traverser with the given visitor."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrap the given list of methods in a class with exponential - backretry mechanism.", "response": "def with_retry(cls, methods):\n    \"\"\"\n    Wraps the given list of methods in a class with an exponential-back\n    retry mechanism.\n    \"\"\"\n    retry_with_backoff = retry(\n        retry_on_exception=lambda e: isinstance(e, BotoServerError),\n        wait_exponential_multiplier=1000,\n        wait_exponential_max=10000\n    )\n    for method in methods:\n        m = getattr(cls, method, None)\n        if isinstance(m, collections.Callable):\n            setattr(cls, method, retry_with_backoff(m))\n    return cls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef string(value) -> str:\r\n        return system_json.dumps(Json(value).safe_object(), ensure_ascii=False)", "response": "string dict object value to JSON"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a JSON string to dict or object", "response": "def parse(string, is_file=False, obj=False):\r\n        \"\"\" Convert a JSON string to dict/object \"\"\"\r\n        try:\r\n            if obj is False:\r\n                if is_file:\r\n                    return system_json.load(string)\r\n                return system_json.loads(string, encoding='utf8')\r\n            else:\r\n                if is_file:\r\n                    return system_json.load(\r\n                        string,\r\n                        object_hook=lambda d: namedtuple('j', d.keys())\r\n                        (*d.values()), ensure_ascii=False, encoding='utf8')\r\n                return system_json.loads(\r\n                    string,\r\n                    object_hook=lambda d: namedtuple('j', d.keys())\r\n                    (*d.values()), encoding='utf8')\r\n        except (Exception, BaseException) as error:\r\n            try:\r\n                if current_app.config['DEBUG']:\r\n                    raise error\r\n            except RuntimeError as flask_error:\r\n                raise error\r\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_file(file_path) -> dict:\r\n        with io.open(file_path, 'r', encoding='utf-8') as json_stream:\r\n            return Json.parse(json_stream, True)", "response": "Load the base class from a JSON file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef safe_values(self, value):\r\n        # TODO: override-able?\r\n        string_val = \"\"\r\n        if isinstance(value, datetime.date):\r\n            try:\r\n                string_val = value.strftime('{0}{1}{2}'.format(\r\n                    current_app.config['DATETIME']['DATE_FORMAT'],\r\n                    current_app.config['DATETIME']['SEPARATOR'],\r\n                    current_app.config['DATETIME']['TIME_FORMAT']))\r\n            except RuntimeError as error:\r\n                string_val = value.strftime('%Y-%m-%d %H:%M:%S')\r\n        elif isinstance(value, bytes):\r\n            string_val = value.decode('utf-8')\r\n        elif isinstance(value, decimal.Decimal):\r\n            string_val = float(value)\r\n        else:\r\n            string_val = value\r\n        return string_val", "response": "Parse non - string values that will not serialize"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef camel_case(self, snake_case):\r\n        components = snake_case.split('_')\r\n        return components[0] + \"\".join(x.title() for x in components[1:])", "response": "Convert snake case to camel case"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting object to flattened object", "response": "def __find_object_children(self, obj) -> dict:\r\n        \"\"\" Convert object to flattened object \"\"\"\r\n        if hasattr(obj, 'items') and \\\r\n                isinstance(obj.items, types.BuiltinFunctionType):\r\n            return self.__construct_object(obj)\r\n        elif isinstance(obj, (list, tuple, set)):\r\n            return self.__construct_list(obj)\r\n        else:\r\n            exclude_list = []\r\n            if hasattr(obj, '_sa_instance_state'):\r\n                # load only deferred objects\r\n                if len(orm.attributes.instance_state(obj).unloaded) > 0:\r\n                    mapper = inspect(obj)\r\n                    for column in mapper.attrs:\r\n                        column.key\r\n                        column.value\r\n            if hasattr(obj, 'json_exclude_list'):\r\n                # do not serialize any values in this list\r\n                exclude_list = obj.json_exclude_list\r\n            return self.__construct_object(vars(obj), exclude_list)\r\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconstruct a list of items from a list of items", "response": "def __construct_list(self, list_value):\r\n        \"\"\" Loop list/set/tuple and parse values \"\"\"\r\n        array = []\r\n        for value in list_value:\r\n            array.append(self.__iterate_value(value))\r\n        return array"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a new object from a dict object.", "response": "def __construct_object(self, obj, exclude_list=[]):\r\n        \"\"\" Loop dict/class object and parse values \"\"\"\r\n        new_obj = {}\r\n        for key, value in obj.items():\r\n            if str(key).startswith('_') or \\\r\n                    key is 'json_exclude_list' or key in exclude_list:\r\n                continue\r\n            new_obj[self.camel_case(key)] = self.__iterate_value(value)\r\n        return new_obj"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __iterate_value(self, value):\r\n        if hasattr(value, '__dict__') or isinstance(value, dict):\r\n            return self.__find_object_children(value)  # go through dict/class\r\n        elif isinstance(value, (list, tuple, set)):\r\n            return self.__construct_list(value)  # go through list\r\n        return self.safe_values(value)", "response": "Iterate over a value for JSON serialization"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nwrites a VocabularyKey Xml as per Healthvault schema.", "response": "def write_xml(self):\n        '''\n            Writes a VocabularyKey Xml as per Healthvault schema.\n\n            :returns: lxml.etree.Element representing a single VocabularyKey\n        '''\n        key = None\n        if self. language is not None:\n            lang = {}\n            lang['{http://www.w3.org/XML/1998/namespace}lang'] = self.language\n            key = etree.Element('vocabulary-key', attrib=lang)\n        else:\n            key = etree.Element('vocabulary-key')\n\n        name = etree.Element('name')\n        name.text = self.name\n        key.append(name)\n\n        if self.family is not None:\n            family = etree.Element('family')\n            family.text = self.family\n            key.append(family)\n\n        if self.version is not None:\n            version = etree.Element('version')\n            version.text = self.version\n            key.append(version)\n\n        if self.code_value is not None:\n            code_value = etree.Element('code-value')\n            code_value.text = self.code_value\n            key.append(code_value)\n\n        return key"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a VocabularyKey from an Xml as per Healthvault schema.", "response": "def parse_xml(self, key_xml):\n        '''\n            Parse a VocabularyKey from an Xml as per Healthvault\n            schema.\n\n            :param key_xml: lxml.etree.Element representing a single VocabularyKey\n        '''\n        xmlutils = XmlUtils(key_xml)\n        self.name = xmlutils.get_string_by_xpath('name')\n        self.family = xmlutils.get_string_by_xpath('family')\n        self.version = xmlutils.get_string_by_xpath('version')\n        self.description = xmlutils.get_string_by_xpath('description')\n\n        self.language = xmlutils.get_lang()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_and_exit(results):\n    for success, value in results:\n        if success:\n            print value.encode(locale.getpreferredencoding())\n        else:\n            value.printTraceback()", "response": "Print each result and stop the reactor."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef main(reactor):\n    parser = argparse.ArgumentParser(\n        description='Fetch a URI or series of URIs and print a title '\n                    'or summary for each.',\n        epilog='If no URIs are passed on the command line, they are '\n               'read from standard input, one per line.')\n    parser.add_argument(\n        'uris', metavar='URI', nargs='*', help='URI to fetch')\n    parser.add_argument(\n        '-H', '--hostname-tag', action='store_true',\n        help='prefix titles with a hostname tag')\n    args = parser.parse_args()\n    uris = args.uris or imap(lambda x: x.strip(), sys.stdin)\n    finished = DeferredList([\n        fetch_title(uri.decode(locale.getpreferredencoding()),\n                    hostname_tag=args.hostname_tag, friendly_errors=True)\n        for uri in uris])\n    finished.addCallback(print_and_exit)\n    return finished", "response": "Entry point for the main command line entry point."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to add 3D View with vector or 2D array x along axis returns dict with result of operation", "response": "def add(self, x, axis):\n        \"\"\"Function to add 3D View with vector or 2D array (type = numpy.ndarray or 2D Field or 2D View) or 2D View with vector (type = numpy.ndarray)\n        :param x: array(1D, 2D) or field (2D) or View(2D)\n        :param axis: specifies axis, eg. axis = (1,2) plane lies in yz-plane, axis=0 vector along x axis\n        :return: dict with result of operation (same form as view.d)\n        \"\"\"\n        return self.__array_op(operator.add, x, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfunctions to sub 3D View with vector or 2D array x along axis", "response": "def sub(self, x, axis):\n        \"\"\"Function to sub 3D View with vector or 2D array (type = numpy.ndarray or 2D Field or 2D View) or 2D View with vector (type = numpy.ndarray)\n        :param x: array(1D, 2D) or field (2D) or View(2D)\n        :param axis: specifies axis, eg. axis = (1,2) plane lies in yz-plane, axis=0 vector along x axis\n        :return: dict with result of operation (same form as view.d)\n        \"\"\"\n        return self.__array_op(operator.sub, x, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef mul(self, x, axis):\n        return self.__array_op(operator.mul, x, axis)", "response": "Function to multiply 3D View with vector or 2D array x along axis"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef div(self, x, axis):\n        return self.__array_op(operator.div, x, axis)", "response": "Function to divide 3D View by vector or 2D array"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfunctions to modulo 3D View with vector or 2D array x and axis", "response": "def mod(self, x, axis):\n        \"\"\"Function to modulo 3D View with vector or 2D array (type = numpy.ndarray or 2D Field or 2D View) or 2D View with vector (type = numpy.ndarray)\n        :param x: array(1D, 2D) or field (2D) or View(2D)\n        :param axis: specifies axis, eg. axis = (1,2) plane lies in yz-plane, axis=0 vector along x axis\n        :return: dict with result of operation (same form as view.d)\n        \"\"\"\n        return self.__array_op(operator.mod, x, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfunctioning to power 3D View with vector or 2D array x and axis", "response": "def pow(self, x, axis):\n        \"\"\"Function to power 3D View with vector or 2D array (type = numpy.ndarray or 2D Field or 2D View) or 2D View with vector (type = numpy.ndarray)\n        :param x: array(1D, 2D) or field (2D) or View(2D)\n        :param axis: specifies axis, eg. axis = (1,2) plane lies in yz-plane, axis=0 vector along x axis\n        :return: dict with result of operation (same form as view.d)\n        \"\"\"\n        return self.__array_op(operator.pow, x, axis)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload any environment variables that are MACH9_ prefixed and applies them to the configuration if present.", "response": "def load_environment_vars(self):\n        \"\"\"\n        Looks for any MACH9_ prefixed environment variables and applies\n        them to the configuration if present.\n        \"\"\"\n        for k, v in os.environ.items():\n            if k.startswith(MACH9_PREFIX):\n                _, config_key = k.split(MACH9_PREFIX, 1)\n                self[config_key] = v"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncopy an existing structure and all of it s children", "response": "def copy(self, parent=None):\n        \"\"\"Copies an existing structure and all of it's children\"\"\"\n        new = Structure(None, parent=parent)\n        new.key = self.key\n        new.type_ = self.type_\n        new.val_guaranteed = self.val_guaranteed\n        new.key_guaranteed = self.key_guaranteed\n        for child in self.children:\n            new.children.append(child.copy(new))\n        return new"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the number of ancestors that are dictionaries", "response": "def generation(self):\n        \"\"\"Returns the number of ancestors that are dictionaries\"\"\"\n        if not self.parent:\n            return 0\n        elif self.parent.is_dict:\n            return 1 + self.parent.generation\n        else:\n            return self.parent.generation"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef type_string(self):\n        if self.is_tuple:\n            subtypes = [item.type_string for item in self.children]\n            return '{}({})'.format(\n                '' if self.val_guaranteed else '*',\n                ', '.join(subtypes))\n        elif self.is_list:\n            return '{}[{}]'.format(\n                '' if self.val_guaranteed else '*',\n                self.children[0].type_string)\n        else:\n            return '{}{}'.format(\n                '' if self.val_guaranteed else '*',\n                self.type_.__name__)", "response": "Returns a string representing the type of the structure"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the number of excluded patches from patches_base", "response": "def get_n_excluded_patches(self):\n        \"\"\"\n        Gets number of excluded patches from patches_base:\n        #patches_base=1.0.0+THIS_NUMBER\n        \"\"\"\n        base = self.get_patches_base()\n        if not base:\n            return 0\n        p = base.rfind('+')\n        if p == -1:\n            return 0\n        try:\n            n = int(base[p+1:])\n            return n\n        except TypeError:\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_field(obj, field_name, value):\n    old = getattr(obj, field_name)\n    field = obj._meta.get_field(field_name)\n    # is_relation is Django 1.8 only\n    if field.is_relation:\n        # If field_name is the `_id` field, then there is no 'pk' attr and\n        # old/value *is* the pk\n        old_repr = None if old is None else getattr(old, 'pk', old)\n        new_repr = None if value is None else getattr(value, 'pk', value)\n    elif field.__class__.__name__ == 'DateTimeField':\n        old_repr = None if old is None else datetime_repr(old)\n        new_repr = None if value is None else datetime_repr(value)\n    else:\n        old_repr = None if old is None else str(old)\n        new_repr = None if value is None else str(value)\n    if old_repr != new_repr:\n        setattr(obj, field_name, value)\n        if not hasattr(obj, DIRTY):\n            setattr(obj, DIRTY, [])\n        getattr(obj, DIRTY).append(dict(\n            field_name=field_name,\n            old_value=old_repr,\n            new_value=new_repr,\n        ))", "response": "Fancy setattr with debugging."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obj_update(obj, data: dict, *, update_fields=UNSET, save: bool=True) -> bool:\n    for field_name, value in data.items():\n        set_field(obj, field_name, value)\n    dirty_data = getattr(obj, DIRTY, None)\n    if not dirty_data:\n        return False\n\n    logger.debug(\n        human_log_formatter(dirty_data),\n        extra={\n            'model': obj._meta.object_name,\n            'pk': obj.pk,\n            'changes': json_log_formatter(dirty_data),\n        }\n    )\n    if update_fields == UNSET:\n        update_fields = list(map(itemgetter('field_name'), dirty_data))\n    if not save:\n        update_fields = ()\n    obj.save(update_fields=update_fields)\n    delattr(obj, DIRTY)\n    return True", "response": "Update the object with the given data dict."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef obj_update_or_create(model, defaults=None, update_fields=UNSET, **kwargs):\n    obj, created = model.objects.get_or_create(defaults=defaults, **kwargs)\n    if created:\n        logger.debug('CREATED %s %s',\n                     model._meta.object_name,\n                     obj.pk,\n                     extra={'pk': obj.pk})\n    else:\n        obj_update(obj, defaults, update_fields=update_fields)\n    return obj, created", "response": "Mimic queryset. update_or_create but using obj_update."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetecting the partitioning scheme of the source file.", "response": "def detect_scheme(filename):\n    \"\"\"Detects partitioning scheme of the source\n\n    Args:\n        filename (str): path to file or device for detection of \\\n        partitioning scheme.\n\n    Returns:\n        SCHEME_MBR, SCHEME_GPT or SCHEME_UNKNOWN\n\n    Raises:\n        IOError: The file doesn't exist or cannot be opened for reading\n\n    >>> from rawdisk.scheme.common import *\n    >>> scheme = detect_scheme('/dev/disk1')\n    >>> if scheme == PartitionScheme.SCHEME_MBR:\n    >>> <...>\n    \"\"\"\n\n    logger = logging.getLogger(__name__)\n    logger.info('Detecting partitioning scheme')\n\n    with open(filename, 'rb') as f:\n        # Look for MBR signature first\n        f.seek(mbr.MBR_SIG_OFFSET)\n        data = f.read(mbr.MBR_SIG_SIZE)\n        signature = struct.unpack(\"<H\", data)[0]\n\n        if signature != mbr.MBR_SIGNATURE:\n            # Something else\n            logger.debug('Unknown partitioning scheme')\n            return PartitionScheme.SCHEME_UNKNOWN\n        else:\n            # Could be MBR or GPT, look for GPT header\n            f.seek(gpt.GPT_HEADER_OFFSET)\n            data = f.read(gpt.GPT_SIG_SIZE)\n            signature = struct.unpack(\"<8s\", data)[0]\n\n            if signature != gpt.GPT_SIGNATURE:\n                logger.debug('MBR scheme detected')\n                return PartitionScheme.SCHEME_MBR\n            else:\n                logger.debug('GPT scheme detected')\n                return PartitionScheme.SCHEME_GPT"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef main():\n    '''Entry point'''\n    if len(sys.argv) == 1:\n        print(\"Usage: tyler [filename]\")\n        sys.exit(0)\n    filename = sys.argv[1]\n\n    if not os.path.isfile(filename):\n        print(\"Specified file does not exists\")\n        sys.exit(8)\n\n    my_tyler = Tyler(filename=filename)\n    while True:\n        try:\n            for line in my_tyler:\n                print(line)\n            time.sleep(1)\n        except KeyboardInterrupt:\n            print(\"Quit signal received\")\n            sys.exit(0)", "response": "Entry point for tyler."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the file has been rolled", "response": "def _has_file_rolled(self):\n        \"\"\"Check if the file has been rolled\"\"\"\n        # if the size is smaller then before, the file has\n        # probabilly been rolled\n        if self._fh:\n            size = self._getsize_of_current_file()\n            if size < self.oldsize:\n                return True\n\n            self.oldsize = size\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nopens a file to be tailed", "response": "def _open_file(self, filename):\n        \"\"\"Open a file to be tailed\"\"\"\n        if not self._os_is_windows:\n            self._fh = open(filename, \"rb\")\n            self.filename = filename\n\n            self._fh.seek(0, os.SEEK_SET)\n            self.oldsize = 0\n            return\n\n        # if we're in Windows, we need to use the WIN32 API to open the\n        # file without locking it\n        import win32file\n        import msvcrt\n\n        handle = win32file.CreateFile(filename,\n                                      win32file.GENERIC_READ,\n                                      win32file.FILE_SHARE_DELETE |\n                                      win32file.FILE_SHARE_READ |\n                                      win32file.FILE_SHARE_WRITE,\n                                      None,\n                                      win32file.OPEN_EXISTING,\n                                      0,\n                                      None)\n        detached_handle = handle.Detach()\n        file_descriptor = msvcrt.open_osfhandle(\n            detached_handle, os.O_RDONLY)\n\n        self._fh = open(file_descriptor, \"rb\")\n        self.filename = filename\n\n        self._fh.seek(0, os.SEEK_SET)\n        self.oldsize = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a filehandle to the file being tailed", "response": "def _filehandle(self):\n        \"\"\"\n        Return a filehandle to the file being tailed\n        \"\"\"\n        # if file is opened and it has been rolled we need to close the file\n        # and then to reopen it\n        if self._fh and self._has_file_rolled():\n            try:\n                self._fh.close()\n            except Exception:\n                pass\n\n            self._fh = None\n\n        # if the file is closed (or has been closed right now), open it\n        if not self._fh:\n            self._open_file(self.filename)\n\n            if not self.opened_before:\n                self.opened_before = True\n                self._fh.seek(0, os.SEEK_END)\n\n        return self._fh"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the socket. gethostname attribute on each save.", "response": "def pre_save(self, model_instance, add):\n        \"\"\"Updates socket.gethostname() on each save.\"\"\"\n        value = socket.gethostname()\n        setattr(model_instance, self.attname, value)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a class from a dotted string", "response": "def get_class(class_string):\n    \"\"\"\n    Get a class from a dotted string\n    \"\"\"\n    split_string = class_string.encode('ascii').split('.')\n    import_path = '.'.join(split_string[:-1])\n    class_name = split_string[-1]\n\n    if class_name:\n        try:\n            if import_path:\n                mod = __import__(import_path, globals(), {}, [class_name])\n                cls = getattr(mod, class_name)\n            else:\n                cls = __import__(class_name, globals(), {})\n            if cls:\n                return cls\n        except (ImportError, AttributeError):\n            pass\n\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _register_handler(event, fun, external=False):\n    registry = core.HANDLER_REGISTRY\n    if external:\n        registry = core.EXTERNAL_HANDLER_REGISTRY\n\n    if not isinstance(event, basestring):\n        # If not basestring, it is a BaseEvent subclass.\n        # This occurs when class methods are registered as handlers\n        event = core.parse_event_to_name(event)\n\n    if event in registry:\n        registry[event].append(fun)\n    else:\n        registry[event] = [fun]\n    return fun", "response": "Register a function to be an event handler"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef handler(param):\n    if isinstance(param, basestring):\n        return lambda f: _register_handler(param, f)\n    else:\n        core.HANDLER_METHOD_REGISTRY.append(param)\n        return param", "response": "Decorator that associates a handler to a class."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_keys(self, *keys):\n        current_keys = set(self.data.keys())\n        needed_keys = set(keys)\n        if not needed_keys.issubset(current_keys):\n            raise ValidationError(\n                'One of the following keys are missing from the '\n                'event\\'s data: {}'.format(\n                    ', '.join(needed_keys.difference(current_keys)))\n            )\n        return True", "response": "This method checks that the keys received in the event s data are present in the event s data."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a github project to the data folder unzips it and deletes the zip file. Returns the project name and the path to the project folder.", "response": "def addProject(gh_link):\n    ''' Adds a github project to the data folder, unzips it, and deletes the zip file.\n    Returns the project name and the path to the project folder. '''\n    name = os.path.basename(gh_link)\n    zipurl = gh_link+\"/archive/master.zip\"\n    outzip = os.path.join('temp_data',name+'.zip')\n    if not os.path.exists('temp_data'):\n        os.makedirs('temp_data')\n    downloadFile(zipurl,outzip)\n    zip = zipfile.ZipFile(outzip,mode='r')\n    outpath = os.path.join('temp_data',name)\n    zip.extractall(outpath)\n    zip.close()\n    os.remove(outzip)\n    return name,outpath"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a file from a URL.", "response": "def downloadFile(url,outfile=None): \n    ''' Copied from  http://stackoverflow.com/questions/16694907/how-to-download-large-file-in-python-with-requests-py '''\n    if not outfile:\n        outfile = url.split('/')[-1]\n    r = requests.get(url, stream=True)\n    with open(outfile, 'wb') as f:\n        for chunk in r.iter_content(chunk_size=1024): \n            if chunk: \n                f.write(chunk)\n    return outfile"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove existing json datafiles in the target directory.", "response": "def cleanDir(self):\n        ''' Remove existing json datafiles in the target directory. '''\n        if os.path.isdir(self.outdir):\n            baddies = ['tout.json','nout.json','hout.json']\n            for file in baddies:\n                filepath = os.path.join(self.outdir,file)\n                if os.path.isfile(filepath):\n                    os.remove(filepath)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef makeHTML(self,mustachepath,htmlpath):\n        '''Write an html file by applying this ideogram's attributes to a mustache template. '''\n        subs = dict()\n        if self.title:\n            subs[\"title\"]=self.title\n            subs[\"has_title\"]=True\n        else:\n            subs[\"has_title\"]=False\n        subs[\"font_size\"] = self.font_size\n        subs[\"font_family\"] = self.font_family\n        subs[\"colorscheme\"] = self.colorscheme\n        subs[\"title_color\"] = self.title_color\n        subs[\"bgcolor\"] = self.bgcolor\n        with open(mustachepath,'r') as infile:\n            mustache_text = pystache.render(infile.read(), subs)\n            with open(htmlpath,'w+') as outfile:\n                outfile.write(mustache_text)", "response": "Write an html file by applying this ideogram s attributes to a mustache template."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the particlees age in a variety of units.", "response": "def get_age(self, **kwargs):\n        \"\"\"\n        Returns the particlees age (how long it has been forced) in a variety of units.\n        Rounded to 8 decimal places.\n\n        Parameters:\n            units (optional) = 'days' (default), 'hours', 'minutes', or 'seconds'\n        \"\"\"\n        try:\n            units = kwargs.get('units', None)\n            if units is None:\n                return self._age\n            units = units.lower()\n            if units == \"days\":\n                z = self._age\n            elif units == \"hours\":\n                z = self._age * 24.\n            elif units == \"minutes\":\n                z = self._age * 24. * 60.\n            elif units == \"seconds\":\n                z = self._age * 24. * 60. * 60.\n            else:\n                raise\n            return round(z,8) \n        except StandardError:\n            raise KeyError(\"Could not return age of particle\")"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef age(self, **kwargs):\n        if kwargs.get('days', None) is not None:\n            self._age += kwargs.get('days')\n            return\n        if kwargs.get('hours', None) is not None:\n            self._age += kwargs.get('hours') / 24.\n            return\n        if kwargs.get('minutes', None) is not None:\n            self._age += kwargs.get('minutes') / 24. / 60.\n            return\n        if kwargs.get('seconds', None) is not None:\n            self._age += kwargs.get('seconds') / 24. / 60. / 60.\n            return\n\n        raise KeyError(\"Could not age particle, please specify 'days', 'hours', 'minutes', or 'seconds' parameter\")", "response": "Age this particle.\n\n        parameters (optional, only one allowed):\n            days (default)\n            hours\n            minutes\n            seconds"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalized_indexes(self, model_timesteps):\n\n        # Clean up locations\n        # If duplicate time instances, remove the lower index \n        clean_locs = []\n        for i,loc in enumerate(self.locations):\n            try:\n                if loc.time == self.locations[i+1].time:\n                    continue\n                else:\n                    clean_locs.append(loc)\n            except StandardError:\n                clean_locs.append(loc)\n\n        if len(clean_locs) == len(model_timesteps):\n           return [ind for ind,loc in enumerate(self.locations) if loc in clean_locs]\n        elif len(model_timesteps) < len(clean_locs):\n            # We have at least one internal timestep for this particle\n            # Pull out the matching location indexes\n            indexes = [ind for ind,loc in enumerate(self.locations) if loc in clean_locs]\n            if len(model_timesteps) == len(indexes):\n                return indexes\n            raise ValueError(\"Can't normalize\")           \n        elif len(model_timesteps) > len(clean_locs):\n            # The particle stopped before forcing for all of the model timesteps\n            raise ValueError(\"Particle has less locations than model timesteps\")", "response": "This function will return the list of indexes that are used to run the particle at the given timestep."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_satisfied_by(self, candidate: Any, **kwds: Any) -> bool:\n        candidate_name = self._candidate_name\n        context = self._context\n        if context:\n            if candidate_name in kwds:\n                raise ValueError(f\"Candidate name '{candidate_name}' must \"\n                                 \"not be given as keyword.\")\n            context.update(kwds)\n        context[candidate_name] = candidate\n        try:\n            code = self._code\n        except AttributeError:\n            self._code = code = compile(self._ast_expr, '<str>', mode='eval')\n        return eval(code, context)", "response": "Return True if candidate satisfies the specification."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_edge(self, fr, to):\n        fr = self.add_vertex(fr)\n        to = self.add_vertex(to)\n        self.adjacency[fr].children.add(to)\n        self.adjacency[to].parents.add(fr)", "response": "Add an edge between two vertices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a vertex to the graph.", "response": "def add_vertex(self, v):\n        \"\"\"\n        Add a vertex to the graph. The vertex must implement __hash__ and __eq__ as it will be stored in a set.\n        :param v: vertex\n        :return: graph owned vertex\n        \"\"\"\n        if v not in self.adjacency:\n            self.adjacency[v] = Vertex(v)\n        return self.adjacency[v].vertex"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new volume then clone the contents of the backup into the new volume", "response": "def clone(self, source_id, backup_id, size,\n              volume_id=None, source_host=None):\n        \"\"\"\n        create a volume then clone the contents of\n        the backup into the new volume\n        \"\"\"\n        volume_id = volume_id or str(uuid.uuid4())\n        return self.http_put('/volumes/%s' % volume_id,\n                             params=self.unused({\n                                 'source_host': source_host,\n                                 'source_volume_id': source_id,\n                                 'backup_id': backup_id,\n                                 'size': size\n                             }))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a backup of a volume", "response": "def create(self, volume_id, backup_id=None, timestamp=None):\n        \"\"\"\n        create a backup of a volume\n        \"\"\"\n        backup_id = backup_id or str(uuid.uuid4())\n        timestamp = timestamp or int(time())\n        return self.http_put('/volumes/%s/backups/%s' % (volume_id, backup_id),\n                             params={'timestamp': timestamp})"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an export for a volume", "response": "def create(self, volume_id, ip=None):\n        \"\"\"\n        create an export for a volume\n        \"\"\"\n        if ip:\n            return self.http_put('/volumes/%s/export?ip=%s' % (volume_id, ip))\n        return self.http_put('/volumes/%s/export' % volume_id)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading boards from boards. txt.", "response": "def boards(hwpack='arduino'):\n    \"\"\"read boards from boards.txt.\n\n    :param core_package: 'all,'arduino',..\n\n    \"\"\"\n    bunch = read_properties(boards_txt(hwpack))\n\n    bunch_items = list(bunch.items())\n\n    # remove invalid boards\n    for bid, board in bunch_items:\n        if 'build' not in board.keys() or 'name' not in board.keys():\n            log.debug('invalid board found: %s', bid)\n            del bunch[bid]\n\n    return bunch"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning installed board names.", "response": "def board_names(hwpack='arduino'):\n    \"\"\"return installed board names.\"\"\"\n    ls = list(boards(hwpack).keys())\n    ls.sort()\n    return ls"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef print_boards(hwpack='arduino', verbose=False):\n    if verbose:\n        pp(boards(hwpack))\n    else:\n        print('\\n'.join(board_names(hwpack)))", "response": "print boards from boards. txt"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_lib_dir(root):\n    root = path(root)\n    log.debug('files in dir: %s', root)\n    for x in root.walkfiles():\n        log.debug('  %s', x)\n\n    # only 1 dir in root? (example: github)\n    if not len(root.files()) and len(root.dirs()) == 1:\n        log.debug('go inside root')\n        root = root.dirs()[0]\n\n    if len(root.files('keywords.txt')):\n        root = rename_root(root)\n        return root, root\n\n    keywords = list(root.walkfiles('keywords.txt'))\n    if len(keywords):\n        if len(keywords) > 1:\n            log.warning('more keywords.txt found. Installing only one.  %s', keywords)  \n\n        lib_dir = keywords[0].parent\n        lib_dir = fix_libdir(lib_dir)\n        return root, lib_dir\n\n    header_only = len(list(noexample(root.walkfiles('*.cpp')))) == 0\n    log.debug('header_only: %s', header_only)\n    lib_dir = None\n\n    headers = list(noexample(root.walkfiles('*.h')))\n\n    for h in headers:\n        cpp = h.stripext() + '.cpp'\n        if (header_only or cpp.exists()) and h.parent.name.lower() == h.namebase.lower():\n            assert not lib_dir\n            lib_dir = h.parent\n            log.debug('found lib: %s', lib_dir)\n\n    if not lib_dir:\n        if len(headers) == 1 and len(list(root.files('*.h'))) == 0:\n            log.debug('only 1 header, not in root')\n            lib_dir = headers[0].parent\n            lib_dir = rename_root(lib_dir)\n\n    if not lib_dir:\n        # xxx.cpp and xxx.h in root? -> rename root dir\n        root = rename_root(root)\n        return root, root\n#        for h in root.files('*.h'):\n#            cpp = h.stripext() + '.cpp'\n#            if  header_only or cpp.exists():\n#                assert not lib_dir\n#                root.rename(root.parent / h.namebase)\n#                root = lib_dir = root.parent / h.namebase\n    assert lib_dir\n    return root, lib_dir", "response": "search for lib dir under root."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfind examples not under lib dir and move them into examples", "response": "def move_examples(root, lib_dir):\n    \"\"\"find examples not under lib dir, and move into ``examples``\"\"\"\n    all_pde = files_multi_pattern(root, INO_PATTERNS)\n    lib_pde = files_multi_pattern(lib_dir, INO_PATTERNS)\n    stray_pde = all_pde.difference(lib_pde)\n    if len(stray_pde) and not len(lib_pde):\n        log.debug(\n            'examples found outside lib dir, moving them: %s', stray_pde)\n        examples = lib_dir / EXAMPLES\n        examples.makedirs()\n        for x in stray_pde:\n            d = examples / x.namebase\n            d.makedirs()\n            x.move(d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrename examples dir to examples", "response": "def fix_examples_dir(lib_dir):\n    \"\"\"rename examples dir to ``examples``\"\"\"\n    for x in lib_dir.dirs():\n        if x.name.lower() == EXAMPLES:\n            return\n    for x in lib_dir.dirs():\n        if x.name.lower() == EXAMPLES:\n            _fix_dir(x)\n            return\n    for x in lib_dir.dirs():\n        if 'example' in x.name.lower():\n            _fix_dir(x)\n            return\n    for x in lib_dir.dirs():\n        if len(files_multi_pattern(x, INO_PATTERNS)):\n            _fix_dir(x)\n            return"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef install_lib(url, replace_existing=False, fix_wprogram=True):\n    d = tmpdir(tmpdir())\n    f = download(url)\n    Archive(f).extractall(d)\n\n    clean_dir(d)\n    d, src_dlib = find_lib_dir(d)\n    move_examples(d, src_dlib)\n    fix_examples_dir(src_dlib)\n    if fix_wprogram:\n        fix_wprogram_in_files(src_dlib)\n\n    targ_dlib = libraries_dir() / src_dlib.name\n    if targ_dlib.exists():\n        log.debug('library already exists: %s', targ_dlib)\n        if replace_existing:\n            log.debug('remove %s', targ_dlib)\n            targ_dlib.rmtree()\n        else:\n            raise ConfduinoError('library already exists:' + targ_dlib)\n\n    log.debug('move %s -> %s', src_dlib, targ_dlib)\n    src_dlib.move(targ_dlib)\n\n    libraries_dir().copymode(targ_dlib)\n    for x in targ_dlib.walk():\n        libraries_dir().copymode(x)\n    return targ_dlib.name", "response": "install library from web or local files system."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of a specific configuration variable for strudel. packages.", "response": "def get_config(variable, default=None):\n    \"\"\" Get configuration variable for strudel.* packages\n\n    Args:\n        variable (str): name of the config variable\n        default: value to use of config variable not set\n\n    Returns:\n        variable value\n\n    Order of search:\n        1. stutils.CONFIG\n        2. settings.py of the current folder\n        3. environment variable\n\n    Known config vars so far:\n        strudel.utils\n        ST_FS_CACHE_DURATION - duration of filesystem cache in seconds\n        ST_FS_CACHE_PATH - path to the folder to store filesystem cache\n\n        strudel.ecosystems\n        PYPI_SAVE_PATH - place to store downloaded PyPI packages\n        PYPI_TIMEOUT - network timeout for PyPI API\n\n        strudel.scraper\n        GITHUB_API_TOKENS - comma separated list of GitHub tokens\n        GITLAB_API_TOKENS - same for GitLab API\n    \"\"\"\n    if variable in CONFIG:\n        return CONFIG[variable]\n\n    if hasattr(settings, variable):\n        return getattr(settings, variable)\n\n    if variable in os.environ:\n        return os.environ[variable]\n\n    return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntries to call f n times before giving up. Wait 2 ** n seconds before retries.", "response": "def _retry(n, f, *args, **kwargs):\n    '''Try to call f(*args, **kwargs) \"n\" times before giving up. Wait\n    2**n seconds before retries.'''\n\n    for i in range(n):\n        try:\n            return f(*args, **kwargs)\n        except Exception as exc:\n            if i == n - 1:\n                log.error(\n                    '%s permanently failed with %r', f.__name__, exc)\n                raise\n            else:\n                log.warning(\n                    '%s attempt #%d failed with %r', f.__name__, i, exc)\n                time.sleep(2 ** i)\n    raise RuntimeError('Should never get here!')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _init_supervisor_rpc(self, rpc_or_port):\n        '''Initialize supervisor RPC.\n\n        Allow passing in an RPC connection, or a port number for\n        making one.\n\n        '''\n        if isinstance(rpc_or_port, int):\n            if self.username:\n                leader = 'http://{self.username}:{self.password}@'\n            else:\n                leader = 'http://'\n            tmpl = leader + '{self.name}:{port}'\n            url = tmpl.format(self=self, port=rpc_or_port)\n            self.rpc = xmlrpc_client.ServerProxy(\n                url, transport=TimeoutTransport())\n        else:\n            self.rpc = rpc_or_port\n        self.supervisor = self.rpc.supervisor", "response": "Initialize supervisor RPC.\n\n        Allow passing in an RPC connection, or a port number for\n        making one."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninitializes a StrictRedis instance based on a Redis spec.", "response": "def _init_redis(redis_spec):\n        \"\"\"\n        Return a StrictRedis instance or None based on redis_spec.\n\n        redis_spec may be None, a Redis URL, or a StrictRedis instance\n        \"\"\"\n        if not redis_spec:\n            return\n        if isinstance(redis_spec, six.string_types):\n            return redis.StrictRedis.from_url(redis_spec)\n        # assume any other value is a valid instance\n        return redis_spec"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the base hostname for the current environment.", "response": "def _get_base():\n        \"\"\"\n        if 'deploy' resolves in this environment, use the hostname for which\n        that name resolves.\n        Override with 'VELOCIRAPTOR_URL'\n        \"\"\"\n        try:\n            name, _aliaslist, _addresslist = socket.gethostbyname_ex('deploy')\n        except socket.gaierror:\n            name = 'deploy'\n        fallback = 'https://{name}/'.format(name=name)\n        return os.environ.get('VELOCIRAPTOR_URL', fallback)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_all(cls, vr, params=None):\n        ob_docs = vr.query(cls.base, params)\n        return [cls(vr, ob) for ob in ob_docs]", "response": "Create instances of all objects found\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndispatching changes to the current swarm and returns the result.", "response": "def dispatch(self, **changes):\n        \"\"\"\n        Patch the swarm with changes and then trigger the swarm.\n        \"\"\"\n        self.patch(**changes)\n        trigger_url = self._vr._build_url(self.resource_uri, 'swarm/')\n        resp = self._vr.session.post(trigger_url)\n        resp.raise_for_status()\n        try:\n            return resp.json()\n        except ValueError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrequest an communication token from Grooveshark", "response": "def _get_token(self):\n        '''\n        requests an communication token from Grooveshark\n        '''\n        self.session.token = self.request(\n            'getCommunicationToken',\n            {'secretKey': self.session.secret},\n            {'uuid': self.session.user,\n             'session': self.session.session,\n             'clientRevision': grooveshark.const.CLIENTS['htmlshark']['version'],\n             'country': self.session.country,\n             'privacy': 0,\n             'client': 'htmlshark'})[1]\n        self.session.time = time.time()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a request token", "response": "def _request_token(self, method, client):\n        '''\n        generates a request token\n        '''\n        if time.time() - self.session.time > grooveshark.const.TOKEN_TIMEOUT:\n            self._get_token()\n        random_value = self._random_hex()\n        return random_value + hashlib.sha1((method + ':' + self.session.token + ':' + grooveshark.const.CLIENTS[client]['token'] + ':' + random_value).encode('utf-8')).hexdigest()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef request(self, method, parameters, header):\n        '''\n        Grooveshark API request\n        '''\n        data = json.dumps({\n            'parameters': parameters,\n            'method': method,\n            'header': header})\n        request = urllib.Request(\n            'https://grooveshark.com/more.php?%s' % (method),\n            data=data.encode('utf-8'), headers=self._json_request_header())\n        with contextlib.closing(self.urlopen(request)) as response:\n            result = json.loads(response.read().decode('utf-8'))\n            if 'result' in result:\n                return response.info(), result['result']\n            elif 'fault' in result:\n                raise RequestError(result['fault']['message'],\n                                   result['fault']['code'])\n            else:\n                raise UnknownError(result)", "response": "Request a new object from the Grooveshark API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating Grooveshark API Json header", "response": "def header(self, method, client='htmlshark'):\n        '''\n        generates Grooveshark API Json header\n        '''\n        return {'token': self._request_token(method, client),\n                'privacy': 0,\n                'uuid': self.session.user,\n                'clientRevision': grooveshark.const.CLIENTS[client]['version'],\n                'session': self.session.session,\n                'client': client,\n                'country': self.session.country}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting songs belong to a specific genre. :param radio: genre to listen to :rtype: a :class:`Radio` object Genres: This list is incomplete because there isn't an English translation for some genres. Please look at the sources for all possible Tags. +-------------------------------------+-------------------------------+ | Constant | Genre | +=====================================+===============================+ | :const:`Radio.GENRE_RNB` | R and B | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_JAZZ` | Jazz | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_ROCK` | Rock | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_CLASSICAL` | Classical | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_DUBSTEP` | Dubstep | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_BLUES` | Blues | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_FOLK` | Folk | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_ELECTRONICA` | Electronica | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_CHRISTMAS` | Christmas | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_OLDIES` | Oldies | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_COUNTRY` | Country | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_EXPERIMENTAL` | Experimental | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_POP` | Pop | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_INDIE` | Indie | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_BLUEGRASS` | Bluegrass | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_RAP` | Rap | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_AMBIENT` | Ambient | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_TRANCE` | Trance | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_REGGAE` | Reggae | +-------------------------------------+-------------------------------+ | :const:`Radio.GENRE_METAL` | Metal | +-------------------------------------+-------------------------------+", "response": "def radio(self, radio):\n        '''\n        Get songs belong to a specific genre.\n\n        :param radio: genre to listen to\n        :rtype: a :class:`Radio` object\n\n        Genres:\n\n        This list is incomplete because there isn't an English translation for\n        some genres.\n        Please look at the sources for all possible Tags.\n\n        +-------------------------------------+-------------------------------+\n        | Constant                            | Genre                         |\n        +=====================================+===============================+\n        | :const:`Radio.GENRE_RNB`            | R and B                       |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_JAZZ`           | Jazz                          |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_ROCK`           | Rock                          |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_CLASSICAL`      | Classical                     |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_DUBSTEP`        | Dubstep                       |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_BLUES`          | Blues                         |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_FOLK`           | Folk                          |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_ELECTRONICA`    | Electronica                   |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_CHRISTMAS`      | Christmas                     |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_OLDIES`         | Oldies                        |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_COUNTRY`        | Country                       |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_EXPERIMENTAL`   | Experimental                  |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_POP`            | Pop                           |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_INDIE`          | Indie                         |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_BLUEGRASS`      | Bluegrass                     |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_RAP`            | Rap                           |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_AMBIENT`        | Ambient                       |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_TRANCE`         | Trance                        |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_REGGAE`         | Reggae                        |\n        +-------------------------------------+-------------------------------+\n        | :const:`Radio.GENRE_METAL`          | Metal                         |\n        +-------------------------------------+-------------------------------+\n        '''\n        artists = self.connection.request(\n            'getArtistsForTagRadio',\n            {'tagID': radio},\n            self.connection.header('getArtistsForTagRadio', 'jsqueue'))[1]\n        return Radio(artists, radio, self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the album and create an Album object.", "response": "def _parse_album(self, album):\n        '''\n        Parse search json-data and create an :class:`Album` object.\n        '''\n        if album['CoverArtFilename']:\n            cover_url = '%sm%s' % (grooveshark.const.ALBUM_COVER_URL,\n                                   album['CoverArtFilename'])\n        else:\n            cover_url = None\n        return Album(\n            album['AlbumID'],\n            album['Name'],\n            album['ArtistID'],\n            album['ArtistName'],\n            cover_url,\n            self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse search json - data and create a : class : Playlist object.", "response": "def _parse_playlist(self, playlist):\n        '''\n        Parse search json-data and create a :class:`Playlist` object.\n        '''\n        if playlist['Picture']:\n            cover_url = '%s70_%s' % (grooveshark.const.PLAYLIST_COVER_URL,\n                                     playlist['Picture'])\n        else:\n            cover_url = None\n        return Playlist(\n            playlist['PlaylistID'],\n            playlist['Name'],\n            cover_url,\n            self.connection)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching for songs artists and albums.", "response": "def search(self, query, type=SONGS):\n        '''\n        Search for songs, artists and albums.\n\n        :param query: search string\n        :param type: type to search for\n        :rtype: a generator generates :class:`Song`, :class:`Artist` and :class:`Album` objects\n\n        Search Types:\n\n        +---------------------------------+---------------------------------+\n        | Constant                        | Meaning                         |\n        +=================================+=================================+\n        | :const:`Client.SONGS`           | Search for songs                |\n        +---------------------------------+---------------------------------+\n        | :const:`Client.ARTISTS`         | Search for artists              |\n        +---------------------------------+---------------------------------+\n        | :const:`Client.ALBUMS`          | Search for albums               |\n        +---------------------------------+---------------------------------+\n        | :const:`Client.PLAYLISTS`       | Search for playlists            |\n        +---------------------------------+---------------------------------+\n        '''\n        result = self.connection.request(\n            'getResultsFromSearch',\n            {'query': query, 'type': type, 'guts': 0, 'ppOverride': False},\n            self.connection.header('getResultsFromSearch'))[1]['result']\n        if type == self.SONGS:\n            return (Song.from_response(song, self.connection)\n                    for song in result)\n        elif type == self.ARTISTS:\n            return (Artist(artist['ArtistID'], artist['Name'], self.connection)\n                    for artist in result)\n        elif type == self.ALBUMS:\n            return (self._parse_album(album) for album in result)\n        elif type == self.PLAYLISTS:\n            return (self._parse_playlist(playlist) for playlist in result)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting popular songs. :param period: time period :rtype: a generator generates :class:`Song` objects Time periods: +---------------------------------+-----------------------------------+ | Constant | Meaning | +=================================+===================================+ | :const:`Client.DAILY` | Popular songs of this day | +---------------------------------+-----------------------------------+ | :const:`Client.MONTHLY` | Popular songs of this month | +---------------------------------+-----------------------------------+", "response": "def popular(self, period=DAILY):\n        '''\n        Get popular songs.\n\n        :param period: time period\n        :rtype: a generator generates :class:`Song` objects\n\n        Time periods:\n\n        +---------------------------------+-----------------------------------+\n        | Constant                        | Meaning                           |\n        +=================================+===================================+\n        | :const:`Client.DAILY`           | Popular songs of this day         |\n        +---------------------------------+-----------------------------------+\n        | :const:`Client.MONTHLY`         | Popular songs of this month       |\n        +---------------------------------+-----------------------------------+\n        '''\n        songs = self.connection.request(\n            'popularGetSongs',\n            {'type': period},\n            self.connection.header('popularGetSongs'))[1]['Songs']\n        return (Song.from_response(song, self.connection) for song in songs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a playlist from it s ID.", "response": "def playlist(self, playlist_id):\n        '''\n        Get a playlist from it's ID\n\n        :param playlist_id: ID of the playlist\n        :rtype: a :class:`Playlist` object\n        '''\n        playlist = self.connection.request(\n            'getPlaylistByID',\n            {'playlistID': playlist_id},\n            self.connection.header('getPlaylistByID'))[1]\n        return self._parse_playlist(playlist)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef collection(self, user_id):\n        # TODO further evaluation of the page param, I don't know where the\n        # limit is.\n        dct = {'userID': user_id, 'page': 0}\n        r = 'userGetSongsInLibrary'\n        result = self.connection.request(r, dct, self.connection.header(r))\n        songs = result[1]['Songs']\n        return [Song.from_response(song, self.connection) for song in songs]", "response": "Get the song collection of a user."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef hwpack_names():\n    ls = hwpack_dir().listdir()\n    ls = [x.name for x in ls]\n    ls = [x for x in ls if x != 'tools']\n    arduino_included = 'arduino' in ls\n    ls = [x for x in ls if x != 'arduino']\n    ls.sort()\n    if arduino_included:\n        ls = ['arduino'] + ls  # move to 1st pos\n    return ls", "response": "return installed hardware package names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _create_parser(self, html_parser, current_url):\n\n        css_code = ''\n\n        elements = html_parser.find(\n            'style,link[rel=\"stylesheet\"]'\n        ).list_results()\n        for element in elements:\n            if element.get_tag_name() == 'STYLE':\n                css_code = css_code + element.get_text_content()\n            else:\n                css_code = css_code + requests.get(\n                    urljoin(current_url, element.get_attribute('href'))\n                ).text\n\n        self.stylesheet = tinycss.make_parser().parse_stylesheet(css_code)", "response": "Create the tinycss stylesheet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbreaking a list into n pieces.", "response": "def partition(thelist, n):\n    \"\"\"\n    Break a list into ``n`` pieces. The last list may be larger than the rest if\n    the list doesn't break cleanly. That is::\n \n        >>> l = range(10)\n \n        >>> partition(l, 2)\n        [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n \n        >>> partition(l, 3)\n        [[0, 1, 2], [3, 4, 5], [6, 7, 8, 9]]\n \n        >>> partition(l, 4)\n        [[0, 1], [2, 3], [4, 5], [6, 7, 8, 9]]\n \n        >>> partition(l, 5)\n        [[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n \n    \"\"\"\n    try:\n        n = int(n)\n        thelist = list(thelist)\n    except (ValueError, TypeError):\n        return [thelist]\n    p = len(thelist) / n\n    return [thelist[p*i:p*(i+1)] for i in range(n - 1)] + [thelist[p*(i+1):]]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbreaks a list into n peices but horizontally. That is vandale.", "response": "def partition_horizontal(thelist, n):\n    \"\"\"\n    Break a list into ``n`` peices, but \"horizontally.\" That is, \n    ``partition_horizontal(range(10), 3)`` gives::\n    \n        [[1, 2, 3],\n         [4, 5, 6],\n         [7, 8, 9],\n         [10]]\n        \n    Clear as mud?\n    \"\"\"\n    try:\n        n = int(n)\n        thelist = list(thelist)\n    except (ValueError, TypeError):\n        return [thelist]\n    newlists = [list() for i in range(int(ceil(len(thelist) / float(n))))]\n    for i, val in enumerate(thelist):\n        newlists[i/n].append(val)\n    return newlists"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngive a list of items and a number return a list of items that are part of the list.", "response": "def partition_horizontal_twice(thelist, numbers):\n    \"\"\"\n    numbers is split on a comma to n and n2.\n    Break a list into peices each peice alternating between n and n2 items long \n    ``partition_horizontal_twice(range(14), \"3,4\")`` gives::\n    \n        [[0, 1, 2],\n         [3, 4, 5, 6], \n         [7, 8, 9], \n         [10, 11, 12, 13]]\n    \n    Clear as mud?\n    \"\"\"\n    n, n2 = numbers.split(',')\n    try:\n        n = int(n)\n        n2 = int(n2)\n        thelist = list(thelist)\n    except (ValueError, TypeError):\n        return [thelist]\n    newlists = []\n    while thelist:\n        newlists.append(thelist[:n])\n        thelist = thelist[n:]\n        newlists.append(thelist[:n2])\n        thelist = thelist[n2:]\n    return newlists"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef readline(self, prompt=''):\r\n        u'''Try to act like GNU readline.'''\r\n        # handle startup_hook\r\n        if self.first_prompt:\r\n            self.first_prompt = False\r\n            if self.startup_hook:\r\n                try:\r\n                    self.startup_hook()\r\n                except:\r\n                    print u'startup hook failed'\r\n                    traceback.print_exc()\r\n\r\n        c = self.console\r\n        self.l_buffer.reset_line()\r\n        self.prompt = prompt\r\n        self._print_prompt()\r\n\r\n        if self.pre_input_hook:\r\n            try:\r\n                self.pre_input_hook()\r\n            except:\r\n                print u'pre_input_hook failed'\r\n                traceback.print_exc()\r\n                self.pre_input_hook = None\r\n\r\n        log(u\"in readline: %s\"%self.paste_line_buffer)\r\n        if len(self.paste_line_buffer)>0:\r\n            self.l_buffer=lineobj.ReadlineTextBuffer(self.paste_line_buffer[0])\r\n            self._update_line()\r\n            self.paste_line_buffer=self.paste_line_buffer[1:]\r\n            c.write(u'\\r\\n')\r\n        else:\r\n            self._readline_from_keyboard()\r\n            c.write(u'\\r\\n')\r\n\r\n        self.add_history(self.l_buffer.copy())\r\n\r\n        log(u'returning(%s)' % self.l_buffer.get_line_text())\r\n        return self.l_buffer.get_line_text() + '\\n'", "response": "Try to act like GNU readline."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef history_search_forward(self, e): # ()\r\n        u'''Search forward through the history for the string of characters\r\n        between the start of the current line and the point. This is a\r\n        non-incremental search. By default, this command is unbound.'''\r\n        self.l_buffer=self._history.history_search_forward(self.l_buffer)", "response": "Search forward through the history for the string of characters between the start of the current line and the point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef history_search_backward(self, e): # ()\r\n        u'''Search backward through the history for the string of characters\r\n        between the start of the current line and the point. This is a\r\n        non-incremental search. By default, this command is unbound.'''\r\n        self.l_buffer=self._history.history_search_backward(self.l_buffer)", "response": "Search backward through the history for the string of characters between the start of the current line and the point e."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninserts the next character typed to the line verbatim.", "response": "def quoted_insert(self, e): # (C-q or C-v)\r\n        u'''Add the next character typed to the line verbatim. This is how to\r\n        insert key sequences like C-q, for example.'''\r\n        e = self.console.getkeypress()\r\n        self.insert_text(e.char)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef paste(self,e):\r\n        u'''Paste windows clipboard'''\r\n        if self.enable_win32_clipboard:\r\n                txt=clipboard.get_clipboard_text_and_convert(False)\r\n                self.insert_text(txt)", "response": "Paste the text from the clipboard."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef paste_mulitline_code(self,e):\r\n        u'''Paste windows clipboard'''\r\n        reg=re.compile(u\"\\r?\\n\")\r\n        if self.enable_win32_clipboard:\r\n                txt=clipboard.get_clipboard_text_and_convert(False)\r\n                t=reg.split(txt)\r\n                t=[row for row in t if row.strip()!=u\"\"] #remove empty lines\r\n                if t!=[u\"\"]:\r\n                    self.insert_text(t[0])\r\n                    self.add_history(self.l_buffer.copy())\r\n                    self.paste_line_buffer=t[1:]\r\n                    log(u\"multi: %s\"%self.paste_line_buffer)\r\n                    return True\r\n                else:\r\n                    return False", "response": "uPaste multi - line code into the clipboard."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ninitializes the editing mode.", "response": "def init_editing_mode(self, e): # (C-e)\r\n        u'''When in vi command mode, this causes a switch to emacs editing\r\n        mode.'''\r\n\r\n        self._bind_exit_key(u'Control-d')\r\n        self._bind_exit_key(u'Control-z')\r\n\r\n        # I often accidentally hold the shift or control while typing space\r\n        self._bind_key(u'Shift-space',       self.self_insert)\r\n        self._bind_key(u'Control-space',     self.self_insert)\r\n        self._bind_key(u'Return',            self.accept_line)\r\n        self._bind_key(u'Left',              self.backward_char)\r\n        self._bind_key(u'Control-b',         self.backward_char)\r\n        self._bind_key(u'Right',             self.forward_char)\r\n        self._bind_key(u'Control-f',         self.forward_char)\r\n        self._bind_key(u'BackSpace',         self.backward_delete_char)\r\n        self._bind_key(u'Home',              self.beginning_of_line)\r\n        self._bind_key(u'End',               self.end_of_line)\r\n        self._bind_key(u'Delete',            self.delete_char)\r\n        self._bind_key(u'Control-d',         self.delete_char)\r\n        self._bind_key(u'Clear',             self.clear_screen)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main(cls, args=None):\n        if args is None:\n            args = sys.argv[1:]\n\n        try:\n            o = cls()\n            o.parseOptions(args)\n        except usage.UsageError as e:\n            print(o.getSynopsis())\n            print(o.getUsage())\n            print(str(e))\n            return 1\n        except CLIError as ce:\n            print(str(ce))\n            return ce.returnCode\n\n        return 0", "response": "Main entry point for the\n            command - line interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a single three -ple of the following for all provided schemas.", "response": "def compose_schemas(*schemas):\n    \"\"\"\n    Returns a single three-ple of the following for all provided schemas:\n        - a map of attribute names to attributes for all related schema\n        attributes\n        - a set of names of all related required schema attributes\n        - a set of names of all related default schema attributes\n    For the sake of performance, values are written-to and returned-from the\n    jsonattrs cache.\n    \"\"\"\n    key = 'jsonattrs:compose:' + ','.join([str(s.pk) for s in schemas])\n    cached = caches['jsonattrs'].get(key)\n    if cached:\n        s_attrs, required_attrs, default_attrs = cached\n        # Deserialize attrs when retrieving from cache\n        attrs = OrderedDict((k, Attribute(**v)) for k, v in s_attrs.items())\n        return attrs, required_attrs, default_attrs\n\n    # Extract schema attributes, names of required attributes and\n    # names of attributes with defaults, composing schemas.\n    schema_attrs = [\n        s.attributes.select_related('attr_type').all() for s in schemas]\n    attrs = OrderedDict()\n    required_attrs = set()\n    default_attrs = set()\n    for attributes in schema_attrs:\n        for attr in attributes:\n            if attr.omit:\n                if attr.name in attrs:\n                    del attrs[attr.name]\n            else:\n                attrs[attr.name] = attr\n\n    required_attrs = {n for n, a in attrs.items() if a.required}\n    default_attrs = {n for n, a in attrs.items()\n                     if a.default is not None and a.default != ''}\n\n    # Serialize attrs to make it smaller in cache\n    s_attrs = OrderedDict((k, v.to_dict()) for k, v in attrs.items())\n    caches['jsonattrs'].set(key, (s_attrs, required_attrs, default_attrs))\n    return attrs, required_attrs, default_attrs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _index_files(path):\n        with zipfile.ZipFile(path) as zf:\n            names = sorted(zf.namelist())\n            names = [nn for nn in names if nn.endswith(\".tif\")]\n            names = [nn for nn in names if nn.startswith(\"SID PHA\")]\n            phasefiles = []\n            for name in names:\n                with zf.open(name) as pt:\n                    fd = io.BytesIO(pt.read())\n                    if SingleTifPhasics.verify(fd):\n                        phasefiles.append(name)\n            return phasefiles", "response": "Search zip file for SID PHA files and return list of unique SID PHA files."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlist of Phasics tif file names in the input zip file", "response": "def files(self):\n        \"\"\"List of Phasics tif file names in the input zip file\"\"\"\n        if self._files is None:\n            self._files = SeriesZipTifPhasics._index_files(self.path)\n        return self._files"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nverifies that path is a zip file with Phasics TIFF files", "response": "def verify(path):\n        \"\"\"Verify that `path` is a zip file with Phasics TIFF files\"\"\"\n        valid = False\n        try:\n            zf = zipfile.ZipFile(path)\n        except (zipfile.BadZipfile, IsADirectoryError):\n            pass\n        else:\n            names = sorted(zf.namelist())\n            names = [nn for nn in names if nn.endswith(\".tif\")]\n            names = [nn for nn in names if nn.startswith(\"SID PHA\")]\n            for name in names:\n                with zf.open(name) as pt:\n                    fd = io.BytesIO(pt.read())\n                    if SingleTifPhasics.verify(fd):\n                        valid = True\n                        break\n            zf.close()\n        return valid"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(pattern, *args, **kw):\n  '''\n  Given a package asset-spec glob-pattern `pattern`, returns an\n  :class:`AssetGroup` object, which in turn can act as a generator of\n  :class:`Asset` objects that match the pattern.\n\n  Example:\n\n  .. code-block:: python\n\n    import asset\n\n    # concatenate all 'css' files into one string:\n    css = asset.load('mypackage:static/style/**.css').read()\n\n  '''\n\n  spec = pattern\n\n  if ':' not in pattern:\n    raise ValueError('`pattern` must be in the format \"PACKAGE:GLOB\"')\n\n  pkgname, pkgpat = pattern.split(':', 1)\n  pkgdir, pattern = globre.compile(pkgpat, split_prefix=True, flags=globre.EXACT)\n\n  if pkgdir:\n    idx = pkgdir.rfind('/')\n    pkgdir = pkgdir[:idx] if idx >= 0 else ''\n\n  group = AssetGroup(pkgname, pkgdir, pattern, spec)\n  if globre.iswild(pkgpat):\n    return group\n  return Asset(group, pkgname, pkgpat)", "response": "Load an asset group from a package asset - spec glob - pattern pattern."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a generator of chunks from the given stream with a maximum size of size.", "response": "def chunks(stream, size=None):\n  '''\n  Returns a generator of chunks from the `stream` with a maximum\n  size of `size`. I don't know why this isn't part of core Python.\n\n  :Parameters:\n\n  stream : file-like object\n\n    The stream to fetch the chunks from. Note that the stream will\n    not be repositioned in any way.\n\n  size : int | 'lines'; default: null\n\n    If a integer, the size of the chunks to return. If the\n    string ``\"lines\"``, then behaves the same as `file.read()`.\n    If unspecified or null, defaults to the package default\n    MAXBUF size (usually 8 KiB).\n  '''\n  if size == 'lines':\n    for item in stream:\n    # for item in stream.readline():\n      yield item\n    return\n  if size is None:\n    size = MAXBUF\n  while True:\n    buf = stream.read(size)\n    if not buf:\n      return\n    yield buf"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a DEBUG log file COMMAND - YYYYMMDD - HHMMSS.ffffff. log.", "response": "def write_logfile():\n    # type: () -> None\n    \"\"\"Write a DEBUG log file COMMAND-YYYYMMDD-HHMMSS.ffffff.log.\"\"\"\n    command = os.path.basename(os.path.realpath(os.path.abspath(sys.argv[0])))\n    now = datetime.datetime.now().strftime('%Y%m%d-%H%M%S.%f')\n    filename = '{}-{}.log'.format(command, now)\n    with open(filename, 'w') as logfile:\n        if six.PY3:\n            logfile.write(_LOGFILE_STREAM.getvalue())\n        else:\n            logfile.write(_LOGFILE_STREAM.getvalue().decode(  # type: ignore\n                errors='replace'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nlog exceptions instead of printing a traceback to stderr.", "response": "def excepthook(type, value, traceback):  # pylint: disable=unused-argument\n    \"\"\"Log exceptions instead of printing a traceback to stderr.\"\"\"\n    try:\n        six.reraise(type, value, traceback)\n    except type:\n        _LOGGER.exception(str(value))\n    if isinstance(value, KeyboardInterrupt):\n        message = \"Cancelling at the user's request.\"\n    else:\n        message = handle_unexpected_exception(value)\n    print(message, file=sys.stderr)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an error message and write a log file if logging was not enabled.", "response": "def handle_unexpected_exception(exc):\n    # type: (BaseException) -> str\n    \"\"\"Return an error message and write a log file if logging was not enabled.\n\n    Args:\n        exc: The unexpected exception.\n\n    Returns:\n        A message to display to the user concerning the unexpected exception.\n    \"\"\"\n    try:\n        write_logfile()\n        addendum = 'Please see the log file for more information.'\n    except IOError:\n        addendum = 'Unable to write log file.'\n    try:\n        message = str(exc)\n        return '{}{}{}'.format(message, '\\n' if message else '', addendum)\n    except Exception:  # pylint: disable=broad-except\n        return str(exc)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_logging(log_level):\n    # type: (typing.Union[None, int]) -> None\n    \"\"\"Configure the root logger and a logfile handler.\n\n    Args:\n        log_level: The logging level to set the logger handler.\n    \"\"\"\n    root_logger = logging.getLogger()\n    root_logger.setLevel(logging.DEBUG)\n    logfile_handler = logging.StreamHandler(_LOGFILE_STREAM)\n    logfile_handler.setLevel(logging.DEBUG)\n    logfile_handler.setFormatter(logging.Formatter(\n        '%(levelname)s [%(asctime)s][%(name)s] %(message)s'))\n    root_logger.addHandler(logfile_handler)\n    if signal.getsignal(signal.SIGTERM) == signal.SIG_DFL:\n        signal.signal(signal.SIGTERM, _logfile_sigterm_handler)\n    if log_level:\n        handler = logging.StreamHandler()\n        handler.setFormatter(_LogColorFormatter())\n        root_logger.setLevel(log_level)\n        root_logger.addHandler(handler)", "response": "Configure the root logger and a logfile handler."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the log level from the CLI arguments.", "response": "def get_log_level(args):\n    # type: (typing.Dict[str, typing.Any]) -> int\n    \"\"\"Get the log level from the CLI arguments.\n\n    Removes logging arguments from sys.argv.\n\n    Args:\n        args: The parsed docopt arguments to be used to determine the logging\n            level.\n\n    Returns:\n        The correct log level based on the three CLI arguments given.\n\n    Raises:\n        ValueError: Raised if the given log level is not in the acceptable\n            list of values.\n    \"\"\"\n    index = -1\n    log_level = None\n    if '<command>' in args and args['<command>']:\n        index = sys.argv.index(args['<command>'])\n    if args.get('--debug'):\n        log_level = 'DEBUG'\n        if '--debug' in sys.argv and sys.argv.index('--debug') < index:\n            sys.argv.remove('--debug')\n        elif '-d' in sys.argv and sys.argv.index('-d') < index:\n            sys.argv.remove('-d')\n    elif args.get('--verbose'):\n        log_level = 'INFO'\n        if '--verbose' in sys.argv and sys.argv.index('--verbose') < index:\n            sys.argv.remove('--verbose')\n        elif '-v' in sys.argv and sys.argv.index('-v') < index:\n            sys.argv.remove('-v')\n    elif args.get('--log-level'):\n        log_level = args['--log-level']\n        sys.argv.remove('--log-level')\n        sys.argv.remove(log_level)\n    if log_level not in (None, 'DEBUG', 'INFO', 'WARN', 'ERROR'):\n        raise exceptions.InvalidLogLevelError(log_level)\n    return getattr(logging, log_level) if log_level else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _logfile_sigterm_handler(*_):\n    # type: (...) -> None\n    \"\"\"Handle exit signals and write out a log file.\n\n    Raises:\n        SystemExit: Contains the signal as the return code.\n    \"\"\"\n    logging.error('Received SIGTERM.')\n    write_logfile()\n    print('Received signal. Please see the log file for more information.',\n          file=sys.stderr)\n    sys.exit(signal)", "response": "Handles SIGTERM and SIGTERM signals and write out a log file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef format(self, record):\n        # type: (logging.LogRecord) -> str\n        \"\"\"Format the log record with timestamps and level based colors.\n\n        Args:\n            record: The log record to format.\n\n        Returns:\n            The formatted log record.\n        \"\"\"\n        if record.levelno >= logging.ERROR:\n            color = colorama.Fore.RED\n        elif record.levelno >= logging.WARNING:\n            color = colorama.Fore.YELLOW\n        elif record.levelno >= logging.INFO:\n            color = colorama.Fore.RESET\n        else:\n            color = colorama.Fore.CYAN\n        format_template = (\n            '{}{}%(levelname)s{} [%(asctime)s][%(name)s]{} %(message)s')\n        if sys.stdout.isatty():\n            self._fmt = format_template.format(\n                colorama.Style.BRIGHT,\n                color,\n                colorama.Fore.RESET,\n                colorama.Style.RESET_ALL\n            )\n        else:\n            self._fmt = format_template.format(*[''] * 4)\n        if six.PY3:\n            self._style._fmt = self._fmt  # pylint: disable=protected-access\n        return super(_LogColorFormatter, self).format(record)", "response": "Format the log record with timestamps and level based colors."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the OAuth2 URL for inviting the bot into servers.", "response": "def oauth_url(client_id, permissions=None, server=None, redirect_uri=None):\r\n    \"\"\"A helper function that returns the OAuth2 URL for inviting the bot\r\n    into servers.\r\n\r\n    Parameters\r\n    -----------\r\n    client_id : str\r\n        The client ID for your bot.\r\n    permissions : :class:`Permissions`\r\n        The permissions you're requesting. If not given then you won't be requesting any\r\n        permissions.\r\n    server : :class:`Server`\r\n        The server to pre-select in the authorization screen, if available.\r\n    redirect_uri : str\r\n        An optional valid redirect URI.\r\n    \"\"\"\r\n    url = 'https://discordapp.com/oauth2/authorize?client_id={}&scope=bot'.format(client_id)\r\n    if permissions is not None:\r\n        url = url + '&permissions=' + str(permissions.value)\r\n    if server is not None:\r\n        url = url + \"&guild_id=\" + server.id\r\n    if redirect_uri is not None:\r\n        from urllib.parse import urlencode\r\n        url = url + \"&response_type=code&\" + urlencode({'redirect_uri': redirect_uri})\r\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ask_question(self, question_text, question=None):\n        if question is not None:\n            q = question.to_dict()\n        else:\n            q = WatsonQuestion(question_text).to_dict()\n        r = requests.post(self.url + '/question', json={'question': q}, headers={\n            'Accept': 'application/json',\n            'X-SyncTimeout': 30\n        }, auth=(self.username, self.password))\n        try:\n            response_json = r.json()\n        except ValueError:\n            raise Exception('Failed to parse response JSON')\n        return WatsonAnswer(response_json)", "response": "Ask Watson a question via the Question and Answer API."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nloop and waits on queue calling queue s next_task method.", "response": "def process_queue(queue=None, **kwargs):\n    \"\"\"Loops and waits on queue calling queue's `next_task` method.\n\n    If an exception occurs, log the error, log the exception,\n    and break.\n    \"\"\"\n    while True:\n        item = queue.get()\n        if item is None:\n            queue.task_done()\n            logger.info(f\"{queue}: exiting process queue.\")\n            break\n        filename = os.path.basename(item)\n        try:\n            queue.next_task(item, **kwargs)\n        except Exception as e:\n            queue.task_done()\n            logger.warn(f\"{queue}: item={filename}. {e}\\n\")\n            logger.exception(e)\n            sys.stdout.write(\n                style.ERROR(\n                    f\"{queue}. item={filename}. {e}. Exception has been logged.\\n\"\n                )\n            )\n            sys.stdout.flush()\n            break\n        else:\n            logger.info(f\"{queue}: Successfully processed {filename}.\\n\")\n        queue.task_done()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fs_cache(app_name='', cache_type='', idx=1,\n             expires=DEFAULT_EXPIRES, cache_dir='', helper_class=_FSCacher):\n    \"\"\"\n    A decorator to cache results of functions returning\n    pd.DataFrame or pd.Series objects under:\n    <cache_dir>/<app_name>/<cache_type>/<func_name>.<param_string>.csv,\n    missing parts, like app_name and cache_type, will be omitted\n\n    If cache_dir is omitted, stutils 'ST_FS_CACHE_PATH' conf dir will be used.\n    If 'ST_FS_CACHE_PATH' is not configured, a temporary directory\n    will be created.\n\n    :param app_name: if present, cache files for this application will be\n        stored in a separate folder\n    :param idx: number of columns to use as an index\n    :param cache_type: if present, cache files within app directory will be\n        separated into different folders by their cache_type.\n    :param expires: cache duration in seconds\n    :param cache_dir: set custom file cache path\n    \"\"\"\n\n    def decorator(func):\n        return helper_class(func, cache_dir, app_name, cache_type, idx, expires)\n\n    return decorator", "response": "A function decorator that creates a temporary directory and stores the results of functions returning a pd. DataFrame or pd. Series objects under the specified cache_dir."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cached_method(func):\n    @functools.wraps(func)\n    def wrapper(self, *args):\n        if not hasattr(self, \"_cache\"):\n            self._cache = {}\n        key = _argstring((func.__name__,) + args)\n        if key not in self._cache:\n            self._cache[key] = func(self, *args)\n        return self._cache[key]\n    return wrapper", "response": "Memoize for class methods"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef guard(func):\n    semaphore = threading.Lock()\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        semaphore.acquire()\n        try:\n            return func(*args, **kwargs)\n        finally:\n            semaphore.release()\n\n    return wrapper", "response": "A decorator that prevents the decorated function from parallel execution."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply stutils.mapreduce.map to the given function", "response": "def threadpool(num_workers=None):\n    \"\"\"Apply stutils.mapreduce.map to the given function\"\"\"\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(data):\n            return mapreduce.map(func, data, num_workers)\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef invalidate_all(self):\n        for fname in os.listdir(self.cache_path):\n            if fname.startswith(self.func.__name__ + \".\"):\n                os.remove(os.path.join(self.cache_path, fname))", "response": "Remove all files caching this function"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef key(self):\n\n        return [part.strip() for part in self.href.split(\"/\") if part.strip()][\n            -1]", "response": "Return the key of the resource."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a PluginSet object for the specified setuptools - style order of plugins.", "response": "def plugins(group, spec=None):\n  # TODO: share this documentation with `../doc/plugin.rst`...\n  '''\n  Returns a `PluginSet` object for the specified setuptools-style\n  entrypoint `group`. This is just a wrapper around\n  `pkg_resources.iter_entry_points` that allows the plugins to sort\n  and override themselves.\n\n  The optional `spec` parameter controls how and what plugins are\n  loaded. If it is ``None`` or the special value ``'*'``, then the\n  normal plugin loading will occur, i.e. all registered plugins will\n  be loaded and their self-declared ordering and dependencies will be\n  applied.\n\n  Otherwise, the `spec` is taken as a comma- or whitespace-separated\n  list of plugins to load. In this mode, the `spec` can either specify\n  an exact list of plugins to load, in the specified order, referred\n  to as an \"absolute\" spec. Otherwise, it is a \"relative\" spec, which\n  indicates that it only adjusts the standard registered plugin\n  loading. A spec is a list of either absolute or relative\n  instructions, and they cannot be mixed.\n\n  In either mode, a plugin is identified either by name for registered\n  plugins (e.g. ``foo``), or by fully-qualified Python module and\n  symbol name for unregistered plugins\n  (e.g. ``package.module.symbol``).\n\n  Plugins in an absolute spec are loaded in the order specified and\n  can be optionally prefixed with the following special characters:\n\n  * ``'?'`` : the specified plugin should be loaded if available.  If\n    it is not registered, cannot be found, or cannot be loaded, then\n    it is ignored (a DEBUG log message will be emitted, however).\n\n  Plugins in a relative spec are always prefixed with at least one of\n  the following special characters:\n\n  * ``'-'`` : removes the specified plugin; this does not affect\n    plugin ordering, it only removes the plugin from the loaded\n    list. If the plugin does not exist, no error is thrown.\n\n  * ``'+'`` : adds or requires the specified plugin to the loaded\n    set. If the plugin is not a named/registered plugin, then it will\n    be loaded as an asset-symbol, i.e. a Python-dotted module and\n    symbol name. If the plugin does not exist or cannot be loaded,\n    this will throw an error. It does not affect the plugin ordering\n    of registered plugins.\n\n  * ``'/'`` : the plugin name is taken as a regular expression that\n    will be used to match plugin names and it must terminate in a\n    slash. Note that this must be the **last** element in the spec\n    list.\n\n  Examples:\n\n  * ``'*'`` : load all registered plugins.\n\n  * ``'foo,bar'`` : load the \"foo\" plugin, then the \"bar\" plugin.\n\n  * ``'foo,?bar'`` : load the \"foo\" plugin and if the \"bar\" plugin\n    exists, load it too.\n\n  * ``'-zig'`` : load all registered plugins except the \"zig\" plugin.\n\n  * ``'+pkg.foo.bar'`` : load all registered plugins and then load\n    the \"pkg.foo.bar\" Python symbol.\n\n  * ``'pkg.foo.bar'`` : load only the \"pkg.foo.bar\" Python symbol.\n  '''\n  pspec  = _parse_spec(spec)\n  plugs  = list(_get_registered_plugins(group, pspec))\n  plugs  += list(_get_unregistered_plugins(group, plugs, pspec))\n  return PluginSet(group, spec, list(_sort_plugins(group, plugs, pspec, spec)))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling each plugin in this PluginSet with the specified object arguments and keywords in the standard group plugin order.", "response": "def handle(self, object, *args, **kw):\n    '''\n    Calls each plugin in this PluginSet with the specified object,\n    arguments, and keywords in the standard group plugin order. The\n    return value from each successive invoked plugin is passed as the\n    first parameter to the next plugin. The final return value is the\n    object returned from the last plugin.\n\n    If this plugin set is empty (i.e. no plugins exist or matched the\n    spec), then a ValueError exception is thrown.\n    '''\n    if not bool(self):\n      if not self.spec or self.spec == SPEC_ALL:\n        raise ValueError('No plugins available in group %r' % (self.group,))\n      raise ValueError(\n        'No plugins in group %r matched %r' % (self.group, self.spec))\n    for plugin in self.plugins:\n      object = plugin.handle(object, *args, **kw)\n    return object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the object passed to the plugin set.", "response": "def filter(self, object, *args, **kw):\n    '''\n    Identical to `PluginSet.handle`, except:\n\n    #. If this plugin set is empty, `object` is returned as-is.\n    #. If any plugin returns ``None``, it is returned without\n       calling any further plugins.\n    '''\n    for plugin in self.plugins:\n      object = plugin.handle(object, *args, **kw)\n      if object is None:\n        return object\n    return object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new PluginSet that has only the plugins in this that are named name.", "response": "def select(self, name):\n    '''\n    Returns a new PluginSet that has only the plugins in this that are\n    named `name`.\n    '''\n    return PluginSet(self.group, name, [\n      plug for plug in self.plugins if plug.name == name])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef browse_home_listpage_url(self,\n                                 state=None,\n                                 county=None,\n                                 zipcode=None,\n                                 street=None,\n                                 **kwargs):\n        \"\"\"\n        Construct an url of home list page by state, county, zipcode, street.\n\n        Example:\n\n        - https://www.zillow.com/browse/homes/ca/\n        - https://www.zillow.com/browse/homes/ca/los-angeles-county/\n        - https://www.zillow.com/browse/homes/ca/los-angeles-county/91001/\n        - https://www.zillow.com/browse/homes/ca/los-angeles-county/91001/tola-ave_5038895/\n        \"\"\"\n        url = self.domain_browse_homes\n        for item in [state, county, zipcode, street]:\n            if item:\n                url = url + \"/%s\" % item\n        url = url + \"/\"\n        return url", "response": "Construct an url of home list page by state county zipcode street."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef hamming(s, t):\n    if len(s) != len(t):\n        raise ValueError('Hamming distance needs strings of equal length.')\n    return sum(s_ != t_ for s_, t_ in zip(s, t))", "response": "Calculate the Hamming distance between two strings. From Wikipedia article"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nrender the HTML for a bundle in place", "response": "def _render_bundle(bundle_name):\n    \"\"\"\n    Renders the HTML for a bundle in place - one HTML tag or many depending on settings.USE_BUNDLES\n    \"\"\"\n    try:\n        bundle = get_bundles()[bundle_name]\n    except KeyError:\n        raise ImproperlyConfigured(\"Bundle '%s' is not defined\" % bundle_name)\n\n    if bundle.use_bundle:\n        return _render_file(bundle.bundle_type, bundle.get_url(), attrs=({'media':bundle.media} if bundle.media else {}))\n\n    # Render files individually\n    bundle_files = []\n\n    for bundle_file in bundle.files:\n        if bundle_file.precompile_in_debug:\n            bundle_files.append(_render_file(bundle_file.bundle_type, bundle_file.precompile_url, attrs=({'media':bundle_file.media} if bundle.media else {})))\n        else:\n            bundle_files.append(_render_file(bundle_file.file_type, bundle_file.file_url, attrs=({'media':bundle_file.media} if bundle.media else {})))\n\n    return '\\n'.join(bundle_files)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract resource data from the given string representation and converts them to a new resource or updates the given resource.", "response": "def from_string(self, string_representation, resource=None):\n        \"\"\"\n        Extracts resource data from the given string and converts them to\n        a new resource or updates the given resource from it.\n        \"\"\"\n        stream = NativeIO(string_representation)\n        return self.from_stream(stream, resource=resource)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract resource data from the given bytes representation and calls from_string with the resulting text representation.", "response": "def from_bytes(self, bytes_representation, resource=None):\n        \"\"\"\n        Extracts resource data from the given bytes representation and calls\n        :method:`from_string` with the resulting text representation.\n        \"\"\"\n        text = bytes_representation.decode(self.encoding)\n        return self.from_string(text, resource=resource)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the given resource to a string representation and returns it.", "response": "def to_string(self, obj):\n        \"\"\"\n        Converts the given resource to a string representation and returns\n        it.\n        \"\"\"\n        stream = NativeIO()\n        self.to_stream(obj, stream)\n        return text_(stream.getvalue(), encoding=self.encoding)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef to_bytes(self, obj, encoding=None):\n        if encoding is None:\n            encoding = self.encoding\n        text = self.to_string(obj)\n        return bytes_(text, encoding=self.encoding)", "response": "Converts the given resource to bytes representation in the specified encoding and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts the given bytes representation to resource data.", "response": "def data_from_bytes(self, byte_representation):\n        \"\"\"\n        Converts the given bytes representation to resource data.\n        \"\"\"\n        text = byte_representation.decode(self.encoding)\n        return self.data_from_string(text)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the given data element into a string representation.", "response": "def data_to_string(self, data_element):\n        \"\"\"\n        Converts the given data element into a string representation.\n\n        :param data_element: object implementing\n            :class:`everest.representers.interfaces.IExplicitDataElement`\n        :returns: string representation (using the MIME content type\n            configured for this representer)\n        \"\"\"\n        stream = NativeIO()\n        self.data_to_stream(data_element, stream)\n        return stream.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef data_to_bytes(self, data_element, encoding=None):\n        if encoding is None:\n            encoding = self.encoding\n        text = self.data_to_string(data_element)\n        return bytes_(text, encoding=encoding)", "response": "Converts the given data element into a byte string representation using the : method data_to_string method and encodes the resulting bytes representation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_from_resource_class(cls, resource_class):\n        mp_reg = get_mapping_registry(cls.content_type)\n        mp = mp_reg.find_or_create_mapping(resource_class)\n        return cls(resource_class, mp)", "response": "Creates a new representer from the given resource class."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef data_from_stream(self, stream):\n        parser = self._make_representation_parser(stream, self.resource_class,\n                                                  self._mapping)\n        return parser.run()", "response": "Creates a data element reading a representation from the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the given data element to the given stream.", "response": "def data_to_stream(self, data_element, stream):\n        \"\"\"\n        Writes the given data element to the given stream.\n        \"\"\"\n        generator = \\\n            self._make_representation_generator(stream, self.resource_class,\n                                                self._mapping)\n        generator.run(data_element)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting the given data element to a resource.", "response": "def resource_from_data(self, data_element, resource=None):\n        \"\"\"\n        Converts the given data element to a resource.\n\n        :param data_element: object implementing\n            :class:`everest.representers.interfaces.IExplicitDataElement`\n        \"\"\"\n        return self._mapping.map_to_resource(data_element, resource=resource)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the options and attribute options of the mapping associated with this representer with the given dictionaries.", "response": "def configure(self, options=None, attribute_options=None): # pylint: disable=W0221\n        \"\"\"\n        Configures the options and attribute options of the mapping associated\n        with this representer with the given dictionaries.\n\n        :param dict options: configuration options for the mapping associated\n          with this representer.\n        :param dict attribute_options: attribute options for the mapping\n          associated with this representer.\n        \"\"\"\n        self._mapping.update(options=options,\n                             attribute_options=attribute_options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef with_updated_configuration(self, options=None,\n                                   attribute_options=None):\n        \"\"\"\n        Returns a context in which this representer is updated with the\n        given options and attribute options.\n        \"\"\"\n        return self._mapping.with_updated_configuration(options=options,\n                                                        attribute_options=\n                                                            attribute_options)", "response": "Returns a new context with the given options and attribute options updated."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves a particle to a new location given a starting point u v and w velocity components.", "response": "def move(self, particle, u, v, w, modelTimestep, **kwargs):\n        \"\"\"\n        Returns the lat, lon, H, and velocity of a projected point given a starting\n        lat and lon (dec deg), a depth (m) below sea surface (positive up), u, v, and w velocity components (m/s), a horizontal and vertical\n        displacement coefficient (m^2/s) H (m), and a model timestep (s).\n\n        GreatCircle calculations are done based on the Vincenty Direct method.\n\n        Returns a dict like:\n            {   'latitude': x, \n                'azimuth': x,\n                'reverse_azimuth': x, \n                'longitude': x, \n                'depth': x, \n                'u': x\n                'v': x, \n                'w': x, \n                'distance': x, \n                'angle': x, \n                'vertical_distance': x, \n                'vertical_angle': x }\n        \"\"\"\n\n        logger.debug(\"U: %s, V: %s, W: %s\" % (str(u),str(v),str(w)))\n\n        # IMPORTANT:\n        # If we got no data from the model, we are using the last available value stored in the particles!\n        if (u is None) or (u is not None and math.isnan(u)):\n            u = particle.last_u()\n        if (v is None) or (v is not None and math.isnan(v)):\n            v = particle.last_v()\n        if (w is None) or (w is not None and math.isnan(w)):\n            w = particle.last_w()\n\n        particle.u_vector = u\n        particle.v_vector = v\n        particle.w_vector = w\n\n        if particle.halted:\n            u,v,w = 0,0,0\n        else:\n            u += AsaRandom.random() * ((2 * self._horizDisp / modelTimestep) ** 0.5) # u transformation calcualtions\n            v += AsaRandom.random() * ((2 * self._horizDisp / modelTimestep) ** 0.5) # v transformation calcualtions\n            w += AsaRandom.random() * ((2 * self._vertDisp / modelTimestep) ** 0.5) # w transformation calculations\n\n        result = AsaTransport.distance_from_location_using_u_v_w(u=u, v=v, w=w, timestep=modelTimestep, location=particle.location)\n        result['u'] = u\n        result['v'] = v\n        result['w'] = w\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jsPath(path):\n    '''Returns a relative path without \\, -, and . so that \n    the string will play nicely with javascript.'''\n    shortPath=path.replace(\n            \"C:\\\\Users\\\\scheinerbock\\\\Desktop\\\\\"+\n            \"ideogram\\\\scrapeSource\\\\test\\\\\",\"\")\n    noDash = shortPath.replace(\"-\",\"_dash_\")\n    jsPath=noDash.replace(\"\\\\\",\"_slash_\").replace(\".\",\"_dot_\")\n    return jsPath", "response": "Returns a relative path with \\ - and. so that \n    the string will play nicely with javascript."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jsName(path,name):\n    '''Returns a name string without \\, -, and . so that \n    the string will play nicely with javascript.'''\n    shortPath=path.replace(\n            \"C:\\\\Users\\\\scheinerbock\\\\Desktop\\\\\"+\n            \"ideogram\\\\scrapeSource\\\\test\\\\\",\"\")\n    noDash = shortPath.replace(\"-\",\"_dash_\")\n    jsPath=noDash.replace(\"\\\\\",\"_slash_\").replace(\".\",\"_dot_\")\n    jsName=jsPath+'_slash_'+name\n    return jsName", "response": "Returns a name string with \\ - and. so that \n    the string will play nicely with javascript."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a list of nodes in fdefs that have no inbound edges", "response": "def getStartNodes(fdefs,calls):\n    '''Return a list of nodes in fdefs that have no inbound edges'''\n    s=[]\n    for source in fdefs:\n        for fn in fdefs[source]:\n            inboundEdges=False\n            for call in calls:\n                if call.target==fn:\n                    inboundEdges=True\n            if not inboundEdges:\n                s.append(fn)\n    return s"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef jsonGraph(fdefs,calls,outfile='nout.json'):\n    '''For reference, each node has:\n    \n    node.name   (string)\n    node.source (string)\n    node.weight (int)\n    node.pclass (class node object) \n    \n    Each call contains a node in call.source and call.target\n    '''\n    outpath = os.path.join('data',outfile)\n    data = dict()\n    ids = dict()\n    nodelist = []\n    for fnlist in fdefs.values():\n        for fn in fnlist:\n            if isInCalls(fn,calls):\n                tagged_node = getTaggedNode(fn,ids)\n                nodelist.append(tagged_node)\n            else:\n                #print(\"omitted\")\n                pass\n    linklist = [] #list of links, NOT a linked list ;D\n    for call in calls:\n        for link in linklist:\n            if call.source.id == link[\"source\"]:\n                if call.target.id == link[\"target\"]:\n                    link[\"value\"] += 1\n                    break\n        else:\n            link = dict()\n            link[\"source\"] = call.source.id\n            link[\"target\"] = call.target.id\n            link[\"value\"]  = 1\n            linklist.append(link)\n    \n    data[\"links\"] = linklist\n    data[\"nodes\"] = nodelist\n    with open(outpath, 'w+') as f:\n        f.write(json.dumps(data, indent=2))\n    return", "response": "This function creates a JSON graph of the given fdefs and calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a list of the children of current that are not in used.", "response": "def getChildren(current,calls,blacklist=[]):\n    ''' Return a list of the children of current that are not in used. '''\n    return [c.target for c in calls if c.source==current and c.target not in blacklist]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tagAttributes_while(fdef_master_list,root):\n    '''Tag each node under root with the appropriate depth. '''\n    depth = 0\n    current = root\n    untagged_nodes = [root]\n    while untagged_nodes:\n        current = untagged_nodes.pop()\n        for x in fdef_master_list:\n            if jsName(x.path,x.name) == current['name']:\n                current['path'] = x.path\n        if children in current:\n            for child in children:\n                child[\"depth\"] = depth\n                untagged_nodes.append(child)\n        if depth not in current:\n            current[\"depth\"] = depth\n            depth += 1\n    return root", "response": "Tag each node under root with the appropriate depth."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_old_tmp_files(profiles=None, max_lifetime=(7 * 24)):\n    assert isinstance(profiles, (list, tuple)) or profiles is None\n    if profiles is None:\n        profiles = dju_settings.DJU_IMG_UPLOAD_PROFILES.keys()\n    profiles = set(('default',) + tuple(profiles))\n    total = removed = 0\n    old_dt = datetime.datetime.utcnow() - datetime.timedelta(hours=max_lifetime)\n    for profile in profiles:\n        conf = get_profile_configs(profile=profile)\n        root_path = os.path.join(settings.MEDIA_ROOT, dju_settings.DJU_IMG_UPLOAD_SUBDIR, conf['PATH'])\n        for file_path in get_files_recursive(root_path):\n            m = re_tmp.match(os.path.basename(file_path))\n            if m is None:\n                continue\n            total += 1\n            fdt = dtstr_to_datetime(m.group('dtstr'))\n            if fdt and old_dt > fdt:\n                os.remove(file_path)\n                removed += 1\n    return removed, total", "response": "Removes old temp files that are older than expiration_hours."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove all images from the given list of profiles.", "response": "def remake_images_variants(profiles, clear=True):\n    \"\"\"\n    \u041f\u0435\u0440\u0435\u0441\u0442\u0432\u043e\u0440\u044e\u0454 \u0432\u0430\u0440\u0456\u0430\u043d\u0442\u0438 \u0434\u043b\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u0437\u0433\u0456\u0434\u043d\u043e \u043d\u0430\u043b\u0430\u0448\u0442\u0443\u0432\u0430\u043d\u044c.\n    profiles - \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u0440\u043e\u0444\u0456\u043b\u0456\u0432, \u0434\u043b\u044f \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u044f\u043a\u0438\u0445 \u0442\u0440\u0435\u0431\u0430 \u043f\u0435\u0440\u0435\u0441\u0442\u0432\u043e\u0440\u0438\u0442\u0438 \u0432\u0430\u0440\u0456\u0430\u043d\u0442\u0438.\n    clear - \u044f\u043a\u0449\u043e True, \u0442\u043e\u0434\u0456 \u043f\u0435\u0440\u0435\u0434 \u0441\u0442\u0432\u043e\u0440\u0435\u043d\u043d\u044f\u043c \u0432\u0430\u0440\u0456\u0430\u043d\u0442\u0456\u0432 \u0431\u0443\u0434\u0443\u0442\u044c \u0432\u0438\u0434\u0430\u043b\u0435\u043d\u0456 \u0412\u0421\u0406 \u043f\u043e\u043f\u0435\u0440\u0435\u0434\u043d\u0456 \u0432\u0430\u0440\u0456\u0430\u043d\u0442\u0438.\n    \"\"\"\n    assert isinstance(profiles, (list, tuple)) or profiles is None\n    if profiles is None:\n        profiles = dju_settings.DJU_IMG_UPLOAD_PROFILES.keys()\n    profiles = set(('default',) + tuple(profiles))\n    removed = remade = 0\n    for profile in profiles:\n        conf = get_profile_configs(profile=profile)\n        root_path = os.path.join(settings.MEDIA_ROOT, dju_settings.DJU_IMG_UPLOAD_SUBDIR, conf['PATH'])\n        if clear:\n            for fn in get_files_recursive(root_path):\n                if dju_settings.DJU_IMG_UPLOAD_VARIANT_SUFFIX in os.path.basename(fn):\n                    os.remove(fn)\n                    removed += 1\n        for fn in get_files_recursive(root_path):\n            filename = os.path.basename(fn)\n            if dju_settings.DJU_IMG_UPLOAD_VARIANT_SUFFIX in filename:\n                continue\n            if dju_settings.DJU_IMG_UPLOAD_MAIN_SUFFIX not in filename:\n                continue\n            img_id = '{profile}:{name}'.format(\n                profile=profile,\n                name=filename[:filename.find(dju_settings.DJU_IMG_UPLOAD_MAIN_SUFFIX)]\n            )\n            with open(fn, 'rb') as f:\n                for v_conf in conf['VARIANTS']:\n                    label = v_conf['LABEL']\n                    if not label:\n                        label = get_variant_label(v_conf)\n                    v_f = adjust_image(f, max_size=v_conf['MAX_SIZE'], new_format=v_conf['FORMAT'],\n                                       jpeg_quality=v_conf['JPEG_QUALITY'], fill=v_conf['FILL'],\n                                       stretch=v_conf['STRETCH'], return_new_image=True)\n                    v_relative_path = get_relative_path_from_img_id(img_id, variant_label=label,\n                                                                    ext=image_get_format(v_f))\n                    v_full_path = media_path(v_relative_path)\n                    save_file(v_f, v_full_path)\n                    remade += 1\n    return removed, remade"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef next_task(self, item, **kwargs):\n        filename = os.path.basename(item)\n        try:\n            self.tx_importer.import_batch(filename=filename)\n        except TransactionImporterError as e:\n            raise TransactionsFileQueueError(e) from e\n        else:\n            self.archive(filename)", "response": "Calls import_batch for the next filename in the queue\n        and archives the file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_public_comments_for_model(model):\n    if not IS_INSTALLED:\n        # No local comments, return empty queryset.\n        # The project might be using DISQUS or Facebook comments instead.\n        return CommentModelStub.objects.none()\n    else:\n        return CommentModel.objects.for_model(model).filter(is_public=True, is_removed=False)", "response": "Get public comments for the given model."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_comments_are_open(instance):\n    if not IS_INSTALLED:\n        return False\n\n    try:\n        # Get the moderator which is installed for this model.\n        mod = moderator._registry[instance.__class__]\n    except KeyError:\n        # No moderator = no restrictions\n        return True\n\n    # Check the 'enable_field', 'auto_close_field' and 'close_after',\n    # by reusing the basic Django policies.\n    return CommentModerator.allow(mod, None, instance, None)", "response": "Check if comments are open for the instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_comments_are_moderated(instance):\n    if not IS_INSTALLED:\n        return False\n\n    try:\n        # Get the moderator which is installed for this model.\n        mod = moderator._registry[instance.__class__]\n    except KeyError:\n        # No moderator = no moderation\n        return False\n\n    # Check the 'auto_moderate_field', 'moderate_after',\n    # by reusing the basic Django policies.\n    return CommentModerator.moderate(mod, None, instance, None)", "response": "Check if comments are moderated for the given instance."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate local indices for local data field", "response": "def calc_local_indices(shape, num_partitions, coordinate):\n    \"\"\" calculate local indices, return start and stop index per dimension per process for local data field\n\n    :param shape: global shape of data\n    :param num_partitions: number of partition for each dimension (from MPI.Compute_dims())\n    :param coordinate: cartesian coordinate descriptor (from CARTESIAN_COMMUNICATOR.Get_coords(rank))\n\n    :return: tuple of start/stop index per dimension ((start_x, stop_x), (start_y, stop_y), ...)\n    \"\"\"\n    dimension = len(shape)\n    # check matching of cartesian communicator and shape\n    assert dimension == len(num_partitions)\n\n    decomposed_shapes = []\n    # build shape list for every dimension\n    for idx in range(dimension):\n        local_shape = shape[idx] // num_partitions[idx]\n        temp_shape_list = []\n\n        for _ in range(num_partitions[idx]):\n            temp_shape_list.append(local_shape)\n\n        # expand local partitions to match global shape\n        for j in range(shape[idx] % num_partitions[idx]):\n            temp_shape_list[j] += 1\n\n        # decomposed_shapes[dimension][partition]\n        decomposed_shapes.append(temp_shape_list)\n\n    # calculate indices for partitions\n    indices = []\n\n    # TODO: redefine calculation -> first select and calculate\n    for i in range(dimension):\n\n        temp_index_list = []\n\n        start_idx = 0\n        end_idx = 0\n\n        for j in range(num_partitions[i]):\n\n            end_idx = end_idx + decomposed_shapes[i][j]\n            temp_index_list.append([start_idx, end_idx])\n            start_idx = end_idx\n\n        indices.append(temp_index_list)\n\n    start_index = []\n    stop_index = []\n    shape = []\n\n    # select partition, start and stop index\n    for idx in range(dimension):\n        start_index.append(indices[idx][coordinate[idx]][0])\n        stop_index.append(indices[idx][coordinate[idx]][1])\n        shape.append(decomposed_shapes[idx][coordinate[idx]])\n\n    shape = tuple(shape)\n    start_index = tuple(start_index)\n    stop_index = tuple(stop_index)\n    return start_index, stop_index, shape"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_file(self, filename):\n        with open(filename, 'r') as sourcefile:\n            self.set_string(sourcefile.read())", "response": "Read in file contents and set the current string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_string(self, string):\n        self.string = string\n        self.length = len(string)\n        self.reset_position()", "response": "Set the working string and its length then reset positions."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds to the working string and its length and reset eos.", "response": "def add_string(self, string):\n        \"\"\"Add to the working string and its length and reset eos.\"\"\"\n        self.string += string\n        self.length += len(string)\n        self.eos = 0"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreset all current positions.", "response": "def reset_position(self):\n        \"\"\"Reset all current positions.\"\"\"\n        self.pos = 0\n        self.col = 0\n        self.row = 1\n        self.eos = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns boolean indicating if the current working string has at least length characters.", "response": "def has_space(self, length=1, offset=0):\n        \"\"\"Returns boolean if self.pos + length < working string length.\"\"\"\n        return self.pos + (length + offset) - 1 < self.length"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef eol_distance_next(self, offset=0):\n        distance = 0\n        for char in self.string[self.pos + offset:]:\n            if char == '\\n':\n                break\n            else:\n                distance += 1\n        return distance", "response": "Return the amount of characters until the next newline."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef eol_distance_last(self, offset=0):\n        distance = 0\n        for char in reversed(self.string[:self.pos + offset]):\n            if char == '\\n':\n                break\n            else:\n                distance += 1\n        return distance", "response": "Return the ammount of characters until the last newline."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving current position backwards by length.", "response": "def spew_length(self, length):\n        \"\"\"Move current position backwards by length.\"\"\"\n        pos = self.pos\n        if not pos or length > pos:\n            return None\n\n        row = self.row\n        for char in reversed(self.string[pos - length:pos]):\n            pos -= 1\n            if char == '\\n':  # handle a newline char\n                row -= 1\n\n        self.pos = pos\n        self.col = self.eol_distance_last()\n        self.row = row\n\n        if self.has_space():  # Set eos if there is no more space left.\n            self.eos = 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eat_length(self, length):\n        pos = self.pos\n        if self.eos or pos + length > self.length:\n            return None\n\n        col = self.col\n        row = self.row\n        for char in self.string[pos:pos + length]:\n            col += 1\n            pos += 1\n            if char == '\\n':  # handle a newline char\n                col = 0\n                row += 1\n\n        self.pos = pos\n        self.col = col\n        self.row = row\n\n        if not self.has_space():  # Set eos if there is no more space left.\n            self.eos = 1", "response": "Move current position forward by length and sets eos if needed."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmove current position by length of string and count lines by \\ n.", "response": "def eat_string(self, string):\n        \"\"\"Move current position by length of string and count lines by \\n.\"\"\"\n        pos = self.pos\n        if self.eos or pos + len(string) > self.length:\n            return None\n\n        col = self.col\n        row = self.row\n        for char in string:\n            col += 1\n            pos += 1\n            if char == '\\n':  # handle a newline char\n                col = 0\n                row += 1\n\n        self.pos = pos\n        self.col = col\n        self.row = row\n\n        if not self.has_space():  # Set eos if there is no more space left.\n            self.eos = 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef eat_line(self):\n        if self.eos:\n            return None\n        eat_length = self.eat_length\n        get_char = self.get_char\n        has_space = self.has_space\n        while has_space() and get_char() != '\\n':\n            eat_length(1)\n        eat_length(1)", "response": "Move current position forward until the next line."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_char(self, offset=0):\n        if not self.has_space(offset=offset):\n            return ''\n\n        return self.string[self.pos + offset]", "response": "Return the current character in the working string."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_length(self, length, trim=0, offset=0):\n        if trim and not self.has_space(offset + length):\n            return self.string[self.pos + offset:]\n        elif self.has_space(offset + length):\n            return self.string[self.pos + offset:self.pos + offset + length]\n        else:\n            return ''", "response": "Return string at current position + length."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a string from current position until a whitespace.", "response": "def get_string(self, offset=0):\n        \"\"\"Return non space chars from current position until a whitespace.\"\"\"\n        if not self.has_space(offset=offset):\n            return ''\n\n        # Get a char for each char in the current string from pos onward\n        #  solong as the char is not whitespace.\n        string = self.string\n        pos = self.pos + offset\n        for i, char in enumerate(string[pos:]):\n            if char.isspace():\n                return string[pos:pos + i]\n        else:\n            return string[pos:]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rest_of_string(self, offset=0):\n        if self.has_space(offset=offset):\n            return self.string[self.pos + offset:]\n        else:\n            return ''", "response": "A copy of the current position till the end of the source string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a SourceLine of the current line.", "response": "def get_current_line(self):\n        \"\"\"Return a SourceLine of the current line.\"\"\"\n        if not self.has_space():\n            return None\n\n        pos = self.pos - self.col\n        string = self.string\n        end = self.length\n\n        output = []\n        while pos < len(string) and string[pos] != '\\n':\n            output.append(string[pos])\n            pos += 1\n            if pos == end:\n                break\n        else:\n            output.append(string[pos])\n\n        if not output:\n            return None\n\n        return SourceLine(''.join(output), self.row)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_lines(self, first, last):\n        line = 1\n        linestring = []\n        linestrings = []\n        for char in self.string:\n            if line >= first and line <= last:\n                linestring.append(char)\n                if char == '\\n':\n                    linestrings.append((''.join(linestring), line))\n                    linestring = []\n            elif line > last:\n                break\n\n            if char == '\\n':\n                line += 1\n        if linestring:\n            linestrings.append((''.join(linestring), line))\n        elif not linestrings:\n            return None\n\n        return [SourceLine(string, lineno) for string, lineno in linestrings]", "response": "Return SourceLines for lines between and including first & last."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_surrounding_lines(self, past=1, future=1):\n        string = self.string\n        pos = self.pos - self.col\n        end = self.length\n        row = self.row\n\n        linesback = 0\n        while linesback > -past:\n            if pos <= 0:\n                break\n            elif string[pos - 2] == '\\n':\n                linesback -= 1\n            pos -= 1\n\n        output = []\n        linestring = []\n        lines = future + 1\n        while linesback < lines:\n            if pos >= end:\n                linestring.append(string[pos - 1])\n                output.append(\n                    SourceLine(''.join(linestring[:-1]), row + linesback))\n                break\n            elif string[pos] == '\\n':\n                linestring.append(string[pos])\n                pos += 1\n                output.append(\n                    SourceLine(''.join(linestring), row + linesback))\n                linesback += 1\n                linestring = []\n            linestring.append(string[pos])\n            pos += 1\n\n        return output", "response": "Return the current line and x y previous and future lines."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning all lines of the SourceString as a list of SourceLine s.", "response": "def get_all_lines(self):\n        \"\"\"Return all lines of the SourceString as a list of SourceLine's.\"\"\"\n        output = []\n        line = []\n        lineno = 1\n        for char in self.string:\n            line.append(char)\n            if char == '\\n':\n                output.append(SourceLine(''.join(line), lineno))\n                line = []\n                lineno += 1\n        if line:\n            output.append(SourceLine(''.join(line), lineno))\n\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning 1 if string can be matches against SourceString s current position.", "response": "def match_string(self, string, word=0, offset=0):\n        \"\"\"Returns 1 if string can be matches against SourceString's\n        current position.\n\n        If word is >= 1 then it will only match string followed by whitepsace.\n        \"\"\"\n        if word:\n            return self.get_string(offset) == string\n        return self.get_length(len(string), offset) == string"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef match_any_string(self, strings, word=0, offset=0):\n        if word:\n            current = self.get_string(offset)\n            return current if current in strings else ''\n        current = ''\n\n        currentlength = 0\n        length = 0\n        for string in strings:\n            length = len(string)\n            if length != currentlength:\n                current = self.get_length(length, offset)\n            if string == current:\n                return string\n        return ''", "response": "Attempts to match each string in strings in order. Returns an empty string if no match."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef match_any_char(self, chars, offset=0):\n        if not self.has_space(offset=offset):\n            return ''\n        current = self.string[self.pos + offset]\n        return current if current in chars else ''", "response": "Match and return the current SourceString char if its in chars."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmatching each char sequentially from current SourceString position until the pattern does not match and return all maches.", "response": "def match_function_pattern(self, first, rest=None, least=1, offset=0):\n        \"\"\"Match each char sequentially from current SourceString position\n        until the pattern doesnt match and return all maches.\n\n        Integer argument least defines and minimum amount of chars that can\n        be matched.\n\n        This version takes functions instead of string patterns.\n        Each function must take one argument, a string, and return a\n        value that can be evauluated as True or False.\n\n        If rest is defined then first is used only to match the first arg\n        and the rest of the chars are matched against rest.\n        \"\"\"\n        if not self.has_space(offset=offset):\n            return ''\n        firstchar = self.string[self.pos + offset]\n        if not first(firstchar):\n            return ''\n\n        output = [firstchar]\n        pattern = first if rest is None else rest\n\n        for char in self.string[self.pos + offset + 1:]:\n            if pattern(char):\n                output.append(char)\n            else:\n                break\n\n        if len(output) < least:\n            return ''\n\n        return ''.join(output)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncounts the number of indents that can be tabs or spacecount", "response": "def count_indents(self, spacecount, tabs=0, offset=0):\n        \"\"\"Counts the number of indents that can be tabs or spacecount\n        number of spaces in a row from the current line.\n        \"\"\"\n        if not self.has_space(offset=offset):\n            return 0\n        spaces = 0\n        indents = 0\n        for char in self.string[self.pos + offset - self.col:]:\n            if char == ' ':\n                spaces += 1\n            elif tabs and char == '\\t':\n                indents += 1\n                spaces = 0\n            else:\n                break\n            if spaces == spacecount:\n                indents += 1\n                spaces = 0\n        return indents"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncount the number of indents that can be tabs or spacecount.", "response": "def count_indents_length(self, spacecount, tabs=0, offset=0):\n        \"\"\"Counts the number of indents that can be tabs or spacecount\n        number of spaces in a row from the current line.\n\n        Also returns the character length of the indents.\n        \"\"\"\n        if not self.has_space(offset=offset):\n            return 0\n        spaces = 0\n        indents = 0\n        charlen = 0\n        for char in self.string[self.pos + offset - self.col:]:\n            if char == ' ':\n                spaces += 1\n            elif tabs and char == '\\t':\n                indents += 1\n                spaces = 0\n            else:\n                break\n            charlen += 1\n            if spaces == spacecount:\n                indents += 1\n                spaces = 0\n        return (indents, charlen)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef count_indents_last_line(self, spacecount, tabs=0, back=5):\n        if not self.has_space():\n            return 0\n        lines = self.get_surrounding_lines(back, 0)\n\n        for line in reversed(lines):\n            if not line.string.isspace():\n                return line.count_indents(spacecount, tabs)\n        return 0", "response": "Finds the last meaningful line and returns its indent level."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the last meaningful line and returns its indent level and the character length.", "response": "def count_indents_length_last_line(self, spacecount, tabs=0, back=5):\n        \"\"\"Finds the last meaningful line and returns its indent level and\n        character length.\n        Back specifies the amount of lines to look back for a none whitespace\n        line.\n        \"\"\"\n        if not self.has_space():\n            return 0\n        lines = self.get_surrounding_lines(back, 0)\n\n        for line in reversed(lines):\n            if not line.string.isspace():\n                return line.count_indents_length(spacecount, tabs)\n        return (0, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the position forwards to the next non newline space character.", "response": "def skip_whitespace(self, newlines=0):\n        \"\"\"Moves the position forwards to the next non newline space character.\n        If newlines >= 1 include newlines as spaces.\n        \"\"\"\n        if newlines:\n            while not self.eos:\n                if self.get_char().isspace():\n                    self.eat_length(1)\n                else:\n                    break\n        else:\n            char = ''\n            while not self.eos:\n                char = self.get_char()\n                if char.isspace() and char != '\\n':\n                    self.eat_length(1)\n                else:\n                    break"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pretty_print(self, carrot=False):\n        lineno = self.lineno\n        padding = 0\n        if lineno < 1000:\n            padding = 1\n        if lineno < 100:\n            padding = 2\n        if lineno < 10:\n            padding = 3\n\n        string = str(lineno) + (' ' * padding) + '|' + self.string\n        if carrot:\n            string += '\\n' + (' ' * (self.col + 5))\n        return string", "response": "Return a string of this line including the current character position."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef safe_exit(output):\n    try:\n        sys.stdout.write(output)\n        sys.stdout.flush()\n    except IOError:\n        pass", "response": "exit without breaking pipes"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn Markdown text of selected fragment", "response": "def frag2text(endpoint, stype, selector,\n              clean=False, raw=False, verbose=False):\n    \"\"\"returns Markdown text of selected fragment.\n\n    Args:\n        endpoint: URL, file, or HTML string\n        stype: { 'css' | 'xpath' }\n        selector: CSS selector or XPath expression\n    Returns:\n        Markdown text\n    Options:\n        clean: cleans fragment (lxml.html.clean defaults)\n        raw: returns raw HTML fragment\n        verbose: show http status, encoding, headers\n    \"\"\"\n    try:\n        return main(endpoint, stype, selector, clean, raw, verbose)\n    except StandardError as err:\n        return err"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns local file contents as endpoint.", "response": "def read(self, _file):\n        \"\"\"return local file contents as endpoint.\"\"\"\n        with open(_file) as fh:\n            data = fh.read()\n            if self.verbose:\n                sys.stdout.write(\"read %d bytes from %s\\n\"\n                                 % (fh.tell(), _file))\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn text content of HTTP GET response.", "response": "def GET(self, url):\n        \"\"\"returns text content of HTTP GET response.\"\"\"\n        r = requests.get(url)\n        if self.verbose:\n            sys.stdout.write(\"%s %s\\n\" % (r.status_code, r.encoding))\n            sys.stdout.write(str(r.headers) + \"\\n\")\n        self.encoding = r.encoding\n        return r.text"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning WHATWG spec HTML fragment from selector expression.", "response": "def select(self, html, stype, expression):\n        \"\"\"returns WHATWG spec HTML fragment from selector expression.\"\"\"\n        etree = html5lib.parse(html,\n                               treebuilder='lxml',\n                               namespaceHTMLElements=False)\n        if stype == 'css':\n            selector = lxml.cssselect.CSSSelector(expression)\n            frag = list(selector(etree))\n        else:\n            frag = etree.xpath(expression)\n        if not frag:\n            raise RuntimeError(\"Nothing found for: %s\" % expression)\n        return \"\".join([lxml.etree.tostring(x) for x in frag])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nremoving evil HTML per lxml. html. clean defaults.", "response": "def clean(self, html):\n        \"\"\"removes evil HTML per lxml.html.clean defaults.\"\"\"\n        return lxml.html.clean.clean_html(unicode(html, self.encoding))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef filesystem_repository(_context, name=None, make_default=False,\n                          aggregate_class=None, repository_class=None,\n                          directory=None, content_type=None):\n    \"\"\"\n    Directive for registering a file-system based repository.\n    \"\"\"\n    cnf = {}\n    if not directory is None:\n        cnf['directory'] = directory\n    if not content_type is None:\n        cnf['content_type'] = content_type\n    _repository(_context, name, make_default,\n                aggregate_class, repository_class,\n                REPOSITORY_TYPES.FILE_SYSTEM, 'add_filesystem_repository',\n                cnf)", "response": "Register a new file - system based repository."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rdb_repository(_context, name=None, make_default=False,\n                   aggregate_class=None, repository_class=None,\n                   db_string=None, metadata_factory=None):\n    \"\"\"\n    Directive for registering a RDBM based repository.\n    \"\"\"\n    cnf = {}\n    if not db_string is None:\n        cnf['db_string'] = db_string\n    if not metadata_factory is None:\n        cnf['metadata_factory'] = metadata_factory\n    _repository(_context, name, make_default,\n                aggregate_class, repository_class,\n                REPOSITORY_TYPES.RDB, 'add_rdb_repository', cnf)", "response": "Register a new RDB repository."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _filter(self, dict, keep):\n        if not keep:\n            return dict\n\n        result = {}\n        for key, value in dict.iteritems():\n            if key in keep:\n                result[key] = value\n        return result", "response": "Filter out any keys not in keep"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_county_estimate(self, table, variable, code, datum):\n        try:\n            division = Division.objects.get(\n                code=\"{}{}\".format(datum[\"state\"], datum[\"county\"]),\n                level=self.COUNTY_LEVEL,\n            )\n            CensusEstimate.objects.update_or_create(\n                division=division,\n                variable=variable,\n                defaults={\"estimate\": datum[code] or 0},\n            )\n        except ObjectDoesNotExist:\n            print(\"ERROR: {}, {}\".format(datum[\"NAME\"], datum[\"state\"]))", "response": "Writes a county estimate to a census series."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting all districts in a given state and estimate.", "response": "def get_district_estimates_by_state(\n        self, api, table, variable, estimate, state\n    ):\n        \"\"\"\n        Calls API for all districts in a state and a given estimate.\n        \"\"\"\n        state = Division.objects.get(level=self.STATE_LEVEL, code=state)\n        district_data = api.get(\n            (\"NAME\", estimate),\n            {\n                \"for\": \"congressional district:*\",\n                \"in\": \"state:{}\".format(state.code),\n            },\n            year=int(table.year),\n        )\n        for datum in district_data:\n            self.write_district_estimate(table, variable, estimate, datum)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_county_estimates_by_state(\n        self, api, table, variable, estimate, state\n    ):\n        \"\"\"\n        Calls API for all counties in a state and a given estimate.\n        \"\"\"\n        state = Division.objects.get(level=self.STATE_LEVEL, code=state)\n        county_data = api.get(\n            (\"NAME\", estimate),\n            {\"for\": \"county:*\", \"in\": \"state:{}\".format(state.code)},\n            year=int(table.year),\n        )\n        for datum in county_data:\n            self.write_county_estimate(table, variable, estimate, datum)", "response": "Calls API for all counties in a given state and a given estimate."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a given state estimate for a given state.", "response": "def get_state_estimates_by_state(\n        self, api, table, variable, estimate, state\n    ):\n        \"\"\"\n        Calls API for a state and a given estimate.\n        \"\"\"\n        state = Division.objects.get(level=self.STATE_LEVEL, code=state)\n        state_data = api.get(\n            (\"NAME\", estimate),\n            {\"for\": \"state:{}\".format(state.code)},\n            year=int(table.year),\n        )\n        for datum in state_data:\n            self.write_state_estimate(table, variable, estimate, datum)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef aggregate_variable(estimate, id):\n        estimates = [\n            variable.estimates.get(division__id=id).estimate\n            for variable in estimate.variable.label.variables.all()\n        ]\n        method = estimate.variable.label.aggregation\n        if method == \"s\":\n            aggregate = sum(estimates)\n        elif method == \"a\":\n            aggregate = statistics.mean(estimates)\n        elif method == \"m\":\n            aggregate = statistics.median(estimates)\n        else:\n            aggregate = None\n        return aggregate", "response": "Aggregate census table variables by a custom label."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef aggregate_national_estimates_by_district(self):\n        data = {}\n        fips = \"00\"\n        aggregated_labels = []\n        states = Division.objects.filter(level=self.DISTRICT_LEVEL)\n        estimates = CensusEstimate.objects.filter(\n            division__level=self.DISTRICT_LEVEL\n        )\n        for estimate in estimates:\n            series = estimate.variable.table.series\n            year = estimate.variable.table.year\n            table = estimate.variable.table.code\n            label = estimate.variable.label.label\n            table_label = \"{}{}\".format(table, label)\n            code = estimate.variable.code\n            if series not in data:\n                data[series] = {}\n            if year not in data[series]:\n                data[series][year] = {}\n            if table not in data[series][year]:\n                data[series][year][table] = {}\n            if fips not in data[series][year][table]:\n                data[series][year][table][fips] = {}\n            if label is not None:\n                if table_label not in aggregated_labels:\n                    # c= {**a, **b}\n                    aggregated_labels.append(table_label)\n                    data[series][year][table][fips][label] = [\n                        self.aggregate_variable(estimate, division.id)\n                        for division in states\n                        if len(\n                            CensusEstimate.objects.filter(\n                                variable=estimate.variable,\n                                division=division.id,\n                            )\n                        )\n                        > 0\n                    ]\n            else:\n                if code in data[series][year][table][fips]:\n                    data[series][year][table][fips][code].append(\n                        estimate.estimate\n                    )\n                else:\n                    data[series][year][table][fips][code] = [estimate.estimate]\n        # print(data)\n        return data", "response": "Aggregate district - level estimates for each table within the country."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\naggregates county - level estimates for each table within a given state.", "response": "def aggregate_state_estimates_by_county(self, parent):\n        \"\"\"\n        Aggregates county-level estimates for each table within a given state.\n\n        Creates data structure designed for an export in this format:\n        ...{series}/{year}/{table}/{state_fips}/counties.json\n        \"\"\"\n        data = {}\n        for division in tqdm(\n            Division.objects.filter(level=self.COUNTY_LEVEL, parent=parent)\n        ):\n            fips = division.code\n            id = division.id\n            aggregated_labels = []  # Keep track of already agg'ed variables\n            for estimate in division.census_estimates.all():\n                series = estimate.variable.table.series\n                year = estimate.variable.table.year\n                table = estimate.variable.table.code\n                label = estimate.variable.label.label\n                table_label = \"{}{}\".format(table, label)\n                code = estimate.variable.code\n                if series not in data:\n                    data[series] = {}\n                if year not in data[series]:\n                    data[series][year] = {}\n                if table not in data[series][year]:\n                    data[series][year][table] = {}\n                if fips not in data[series][year][table]:\n                    data[series][year][table][fips] = {}\n                if label is not None:\n                    if table_label not in aggregated_labels:\n                        aggregated_labels.append(table_label)\n                        data[series][year][table][fips][\n                            label\n                        ] = self.aggregate_variable(estimate, id)\n                else:\n                    data[series][year][table][division.code][\n                        code\n                    ] = estimate.estimate\n        # print(data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xml(self, fn=None, src='word/document.xml', XMLClass=XML, **params):\n        \"return the src with the given transformation applied, if any.\"\n        if src in self.xml_cache: return self.xml_cache[src]\n        if src not in self.zipfile.namelist(): return\n        x = XMLClass(\n                fn=fn or (self.fn and self.fn.replace('.docx', '.xml')) or None,\n                root=self.zipfile.read(src))\n        self.xml_cache[src] = x\n        return x", "response": "return the src with the given transformation applied if any."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a cp : metadata element with the metadata in the document", "response": "def metadata(self):\n        \"\"\"return a cp:metadata element with the metadata in the document\"\"\"\n        md = self.xml(src=\"docProps/core.xml\")\n        if md is None:\n            md = XML(root=etree.Element(\"{%(cp)s}metadata\" % self.NS))\n        return md.root"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stylemap(self, definitions=True, all=True, cache=False):\n        if self._stylemap is not None and cache==True:\n            return self._stylemap\n        else:\n            self._stylemap = None              # expire the cache\n            x = self.xml(src='word/styles.xml')\n            document = self.xml(src='word/document.xml')\n            footnotes = self.xml(src='word/footnotes.xml')  # None if no footnotes\n            endnotes = self.xml(src='word/endnotes.xml')    # None if no endnotes\n            d = Dict()\n            for s in x.root.xpath(\"w:style\", namespaces=self.NS):\n                style = Dict()\n                style.id = s.get(\"{%(w)s}styleId\" % self.NS)\n                style.type = s.get(\"{%(w)s}type\" % self.NS)\n                style.xpath = \"//w:rStyle[@w:val='%(id)s'] | //w:pStyle[@w:val='%(id)s']\" % style\n                if all == False:\n                    uses = document.root.xpath(style.xpath, namespaces=DOCX.NS)\n                    if len(uses)==0:\n                        # try footnotes and endnotes\n                        if footnotes is not None:\n                            uses = footnotes.root.xpath(style.xpath, namespaces=DOCX.NS)\n                        if len(uses)==0:\n                            if endnotes is not None:\n                                uses = endnotes.root.xpath(style.xpath, namespaces=DOCX.NS)\n                            if len(uses)==0:\n                                continue\n                LOG.debug(\"%s %r\" % (s.tag, s.attrib))\n                style.name = XML.find(s, \"w:name/@w:val\", namespaces=self.NS)\n                if style.name is None:\n                    LOG.debug(\"style without name: %r\" % style)\n                d[style.id] = style\n                LOG.debug(style)\n                if definitions is True: \n                    bo = s.find(\"{%(w)s}basedOn\" % DOCX.NS)\n                    if bo is not None:\n                        style.basedOn = bo.get(\"{%(w)s}val\" % DOCX.NS)\n                    style.properties = Dict()\n                    for pr in s.xpath(\"w:pPr/* | w:rPr/*\", namespaces=DOCX.NS):\n                        tag = re.sub(r\"^\\{[^}]*\\}\", \"\", pr.tag)\n                        props = Dict()\n                        for attr in pr.attrib.keys():\n                            k = re.sub(r\"^\\{[^}]*\\}\", \"\", attr)\n                            props[k] = pr.get(attr)\n                        style.properties[tag] = props\n            if cache is True: \n                self._stylemap = d\n            return d", "response": "return a dictionary of styles keyed to the id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef endnotemap(self, cache=True):\n        if self.__endnotemap is not None and cache==True:\n            return self.__endnotemap\n        else:\n            x = self.xml(src='word/endnotes.xml')\n            d = Dict()\n            if x is None: return d\n            for endnote in x.root.xpath(\"w:endnote\", namespaces=self.NS):\n                id = endnote.get(\"{%(w)s}id\" % self.NS)\n                typ = endnote.get(\"{%(w)s}type\" % self.NS)\n                d[id] = Dict(id=id, type=typ, elem=endnote)\n            if cache==True: self.__endnotemap = d\n            return d", "response": "return the endnotes from the docx keyed to string id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the footnotes from the docx keyed to string id.", "response": "def footnotemap(self, cache=True):\n        \"\"\"return the footnotes from the docx, keyed to string id.\"\"\"\n        if self.__footnotemap is not None and cache==True:\n            return self.__footnotemap\n        else:\n            x = self.xml(src='word/footnotes.xml')\n            d = Dict()\n            if x is None: return d\n            for footnote in x.root.xpath(\"w:footnote\", namespaces=self.NS):\n                id = footnote.get(\"{%(w)s}id\" % self.NS)\n                typ = footnote.get(\"{%(w)s}type\" % self.NS)\n                d[id] = Dict(id=id, type=typ, elem=footnote)\n            if cache==True: self.__footnotemap = d\n            return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef commentmap(self, cache=True):\n        if self.__commentmap is not None and cache==True:\n            return self.__commentmap\n        else:\n            x = self.xml(src='word/comments.xml')\n            d = Dict()\n            if x is None: return d\n            for comment in x.root.xpath(\"w:comment\", namespaces=self.NS):\n                id = comment.get(\"{%(w)s}id\" % self.NS)\n                typ = comment.get(\"{%(w)s}type\" % self.NS)\n                d[id] = Dict(id=id, type=typ, elem=comment)\n            if cache==True: self.__commentmap = d\n            return d", "response": "return the comments from the docx keyed to string id."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts Word date / time picture ( msformat ) into a strftime format string", "response": "def strftime_string(C, msformat):\n        \"convert Word date/time picture (msformat) into a strftime format string\"\n        s = msformat\n        s = re.sub(r\"%\", \"%%\", s)                   # percent sign\n        s = re.sub(r\"(?<!%)\\b(y(?:yyy)?)\\b\", \"%Y\", s)   # 4-digit year\n        s = re.sub(r\"(?<!%)\\b(yy)\\b\", \"%y\", s)     # 2-digit year\n        s = re.sub(r\"(?<!%)\\b(MMMM)\\b\", \"%B\", s)   # full month\n        s = re.sub(r\"(?<!%)\\b(MMM)\\b\", \"%b\", s)    # abbrev. month\n        s = re.sub(r\"(?<!%)\\b(MM)\\b\", \"%m\", s)     # 2-digit month\n        s = re.sub(r\"(?<!%)\\b(dd?)\\b\", \"%d\", s)    # day\n        s = re.sub(r\"(?<!%)\\b(hh?)\\b\", \"%I\", s)    # 12-hr hour\n        s = re.sub(r\"(?<!%)\\b(HH?)\\b\", \"%H\", s)    # 24-hr hour\n        s = re.sub(r\"(?<!%)\\b(mm?)\\b\", \"%M\", s)    # minute\n        s = re.sub(r\"(?<!%)\\b(ss?)\\b\", \"%S\", s)    # second\n        s = re.sub(r\"(?<!%)\\b(am/pm)\\b\", \"%p\", s)  # 2-digit year\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the Word val to a CSS unit", "response": "def val_to_css(C, val, factor, unit=CSS.rem, pt_per_em=12., decimals=2):\n        \"\"\"convert the Word val to a CSS unit\n        val     : The raw Word val\n        factor  : The conversion factor. If font sizes, typically factor=1/2., others factor=1/20.\n        unit    : The CSS unit to which we are converting, default CSS.rem\n        pt_per_em : The number of CSS.pt per em. 12. is the default, but 'tain't necessarily so.\n        \"\"\"\n        return (round(float(val) * factor / pt_per_em, decimals) * CSS.rem).asUnit(unit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the selector for the given stylemap style", "response": "def selector(C, style):\n        \"\"\"return the selector for the given stylemap style\"\"\"\n        clas = C.classname(style.name)\n        if style.type == 'paragraph':\n            # heading outline levels are 0..7 internally, indicating h1..h8\n            outlineLvl = int((style.properties.get('outlineLvl') or {}).get('val') or 8) + 1\n            if outlineLvl < 9:\n                tag = 'h%d' % outlineLvl\n            else:\n                tag = 'p'\n        elif style.type == 'character':\n            tag = 'span'\n        elif style.type == 'table':\n            tag = 'table'\n        elif style.type == 'numbering':\n            tag = 'ol'\n        return \"%s.%s\" % (tag, clas)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a CSS stylesheet in a Text document using DOCX. stylemap(), above.", "response": "def stylesheet(self, fn=None, unit=CSS.rem, pt_per_em=None, decimals=2, font_factor=1/2., space_factor=1/20.):\n        \"\"\"create a CSS stylesheet in a Text document, using DOCX.stylemap(), above.\"\"\"\n        styles = self.stylemap(definitions=True, all=True, cache=False)\n        used_styles = self.stylemap(definitions=False, all=False, cache=False)\n        css = CSS(fn=fn or (self.fn and self.fn.replace('.docx', '.css')) or None)\n        if pt_per_em is None:\n            # use the size of the \"Normal\" font as 1.0em by definition\n            normal = [styles[k] for k in styles if styles[k].name=='Normal'][0]\n            if normal.properties.get('sz') is not None:\n                pt_per_em = float(normal.properties['sz'].val) * font_factor\n            else:\n                pt_per_em = 12.\n        for styleName in used_styles:\n            style = styles[styleName]\n            sel = self.selector(style)\n            css.styles[sel] = self.style_properties(styles, styleName, unit=unit, pt_per_em=pt_per_em, decimals=decimals, font_factor=font_factor, space_factor=space_factor)\n            LOG.debug(\"%s %r\" % (sel, css.styles[sel]))\n\n        return css"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef load_into_collection_from_stream(collection, stream, content_type):\n    rpr = as_representer(collection, content_type)\n    with stream:\n        data_el = rpr.data_from_stream(stream)\n    rpr.resource_from_data(data_el, resource=collection)", "response": "Loads resources from the given stream into the given collection resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_collection_from_stream(resource, stream, content_type):\n    coll = create_staging_collection(resource)\n    load_into_collection_from_stream(coll, stream, content_type)\n    return coll", "response": "Loads a new collection for the given resource from the given stream."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading resources from the specified file into the given collection.", "response": "def load_into_collection_from_file(collection, filename,\n                                   content_type=None):\n    \"\"\"\n    Loads resources from the specified file into the given collection\n    resource.\n\n    If no content type is provided, an attempt is made to look up the\n    extension of the given filename in the MIME content type registry.\n    \"\"\"\n    if content_type is None:\n        ext = os.path.splitext(filename)[1]\n        try:\n            content_type = MimeTypeRegistry.get_type_for_extension(ext)\n        except KeyError:\n            raise ValueError('Could not infer MIME type for file extension '\n                             '\"%s\".' % ext)\n    load_into_collection_from_stream(collection, open(filename, 'rU'),\n                                     content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nloading a new collection for the given resource and file.", "response": "def load_collection_from_file(resource, filename, content_type=None):\n    \"\"\"\n    Creates a new collection for the registered resource and calls\n    `load_into_collection_from_file` with it.\n    \"\"\"\n    coll = create_staging_collection(resource)\n    load_into_collection_from_file(coll, filename,\n                                   content_type=content_type)\n    return coll"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads resources from the given URL into the given collection.", "response": "def load_into_collection_from_url(collection, url, content_type=None):\n    \"\"\"\n    Loads resources from the representation contained in the given URL into\n    the given collection resource.\n\n    :returns: collection resource\n    \"\"\"\n    parsed = urlparse.urlparse(url)\n    scheme = parsed.scheme # pylint: disable=E1101\n    if scheme == 'file':\n        # Assume a local path.\n        load_into_collection_from_file(collection,\n                                       parsed.path, # pylint: disable=E1101\n                                       content_type=content_type)\n    else:\n        raise ValueError('Unsupported URL scheme \"%s\".' % scheme)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new collection for the registered resource and loads it into the collection with it.", "response": "def load_collection_from_url(resource, url, content_type=None):\n    \"\"\"\n    Creates a new collection for the registered resource and calls\n    `load_into_collection_from_url` with it.\n    \"\"\"\n    coll = create_staging_collection(resource)\n    load_into_collection_from_url(coll, url, content_type=content_type)\n    return coll"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef load_into_collections_from_zipfile(collections, zipfile):\n    with ZipFile(zipfile) as zipf:\n        names = zipf.namelist()\n        name_map = dict([(os.path.splitext(name)[0], index)\n                         for (index, name) in enumerate(names)])\n        for coll in collections:\n            coll_name = get_collection_name(coll)\n            index = name_map.get(coll_name)\n            if index is None:\n                continue\n            coll_fn = names[index]\n            ext = os.path.splitext(coll_fn)[1]\n            try:\n                content_type = \\\n                    MimeTypeRegistry.get_type_for_extension(ext)\n            except KeyError:\n                raise ValueError('Could not infer MIME type for file '\n                                 'extension \"%s\".' % ext)\n            # Strings are always written as UTF-8 encoded byte strings when\n            # the zip file is created, so we have to wrap the iterator into\n            # a decoding step.\n            coll_data = DecodingStream(zipf.open(coll_fn, 'r'))\n            load_into_collection_from_stream(coll,\n                                             coll_data,\n                                             content_type)", "response": "Loads resources contained in the given ZIP archive into each of the given collections."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dump_resource(resource, stream, content_type=None):\n    if content_type is None:\n        content_type = CsvMime\n    rpr = as_representer(resource, content_type)\n    rpr.to_stream(resource, stream)", "response": "Dumps the given resource to the given stream using the specified MIME\n    content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef build_resource_dependency_graph(resource_classes,\n                                    include_backrefs=False):\n    \"\"\"\n    Builds a graph of dependencies among the given resource classes.\n\n    The dependency graph is a directed graph with member resource classes as\n    nodes. An edge between two nodes represents a member or collection\n    attribute.\n\n    :param resource_classes: resource classes to determine interdependencies\n      of.\n    :type resource_classes: sequence of registered resources.\n    :param bool include_backrefs: flag indicating if dependencies\n      introduced by back-references (e.g., a child resource referencing its\n      parent) should be included in the dependency graph.\n    \"\"\"\n    def visit(mb_cls, grph, path, incl_backrefs):\n        for attr_name in get_resource_class_attribute_names(mb_cls):\n            if is_resource_class_terminal_attribute(mb_cls, attr_name):\n                continue\n            child_descr = getattr(mb_cls, attr_name)\n            child_mb_cls = get_member_class(child_descr.attr_type)\n            # We do not follow cyclic references back to a resource class\n            # that is last in the path.\n            if len(path) > 0 and child_mb_cls is path[-1] \\\n               and not incl_backrefs:\n                continue\n            if not grph.has_node(child_mb_cls):\n                grph.add_node(child_mb_cls)\n                path.append(mb_cls)\n                visit(child_mb_cls, grph, path, incl_backrefs)\n                path.pop()\n            if not grph.has_edge((mb_cls, child_mb_cls)):\n                grph.add_edge((mb_cls, child_mb_cls))\n    dep_grph = digraph()\n    for resource_class in resource_classes:\n        mb_cls = get_member_class(resource_class)\n        if not dep_grph.has_node(mb_cls):\n            dep_grph.add_node(mb_cls)\n            visit(mb_cls, dep_grph, [], include_backrefs)\n    return dep_grph", "response": "Builds a graph of dependencies among the given resource classes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a dependency graph of the given resource.", "response": "def build_resource_graph(resource, dependency_graph=None):\n    \"\"\"\n    Traverses the graph of resources that is reachable from the given\n    resource.\n\n    If a resource dependency graph is given, links to other resources are\n    only followed if the dependency graph has an edge connecting the two\n    corresponding resource classes; otherwise, a default graph is built\n    which ignores all direct cyclic resource references.\n\n    :resource: a :class:`everest.resources.MemberResource` instance.\n    :returns: a :class:`ResourceGraph` instance representing the graph of\n        resources reachable from the given resource.\n    \"\"\"\n    def visit(rc, grph, dep_grph):\n        mb_cls = type(rc)\n        attr_map = get_resource_class_attributes(mb_cls)\n        for attr_name, attr in iteritems_(attr_map):\n            if is_resource_class_terminal_attribute(mb_cls, attr_name):\n                continue\n            # Only follow the resource attribute if the dependency graph\n            # has an edge here.\n            child_mb_cls = get_member_class(attr.attr_type)\n            if not dep_grph.has_edge((mb_cls, child_mb_cls)):\n                continue\n            child_rc = getattr(rc, attr_name)\n            if is_resource_class_collection_attribute(mb_cls, attr_name):\n                for child_mb in child_rc:\n                    if not grph.has_node(child_mb): # Ignore cyclic references.\n                        grph.add_node(child_mb)\n                        grph.add_edge((rc, child_mb))\n                        visit(child_mb, grph, dep_grph)\n            else: # Member.\n                if not grph.has_node(child_rc): # Ignore cyclic references.\n                    grph.add_node(child_rc)\n                    grph.add_edge((rc, child_rc))\n                    visit(child_rc, grph, dep_grph)\n    if  dependency_graph is None:\n        dependency_graph = build_resource_dependency_graph(\n                                            [get_member_class(resource)])\n    graph = ResourceGraph()\n    if provides_member_resource(resource):\n        rcs = [resource]\n    else:\n        rcs = resource\n    for rc in rcs:\n        graph.add_node(rc)\n        visit(rc, graph, dependency_graph)\n    return graph"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_connected_resources(resource, dependency_graph=None):\n    # Build a resource_graph.\n    resource_graph = \\\n                build_resource_graph(resource,\n                                     dependency_graph=dependency_graph)\n    entity_map = OrderedDict()\n    for mb in topological_sorting(resource_graph):\n        mb_cls = get_member_class(mb)\n        ents = entity_map.get(mb_cls)\n        if ents is None:\n            ents = []\n            entity_map[mb_cls] = ents\n        ents.append(mb.get_entity())\n    return entity_map", "response": "Returns a dictionary mapping member resource classes to new collections containing the members found."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef dump_resource_to_files(resource, content_type=None, directory=None):\n    if directory is None:\n        directory = os.getcwd() # pragma: no cover\n    if content_type is None:\n        content_type = CsvMime\n    srl = ConnectedResourcesSerializer(content_type)\n    srl.to_files(resource, directory=directory)", "response": "Dump a resource to a CSV file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndump a resource to a zipfile.", "response": "def dump_resource_to_zipfile(resource, zipfile, content_type=None):\n    \"\"\"\n    Convenience function. See\n    :meth:`everest.resources.io.ConnectedResourcesSerializer.to_zipfile` for\n    details.\n\n    The given context type defaults to CSV.\n    \"\"\"\n    if content_type is None:\n        content_type = CsvMime\n    srl = ConnectedResourcesSerializer(content_type)\n    srl.to_zipfile(resource, zipfile)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_strings(self, resource):\n        collections = self.__collect(resource)\n        # Build a map of representations.\n        rpr_map = OrderedDict()\n        for (mb_cls, coll) in iteritems_(collections):\n            strm = NativeIO('w')\n            dump_resource(coll, strm, content_type=self.__content_type)\n            rpr_map[mb_cls] = strm.getvalue()\n        return rpr_map", "response": "Dumps all resources reachable from the given resource to a map of string representations using the specified content type."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndump the given resource and all resources linked to it into a set of of representation files in the given directory.", "response": "def to_files(self, resource, directory):\n        \"\"\"\n        Dumps the given resource and all resources linked to it into a set of\n        representation files in the given directory.\n        \"\"\"\n        collections = self.__collect(resource)\n        for (mb_cls, coll) in iteritems_(collections):\n            fn = get_write_collection_path(mb_cls,\n                                           self.__content_type,\n                                           directory=directory)\n            with open_text(os.path.join(directory, fn)) as strm:\n                dump_resource(coll, strm, content_type=self.__content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_zipfile(self, resource, zipfile):\n        rpr_map = self.to_strings(resource)\n        with ZipFile(zipfile, 'w') as zipf:\n            for (mb_cls, rpr_string) in iteritems_(rpr_map):\n                fn = get_collection_filename(mb_cls, self.__content_type)\n                zipf.writestr(fn, rpr_string, compress_type=ZIP_DEFLATED)", "response": "Dumps the given resource and all resources linked to it into the givenZIP file."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef read(self):\n        p = os.path.join(self.path, self.name)\n        try:\n            with open(p) as f:\n                json_text = f.read()\n        except FileNotFoundError as e:\n            raise JSONFileError(e) from e\n        try:\n            json.loads(json_text)\n        except (json.JSONDecodeError, TypeError) as e:\n            raise JSONFileError(f\"{e} Got {p}\") from e\n        return json_text", "response": "Returns the contents as validated JSON text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef deserialized_objects(self):\n        if not self._deserialized_objects:\n            json_text = self.read()\n            self._deserialized_objects = self.deserialize(json_text=json_text)\n        return self._deserialized_objects", "response": "Returns a generator of deserialized objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef exists(self, batch_id=None):\n        try:\n            self.model.objects.get(batch_id=batch_id)\n        except self.model.DoesNotExist:\n            return False\n        return True", "response": "Returns True if the batch_id exists in the history."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nupdating the history model with the given parameters.", "response": "def update(\n        self,\n        filename=None,\n        batch_id=None,\n        prev_batch_id=None,\n        producer=None,\n        count=None,\n    ):\n        \"\"\"Creates an history model instance.\n        \"\"\"\n        # TODO: refactor model enforce unique batch_id\n        # TODO: refactor model to not allow NULLs\n        if not filename:\n            raise BatchHistoryError(\"Invalid filename. Got None\")\n        if not batch_id:\n            raise BatchHistoryError(\"Invalid batch_id. Got None\")\n        if not prev_batch_id:\n            raise BatchHistoryError(\"Invalid prev_batch_id. Got None\")\n        if not producer:\n            raise BatchHistoryError(\"Invalid producer. Got None\")\n        if self.exists(batch_id=batch_id):\n            raise IntegrityError(\"Duplicate batch_id\")\n        try:\n            obj = self.model.objects.get(batch_id=batch_id)\n        except self.model.DoesNotExist:\n            obj = self.model(\n                filename=filename,\n                batch_id=batch_id,\n                prev_batch_id=prev_batch_id,\n                producer=producer,\n                total=count,\n            )\n            obj.transaction_file.name = filename\n            obj.save()\n        return obj"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef populate(self, deserialized_txs=None, filename=None, retry=None):\n        if not deserialized_txs:\n            raise BatchError(\"Failed to populate batch. There are no objects to add.\")\n        self.filename = filename\n        if not self.filename:\n            raise BatchError(\"Invalid filename. Got None\")\n        try:\n            for deserialized_tx in deserialized_txs:\n                self.peek(deserialized_tx)\n                self.objects.append(deserialized_tx.object)\n                break\n            for deserialized_tx in deserialized_txs:\n                self.objects.append(deserialized_tx.object)\n        except DeserializationError as e:\n            raise BatchDeserializationError(e) from e\n        except JSONFileError as e:\n            raise BatchDeserializationError(e) from e", "response": "Populates the batch with unsaved model instances from a generator of deserialized objects."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npeeking into first tx and sets self attrs or raise.", "response": "def peek(self, deserialized_tx):\n        \"\"\"Peeks into first tx and sets self attrs or raise.\n        \"\"\"\n        self.batch_id = deserialized_tx.object.batch_id\n        self.prev_batch_id = deserialized_tx.object.prev_batch_id\n        self.producer = deserialized_tx.object.producer\n        if self.batch_history.exists(batch_id=self.batch_id):\n            raise BatchAlreadyProcessed(\n                f\"Batch {self.batch_id} has already been processed\"\n            )\n        if self.prev_batch_id != self.batch_id:\n            if not self.batch_history.exists(batch_id=self.prev_batch_id):\n                raise InvalidBatchSequence(\n                    f\"Invalid import sequence. History does not exist for prev_batch_id. \"\n                    f\"Got file='{self.filename}', prev_batch_id=\"\n                    f\"{self.prev_batch_id}, batch_id={self.batch_id}.\"\n                )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save(self):\n        saved = 0\n        if not self.objects:\n            raise BatchError(\"Save failed. Batch is empty\")\n        for deserialized_tx in self.objects:\n            try:\n                self.model.objects.get(pk=deserialized_tx.pk)\n            except self.model.DoesNotExist:\n                data = {}\n                for field in self.model._meta.get_fields():\n                    try:\n                        data.update({field.name: getattr(deserialized_tx, field.name)})\n                    except AttributeError:\n                        pass\n                self.model.objects.create(**data)\n                saved += 1\n        return saved", "response": "Saves all model instances in the batch as model."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef import_batch(self, filename):\n        batch = self.batch_cls()\n        json_file = self.json_file_cls(name=filename, path=self.path)\n        try:\n            deserialized_txs = json_file.deserialized_objects\n        except JSONFileError as e:\n            raise TransactionImporterError(e) from e\n        try:\n            batch.populate(deserialized_txs=deserialized_txs, filename=json_file.name)\n        except (\n            BatchDeserializationError,\n            InvalidBatchSequence,\n            BatchAlreadyProcessed,\n        ) as e:\n            raise TransactionImporterError(e) from e\n        batch.save()\n        batch.update_history()\n        return batch", "response": "Imports the batch of outgoing transactions into a new model IncomingTransaction."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nborrow from web. py", "response": "def timelimit(timeout):\n    \"\"\"borrowed from web.py\"\"\"\n    def _1(function):\n        def _2(*args, **kw):\n            class Dispatch(threading.Thread):\n                def __init__(self):\n                    threading.Thread.__init__(self)\n                    self.result = None\n                    self.error = None\n\n                    self.setDaemon(True)\n                    self.start()\n\n                def run(self):\n                    try:\n                        self.result = function(*args, **kw)\n                    except:\n                        self.error = sys.exc_info()\n\n            c = Dispatch()\n            c.join(timeout)\n            if c.isAlive():\n                raise TimeoutError, 'took too long'\n            if c.error:\n                raise c.error[0], c.error[1]\n            return c.result\n        return _2\n    return _1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the root element of the resource set.", "response": "def root(self):\n        \"\"\"\n        TODO(rdelinger) rename this as to_xml or something similar\n        \"\"\"\n        self.xml_root = ElementTree.Element('interface')\n        self.xml_root.set('type', self.type)\n        if self.mac is not None:\n            mac = ElementTree.SubElement(self.xml_root, 'mac')\n            mac.set('address', self.mac)\n        _source = ElementTree.SubElement(self.xml_root, 'source')\n        _source.set(self.type, self.source)\n        _model = ElementTree.SubElement(self.xml_root, 'model')\n        _model.set('type', self.model)\n        return self.xml_root"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _populateBuffer(self, stream, n):\n        try:\n            for x in xrange(n):\n                output = stream.next()\n                self._buffer.write(output)\n        except StopIteration, e:\n            self._deferred.callback(None)\n        except Exception, e:\n            self._deferred.errback(e)\n        else:\n            self.delayedCall = reactor.callLater(CALL_DELAY, self._populateBuffer, stream, n)", "response": "Populate the internal buffer with the next n elements from the genshi stream."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_message(\n        json_meta, data, data_type=0, version=b'\\x00\\x01@\\x00'):\n    \"\"\"Create message, containing meta and data in df-envelope format.\n\n    @json_meta - metadata\n    @data - binary data\n    @data_type - data type code for binary data\n    @version - version of machine header\n    @return - message as bytearray\n\n    \"\"\"\n    __check_data(data)\n    meta = __prepare_meta(json_meta)\n    data = __compress(json_meta, data)\n    header = __create_machine_header(\n        json_meta, data, data_type, version)\n\n    return header + meta + data", "response": "Create message in df - envelope format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_from_file(filename, nodata=False):\n    header = None\n    with open(filename, \"rb\") as file:\n        header = read_machine_header(file)\n        meta_raw = file.read(header['meta_len'])\n        meta = __parse_meta(meta_raw, header)\n        data = b''\n        if not nodata:\n            data = __decompress(meta, file.read(header['data_len']))\n\n        return header, meta, data", "response": "Parse df message from file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_message(message, nodata=False):\n    header = read_machine_header(message)\n    h_len = __get_machine_header_length(header)\n    meta_raw = message[h_len:h_len + header['meta_len']]\n    meta = __parse_meta(meta_raw, header)\n    data_start = h_len + header['meta_len']\n    data = b''\n    if not nodata:\n        data = __decompress(\n            meta,\n            message[data_start:data_start + header['data_len']]\n        )\n    return header, meta, data", "response": "Parse df message from bytearray."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse binary header. @data - bytearray, contains binary header of file opened in 'rb' mode @return - parsed binary header", "response": "def read_machine_header(data):\n    \"\"\"Parse binary header.\n\n    @data - bytearray, contains binary header of file opened in 'rb' mode\n    @return - parsed binary header\n\n    \"\"\"\n    if isinstance(data, (bytes, bytearray)):\n        stream = io.BytesIO(data)\n    elif isinstance(data, io.BufferedReader):\n        stream = data\n    else:\n        raise ValueError(\"data should be either bytearray or file 'rb' mode.\")\n\n    header = dict()\n    header_type = stream.read(6)\n    if header_type == b\"#!\\x00\\x01@\\x00\":\n        header['type'] = header_type[2:6]\n        header['time'] = struct.unpack('>I', stream.read(4))[0]\n        header['meta_type'] = struct.unpack('>I', stream.read(4))[0]\n        header['meta_len'] = struct.unpack('>I', stream.read(4))[0]\n        header['data_type'] = struct.unpack('>I', stream.read(4))[0]\n        header['data_len'] = struct.unpack('>I', stream.read(4))[0]\n        stream.read(4)\n    elif header_type == b\"#~DF02\":\n        header['type'] = header_type[2:6]\n        header['meta_type'] = stream.read(2)\n        header['meta_len'] = struct.unpack('>I', stream.read(4))[0]\n        header['data_len'] = struct.unpack('>I', stream.read(4))[0]\n        stream.read(4)\n    else:\n        raise NotImplementedError(\n            \"Parser for machine header %s not implemented\" %\n            (header_type.decode()))\n\n    return header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nextract complete messages from stream and cut out them from stream.", "response": "def get_messages_from_stream(data):\n    \"\"\"Extract complete messages from stream and cut out them from stream.\n\n    @data - stream binary data\n    @return - [list of messages, choped stream data]\n\n    \"\"\"\n    messages = []\n    iterator = HEADER_RE.finditer(data)\n    last_pos = 0\n    for match in iterator:\n        pos = match.span()[0]\n        header = read_machine_header(data[pos:])\n        h_len = __get_machine_header_length(header)\n        cur_last_pos = pos + h_len + header['meta_len'] + header['data_len']\n\n        if cur_last_pos > len(data):\n            break\n\n        header, meta, bin_data = parse_message(data[pos:])\n        messages.append({'header': header, 'meta': meta, 'data': bin_data})\n\n        last_pos = cur_last_pos\n\n    data = data[last_pos:]\n    return messages, data"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clone(self, options=None, attribute_options=None):\n        copied_cfg = self.__configurations[-1].copy()\n        upd_cfg = type(copied_cfg)(options=options,\n                                   attribute_options=attribute_options)\n        copied_cfg.update(upd_cfg)\n        return self.__class__(self.__mp_reg, self.__mapped_cls,\n                              self.__de_cls, copied_cfg)", "response": "Returns a clone of this mapping that is configured with the given options and attribute option dictionaries."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate this mapping with the given options and attribute option maps.", "response": "def update(self, options=None, attribute_options=None):\n        \"\"\"\n        Updates this mapping with the given option and attribute option maps.\n\n        :param dict options: Maps representer options to their values.\n        :param dict attribute_options: Maps attribute names to dictionaries\n          mapping attribute options to their values.\n        \"\"\"\n        attr_map = self.__get_attribute_map(self.__mapped_cls, None, 0)\n        for attributes in attribute_options:\n            for attr_name in attributes:\n                if not attr_name in attr_map:\n                    raise AttributeError('Trying to configure non-existing '\n                                         'resource attribute \"%s\"'\n                                         % (attr_name))\n        cfg = RepresenterConfiguration(options=options,\n                                       attribute_options=attribute_options)\n        self.configuration.update(cfg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an ordered map of the mapped attributes for the given mapped class and attribute key.", "response": "def get_attribute_map(self, mapped_class=None, key=None):\n        \"\"\"\n        Returns an ordered map of the mapped attributes for the given mapped\n        class and attribute key.\n\n        :param key: Tuple of attribute names specifying a path to a nested\n          attribute in a resource tree. If this is not given, all attributes\n          in this mapping will be returned.\n        \"\"\"\n        if mapped_class is None:\n            mapped_class = self.__mapped_cls\n        if key is None:\n            key = MappedAttributeKey(())\n        return OrderedDict([(attr.resource_attr, attr)\n                            for attr in self._attribute_iterator(mapped_class,\n                                                                 key)])"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_attribute(self, attribute_name, mapped_class=None, key=None):\n        attr_map = self.__get_attribute_map(mapped_class, key, 0)\n        try:\n            return attr_map[attribute_name]\n        except KeyError:\n            raise AttributeError(attribute_name)", "response": "Returns the specified attribute from the map of all mapped attributes with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_attribute_by_repr(self, attribute_repr_name, mapped_class=None,\n                              key=None):\n        \"\"\"\n        Returns the attribute (specified by its representation name) from\n        the map of all mapped attributes for the given mapped class and\n        attribute key. See :method:`get_attribute_map` for details.\n        \"\"\"\n        attr_map = self.__get_attribute_map(mapped_class, key, 1)\n        try:\n            return attr_map[attribute_repr_name]\n        except KeyError:\n            raise AttributeError(attribute_repr_name)", "response": "Returns the attribute specified by its representation name."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator over all mapped attributes for the given mapped_class and attribute key.", "response": "def attribute_iterator(self, mapped_class=None, key=None):\n        \"\"\"\n        Returns an iterator over all mapped attributes for the given mapped\n        class and attribute key. See :method:`get_attribute_map` for details.\n        \"\"\"\n        for attr in self._attribute_iterator(mapped_class, key):\n            yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn an iterator over all terminal mapped attributes for the given mapped class and attribute key.", "response": "def terminal_attribute_iterator(self, mapped_class=None, key=None):\n        \"\"\"\n        Returns an iterator over all terminal mapped attributes for the given\n        mapped class and attribute key. See :method:`get_attribute_map` for\n        details.\n        \"\"\"\n        for attr in self._attribute_iterator(mapped_class, key):\n            if attr.kind == RESOURCE_ATTRIBUTE_KINDS.TERMINAL:\n                yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new data element for the given mapped class.", "response": "def create_data_element(self, mapped_class=None):\n        \"\"\"\n        Returns a new data element for the given mapped class.\n\n        :returns: object implementing :class:`IResourceDataElement`.\n        \"\"\"\n        if not mapped_class is None and mapped_class != self.__mapped_cls:\n            mp = self.__mp_reg.find_or_create_mapping(mapped_class)\n            data_el = mp.create_data_element()\n        else:\n            data_el = self.__de_cls.create()\n        return data_el"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_linked_data_element(self, url, kind, id=None, # pylint: disable=W0622\n                                   relation=None, title=None):\n        \"\"\"\n        Returns a new linked data element for the given url and kind.\n\n        :param str url: URL to assign to the linked data element.\n        :param str kind: kind of the resource that is linked. One of the\n          constantes defined by :class:`everest.constants.RESOURCE_KINDS`.\n        :returns: object implementing :class:`ILinkedDataElement`.\n        \"\"\"\n        mp = self.__mp_reg.find_or_create_mapping(Link)\n        return mp.data_element_class.create(url, kind, id=id,\n                                            relation=relation, title=title)", "response": "Creates a new linked data element for the given url and kind."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a new data element for the given resource object.", "response": "def create_data_element_from_resource(self, resource):\n        \"\"\"\n        Returns a new data element for the given resource object.\n\n        :returns: object implementing :class:`IResourceDataElement`.\n        \"\"\"\n        mp = self.__mp_reg.find_or_create_mapping(type(resource))\n        return mp.data_element_class.create_from_resource(resource)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_linked_data_element_from_resource(self, resource):\n        mp = self.__mp_reg.find_or_create_mapping(Link)\n        return mp.data_element_class.create_from_resource(resource)", "response": "Returns a new linked data element for the given resource object."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmaps the given data element to a resource or updates the given resource.", "response": "def map_to_resource(self, data_element, resource=None):\n        \"\"\"\n        Maps the given data element to a new resource or updates the given\n        resource.\n\n        :raises ValueError: If :param:`data_element` does not provide\n          :class:`everest.representers.interfaces.IDataElement`.\n        \"\"\"\n        if not IDataElement.providedBy(data_element): # pylint:disable=E1101\n            raise ValueError('Expected data element, got %s.' % data_element)\n        if resource is None:\n            coll = \\\n                create_staging_collection(data_element.mapping.mapped_class)\n            agg = coll.get_aggregate()\n            agg.add(data_element)\n            if IMemberDataElement.providedBy(data_element): # pylint: disable=E1101\n                ent = next(iter(agg))\n                resource = \\\n                    data_element.mapping.mapped_class.create_from_entity(ent)\n            else:\n                resource = coll\n        else:\n            resource.update(data_element)\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_to_data_element(self, resource):\n        trv = ResourceTreeTraverser(resource, self.as_pruning())\n        visitor = DataElementBuilderResourceTreeVisitor(self)\n        trv.run(visitor)\n        return visitor.data_element", "response": "Maps the given resource to a data element tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef as_pruning(self):\n        return PruningMapping(self.__mp_reg, self.__mapped_cls, self.__de_cls,\n                              self.__configurations[-1])", "response": "Returns a copy of this mapping with the is_pruning flag set to\n        * True*."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\npush a configuration object onto the stack of configurations.", "response": "def push_configuration(self, configuration):\n        \"\"\"\n        Pushes the given configuration object on the stack of configurations\n        managed by this mapping and makes it the active configuration.\n        \"\"\"\n        self.__mapped_attr_cache.clear()\n        self.__configurations.append(configuration)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopping the last configuration from the stack of configurations managed by this mapping.", "response": "def pop_configuration(self):\n        \"\"\"\n        Pushes the currently active configuration from the stack of\n        configurations managed by this mapping.\n\n        :raises IndexError: If there is only one configuration in the stack.\n        \"\"\"\n        if len(self.__configurations) == 1:\n            raise IndexError('Can not pop the last configuration from the '\n                             'stack of configurations.')\n        self.__configurations.pop()\n        self.__mapped_attr_cache.clear()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new MappingConfigurationContext with the given options and attribute options.", "response": "def with_updated_configuration(self, options=None,\n                                   attribute_options=None):\n        \"\"\"\n        Returns a context in which this mapping is updated with the given\n        options and attribute options.\n        \"\"\"\n        new_cfg = self.__configurations[-1].copy()\n        if not options is None:\n            for o_name, o_value in iteritems_(options):\n                new_cfg.set_option(o_name, o_value)\n        if not attribute_options is None:\n            for attr_name, ao_opts in iteritems_(attribute_options):\n                for ao_name, ao_value in iteritems_(ao_opts):\n                    new_cfg.set_attribute_option(attr_name, ao_name, ao_value)\n#        upd_cfg = type(new_cfg)(options=options,\n#                                attribute_options=attribute_options)\n#        new_cfg.update(upd_cfg)\n        return MappingConfigurationContext(self, new_cfg)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an iterator over the attributes in this mapping for the given mapped class and attribute key.", "response": "def _attribute_iterator(self, mapped_class, key):\n        \"\"\"\n        Returns an iterator over the attributes in this mapping for the\n        given mapped class and attribute key.\n\n        If this is a pruning mapping, attributes that are ignored because\n        of a custom configuration or because of the default ignore rules\n        are skipped.\n        \"\"\"\n        for attr in \\\n          itervalues_(self.__get_attribute_map(mapped_class, key, 0)):\n            if self.is_pruning:\n                do_ignore = attr.should_ignore(key)\n            else:\n                do_ignore = False\n            if not do_ignore:\n                yield attr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_mapping(self, mapped_class, configuration=None):\n        cfg = self.__configuration.copy()\n        if not configuration is None:\n            cfg.update(configuration)\n        provided_ifcs = provided_by(object.__new__(mapped_class))\n        if IMemberResource in provided_ifcs:\n            base_data_element_class = self.member_data_element_base_class\n        elif ICollectionResource in provided_ifcs:\n            base_data_element_class = self.collection_data_element_base_class\n        elif IResourceLink in provided_ifcs:\n            base_data_element_class = self.linked_data_element_base_class\n        else:\n            raise ValueError('Mapped class for data element class does not '\n                             'implement one of the required interfaces.')\n        name = \"%s%s\" % (mapped_class.__name__,\n                         base_data_element_class.__name__)\n        de_cls = type(name, (base_data_element_class,), {})\n        mp = self.mapping_class(self, mapped_class, de_cls, cfg)\n        # Set the data element class' mapping.\n        # FIXME: This looks like a hack.\n        de_cls.mapping = mp\n        return mp", "response": "Creates a new mapping for the given mapped class and representer configuration."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the mapping registered for the given mapped class or None if no mapping can be found.", "response": "def find_mapping(self, mapped_class):\n        \"\"\"\n        Returns the mapping registered for the given mapped class or any of\n        its base classes. Returns `None` if no mapping can be found.\n\n        :param mapped_class: mapped type\n        :type mapped_class: type\n        :returns: instance of :class:`Mapping` or `None`\n        \"\"\"\n        if not self.__is_initialized:\n            self.__is_initialized = True\n            self._initialize()\n        mapping = None\n        for base_cls in mapped_class.__mro__:\n            try:\n                mapping = self.__mappings[base_cls]\n            except KeyError:\n                continue\n            else:\n                break\n        return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the mapping for the given mapped class or creates one if one is not found.", "response": "def find_or_create_mapping(self, mapped_class):\n        \"\"\"\n        First calls :meth:`find_mapping` to check if a mapping for the given\n        mapped class or any of its base classes has been created. If not, a\n        new one is created with a default configuration, registered\n        automatically and returned.\n        \"\"\"\n        mapping = self.find_mapping(mapped_class)\n        if mapping is None:\n            mapping = self.create_mapping(mapped_class)\n            self.set_mapping(mapping)\n        return mapping"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eachMethod(decorator, methodFilter=lambda fName: True):\n    if isinstance(methodFilter, basestring):\n        # Is it a string? If it is, change it into a function that takes a string.\n        prefix = methodFilter\n        methodFilter = lambda fName: fName.startswith(prefix)\n\n    ismethod = lambda fn: inspect.ismethod(fn) or inspect.isfunction(fn)\n\n    def innerDeco(cls):\n        assert inspect.isclass(cls), \"eachMethod is designed to be used only on classes\"\n        for fName, fn in inspect.getmembers(cls):\n            if methodFilter(fName):\n                if ismethod(fn):\n                    # We attempt to avoid decorating staticmethods by looking for an arg named cls\n                    # or self; this is a kludge, but there's no other way to tell, and\n                    # staticmethods do not work correctly with eachMethod\n                    if getargspec(fn).args[0] not in ['cls', 'self']:\n                        continue\n\n                    setattr(cls, fName, decorator(fn))\n\n        return cls\n    return innerDeco", "response": "Class decorator that wraps every single method in its own method decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the path to a sibling of a file in the filesystem.", "response": "def _sibpath(path, sibling):\n    \"\"\"\n    Return the path to a sibling of a file in the filesystem.\n\n    This is useful in conjunction with the special C{__file__} attribute\n    that Python provides for modules, so modules can load associated\n    resource files.\n\n    (Stolen from twisted.python.util)\n    \"\"\"\n    return os.path.join(os.path.dirname(os.path.abspath(path)), sibling)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parseDate(dateString, strict=True):\n    if (not strict) and (not dateString):\n        return None\n\n    if not isinstance(dateString, basestring):\n        raise TypeError('%r is not a string' % dateString)\n\n    return parser.parse(dateString)", "response": "Parse a string date or time into a datetime object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cache(cls, func):\n\n        @functools.wraps(func)\n        def func_wrapper(*args, **kwargs):\n            func_key = cls.get_key(func)\n            val_cache = cls.get_cache(func_key)\n            lock = cls.get_cache_lock(func_key)\n\n            return cls._get_value_from_cache(\n                func, val_cache, lock, *args, **kwargs)\n\n        return func_wrapper", "response": "Decorator for the Global cache decorator."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsave the cache to `self` This decorator take it for granted that the decorated function is a method. The first argument of the function is `self`. :param func: function to decorate :return: the decorator", "response": "def instance_cache(cls, func):\n        \"\"\" Save the cache to `self`\n\n        This decorator take it for granted that the decorated function\n        is a method.  The first argument of the function is `self`.\n\n        :param func: function to decorate\n        :return: the decorator\n        \"\"\"\n\n        @functools.wraps(func)\n        def func_wrapper(*args, **kwargs):\n            if not args:\n                raise ValueError('`self` is not available.')\n            else:\n                the_self = args[0]\n            func_key = cls.get_key(func)\n            val_cache = cls.get_self_cache(the_self, func_key)\n            lock = cls.get_self_cache_lock(the_self, func_key)\n\n            return cls._get_value_from_cache(\n                func, val_cache, lock, *args, **kwargs)\n\n        return func_wrapper"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clear_instance_cache(cls, func):\n\n        @functools.wraps(func)\n        def func_wrapper(*args, **kwargs):\n            if not args:\n                raise ValueError('`self` is not available.')\n            else:\n                the_self = args[0]\n\n            cls.clear_self_cache(the_self)\n            return func(*args, **kwargs)\n\n        return func_wrapper", "response": "Decorator to clear the instance cache by the instance_cache decorator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef persisted(cls, seconds=0, minutes=0, hours=0, days=0, weeks=0):\n        days += weeks * 7\n        hours += days * 24\n        minutes += hours * 60\n        seconds += minutes * 60\n\n        if seconds == 0:\n            # default to 1 day\n            seconds = 24 * 60 * 60\n\n        def get_persisted_file(hash_number):\n            folder = cls.get_persist_folder()\n            if not os.path.exists(folder):\n                os.makedirs(folder)\n            return os.path.join(folder, '{}.pickle'.format(hash_number))\n\n        def is_expired(filename):\n            if os.path.exists(filename):\n                file_age = cls.get_file_age(filename)\n                if file_age > seconds:\n                    log.debug('persisted cache expired: {}'.format(filename))\n                    ret = True\n                else:\n                    ret = False\n            else:\n                ret = True\n            return ret\n\n        def decorator(func):\n\n            def func_wrapper(*args, **kwargs):\n                def _key_gen():\n                    string = '{}-{}-{}-{}'.format(\n                        func.__module__,\n                        func.__name__,\n                        args,\n                        kwargs.items()\n                    )\n                    return hashlib.sha256(string.encode('utf-8')).hexdigest()\n\n                key = _key_gen()\n                persisted_file = get_persisted_file(key)\n                if is_expired(persisted_file):\n                    ret = func(*args, **kwargs)\n                    with open(persisted_file, 'wb') as f:\n                        pickle.dump(ret, f)\n                else:\n                    with open(persisted_file, 'rb') as f:\n                        ret = pickle.load(f)\n                return ret\n\n            return func_wrapper\n\n        return decorator", "response": "Decorator that caches the return of the function for given time."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getEvents(self, repo_user, repo_name, until_id=None):\n        done = False\n        page = 0\n        events = []\n        while not done:\n            new_events = yield self.api.makeRequest(\n                    ['repos', repo_user, repo_name, 'events'],\n                    page)\n\n            # terminate if we find a matching ID\n            if new_events:\n                for event in new_events:\n                    if event['id'] == until_id:\n                        done = True\n                        break\n                    events.append(event)\n            else:\n                done = True\n\n            page += 1\n        defer.returnValue(events)", "response": "Get all repository events following paging until the end\n            or until UNTIL_ID is seen. Returns a Deferred that resolves with the list of events."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a specific hook.", "response": "def getHook(self, repo_user, repo_name, hook_id):\n        \"\"\"\n        GET /repos/:owner/:repo/hooks/:id\n\n        Returns the Hook.\n        \"\"\"\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name, 'hooks', str(hook_id)],\n            method='GET',\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nedits a hook in the specified repository.", "response": "def editHook(self, repo_user, repo_name, hook_id, name, config,\n            events=None, add_events=None, remove_events=None, active=None):\n        \"\"\"\n        PATCH /repos/:owner/:repo/hooks/:id\n\n        :param hook_id: Id of the hook.\n        :param name:  The name of the service that is being called.\n        :param config: A Hash containing key/value pairs to provide settings\n                       for this hook.\n        \"\"\"\n        post = dict(\n                name=name,\n                config=config,\n                )\n        if events is not None:\n            post['events'] = events\n\n        if add_events is not None:\n            post['add_events'] = add_events\n\n        if remove_events is not None:\n            post['remove_events'] = remove_events\n\n        if active is not None:\n            post['active'] = active\n\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name, 'hooks', str(hook_id)],\n            method='PATCH',\n            post=post,\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting statuses from a specific revision.", "response": "def getStatuses(self, repo_user, repo_name, sha):\n        \"\"\"\n        :param sha: Full sha to list the statuses from.\n        :return: A defered with the result from GitHub.\n        \"\"\"\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name, 'statuses', sha],\n            method='GET')"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a status for a specific revision.", "response": "def createStatus(self,\n            repo_user, repo_name, sha, state, target_url=None,\n            description=None, context=None):\n        \"\"\"\n        :param sha: Full sha to create the status for.\n        :param state: one of the following 'pending', 'success', 'error'\n                      or 'failure'.\n        :param target_url: Target url to associate with this status.\n        :param description: Short description of the status.\n        :return: A defered with the result from GitHub.\n        \"\"\"\n        payload = {'state': state}\n\n        if description is not None:\n            payload['description'] = description\n\n        if target_url is not None:\n            payload['target_url'] = target_url\n\n        if context is not None:\n            payload['context'] = context\n\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name, 'statuses', sha],\n            method='POST',\n            post=payload)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef edit(self, repo_user, repo_name, pull_number,\n             title=None, body=None, state=None):\n        \"\"\"\n        PATCH /repos/:owner/:repo/pulls/:number\n\n        :param pull_number: The pull request's number\n        :param title: The new title for the pull request\n        :param body: The new top-level body for the pull request\n        :param state: The new top-level body for the pull request\n        \"\"\"\n        if not any((title, body, state)):\n            raise ValueError(\"must provide at least one of:\"\n                             \" title, body, state\")\n\n        post = {}\n        if title is not None:\n            post['title'] = title\n        if body is not None:\n            post['body'] = body\n        if state is not None:\n            if state not in ('open', 'closed'):\n                raise ValueError(\"state must be either 'open' or 'closed'\")\n            post['state'] = state\n\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name, 'pulls', pull_number],\n            method='PATCH',\n            post=post)", "response": "Edit the top - level content of a pull request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new comment on an issue.", "response": "def create(self, repo_user, repo_name, issue_number, body):\n        \"\"\"\n        PATCH /repos/:owner/:repo/issues/:number/comments\n\n        :param issue_number: The issue's (or pull request's) number\n        :param body: The body of this comment\n        \"\"\"\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name,\n             'issues', issue_number, 'comments'],\n            method='POST',\n            post=dict(body=body))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget / repos/:owner/:repo / pulls/:number / comments", "response": "def getPullRequestComments(self, repo_user, repo_name, pull_number):\n        \"\"\"\n        GET /repos/:owner/:repo/pulls/:number/comments\n\n        :param pull_number: The pull request's number.\n        \"\"\"\n        return self.api.makeRequestAllPages(\n            ['repos', repo_user, repo_name,\n             'pulls', str(pull_number), 'comments'])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting / repos / owner / repo / pull / comments / comment_id", "response": "def getComment(self, repo_user, repo_name, comment_id):\n        \"\"\"\n        GET /repos/:owner/:repo/pull/comments/:number\n\n        :param comment_id: The review comment's ID.\n        \"\"\"\n        return self.api.makeRequest(\n            ['repos', repo_user, repo_name,\n             'pulls', 'comments', str(comment_id)])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef createComment(self, repo_user, repo_name, pull_number,\n                      body, commit_id, path, position):\n        \"\"\"\n        POST /repos/:owner/:repo/pulls/:number/comments\n\n        :param pull_number: The pull request's ID.\n        :param body: The text of the comment.\n        :param commit_id: The SHA of the commit to comment on.\n        :param path: The relative path of the file to comment on.\n        :param position: The line index in the diff to comment on.\n        \"\"\"\n        return self.api.makeRequest(\n            [\"repos\", repo_user, repo_name,\n             \"pulls\", str(pull_number), \"comments\"],\n            method=\"POST\",\n            data=dict(body=body,\n                      commit_id=commit_id,\n                      path=path,\n                      position=position))", "response": "Creates a comment on a pull request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreply to a comment.", "response": "def replyToComment(self, repo_user, repo_name, pull_number,\n                       body, in_reply_to):\n        \"\"\"\n        POST /repos/:owner/:repo/pulls/:number/comments\n\n        Like create, but reply to an existing comment.\n\n        :param body: The text of the comment.\n        :param in_reply_to: The comment ID to reply to.\n        \"\"\"\n        return self.api.makeRequest(\n            [\"repos\", repo_user, repo_name,\n             \"pulls\", str(pull_number), \"comments\"],\n            method=\"POST\",\n            data=dict(body=body,\n                      in_reply_to=in_reply_to))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef editComment(self, repo_user, repo_name, comment_id, body):\n        return self.api.makeRequest(\n            [\"repos\", repo_user, repo_name,\n             \"pulls\", \"comments\", str(comment_id)],\n            method=\"POST\",\n            data=dict(body=body))", "response": "Edit a comment in a branch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef deleteComment(self, repo_user, repo_name, comment_id):\n        return self.api.makeRequest(\n            [\"repos\", repo_user, repo_name,\n             \"pulls\", \"comments\", str(comment_id)],\n            method=\"DELETE\")", "response": "Delete a comment from a branch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_project_path(cls, path):\n        path = vistir.compat.Path(path)\n        if path.name == 'Pipfile':\n            pipfile_path = path\n            path = path.parent\n        else:\n            pipfile_path = path / 'Pipfile'\n        pipfile_location = cls.normalize_path(pipfile_path)\n        venv_path = path / '.venv'\n        if venv_path.exists():\n            if not venv_path.is_dir():\n                possible_path = vistir.compat.Path(venv_path.read_text().strip())\n                if possible_path.exists():\n                    return cls(possible_path.as_posix())\n            else:\n                if venv_path.joinpath('lib').exists():\n                    return cls(venv_path.as_posix())\n        sanitized = re.sub(r'[ $`!*@\"\\\\\\r\\n\\t]', \"_\", path.name)[0:42]\n        hash_ = hashlib.sha256(pipfile_location.encode()).digest()[:6]\n        encoded_hash = base64.urlsafe_b64encode(hash_).decode()\n        hash_fragment = encoded_hash[:8]\n        venv_name = \"{0}-{1}\".format(sanitized, hash_fragment)\n        return cls(cls.get_workon_home().joinpath(venv_name).as_posix())", "response": "Utility for finding a virtualenv location based on a project path"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the system path information for a given python executable.", "response": "def get_sys_path(cls, python_path):\n        \"\"\"Get the :data:`sys.path` data for a given python executable.\n\n        :param str python_path: Path to a specific python executable.\n        :return: The system path information for that python runtime.\n        :rtype: list\n        \"\"\"\n\n        command = [python_path, \"-c\", \"import json, sys; print(json.dumps(sys.path))\"]\n        c = vistir.misc.run(command, return_object=True, block=True, nospin=True)\n        assert c.returncode == 0, \"failed loading virtualenv path\"\n        sys_path = json.loads(c.out.strip())\n        return sys_path"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the arguments to pass to the interpreter when installing the supplied package in the virtualenv.", "response": "def get_setup_install_args(self, pkgname, setup_py, develop=False):\n        \"\"\"Get setup.py install args for installing the supplied package in the virtualenv\n\n        :param str pkgname: The name of the package to install\n        :param str setup_py: The path to the setup file of the package\n        :param bool develop: Whether the package is in development mode\n        :return: The installation arguments to pass to the interpreter when installing\n        :rtype: list\n        \"\"\"\n\n        headers = self.base_paths[\"headers\"]\n        headers = headers / \"python{0}\".format(self.python_version) / pkgname\n        install_arg = \"install\" if not develop else \"develop\"\n        return [\n            self.python, \"-u\", \"-c\", SETUPTOOLS_SHIM % setup_py, install_arg,\n            \"--single-version-externally-managed\",\n            \"--install-headers={0}\".format(self.base_paths[\"headers\"]),\n            \"--install-purelib={0}\".format(self.base_paths[\"purelib\"]),\n            \"--install-platlib={0}\".format(self.base_paths[\"platlib\"]),\n            \"--install-scripts={0}\".format(self.base_paths[\"scripts\"]),\n            \"--install-data={0}\".format(self.base_paths[\"data\"]),\n        ]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setuptools_install(self, chdir_to, pkg_name, setup_py_path=None, editable=False):\n\n        install_options = [\"--prefix={0}\".format(self.prefix.as_posix()),]\n        with vistir.contextmanagers.cd(chdir_to):\n            c = self.run(\n                self.get_setup_install_args(pkg_name, setup_py_path, develop=editable) +\n                install_options, cwd=chdir_to\n            )\n            return c.returncode", "response": "Install an sdist or an editable package into the virtualenv"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninstalls a package into the virtualenv", "response": "def install(self, req, editable=False, sources=[]):\n        \"\"\"Install a package into the virtualenv\n\n        :param req: A requirement to install\n        :type req: :class:`requirementslib.models.requirement.Requirement`\n        :param bool editable: Whether the requirement is editable, defaults to False\n        :param list sources: A list of pip sources to consult, defaults to []\n        :return: A return code, 0 if successful\n        :rtype: int\n        \"\"\"\n\n        try:\n            packagebuilder = self.safe_import(\"packagebuilder\")\n        except ImportError:\n            packagebuilder = None\n        with self.activated(include_extras=False):\n            if not packagebuilder:\n                return 2\n            ireq = req.as_ireq()\n            sources = self.filter_sources(req, sources)\n            cache_dir = os.environ.get('PASSA_CACHE_DIR',\n                os.environ.get(\n                    'PIPENV_CACHE_DIR',\n                    vistir.path.create_tracked_tempdir(prefix=\"passabuild\")\n                )\n            )\n            built = packagebuilder.build.build(ireq, sources, cache_dir)\n            if isinstance(built, distlib.wheel.Wheel):\n                maker = distlib.scripts.ScriptMaker(None, None)\n                built.install(self.paths, maker)\n            else:\n                path = vistir.compat.Path(built.path)\n                cd_path = path.parent\n                setup_py = cd_path.joinpath(\"setup.py\")\n                return self.setuptools_install(\n                    cd_path.as_posix(), req.name, setup_py.as_posix(),\n                    editable=req.editable\n                )\n            return 0"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef activated(self, include_extras=True, extra_dists=[]):\n\n        original_path = sys.path\n        original_prefix = sys.prefix\n        original_user_base = os.environ.get(\"PYTHONUSERBASE\", None)\n        original_venv = os.environ.get(\"VIRTUAL_ENV\", None)\n        parent_path = vistir.compat.Path(__file__).absolute().parent.parent.as_posix()\n        prefix = self.prefix.as_posix()\n        with vistir.contextmanagers.temp_environ(), vistir.contextmanagers.temp_path():\n            os.environ[\"PATH\"] = os.pathsep.join([\n                vistir.compat.fs_str(self.scripts_dir),\n                vistir.compat.fs_str(self.prefix.as_posix()),\n                os.environ.get(\"PATH\", \"\")\n            ])\n            os.environ[\"PYTHONIOENCODING\"] = vistir.compat.fs_str(\"utf-8\")\n            os.environ[\"PYTHONDONTWRITEBYTECODE\"] = vistir.compat.fs_str(\"1\")\n            os.environ[\"PATH\"] = self.base_paths[\"PATH\"]\n            os.environ[\"PYTHONPATH\"] = self.base_paths[\"PYTHONPATH\"]\n            if self.is_venv:\n                os.environ[\"VIRTUAL_ENV\"] = vistir.compat.fs_str(prefix)\n            sys.path = self.sys_path\n            sys.prefix = self.sys_prefix\n            site.addsitedir(self.base_paths[\"purelib\"])\n            if include_extras:\n                site.addsitedir(parent_path)\n                extra_dists = list(self.extra_dists) + extra_dists\n                for extra_dist in extra_dists:\n                    if extra_dist not in self.get_working_set():\n                        extra_dist.activate(self.sys_path)\n                sys.modules[\"recursive_monkey_patch\"] = self.recursive_monkey_patch\n            try:\n                yield\n            finally:\n                del os.environ[\"VIRTUAL_ENV\"]\n                if original_user_base:\n                    os.environ[\"PYTHONUSERBASE\"] = original_user_base\n                if original_venv:\n                    os.environ[\"VIRTUAL_ENV\"] = original_venv\n                sys.path = original_path\n                sys.prefix = original_prefix\n                six.moves.reload_module(pkg_resources)", "response": "A context manager which activates the virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command with ~subprocess. Popen in the context of the virtual environment.", "response": "def run(self, cmd, cwd=os.curdir):\n        \"\"\"Run a command with :class:`~subprocess.Popen` in the context of the virtualenv\n\n        :param cmd: A command to run in the virtual environment\n        :type cmd: str or list\n        :param str cwd: The working directory in which to execute the command, defaults to :data:`os.curdir`\n        :return: A finished command object\n        :rtype: :class:`~subprocess.Popen`\n        \"\"\"\n\n        c = None\n        with self.activated():\n            script = vistir.cmdparse.Script.parse(cmd)\n            c = vistir.misc.run(script._parts, return_object=True, nospin=True, cwd=cwd)\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_monkeypatched_pathset(self):\n\n        from pip_shims.shims import InstallRequirement\n        # Determine the path to the uninstall module name based on the install module name\n        uninstall_path = InstallRequirement.__module__.replace(\n            \"req_install\", \"req_uninstall\"\n        )\n        req_uninstall = self.safe_import(uninstall_path)\n        self.recursive_monkey_patch.monkey_patch(\n            PatchedUninstaller, req_uninstall.UninstallPathSet\n        )\n        return req_uninstall.UninstallPathSet", "response": "Returns a monkeypatched UninstallPathSet which enables uninstallation of packages from the virtualenv packages\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef uninstall(self, pkgname, *args, **kwargs):\n\n        auto_confirm = kwargs.pop(\"auto_confirm\", True)\n        verbose = kwargs.pop(\"verbose\", False)\n        with self.activated():\n            pathset_base = self.get_monkeypatched_pathset()\n            dist = next(\n                iter(filter(lambda d: d.project_name == pkgname, self.get_working_set())),\n                None\n            )\n            pathset = pathset_base.from_dist(dist)\n            if pathset is not None:\n                pathset.remove(auto_confirm=auto_confirm, verbose=verbose)\n            try:\n                yield pathset\n            except Exception as e:\n                if pathset is not None:\n                    pathset.rollback()\n            else:\n                if pathset is not None:\n                    pathset.commit()\n            if pathset is None:\n                return", "response": "A context manager which allows uninstallation of packages from the virtualenv."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves arduino examples all directory.", "response": "def remove_examples_all():\n    \"\"\"remove arduino/examples/all directory.\n\n    :rtype: None\n\n    \"\"\"\n    d = examples_all_dir()\n    if d.exists():\n        log.debug('remove %s', d)\n        d.rmtree()\n    else:\n        log.debug('nothing to remove: %s', d)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getRootNode(nodes):\n    '''Return the node with the most children'''\n    max = 0\n    root = None\n    for i in nodes:\n        if len(i.children) > max:\n            max = len(i.children)\n            root = i\n    return root", "response": "Return the node with the most children"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting next node in a breadth - first traversal of nodes that have not been used yet", "response": "def getNextNode(nodes,usednodes,parent):\n    '''Get next node in a breadth-first traversal of nodes that have not been used yet'''\n    for e in edges:\n        if e.source==parent:\n            if e.target in usednodes:\n                x = e.target\n                break\n        elif e.target==parent:\n            if e.source in usednoes:\n                x = e.source\n                break  \n    return x"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalculating the position of the circle tangent to the parent circle with the line connecting the centers of the two circles meeting the x axis at angle theta.", "response": "def calcPosition(self,parent_circle):\n        ''' Position the circle tangent to the parent circle with the line connecting the centers of the two circles meeting the x axis at angle theta. '''\n        if r not in self:\n            raise AttributeError(\"radius must be calculated before position.\")\n        if theta not in self:\n            raise AttributeError(\"theta must be set before position can be calculated.\")\n        x_offset = math.cos(t_radians) * (parent_circle.r + self.r)\n        y_offset = math.sin(t_radians) * (parent_circle.r + self.r)\n        self.x = parent_circle.x + x_offset\n        self.y = parent_circle.y + y_offset"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef upload_progress(request):\n    if 'X-Progress-ID' in request.GET:\n        progress_id = request.GET['X-Progress-ID']\n    elif 'X-Progress-ID' in request.META:\n        progress_id = request.META['X-Progress-ID']\n    if progress_id:\n        cache_key = \"%s_%s\" % (request.META['REMOTE_ADDR'], progress_id)\n        data = cache.get(cache_key)\n        return HttpResponse(simplejson.dumps(data))", "response": "Returns the upload progress and total length values"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates username created on ADD only.", "response": "def pre_save(self, model_instance, add):\n        \"\"\"Updates username created on ADD only.\"\"\"\n        value = super(UserField, self).pre_save(model_instance, add)\n        if not value and not add:\n            # fall back to OS user if not accessing through browser\n            # better than nothing ...\n            value = self.get_os_username()\n            setattr(model_instance, self.attname, value)\n            return value\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning this site - package esri toolbox directory.", "response": "def sys_toolbox_dir():\n    \"\"\"\n    Returns this site-package esri toolbox directory.\n    \"\"\"\n    return os.path.join(os.path.dirname(os.path.abspath(__file__)), 'esri', 'toolboxes')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef appdata_roaming_dir():\n    install = arcpy.GetInstallInfo('desktop')\n    app_data = arcpy.GetSystemEnvironment(\"APPDATA\")\n    product_dir = ''.join((install['ProductName'], major_version()))\n    return os.path.join(app_data, 'ESRI', product_dir)", "response": "Returns the roaming AppData directory for the installed ArcGIS Desktop."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndecorates a function to be registered as a route", "response": "def route(self, uri, methods=frozenset({'GET'}), host=None,\n              strict_slashes=False, stream=False, websocket=False):\n        '''Decorate a function to be registered as a route\n\n        :param uri: path of the URL\n        :param methods: list or tuple of methods allowed\n        :param host:\n        :param strict_slashes:\n        :param stream:\n        :return: decorated function\n        '''\n\n        # Fix case where the user did not prefix the URL with a /\n        # and will probably get confused as to why it's not working\n        if not uri.startswith('/'):\n            uri = '/' + uri\n\n        def response(handler):\n            if websocket:\n                handler.is_websocket = True\n            elif stream:\n                handler.is_stream = True\n            self.router.add(uri=uri, methods=methods, handler=handler,\n                            host=host, strict_slashes=strict_slashes)\n            return handler\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef middleware(self, middleware_or_request):\n        '''Decorate and register middleware to be called before a request.\n        Can either be called as @app.middleware or @app.middleware('request')\n        '''\n        def register_middleware(middleware, attach_to='request'):\n            if attach_to == 'request':\n                self.request_middleware.append(middleware)\n            if attach_to == 'response':\n                self.response_middleware.appendleft(middleware)\n            return middleware\n\n        # Detect which way this was called, @middleware or @middleware('AT')\n        if callable(middleware_or_request):\n            return register_middleware(middleware_or_request)\n\n        else:\n            return partial(register_middleware,\n                           attach_to=middleware_or_request)", "response": "Decorate and register middleware to be called before a request."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nregistering a root to serve files from.", "response": "def static(self, uri, file_or_directory, pattern=r'/?.+',\n               use_modified_since=True, use_content_range=False):\n        '''Register a root to serve files from. The input can either be a\n        file or a directory. See\n        '''\n        static_register(self, uri, file_or_directory, pattern,\n                        use_modified_since, use_content_range)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef blueprint(self, blueprint, **options):\n        '''Register a blueprint on the application.\n\n        :param blueprint: Blueprint object\n        :param options: option dictionary with blueprint defaults\n        :return: Nothing\n        '''\n        if blueprint.name in self.blueprints:\n            assert self.blueprints[blueprint.name] is blueprint, \\\n                'A blueprint with the name \"%s\" is already registered.  ' \\\n                'Blueprint names must be unique.' % \\\n                (blueprint.name,)\n        else:\n            self.blueprints[blueprint.name] = blueprint\n            self._blueprint_order.append(blueprint)\n        blueprint.register(self, options)", "response": "Register a blueprint on the application."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a URL based on a view name and the values provided.", "response": "def url_for(self, view_name: str, **kwargs):\n        '''Build a URL based on a view name and the values provided.\n\n        In order to build a URL, all request parameters must be supplied as\n        keyword arguments, and each parameter must pass the test for the\n        specified parameter type. If these conditions are not met, a\n        `URLBuildError` will be thrown.\n\n        Keyword arguments that are not request parameters will be included in\n        the output URL's query string.\n\n        :param view_name: string referencing the view name\n        :param \\*\\*kwargs: keys and values that are used to build request\n            parameters and query string arguments.\n\n        :return: the built URL\n\n        Raises:\n            URLBuildError\n        '''\n        # find the route by the supplied view name\n        uri, route = self.router.find_route_by_view_name(view_name)\n\n        if not uri or not route:\n            raise URLBuildError(\n                    'Endpoint with name `{}` was not found'.format(\n                        view_name))\n\n        if uri != '/' and uri.endswith('/'):\n            uri = uri[:-1]\n\n        out = uri\n\n        # find all the parameters we will need to build in the URL\n        matched_params = re.findall(\n            self.router.parameter_pattern, uri)\n\n        # _method is only a placeholder now, don't know how to support it\n        kwargs.pop('_method', None)\n        anchor = kwargs.pop('_anchor', '')\n        # _external need SERVER_NAME in config or pass _server arg\n        external = kwargs.pop('_external', False)\n        scheme = kwargs.pop('_scheme', '')\n        if scheme and not external:\n            raise ValueError('When specifying _scheme, _external must be True')\n\n        netloc = kwargs.pop('_server', None)\n        if netloc is None and external:\n            netloc = self.config.get('SERVER_NAME', '')\n\n        for match in matched_params:\n            name, _type, pattern = self.router.parse_parameter_string(\n                match)\n            # we only want to match against each individual parameter\n            specific_pattern = '^{}$'.format(pattern)\n            supplied_param = None\n\n            if kwargs.get(name):\n                supplied_param = kwargs.get(name)\n                del kwargs[name]\n            else:\n                raise URLBuildError(\n                    'Required parameter `{}` was not passed to url_for'.format(\n                        name))\n\n            supplied_param = str(supplied_param)\n            # determine if the parameter supplied by the caller passes the test\n            # in the URL\n            passes_pattern = re.match(specific_pattern, supplied_param)\n\n            if not passes_pattern:\n                if _type != str:\n                    msg = (\n                        'Value \"{}\" for parameter `{}` does not '\n                        'match pattern for type `{}`: {}'.format(\n                            supplied_param, name, _type.__name__, pattern))\n                else:\n                    msg = (\n                        'Value \"{}\" for parameter `{}` '\n                        'does not satisfy pattern {}'.format(\n                            supplied_param, name, pattern))\n                raise URLBuildError(msg)\n\n            # replace the parameter in the URL with the supplied value\n            replacement_regex = '(<{}.*?>)'.format(name)\n\n            out = re.sub(\n                replacement_regex, supplied_param, out)\n\n        # parse the remainder of the keyword arguments into a querystring\n        query_string = urlencode(kwargs, doseq=True) if kwargs else ''\n        # scheme://netloc/path;parameters?query#fragment\n        out = urlunparse((scheme, netloc, out, '', query_string, anchor))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts a long integer into an octet string.", "response": "def i2osp(self, long_integer, block_size):\n        'Convert a long integer into an octet string.'\n        hex_string = '%X' % long_integer\n        if len(hex_string) > 2 * block_size:\n            raise ValueError('integer %i too large to encode in %i octets' % (long_integer, block_size))\n        return a2b_hex(hex_string.zfill(2 * block_size))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexports as excel wb: output: fn: file name", "response": "def export_xlsx(wb, output, fn):\n    \"\"\"\n    export as excel\n    wb:\n    output:\n    fn: file name\n    \"\"\"\n    wb.close()\n    output.seek(0)\n    response = HttpResponse(output.read(), content_type=\"application/vnd.ms-excel\")\n    cd = codecs.encode('attachment;filename=%s' % fn, 'utf-8')\n    response['Content-Disposition'] = cd\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef xlsw_write_row(ws, row_idx, row, fmt=None):\n    for col_idx in range(len(row)):\n        ws.write(row_idx, col_idx, row[col_idx], fmt)\n    row_idx += 1\n    return row_idx", "response": "write a row to the log file"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexports as excel filename: file name titles: title for this table qs: queryset to export func_data: a function to format object to list. ex: `lambda o: [o.pk, o.name]`", "response": "def simple_export2xlsx(filename, titles, qs, func_data):\n    \"\"\"\n    export as excel\n    filename: file name\n    titles: title for this table\n    qs: queryset to export\n    func_data: a function to format object to list. ex: `lambda o: [o.pk, o.name]`\n    \"\"\"\n    output = BytesIO()\n    wb = xlwt.Workbook(output)\n    ws = wb.add_worksheet(filename)\n    header_fmt = wb.add_format()\n    header_fmt.set_bg_color('#C4D89E')\n    row_idx = 0\n    row_idx = xlsw_write_row(ws, row_idx, titles, header_fmt)\n    for o in qs:\n        row_idx = xlsw_write_row(ws, row_idx, func_data(o))\n    fn = '%s-%s.xlsx' % (filename, datetime.now())\n    return export_xlsx(wb, output, fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add(self, iterable):\n        item1 = item2 = MarkovChain.START\n        for item3 in iterable:\n            self[(item1, item2)].add_side(item3)\n            item1 = item2\n            item2 = item3\n        self[(item1, item2)].add_side(MarkovChain.END)", "response": "Insert an iterable into the markov chain."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a list of elements from the markov chain.", "response": "def random_output(self, max=100):\n        \"\"\" Generate a list of elements from the markov chain.\n            The `max` value is in place in order to prevent excessive iteration.\n        \"\"\"\n        output = []\n        item1 = item2 = MarkovChain.START\n        for i in range(max-3):\n            item3 = self[(item1, item2)].roll()\n            if item3 is MarkovChain.END:\n                break\n            output.append(item3)\n            item1 = item2\n            item2 = item3\n        return output"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstart the periodic runner for the current object.", "response": "def start(self):\n        \"\"\"\n        Start the periodic runner\n        \"\"\"\n        if self._isRunning:\n            return\n\n        if self._cease.is_set():\n            self._cease.clear()  # restart\n\n        class Runner(threading.Thread):\n            @classmethod\n            def run(cls):\n                nextRunAt = cls.setNextRun()\n\n                while not self._cease.is_set():\n                    if datetime.now() >= nextRunAt:\n                        self._run()\n                        nextRunAt = cls.setNextRun()\n\n            @classmethod\n            def setNextRun(cls):\n                # return datetime.now() + timedelta(seconds=self._interval)\n                return self._interval.nextRunAt()\n\n        runner = Runner()\n        runner.setDaemon(True)\n        runner.start()\n        self._isRunning = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef useThis(self, *args, **kwargs):\n        self._callback = functools.partial(self._callback, *args, **kwargs)", "response": "Change parameter of the callback function to use when executing the\n         callback function."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nstop the periodic runner.", "response": "def stop(self):\n        \"\"\"\n        Stop the periodic runner\n        \"\"\"\n        self._cease.set()\n        time.sleep(0.1)  # let the thread closing correctly.\n        self._isRunning = False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nforcing Slash ----------- Wrap a bottle route with this decorator to force a trailing slash. This is useful for the root of your application or places where TrailingSlash doesn't work", "response": "def force_slash(fn):\n    \"\"\"\n    Force Slash\n    -----------\n\n    Wrap a bottle route with this decorator to force a trailing slash. This is useful for the root of your application or places where TrailingSlash doesn't work\n    \"\"\"\n    @wraps(fn)\n    def wrapped(*args, **kwargs):\n        if request.environ['PATH_INFO'].endswith('/'):\n            return fn(*args, **kwargs)\n        else:\n            redirect(request.environ['SCRIPT_NAME'] + request.environ['PATH_INFO'] + '/')\n    return wrapped"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the user is authenticated and if so check if the session is valid", "response": "def condition(self) -> bool:\r\n        \"\"\" check JWT, then check session for validity \"\"\"\r\n        jwt = JWT()\r\n        if jwt.verify_http_auth_token():\r\n            if not current_app.config['AUTH']['FAST_SESSIONS']:\r\n                session = SessionModel.where_session_id(\r\n                    jwt.data['session_id'])\r\n                if session is None:\r\n                    return False\r\n            Session.set_current_session(jwt.data['session_id'])\r\n            return True\r\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nrenders as hidden widget", "response": "def render_hidden(name, value):\n    \"\"\" render as hidden widget \"\"\"\n    if isinstance(value, list):\n        return MultipleHiddenInput().render(name, value)\n    return HiddenInput().render(name, value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_only_selected_choices(self, value):\n        schoices = self.choices\n        selected_choices = set([force_text(v) for v in value if v])\n        if isinstance(schoices, ModelChoiceIterator):\n            schoices.queryset = schoices.queryset.filter(pk__in=selected_choices)\n        else:\n            schoices = [e for e in schoices if force_text(e) in selected_choices]\n        return schoices", "response": "Return a list of optgroups for this widget."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a batch instance given the filename.", "response": "def get_batch(self, filename=None):\n        \"\"\"Returns a batch instance given the filename.\n        \"\"\"\n        try:\n            history = self.history_model.objects.get(filename=filename)\n        except self.history_model.DoesNotExist as e:\n            raise TransactionsFileQueueError(\n                f\"Batch history not found for '{filename}'.\"\n            ) from e\n        if history.consumed:\n            raise TransactionsFileQueueError(\n                f\"Batch closed for '{filename}'. Got consumed=True\"\n            )\n        batch = self.batch_cls()\n        batch.batch_id = history.batch_id\n        batch.filename = history.filename\n        return batch"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_items(self, html):\n        captcha_patterns = [\n            \"https://www.google.com/recaptcha/api.js\", \"I'm not a robot\"]\n        for captcha_pattern in captcha_patterns:\n            if captcha_pattern in html:\n                raise exc.CaptchaError(\"Found %r in html!\" % captcha_pattern)\n\n        data = list()\n        soup = self.to_soup(html)\n\n        div = soup.find(\"div\", class_=\"zsg-lg-1-2 zsg-sm-1-1\")\n\n        for li in div.find_all(\"li\"):\n            a = li.find_all(\"a\")[0]\n            href = a[\"href\"]\n            name = a.text.strip()\n            data.append((href, name))\n        return data", "response": "Get items from list page."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting house detail from a given HTML page.", "response": "def get_house_detail(self, html):\n        \"\"\"Get bedroom, bathroom, sqft and more information.\n\n        Example: http://www.zillow.com/homedetails/8510-Whittier-Blvd-Bethesda-MD-20817/37183103_zpid/\n        \"\"\"\n        if \"I'm not a robot\" in html:\n            raise exc.CaptchaError(url)\n\n        data = {\"errors\": dict()}\n        soup = self.get_soup(html)\n\n        # header part, bedroom, bathroom, sqft\n        header = soup.find(\"header\", class_=\"zsg-content-header addr\")\n        if header is None:\n            raise exc.ParseError(url)\n\n        try:\n            h3 = header.find(\"h3\")\n            if h3 is None:\n                raise exc.ParseError\n\n            span_list = h3.find_all(\"span\", class_=\"addr_bbs\")\n            if len(span_list) != 3:\n                raise exc.ParseError\n\n            text = span_list[0].text\n            try:\n                bedroom = float_filter(text)\n                data[\"bedroom\"] = bedroom\n            except:\n                data[\"errors\"][\n                    \"bedroom\"] = \"can't parse bedroom from %r\" % text\n\n            text = span_list[1].text\n            try:\n                bathroom = float_filter(text)\n                data[\"bathroom\"] = bathroom\n            except:\n                data[\"errors\"][\n                    \"bathroom\"] = \"can't parse bathroom from %r\" % text\n\n            text = span_list[2].text\n            try:\n                sqft = int_filter(text)\n                data[\"sqft\"] = sqft\n            except:\n                data[\"errors\"][\"sqft\"] = \"can't parse sqft from %r\" % text\n        except:\n            pass\n\n        # Facts, Features, Construction, Other (FFCO)\n        div_list = soup.find_all(\n            \"div\", class_=re.compile(\"fact-group-container zsg-content-component\"))\n\n        for div in div_list:\n            h3 = div.find(\"h3\")\n            if h3.text == \"Facts\":\n                try:\n                    facts = list()\n                    for li in div.find_all(\"li\"):\n                        facts.append(li.text.strip())\n                    data[\"facts\"] = facts\n                except Exception as e:\n                    data[\"errors\"][\"facts\"] = str(e)\n\n            if h3.text == \"Features\":\n                features = list()\n                try:\n                    for li in div.find_all(\"li\"):\n                        if '\"targetDiv\"' not in li.text:\n                            features.append(li.text.strip())\n                    data[\"features\"] = features\n                except Exception as e:\n                    data[\"errors\"][\"features\"] = repr(e)\n\n            if h3.text == \"Appliances Included\":\n                appliances = list()\n                try:\n                    for li in div.find_all(\"li\"):\n                        appliances.append(li.text.strip())\n                    data[\"appliances\"] = appliances\n                except Exception as e:\n                    data[\"errors\"][\"appliances\"] = repr(e)\n\n            if h3.text == \"Additional Features\":\n                additional_features = list()\n                try:\n                    for li in div.find_all(\"li\"):\n                        additional_features.append(li.text.strip())\n                    data[\"additional_features\"] = additional_features\n                except Exception as e:\n                    data[\"errors\"][\"additional_features\"] = repr(e)\n\n            if h3.text == \"Construction\":\n                construction = list()\n                try:\n                    for li in div.find_all(\"li\"):\n                        construction.append(li.text.strip())\n                    data[\"construction\"] = construction\n                except Exception as e:\n                    data[\"errors\"][\"construction\"] = repr(e)\n\n            if h3.text == \"Other\":\n                other = list()\n                try:\n                    for li in div.find_all(\"li\"):\n                        other.append(li.text.strip())\n                    data[\"other\"] = other\n                except Exception as e:\n                    data[\"errors\"][\"other\"] = repr(e)\n\n        if len(data[\"errors\"]) == 0:\n            del data[\"errors\"]\n\n        if data:\n            return data\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncopying the contents of src_dir to dest_dir.", "response": "def __copy_tree(src_dir, dest_dir):\r\n    \"\"\"\r\n    The shutil.copytree() or distutils.dir_util.copy_tree() will happen to report\r\n    error list below if we invoke it again and again ( at least in python 2.7.4 ):\r\n\r\n    IOError: [Errno 2] No such file or directory: ...\r\n\r\n    So we have to write our's copy_tree() for that purpose.\r\n    \"\"\"\r\n\r\n    if not os.path.exists(dest_dir):\r\n        os.makedirs(dest_dir)\r\n        shutil.copystat(src_dir, dest_dir)\r\n\r\n    for entry in os.listdir(src_dir):\r\n        from_path = os.path.join(src_dir, entry)\r\n        to_path = os.path.join(dest_dir, entry)\r\n        if os.path.isdir(from_path):\r\n            __copy_tree(from_path, to_path)\r\n        else:\r\n            shutil.copy2(from_path, to_path)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a preprocessed source directory.", "response": "def preprocess_source(base_dir=os.curdir):\r\n    \"\"\"\r\n    A special method for convert all source files to compatible with current\r\n    python version during installation time.\r\n\r\n    The source directory layout must like this :\r\n\r\n    base_dir --+\r\n               |\r\n               +-- src (All sources are placed into this directory)\r\n               |\r\n               +-- preprocessed (Preprocessed sources are placed into this\r\n               |   directory)\r\n               |\r\n               +-- setup.py\r\n               |\r\n               ...\r\n\r\n    @return Preprocessed source directory\r\n    \"\"\"\r\n\r\n    source_path = os.path.join(base_dir, SOURCE_DIR)\r\n    destination_path = os.path.join(base_dir, PREPROCESSED_DIR)\r\n\r\n    # The 'build' and 'dist' folder sometimes will not update! So we need to\r\n    # remove them all !\r\n    shutil.rmtree(os.path.join(base_dir, 'build'), ignore_errors=True)\r\n    shutil.rmtree(os.path.join(base_dir, 'dist'), ignore_errors=True)\r\n\r\n    # Remove all unused directories\r\n    directories = []\r\n    directory_patterns = ['__pycache__', '*.egg-info']\r\n    for root, dirs, files in os.walk(destination_path):\r\n        for adir in dirs:\r\n            for pattern in directory_patterns:\r\n                if fnmatch.fnmatch(adir, pattern):\r\n                    directories.append(os.path.join(root, adir))\r\n                    break\r\n\r\n    for adir in directories:\r\n        shutil.rmtree(adir, ignore_errors=True)\r\n\r\n    if sys.version_info[0] >= 3:\r\n        # We wrote program implicated by version 3, if python version\r\n        # large or equal than 3, we need not change the sources.\r\n        return source_path\r\n\r\n    # Check and prepare 3to2 module.\r\n    try:\r\n        from lib3to2.main import main as lib3to2_main\r\n    except ImportError:\r\n        try:\r\n            from pip import main as pipmain\r\n        except:\r\n            from pip._internal import main as pipmain\r\n\r\n        pipmain(['install', '3to2'])\r\n\r\n        from lib3to2.main import main as lib3to2_main\r\n\r\n    # Remove old preprocessed sources.\r\n    if not os.path.exists(destination_path):\r\n        __copy_tree(source_path, destination_path)\r\n        lib3to2_main(\"lib3to2.fixes\",\r\n                     [\"-w\", \"-n\", \"--no-diffs\"] + [destination_path])\r\n    else:\r\n        # Remove all files that only in right side\r\n        # Copy all files that only in left side to right side, then\r\n        # 3to2 on these files\r\n\r\n        files = []\r\n        dirs = []\r\n\r\n        cmp_result = filecmp.dircmp(source_path, destination_path)\r\n        dirs.append(cmp_result)\r\n\r\n        while len(dirs) > 0:\r\n\r\n            # Get the last one compare result\r\n            cmp_result = dirs[-1]\r\n            del dirs[-1]\r\n\r\n            # Append all sub-dirs compare results, so that we could\r\n            # continue our loop.\r\n            dirs.extend(list(cmp_result.subdirs.values()))\r\n\r\n            # Remove all files that only in right side\r\n            for file_name in cmp_result.right_only:\r\n                file_path = os.path.join(cmp_result.right, file_name)\r\n                if os.path.isdir(file_path):\r\n                    shutil.rmtree(file_path, ignore_errors=True)\r\n                    continue\r\n\r\n                # Only parse files.\r\n                try:\r\n                    os.remove(file_path)\r\n                except:\r\n                    pass\r\n\r\n            # Copy all files that only in left side to right side or\r\n            # different files, then 3to2 on these files\r\n            for file_name in (cmp_result.left_only + cmp_result.diff_files):\r\n                left_file_path = os.path.join(cmp_result.left, file_name)\r\n                right_file_path = os.path.join(cmp_result.right, file_name)\r\n\r\n                if os.path.isdir(left_file_path):\r\n                    __copy_tree(left_file_path, right_file_path)\r\n                    files.append(right_file_path)\r\n                    continue\r\n\r\n                if not fnmatch.fnmatch(file_name, \"*.py\"):\r\n                    continue\r\n\r\n                try:\r\n                    os.remove(right_file_path)\r\n                except:\r\n                    pass\r\n\r\n                shutil.copy2(left_file_path, right_file_path)\r\n                files.append(right_file_path)\r\n\r\n        if len(files) > 0:\r\n            lib3to2_main(\"lib3to2.fixes\", [\"-w\", \"-n\", \"--no-diffs\"] + files)\r\n\r\n    return destination_path"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_time(self, loc4d=None):\n        if loc4d is None:\n            raise ValueError(\"Location4D object can not be None\")\n\n        if self.pattern == self.PATTERN_CYCLE:\n            c = SunCycles.cycles(loc=loc4d)\n            if self.cycle == self.CYCLE_SUNRISE:\n                r = c[SunCycles.RISING]\n            elif self.cycle == self.CYCLE_SUNSET:\n                r = c[SunCycles.SETTING]\n            td = timedelta(hours=self.time_delta)\n            if self.plus_or_minus == self.HOURS_PLUS:\n                r = r + td\n            elif self.plus_or_minus == self.HOURS_MINUS:\n                r = r - td\n            return r\n        elif self.pattern == self.PATTERN_SPECIFICTIME:\n            return self._time.replace(year=loc4d.time.year, month=loc4d.time.month, day=loc4d.time.day)", "response": "Calculates the time at which this Diel migration is actually happening."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nmoving the particle to the new location.", "response": "def move(self, particle, u, v, w, modelTimestep, **kwargs):\n\n        # If the particle is settled, don't move it anywhere\n        if particle.settled:\n            return { 'u': 0, 'v': 0, 'w': 0 }\n\n        # If the particle is halted (but not settled), don't move it anywhere\n        if particle.halted:\n            return { 'u': 0, 'v': 0, 'w': 0 }\n\n        # How far could I move?  We don't want to overshoot our desired depth.\n        vertical_potential = w * modelTimestep\n\n        \"\"\"\n            This only works if min is less than max.\n            No checks are done here, so it should be done before\n            calling this function.\n        \"\"\"\n\n        \"\"\" I'm below my desired max depth, so i need to go down\n\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n            -------------------------------------- min\n            -------------------------------------- max\n                                x                  me\n            ______________________________________\n        \"\"\"\n        if particle.location.depth < self.max_depth:\n            logger.debug(\"DIEL: %s - Moving UP to desired depth from %f\" % (self.logstring(), particle.location.depth))\n\n            # If we are going to overshoot the desired minimum depth,\n            # calculate a new w to land in the middle of the range.\n            overshoot_distance = abs(particle.location.depth - self.min_depth)\n            if overshoot_distance < abs(vertical_potential):\n                halfway_distance = abs((self.max_depth - self.min_depth) / 2)\n                w = ((overshoot_distance - halfway_distance) / modelTimestep)\n\n            return { 'u': u, 'v': v, 'w': w }\n\n        \"\"\" I'm above my desired min depth, so i need to go down\n\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n                                x                  me\n            -------------------------------------- min\n            -------------------------------------- max\n            ______________________________________\n        \"\"\"\n        if particle.location.depth > self.min_depth:\n            logger.debug(\"DIEL: %s - Moving DOWN to desired depth from %f\" % (self.logstring(), particle.location.depth))\n\n            # If we are going to overshoot the desired maximum depth,\n            # calculate a new w to land in the middle of the range.\n            overshoot_distance = abs(particle.location.depth - self.max_depth)\n            if overshoot_distance < abs(vertical_potential):\n                halfway_distance = abs((self.max_depth - self.min_depth) / 2)\n                w = ((overshoot_distance - halfway_distance) / modelTimestep)\n\n            return { 'u': u, 'v': v, 'w': -w }\n\n        \"\"\" I'm in my desired depth, so I'm just gonna chill here\n\n            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n            -------------------------------------- min\n                                x                  me\n            -------------------------------------- max\n            ______________________________________\n        \"\"\"\n        return { 'u': u, 'v': v, 'w': 0 }"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a relationship aggregate for the given relationship.", "response": "def make_relationship_aggregate(self, relationship):\n        \"\"\"\n        Returns a new relationship aggregate for the given relationship.\n\n        :param relationship: Instance of\n          :class:`everest.entities.relationship.DomainRelationship`.\n        \"\"\"\n        if not self._session.IS_MANAGING_BACKREFERENCES:\n            relationship.direction &= ~RELATIONSHIP_DIRECTIONS.REVERSE\n        return RelationshipAggregate(self, relationship)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the request body chunk from the ASGI API.", "response": "def get_request_body_chunk(self, content: bytes, closed: bool,\n                               more_content: bool) -> Dict[str, Any]:\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#request-body-chunk\n        '''\n        return {\n            'content': content,\n            'closed': closed,\n            'more_content': more_content\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_message(self, transport, http_version: str, method: bytes,\n                    url: bytes, headers: List[List[bytes]]) -> Dict[str, Any]:\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#request\n        '''\n        url_obj = parse_url(url)\n        if url_obj.schema is None:\n            if transport.get_extra_info('sslcontext'):\n                scheme = 'https'\n            else:\n                scheme = 'http'\n        else:\n            scheme = url_obj.schema.decode()\n        path = '' if url_obj.path is None else url_obj.path.decode('utf-8')\n        query = b'' if url_obj.query is None else url_obj.query\n        return {\n            'channel': 'http.request',\n            'reply_channel': None,\n            'http_version': http_version,\n            'method': method.decode(),\n            'scheme': scheme,\n            'path': path,\n            'query_string': query,\n            'root_path': '',\n            'headers': headers,\n            'body': b'',\n            'body_channel': None,\n            'client': transport.get_extra_info('peername'),\n            'server': transport.get_extra_info('sockname')\n        }", "response": "Get the message from the transport."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef snp_query(G, bim, Isnp):\r\n    bim_out = bim[Isnp].reset_index(drop=True)\r\n    G_out = G[bim_out.i.values]\r\n    bim_out.i = pd.Series(sp.arange(bim_out.shape[0]), index=bim_out.index)\r\n    return G_out, bim_out", "response": "r Query the genetic data for the most specific variant in a single genetic dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef standardize_snps(G):\r\n    mean = G.mean(0)\r\n    std = G.std(0)\r\n    return (G - mean) / std", "response": "r Standardize the n_snps array of a single object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nregistering the given entity as NEW.", "response": "def register_new(self, entity_class, entity):\n        \"\"\"\n        Registers the given entity for the given class as NEW.\n\n        :raises ValueError: If the given entity already holds state that was\n          created by another Unit Of Work.\n        \"\"\"\n        EntityState.manage(entity, self)\n        EntityState.get_state(entity).status = ENTITY_STATUS.NEW\n        self.__entity_set_map[entity_class].add(entity)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nregistering the given entity for the given class as CLEAN.", "response": "def register_clean(self, entity_class, entity):\n        \"\"\"\n        Registers the given entity for the given class as CLEAN.\n\n        :returns: Cloned entity.\n        \"\"\"\n        EntityState.manage(entity, self)\n        EntityState.get_state(entity).status = ENTITY_STATUS.CLEAN\n        self.__entity_set_map[entity_class].add(entity)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering the given entity as DELETED.", "response": "def register_deleted(self, entity_class, entity):\n        \"\"\"\n        Registers the given entity for the given class as DELETED.\n\n        :raises ValueError: If the given entity already holds state that was\n          created by another Unit Of Work.\n        \"\"\"\n        EntityState.manage(entity, self)\n        EntityState.get_state(entity).status = ENTITY_STATUS.DELETED\n        self.__entity_set_map[entity_class].add(entity)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given entity is marked with status NEW. Returns False if the given entity has no state information.", "response": "def is_marked_new(self, entity):\n        \"\"\"\n        Checks if the given entity is marked with status NEW. Returns `False`\n        if the entity has no state information.\n        \"\"\"\n        try:\n            result = EntityState.get_state(entity).status == ENTITY_STATUS.NEW\n        except ValueError:\n            result = False\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the given entity is marked with status DELETED. Returns False if the given entity has no state information.", "response": "def is_marked_deleted(self, entity):\n        \"\"\"\n        Checks if the given entity is marked with status DELETED. Returns\n        `False` if the entity has no state information.\n        \"\"\"\n        try:\n            result = EntityState.get_state(entity).status \\\n                                                    == ENTITY_STATUS.DELETED\n        except ValueError:\n            result = False\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mark_clean(self, entity):\n        state = EntityState.get_state(entity)\n        state.status = ENTITY_STATUS.CLEAN\n        state.is_persisted = True", "response": "Mark the given entity as CLEAN."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an iterator over all entity states held by this Unit Of Work.", "response": "def iterator(self):\n        \"\"\"\n        Returns an iterator over all entity states held by this Unit Of Work.\n        \"\"\"\n        # FIXME: There is no dependency tracking; objects are iterated in\n        #        random order.\n        for ent_cls in list(self.__entity_set_map.keys()):\n            for ent in self.__entity_set_map[ent_cls]:\n                yield EntityState.get_state(ent)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the state of all entities held by this Unit Of Work.", "response": "def reset(self):\n        \"\"\"\n        Releases all entities held by this Unit Of Work (i.e., removes state\n        information from all registered entities and clears the entity map).\n        \"\"\"\n        for ents in self.__entity_set_map.values():\n            for ent in ents:\n                EntityState.release(ent, self)\n        self.__entity_set_map.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a text field to parse for a value in the request", "response": "def add_field(self, name, default=None, required=False, error=None):\r\n        \"\"\" Add a text/non-file field to parse for a value in the request \"\"\"\r\n        if name is None:\r\n            return\r\n        self.field_arguments.append(dict(\r\n            name=name,\r\n            default=default,\r\n            required=required,\r\n            error=error))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a file field to parse on request", "response": "def add_file(self, name, required=False, error=None, extensions=None):\r\n        \"\"\" Add a file field to parse on request (uploads) \"\"\"\r\n        if name is None:\r\n            return\r\n        self.file_arguments.append(dict(\r\n            name=name,\r\n            required=required,\r\n            error=error,\r\n            extensions=extensions))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef file_save(self, name, filename=None, folder=\"\", keep_ext=True) -> bool:\r\n        if name in self.files:\r\n            file_object = self.files[name]\r\n            clean_filename = secure_filename(file_object.filename)\r\n            if filename is not None and keep_ext:\r\n                clean_filename = filename + \".%s\" % \\\r\n                    (clean_filename.rsplit('.', 1)[1].lower())\r\n            elif filename is not None and not keep_ext:\r\n                clean_filename = filename\r\n            file_object.save(os.path.join(\r\n                current_app.config['UPLOADS']['FOLDER'],\r\n                folder, clean_filename))\r\n        return None", "response": "Save a file in the given folder."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(self, fail_callback=None):\r\n        # get text fields\r\n        for field in self.field_arguments:\r\n            self.values[field['name']] = self.__get_value(field['name'])\r\n            if self.values[field['name']] is None and field['required']:\r\n                if fail_callback is not None:\r\n                    fail_callback()\r\n                self.__invalid_request(field['error'])\r\n        # get file fields\r\n        for file in self.file_arguments:\r\n            self.files[file['name']] = self.__get_file(file)\r\n            if self.files[file['name']] is None and file['required']:\r\n                if fail_callback is not None:\r\n                    fail_callback()\r\n                self.__invalid_request(file['error'])", "response": "Parse the fields and files for values and files."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __get_value(self, field_name):\r\n        value = request.values.get(field_name)\r\n        if value is None:\r\n            if self.json_form_data is None:\r\n                value = None\r\n            elif field_name in self.json_form_data:\r\n                value = self.json_form_data[field_name]\r\n        return value", "response": "Get the value of a field in the request Json."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the file and do a security check", "response": "def __get_file(self, file):\r\n        \"\"\" Get request file and do a security check \"\"\"\r\n        file_object = None\r\n        if file['name'] in request.files:\r\n            file_object = request.files[file['name']]\r\n            clean_filename = secure_filename(file_object.filename)\r\n            if clean_filename == '':\r\n                return file_object\r\n            if file_object and self.__allowed_extension(\r\n                    clean_filename, file['extensions']):\r\n                return file_object\r\n        elif file['name'] not in request.files and file['required']:\r\n            return file_object\r\n        return file_object"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if the file extension is allowed by the given list of extensions.", "response": "def __allowed_extension(self, filename, extensions):\r\n        \"\"\" Check allowed file extensions \"\"\"\r\n        allowed_extensions = current_app.config['UPLOADS']['EXTENSIONS']\r\n        if extensions is not None:\r\n            allowed_extensions = extensions\r\n        return '.' in filename and filename.rsplit('.', 1)[1].lower() in \\\r\n            allowed_extensions"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn unpacked Python struct array.", "response": "def get_field(self, offset, length, format):\n        \"\"\"Returns unpacked Python struct array.\n\n        Args:\n            offset (int): offset to byte array within structure\n            length (int): how many bytes to unpack\n            format (str): Python struct format string for unpacking\n\n        See Also:\n            https://docs.python.org/2/library/struct.html#format-characters\n        \"\"\"\n        return struct.unpack(format, self.data[offset:offset + length])[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a string from the data in the cache.", "response": "def get_string(self, offset, length):\n        \"\"\"Returns string (length bytes)\n\n        Args:\n            offset (int): sring offset in byte array\n            length (int): string length\n        \"\"\"\n        return struct.unpack(str(length) + \"s\", self.data[\n                                                offset:offset + length\n                                                ])[0]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export(self, filename, offset=0, length=None):\n        self.__validate_offset(filename=filename, offset=offset, length=length)\n\n        with open(filename, 'w') as f:\n            if length is None:\n                length = len(self.data) - offset\n\n            if offset > 0:\n                output = self.data[offset:length]\n            else:\n                output = self.data[:length]\n\n            f.write(output)", "response": "Exports the byte array to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a tempdir context for the cwd and remove it after.", "response": "def tmpdir():\n    \"\"\"\n    Create a tempdir context for the cwd and remove it after.\n    \"\"\"\n    target = None\n    try:\n        with _tmpdir_extant() as target:\n            yield target\n    finally:\n        if target is not None:\n            shutil.rmtree(target, ignore_errors=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(command, verbose=False):\n    def do_nothing(*args, **kwargs):\n        return None\n\n    v_print = print if verbose else do_nothing\n\n    p = subprocess.Popen(\n        command,\n        shell=True,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        universal_newlines=True,\n    )\n\n    v_print(\"run:\", command)\n\n    def log_and_yield(line):\n        if six.PY2:\n            # If not unicode, try to decode it first\n            if isinstance(line, str):\n                line = line.decode('utf8', 'replace')\n        v_print(line)\n        return line\n\n    output = ''.join(map(log_and_yield, p.stdout))\n    status_code = p.wait()\n\n    return CommandResult(command, output, status_code)", "response": "Run a shell command and return the output and status code."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_redis_url(url):\n    warnings.warn(\n        \"Use redis.StrictRedis.from_url instead\", DeprecationWarning,\n        stacklevel=2)\n    parsed = urllib.parse.urlsplit(url)\n    return {\n        'host': parsed.hostname,\n        'port': parsed.port,\n        'db': int(parsed.path.replace('/', '')),\n    }", "response": "Given a url like redis://localhost : 6379/0 return a dict with host port and db members."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef lock_file(f, block=False):\n    try:\n        flags = fcntl.LOCK_EX\n        if not block:\n            flags |= fcntl.LOCK_NB\n        fcntl.flock(f.fileno(), flags)\n    except IOError as e:\n        if e.errno in (errno.EACCES, errno.EAGAIN):\n            raise SystemExit(\"ERROR: %s is locked by another process.\" %\n                             f.name)\n        raise", "response": "If block=False (the default), die hard and fast if another process has\n    already grabbed the lock for this file.\n\n    If block=True, wait for the lock to be released, then continue."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch PATH for executable files with the given name.", "response": "def which(name, flags=os.X_OK):\n    \"\"\"\n    Search PATH for executable files with the given name.\n\n    Taken from Twisted.\n    \"\"\"\n    result = []\n    exts = filter(None, os.environ.get('PATHEXT', '').split(os.pathsep))\n    path = os.environ.get('PATH', None)\n    if path is None:\n        return []\n    for p in os.environ.get('PATH', '').split(os.pathsep):\n        p = os.path.join(p, name)\n        if os.access(p, flags):\n            result.append(p)\n        for e in exts:\n            pext = p + e\n            if os.access(pext, flags):\n                result.append(pext)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasking the current host what version of LXC it has. Returns it as a string.", "response": "def get_lxc_version():\n    \"\"\" Asks the current host what version of LXC it has.  Returns it as a\n    string. If LXC is not installed, raises subprocess.CalledProcessError\"\"\"\n\n    runner = functools.partial(\n        subprocess.check_output,\n        stderr=subprocess.STDOUT,\n        universal_newlines=True,\n    )\n\n    # Old LXC had an lxc-version executable, and prefixed its result with\n    # \"lxc version: \"\n    try:\n        result = runner(['lxc-version']).rstrip()\n        return parse_version(result.replace(\"lxc version: \", \"\"))\n    except (OSError, subprocess.CalledProcessError):\n        pass\n\n    # New LXC instead has a --version option on most installed executables.\n    return parse_version(runner(['lxc-start', '--version']).rstrip())"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_qpimage(self, idx=0):\n        if self._bgdata:\n            # The user has explicitly chosen different background data\n            # using `get_qpimage_raw`.\n            qpi = super(SingleHdf5Qpimage, self).get_qpimage()\n        else:\n            # We can use the background data stored in the qpimage hdf5 file\n            qpi = qpimage.QPImage(h5file=self.path,\n                                  h5mode=\"r\",\n                                  h5dtype=self.as_type,\n                                  ).copy()\n            # Force meta data\n            for key in self.meta_data:\n                qpi[key] = self.meta_data[key]\n            # set identifier\n            qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi", "response": "Return a copy of the QPImage object with the metadata and background data."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a copy of the QPImage with background correction", "response": "def get_qpimage_raw(self, idx=0):\n        \"\"\"Return QPImage without background correction\"\"\"\n        qpi = qpimage.QPImage(h5file=self.path,\n                              h5mode=\"r\",\n                              h5dtype=self.as_type,\n                              ).copy()\n        # Remove previously performed background correction\n        qpi.set_bg_data(None)\n        # Force meta data\n        for key in self.meta_data:\n            qpi[key] = self.meta_data[key]\n        # set identifier\n        qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef simulate(s0, transmat, steps=1):\n    # Single-Step simulation\n    if steps == 1:\n        return np.dot(s0, transmat)\n\n    # Multi-Step simulation\n    out = np.zeros(shape=(steps + 1, len(s0)), order='C')\n    out[0, :] = s0\n\n    for i in range(1, steps + 1):\n        out[i, :] = np.dot(out[i - 1, :], transmat)\n\n    return out", "response": "Simulate the next state of a new key - vector."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndepending on input data type the storage type is either field or phase.", "response": "def storage_type(self):\n        \"\"\"Depending on input data type, the storage type is either\n        \"field\" (complex) or \"phase\" (real).\"\"\"\n        nf = np.load(str(self.path), mmap_mode=\"c\", allow_pickle=False)\n        if np.iscomplexobj(nf):\n            st = \"field\"\n        else:\n            st = \"phase\"\n        return st"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning QPImage with background correction", "response": "def get_qpimage_raw(self, idx=0):\n        \"\"\"Return QPImage without background correction\"\"\"\n        # Load experimental data\n        nf = np.load(str(self.path), mmap_mode=\"c\", allow_pickle=False)\n        meta_data = copy.copy(self.meta_data)\n        qpi = qpimage.QPImage(data=nf,\n                              which_data=self.storage_type,\n                              meta_data=meta_data,\n                              h5dtype=self.as_type)\n        # get identifier\n        qpi[\"identifier\"] = self.get_identifier(idx)\n        return qpi"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef verify(path):\n        path = pathlib.Path(path)\n        valid = False\n        if path.suffix == \".npy\":\n            try:\n                nf = np.load(str(path), mmap_mode=\"r\", allow_pickle=False)\n            except (OSError, ValueError, IsADirectoryError):\n                pass\n            else:\n                if len(nf.shape) == 2:\n                    valid = True\n        return valid", "response": "Verify that path has a supported numpy file format"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the name of the file without its extension.", "response": "def _get_stem(self):\n        \"\"\" Return the name of the file without it's extension. \"\"\"\n        filename = os.path.basename(self.src_path)\n        stem, ext = os.path.splitext(filename)\n        return \"index\" if stem in (\"index\", \"README\", \"__init__\") else stem"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks that a given bit of data conforms to the type provided by the type provided by the user.", "response": "def type_check(thetype, data, bindings = None):\n    \"\"\" Checks that a given bit of data conforms to the type provided  \"\"\"\n    if not bindings: bindings = Bindings()\n    if isinstance(thetype, core.RecordType):\n        for name,child in zip(thetype.child_names, thetype.child_types):\n            value = data[name]\n            type_check(child, value, bindings)\n    elif isinstance(thetype, core.TupleType):\n        assert isinstance(data, tuple)\n        assert len(data) == len(thetype.child_types)\n        for value,child_type in zip(data, thetype.child_types):\n            type_check(child_type, value, bindings)\n    elif isinstance(thetype, core.UnionType):\n        assert isinstance(thetype, dict)\n        children = [(name,child) for name,child in zip(thetype.child_names, thetype.child_types) if name in data]\n        assert len(fields) == 1, \"0 or more than 1 entry in Union\"\n        child_name,child_type = children[0]\n        type_check(child_type, data[child_name], bindings)\n    elif isinstance(thetype, core.TypeApp):\n        # Type applications are tricky.  These will \"affect\" bindings\n        bindings.push()\n        for k,v in thetype.param_values.items():\n            bindings[k] = v\n        type_check(thetype.root_type, data, bindings)\n        bindings.pop()\n    elif isinstance(thetype, core.TypeVar):\n        # Find the binding for this type variable\n        bound_type = bindings[thetype.name]\n        if bound_type is None:\n            raise errors.ValidationError(\"TypeVar(%s) is not bound to a type.\" % thetype.name)\n        type_check(bound_type, data, bindings)\n    elif isinstance(thetype, core.NativeType):\n        # Native types are interesting - these can be plain types such as Int, Float etc\n        # or they can be generic types like Array<T>, Map<K,V>\n        # While plain types are fine, generic types (ie native types with args) pose a problem.\n        # How do we perform type checking on \"contents\" of the data given native types.\n        # We need native types to be able to apply mapper functions on data as they see fit.\n        # So to deal with custom validations on native types we need\n        # native types to expose mapper functors for us!!!\n        if thetype.args and thetype.mapper_functor:\n            def type_check_functor(*values):\n                for arg, value in zip(thetype.args, values):\n                    bound_type = bindings[arg]\n                    if bound_type is None:\n                        raise errors.ValidationError(\"Arg(%s) is not bound to a type.\" % arg)\n                    type_check(bound_type, value)\n            thetype.mapper_functor(type_check_functor, data)\n\n    # Finally apply any other validators that were nominated \n    # specifically for that particular type\n    if thetype.validator:\n        thetype.validator(thetype, data, bindings)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_templates(entry_point, py_entry_point, auto_write, output_dir):\n    '''Copy formatted templates from scrim/bin to output directory\n\n    Attributes:\n        entry_point: Name of shell script\n        py_entry_point: Name of python console script\n        auto_write: Sets SCRIM_AUTO_WRITE to True\n        output_dir: Guess\n    '''\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    scripts = []\n    for f in os.listdir(bin_path()):\n        ext = os.path.splitext(f)[-1]\n        newline = NEWLINE_MAP.get(ext, '\\n')\n        template = bin_path(f)\n        destination = output_dir + '/' + entry_point + ext\n        scripts.append(destination)\n\n        with io.open(template, 'r') as f:\n            code = f.read()\n        code = code.replace('{{entry_point}}', entry_point)\n        code = code.replace('{{py_entry_point}}', py_entry_point)\n        code = code.replace('{{auto_write}}', str(int(auto_write)))\n\n        with io.open(destination, 'w', newline=newline) as f:\n            f.write(code)\n\n    return scripts", "response": "Copy formatted templates from scrim bin to output directory"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_setup(filepath):\n    '''Get the kwargs from the setup function in setup.py'''\n    # TODO: Need to parse setup.cfg and merge with the data from below\n\n    # Monkey patch setuptools.setup to capture keyword arguments\n    setup_kwargs = {}\n\n    def setup_interceptor(**kwargs):\n        setup_kwargs.update(kwargs)\n\n    import setuptools\n    setuptools_setup = setuptools.setup\n    setuptools.setup = setup_interceptor\n\n    # Manually compile setup.py\n    with open(filepath, 'r') as f:\n        code = compile(f.read(), '', 'exec')\n    setup = ModuleType('setup')\n    exec(code, setup.__dict__)\n\n    # Remove monkey patch\n    setuptools.setup = setuptools_setup\n    return setup_kwargs", "response": "Get the kwargs from the setup. py file in setup. cfg"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_console_scripts(setup_data):\n    '''Parse and return a list of console_scripts from setup_data'''\n\n    # TODO: support ini format of entry_points\n    # TODO: support setup.cfg entry_points as available in pbr\n\n    if 'entry_points' not in setup_data:\n        return []\n\n    console_scripts = setup_data['entry_points'].get('console_scripts', [])\n    return [script.split('=')[0].strip() for script in console_scripts]", "response": "Parse and return a list of console_scripts from setup_data"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an instance of the named plugin and return it", "response": "def build_plugin(cls, class_name, config):\n        \"\"\"Create an instance of the named plugin and return it\n        :param class_name: fully qualified name of class \n        :type class_name: str\n        :param config: the supporting configuration for plugin \n        :type config: PluginConfig\n        :rtype: AbstractPlugin\n        :return: an instance of a concrete implementation of AbstractPlugin\n        \"\"\"\n        mod_path, class_name = class_name.rsplit('.', 1)\n        plugin_cls = getattr(importlib.import_module(mod_path), class_name)\n        return plugin_cls(config)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating an instance of the named plugin and return it", "response": "def build_plugins(cls, plugins_conf):\n        \"\"\"Create an instance of the named plugin and return it\n        :param plugins_conf: dict of {alias: dict(plugin builder params) } \n        :type plugins_conf: dict\n        :rtype: dict[str, AbstractPlugin]\n        :return: dict of alias: plugin instance\n        \"\"\"\n        plugins = {}\n        for alias, params_dict in plugins_conf.items():\n            plugin_config = PluginConfig(**(params_dict.get('config') or {}))\n            plugins[alias] = cls.build_plugin(class_name=params_dict['class_name'], config=plugin_config)\n        return plugins"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef install_programmer(programmer_id, programmer_options, replace_existing=False):\n    doaction = 0\n    if programmer_id in programmers().keys():\n        log.debug('programmer already exists: %s', programmer_id)\n        if replace_existing:\n            log.debug('remove programmer: %s', programmer_id)\n            remove_programmer(programmer_id)\n            doaction = 1\n    else:\n        doaction = 1\n\n    if doaction:\n        lines = bunch2properties(programmer_id, programmer_options)\n        programmers_txt().write_lines([''] + lines, append=1)", "response": "install programmer in programmers. txt."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse a filter - tag argument and returns a key value tuple", "response": "def filter_tag(arg):\n    \"\"\" Parses a --filter-tag argument \"\"\"\n    try:\n        strip_len = len('Key=')\n        key, value = arg[strip_len:].split(',Value=', 1)\n        return key, value\n    except:\n        msg = 'Invalid --filter-tag argument: {}'\n        raise argparse.ArgumentTypeError(msg.format(arg))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a file argument i. e. starts with file://", "response": "def file_arg(arg):\n    \"\"\"\n    Parses a file argument, i.e. starts with file://\n    \"\"\"\n    prefix = 'file://'\n\n    if arg.startswith(prefix):\n        return os.path.abspath(arg[len(prefix):])\n    else:\n        msg = 'Invalid file argument \"{}\", does not begin with \"file://\"'\n        raise argparse.ArgumentTypeError(msg.format(arg))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nschedule a job to run at the given time.", "response": "def schedule(self, job, when):\n        \"\"\" Schedule job to run at when nanoseconds since the UNIX epoch.\"\"\"\n        pjob = pickle.dumps(job)\n        self._redis.zadd('ss:scheduled', when, pjob)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef schedule_in(self, job, timedelta):\n        now = long(self._now() * 1e6)\n        when = now + timedelta.total_seconds() * 1e6\n        self.schedule(job, when)", "response": "Schedule a job to run at datetime. timedelta from now."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nschedules a job to run as soon as possible.", "response": "def schedule_now(self, job):\n        \"\"\" Schedule job to run as soon as possible.\"\"\"\n        now = long(self._now() * 1e6)\n        self.schedule(job, now)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the appropriate value for attribute aria - autocomplete of field.", "response": "def _get_aria_autocomplete(self, field):\n        \"\"\"\n        Returns the appropriate value for attribute aria-autocomplete of field.\n\n        :param field: The field.\n        :type field: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :return: The ARIA value of field.\n        :rtype: str\n        \"\"\"\n\n        tag_name = field.get_tag_name()\n        input_type = None\n        if field.has_attribute('type'):\n            input_type = field.get_attribute('type').lower()\n        if (\n            (tag_name == 'TEXTAREA')\n            or (\n                (tag_name == 'INPUT')\n                and (not (\n                    (input_type == 'button')\n                    or (input_type == 'submit')\n                    or (input_type == 'reset')\n                    or (input_type == 'image')\n                    or (input_type == 'file')\n                    or (input_type == 'checkbox')\n                    or (input_type == 'radio')\n                    or (input_type == 'hidden')\n                ))\n            )\n        ):\n            value = None\n            if field.has_attribute('autocomplete'):\n                value = field.get_attribute('autocomplete').lower()\n            else:\n                form = self.parser.find(field).find_ancestors(\n                    'form'\n                ).first_result()\n                if (form is None) and (field.has_attribute('form')):\n                    form = self.parser.find(\n                        '#' + field.get_attribute('form')\n                    ).first_result()\n                if (form is not None) and (form.has_attribute('autocomplete')):\n                    value = form.get_attribute('autocomplete').lower()\n            if value == 'on':\n                return 'both'\n            elif (\n                (field.has_attribute('list'))\n                and (self.parser.find(\n                    'datalist[id=\"' + field.get_attribute('list') + '\"]'\n                ).first_result() is not None)\n            ):\n                return 'list'\n            elif value == 'off':\n                return 'none'\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate the scripts used by solutions.", "response": "def _generate_validation_scripts(self):\n        \"\"\"\n        Include the scripts used by solutions.\n        \"\"\"\n\n        id_script_list_validation_fields = (\n            AccessibleFormImplementation.ID_SCRIPT_LIST_VALIDATION_FIELDS\n        )\n        local = self.parser.find('head,body').first_result()\n        if local is not None:\n            if (\n                self.parser.find(\n                    '#'\n                    + AccessibleEventImplementation.ID_SCRIPT_COMMON_FUNCTIONS\n                ).first_result() is None\n            ):\n                common_functions_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'common.js'\n                    ),\n                    'r'\n                )\n                common_functions_content = common_functions_file.read()\n                common_functions_file.close()\n\n                common_functions_script = self.parser.create_element('script')\n                common_functions_script.set_attribute(\n                    'id',\n                    AccessibleEventImplementation.ID_SCRIPT_COMMON_FUNCTIONS\n                )\n                common_functions_script.set_attribute(\n                    'type',\n                    'text/javascript'\n                )\n                common_functions_script.append_text(common_functions_content)\n                local.prepend_element(common_functions_script)\n\n            self.script_list_fields_with_validation = self.parser.find(\n                '#'\n                + id_script_list_validation_fields\n            ).first_result()\n            if self.script_list_fields_with_validation is None:\n                script_list_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'scriptlist_validation_fields.js'\n                    ),\n                    'r'\n                )\n                script_list_content = script_list_file.read()\n                script_list_file.close()\n\n                self.script_list_fields_with_validation = (\n                    self.parser.create_element('script')\n                )\n                self.script_list_fields_with_validation.set_attribute(\n                    'id',\n                    id_script_list_validation_fields\n                )\n                self.script_list_fields_with_validation.set_attribute(\n                    'type',\n                    'text/javascript'\n                )\n                self.script_list_fields_with_validation.append_text(\n                    script_list_content\n                )\n                local.append_element(self.script_list_fields_with_validation)\n            if (\n                self.parser.find(\n                    '#'\n                    + AccessibleFormImplementation.ID_SCRIPT_EXECUTE_VALIDATION\n                ).first_result() is None\n            ):\n                script_function_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'validation.js'\n                    ),\n                    'r'\n                )\n                script_function_content = script_function_file.read()\n                script_function_file.close()\n\n                script_function = self.parser.create_element('script')\n                script_function.set_attribute(\n                    'id',\n                    AccessibleFormImplementation.ID_SCRIPT_EXECUTE_VALIDATION\n                )\n                script_function.set_attribute('type', 'text/javascript')\n                script_function.append_text(script_function_content)\n                self.parser.find('body').first_result().append_element(\n                    script_function\n                )\n        self.scripts_added = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nvalidate the field when its value change.", "response": "def _validate(self, field, list_attribute):\n        \"\"\"\n        Validate the field when its value change.\n\n        :param field: The field.\n        :param list_attribute: The list attribute of field with validation.\n        \"\"\"\n\n        if not self.scripts_added:\n            self._generate_validation_scripts()\n        self.id_generator.generate_id(field)\n        self.script_list_fields_with_validation.append_text(\n            'hatemileValidationList.'\n            + list_attribute\n            + '.push(\"'\n            + field.get_attribute('id')\n            + '\");'\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove(item):\n    if os.path.isdir(item):\n        shutil.rmtree(item)\n    else:\n        # Assume it's a file. error if not.\n        os.remove(item)", "response": "Delete item whether it s a file a folder or a folder\n    full of other files and folders."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngive a directory and a pattern of files remove them.", "response": "def remove_pattern(root, pat, verbose=True):\n    \"\"\"\n    Given a directory, and a pattern of files like \"garbage.txt\" or\n    \"*pyc\" inside it, remove them.\n\n    Try not to delete the whole OS while you're at it.\n    \"\"\"\n    print(\"removing pattern\", root, pat)\n    combined = root + pat\n    print('combined', combined)\n    items = glob.glob(combined)\n    print('items', items)\n    for item in items:\n        print('item', item)\n        if is_inside(root, item):\n            remove(item)\n        elif verbose:\n            print(\"{item} is not inside {root}! Skipping.\".format(**vars()))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngive a root path read any. slugignore file inside and return a list of patterns that should be removed prior to slug compilation.", "response": "def get_slugignores(root, fname='.slugignore'):\n    \"\"\"\n    Given a root path, read any .slugignore file inside and return a list of\n    patterns that should be removed prior to slug compilation.\n\n    Return empty list if file does not exist.\n    \"\"\"\n    try:\n        with open(os.path.join(root, fname)) as f:\n            return [l.rstrip('\\n') for l in f]\n    except IOError:\n        return []"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a path remove any patterns that are not in the. slugignore list.", "response": "def clean_slug_dir(root):\n    \"\"\"\n    Given a path, delete anything specified in .slugignore.\n    \"\"\"\n    if not root.endswith('/'):\n        root += '/'\n    for pattern in get_slugignores(root):\n        print(\"pattern\", pattern)\n        remove_pattern(root, pattern)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses passed arguments from shell.", "response": "def _parse(args):\n    \"\"\"Parse passed arguments from shell.\"\"\"\n\n    ordered = []\n    opt_full = dict()\n    opt_abbrev = dict()\n\n    args = args + ['']  # Avoid out of range\n    i = 0\n\n    while i < len(args) - 1:\n        arg = args[i]\n        arg_next = args[i+1]\n        if arg.startswith('--'):\n            if arg_next.startswith('-'):\n                raise ValueError('{} lacks value'.format(arg))\n            else:\n                opt_full[arg[2:]] = arg_next\n                i += 2\n        elif arg.startswith('-'):\n            if arg_next.startswith('-'):\n                raise ValueError('{} lacks value'.format(arg))\n            else:\n                opt_abbrev[arg[1:]] = arg_next\n                i += 2\n        else:\n            ordered.append(arg)\n            i += 1\n    \n    return ordered, opt_full, opt_abbrev"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _construct_optional(params):\n\n    args = []\n    filtered = {key: arg.default for key, arg in params.items() if arg.default != inspect._empty}\n    for key, default in filtered.items():\n        arg = OptionalArg(full=key, abbrev=key[0].lower(), default=default)\n        args.append(arg)\n\n    args_full, args_abbrev = dict(), dict()\n\n    # Resolve conflicts\n    known_count = defaultdict(int)\n    for arg in args:\n        args_full[arg.full] = arg\n\n        if known_count[arg.abbrev] == 0:\n            args_abbrev[arg.abbrev] = arg\n        elif known_count[arg.abbrev] == 1:\n            new_abbrev = arg.abbrev.upper()\n            args_full[arg.full] = OptionalArg(full=arg.full, abbrev=new_abbrev, default=arg.default)\n            args_abbrev[new_abbrev] = args_full[arg.full]\n        else:\n            new_abbrev = arg.abbrev.upper() + str(known_count[arg.abbrev])\n            args_full[arg.full] = OptionalArg(full=arg.full, abbrev=new_abbrev, default=arg.default)\n            args_abbrev[new_abbrev] = args_full[arg.full]\n        known_count[arg.abbrev] += 1\n    return args_full, args_abbrev", "response": "Construct optional args key and abbreviated key from signature."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _keyboard_access(self, element):\n        # pylint: disable=no-self-use\n\n        if not element.has_attribute('tabindex'):\n            tag = element.get_tag_name()\n            if (tag == 'A') and (not element.has_attribute('href')):\n                element.set_attribute('tabindex', '0')\n            elif (\n                (tag != 'A')\n                and (tag != 'INPUT')\n                and (tag != 'BUTTON')\n                and (tag != 'SELECT')\n                and (tag != 'TEXTAREA')\n            ):\n                element.set_attribute('tabindex', '0')", "response": "Provides keyboard access for element if it not has."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates the main scripts for the current page.", "response": "def _generate_main_scripts(self):\n        \"\"\"\n        Include the scripts used by solutions.\n        \"\"\"\n\n        head = self.parser.find('head').first_result()\n        if head is not None:\n            common_functions_script = self.parser.find(\n                '#'\n                + AccessibleEventImplementation.ID_SCRIPT_COMMON_FUNCTIONS\n            ).first_result()\n            if common_functions_script is None:\n                common_functions_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'common.js'\n                    ),\n                    'r'\n                )\n                common_functions_content = common_functions_file.read()\n                common_functions_file.close()\n\n                common_functions_script = self.parser.create_element('script')\n                common_functions_script.set_attribute(\n                    'id',\n                    AccessibleEventImplementation.ID_SCRIPT_COMMON_FUNCTIONS\n                )\n                common_functions_script.set_attribute(\n                    'type',\n                    'text/javascript'\n                )\n                common_functions_script.append_text(common_functions_content)\n                head.prepend_element(common_functions_script)\n            if (\n                self.parser.find(\n                    '#'\n                    + AccessibleEventImplementation.ID_SCRIPT_EVENT_LISTENER\n                ).first_result() is None\n            ):\n                event_listener_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'eventlistener.js'\n                    ),\n                    'r'\n                )\n                event_listener_script_content = event_listener_file.read()\n                event_listener_file.close()\n\n                script = self.parser.create_element('script')\n                script.set_attribute(\n                    'id',\n                    AccessibleEventImplementation.ID_SCRIPT_EVENT_LISTENER\n                )\n                script.set_attribute('type', 'text/javascript')\n                script.append_text(event_listener_script_content)\n                common_functions_script.insert_after(script)\n        local = self.parser.find('body').first_result()\n        if local is not None:\n            self.script_list = self.parser.find(\n                '#'\n                + AccessibleEventImplementation.ID_LIST_IDS_SCRIPT\n            ).first_result()\n            if self.script_list is None:\n                self.script_list = self.parser.create_element('script')\n                self.script_list.set_attribute(\n                    'id',\n                    AccessibleEventImplementation.ID_LIST_IDS_SCRIPT\n                )\n                self.script_list.set_attribute('type', 'text/javascript')\n                self.script_list.append_text('var activeElements = [];')\n                self.script_list.append_text('var hoverElements = [];')\n                self.script_list.append_text('var dragElements = [];')\n                self.script_list.append_text('var dropElements = [];')\n                local.append_element(self.script_list)\n            if self.parser.find(\n                    '#'\n                    + AccessibleEventImplementation.ID_FUNCTION_SCRIPT_FIX\n            ).first_result() is None:\n                include_file = open(\n                    os.path.join(\n                        os.path.dirname(os.path.dirname(os.path.dirname(\n                            os.path.realpath(__file__)\n                        ))),\n                        'js',\n                        'include.js'\n                    ),\n                    'r'\n                )\n                local_include_script_content = include_file.read()\n                include_file.close()\n\n                script_function = self.parser.create_element('script')\n                script_function.set_attribute(\n                    'id',\n                    AccessibleEventImplementation.ID_FUNCTION_SCRIPT_FIX\n                )\n                script_function.set_attribute('type', 'text/javascript')\n                script_function.append_text(local_include_script_content)\n                local.append_element(script_function)\n        self.main_script_added = True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadd a type of event in element.", "response": "def _add_event_in_element(self, element, event):\n        \"\"\"\n        Add a type of event in element.\n\n        :param element: The element.\n        :type element: hatemile.util.html.htmldomelement.HTMLDOMElement\n        :param event: The type of event.\n        :type event: str\n        \"\"\"\n\n        if not self.main_script_added:\n            self._generate_main_scripts()\n\n        if self.script_list is not None:\n            self.id_generator.generate_id(element)\n            self.script_list.append_text(\n                event\n                + \"Elements.push('\"\n                + element.get_attribute('id')\n                + \"');\"\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tee(process, filter):\n    lines = []\n\n    while True:\n        line = process.stdout.readline()\n        if line:\n            if sys.version_info[0] >= 3:\n                line = decode(line)\n            stripped_line = line.rstrip()\n            if filter(stripped_line):\n                sys.stdout.write(line)\n            lines.append(stripped_line)\n        elif process.poll() is not None:\n            process.stdout.close()\n            break\n    return lines", "response": "Read lines from process. stdout and echo them to sys. stdout."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread lines from process. stderr and echo them to sys. stderr.", "response": "def tee2(process, filter):\n    \"\"\"Read lines from process.stderr and echo them to sys.stderr.\n\n    The 'filter' is a callable which is invoked for every line,\n    receiving the line as argument. If the filter returns True, the\n    line is echoed to sys.stderr.\n    \"\"\"\n    while True:\n        line = process.stderr.readline()\n        if line:\n            if sys.version_info[0] >= 3:\n                line = decode(line)\n            stripped_line = line.rstrip()\n            if filter(stripped_line):\n                sys.stderr.write(line)\n        elif process.returncode is not None:\n            process.stderr.close()\n            break"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns a command and returns a two - tuple of exit code and lines read.", "response": "def run(args, echo=True, echo2=True, shell=False, cwd=None, env=None):\n    \"\"\"Run 'args' and return a two-tuple of exit code and lines read.\n\n    If 'echo' is True, the stdout stream is echoed to sys.stdout.\n    If 'echo2' is True, the stderr stream is echoed to sys.stderr.\n\n    The 'echo' and 'echo2' arguments may be callables, in which\n    case they are used as tee filters.\n\n    If 'shell' is True, args are executed via the shell.\n    The 'cwd' argument causes the child process to be executed in cwd.\n    The 'env' argument allows to pass a dict replacing os.environ.\n    \"\"\"\n    if not callable(echo):\n        echo = On() if echo else Off()\n\n    if not callable(echo2):\n        echo2 = On() if echo2 else Off()\n\n    process = Popen(\n        args,\n        stdout=PIPE,\n        stderr=PIPE,\n        shell=shell,\n        cwd=cwd,\n        env=env\n    )\n\n    with background_thread(tee2, (process, echo2)):\n        lines = tee(process, echo)\n\n    return process.returncode, lines"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering the given representer class with this registry using the given MIME content type as the key.", "response": "def register_representer_class(self, representer_class):\n        \"\"\"\n        Registers the given representer class with this registry, using\n        its MIME content type as the key.\n        \"\"\"\n        if representer_class in self.__rpr_classes.values():\n            raise ValueError('The representer class \"%s\" has already been '\n                             'registered.' % representer_class)\n        self.__rpr_classes[representer_class.content_type] = representer_class\n        if issubclass(representer_class, MappingResourceRepresenter):\n            # Create and hold a mapping registry for the registered resource\n            # representer class.\n            mp_reg = representer_class.make_mapping_registry()\n            self.__mp_regs[representer_class.content_type] = mp_reg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nregister a representer factory for the given resource class and content type.", "response": "def register(self, resource_class, content_type, configuration=None):\n        \"\"\"\n        Registers a representer factory for the given combination of resource\n        class and content type.\n\n        :param configuration: representer configuration. A default instance\n          will be created if this is not given.\n        :type configuration:\n            :class:`everest.representers.config.RepresenterConfiguration`\n        \"\"\"\n        if not issubclass(resource_class, Resource):\n            raise ValueError('Representers can only be registered for '\n                             'resource classes (got: %s).' % resource_class)\n        if not content_type in self.__rpr_classes:\n            raise ValueError('No representer class has been registered for '\n                             'content type \"%s\".' % content_type)\n        # Register a factory resource -> representer for the given combination\n        # of resource class and content type.\n        rpr_cls = self.__rpr_classes[content_type]\n        self.__rpr_factories[(resource_class, content_type)] = \\\n                                            rpr_cls.create_from_resource_class\n        if issubclass(rpr_cls, MappingResourceRepresenter):\n            # Create or update an attribute mapping.\n            mp_reg = self.__mp_regs[content_type]\n            mp = mp_reg.find_mapping(resource_class)\n            if mp is None:\n                # No mapping was registered yet for this resource class or any\n                # of its base classes; create a new one on the fly.\n                new_mp = mp_reg.create_mapping(resource_class, configuration)\n            elif not configuration is None:\n                if resource_class is mp.mapped_class:\n                    # We have additional configuration for an existing mapping.\n                    mp.configuration.update(configuration)\n                    new_mp = mp\n                else:\n                    # We have a derived class with additional configuration.\n                    new_mp = mp_reg.create_mapping(\n                                            resource_class,\n                                            configuration=mp.configuration)\n                    new_mp.configuration.update(configuration)\n            elif not resource_class is mp.mapped_class:\n                # We have a derived class without additional configuration.\n                new_mp = mp_reg.create_mapping(resource_class,\n                                               configuration=mp.configuration)\n            else:\n                # We found a dynamically created mapping for the right class\n                # without additional configuration; do not create a new one.\n                new_mp = None\n            if not new_mp is None:\n                # Store the new (or updated) mapping.\n                mp_reg.set_mapping(new_mp)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, resource_class, content_type):\n        rpr_fac = self.__find_representer_factory(resource_class,\n                                                  content_type)\n        if rpr_fac is None:\n            # Register a representer with default configuration on the fly\n            # and look again.\n            self.register(resource_class, content_type)\n            rpr_fac = self.__find_representer_factory(resource_class,\n                                                      content_type)\n        return rpr_fac(resource_class)", "response": "Creates a representer for the given resource and content type."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_gpg_home(appname, config_dir=None):\n\n    assert is_valid_appname(appname)\n    config_dir = get_config_dir( config_dir )\n    path = os.path.join( config_dir, \"gpgkeys\", appname )\n\n    if not os.path.exists(path):\n        os.makedirs( path, 0700 )\n    else:\n        os.chmod( path, 0700 )\n\n    return path", "response": "Make GPG keyring dir for a particular application."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the GPG keyring directory for a particular application.", "response": "def get_gpg_home( appname, config_dir=None ):\n    \"\"\"\n    Get the GPG keyring directory for a particular application.\n    Return the path.\n    \"\"\"\n    assert is_valid_appname(appname)\n    config_dir = get_config_dir( config_dir )\n    path = os.path.join( config_dir, \"gpgkeys\", appname )\n    return path"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmake a temporary directory that holds GPG keys that are not going to be stored to the application s keyring.", "response": "def make_gpg_tmphome( prefix=None, config_dir=None ):\n    \"\"\"\n    Make a temporary directory to hold GPG keys that are not \n    going to be stored to the application's keyring.\n    \"\"\"\n    if prefix is None:\n        prefix = \"tmp\"\n\n    config_dir = get_config_dir( config_dir )\n    tmppath = os.path.join( config_dir, \"tmp\" )\n    if not os.path.exists( tmppath ):\n        os.makedirs( tmppath, 0700 )\n\n    tmpdir = tempfile.mkdtemp( prefix=(\"%s-\" % prefix), dir=tmppath )\n    return tmpdir"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstores a key locally into a blockchain ID", "response": "def gpg_stash_key( appname, key_bin, config_dir=None, gpghome=None ):\n    \"\"\"\n    Store a key locally to our app keyring.\n    Does NOT put it into a blockchain ID\n    Return the key ID on success\n    Return None on error\n    \"\"\"\n\n    assert is_valid_appname(appname)\n    key_bin = str(key_bin)\n    assert len(key_bin) > 0\n\n    if gpghome is None:\n        config_dir = get_config_dir( config_dir )\n        keydir = make_gpg_home( appname, config_dir=config_dir )\n    else:\n        keydir = gpghome\n\n    gpg = gnupg.GPG( homedir=keydir )\n    res = gpg.import_keys( key_bin )\n\n    try:\n        assert res.count == 1, \"Failed to store key (%s)\" % res\n    except AssertionError, e:\n        log.exception(e)\n        log.error(\"Failed to store key to %s\" % keydir)\n        log.debug(\"res: %s\" % res.__dict__)\n        log.debug(\"(%s)\\n%s\" % (len(key_bin), key_bin))\n        return None\n\n    return res.fingerprints[0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndownload a GPG key from a key server.", "response": "def gpg_download_key( key_id, key_server, config_dir=None ):\n    \"\"\"\n    Download a GPG key from a key server.\n    Do not import it into any keyrings.\n    Return the ASCII-armored key\n    \"\"\"\n\n    config_dir = get_config_dir( config_dir )\n    tmpdir = make_gpg_tmphome( prefix=\"download\", config_dir=config_dir )\n    gpg = gnupg.GPG( homedir=tmpdir )\n    recvdat = gpg.recv_keys( key_server, key_id )\n    fingerprint = None\n\n    try:\n        assert recvdat.count == 1\n        assert len(recvdat.fingerprints) == 1\n        fingerprint = recvdat.fingerprints[0]\n\n    except AssertionError, e:\n        log.exception(e)\n        log.error( \"Failed to fetch key '%s' from '%s'\" % (key_id, key_server))\n        shutil.rmtree( tmpdir )\n        return None\n\n    keydat = gpg.export_keys( [fingerprint] )\n    shutil.rmtree( tmpdir )\n    return str(keydat)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the key ID of a given serialized key", "response": "def gpg_key_fingerprint( key_data, config_dir=None ):\n    \"\"\"\n    Get the key ID of a given serialized key\n    Return the fingerprint on success\n    Return None on error\n    \"\"\"\n\n    key_data = str(key_data)\n\n    config_dir = get_config_dir( config_dir )\n    tmpdir = make_gpg_tmphome( prefix=\"key_id-\", config_dir=config_dir )\n    gpg = gnupg.GPG( homedir=tmpdir )\n    res = gpg.import_keys( key_data )\n\n    try:\n        assert res.count == 1, \"Failed to import key\"\n        assert len(res.fingerprints) == 1, \"Nonsensical GPG response: wrong number of fingerprints\"\n        fingerprint = res.fingerprints[0]\n        shutil.rmtree(tmpdir)\n        return fingerprint\n    except AssertionError, e:\n        log.exception(e)\n        shutil.rmtree(tmpdir)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef gpg_verify_key( key_id, key_data, config_dir=None ):\n\n    key_data = str(key_data)\n\n    config_dir = get_config_dir( config_dir )\n    sanitized_key_id = \"\".join( key_id.upper().split(\" \") )\n    \n    if len(sanitized_key_id) < 16:\n        log.debug(\"Fingerprint is too short to be secure\")\n        return False\n\n    fingerprint = gpg_key_fingerprint( key_data, config_dir=config_dir )\n    if fingerprint is None:\n        log.debug(\"Failed to fingerprint key\")\n        return False\n\n    if sanitized_key_id != fingerprint and not fingerprint.endswith( sanitized_key_id ):\n        log.debug(\"Imported key does not match the given ID\")\n        return False\n\n    else:\n        return True", "response": "Verify that a given serialized key is valid for the given key ID."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the ASCII - armored key given the ID", "response": "def gpg_export_key( appname, key_id, config_dir=None, include_private=False ):\n    \"\"\"\n    Get the ASCII-armored key, given the ID\n    \"\"\"\n\n    assert is_valid_appname(appname)\n    config_dir = get_config_dir( config_dir )\n    keydir = get_gpg_home( appname, config_dir=config_dir )\n    gpg = gnupg.GPG( homedir=keydir )\n    keydat = gpg.export_keys( [key_id], secret=include_private )\n\n    if not keydat:\n        log.debug(\"Failed to export key %s from '%s'\" % (key_id, keydir))\n\n    assert keydat\n    return keydat"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists all GPG keys in a user profile", "response": "def gpg_list_profile_keys( blockchain_id, proxy=None, wallet_keys=None, config_dir=None ):\n    \"\"\"\n    List all GPG keys in a user profile:\n    Return a list of {'identifier': key ID, 'contentUrl': URL to the key data} on success\n    Raise on error\n    Return {'error': ...} on failure\n    \"\"\"\n\n    config_dir = get_config_dir( config_dir )\n    client_config_path = os.path.join(config_dir, blockstack_client.CONFIG_FILENAME )\n\n    if proxy is None:\n        proxy = blockstack_client.get_default_proxy( config_path=client_config_path )\n\n    accounts = blockstack_client.list_accounts( blockchain_id, proxy=proxy )\n    if 'error' in accounts:\n        return accounts\n\n    accounts = accounts.pop('accounts')\n\n    # extract\n    ret = []\n    for account in accounts:\n        if account['service'] != 'pgp':\n            continue \n\n        info = {\n            \"identifier\": account['identifier'],\n            \"contentUrl\": account['contentUrl']\n        }\n\n        if 'keyName' in account.keys():\n            info['keyName'] = account['keyName']\n\n        ret.append(info)\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef gpg_list_app_keys( blockchain_id, appname, proxy=None, wallet_keys=None, config_dir=None ):\n\n    raise Exception(\"BROKEN; depends on list_mutable_data\")\n\n    assert is_valid_appname(appname)\n\n    config_dir = get_config_dir( config_dir )\n    client_config_path = os.path.join(config_dir, blockstack_client.CONFIG_FILENAME )\n\n    if proxy is None:\n        proxy = blockstack_client.get_default_proxy( config_path=client_config_path )\n\n    key_info = []\n    key_prefix = \"gpg.%s.\" % appname\n\n    # immutable data key listing (look for keys that start with 'appname:')\n    immutable_listing = list_immutable_data( blockchain_id, proxy=proxy )\n    if 'error' in immutable_listing:\n        raise Exception(\"Blockstack error: %s\" % immutable_listing['error'])\n\n    for immutable in immutable_listing['data']:\n        name = immutable['data_id']\n        data_hash = immutable['hash']\n        if name.startswith( key_prefix ):\n            key_info.append( {\n                'keyName': name[len(key_prefix):],\n                'contentUrl': make_immutable_data_url( blockchain_id, name, data_hash )\n            })\n\n    # mutable data key listing (look for keys that start with 'appname:')\n    # TODO: use 'accounts'\n    mutable_listing = list_mutable_data( blockchain_id, proxy=proxy, wallet_keys=wallet_keys )\n    if 'error' in mutable_listing:\n        raise Exception(\"Blockstack error: %s\" % mutable_listing['error'])\n\n    for mutable in mutable_listing['data']:\n        name = mutable['data_id']\n        version = mutable['version']\n        if name.startswith( key_prefix ):\n            key_info.append( {\n                'keyName': name[len(key_prefix):],\n                'contentUrl': make_mutable_data_url( blockchain_id, name, version )\n            })\n\n    return key_info", "response": "List the set of available GPG keys tagged for a given application."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gpg_fetch_key( key_url, key_id=None, config_dir=None ):\n\n    dat = None\n    from_blockstack = False\n\n    # make sure it's valid \n    try:\n        urlparse.urlparse(key_url)\n    except:\n        log.error(\"Invalid URL\")\n        return None\n\n    if \"://\" in key_url and not key_url.lower().startswith(\"iks://\"):\n\n        opener = None \n        key_data = None\n\n        # handle blockstack:// URLs\n        if key_url.startswith(\"blockstack://\"):\n            blockstack_opener = BlockstackHandler( config_path=os.path.join(config_dir, blockstack_client.CONFIG_FILENAME) )\n            opener = urllib2.build_opener( blockstack_opener )\n            from_blockstack = True\n\n        elif key_url.lower().startswith(\"http://\") or key_url.lower().startswith(\"https://\"):\n            # fetch, but at least try not to look like a bot\n            opener = urllib2.build_opener()\n            opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n\n        else:\n            # defaults\n            opener = urllib2.build_opener()\n\n        try:\n            f = opener.open( key_url )\n            key_data_str = f.read()\n            key_data = None\n\n            if from_blockstack:\n                # expect: {'key name': 'PEM string'}\n                key_data_dict = json.loads(key_data_str)\n                assert len(key_data_dict) == 1, \"Got multiple keys\"\n                key_data = str(key_data_dict[key_data_dict.keys()[0]])\n\n            else:\n                # expect: PEM string\n                key_data = key_data_str\n\n            f.close()\n\n        except Exception, e:\n            log.exception(e)\n            if key_id is not None:\n                log.error(\"Failed to fetch key '%s' from '%s'\" % (key_id, key_url))\n            else:\n                log.error(\"Failed to fetch key from '%s'\" % key_url)\n            return None\n\n        # verify, if we have the ID.\n        # if we don't have the key ID, then we must be fetching from blockstack \n        # (since then the data will have already been verified by the protocol, using locally-hosted trusted information)\n        if not from_blockstack and key_id is None:\n            log.error( \"No key ID given for key located at %s\" % key_url )\n            return None\n\n        if key_id is not None:\n            rc = gpg_verify_key( key_id, key_data, config_dir=config_dir )\n            if not rc:\n                log.error(\"Failed to verify key %s\" % key_id)\n                return None\n\n        dat = key_data \n\n    else:\n        # iks protocol, fetch from keyserver\n        key_server = key_url\n        if '://' in key_server:\n            key_server = urlparse.urlparse(key_server).netloc\n\n        dat = gpg_download_key( key_id, key_server, config_dir=config_dir )\n        assert dat is not None and len(dat) > 0, \"BUG: no key data received for '%s' from '%s'\" % (key_id, key_url)\n\n    return dat", "response": "Fetch a GPG public key from a given URL."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gpg_profile_put_key( blockchain_id, key_id, key_name=None, immutable=True, txid=None, key_url=None, use_key_server=True, key_server=None, proxy=None, wallet_keys=None, gpghome=None ):\n\n    if key_name is not None:\n        assert is_valid_keyname(key_name)\n\n    if key_server is None:\n        key_server = DEFAULT_KEY_SERVER \n\n    if gpghome is None:\n        gpghome = get_default_gpg_home()\n\n    put_res = {}\n    extra_fields = {}\n    key_data = None\n    if key_name is not None:\n        extra_fields = {'keyName': key_name}\n\n    if key_url is None:\n\n        gpg = gnupg.GPG( homedir=gpghome )\n\n        if use_key_server:\n            # replicate key data to default server first \n            res = gpg.send_keys( key_server, key_id )\n            if len(res.data) > 0:\n                # error \n                log.error(\"GPG failed to upload key '%s'\" % key_id)\n                log.error(\"GPG error:\\n%s\" % res.stderr)\n                return {'error': 'Failed to repliate GPG key to default keyserver'}\n\n        key_data = gpg.export_keys( [key_id] )\n\n        if immutable:\n            # replicate to immutable storage \n            immutable_result = client.put_immutable( blockchain_id, key_id, {key_id: key_data}, proxy=proxy, txid=txid, wallet_keys=wallet_keys )\n            if 'error' in immutable_result:\n                return {'error': 'Failed to store hash of key %s to the blockchain.  Error message: \"%s\"' % (key_id, immutable_result['error'])}\n\n            else:\n                put_res['transaction_hash'] = immutable_result['transaction_hash']\n                put_res['zonefile_hash'] = immutable_result['zonefile_hash']\n\n            key_url = client.make_immutable_data_url( blockchain_id, key_id, client.get_data_hash(key_data) )\n\n        else:\n            # replicate to mutable storage \n            mutable_name = key_name\n            if key_name is None:\n                mutable_name = key_id\n\n            mutable_result = client.put_mutable( blockchain_id, key_id, {mutable_name: key_data}, proxy=proxy, wallet_keys=wallet_keys )\n            if 'error' in mutable_result:\n                return {'error': 'Failed to store key %s.  Error message: \"%s\"' % (key_id, mutable_result['error'])}\n\n            key_url = client.make_mutable_data_url( blockchain_id, key_id, mutable_result['version'] ) \n\n    put_account_res = client.put_account( blockchain_id, \"pgp\", key_id, key_url, proxy=proxy, wallet_keys=wallet_keys, **extra_fields )\n    if 'error' in put_account_res:\n        return put_account_res\n\n    else:\n        put_account_res.update( put_res )\n        put_account_res['key_url'] = key_url\n        put_account_res['key_id'] = key_id\n        return put_account_res", "response": "This function uploads a local GPG key into a blockchain ID s global account."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a GPG key from a blockchain ID s global keyring.", "response": "def gpg_profile_delete_key( blockchain_id, key_id, proxy=None, wallet_keys=None ):\n    \"\"\"\n    Remove a GPG from a blockchain ID's global account.\n    Do NOT remove it from the local keyring.\n    Return {'status': True, ...} on success.  May include 'delete_errors' if any specific keys couldn't be removed.\n    Return {'error': ...} on error\n    \"\"\"\n\n    res = client.delete_account( blockchain_id, \"pgp\", key_id, proxy=proxy, wallet_keys=wallet_keys )\n    if 'error' in res:\n        return res \n\n    removed_accounts = res['removed']\n    errors = []\n    \n    # blow away all state \n    for account in removed_accounts:\n        if not account.has_key('contentUrl'):\n            continue \n\n        key_url = account['contentUrl']\n        if key_url.startswith(\"blockstack://\"):\n            # delete\n            try:\n                res = client.data_delete( key_url, proxy=proxy, wallet_keys=wallet_keys )\n                if 'error' in res:\n                    errors.append({'key_url': key_url, 'message': res['error']})\n            except AssertionError, e:\n                log.exception(e)\n                log.error(\"Failed to delete '%s'\" % key_url)\n                raise\n\n            except Exception, e:\n                log.exception(e)\n                log.error(\"Failed to delete '%s'\" % key_url)\n                continue\n\n    ret = {'status': True}\n    if len(errors) > 0:\n        ret['delete_errors'] = errors\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new GPG key and store it in the global keyring", "response": "def gpg_profile_create_key( blockchain_id, keyname, immutable=True, proxy=None, wallet_keys=None, config_dir=None, gpghome=None, use_key_server=True, key_server=None ):\n    \"\"\"\n    Create a new account key.\n    Select good default GPG values (4096-bit, RSA/RSA)\n    Note that without rngd running, this may take a while.\n    Add the new key to the user's account.\n\n    Return {'status': True, 'key_url': ..., 'key_id': ..., } on success\n    Return {'error': ...} on error\n    \"\"\"\n\n    assert is_valid_keyname(keyname)\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    if gpghome is None:\n        gpghome = get_default_gpg_home()\n\n    keydir = make_gpg_tmphome( \"create-account-\", config_dir=config_dir )\n    gpg = gnupg.GPG( homedir=keydir )\n\n    log.debug(\"Generating GPG key (this may take a while)\")\n\n    key_input = gpg.gen_key_input( key_type=\"RSA\", name_email=blockchain_id, key_length=4096, name_real=keyname )\n    key_res = gpg.gen_key( key_input )\n    assert key_res\n\n    key_id = key_res.fingerprint\n    key_data = gpg.export_keys( [key_id] )\n    assert key_data\n\n    # save the key itself, to the global keyring\n    rc = gpg_stash_key( keyname, key_data, gpghome=gpghome ) \n    assert rc, \"Failed to store key '%s' (%s)\" % (keyname, key_id)\n    \n    shutil.rmtree(keydir)\n\n    # propagate to blockstack\n    add_res = gpg_profile_put_key( blockchain_id, key_id, immutable=immutable, use_key_server=use_key_server, key_server=key_server, key_name=keyname, proxy=proxy, wallet_keys=wallet_keys, gpghome=gpghome )\n    return add_res"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the key from a profile", "response": "def gpg_profile_get_key( blockchain_id, keyname, key_id=None, proxy=None, wallet_keys=None, config_dir=None, gpghome=None ):\n    \"\"\"\n    Get the profile key\n    Return {'status': True, 'key_data': ..., 'key_id': ...} on success\n    Return {'error': ...} on error\n    \"\"\"\n    \n    assert is_valid_keyname( keyname )\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    if gpghome is None:\n        gpghome = get_default_gpg_home()\n\n    accounts = blockstack_client.list_accounts( blockchain_id, proxy=proxy )\n    if 'error' in accounts:\n        return accounts\n\n    accounts = accounts.pop('accounts')\n\n    if len(accounts) == 0:\n        return {'error': 'No accounts in this profile'}\n\n    all_gpg_accounts = filter( lambda a: a['service'] == 'pgp', accounts )\n    if len(all_gpg_accounts) == 0:\n        return {'error': 'No GPG accounts in this profile'}\n    \n    # find the one with this key name \n    gpg_accounts = filter( lambda ga: (ga.has_key('keyName') and ga['keyName'] == keyname) or (key_id is not None and ga['identifier'] == key_id), all_gpg_accounts )\n    if len(gpg_accounts) == 0:\n        return {'error': 'No such GPG key found'}\n\n    if len(gpg_accounts) > 1:\n        return {'error': 'Multiple keys with that name'}\n\n    key_url = gpg_accounts[0].get('contentUrl', DEFAULT_KEY_SERVER)\n\n    # go get the key \n    key_data = gpg_fetch_key( key_url, key_id=gpg_accounts[0]['identifier'], config_dir=config_dir )\n    if key_data is None:\n        return {'error': 'Failed to download and verify key'}\n\n    ret = {\n        'status': True,\n        'key_id': gpg_accounts[0]['identifier'],\n        'key_data': key_data\n    }\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstores a private key locally to an application - specific keyring.", "response": "def gpg_app_put_key( blockchain_id, appname, keyname, key_data, txid=None, immutable=False, proxy=None, wallet_keys=None, config_dir=None ):\n    \"\"\"\n    Put an application GPG key.\n    Stash the private key locally to an app-specific keyring.\n\n    Return {'status': True, 'key_url': ..., 'key_data': ...} on success\n    Return {'error': ...} on error\n    \n    If immutable is True, then store the data as an immutable entry (e.g. update the zonefile with the key hash)\n    This is a time-consuming operation (on the order of an hour), and you will get back the transaction ID\n    on a successful execution.  It is up to you to wait until the transaction is confirmed before using the key.\n\n    Otherwise, the key is stored to mutable storage.\n    \"\"\"\n\n    assert is_valid_appname(appname)\n    assert is_valid_keyname(keyname)\n\n    try:\n        keydir = make_gpg_home( appname, config_dir=config_dir )\n        key_id = gpg_stash_key( appname, key_data, config_dir=config_dir, gpghome=keydir )\n        assert key_id is not None, \"Failed to stash key\"\n        log.debug(\"Stashed app key '%s:%s' (%s) under '%s'\" % (appname, keyname, key_id, keydir))\n    except Exception, e:\n        log.exception(e)\n        log.error(\"Failed to store GPG key '%s'\" % keyname)\n        return {'error': \"Failed to store GPG key locally\"}\n\n    # get public key... \n    assert is_valid_appname(appname)\n    try:\n        pubkey_data = gpg_export_key( appname, key_id, config_dir=config_dir ) \n    except:\n        return {'error': 'Failed to load key'}\n\n    fq_key_name = \"gpg.%s.%s\" % (appname, keyname)\n    key_url = None\n\n    if not immutable:\n        res = client.put_mutable( blockchain_id, fq_key_name, {fq_key_name: pubkey_data}, txid=txid, proxy=proxy, wallet_keys=wallet_keys )\n        if 'error' in res:\n            return res\n\n        key_url = client.make_mutable_data_url( blockchain_id, fq_key_name, res['version'] )\n    \n    else:\n        res = client.put_immutable( blockchain_id, fq_key_name, {fq_key_name: pubkey_data}, txid=txid, proxy=proxy, wallet_keys=wallet_keys )\n        if 'error' in res:\n            return res \n\n        key_url = client.make_immutable_data_url( blockchain_id, fq_key_name, res['immutable_data_hash'] )\n\n    res['key_url'] = key_url\n    res['key_data'] = pubkey_data\n    res['key_id'] = gpg_key_fingerprint( pubkey_data, config_dir=config_dir )\n    log.debug(\"Put key %s:%s (%s) to %s\" % (appname, keyname, res['key_id'], key_url))\n    return res"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gpg_app_delete_key( blockchain_id, appname, keyname, txid=None, immutable=False, proxy=None, wallet_keys=None, config_dir=None ):\n    \n    assert is_valid_appname(appname)\n    assert is_valid_keyname(keyname)\n\n    fq_key_name = \"gpg.%s.%s\" % (appname, keyname)\n    result = {}\n    dead_pubkey_dict = None\n    dead_pubkey = None\n    key_id = None\n\n    if not immutable:\n        # find the key first, so we can get the key ID and then remove it locally \n        dead_pubkey_dict = client.get_mutable( blockchain_id, fq_key_name, proxy=proxy, wallet_keys=wallet_keys )\n        if 'error' in dead_pubkey_dict:\n            return dead_pubkey_dict\n\n    else:\n       # need the key ID so we can unstash locally\n        dead_pubkey_dict = client.get_immutable( blockchain_id, None, data_id=fq_key_name, proxy=proxy )\n        if 'error' in dead_pubkey_dict:\n            return dead_pubkey_dict\n    \n    dead_pubkey_kv = dead_pubkey_dict['data']\n    assert len(dead_pubkey_kv.keys()) == 1, \"Not a public key we wrote: %s\" % dead_pubkey_kv\n\n    dead_pubkey = dead_pubkey_kv[ dead_pubkey_kv.keys()[0] ]\n    key_id = gpg_key_fingerprint( dead_pubkey, config_dir=config_dir )\n    assert key_id is not None, \"Failed to load pubkey fingerprint\"\n    \n    # actually delete \n    if not immutable:\n        result = client.delete_mutable( blockchain_id, fq_key_name, proxy=proxy, wallet_keys=wallet_keys )\n\n    else:\n        result = client.delete_immutable( blockchain_id, None, data_id=fq_key_name, wallet_keys=wallet_keys, proxy=proxy )\n        \n    if 'error' in result:\n        return result\n\n    # unstash\n    try:\n        rc = gpg_unstash_key( appname, key_id, config_dir=config_dir )\n        assert rc, \"Failed to unstash key\"\n    except:\n        log.warning(\"Failed to remove private key for '%s'\" % key_id )\n        result['warning'] = \"Failed to remove private key\"\n        if os.environ.get('BLOCKSTACK_TEST') is not None:\n            # make sure this never happens in testing\n            raise\n\n    return result", "response": "This function deletes an application GPG key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gpg_app_create_key( blockchain_id, appname, keyname, txid=None, immutable=False, proxy=None, wallet_keys=None, config_dir=None ):\n\n    assert is_valid_appname(appname)\n    assert is_valid_keyname(keyname)\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    client_config_path = os.path.join(config_dir, blockstack_client.CONFIG_FILENAME)\n    if proxy is None:\n        proxy = blockstack_client.get_default_proxy(config_path=client_config_path)\n\n    keydir = make_gpg_tmphome( \"create-app-\", config_dir=config_dir )\n    gpg = gnupg.GPG( homedir=keydir )\n\n    log.debug(\"Generating GPG key (this may take a while)\")\n\n    key_input = gpg.gen_key_input( key_type=\"RSA\", name_email=blockchain_id + \"/\" + appname, key_length=4096, name_real=keyname )\n    key_res = gpg.gen_key( key_input )\n    key_id = key_res.fingerprint\n    key_data = gpg.export_keys( [key_id], secret=True )\n\n    shutil.rmtree(keydir)\n\n    # propagate to blockstack\n    add_res = gpg_app_put_key( blockchain_id, appname, keyname, key_data, txid=txid, immutable=immutable, proxy=proxy, wallet_keys=wallet_keys, config_dir=config_dir )\n    return add_res", "response": "Create a new application GPG key."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gpg_app_get_key( blockchain_id, appname, keyname, immutable=False, key_id=None, key_hash=None, key_version=None, proxy=None, config_dir=None ):\n\n    assert is_valid_appname(appname)\n    assert is_valid_keyname(keyname)\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    fq_key_name = \"gpg.%s.%s\" % (appname, keyname)\n    key_url = None \n\n    if immutable:\n        # try immutable\n        key_url = blockstack_client.make_immutable_data_url( blockchain_id, fq_key_name, key_hash )\n\n    else:\n        # try mutable \n        key_url = blockstack_client.make_mutable_data_url( blockchain_id, fq_key_name, key_version )\n\n    log.debug(\"fetch '%s'\" % key_url)\n    key_data = gpg_fetch_key( key_url, key_id, config_dir=config_dir )\n    if key_data is None:\n        return {'error': 'Failed to fetch key'}\n\n    if key_id is None:\n        key_id = gpg_key_fingerprint( key_data, config_dir=config_dir )\n\n    ret = {\n        'status': True,\n        'key_id': key_id,\n        'key_data': key_data,\n        'app_name': appname\n    }\n\n    return ret", "response": "Get an app - specific GPG key."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsigns a file on disk.", "response": "def gpg_sign( path_to_sign, sender_key_info, config_dir=None, passphrase=None ):\n    \"\"\"\n    Sign a file on disk.\n    @sender_key_info should be a dict with\n    {\n        'key_id': ...\n        'key_data': ...\n        'app_name': ...\n    }\n    Return {'status': True, 'sig': ...} on success\n    Return {'error': ...} on error\n    \"\"\"\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    # ingest keys \n    tmpdir = make_gpg_tmphome( prefix=\"sign\", config_dir=config_dir )\n\n    try:\n        sender_privkey = gpg_export_key( sender_key_info['app_name'], sender_key_info['key_id'], include_private=True, config_dir=config_dir )\n    except Exception, e:\n        log.exception(e)\n        shutil.rmtree(tmpdir)\n        return {'error': 'No such private key'}\n\n    res = gpg_stash_key( \"sign\", sender_privkey, config_dir=config_dir, gpghome=tmpdir )\n    if res is None:\n        shutil.rmtree(tmpdir)\n        return {'error': 'Failed to load sender private key'}\n\n    # do the signature\n    gpg = gnupg.GPG( homedir=tmpdir )\n    res = None\n\n    with open(path_to_sign, \"r\") as fd_in:\n        res = gpg.sign_file( fd_in, keyid=sender_key_info['key_id'], passphrase=passphrase, detach=True )\n\n    shutil.rmtree(tmpdir)\n\n    if not res:\n        log.debug(\"sign_file error: %s\" % res.__dict__)\n        log.debug(\"signer: %s\" % sender_key_info['key_id'])\n        return {'error': 'Failed to sign data'}\n    \n    return {'status': True, 'sig': res.data }"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef gpg_verify( path_to_verify, sigdata, sender_key_info, config_dir=None ):\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    # ingest keys \n    tmpdir = make_gpg_tmphome( prefix=\"verify\", config_dir=config_dir )\n    res = gpg_stash_key( \"verify\", sender_key_info['key_data'], config_dir=config_dir, gpghome=tmpdir )\n    if res is None:\n        shutil.rmtree(tmpdir)\n        return {'error': 'Failed to stash key %s' % sender_key_info['key_id']}\n\n    # stash detached signature \n    fd, path = tempfile.mkstemp( prefix=\".sig-verify-\" )\n    f = os.fdopen(fd, \"w\")\n    f.write( sigdata )\n    f.flush()\n    os.fsync(f.fileno())\n    f.close()\n\n    # verify \n    gpg = gnupg.GPG( homedir=tmpdir )\n\n    with open(path, \"r\") as fd_in:\n        res = gpg.verify_file( fd_in, data_filename=path_to_verify )\n\n    shutil.rmtree(tmpdir)\n    try:\n        os.unlink(path)\n    except:\n        pass\n\n    if not res:\n        log.debug(\"verify_file error: %s\" % res.__dict__)\n        return {'error': 'Failed to decrypt data'}\n\n    log.debug(\"verification succeeded from keys in %s\" % config_dir)\n    return {'status': True}", "response": "Verify a file on disk."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef gpg_encrypt( fd_in, path_out, sender_key_info, recipient_key_infos, passphrase=None, config_dir=None ):\n\n    if config_dir is None:\n        config_dir = get_config_dir()\n\n    # ingest keys \n    tmpdir = make_gpg_tmphome( prefix=\"encrypt\", config_dir=config_dir )\n    for key_info in recipient_key_infos:\n        res = gpg_stash_key( \"encrypt\", key_info['key_data'], config_dir=config_dir, gpghome=tmpdir )\n        if res is None:\n            shutil.rmtree(tmpdir)\n            return {'error': 'Failed to stash key %s' % key_info['key_id']}\n\n    # copy over our key\n    try:\n        sender_privkey = gpg_export_key( sender_key_info['app_name'], sender_key_info['key_id'], include_private=True, config_dir=config_dir )\n    except Exception, e:\n        log.exception(e)\n        shutil.rmtree(tmpdir)\n        return {'error': 'No such private key'}\n\n    res = gpg_stash_key( \"encrypt\", sender_privkey, config_dir=config_dir, gpghome=tmpdir )\n    if res is None:\n        shutil.rmtree(tmpdir)\n        return {'error': 'Failed to load sender private key'}\n\n    recipient_key_ids = [r['key_id'] for r in recipient_key_infos]\n\n    # do the encryption\n    gpg = gnupg.GPG( homedir=tmpdir )\n    res = gpg.encrypt_file( fd_in, recipient_key_ids, sign=sender_key_info['key_id'], passphrase=passphrase, output=path_out, always_trust=True )\n    shutil.rmtree(tmpdir)\n\n    if res.status != 'encryption ok':\n        log.debug(\"encrypt_file error: %s\" % res.__dict__)\n        log.debug(\"recipients: %s\" % recipient_key_ids)\n        log.debug(\"signer: %s\" % sender_key_info['key_id'])\n        return {'error': 'Failed to encrypt data'}\n    \n    return {'status': True}", "response": "Encrypt a file - like object with a set of keys."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_primary_command_usage(message=''):\n    # type: (str) -> str\n    \"\"\"Return the usage string for the primary command.\"\"\"\n    if not settings.merge_primary_command and None in settings.subcommands:\n        return format_usage(settings.subcommands[None].__doc__)\n    if not message:\n        message = '\\n{}\\n'.format(settings.message) if settings.message else ''\n    doc = _DEFAULT_DOC.format(message=message)\n    if None in settings.subcommands:\n        return _merge_doc(doc, settings.subcommands[None].__doc__)\n    return format_usage(doc)", "response": "Return the usage string for the primary command."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints out a help message and exit the program.", "response": "def get_help_usage(command):\n    # type: (str) -> None\n    \"\"\"Print out a help message and exit the program.\n\n    Args:\n        command: If a command value is supplied then print the help message for\n            the command module if available. If the command is '-a' or '--all',\n            then print the standard help message but with a full list of\n            available commands.\n\n    Raises:\n        ValueError: Raised if the help message is requested for an invalid\n            command or an unrecognized option is passed to help.\n    \"\"\"\n    if not command:\n        doc = get_primary_command_usage()\n    elif command in ('-a', '--all'):\n        subcommands = [k for k in settings.subcommands if k is not None]\n        available_commands = subcommands + ['help']\n        command_doc = '\\nAvailable commands:\\n{}\\n'.format(\n            '\\n'.join('  {}'.format(c) for c in sorted(available_commands)))\n        doc = get_primary_command_usage(command_doc)\n    elif command.startswith('-'):\n        raise ValueError(\"Unrecognized option '{}'.\".format(command))\n    elif command in settings.subcommands:\n        subcommand = settings.subcommands[command]\n        doc = format_usage(subcommand.__doc__)\n    docopt.docopt(doc, argv=('--help',))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format_usage(doc, width=None):\n    # type: (str, Optional[int]) -> str\n    \"\"\"Format the docstring for display to the user.\n\n    Args:\n        doc: The docstring to reformat for display.\n\n    Returns:\n        The docstring formatted to parse and display to the user. This includes\n        dedenting, rewrapping, and translating the docstring if necessary.\n    \"\"\"\n    sections = doc.replace('\\r', '').split('\\n\\n')\n    width = width or get_terminal_size().columns or 80\n    return '\\n\\n'.join(_wrap_section(s.strip(), width) for s in sections)", "response": "Format the docstring for display to the user."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing a docopt - style string for commands and subcommands.", "response": "def parse_commands(docstring):\n    # type: (str) -> Generator[Tuple[List[str], List[str]], None, None]\n    \"\"\"Parse a docopt-style string for commands and subcommands.\n\n    Args:\n        docstring: A docopt-style string to parse. If the string is not a valid\n            docopt-style string, it will not yield and values.\n\n    Yields:\n        All tuples of commands and subcommands found in the docopt docstring.\n    \"\"\"\n    try:\n        docopt.docopt(docstring, argv=())\n    except (TypeError, docopt.DocoptLanguageError):\n        return\n    except docopt.DocoptExit:\n        pass\n    for command in _parse_section('usage', docstring):\n        args = command.split()\n        commands = []\n        i = 0\n        for i, arg in enumerate(args):\n            if arg[0].isalpha() and not arg[0].isupper():\n                commands.append(arg)\n            else:\n                break\n        yield commands, args[i:]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nmerge two usage strings together.", "response": "def _merge_doc(original, to_merge):\n    # type: (str, str) -> str\n    \"\"\"Merge two usage strings together.\n\n    Args:\n        original: The source of headers and initial section lines.\n        to_merge: The source for the additional section lines to append.\n\n    Returns:\n        A new usage string that contains information from both usage strings.\n    \"\"\"\n    if not original:\n        return to_merge or ''\n    if not to_merge:\n        return original or ''\n    sections = []\n    for name in ('usage', 'arguments', 'options'):\n        sections.append(_merge_section(\n            _get_section(name, original),\n            _get_section(name, to_merge)\n        ))\n    return format_usage('\\n\\n'.join(s for s in sections).rstrip())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _merge_section(original, to_merge):\n    # type: (str, str) -> str\n    \"\"\"Merge two sections together.\n\n    Args:\n        original: The source of header and initial section lines.\n        to_merge: The source for the additional section lines to append.\n\n    Returns:\n        A new section string that uses the header of the original argument and\n        the section lines from both.\n    \"\"\"\n    if not original:\n        return to_merge or ''\n    if not to_merge:\n        return original or ''\n    try:\n        index = original.index(':') + 1\n    except ValueError:\n        index = original.index('\\n')\n    name = original[:index].strip()\n    section = '\\n  '.join(\n        (original[index + 1:].lstrip(), to_merge[index + 1:].lstrip())\n    ).rstrip()\n    return '{name}\\n  {section}'.format(name=name, section=section)", "response": "Merge two sections together."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_section(name, source):\n    # type: (str, str) -> Optional[str]\n    \"\"\"Extract the named section from the source.\n\n    Args:\n        name: The name of the section to extract (e.g. \"Usage\").\n        source: The usage string to parse.\n\n    Returns:\n        A string containing only the requested section. If the section appears\n        multiple times, each instance will be merged into a single section.\n    \"\"\"\n    pattern = re.compile(\n        '^([^\\n]*{name}[^\\n]*\\n?(?:[ \\t].*?(?:\\n|$))*)'.format(name=name),\n        re.IGNORECASE | re.MULTILINE)\n    usage = None\n    for section in pattern.findall(source):\n        usage = _merge_section(usage, section.strip())\n    return usage", "response": "Extract the named section from the source string."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _wrap_section(source, width):\n    # type: (str, int) -> str\n    \"\"\"Wrap the given section string to the current terminal size.\n\n    Intelligently wraps the section string to the given width. When wrapping\n    section lines, it auto-adjusts the spacing between terms and definitions.\n    It also adjusts commands the fit the correct length for the arguments.\n\n    Args:\n        source: The section string to wrap.\n\n    Returns:\n        The wrapped section string.\n    \"\"\"\n    if _get_section('usage', source):\n        return _wrap_usage_section(source, width)\n    if _is_definition_section(source):\n        return _wrap_definition_section(source, width)\n    lines = inspect.cleandoc(source).splitlines()\n    paragraphs = (textwrap.wrap(line, width, replace_whitespace=False)\n                  for line in lines)\n    return '\\n'.join(line for paragraph in paragraphs for line in paragraph)", "response": "Wraps the given section string to the current terminal size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining if the source describes a definition section.", "response": "def _is_definition_section(source):\n    \"\"\"Determine if the source is a definition section.\n\n    Args:\n        source: The usage string source that may be a section.\n\n    Returns:\n        True if the source describes a definition section; otherwise, False.\n    \"\"\"\n    try:\n        definitions = textwrap.dedent(source).split('\\n', 1)[1].splitlines()\n        return all(\n            re.match(r'\\s\\s+((?!\\s\\s).+)\\s\\s+.+', s) for s in definitions)\n    except IndexError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _wrap_usage_section(source, width):\n    # type: (str, int) -> str\n    \"\"\"Wrap the given usage section string to the current terminal size.\n\n    Note:\n        Commands arguments are wrapped to the column that the arguments began\n        on the first line of the command.\n\n    Args:\n        source: The section string to wrap.\n\n    Returns:\n        The wrapped section string.\n    \"\"\"\n    if not any(len(line) > width for line in source.splitlines()):\n        return source\n    section_header = source[:source.index(':') + 1].strip()\n    lines = [section_header]\n    for commands, args in parse_commands(source):\n        command = '  {} '.format(' '.join(commands))\n        max_len = width - len(command)\n        sep = '\\n' + ' ' * len(command)\n        wrapped_args = sep.join(textwrap.wrap(' '.join(args), max_len))\n        full_command = command + wrapped_args\n        lines += full_command.splitlines()\n    return '\\n'.join(lines)", "response": "Wrap the given usage section string to the current terminal size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _wrap_definition_section(source, width):\n    # type: (str, int) -> str\n    \"\"\"Wrap the given definition section string to the current terminal size.\n\n    Note:\n        Auto-adjusts the spacing between terms and definitions.\n\n    Args:\n        source: The section string to wrap.\n\n    Returns:\n        The wrapped section string.\n    \"\"\"\n    index = source.index('\\n') + 1\n    definitions, max_len = _get_definitions(source[index:])\n    sep = '\\n' + ' ' * (max_len + 4)\n    lines = [source[:index].strip()]\n    for arg, desc in six.iteritems(definitions):\n        wrapped_desc = sep.join(textwrap.wrap(desc, width - max_len - 4))\n        lines.append('  {arg:{size}}  {desc}'.format(\n            arg=arg,\n            size=str(max_len),\n            desc=wrapped_desc\n        ))\n    return '\\n'.join(lines)", "response": "Wrap the given definition section string to the current terminal size."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_definitions(source):\n    # type: (str) -> Tuple[Dict[str, str], int]\n    \"\"\"Extract a dictionary of arguments and definitions.\n\n    Args:\n        source: The source for a section of a usage string that contains\n            definitions.\n\n    Returns:\n        A two-tuple containing a dictionary of all arguments and definitions as\n        well as the length of the longest argument.\n    \"\"\"\n    max_len = 0\n    descs = collections.OrderedDict()  # type: Dict[str, str]\n    lines = (s.strip() for s in source.splitlines())\n    non_empty_lines = (s for s in lines if s)\n    for line in non_empty_lines:\n        if line:\n            arg, desc = re.split(r'\\s\\s+', line.strip())\n            arg_len = len(arg)\n            if arg_len > max_len:\n                max_len = arg_len\n            descs[arg] = desc\n    return descs, max_len", "response": "Extract a dictionary of arguments and definitions from a source string that contains\n            definitions."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a section from the source code.", "response": "def _parse_section(name, source):\n    # type: (str, str) -> List[str]\n    \"\"\"Yield each section line.\n\n    Note:\n        Depending on how it is wrapped, a section line can take up more than\n        one physical line.\n\n    Args:\n        name: The name of the section to extract (e.g. \"Usage\").\n        source: The usage string to parse.\n\n    Returns:\n        A list containing each line, de-wrapped by whitespace from the source\n        code.\n        If the section is defined multiple times in the source code, all lines\n        from all sections with that name will be returned.\n    \"\"\"\n    section = textwrap.dedent(_get_section(name, source)[7:])\n    commands = []  # type: List[str]\n    for line in section.splitlines():\n        if not commands or line[:1].isalpha() and line[:1].islower():\n            commands.append(line)\n        else:\n            commands[-1] = '{} {}'.format(commands[-1].strip(), line.strip())\n    return commands"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef move(self, particle, u, v, w, modelTimestep, **kwargs):\n\n        # Kill the particle if it isn't settled and isn't already dead.\n        if not particle.settled and not particle.dead:\n            particle.die()\n\n        # Still save the temperature and salinity for the model output\n        temp = kwargs.get('temperature', None)\n        if temp is not None and math.isnan(temp):\n            temp = None\n        particle.temp = temp\n\n        salt = kwargs.get('salinity', None)\n        if salt is not None and math.isnan(salt):\n            salt = None\n        particle.salt = salt\n\n        u = 0\n        v = 0\n        w = 0\n\n        # Do the calculation to determine the new location\n        result = AsaTransport.distance_from_location_using_u_v_w(u=u, v=v, w=w, timestep=modelTimestep, location=particle.location)\n        result['u'] = u\n        result['v'] = v\n        result['w'] = w\n        return result", "response": "Move the given particle to the new location."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_current_history_length(self):\r\n        u'''Return the number of lines currently in the history.\r\n        (This is different from get_history_length(), which returns \r\n        the maximum number of lines that will be written to a history file.)'''\r\n        value = len(self.history)\r\n        log(u\"get_current_history_length:%d\"%value)\r\n        return value", "response": "Return the length of the current history file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_history_item(self, index):\r\n        u'''Return the current contents of history item at index (starts with index 1).'''\r\n        item = self.history[index - 1]\r\n        log(u\"get_history_item: index:%d item:%r\"%(index, item))\r\n        return item.get_line_text()", "response": "Return the current contents of the history item at index."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a readline history file.", "response": "def read_history_file(self, filename=None): \r\n        u'''Load a readline history file.'''\r\n        if filename is None:\r\n            filename = self.history_filename\r\n        try:\r\n            for line in open(filename, u'r'):\r\n                self.add_history(lineobj.ReadLineTextBuffer(ensure_unicode(line.rstrip())))\r\n        except IOError:\r\n            self.history = []\r\n            self.history_cursor = 0"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave a readline history file.", "response": "def write_history_file(self, filename = None): \r\n        u'''Save a readline history file.'''\r\n        if filename is None:\r\n            filename = self.history_filename\r\n        fp = open(filename, u'wb')\r\n        for line in self.history[-self.history_length:]:\r\n            fp.write(ensure_str(line.get_line_text()))\r\n            fp.write(u'\\n')\r\n        fp.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a line to the history buffer as if it was the last line typed.", "response": "def add_history(self, line):\r\n        u'''Append a line to the history buffer, as if it was the last line typed.'''\r\n        if not hasattr(line, \"get_line_text\"):\r\n            line = lineobj.ReadLineTextBuffer(line)\r\n        if not line.get_line_text():\r\n            pass\r\n        elif len(self.history) > 0 and self.history[-1].get_line_text() == line.get_line_text():\r\n            pass\r\n        else:\r\n            self.history.append(line)\r\n        self.history_cursor = len(self.history)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef previous_history(self, current): # (C-p)\r\n        u'''Move back through the history list, fetching the previous command. '''\r\n        if self.history_cursor == len(self.history):\r\n            self.history.append(current.copy()) #do not use add_history since we do not want to increment cursor\r\n            \r\n        if self.history_cursor > 0:\r\n            self.history_cursor -= 1\r\n            current.set_line(self.history[self.history_cursor].get_line_text())\r\n            current.point = lineobj.EndOfLine", "response": "Move back through the history list fetching the previous command."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef next_history(self, current): # (C-n)\r\n        u'''Move forward through the history list, fetching the next command. '''\r\n        if self.history_cursor < len(self.history) - 1:\r\n            self.history_cursor += 1\r\n            current.set_line(self.history[self.history_cursor].get_line_text())", "response": "Move forward through the history list fetching the next command."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef beginning_of_history(self): # (M-<)\r\n        u'''Move to the first line in the history.'''\r\n        self.history_cursor = 0\r\n        if len(self.history) > 0:\r\n            self.l_buffer = self.history[0]", "response": "Move to the first line in the history."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef end_of_history(self, current): # (M->)\r\n        u'''Move to the end of the input history, i.e., the line currently\r\n        being entered.'''\r\n        self.history_cursor = len(self.history)\r\n        current.set_line(self.history[-1].get_line_text())", "response": "Move to the end of the history."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the datetimes of the model timesteps and return them as a list of lists of times and new times", "response": "def get_time_objects_from_model_timesteps(cls, times, start):\n        \"\"\"\n        Calculate the datetimes of the model timesteps\n\n        times should start at 0 and be in seconds\n\n        \"\"\"\n        modelTimestep = []\n        newtimes = []\n\n        for i in xrange(0, len(times)):\n            try:\n                modelTimestep.append(times[i+1] - times[i])\n            except StandardError:\n                modelTimestep.append(times[i] - times[i-1])\n            newtimes.append(start + timedelta(seconds=times[i]))\n      \n        return (modelTimestep, newtimes)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef fill_polygon_with_points(cls, goal=None, polygon=None):\n        if goal is None:\n            raise ValueError(\"Must specify the number of points (goal) to fill the polygon with\")\n\n        if polygon is None or (not isinstance(polygon, Polygon) and not isinstance(polygon, MultiPolygon)):\n            raise ValueError(\"Must specify a polygon to fill points with\")\n\n        minx = polygon.bounds[0] \n        maxx = polygon.bounds[2] \n        miny = polygon.bounds[1] \n        maxy = polygon.bounds[3] \n\n        points = []\n        now = time.time()\n        while len(points) < goal:\n            random_x = random.uniform(minx, maxx)\n            random_y = random.uniform(miny, maxy)\n            p = Point(random_x, random_y)\n            if p.within(polygon):\n                points.append(p)\n\n        logger.info(\"Filling polygon with points took %f seconds\" % (time.time() - now))\n\n        return points", "response": "Fill a shapely polygon with X number of points"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalculating the greate distance from a location using u v and w.", "response": "def distance_from_location_using_u_v_w(cls, u=None, v=None, w=None, timestep=None, location=None):\n        \"\"\"\n            Calculate the greate distance from a location using u, v, and w.\n\n            u, v, and w must be in the same units as the timestep.  Stick with seconds.\n\n        \"\"\"\n        # Move horizontally\n        distance_horiz = 0\n        azimuth = 0\n        angle = 0\n        depth = location.depth\n\n        if u is not 0 and v is not 0:\n            s_and_d = AsaMath.speed_direction_from_u_v(u=u,v=v) # calculates velocity in m/s from transformed u and v\n            distance_horiz = s_and_d['speed'] * timestep # calculate the horizontal distance in meters using the velocity and model timestep\n            angle = s_and_d['direction']\n            # Great circle calculation \n            # Calculation takes in azimuth (heading from North, so convert our mathematical angle to azimuth)\n            azimuth = AsaMath.math_angle_to_azimuth(angle=angle)\n            \n        distance_vert = 0.\n        if w is not None:\n            # Move vertically\n            # Depth is positive up, negative down.  w wil be negative if moving down, and positive if moving up\n            distance_vert = w * timestep\n            depth += distance_vert # calculate the vertical distance in meters using w (m/s) and model timestep (s)\n            \n\n        if distance_horiz != 0:\n            vertical_angle = math.degrees(math.atan(distance_vert / distance_horiz))\n            gc_result = AsaGreatCircle.great_circle(distance=distance_horiz, azimuth=azimuth, start_point=location) \n        else:\n            # Did we go up or down?\n            vertical_angle = 0.\n            if distance_vert < 0:\n                # Down\n                vertical_angle = 270.\n            elif distance_vert > 0:\n                # Up\n                vertical_angle = 90.\n            gc_result = { 'latitude': location.latitude, 'longitude': location.longitude, 'reverse_azimuth': 0 }\n            \n        #logger.info(\"Particle moving from %fm to %fm from a vertical speed of %f m/s over %s seconds\" % (location.depth, depth, w, str(timestep)))            \n        gc_result['azimuth'] = azimuth\n        gc_result['depth'] = depth\n        gc_result['distance'] = distance_horiz\n        gc_result['angle'] = angle\n        gc_result['vertical_distance'] = distance_vert\n        gc_result['vertical_angle'] = vertical_angle\n        return gc_result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef map(func, data, num_workers=None):\n    # type: (callable, Iterable, Optional[int]) -> Iterable\n    \"\"\" Map an iterable using multithreading\n    >>> s = pd.Series(range(120, 0, -1))\n    >>> s2 = map(lambda i, x: x ** 3.75, s)\n    >>> isinstance(s2, type(s))\n    True\n    >>> len(s) == len(s2)\n    True\n    >>> (s2 == s.map(lambda x: x ** 3.75)).all()\n    True\n    >>> s = list(range(120, 0, -1))\n    >>> s2 = map(lambda i, x: x ** 3.75, s)\n    >>> isinstance(s2, type(s))\n    True\n    >>> len(s) == len(s2)\n    True\n    >>> all(x ** 3.75 == s2[i] for i, x in enumerate(s))\n    True\n    >>> s = dict(enumerate(range(120, 0, -1)))\n    >>> s2 = map(lambda i, x: x ** 3.75, s)\n    >>> isinstance(s2, type(s))\n    True\n    >>> len(s) == len(s2)\n    True\n    >>> all(x ** 3.75 == s2[i] for i, x in s.items())\n    True\n    \"\"\"\n    backend = ThreadPool(n_workers=num_workers)\n    iterable = None\n    # pd.Series didn't have .items() until pandas 0.21,\n    # so iteritems for older versions\n    for method in ('iterrows', 'iteritems', 'items'):\n        if hasattr(data, method):\n            iterable = getattr(data, method)()\n            break\n    if iterable is None:\n        iterable = enumerate(data)\n\n    mapped = {}\n\n    def collect(key):\n        def process(res):\n            mapped[key] = res\n        return process\n\n    for key, value in iterable:\n        backend.submit(func, key, value, callback=collect(key))\n\n    backend.shutdown()\n\n    if isinstance(data, pd.DataFrame):\n        return pd.DataFrame.from_dict(\n            mapped, orient='index').reindex(data.index)\n    elif isinstance(data, pd.Series):\n        return pd.Series(mapped).reindex(data.index)\n    elif isinstance(data, list):\n        return [mapped[i] for i in range(len(data))]\n    else:\n        # in Python, hash(<int>) := <int>, so guaranteed to be in order for list\n        # and tuple. For other types\n        return type(data)(mapped)", "response": "Map an iterable using multithreading\n   "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shutdown(self):\n        # cleanup\n        self.started = False\n        try:\n            # nice way of doing things - let's wait until all items\n            # in the queue are processed\n            for t in self._threads:\n                t.join()\n        finally:\n            # Emergency brake - if a KeyboardInterrupt is raised,\n            # threads will finish processing current task and exit\n            self.stopped = True", "response": "Wait for all threads to finish processing all items in the queue and exit the current thread."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unpack_bytes(bytes):\r\n    if bytes == b'':\r\n        return 0\r\n    int_length = 4\r\n    len_diff = int_length - len(bytes)\r\n    bytes = bytes + len_diff * b'\\x00'\r\n    return struct.unpack(\"<L\", bytes)[0]", "response": "Unpack a set of bytes into an integer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all sprints that have been assigned to a task.", "response": "def get_sprints():\n    \"\"\"\n    Returns all sprints, enriched with their assigned tasks.\n\n    The project should only have one ``sprints.py`` module. We will define it's\n    path via the ``RAPID_PROTOTYPING_SPRINTS_MODULE`` setting. The setting\n    should be the fully qualified name of the ``sprints.py`` module (i.e.\n    ``projectname.context.sprints.sprints``).\n\n    Furthermore the project can have any amount of ``*_costs.py`` modules in\n    any folder (as long as they are on the pythonpath).\n\n    This function will find all ``*_costs.py`` modules and add those tasks,\n    that have been assigned to a sprint, to the corresponding sprints in the\n    ``sprints.py`` module.\n\n    \"\"\"\n    sprints = load_member_from_setting(\n        'RAPID_PROTOTYPING_SPRINTS_MODULE')\n\n    all_tasks = []\n    # TODO The onerror parameter is basically a workaround to ignore errors\n    # The reason for that being, that in my case, the GeoDjango package was in\n    # the path, permanently requesting certain libraries on import. Since they\n    # were not present, the search was aborted with an OSError.\n    for importer, package_name, _ in pkgutil.walk_packages(\n            onerror=lambda p: p):\n        if not package_name.endswith('_costs'):\n            continue\n        if not getattr(settings, 'TEST_RUN', None) and (\n                '.test_app.' in package_name):  # pragma: nocover\n            continue\n        costs = load_member(package_name + '.costs')\n        for task in costs:\n            all_tasks.append(task)\n    sorted_tasks = sorted(all_tasks, key=itemgetter('id'))\n\n    for sprint in sprints:\n        remaining_time = 0\n        sprint['tasks'] = []\n        for task in sorted_tasks:\n            if task.get('sprint') == sprint.get('id'):\n                if not task.get('actual_time'):\n                    remaining_time += \\\n                        task.get('developer_time') or task.get('time')\n                sprint.get('tasks').append(task)\n        sprint['remaining_time'] = remaining_time\n        sprint['remaining_hours'] = round(float(remaining_time) / 60, 2)\n    return sprints"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd 15% overhead costs to the list of costs.", "response": "def append_overhead_costs(costs, new_id, overhead_percentage=0.15):\n    \"\"\"\n    Adds 15% overhead costs to the list of costs.\n\n    Usage::\n\n        from rapid_prototyping.context.utils import append_overhead_costs\n        costs = [\n            ....\n        ]\n        costs = append_overhead_costs(costs, MAIN_ID + get_counter(counter)[0])\n\n    :param costs: Your final list of costs.\n    :param new_id: The id that this new item should get.\n\n    \"\"\"\n    total_time = 0\n    for item in costs:\n        total_time += item['time']\n\n    costs.append({\n        'id': new_id,\n        'task': 'Overhead, Bufixes & Iterations',\n        'time': total_time * overhead_percentage, },\n    )\n    return costs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef arduino_path():\n\n    x = _ARDUINO_PATH\n    if not x:\n        x = os.environ.get('ARDUINO_HOME')\n\n    if not x:\n        x = arduino_default_path()\n\n    assert x, str(x)\n\n    x = path(x).expand().abspath()\n\n    assert x.exists(), 'arduino path not found:' + str(x)\n    return x", "response": "expanded root path of arduino root"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate a 3 - tuple for the two modname_nunja and one modpath_nunja functions for the given entry_point base_module and fext.", "response": "def generate_modname_nunja(\n        entry_point, base_module, fext, text_prefix=REQUIREJS_TEXT_PREFIX):\n    \"\"\"\n    Generate a 3-tuple for the two modname_* and one modpath_* functions\n    required.\n    \"\"\"\n\n    def modname_nunja_template(fragments):\n        # Nunja explicitly requires requirejs-text for the dynamic\n        # loading of templates.  Also by convention, the filename\n        # extension should be included as the modname is based for\n        # the \"standard\" AMD/JavaScript module naming construction.\n        return text_prefix + modname_nunja_script(fragments) + fext\n\n    def modname_nunja_script(fragments):\n        # Do note that in the main implementation, entry points with\n        # multiple attrs will not be resolved and thus this behavior is\n        # very undefined; hence the len check is removed.\n        offset = len(base_module.__name__.split('.'))\n        return '/'.join([entry_point.name] + fragments[offset:])\n\n    def modpath_pkg_resources_entry_point(module, entry_point_=None):\n        \"\"\"\n        Goes through pkg_resources for compliance with various PEPs.\n\n        This one accepts a module as argument.\n        \"\"\"\n\n        if entry_point != entry_point_:\n            logger.warning(\n                'modpath function created for %r got unexpected entrypoint %r',\n                entry_point, entry_point_,\n            )\n\n        if module is not base_module:\n            logger.warning(\n                'modpath function created for %r got unexpected module %r',\n                base_module, module,\n            )\n\n        try:\n            # As a consequence of returning the first entry point attrs,\n            # we effectively remap the module path for the given module\n            # name to this new path, so the above two functions will\n            # never see the attrs within the fragment, as all fragments\n            # before the base path (which is returned here) are to be\n            # provided by the module name.  For more details refer to\n            # tests.\n            return [join(resource_filename_mod_entry_point(\n                module.__name__, entry_point), entry_point.attrs[0])]\n        except ImportError:\n            logger.warning(\"%r could not be located as a module\", module)\n        except Exception:\n            logger.warning(\"%r does not appear to be a valid module\", module)\n\n        return []\n\n    return (\n        modname_nunja_template, modname_nunja_script,\n        modpath_pkg_resources_entry_point,\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef updateFGDBfromSDE(fgdb, sde, logger=None):\n    global changes\n    \"\"\"\n    fgdb: file geodatabase\n    sde: sde geodatabase connection\n    logger: agrc.logging.Logger (optional)\n\n    returns: String[] - the list of errors\n\n    Loops through the file geodatabase feature classes and looks for\n    matches in the SDE database. If there is a match, it does a schema check\n    and then updates the data.\n    \"\"\"\n\n    def log(msg):\n        if logger:\n            logger.logMsg(msg)\n        else:\n            print msg\n\n    def updateData(isTable):\n        try:\n            # validate that there was not a schema change\n            arcpy.env.workspace = fgdb\n            layer = sdeFC + '_Layer'\n            if not isTable:\n                arcpy.MakeFeatureLayer_management(sdeFC, layer, '1 = 2')\n            else:\n                arcpy.MakeTableView_management(sdeFC, layer, '1 = 2')\n\n            try:\n                arcpy.Append_management(layer, f, 'TEST')\n                log('schema test passed')\n                passed = True\n            except arcpy.ExecuteError as e:\n                if '000466' in e.message:\n                    log(e.message)\n                    msg = 'schema change detected'\n                    msg += '\\n\\n{0}'.format(getFieldDifferences(sdeFC, f))\n                    errors.append('{}: {}'.format(f, msg))\n                    log(msg)\n                    passed = False\n                    return passed\n                else:\n                    raise e\n            arcpy.Delete_management(layer)\n\n            log('checking for changes...')\n            if checkForChanges(f, sdeFC, isTable) and passed:\n                log('updating data...')\n                arcpy.TruncateTable_management(f)\n\n                # edit session required for data that participates in relationships\n                editSession = arcpy.da.Editor(fgdb)\n                editSession.startEditing(False, False)\n                editSession.startOperation()\n\n                fields = [fld.name for fld in arcpy.ListFields(f)]\n                fields = filter_fields(fields)\n                if not isTable:\n                    fields.append('SHAPE@')\n                    outputSR = arcpy.Describe(f).spatialReference\n                else:\n                    outputSR = None\n                with arcpy.da.InsertCursor(f, fields) as icursor, \\\n                    arcpy.da.SearchCursor(sdeFC, fields, sql_clause=(None, 'ORDER BY OBJECTID'),\n                                          spatial_reference=outputSR) as cursor:\n                    for row in cursor:\n                        icursor.insertRow(row)\n\n                editSession.stopOperation()\n                editSession.stopEditing(True)\n\n                changes.append(f.upper())\n            else:\n                log('no changes found')\n        except:\n            errors.append('Error updating: {}'.format(f))\n            if logger:\n                logger.logError()\n\n    log('** Updating {} from {}'.format(fgdb, sde))\n    errors = []\n\n    # loop through local feature classes\n    arcpy.env.workspace = fgdb\n    fcs = arcpy.ListFeatureClasses() + arcpy.ListTables()\n    totalFcs = len(fcs)\n    i = 0\n    for f in fcs:\n        i = i + 1\n        log('{} of {} | {}'.format(i, totalFcs, f))\n\n        found = False\n\n        # search for match in stand-alone feature classes\n        arcpy.env.workspace = sde\n        matches = arcpy.ListFeatureClasses('*.{}'.format(f)) + arcpy.ListTables('*.{}'.format(f))\n        if matches is not None and len(matches) > 0:\n            match = matches[0]\n            sdeFC = join(sde, match)\n            found = True\n        else:\n            # search in feature datasets\n            datasets = arcpy.ListDatasets()\n            if len(datasets) > 0:\n                # loop through datasets\n                for ds in datasets:\n                    matches = arcpy.ListFeatureClasses('*.{}'.format(f), None, ds)\n                    if matches is not None and len(matches) > 0:\n                        match = matches[0]\n                        sdeFC = join(sde, match)\n                        found = True\n                        break\n        if not found:\n            msg = 'no match found in sde'\n            errors.append(\"{}: {}\".format(f, msg))\n            log(msg)\n            continue\n\n        updateData(arcpy.Describe(join(fgdb, f)).datasetType == 'Table')\n\n    return (errors, changes)", "response": "updateFGDBfromSDE - update the FGDB file with the data from the SDE"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncheck if there are changes in the current language of the current language of the current language", "response": "def checkForChanges(f, sde, isTable):\n    \"\"\"\n    returns False if there are no changes\n\n    \"\"\"\n    # try simple feature count first\n    fCount = int(arcpy.GetCount_management(f).getOutput(0))\n    sdeCount = int(arcpy.GetCount_management(sde).getOutput(0))\n    if fCount != sdeCount:\n        return True\n\n    fields = [fld.name for fld in arcpy.ListFields(f)]\n\n    # filter out shape fields\n    if not isTable:\n        fields = filter_fields(fields)\n\n        d = arcpy.Describe(f)\n        shapeType = d.shapeType\n        if shapeType == 'Polygon':\n            shapeToken = 'SHAPE@AREA'\n        elif shapeType == 'Polyline':\n            shapeToken = 'SHAPE@LENGTH'\n        elif shapeType == 'Point':\n            shapeToken = 'SHAPE@XY'\n        else:\n            shapeToken = 'SHAPE@JSON'\n        fields.append(shapeToken)\n\n        def parseShape(shapeValue):\n            if shapeValue is None:\n                return 0\n            elif shapeType in ['Polygon', 'Polyline']:\n                return shapeValue\n            elif shapeType == 'Point':\n                if shapeValue[0] is not None and shapeValue[1] is not None:\n                    return shapeValue[0] + shapeValue[1]\n                else:\n                    return 0\n            else:\n                return shapeValue\n\n        outputSR = arcpy.Describe(f).spatialReference\n    else:\n        outputSR = None\n\n    changed = False\n    with arcpy.da.SearchCursor(f, fields, sql_clause=(None, 'ORDER BY OBJECTID')) as fCursor, \\\n            arcpy.da.SearchCursor(sde, fields, sql_clause=(None, 'ORDER BY OBJECTID'),\n                                  spatial_reference=outputSR) as sdeCursor:\n        for fRow, sdeRow in izip(fCursor, sdeCursor):\n            if fRow != sdeRow:\n                # check shapes first\n                if fRow[-1] != sdeRow[-1] and not isTable:\n                    if shapeType not in ['Polygon', 'Polyline', 'Point']:\n                        changed = True\n                        break\n                    fShape = parseShape(fRow[-1])\n                    sdeShape = parseShape(sdeRow[-1])\n                    try:\n                        assert_almost_equal(fShape, sdeShape, -1)\n                        # trim off shapes\n                        fRow = list(fRow[:-1])\n                        sdeRow = list(sdeRow[:-1])\n                    except AssertionError:\n                        changed = True\n                        break\n\n                # trim microseconds since they can be off by one between file and sde databases\n                for i in range(len(fRow)):\n                    if type(fRow[i]) is datetime:\n                        fRow = list(fRow)\n                        sdeRow = list(sdeRow)\n                        fRow[i] = fRow[i].replace(microsecond=0)\n                        try:\n                            sdeRow[i] = sdeRow[i].replace(microsecond=0)\n                        except:\n                            pass\n\n                # compare all values except OBJECTID\n                if fRow[1:] != sdeRow[1:]:\n                    changed = True\n                    break\n\n    return changed"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download_file_powershell(url, target, headers={}):\n    target = os.path.abspath(target)\n\n    powershell_cmd = \"$request = (new-object System.Net.WebClient);\"\n    for k, v in headers.items():\n        powershell_cmd += \"$request.headers['%s'] = '%s';\" % (k, v)\n    powershell_cmd += \"$request.DownloadFile(%(url)r, %(target)r)\" % vars()\n\n    cmd = [\n        'powershell',\n        '-Command',\n        powershell_cmd,\n    ]\n\n    _clean_check(cmd, target)", "response": "Download the file at url to target using Powershell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndownload a file from a URL to a file - like object.", "response": "def download_file_insecure_to_io(url, target_file=None, headers={}):\n    \"\"\"\n    Use Python to download the file, even though it cannot authenticate the\n    connection.\n    \"\"\"\n\n    src = None\n    try:\n        req = Request(\n            url,\n            data=None,\n            headers=headers\n        )\n\n        src = urlopen(req)\n\n        # Read/write all in one block, so we don't create a corrupt file\n        # if the download is interrupted.\n        data = src.read()\n        target_file.write(data)\n    finally:\n        if src:\n            src.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef compute_probability(trajectory_files, bbox=None, \n                        nx=None, ny=None, method='overall', parameter='location'):\n    \"\"\"\n        This function creates a probability (stochastic) grid \n        for trajectory model data using 'overall' method (based\n        on normalization by nsteps * nparticles) or 'run' method\n        (based on normalization by run).\n        \n        probability_grid = compute_probability([myfile1.nc, myfile2.nc],\n                                               bbox = [-75, 23, -60, 45],\n                                               nx = 1000, ny = 1000,\n                                               method = 'overall')  \n        stoch.compute_probability(['/media/sf_Python/trajectories.nc'],bbox=[-148,60,-146,61],nx=500,ny=500,method='overall',parameter='settlement')\n    \"\"\"\n    xarray = np.linspace(float(bbox[0]), float(bbox[2]), int(nx)+1) \n    yarray = np.linspace(float(bbox[1]), float(bbox[3]), int(ny)+1)\n    if method=='overall':\n        prob = np.zeros((ny, nx))\n        for runfile in trajectory_files:\n            run = netCDF4.Dataset(runfile)\n            if parameter == 'location':\n                lat = run.variables['lat'][:].flatten()\n                lon = run.variables['lon'][:].flatten()\n                column_i, row_i = [], []\n                for clon, clat in zip(lon, lat):\n                    column_i.append(bisect.bisect(xarray, clon))\n                    row_i.append(bisect.bisect(yarray, clat))\n                    try:\n                        prob[row_i[-1], column_i[-1]] += 1\n                    except StandardError:\n                        pass\n            elif parameter == 'settlement':\n                for i in range(run.variables['time'].shape[0]):\n                    settle_index = np.where(run.variables['settled'][i,:]==1)\n                    if len(settle_index[0]) > 0:\n                        lat = run.variables['lat'][i, settle_index[0]].flatten()\n                        lon = run.variables['lon'][i, settle_index[0]].flatten()\n                        column_i, row_i = [], []    \n                        for clon, clat in zip(lon, lat):\n                            column_i.append(bisect.bisect(xarray, clon))\n                            row_i.append(bisect.bisect(yarray, clat))\n                            try:\n                                prob[row_i[-1], column_i[-1]] += 1\n                            except StandardError:\n                                pass\n            else:\n                raise ValueError(\"Parameter for stochastic assessment not valid\")\n        shape = run.variables['time'].shape\n        prob = prob / (shape[0] * len(trajectory_files)) # Assumes same # of particles\n                                                         # for every run, may be bad\n                                                         # assumtion\n    elif method=='run':\n        prob = []\n        for i, runfile in enumerate(trajectory_files):\n            prob.append(np.zeros((ny, nx)))\n            run = netCDF4.Dataset(runfile)\n            if parameter == 'location':\n\t\t        lat = run.variables['lat'][:].flatten()\n\t\t        lon = run.variables['lon'][:].flatten()\n            elif parameter == 'settlement':\n                settle_index = np.where(run.variables['settled'][-1,:]==1)[0]\n                lat = run.variables['lat'][-1, settle_index].flatten()\n                lon = run.variables['lon'][-1, settle_index].flatten()\n            else:\n                raise ValueError(\"Parameter for stochastic assessment not valid\")\n            column_i, row_i = [], []\n            for clon, clat in zip(lon, lat):\n                column_i.append(bisect.bisect(xarray, clon))\n                row_i.append(bisect.bisect(yarray, clat))\n                try:\n\t                if prob[i][row_i[-1], column_i[-1]] == 0:\n\t                \tprob[i][row_i[-1], column_i[-1]] = 1\n                except StandardError:\n                    pass\n        prob2 = np.zeros((ny, nx))\n        for run in prob:\n            prob2 = run + prob2\n        prob = prob2 / len(prob)\n    return prob", "response": "This function creates a probability grid for trajectory model data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef compute_probability_settle(trajectory_files, bbox=None, \n                        nx=1000, ny=1000, method='overall'):\n    \"\"\"\n        This function creates a probability (stochastic) grid \n        for trajectory model data based on settlement location, \n        normalized by run.\n        \n        probability_grid = compute_probability_settle([myfile1.nc, myfile2.nc],\n                                               bbox = [-75, 23, -60, 45],\n                                               nx = 1000, ny = 1000,\n                                               method='overall')  \n    \"\"\"\n    prob = compute_probability(trajectory_files,\n                               bbox,\n                               nx, ny,\n                               method,\n                               parameter='settlement',\n                              )\n    return prob", "response": "This function computes the probability of a trajectory model data based on settlement location."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef export_probability(outputname, **kwargs):\n    bbox = kwargs.get('bbox', None)\n    nx, ny = kwargs.get('nx', None), kwargs.get('ny', None)\n    if bbox == None:\n        raise ValueError('Must supply bbox keyword argument.')\n    if nx == None or ny == None:\n        raise ValueError('Must supply nx and ny keyword arguments.')\n    prob = compute_probability(**kwargs)\n    export_grid(outputname, prob, bbox, nx, ny)", "response": "Calculate probability and export to gis raster grid\n format. \n "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __total_pages(self) -> int:\r\n        row_count = self.model.query.count()\r\n        if isinstance(row_count, int):\r\n            return int(row_count / self.limit)\r\n        return None", "response": "Return the total number of pages created by limit"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __filter_query(self) -> str:\r\n        filter_query = 'WHERE %s'\r\n        bind_values = {}\r\n        if not self.__filters:\r\n            return None\r\n        for filter in self.__filters:\r\n            bind = {\r\n                'name': Security.random_string(5),\r\n                'value': filter['value']}\r\n            filter_str = '%s %s :%s' % \\\r\n                (filter['column'], filter['operator'], bind['name'])\r\n            bind_values[bind['name']] = bind['value']\r\n            filter_query = filter_query % (filter_str + ' AND %s')\r\n        return {\r\n            'query': filter_query.replace(' AND %s', ''),\r\n            'binds': bind_values}", "response": "Generate a WHERE and AND string for SQL"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef page(self, page_number=0) -> list:\r\n        # workaround flask-sqlalchemy/issues/516\r\n        offset = page_number * self.limit\r\n        sql = 'SELECT * FROM %s {} LIMIT :li OFFSET :o' \\\r\n            % (self.model.__tablename__)\r\n        filter_query = self.__filter_query()\r\n        if filter_query is None:\r\n            sql = text(sql.format(''))\r\n            result = self.model.db.engine.execute(\r\n                sql, li=self.limit, o=offset)\r\n        else:\r\n            filter_query['binds']['li'] = self.limit\r\n            filter_query['binds']['o'] = offset\r\n            sql = text(sql.format(filter_query['query']))\r\n            result = self.model.db.engine.execute(\r\n                sql, **filter_query['binds'])\r\n        result_keys = result.keys()\r\n        result_models = []\r\n        for row in result:\r\n            model = self.model()\r\n            key_count = 0\r\n            for key in result_keys:\r\n                setattr(model, key, row[key_count])\r\n                key_count = key_count + 1\r\n            result_models.append(model)\r\n        return result_models", "response": "Return list of models by page_number based on limit"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the JSON paginate links", "response": "def links(self, base_link, current_page) -> dict:\r\n        \"\"\" Return JSON paginate links \"\"\"\r\n        max_pages = self.max_pages - 1 if \\\r\n            self.max_pages > 0 else self.max_pages\r\n        base_link = '/%s' % (base_link.strip(\"/\"))\r\n        self_page = current_page\r\n        prev = current_page - 1 if current_page is not 0 else None\r\n        prev_link = '%s/page/%s/%s' % (base_link, prev, self.limit) if \\\r\n            prev is not None else None\r\n        next = current_page + 1 if current_page < max_pages else None\r\n        next_link = '%s/page/%s/%s' % (base_link, next, self.limit) if \\\r\n            next is not None else None\r\n        first = 0\r\n        last = max_pages\r\n        return {\r\n            'self': '%s/page/%s/%s' % (base_link, self_page, self.limit),\r\n            'prev': prev_link,\r\n            'next': next_link,\r\n            'first': '%s/page/%s/%s' % (base_link, first, self.limit),\r\n            'last': '%s/page/%s/%s' % (base_link, last, self.limit),\r\n        }"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a dict for a JSON paginate", "response": "def json_paginate(self, base_url, page_number):\r\n        \"\"\" Return a dict for a JSON paginate \"\"\"\r\n        data = self.page(page_number)\r\n        first_id = None\r\n        last_id = None\r\n        if data:\r\n            first_id = data[0].id\r\n            last_id = data[-1].id\r\n        return {\r\n            'meta': {\r\n                'total_pages': self.max_pages,\r\n                'first_id': first_id,\r\n                'last_id': last_id,\r\n                'current_page': page_number\r\n            },\r\n            'data': self.page(page_number),\r\n            'links': self.links(base_url, page_number)\r\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef log_level(level_string):\r\n\tif level_string.isdigit():\r\n\t\treturn int(level_string)\r\n\treturn getattr(logging, level_string.upper())", "response": "Returns a log level for a string"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds arguments to an ArgumentParser or OptionParser for purposes of creating a logging level.", "response": "def add_arguments(parser, default_level=logging.INFO):\r\n\t\"\"\"\r\n\tAdd arguments to an ArgumentParser or OptionParser for purposes of\r\n\tgrabbing a logging level.\r\n\t\"\"\"\r\n\tadder = (\r\n\t\tgetattr(parser, 'add_argument', None)\r\n\t\tor getattr(parser, 'add_option')\r\n\t)\r\n\tadder(\r\n\t\t'-l', '--log-level', default=default_level, type=log_level,\r\n\t\thelp=\"Set log level (DEBUG, INFO, WARNING, ERROR)\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup(options, **kwargs):\r\n\tparams = dict(kwargs)\r\n\tparams.update(level=options.log_level)\r\n\tlogging.basicConfig(**params)", "response": "Setup logging with options or arguments from an OptionParser or\r\n\tArgumentParser."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_requests_logging(level):\r\n\trequests_log = logging.getLogger(\"requests.packages.urllib3\")\r\n\trequests_log.setLevel(level)\r\n\trequests_log.propagate = True\r\n\r\n\t# enable debugging at httplib level\r\n\thttp_client.HTTPConnection.debuglevel = level <= logging.DEBUG", "response": "Setup logging for requests"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _set_period(self, period):\r\n\t\tself._period = period\r\n\t\tif period:\r\n\t\t\tself._period_seconds = tempora.get_period_seconds(self._period)\r\n\t\t\tself._date_format = tempora.get_date_format_string(\r\n\t\t\t\tself._period_seconds)\r\n\t\telse:\r\n\t\t\tself._period_seconds = 0\r\n\t\t\tself._date_format = ''", "response": "Sets the period for the timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_filename(self, t):\r\n\t\troot, ext = os.path.splitext(self.base_filename)\r\n\t\t# remove seconds not significant to the period\r\n\t\tif self._period_seconds:\r\n\t\t\tt -= t % self._period_seconds\r\n\t\t# convert it to a datetime object for formatting\r\n\t\tdt = datetime.datetime.utcfromtimestamp(t)\r\n\t\t# append the datestring to the filename\r\n\t\t# workaround for datetime.strftime not handling '' properly\r\n\t\tappended_date = (\r\n\t\t\tdt.strftime(self._date_format)\r\n\t\t\tif self._date_format != '' else ''\r\n\t\t)\r\n\t\tif appended_date:\r\n\t\t\t# in the future, it would be nice for this format\r\n\t\t\t#  to be supplied as a parameter.\r\n\t\t\tresult = root + ' ' + appended_date + ext\r\n\t\telse:\r\n\t\t\tresult = self.base_filename\r\n\t\treturn result", "response": "Returns the appropriate filename for the given time"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nemits a record to the log file.", "response": "def emit(self, record):\r\n\t\t\"\"\"\r\n\t\tEmit a record.\r\n\r\n\t\tOutput the record to the file, ensuring that the currently-\r\n\t\topened file has the correct date.\r\n\t\t\"\"\"\r\n\t\tnow = time.time()\r\n\t\tcurrent_name = self.get_filename(now)\r\n\t\ttry:\r\n\t\t\tif not self.stream.name == current_name:\r\n\t\t\t\tself._use_file(current_name)\r\n\t\texcept AttributeError:\r\n\t\t\t# a stream has not been created, so create one.\r\n\t\t\tself._use_file(current_name)\r\n\t\tlogging.StreamHandler.emit(self, record)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_vertex(self, v, partition):\n        self.graph.add_vertex(v)\n        self.partitions[partition].add(v)", "response": "Add a vertex to the graph"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_edge(self, fr, to):\n        if fr not in set(self.graph.vs):  # ToDo: find out why item can be in set but not dict\n            raise ValueError('can not connect unknown vertices in n-partite graphs, {!r} missing'.format(fr))\n        elif to not in set(self.graph.vs):\n            raise ValueError('can not connect unknown vertices in n-partite graphs, {!r} missing'.format(to))\n        self.graph.add_edge(fr, to)", "response": "Add an outward edge to a source vertex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister a handler with Mach9.", "response": "def register(app, uri, file_or_directory, pattern,\n             use_modified_since, use_content_range):\n    # TODO: Though mach9 is not a file server, I feel like we should at least\n    #       make a good effort here.  Modified-since is nice, but we could\n    #       also look into etags, expires, and caching\n    \"\"\"\n    Register a static directory handler with Mach9 by adding a route to the\n    router and registering a handler.\n\n    :param app: Mach9\n    :param file_or_directory: File or directory path to serve from\n    :param uri: URL to serve from\n    :param pattern: regular expression used to match files in the URL\n    :param use_modified_since: If true, send file modified time, and return\n                               not modified if the browser's matches the\n                               server's\n    :param use_content_range: If true, process header for range requests\n                              and sends the file part that is requested\n    \"\"\"\n    # If we're not trying to match a file directly,\n    # serve from the folder\n    if not path.isfile(file_or_directory):\n        uri += '<file_uri:' + pattern + '>'\n\n    async def _handler(request, file_uri=None):\n        # Using this to determine if the URL is trying to break out of the path\n        # served.  os.path.realpath seems to be very slow\n        if file_uri and '../' in file_uri:\n            raise InvalidUsage(\"Invalid URL\")\n        # Merge served directory and requested file if provided\n        # Strip all / that in the beginning of the URL to help prevent python\n        # from herping a derp and treating the uri as an absolute path\n        root_path = file_path = file_or_directory\n        if file_uri:\n            file_path = path.join(\n                file_or_directory, sub('^[/]*', '', file_uri))\n\n        # URL decode the path sent by the browser otherwise we won't be able to\n        # match filenames which got encoded (filenames with spaces etc)\n        file_path = path.abspath(unquote(file_path))\n        if not file_path.startswith(path.abspath(unquote(root_path))):\n            raise FileNotFound('File not found',\n                               path=file_or_directory,\n                               relative_url=file_uri)\n        try:\n            headers = {}\n            # Check if the client has been sent this file before\n            # and it has not been modified since\n            stats = None\n            if use_modified_since:\n                stats = await stat(file_path)\n                modified_since = strftime(\n                    '%a, %d %b %Y %H:%M:%S GMT', gmtime(stats.st_mtime))\n                if request.headers.get('If-Modified-Since') == modified_since:\n                    return HTTPResponse(status=304)\n                headers['Last-Modified'] = modified_since\n            _range = None\n            if use_content_range:\n                _range = None\n                if not stats:\n                    stats = await stat(file_path)\n                headers['Accept-Ranges'] = 'bytes'\n                headers['Content-Length'] = str(stats.st_size)\n                if request.method != 'HEAD':\n                    try:\n                        _range = ContentRangeHandler(request, stats)\n                    except HeaderNotFound:\n                        pass\n                    else:\n                        del headers['Content-Length']\n                        for key, value in _range.headers.items():\n                            headers[key] = value\n            if request.method == 'HEAD':\n                return HTTPResponse(\n                    headers=headers,\n                    content_type=guess_type(file_path)[0] or 'text/plain')\n            else:\n                return await file(file_path, headers=headers, _range=_range)\n        except ContentRangeError:\n            raise\n        except Exception:\n            raise FileNotFound('File not found',\n                               path=file_or_directory,\n                               relative_url=file_uri)\n\n    app.route(uri, methods=['GET', 'HEAD'])(_handler)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfixing import statements in a script.", "response": "def fix_imports(script):\n    \"\"\"\n    Replace \"from PyQt5 import\" by \"from pyqode.qt import\".\n\n    :param script: script path\n    \"\"\"\n    with open(script, 'r') as f_script:\n        lines = f_script.read().splitlines()\n    new_lines = []\n    for l in lines:\n        if l.startswith(\"import \"):\n            l = \"from . \" + l\n        if \"from PyQt5 import\" in l:\n            l = l.replace(\"from PyQt5 import\", \"from pyqode.qt import\")\n        new_lines.append(l)\n    with open(script, 'w') as f_script:\n        f_script.write(\"\\n\".join(new_lines))"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nevaluating a Python script containing a Python params dictionary.", "response": "def eval_py(self, _globals, _locals):\n        \"\"\"\n        Evaluates a file containing a Python params dictionary.\n        \"\"\"\n        try:\n            params = eval(self.script, _globals, _locals)\n        except NameError as e:\n            raise Exception(\n                'Failed to evaluate parameters: {}'\n                .format(str(e))\n            )\n        except ResolutionError as e:\n            raise Exception('GetOutput: {}'.format(str(e)))\n\n        return params"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new(cls, arg):\n        content = None\n\n        if arg.kind == 'file':\n            if os.path.exists(arg.value):\n                with open(arg.value, 'r') as f:\n                    content = f.read()\n            else:\n                raise Exception('File does not exist: {}'.format(arg.value))\n        elif arg.kind == 'cli':\n            content = arg.value\n\n        for source_cls in cls.sources:\n            if source_cls.supports_source(arg):\n                return source_cls(content)\n\n        msg = 'Unsupported Parameter Source \"{}\"'\n        raise Execption(msg.format(arg.value))", "response": "Creates a new Parameter object from the given ParameterArgument."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the minimal pitch between two neighboring nodes of the mesh in each direction.", "response": "def minimum_pitch(self):\n        \"\"\" Returns the minimal pitch between two neighboring nodes of the mesh in each direction.\n\n        :return: Minimal pitch in each direction.\n        \"\"\"\n        pitch = self.pitch\n        minimal_pitch = []\n\n        for p in pitch:\n            minimal_pitch.append(min(p))\n\n        return min(minimal_pitch)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef surrounding_nodes(self, position):\n\n        n_node_index, n_node_position, n_node_error = self.nearest_node(position)\n\n        if n_node_error == 0.0:\n\n            index_mod = []\n\n            for i in range(len(n_node_index)):\n\n                new_point = np.asarray(n_node_position)\n                new_point[i] += 1.e-5*np.abs(new_point[i])\n\n                try:\n                    self.nearest_node(tuple(new_point))\n                    index_mod.append(-1)\n                except ValueError:\n                    index_mod.append(1)\n\n        else:\n            # Check if node_position is larger or smaller in resp. axes than position\n\n            index_mod = []\n\n            for i in range(len(n_node_index)):\n                if n_node_position[i] > position[i]:\n                    index_mod.append(-1)\n                else:\n                    index_mod.append(1)\n\n        return tuple(n_node_index), tuple(index_mod)", "response": "Returns nearest node indices and direction of opposite node."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse a string of color syntax from a formatted string.", "response": "def parse(self, format_string):\n        \"\"\"Parse color syntax from a formatted string.\"\"\"\n        txt, state = '', 0\n        colorstack = [(None, None)]\n        itokens = self.tokenize(format_string)\n\n        for token, escaped in itokens:\n            if token == self._START_TOKEN and not escaped:\n                if txt:\n                    yield txt, colorstack[-1]\n                    txt = ''\n\n                state += 1\n                colors = self.extract_syntax(colorise.compat.next(itokens)[0])\n                colorstack.append(tuple(b or a\n                                        for a, b in zip(colorstack[-1],\n                                                        colors)))\n            elif token == self._FMT_TOKEN and not escaped:\n                # if state == 0:\n                #     raise ColorSyntaxError(\"Missing '{0}'\"\n                #                            .format(self._START_TOKEN))\n\n                if state % 2 != 0:\n                    state += 1\n                else:\n                    txt += token\n            elif token == self._STOP_TOKEN and not escaped:\n                if state < 2:\n                    raise ColorSyntaxError(\"Missing '{0}' or '{1}'\"\n                                           .format(self._STOP_TOKEN,\n                                                   self._FMT_TOKEN))\n\n                if txt:\n                    yield txt, colorstack[-1]\n                    txt = ''\n\n                state -= 2\n                colorstack.pop()\n            else:\n                txt += token\n\n        if state != 0:\n            raise ColorSyntaxError(\"Invalid color format\")\n\n        if txt:\n            yield txt, colorstack[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract_syntax(self, syntax):\n        tokens = syntax.split(self._COLOR_DELIM)\n        r = [None, None]\n\n        for token in tokens:\n            for i, e in enumerate(('fg=', 'bg=')):\n                if token.startswith(e):\n                    r[i] = token[3:]\n\n            if r == [None, None]:\n                raise ColorSyntaxError(\"Unexpected color syntax '{0}'\"\n                                       .format(token))\n\n        return tuple(r)", "response": "Parse and extract color and markup syntax from a format string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_mapping(cls, evidence_mapping):\n        return cls(metadata_map=MetadataMap.from_mapping(evidence_mapping['metadataMap']),\n                   copyright=evidence_mapping['copyright'],\n                   id=evidence_mapping['id'],\n                   terms_of_use=evidence_mapping['termsOfUse'],\n                   document=evidence_mapping['document'],\n                   title=evidence_mapping['title'],\n                   text=evidence_mapping['text'],\n                   value=evidence_mapping['value'])", "response": "Create an Evidence instance from a given mapping."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconverts obj_data into a new object", "response": "def to_obj(cls, obj_data=None, *fields, **field_map):\n    ''' prioritize obj_dict when there are conficts '''\n    obj_dict = obj_data.__dict__ if hasattr(obj_data, '__dict__') else obj_data\n    if not fields:\n        fields = obj_dict.keys()\n    obj = cls()\n    update_obj(obj_dict, obj, *fields, **field_map)\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self, auto_commit=None, schema=None):\n        ''' Create a context to execute queries '''\n        if schema is None:\n            schema = self.schema\n        ac = auto_commit if auto_commit is not None else schema.auto_commit\n        exe = ExecutionContext(self.path, schema=schema, auto_commit=ac)\n        # setup DB if required\n        if not os.path.isfile(self.path) or os.path.getsize(self.path) == 0:\n            getLogger().warning(\"DB does not exist at {}. Setup is required.\".format(self.path))\n            # run setup files\n            if schema is not None and schema.setup_files:\n                for file_path in schema.setup_files:\n                    getLogger().debug(\"Executing script file: {}\".format(file_path))\n                    exe.cur.executescript(self.read_file(file_path))\n            # run setup scripts\n            if schema.setup_scripts:\n                for script in schema.setup_scripts:\n                    exe.cur.executescript(script)\n        return exe", "response": "Open a new ExecutionContext object and return it."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nbuild an INSERT query", "response": "def build_insert(self, table, values, columns=None):\n        ''' Insert an active record into DB and return lastrowid if available '''\n        if not columns:\n            columns = table.columns\n        if len(values) < len(columns):\n            column_names = ','.join(columns[-len(values):])\n        else:\n            column_names = ','.join(columns)\n        query = \"INSERT INTO %s (%s) VALUES (%s) \" % (table.name, column_names, ','.join(['?'] * len(values)))\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsupporting these keywords where values orderby limit and columns", "response": "def select_record(self, table, where=None, values=None, orderby=None, limit=None, columns=None):\n        ''' Support these keywords where, values, orderby, limit and columns'''\n        query = self.schema.query_builder.build_select(table, where, orderby, limit, columns)\n        return table.to_table(self.execute(query, values), columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a name should be excluded.", "response": "def should_be_excluded(name, exclude_patterns):\n    \"\"\"Check if a name should be excluded.\n\n    Returns True if name matches at least one of the exclude patterns in\n    the exclude_patterns list.\n\n    \"\"\"\n    for pattern in exclude_patterns:\n        if fnmatch.fnmatch(name, pattern):\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nfilters the subdirs that have already been visited.", "response": "def filter_visited(curr_dir, subdirs, already_visited, follow_dirlinks, on_error):\n    \"\"\"Filter subdirs that have already been visited.\n\n    This is used to avoid loops in the search performed by os.walk() in\n    index_files_by_size.\n\n    curr_dir is the path of the current directory, as returned by os.walk().\n\n    subdirs is the list of subdirectories for the current directory, as\n    returned by os.walk().\n\n    already_visited is a set of tuples (st_dev, st_ino) of already\n    visited directories. This set will not be modified.\n\n    on error is a function f(OSError) -> None, to be called in case of\n    error.\n\n    Returns a tuple: the new (possibly filtered) subdirs list, and a new\n    set of already visited directories, now including the subdirs.\n\n    \"\"\"\n    filtered = []\n    to_visit = set()\n    _already_visited = already_visited.copy()\n\n    try:\n        # mark the current directory as visited, so we catch symlinks to it\n        # immediately instead of after one iteration of the directory loop\n        file_info = os.stat(curr_dir) if follow_dirlinks else os.lstat(curr_dir)\n        _already_visited.add((file_info.st_dev, file_info.st_ino))\n    except OSError as e:\n        on_error(e)\n\n    for subdir in subdirs:\n        full_path = os.path.join(curr_dir, subdir)\n        try:\n            file_info = os.stat(full_path) if follow_dirlinks else os.lstat(full_path)\n        except OSError as e:\n            on_error(e)\n            continue\n\n        if not follow_dirlinks and stat.S_ISLNK(file_info.st_mode):\n            # following links to dirs is disabled, ignore this one\n            continue\n\n        dev_inode = (file_info.st_dev, file_info.st_ino)\n        if dev_inode not in _already_visited:\n            filtered.append(subdir)\n            to_visit.add(dev_inode)\n        else:\n            on_error(OSError(errno.ELOOP, \"directory loop detected\", full_path))\n\n    return filtered, _already_visited.union(to_visit)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef calculate_md5(filename, length):\n    assert length >= 0\n\n    # shortcut: MD5 of an empty string is 'd41d8cd98f00b204e9800998ecf8427e',\n    # represented here in binary\n    if length == 0:\n        return '\\xd4\\x1d\\x8c\\xd9\\x8f\\x00\\xb2\\x04\\xe9\\x80\\t\\x98\\xec\\xf8\\x42\\x7e'\n\n    md5_summer = hashlib.md5()\n\n    f = open(filename, 'rb')\n\n    try:\n        bytes_read = 0\n\n        while bytes_read < length:\n            chunk_size = min(MD5_CHUNK_SIZE, length - bytes_read)\n\n            chunk = f.read(chunk_size)\n\n            if not chunk:\n                # found EOF: means length was larger than the file size, or\n                # file was truncated while reading -- print warning?\n                break\n\n            md5_summer.update(chunk)\n\n            bytes_read += len(chunk)\n\n    finally:\n        f.close()\n\n    md5 = md5_summer.digest()\n\n    return md5", "response": "Calculate the MD5 hash of a file up to length bytes. Returns the MD5 in its binary form as an 8 - byte string. Raises IOError if file is truncated or OSError if file is truncated."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding duplicates in a list of files comparing up to max_size bytes.", "response": "def find_duplicates(filenames, max_size):\n    \"\"\"Find duplicates in a list of files, comparing up to `max_size` bytes.\n\n    Returns a 2-tuple of two values: ``(duplicate_groups, errors)``.\n\n    `duplicate_groups` is a (possibly empty) list of lists: the names of\n    files that have at least two copies, grouped together.\n\n    `errors` is a list of error messages that occurred. If empty, there were\n    no errors.\n\n    For example, assuming ``a1`` and ``a2`` are identical, ``c1`` and ``c2`` are\n    identical, and ``b`` is different from all others::\n\n      >>> dups, errs = find_duplicates(['a1', 'a2', 'b', 'c1', 'c2'], 1024)\n      >>> dups\n      [['a1', 'a2'], ['c1', 'c2']]\n      >>> errs\n      []\n\n    Note that ``b`` is not included in the results, as it has no duplicates.\n\n    \"\"\"\n    errors = []\n\n    # shortcut: can't have duplicates if there aren't at least 2 files\n    if len(filenames) < 2:\n        return [], errors\n\n    # shortcut: if comparing 0 bytes, they're all the same\n    if max_size == 0:\n        return [filenames], errors\n\n    files_by_md5 = {}\n\n    for filename in filenames:\n        try:\n            md5 = calculate_md5(filename, max_size)\n        except EnvironmentError as e:\n            msg = \"unable to calculate MD5 for '%s': %s\" % (filename, e.strerror)\n            sys.stderr.write(\"%s\\n\" % msg)\n            errors.append(msg)\n            continue\n\n        if md5 not in files_by_md5:\n            # unique beginning so far; index it on its own\n            files_by_md5[md5] = [filename]\n        else:\n            # found a potential duplicate (same beginning)\n            files_by_md5[md5].append(filename)\n\n    # Filter out the unique files (lists of files with the same md5 that\n    # only contain 1 file), and create a list of the lists of duplicates.\n    # Don't use values() because on Python 2 this creates a list of all\n    # values (file lists), and that may be very large.\n    duplicates = [l for l in py3compat.itervalues(files_by_md5) if len(l) >= 2]\n\n    return duplicates, errors"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef semimajor(P,M):\n    if type(P) != Quantity:\n        P = P*u.day\n    if type(M) != Quantity:\n        M = M*u.M_sun\n    a = ((P/2/np.pi)**2*const.G*M)**(1./3)\n    return a.to(u.AU)", "response": "Calculates the semimajor of the given quantity P and M."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a random SkyCoord object with n positions randomly oriented on the unit sphere", "response": "def random_spherepos(n):\n    \"\"\"returns SkyCoord object with n positions randomly oriented on the unit sphere\n\n    Parameters\n    ----------\n    n : int\n        number of positions desired\n\n    Returns\n    -------\n    c : ``SkyCoord`` object with random positions \n    \"\"\"\n    signs = np.sign(rand.uniform(-1,1,size=n))\n    thetas = Angle(np.arccos(rand.uniform(size=n)*signs),unit=u.rad) #random b/w 0 and 180\n    phis = Angle(rand.uniform(0,2*np.pi,size=n),unit=u.rad)\n    c = SkyCoord(phis,thetas,1,representation='physicsspherical')\n    return c"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef orbitproject(x,y,inc,phi=0,psi=0):\n\n    x2 = x*np.cos(phi) + y*np.sin(phi)\n    y2 = -x*np.sin(phi) + y*np.cos(phi)\n    z2 = y2*np.sin(inc)\n    y2 = y2*np.cos(inc)\n\n    xf = x2*np.cos(psi) - y2*np.sin(psi)\n    yf = x2*np.sin(psi) + y2*np.cos(psi)\n\n    return (xf,yf,z2)", "response": "Return a new object that is a copy of the original x y z vector and the new observer s coordinate frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the positions in projected AU and velocities in km / s for given mean anomalies eccentricities semimajors and mreds.", "response": "def orbit_posvel(Ms,eccs,semimajors,mreds,obspos=None):\n    \"\"\"returns positions in projected AU and velocities in km/s for given mean anomalies\n\n    Returns positions and velocities as SkyCoord objects.  Uses\n    ``orbitutils.kepler.Efn`` to calculate eccentric anomalies using interpolation.    \n\n    Parameters\n    ----------\n    Ms, eccs, semimajors, mreds : float or array-like\n        Mean anomalies, eccentricities, semimajor axes (AU), reduced masses (Msun).\n\n    obspos : ``None``, (x,y,z) tuple or ``SkyCoord`` object\n        Locations of observers for which to return coordinates.\n        If ``None`` then populate randomly on sphere.  If (x,y,z) or\n        ``SkyCoord`` object provided, then use those.\n\n    Returns\n    -------\n    pos,vel : ``SkyCoord``\n        Objects representing the positions and velocities, the coordinates\n        of which are ``Quantity`` objects that have units.  Positions are in\n        projected AU and velocities in km/s. \n    \"\"\"\n\n    Es = Efn(Ms,eccs) #eccentric anomalies by interpolation\n\n    rs = semimajors*(1-eccs*np.cos(Es))\n    nus = 2 * np.arctan2(np.sqrt(1+eccs)*np.sin(Es/2),np.sqrt(1-eccs)*np.cos(Es/2))\n\n    xs = semimajors*(np.cos(Es) - eccs)         #AU\n    ys = semimajors*np.sqrt(1-eccs**2)*np.sin(Es)  #AU\n    \n    Edots = np.sqrt(G*mreds*MSUN/(semimajors*AU)**3)/(1-eccs*np.cos(Es))\n        \n    xdots = -semimajors*AU*np.sin(Es)*Edots/1e5  #km/s\n    ydots = semimajors*AU*np.sqrt(1-eccs**2)*np.cos(Es)*Edots/1e5 # km/s\n        \n    n = np.size(xs)\n\n    orbpos = SkyCoord(xs,ys,0*u.AU,representation='cartesian',unit='AU')\n    orbvel = SkyCoord(xdots,ydots,0*u.km/u.s,representation='cartesian',unit='km/s')\n    if obspos is None:\n        obspos = random_spherepos(n) #observer position\n    if type(obspos) == type((1,2,3)):\n        obspos = SkyCoord(obspos[0],obspos[1],obspos[2],\n                          representation='cartesian').represent_as('physicsspherical')\n\n    if not hasattr(obspos,'theta'): #if obspos not physics spherical, make it \n        obspos = obspos.represent_as('physicsspherical')\n        \n    #random orientation of the sky 'x-y' coordinates\n    psi = rand.random(n)*2*np.pi  \n\n    #transform positions and velocities into observer coordinates\n    x,y,z = orbitproject(orbpos.x,orbpos.y,obspos.theta,obspos.phi,psi)\n    vx,vy,vz = orbitproject(orbvel.x,orbvel.y,obspos.theta,obspos.phi,psi)\n\n    return (SkyCoord(x,y,z,representation='cartesian'),\n            SkyCoord(vx,vy,vz,representation='cartesian'))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a dict of all instance variables with truthy values camelized", "response": "def to_dict(self):\n        \"\"\"\n        Return a dict of all instance variables with truthy values,\n        with key names camelized\n        \"\"\"\n        return {\n            inflection.camelize(k, False): v\n            for k, v in self.__dict__.items()\n            if v\n        }"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the absolute path of the file that is fully expanded.", "response": "def fully_expanded_path(self):\n        \"\"\"\n        Returns the absolutely absolute path. Calls os.(\n        normpath, normcase, expandvars and expanduser).\n        \"\"\"\n        return os.path.abspath(\n            os.path.normpath(\n                os.path.normcase(\n                    os.path.expandvars(\n                        os.path.expanduser(self.path)))))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef depth(self):\n        return len(self.path.rstrip(os.sep).split(os.sep))", "response": "Returns the number of ancestors of this directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating the ancestors of the current object.", "response": "def ancestors(self, stop=None):\n        \"\"\"\n        Generates the parents until stop or the absolute\n        root directory is reached.\n        \"\"\"\n        folder = self\n        while folder.parent != stop:\n            if folder.parent == folder:\n                return\n            yield folder.parent\n            folder = folder.parent"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nchecking if this folder is inside the given ancestor.", "response": "def is_descendant_of(self, ancestor):\n        \"\"\"\n        Checks if this folder is inside the given ancestor.\n        \"\"\"\n        stop = Folder(ancestor)\n        for folder in self.ancestors():\n            if folder == stop:\n                return True\n            if stop.depth > folder.depth:\n                return False\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the relative path of the current path starting at root.", "response": "def get_relative_path(self, root):\n        \"\"\"\n        Gets the fragment of the current path starting at root.\n        \"\"\"\n        if self.path == root:\n            return ''\n        ancestors = self.ancestors(stop=root)\n        return functools.reduce(lambda f, p: Folder(p.name).child(f),\n                                ancestors,\n                                self.name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_mirror(self, target_root, source_root=None):\n        fragment = self.get_relative_path(\n                        source_root if source_root else self.parent)\n        return Folder(target_root).child(fragment)", "response": "Returns a File object that reperesents if the entire\n        fragment of this directory starting with source_root was copied\n        to target_root."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a File object that would represent the given path.", "response": "def file_or_folder(path):\n        \"\"\"\n        Returns a File or Folder object that would represent the given path.\n        \"\"\"\n        target = unicode(path)\n        return Folder(target) if os.path.isdir(target) else File(target)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns true if this is a binary file.", "response": "def is_binary(self):\n        \"\"\"Return true if this is a binary file.\"\"\"\n        with open(self.path, 'rb') as fin:\n            CHUNKSIZE = 1024\n            while 1:\n                chunk = fin.read(CHUNKSIZE)\n                if b'\\0' in chunk:\n                    return True\n                if len(chunk) < CHUNKSIZE:\n                    break\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a temporary file and writes the text into it", "response": "def make_temp(text):\n        \"\"\"\n        Creates a temprorary file and writes the `text` into it\n        \"\"\"\n        import tempfile\n        (handle, path) = tempfile.mkstemp(text=True)\n        os.close(handle)\n        afile = File(path)\n        afile.write(text)\n        return afile"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_all(self, encoding='utf-8'):\n        logger.info(\"Reading everything from %s\" % self)\n        with codecs.open(self.path, 'r', encoding) as fin:\n            read_text = fin.read()\n        return read_text", "response": "Reads the content of the file and returns the content as a string."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the given text to the file.", "response": "def write(self, text, encoding=\"utf-8\"):\n        \"\"\"\n        Writes the given text to the file using the given encoding.\n        \"\"\"\n        logger.info(\"Writing to %s\" % self)\n        with codecs.open(self.path, 'w', encoding) as fout:\n            fout.write(text)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncopies the file to the given destination.", "response": "def copy_to(self, destination):\n        \"\"\"\n        Copies the file to the given destination. Returns a File\n        object that represents the target file. `destination` must\n        be a File or Folder object.\n        \"\"\"\n        target = self.__get_destination__(destination)\n        logger.info(\"Copying %s to %s\" % (self, target))\n        shutil.copy(self.path, unicode(destination))\n        return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef etag(self):\n        CHUNKSIZE = 1024 * 64\n        from hashlib import md5\n        hash = md5()\n        with open(self.path) as fin:\n            chunk = fin.read(CHUNKSIZE)\n            while chunk:\n                hash_update(hash, chunk)\n                chunk = fin.read(CHUNKSIZE)\n        return hash.hexdigest()", "response": "Generates etag from file contents."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef walk(self, walk_folders=False, walk_files=False):\n\n        if not walk_files and not walk_folders:\n            return\n\n        for root, _, a_files in os.walk(self.folder.path, followlinks=True):\n            folder = Folder(root)\n            if walk_folders:\n                yield folder\n            if walk_files:\n                for a_file in a_files:\n                    if (not self.pattern or fnmatch.fnmatch(a_file,\n                                                            self.pattern)):\n                        yield File(folder.child(a_file))", "response": "A simple generator that yields a File or Folder object based on the arguments."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef list(self, list_folders=False, list_files=False):\n\n        a_files = os.listdir(self.folder.path)\n        for a_file in a_files:\n            path = self.folder.child(a_file)\n            if os.path.isdir(path):\n                if list_folders:\n                    yield Folder(path)\n            elif list_files:\n                if not self.pattern or fnmatch.fnmatch(a_file, self.pattern):\n                    yield File(path)", "response": "A simple generator that yields a File or Folder object based on the arguments."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a folder object by combining the fragment to this folder s path", "response": "def child_folder(self, fragment):\n        \"\"\"\n        Returns a folder object by combining the fragment to this folder's path\n        \"\"\"\n        return Folder(os.path.join(self.path, Folder(fragment).path))"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef child(self, fragment):\n        return os.path.join(self.path, FS(fragment).path)", "response": "Returns the path of a child item represented by fragment."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef make(self):\n        try:\n            if not self.exists:\n                logger.info(\"Creating %s\" % self.path)\n                os.makedirs(self.path)\n        except os.error:\n            pass\n        return self", "response": "Creates the directory and any of the missing directories in the path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef zip(self, target=None, basepath=None):\n        target = self.parent.child(target or self.name + '.zip')\n        basepath = basepath or self.path\n        from zipfile import ZipFile\n        with ZipFile(target, 'w') as zip:\n            with self.walker as walker:\n                @walker.file_visitor\n                def add_file(f):\n                    zip.write(f.path, f.get_relative_path(basepath))", "response": "Zips the contents of this folder into a new file."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndelete the directory if it exists.", "response": "def delete(self):\n        \"\"\"\n        Deletes the directory if it exists.\n        \"\"\"\n        if self.exists:\n            logger.info(\"Deleting %s\" % self.path)\n            shutil.rmtree(self.path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef move_to(self, destination):\n        target = self.__get_destination__(destination)\n        logger.info(\"Move %s to %s\" % (self, target))\n        shutil.move(self.path, unicode(target))\n        return target", "response": "Moves this directory to the given destination. Returns a Folder object containing the moved directory."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nmoves this directory to the given destination. Returns a Folder object containing the moved directory.", "response": "def rename_to(self, destination_name):\n        \"\"\"\n        Moves this directory to the given destination. Returns a Folder object\n        that represents the moved directory.\n        \"\"\"\n        target = self.parent.child_folder(destination_name)\n        logger.info(\"Rename %s to %s\" % (self, target))\n        shutil.move(self.path, unicode(target))\n        return target"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _create_target_tree(self, target):\n        source = self\n        with source.walker as walker:\n\n            @walker.folder_visitor\n            def visit_folder(folder):\n                \"\"\"\n                Create the mirror directory\n                \"\"\"\n                if folder != source:\n                    Folder(folder.get_mirror(target, source)).make()", "response": "Create the target tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef copy_contents_to(self, destination):\n        logger.info(\"Copying contents of %s to %s\" % (self, destination))\n        target = Folder(destination)\n        target.make()\n        self._create_target_tree(target)\n        dir_util.copy_tree(self.path, unicode(target))\n        return target", "response": "Copies the contents of this directory to the given destination."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts a new thread to process Cron", "response": "def __start(self):\n        \"\"\" Start a new thread to process Cron \"\"\"\n        thread = Thread(target=self.__loop, args=())\n        thread.daemon = True  # daemonize thread\n        thread.start()\n        self.__enabled = True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconverting the passed attr to a BetterDict", "response": "def __dict_to_BetterDict(self, attr):\n        \"\"\"Convert the passed attr to a BetterDict if the value is a dict\n\n        Returns: The new value of the passed attribute.\"\"\"\n        if type(self[attr]) == dict:\n            self[attr] = BetterDict(self[attr])\n\n        return self[attr]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _bd_(self):\n        if not getattr(self, '__bd__', False):\n            self.__bd = BetterDictLookUp(self)\n\n        return self.__bd", "response": "Property that allows dot lookups of otherwise hidden attributes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef create_or_update(sender, **kwargs):\n    now = datetime.datetime.now()\n\n    # I can't explain why this import fails unless it's here.\n    from activity_monitor.models import Activity\n    instance = kwargs['instance']\n\n    # Find this object's content type and model class.\n    instance_content_type = ContentType.objects.get_for_model(sender)\n    instance_model        = sender\n    content_object        = instance_model.objects.get(id=instance.id)\n\n    # check to see if the activity already exists. Will need later.\n    try:\n        activity = Activity.objects.get(content_type=instance_content_type, object_id=content_object.id)\n    except:\n        activity = None\n\n    # We now know the content type, the model (sender), content type and content object.\n    # We need to loop through ACTIVITY_MONITOR_MODELS in settings for other fields\n    for activity_setting in settings.ACTIVITY_MONITOR_MODELS:\n        this_app_label    = activity_setting['model'].split('.')[0]\n        this_model_label  = activity_setting['model'].split('.')[1]\n        this_content_type = ContentType.objects.get(app_label=this_app_label, model=this_model_label)\n\n        if this_content_type == instance_content_type:\n            # first, check to see if we even WANT to register this activity.\n            # use the boolean 'check' field. Also, delete if needed.\n            if 'check' in activity_setting:\n                if getattr(instance, activity_setting['check']) is False:\n                    if activity:\n                        activity.delete()\n                    return\n\n            # does it use the default manager (objects) or a custom manager?\n            try:\n                manager = activity_setting['manager']\n            except:\n                manager  = 'objects'\n\n            # what field denotes the activity time? created is default\n            try:\n                timestamp = getattr(instance, activity_setting['date_field'])\n            except:\n                timestamp = getattr(instance, 'created')\n\n            # if the given time stamp is a daterather than datetime type,\n            # normalize it out to a datetime\n            if type(timestamp) == type(now):\n                clean_timestamp = timestamp\n            else:\n                clean_timestamp = datetime.datetime.combine(timestamp, datetime.time())\n\n           # Find a valid user object\n            if 'user_field' in activity_setting:  # pull the user object from instance using user_field\n                user = getattr(instance, activity_setting['user_field'])\n            elif this_model_label == 'user' or this_model_label == 'profile':  # this IS auth.user or a Django 1.5 custom user\n                user = instance\n            else:  # we didn't specify a user, so it must be instance.user\n                user = instance.user\n\n            # BAIL-OUT CHECKS\n            # Determine all the reasons we would want to bail out.\n            # Make sure it's not a future item, like a future-published blog entry.\n            if clean_timestamp > now:\n                return\n            # or some really old content that was just re-saved for some reason\n            if clean_timestamp < (now - datetime.timedelta(days=3)):\n                return\n            # or there's not a user object\n            if not user:\n                return\n            # or the user is god or staff, and we're filtering out, don't add to monitor\n            if user.is_superuser and 'filter_superuser' in activity_setting:\n                return\n            if user.is_staff and 'filter_staff' in activity_setting:\n                return\n\n            # build a default string representation\n            # note that each activity can get back to the object via get_absolute_url()\n            verb = activity_setting.get('verb', None)\n            override_string = activity_setting.get('override_string', None)\n\n\n    # MANAGER CHECK\n    # Make sure the item \"should\" be registered, based on the manager argument.\n    # If InstanceModel.manager.all() includes this item, then register. Otherwise, return.\n    # Also, check to see if it should be deleted.\n    try:\n        getattr(instance_model, manager).get(pk=instance.pk)\n    except instance_model.DoesNotExist:\n        try:\n            activity.delete()\n            return\n        except Activity.DoesNotExist:\n            return\n\n    if user and clean_timestamp and instance:\n        if not activity:  # If the activity didn't already exist, create it.\n            activity = Activity(\n                actor          = user,\n                content_type   = instance_content_type,\n                object_id      = content_object.id,\n                content_object = content_object,\n                timestamp      = clean_timestamp,\n                verb = verb,\n                override_string = override_string,\n            )\n            activity.save()\n        return activity", "response": "Create or update an Activity Monitor item from some instance."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef highlight_differences(s1, s2, color):\n    ls1, ls2 = len(s1), len(s2)\n\n    diff_indices = [i for i, (a, b) in enumerate(zip(s1, s2)) if a != b]\n\n    print(s1)\n\n    if ls2 > ls1:\n        colorise.cprint('_' * (ls2-ls1), fg=color)\n    else:\n        print()\n\n    colorise.highlight(s2, indices=diff_indices, fg=color, end='')\n\n    if ls1 > ls2:\n        colorise.cprint('_' * (ls1-ls2), fg=color)\n    else:\n        print()", "response": "Highlight the characters in s1 that differ from those in s2."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses the VocabularyCodeSet object from an xml.", "response": "def parse_xml(self, xml):\n        '''\n            :param key_xml: lxml.etree.Element representing a single VocabularyCodeSet\n        '''\n        xmlutils = XmlUtils(xml)\n        self.name = xmlutils.get_string_by_xpath('name')\n        self.family = xmlutils.get_string_by_xpath('family')\n        self.version = xmlutils.get_string_by_xpath('version')\n        for item in xml.xpath('code-item'):\n            self.code_item.append(VocabularyCodeItem(item))\n        self.is_vocab_truncated = xmlutils.get_bool_by_xpath('is-vocab-truncated')\n        self.language = xmlutils.get_lang()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting Hankaku to Full - width Katakana.", "response": "def h2z(text, ignore='', kana=True, ascii=False, digit=False):\n    \"\"\"Convert Half-width (Hankaku) Katakana to Full-width (Zenkaku) Katakana\n\n    Params:\n        <unicode> text\n        <unicode> ignore\n    Return:\n        <unicode> converted_text\n    \"\"\"\n    def _conv_dakuten(text):\n        \"\"\"\n        \u534a\u89d2\u6fc1\u70b9\u30ab\u30ca\u3092\u5168\u89d2\u306b\u5909\u63db\n        \"\"\"\n        text = text.replace(u\"\uff76\uff9e\", u\"\u30ac\").replace(u\"\uff77\uff9e\", u\"\u30ae\")\n        text = text.replace(u\"\uff78\uff9e\", u\"\u30b0\").replace(u\"\uff79\uff9e\", u\"\u30b2\")\n        text = text.replace(u\"\uff7a\uff9e\", u\"\u30b4\").replace(u\"\uff7b\uff9e\", u\"\u30b6\")\n        text = text.replace(u\"\uff7c\uff9e\", u\"\u30b8\").replace(u\"\uff7d\uff9e\", u\"\u30ba\")\n        text = text.replace(u\"\uff7e\uff9e\", u\"\u30bc\").replace(u\"\uff7f\uff9e\", u\"\u30be\")\n        text = text.replace(u\"\uff80\uff9e\", u\"\u30c0\").replace(u\"\uff81\uff9e\", u\"\u30c2\")\n        text = text.replace(u\"\uff82\uff9e\", u\"\u30c5\").replace(u\"\uff83\uff9e\", u\"\u30c7\")\n        text = text.replace(u\"\uff84\uff9e\", u\"\u30c9\").replace(u\"\uff8a\uff9e\", u\"\u30d0\")\n        text = text.replace(u\"\uff8b\uff9e\", u\"\u30d3\").replace(u\"\uff8c\uff9e\", u\"\u30d6\")\n        text = text.replace(u\"\uff8d\uff9e\", u\"\u30d9\").replace(u\"\uff8e\uff9e\", u\"\u30dc\")\n        text = text.replace(u\"\uff8a\uff9f\", u\"\u30d1\").replace(u\"\uff8b\uff9f\", u\"\u30d4\")\n        text = text.replace(u\"\uff8c\uff9f\", u\"\u30d7\").replace(u\"\uff8d\uff9f\", u\"\u30da\")\n        return text.replace(u\"\uff8e\uff9f\", u\"\u30dd\").replace(u\"\uff73\uff9e\", u\"\u30f4\")\n\n    if ascii:\n        if digit:\n            if kana:\n                h2z_map = H2Z_ALL\n            else:\n                h2z_map = H2Z_AD\n        elif kana:\n            h2z_map = H2Z_AK\n        else:\n            h2z_map = H2Z_A\n    elif digit:\n        if kana:\n            h2z_map = H2Z_DK\n        else:\n            h2z_map = H2Z_D\n    else:\n        h2z_map = H2Z_K\n    if kana:\n        text = _conv_dakuten(text)\n    if ignore:\n        h2z_map = _exclude_ignorechar(ignore, h2z_map.copy())\n    return _convert(text, h2z_map)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(text, mode='NFKC', ignore=''):\n    text = text.replace(u'\u301c', u'\u30fc').replace(u'\uff5e', u'\u30fc')\n    text = text.replace(u\"\u2019\", \"'\").replace(u'\u201d', '\"').replace(u'\u201c', '``')\n    text = text.replace(u'\u2015', '-').replace(u'\u2010', u'-')\n    return unicodedata.normalize(mode, text)", "response": "u Convert Hankaku ASCII and DIGIT to Full - width ASCII and DIGIT and Hankaku."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_jinja_env():\n    template_dir = os.path.join(os.path.dirname(__file__), 'templates')\n    env = jinja2.Environment(\n        loader=jinja2.FileSystemLoader(template_dir),\n        autoescape=jinja2.select_autoescape(['html'])\n    )\n    env.filters['simple_date'] = filter_simple_date\n    env.filters['paragraphify'] = filter_paragraphify\n    return env", "response": "Create a Jinja2 environment."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef render_homepage(config, env):\n    template = env.get_template('homepage.jinja')\n    rendered_page = template.render(\n        config=config)\n    return rendered_page", "response": "Render the homepage. jinja template."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef filter_paragraphify(value):\n    value = re.sub(r'\\r\\n|\\r|\\n', '\\n', value)  # Normalize newlines\n    paras = re.split('\\n{2,}', value)\n    paras = ['<p>{0}</p>'.format(p) for p in paras if len(p) > 0]\n    return jinja2.Markup('\\n\\n'.join(paras))", "response": "Convert text into one or more paragraphs including <p > tags."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef d_cal(calibcurve, rcmean, w2, cutoff=0.0001, normal_distr=False, t_a=3, t_b=4):\n    assert t_b - 1 == t_a\n    if normal_distr:\n        # TODO(brews): Test this. Line 946 of Bacon.R.\n        std = np.sqrt(calibcurve.error ** 2 + w2)\n        dens = stats.norm(loc=rcmean, scale=std).pdf(calibcurve.c14age)\n    else:\n        # TODO(brews): Test this. Line 947 of Bacon.R.\n        dens = (t_b + ((rcmean - calibcurve.c14age) ** 2) / (2 * (calibcurve.error ** 2 + w2))) ** (-1 * (t_a + 0.5))\n    cal = np.array([calibcurve.calbp.copy(), dens]).T\n    cal[:, 1] = cal[:, 1] / cal[:, 1].sum()\n    # \"ensure that also very precise dates get a range of probabilities\"\n    cutoff_mask = cal[:, 1] > cutoff\n    if cutoff_mask.sum() > 5:\n        out = cal[cutoff_mask, :]\n    else:\n        calx = np.linspace(cal[:, 0].min(), cal[:, 0].max(), num=50)\n        caly = np.interp(calx, cal[:, 0], cal[:, 1])\n        out = np.array([calx, caly / caly.sum()]).T\n    return out", "response": "Get calendar date probabilities for a given calendar curve."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef calibrate_dates(chron, calib_curve, d_r, d_std, cutoff=0.0001, normal_distr=False, t_a=[3], t_b=[4]):\n    # Python version of .bacon.calib() on line 908 in Bacon.R\n\n    # .bacon.calib - line 908\n\n    # rcmean = 4128; w2 = 4225; t_a=3; t_b=4\n    # test = d_cal(cc = calib_curve.rename(columns = {0:'a', 1:'b', 2:'c'}), rcmean = 4128, w2 = 4225, t_a=t_a,\n    # t_b=t_b, cutoff=cutoff, normal = normal)\n\n    # Line 959 of Bacon.R\n    # calib = list(dets.iloc[:, 3])\n    # Now Bacon goes and checks the ncol in the dets See line #960 in Bacon.R\n\n    # Line #973\n    # TODO(brews): Check that `normal_dist` is used and documented correctly in docstring above.\n    # TODO(brews): Check whether we call returned values densities, freqs or what options we should have.\n    n = len(chron.depth)\n    calib_curve = np.array(calib_curve)\n    t_a = np.array(t_a)\n    t_b = np.array(t_b)\n    assert t_b - 1 == t_a\n    d_r = np.array(d_r)\n    d_std = np.array(d_std)\n    if len(t_a) == 1:\n        t_a = np.repeat(t_a, n)\n    if len(t_b) == 1:\n        t_b = np.repeat(t_b, n)\n    if len(d_r) == 1:\n        d_r = np.repeat(d_r, n)\n    if len(d_std) == 1:\n        d_std = np.repeat(d_std, n)\n    if len(calib_curve) == 1:\n        calib_curve = np.repeat(calib_curve, n)\n\n    calib_probs = []\n    rcmean = chron.age - d_r\n    w2 = chron.error ** 2 + d_std ** 2\n    for i in range(n):\n        age_realizations = d_cal(calib_curve[i], rcmean=rcmean[i], w2=w2[i],\n                                 t_a=t_a[i], t_b=t_b[i],\n                                 cutoff=cutoff, normal_distr=normal_distr)\n        calib_probs.append(age_realizations)\n    return np.array(chron.depth), calib_probs", "response": "Calibration of dates for a dated proxy - like segment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search(self, read_cache=True, ssl_verify=True, recid=None, **kwparams):\n        parse_results = False\n        of = kwparams.get('of', \"\")\n        if of == \"\":\n            parse_results = True\n            of = \"xm\"\n            kwparams['of'] = of\n        params = kwparams\n        cache_key = (json.dumps(params), parse_results)\n\n        if cache_key not in self.cached_queries or \\\n                not read_cache:\n            if recid:\n                results = requests.get(self.server_url + '/record/' + recid,\n                                       params=params, cookies=self.cookies,\n                                       stream=True, verify=ssl_verify,\n                                       allow_redirects=True)\n                if results.history:\n                    new_recid = urlparse(results.url).path.split('/')[-1]\n                    raise InvenioConnectorServerError('The record has been'\n                                                      'merged with recid ' +\n                                                      new_recid)\n            else:\n                results = requests.get(self.server_url + \"/search\",\n                                       params=params, cookies=self.cookies,\n                                       stream=True, verify=ssl_verify)\n            if 'youraccount/login' in results.url:\n                # Current user not able to search collection\n                raise InvenioConnectorAuthError(\n                    \"You are trying to search a restricted collection. \"\n                    \"Please authenticate yourself.\\n\")\n        else:\n            return self.cached_queries[cache_key]\n\n        if parse_results:\n            # FIXME: we should not try to parse if results is string\n            parsed_records = self._parse_results(results.raw,\n                                                 self.cached_records)\n            self.cached_queries[cache_key] = parsed_records\n            return parsed_records\n        else:\n            # pylint: disable=E1103\n            # The whole point of the following code is to make sure we can\n            # handle two types of variable.\n            try:\n                res = results.content\n            except AttributeError:\n                res = results\n            # pylint: enable=E1103\n\n            if of == \"id\":\n                try:\n                    if isinstance(res, binary_type):\n                        # Transform to list\n                        res = [int(recid.strip()) for record_id in\n                               res.decode('utf-8').strip(\"[]\").split(\",\")\n                               if record_id.strip() != \"\"]\n                    res.reverse()\n                except (ValueError, AttributeError):\n                    res = []\n            self.cached_queries[cache_key] = res\n            return res", "response": "Perform a search for the given record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef search_with_retry(self, sleeptime=3.0, retrycount=3, **params):\n        results = []\n        count = 0\n        while count < retrycount:\n            try:\n                results = self.search(**params)\n                break\n            except requests.exceptions.Timeout:\n                sys.stderr.write(\"Timeout while searching...Retrying\\n\")\n                time.sleep(sleeptime)\n                count += 1\n        else:\n            sys.stderr.write(\n                \"Aborting search after %d attempts.\\n\" % (retrycount,))\n        return results", "response": "Perform a search with retrycount times."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the records from the public basket with given bskid", "response": "def get_records_from_basket(self, bskid, group_basket=False,\n                                read_cache=True):\n        \"\"\"\n        Returns the records from the (public) basket with given bskid\n        \"\"\"\n        if bskid not in self.cached_baskets or not read_cache:\n            if self.user:\n                if group_basket:\n                    group_basket = '&category=G'\n                else:\n                    group_basket = ''\n                results = requests.get(\n                    self.server_url + \"/yourbaskets/display?of=xm&bskid=\" +\n                    str(bskid) + group_basket, cookies=self.cookies,\n                    stream=True)\n            else:\n                results = requests.get(\n                    self.server_url +\n                    \"/yourbaskets/display_public?of=xm&bskid=\" + str(bskid),\n                    stream=True)\n        else:\n            return self.cached_baskets[bskid]\n\n        parsed_records = self._parse_results(results.raw, self.cached_records)\n        self.cached_baskets[bskid] = parsed_records\n        return parsed_records"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef upload_marcxml(self, marcxml, mode):\n        if mode not in [\"-i\", \"-r\", \"-c\", \"-a\", \"-ir\"]:\n            raise NameError(\"Incorrect mode \" + str(mode))\n\n        return requests.post(self.server_url + \"/batchuploader/robotupload\",\n                             data={'file': marcxml, 'mode': mode},\n                             headers={'User-Agent': CFG_USER_AGENT})", "response": "Upload a record to the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the URL to this record. Returns None if not known.", "response": "def url(self):\n        \"\"\"\n        Returns the URL to this record.\n        Returns None if not known\n        \"\"\"\n        if self.server_url is not None and \\\n                self.recid is not None:\n            return '/'.join(\n                [self.server_url, CFG_SITE_RECORD, str(self.recid)])\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean_twitter_list(twitter_list,\n                       sent_tokenize, _treebank_word_tokenize,\n                       tagger, lemmatizer, lemmatize, stopset,\n                       first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                       pos_set):\n    \"\"\"\n    Extracts the *set* of keywords found in a Twitter list (name + description).\n\n    Inputs: - twitter_list: A Twitter list in json format.\n            - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\".\n\n    Output: - keyword_set: A set of keywords (i.e. not a bag-of-words) in python set format.\n            - lemma_to_keywordbag: A python dictionary that maps stems/lemmas to original topic keywords.\n    \"\"\"\n    name_lemmas, name_lemma_to_keywordbag = clean_document(twitter_list[\"name\"].replace(\"_\", \" \").replace(\"-\", \" \"),\n                                                           sent_tokenize, _treebank_word_tokenize,\n                                                           tagger, lemmatizer, lemmatize, stopset,\n                                                           first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                           pos_set)\n    description_lemmas, description_lemma_to_keywordbag = clean_document(twitter_list[\"description\"].replace(\"_\", \" \").replace(\"-\", \" \"),\n                                                           sent_tokenize, _treebank_word_tokenize,\n                                                           tagger, lemmatizer, lemmatize, stopset,\n                                                           first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                           pos_set)\n\n    keyword_set = set(name_lemmas + description_lemmas)\n\n    lemma_to_keywordbag = defaultdict(lambda: defaultdict(int))\n    for lemma, keywordbag in name_lemma_to_keywordbag.items():\n        for keyword, multiplicity in keywordbag.items():\n            lemma_to_keywordbag[lemma][keyword] += multiplicity\n\n    for lemma, keywordbag in description_lemma_to_keywordbag.items():\n        for keyword, multiplicity in keywordbag.items():\n            lemma_to_keywordbag[lemma][keyword] += multiplicity\n\n    return keyword_set, lemma_to_keywordbag", "response": "This function extracts the set of keywords from a Twitter list."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef clean_list_of_twitter_list(list_of_twitter_lists,\n                               sent_tokenize, _treebank_word_tokenize,\n                               tagger, lemmatizer, lemmatize, stopset,\n                               first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                               pos_set):\n    \"\"\"\n    Extracts the sets of keywords for each Twitter list.\n\n    Inputs: - list_of_twitter_lists: A python list of Twitter lists in json format.\n            - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\".\n\n    Output: - list_of_keyword_sets: A list of sets of keywords (i.e. not a bag-of-words) in python set format.\n            - list_of_lemma_to_keywordbags: List of python dicts that map stems/lemmas to original topic keywords.\n    \"\"\"\n    list_of_keyword_sets = list()\n    append_keyword_set = list_of_keyword_sets.append\n\n    list_of_lemma_to_keywordbags = list()\n    append_lemma_to_keywordbag = list_of_lemma_to_keywordbags.append\n\n    if list_of_twitter_lists is not None:\n        for twitter_list in list_of_twitter_lists:\n            if twitter_list is not None:\n                keyword_set, lemma_to_keywordbag = clean_twitter_list(twitter_list,\n                                                                      sent_tokenize, _treebank_word_tokenize,\n                                                                      tagger, lemmatizer, lemmatize, stopset,\n                                                                      first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                                      pos_set)\n                append_keyword_set(keyword_set)\n                append_lemma_to_keywordbag(lemma_to_keywordbag)\n\n    return list_of_keyword_sets, list_of_lemma_to_keywordbags", "response": "This function takes a list of Twitter lists and returns a list of lists that are not bag - of - words."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef user_twitter_list_bag_of_words(twitter_list_corpus,\n                                   sent_tokenize, _treebank_word_tokenize,\n                                   tagger, lemmatizer, lemmatize, stopset,\n                                   first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                   pos_set):\n    \"\"\"\n    Extract a bag-of-words for a corpus of Twitter lists pertaining to a Twitter user.\n\n    Inputs: - twitter_list_corpus: A python list of Twitter lists in json format.\n            - lemmatizing: A string containing one of the following: \"porter\", \"snowball\" or \"wordnet\".\n\n    Output: - bag_of_words: A bag-of-words in python dictionary format.\n            - lemma_to_keywordbag_total: Aggregated python dictionary that maps stems/lemmas to original topic keywords.\n    \"\"\"\n    # Extract a bag-of-words from a list of Twitter lists.\n    # May result in empty sets\n    list_of_keyword_sets, list_of_lemma_to_keywordbags = clean_list_of_twitter_list(twitter_list_corpus,\n                                                                                    sent_tokenize, _treebank_word_tokenize,\n                                                                                    tagger, lemmatizer, lemmatize, stopset,\n                                                                                    first_cap_re, all_cap_re, digits_punctuation_whitespace_re,\n                                                                                    pos_set)\n\n    # Reduce keyword sets.\n    bag_of_words = reduce_list_of_bags_of_words(list_of_keyword_sets)\n\n    # Reduce lemma to keywordbag maps.\n    lemma_to_keywordbag_total = defaultdict(lambda: defaultdict(int))\n    for lemma_to_keywordbag in list_of_lemma_to_keywordbags:\n        for lemma, keywordbag in lemma_to_keywordbag.items():\n            for keyword, multiplicity in keywordbag.items():\n                lemma_to_keywordbag_total[lemma][keyword] += multiplicity\n\n    return bag_of_words, lemma_to_keywordbag_total", "response": "This function extracts a bag - of - words from a list of Twitter lists pertaining to a Twitter user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef response(self, request, exception):\n        handler = self.lookup(exception)\n        response = None\n        try:\n            if handler:\n                response = handler(request=request, exception=exception)\n            if response is None:\n                response = self.default(request=request, exception=exception)\n        except Exception:\n            self.log(format_exc())\n            if self.debug:\n                url = getattr(request, 'url', 'unknown')\n                response_message = (\n                    'Exception raised in exception handler \"{}\" '\n                    'for uri: \"{}\"\\n{}').format(\n                        handler.__name__, url, format_exc())\n                self._log.error(response_message)\n                return text(response_message, 500)\n            else:\n                return text('An error occurred while handling an error', 500)\n        return response", "response": "Fetches and executes an exception handler and returns a response object"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a generator of n - length chunks of an iterable.", "response": "def grouper(iterable, n, pad_value=None):\n    \"\"\"\n    Returns a generator of n-length chunks of an input iterable, with appropriate padding at the end.\n\n    Example: grouper(3, 'abcdefg', 'x') --> ('a','b','c'), ('d','e','f'), ('g','x','x')\n\n    Inputs: - iterable: The source iterable that needs to be chunkified.\n            - n: The size of the chunks.\n            - pad_value: The value with which the last chunk will be padded.\n\n    Output: - chunk_gen: A generator of n-length chunks of an input iterable.\n    \"\"\"\n    chunk_gen = (chunk for chunk in zip_longest(*[iter(iterable)]*n, fillvalue=pad_value))\n    return chunk_gen"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef chunks(iterable, n):\n    for i in np.arange(0, len(iterable), n):\n        yield iterable[i:i+n]", "response": "A generator that yields 100 - length sub - list chunks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a generator that yields n - length chunks of an iterable.", "response": "def split_every(iterable, n):  # TODO: Remove this, or make it return a generator.\n    \"\"\"\n    A generator of n-length chunks of an input iterable\n    \"\"\"\n    i = iter(iterable)\n    piece = list(islice(i, n))\n    while piece:\n        yield piece\n        piece = list(islice(i, n))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmerge properties of a node with a value", "response": "def merge_properties(item_properties, prop_name, merge_value):\n    \"\"\"\n    Tries to figure out which type of property value that should be merged and\n    invoke the right function.\n    Returns new properties if the merge was successful otherwise False.\n    \"\"\"\n    existing_value = item_properties.get(prop_name, None)\n    if not existing_value:  # A node without existing values for the property\n        item_properties[prop_name] = merge_value\n    else:\n        if type(merge_value) is int or type(merge_value) is str:\n            item_properties[prop_name] = existing_value + merge_value\n        elif type(merge_value) is list:\n            item_properties[prop_name] = merge_list(existing_value, merge_value)\n        else:\n            return False\n    return item_properties"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreverse operator function :param f: operator.add/sub/mul... used operator :param x: other object field should be add/sub... with :return: dictionary (same shape as field.d) with result of operation", "response": "def __rmath(self, f, x):\n        \"\"\"reverse operator function\n        :param f: operator.add/sub/mul... used operator\n        :param x: other object field should be add/sub... with\n        :return: dictionary (same shape as field.d) with result of operation\n        \"\"\"\n\n        d = {}\n        if isinstance(x, (int, long, float, complex)):\n            for i in self.__d: d[i] = f(x , self.__d[i])\n        else: raise ValueError('Cannot execute reverse operator, only (int, float, complex) as first operand possible')\n\n        return d"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a id for a element.", "response": "def generate_id(self, element):\n        \"\"\"\n        Generate a id for a element.\n\n        :param element: The element.\n        :type element: hatemile.util.html.HTMLDOMElement\n        \"\"\"\n\n        if not element.has_attribute('id'):\n            element.set_attribute('id', self.prefix_id + str(self.count))\n            self.count = self.count + 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nfetch census data from table.", "response": "def fetch_state_data(self, states):\n        \"\"\"\n        Fetch census estimates from table.\n        \"\"\"\n        print(\"Fetching census data\")\n        for table in CensusTable.objects.all():\n            api = self.get_series(table.series)\n            for variable in table.variables.all():\n                estimate = \"{}_{}\".format(table.code, variable.code)\n                print(\n                    \">> Fetching {} {} {}\".format(\n                        table.year, table.series, estimate\n                    )\n                )\n                for state in tqdm(states):\n                    self.get_state_estimates_by_state(\n                        api=api,\n                        table=table,\n                        variable=variable,\n                        estimate=estimate,\n                        state=state,\n                    )\n                    self.get_county_estimates_by_state(\n                        api=api,\n                        table=table,\n                        variable=variable,\n                        estimate=estimate,\n                        state=state,\n                    )\n                    self.get_district_estimates_by_state(\n                        api=api,\n                        table=table,\n                        variable=variable,\n                        estimate=estimate,\n                        state=state,\n                    )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef has(self, name):\n        for a in self.all_annotations:\n            if a.name == name:\n                return True\n        return False", "response": "Returns True if there is at least one annotation by a given name otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the first annotation by a given name.", "response": "def get_first(self, name):\n        \"\"\"\n        Get the first annotation by a given name.\n        \"\"\"\n        for a in self.all_annotations:\n            if a.name == name:\n                return a\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget all the annotation by a given name.", "response": "def get_all(self, name):\n        \"\"\"\n        Get all the annotation by a given name.\n        \"\"\"\n        return [annot for annot in self.all_annotations if annot.name == name]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef first_value_of(self, name, default_value = None):\n        vals = self.values_of(name)\n        if vals is not None:\n            return vals if type(vals) is not list else vals[0]\n        return default_value", "response": "Returns the first value of a particular param by name if it exists otherwise false."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_long_description():\n\n    with open(\n        os.path.join(BASE_DIRECTORY, 'README.md'),\n        'r',\n        encoding='utf-8'\n    ) as readme_file:\n        return readme_file.read()", "response": "Returns the long description of HaTeMiLe for Python."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the packages used for HaTeMiLe for Python.", "response": "def get_packages():\n    \"\"\"\n    Returns the packages used for HaTeMiLe for Python.\n\n    :return: The packages used for HaTeMiLe for Python.\n    :rtype: list(str)\n    \"\"\"\n\n    packages = find_packages(exclude=['tests'])\n    packages.append('')\n    packages.append('js')\n    packages.append(LOCALES_DIRECTORY)\n\n    for directory in os.listdir(LOCALES_DIRECTORY):\n        packages.append(LOCALES_DIRECTORY + '.' + directory)\n    return packages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_package_data():\n\n    package_data = {\n        '': ['*.xml'],\n        'js': ['*.js'],\n        LOCALES_DIRECTORY: ['*']\n    }\n\n    for directory in os.listdir(LOCALES_DIRECTORY):\n        package_data[LOCALES_DIRECTORY + '.' + directory] = ['*.json']\n    return package_data", "response": "Returns the package data for HaTeMiLe for Python."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_requirements():\n\n    requirements = []\n    with open(\n        os.path.join(BASE_DIRECTORY, 'requirements.txt'),\n        'r',\n        encoding='utf-8'\n    ) as requirements_file:\n        lines = requirements_file.readlines()\n        for line in lines:\n            requirements.append(line.strip())\n    return requirements", "response": "Returns the content of requirements. txt in a list."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef where_earliest(cls, user_id):\r\n        return cls.query.filter_by(user_id=user_id)\\\r\n            .order_by(cls.created_at.asc()).first()", "response": "Get the first instance of the class where user_id is the earliest session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncount the number of users who have the given user_id.", "response": "def count(cls, user_id):\r\n        \"\"\" Count sessions with user_id \"\"\"\r\n        return cls.query.with_entities(\r\n            cls.user_id).filter_by(user_id=user_id).count()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef hydrate_callable_with_edge_node_map(\n            self,\n            edge_node_map,\n            callable_function,\n            parameter_lambda\n        ):\n        \"\"\"\n        args and kwargs intentionally not *args and **kwargs\n        \"\"\"\n\n        def extract_kwargs_dict(*args, **kwargs):\n            return kwargs\n\n        def extract_args_list(*args, **kwargs):\n            return list(args)\n\n        args = parameter_lambda(extract_args_list)\n        kwargs = parameter_lambda(extract_kwargs_dict)\n\n        arg_list = [edge_node_map[node_id] for node_id in list(args)]\n\n        kwarg_map = {}\n\n        for kwarg in kwargs:\n            kwarg_map[kwarg] = edge_node_map[kwargs[kwarg]]\n\n        return callable_function(*arg_list, **kwarg_map)", "response": "Hydrates a callable function with the edge node map."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the current branch name", "response": "def get_branch():\n        \"\"\"\n        Returns the current code branch\n        \"\"\"\n        if os.getenv('GIT_BRANCH'):\n            # Travis\n            branch = os.getenv('GIT_BRANCH')\n        elif os.getenv('BRANCH_NAME'):\n            # Jenkins 2\n            branch = os.getenv('BRANCH_NAME')\n        else:\n            branch = check_output(\n                \"git rev-parse --abbrev-ref HEAD\".split(\" \")\n                ).decode('utf-8').strip()\n\n        return branch.replace(\"/\", \"_\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_version():\n        try:\n            return check_output(\n                \"git describe --tags\".split(\" \")\n                ).decode('utf-8').strip()\n        except CalledProcessError:\n            return check_output(\n                \"git rev-parse --short HEAD\".split(\" \")\n                ).decode('utf-8').strip()", "response": "Returns the current version of the current version of the user."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef jenkins_last_build_sha():\n        job_url = os.getenv('JOB_URL')\n        job_json_url = \"{0}/api/json\".format(job_url)\n        response = urllib.urlopen(job_json_url)\n        job_data = json.loads(response.read())\n\n        last_completed_build_url = job_data['lastCompletedBuild']['url']\n        last_complete_build_json_url = \"{0}/api/json\".format(last_completed_build_url)\n\n        response = urllib.urlopen(last_complete_build_json_url)\n        last_completed_build = json.loads(response.read())\n\n        return last_completed_build[1]['lastBuiltRevision']['SHA1']", "response": "Returns the sha of the last completed jenkins build for this project."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_changed_files_from(old_commit_sha, new_commit_sha):\n        return check_output(\n            \"git diff-tree --no-commit-id --name-only -r {0}..{1}\".format(\n                old_commit_sha,\n                new_commit_sha\n            ).split(\" \")\n            ).decode('utf-8').strip()", "response": "Returns a list of the files changed between two commits\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstores all SNOW tweets in a mongodb collection.", "response": "def store_snow_tweets_from_disk_to_mongodb(snow_tweets_folder):\n    \"\"\"\n    Store all SNOW tweets in a mongodb collection.\n    \"\"\"\n    client = pymongo.MongoClient(\"localhost\", 27017)\n\n    db = client[\"snow_tweet_storage\"]\n    collection = db[\"tweets\"]\n\n    for tweet in extract_all_snow_tweets_from_disk_generator(snow_tweets_folder):\n        collection.insert(tweet)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsaves file f to full_path and set rules.", "response": "def save_file(f, full_path):\n    \"\"\"\n    Saves file f to full_path and set rules.\n    \"\"\"\n    make_dirs_for_file_path(full_path, mode=dju_settings.DJU_IMG_CHMOD_DIR)\n    with open(full_path, 'wb') as t:\n        f.seek(0)\n        while True:\n            buf = f.read(dju_settings.DJU_IMG_RW_FILE_BUFFER_SIZE)\n            if not buf:\n                break\n            t.write(buf)\n    os.chmod(full_path, dju_settings.DJU_IMG_CHMOD_FILE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_profile_configs(profile=None, use_cache=True):\n    if use_cache and profile in _profile_configs_cache:\n        return _profile_configs_cache[profile]\n    profile_conf = None\n    if profile is not None:\n        try:\n            profile_conf = dju_settings.DJU_IMG_UPLOAD_PROFILES[profile]\n        except KeyError:\n            if profile != 'default':\n                raise ValueError(unicode(ERROR_MESSAGES['unknown_profile']) % {'profile': profile})\n    conf = copy.deepcopy(dju_settings.DJU_IMG_UPLOAD_PROFILE_DEFAULT)\n    if profile_conf:\n        conf.update(copy.deepcopy(profile_conf))\n        for v_i in xrange(len(conf['VARIANTS'])):\n            v = conf['VARIANTS'][v_i]\n            conf['VARIANTS'][v_i] = copy.deepcopy(dju_settings.DJU_IMG_UPLOAD_PROFILE_VARIANT_DEFAULT)\n            conf['VARIANTS'][v_i].update(v)\n    if use_cache:\n        _profile_configs_cache[profile] = conf\n    return conf", "response": "Returns upload configs for the specified profile."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn path to file relative MEDIA_URL.", "response": "def get_relative_path_from_img_id(img_id, variant_label=None, ext=None, create_dirs=False):\n    \"\"\"\n    Returns path to file relative MEDIA_URL.\n    \"\"\"\n    profile, base_name = img_id.split(':', 1)\n    conf = get_profile_configs(profile)\n    if not variant_label:\n        status_suffix = dju_settings.DJU_IMG_UPLOAD_MAIN_SUFFIX\n    else:\n        status_suffix = dju_settings.DJU_IMG_UPLOAD_VARIANT_SUFFIX\n    name, file_ext = os.path.splitext(base_name)\n    prefix = ''\n    if name.startswith(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):\n        name = name[len(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):]\n        prefix = dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX\n    name_parts = name.split('_', 2)\n    name = '{name}{status_suffix}{hash}'.format(\n        name=name,\n        status_suffix=status_suffix,\n        hash=get_hash('_'.join(name_parts[:2]), variant_label=variant_label)\n    )\n    if variant_label:\n        name += '_' + variant_label\n    if ext:\n        file_ext = ext\n    elif variant_label:\n        for var_conf in conf['VARIANTS']:\n            var_conf_label = var_conf['LABEL'] or get_variant_label(var_conf)\n            if var_conf_label == variant_label:\n                if var_conf['FORMAT']:\n                    file_ext = var_conf['FORMAT'].lower()\n                break\n    if file_ext and not file_ext.startswith('.'):\n        file_ext = '.' + file_ext\n    relative_path = os.path.join(\n        dju_settings.DJU_IMG_UPLOAD_SUBDIR,\n        conf['PATH'],\n        name_parts[0][-2:],\n        (prefix + name + file_ext)\n    ).replace('\\\\', '/')\n    if create_dirs:\n        path = media_path(relative_path)\n        make_dirs_for_file_path(path, mode=dju_settings.DJU_IMG_CHMOD_DIR)\n    return relative_path"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if img_id has real file on filesystem.", "response": "def is_img_id_exists(img_id):\n    \"\"\"\n    Checks if img_id has real file on filesystem.\n    \"\"\"\n    main_rel_path = get_relative_path_from_img_id(img_id)\n    main_path = media_path(main_rel_path)\n    return os.path.isfile(main_path)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if img_id is valid.", "response": "def is_img_id_valid(img_id):\n    \"\"\"\n    Checks if img_id is valid.\n    \"\"\"\n    t = re.sub(r'[^a-z0-9_:\\-\\.]', '', img_id, re.IGNORECASE)\n    t = re.sub(r'\\.+', '.', t)\n    if img_id != t or img_id.count(':') != 1:\n        return False\n    profile, base_name = img_id.split(':', 1)\n    if not profile or not base_name:\n        return False\n    try:\n        get_profile_configs(profile)\n    except ValueError:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_variant_label(v_conf):\n    if v_conf['MAX_SIZE'][0] is None:\n        return 'h{}'.format(v_conf['MAX_SIZE'][1])\n    if v_conf['MAX_SIZE'][1] is None:\n        return 'w{}'.format(v_conf['MAX_SIZE'][0])\n    return '{}x{}'.format(*v_conf['MAX_SIZE'])", "response": "Generates a label for a variant image based settings."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_files_by_img_id(img_id, check_hash=True):\n    main_rel_path = get_relative_path_from_img_id(img_id)\n    main_path = media_path(main_rel_path)\n    if not os.path.isfile(main_path):\n        return None\n    filename = os.path.basename(main_rel_path)\n    name_left_part = filename.split(dju_settings.DJU_IMG_UPLOAD_MAIN_SUFFIX, 1)[0]\n    img_name = name_left_part\n    if img_name.startswith(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):\n        img_name = img_name[len(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):]\n    img_name_parts = img_name.split('_', 2)\n    img_name = '_'.join(img_name_parts[:2])\n    search_pattern = name_left_part + dju_settings.DJU_IMG_UPLOAD_VARIANT_SUFFIX + '*'\n    search_dir = os.path.dirname(main_path)\n    variants = {}\n    for var_path in glob.iglob(os.path.join(search_dir, search_pattern.replace('\\\\', '/'))):\n        var_filename = os.path.basename(var_path)\n        m = variant_hash_label_re.match(var_filename)\n        if not m:\n            continue\n        var_hash, var_label = m.groups()\n        if check_hash and var_hash != get_hash(img_name, var_label):\n            continue\n        variants[var_label] = os.path.relpath(var_path, settings.MEDIA_ROOT)\n    return {\n        'main': main_rel_path,\n        'variants': variants,\n    }", "response": "returns list of files by img_id"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_all_files_of_img_id(img_id):\n    files = get_files_by_img_id(img_id, check_hash=False)\n    if files:\n        os.remove(media_path(files['main']))\n        for fn in files['variants'].values():\n            os.remove(media_path(fn))", "response": "Removes all files of the given img_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove tmp prefix from filename.", "response": "def remove_tmp_prefix_from_filename(filename):\n    \"\"\"\n    Remove tmp prefix from filename.\n    \"\"\"\n    if not filename.startswith(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):\n        raise RuntimeError(ERROR_MESSAGES['filename_hasnt_tmp_prefix'] % {'filename': filename})\n    return filename[len(dju_settings.DJU_IMG_UPLOAD_TMP_PREFIX):]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove tmp prefix from file path or url.", "response": "def remove_tmp_prefix_from_file_path(file_path):\n    \"\"\"\n    Remove tmp prefix from file path or url.\n    \"\"\"\n    path, filename = os.path.split(file_path)\n    return os.path.join(path, remove_tmp_prefix_from_filename(filename)).replace('\\\\', '/')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn img_id with tmp prefix removed from filename and rename main and variant files.", "response": "def make_permalink(img_id):\n    \"\"\"\n    Removes tmp prefix from filename and rename main and variant files.\n    Returns img_id without tmp prefix.\n    \"\"\"\n    profile, filename = img_id.split(':', 1)\n    new_img_id = profile + ':' + remove_tmp_prefix_from_filename(filename)\n    urls = get_files_by_img_id(img_id)\n    if urls is None:\n        return urls\n    move_list = {(urls['main'], remove_tmp_prefix_from_file_path(urls['main']))}\n    for var_label, var_file_path in urls['variants'].iteritems():\n        move_list.add((var_file_path, remove_tmp_prefix_from_file_path(var_file_path)))\n    for file_path_from, file_path_to in move_list:\n        os.rename(media_path(file_path_from), media_path(file_path_to))\n    return new_img_id"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef upload_from_fs(fn, profile=None, label=None):\n    if not os.path.isfile(fn):\n        raise ValueError('File is not exists: {}'.format(fn))\n    if profile is None:\n        profile = 'default'\n    conf = get_profile_configs(profile)\n    with open(fn, 'rb') as f:\n        if not is_image(f, types=conf['TYPES']):\n            msg = (('Format of uploaded file \"%(name)s\" is not allowed. '\n                    'Allowed formats is: %(formats)s.') %\n                   {'name': fn, 'formats': ', '.join(map(lambda t: t.upper(), conf['TYPES']))})\n            raise RuntimeError(msg)\n        return _custom_upload(f, profile, label, conf)", "response": "Uploads image from file fn with TMP prefix and returns img_id."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_from_fileobject(f, profile=None, label=None):\n    if profile is None:\n        profile = 'default'\n    conf = get_profile_configs(profile)\n    f.seek(0)\n    if not is_image(f, types=conf['TYPES']):\n        msg = (('Format of uploaded file is not allowed. '\n                'Allowed formats is: %(formats)s.') %\n               {'formats': ', '.join(map(lambda t: t.upper(), conf['TYPES']))})\n        raise RuntimeError(msg)\n    return _custom_upload(f, profile, label, conf)", "response": "Uploads image from file - like object f with TMP prefix and returns img_id."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninitializing the Flask application.", "response": "def init_app(self, app):\n        \"\"\"Flask application initialization.\"\"\"\n        app.extensions['invenio-documents'] = self\n        app.cli.add_command(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef request(self, method, url, **kwargs):\n\n        if \"data\" in kwargs:\n            kwargs[\"data\"] = json.dumps(kwargs[\"data\"])\n\n        kwargs[\"headers\"] = {\n            'Content-Type': 'application/json',\n            'Authorization': 'token %s' % self.__token__,\n        }\n        req = make_request(\n            method,\n            url,\n            **kwargs\n        )\n        self.logger.debug(\n            \"Request::{}::{}\".format(method, url),\n            extra={\n                \"request\": kwargs,\n                \"response\": {\"headers\": req.headers, \"code\": req.status_code, \"data\": req.content}\n            }\n        )\n        return req", "response": "Make a request to the Github API and return a Response object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef default_branch(self, file):\n        if isinstance(self.__default_branch__, str):\n            return self.__default_branch__\n        elif self.__default_branch__ == GithubProxy.DEFAULT_BRANCH.NO:\n            return self.master_upstream\n        else:\n            return file.sha[:8]", "response": "Decide the name of the default branch given the file and the configuration\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize the application and register the blueprint of the current nemo app", "response": "def init_app(self, app):\n        \"\"\" Initialize the application and register the blueprint\n\n        :param app: Flask Application\n        :return: Blueprint of the current nemo app\n        :rtype: flask.Blueprint\n\n        \"\"\"\n        self.app = app\n        self.__blueprint__ = Blueprint(\n            self.__name__,\n            self.__name__,\n            url_prefix=self.__prefix__,\n        )\n\n        for url, name, methods in self.__urls__:\n            self.blueprint.add_url_rule(\n                url,\n                view_func=getattr(self, name),\n                endpoint=name.replace(\"r_\", \"\"),\n                methods=methods\n            )\n        self.app = self.app.register_blueprint(self.blueprint)\n\n        return self.blueprint"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a new file on github and return the File object.", "response": "def put(self, file):\n        \"\"\" Create a new file on github\n\n        :param file: File to create\n        :return: File or self.ProxyError\n        \"\"\"\n        input_ = {\n            \"message\": file.logs,\n            \"author\": file.author.dict(),\n            \"content\": file.base64,\n            \"branch\": file.branch\n        }\n        uri = \"{api}/repos/{origin}/contents/{path}\".format(\n            api=self.github_api_url,\n            origin=self.origin,\n            path=file.path\n        )\n        data = self.request(\"PUT\", uri, data=input_)\n\n        if data.status_code == 201:\n            file.pushed = True\n            return file\n        else:\n            decoded_data = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, (decoded_data, \"message\"),\n                step=\"put\", context={\n                    \"uri\": uri,\n                    \"params\": input_\n                }\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck on github if a file exists and if so update the blob if it exists.", "response": "def get(self, file):\n        \"\"\" Check on github if a file exists\n\n        :param file: File to check status of\n        :return: File with new information, including blob, or Error\n        :rtype: File or self.ProxyError\n        \"\"\"\n        uri = \"{api}/repos/{origin}/contents/{path}\".format(\n            api=self.github_api_url,\n            origin=self.origin,\n            path=file.path\n        )\n        params = {\n            \"ref\": file.branch\n        }\n        data = self.request(\"GET\", uri, params=params)\n        # We update the file blob because it exists and we need it for update\n        if data.status_code == 200:\n            data = json.loads(data.content.decode(\"utf-8\"))\n            file.blob = data[\"sha\"]\n        elif data.status_code == 404:\n            pass\n        else:\n            decoded_data = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, (decoded_data, \"message\"),\n                step=\"get\", context={\n                    \"uri\": uri,\n                    \"params\": params\n                }\n            )\n        return file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef update(self, file):\n        params = {\n            \"message\": file.logs,\n            \"author\": file.author.dict(),\n            \"content\": file.base64,\n            \"sha\": file.blob,\n            \"branch\": file.branch\n        }\n        uri = \"{api}/repos/{origin}/contents/{path}\".format(\n            api=self.github_api_url,\n            origin=self.origin,\n            path=file.path\n        )\n        data = self.request(\"PUT\", uri, data=params)\n        if data.status_code == 200:\n            file.pushed = True\n            return file\n        else:\n            reply = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, (reply, \"message\"),\n                step=\"update\", context={\n                    \"uri\": uri,\n                    \"params\": params\n                }\n            )", "response": "Update the content of a file with new information."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a pull request for a file.", "response": "def pull_request(self, file):\n        \"\"\" Create a pull request\n\n        :param file: File to push through pull request\n        :return: URL of the PullRequest or Proxy Error\n        \"\"\"\n        uri = \"{api}/repos/{upstream}/pulls\".format(\n            api=self.github_api_url,\n            upstream=self.upstream,\n            path=file.path\n        )\n        params = {\n          \"title\": \"[Proxy] {message}\".format(message=file.logs),\n          \"body\": \"\",\n          \"head\": \"{origin}:{branch}\".format(origin=self.origin.split(\"/\")[0], branch=file.branch),\n          \"base\": self.master_upstream\n        }\n        data = self.request(\"POST\", uri, data=params)\n\n        if data.status_code == 201:\n            return json.loads(data.content.decode(\"utf-8\"))[\"html_url\"]\n        else:\n            reply = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, reply[\"message\"],\n                step=\"pull_request\", context={\n                    \"uri\": uri,\n                    \"params\": params\n                }\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a reference exists in the repository", "response": "def get_ref(self, branch, origin=None):\n        \"\"\" Check if a reference exists\n\n        :param branch: The branch to check if it exists\n        :return: Sha of the branch if it exists, False if it does not exist, self.ProxyError if it went wrong\n        \"\"\"\n        if not origin:\n            origin = self.origin\n        uri = \"{api}/repos/{origin}/git/refs/heads/{branch}\".format(\n            api=self.github_api_url,\n            origin=origin,\n            branch=branch\n        )\n        data = self.request(\"GET\", uri)\n        if data.status_code == 200:\n            data = json.loads(data.content.decode(\"utf-8\"))\n            if isinstance(data, list):\n                # No addresses matches, we get search results which stars with {branch}\n                return False\n            #  Otherwise, we get one record\n            return data[\"object\"][\"sha\"]\n        elif data.status_code == 404:\n            return False\n        else:\n            decoded_data = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, (decoded_data, \"message\"),\n                step=\"get_ref\", context={\n                    \"uri\": uri\n                }\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a branch on github and return the sha of the branch", "response": "def make_ref(self, branch):\n        \"\"\" Make a branch on github\n\n        :param branch: Name of the branch to create\n        :return: Sha of the branch or self.ProxyError\n        \"\"\"\n        master_sha = self.get_ref(self.master_upstream)\n        if not isinstance(master_sha, str):\n            return self.ProxyError(\n                404,\n                \"The default branch from which to checkout is either not available or does not exist\",\n                step=\"make_ref\"\n            )\n\n        params = {\n          \"ref\": \"refs/heads/{branch}\".format(branch=branch),\n          \"sha\": master_sha\n        }\n        uri = \"{api}/repos/{origin}/git/refs\".format(\n            api=self.github_api_url,\n            origin=self.origin\n        )\n        data = self.request(\"POST\", uri, data=params)\n\n        if data.status_code == 201:\n            data = json.loads(data.content.decode(\"utf-8\"))\n            return data[\"object\"][\"sha\"]\n        else:\n            decoded_data = json.loads(data.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                data.status_code, (decoded_data, \"message\"),\n                step=\"make_ref\", context={\n                    \"uri\": uri,\n                    \"params\": params\n                }\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks the sha of the content with the secret", "response": "def check_sha(self, sha, content):\n        \"\"\" Check sent sha against the salted hash of the content\n\n        :param sha: SHA sent through fproxy-secure-hash header\n        :param content: Base 64 encoded Content\n        :return: Boolean indicating equality\n        \"\"\"\n        rightful_sha = sha256(bytes(\"{}{}\".format(content, self.secret), \"utf-8\")).hexdigest()\n        return sha == rightful_sha"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npatch the branch with the given sha.", "response": "def patch_ref(self, sha):\n        \"\"\" Patch reference on the origin master branch\n\n        :param sha: Sha to use for the branch\n        :return: Status of success\n        :rtype: str or self.ProxyError\n        \"\"\"\n        uri = \"{api}/repos/{origin}/git/refs/heads/{branch}\".format(\n            api=self.github_api_url,\n            origin=self.origin,\n            branch=self.master_fork\n        )\n        data = {\n            \"sha\": sha,\n            \"force\": True\n        }\n        reply = self.request(\n            \"PATCH\",\n            uri,\n            data=data\n        )\n        if reply.status_code == 200:\n            dic = json.loads(reply.content.decode(\"utf-8\"))\n            return dic[\"object\"][\"sha\"]\n        else:\n            dic = json.loads(reply.content.decode(\"utf-8\"))\n            return self.ProxyError(\n                reply.status_code,\n                (dic, \"message\"),\n                step=\"patch\",\n                context={\n                    \"uri\": uri,\n                    \"data\": data\n                }\n            )"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions which receives the data from Perseids and returns a PR link to the Perseids branch.", "response": "def r_receive(self, filename):\n        \"\"\" Function which receives the data from Perseids\n\n            - Check the branch does not exist\n            - Make the branch if needed\n            - Receive PUT from Perseids\n            - Check if content exist\n            - Update/Create content\n            - Open Pull Request\n            - Return PR link to Perseids\n\n        It can take a \"branch\" URI parameter for the name of the branch\n\n        :param filename: Path for the file\n        :return: JSON Response with status_code 201 if successful.\n        \"\"\"\n        ###########################################\n        # Retrieving data\n        ###########################################\n        content = request.data.decode(\"utf-8\")\n        # Content checking\n        if not content:\n            error = self.ProxyError(300, \"Content is missing\")\n            return error.response()\n\n        author_name = request.args.get(\"author_name\", self.default_author.name)\n        author_email = request.args.get(\"author_email\", self.default_author.email)\n        author = Author(author_name, author_email)\n\n        date = request.args.get(\"date\", datetime.datetime.now().date().isoformat())\n        logs = request.args.get(\"logs\", \"{} updated {}\".format(author.name, filename))\n\n        self.logger.info(\"Receiving query from {}\".format(author_name), extra={\"IP\": request.remote_addr})\n\n        ###########################################\n        # Checking data security\n        ###########################################\n        secure_sha = None\n        if \"fproxy-secure-hash\" in request.headers:\n            secure_sha = request.headers[\"fproxy-secure-hash\"]\n\n        if not secure_sha or not self.check_sha(secure_sha, content):\n            error = self.ProxyError(300, \"Hash does not correspond with content\")\n            return error.response()\n\n        ###########################################\n        # Setting up data\n        ###########################################\n        file = File(\n            path=filename,\n            content=content,\n            author=author,\n            date=date,\n            logs=logs\n        )\n        file.branch = request.args.get(\"branch\", self.default_branch(file))\n\n        ###########################################\n        # Ensuring branch exists\n        ###########################################\n        branch_status = self.get_ref(file.branch)\n\n        if isinstance(branch_status, self.ProxyError):  # If we have an error from github API\n            return branch_status.response()\n        elif not branch_status:  # If it does not exist\n            # We create a branch\n            branch_status = self.make_ref(file.branch)\n            # If branch creation did not work\n            if isinstance(branch_status, self.ProxyError):\n                return branch_status.response()\n\n        ###########################################\n        # Pushing files\n        ###########################################\n        # Check if file exists\n        # It feeds file.blob parameter, which tells us the sha of the file if it exists\n        file = self.get(file)\n        if isinstance(file, self.ProxyError):  # If we have an error from github API\n            return file.response()\n\n        # If it has a blob set up, it means we can update given file\n        if file.blob:\n            file = self.update(file)\n        # Otherwise, we create it\n        else:\n            file = self.put(file)\n\n        if isinstance(file, self.ProxyError):\n            return file.response()\n        ###########################################\n        # Making pull request\n        ###########################################\n\n        pr_url = self.pull_request(file)\n        if isinstance(pr_url, self.ProxyError):\n            return pr_url.response()\n\n        reply = {\n            \"status\": \"success\",\n            \"message\": \"The workflow was well applied\",\n            \"pr_url\": pr_url\n        }\n        data = jsonify(reply)\n        data.status_code = 201\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating a master branch and the master branch of the origin repository.", "response": "def r_update(self):\n        \"\"\" Updates a fork Master\n\n            - Check the ref of the origin repository\n            - Patch reference of fork repository\n            - Return status to Perseids\n\n        :return: JSON Response with status_code 201 if successful.\n        \"\"\"\n\n        # Getting Master Branch\n        upstream = self.get_ref(self.master_upstream, origin=self.upstream)\n        if isinstance(upstream, bool):\n            return (ProxyError(\n                404, \"Upstream Master branch '{0}' does not exist\".format(self.master_upstream),\n                step=\"get_upstream_ref\"\n            )).response()\n        elif isinstance(upstream, self.ProxyError):\n            return upstream.response()\n\n        # Patching\n        new_sha = self.patch_ref(upstream)\n        if isinstance(new_sha, self.ProxyError):\n            return new_sha.response()\n\n        self.logger.info(\"Updated repository {} to sha {}\".format(self.origin, new_sha), extra={\"former_sha\": upstream})\n        return jsonify({\n            \"status\": \"success\",\n            \"commit\": new_sha\n        })"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef int_filter(text):\n    res = list()\n    for char in text:\n        if char.isdigit():\n            res.append(char)\n    return int(\"\".join(res))", "response": "Extract integer from text."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef float_filter(text):\n    res = list()\n    for char in text:\n        if (char.isdigit() or (char == \".\")):\n            res.append(char)\n    return float(\"\".join(res))", "response": "Extract float from text."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load(self, filename, offset):\n        try:\n            self.offset = offset\n            # self.fd = open(filename, 'rb')\n            # self.fd.close()\n        except IOError as e:\n            print(e)", "response": "Will eventually load information for Apple_Boot volume.\n        Not yet implemented"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbinds a type to the object", "response": "def bind_type(type_to_bind: hexdi.core.restype, accessor: hexdi.core.clstype, lifetime_manager: hexdi.core.ltype):\n    \"\"\"\n    shortcut for bind_type on root container\n\n    :param type_to_bind: type that will be resolved by accessor\n    :param accessor: accessor for resolving object\n    :param lifetime_manager: type of lifetime manager for this binding\n    \"\"\"\n    hexdi.core.get_root_container().bind_type(type_to_bind, accessor, lifetime_manager)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind_transient(type_to_bind: hexdi.core.restype, accessor: hexdi.core.clstype):\n    hexdi.core.get_root_container().bind_type(type_to_bind, accessor, lifetime.PerResolveLifeTimeManager)", "response": "shortcut for bind_type with PerResolveLifeTimeManager on root container"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_series(self, series):\n        if series == \"acs1\":\n            return self.census.acs1dp\n        elif series == \"acs5\":\n            return self.census.acs5\n        elif series == \"sf1\":\n            return self.census.sf1\n        elif series == \"sf3\":\n            return self.census.sf3\n        else:\n            return None", "response": "Returns a census series API handler."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write_xml(self):\n        '''\n            :return: Xml for order by property\n            :rtype: lxml.etree.Element\n        '''\n        order_by_specs = etree.Element('order-by-property')\n\n        order_by_specs.attrib['type-id'] = self.typeid\n        order_by_specs.attrib['property-name'] = self.property_name\n        order_by_specs.attrib['direction'] = self.direction\n        return order_by_specs", "response": "Return the Xml for order by property in the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nfinds similar objects using related tags.", "response": "def similar_objects(self, num=None, **filters):\n        \"\"\"\n        Find similar objects using related tags.\n        \"\"\"\n        tags = self.tags\n        if not tags:\n            return []\n\n        content_type = ContentType.objects.get_for_model(self.__class__)\n        filters['content_type'] = content_type\n\n        # can't filter, see\n        # - https://github.com/alex/django-taggit/issues/32\n        # - https://django-taggit.readthedocs.io/en/latest/api.html#TaggableManager.similar_objects\n        #\n        # Otherwise this would be possible:\n        # return tags.similar_objects(**filters)\n\n        lookup_kwargs = tags._lookup_kwargs()\n        lookup_keys = sorted(lookup_kwargs)\n        subq = tags.all()\n        qs = (tags.through.objects\n              .values(*lookup_kwargs.keys())\n              .annotate(n=models.Count('pk'))\n              .exclude(**lookup_kwargs)\n              .filter(tag__in=list(subq))\n              .order_by('-n'))\n\n        # from https://github.com/alex/django-taggit/issues/32#issuecomment-1002491\n        if filters is not None:\n            qs = qs.filter(**filters)\n\n        if num is not None:\n            qs = qs[:num]\n\n        # Normal taggit code continues\n\n        # TODO: This all feels like a bit of a hack.\n        items = {}\n        if len(lookup_keys) == 1:\n            # Can we do this without a second query by using a select_related()\n            # somehow?\n            f = tags.through._meta.get_field_by_name(lookup_keys[0])[0]\n            objs = f.rel.to._default_manager.filter(**{\n                \"%s__in\" % f.rel.field_name: [r[\"content_object\"] for r in qs]\n            })\n            for obj in objs:\n                items[(getattr(obj, f.rel.field_name),)] = obj\n        else:\n            preload = {}\n            for result in qs:\n                preload.setdefault(result['content_type'], set())\n                preload[result[\"content_type\"]].add(result[\"object_id\"])\n\n            for ct, obj_ids in preload.items():\n                ct = ContentType.objects.get_for_id(ct)\n                for obj in ct.model_class()._default_manager.filter(pk__in=obj_ids):\n                    items[(ct.pk, obj.pk)] = obj\n\n        results = []\n        for result in qs:\n            obj = items[\n                tuple(result[k] for k in lookup_keys)\n            ]\n            obj.similar_tags = result[\"n\"]\n            results.append(obj)\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set(self, repo):\n        name = repo.name\n        if name in self.__repositories \\\n           and self.__repositories[name].is_initialized:\n            raise ValueError('Can not replace repositories that have been '\n                             'initialized.')\n        self.__repositories[name] = repo", "response": "Sets the given repository."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef new(self, repo_type, name=None, make_default=False,\n            repository_class=None, aggregate_class=None,\n            configuration=None):\n        \"\"\"\n        Creates a new repository of the given type. If the root repository\n        domain (see :class:`everest.repositories.constants.REPOSITORY_DOMAINS`)\n        is passed as a repository name, the type string is used as the name;\n        if no name is passed, a unique name is created automatically.\n        \"\"\"\n        if name == REPOSITORY_DOMAINS.ROOT:\n            # Unless explicitly configured differently, all root repositories\n            # join the transaction.\n            join_transaction = True\n            autocommit = False\n            name = repo_type\n        else:\n            join_transaction = False\n            if name is None:\n                name = \"%s%d\" % (repo_type, next(self.__repo_id_gen))\n            # The system repository is special in that its repository\n            # should not join the transaction but still commit all changes.\n            autocommit = name == REPOSITORY_DOMAINS.SYSTEM\n        if repository_class is None:\n            reg = get_current_registry()\n            repository_class = reg.queryUtility(IRepository, name=repo_type)\n            if repository_class is None:\n                raise ValueError('Unknown repository type \"%s\".' % repo_type)\n        repo = repository_class(name,\n                                aggregate_class,\n                                join_transaction=join_transaction,\n                                autocommit=autocommit)\n        if not configuration is None:\n            repo.configure(**configuration)\n        if make_default:\n            self.__default_repo = repo\n        return repo", "response": "Creates a new repository of the given type."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_system_repository(self, repository_type, reset_on_start,\n                                repository_class=None):\n        \"\"\"\n        Sets up the system repository with the given repository type.\n\n        :param str repository_type: Repository type to use for the SYSTEM\n          repository.\n        :param bool reset_on_start: Flag to indicate whether stored system\n          resources should be discarded on startup.\n        :param repository_class: class to use for the system repository. If\n          not given, the registered class for the given type will be used.\n        \"\"\"\n        # Set up the system entity repository (this does not join the\n        # transaction and is in autocommit mode).\n        cnf = dict(messaging_enable=True,\n                   messaging_reset_on_start=reset_on_start)\n        system_repo = self.new(repository_type,\n                               name=REPOSITORY_DOMAINS.SYSTEM,\n                               repository_class=repository_class,\n                               configuration=cnf)\n        self.set(system_repo)", "response": "Sets up the system repository with the given repository type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef initialize_all(self):\n        for repo in itervalues_(self.__repositories):\n            if not repo.is_initialized:\n                repo.initialize()", "response": "Initializes all the related objects in this instance."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a new HTTPResponse object with the given body.", "response": "def raw(body, status=200, headers=None,\n        content_type='application/octet-stream'):\n    '''\n    Returns response object without encoding the body.\n    :param body: Response data.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    :param content_type: the content type (string) of the response.\n    '''\n    return HTTPResponse(body_bytes=body, status=status, headers=headers,\n                        content_type=content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a HTTPResponse object with body in html format.", "response": "def html(body, status=200, headers=None):\n    '''\n    Returns response object with body in html format.\n    :param body: Response data to be encoded.\n    :param status: Response code.\n    :param headers: Custom Headers.\n    '''\n    return HTTPResponse(body, status=status, headers=headers,\n                        content_type='text/html; charset=utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a response object with file data.", "response": "async def file(location, mime_type=None, headers=None, _range=None):\n    '''Return a response object with file data.\n\n    :param location: Location of file on system.\n    :param mime_type: Specific mime_type.\n    :param headers: Custom Headers.\n    :param _range:\n    '''\n    filename = path.split(location)[-1]\n\n    async with open_async(location, mode='rb') as _file:\n        if _range:\n            await _file.seek(_range.start)\n            out_stream = await _file.read(_range.size)\n            headers['Content-Range'] = 'bytes %s-%s/%s' % (\n                _range.start, _range.end, _range.total)\n        else:\n            out_stream = await _file.read()\n\n    mime_type = mime_type or guess_type(filename)[0] or 'text/plain'\n\n    return HTTPResponse(status=200,\n                        headers=headers,\n                        content_type=mime_type,\n                        body_bytes=out_stream)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nabort execution and cause a 302 redirect.", "response": "def redirect(to, headers=None, status=302,\n             content_type='text/html; charset=utf-8'):\n    '''Abort execution and cause a 302 redirect (by default).\n\n    :param to: path or fully qualified URL to redirect to\n    :param headers: optional dict of headers to include in the new request\n    :param status: status code (int) of the new request, defaults to 302\n    :param content_type: the content type (string) of the response\n    :returns: the redirecting Response\n    '''\n    headers = headers or {}\n\n    # According to RFC 7231, a relative URI is now permitted.\n    headers['Location'] = to\n\n    return HTTPResponse(\n        status=status,\n        headers=headers,\n        content_type=content_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_message(self, more_content):\n        '''\n        http://channels.readthedocs.io/en/stable/asgi/www.html#response\n        '''\n        return {\n            'status': self.status,\n            'content': self.body,\n            'headers': self._parse_headers(),\n            'more_content': more_content\n        }", "response": "Returns a dict of the status content headers and more_content."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_bundles():\n    global _cached_bundles\n\n    if not _cached_bundles:\n        _cached_bundles = BundleManager()\n\n        for bundle_conf in bundles_settings.BUNDLES:\n            _cached_bundles[bundle_conf[0]] = Bundle(bundle_conf)\n\n    return _cached_bundles", "response": "Returns a list of all bundles that are available for the current project"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the bundle versions for the current node", "response": "def get_bundle_versions():\n    \"\"\"\n    Used to cache the bundle versions rather than loading them from the bundle versions file every time they're used\n    \"\"\"\n    global _cached_versions\n    if not bundles_settings.BUNDLES_VERSION_FILE:\n        _cached_versions = {}\n    if _cached_versions is None:\n        locs = {}\n        try:\n            execfile(bundles_settings.BUNDLES_VERSION_FILE, locs)\n            _cached_versions = locs['BUNDLES_VERSIONS']\n        except IOError:\n            _cached_versions = {}\n    return _cached_versions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the full path to the bundled bundle file.", "response": "def get_url(self, version=None):\n        \"\"\"\n        Return the filename of the bundled bundle\n        \"\"\"\n        if self.fixed_bundle_url:\n            return self.fixed_bundle_url\n        return '%s.%s.%s' % (os.path.join(self.bundle_url_root, self.bundle_filename), version or self.get_version(), self.bundle_type)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of file urls", "response": "def get_file_urls(self):\n        \"\"\"\n        Return a list of file urls - will return a single item if settings.USE_BUNDLES is True\n        \"\"\"\n        if self.use_bundle:\n            return [self.get_url()]\n        return [bundle_file.file_url for bundle_file in self.files]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a batch instance after exporting a batch of txs.", "response": "def export_batch(self):\n        \"\"\"Returns a batch instance after exporting a batch of txs.\n        \"\"\"\n        batch = self.batch_cls(\n            model=self.model, history_model=self.history_model, using=self.using\n        )\n        if batch.items:\n            try:\n                json_file = self.json_file_cls(batch=batch, path=self.path)\n                json_file.write()\n            except JSONDumpFileError as e:\n                raise TransactionExporterError(e)\n            batch.close()\n            return batch\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(input_dict, environment_dict):\n\n  if environment_dict['currentkeyname'] is None or not seash_global_variables.keys[environment_dict['currentkeyname']]['privatekey']:\n    raise seash_exceptions.UserError(\"Error, must get as an identity with a private key\")\n\n  # Activate secure mode if user did not specify the insecure keyword\n  allow_ssl_insecure = _get_user_argument(input_dict, 'insecure') is not None\n  vesselcount = int(_get_user_argument(input_dict, 'vesselcount'))\n\n  try:\n    vesseltype = _get_user_argument(input_dict, 'type')\n  # User may not have specified a vesseltype\n  except IndexError:\n    vesseltype = None\n\n  if not vesseltype in ['wan', 'lan', 'nat', None]:\n    raise seash_exceptions.UserError(\"Error, unknown vessel type '\"+vesseltype+\"'\")\n\n  client = _connect_to_clearinghouse(environment_dict['currentkeyname'],\n    allow_ssl_insecure)\n\n  # Get the vessels!\n  try:\n    if vesseltype is None:\n      vesseldicts = client.acquire_random_resources(vesselcount)\n    else:\n      vesseldicts = client.acquire_resources(vesseltype, vesselcount)\n\n    _update_targets(vesseldicts, environment_dict)\n  except (seattleclearinghouse_xmlrpc.UnableToAcquireResourcesError, seattleclearinghouse_xmlrpc.NotEnoughCreditsError), e:\n    print str(e)", "response": "Get the vessels from the Clearinghouse."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef release(input_dict, environment_dict):\n  # Activate secure mode if user did not specify the insecure keyword\n  allow_ssl_insecure = _get_user_argument(input_dict, 'insecure') is not None\n\n  # Get the group name to release\n  groupname = environment_dict['currenttarget']\n  nodelist = seash_global_variables.targets[groupname]\n\n  # Get the Clearinghouse vessel handles for each vessel\n  retdict = seash_helper.contact_targets(nodelist, _get_clearinghouse_vessel_handle)\n\n  clearinghouse_vesselhandles = []\n  faillist = []\n  # parse the output so we can print out something intelligible\n  for nodename in retdict:\n\n    if retdict[nodename][0]:\n      clearinghouse_vesselhandles.append(retdict[nodename][1])\n    else:\n      faillist.append(nodename)\n\n  # Release!\n  client = _connect_to_clearinghouse(environment_dict['currentkeyname'],\n    allow_ssl_insecure)\n  client.release_resources(clearinghouse_vesselhandles)\n\n  # Remove each vessel from the targets list\n  removed_nodehandles = seash_global_variables.targets[groupname][:]\n  for handle in removed_nodehandles:\n    for target in seash_global_variables.targets:\n      if handle in seash_global_variables.targets[target]:\n        seash_global_variables.targets[target].remove(handle)", "response": "Releases the specified vessels from the current seash base."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the list of targets that the user can access on.", "response": "def _update_targets(vesseldicts, environment_dict):\n  \"\"\"\n  <Purpose>\n    Connects to the nodes in the vesseldicts and adds them to the list\n    of valid targets.\n\n  <Arguments>\n    vesseldicts:\n        A list of vesseldicts obtained through\n        SeattleClearinghouseClient calls.\n\n  <Side Effects>\n    All valid targets that the user can access on the specified nodes\n    are added to the list of targets.\n\n  <Exceptions>\n    None\n\n  <Returns>\n    None\n  \"\"\"\n  # Compile a list of the nodes that we need to check\n  nodelist = []\n  for vesseldict in vesseldicts:\n    nodeip_port = vesseldict['node_ip']+':'+str(vesseldict['node_port'])\n    if not nodeip_port in nodelist:\n      nodelist.append(nodeip_port)\n\n  # we'll output a message about the new keys later...\n  newidlist = []\n  faillist = []\n\n  # Clear the list so that the user doesn't target vessels acquired from\n  # previous requests when targeting this group\n  seash_global_variables.targets['acquired'] = []\n  print nodelist\n\n  # currently, if I browse more than once, I look up everything again...\n  retdict = seash_helper.contact_targets(\n    nodelist,\n    seash_helper.browse_target,\n    environment_dict['currentkeyname'],\n    'acquired')\n\n  # parse the output so we can print out something intelligible\n  for nodename in retdict:\n    if retdict[nodename][0]:\n      newidlist = newidlist + retdict[nodename][1]\n    else:\n      faillist.append(nodename)\n\n  seash_helper.print_vessel_errors(retdict)\n\n  if len(newidlist) == 0:\n    print \"Could not add any new targets.\"\n  else:\n    print \"Added targets: \"+\", \".join(newidlist)\n\n  if len(seash_global_variables.targets['acquired']) > 0:\n    num_targets = str(len(seash_global_variables.targets['acquired']))\n    print \"Added group 'acquired' with \"+num_targets+\" targets\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_clearinghouse_vessel_handle(vesselhandle):\n  host, portstring, vesselname = vesselhandle.split(':')\n  port = int(portstring)\n\n  # get information about the node's vessels\n  try:\n    nodehandle = nmclient.nmclient_createhandle(host, port,\n      timeout=seash_global_variables.globalseashtimeout)\n\n  except NMClientException,e:\n    return (False, str(e))\n\n  try:\n    # We need to get the nodekey on this vessel\n    vesseldict = nmclient.nmclient_getvesseldict(nodehandle)\n  except NMClientException,e:\n    return (False, str(e))\n  finally:\n    nmclient.nmclient_destroyhandle(nodehandle)\n\n  nodekeystr = rsa.rsa_publickey_to_string(vesseldict['nodekey'])\n  return (True, nodekeystr+':'+vesselname)", "response": "Get the nodekey of a vessel."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nensures key is either in schema s attributes or already set on self.", "response": "def _check_key(self, key):\n        \"\"\"\n        Ensure key is either in schema's attributes or already set on self.\n        \"\"\"\n        self.setup_schema()\n        if key not in self._attrs and key not in self:\n            raise KeyError(key)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef similar(self):\n        if self._similar is None:\n            self._similar = [\n                Artist(artist['ArtistID'], artist['Name'], self._connection)\n                for artist in self._connection.request(\n                    'artistGetSimilarArtists',\n                    {'artistID': self.id},\n                    self._connection.header('artistGetSimilarArtists'))[1]['SimilarArtists']]\n        return iter(self._similar)", "response": "get the similar artists as an iterator over Artist objects"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an iterator over the songs in the artist", "response": "def songs(self):\n        \"\"\"\n        iterator over artist's songs as :class:`Song` objects\n        \"\"\"\n        if self._songs is None:\n            self._songs = [Song.from_response(song, self._connection) for song in\n                           self._connection.request(\n                               'artistGetArtistSongs',\n                               {'artistID': self.id},\n                               self._connection.header('artistGetArtistSongs'))[1]]\n        return iter(self._songs)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef query_params(self, params, key, def_value, short_hand=None):\n    if key not in params and short_hand:\n        # value is associated with shorthand, move to key\n        params[key] = params.get(short_hand, def_value)\n        del params[short_hand]\n    elif key not in params and not short_hand:\n        params[key] = def_value\n    elif key in params:\n        # key is there, also possibly shorthand\n        # assume def value at this point is not needed\n        if short_hand in params:\n            del params[short_hand]\n    return params", "response": "Updates the params dict to use the key and value."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndownload a HiRISE EDR set of. IMG files to the CWD", "response": "def hirise_edr(self, pid, chunk_size=1024*1024):\n        \"\"\"\n        Download a HiRISE EDR set of .IMG files to the CWD\n\n        You must know the full id to specifiy the filter to use, ie:\n        PSP_XXXXXX_YYYY         will download every EDR IMG file available\n        PSP_XXXXXX_YYYY_R       will download every EDR RED filter IMG file\n        PSP_XXXXXX_YYYY_BG12_0  will download only the BG12_0\n\n        As a wild card is auto applied to the end of the provided pid\n\n        pid: product ID of the CTX EDR, partial IDs ok\n        chunk_size: Chunk size in bytes to use in download\n        \"\"\"\n        productid = \"{}*\".format(pid)\n\n        query = {\"target\"    : \"mars\",\n                 \"query\"     : \"product\",\n                 \"results\"   : \"f\",\n                 \"output\"    : \"j\",\n                 \"pt\"        : \"EDR\",\n                 \"iid\"       : \"HiRISE\",\n                 \"ihid\"      : \"MRO\",\n                 \"productid\" : productid}\n\n        # Query the ODE\n        products = query_ode(self.ode_url, query)\n        # Validate query results with conditions for this particular query\n        if len(products) > 30:\n            print(\"Error: Too many products selected for in query, Make PID more specific\")\n            sys.exit(1)\n        if not isinstance(products, list):\n            print(\"Error: Too few responses from server to be a full HiRISE EDR, \")\n        else:\n            # proceed to download\n            for product in products:\n                download_edr_img_files(product, self.https, chunk_size)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nperform a mostly arbitrary meta_data query and dump to std out", "response": "def get_meta(self, **kwargs):\n        \"\"\"\n        Perform a mostly arbitrary meta_data query and dump to std out\n        :param kwargs:\n        :return:\n        \"\"\"\n        query = kwargs\n        # filters\n        query = query_params(query, 'productid', None, short_hand='pid')\n        query = query_params(query, 'query', 'product')\n        query = query_params(query, 'results', 'm')\n        query = query_params(query, 'output', 'j')\n        return query_ode(self.ode_url, query=query)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsuggests mean accumulation rate for each date in the core age - depth data.", "response": "def suggest_accumulation_rate(chron):\n    \"\"\"From core age-depth data, suggest mean accumulation rate (cm/y)\n    \"\"\"\n    # Follow's Bacon's method @ Bacon.R ln 30 - 44\n    # Suggested round vals.\n    sugg = np.tile([1, 2, 5], (4, 1)) * np.reshape(np.repeat([0.1, 1.0, 10, 100], 3), (4, 3))\n    # Get ballpark accumulation rates, uncalibrated dates.\n    ballpacc = stats.linregress(x=chron.depth, y=chron.age * 1.1).slope\n    ballpacc = np.abs(sugg - ballpacc)\n    sugg = sugg.flat[ballpacc.argmin()]  # Suggest rounded acc.rate with lowest abs diff.\n    return sugg"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nverifying NTFS filesystem signature at offset 0x03.", "response": "def detect(self, filename, offset, standalone=False):\n        \"\"\"Verifies NTFS filesystem signature.\n\n        Returns:\n            bool: True if filesystem signature at offset 0x03 \\\n            matches 'NTFS    ', False otherwise.\n        \"\"\"\n        r = RawStruct(\n            filename=filename,\n            offset=offset + SIG_OFFSET,\n            length=SIG_SIZE)\n\n        oem_id = r.data\n\n        if oem_id == b\"NTFS    \":\n            return True\n\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load(cls, v):\n        if v is None:\n            return []\n        if isinstance(v, list):\n            return [ Action(s) for s in v ]\n        elif isinstance(v, str):\n            return [Action(v)]\n        else:\n            raise ParseError(\"Couldn't parse action: %r\" % v)", "response": "Load the action from configuration"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nloads Automatons from a stream", "response": "def load_stream(cls, st):\n        \"\"\"Load Automatons from a stream\"\"\"\n        y = yaml.load(st)\n        return [ Automaton(k, v) for k, v in y.iteritems() ]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef make_dot(self, filename_or_stream, auts):\n        if isinstance(filename_or_stream, str):\n            stream = file(filename_or_stream, 'w')\n        else:\n            stream = filename_or_stream\n        \n        dot = DotFile(stream)\n        \n        for aut in auts:\n            dot.start(aut.name)\n            dot.node('shape=Mrecord width=1.5')\n    \n            for st in aut.states:\n                label = st.name\n                if st.entering:\n                    label += '|%s' % '\\\\l'.join(str(st) for st in st.entering)\n                if st.leaving:\n                    label += '|%s' % '\\\\l'.join(str(st) for st in st.leaving)\n                label = '{%s}' % label\n                    \n                dot.state(st.name, label=label)\n                \n            for st in aut.states:\n                for tr in st.transitions:\n                    dot.transition(tr.s_from.name, tr.s_to.name, tr.when)\n            \n            dot.end()\n            \n        dot.finish()", "response": "Create a graphviz. dot representation of the automaton."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load(self, config):\n        self.config = config\n        \n        if 'start' not in self.config:\n            raise ParseError('missing start entry')\n        if 'states' not in self.config:\n            raise ParseError('missing states entry')\n        if 'transitions' not in self.config:\n            raise ParseError('missing transitions entry')\n\n        for state, val in self.config['states'].iteritems():\n            state = State(state)\n            state.entering = Action.load(val.get('entering'))\n            state.leaving = Action.load(val.get('leaving'))\n            \n            self.states.add(state)\n            \n        self.start = self.states[self.config['start']]\n        \n        for transition, val in self.config['transitions'].iteritems():\n            if '->' in transition:\n                # from->to\n                lft, rgt = transition.split('->')\n                if lft == '*':\n                    sfroms = self.states.keys()\n                else:\n                    sfroms = lft.split(',')\n                if rgt == '*':\n                    stos = self.states.keys()\n                else:\n                    stos = rgt.split(',')\n                pairs = ((f, t) for f in sfroms for t in stos)\n            else:\n                # self transition 'from1,from2' = from1->from1, from2->from2\n                if transition == '*':\n                    ss = self.states.keys()\n                else:\n                    ss = transition.split(',')\n                pairs = ((x, x) for x in ss)\n                \n            for sfrom, sto in pairs:\n                if sfrom not in self.states:\n                    raise ParseError(\"Could find state %r\" % sfrom)\n                if sto not in self.states:\n                    raise ParseError(\"Could find state %r\" % sto)\n\n                s_from = self.states[sfrom]\n                s_to = self.states[sto]\n                \n                if not isinstance(val, list):\n                    val = [val]\n                for v in val:\n                    when = v['when']\n                    actions = Action.load(v.get('actions'))\n                    transition = Transition(s_from, s_to, Condition(when), actions)\n                    s_from.transitions.append(transition)", "response": "Load the configuration and return the state object."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsplits the path up into useful parts bucket obj_key", "response": "def _parse_url(url=None):\n    \"\"\"Split the path up into useful parts: bucket, obj_key\"\"\"\n    if url is None:\n        return ('', '')\n\n    scheme, netloc, path, _, _ = parse.urlsplit(url)\n\n    if scheme != 's3':\n        raise InvalidURL(url, \"URL scheme must be s3://\")\n\n    if path and not netloc:\n        raise InvalidURL(url)\n\n    return netloc, path[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, url=None, delimiter=\"/\"):\n        params = {'Delimiter': delimiter}\n        bucket, obj_key = _parse_url(url)\n\n        if bucket:\n            params['Bucket'] = bucket\n        else:\n            return self.call(\"ListBuckets\", response_data_key=\"Buckets\")\n\n        if obj_key:\n            params['Prefix'] = obj_key\n\n        objects = self.call(\"ListObjects\", response_data_key=\"Contents\",\n                            **params)\n        if objects:\n            for obj in objects:\n                obj['url'] = \"s3://{0}/{1}\".format(bucket, obj['Key'])\n\n        return objects", "response": "Get all objects in the specified url."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a bucket directory or empty file.", "response": "def create(self, url):\n        \"\"\"Create a bucket, directory, or empty file.\"\"\"\n        bucket, obj_key = _parse_url(url)\n\n        if not bucket:\n            raise InvalidURL(url,\n                             \"You must specify a bucket and (optional) path\")\n\n        if obj_key:\n            target = \"/\".join((bucket, obj_key))\n        else:\n            target = bucket\n\n        return self.call(\"CreateBucket\", bucket=target)"}
