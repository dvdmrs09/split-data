{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninferring the vegalite typecode from an array - like input", "response": "def infer_vegalite_type(data, ordinal_threshold=6):\n    \"\"\"\n    From an array-like input, infer the correct vega typecode\n    ('ordinal', 'nominal', 'quantitative', or 'temporal')\n\n    Parameters\n    ----------\n    data: Numpy array or Pandas Series\n        data for which the type will be inferred\n    ordinal_threshold: integer (default: 0)\n        integer data will result in a 'quantitative' type, unless the\n        number of unique values is smaller than ordinal_threshold.\n\n    Adapted from code at http://github.com/altair-viz/altair/\n    Licence: BSD-3\n    \"\"\"\n    # infer based on the dtype of the input\n    typ = pd_infer_dtype(data, **_infer_dtype_kwds)\n\n    # TODO: Once this returns 'O', please update test_select_x and test_select_y in test_api.py\n\n    if typ in ('mixed-integer', 'integer'):\n        if ordinal_threshold and pd.Series(data).nunique() <= ordinal_threshold:\n            return 'ordinal'\n        else:\n            return 'quantitative'\n    elif typ in ('floating', 'mixed-integer-float', 'complex'):\n        return 'quantitative'\n    elif typ in ('string', 'bytes', 'categorical', 'boolean', 'mixed', 'unicode', 'object'):\n        return 'nominal'\n    elif typ in ('datetime', 'datetime64', 'timedelta',\n                 'timedelta64', 'date', 'time', 'period'):\n        return 'temporal'\n    else:\n        warnings.warn(\"I don't know how to infer vegalite type from '{0}'.  \"\n                      \"Defaulting to nominal.\".format(typ))\n        return 'nominal'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef unpivot_frame(frame, x=None, y=None,\n                  var_name='variable', value_name='value'):\n    \"\"\"Unpivot a dataframe for use with Vega/Vega-Lite\n\n    The input is a frame with any number of columns,\n    output is a frame with three columns: x value, y values,\n    and variable names.\n    \"\"\"\n    if x is None:\n        cols = frame.columns\n        frame = frame.reset_index()\n        x = (set(frame.columns) - set(cols)).pop()\n    # frame.melt doesn't properly check for nonexisting columns, so we\n    # start by indexing here. Tuples of column names also need to be\n    # converted to lists for checking indexing\n    if isinstance(x, tuple):\n        x = list(x)\n    if isinstance(y, tuple):\n        y = list(y)\n    if x is not None:\n        _ = frame[x] # noqa\n    if y is not None:\n        _ = frame[y] # noqa\n    return frame.melt(id_vars=x, value_vars=y,\n                      var_name=var_name, value_name=value_name)", "response": "Unpivot a dataframe for use with Vega - Lite"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef validate_aggregation(agg):\n    if agg is None:\n        return agg\n    supported_aggs = ['mean', 'sum', 'median', 'min', 'max', 'count']\n    numpy_aggs = {getattr(np, a): a\n                  for a in ['mean', 'sum', 'median', 'min', 'max']}\n    builtin_aggs = {min: 'min', max: 'max', sum: 'sum'}\n\n    agg = numpy_aggs.get(agg, agg)\n    agg = builtin_aggs.get(agg, agg)\n\n    if agg not in supported_aggs:\n        raise ValueError(\"Unrecognized Vega-Lite aggregation: {0}\".format(agg))\n\n    return agg", "response": "Validate an aggregation for use in Vega - Lite."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef version(path):\n    version_file = read(path)\n    version_match = re.search(r\"\"\"^__version__ = ['\"]([^'\"]*)['\"]\"\"\",\n                              version_file, re.M)\n    if version_match:\n        return version_match.group(1)\n    raise RuntimeError(\"Unable to find version string.\")", "response": "Obtain the packge version from a python file e. g. pkg / __init__. py\n    See <https://packaging. python. org / en / latest / single_source_version. html >"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef scatter_matrix(frame, c=None, s=None, figsize=None, dpi=72.0, **kwds):\n    if kwds:\n        warnings.warn(\n            \"Unrecognized keywords in pdvega.scatter_matrix: {0}\"\n            \"\".format(list(kwds.keys()))\n        )\n\n    cols = [\n        col\n        for col in frame.columns\n        if col not in [c, s]\n        if infer_vegalite_type(frame[col], ordinal_threshold=0) == \"quantitative\"\n    ]\n\n    spec = {\n        \"$schema\": \"https://vega.github.io/schema/vega-lite/v2.json\",\n        \"repeat\": {\"row\": cols, \"column\": cols[::-1]},\n        \"spec\": {\n            \"mark\": \"point\",\n            \"selection\": {\n                \"brush\": {\n                    \"type\": \"interval\",\n                    \"resolve\": \"union\",\n                    \"on\": \"[mousedown[event.shiftKey], window:mouseup] > window:mousemove!\",\n                    \"translate\": \"[mousedown[event.shiftKey], window:mouseup] > window:mousemove!\",\n                    \"zoom\": \"wheel![event.shiftKey]\",\n                },\n                \"grid\": {\n                    \"type\": \"interval\",\n                    \"resolve\": \"global\",\n                    \"bind\": \"scales\",\n                    \"translate\": \"[mousedown[!event.shiftKey], window:mouseup] > window:mousemove!\",\n                    \"zoom\": \"wheel![!event.shiftKey]\",\n                },\n            },\n            \"encoding\": {\n                \"x\": {\"field\": {\"repeat\": \"column\"}, \"type\": \"quantitative\"},\n                \"y\": {\"field\": {\"repeat\": \"row\"}, \"type\": \"quantitative\"},\n                \"color\": {\"condition\": {\"selection\": \"brush\"}, \"value\": \"grey\"},\n            },\n        },\n    }\n\n    if figsize is not None:\n        width_inches, height_inches = figsize\n        spec[\"spec\"][\"width\"] = 0.8 * dpi * width_inches / len(cols)\n        spec[\"spec\"][\"height\"] = 0.8 * dpi * height_inches / len(cols)\n\n    if s is not None:\n        spec[\"spec\"][\"encoding\"][\"size\"] = {\n            \"field\": s, \"type\": infer_vegalite_type(frame[s])\n        }\n\n    cond = spec[\"spec\"][\"encoding\"][\"color\"][\"condition\"]\n    if c is None:\n        cond[\"value\"] = \"steelblue\"\n    else:\n        cond[\"field\"] = c\n        cond[\"type\"] = infer_vegalite_type(frame[c])\n\n    chart = alt.Chart().from_dict(spec)\n    chart.data = frame\n    return chart", "response": "Draw a scatter matrix of the current language."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngenerating an Andrews curves visualization for visualising clusters of a single class.", "response": "def andrews_curves(\n    data, class_column, samples=200, alpha=None, width=450, height=300, **kwds\n):\n    \"\"\"\n    Generates an Andrews curves visualization for visualising clusters of\n    multivariate data.\n\n    Andrews curves have the functional form:\n\n    f(t) = x_1/sqrt(2) + x_2 sin(t) + x_3 cos(t) +\n           x_4 sin(2t) + x_5 cos(2t) + ...\n\n    Where x coefficients correspond to the values of each dimension and t is\n    linearly spaced between -pi and +pi. Each row of frame then corresponds to\n    a single curve.\n\n    Parameters:\n    -----------\n    data : DataFrame\n        Data to be plotted, preferably normalized to (0.0, 1.0)\n    class_column : string\n        Name of the column containing class names\n    samples : integer\n        Number of points to plot in each curve\n    alpha: float, optional\n        The transparency of the lines\n    width : int, optional\n        the width of the plot in pixels\n    height : int, optional\n        the height of the plot in pixels\n    **kwds: keywords\n        Additional options\n\n    Returns:\n    --------\n    chart: alt.Chart object\n\n    \"\"\"\n    if kwds:\n        warnings.warn(\n            \"Unrecognized keywords in pdvega.andrews_curves(): {0}\"\n            \"\".format(list(kwds.keys()))\n        )\n\n    t = np.linspace(-np.pi, np.pi, samples)\n    vals = data.drop(class_column, axis=1).values.T\n\n    curves = np.outer(vals[0], np.ones_like(t))\n    for i in range(1, len(vals)):\n        ft = ((i + 1) // 2) * t\n        if i % 2 == 1:\n            curves += np.outer(vals[i], np.sin(ft))\n        else:\n            curves += np.outer(vals[i], np.cos(ft))\n\n    df = pd.DataFrame(\n        {\n            \"t\": np.tile(t, curves.shape[0]),\n            \"sample\": np.repeat(np.arange(curves.shape[0]), curves.shape[1]),\n            \" \": curves.ravel(),\n            class_column: np.repeat(data[class_column], samples),\n        }\n    )\n\n    chart = alt.Chart(df).properties(width=width, height=height).mark_line()\n    chart = chart.encode(\n        x=alt.X(field=\"t\", type=\"quantitative\"),\n        y=alt.Y(field=\" \", type=\"quantitative\"),\n        color=alt.Color(field=class_column, type=infer_vegalite_type(df[class_column])),\n        detail=alt.Detail(field='sample', type=\"quantitative\")\n    )\n\n    if alpha is None and df[class_column].nunique() > 20:\n        alpha = 0.5\n\n    if alpha is not None:\n        assert 0 <= alpha <= 1\n        return chart.encode(opacity=alt.value(alpha))\n\n    return chart"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparallel coordinates plotting. Parameters ---------- frame: DataFrame class_column: str Column name containing class names cols: list, optional A list of column names to use alpha: float, optional The transparency of the lines interactive : bool, optional if True (default) then produce an interactive plot width : int, optional the width of the plot in pixels height : int, optional the height of the plot in pixels var_name : string, optional the legend title value_name : string, optional the y-axis label Returns ------- chart: alt.Chart object The altair representation of the plot. See Also -------- pandas.plotting.parallel_coordinates : matplotlib version of this routine", "response": "def parallel_coordinates(\n    data,\n    class_column,\n    cols=None,\n    alpha=None,\n    width=450,\n    height=300,\n    interactive=True,\n    var_name=\"variable\",\n    value_name=\"value\",\n    **kwds\n):\n    \"\"\"\n    Parallel coordinates plotting.\n\n    Parameters\n    ----------\n    frame: DataFrame\n    class_column: str\n        Column name containing class names\n    cols: list, optional\n        A list of column names to use\n    alpha: float, optional\n        The transparency of the lines\n    interactive : bool, optional\n        if True (default) then produce an interactive plot\n    width : int, optional\n        the width of the plot in pixels\n    height : int, optional\n        the height of the plot in pixels\n    var_name : string, optional\n        the legend title\n    value_name : string, optional\n        the y-axis label\n\n    Returns\n    -------\n    chart: alt.Chart object\n        The altair representation of the plot.\n\n    See Also\n    --------\n    pandas.plotting.parallel_coordinates : matplotlib version of this routine\n    \"\"\"\n    if kwds:\n        warnings.warn(\n            \"Unrecognized keywords in pdvega.scatter_matrix: {0}\"\n            \"\".format(list(kwds.keys()))\n        )\n\n    # Transform the dataframe to be used in Vega-Lite\n    if cols is not None:\n        data = data[list(cols) + [class_column]]\n    cols = data.columns\n    df = data.reset_index()\n    index = (set(df.columns) - set(cols)).pop()\n    assert index in df.columns\n    df = df.melt([index, class_column], var_name=var_name, value_name=value_name)\n\n    chart = alt.Chart(df).properties(width=width, height=height)\n    chart = chart.mark_line().encode(\n         x=alt.X(field=var_name, type=infer_vegalite_type(df[var_name])),\n         y=alt.Y(field=value_name, type=infer_vegalite_type(df[value_name])),\n         color=alt.Color(field=class_column, type=infer_vegalite_type(df[class_column])),\n         detail=alt.Detail(field=index, type=infer_vegalite_type(df[index]))\n    )\n\n    if alpha is None and df[class_column].nunique() > 20:\n        alpha = 0.3\n\n    if alpha is not None:\n        assert 0 <= alpha <= 1\n        return chart.encode(opacity=alt.value(alpha))\n    return chart"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nlag plot for time series.", "response": "def lag_plot(data, lag=1, kind=\"scatter\", **kwds):\n    \"\"\"Lag plot for time series.\n\n    Parameters\n    ----------\n    data: pandas.Series\n        the time series to plot\n    lag: integer\n        The lag of the scatter plot, default=1\n    kind: string\n        The kind of plot to use (e.g. 'scatter', 'line')\n    **kwds:\n        Additional keywords passed to data.vgplot.scatter\n\n    Returns\n    -------\n    chart: alt.Chart object\n    \"\"\"\n    if lag != int(lag) or int(lag) <= 0:\n        raise ValueError(\"lag must be a positive integer\")\n    lag = int(lag)\n\n    values = data.values\n    y1 = \"y(t)\"\n    y2 = \"y(t + {0})\".format(lag)\n    lags = pd.DataFrame({y1: values[:-lag].T.ravel(), y2: values[lag:].T.ravel()})\n\n    if isinstance(data, pd.DataFrame):\n        lags[\"variable\"] = np.repeat(data.columns, lags.shape[0] / data.shape[1])\n        kwds[\"c\"] = \"variable\"\n\n    return lags.vgplot(kind=kind, x=y1, y=y2, **kwds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dict_hash(dct):\n    dct_s = json.dumps(dct, sort_keys=True)\n\n    try:\n        m = md5(dct_s)\n    except TypeError:\n        m = md5(dct_s.encode())\n\n    return m.hexdigest()", "response": "Return a hash of the contents of a dictionary"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nexecute a code block and return the last line of the code block.", "response": "def exec_then_eval(code, namespace=None):\n    \"\"\"Exec a code block & return evaluation of the last line\"\"\"\n    # TODO: make this less brittle.\n    namespace = namespace or {}\n\n    block = ast.parse(code, mode='exec')\n    last = ast.Expression(block.body.pop().value)\n\n    exec(compile(block, '<string>', mode='exec'), namespace)\n    return eval(compile(last, '<string>', mode='eval'), namespace)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nimports the object given by clsname.", "response": "def import_obj(clsname, default_module=None):\n    \"\"\"\n    Import the object given by clsname.\n    If default_module is specified, import from this module.\n    \"\"\"\n    if default_module is not None:\n        if not clsname.startswith(default_module + '.'):\n            clsname = '{0}.{1}'.format(default_module, clsname)\n    mod, clsname = clsname.rsplit('.', 1)\n    mod = importlib.import_module(mod)\n    try:\n        obj = getattr(mod, clsname)\n    except AttributeError:\n        raise ImportError('Cannot import {0} from {1}'.format(clsname, mod))\n    return obj"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nstrip the vega - lite extension from filename", "response": "def strip_vl_extension(filename):\n    \"\"\"Strip the vega-lite extension (either vl.json or json) from filename\"\"\"\n    for ext in ['.vl.json', '.json']:\n        if filename.endswith(ext):\n            return filename[:-len(ext)]\n    else:\n        return filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prev_this_next(it, sentinel=None):\n    i1, i2, i3 = tee(it, 3)\n    next(i3, None)\n    return zip(chain([sentinel], i1), i2, chain(i3, [sentinel]))", "response": "Utility to return ( prev this next ) tuples from an iterator"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget TurboCARTO CartoCSS based on input parameters", "response": "def get_scheme_cartocss(column, scheme_info):\n    \"\"\"Get TurboCARTO CartoCSS based on input parameters\"\"\"\n    if 'colors' in scheme_info:\n        color_scheme = '({})'.format(','.join(scheme_info['colors']))\n    else:\n        color_scheme = 'cartocolor({})'.format(scheme_info['name'])\n    if not isinstance(scheme_info['bins'], int):\n        bins = ','.join(str(i) for i in scheme_info['bins'])\n    else:\n        bins = scheme_info['bins']\n    bin_method = scheme_info['bin_method']\n    comparison = ', {}'.format(BinMethod.mapping.get(bin_method, '>='))\n    return ('ramp([{column}], {color_scheme}, '\n            '{bin_method}({bins}){comparison})').format(\n                column=column,\n                color_scheme=color_scheme,\n                bin_method=bin_method,\n                bins=bins,\n                comparison=comparison)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef custom(colors, bins=None, bin_method=BinMethod.quantiles):\n    return {\n        'colors': colors,\n        'bins': bins if bins is not None else len(colors),\n        'bin_method': bin_method,\n    }", "response": "Create a custom scheme."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a custom scheme based on CARTOColors.", "response": "def scheme(name, bins, bin_method='quantiles'):\n    \"\"\"Return a custom scheme based on CARTOColors.\n\n    Args:\n        name (str): Name of a CARTOColor.\n        bins (int or iterable): If an `int`, the number of bins for classifying\n          data. CARTOColors have 7 bins max for quantitative data, and 11 max\n          for qualitative data. If `bins` is a `list`, it is the upper range\n          for classifying data. E.g., `bins` can be of the form ``(10, 20, 30,\n          40, 50)``.\n        bin_method (str, optional): One of methods in :obj:`BinMethod`.\n          Defaults to ``quantiles``. If `bins` is an interable, then that is\n          the bin method that will be used and this will be ignored.\n\n    .. Warning::\n\n       Input types are particularly sensitive in this function, and little\n       feedback is given for errors. ``name`` and ``bin_method`` arguments\n       are case-sensitive.\n\n    \"\"\"\n    return {\n        'name': name,\n        'bins': bins,\n        'bin_method': (bin_method if isinstance(bins, int) else ''),\n    }"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _is_authenticated(self):\n        if not self.auth_api_client.is_valid_api_key():\n            raise CartoException(\n                'Cannot authenticate user `{}`. Check credentials.'.format(\n                    self.creds.username()))", "response": "Checks if credentials allow for authenticated carto access"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads a table from CARTO into a pandas DataFrames.", "response": "def read(self, table_name, limit=None, decode_geom=False, shared_user=None, retry_times=3):\n        \"\"\"Read a table from CARTO into a pandas DataFrames.\n\n        Args:\n            table_name (str): Name of table in user's CARTO account.\n            limit (int, optional): Read only `limit` lines from\n                `table_name`. Defaults to ``None``, which reads the full table.\n            decode_geom (bool, optional): Decodes CARTO's geometries into a\n              `Shapely <https://github.com/Toblerity/Shapely>`__\n              object that can be used, for example, in `GeoPandas\n              <http://geopandas.org/>`__.\n            shared_user (str, optional): If a table has been shared with you,\n              specify the user name (schema) who shared it.\n            retry_times (int, optional): If the read call is rate limited,\n              number of retries to be made\n\n        Returns:\n            pandas.DataFrame: DataFrame representation of `table_name` from\n            CARTO.\n\n        Example:\n            .. code:: python\n\n                import cartoframes\n                cc = cartoframes.CartoContext(BASEURL, APIKEY)\n                df = cc.read('acadia_biodiversity')\n        \"\"\"\n        # choose schema (default user - org or standalone - or shared)\n        schema = 'public' if not self.is_org else (\n            shared_user or self.creds.username())\n\n        dataset = Dataset(self, table_name, schema)\n        return dataset.download(limit, decode_geom, retry_times)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlisting all tables in user s CARTO account", "response": "def tables(self):\n        \"\"\"List all tables in user's CARTO account\n\n        Returns:\n            :obj:`list` of :py:class:`Table <cartoframes.analysis.Table>`\n\n        \"\"\"\n        datasets = DatasetManager(self.auth_client).filter(\n            show_table_size_and_row_count='false',\n            show_table='false',\n            show_stats='false',\n            show_likes='false',\n            show_liked='false',\n            show_permission='false',\n            show_uses_builder_features='false',\n            show_synchronization='false',\n            load_totals='false')\n        return [Table.from_dataset(d) for d in datasets]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef write(self, df, table_name, temp_dir=CACHE_DIR, overwrite=False,\n              lnglat=None, encode_geom=False, geom_col=None, **kwargs):\n        \"\"\"Write a DataFrame to a CARTO table.\n\n        Examples:\n            Write a pandas DataFrame to CARTO.\n\n            .. code:: python\n\n                cc.write(df, 'brooklyn_poverty', overwrite=True)\n\n            Scrape an HTML table from Wikipedia and send to CARTO with content\n            guessing to create a geometry from the country column. This uses\n            a CARTO Import API param `content_guessing` parameter.\n\n            .. code:: python\n\n                url = 'https://en.wikipedia.org/wiki/List_of_countries_by_life_expectancy'\n                # retrieve first HTML table from that page\n                df = pd.read_html(url, header=0)[0]\n                # send to carto, let it guess polygons based on the 'country'\n                #   column. Also set privacy to 'public'\n                cc.write(df, 'life_expectancy',\n                         content_guessing=True,\n                         privacy='public')\n                cc.map(layers=Layer('life_expectancy',\n                                    color='both_sexes_life_expectancy'))\n\n        Args:\n            df (pandas.DataFrame): DataFrame to write to ``table_name`` in user\n                CARTO account\n            table_name (str): Table to write ``df`` to in CARTO.\n            temp_dir (str, optional): Directory for temporary storage of data\n                that is sent to CARTO. Defaults are defined by `appdirs\n                <https://github.com/ActiveState/appdirs/blob/master/README.rst>`__.\n            overwrite (bool, optional): Behavior for overwriting ``table_name``\n                if it exits on CARTO. Defaults to ``False``.\n            lnglat (tuple, optional): lng/lat pair that can be used for\n                creating a geometry on CARTO. Defaults to ``None``. In some\n                cases, geometry will be created without specifying this. See\n                CARTO's `Import API\n                <https://carto.com/developers/import-api/reference/#tag/Standard-Tables>`__\n                for more information.\n            encode_geom (bool, optional): Whether to write `geom_col` to CARTO\n                as `the_geom`.\n            geom_col (str, optional): The name of the column where geometry\n                information is stored. Used in conjunction with `encode_geom`.\n            **kwargs: Keyword arguments to control write operations. Options\n                are:\n\n                - `compression` to set compression for files sent to CARTO.\n                  This will cause write speedups depending on the dataset.\n                  Options are ``None`` (no compression, default) or ``gzip``.\n                - Some arguments from CARTO's Import API. See the `params\n                  listed in the documentation\n                  <https://carto.com/developers/import-api/reference/#tag/Standard-Tables>`__\n                  for more information. For example, when using\n                  `content_guessing='true'`, a column named 'countries' with\n                  country names will be used to generate polygons for each\n                  country. Another use is setting the privacy of a dataset. To\n                  avoid unintended consequences, avoid `file`, `url`, and other\n                  similar arguments.\n\n        Returns:\n            :py:class:`Dataset <cartoframes.datasets.Dataset>`\n\n        .. note::\n            DataFrame indexes are changed to ordinary columns. CARTO creates\n            an index called `cartodb_id` for every table that runs from 1 to\n            the length of the DataFrame.\n        \"\"\"  # noqa\n        tqdm.write('Params: encode_geom, geom_col and everything in kwargs are deprecated and not being used any more')\n        dataset = Dataset(self, table_name, df=df)\n\n        if_exists = Dataset.FAIL\n        if overwrite:\n            if_exists = Dataset.REPLACE\n\n        dataset = dataset.upload(with_lonlat=lnglat, if_exists=if_exists)\n\n        tqdm.write('Table successfully written to CARTO: {table_url}'.format(\n            table_url=utils.join_url(self.creds.base_url(),\n                                     'dataset',\n                                     dataset.table_name)))\n\n        return dataset", "response": "Write a pandas DataFrame to a CARTO table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_privacy(self, table_name):\n        ds_manager = DatasetManager(self.auth_client)\n        try:\n            dataset = ds_manager.get(table_name)\n            return dataset.privacy.lower()\n        except NotFoundException:\n            return None", "response": "gets current privacy of a table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nupdate the privacy of a dataset", "response": "def _update_privacy(self, table_name, privacy):\n        \"\"\"Updates the privacy of a dataset\"\"\"\n        ds_manager = DatasetManager(self.auth_client)\n        dataset = ds_manager.get(table_name)\n        dataset.privacy = privacy\n        dataset.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes a table in user s CARTO account.", "response": "def delete(self, table_name):\n        \"\"\"Delete a table in user's CARTO account.\n\n        Args:\n            table_name (str): Name of table to delete\n\n        Returns:\n            bool: `True` if table is removed\n\n        \"\"\"\n        dataset = Dataset(self, table_name)\n        deleted = dataset.delete()\n        if deleted:\n            return deleted\n\n        raise CartoException('''The table `{}` doesn't exist'''.format(table_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npull the result from an arbitrary SELECT SQL query from a CARTO account and return a pandas DataFrame.", "response": "def fetch(self, query, decode_geom=False):\n        \"\"\"Pull the result from an arbitrary SELECT SQL query from a CARTO account\n        into a pandas DataFrame.\n\n        Args:\n            query (str): SELECT query to run against CARTO user database. This data\n              will then be converted into a pandas DataFrame.\n            decode_geom (bool, optional): Decodes CARTO's geometries into a\n              `Shapely <https://github.com/Toblerity/Shapely>`__\n              object that can be used, for example, in `GeoPandas\n              <http://geopandas.org/>`__.\n\n        Returns:\n            pandas.DataFrame: DataFrame representation of query supplied.\n            Pandas data types are inferred from PostgreSQL data types.\n            In the case of PostgreSQL date types, dates are attempted to be\n            converted, but on failure a data type 'object' is used.\n\n        Examples:\n            This query gets the 10 highest values from a table and\n            returns a dataframe.\n\n            .. code:: python\n\n                topten_df = cc.query(\n                    '''\n                      SELECT * FROM\n                      my_table\n                      ORDER BY value_column DESC\n                      LIMIT 10\n                    '''\n                )\n\n            This query joins points to polygons based on intersection, and\n            aggregates by summing the values of the points in each polygon. The\n            query returns a dataframe, with a geometry column that contains\n            polygons.\n\n            .. code:: python\n\n                points_aggregated_to_polygons = cc.query(\n                    '''\n                      SELECT polygons.*, sum(points.values)\n                      FROM polygons JOIN points\n                      ON ST_Intersects(points.the_geom, polygons.the_geom)\n                      GROUP BY polygons.the_geom, polygons.cartodb_id\n                    ''',\n                    decode_geom=True\n                )\n\n        \"\"\"\n        copy_query = 'COPY ({query}) TO stdout WITH (FORMAT csv, HEADER true)'.format(query=query)\n        query_columns = get_columns(self, query)\n\n        result = recursive_read(self, copy_query)\n        df_types = dtypes(query_columns, exclude_dates=True)\n\n        df = pd.read_csv(result, dtype=df_types,\n                         parse_dates=date_columns_names(query_columns),\n                         true_values=['t'],\n                         false_values=['f'],\n                         index_col='cartodb_id' if 'cartodb_id' in df_types.keys() else False,\n                         converters={'the_geom': lambda x: _decode_geom(x) if decode_geom else x})\n\n        if decode_geom:\n            df.rename({'the_geom': 'geometry'}, axis='columns', inplace=True)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\npulling the result from an arbitrary SQL SELECT query from a CARTO account into a pandas DataFrame.", "response": "def query(self, query, table_name=None, decode_geom=False, is_select=None):\n        \"\"\"Pull the result from an arbitrary SQL SELECT query from a CARTO account\n        into a pandas DataFrame. This is the default behavior, when `is_select=True`\n\n        Can also be used to perform database operations (creating/dropping tables,\n        adding columns, updates, etc.). In this case, you have to explicitly\n        specify `is_select=False`\n\n        This method is a helper for the `CartoContext.fetch` and `CartoContext.execute`\n        methods. We strongly encourage you to use any of those methods depending on the\n        type of query you want to run. If you want to get the results of a `SELECT` query\n        into a pandas DataFrame, then use `CartoContext.fetch`. For any other query that\n        performs an operation into the CARTO database, use `CartoContext.execute`\n\n        Args:\n            query (str): Query to run against CARTO user database. This data\n              will then be converted into a pandas DataFrame.\n            table_name (str, optional): If set (and `is_select=True`), this will create a new\n              table in the user's CARTO account that is the result of the SELECT\n              query provided. Defaults to None (no table created).\n            decode_geom (bool, optional): Decodes CARTO's geometries into a\n              `Shapely <https://github.com/Toblerity/Shapely>`__\n              object that can be used, for example, in `GeoPandas\n              <http://geopandas.org/>`__. It only works for SELECT queries when `is_select=True`\n            is_select (bool, optional): This argument has to be set depending on the query\n              performed. True for SELECT queries, False for any other query.\n              For the case of a SELECT SQL query (`is_select=True`) the result will be stored into a\n              pandas DataFrame.\n              When an arbitrary SQL query (`is_select=False`) it will perform a database\n              operation (UPDATE, DROP, INSERT, etc.)\n              By default `is_select=None` that means that the method will return a dataframe if\n              the `query` starts with a `select` clause, otherwise it will just execute the query\n              and return `None`\n\n        Returns:\n            pandas.DataFrame: When `is_select=True` and the query is actually a SELECT query\n            this method returns a pandas DataFrame representation of query supplied otherwise\n            returns None.\n            Pandas data types are inferred from PostgreSQL data types.\n            In the case of PostgreSQL date types, dates are attempted to be\n            converted, but on failure a data type 'object' is used.\n\n        Raises:\n            CartoException: If there's any error when executing the query\n\n        Examples:\n            Query a table in CARTO and write a new table that is result of\n            query. This query gets the 10 highest values from a table and\n            returns a dataframe, as well as creating a new table called\n            'top_ten' in the CARTO account.\n\n            .. code:: python\n\n                topten_df = cc.query(\n                    '''\n                      SELECT * FROM\n                      my_table\n                      ORDER BY value_column DESC\n                      LIMIT 10\n                    ''',\n                    table_name='top_ten'\n                )\n\n            This query joins points to polygons based on intersection, and\n            aggregates by summing the values of the points in each polygon. The\n            query returns a dataframe, with a geometry column that contains\n            polygons and also creates a new table called\n            'points_aggregated_to_polygons' in the CARTO account.\n\n            .. code:: python\n\n                points_aggregated_to_polygons = cc.query(\n                    '''\n                      SELECT polygons.*, sum(points.values)\n                      FROM polygons JOIN points\n                      ON ST_Intersects(points.the_geom, polygons.the_geom)\n                      GROUP BY polygons.the_geom, polygons.cartodb_id\n                    ''',\n                    table_name='points_aggregated_to_polygons',\n                    decode_geom=True\n                )\n\n            Drops `my_table`\n\n            .. code:: python\n\n                cc.query(\n                    '''\n                      DROP TABLE my_table\n                    '''\n                )\n\n            Updates the column `my_column` in the table `my_table`\n\n            .. code:: python\n\n                cc.query(\n                    '''\n                      UPDATE my_table SET my_column = 1\n                    '''\n                )\n\n        \"\"\"\n        dataframe = None\n\n        is_select_query = is_select or (is_select is None and query.strip().lower().startswith('select'))\n        if is_select_query:\n            if table_name:\n                dataset = Dataset.create_from_query(self, query, table_name)\n                dataframe = dataset.download(decode_geom=decode_geom)\n            else:\n                dataframe = self.fetch(query, decode_geom=decode_geom)\n        else:\n            self.execute(query)\n\n        return dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nproduces a CARTO map visualizing data layers.", "response": "def map(self, layers=None, interactive=True,\n            zoom=None, lat=None, lng=None, size=(800, 400),\n            ax=None):\n        \"\"\"Produce a CARTO map visualizing data layers.\n\n        Examples:\n            Create a map with two data :py:class:`Layer\n            <cartoframes.layer.Layer>`\\s, and one :py:class:`BaseMap\n            <cartoframes.layer.BaseMap>` layer::\n\n                import cartoframes\n                from cartoframes import Layer, BaseMap, styling\n                cc = cartoframes.CartoContext(BASEURL, APIKEY)\n                cc.map(layers=[BaseMap(),\n                               Layer('acadia_biodiversity',\n                                     color={'column': 'simpson_index',\n                                            'scheme': styling.tealRose(7)}),\n                               Layer('peregrine_falcon_nest_sites',\n                                     size='num_eggs',\n                                     color={'column': 'bird_id',\n                                            'scheme': styling.vivid(10))],\n                       interactive=True)\n\n            Create a snapshot of a map at a specific zoom and center::\n\n                cc.map(layers=Layer('acadia_biodiversity',\n                                    color='simpson_index'),\n                       interactive=False,\n                       zoom=14,\n                       lng=-68.3823549,\n                       lat=44.3036906)\n        Args:\n            layers (list, optional): List of zero or more of the following:\n\n                - :py:class:`Layer <cartoframes.layer.Layer>`: cartoframes\n                  :py:class:`Layer <cartoframes.layer.Layer>` object for\n                  visualizing data from a CARTO table. See :py:class:`Layer\n                  <cartoframes.layer.Layer>` for all styling options.\n                - :py:class:`BaseMap <cartoframes.layer.BaseMap>`: Basemap for\n                  contextualizng data layers. See :py:class:`BaseMap\n                  <cartoframes.layer.BaseMap>` for all styling options.\n                - :py:class:`QueryLayer <cartoframes.layer.QueryLayer>`: Layer\n                  from an arbitrary query. See :py:class:`QueryLayer\n                  <cartoframes.layer.QueryLayer>` for all styling options.\n\n            interactive (bool, optional): Defaults to ``True`` to show an\n                interactive slippy map. Setting to ``False`` creates a static\n                map.\n            zoom (int, optional): Zoom level of map. Acceptable values are\n                usually in the range 0 to 19. 0 has the entire earth on a\n                single tile (256px square). Zoom 19 is the size of a city\n                block. Must be used in conjunction with ``lng`` and ``lat``.\n                Defaults to a view to have all data layers in view.\n            lat (float, optional): Latitude value for the center of the map.\n                Must be used in conjunction with ``zoom`` and ``lng``. Defaults\n                to a view to have all data layers in view.\n            lng (float, optional): Longitude value for the center of the map.\n                Must be used in conjunction with ``zoom`` and ``lat``. Defaults\n                to a view to have all data layers in view.\n            size (tuple, optional): List of pixel dimensions for the map.\n                Format is ``(width, height)``. Defaults to ``(800, 400)``.\n            ax: matplotlib axis on which to draw the image. Only used when\n                ``interactive`` is ``False``.\n\n        Returns:\n            IPython.display.HTML or matplotlib Axes: Interactive maps are\n            rendered as HTML in an `iframe`, while static maps are returned as\n            matplotlib Axes objects or IPython Image.\n        \"\"\"\n        # TODO: add layers preprocessing method like\n        #       layers = process_layers(layers)\n        #       that uses up to layer limit value error\n        if layers is None:\n            layers = []\n        elif not isinstance(layers, collections.Iterable):\n            layers = [layers]\n        else:\n            layers = list(layers)\n\n        if len(layers) > 8:\n            raise ValueError('Map can have at most 8 layers')\n\n        nullity = [zoom is None, lat is None, lng is None]\n        if any(nullity) and not all(nullity):\n            raise ValueError('Zoom, lat, and lng must all or none be provided')\n\n        # When no layers are passed, set default zoom\n        if ((len(layers) == 0 and zoom is None) or\n                (len(layers) == 1 and layers[0].is_basemap)):\n            [zoom, lat, lng] = [1, 0, 0]\n        has_zoom = zoom is not None\n\n        # Check for a time layer, if it exists move it to the front\n        time_layers = [idx for idx, layer in enumerate(layers)\n                       if not layer.is_basemap and layer.time]\n        time_layer = layers[time_layers[0]] if len(time_layers) > 0 else None\n        if len(time_layers) > 1:\n            raise ValueError('Map can at most take 1 Layer with time '\n                             'column/field')\n        if time_layer:\n            if not interactive:\n                raise ValueError('Map cannot display a static image with a '\n                                 'time column')\n            layers.append(layers.pop(time_layers[0]))\n\n        base_layers = [idx for idx, layer in enumerate(layers)\n                       if layer.is_basemap]\n        # Check basemaps, add one if none exist\n        if len(base_layers) > 1:\n            raise ValueError('Map can at most take one BaseMap layer')\n        elif len(base_layers) == 1:\n            # move baselayer to first position\n            layers.insert(0, layers.pop(base_layers[0]))\n\n            # add labels layer if requested\n            if layers[0].is_basic() and layers[0].labels == 'front':\n                layers.append(BaseMap(layers[0].source,\n                                      labels='front',\n                                      only_labels=True))\n                layers[0].labels = None\n        elif not base_layers:\n            # default basemap is dark with labels in back\n            # labels will be changed if all geoms are non-point\n            layers.insert(0, BaseMap())\n            geoms = set()\n\n        # Setup layers\n        for idx, layer in enumerate(layers):\n            if not layer.is_basemap:\n                # get schema of style columns\n                if layer.style_cols:\n                    resp = self.sql_client.send(\n                        utils.minify_sql((\n                            'SELECT {cols}',\n                            'FROM ({query}) AS _wrap',\n                            'LIMIT 0',\n                        )).format(cols=','.join(layer.style_cols),\n                                  comma=',' if layer.style_cols else '',\n                                  query=layer.orig_query),\n                        **DEFAULT_SQL_ARGS)\n                    self._debug_print(layer_fields=resp)\n                    for stylecol, coltype in utils.dict_items(resp['fields']):\n                        layer.style_cols[stylecol] = coltype['type']\n                layer.geom_type = self._geom_type(layer)\n                if not base_layers:\n                    geoms.add(layer.geom_type)\n                # update local style schema to help build proper defaults\n            layer._setup(layers, idx)\n\n        # set labels on top if there are no point geometries and a basemap\n        #  is not specified\n        if not base_layers and 'point' not in geoms:\n            layers[0] = BaseMap(labels='front')\n\n        # If basemap labels are on front, add labels layer\n        basemap = layers[0]\n        if basemap.is_basic() and basemap.labels == 'front':\n            layers.append(BaseMap(basemap.source,\n                                  labels=basemap.labels,\n                                  only_labels=True))\n\n        nb_layers = non_basemap_layers(layers)\n        if time_layer and len(nb_layers) > 1:\n            raise ValueError('Maps with a time element can only consist of a '\n                             'time layer and a basemap. This constraint will '\n                             'be removed in the future.')\n        options = {'basemap_url': basemap.url}\n\n        for idx, layer in enumerate(nb_layers):\n            self._check_query(layer.query,\n                              style_cols=layer.style_cols)\n            options['cartocss_' + str(idx)] = layer.cartocss\n            options['sql_' + str(idx)] = layer.query\n\n        params = {\n            'config': json.dumps(options),\n            'anti_cache': random.random(),\n        }\n\n        if has_zoom:\n            params.update({'zoom': zoom, 'lat': lat, 'lon': lng})\n            options.update({'zoom': zoom, 'lat': lat, 'lng': lng})\n        else:\n            bounds = self._get_bounds(nb_layers)\n            options.update(bounds)\n            bbox = '{west},{south},{east},{north}'.format(**bounds)\n            params.update(dict(bbox=bbox))\n\n        map_name = self._send_map_template(layers, has_zoom=has_zoom)\n        api_url = utils.join_url(self.creds.base_url(), 'api/v1/map')\n\n        static_url = ('{url}.png?{params}').format(\n            url=utils.join_url(api_url, 'static/named',\n                               map_name, size[0], size[1]),\n            params=urlencode(params))\n\n        html = '<img src=\"{url}\" />'.format(url=static_url)\n        self._debug_print(static_url=static_url)\n\n        # TODO: write this as a private method\n        if interactive:\n            netloc = urlparse(self.creds.base_url()).netloc\n            domain = 'carto.com' if netloc.endswith('.carto.com') else netloc\n\n            config = {\n                'user_name': self.creds.username(),\n                'maps_api_template': self.creds.base_url(),\n                'sql_api_template': self.creds.base_url(),\n                'tiler_protocol': 'https',\n                'tiler_domain': domain,\n                'tiler_port': '80',\n                'type': 'torque' if time_layer else 'namedmap',\n                'named_map': {\n                    'name': map_name,\n                    'params': {\n                        k: utils.safe_quotes(v, escape_single_quotes=True)\n                        for k, v in utils.dict_items(options)\n                    },\n                },\n            }\n\n            map_options = {\n                'filter': ['mapnik', 'torque', ],\n                'https': True,\n            }\n\n            if time_layer:\n                # get turbo-carto processed cartocss\n                resp = self._auth_send(\n                    'api/v1/map/named/{}'.format(map_name),\n                    'POST',\n                    data=params['config'],\n                    headers={'Content-Type': 'application/json'})\n\n                # check if errors in cartocss (already turbo-carto processed)\n                if 'errors' not in resp:\n                    # replace previous cartocss with turbo-carto processed\n                    #  version\n                    layer.cartocss = (resp['metadata']\n                                          ['layers']\n                                          [1]\n                                          ['meta']\n                                          ['cartocss'])\n                config.update({\n                    'order': 1,\n                    'options': {\n                        'query': time_layer.query,\n                        'user_name': self.creds.username(),\n                        'tile_style': layer.cartocss\n                    }\n                })\n                config['named_map'].update({\n                    'layers': [{\n                        'layer_name': 't',\n                    }],\n                })\n                map_options.update({\n                    'time_slider': True,\n                    'loop': True,\n                })\n            bounds = [] if has_zoom else [[options['north'], options['east']],\n                                          [options['south'], options['west']]]\n\n            content = self._get_iframe_srcdoc(\n                config=config,\n                bounds=bounds,\n                options=options,\n                map_options=map_options,\n                top_layer_url=top_basemap_layer_url(layers)\n            )\n\n            img_html = html\n            html = (\n                '<iframe srcdoc=\"{content}\" width=\"{width}\" height=\"{height}\">'\n                '  Preview image: {img_html}'\n                '</iframe>'\n            ).format(content=utils.safe_quotes(content),\n                     width=size[0],\n                     height=size[1],\n                     img_html=img_html)\n            return HTML(html)\n        elif HAS_MATPLOTLIB:\n            raw_data = mpi.imread(static_url, format='png')\n            if ax is None:\n                dpi = mpi.rcParams['figure.dpi']\n                mpl_size = (size[0] / dpi, size[1] / dpi)\n                fig = plt.figure(figsize=mpl_size, dpi=dpi, frameon=False)\n                fig.subplots_adjust(left=0, right=1, top=1, bottom=0)\n                ax = plt.gca()\n            ax.imshow(raw_data)\n            ax.axis('off')\n            return ax\n        else:\n            return Image(url=static_url,\n                         embed=True,\n                         format='png',\n                         width=size[0],\n                         height=size[1],\n                         metadata=dict(origin_url=static_url))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets geometry type of specified layer", "response": "def _geom_type(self, source):\n        \"\"\"gets geometry type(s) of specified layer\"\"\"\n        if isinstance(source, AbstractLayer):\n            query = source.orig_query\n        else:\n            query = 'SELECT * FROM \"{table}\"'.format(table=source)\n        resp = self.sql_client.send(\n            utils.minify_sql((\n                'SELECT',\n                '    CASE WHEN ST_GeometryType(the_geom)',\n                '               in (\\'ST_Point\\', \\'ST_MultiPoint\\')',\n                '         THEN \\'point\\'',\n                '         WHEN ST_GeometryType(the_geom)',\n                '              in (\\'ST_LineString\\', \\'ST_MultiLineString\\')',\n                '         THEN \\'line\\'',\n                '         WHEN ST_GeometryType(the_geom)',\n                '              in (\\'ST_Polygon\\', \\'ST_MultiPolygon\\')',\n                '         THEN \\'polygon\\'',\n                '         ELSE null END AS geom_type,',\n                '    count(*) as cnt',\n                'FROM ({query}) AS _wrap',\n                'WHERE the_geom IS NOT NULL',\n                'GROUP BY 1',\n                'ORDER BY 2 DESC',\n            )).format(query=query),\n            **DEFAULT_SQL_ARGS)\n        if resp['total_rows'] > 1:\n            warn('There are multiple geometry types in {query}: '\n                 '{geoms}. Styling by `{common_geom}`, the most common'.format(\n                     query=query,\n                     geoms=','.join(g['geom_type'] for g in resp['rows']),\n                     common_geom=resp['rows'][0]['geom_type']))\n        elif resp['total_rows'] == 0:\n            raise ValueError('No geometry for layer. Check all layer tables '\n                             'and queries to ensure there are geometries.')\n        return resp['rows'][0]['geom_type']"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding all boundaries available for the world or a `region`. If `boundary` is specified, get all available boundary polygons for the region specified (if any). This method is espeically useful for getting boundaries for a region and, with :py:meth:`CartoContext.data <cartoframes.context.CartoContext.data>` and :py:meth:`CartoContext.data_discovery <cartoframes.context.CartoContext.data_discovery>`, getting tables of geometries and the corresponding raw measures. For example, if you want to analyze how median income has changed in a region (see examples section for more). Examples: Find all boundaries available for Australia. The columns `geom_name` gives us the name of the boundary and `geom_id` is what we need for the `boundary` argument. .. code:: python import cartoframes cc = cartoframes.CartoContext('base url', 'api key') au_boundaries = cc.data_boundaries(region='Australia') au_boundaries[['geom_name', 'geom_id']] Get the boundaries for Australian Postal Areas and map them. .. code:: python from cartoframes import Layer au_postal_areas = cc.data_boundaries(boundary='au.geo.POA') cc.write(au_postal_areas, 'au_postal_areas') cc.map(Layer('au_postal_areas')) Get census tracts around Idaho Falls, Idaho, USA, and add median income from the US census. Without limiting the metadata, we get median income measures for each census in the Data Observatory. .. code:: python cc = cartoframes.CartoContext('base url', 'api key') # will return DataFrame with columns `the_geom` and `geom_ref` tracts = cc.data_boundaries( boundary='us.census.tiger.census_tract', region=[-112.096642,43.429932,-111.974213,43.553539]) # write geometries to a CARTO table cc.write(tracts, 'idaho_falls_tracts') # gather metadata needed to look up median income median_income_meta = cc.data_discovery( 'idaho_falls_tracts', keywords='median income', boundaries='us.census.tiger.census_tract') # get median income data and original table as new dataframe idaho_falls_income = cc.data( 'idaho_falls_tracts', median_income_meta, how='geom_refs') # overwrite existing table with newly-enriched dataframe cc.write(idaho_falls_income, 'idaho_falls_tracts', overwrite=True) Args: boundary (str, optional): Boundary identifier for the boundaries that are of interest. For example, US census tracts have a boundary ID of ``us.census.tiger.census_tract``, and Brazilian Municipios have an ID of ``br.geo.municipios``. Find IDs by running :py:meth:`CartoContext.data_boundaries <cartoframes.context.CartoContext.data_boundaries>` without any arguments, or by looking in the `Data Observatory catalog <http://cartodb.github.io/bigmetadata/>`__. region (str, optional): Region where boundary information or, if `boundary` is specified, boundary polygons are of interest. `region` can be one of the following: - table name (str): Name of a table in user's CARTO account - bounding box (list of float): List of four values (two lng/lat pairs) in the following order: western longitude, southern latitude, eastern longitude, and northern latitude. For example, Switzerland fits in ``[5.9559111595,45.8179931641,10.4920501709,47.808380127]`` timespan (str, optional): Specific timespan to get geometries from. Defaults to use the most recent. See the Data Observatory catalog for more information. decode_geom (bool, optional): Whether to return the geometries as Shapely objects or keep them encoded as EWKB strings. Defaults to False. include_nonclipped (bool, optional): Optionally include non-shoreline-clipped boundaries. These boundaries are the raw boundaries provided by, for example, US Census Tiger. Returns: pandas.DataFrame: If `boundary` is specified, then all available boundaries and accompanying `geom_refs` in `region` (or the world if `region` is ``None`` or not specified) are returned. If `boundary` is not specified, then a DataFrame of all available boundaries in `region` (or the world if `region` is ``None``)", "response": "def data_boundaries(self, boundary=None, region=None, decode_geom=False,\n                        timespan=None, include_nonclipped=False):\n        \"\"\"\n        Find all boundaries available for the world or a `region`. If\n        `boundary` is specified, get all available boundary polygons for the\n        region specified (if any). This method is espeically useful for getting\n        boundaries for a region and, with :py:meth:`CartoContext.data\n        <cartoframes.context.CartoContext.data>` and\n        :py:meth:`CartoContext.data_discovery\n        <cartoframes.context.CartoContext.data_discovery>`, getting tables of\n        geometries and the corresponding raw measures. For example, if you want\n        to analyze how median income has changed in a region (see examples\n        section for more).\n\n        Examples:\n\n            Find all boundaries available for Australia. The columns\n            `geom_name` gives us the name of the boundary and `geom_id`\n            is what we need for the `boundary` argument.\n\n            .. code:: python\n\n                import cartoframes\n                cc = cartoframes.CartoContext('base url', 'api key')\n                au_boundaries = cc.data_boundaries(region='Australia')\n                au_boundaries[['geom_name', 'geom_id']]\n\n            Get the boundaries for Australian Postal Areas and map them.\n\n            .. code:: python\n\n                from cartoframes import Layer\n                au_postal_areas = cc.data_boundaries(boundary='au.geo.POA')\n                cc.write(au_postal_areas, 'au_postal_areas')\n                cc.map(Layer('au_postal_areas'))\n\n            Get census tracts around Idaho Falls, Idaho, USA, and add median\n            income from the US census. Without limiting the metadata, we get\n            median income measures for each census in the Data Observatory.\n\n            .. code:: python\n\n                cc = cartoframes.CartoContext('base url', 'api key')\n                # will return DataFrame with columns `the_geom` and `geom_ref`\n                tracts = cc.data_boundaries(\n                    boundary='us.census.tiger.census_tract',\n                    region=[-112.096642,43.429932,-111.974213,43.553539])\n                # write geometries to a CARTO table\n                cc.write(tracts, 'idaho_falls_tracts')\n                # gather metadata needed to look up median income\n                median_income_meta = cc.data_discovery(\n                    'idaho_falls_tracts',\n                    keywords='median income',\n                    boundaries='us.census.tiger.census_tract')\n                # get median income data and original table as new dataframe\n                idaho_falls_income = cc.data(\n                    'idaho_falls_tracts',\n                    median_income_meta,\n                    how='geom_refs')\n                # overwrite existing table with newly-enriched dataframe\n                cc.write(idaho_falls_income,\n                         'idaho_falls_tracts',\n                         overwrite=True)\n\n        Args:\n            boundary (str, optional): Boundary identifier for the boundaries\n              that are of interest. For example, US census tracts have a\n              boundary ID of ``us.census.tiger.census_tract``, and Brazilian\n              Municipios have an ID of ``br.geo.municipios``. Find IDs by\n              running :py:meth:`CartoContext.data_boundaries\n              <cartoframes.context.CartoContext.data_boundaries>`\n              without any arguments, or by looking in the `Data Observatory\n              catalog <http://cartodb.github.io/bigmetadata/>`__.\n            region (str, optional): Region where boundary information or,\n              if `boundary` is specified, boundary polygons are of interest.\n              `region` can be one of the following:\n\n                - table name (str): Name of a table in user's CARTO account\n                - bounding box (list of float): List of four values (two\n                  lng/lat pairs) in the following order: western longitude,\n                  southern latitude, eastern longitude, and northern latitude.\n                  For example, Switzerland fits in\n                  ``[5.9559111595,45.8179931641,10.4920501709,47.808380127]``\n            timespan (str, optional): Specific timespan to get geometries from.\n              Defaults to use the most recent. See the Data Observatory catalog\n              for more information.\n            decode_geom (bool, optional): Whether to return the geometries as\n              Shapely objects or keep them encoded as EWKB strings. Defaults\n              to False.\n            include_nonclipped (bool, optional): Optionally include\n              non-shoreline-clipped boundaries. These boundaries are the raw\n              boundaries provided by, for example, US Census Tiger.\n\n        Returns:\n            pandas.DataFrame: If `boundary` is specified, then all available\n            boundaries and accompanying `geom_refs` in `region` (or the world\n            if `region` is ``None`` or not specified) are returned. If\n            `boundary` is not specified, then a DataFrame of all available\n            boundaries in `region` (or the world if `region` is ``None``)\n        \"\"\"\n        # TODO: create a function out of this?\n        if isinstance(region, str):\n            # see if it's a table\n            try:\n                geom_type = self._geom_type(region)\n                if geom_type in ('point', 'line', ):\n                    bounds = ('(SELECT ST_ConvexHull(ST_Collect(the_geom)) '\n                              'FROM {table})').format(table=region)\n                else:\n                    bounds = ('(SELECT ST_Union(the_geom) '\n                              'FROM {table})').format(table=region)\n            except CartoException:\n                # see if it's a Data Obs region tag\n                regionsearch = '\"geom_tags\"::text ilike \\'%{}%\\''.format(\n                    get_countrytag(region))\n                bounds = 'ST_MakeEnvelope(-180.0, -85.0, 180.0, 85.0, 4326)'\n        elif isinstance(region, collections.Iterable):\n            if len(region) != 4:\n                raise ValueError(\n                    '`region` should be a list of the geographic bounds of a '\n                    'region in the following order: western longitude, '\n                    'southern latitude, eastern longitude, and northern '\n                    'latitude. For example, Switerland fits in '\n                    '``[5.9559111595,45.8179931641,10.4920501709,'\n                    '47.808380127]``.')\n            bounds = ('ST_MakeEnvelope({0}, {1}, {2}, {3}, 4326)').format(\n                *region)\n        elif region is None:\n            bounds = 'ST_MakeEnvelope(-180.0, -85.0, 180.0, 85.0, 4326)'\n        else:\n            raise ValueError('`region` must be a str, a list of two lng/lat '\n                             'pairs, or ``None`` (which defaults to the '\n                             'world)')\n        if include_nonclipped:\n            clipped = None\n        else:\n            clipped = (r\"(geom_id ~ '^us\\.census\\..*_clipped$' OR \"\n                       r\"geom_id !~ '^us\\.census\\..*')\")\n\n        if boundary is None:\n            regionsearch = locals().get('regionsearch')\n            filters = ' AND '.join(r for r in [regionsearch, clipped] if r)\n            query = utils.minify_sql((\n                'SELECT *',\n                'FROM OBS_GetAvailableGeometries(',\n                '  {bounds}, null, null, null, {timespan})',\n                '{filters}')).format(\n                    bounds=bounds,\n                    timespan=utils.pgquote(timespan),\n                    filters='WHERE {}'.format(filters) if filters else '')\n            return self.fetch(query, decode_geom=True)\n\n        query = utils.minify_sql((\n            'SELECT the_geom, geom_refs',\n            'FROM OBS_GetBoundariesByGeometry(',\n            '    {bounds},',\n            '    {boundary},',\n            '    {time})', )).format(\n                bounds=bounds,\n                boundary=utils.pgquote(boundary),\n                time=utils.pgquote(timespan))\n        return self.fetch(query, decode_geom=decode_geom)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_discovery(self, region, keywords=None, regex=None, time=None,\n                       boundaries=None, include_quantiles=False):\n        \"\"\"Discover Data Observatory measures. This method returns the full\n        Data Observatory metadata model for each measure or measures that\n        match the conditions from the inputs. The full metadata in each row\n        uniquely defines a measure based on the timespan, geographic\n        resolution, and normalization (if any). Read more about the metadata\n        response in `Data Observatory\n        <https://carto.com/docs/carto-engine/data/measures-functions/#obs_getmetaextent-geometry-metadata-json-max_timespan_rank-max_score_rank-target_geoms>`__\n        documentation.\n\n        Internally, this method finds all measures in `region` that match the\n        conditions set in `keywords`, `regex`, `time`, and `boundaries` (if\n        any of them are specified). Then, if `boundaries` is not specified, a\n        geographical resolution for that measure will be chosen subject to the\n        type of region specified:\n\n          1. If `region` is a table name, then a geographical resolution that\n             is roughly equal to `region size / number of subunits`.\n          2. If `region` is a country name or bounding box, then a geographical\n             resolution will be chosen roughly equal to `region size / 500`.\n\n        Since different measures are in some geographic resolutions and not\n        others, different geographical resolutions for different measures are\n        oftentimes returned.\n\n        .. tip::\n\n            To remove the guesswork in how geographical resolutions are\n            selected, specify one or more boundaries in `boundaries`. See\n            the boundaries section for each region in the `Data Observatory\n            catalog <http://cartodb.github.io/bigmetadata/>`__.\n\n        The metadata returned from this method can then be used to create raw\n        tables or for augmenting an existing table from these measures using\n        :py:meth:`CartoContext.data <cartoframes.context.CartoContext.data>`.\n        For the full Data Observatory catalog, visit\n        https://cartodb.github.io/bigmetadata/. When working with the metadata\n        DataFrame returned from this method, be careful to only remove rows not\n        columns as `CartoContext.data <cartoframes.context.CartoContext.data>`\n        generally needs the full metadata.\n\n        .. note::\n            Narrowing down a discovery query using the `keywords`, `regex`, and\n            `time` filters is important for getting a manageable metadata\n            set. Besides there being a large number of measures in the DO, a\n            metadata response has acceptable combinations of measures with\n            demonimators (normalization and density), and the same measure from\n            other years.\n\n            For example, setting the region to be United States counties with\n            no filter values set will result in many thousands of measures.\n\n        Examples:\n\n            Get all European Union measures that mention ``freight``.\n\n            .. code::\n\n                meta = cc.data_discovery('European Union',\n                                         keywords='freight',\n                                         time='2010')\n                print(meta['numer_name'].values)\n\n        Arguments:\n            region (str or list of float): Information about the region of\n              interest. `region` can be one of three types:\n\n                - region name (str): Name of region of interest. Acceptable\n                  values are limited to: 'Australia', 'Brazil', 'Canada',\n                  'European Union', 'France', 'Mexico', 'Spain',\n                  'United Kingdom', 'United States'.\n                - table name (str): Name of a table in user's CARTO account\n                  with geometries. The region will be the bounding box of\n                  the table.\n\n                  .. Note:: If a table name is also a valid Data Observatory\n                      region name, the Data Observatory name will be chosen\n                      over the table.\n\n                - bounding box (list of float): List of four values (two\n                  lng/lat pairs) in the following order: western longitude,\n                  southern latitude, eastern longitude, and northern latitude.\n                  For example, Switzerland fits in\n                  ``[5.9559111595,45.8179931641,10.4920501709,47.808380127]``\n\n                .. Note:: Geometry levels are generally chosen by subdividing\n                    the region into the next smallest administrative unit. To\n                    override this behavior, specify the `boundaries` flag. For\n                    example, set `boundaries` to\n                    ``'us.census.tiger.census_tract'`` to choose US census\n                    tracts.\n\n            keywords (str or list of str, optional): Keyword or list of\n              keywords in measure description or name. Response will be matched\n              on all keywords listed (boolean `or`).\n            regex (str, optional): A regular expression to search the measure\n              descriptions and names. Note that this relies on PostgreSQL's\n              case insensitive operator ``~*``. See `PostgreSQL docs\n              <https://www.postgresql.org/docs/9.5/static/functions-matching.html>`__\n              for more information.\n            boundaries (str or list of str, optional): Boundary or list of\n              boundaries that specify the measure resolution. See the\n              boundaries section for each region in the `Data Observatory\n              catalog <http://cartodb.github.io/bigmetadata/>`__.\n            include_quantiles (bool, optional): Include quantiles calculations\n              which are a calculation of how a measure compares to all measures\n              in the full dataset. Defaults to ``False``. If ``True``,\n              quantiles columns will be returned for each column which has it\n              pre-calculated.\n\n        Returns:\n            pandas.DataFrame: A dataframe of the complete metadata model for\n            specific measures based on the search parameters.\n\n        Raises:\n            ValueError: If `region` is a :obj:`list` and does not consist of\n              four elements, or if `region` is not an acceptable region\n            CartoException: If `region` is not a table in user account\n        \"\"\"\n        if isinstance(region, str):\n            try:\n                # see if it's a DO region, nest in {}\n                countrytag = '\\'{{{0}}}\\''.format(\n                    get_countrytag(region))\n                boundary = ('SELECT ST_MakeEnvelope(-180.0, -85.0, 180.0, '\n                            '85.0, 4326) AS env, 500::int AS cnt')\n            except ValueError:\n                # TODO: make this work for general queries\n                # see if it's a table\n                self.sql_client.send(\n                    'EXPLAIN SELECT * FROM {}'.format(region))\n                boundary = (\n                    'SELECT ST_SetSRID(ST_Extent(the_geom), 4326) AS env, '\n                    'count(*)::int AS cnt FROM {table_name}').format(\n                        table_name=region)\n        elif isinstance(region, collections.Iterable):\n            if len(region) != 4:\n                raise ValueError(\n                    '`region` should be a list of the geographic bounds of a '\n                    'region in the following order: western longitude, '\n                    'southern latitude, eastern longitude, and northern '\n                    'latitude. For example, Switerland fits in '\n                    '``[5.9559111595,45.8179931641,10.4920501709,'\n                    '47.808380127]``.'\n                )\n            boundary = ('SELECT ST_MakeEnvelope({0}, {1}, {2}, {3}, 4326) AS '\n                        'env, 500::int AS cnt'.format(*region))\n\n        if locals().get('countrytag') is None:\n            countrytag = 'null'\n\n        if keywords:\n            if isinstance(keywords, str):\n                keywords = [keywords, ]\n            kwsearch = ' OR '.join(\n                ('numer_description ILIKE \\'%{kw}%\\' OR '\n                 'numer_name ILIKE \\'%{kw}%\\'').format(kw=kw)\n                for kw in keywords)\n            kwsearch = '({})'.format(kwsearch)\n\n        if regex:\n            regexsearch = ('(numer_description ~* {regex} OR numer_name '\n                           '~* {regex})').format(regex=utils.pgquote(regex))\n\n        if keywords or regex:\n            subjectfilters = '{kw} {op} {regex}'.format(\n                kw=kwsearch if keywords else '',\n                op='OR' if (keywords and regex) else '',\n                regex=regexsearch if regex else '').strip()\n        else:\n            subjectfilters = ''\n\n        if isinstance(time, str) or time is None:\n            time = [time, ]\n        if isinstance(boundaries, str) or boundaries is None:\n            boundaries = [boundaries, ]\n\n        if all(time) and all(boundaries):\n            bt_filters = 'valid_geom AND valid_timespan'\n        elif all(time) or all(boundaries):\n            bt_filters = 'valid_geom' if all(boundaries) else 'valid_timespan'\n        else:\n            bt_filters = ''\n\n        if bt_filters and subjectfilters:\n            filters = 'WHERE ({s}) AND ({bt})'.format(\n                s=subjectfilters, bt=bt_filters)\n        elif bt_filters or subjectfilters:\n            filters = 'WHERE {f}'.format(f=subjectfilters or bt_filters)\n        else:\n            filters = ''\n\n        quantiles = ('WHERE numer_aggregate <> \\'quantile\\''\n                     if not include_quantiles else '')\n\n        numer_query = utils.minify_sql((\n            'SELECT',\n            '    numer_id,',\n            '    {geom_id} AS geom_id,',\n            '    {timespan} AS numer_timespan,',\n            '    {normalization} AS normalization',\n            '  FROM',\n            '    OBS_GetAvailableNumerators(',\n            '        (SELECT env FROM envelope),',\n            '        {countrytag},',\n            '        null,',  # denom_id\n            '        {geom_id},',\n            '        {timespan})',\n            '{filters}', )).strip()\n\n        # query all numerators for all `time`, `boundaries`, and raw/derived\n        numers = '\\nUNION\\n'.join(\n            numer_query.format(\n                timespan=utils.pgquote(t),\n                geom_id=utils.pgquote(b),\n                normalization=utils.pgquote(n),\n                countrytag=countrytag,\n                filters=filters)\n            for t in time\n            for b in boundaries\n            for n in ('predenominated', None))\n\n        query = utils.minify_sql((\n            'WITH envelope AS (',\n            '    {boundary}',\n            '), numers AS (',\n            '  {numers}',\n            ')',\n            'SELECT *',\n            'FROM json_to_recordset(',\n            '    (SELECT OBS_GetMeta(',\n            '        envelope.env,',\n            '        json_agg(numers),',\n            '        10, 10, envelope.cnt',\n            '    ) AS meta',\n            'FROM numers, envelope',\n            'GROUP BY env, cnt)) as data(',\n            '    denom_aggregate text, denom_colname text,',\n            '    denom_description text, denom_geomref_colname text,',\n            '    denom_id text, denom_name text, denom_reltype text,',\n            '    denom_t_description text, denom_tablename text,',\n            '    denom_type text, geom_colname text, geom_description text,',\n            '    geom_geomref_colname text, geom_id text, geom_name text,',\n            '    geom_t_description text, geom_tablename text,',\n            '    geom_timespan text, geom_type text, id numeric,',\n            '    max_score_rank text, max_timespan_rank text,',\n            '    normalization text, num_geoms numeric, numer_aggregate text,',\n            '    numer_colname text, numer_description text,',\n            '    numer_geomref_colname text, numer_id text,',\n            '    numer_name text, numer_t_description text,',\n            '    numer_tablename text, numer_timespan text,',\n            '    numer_type text, score numeric, score_rank numeric,',\n            '    score_rownum numeric, suggested_name text,',\n            '    target_area text, target_geoms text, timespan_rank numeric,',\n            '    timespan_rownum numeric)',\n            '{quantiles}', )).format(\n                boundary=boundary,\n                numers=numers,\n                quantiles=quantiles).strip()\n        self._debug_print(query=query)\n        return self.fetch(query, decode_geom=True)", "response": "This method returns the full metadata model for each measure or measure in a specific region."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget an augmented CARTO dataset with Data Observatory measures.", "response": "def data(self, table_name, metadata, persist_as=None, how='the_geom'):\n        \"\"\"Get an augmented CARTO dataset with `Data Observatory\n        <https://carto.com/data-observatory>`__ measures. Use\n        `CartoContext.data_discovery\n        <#context.CartoContext.data_discovery>`__ to search for available\n        measures, or see the full `Data Observatory catalog\n        <https://cartodb.github.io/bigmetadata/index.html>`__. Optionally\n        persist the data as a new table.\n\n        Example:\n            Get a DataFrame with Data Observatory measures based on the\n            geometries in a CARTO table.\n\n            .. code::\n\n                cc = cartoframes.CartoContext(BASEURL, APIKEY)\n                median_income = cc.data_discovery('transaction_events',\n                                                  regex='.*median income.*',\n                                                  time='2011 - 2015')\n                df = cc.data('transaction_events',\n                             median_income)\n\n            Pass in cherry-picked measures from the Data Observatory catalog.\n            The rest of the metadata will be filled in, but it's important to\n            specify the geographic level as this will not show up in the column\n            name.\n\n            .. code::\n\n                median_income = [{'numer_id': 'us.census.acs.B19013001',\n                                  'geom_id': 'us.census.tiger.block_group',\n                                  'numer_timespan': '2011 - 2015'}]\n                df = cc.data('transaction_events', median_income)\n\n        Args:\n            table_name (str): Name of table on CARTO account that Data\n                Observatory measures are to be added to.\n            metadata (pandas.DataFrame): List of all measures to add to\n                `table_name`. See :py:meth:`CartoContext.data_discovery\n                <cartoframes.context.CartoContext.data_discovery>` outputs\n                for a full list of metadata columns.\n            persist_as (str, optional): Output the results of augmenting\n                `table_name` to `persist_as` as a persistent table on CARTO.\n                Defaults to ``None``, which will not create a table.\n            how (str, optional): **Not fully implemented**. Column name for\n                identifying the geometry from which to fetch the data. Defaults\n                to `the_geom`, which results in measures that are spatially\n                interpolated (e.g., a neighborhood boundary's population will\n                be calculated from underlying census tracts). Specifying a\n                column that has the geometry identifier (for example, GEOID for\n                US Census boundaries), results in measures directly from the\n                Census for that GEOID but normalized how it is specified in the\n                metadata.\n\n        Returns:\n            pandas.DataFrame: A DataFrame representation of `table_name` which\n            has new columns for each measure in `metadata`.\n\n        Raises:\n            NameError: If the columns in `table_name` are in the\n              ``suggested_name`` column of `metadata`.\n            ValueError: If metadata object is invalid or empty, or if the\n              number of requested measures exceeds 50.\n            CartoException: If user account consumes all of Data Observatory\n              quota\n        \"\"\"\n        # if how != 'the_geom':\n        #   raise NotImplementedError('Data gathering currently only works if '\n        #                             'a geometry is present')\n        if isinstance(metadata, pd.DataFrame):\n            _meta = metadata.copy().reset_index()\n        elif isinstance(metadata, collections.Iterable):\n            query = utils.minify_sql((\n                'WITH envelope AS (',\n                '  SELECT',\n                '    ST_SetSRID(ST_Extent(the_geom)::geometry, 4326) AS env,',\n                '    count(*)::int AS cnt',\n                '  FROM {table_name}',\n                ')',\n                'SELECT *',\n                '  FROM json_to_recordset(',\n                '      (SELECT OBS_GetMeta(',\n                '          envelope.env,',\n                '          (\\'{meta}\\')::json,',\n                '          10, 1, envelope.cnt',\n                '      ) AS meta',\n                '  FROM envelope',\n                '  GROUP BY env, cnt)) as data(',\n                '      denom_aggregate text, denom_colname text,',\n                '      denom_description text, denom_geomref_colname text,',\n                '      denom_id text, denom_name text, denom_reltype text,',\n                '      denom_t_description text, denom_tablename text,',\n                '      denom_type text, geom_colname text,',\n                '      geom_description text,geom_geomref_colname text,',\n                '      geom_id text, geom_name text, geom_t_description text,',\n                '      geom_tablename text, geom_timespan text,',\n                '      geom_type text, id numeric, max_score_rank text,',\n                '      max_timespan_rank text, normalization text, num_geoms',\n                '      numeric,numer_aggregate text, numer_colname text,',\n                '      numer_description text, numer_geomref_colname text,',\n                '      numer_id text, numer_name text, numer_t_description',\n                '      text, numer_tablename text, numer_timespan text,',\n                '      numer_type text, score numeric, score_rank numeric,',\n                '      score_rownum numeric, suggested_name text,',\n                '      target_area text, target_geoms text, timespan_rank',\n                '      numeric, timespan_rownum numeric)',\n            )).format(table_name=table_name,\n                      meta=json.dumps(metadata).replace('\\'', '\\'\\''))\n            _meta = self.fetch(query)\n\n        if _meta.shape[0] == 0:\n            raise ValueError('There are no valid metadata entries. Check '\n                             'inputs.')\n        elif _meta.shape[0] > 50:\n            raise ValueError('The number of metadata entries exceeds 50. Tip: '\n                             'If `metadata` is a pandas.DataFrame, iterate '\n                             'over this object using `metadata.groupby`. If '\n                             'it is a list, iterate over chunks of it. Then '\n                             'combine resulting DataFrames using '\n                             '`pandas.concat`')\n\n        # get column names except the_geom_webmercator\n        dataset = Dataset(self, table_name)\n        table_columns = dataset.get_table_column_names(exclude=['the_geom_webmercator'])\n\n        names = {}\n        for suggested in _meta['suggested_name']:\n            if suggested in table_columns:\n                names[suggested] = utils.unique_colname(suggested, table_columns)\n                warn(\n                    '{s0} was augmented as {s1} because of name '\n                    'collision'.format(s0=suggested, s1=names[suggested])\n                )\n            else:\n                names[suggested] = suggested\n\n        # drop description columns to lighten the query\n        # FIXME https://github.com/CartoDB/cartoframes/issues/593\n        meta_columns = _meta.columns.values\n        drop_columns = []\n        for meta_column in meta_columns:\n            if meta_column.endswith('_description'):\n                drop_columns.append(meta_column)\n\n        if len(drop_columns) > 0:\n            _meta.drop(drop_columns, axis=1, inplace=True)\n\n        cols = ', '.join(\n            '(data->{n}->>\\'value\\')::{pgtype} AS {col}'.format(\n                n=row[0],\n                pgtype=row[1]['numer_type'],\n                col=names[row[1]['suggested_name']])\n            for row in _meta.iterrows())\n        query = utils.minify_sql((\n            'SELECT {table_cols}, {cols}',\n            '  FROM OBS_GetData(',\n            '       (SELECT array_agg({how})',\n            '        FROM \"{tablename}\"),',\n            '       (SELECT \\'{meta}\\'::json)) as m,',\n            '       {tablename} as t',\n            ' WHERE t.\"{rowid}\" = m.id',)).format(\n                how=('(the_geom, cartodb_id)::geomval'\n                     if how == 'the_geom' else how),\n                tablename=table_name,\n                rowid='cartodb_id' if how == 'the_geom' else how,\n                cols=cols,\n                table_cols=','.join('t.{}'.format(c) for c in table_columns),\n                meta=_meta.to_json(orient='records').replace('\\'', '\\'\\''))\n\n        return self.query(query, table_name=persist_as, decode_geom=False, is_select=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if query from Layer or QueryLayer is valid", "response": "def _check_query(self, query, style_cols=None):\n        \"\"\"Checks if query from Layer or QueryLayer is valid\"\"\"\n        try:\n            self.sql_client.send(\n                utils.minify_sql((\n                    'EXPLAIN',\n                    'SELECT',\n                    '  {style_cols}{comma}',\n                    '  the_geom, the_geom_webmercator',\n                    'FROM ({query}) _wrap;',\n                )).format(query=query,\n                          comma=',' if style_cols else '',\n                          style_cols=(','.join(style_cols)\n                                      if style_cols else '')),\n                do_post=False)\n        except Exception as err:\n            raise ValueError(('Layer query `{query}` and/or style column(s) '\n                              '{cols} are not valid: {err}.'\n                              '').format(query=query,\n                                         cols=', '.join(['`{}`'.format(c)\n                                                         for c in style_cols]),\n                                         err=err))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the bounds of all data layers involved in a cartoframes map.", "response": "def _get_bounds(self, layers):\n        \"\"\"Return the bounds of all data layers involved in a cartoframes map.\n\n        Args:\n            layers (list): List of cartoframes layers. See `cartoframes.layers`\n                for all types.\n\n        Returns:\n            dict: Dictionary of northern, southern, eastern, and western bounds\n                of the superset of data layers. Keys are `north`, `south`,\n                `east`, and `west`. Units are in WGS84.\n        \"\"\"\n        extent_query = ('SELECT ST_EXTENT(the_geom) AS the_geom '\n                        'FROM ({query}) AS t{idx}\\n')\n        union_query = 'UNION ALL\\n'.join(\n            [extent_query.format(query=layer.orig_query, idx=idx)\n             for idx, layer in enumerate(layers)\n             if not layer.is_basemap])\n\n        extent = self.sql_client.send(\n            utils.minify_sql((\n                'SELECT',\n                '    ST_XMIN(ext) AS west,',\n                '    ST_YMIN(ext) AS south,',\n                '    ST_XMAX(ext) AS east,',\n                '    ST_YMAX(ext) AS north',\n                'FROM (',\n                '    SELECT ST_Extent(the_geom) AS ext',\n                '    FROM ({union_query}) AS _wrap1',\n                ') AS _wrap2',\n            )).format(union_query=union_query),\n            do_post=False)\n\n        return extent['rows'][0]"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a string that can be used to display a map in the mapbox.", "response": "def vmap(layers,\n         context,\n         size=None,\n         basemap=BaseMaps.voyager,\n         bounds=None,\n         viewport=None,\n         **kwargs):\n    \"\"\"CARTO VL-powered interactive map\n\n    Args:\n        layers (list of Layer-types): List of layers. One or more of\n          :py:class:`Layer <cartoframes.contrib.vector.Layer>`,\n          :py:class:`QueryLayer <cartoframes.contrib.vector.QueryLayer>`, or\n          :py:class:`LocalLayer <cartoframes.contrib.vector.LocalLayer>`.\n        context (:py:class:`CartoContext <cartoframes.context.CartoContext>`):\n          A :py:class:`CartoContext <cartoframes.context.CartoContext>`\n          instance\n        size (tuple of int or str): a (width, height) pair for the size of the map.\n          Default is None, which makes the map 100% wide and 640px tall. If specified as int,\n          will be used as pixels, but you can also use string values for the CSS attributes.\n          So, you could specify it as size=('75%', 250).\n        basemap (str):\n          - if a `str`, name of a CARTO vector basemap. One of `positron`,\n            `voyager`, or `darkmatter` from the :obj:`BaseMaps` class\n          - if a `dict`, Mapbox or other style as the value of the `style` key.\n            If a Mapbox style, the access token is the value of the `token`\n            key.\n        bounds (dict or list): a dict with `east`,`north`,`west`,`south`\n          properties, or a list of floats in the following order: [west,\n          south, east, north]. If not provided the bounds will be automatically\n          calculated to fit all features.\n        viewport (dict): Configure where and how map will be centered. If not specified, or\n            specified without lat / lng, automatic bounds or the bounds argument will be used\n            to center the map. You can specify only zoom, bearing or pitch if you desire\n            automatic bounds but want to tweak the viewport.\n            - lng (float): Longitude to center the map on. Must specify lat as well.\n            - lat (float): Latitude to center the map on. Must specify lng as well.\n            - zoom (float): Zoom level.\n            - bearing (float): A bearing, or heading, is the direction you're facing,\n                measured clockwise as an angle from true north on a compass.\n                (north is 0, east is 90, south is 180, and west is 270).\n            - pitch (float): The angle towards the horizon measured in degrees, with a\n                range between 0 and 60 degrees. Zero degrees results in a two-dimensional\n                map, as if your line of sight forms a perpendicular angle with\n                the earth's surface.\n\n    Example:\n\n        .. code::\n\n            from cartoframes.contrib import vector\n            from cartoframes import CartoContext\n            cc = CartoContext(\n                base_url='https://your_user_name.carto.com',\n                api_key='your api key'\n            )\n            vector.vmap([vector.Layer('table in your account'), ], cc)\n\n        CARTO basemap style.\n\n        .. code::\n\n            from cartoframes.contrib import vector\n            from cartoframes import CartoContext\n            cc = CartoContext(\n                base_url='https://your_user_name.carto.com',\n                api_key='your api key'\n            )\n            vector.vmap(\n                [vector.Layer('table in your account'), ],\n                context=cc,\n                basemap=vector.BaseMaps.darkmatter\n            )\n\n        Custom basemap style. Here we use the Mapbox streets style, which\n        requires an access token.\n\n        .. code::\n\n            from cartoframes.contrib import vector\n            from cartoframes import CartoContext\n            cc = CartoContext(\n                base_url='https://<username>.carto.com',\n                api_key='your api key'\n            )\n            vector.vmap(\n                [vector.Layer('table in your account'), ],\n                context=cc,\n                basemap={\n                    'style': 'mapbox://styles/mapbox/streets-v9',\n                    'token: '<your mapbox token>'\n                }\n            )\n\n        Custom bounds\n\n        .. code::\n\n            from cartoframes.contrib import vector\n            from cartoframes import CartoContext\n            cc = CartoContext(\n                base_url='https://<username>.carto.com',\n                api_key='your api key'\n            )\n            vector.vmap(\n                [vector.Layer('table in your account'), ],\n                context=cc,\n                bounds={'west': -10, 'east': 10, 'north': -10, 'south': 10}\n            )\n\n        Adjusting the map's viewport.\n\n        .. code::\n\n            from cartoframes.contrib import vector\n            from cartoframes import CartoContext\n            cc = CartoContext(\n                base_url='https://<username>.carto.com',\n                api_key='your api key'\n            )\n            vector.vmap(\n                [vector.Layer('table in your account'), ],\n                context=cc,\n                viewport={'lng': 10, 'lat': 15, 'zoom': 10, 'bearing': 90, 'pitch': 45}\n            )\n    \"\"\"\n    if bounds:\n        bounds = _format_bounds(bounds)\n    else:\n        bounds = _get_super_bounds(layers, context)\n\n    jslayers = []\n    for _, layer in enumerate(layers):\n        is_local = isinstance(layer, LocalLayer)\n        intera = (\n            dict(event=layer.interactivity, header=layer.header)\n            if layer.interactivity is not None\n            else None\n        )\n        jslayers.append({\n            'is_local': is_local,\n            'styling': layer.styling,\n            'source': layer._geojson_str if is_local else layer.query,\n            'interactivity': intera,\n            'legend': layer.legend\n        })\n\n    _carto_vl_path = kwargs.get('_carto_vl_path', _DEFAULT_CARTO_VL_PATH)\n    _airship_path = kwargs.get('_airship_path', None)\n\n    html = _get_html_doc(\n            size,\n            jslayers,\n            bounds,\n            creds=context.creds,\n            viewport=viewport,\n            basemap=basemap,\n            _carto_vl_path=_carto_vl_path,\n            _airship_path=_airship_path)\n    return HTML(html)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dictionary of bounding boxes of all local layers in a sequence of objects.", "response": "def _get_bounds_local(layers):\n    \"\"\"Aggregates bounding boxes of all local layers\n\n        return: dict of bounding box of all bounds in layers\n    \"\"\"\n    if not layers:\n        return {'west': None, 'south': None, 'east': None, 'north': None}\n\n    bounds = layers[0].bounds\n\n    for layer in layers[1:]:\n        bounds = np.concatenate(\n            (\n                np.minimum(\n                    bounds[:2],\n                    layer.bounds[:2]\n                ),\n                np.maximum(\n                    bounds[2:],\n                    layer.bounds[2:]\n                )\n            )\n        )\n\n    return dict(zip(['west', 'south', 'east', 'north'], bounds))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking two bounding boxes dicts and gives a new bbox that encompasses them both", "response": "def _combine_bounds(bbox1, bbox2):\n    \"\"\"Takes two bounding boxes dicts and gives a new bbox that encompasses\n    them both\"\"\"\n    WORLD = {'west': -180, 'south': -85.1, 'east': 180, 'north': 85.1}\n    ALL_KEYS = set(WORLD.keys())\n\n    def dict_all_nones(bbox_dict):\n        \"\"\"Returns True if all dict values are None\"\"\"\n        return all(v is None for v in bbox_dict.values())\n\n    # if neither are defined, use the world\n    if not bbox1 and not bbox2:\n        return WORLD\n    # if all nones, use the world\n    if dict_all_nones(bbox1) and dict_all_nones(bbox2):\n        return WORLD\n\n    assert ALL_KEYS == set(bbox1.keys()) and ALL_KEYS == set(bbox2.keys()),\\\n        'Input bounding boxes must have the same dictionary keys'\n    # create dict with cardinal directions and None-valued keys\n    outbbox = dict.fromkeys(['west', 'south', 'east', 'north'])\n\n    def conv2nan(val):\n        \"\"\"convert Nones to np.nans\"\"\"\n        return np.nan if val is None else val\n\n    # set values and/or defaults\n    for coord in ('north', 'east'):\n        outbbox[coord] = np.nanmax([\n                conv2nan(bbox1[coord]),\n                conv2nan(bbox2[coord])\n            ])\n    for coord in ('south', 'west'):\n        outbbox[coord] = np.nanmin([\n                conv2nan(bbox1[coord]),\n                conv2nan(bbox2[coord])\n            ])\n\n    return outbbox"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _compose_style(self):\n        valid_styles = (\n            'color', 'width', 'filter', 'strokeWidth', 'strokeColor',\n        )\n        self.styling = '\\n'.join(\n            '{prop}: {style}'.format(prop=s, style=getattr(self, s))\n            for s in valid_styles\n            if getattr(self, s) is not None\n        )", "response": "Appends prop with style to layer styling"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds interactivity syntax to the styling", "response": "def _set_interactivity(self, interactivity):\n        \"\"\"Adds interactivity syntax to the styling\"\"\"\n        event_default = 'hover'\n        if interactivity is None:\n            return\n        if isinstance(interactivity, (tuple, list)):\n            self.interactivity = event_default\n            interactive_cols = '\\n'.join(\n                '@{0}: ${0}'.format(col) for col in interactivity\n            )\n        elif isinstance(interactivity, str):\n            self.interactivity = event_default\n            interactive_cols = '@{0}: ${0}'.format(interactivity)\n        elif isinstance(interactivity, dict):\n            self.interactivity = interactivity.get('event', event_default)\n            self.header = interactivity.get('header')\n            interactive_cols = '\\n'.join(\n                '@{0}: ${0}'.format(col) for col in interactivity['cols']\n            )\n        else:\n            raise ValueError('`interactivity` must be a str, a list of str, '\n                             'or a dict with a `cols` key')\n\n        self.styling = '\\n'.join([interactive_cols, self.styling])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_countrytag(country):\n    norm_name = {\n        'australia': 'Australia',\n        'brazil': 'Brazil',\n        'brasil': 'Brazil',\n        'canada': 'Canada',\n        'european union': 'European Union',\n        'eu': 'European Union',\n        'e.u.': 'European Union',\n        'france': 'France',\n        'mexico': 'Mexico',\n        'm\u00e9xico': 'Mexico',\n        'm\u00e9jico': 'Mexico',\n        'spain': 'Spain',\n        'espana': 'Spain',\n        'espa\u00f1a': 'Spain',\n        'uk': 'United Kingdom',\n        'u.k.': 'United Kingdom',\n        'united kingdom': 'United Kingdom',\n        'united states of america': 'United States',\n        'united states': 'United States',\n        'us': 'United States',\n        'usa': 'United States',\n        'u.s.': 'United States',\n        'u.s.a.': 'United States'\n    }\n    if country is not None and country.lower() in norm_name:\n        return REGIONTAGS.get(norm_name.get(country.lower()))\n    else:\n        raise ValueError(\n            'The available regions are {0}.'.format(\n                ', '.join('\\'{}\\''.format(k) for k in REGIONTAGS)))", "response": "get the region tag for a given country"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a map name based on supplied parameters", "response": "def get_map_name(layers, has_zoom):\n    \"\"\"Creates a map named based on supplied parameters\"\"\"\n    version = '20170406'\n    num_layers = len(non_basemap_layers(layers))\n    has_labels = len(layers) > 1 and layers[-1].is_basemap\n    has_time = has_time_layer(layers)\n    basemap_id = dict(light=0, dark=1, voyager=2)[layers[0].source]\n\n    return ('cartoframes_ver{version}'\n            '_layers{layers}'\n            '_time{has_time}'\n            '_baseid{baseid}'\n            '_labels{has_labels}'\n            '_zoom{has_zoom}').format(\n                version=version,\n                layers=num_layers,\n                has_time=('1' if has_time else '0'),\n                # TODO: Remove this once baselayer urls can be passed in named\n                #       map config\n                baseid=basemap_id,\n                has_labels=('1' if has_labels else '0'),\n                has_zoom=('1' if has_zoom else '0')\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a map template based on custom parameters supplied", "response": "def get_map_template(layers, has_zoom):\n    \"\"\"Creates a map template based on custom parameters supplied\"\"\"\n    num_layers = len(non_basemap_layers(layers))\n    has_time = has_time_layer(layers)\n    name = get_map_name(layers, has_zoom=has_zoom)\n\n    # Add basemap layer\n    layers_field = [{\n        'type': 'http',\n        'options': {\n            # TODO: Remove this once baselayer urls can be passed in named map\n            #       config\n            'urlTemplate': layers[0].url,\n            # 'urlTemplate': '<%= basemap_url %>',\n            'subdomains': \"abcd\",\n        },\n    }]\n\n    # [BUG] Remove this once baselayer urls can be passed in named map config\n    placeholders = {}\n    # placeholders = {\n    #     'basemap_url': {\n    #         'type': 'sql_ident',\n    #         'default': ('https://cartodb-basemaps-{s}.global.ssl.fastly.net/'\n    #                     'dark_all/{z}/{x}/{y}.png'),\n    #     },\n    # }\n\n    for idx in range(num_layers):\n        layers_field.extend([{\n            'type': ('torque' if (has_time and idx == (num_layers - 1))\n                     else 'mapnik'),\n            'options': {\n                'cartocss_version': '2.1.1',\n                'cartocss': '<%= cartocss_{idx} %>'.format(idx=idx),\n                'sql': '<%= sql_{idx} %>'.format(idx=idx),\n                # [BUG] No [] for templating\n                # 'interactivity': '<%= interactivity_{idx} %>'.format(\n                #                                                 idx=idx),\n            }\n        }])\n        placeholders.update({\n            'cartocss_{idx}'.format(idx=idx): {\n                'type': 'sql_ident',\n                'default': ('#layer {'\n                            ' marker-fill: red;'\n                            ' marker-width: 5;'\n                            ' marker-allow-overlap: true;'\n                            ' marker-line-color: #000; }'),\n            },\n            'sql_{idx}'.format(idx=idx): {\n                'type': 'sql_ident',\n                'default': (\n                        \"SELECT \"\n                        \"ST_PointFromText('POINT(0 0)', 4326) AS the_geom, \"\n                        \"1 AS cartodb_id, \"\n                        \"ST_PointFromText('Point(0 0)', 3857) AS \"\n                        \"the_geom_webmercator\"\n                    ),\n            },\n            # [BUG] No [] for templating\n            # 'interactivity_{idx}'.format(idx=idx): {\n            #     'type': 'sql_ident',\n            #     'default': '[\"cartodb_id\"]',\n            # },\n        })\n\n    # Add labels if they're in front\n    if num_layers > 0 and layers[-1].is_basemap:\n        layers_field.extend([{\n            'type': 'http',\n            'options': {\n                # TODO: Remove this once baselayer urls can be passed in named\n                #       map config\n                'urlTemplate': layers[-1].url,\n                # 'urlTemplate': '<%= basemap_url %>',\n                'subdomains': \"abcd\",\n            },\n        }])\n\n    if has_zoom:\n        view = {\n            'zoom': '<%= zoom %>',\n            'center': {\n                'lng': '<%= lng %>',\n                'lat': '<%= lat %>',\n            },\n        }\n        placeholders.update({\n            'zoom': {\n                'type': 'number',\n                'default': 3,\n            },\n            'lng': {\n                'type': 'number',\n                'default': 0,\n            },\n            'lat': {\n                'type': 'number',\n                'default': 0,\n            },\n        })\n    else:\n        view = {\n            'bounds': {\n                'west': '<%= west %>',\n                'south': '<%= south %>',\n                'east': '<%= east %>',\n                'north': '<%= north %>',\n            },\n        }\n        placeholders.update({\n            'west': {\n                'type': 'number',\n                'default': -45,\n            },\n            'south': {\n                'type': 'number',\n                'default': -45,\n            },\n            'east': {\n                'type': 'number',\n                'default':  45,\n            },\n            'north': {\n                'type': 'number',\n                'default':  45,\n            },\n        })\n\n    return json.dumps({\n        'version': '0.0.1',\n        'name': name,\n        'placeholders': placeholders,\n        'layergroup': {\n            'version': '1.0.1',\n            'layers': layers_field,\n        },\n        'view': view,\n    })"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the color and scheme from the color parameter.", "response": "def _parse_color(self, color):\n        \"\"\"Setup the color scheme\"\"\"\n        # If column was specified, force a scheme\n        # It could be that there is a column named 'blue' for example\n        if isinstance(color, dict):\n            if 'column' not in color:\n                raise ValueError(\"Color must include a 'column' value\")\n            # get scheme if exists. if not, one will be chosen later if needed\n            scheme = color.get('scheme')\n            color = color['column']\n            self.style_cols[color] = None\n        elif (color and\n              color[0] != '#' and\n              color not in webcolors.CSS3_NAMES_TO_HEX):\n            # color specified that is not a web color or hex value so its\n            #  assumed to be a column name\n            color = color\n            self.style_cols[color] = None\n            scheme = None\n        else:\n            # assume it's a color (hex, rgb(...),  or webcolor name)\n            color = color\n            scheme = None\n\n        return color, scheme"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_columns(self):\n        geom_cols = {'the_geom', 'the_geom_webmercator', }\n        col_overlap = set(self.style_cols) & geom_cols\n        if col_overlap:\n            raise ValueError('Style columns cannot be geometry '\n                             'columns. `{col}` was chosen.'.format(\n                                 col=','.join(col_overlap)))", "response": "Validate the options in the styles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _choose_scheme(self):\n        if self.style_cols[self.color] in ('string', 'boolean', ):\n            self.scheme = antique(10)\n        elif self.style_cols[self.color] in ('number', ):\n            self.scheme = mint(5)\n        elif self.style_cols[self.color] in ('date', 'geometry', ):\n            raise ValueError(\n                'Cannot style column `{col}` of type `{type}`. It must be '\n                'numeric, text, or boolean.'.format(\n                    col=self.color, type=self.style_cols[self.color]))", "response": "Choose color scheme based on style_cols."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates the CartoCSS for time - based maps.", "response": "def _setup_time(self, basemap):\n        \"\"\"generates CartoCSS for time-based maps (torque)\"\"\"\n        # validate time column information\n        if self.geom_type != 'point':\n            raise ValueError('Cannot do time-based maps with data in '\n                             '`{query}` since this table does not contain '\n                             'point geometries'.format(\n                                 query=self.orig_query))\n        elif self.style_cols[self.time['column']] not in (\n                'number', 'date', ):\n            raise ValueError('Cannot create an animated map from column '\n                             '`{col}` because it is of type {t1}. It must '\n                             'be of type number or date.'.format(\n                                 col=self.time['column'],\n                                 t1=self.style_cols[self.time['column']]))\n\n        # don't use turbo-carto for animated maps\n        column = self.time['column']\n        frames = self.time['frames']\n        method = self.time['method']\n        duration = self.time['duration']\n        if (self.color in self.style_cols and\n                self.style_cols[self.color] in ('string', 'boolean', )):\n            self.query = minify_sql([\n                'SELECT',\n                '    orig.*, __wrap.cf_value_{col}',\n                'FROM ({query}) AS orig, (',\n                '    SELECT',\n                '      row_number() OVER (',\n                '        ORDER BY val_{col}_cnt DESC) AS cf_value_{col},',\n                '      {col}',\n                '    FROM (',\n                '        SELECT {col}, count({col}) AS val_{col}_cnt',\n                '        FROM ({query}) as orig',\n                '        GROUP BY {col}',\n                '        ORDER BY 2 DESC',\n                '    ) AS _wrap',\n                ') AS __wrap',\n                'WHERE __wrap.{col} = orig.{col}',\n            ]).format(col=self.color, query=self.orig_query)\n            agg_func = '\\'CDB_Math_Mode(cf_value_{})\\''.format(self.color)\n            self.scheme = {\n                'bins': [str(i) for i in range(1, 11)],\n                'name': (self.scheme.get('name') if self.scheme\n                         else 'Bold'),\n                'bin_method': '', }\n        elif (self.color in self.style_cols and\n              self.style_cols[self.color] in ('number', )):\n            self.query = ' '.join([\n                'SELECT *, {col} as value',\n                'FROM ({query}) as _wrap'\n            ]).format(col=self.color, query=self.orig_query)\n            agg_func = '\\'avg({})\\''.format(self.color)\n        else:\n            agg_func = \"'{method}(cartodb_id)'\".format(\n                method=method)\n        self.torque_cartocss = cssify({\n            'Map': {\n                '-torque-frame-count': frames,\n                '-torque-animation-duration': duration,\n                '-torque-time-attribute': \"'{}'\".format(column),\n                '-torque-aggregation-function': agg_func,\n                '-torque-resolution': 1,\n                '-torque-data-aggregation': ('cumulative'\n                                             if self.time['cumulative']\n                                             else 'linear'),\n            },\n        })\n        self.cartocss = (self.torque_cartocss\n                         + self._get_cartocss(basemap, has_time=True))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating cartocss for class properties", "response": "def _get_cartocss(self, basemap, has_time=False):\n        \"\"\"Generate cartocss for class properties\"\"\"\n        if isinstance(self.size, (int, float)):\n            size_style = self.size\n        elif isinstance(self.size, dict):\n            self.size['range'] = (\n                [1, 5] if self.size['range'] == [5, 25]\n                else self.size['range']\n            )\n            size_style = ('ramp([{column}],'\n                          ' range({min_range},{max_range}),'\n                          ' {bin_method}({bins}))').format(\n                              column=self.size['column'],\n                              min_range=self.size['range'][0],\n                              max_range=self.size['range'][1],\n                              bin_method=self.size['bin_method'],\n                              bins=self.size['bins'])\n\n        if self.scheme:\n            color_style = get_scheme_cartocss(\n                'value' if has_time else self.color,\n                self.scheme)\n        else:\n            color_style = self.color\n\n        line_color = '#000' if basemap.source == 'dark' else '#FFF'\n        if self.time:\n            css = cssify({\n                # Torque Point CSS\n                \"#layer\": {\n                    'marker-width': size_style,\n                    'marker-fill': color_style,\n                    'marker-fill-opacity': self.opacity,\n                    'marker-allow-overlap': 'true',\n                    'marker-line-width': 0,\n                    'marker-line-color': line_color,\n                    'marker-line-opacity': 1,\n                    'comp-op': 'source-over',\n                }\n            })\n            if self.color in self.style_cols:\n                css += cssify({\n                    '#layer[{} = null]'.format(self.color): {\n                        'marker-fill': '#666'}\n                    })\n            for trail_num in range(1, self.time['trails'] + 1):\n                # Trails decay as 1/2^n, and grow 30% at each step\n                trail_temp = cssify({\n                    '#layer[frame-offset={}]'.format(trail_num): {\n                        'marker-width': size_style * (1.0 + trail_num * 0.3),\n                        'marker-opacity': 0.9 / 2.0**trail_num,\n                    }\n                })\n                css += trail_temp\n            return css\n        else:\n            if self.geom_type == 'point':\n                css = cssify({\n                    # Point CSS\n                    \"#layer\": {\n                        'marker-width': size_style,\n                        'marker-fill': color_style,\n                        'marker-fill-opacity': self.opacity,\n                        'marker-allow-overlap': 'true',\n                        'marker-line-width': '0.5',\n                        'marker-line-color': line_color,\n                        'marker-line-opacity': '1',\n                    }})\n                if self.color in self.style_cols:\n                    css += cssify({\n                        '#layer[{} = null]'.format(self.color): {\n                            'marker-fill': '#ccc'}\n                        })\n                return css\n            if self.geom_type == 'line':\n                css = cssify({\n                    \"#layer\": {\n                        'line-width': size_style,\n                        'line-color': color_style,\n                        'line-opacity': self.opacity\n                    }})\n                if self.color in self.style_cols:\n                    css += cssify({\n                        '#layer[{} = null]'.format(self.color): {\n                            'line-color': '#ccc'}\n                        })\n                return css\n            if self.geom_type == 'polygon':\n                css = cssify({\n                    \"#layer\": {\n                        'polygon-fill': color_style,\n                        'polygon-opacity': self.opacity,\n                        'polygon-gamma': '0.5',\n                        'line-color': '#FFF',\n                        'line-width': '0.5',\n                        'line-opacity': '0.25',\n                        'line-comp-op': 'hard-light',\n                    }})\n                if self.color in self.style_cols:\n                    css += cssify({\n                        '#layer[{} = null]'.format(self.color): {\n                            'polygon-fill': '#ccc'}\n                        })\n                return css\n            else:\n                raise ValueError('Unsupported geometry type: {}'.format(\n                    self.geom_type))"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nfunctions to get CartoCSS from Python dicts", "response": "def cssify(css_dict):\n    \"\"\"Function to get CartoCSS from Python dicts\"\"\"\n    css = ''\n    for key, value in dict_items(css_dict):\n        css += '{key} {{ '.format(key=key)\n        for field, field_value in dict_items(value):\n            css += ' {field}: {field_value};'.format(field=field,\n                                                     field_value=field_value)\n        css += '} '\n    return css.strip()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_columns(context, query):\n        table_info = context.sql_client.send(query)\n        if 'fields' in table_info:\n            return Column.from_sql_api_fields(table_info['fields'])\n\n        return None", "response": "Get list of cartoframes. columns. Column"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting column names and types from a query", "response": "def get_column_names(context, query):\n        \"\"\"Get column names and types from a query\"\"\"\n        table_info = context.sql_client.send(query)\n        if 'fields' in table_info:\n            return table_info['fields']\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _encode_decode_decorator(func):\n    def wrapper(*args):\n        \"\"\"error catching\"\"\"\n        try:\n            processed_geom = func(*args)\n            return processed_geom\n        except ImportError as err:\n            raise ImportError('The Python package `shapely` needs to be '\n                              'installed to encode or decode geometries. '\n                              '({})'.format(err))\n    return wrapper", "response": "decorator for encoding and decoding geoms"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode encoded wkb into a shapely geometry", "response": "def _decode_geom(ewkb):\n    \"\"\"Decode encoded wkb into a shapely geometry\n    \"\"\"\n    # it's already a shapely object\n    if hasattr(ewkb, 'geom_type'):\n        return ewkb\n\n    from shapely import wkb\n    from shapely import wkt\n    if ewkb:\n        try:\n            return wkb.loads(ba.unhexlify(ewkb))\n        except Exception:\n            try:\n                return wkb.loads(ba.unhexlify(ewkb), hex=True)\n            except Exception:\n                try:\n                    return wkb.loads(ewkb, hex=True)\n                except Exception:\n                    try:\n                        return wkb.loads(ewkb)\n                    except Exception:\n                        try:\n                            return wkt.loads(ewkb)\n                        except Exception:\n                            pass\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks to see if the table exists", "response": "def exists(self):\n        \"\"\"Checks to see if table exists\"\"\"\n        try:\n            self.cc.sql_client.send(\n                'EXPLAIN SELECT * FROM \"{table_name}\"'.format(\n                    table_name=self.table_name),\n                do_post=False)\n            return True\n        except CartoException as err:\n            # If table doesn't exist, we get an error from the SQL API\n            self.cc._debug_print(err=err)\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating the read query", "response": "def _get_read_query(self, table_columns, limit=None):\n        \"\"\"Create the read (COPY TO) query\"\"\"\n        query_columns = [column.name for column in table_columns]\n        query_columns.remove('the_geom_webmercator')\n\n        query = 'SELECT {columns} FROM \"{schema}\".\"{table_name}\"'.format(\n            table_name=self.table_name,\n            schema=self.schema,\n            columns=', '.join(query_columns))\n\n        if limit is not None:\n            if isinstance(limit, int) and (limit >= 0):\n                query += ' LIMIT {limit}'.format(limit=limit)\n            else:\n                raise ValueError(\"`limit` parameter must an integer >= 0\")\n\n        return query"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_table_columns(self):\n        query = 'SELECT * FROM \"{schema}\".\"{table}\" limit 0'.format(table=self.table_name, schema=self.schema)\n        return get_columns(self.cc, query)", "response": "Get column names and types from a table"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets column names and types from a table", "response": "def get_table_column_names(self, exclude=None):\n        \"\"\"Get column names and types from a table\"\"\"\n        query = 'SELECT * FROM \"{schema}\".\"{table}\" limit 0'.format(table=self.table_name, schema=self.schema)\n        columns = get_column_names(self.cc, query).keys()\n\n        if exclude and isinstance(exclude, list):\n            columns = list(set(columns) - set(exclude))\n\n        return columns"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave current user credentials to user directory.", "response": "def save(self, config_loc=None):\n        \"\"\"Saves current user credentials to user directory.\n\n        Args:\n            config_loc (str, optional): Location where credentials are to be\n                stored. If no argument is provided, it will be send to the\n                default location.\n\n        Example:\n\n            .. code::\n\n                from cartoframes import Credentials\n                creds = Credentials(username='eschbacher', key='abcdefg')\n                creds.save()  # save to default location\n\n        \"\"\"\n        if not os.path.exists(_USER_CONFIG_DIR):\n            \"\"\"create directory if not exists\"\"\"\n            os.makedirs(_USER_CONFIG_DIR)\n        with open(_DEFAULT_PATH, 'w') as f:\n            json.dump({'key': self._key, 'base_url': self._base_url,\n                       'username': self._username}, f)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, config_file=None):\n        path_to_remove = config_file or _DEFAULT_PATH\n        try:\n            os.remove(path_to_remove)\n            print('Credentials at {} successfully removed.'.format(\n                path_to_remove))\n        except OSError as err:\n            warnings.warn('No credential file found at {}.'.format(\n                path_to_remove))", "response": "Deletes the credentials file specified in config_file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the credentials of a Credentials instance instead with new values.", "response": "def set(self, key=None, username=None, base_url=None):\n        \"\"\"Update the credentials of a Credentials instance instead with new\n        values.\n\n        Args:\n            key (str): API key of user account. Defaults to previous value if\n                not specified.\n            username (str): User name of account. This parameter is optional if\n                `base_url` is not specified, but defaults to the previous\n                value if not set.\n            base_url (str): Base URL of user account. This parameter is\n                optional if `username` is specified and on CARTO's\n                cloud-based account. Generally of the form\n                ``https://your_user_name.carto.com/`` for cloud-based accounts.\n                If on-prem or otherwise, contact your admin.\n\n        Example:\n\n            .. code::\n\n                from cartoframes import Credentials\n                # load credentials saved in previous session\n                creds = Credentials()\n                # set new API key\n                creds.set(key='new_api_key')\n                # save new creds to default user config directory\n                creds.save()\n\n        Note:\n            If the `username` is specified but the `base_url` is not, the\n            `base_url` will be updated to ``https://<username>.carto.com/``.\n        \"\"\"\n        self.__init__(key=(key or self._key),\n                      username=(username or self._username),\n                      base_url=base_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning or set the base_url.", "response": "def base_url(self, base_url=None):\n        \"\"\"Return or set `base_url`.\n\n        Args:\n            base_url (str, optional): If set, updates the `base_url`. Otherwise\n                returns current `base_url`.\n\n        Note:\n            This does not update the `username` attribute. Separately update\n            the username with ``Credentials.username`` or update `base_url` and\n            `username` at the same time with ``Credentials.set``.\n\n        Example:\n\n            .. code::\n\n                >>> from cartoframes import Credentials\n                # load credentials saved in previous session\n                >>> creds = Credentials()\n                # returns current base_url\n                >>> creds.base_url()\n                'https://eschbacher.carto.com/'\n                # updates base_url with new value\n                >>> creds.base_url('new_base_url')\n        \"\"\"\n        if base_url:\n            # POSTs need to be over HTTPS (e.g., Import API reverts to a GET)\n            if urlparse(base_url).scheme != 'https':\n                raise ValueError(\n\t\t    '`base_url`s need to be over `https`. Update your '\n                    '`base_url`.'\n\t\t)\n            self._base_url = base_url\n        else:\n            return self._base_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_child(self, child):\n        if not issubclass(child.__class__, SceneGraph):\n            raise TypeError(\"child must have parent/child iteration implemented to be a node in a SceneGraph.\")\n        # if not hasattr(child, 'update'):\n            # raise TypeError(\"child must have an attribute update()\")\n\n        child._parent = self\n        self._children.append(child)", "response": "Adds an object as a child in the scene graph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd objects as children in the scene graph.", "response": "def add_children(self, *children, **kwargs):\n        \"\"\"Conveniience function: Adds objects as children in the scene graph.\"\"\"\n        for child in children:\n            self.add_child(child, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        params = {}\n        for key, val in self.__dict__.items():\n            if 'matrix' not in key:\n                k = key[1:] if key[0] == '_' else key\n                params[k] = val\n        # params = {param: params[param] for param in params}\n        return self.__class__(**params)", "response": "Returns a copy of the projection matrix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate Camera. aspect to match the viewport s aspect ratio.", "response": "def match_aspect_to_viewport(self):\n        \"\"\"Updates Camera.aspect to match the viewport's aspect ratio.\"\"\"\n        viewport = self.viewport\n        self.aspect = float(viewport.width) / viewport.height"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the projection matrix.", "response": "def _update_projection_matrix(self):\n        \"\"\"np.array: The Camera's Projection Matrix.  Will be an Orthographic matrix if ortho_mode is set to True.\"\"\"\n\n        # replace gluPerspective (https://www.opengl.org/sdk/docs/man2/xhtml/gluPerspective.xml)\n        ff = 1./np.tan(np.radians(self.fov_y / 2.)) # cotangent(fovy/2)\n        zn, zf = self.z_near, self.z_far\n\n        persp_mat =  np.array([[ff/self.aspect,    0.,              0.,                 0.],\n                              [             0.,    ff,              0.,                 0.],\n                              [             0.,    0., (zf+zn)/(zn-zf), (2.*zf*zn)/(zn-zf)],\n                              [             0.,    0.,             -1.,                 0.]], dtype=np.float32)\n\n        self.projection_matrix[:] = np.dot(persp_mat, self._get_shift_matrix())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef to_pickle(self, filename):\n        with open(filename, 'wb') as f:\n            pickle.dump(self, f)", "response": "Save the current camera to a pickle file given a filename."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload and Returns a Camera from a pickle file given a filename.", "response": "def from_pickle(cls, filename):\n        \"\"\"Loads and Returns a Camera from a pickle file, given a filename.\"\"\"\n        with open(filename, 'rb') as f:\n            cam = pickle.load(f)\n\n        projection = cam.projection.copy()\n        return cls(projection=projection, position=cam.position.xyz, rotation=cam.rotation.__class__(*cam.rotation[:]))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef look_at(self, x, y, z):\n        for camera in self.cameras:\n            camera.look_at(x, y, z)", "response": "Converges the two cameras to look at the specific point"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bind(self):\n        # This is called simply to deal with anything that might be currently bound (for example, Pyglet objects),\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n\n        # Store current viewport size for later\n        self._old_viewport = get_viewport()\n\n        # Bind the FBO, and change the viewport to fit its texture.\n        gl.glBindFramebufferEXT(gl.GL_FRAMEBUFFER_EXT, self.id)  # Rendering off-screen\n        gl.glViewport(0, 0, self.texture.width, self.texture.height)", "response": "Bind the FBO. Anything drawn afterward will be stored in the FBO s texture."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef unbind(self):\n        # Unbind the FBO\n        if self.texture.mipmap:\n            with self.texture:\n                self.texture.generate_mipmap()\n\n        gl.glBindFramebufferEXT(gl.GL_FRAMEBUFFER_EXT, 0)\n\n        # Restore the old viewport size\n        gl.glViewport(*self._old_viewport)", "response": "Unbind the FBO and restore the viewport size."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_opengl_object(gl_gen_function, n=1):\n    handle = gl.GLuint(1)\n    gl_gen_function(n, byref(handle))  # Create n Empty Objects\n    if n > 1:\n        return [handle.value + el for el in range(n)]  # Return list of handle values\n    else:\n        return handle.value", "response": "Creates an OpenGL texture object"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef vec(data, dtype=float):\n        gl_types = {float: gl.GLfloat, int: gl.GLuint}\n        try:\n            gl_dtype = gl_types[dtype]\n        except KeyError:\n            raise TypeError('dtype not recognized.  Recognized types are int and float')\n\n        if gl_dtype == gl.GLuint:\n            for el in data:\n                if el < 0:\n                    raise ValueError(\"integer ratcave.vec arrays are unsigned--negative values are not supported.\")\n\n        return (gl_dtype * len(data))(*data)", "response": "Makes a GLfloat or GLuint vector containing float or uint args."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn Nx3 normal array from Nx3 vertex array.", "response": "def calculate_normals(vertices):\n    \"\"\"Return Nx3 normal array from Nx3 vertex array.\"\"\"\n    verts = np.array(vertices, dtype=float)\n    normals = np.zeros_like(verts)\n    for start, end in pairwise(np.arange(0, verts.shape[0] + 1, 3)):\n        vecs = np.vstack((verts[start + 1] - verts[start], verts[start + 2] - verts[start]))  # Get triangle of vertices and calculate 2-1 and 3-1\n        vecs /= np.linalg.norm(vecs, axis=1, keepdims=True)  # normalize vectors\n        normal = np.cross(*vecs)  # normal is the cross products of vectors.\n        normals[start:end, :] = normal / np.linalg.norm(normal)\n    return normals"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw each visible mesh in the scene from the perspective of the scene s camera and lit by its light.", "response": "def draw(self, clear=True):\n        \"\"\"Draw each visible mesh in the scene from the perspective of the scene's camera and lit by its light.\"\"\"\n        if clear:\n            self.clear()\n\n        with self.gl_states, self.camera, self.light:\n            for mesh in self.meshes:\n                try:\n                    mesh.draw()\n                except AttributeError:\n                    pass"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw360_to_texture(self, cubetexture, **kwargs):\n\n        assert self.camera.projection.aspect == 1. and self.camera.projection.fov_y == 90  # todo: fix aspect property, which currently reads from viewport.\n        if not isinstance(cubetexture, TextureCube):\n            raise ValueError(\"Must render to TextureCube\")\n\n        # for face, rotation in enumerate([[180, 90, 0], [180, -90, 0], [90, 0, 0], [-90, 0, 0], [180, 0, 0], [0, 0, 180]]):\n        old_rotation = self.camera.rotation\n        self.camera.rotation = self.camera.rotation.to_euler(units='deg')\n        for face, rotation in enumerate([[180, -90, 0], [180, 90, 0], [90, 0, 0], [-90, 0, 0], [180, 0, 0], [0, 0, 180]]):  #first 2 switched\n            self.camera.rotation.xyz = rotation\n            cubetexture.attach_to_fbo(face)\n            self.draw(**kwargs)\n        self.camera.rotation = old_rotation", "response": "Draw each visible mesh in the scene from the perspective of the scene s camera and lit by its light and apply it to each face of cubetexture."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef assign_vertex_attrib_location(self, vbo, location):\n        with vbo:\n            if self.n_verts:\n                assert vbo.data.shape[0] == self.n_verts\n            else:\n                self.n_verts = vbo.data.shape[0]\n\n            # vbo.buffer_data()\n            gl.glVertexAttribPointer(location, vbo.data.shape[1], gl.GL_FLOAT, gl.GL_FALSE, 0, 0)\n            gl.glEnableVertexAttribArray(location)", "response": "Assign a vertex attribute to a vbo at a given location."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a copy of the Mesh.", "response": "def copy(self):\n        \"\"\"Returns a copy of the Mesh.\"\"\"\n        return Mesh(arrays=deepcopy([arr.copy() for arr in [self.vertices, self.normals, self.texcoords]]), texture=self.textures, mean_center=deepcopy(self._mean_center),\n                    position=self.position.xyz, rotation=self.rotation.__class__(*self.rotation[:]), scale=self.scale.xyz,\n                    drawmode=self.drawmode, point_size=self.point_size, dynamic=self.dynamic, visible=self.visible,\n                    gl_states=deepcopy(self.gl_states))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef from_pickle(cls, filename):\n        with open(filename, 'rb') as f:\n            mesh = pickle.load(f).copy()\n        return mesh", "response": "Loads and Returns a Mesh from a pickle file given a filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef reset_uniforms(self):\n        self.uniforms['model_matrix'] = self.model_matrix_global.view()\n        self.uniforms['normal_matrix'] = self.normal_matrix_global.view()", "response": "Resets the uniforms to the Mesh object to the \"\"global\"\" coordinate system"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a Mesh with vertices normals texcoords as arrays in that order.", "response": "def from_incomplete_data(cls, vertices, normals=(), texcoords=(), **kwargs):\n        \"\"\"Return a Mesh with (vertices, normals, texcoords) as arrays, in that order.\n           Useful for when you want a standardized array location format across different amounts of info in each mesh.\"\"\"\n        normals = normals if hasattr(texcoords, '__iter__') and len(normals) else vertutils.calculate_normals(vertices)\n        texcoords = texcoords if hasattr(texcoords, '__iter__') and len(texcoords) else np.zeros((vertices.shape[0], 2), dtype=np.float32)\n        return cls(arrays=(vertices, normals, texcoords), **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fill_vao(self):\n        with self.vao:\n            self.vbos = []\n            for loc, verts in enumerate(self.arrays):\n                vbo = VBO(verts)\n                self.vbos.append(vbo)\n                self.vao.assign_vertex_attrib_location(vbo, loc)", "response": "Put array location in VAO for shader in same order as arrays given to Mesh."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndraw the Mesh if it s visible.", "response": "def draw(self):\n        \"\"\" Draw the Mesh if it's visible, from the perspective of the camera and lit by the light. The function sends the uniforms\"\"\"\n        if not self.vao:\n            self.vao = VAO(indices=self.array_indices)\n            self._fill_vao()\n\n        if self.visible:\n            if self.dynamic:\n                for vbo in self.vbos:\n                    vbo._buffer_subdata()\n\n            if self.drawmode == gl.GL_POINTS:\n                gl.glPointSize(self.point_size)\n\n            for texture in self.textures:\n                texture.bind()\n\n            with self.vao as vao:\n                self.uniforms.send()\n                vao.draw(mode=self.drawmode)\n\n            for texture in self.textures:\n                texture.unbind()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a 3x3 cross - product matrix from a 3 - element vector.", "response": "def cross_product_matrix(vec):\n    \"\"\"Returns a 3x3 cross-product matrix from a 3-element vector.\"\"\"\n    return np.array([[0, -vec[2], vec[1]],\n                     [vec[2], 0, -vec[0]],\n                     [-vec[1], vec[0], 0]])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rotation_matrix_between_vectors(from_vec, to_vec):\n    a, b = (trans.unit_vector(vec) for vec in (from_vec, to_vec))\n\n    v = np.cross(a, b)\n    cos = np.dot(a, b)\n    if cos == -1.:\n        raise ValueError(\"Orientation in complete opposite direction\")\n    v_cpm = cross_product_matrix(v)\n    rot_mat = np.identity(3) + v_cpm + np.dot(v_cpm, v_cpm) * (1. / 1. + cos)\n    return rot_mat", "response": "Returns a rotation matrix to rotate from 3d vectors from_vec to to_vec."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _init_coord_properties(self):\n        def gen_getter_setter_funs(*args):\n            indices = [self.coords[coord] for coord in args]\n\n            def getter(self):\n                return tuple(self._array[indices]) if len(args) > 1 else self._array[indices[0]]\n\n            def setter(self, value):\n                setitem(self._array, indices, value)\n                self.notify_observers()\n\n            return getter, setter\n\n        for n_repeats in range(1, len(self.coords)+1):\n            for args in itertools.product(self.coords.keys(), repeat=n_repeats):\n                getter, setter = gen_getter_setter_funs(*args)\n                setattr(self.__class__, ''.join(args), property(fget=getter, fset=setter))", "response": "Generates combinations of named coordinate values mapping them to the internal array."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply some hard - coded texture filtering settings.", "response": "def _apply_filter_settings(self):\n        \"\"\"Applies some hard-coded texture filtering settings.\"\"\"\n        # TODO: Allow easy customization of filters\n        if self.mipmap:\n            gl.glTexParameterf(self.target, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR_MIPMAP_LINEAR)\n        else:\n            gl.glTexParameterf(self.target, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR)\n        gl.glTexParameterf(self.target, gl.GL_TEXTURE_MAG_FILTER, gl.GL_LINEAR)\n\n        gl.glTexParameterf(self.target, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP_TO_EDGE)\n        gl.glTexParameterf(self.target, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP_TO_EDGE)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef attach_to_fbo(self):\n        gl.glFramebufferTexture2DEXT(gl.GL_FRAMEBUFFER_EXT, self.attachment_point, self.target0, self.id, 0)", "response": "Attach the texture to a bound FBO object for rendering to texture."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_image(cls, img_filename, mipmap=False, **kwargs):\n        img = pyglet.image.load(img_filename)\n        tex = img.get_mipmapped_texture() if mipmap else img.get_texture()\n        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)\n        return cls(id=tex.id, data=tex, mipmap=mipmap, **kwargs)", "response": "Uses Pyglet s image. load function to generate a Texture from an image file."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ngenerate an empty texture in OpenGL", "response": "def _genTex2D(self):\n        \"\"\"Generate an empty texture in OpenGL\"\"\"\n        for face in range(6):\n            gl.glTexImage2D(self.target0 + face, 0, self.internal_fmt, self.width, self.height, 0,\n                            self.pixel_fmt, gl.GL_UNSIGNED_BYTE, 0)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_mesh(self, body_name, **kwargs):\n        body = self.bodies[body_name]\n        vertices = body['v']\n        normals = body['vn'] if 'vn' in body else None\n        texcoords = body['vt'] if 'vt' in body else None\n        mesh = Mesh.from_incomplete_data(vertices=vertices, normals=normals, texcoords=texcoords, **kwargs)\n\n        uniforms = kwargs['uniforms'] if 'uniforms' in kwargs else {}\n        if 'material' in body:\n            material_props = {self.material_property_map[key]: value for key, value in iteritems(body['material'])}\n            for key, value in iteritems(material_props):\n                if isinstance(value, str):\n                    if key == 'map_Kd':\n                        if not value in self.textures:\n                            self.textures[value] = Texture.from_image(value)\n                        mesh.textures.append(self.textures[value])\n                    else:\n                        setattr(mesh, key, value)\n                elif hasattr(value, '__len__'):  # iterable materials\n                    mesh.uniforms[key] = value\n                elif key in ['d', 'illum']:  # integer materials\n                    mesh.uniforms[key] = value\n                elif key in ['spec_weight', 'Ni']:  # float materials: should be specially converted to float if not already done.\n                    mesh.uniforms[key] = float(value)\n                else:\n                    print('Warning: Not applying uniform {}: {}'.format(key, value))\n        return mesh", "response": "Builds a mesh from the name in the wavefront file. Takes all keyword arguments that Mesh takes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends all the key - value pairs to the graphics card.", "response": "def send(self):\n        \"\"\"\n        Sends all the key-value pairs to the graphics card.\n        These uniform variables will be available in the currently-bound shader.\n        \"\"\"\n\n        for name, array in iteritems(self):\n\n            shader_id = c_int(0)\n            gl.glGetIntegerv(gl.GL_CURRENT_PROGRAM, byref(shader_id))\n            if shader_id.value == 0:\n                raise UnboundLocalError(\"\"\"Shader not bound to OpenGL context--uniform cannot be sent.\n                ------------ Tip -------------\n                with ratcave.default_shader:\n                    mesh.draw()\n                ------------------------------\n                \"\"\")\n\n            # Attach a shader location value to the array, for quick memory lookup. (gl calls are expensive, for some reason)\n            try:\n                loc, shader_id_for_array = array.loc\n                if shader_id.value != shader_id_for_array:\n                    raise Exception('Uniform location bound to a different shader')\n            except (AttributeError, Exception) as e:\n                array.loc = (gl.glGetUniformLocation(shader_id.value, name.encode('ascii')), shader_id.value)\n\n            if array.ndim == 2:  # Assuming a 4x4 float32 matrix (common for graphics operations)\n                try:\n                    pointer = array.pointer\n                except AttributeError:\n                    array.pointer = array.ctypes.data_as(POINTER(c_float * 16)).contents\n                    pointer = array.pointer\n                gl.glUniformMatrix4fv(array.loc[0], 1, True, pointer)\n\n            else:\n                sendfun = self._sendfuns[array.dtype.kind][len(array) - 1]  # Find correct glUniform function\n                sendfun(array.loc[0], *array)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef bind(self):\n        if not self.is_linked:\n            if not self.is_compiled:\n                self.compile()\n            self.link()\n        super(self.__class__, self).bind()", "response": "Activate this Shader making it the currently - bound program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading the shader programs given the vert and frag filenames and returns a new instance of the class", "response": "def from_file(cls, vert, frag, **kwargs):\n        \"\"\"\n        Reads the shader programs, given the vert and frag filenames\n\n        Arguments:\n            - vert (str): The filename of the vertex shader program (ex: 'vertshader.vert')\n            - frag (str): The filename of the fragment shader program (ex: 'fragshader.frag')\n\n        Returns:\n            - shader (Shader): The Shader using these files.\n        \"\"\"\n        vert_program = open(vert).read()\n        frag_program = open(frag).read()\n        return cls(vert=vert_program, frag=frag_program, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef link(self):\n        gl.glLinkProgram(self.id)\n\n        # Check if linking was successful.  If not, print the log.\n        link_status = c_int(0)\n        gl.glGetProgramiv(self.id, gl.GL_LINK_STATUS, byref(link_status))\n        if not link_status:\n            gl.glGetProgramiv(self.id, gl.GL_INFO_LOG_LENGTH, byref(link_status))  # retrieve the log length\n            buffer = create_string_buffer(link_status.value)  # create a buffer for the log\n            gl.glGetProgramInfoLog(self.id, link_status, None, buffer)  # retrieve the log text\n            print(buffer.value)  # print the log to the console\n\n        self.is_linked = True", "response": "link the program to the active shader."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef look_at(self, x, y, z):\n        new_ori = x - self.position.x, y - self.position.y, z - self.position.z\n        self.orientation = new_ori / np.linalg.norm(new_ori)", "response": "Rotate so orientation is toward ( x y z"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_child(self, child, modify=False):\n        SceneGraph.add_child(self, child)\n        self.notify()\n        if modify:\n            child._model_matrix_transform[:] = trans.inverse_matrix(self.model_matrix_global)\n            child._normal_matrix_transform[:] = trans.inverse_matrix(self.normal_matrix_global)", "response": "Adds an object as a child in the scene graph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nput widgets in the grid", "response": "def grid_widgets(self):\n        \"\"\"Put widgets in the grid\"\"\"\n        sticky = {\"sticky\": \"nswe\"}\n        self.label.grid(row=1, column=1, columnspan=2, **sticky)\n        self.dropdown.grid(row=2, column=1, **sticky)\n        self.entry.grid(row=2, column=2, **sticky)\n        self.button.grid(row=3, column=1, columnspan=2, **sticky)\n        self.radio_one.grid(row=4, column=1, **sticky)\n        self.radio_two.grid(row=4, column=2, **sticky)\n        self.checked.grid(row=5, column=1, **sticky)\n        self.unchecked.grid(row=5, column=2, **sticky)\n        self.scroll.grid(row=1, column=3, rowspan=8, padx=5, **sticky)\n        self.tree.grid(row=6, column=1, columnspan=2, **sticky)\n        self.scale_entry.grid(row=7, column=1, columnspan=2, **sticky)\n        self.combo.grid(row=8, column=1, columnspan=2, **sticky)\n        self.progress.grid(row=9, column=1, columnspan=2, padx=5, pady=5, **sticky)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef screenshot(self, *args):\n        from mss import mss\n        if not os.path.exists(\"screenshots\"):\n            os.makedirs(\"screenshots\")\n        box = {\n            \"top\": self.winfo_y(),\n            \"left\": self.winfo_x(),\n            \"width\": self.winfo_width(),\n            \"height\": self.winfo_height()\n        }\n        screenshot = mss().grab(box)\n        screenshot = Image.frombytes(\"RGB\", screenshot.size, screenshot.rgb)\n        screenshot.save(\"screenshots/{}.png\".format(ttk.Style(self).theme_use()))", "response": "Take a screenshot crop and save"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntaking a screenshot for all themes available", "response": "def screenshot_themes(self, *args):\n        \"\"\"Take a screenshot for all themes available\"\"\"\n        from time import sleep\n        for theme in THEMES:\n            example.set_theme(theme)\n            example.update()\n            sleep(0.05)\n            self.screenshot()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _load_themes(self):\n        with utils.temporary_chdir(utils.get_file_directory()):\n            self._append_theme_dir(\"themes\")\n            self.tk.eval(\"source themes/pkgIndex.tcl\")\n            theme_dir = \"gif\" if not self.png_support else \"png\"\n            self._append_theme_dir(theme_dir)\n            self.tk.eval(\"source {}/pkgIndex.tcl\".format(theme_dir))\n        self.tk.call(\"package\", \"require\", \"ttk::theme::scid\")", "response": "Load the themes into the Tkinter interpreter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nappend a theme dir to the Tk interpreter auto_path", "response": "def _append_theme_dir(self, name):\n        \"\"\"Append a theme dir to the Tk interpreter auto_path\"\"\"\n        path = \"[{}]\".format(get_file_directory() + \"/\" + name)\n        self.tk.call(\"lappend\", \"auto_path\", path)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset new theme to use. Uses a direct tk call to allow usage of the themes supplied with this package.", "response": "def set_theme(self, theme_name):\n        \"\"\"\n        Set new theme to use. Uses a direct tk call to allow usage\n        of the themes supplied with this package.\n\n        :param theme_name: name of theme to activate\n        \"\"\"\n        package = theme_name if theme_name not in self.PACKAGES else self.PACKAGES[theme_name]\n        self.tk.call(\"package\", \"require\", \"ttk::theme::{}\".format(package))\n        self.tk.call(\"ttk::setTheme\", theme_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _setup_images(directory, brightness, saturation, hue, preserve_transparency):\n        for file_name in os.listdir(directory):\n            with open(os.path.join(directory, file_name), \"rb\") as fi:\n                image = Image.open(fi).convert(\"RGBA\")\n            # Only perform required operations\n            if brightness != 1.0:\n                enhancer = ImageEnhance.Brightness(image)\n                image = enhancer.enhance(brightness)\n            if saturation != 1.0:\n                enhancer = ImageEnhance.Color(image)\n                image = enhancer.enhance(saturation)\n            if hue != 1.0:\n                image = imgops.shift_hue(image, hue)\n            if preserve_transparency is True:\n                image = imgops.make_transparent(image)\n            # Save the new image\n            image.save(os.path.join(directory, file_name.replace(\"gif\", \"png\")))\n            image.close()\n        for file_name in (item for item in os.listdir(directory) if item.endswith(\".gif\")):\n            os.remove(os.path.join(directory, file_name))", "response": "Setup the images of a theme based on the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_theme(self, theme_name, toplevel=None, themebg=None):\n        if self._toplevel is not None and toplevel is None:\n            toplevel = self._toplevel\n        if self._themebg is not None and themebg is None:\n            themebg = self._themebg\n        ThemedWidget.set_theme(self, theme_name)\n        color = self._get_bg_color()\n        if themebg is True:\n            self.config(background=color)\n        if toplevel is True:\n            self._setup_toplevel_hook(color)", "response": "Redirect the set_theme call to also set Tk background color"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _setup_toplevel_hook(self, color):\n        def __toplevel__(*args, **kwargs):\n            kwargs.setdefault(\"background\", color)\n            self.__init__toplevel(*args, **kwargs)\n\n        tk.Toplevel.__init__ = __toplevel__", "response": "Setup Toplevel. __init__ hook for background color"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef config(self, kw=None, **kwargs):\n        themebg = kwargs.pop(\"themebg\", self._themebg)\n        toplevel = kwargs.pop(\"toplevel\", self._toplevel)\n        theme = kwargs.pop(\"theme\", self.current_theme)\n        color = self._get_bg_color()\n        if themebg != self._themebg:\n            if themebg is False:\n                self.configure(bg=\"white\")\n            else:\n                self.configure(bg=color)\n            self._themebg = themebg\n        if toplevel != self._toplevel:\n            if toplevel is True:\n                self._setup_toplevel_hook(color)\n            else:\n                tk.Toplevel.__init__ = self.__init__toplevel\n            self._toplevel = toplevel\n        if theme != self.current_theme:\n            self.set_theme(theme)\n        return tk.Tk.config(self, kw, **kwargs)", "response": "configure redirect to support additional options"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting to support additional options", "response": "def cget(self, k):\n        \"\"\"cget redirect to support additional options\"\"\"\n        if k == \"themebg\":\n            return self._themebg\n        elif k == \"toplevel\":\n            return self._toplevel\n        elif k == \"theme\":\n            return self.current_theme\n        return tk.Tk.cget(self, k)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run_command(command):\n    print(\"Running system command: \", command)\n    return_info = os.system(command)\n    if sys.platform == \"win32\":\n        return return_info\n    else:\n        return os.WEXITSTATUS(return_info)", "response": "Runs a system command on the available virtual machine."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nbuilding a binary distribution wheel and install it", "response": "def build_and_install_wheel(python):\n    \"\"\"Build a binary distribution wheel and install it\"\"\"\n    dist_type = \"bdist_wheel\" if not SDIST else \"sdist\"\n    return_code = run_command(\"{} setup.py {}\".format(python, dist_type))\n    if return_code != 0:\n        print(\"Building and installing wheel failed.\")\n        exit(return_code)\n    # Check if an artifact exists\n    assert check_wheel_existence()\n    print(\"Wheel file exists.\")\n    # Install the wheel file\n    wheel = [file for file in os.listdir(\"dist\") if file.endswith((\".whl\", \".tar.gz\"))][0]\n    wheel = os.path.join(\"dist\", wheel)\n    print(\"Wheel file:\", wheel)\n    return_code = run_command(\"{} -m pip install --ignore-installed {}\".format(python, wheel))\n    if return_code != 0:\n        print(\"Installation of wheel failed.\")\n        exit(return_code)\n    print(\"Wheel file installed.\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ci(python=\"python\", codecov=\"codecov\", coverage_file=\"coverage.xml\", wheel=True):\n\n    # Import pip\n    from pip import __version__ as pip_version\n    if Version(pip_version) >= Version(\"10.0.0\"):\n        import pip._internal as pip\n    else:\n        import pip\n\n    # Install requirements with pip\n    pip.main([\"install\"] + DEPENDENCIES + REQUIREMENTS + [\"-U\"])\n    # Build the installation wheel\n    if wheel is True:\n        build_and_install_wheel(python)\n        # Remove all non-essential files\n        for to_delete in TO_DELETE:\n            rmtree(to_delete)\n    # Run the tests on the installed ttkthemes\n    return_code = run_command(\"{} -m nose --with-coverage --cover-xml --cover-package=ttkthemes\".format(python))\n    if return_code != 0:\n        print(\"Tests failed.\")\n        exit(return_code)\n    print(\"Tests successful.\")\n    # Run codecov\n    return_code = run_command(\"{} -f {}\".format(codecov, coverage_file))\n    if return_code != 0:\n        print(\"Codecov failed.\")\n        exit(return_code)\n    # Successfully finished CI\n    exit(0)", "response": "Run the most common CI tasks"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ci_macos():\n    run_command(\"brew install $PYTHON pipenv || echo \\\"Installed PipEnv\\\"\")\n    command_string = \"sudo -H $PIP install \"\n    for element in DEPENDENCIES + REQUIREMENTS + [\"-U\"]:\n        command_string += element + \" \"\n    run_command(command_string)\n    # Build a wheel\n    run_command(\"sudo -H $PYTHON setup.py bdist_wheel\")\n    assert check_wheel_existence()\n    exit(0)", "response": "Setup Travis - CI macOS for wheel building"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets a new theme to use or return current theme name", "response": "def theme_use(self, theme_name=None):\n        \"\"\"\n        Set a new theme to use or return current theme name\n\n        :param theme_name: name of theme to use\n        :returns: active theme name\n        \"\"\"\n        if theme_name is not None:\n            self.set_theme(theme_name)\n        return ttk.Style.theme_use(self)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nlike os.chdir(), but always restores the old working directory For example, code like this... old_curdir = os.getcwd() os.chdir('stuff') do_some_stuff() os.chdir(old_curdir) ...leaves the current working directory unchanged if do_some_stuff() raises an error, so it should be rewritten like this: old_curdir = os.getcwd() os.chdir('stuff') try: do_some_stuff() finally: os.chdir(old_curdir) Or equivalently, like this: with utils.temporary_chdir('stuff'): do_some_stuff()", "response": "def temporary_chdir(new_dir):\n    \"\"\"\n    Like os.chdir(), but always restores the old working directory\n\n    For example, code like this...\n\n        old_curdir = os.getcwd()\n        os.chdir('stuff')\n        do_some_stuff()\n        os.chdir(old_curdir)\n\n    ...leaves the current working directory unchanged if do_some_stuff()\n    raises an error, so it should be rewritten like this:\n\n        old_curdir = os.getcwd()\n        os.chdir('stuff')\n        try:\n            do_some_stuff()\n        finally:\n            os.chdir(old_curdir)\n\n    Or equivalently, like this:\n\n        with utils.temporary_chdir('stuff'):\n            do_some_stuff()\n    \"\"\"\n    old_dir = os.getcwd()\n    os.chdir(new_dir)\n    try:\n        yield\n    finally:\n        os.chdir(old_dir)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_temp_directory():\n    # Supports all platforms supported by tempfile\n    directory = os.path.join(gettempdir(), \"ttkthemes\")\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    return directory", "response": "Return an absolute path to an existing temporary directory"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an absolute path the to themes directory", "response": "def get_themes_directory(theme_name=None, png=False):\n    \"\"\"Return an absolute path the to /themes directory\"\"\"\n    dir_themes = os.path.join(get_file_directory(), \"themes\")\n    if theme_name is None:\n        return dir_themes\n    if theme_name in os.listdir(dir_themes):\n        return dir_themes\n    dir = \"png\" if png is True else \"gif\"\n    return os.path.join(get_file_directory(), dir)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_directory(directory):\n    if os.path.exists(directory):\n        rmtree(directory)\n    os.makedirs(directory)\n    return directory", "response": "Create directory but first delete it if it exists"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shift_hue(image, hue):\n    hue = (hue - 1.0) * 180\n    img = image.copy().convert(\"HSV\")\n    pixels = img.load()\n    for i in range(img.width):\n        for j in range(img.height):\n            h, s, v = pixels[i, j]\n            h = abs(int(h + hue))\n            if h > 255:\n                h -= 255\n            pixels[i, j] = (h, s, v)\n    return img.convert(\"RGBA\")", "response": "Shifts the hue of an image in HSV format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef make_transparent(image):\n    data = image.copy().getdata()\n    modified = []\n    for item in data:\n        if _check_pixel(item) is True:\n            modified.append((255, 255, 255, 255))  # White transparent pixel\n            continue\n        modified.append(item)\n    image.putdata(modified)\n    return image", "response": "Turn all black pixels in an image into transparent ones"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_network():\n    global wlan\n    global secret\n\n    if sys.platform in PYCOM:\n        # Update secret as tuple with wlan mode for PyCom port.\n        wlan = network.WLAN(network.WLAN.STA)\n        secret = (network.WLAN.WPA2, settings.WIFI_PASSWORD)\n    else:\n        # default micropython wlan settings\n        wlan = network.WLAN(network.STA_IF)\n        secret = settings.WIFI_PASSWORD", "response": "Setup platform specific network settings"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconnects to WIFI and waits for connection to be established.", "response": "def _wifi_connect():\n    \"\"\"Connects to WIFI\"\"\"\n    if not wlan.isconnected():\n        wlan.active(True)\n        print(\"NETWORK: connecting to network %s...\" % settings.WIFI_SSID)\n        wlan.connect(settings.WIFI_SSID, secret)\n        while not wlan.isconnected():\n            print(\"NETWORK: waiting for connection...\")\n            utime.sleep(1)\n        print(\"NETWORK: Connected, network config: %s\" % repr(wlan.ifconfig()))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_update(self):\n        _time = time\n        if _time() > self.next_update:\n            self.update_data()\n            self.next_update = _time() + self.interval\n            return True\n        return False", "response": "Returns True if the time for an update is greater than the interval otherwise False."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the property id from topic as integer", "response": "def get_property_id_from_set_topic(self, topic):\n        \"\"\"Return the property id from topic as integer\"\"\"\n        topic = topic.decode()\n        return int(topic.split(\"/\")[-3].split(\"_\")[-1])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_node(self, node):\n        self.nodes.append(node)\n\n        # add node_ids\n        try:\n            if node.node_id != b\"$stats\":\n                self.node_ids.append(node.node_id)\n        except NotImplementedError:\n            raise\n        except Exception:\n            print(\"ERROR: getting Node\")", "response": "add a node class of HomieNode to this device"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsubscribe to all registered device and node topics", "response": "def subscribe_topics(self):\n        \"\"\"subscribe to all registered device and node topics\"\"\"\n        base = self.topic\n        subscribe = self.mqtt.subscribe\n\n        # device topics\n        subscribe(b\"/\".join((base, b\"$stats/interval/set\")))\n        subscribe(b\"/\".join((self.settings.MQTT_BASE_TOPIC, b\"$broadcast/#\")))\n\n        # node topics\n        nodes = self.nodes\n        for node in nodes:\n            for topic in node.subscribe:\n                topic = b\"/\".join((base, topic))\n                # print('MQTT SUBSCRIBE: {}'.format(topic))\n                subscribe(topic)\n                self.topic_callbacks[topic] = node.callback"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef publish_properties(self):\n        publish = self.publish\n\n        # device properties\n        publish(b\"$homie\", b\"3.0.1\")\n        publish(b\"$name\", self.settings.DEVICE_NAME)\n        publish(b\"$state\", b\"init\")\n        publish(b\"$fw/name\", b\"Microhomie\")\n        publish(b\"$fw/version\", __version__)\n        publish(b\"$implementation\", bytes(sys.platform, \"utf-8\"))\n        publish(b\"$localip\", utils.get_local_ip())\n        publish(b\"$mac\", utils.get_local_mac())\n        publish(b\"$stats\", b\"interval,uptime,freeheap\")\n        publish(b\"$stats/interval\", self.stats_interval)\n        publish(b\"$nodes\", b\",\".join(self.node_ids))\n\n        # node properties\n        for node in self.nodes:\n            try:\n                for propertie in node.get_properties():\n                    if propertie:\n                        publish(*propertie)\n            except NotImplementedError:\n                raise\n            except Exception as error:\n                self.node_error(node, error)", "response": "publish device and node properties"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npublishing node data if node has updates", "response": "def publish_data(self):\n        \"\"\"publish node data if node has updates\"\"\"\n        self.publish_device_stats()\n        publish = self.publish\n\n        # node data\n        for node in self.nodes:\n            try:\n                if node.has_update():\n                    for data in node.get_data():\n                        publish(*data)\n            except NotImplementedError:\n                raise\n            except Exception as error:\n                self.node_error(node, error)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\npublishes device and node properties, run forever", "response": "def start(self):\n        \"\"\"publish device and node properties, run forever\"\"\"\n        self.publish_properties()\n        self.subscribe_topics()\n        gc.collect()\n\n        self.set_state(\"ready\")\n\n        while True:\n            try:\n                if not utils.wlan.isconnected():\n                    utils.wifi_connect()\n\n                # publish device data\n                self.publish_data()\n\n                # check for new mqtt messages\n                self.mqtt.check_msg()\n\n                idle()\n                sleep(1)\n            except KeyboardInterrupt:\n                self.set_state(\"disconnected\")\n                self.mqtt.disconnect()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef array(shape, dtype=_np.float64, autolock=False):\n    assert _NP_AVAILABLE, \"To use the shared array object, numpy must be available!\"\n    if not isinstance(dtype, _np.dtype):\n        dtype = _np.dtype(dtype)\n    # Not bothering to translate the numpy dtypes to ctype types directly,\n    # because they're only partially supported. Instead, create a byte ctypes\n    # array of the right size and use a view of the appropriate datatype.\n    shared_arr = _multiprocessing.Array(\n        \"b\", int(_np.prod(shape) * dtype.alignment), lock=autolock\n    )\n    with _warnings.catch_warnings():\n        # For more information on why this is necessary, see\n        # https://www.reddit.com/r/Python/comments/j3qjb/parformatlabpool_replacement\n        _warnings.simplefilter(\"ignore\", RuntimeWarning)\n        data = _np.ctypeslib.as_array(shared_arr).view(dtype).reshape(shape)\n    return data", "response": "Factory method for creating shared memory arrays supporting all numpy dtypes."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets configuration value from environment variables.", "response": "def _get_conf_value(suffix):\n    \"\"\"Get configuration value from PYMP/OMP env variables.\"\"\"\n    pymp_name = \"PYMP_\" + suffix\n    omp_name = \"OMP_\" + suffix\n    value = None\n    for env_name in [pymp_name, omp_name]:\n        # pylint: disable=no-member\n        if env_name in _os.environ:\n            _LOGGER.debug(\n                \"Using %s environment variable: %s.\", env_name, _os.environ[env_name]\n            )\n            value = _os.environ[env_name]\n            break\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef range(self, start, stop=None, step=1):\n        self._assert_active()\n        if stop is None:\n            start, stop = 0, start\n        full_list = range(start, stop, step)\n        per_worker = len(full_list) // self._num_threads\n        rem = len(full_list) % self._num_threads\n        schedule = [\n            per_worker + 1 if thread_idx < rem else per_worker\n            for thread_idx in range(self._num_threads)\n        ]\n        # pylint: disable=undefined-variable\n        start_idx = _functools.reduce(\n            lambda x, y: x + y, schedule[: self.thread_num], 0\n        )\n        end_idx = start_idx + schedule[self._thread_num]\n        return full_list[start_idx:end_idx]", "response": "Get the correctly distributed parallel chunks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget an iterator for this thread s chunk of work.", "response": "def xrange(self, start, stop=None, step=1):\n        \"\"\"\n        Get an iterator for this threads chunk of work.\n\n        This corresponds to using the OpenMP 'dynamic' schedule.\n        \"\"\"\n        self._assert_active()\n        if stop is None:\n            start, stop = 0, start\n        with self._queuelock:\n            pool_loop_reached = max(self._thread_loop_ids)\n            # Get this loop id.\n            self._thread_loop_ids[self._thread_num] += 1\n            loop_id = self._thread_loop_ids[self._thread_num]\n            if pool_loop_reached < loop_id:\n                # No thread reached this loop yet. Set up the queue.\n                for idx in range(start, stop, step):\n                    self._dynamic_queue.put(idx)\n            # Iterate.\n            return _QueueIterator(self._dynamic_queue, loop_id, self)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iterate(self, iterable, element_timeout=None):\n        self._assert_active()\n        with self._queuelock:\n            # Get this loop id.\n            self._thread_loop_ids[self._thread_num] += 1\n            loop_id = self._thread_loop_ids[self._thread_num]\n            # Iterate.\n            return _IterableQueueIterator(\n                self._iter_queue, loop_id, self, iterable, element_timeout\n            )", "response": "Iterate over an iterable."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nupdate the value of the key in the objectConfig with the value entered by the user.", "response": "def _update_value(config, key, instruction, is_sensitive):\n    \"\"\"\n    creates (if needed)  and updates the value of the key in the config with a\n     value entered by the user\n\n    Parameters\n    ----------\n    config: ConfigParser object\n        existing configuration\n    key: string\n        key to update\n    instruction: string\n        text to show in the prompt\n    is_sensitive: bool\n        if true, require confirmation and do not show typed characters\n\n    Notes\n    -----\n    sets key in config passed in\n    \"\"\"\n    if config.has_option(PROFILE, key):\n        current_value = config.get(PROFILE, key)\n    else:\n        current_value = None\n\n    proposed = click.prompt(\n        instruction,\n        default=current_value,\n        hide_input=is_sensitive,\n        confirmation_prompt=is_sensitive,\n    )\n\n    if key == 'host' or key == 'prod_folder':\n        if proposed[-1] == '/':\n            proposed = proposed[:-1]\n\n    if key == 'host':\n        if 'http' != proposed[:4]:\n            proposed = click.prompt(\n                (\"looks like there's an issue - \"\n                 'make sure the host name starts with http'),\n                default=current_value,\n                hide_input=is_sensitive,\n                confirmation_prompt=is_sensitive,\n            )\n    config.set(PROFILE, key, proposed)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure information about Databricks account and default behavior.", "response": "def configure():\n    \"\"\"\n    Configure information about Databricks account and default behavior.\n\n    Configuration is stored in a `.apparatecfg` file. A config file must exist\n     before this package can be used, and can be supplied either directly as a\n     text file or generated using this configuration tool.\n    \"\"\"\n    config = _load_config(CFG_FILE)\n\n    _update_value(\n        config,\n        'host',\n        'Databricks host (e.g. https://my-organization.cloud.databricks.com)',\n        is_sensitive=False,\n    )\n    _update_value(\n        config,\n        'token',\n        'Databricks API token',\n        is_sensitive=True,\n    )\n    _update_value(\n        config,\n        'prod_folder',\n        'Databricks folder for production libraries',\n        is_sensitive=False,\n    )\n\n    with open(CFG_FILE, 'w+') as f:\n        config.write(f)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load_library(filename, match, folder, token, host):\n    with open(filename, 'rb') as file_obj:\n        res = requests.post(\n            host + '/api/1.2/libraries/upload',\n            auth=('token', token),\n            data={\n                'libType': match.lib_type,\n                'name': '{0}-{1}'.format(match.library_name, match.version),\n                'folder': folder,\n            },\n            files={'uri': file_obj}\n        )\n\n    if res.status_code != 200:\n        raise APIError(res)", "response": "Uploads an egg to Databricks filesystem."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_job_list(logger, match, library_mapping, token, host):\n    res = requests.get(\n        host + '/api/2.0/jobs/list',\n        auth=('token', token),\n    )\n    if res.status_code == 200:\n        job_list = []\n        if len(res.json()['jobs']) == 0:\n            return []\n        for job in res.json()['jobs']:\n            logger.debug('job: {}'.format(job['settings']['name']))\n            if 'libraries' in job['settings'].keys():\n                for library in job['settings']['libraries']:\n                    if match.suffix in library.keys():\n                        try:  # if in prod_folder, mapping turns uri into name\n                            job_library_uri = basename(library[match.suffix])\n                            job_match = library_mapping[job_library_uri]\n                        except KeyError:\n                            logger.debug(\n                                'not in library map: {}'\n                                .format(job_library_uri)\n                            )\n                            pass\n                        else:\n                            if match.replace_version(job_match, logger):\n                                job_list.append({\n                                    'job_id': job['job_id'],\n                                    'job_name': job['settings']['name'],\n                                    'library_path': library[match.suffix],\n                                })\n                            else:\n                                logger.debug(\n                                    'not replacable: {}'\n                                    .format(job_match.filename)\n                                )\n                    else:\n                        logger.debug(\n                            'no matching suffix: looking for {}, found {}'\n                            .format(match.suffix, str(library.keys()))\n                        )\n        return job_list\n    else:\n        raise APIError(res)", "response": "get a list of jobs using the major version of the given library"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_library_mapping(logger, prod_folder, token, host):\n    res = requests.get(\n        host + '/api/1.2/libraries/list',\n        auth=('token', token),\n    )\n    if res.status_code == 200:\n        library_list = res.json()\n        library_map = {}\n        id_nums = {}\n        for library in library_list:\n            status_res = (\n                requests\n                .get(\n                    host + '/api/1.2/libraries/status?libraryId={}'\n                    .format(library['id']),\n                    auth=('token', token),\n                )\n            )\n            if status_res.status_code == 200:\n                library_info = status_res.json()\n                # only do any of this for libraries in the production folder\n                if library_info['folder'] != prod_folder:\n                    logger.debug(\n                        'excluded folder: {} in {}, not prod folder ({})'\n                        .format(\n                            library_info['name'],\n                            library_info['folder'],\n                            prod_folder,\n                        )\n                    )\n                    continue\n                if library_info['libType'] == 'python-egg':\n                    full_name = library_info['name'] + '.egg'\n                elif library_info['libType'] == 'java-jar':\n                    full_name = library_info['name'] + '.jar'\n                else:\n                    logger.debug(\n                        'excluded library type: {} is of libType {}, '\n                        'not jar or egg'\n                        .format(\n                            library_info['name'],\n                            library_info['libType'],\n                        )\n                    )\n                    continue\n                try:\n                    name_match = FileNameMatch(full_name)\n                    # map uri to name match object\n                    library_map[library_info['files'][0]] = name_match\n                    # map name to name match object and id number\n                    # we'll need the id number to clean up old libraries\n                    id_nums[library_info['name']] = {\n                        'name_match': name_match,\n                        'id_num': library_info['id'],\n                    }\n                except FileNameError:\n                    logger.debug(\n                        'FileNameError: {} file name is not parsable'\n                        .format(full_name)\n                    )\n                    pass\n            else:\n                raise APIError(status_res)\n        return library_map, id_nums\n    else:\n        raise APIError(res)", "response": "Returns a dictionary mapping a library uri to a base name major version minor version and id number for all libraries in the production folder."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update_job_libraries(\n    logger,\n    job_list,\n    match,\n    new_library_path,\n    token,\n    host,\n):\n    \"\"\"\n    update libraries on jobs using same major version\n\n    Parameters\n    ----------\n    logger: logging object\n        configured in cli_commands.py\n    job_list: list of strings\n        output of get_job_list\n    match: FilenameMatch object\n        match object with suffix\n    new_library_path: string\n        path to library in dbfs (including uri)\n    token: string\n        Databricks API key with admin permissions\n    host: string\n        Databricks account url\n        (e.g. https://fake-organization.cloud.databricks.com)\n\n    Side Effects\n    ------------\n    jobs now require updated version of library\n    \"\"\"\n\n    for job in job_list:\n        get_res = requests.get(\n            host + '/api/2.0/jobs/get?job_id={}'.format(job['job_id']),\n            auth=('token', token),\n        )\n        if get_res.status_code == 200:\n            job_specs = get_res.json()  # copy current job specs\n            settings = job_specs['settings']\n            job_specs.pop('settings')\n            new_libraries = []\n            for lib in settings['libraries']:\n                if (\n                    match.suffix in lib.keys()\n                    and lib[match.suffix] == job['library_path']\n                ):\n                    # replace entry for old library path with new one\n                    new_libraries.append({match.suffix: new_library_path})\n                else:\n                    new_libraries.append(lib)\n            settings['libraries'] = new_libraries\n            job_specs['new_settings'] = settings\n            post_res = requests.post(\n                host + '/api/2.0/jobs/reset',\n                auth=('token', token),\n                data=json.dumps(job_specs)\n            )\n            if post_res.status_code != 200:\n                raise APIError(post_res)\n        else:\n            raise APIError(get_res)", "response": "This function updates the libraries of jobs in a list of jobs."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting any other versions of the same library with the same major version and minor version.", "response": "def delete_old_versions(\n    logger,\n    new_library_match,\n    id_nums,\n    token,\n    prod_folder,\n    host\n):\n    \"\"\"\n    delete any other versions of the same library where:\n        it has the same major version\n        it has a smaller minor version\n        it lives in prod_folder\n\n    Parameters\n    ----------\n    logger: logging object\n        configured in cli_commands.py\n    match: FilenameMatch object\n        match object with library_name_, major_version, minor_version\n    id_nums: dict\n        second output of get_library_mapping\n    token: string\n        Databricks API key with admin permissions\n    prod_folder: string\n        name of folder in Databricks UI containing production libraries\n    host: string\n        Databricks account url\n        (e.g. https://fake-organization.cloud.databricks.com)\n\n    Side Effects\n    ------------\n    delete any other versions of the same library with the same major version\n        and smaller minor versions\n    \"\"\"\n\n    old_versions = []\n    for name, lib in id_nums.items():\n        if new_library_match.replace_version(lib['name_match'], logger):\n            old_versions.append(lib['name_match'].filename)\n            res = requests.post(\n                host + '/api/1.2/libraries/delete',\n                auth=('token', token),\n                data={'libraryId': lib['id_num']},\n            )\n            if res.status_code != 200:\n                raise APIError(res)\n    return old_versions"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nuploading a new library to Databricks and deletes any outdated libraries.", "response": "def update_databricks(logger, path, token, folder, update_jobs, cleanup):\n    \"\"\"\n    upload library, update jobs using the same major version,\n    and delete libraries with the same major and lower minor versions\n    (depending on update_jobs and cleanup flags)\n\n    Parameters\n    ----------\n    logger: logging object\n        configured in cli_commands.py\n    path: string\n        path with name of egg as output from setuptools\n        (e.g. dist/new_library-1.0.0-py3.6.egg)\n    token: string\n        Databricks API key\n    folder: string\n        Databricks folder to upload to\n        (e.g. '/Users/my_email@fake_organization.com/')\n    update_jobs: bool\n        if true, jobs using this library will be updated to point to the\n            new version\n        if false, will not touch jobs or other library versions at all\n    cleanup: bool\n        if true, outdated libraries will be deleted\n        if false, nothing will be deleted\n\n    Side Effects\n    ------------\n    new library in Databricks\n    if update_jobs is true, then updated jobs\n    if update_jobs and cleanup are true, removed outdated libraries\n    \"\"\"\n\n    config = _load_config(CFG_FILE)\n    try:\n        host = config.get(PROFILE, 'host')\n    except NoOptionError:\n        raise ValueError('no host provided: please run `apparate configure`'\n                         ' to get set up')\n    try:\n        prod_folder = config.get(PROFILE, 'prod_folder')\n    except NoOptionError:\n        raise ValueError('no prod_folder provided: please run '\n                         '`apparate configure` to get set up')\n\n    match = FileNameMatch(basename(path))\n\n    try:\n        load_library(path, match, folder, token, host)\n        logger.info(\n            'new library {}-{} loaded to Databricks'\n            .format(match.library_name, match.version)\n        )\n    except APIError as err:\n        if err.code == 'http 500' and 'already exists' in err.message:\n            logger.info(\n                'This version ({}) already exists: '.format(match.version) +\n                'if a change has been made please update your version number. '\n                'Note this error can also occur if you are uploading a jar '\n                'and an egg already exists with the same name and version, '\n                'or vice versa. In this case you will need to choose a '\n                'different library name or a different folder for either the '\n                'egg or the jar.'\n            )\n            return\n        else:\n            raise err\n\n    if update_jobs and folder == prod_folder:\n        library_map, id_nums = get_library_mapping(\n            logger,\n            prod_folder,\n            token,\n            host,\n        )\n        library_uri = [\n            uri for uri, tmp_match in library_map.items()\n            if (\n                match.library_name == tmp_match.library_name\n                and match.version == tmp_match.version\n            )\n        ][0]\n        library_path = 'dbfs:/FileStore/jars/' + library_uri\n\n        job_list = get_job_list(logger, match, library_map, token, host)\n        logger.info(\n            'current major version of library used by jobs: {}'\n            .format(', '.join([i['job_name'] for i in job_list]))\n        )\n\n        if len(job_list) != 0:\n            update_job_libraries(\n                logger,\n                job_list,\n                match,\n                library_path,\n                token,\n                host,\n            )\n            logger.info(\n                'updated jobs: {}'\n                .format(', '.join([i['job_name'] for i in job_list]))\n            )\n\n        if cleanup:\n            old_versions = delete_old_versions(\n                logger,\n                match,\n                id_nums=id_nums,\n                token=token,\n                prod_folder=prod_folder,\n                host=host,\n            )\n            logger.info(\n                'removed old versions: {}'.format(', '.join(old_versions))\n            )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_version(self, other, logger):\n\n        if other.library_name != self.library_name:\n            logger.debug(\n                'not replacable: {} != {} ()'\n                .format(other.library_name, self.library_name, other.filename)\n            )\n            return False\n        elif int(other.major_version) != int(self.major_version):\n            logger.debug(\n                'not replacable: {} != {} ({})'\n                .format(\n                    int(self.major_version),\n                    int(other.major_version),\n                    other.filename,\n                )\n            )\n            return False\n        elif float(other.minor_version) >= float(self.minor_version):\n            logger.debug(\n                'not replacable: {} >= {} ({})'\n                .format(\n                    other.minor_version,\n                    self.minor_version,\n                    other.filename,\n                )\n            )\n            return False\n        else:\n            return True", "response": "Return True if self can safely replace other with self."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresolves input entered as option values with config values", "response": "def _resolve_input(variable, variable_name, config_key, config):\n    \"\"\"\n    Resolve input entered as option values with config values\n\n    If option values are provided (passed in as `variable`), then they are\n     returned unchanged. If `variable` is None, then we first look for a config\n     value to use.\n    If no config value is found, then raise an error.\n\n    Parameters\n    ----------\n    variable: string or numeric\n        value passed in as input by the user\n    variable_name: string\n        name of the variable, for clarity in the error message\n    config_key: string\n        key in the config whose value could be used to fill in the variable\n    config: ConfigParser\n        contains keys/values in .apparatecfg\n    \"\"\"\n    if variable is None:\n        try:\n            variable = config.get(PROFILE, config_key)\n        except NoOptionError:\n            raise ValueError((\n                'no {} found - either provide a command line argument or '\n                'set up a default by running `apparate configure`'\n            ).format(variable_name))\n    return variable"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads an egg to Databricks.", "response": "def upload(path, token, folder):\n    \"\"\"\n    The egg that the provided path points to will be uploaded to Databricks.\n    \"\"\"\n    config = _load_config(CFG_FILE)\n    token = _resolve_input(token, 'token', 'token', config)\n    folder = _resolve_input(folder, 'folder', 'prod_folder', config)\n\n    update_databricks(\n        logger,\n        path,\n        token,\n        folder,\n        update_jobs=False,\n        cleanup=False\n    )"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef upload_and_update(path, token, cleanup):\n    config = _load_config(CFG_FILE)\n    token = _resolve_input(token, 'token', 'token', config)\n    folder = _resolve_input(None, 'folder', 'prod_folder', config)\n\n    update_databricks(\n        logger,\n        path,\n        token,\n        folder,\n        update_jobs=True,\n        cleanup=cleanup\n    )", "response": "Uploads and updates the current version of the current project to Databricks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a SAS token into its components.", "response": "def parse_sas_token(sas_token):\n    \"\"\"Parse a SAS token into its components.\n\n    :param sas_token: The SAS token.\n    :type sas_token: str\n    :rtype: dict[str, str]\n    \"\"\"\n    sas_data = {}\n    token = sas_token.partition(' ')[2]\n    fields = token.split('&')\n    for field in fields:\n        key, value = field.split('=', 1)\n        sas_data[key.lower()] = value\n    return sas_data"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef offset(self):\n        try:\n            return Offset(self._annotations[EventData.PROP_OFFSET].decode('UTF-8'))\n        except (KeyError, AttributeError):\n            return None", "response": "Returns the offset of the event data object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef enqueued_time(self):\n        timestamp = self._annotations.get(EventData.PROP_TIMESTAMP, None)\n        if timestamp:\n            return datetime.datetime.utcfromtimestamp(float(timestamp)/1000)\n        return None", "response": "Returns the enqueued time of the event data object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the partition key of the event data object.", "response": "def partition_key(self):\n        \"\"\"\n        The partition key of the event data object.\n\n        :rtype: bytes\n        \"\"\"\n        try:\n            return self._annotations[self._partition_key]\n        except KeyError:\n            return self._annotations.get(EventData.PROP_PARTITION_KEY, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the partition key of the event data object.", "response": "def partition_key(self, value):\n        \"\"\"\n        Set the partition key of the event data object.\n\n        :param value: The partition key to set.\n        :type value: str or bytes\n        \"\"\"\n        annotations = dict(self._annotations)\n        annotations[self._partition_key] = value\n        header = MessageHeader()\n        header.durable = True\n        self.message.annotations = annotations\n        self.message.header = header\n        self._annotations = annotations"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the application properties on the event data.", "response": "def application_properties(self, value):\n        \"\"\"\n        Application defined properties on the message.\n\n        :param value: The application properties for the EventData.\n        :type value: dict\n        \"\"\"\n        self._app_properties = value\n        properties = dict(self._app_properties)\n        self.message.application_properties = properties"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the body of the event data as a string if the data is of a compatible type.", "response": "def body_as_str(self, encoding='UTF-8'):\n        \"\"\"\n        The body of the event data as a string if the data is of a\n        compatible type.\n\n        :param encoding: The encoding to use for decoding message data.\n         Default is 'UTF-8'\n        :rtype: str or unicode\n        \"\"\"\n        data = self.body\n        try:\n            return \"\".join(b.decode(encoding) for b in data)\n        except TypeError:\n            return six.text_type(data)\n        except:  # pylint: disable=bare-except\n            pass\n        try:\n            return data.decode(encoding)\n        except Exception as e:\n            raise TypeError(\"Message data is not compatible with string type: {}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef body_as_json(self, encoding='UTF-8'):\n        data_str = self.body_as_str(encoding=encoding)\n        try:\n            return json.loads(data_str)\n        except Exception as e:\n            raise TypeError(\"Event data is not compatible with JSON type: {}\".format(e))", "response": "Returns the event body as a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a selector expression of the offset.", "response": "def selector(self):\n        \"\"\"\n        Creates a selector expression of the offset.\n\n        :rtype: bytes\n        \"\"\"\n        operator = \">=\" if self.inclusive else \">\"\n        if isinstance(self.value, datetime.datetime):\n            timestamp = (calendar.timegm(self.value.utctimetuple()) * 1000) + (self.value.microsecond/1000)\n            return (\"amqp.annotation.x-opt-enqueued-time {} '{}'\".format(operator, int(timestamp))).encode('utf-8')\n        if isinstance(self.value, six.integer_types):\n            return (\"amqp.annotation.x-opt-sequence-number {} '{}'\".format(operator, self.value)).encode('utf-8')\n        return (\"amqp.annotation.x-opt-offset {} '{}'\".format(operator, self.value)).encode('utf-8')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an auth token dictionary for making calls to eventhub REST API.", "response": "def get_client_address(self):\n        \"\"\"\n        Returns an auth token dictionary for making calls to eventhub\n        REST API.\n\n        :rtype: str\n        \"\"\"\n        return \"amqps://{}:{}@{}.{}:5671/{}\".format(\n            urllib.parse.quote_plus(self.policy),\n            urllib.parse.quote_plus(self.sas_key),\n            self.sb_name,\n            self.namespace_suffix,\n            self.eh_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an auth token for making calls to eventhub REST API.", "response": "def get_rest_token(self):\n        \"\"\"\n        Returns an auth token for making calls to eventhub REST API.\n\n        :rtype: str\n        \"\"\"\n        uri = urllib.parse.quote_plus(\n            \"https://{}.{}/{}\".format(self.sb_name, self.namespace_suffix, self.eh_name))\n        sas = self.sas_key.encode('utf-8')\n        expiry = str(int(time.time() + 10000))\n        string_to_sign = ('{}\\n{}'.format(uri, expiry)).encode('utf-8')\n        signed_hmac_sha256 = hmac.HMAC(sas, string_to_sign, hashlib.sha256)\n        signature = urllib.parse.quote(base64.b64encode(signed_hmac_sha256.digest()))\n        return 'SharedAccessSignature sr={}&sig={}&se={}&skn={}' \\\n                .format(uri, signature, expiry, self.policy)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening the Sender using the supplied conneciton.", "response": "def open(self):\n        \"\"\"\n        Open the Sender using the supplied conneciton.\n        If the handler has previously been redirected, the redirect\n        context will be used to create a new handler before opening it.\n\n        :param connection: The underlying client shared connection.\n        :type: connection: ~uamqp.connection.Connection\n        \"\"\"\n        self.running = True\n        if self.redirected:\n            self.target = self.redirected.address\n            self._handler = SendClient(\n                self.target,\n                auth=self.client.get_auth(),\n                debug=self.client.debug,\n                msg_timeout=self.timeout,\n                error_policy=self.retry_policy,\n                keep_alive_interval=self.keep_alive,\n                client_name=self.name,\n                properties=self.client.create_properties())\n        self._handler.open()\n        while not self._handler.client_ready():\n            time.sleep(0.05)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef has_started(self):\n        # pylint: disable=protected-access\n        timeout = False\n        auth_in_progress = False\n        if self._handler._connection.cbs:\n            timeout, auth_in_progress = self._handler._auth.handle_token()\n        if timeout:\n            raise EventHubError(\"Authorization timeout.\")\n        if auth_in_progress:\n            return False\n        if not self._handler._client_ready():\n            return False\n        return True", "response": "Returns True if the handler has started all start up processes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef close(self, exception=None):\n        self.running = False\n        if self.error:\n            return\n        if isinstance(exception, errors.LinkRedirect):\n            self.redirected = exception\n        elif isinstance(exception, EventHubError):\n            self.error = exception\n        elif exception:\n            self.error = EventHubError(str(exception))\n        else:\n            self.error = EventHubError(\"This send handler is now closed.\")\n        self._handler.close()", "response": "Closes the send handler."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, event_data):\n        if self.error:\n            raise self.error\n        if not self.running:\n            raise ValueError(\"Unable to send until client has been started.\")\n        if event_data.partition_key and self.partition:\n            raise ValueError(\"EventData partition key cannot be used with a partition sender.\")\n        event_data.message.on_send_complete = self._on_outcome\n        try:\n            self._handler.send_message(event_data.message)\n            if self._outcome != constants.MessageSendResult.Ok:\n                raise Sender._error(self._outcome, self._condition)\n        except errors.MessageException as failed:\n            error = EventHubError(str(failed), failed)\n            self.close(exception=error)\n            raise error\n        except (errors.TokenExpired, errors.AuthenticationException):\n            log.info(\"Sender disconnected due to token error. Attempting reconnect.\")\n            self.reconnect()\n        except (errors.LinkDetach, errors.ConnectionClose) as shutdown:\n            if shutdown.action.retry and self.auto_reconnect:\n                log.info(\"Sender detached. Attempting reconnect.\")\n                self.reconnect()\n            else:\n                log.info(\"Sender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                self.close(exception=error)\n                raise error\n        except errors.MessageHandlerError as shutdown:\n            if self.auto_reconnect:\n                log.info(\"Sender detached. Attempting reconnect.\")\n                self.reconnect()\n            else:\n                log.info(\"Sender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                self.close(exception=error)\n                raise error\n        except Exception as e:\n            log.info(\"Unexpected error occurred (%r). Shutting down.\", e)\n            error = EventHubError(\"Send failed: {}\".format(e))\n            self.close(exception=error)\n            raise error\n        else:\n            return self._outcome", "response": "Sends an event data to the broker and blocks until acknowledgement is received or operation times out."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntransfers an event data and notifies the callback when the operation is done.", "response": "def transfer(self, event_data, callback=None):\n        \"\"\"\n        Transfers an event data and notifies the callback when the operation is done.\n\n        :param event_data: The event to be sent.\n        :type event_data: ~azure.eventhub.common.EventData\n        :param callback: Callback to be run once the message has been send.\n         This must be a function that accepts two arguments.\n        :type callback: callable[~uamqp.constants.MessageSendResult, ~azure.eventhub.common.EventHubError]\n        \"\"\"\n        if self.error:\n            raise self.error\n        if not self.running:\n            raise ValueError(\"Unable to send until client has been started.\")\n        if event_data.partition_key and self.partition:\n            raise ValueError(\"EventData partition key cannot be used with a partition sender.\")\n        if callback:\n            event_data.message.on_send_complete = lambda o, c: callback(o, Sender._error(o, c))\n        self._handler.queue_message(event_data.message)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef wait(self):\n        if self.error:\n            raise self.error\n        if not self.running:\n            raise ValueError(\"Unable to send until client has been started.\")\n        try:\n            self._handler.wait()\n        except (errors.TokenExpired, errors.AuthenticationException):\n            log.info(\"Sender disconnected due to token error. Attempting reconnect.\")\n            self.reconnect()\n        except (errors.LinkDetach, errors.ConnectionClose) as shutdown:\n            if shutdown.action.retry and self.auto_reconnect:\n                log.info(\"Sender detached. Attempting reconnect.\")\n                self.reconnect()\n            else:\n                log.info(\"Sender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                self.close(exception=error)\n                raise error\n        except errors.MessageHandlerError as shutdown:\n            if self.auto_reconnect:\n                log.info(\"Sender detached. Attempting reconnect.\")\n                self.reconnect()\n            else:\n                log.info(\"Sender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                self.close(exception=error)\n                raise error\n        except Exception as e:\n            log.info(\"Unexpected error occurred (%r).\", e)\n            raise EventHubError(\"Send failed: {}\".format(e))", "response": "Wait until all transferred events have been sent."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _on_outcome(self, outcome, condition):\n        self._outcome = outcome\n        self._condition = condition", "response": "Called when the outcome is received for a message delivery."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninitializes the AzureStorageCheckpointLeaseManager object.", "response": "def initialize(self, host):\n        \"\"\"\n        The EventProcessorHost can't pass itself to the AzureStorageCheckpointLeaseManager\n        constructor because it is still being constructed. Do other initialization here\n        also because it might throw and hence we don't want it in the constructor.\n        \"\"\"\n        self.host = host\n        self.storage_client = BlockBlobService(account_name=self.storage_account_name,\n                                               account_key=self.storage_account_key,\n                                               sas_token=self.storage_sas_token,\n                                               endpoint_suffix=self.endpoint_suffix,\n                                               connection_string=self.connection_string,\n                                               request_session=self.request_session)\n        self.consumer_group_directory = self.storage_blob_prefix + self.host.eh_config.consumer_group"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the checkpoint data associated with the given partition.", "response": "async def get_checkpoint_async(self, partition_id):\n        \"\"\"\n        Get the checkpoint data associated with the given partition.\n        Could return null if no checkpoint has been created for that partition.\n\n        :param partition_id: The partition ID.\n        :type partition_id: str\n        :return: Given partition checkpoint info, or `None` if none has been previously stored.\n        :rtype: ~azure.eventprocessorhost.checkpoint.Checkpoint\n        \"\"\"\n        lease = await self.get_lease_async(partition_id)\n        checkpoint = None\n        if lease:\n            if lease.offset:\n                checkpoint = Checkpoint(partition_id, lease.offset,\n                                        lease.sequence_number)\n        return checkpoint"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the given partition checkpoint if it doesn t exist. Do nothing.", "response": "async def create_checkpoint_if_not_exists_async(self, partition_id):\n        \"\"\"\n        Create the given partition checkpoint if it doesn't exist.Do nothing if it does exist.\n        The offset/sequenceNumber for a freshly-created checkpoint should be set to StartOfStream/0.\n\n        :param partition_id: The partition ID.\n        :type partition_id: str\n        :return: The checkpoint for the given partition, whether newly created or already existing.\n        :rtype: ~azure.eventprocessorhost.checkpoint.Checkpoint\n        \"\"\"\n        checkpoint = await self.get_checkpoint_async(partition_id)\n        if not checkpoint:\n            await self.create_lease_if_not_exists_async(partition_id)\n            checkpoint = Checkpoint(partition_id)\n        return checkpoint"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating the lease with the offset and sequenceNumber in the provided checkpoint.", "response": "async def update_checkpoint_async(self, lease, checkpoint):\n        \"\"\"\n        Update the checkpoint in the store with the offset/sequenceNumber in the provided checkpoint\n        checkpoint:offset/sequeceNumber to update the store with.\n\n        :param lease: The stored lease to be updated.\n        :type lease: ~azure.eventprocessorhost.lease.Lease\n        :param checkpoint: The checkpoint to update the lease with.\n        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint\n        \"\"\"\n        new_lease = AzureBlobLease()\n        new_lease.with_source(lease)\n        new_lease.offset = checkpoint.offset\n        new_lease.sequence_number = checkpoint.sequence_number\n        return await self.update_lease_async(new_lease)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates the lease store if it does not exist.", "response": "async def create_lease_store_if_not_exists_async(self):\n        \"\"\"\n        Create the lease store if it does not exist, do nothing if it does exist.\n\n        :return: `True` if the lease store already exists or was created successfully, `False` if not.\n        :rtype: bool\n        \"\"\"\n        try:\n            await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.create_container,\n                    self.lease_container_name))\n\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.error(\"%r\", err)\n            raise err\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the lease info for the specified partition.", "response": "async def get_lease_async(self, partition_id):\n        \"\"\"\n        Return the lease info for the specified partition.\n        Can return null if no lease has been created in the store for the specified partition.\n\n        :param partition_id: The partition ID.\n        :type partition_id: str\n        :return: lease info for the partition, or `None`.\n        :rtype: ~azure.eventprocessorhost.lease.Lease\n        \"\"\"\n        try:\n            blob = await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.get_blob_to_text,\n                    self.lease_container_name, partition_id))\n            lease = AzureBlobLease()\n            lease.with_blob(blob)\n            async def state():\n                \"\"\"\n                Allow lease to curry storage_client to get state\n                \"\"\"\n                try:\n                    loop = asyncio.get_event_loop()\n                    res = await loop.run_in_executor(\n                        self.executor,\n                        functools.partial(\n                            self.storage_client.get_blob_properties,\n                            self.lease_container_name,\n                            partition_id))\n                    return res.properties.lease.state\n                except Exception as err:  # pylint: disable=broad-except\n                    _logger.error(\"Failed to get lease state %r %r\", err, partition_id)\n\n            lease.state = state\n            return lease\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.error(\"Failed to get lease %r %r\", err, partition_id)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def get_all_leases(self):\n        lease_futures = []\n        partition_ids = await self.host.partition_manager.get_partition_ids_async()\n        for partition_id in partition_ids:\n            lease_futures.append(self.get_lease_async(partition_id))\n        return lease_futures", "response": "Return the lease info for all partitions."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def create_lease_if_not_exists_async(self, partition_id):\n        return_lease = None\n        try:\n            return_lease = AzureBlobLease()\n            return_lease.partition_id = partition_id\n            serializable_lease = return_lease.serializable()\n            json_lease = json.dumps(serializable_lease)\n            _logger.info(\"Creating Lease %r %r %r\",\n                         self.lease_container_name,\n                         partition_id,\n                         json.dumps({k:v for k, v in serializable_lease.items() if k != 'event_processor_context'}))\n            await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.create_blob_from_text,\n                    self.lease_container_name,\n                    partition_id,\n                    json_lease))\n        except Exception:  # pylint: disable=broad-except\n            try:\n                return_lease = await self.get_lease_async(partition_id)\n            except Exception as err:  # pylint: disable=broad-except\n                _logger.error(\"Failed to create lease %r\", err)\n                raise err\n        return return_lease", "response": "Create in the store the lease info for the given partition if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndeleting the lease info for the given partition from the store.", "response": "async def delete_lease_async(self, lease):\n        \"\"\"\n        Delete the lease info for the given partition from the store.\n        If there is no stored lease for the given partition, that is treated as success.\n\n        :param lease: The stored lease to be deleted.\n        :type lease: ~azure.eventprocessorhost.lease.Lease\n        \"\"\"\n        await self.host.loop.run_in_executor(\n            self.executor,\n            functools.partial(\n                self.storage_client.delete_blob,\n                self.lease_container_name,\n                lease.partition_id,\n                lease_id=lease.token))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nacquires a lease on the desired partition.", "response": "async def acquire_lease_async(self, lease):\n        \"\"\"\n        Acquire the lease on the desired partition for this EventProcessorHost.\n        Note that it is legal to acquire a lease that is already owned by another host.\n        Lease-stealing is how partitions are redistributed when additional hosts are started.\n\n        :param lease: The stored lease to be acquired.\n        :type lease: ~azure.eventprocessorhost.lease.Lease\n        :return: `True` if the lease was acquired successfully, `False` if not.\n        :rtype: bool\n        \"\"\"\n        retval = True\n        new_lease_id = str(uuid.uuid4())\n        partition_id = lease.partition_id\n        try:\n            if asyncio.iscoroutinefunction(lease.state):\n                state = await lease.state()\n            else:\n                state = lease.state()\n            if state == \"leased\":\n                if not lease.token:\n                    # We reach here in a race condition: when this instance of EventProcessorHost\n                    # scanned the lease blobs, this partition was unowned (token is empty) but\n                    # between then and now, another instance of EPH has established a lease\n                    # (getLeaseState() is LEASED). We normally enforcethat we only steal the lease\n                    # if it is still owned by the instance which owned it when we scanned, but we\n                    # can't do that when we don't know who owns it. The safest thing to do is just\n                    # fail the acquisition. If that means that one EPH instance gets more partitions\n                    # than it should, rebalancing will take care of that quickly enough.\n                    retval = False\n                else:\n                    _logger.info(\"ChangingLease %r %r\", self.host.guid, lease.partition_id)\n                    await self.host.loop.run_in_executor(\n                        self.executor,\n                        functools.partial(\n                            self.storage_client.change_blob_lease,\n                            self.lease_container_name,\n                            partition_id,\n                            lease.token,\n                            new_lease_id))\n                    lease.token = new_lease_id\n            else:\n                _logger.info(\"AcquiringLease %r %r\", self.host.guid, lease.partition_id)\n                lease.token = await self.host.loop.run_in_executor(\n                    self.executor,\n                    functools.partial(\n                        self.storage_client.acquire_blob_lease,\n                        self.lease_container_name,\n                        partition_id,\n                        self.lease_duration,\n                        new_lease_id))\n            lease.owner = self.host.host_name\n            lease.increment_epoch()\n            # check if this solves the issue\n            retval = await self.update_lease_async(lease)\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.error(\"Failed to acquire lease %r %r %r\", err, partition_id, lease.token)\n            return False\n\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def renew_lease_async(self, lease):\n        try:\n            await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.renew_blob_lease,\n                    self.lease_container_name,\n                    lease.partition_id,\n                    lease_id=lease.token,\n                    timeout=self.lease_duration))\n        except Exception as err:  # pylint: disable=broad-except\n            if \"LeaseIdMismatchWithLeaseOperation\" in str(err):\n                _logger.info(\"LeaseLost on partition %r\", lease.partition_id)\n            else:\n                _logger.error(\"Failed to renew lease on partition %r with token %r %r\",\n                              lease.partition_id, lease.token, err)\n            return False\n        return True", "response": "Renews a lease currently held by this host."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def release_lease_async(self, lease):\n        lease_id = None\n        try:\n            _logger.info(\"Releasing lease %r %r\", self.host.guid, lease.partition_id)\n            lease_id = lease.token\n            released_copy = AzureBlobLease()\n            released_copy.with_lease(lease)\n            released_copy.token = None\n            released_copy.owner = None\n            released_copy.state = None\n            await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.create_blob_from_text,\n                    self.lease_container_name,\n                    lease.partition_id,\n                    json.dumps(released_copy.serializable()),\n                    lease_id=lease_id))\n            await self.host.loop.run_in_executor(\n                self.executor,\n                functools.partial(\n                    self.storage_client.release_blob_lease,\n                    self.lease_container_name,\n                    lease.partition_id,\n                    lease_id))\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.error(\"Failed to release lease %r %r %r\",\n                          err, lease.partition_id, lease_id)\n            return False\n        return True", "response": "Release a lease currently held by this host."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the store with the information in the provided lease.", "response": "async def update_lease_async(self, lease):\n        \"\"\"\n        Update the store with the information in the provided lease. It is necessary to currently\n        hold a lease in order to update it. If the lease has been stolen, or expired, or released,\n        it cannot be updated. Updating should renew the lease before performing the update to\n        avoid lease expiration during the process.\n\n        :param lease: The stored lease to be updated.\n        :type lease: ~azure.eventprocessorhost.lease.Lease\n        :return: `True` if the updated was performed successfully, `False` if not.\n        :rtype: bool\n        \"\"\"\n        if lease is None:\n            return False\n\n        if not lease.token:\n            return False\n\n        _logger.debug(\"Updating lease %r %r\", self.host.guid, lease.partition_id)\n\n        # First, renew the lease to make sure the update will go through.\n        if await self.renew_lease_async(lease):\n            try:\n                await self.host.loop.run_in_executor(\n                    self.executor,\n                    functools.partial(\n                        self.storage_client.create_blob_from_text,\n                        self.lease_container_name,\n                        lease.partition_id,\n                        json.dumps(lease.serializable()),\n                        lease_id=lease.token))\n\n            except Exception as err:  # pylint: disable=broad-except\n                _logger.error(\"Failed to update lease %r %r %r\",\n                              self.host.guid, lease.partition_id, err)\n                raise err\n        else:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nopen the Receiver using the supplied conneciton.", "response": "async def open_async(self):\n        \"\"\"\n        Open the Receiver using the supplied conneciton.\n        If the handler has previously been redirected, the redirect\n        context will be used to create a new handler before opening it.\n\n        :param connection: The underlying client shared connection.\n        :type: connection: ~uamqp.async_ops.connection_async.ConnectionAsync\n        \"\"\"\n        # pylint: disable=protected-access\n        self.running = True\n        if self.redirected:\n            self.source = self.redirected.address\n            source = Source(self.source)\n            if self.offset is not None:\n                source.set_filter(self.offset.selector())\n            alt_creds = {\n                \"username\": self.client._auth_config.get(\"iot_username\"),\n                \"password\":self.client._auth_config.get(\"iot_password\")}\n            self._handler = ReceiveClientAsync(\n                source,\n                auth=self.client.get_auth(**alt_creds),\n                debug=self.client.debug,\n                prefetch=self.prefetch,\n                link_properties=self.properties,\n                timeout=self.timeout,\n                error_policy=self.retry_policy,\n                keep_alive_interval=self.keep_alive,\n                client_name=self.name,\n                properties=self.client.create_properties(),\n                loop=self.loop)\n        await self._handler.open_async()\n        while not await self._handler.client_ready_async():\n            await asyncio.sleep(0.05)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning True if the handler has completed all start up processes such as the connection session link and authentication and the client is ready to process messages.", "response": "async def has_started(self):\n        \"\"\"\n        Whether the handler has completed all start up processes such as\n        establishing the connection, session, link and authentication, and\n        is not ready to process messages.\n        **This function is now deprecated and will be removed in v2.0+.**\n\n        :rtype: bool\n        \"\"\"\n        # pylint: disable=protected-access\n        timeout = False\n        auth_in_progress = False\n        if self._handler._connection.cbs:\n            timeout, auth_in_progress = await self._handler._auth.handle_token_async()\n        if timeout:\n            raise EventHubError(\"Authorization timeout.\")\n        if auth_in_progress:\n            return False\n        if not await self._handler._client_ready_async():\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ngenerate a shared access signiture token as a string literal.", "response": "def _generate_sas_token(uri, policy, key, expiry=None):\n    \"\"\"Create a shared access signiture token as a string literal.\n    :returns: SAS token as string literal.\n    :rtype: str\n    \"\"\"\n    from base64 import b64encode, b64decode\n    from hashlib import sha256\n    from hmac import HMAC\n    if not expiry:\n        expiry = time.time() + 3600  # Default to 1 hour.\n    encoded_uri = quote_plus(uri)\n    ttl = int(expiry)\n    sign_key = '%s\\n%d' % (encoded_uri, ttl)\n    signature = b64encode(HMAC(b64decode(key), sign_key.encode('utf-8'), sha256).digest())\n    result = {\n        'sr': uri,\n        'sig': signature,\n        'se': str(ttl)}\n    if policy:\n        result['skn'] = policy\n    return 'SharedAccessSignature ' + urlencode(result)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate an EventHubClient from an existing auth token or token generator.", "response": "def from_sas_token(cls, address, sas_token, eventhub=None, **kwargs):\n        \"\"\"Create an EventHubClient from an existing auth token or token generator.\n\n        :param address: The Event Hub address URL\n        :type address: str\n        :param sas_token: A SAS token or function that returns a SAS token. If a function is supplied,\n         it will be used to retrieve subsequent tokens in the case of token expiry. The function should\n         take no arguments.\n        :type sas_token: str or callable\n        :param eventhub: The name of the EventHub, if not already included in the address URL.\n        :type eventhub: str\n        :param debug: Whether to output network trace logs to the logger. Default\n         is `False`.\n        :type debug: bool\n        :param http_proxy: HTTP proxy settings. This must be a dictionary with the following\n         keys: 'proxy_hostname' (str value) and 'proxy_port' (int value).\n         Additionally the following keys may also be present: 'username', 'password'.\n        :type http_proxy: dict[str, Any]\n        :param auth_timeout: The time in seconds to wait for a token to be authorized by the service.\n         The default value is 60 seconds. If set to 0, no timeout will be enforced from the client.\n        :type auth_timeout: int\n        \"\"\"\n        address = _build_uri(address, eventhub)\n        return cls(address, sas_token=sas_token, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_connection_string(cls, conn_str, eventhub=None, **kwargs):\n        address, policy, key, entity = _parse_conn_str(conn_str)\n        entity = eventhub or entity\n        address = _build_uri(address, entity)\n        return cls(address, username=policy, password=key, **kwargs)", "response": "Create an EventHubClient from a connection string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an EventHubClient from an IoTHub connection string.", "response": "def from_iothub_connection_string(cls, conn_str, **kwargs):\n        \"\"\"\n        Create an EventHubClient from an IoTHub connection string.\n\n        :param conn_str: The connection string.\n        :type conn_str: str\n        :param debug: Whether to output network trace logs to the logger. Default\n         is `False`.\n        :type debug: bool\n        :param http_proxy: HTTP proxy settings. This must be a dictionary with the following\n         keys: 'proxy_hostname' (str value) and 'proxy_port' (int value).\n         Additionally the following keys may also be present: 'username', 'password'.\n        :type http_proxy: dict[str, Any]\n        :param auth_timeout: The time in seconds to wait for a token to be authorized by the service.\n         The default value is 60 seconds. If set to 0, no timeout will be enforced from the client.\n        :type auth_timeout: int\n        \"\"\"\n        address, policy, key, _ = _parse_conn_str(conn_str)\n        hub_name = address.split('.')[0]\n        username = \"{}@sas.root.{}\".format(policy, hub_name)\n        password = _generate_sas_token(address, policy, key)\n        client = cls(\"amqps://\" + address, username=username, password=password, **kwargs)\n        client._auth_config = {  # pylint: disable=protected-access\n            'iot_username': policy,\n            'iot_password': key,\n            'username': username,\n            'password': password}\n        return client"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_properties(self):  # pylint: disable=no-self-use\n        properties = {}\n        properties[\"product\"] = \"eventhub.python\"\n        properties[\"version\"] = __version__\n        properties[\"framework\"] = \"Python {}.{}.{}\".format(*sys.version_info[0:3])\n        properties[\"platform\"] = sys.platform\n        return properties", "response": "Create the properties dictionary for the eventhub connection."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nruns the EventHubClient in blocking mode.", "response": "def run(self):\n        \"\"\"\n        Run the EventHubClient in blocking mode.\n        Opens the connection and starts running all Sender/Receiver clients.\n        Returns a list of the start up results. For a succcesful client start the\n        result will be `None`, otherwise the exception raised.\n        If all clients failed to start, then run will fail, shut down the connection\n        and raise an exception.\n        If at least one client starts up successfully the run command will succeed.\n\n        :rtype: list[~azure.eventhub.common.EventHubError]\n        \"\"\"\n        log.info(\"%r: Starting %r clients\", self.container_id, len(self.clients))\n        try:\n            self._start_clients()\n            redirects = [c.redirected for c in self.clients if c.redirected]\n            failed = [c.error for c in self.clients if c.error]\n            if failed and len(failed) == len(self.clients):\n                log.warning(\"%r: All clients failed to start.\", self.container_id)\n                raise failed[0]\n            if failed:\n                log.warning(\"%r: %r clients failed to start.\", self.container_id, len(failed))\n            elif redirects:\n                self._handle_redirect(redirects)\n        except EventHubError:\n            self.stop()\n            raise\n        except Exception as e:\n            self.stop()\n            raise EventHubError(str(e))\n        return failed"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nstop the EventHubClient and all its Sender and Receiver clients.", "response": "def stop(self):\n        \"\"\"\n        Stop the EventHubClient and all its Sender/Receiver clients.\n        \"\"\"\n        log.info(\"%r: Stopping %r clients\", self.container_id, len(self.clients))\n        self.stopped = True\n        self._close_clients()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget details on the specified EventHub.", "response": "def get_eventhub_info(self):\n        \"\"\"\n        Get details on the specified EventHub.\n        Keys in the details dictionary include:\n            -'name'\n            -'type'\n            -'created_at'\n            -'partition_count'\n            -'partition_ids'\n\n        :rtype: dict\n        \"\"\"\n        alt_creds = {\n            \"username\": self._auth_config.get(\"iot_username\"),\n            \"password\":self._auth_config.get(\"iot_password\")}\n        try:\n            mgmt_auth = self._create_auth(**alt_creds)\n            mgmt_client = uamqp.AMQPClient(self.mgmt_target, auth=mgmt_auth, debug=self.debug)\n            mgmt_client.open()\n            mgmt_msg = Message(application_properties={'name': self.eh_name})\n            response = mgmt_client.mgmt_request(\n                mgmt_msg,\n                constants.READ_OPERATION,\n                op_type=b'com.microsoft:eventhub',\n                status_code_field=b'status-code',\n                description_fields=b'status-description')\n            eh_info = response.get_data()\n            output = {}\n            if eh_info:\n                output['name'] = eh_info[b'name'].decode('utf-8')\n                output['type'] = eh_info[b'type'].decode('utf-8')\n                output['created_at'] = datetime.datetime.fromtimestamp(float(eh_info[b'created_at'])/1000)\n                output['partition_count'] = eh_info[b'partition_count']\n                output['partition_ids'] = [p.decode('utf-8') for p in eh_info[b'partition_ids']]\n            return output\n        finally:\n            mgmt_client.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a receiver to the client for a particular consumer group and partition.", "response": "def add_receiver(\n            self, consumer_group, partition, offset=None, prefetch=300,\n            operation=None, keep_alive=30, auto_reconnect=True):\n        \"\"\"\n        Add a receiver to the client for a particular consumer group and partition.\n\n        :param consumer_group: The name of the consumer group.\n        :type consumer_group: str\n        :param partition: The ID of the partition.\n        :type partition: str\n        :param offset: The offset from which to start receiving.\n        :type offset: ~azure.eventhub.common.Offset\n        :param prefetch: The message prefetch count of the receiver. Default is 300.\n        :type prefetch: int\n        :operation: An optional operation to be appended to the hostname in the source URL.\n         The value must start with `/` character.\n        :type operation: str\n        :rtype: ~azure.eventhub.receiver.Receiver\n        \"\"\"\n        path = self.address.path + operation if operation else self.address.path\n        source_url = \"amqps://{}{}/ConsumerGroups/{}/Partitions/{}\".format(\n            self.address.hostname, path, consumer_group, partition)\n        handler = Receiver(\n            self, source_url, offset=offset, prefetch=prefetch,\n            keep_alive=keep_alive, auto_reconnect=auto_reconnect)\n        self.clients.append(handler)\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a sender to the EventHub object.", "response": "def add_sender(self, partition=None, operation=None, send_timeout=60, keep_alive=30, auto_reconnect=True):\n        \"\"\"\n        Add a sender to the client to EventData object to an EventHub.\n\n        :param partition: Optionally specify a particular partition to send to.\n         If omitted, the events will be distributed to available partitions via\n         round-robin.\n        :type parition: str\n        :operation: An optional operation to be appended to the hostname in the target URL.\n         The value must start with `/` character.\n        :type operation: str\n        :param send_timeout: The timeout in seconds for an individual event to be sent from the time that it is\n         queued. Default value is 60 seconds. If set to 0, there will be no timeout.\n        :type send_timeout: int\n        :param keep_alive: The time interval in seconds between pinging the connection to keep it alive during\n         periods of inactivity. The default value is 30 seconds. If set to `None`, the connection will not\n         be pinged.\n        :type keep_alive: int\n        :param auto_reconnect: Whether to automatically reconnect the sender if a retryable error occurs.\n         Default value is `True`.\n        :rtype: ~azure.eventhub.sender.Sender\n        \"\"\"\n        target = \"amqps://{}{}\".format(self.address.hostname, self.address.path)\n        if operation:\n            target = target + operation\n        handler = Sender(\n            self, target, partition=partition, send_timeout=send_timeout,\n            keep_alive=keep_alive, auto_reconnect=auto_reconnect)\n        self.clients.append(handler)\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate an instance of ~uamqp. authentication. cbs_auth_async. SASLPlainAuthAsync to authenticate the user and password.", "response": "def _create_auth(self, username=None, password=None):\n        \"\"\"\n        Create an ~uamqp.authentication.cbs_auth_async.SASTokenAuthAsync instance to authenticate\n        the session.\n\n        :param username: The name of the shared access policy.\n        :type username: str\n        :param password: The shared access key.\n        :type password: str\n        \"\"\"\n        if self.sas_token:\n            token = self.sas_token() if callable(self.sas_token) else self.sas_token\n            try:\n                expiry = int(parse_sas_token(token)['se'])\n            except (KeyError, TypeError, IndexError):\n                raise ValueError(\"Supplied SAS token has no valid expiry value.\")\n            return authentication.SASTokenAsync(\n                self.auth_uri, self.auth_uri, token,\n                expires_at=expiry,\n                timeout=self.auth_timeout,\n                http_proxy=self.http_proxy)\n\n        username = username or self._auth_config['username']\n        password = password or self._auth_config['password']\n        if \"@sas.root\" in username:\n            return authentication.SASLPlain(\n                self.address.hostname, username, password, http_proxy=self.http_proxy)\n        return authentication.SASTokenAsync.from_shared_access_key(\n            self.auth_uri, username, password, timeout=self.auth_timeout, http_proxy=self.http_proxy)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def run_async(self):\n        log.info(\"%r: Starting %r clients\", self.container_id, len(self.clients))\n        tasks = [self._start_client_async(c) for c in self.clients]\n        try:\n            await asyncio.gather(*tasks)\n            redirects = [c.redirected for c in self.clients if c.redirected]\n            failed = [c.error for c in self.clients if c.error]\n            if failed and len(failed) == len(self.clients):\n                log.warning(\"%r: All clients failed to start.\", self.container_id)\n                raise failed[0]\n            if failed:\n                log.warning(\"%r: %r clients failed to start.\", self.container_id, len(failed))\n            elif redirects:\n                await self._handle_redirect(redirects)\n        except EventHubError:\n            await self.stop_async()\n            raise\n        except Exception as exp:\n            await self.stop_async()\n            raise EventHubError(str(exp))\n        return failed", "response": "Starts the EventHubClient asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def stop_async(self):\n        log.info(\"%r: Stopping %r clients\", self.container_id, len(self.clients))\n        self.stopped = True\n        await self._close_clients_async()", "response": "Stop the EventHubClient and all its Sender and Receiver clients."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get_eventhub_info_async(self):\n        alt_creds = {\n            \"username\": self._auth_config.get(\"iot_username\"),\n            \"password\":self._auth_config.get(\"iot_password\")}\n        try:\n            mgmt_auth = self._create_auth(**alt_creds)\n            mgmt_client = AMQPClientAsync(self.mgmt_target, auth=mgmt_auth, debug=self.debug)\n            await mgmt_client.open_async()\n            mgmt_msg = Message(application_properties={'name': self.eh_name})\n            response = await mgmt_client.mgmt_request_async(\n                mgmt_msg,\n                constants.READ_OPERATION,\n                op_type=b'com.microsoft:eventhub',\n                status_code_field=b'status-code',\n                description_fields=b'status-description')\n            eh_info = response.get_data()\n            output = {}\n            if eh_info:\n                output['name'] = eh_info[b'name'].decode('utf-8')\n                output['type'] = eh_info[b'type'].decode('utf-8')\n                output['created_at'] = datetime.datetime.fromtimestamp(float(eh_info[b'created_at'])/1000)\n                output['partition_count'] = eh_info[b'partition_count']\n                output['partition_ids'] = [p.decode('utf-8') for p in eh_info[b'partition_ids']]\n            return output\n        finally:\n            await mgmt_client.close_async()", "response": "Get details on the specified EventHub async."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds an async receiver to the client for a particular consumer group and partition.", "response": "def add_async_receiver(\n            self, consumer_group, partition, offset=None, prefetch=300,\n            operation=None, keep_alive=30, auto_reconnect=True, loop=None):\n        \"\"\"\n        Add an async receiver to the client for a particular consumer group and partition.\n\n        :param consumer_group: The name of the consumer group.\n        :type consumer_group: str\n        :param partition: The ID of the partition.\n        :type partition: str\n        :param offset: The offset from which to start receiving.\n        :type offset: ~azure.eventhub.common.Offset\n        :param prefetch: The message prefetch count of the receiver. Default is 300.\n        :type prefetch: int\n        :operation: An optional operation to be appended to the hostname in the source URL.\n         The value must start with `/` character.\n        :type operation: str\n        :rtype: ~azure.eventhub.async_ops.receiver_async.ReceiverAsync\n        \"\"\"\n        path = self.address.path + operation if operation else self.address.path\n        source_url = \"amqps://{}{}/ConsumerGroups/{}/Partitions/{}\".format(\n            self.address.hostname, path, consumer_group, partition)\n        handler = AsyncReceiver(\n            self, source_url, offset=offset, prefetch=prefetch,\n            keep_alive=keep_alive, auto_reconnect=auto_reconnect, loop=loop)\n        self.clients.append(handler)\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd an async sender to the EventHub.", "response": "def add_async_sender(\n            self, partition=None, operation=None, send_timeout=60,\n            keep_alive=30, auto_reconnect=True, loop=None):\n        \"\"\"\n        Add an async sender to the client to send ~azure.eventhub.common.EventData object\n        to an EventHub.\n\n        :param partition: Optionally specify a particular partition to send to.\n         If omitted, the events will be distributed to available partitions via\n         round-robin.\n        :type partition: str\n        :operation: An optional operation to be appended to the hostname in the target URL.\n         The value must start with `/` character.\n        :type operation: str\n        :param send_timeout: The timeout in seconds for an individual event to be sent from the time that it is\n         queued. Default value is 60 seconds. If set to 0, there will be no timeout.\n        :type send_timeout: int\n        :param keep_alive: The time interval in seconds between pinging the connection to keep it alive during\n         periods of inactivity. The default value is 30 seconds. If set to `None`, the connection will not\n         be pinged.\n        :type keep_alive: int\n        :param auto_reconnect: Whether to automatically reconnect the sender if a retryable error occurs.\n         Default value is `True`.\n        :type auto_reconnect: bool\n        :rtype: ~azure.eventhub.async_ops.sender_async.SenderAsync\n        \"\"\"\n        target = \"amqps://{}{}\".format(self.address.hostname, self.address.path)\n        if operation:\n            target = target + operation\n        handler = AsyncSender(\n            self, target, partition=partition, send_timeout=send_timeout, keep_alive=keep_alive,\n            auto_reconnect=auto_reconnect, loop=loop)\n        self.clients.append(handler)\n        return handler"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_source(self, checkpoint):\n        self.partition_id = checkpoint.partition_id\n        self.offset = checkpoint.offset\n        self.sequence_number = checkpoint.sequence_number", "response": "Creates a new checkpoint from an existing checkpoint."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef with_blob(self, blob):\n        content = json.loads(blob.content)\n        self.partition_id = content[\"partition_id\"]\n        self.owner = content[\"owner\"]\n        self.token = content[\"token\"]\n        self.epoch = content[\"epoch\"]\n        self.offset = content[\"offset\"]\n        self.sequence_number = content[\"sequence_number\"]\n        self.event_processor_context = content.get(\"event_processor_context\")", "response": "Init Azure Blob Lease with existing blob."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def is_expired(self):\n        if asyncio.iscoroutinefunction(self.state):\n            current_state = await self.state()\n        else:\n            current_state = self.state()\n        if current_state:\n            return current_state != \"leased\"\n        return False", "response": "Check and return Azure Blob Lease state using Storage API."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nmakes pump sync so that it can be run in a thread.", "response": "def run(self):\n        \"\"\"\n        Makes pump sync so that it can be run in a thread.\n        \"\"\"\n        self.loop = asyncio.new_event_loop()\n        self.loop.run_until_complete(self.open_async())"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_pump_status(self, status):\n        self.pump_status = status\n        _logger.info(\"%r partition %r\", status, self.lease.partition_id)", "response": "Sets the status of the pump."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_lease(self, new_lease):\n        if self.partition_context:\n            self.partition_context.lease = new_lease\n            self.partition_context.event_processor_context = new_lease.event_processor_context", "response": "Sets a new partition lease to be processed by the pump."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def process_events_async(self, events):\n        if events:\n            # Synchronize to serialize calls to the processor. The handler is not installed until\n            # after OpenAsync returns, so ProcessEventsAsync cannot conflict with OpenAsync. There\n            # could be a conflict between ProcessEventsAsync and CloseAsync, however. All calls to\n            # CloseAsync are protected by synchronizing too.\n            try:\n                last = events[-1]\n                if last is not None:\n                    self.partition_context.set_offset_and_sequence_number(last)\n                    await self.processor.process_events_async(self.partition_context, events)\n            except Exception as err:  # pylint: disable=broad-except\n                await self.process_error_async(err)", "response": "Process events from the partition context."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def on_open_async(self):\n        _opened_ok = False\n        _retry_count = 0\n        while (not _opened_ok) and (_retry_count < 5):\n            try:\n                await self.open_clients_async()\n                _opened_ok = True\n            except Exception as err:  # pylint: disable=broad-except\n                _logger.warning(\n                    \"%r,%r PartitionPumpWarning: Failure creating client or receiver, retrying: %r\",\n                    self.host.guid, self.partition_context.partition_id, err)\n                last_exception = err\n                _retry_count += 1\n\n        if not _opened_ok:\n            await self.processor.process_error_async(self.partition_context, last_exception)\n            self.set_pump_status(\"OpenFailed\")\n\n        if self.pump_status == \"Opening\":\n            loop = asyncio.get_event_loop()\n            self.set_pump_status(\"Running\")\n            await self.eh_client.run_async()\n            self.running = loop.create_task(self.partition_receiver.run())\n\n        if self.pump_status in [\"OpenFailed\", \"Errored\"]:\n            self.set_pump_status(\"Closing\")\n            await self.clean_up_clients_async()\n            self.set_pump_status(\"Closed\")", "response": "A method that creates a new client or receiver asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nopen event hub clients and receive handlers.", "response": "async def open_clients_async(self):\n        \"\"\"\n        Responsible for establishing connection to event hub client\n        throws EventHubsException, IOException, InterruptedException, ExecutionException.\n        \"\"\"\n        await self.partition_context.get_initial_offset_async()\n        # Create event hub client and receive handler and set options\n        self.eh_client = EventHubClientAsync(\n            self.host.eh_config.client_address,\n            debug=self.host.eph_options.debug_trace,\n            http_proxy=self.host.eph_options.http_proxy)\n        self.partition_receive_handler = self.eh_client.add_async_receiver(\n            self.partition_context.consumer_group_name,\n            self.partition_context.partition_id,\n            Offset(self.partition_context.offset),\n            prefetch=self.host.eph_options.prefetch_count,\n            keep_alive=self.host.eph_options.keep_alive_interval,\n            auto_reconnect=self.host.eph_options.auto_reconnect_on_error,\n            loop=self.loop)\n        self.partition_receiver = PartitionReceiver(self)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def clean_up_clients_async(self):\n        if self.partition_receiver:\n            if self.eh_client:\n                await self.eh_client.stop_async()\n                self.partition_receiver = None\n                self.partition_receive_handler = None\n                self.eh_client = None", "response": "Cleans up the client threads."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def on_closing_async(self, reason):\n        self.partition_receiver.eh_partition_pump.set_pump_status(\"Errored\")\n        try:\n            await self.running\n        except TypeError:\n            _logger.debug(\"No partition pump running.\")\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.info(\"Error on closing partition pump: %r\", err)\n        await self.clean_up_clients_async()", "response": "Overides partition pump on closing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun the async partion reciever event loop to retrive messages from the event queue.", "response": "async def run(self):\n        \"\"\"\n        Runs the async partion reciever event loop to retrive messages from the event queue.\n        \"\"\"\n        # Implement pull max batch from queue instead of one message at a time\n        while self.eh_partition_pump.pump_status != \"Errored\" and not self.eh_partition_pump.is_closing():\n            if self.eh_partition_pump.partition_receive_handler:\n                try:\n                    msgs = await self.eh_partition_pump.partition_receive_handler.receive(\n                        max_batch_size=self.max_batch_size,\n                        timeout=self.recieve_timeout)\n                except Exception as e:  # pylint: disable=broad-except\n                    _logger.info(\"Error raised while attempting to receive messages: %r\", e)\n                    await self.process_error_async(e)\n                else:\n                    if not msgs:\n                        _logger.info(\"No events received, queue size %r, release %r\",\n                                     self.eh_partition_pump.partition_receive_handler.queue_size,\n                                     self.eh_partition_pump.host.eph_options.release_pump_on_timeout)\n                        if self.eh_partition_pump.host.eph_options.release_pump_on_timeout:\n                            await self.process_error_async(TimeoutError(\"No events received\"))\n                    else:\n                        await self.process_events_async(msgs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nhandling processing errors and sets the status of the pump to errored.", "response": "async def process_error_async(self, error):\n        \"\"\"\n        Handles processing errors this is never called since python recieve client doesn't\n        have error handling implemented (TBD add fault pump handling).\n\n        :param error: An error the occurred.\n        :type error: Exception\n        \"\"\"\n        try:\n            await self.eh_partition_pump.process_error_async(error)\n        finally:\n            self.eh_partition_pump.set_pump_status(\"Errored\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef with_partition_id(self, partition_id):\n        self.partition_id = partition_id\n        self.owner = None\n        self.token = None\n        self.epoch = 0\n        self.event_processor_context = None", "response": "Init with partition Id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate offset based on event.", "response": "def set_offset_and_sequence_number(self, event_data):\n        \"\"\"\n        Updates offset based on event.\n\n        :param event_data: A received EventData with valid offset and sequenceNumber.\n        :type event_data: ~azure.eventhub.common.EventData\n        \"\"\"\n        if not event_data:\n            raise Exception(event_data)\n        self.offset = event_data.offset.value\n        self.sequence_number = event_data.sequence_number"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def get_initial_offset_async(self): # throws InterruptedException, ExecutionException\n        _logger.info(\"Calling user-provided initial offset provider %r %r\",\n                     self.host.guid, self.partition_id)\n        starting_checkpoint = await self.host.storage_manager.get_checkpoint_async(self.partition_id)\n        if not starting_checkpoint:\n            # No checkpoint was ever stored. Use the initialOffsetProvider instead\n            # defaults to \"-1\"\n            self.offset = self.host.eph_options.initial_offset_provider\n            self.sequence_number = -1\n        else:\n            self.offset = starting_checkpoint.offset\n            self.sequence_number = starting_checkpoint.sequence_number\n\n        _logger.info(\"%r %r Initial offset/sequenceNumber provided %r/%r\",\n                     self.host.guid, self.partition_id, self.offset, self.sequence_number)\n        return self.offset", "response": "Get the initial offset for processing the partition."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def checkpoint_async(self, event_processor_context=None):\n        captured_checkpoint = Checkpoint(self.partition_id, self.offset, self.sequence_number)\n        await self.persist_checkpoint_async(captured_checkpoint, event_processor_context)\n        self.event_processor_context = event_processor_context", "response": "This method generates a checkpoint for the current partition using the curren offset and sequenceNumber for the current event processor and persists it to the checkpoint manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def checkpoint_async_event_data(self, event_data, event_processor_context=None):\n        if not event_data:\n            raise ValueError(\"event_data\")\n        if event_data.sequence_number > self.sequence_number:\n            #We have never seen this sequence number yet\n            raise ValueError(\"Argument Out Of Range event_data x-opt-sequence-number\")\n\n        await self.persist_checkpoint_async(Checkpoint(self.partition_id,\n                                                       event_data.offset.value,\n                                                       event_data.sequence_number),\n                                            event_processor_context)\n        self.event_processor_context = event_processor_context", "response": "Writes the received EventData instance to the checkpoint store."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the parition context as a string", "response": "def to_string(self):\n        \"\"\"\n        Returns the parition context in the following format:\n        \"PartitionContext({EventHubPath}{ConsumerGroupName}{PartitionId}{SequenceNumber})\"\n\n        :rtype: str\n        \"\"\"\n        return \"PartitionContext({}{}{}{})\".format(self.eh_path,\n                                                   self.consumer_group_name,\n                                                   self.partition_id,\n                                                   self.sequence_number)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\npersists the checkpoint to Azure.", "response": "async def persist_checkpoint_async(self, checkpoint, event_processor_context=None):\n        \"\"\"\n        Persists the checkpoint, and - optionally - the state of the Event Processor.\n\n        :param checkpoint: The checkpoint to persist.\n        :type checkpoint: ~azure.eventprocessorhost.checkpoint.Checkpoint\n        :param event_processor_context An optional custom state value for the Event Processor.\n         This data must be in a JSON serializable format.\n        :type event_processor_context: str or dict\n        \"\"\"\n        _logger.debug(\"PartitionPumpCheckpointStart %r %r %r %r\",\n                      self.host.guid, checkpoint.partition_id, checkpoint.offset, checkpoint.sequence_number)\n        try:\n            in_store_checkpoint = await self.host.storage_manager.get_checkpoint_async(checkpoint.partition_id)\n            if not in_store_checkpoint or checkpoint.sequence_number >= in_store_checkpoint.sequence_number:\n                if not in_store_checkpoint:\n                    _logger.info(\"persisting checkpoint %r\", checkpoint.__dict__)\n                    await self.host.storage_manager.create_checkpoint_if_not_exists_async(checkpoint.partition_id)\n\n                self.lease.event_processor_context = event_processor_context\n                if not await self.host.storage_manager.update_checkpoint_async(self.lease, checkpoint):\n                    _logger.error(\"Failed to persist checkpoint for partition: %r\", self.partition_id)\n                    raise Exception(\"failed to persist checkpoint\")\n                self.lease.offset = checkpoint.offset\n                self.lease.sequence_number = checkpoint.sequence_number\n            else:\n                _logger.error(  # pylint: disable=logging-not-lazy\n                    \"Ignoring out of date checkpoint with offset %r/sequence number %r because \" +\n                    \"current persisted checkpoint has higher offset %r/sequence number %r\",\n                    checkpoint.offset,\n                    checkpoint.sequence_number,\n                    in_store_checkpoint.offset,\n                    in_store_checkpoint.sequence_number)\n                raise Exception(\"offset/sequenceNumber invalid\")\n\n        except Exception as err:\n            _logger.error(\"PartitionPumpCheckpointError %r %r %r\",\n                          self.host.guid, checkpoint.partition_id, err)\n            raise\n        finally:\n            _logger.debug(\"PartitionPumpCheckpointStop %r %r\",\n                          self.host.guid, checkpoint.partition_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def close_async(self, context, reason):\n        logger.info(\"Connection closed (reason {}, id {}, offset {}, sq_number {})\".format(\n            reason,\n            context.partition_id,\n            context.offset,\n            context.sequence_number))", "response": "Called by event processor host to indicate that the connection is being closed."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def process_events_async(self, context, messages):\n        logger.info(\"Events processed {}\".format(context.sequence_number))\n        await context.checkpoint_async()", "response": "Called by the event processor host when a batch of events has arrived."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef open(self):\n        # pylint: disable=protected-access\n        self.running = True\n        if self.redirected:\n            self.source = self.redirected.address\n            source = Source(self.source)\n            if self.offset is not None:\n                source.set_filter(self.offset.selector())\n            alt_creds = {\n                \"username\": self.client._auth_config.get(\"iot_username\"),\n                \"password\":self.client._auth_config.get(\"iot_password\")}\n            self._handler = ReceiveClient(\n                source,\n                auth=self.client.get_auth(**alt_creds),\n                debug=self.client.debug,\n                prefetch=self.prefetch,\n                link_properties=self.properties,\n                timeout=self.timeout,\n                error_policy=self.retry_policy,\n                keep_alive_interval=self.keep_alive,\n                client_name=self.name,\n                properties=self.client.create_properties())\n        self._handler.open()\n        while not self._handler.client_ready():\n            time.sleep(0.05)", "response": "Open the Receiver using the supplied conneciton."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef receive(self, max_batch_size=None, timeout=None):\n        if self.error:\n            raise self.error\n        if not self.running:\n            raise ValueError(\"Unable to receive until client has been started.\")\n        data_batch = []\n        try:\n            timeout_ms = 1000 * timeout if timeout else 0\n            message_batch = self._handler.receive_message_batch(\n                max_batch_size=max_batch_size,\n                timeout=timeout_ms)\n            for message in message_batch:\n                event_data = EventData(message=message)\n                self.offset = event_data.offset\n                data_batch.append(event_data)\n            return data_batch\n        except (errors.TokenExpired, errors.AuthenticationException):\n            log.info(\"Receiver disconnected due to token error. Attempting reconnect.\")\n            self.reconnect()\n            return data_batch\n        except (errors.LinkDetach, errors.ConnectionClose) as shutdown:\n            if shutdown.action.retry and self.auto_reconnect:\n                log.info(\"Receiver detached. Attempting reconnect.\")\n                self.reconnect()\n                return data_batch\n            log.info(\"Receiver detached. Shutting down.\")\n            error = EventHubError(str(shutdown), shutdown)\n            self.close(exception=error)\n            raise error\n        except errors.MessageHandlerError as shutdown:\n            if self.auto_reconnect:\n                log.info(\"Receiver detached. Attempting reconnect.\")\n                self.reconnect()\n                return data_batch\n            log.info(\"Receiver detached. Shutting down.\")\n            error = EventHubError(str(shutdown), shutdown)\n            self.close(exception=error)\n            raise error\n        except Exception as e:\n            log.info(\"Unexpected error occurred (%r). Shutting down.\", e)\n            error = EventHubError(\"Receive failed: {}\".format(e))\n            self.close(exception=error)\n            raise error", "response": "Receive events from the EventHub."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a list of all the event hub partition IDs.", "response": "async def get_partition_ids_async(self):\n        \"\"\"\n        Returns a list of all the event hub partition IDs.\n\n        :rtype: list[str]\n        \"\"\"\n        if not self.partition_ids:\n            try:\n                eh_client = EventHubClientAsync(\n                    self.host.eh_config.client_address,\n                    debug=self.host.eph_options.debug_trace,\n                    http_proxy=self.host.eph_options.http_proxy)\n                try:\n                    eh_info = await eh_client.get_eventhub_info_async()\n                    self.partition_ids = eh_info['partition_ids']\n                except Exception as err:  # pylint: disable=broad-except\n                    raise Exception(\"Failed to get partition ids\", repr(err))\n            finally:\n                await eh_client.stop_async()\n        return self.partition_ids"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def start_async(self):\n        if self.run_task:\n            raise Exception(\"A PartitionManager cannot be started multiple times.\")\n\n        partition_count = await self.initialize_stores_async()\n        _logger.info(\"%r PartitionCount: %r\", self.host.guid, partition_count)\n        self.run_task = asyncio.ensure_future(self.run_async())", "response": "Starts the partition manager."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nterminates the partition manger.", "response": "async def stop_async(self):\n        \"\"\"\n        Terminiates the partition manger.\n        \"\"\"\n        self.cancellation_token.cancel()\n        if self.run_task and not self.run_task.done():\n            await self.run_task"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nstarts the main loop and manages exceptions and cleanup.", "response": "async def run_async(self):\n        \"\"\"\n        Starts the run loop and manages exceptions and cleanup.\n        \"\"\"\n        try:\n            await self.run_loop_async()\n        except Exception as err:  # pylint: disable=broad-except\n            _logger.error(\"Run loop failed %r\", err)\n\n        try:\n            _logger.info(\"Shutting down all pumps %r\", self.host.guid)\n            await self.remove_all_pumps_async(\"Shutdown\")\n        except Exception as err:  # pylint: disable=broad-except\n            raise Exception(\"Failed to remove all pumps {!r}\".format(err))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def initialize_stores_async(self):\n        await self.host.storage_manager.create_checkpoint_store_if_not_exists_async()\n        partition_ids = await self.get_partition_ids_async()\n        retry_tasks = []\n        for partition_id in partition_ids:\n            retry_tasks.append(\n                self.retry_async(\n                    self.host.storage_manager.create_checkpoint_if_not_exists_async,\n                    partition_id=partition_id,\n                    retry_message=\"Failure creating checkpoint for partition, retrying\",\n                    final_failure_message=\"Out of retries creating checkpoint blob for partition\",\n                    max_retries=5,\n                    host_id=self.host.host_name))\n\n        await asyncio.gather(*retry_tasks)\n        return len(partition_ids)", "response": "Intializes the partition checkpoint and lease store ensures that a checkpoint store exists for all partitions."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretries a function in the cluster.", "response": "def retry(self, func, partition_id, retry_message, final_failure_message, max_retries, host_id):\n        \"\"\"\n        Make attempt_renew_lease async call sync.\n        \"\"\"\n        loop = asyncio.new_event_loop()\n        loop.run_until_complete(self.retry_async(func, partition_id, retry_message,\n                                                 final_failure_message, max_retries, host_id))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def retry_async(self, func, partition_id, retry_message,\n                          final_failure_message, max_retries, host_id):\n        \"\"\"\n        Throws if it runs out of retries. If it returns, action succeeded.\n        \"\"\"\n        created_okay = False\n        retry_count = 0\n        while not created_okay and retry_count <= max_retries:\n            try:\n                await func(partition_id)\n                created_okay = True\n            except Exception as err:  # pylint: disable=broad-except\n                _logger.error(\"%r %r %r %r\", retry_message, host_id, partition_id, err)\n                retry_count += 1\n        if not created_okay:\n            raise Exception(host_id, final_failure_message)", "response": "Retry the given function for a given partition."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def run_loop_async(self):\n        while not self.cancellation_token.is_cancelled:\n            lease_manager = self.host.storage_manager\n            # Inspect all leases.\n            # Acquire any expired leases.\n            # Renew any leases that currently belong to us.\n            getting_all_leases = await lease_manager.get_all_leases()\n            leases_owned_by_others_q = Queue()\n            renew_tasks = [\n                self.attempt_renew_lease_async(\n                    get_lease_task,\n                    owned_by_others_q=leases_owned_by_others_q,\n                    lease_manager=lease_manager)\n                for get_lease_task in getting_all_leases]\n            await asyncio.gather(*renew_tasks)\n\n            # Extract all leasees leases_owned_by_others and our_lease_count from the\n            all_leases = {}\n            leases_owned_by_others = []\n            our_lease_count = 0\n            while not leases_owned_by_others_q.empty():\n                lease_owned_by_other = leases_owned_by_others_q.get()\n                # Check if lease is owned by other and append\n                if lease_owned_by_other[0]:\n                    leases_owned_by_others.append(lease_owned_by_other[1])\n                else:\n                    our_lease_count += 1\n                all_leases[lease_owned_by_other[1].partition_id] = lease_owned_by_other[1]\n\n            # Grab more leases if available and needed for load balancing\n            leases_owned_by_others_count = len(leases_owned_by_others)\n            if leases_owned_by_others_count > 0:\n                steal_this_lease = self.which_lease_to_steal(\n                    leases_owned_by_others, our_lease_count)\n                if steal_this_lease:\n                    try:\n                        _logger.info(\"Lease to steal %r\", steal_this_lease.serializable())\n                        if await lease_manager.acquire_lease_async(steal_this_lease):\n                            _logger.info(\"Stole lease sucessfully %r %r\",\n                                         self.host.guid, steal_this_lease.partition_id)\n                        else:\n                            _logger.info(\"Failed to steal lease for partition %r %r\",\n                                         self.host.guid, steal_this_lease.partition_id)\n                    except Exception as err:  # pylint: disable=broad-except\n                        _logger.error(\"Failed to steal lease %r\", err)\n\n            for partition_id in all_leases:\n                try:\n                    updated_lease = all_leases[partition_id]\n                    if updated_lease.owner == self.host.host_name:\n                        _logger.debug(\"Attempting to renew lease %r %r\",\n                                      self.host.guid, partition_id)\n                        await self.check_and_add_pump_async(partition_id, updated_lease)\n                    else:\n                        _logger.debug(\"Removing pump due to lost lease.\")\n                        await self.remove_pump_async(partition_id, \"LeaseLost\")\n                except Exception as err:  # pylint: disable=broad-except\n                    _logger.error(\"Failed to update lease %r\", err)\n            await asyncio.sleep(lease_manager.lease_renew_interval)", "response": "This is the main loop for allocating and manging pumps."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def check_and_add_pump_async(self, partition_id, lease):\n        if partition_id in self.partition_pumps:\n            # There already is a pump. Make sure the pump is working and replace the lease.\n            captured_pump = self.partition_pumps[partition_id]\n            if captured_pump.pump_status == \"Errored\" or captured_pump.is_closing():\n                # The existing pump is bad. Remove it.\n                await self.remove_pump_async(partition_id, \"Shutdown\")\n            else:\n                # Pump is working, should just replace the lease.\n                # This is causing a race condition since if the checkpoint is being updated\n                # when the lease changes then the pump will error and shut down\n                captured_pump.set_lease(lease)\n        else:\n            _logger.info(\"Starting pump %r %r\", self.host.guid, partition_id)\n            await self.create_new_pump_async(partition_id, lease)", "response": "Check if a pump is working and add it to the lease."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def create_new_pump_async(self, partition_id, lease):\n        loop = asyncio.get_event_loop()\n        partition_pump = EventHubPartitionPump(self.host, lease)\n        # Do the put after start, if the start fails then put doesn't happen\n        loop.create_task(partition_pump.open_async())\n        self.partition_pumps[partition_id] = partition_pump\n        _logger.info(\"Created new partition pump %r %r\", self.host.guid, partition_id)", "response": "Create a new pump thread with a given lease."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a single partiton pump.", "response": "async def remove_pump_async(self, partition_id, reason):\n        \"\"\"\n        Stops a single partiton pump.\n\n        :param partition_id: The partition ID.\n        :type partition_id: str\n        :param reason: A reason for closing.\n        :type reason: str\n        \"\"\"\n        if partition_id in self.partition_pumps:\n            captured_pump = self.partition_pumps[partition_id]\n            if not captured_pump.is_closing():\n                await captured_pump.close_async(reason)\n            # else, pump is already closing/closed, don't need to try to shut it down again\n            del self.partition_pumps[partition_id]  # remove pump\n            _logger.debug(\"Removed pump %r %r\", self.host.guid, partition_id)\n            _logger.debug(\"%r pumps still running\", len(self.partition_pumps))\n        else:\n            # PartitionManager main loop tries to remove pump for every partition that the\n            # host does not own, just to be sure. Not finding a pump for a partition is normal\n            # and expected most of the time.\n            _logger.debug(\"No pump found to remove for this partition %r %r\",\n                          self.host.guid, partition_id)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def remove_all_pumps_async(self, reason):\n        pump_tasks = [self.remove_pump_async(p_id, reason) for p_id in self.partition_pumps]\n        await asyncio.gather(*pump_tasks)\n        return True", "response": "Stops all partition pumps and returns True if all pumps are still open."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndetermines and return which lease to steal from.", "response": "def which_lease_to_steal(self, stealable_leases, have_lease_count):\n        \"\"\"\n        Determines and return which lease to steal\n        If the number of leases is a multiple of the number of hosts, then the desired\n        configuration is that all hosts own the name number of leases, and the\n        difference between the \"biggest\" owner and any other is 0.\n\n        If the number of leases is not a multiple of the number of hosts, then the most\n        even configurationpossible is for some hosts to have (self, leases/hosts) leases\n        and others to have (self, (self, leases/hosts) + 1). For example, for 16 partitions\n        distributed over five hosts, the distribution would be 4, 3, 3, 3, 3, or any of the\n        possible reorderings.\n\n        In either case, if the difference between this host and the biggest owner is 2 or more,\n        then thesystem is not in the most evenly-distributed configuration, so steal one lease\n        from the biggest. If there is a tie for biggest, we pick whichever appears first in the\n        list because it doesn't really matter which \"biggest\" is trimmed down.\n\n        Stealing one at a time prevents flapping because it reduces the difference between the\n        biggest and this host by two at a time. If the starting difference is two or greater,\n        then the difference cannot end up below 0. This host may become tied for biggest, but it\n        cannot become larger than the host that it is stealing from.\n\n        :param stealable_leases: List of leases to determine which can be stolen.\n        :type stealable_leases: list[~azure.eventprocessorhost.lease.Lease]\n        :param have_lease_count: Lease count.\n        :type have_lease_count: int\n        :rtype: ~azure.eventprocessorhost.lease.Lease\n        \"\"\"\n        counts_by_owner = self.count_leases_by_owner(stealable_leases)\n        biggest_owner = (sorted(counts_by_owner.items(), key=lambda kv: kv[1])).pop()\n        steal_this_lease = None\n        if (biggest_owner[1] - have_lease_count) >= 2:\n            steal_this_lease = [l for l in stealable_leases if l.owner == biggest_owner[0]][0]\n\n        return steal_this_lease"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef count_leases_by_owner(self, leases):  # pylint: disable=no-self-use\n        owners = [l.owner for l in leases]\n        return dict(Counter(owners))", "response": "Returns a dictionary of leases by owner."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef attempt_renew_lease(self, lease_task, owned_by_others_q, lease_manager):\n        loop = asyncio.new_event_loop()\n        loop.run_until_complete(self.attempt_renew_lease_async(lease_task, owned_by_others_q, lease_manager))", "response": "Attempt to renew a lease."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nopens the Sender using the supplied conneciton.", "response": "async def open_async(self):\n        \"\"\"\n        Open the Sender using the supplied conneciton.\n        If the handler has previously been redirected, the redirect\n        context will be used to create a new handler before opening it.\n\n        :param connection: The underlying client shared connection.\n        :type: connection: ~uamqp.async_ops.connection_async.ConnectionAsync\n        \"\"\"\n        self.running = True\n        if self.redirected:\n            self.target = self.redirected.address\n            self._handler = SendClientAsync(\n                self.target,\n                auth=self.client.get_auth(),\n                debug=self.client.debug,\n                msg_timeout=self.timeout,\n                error_policy=self.retry_policy,\n                keep_alive_interval=self.keep_alive,\n                client_name=self.name,\n                properties=self.client.create_properties(),\n                loop=self.loop)\n        await self._handler.open_async()\n        while not await self._handler.client_ready_async():\n            await asyncio.sleep(0.05)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the send handler.", "response": "async def close_async(self, exception=None):\n        \"\"\"\n        Close down the handler. If the handler has already closed,\n        this will be a no op. An optional exception can be passed in to\n        indicate that the handler was shutdown due to error.\n\n        :param exception: An optional exception if the handler is closing\n         due to an error.\n        :type exception: Exception\n        \"\"\"\n        self.running = False\n        if self.error:\n            return\n        if isinstance(exception, errors.LinkRedirect):\n            self.redirected = exception\n        elif isinstance(exception, EventHubError):\n            self.error = exception\n        elif isinstance(exception, (errors.LinkDetach, errors.ConnectionClose)):\n            self.error = EventHubError(str(exception), exception)\n        elif exception:\n            self.error = EventHubError(str(exception))\n        else:\n            self.error = EventHubError(\"This send handler is now closed.\")\n        await self._handler.close_async()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until all transferred events have been sent.", "response": "async def wait_async(self):\n        \"\"\"\n        Wait until all transferred events have been sent.\n        \"\"\"\n        if self.error:\n            raise self.error\n        if not self.running:\n            raise ValueError(\"Unable to send until client has been started.\")\n        try:\n            await self._handler.wait_async()\n        except (errors.TokenExpired, errors.AuthenticationException):\n            log.info(\"AsyncSender disconnected due to token error. Attempting reconnect.\")\n            await self.reconnect_async()\n        except (errors.LinkDetach, errors.ConnectionClose) as shutdown:\n            if shutdown.action.retry and self.auto_reconnect:\n                log.info(\"AsyncSender detached. Attempting reconnect.\")\n                await self.reconnect_async()\n            else:\n                log.info(\"AsyncSender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                await self.close_async(exception=error)\n                raise error\n        except errors.MessageHandlerError as shutdown:\n            if self.auto_reconnect:\n                log.info(\"AsyncSender detached. Attempting reconnect.\")\n                await self.reconnect_async()\n            else:\n                log.info(\"AsyncSender detached. Shutting down.\")\n                error = EventHubError(str(shutdown), shutdown)\n                await self.close_async(exception=error)\n                raise error\n        except Exception as e:\n            log.info(\"Unexpected error occurred (%r).\", e)\n            raise EventHubError(\"Send failed: {}\".format(e))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def start(self):\n        try:\n            self.reader, self.writer = await asyncio.open_connection(\n                self.ip_address, self.port, loop=self.loop)\n        except OSError:\n            print(\"Can't open connection to \" + self.ip_address)\n            sys.exit(0)", "response": "This method opens an IP connection on the IP device and opens an IP connection on the IP device."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef loop():\n    print(\"Straight\")\n    board.digital_write(L_CTRL_1, 1)\n    board.digital_write(L_CTRL_2, 0)\n    board.analog_write(PWM_L, 245)\n    board.digital_write(R_CTRL_1, 1)\n    board.digital_write(R_CTRL_2, 0)\n    board.analog_write(PWM_R, 245)\n    board.sleep(2.0)\n\n    print(\"CW spin\")\n    board.digital_write(L_CTRL_1, 1)\n    board.digital_write(L_CTRL_2, 0)\n    board.analog_write(PWM_L, 245)\n    board.digital_write(R_CTRL_1, 0)\n    board.digital_write(R_CTRL_2, 1)\n    board.analog_write(PWM_R, 245)\n    board.sleep(2.0)\n\n    print(\"CCW spin\")\n    board.digital_write(L_CTRL_1, 0)\n    board.digital_write(L_CTRL_2, 1)\n    board.analog_write(PWM_L, 245)\n    board.digital_write(R_CTRL_1, 1)\n    board.digital_write(R_CTRL_2, 0)\n    board.analog_write(PWM_R, 245)\n    board.sleep(2.0)\n\n    print(\"Stop\")\n    board.digital_write(L_CTRL_1, 1)\n    board.digital_write(L_CTRL_2, 0)\n    board.analog_write(PWM_L, 0)\n    board.digital_write(R_CTRL_1, 1)\n    board.digital_write(R_CTRL_2, 0)\n    board.analog_write(PWM_R, 0)\n    board.sleep(5.0)", "response": "Function that gets called once as soon as it finishes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nretrieving the last data update for the specified digital pin. It is intended for a polling application. :param pin: Digital pin number :returns: Last value reported for the digital pin", "response": "def digital_read(self, pin):\n        \"\"\"\n        Retrieve the last data update for the specified digital pin.\n        It is intended for a polling application.\n\n        :param pin: Digital pin number\n\n        :returns: Last value reported for the digital pin\n        \"\"\"\n        task = asyncio.ensure_future(self.core.digital_read(pin))\n        value = self.loop.run_until_complete(task)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encoder_config(self, pin_a, pin_b, cb=None, cb_type=None,\n                       hall_encoder=False):\n        \"\"\"\n        This command enables the rotary encoder (2 pin + ground) and will\n        enable encoder reporting.\n\n        This is a FirmataPlus feature.\n\n        Encoder data is retrieved by performing a digital_read from\n        pin a (encoder pin 1)\n\n        :param pin_a: Encoder pin 1.\n\n        :param pin_b: Encoder pin 2.\n\n        :param cb: callback function to report encoder changes\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call\n                        or Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :param hall_encoder: wheel hall_encoder - set to True to select\n                             hall encoder support support.\n\n        :returns: No return value\n        \"\"\"\n        task = asyncio.ensure_future(self.core.encoder_config(pin_a, pin_b,\n                                                              cb, cb_type,\n                                                              hall_encoder))\n        self.loop.run_until_complete(task)", "response": "This command enables the rotary encoder reporting and reporting."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable_digital_reporting(self, pin):\n        task = asyncio.ensure_future(self.core.enable_digital_reporting(pin))\n        self.loop.run_until_complete(task)", "response": "Enables digital reporting on for all the available modules."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef extended_analog(self, pin, data):\n        task = asyncio.ensure_future(self.core.extended_analog(pin, data))\n        self.loop.run_until_complete(task)", "response": "This method sends an extended - data analog write command to the selected pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_analog_map(self, cb=None):\n        task = asyncio.ensure_future(self.core.get_analog_map())\n        report = self.loop.run_until_complete(task)\n        if cb:\n            cb(report)\n        else:\n            return report", "response": "This method requests and returns an analog map."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef i2c_config(self, read_delay_time=0):\n        task = asyncio.ensure_future(self.core.i2c_config(read_delay_time))\n        self.loop.run_until_complete(task)", "response": "This method configures Arduino i2c with an optional read delay time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the last data read from i2c device.", "response": "def i2c_read_data(self, address):\n        \"\"\"\n        Retrieve result of last data read from i2c device.\n        i2c_read_request should be called before trying to retrieve data.\n        It is intended for use by a polling application.\n\n        :param address: i2c\n\n        :returns: last data read or None if no data is present.\n        \"\"\"\n        task = asyncio.ensure_future(self.core.i2c_read_data(address))\n        value = self.loop.run_until_complete(task)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef i2c_read_request(self, address, register, number_of_bytes, read_type,\n                         cb=None, cb_type=None):\n        \"\"\"\n        This method issues an i2c read request for a single read,continuous\n        read or a stop, specified by the read_type.\n        Because different i2c devices return data at different rates,\n        if a callback is not specified, the user must first call this method\n        and then call i2c_read_data  after waiting for sufficient time for the\n        i2c device to respond.\n        Some devices require that transmission be restarted\n        (e.g. MMA8452Q accelerometer).\n        Use I2C_READ | I2C_RESTART_TX for those cases.\n\n        :param address: i2c device\n\n        :param register: i2c register number\n\n        :param number_of_bytes: number of bytes to be returned\n\n        :param read_type:  Constants.I2C_READ, Constants.I2C_READ_CONTINUOUSLY\n                           or Constants.I2C_STOP_READING.\n\n        Constants.I2C_RESTART_TX may be OR'ed when required\n        :param cb: optional callback reference\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :returns: No return value\n        \"\"\"\n\n        task = asyncio.ensure_future(self.core.i2c_read_request(address, register,\n                                                                number_of_bytes,\n                                                                read_type,\n                                                                cb,\n                                                                cb_type))\n        self.loop.run_until_complete(task)", "response": "This method issues an i2c read request for a specific set of values."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite data to an i2c device. :param address: i2c device address :param args: A variable number of bytes to be sent to the device passed in as a list. :returns: No return value", "response": "def i2c_write_request(self, address, args):\n        \"\"\"\n        Write data to an i2c device.\n\n        :param address: i2c device address\n\n        :param args: A variable number of bytes to be sent to the device\n                     passed in as a list.\n\n        :returns: No return value\n        \"\"\"\n        task = asyncio.ensure_future(self.core.i2c_write_request(address, args))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef keep_alive(self, period=1, margin=.3):\n        asyncio.ensure_future(self.core.keep_alive(period, margin))", "response": "Send a keep alive message to Arduino."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef play_tone(self, pin, tone_command, frequency, duration=None):\n        task = asyncio.ensure_future(self.core.play_tone(pin, tone_command,\n                                                         frequency, duration))\n        self.loop.run_until_complete(task)", "response": "This method will call the Tone library for the selected pin and play the specified tone command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef send_reset(self):\n        task = asyncio.ensure_future(self.core.send_reset())\n        self.loop.run_until_complete(task)", "response": "Send a reset command to get the current set of Firmata entries"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef servo_config(self, pin, min_pulse=544, max_pulse=2400):\n        task = asyncio.ensure_future(self.core.servo_config(pin, min_pulse,\n                                                            max_pulse))\n        self.loop.run_until_complete(task)", "response": "This method configures the Arduino for servo operation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_analog_latch(self, pin, threshold_type, threshold_value,\n                         cb=None, cb_type=None):\n        \"\"\"\n        This method \"arms\" an analog pin for its data to be latched and\n        saved in the latching table.\n        If a callback method is provided, when latching criteria is achieved,\n        the callback function is called with latching data notification.\n\n        :param pin: Analog pin number (value following an 'A' designator,\n                    i.e. A5 = 5\n\n        :param threshold_type: Constants.LATCH_GT | Constants.LATCH_LT  |\n                               Constants.LATCH_GTE | Constants.LATCH_LTE\n\n        :param threshold_value: numerical value - between 0 and 1023\n\n        :param cb: callback method\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :returns: True if successful, False if parameter data is invalid\n        \"\"\"\n\n        task = asyncio.ensure_future(self.core.set_analog_latch(pin, threshold_type, threshold_value, cb, cb_type))\n        result = self.loop.run_until_complete(task)\n        return result", "response": "This method is used to set an analog pin for its data to be latched and latched in the latching table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_pin_mode(self, pin_number, pin_state, callback=None, cb_type=None):\n        task = asyncio.ensure_future(self.core.set_pin_mode(pin_number, pin_state, callback, cb_type))\n        self.loop.run_until_complete(task)", "response": "This method sets the pin mode for the specified Arduino Pin."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming an asyncio sleep for the time specified in seconds. T his method should be used in place of time.sleep() :param time: time in seconds :returns: No return value", "response": "def sleep(self, time):\n        \"\"\"\n        Perform an asyncio sleep for the time specified in seconds. T\n        his method should be used in place of time.sleep()\n\n        :param time: time in seconds\n        :returns: No return value\n        \"\"\"\n        try:\n            task = asyncio.ensure_future(self.core.sleep(time))\n            self.loop.run_until_complete(task)\n\n        except asyncio.CancelledError:\n            pass\n        except RuntimeError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shutdown(self):\n        task = asyncio.ensure_future(self.core.shutdown())\n        self.loop.run_until_complete(task)", "response": "Shutdown the application and exit the application and return the value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nretrieving Ping ( HC - SR04 type data.", "response": "def sonar_data_retrieve(self, trigger_pin):\n        \"\"\"\n        Retrieve Ping (HC-SR04 type) data. The data is presented as a\n        dictionary.\n        The 'key' is the trigger pin specified in sonar_config() and the\n        'data' is the current measured distance (in centimeters)\n        for that pin. If there is no data, the value is set to None.\n        This is a FirmataPlus feature.\n\n        :param trigger_pin: trigger pin specified in sonar_config\n\n        :returns: active_sonar_map\n        \"\"\"\n        task = asyncio.ensure_future(self.core.sonar_data_retrieve(trigger_pin))\n        sonar_data = self.loop.run_until_complete(task)\n        return sonar_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sonar_config(self, trigger_pin, echo_pin, cb=None, ping_interval=50,\n                     max_distance=200, cb_type=None):\n        \"\"\"\n        Configure the pins,ping interval and maximum distance for an HC-SR04\n        type device.\n        Single pin configuration may be used. To do so, set both the trigger\n        and echo pins to the same value.\n        Up to a maximum of 6 SONAR devices is supported\n        If the maximum is exceeded a message is sent to the console and the\n        request is ignored.\n        NOTE: data is measured in centimeters\n\n        This is FirmataPlus feature.\n\n        :param trigger_pin: The pin number of for the trigger (transmitter).\n\n        :param echo_pin: The pin number for the received echo.\n\n        :param cb: optional callback function to report sonar data changes\n\n        :param ping_interval: Minimum interval between pings. Lowest number\n                              to use is 33 ms.Max is 127\n\n        :param max_distance: Maximum distance in cm. Max is 200.\n\n        :param cb_type: direct call or asyncio yield from\n\n        :returns: No return value\n        \"\"\"\n        task = asyncio.ensure_future(self.core.sonar_config(trigger_pin,\n                                                            echo_pin, cb,\n                                                            ping_interval,\n                                                            max_distance, cb_type))\n        self.loop.run_until_complete(task)", "response": "Configure the pins ping_interval and max_distance for an HC - SR04 - type device."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures stepper motor prior to operation.", "response": "def stepper_config(self, steps_per_revolution, stepper_pins):\n        \"\"\"\n        Configure stepper motor prior to operation.\n        This is a FirmataPlus feature.\n\n        :param steps_per_revolution: number of steps per motor revolution\n\n        :param stepper_pins: a list of control pin numbers - either 4 or 2\n\n        :returns: No return value\n\n        \"\"\"\n        task = asyncio.ensure_future(self.core.stepper_config(steps_per_revolution,\n                                                              stepper_pins))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef stepper_step(self, motor_speed, number_of_steps):\n        task = asyncio.ensure_future(self.core.stepper_step(motor_speed,\n                                                            number_of_steps))\n        self.loop.run_until_complete(task)", "response": "Move a stepper motor for the specified number of steps at the specified speed"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes Pixy and enable Pixy block reporting.", "response": "def pixy_init(self, max_blocks=5, cb=None, cb_type=None):\n        \"\"\"\n        Initialize Pixy and will enable Pixy block reporting.\n        This is a FirmataPlusRB feature.\n\n        :param cb: callback function to report Pixy blocks\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :param max_blocks: Maximum number of Pixy blocks to report when many\n                           signatures are found.\n\n        :returns: No return value.\n        \"\"\"\n        task = asyncio.ensure_future(self.core.pixy_init(max_blocks, cb, cb_type))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsending the setServos Pixy command. This method sets the pan/tilt servos that are plugged into Pixy's two servo ports. :param s0: value 0 to 1000 :param s1: value 0 to 1000 :returns: No return value.", "response": "def pixy_set_servos(self, s0, s1):\n        \"\"\"\n        Sends the setServos Pixy command.\n        This method sets the pan/tilt servos that are plugged into Pixy's two servo ports.\n\n        :param s0: value 0 to 1000\n\n        :param s1: value 0 to 1000\n\n        :returns: No return value.\n        \"\"\"\n        task = asyncio.ensure_future(self.core.pixy_set_servos(s0, s1))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending the setBrightness Pixy command. This method sets the brightness (exposure) of Pixy's camera. :param brightness: range between 0 and 255 with 255 being the brightest setting :returns: No return value.", "response": "def pixy_set_brightness(self, brightness):\n        \"\"\"\n        Sends the setBrightness Pixy command.\n        This method sets the brightness (exposure) of Pixy's camera.\n\n        :param brightness: range between 0 and 255 with 255 being the\n                           brightest setting\n\n        :returns: No return value.\n        \"\"\"\n        task = asyncio.ensure_future(self.core.pixy_set_brightness(brightness))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends the setLed Pixy command. This method sets the RGB LED on front of Pixy. :param r: red range between 0 and 255 :param g: green range between 0 and 255 :param b: blue range between 0 and 255 :returns: No return value.", "response": "def pixy_set_led(self, r, g, b):\n        \"\"\"\n        Sends the setLed Pixy command.\n        This method sets the RGB LED on front of Pixy.\n\n        :param r: red range between 0 and 255\n\n        :param g: green range between 0 and 255\n\n        :param b: blue range between 0 and 255\n\n        :returns: No return value.\n        \"\"\"\n        task = asyncio.ensure_future(self.core.pixy_set_led(r, g, b))\n        self.loop.run_until_complete(task)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nupdating the Pixy data structure.", "response": "def pixy_value_update(current_pan_angle_deg, prev_pan_move_deg, blocks):\n    \"\"\" Prints the Pixy blocks data.\"\"\"\n    if len(blocks) > 0:\n        pan_error = X_CENTER - blocks[0][\"x\"]\n        if math.fabs(pan_error) < 20.0:\n            print(\"Close enough.\")\n            return current_pan_angle_deg, 0\n        pan_move_deg = 1 if pan_error > 0 else -1\n        if prev_pan_move_deg > 0 and pan_move_deg > 0:\n            pan_move_deg = 3\n        if prev_pan_move_deg < 0 and pan_move_deg < 0:\n            pan_move_deg = -3\n        current_pan_angle_deg += pan_move_deg\n        if current_pan_angle_deg > 150:\n            current_pan_angle_deg = 150\n        if current_pan_angle_deg < 20:\n            current_pan_angle_deg = 20\n        print(\"x: {}  pan_error: {}  pan_move_deg: {}  angle: {}\".format(blocks[0][\"x\"], pan_error, pan_move_deg, current_pan_angle_deg))\n        return current_pan_angle_deg, pan_move_deg\n    return current_pan_angle_deg, 0"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_pixy_blocks(blocks):\n    print(\"Detected \" + str(len(blocks)) + \" Pixy blocks:\")\n    if len(blocks) > 0 and not \"signature\" in blocks[0]:\n        print(\"Something went wrong.  This does not appear to be a printable block.\")\n        board.shutdown()\n        return\n    for block_index in range(len(blocks)):\n        block = blocks[block_index]\n        print(\"  block {}: sig: {}  x: {} y: {} width: {} height: {}\".format(\n                block_index, block[\"signature\"], block[\"x\"], block[\"y\"], block[\"width\"], block[\"height\"]))", "response": "Prints the Pixy blocks data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef standby(self):\n        register = self.MMA8452Q_Register['CTRL_REG1']\n        self.board.i2c_read_request(self.address, register, 1,\n                                    Constants.I2C_READ | Constants.I2C_END_TX_MASK,\n                                    self.data_val, Constants.CB_TYPE_DIRECT)\n\n\n        ctrl1 = self.wait_for_read_result()\n\n        ctrl1 = (ctrl1[self.data_start]) & ~0x01\n        self.callback_data = []\n\n        self.board.i2c_write_request(self.address, [register, ctrl1])", "response": "Put the device into standby mode so that the registers can be set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the device scale register. Device must be in standby before calling this function @param scale: scale factor @return: No return value", "response": "def set_scale(self, scale):\n        \"\"\"\n        Set the device scale register.\n        Device must be in standby before calling this function\n        @param scale: scale factor\n        @return: No return value\n        \"\"\"\n        register = self.MMA8452Q_Register['XYZ_DATA_CFG']\n        self.board.i2c_read_request(self.address, register, 1,\n                                    Constants.I2C_READ | Constants.I2C_END_TX_MASK,\n                                    self.data_val, Constants.CB_TYPE_DIRECT)\n\n\n        config_reg = self.wait_for_read_result()\n        config_reg = config_reg[self.data_start]\n        config_reg &= 0xFC  # Mask out scale bits\n        config_reg |= (scale >> 2)\n        self.board.i2c_write_request(self.address, [register, config_reg])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the device output data rate. Device must be in standby before calling this function @param output_data_rate: Desired data rate @return: No return value.", "response": "def set_output_data_rate(self, output_data_rate):\n        \"\"\"\n        Set the device output data rate.\n        Device must be in standby before calling this function\n        @param output_data_rate: Desired data rate\n        @return: No return value.\n        \"\"\"\n        # self.standby()\n        register = self.MMA8452Q_Register['CTRL_REG1']\n        self.board.i2c_read_request(self.address, register, 1,\n                                    Constants.I2C_READ | Constants.I2C_END_TX_MASK,\n                                    self.data_val, Constants.CB_TYPE_DIRECT)\n\n\n        control_reg = self.wait_for_read_result()\n        control_reg = control_reg[self.data_start]\n\n        control_reg &= 0xC7  # Mask out data rate bits\n        control_reg |= (output_data_rate << 3)\n        self.board.i2c_write_request(self.address, [register, control_reg])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef read(self, callback=None):\n        register = self.MMA8452Q_Register['OUT_X_MSB']\n        self.board.i2c_read_request(self.address, register, 6,\n                                    Constants.I2C_READ | Constants.I2C_END_TX_MASK,\n                                    self.data_val, Constants.CB_TYPE_DIRECT)\n\n\n        # get x y z data\n        xyz = self.wait_for_read_result()\n        self.board.sleep(.001)  # string off address and register bytes\n        xyz = xyz[2:]\n\n        xmsb = xyz[0]\n        xlsb = xyz[1]\n        ymsb = xyz[2]\n        ylsb = xyz[3]\n        zmsb = xyz[4]\n        zlsb = xyz[5]\n\n        xa = int((xmsb << 8) | xlsb) >> 4\n\n        if xmsb > 127:\n            xa = 4095 - xa\n            xa = ~xa + 1\n\n        ya = int(((ymsb << 8) | ylsb)) >> 4\n\n        if ymsb > 127:\n            ya = 4095 - ya\n            ya = ~ya + 1\n\n        za = int((zmsb << 8) | zlsb) >> 4\n\n        if zmsb > 127:\n            za = 4095 - za\n            za = ~za + 1\n\n        cx = xa / 2048 * self.scale\n        cy = ya / 2048 * self.scale\n        cz = za / 2048 * self.scale\n\n        angle_xz = 180 * math.atan2(xa, za) / math.pi\n        angle_xy = 180 * math.atan2(xa, ya) / math.pi\n        angle_yz = 180 * math.atan2(ya, za) / math.pi\n\n        if callback:\n            callback([xa, ya, za, cx, cy, cz, angle_xz, angle_yz, angle_xy])\n        self.board.sleep(.001)\n\n        return [xa, ya, za, cx, cy, cz, angle_xz, angle_yz, angle_xy]", "response": "Read the current state of the current entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_for_read_result(self):\n        while not self.callback_data:\n            self.board.sleep(.001)\n        rval = self.callback_data\n        self.callback_data = []\n        return rval", "response": "This is a utility function to wait for return data call back\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef left_motor(self, speed, durationS=-1.0):\n        if speed > 0:\n            self.left_rev(min(abs(speed), 255))\n        else:\n            self.left_fwd(min(abs(speed), 255))\n        if durationS > 0:\n            self.board.sleep(durationS)\n            self.left_stop()", "response": "Basically the same as drive but omitting the right motor."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nallows left motor to coast to a stop", "response": "def left_brake(self):\n        \"\"\"allows left motor to coast to a stop\"\"\"\n        self.board.digital_write(L_CTRL_1, 1)\n        self.board.digital_write(L_CTRL_2, 1)\n        self.board.analog_write(PWM_L, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef right_brake(self):\n        self.board.digital_write(R_CTRL_1, 1)\n        self.board.digital_write(R_CTRL_2, 1)\n        self.board.analog_write(PWM_R, 0)", "response": "allows left motor to coast to a stop"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing left motor to coast to a stop", "response": "def left_stop(self):\n        \"\"\"allows left motor to coast to a stop\"\"\"\n        self.board.digital_write(L_CTRL_1, 0)\n        self.board.digital_write(L_CTRL_2, 0)\n        self.board.analog_write(PWM_L, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nallowing left motor to coast to a stop", "response": "def right_stop(self):\n        \"\"\"allows left motor to coast to a stop\"\"\"\n        self.board.digital_write(R_CTRL_1, 0)\n        self.board.digital_write(R_CTRL_2, 0)\n        self.board.analog_write(PWM_R, 0)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pivot(self, speed, durationS=-1.0):\n        if speed < 0:\n            self.left_fwd(min(abs(speed), 255))\n            self.right_rev(min(abs(speed), 255))\n        else:\n            self.left_rev(min(abs(speed), 255))\n            self.right_fwd(min(abs(speed), 255))\n        if durationS > 0:\n            self.board.sleep(durationS)\n            self.left_stop()\n            self.right_stop()", "response": "Pivot the redBot to the specified speed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def read_portrait_landscape(self, callback=None):\n        register = self.MMA8452Q_Register['PL_STATUS']\n        await self.board.i2c_read_request(self.address, register, 1,\n                                               Constants.I2C_READ | Constants.I2C_END_TX_MASK,\n                                               self.data_val, Constants.CB_TYPE_ASYNCIO)\n\n        pl_status = await self.wait_for_read_result()\n        pl_status = pl_status[self.data_start]\n        if pl_status & 0x40:  # Z-tilt lockout\n            pl_status = self.LOCKOUT\n        else:  # Otherwise return LAPO status\n            pl_status = (pl_status & 0x6) >> 1\n\n        if callback:\n            await callback(pl_status)\n        await asyncio.sleep(.001)\n\n        return pl_status", "response": "This function reads the portrait or landscape status register of the MMA8452Q and returns either PORTRAIT_U PORTRAIT_D LANDSCAPE_R LANDSCAPE_L or LAPO status."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def wait_for_read_result(self):\n        while not self.callback_data:\n            await asyncio.sleep(.001)\n        rval = self.callback_data\n        self.callback_data = []\n        return rval", "response": "This is a utility function to wait for return data call back\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nprints the Pixy blocks data.", "response": "def pixy_value_update(blocks):\n    \"\"\" Prints the Pixy blocks data.\"\"\"\n    if len(blocks) > 0:\n        pan_error = X_CENTER - blocks[0][\"x\"]\n        tilt_error = blocks[0][\"y\"] - Y_CENTER\n        pan_loop.update(pan_error)\n        tilt_loop.update(tilt_error)\n\n        loop = asyncio.get_event_loop()\n        if loop.is_running():\n            # This is the version that will be used since we are in a callback, but I wanted to show how to\n            # properly protect against calls to board.something when you don't know if you are in the non-async\n            # land vs when you are currently executing code from within async land.\n            asyncio.ensure_future(board.core.analog_write(PIN_PAN_SERVO, int(pan_loop.position * 180 / 1000)))\n            asyncio.ensure_future(board.core.analog_write(PIN_TILT_SERVO, int(tilt_loop.position * 180 / 1000)))\n        else:\n            board.analog_write(PIN_PAN_SERVO, int(pan_loop.position * 180 / 1000))\n            board.analog_write(PIN_TILT_SERVO, int(tilt_loop.position * 180 / 1000))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def pin_6_pwm_128(my_board):\n    # set the pin mode\n    await my_board.set_pin_mode(6, Constants.PWM)\n\n    # set the pin to 128\n    await my_board.analog_write(6, 128)\n\n    # let the led stay lit for 3 seconds\n    await asyncio.sleep(3)\n\n    # shutdown\n    await my_board.shutdown()", "response": "This function is used to set the digital pin 6 as a PWM output and set its output value to 128."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nblinks LED 13 @return: No Return Value", "response": "async def blink(my_board):\n    \"\"\"\n    Blink LED 13\n    @return: No Return Value\n    \"\"\"\n    # set the pin mode\n    await my_board.set_pin_mode(13, Constants.OUTPUT)\n\n    for i in range(0, 5):\n        await my_board.digital_write(13, 1)\n        await asyncio.sleep(1)\n        await my_board.digital_write(13, 0)\n        await asyncio.sleep(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nturns RedBot to the Right", "response": "def turn_right():\n    \"\"\"turns RedBot to the Right\"\"\"\n    motors.left_motor(-150)  # spin CCW\n    motors.right_motor(-150)  # spin CCW\n    board.sleep(0.5)\n    motors.brake();\n    board.sleep(0.1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef turn_left():\n    motors.left_motor(150)  # spin CCW\n    motors.right_motor(150)  # spin CCW\n    board.sleep(0.5)\n    motors.brake();\n    board.sleep(0.1)", "response": "turns RedBot to the Left"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef start(self):\n\n        # check if user specified a socket transport\n        if self.ip_address:\n            self.socket = PymataSocket(self.ip_address, self.ip_port, self.loop)\n            self.loop.run_until_complete((self.socket.start()))\n            # set the read and write handles\n            self.read = self.socket.read\n            self.write = self.socket.write\n            for i in range(0, len(self.ip_handshake)):\n                self.loop.run_until_complete((self.read()))\n        else:\n            try:\n                self.serial_port = PymataSerial(self.com_port, 57600,\n                                                self.sleep_tune,\n                                                self.log_output)\n                # set the read and write handles\n                self.read = self.serial_port.read\n                self.write = self.serial_port.write\n            except serial.SerialException:\n                if self.log_output:\n                    log_string = 'Cannot instantiate serial interface: ' \\\n                                 + self.com_port\n                    logging.exception(log_string)\n                else:\n                    print(\n                        'Cannot instantiate serial interface: ' + self.com_port)\n                    print('To see a list of serial ports, type: \"list_serial_ports\" in your console.')\n                sys.exit(0)\n\n        # wait for arduino to go through a reset cycle if need be\n        time.sleep(self.arduino_wait)\n\n        # register the get_command method with the event loop\n        # self.loop = asyncio.get_event_loop()\n        self.the_task = self.loop.create_task(self._command_dispatcher())\n\n        # get arduino firmware version and print it\n        try:\n            firmware_version = self.loop.run_until_complete(self.get_firmware_version())\n            if self.log_output:\n                log_string = \"\\nArduino Firmware ID: \" + firmware_version\n                logging.exception(log_string)\n            else:\n                print(\"\\nArduino Firmware ID: \" + firmware_version)\n        except TypeError:\n            print('\\nIs your serial cable plugged in and do you have the correct Firmata sketch loaded?')\n            print('Is the COM port correct?')\n            print('To see a list of serial ports, type: \"list_serial_ports\" in your console.')\n            sys.exit(0)\n\n        # try to get an analog pin map. if it comes back as none - shutdown\n        report = self.loop.run_until_complete(self.get_analog_map())\n        if not report:\n            if self.log_output:\n                log_string = '*** Analog map retrieval timed out. ***'\n\n                logging.exception(log_string)\n                log_string = '\\nDo you have Arduino connectivity and do you ' \\\n                             'have a Firmata sketch uploaded to the board?'\n                logging.exception(log_string)\n\n            else:\n                print('*** Analog map retrieval timed out. ***')\n                print('\\nDo you have Arduino connectivity and do you have a '\n                      'Firmata sketch uploaded to the board?')\n            try:\n                loop = self.loop\n                for t in asyncio.Task.all_tasks(loop):\n                    t.cancel()\n                loop.run_until_complete(asyncio.sleep(.1))\n                loop.close()\n                loop.stop()\n                sys.exit(0)\n            except RuntimeError:\n                # this suppresses the Event Loop Is Running message, which may\n                # be a bug in python 3\n                sys.exit(0)\n            except TypeError:\n                sys.exit(0)\n\n        # custom assemble the pin lists\n        for pin in report:\n            digital_data = PinData()\n            self.digital_pins.append(digital_data)\n            if pin != Constants.IGNORE:\n                analog_data = PinData()\n                self.analog_pins.append(analog_data)\n\n        if self.log_output:\n            log_string = 'Auto-discovery complete. Found ' + \\\n                         str(len(self.digital_pins)) + ' Digital Pins and ' + \\\n                         str(len(self.analog_pins)) + ' Analog Pins'\n            logging.info(log_string)\n        else:\n            print('{} {} {} {} {}'.format('Auto-discovery complete. Found',\n                                          len(self.digital_pins),\n                                          'Digital Pins and',\n                                          len(self.analog_pins),\n                                          'Analog Pins\\n\\n'))\n        self.first_analog_pin = len(self.digital_pins) - len(self.analog_pins)", "response": "This method instantiates the serial interface and then instantiates the command loop and registers the task with the event loop."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def analog_write(self, pin, value):\n        if PrivateConstants.ANALOG_MESSAGE + pin < 0xf0:\n            command = [PrivateConstants.ANALOG_MESSAGE + pin, value & 0x7f,\n                       (value >> 7) & 0x7f]\n            await self._send_command(command)\n        else:\n            await self.extended_analog(pin, value)", "response": "This method writes an analog message to the specified pin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def digital_pin_write(self, pin, value):\n\n        command = (PrivateConstants.SET_DIGITAL_PIN_VALUE, pin, value)\n\n        await self._send_command(command)", "response": "This method is used to write the specified value to the specified pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def digital_write(self, pin, value):\n        # The command value is not a fixed value, but needs to be calculated\n        # using the pin's port number\n        port = pin // 8\n\n        calculated_command = PrivateConstants.DIGITAL_MESSAGE + port\n        mask = 1 << (pin % 8)\n        # Calculate the value for the pin's position in the port mask\n        if value == 1:\n            PrivateConstants.DIGITAL_OUTPUT_PORT_PINS[port] |= mask\n        else:\n            PrivateConstants.DIGITAL_OUTPUT_PORT_PINS[port] &= ~mask\n\n        # Assemble the command\n        command = (calculated_command,\n                   PrivateConstants.DIGITAL_OUTPUT_PORT_PINS[port] & 0x7f,\n                   (PrivateConstants.DIGITAL_OUTPUT_PORT_PINS[port] >> 7) & 0x7f)\n\n        await self._send_command(command)", "response": "This method writes the value to the specified pin."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndisable analog reporting for a single analog pin.", "response": "async def disable_analog_reporting(self, pin):\n        \"\"\"\n        Disables analog reporting for a single analog pin.\n\n        :param pin: Analog pin number. For example for A0, the number is 0.\n\n        :returns: No return value\n        \"\"\"\n        command = [PrivateConstants.REPORT_ANALOG + pin,\n                   PrivateConstants.REPORTING_DISABLE]\n        await self._send_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisabling digital reporting for the specified pin.", "response": "async def disable_digital_reporting(self, pin):\n        \"\"\"\n        Disables digital reporting. By turning reporting off for this pin,\n        Reporting is disabled for all 8 bits in the \"port\"\n\n        :param pin: Pin and all pins for this port\n\n        :returns: No return value\n        \"\"\"\n        port = pin // 8\n        command = [PrivateConstants.REPORT_DIGITAL + port,\n                   PrivateConstants.REPORTING_DISABLE]\n        await self._send_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nenables reporting for an analog pin.", "response": "async def enable_analog_reporting(self, pin):\n        \"\"\"\n        Enables analog reporting. By turning reporting on for a single pin,\n\n        :param pin: Analog pin number. For example for A0, the number is 0.\n\n        :returns: No return value\n        \"\"\"\n        command = [PrivateConstants.REPORT_ANALOG + pin,\n                   PrivateConstants.REPORTING_ENABLE]\n        await self._send_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nenables digital reporting on for all 8 bits in the port.", "response": "async def enable_digital_reporting(self, pin):\n        \"\"\"\n        Enables digital reporting. By turning reporting on for all 8 bits\n        in the \"port\" - this is part of Firmata's protocol specification.\n\n        :param pin: Pin and all pins for this port\n\n        :returns: No return value\n            \"\"\"\n        port = pin // 8\n        command = [PrivateConstants.REPORT_DIGITAL + port,\n                   PrivateConstants.REPORTING_ENABLE]\n        await self._send_command(command)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def get_analog_latch_data(self, pin):\n        key = 'A' + str(pin)\n        if key in self.latch_map:\n            entry = self.latch_map.get(key)\n            return entry\n        else:\n            return None", "response": "Get the latched state threshold value threshold value and time stamp for the specified pin."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_analog_map(self):\n        # get the current time to make sure a report is retrieved\n        current_time = time.time()\n\n        # if we do not have existing report results, send a Firmata\n        # message to request one\n        if self.query_reply_data.get(\n                PrivateConstants.ANALOG_MAPPING_RESPONSE) is None:\n            await self._send_sysex(PrivateConstants.ANALOG_MAPPING_QUERY)\n            # wait for the report results to return for 2 seconds\n            # if the timer expires, shutdown\n            while self.query_reply_data.get(\n                    PrivateConstants.ANALOG_MAPPING_RESPONSE) is None:\n                elapsed_time = time.time()\n                if elapsed_time - current_time > 4:\n                    return None\n                await asyncio.sleep(self.sleep_tune)\n        return self.query_reply_data.get(\n            PrivateConstants.ANALOG_MAPPING_RESPONSE)", "response": "This method requests a Firmata analog map query and returns the results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget digital latch data for a given pin.", "response": "async def get_digital_latch_data(self, pin):\n        \"\"\"\n        A list is returned containing the latch state for the pin, the\n        latched value, and the time stamp\n        [pin_num, latch_state, latched_value, time_stamp]\n\n        :param pin: Pin number.\n\n        :returns:  [latched_state, threshold_type, threshold_value,\n                   latched_data, time_stamp]\n        \"\"\"\n        key = 'D' + str(pin)\n        if key in self.latch_map:\n            entry = self.latch_map.get(key)\n            return entry\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nnote THIS METHOD MUST BE CALLED BEFORE ANY I2C REQUEST IS MADE This method initializes Firmata for I2c operations. :param read_delay_time (in microseconds): an optional parameter, default is 0 :returns: No Return Value", "response": "async def i2c_config(self, read_delay_time=0):\n        \"\"\"\n        NOTE: THIS METHOD MUST BE CALLED BEFORE ANY I2C REQUEST IS MADE\n        This method initializes Firmata for I2c operations.\n\n        :param read_delay_time (in microseconds): an optional parameter,\n                                                  default is 0\n\n        :returns: No Return Value\n        \"\"\"\n        data = [read_delay_time & 0x7f, (read_delay_time >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.I2C_CONFIG, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def i2c_read_request(self, address, register, number_of_bytes,\n                               read_type, cb=None, cb_type=None):\n        \"\"\"\n        This method requests the read of an i2c device. Results are retrieved\n        by a call to i2c_get_read_data(). or by callback.\n\n        If a callback method is provided, when data is received from the\n        device it will be sent to the callback method.\n        Some devices require that transmission be restarted\n        (e.g. MMA8452Q accelerometer).\n        Use Constants.I2C_READ | Constants.I2C_END_TX_MASK for those cases.\n\n        :param address: i2c device address\n\n        :param register: register number (can be set to zero)\n\n        :param number_of_bytes: number of bytes expected to be returned\n\n        :param read_type: I2C_READ  or I2C_READ_CONTINUOUSLY. I2C_END_TX_MASK\n                          may be OR'ed when required\n\n        :param cb: Optional callback function to report i2c data as a\n                   result of read command\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :returns: No return value.\n        \"\"\"\n        if address not in self.i2c_map:\n            # self.i2c_map[address] = [None, cb]\n            self.i2c_map[address] = {'value': None, 'callback': cb,\n                                     'callback_type': cb_type}\n        data = [address, read_type, register & 0x7f, (register >> 7) & 0x7f,\n                number_of_bytes & 0x7f, (number_of_bytes >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.I2C_REQUEST, data)", "response": "This method requests the read of an i2c device."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def i2c_write_request(self, address, args):\n        data = [address, Constants.I2C_WRITE]\n        for item in args:\n            item_lsb = item & 0x7f\n            data.append(item_lsb)\n            item_msb = (item >> 7) & 0x7f\n            data.append(item_msb)\n        await self._send_sysex(PrivateConstants.I2C_REQUEST, data)", "response": "This function sends a write request to an i2c device."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a keep alive message to the Arduino.", "response": "async def keep_alive(self, period=1, margin=.3):\n        \"\"\"\n        Periodically send a keep alive message to the Arduino.\n        Frequency of keep alive transmission is calculated as follows:\n        keep_alive_sent = period - (period * margin)\n\n\n        :param period: Time period between keepalives. Range is 0-10 seconds.\n                       0 disables the keepalive mechanism.\n\n        :param margin: Safety margin to assure keepalives are sent before\n                    period expires. Range is 0.1 to 0.9\n        :returns: No return value\n        \"\"\"\n        if period < 0:\n            period = 0\n        if period > 10:\n            period = 10\n        self.period = period\n        if margin < .1:\n            margin = .1\n        if margin > .9:\n            margin = .9\n        self.margin = margin\n        self.keep_alive_interval = [period & 0x7f, (period >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.SAMPLING_INTERVAL,\n                               self.keep_alive_interval)\n        while True:\n            if self.period:\n                await asyncio.sleep(period - (period - (period * margin)))\n                await self._send_sysex(PrivateConstants.KEEP_ALIVE,\n                                       self.keep_alive_interval)\n            else:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def play_tone(self, pin, tone_command, frequency, duration):\n        # convert the integer values to bytes\n        if tone_command == Constants.TONE_TONE:\n            # duration is specified\n            if duration:\n                data = [tone_command, pin, frequency & 0x7f, (frequency >> 7) & 0x7f,\n                        duration & 0x7f, (duration >> 7) & 0x7f]\n\n            else:\n                data = [tone_command, pin,\n                        frequency & 0x7f, (frequency >> 7) & 0x7f, 0, 0]\n        # turn off tone\n        else:\n            data = [tone_command, pin]\n        await self._send_sysex(PrivateConstants.TONE_DATA, data)", "response": "This method will call the Tone library for the selected pin and play the specified tone."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures a servo pin. Set pulse min max in ms.", "response": "async def servo_config(self, pin, min_pulse=544, max_pulse=2400):\n        \"\"\"\n        Configure a pin as a servo pin. Set pulse min, max in ms.\n        Use this method (not set_pin_mode) to configure a pin for servo\n        operation.\n\n        :param pin: Servo Pin.\n\n        :param min_pulse: Min pulse width in ms.\n\n        :param max_pulse: Max pulse width in ms.\n\n        :returns: No return value\n        \"\"\"\n        command = [pin, min_pulse & 0x7f, (min_pulse >> 7) & 0x7f, max_pulse & 0x7f,\n                   (max_pulse >> 7) & 0x7f]\n\n        await self._send_sysex(PrivateConstants.SERVO_CONFIG, command)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def set_analog_latch(self, pin, threshold_type, threshold_value,\n                               cb=None, cb_type=None):\n        \"\"\"\n        This method \"arms\" an analog pin for its data to be latched and saved\n        in the latching table\n        If a callback method is provided, when latching criteria is achieved,\n        the callback function is called with latching data notification.\n\n        Data returned in the callback list has the pin number as the\n        first element,\n\n        :param pin: Analog pin number\n                    (value following an 'A' designator, i.e. A5 = 5\n\n        :param threshold_type: ANALOG_LATCH_GT | ANALOG_LATCH_LT  |\n                               ANALOG_LATCH_GTE | ANALOG_LATCH_LTE\n\n        :param threshold_value: numerical value - between 0 and 1023\n\n        :param cb: callback method\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :returns: True if successful, False if parameter data is invalid\n        \"\"\"\n        if Constants.LATCH_GT <= threshold_type <= Constants.LATCH_LTE:\n            key = 'A' + str(pin)\n            if 0 <= threshold_value <= 1023:\n                self.latch_map[key] = [Constants.LATCH_ARMED, threshold_type,\n                                       threshold_value, 0, 0, cb, cb_type]\n                return True\n        else:\n            return False", "response": "This method is used to set an analog pin for its data to be latched and saved in latching table. This method is used to set the latching data for an analog pin."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def set_pin_mode(self, pin_number, pin_state, callback=None,\n                           callback_type=None):\n        \"\"\"\n        This method sets the pin mode for the specified pin.\n        For Servo, use servo_config() instead.\n\n        :param pin_number: Arduino Pin Number\n\n        :param pin_state: INPUT/OUTPUT/ANALOG/PWM/PULLUP - for SERVO use\n                          servo_config()\n\n        :param callback: Optional: A reference to a call back function to be\n                         called when pin data value changes\n\n        :param callback_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n\n        :returns: No return value\n        \"\"\"\n\n        # There is a potential start up race condition when running pymata3.\n        # This is a workaround for that race condition\n        #\n        if not len(self.digital_pins):\n            await asyncio.sleep(2)\n        if callback:\n            if pin_state == Constants.INPUT:\n                self.digital_pins[pin_number].cb = callback\n                self.digital_pins[pin_number].cb_type = callback_type\n            elif pin_state == Constants.ANALOG:\n                self.analog_pins[pin_number].cb = callback\n                self.analog_pins[pin_number].cb_type = callback_type\n            else:\n                if self.log_output:\n                    log_string = 'set_pin_mode: callback ignored for ' \\\n                                 'pin state: ' + pin_state\n                    logging.info(log_string)\n                else:\n                    print('{} {}'.format('set_pin_mode: callback ignored for '\n                                         'pin state:', pin_state))\n\n        pin_mode = pin_state\n\n        if pin_mode == Constants.ANALOG:\n            pin_number = pin_number + self.first_analog_pin\n\n        command = [PrivateConstants.SET_PIN_MODE, pin_number, pin_mode]\n        await self._send_command(command)\n        if pin_state == Constants.ANALOG:\n            await self.enable_analog_reporting(pin_number)\n        elif pin_state == Constants.INPUT:\n            await self.enable_digital_reporting(pin_number)\n        else:\n            pass\n\n        await self.sleep(.05)", "response": "This method sets the pin mode for the specified Arduino Pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def shutdown(self):\n\n        if self.log_output:\n            logging.info('Shutting down ...')\n        else:\n            print('Shutting down ...')\n\n        await self.send_reset()\n\n        try:\n            self.loop.stop()\n        except:\n            pass\n        try:\n            self.loop.close()\n        except:\n            pass\n        sys.exit(0)", "response": "This method attempts an orderly shutdown of the current instance and closes the loop."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def sonar_config(self, trigger_pin, echo_pin, cb=None,\n                           ping_interval=50, max_distance=200, cb_type=None):\n        \"\"\"\n        Configure the pins,ping interval and maximum distance for an HC-SR04\n        type device.\n        Single pin configuration may be used. To do so, set both the trigger\n        and echo pins to the same value.\n        Up to a maximum of 6 SONAR devices is supported\n        If the maximum is exceeded a message is sent to the console and the\n        request is ignored.\n        NOTE: data is measured in centimeters\n\n        :param trigger_pin: The pin number of for the trigger (transmitter).\n\n        :param echo_pin: The pin number for the received echo.\n\n        :param cb: optional callback function to report sonar data changes\n\n        :param ping_interval: Minimum interval between pings. Lowest number\n                              to use is 33 ms. Max is 127ms.\n\n        :param max_distance: Maximum distance in cm. Max is 200.\n\n        :param cb_type: Constants.CB_TYPE_DIRECT = direct call or\n                        Constants.CB_TYPE_ASYNCIO = asyncio coroutine\n        :returns: No return value.\n        \"\"\"\n        # if there is an entry for the trigger pin in existence, just exit\n        if trigger_pin in self.active_sonar_map:\n            return\n\n        if max_distance > 200:\n            max_distance = 200\n        max_distance_lsb = max_distance & 0x7f\n        max_distance_msb = (max_distance >> 7) & 0x7f\n        data = [trigger_pin, echo_pin, ping_interval, max_distance_lsb,\n                max_distance_msb]\n        await self.set_pin_mode(trigger_pin, Constants.SONAR, Constants.INPUT)\n        await self.set_pin_mode(echo_pin, Constants.SONAR, Constants.INPUT)\n        # update the ping data map for this pin\n        if len(self.active_sonar_map) > 6:\n            if self.log_output:\n                logging.exception('sonar_config: maximum number of '\n                                  'devices assigned - ignoring request')\n            else:\n                print('sonar_config: maximum number of devices assigned'\n                      ' - ignoring request')\n        else:\n            self.active_sonar_map[trigger_pin] = [cb, cb_type, 0]\n\n        await self._send_sysex(PrivateConstants.SONAR_CONFIG, data)", "response": "Configure the sonar data for a specific HC - SR04 type device."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def sonar_data_retrieve(self, trigger_pin):\n        # sonar_pin_entry = self.active_sonar_map[pin]\n        sonar_pin_entry = self.active_sonar_map.get(trigger_pin)\n        value = sonar_pin_entry[1]\n        return value", "response": "Retrieve the data for a specific pin from the active_sonar_map."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def stepper_config(self, steps_per_revolution, stepper_pins):\n        data = [PrivateConstants.STEPPER_CONFIGURE, steps_per_revolution & 0x7f,\n                (steps_per_revolution >> 7) & 0x7f]\n        for pin in range(len(stepper_pins)):\n            data.append(stepper_pins[pin])\n        await self._send_sysex(PrivateConstants.STEPPER_DATA, data)", "response": "Configure stepper motor prior to operation."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmoving a stepper motor for the number of steps at the specified speed This is a FirmataPlus feature. :param motor_speed: 21 bits of data to set motor speed :param number_of_steps: 14 bits for number of steps & direction positive is forward, negative is reverse :returns: No return value.", "response": "async def stepper_step(self, motor_speed, number_of_steps):\n        \"\"\"\n        Move a stepper motor for the number of steps at the specified speed\n        This is a FirmataPlus feature.\n\n        :param motor_speed: 21 bits of data to set motor speed\n\n        :param number_of_steps: 14 bits for number of steps & direction\n                                positive is forward, negative is reverse\n\n        :returns: No return value.\n        \"\"\"\n        if number_of_steps > 0:\n            direction = 1\n        else:\n            direction = 0\n        abs_number_of_steps = abs(number_of_steps)\n        data = [PrivateConstants.STEPPER_STEP, motor_speed & 0x7f,\n                (motor_speed >> 7) & 0x7f, (motor_speed >> 14) & 0x7f,\n                abs_number_of_steps & 0x7f, (abs_number_of_steps >> 7) & 0x7f, direction]\n        await self._send_sysex(PrivateConstants.STEPPER_DATA, data)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def pixy_init(self, max_blocks=5, cb=None, cb_type=None):\n        if cb:\n            self.digital_pins[PrivateConstants.PIN_PIXY_MOSI].cb = cb  # Pixy uses SPI.  Pin 11 is MOSI.\n        if cb_type:\n            self.digital_pins[PrivateConstants.PIN_PIXY_MOSI].cb_type = cb_type\n        data = [PrivateConstants.PIXY_INIT, max_blocks & 0x7f]\n        await self._send_sysex(PrivateConstants.PIXY_CONFIG, data)", "response": "Initialize Pixy and enable Pixy block reporting."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def pixy_set_servos(self, s0, s1):\n        data = [PrivateConstants.PIXY_SET_SERVOS, s0 & 0x7f, (s0 >> 7) & 0x7f,\n                s1 & 0x7f, (s1 >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.PIXY_CONFIG, data)", "response": "This method sends the setServos Pixy command. It is used to set the pan and tilt servos that are plugged into Pixy s two servo ports."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def pixy_set_brightness(self, brightness):\n        data = [PrivateConstants.PIXY_SET_BRIGHTNESS, brightness & 0x7f,\n                (brightness >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.PIXY_CONFIG, data)", "response": "This method sends the setBrightness Pixy command. It is used to set the brightness of the Pixy s camera."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the setLed Pixy command. This method sets the RGB LED on front of Pixy. :param r: red range between 0 and 255 :param g: green range between 0 and 255 :param b: blue range between 0 and 255 :returns: No return value.", "response": "async def pixy_set_led(self, r, g, b):\n        \"\"\"\n        Sends the setLed Pixy command.\n        This method sets the RGB LED on front of Pixy.\n\n        :param r: red range between 0 and 255\n\n        :param g: green range between 0 and 255\n\n        :param b: blue range between 0 and 255\n\n        :returns: No return value.\n        \"\"\"\n        data = [PrivateConstants.PIXY_SET_LED, r & 0x7f, (r >> 7) & 0x7f,\n                g & 0x7f, (g >> 7) & 0x7f, b & 0x7f,\n                (b >> 7) & 0x7f]\n        await self._send_sysex(PrivateConstants.PIXY_CONFIG, data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def _command_dispatcher(self):\n        # sysex commands are assembled into this list for processing\n        sysex = []\n\n        while True:\n            try:\n                next_command_byte = await self.read()\n                # if this is a SYSEX command, then assemble the entire\n                # command process it\n                if next_command_byte == PrivateConstants.START_SYSEX:\n                    while next_command_byte != PrivateConstants.END_SYSEX:\n                        await asyncio.sleep(self.sleep_tune)\n                        next_command_byte = await self.read()\n                        sysex.append(next_command_byte)\n                    await self.command_dictionary[sysex[0]](sysex)\n                    sysex = []\n                    await asyncio.sleep(self.sleep_tune)\n                # if this is an analog message, process it.\n                elif 0xE0 <= next_command_byte <= 0xEF:\n                    # analog message\n                    # assemble the entire analog message in command\n                    command = []\n                    # get the pin number for the message\n                    pin = next_command_byte & 0x0f\n                    command.append(pin)\n                    # get the next 2 bytes for the command\n                    command = await self._wait_for_data(command, 2)\n                    # process the analog message\n                    await self._analog_message(command)\n                # handle the digital message\n                elif 0x90 <= next_command_byte <= 0x9F:\n                    command = []\n                    port = next_command_byte & 0x0f\n                    command.append(port)\n                    command = await self._wait_for_data(command, 2)\n                    await self._digital_message(command)\n                # handle all other messages by looking them up in the\n                # command dictionary\n                elif next_command_byte in self.command_dictionary:\n                    await self.command_dictionary[next_command_byte]()\n                    await asyncio.sleep(self.sleep_tune)\n                else:\n                    # we need to yield back to the loop\n                    await asyncio.sleep(self.sleep_tune)\n                    continue\n            except Exception as ex:\n                # A error occurred while transmitting the Firmata message, message arrived invalid.\n                if self.log_output:\n                    logging.exception(ex)\n                else:\n                    print(ex)\n                await self.shutdown()\n\n                await self.serial_port.close()\n\n                print(\"An exception occurred on the asyncio event loop while receiving data.  Invalid message.\")\n                loop = self.loop\n                for t in asyncio.Task.all_tasks(loop):\n                    t.cancel()\n                loop.run_until_complete(asyncio.sleep(.1))\n                loop.close()\n                loop.stop()\n                sys.exit(0)", "response": "This method is a private method that handles all the commands in the command_dictionary and processes the data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _encoder_data(self, data):\n        # strip off sysex start and end\n        data = data[1:-1]\n        pin = data[0]\n        if not self.hall_encoder:\n            val = int((data[PrivateConstants.MSB] << 7) +\n                      data[PrivateConstants.LSB])\n            # set value so that it shows positive and negative values\n            if val > 8192:\n                val -= 16384\n            # if this value is different that is what is already in the\n            # table store it and check for callback\n            if val != self.digital_pins[pin].current_value:\n                self.digital_pins[pin].current_value = val\n                if self.digital_pins[pin].cb:\n                    # self.digital_pins[pin].cb([pin, val])\n                    if self.digital_pins[pin].cb_type:\n                        await self.digital_pins[pin].cb(val)\n                    else:\n                        # self.digital_pins[pin].cb(data)\n                        loop = self.loop\n                        loop.call_soon(self.digital_pins[pin].cb, val)\n        else:\n            hall_data = [int((data[2] << 7) + data[1]), int((data[5] << 7) +\n                                                            data[4])]\n\n            if self.digital_pins[pin].cb_type:\n                await self.digital_pins[pin].cb(hall_data)\n            else:\n                # self.digital_pins[pin].cb(data)\n                loop = self.loop\n                loop.call_soon(self.digital_pins[pin].cb, hall_data)", "response": "This is a private message handler method. It handles encoder data messages. It handles encoder data messages. It handles encoder data messages."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _report_version(self):\n        # get next two bytes\n        major = await self.read()\n        version_string = str(major)\n        minor = await self.read()\n        version_string += '.'\n        version_string += str(minor)\n        self.query_reply_data[PrivateConstants.REPORT_VERSION] = version_string", "response": "This method reads the report version from the server and stores it in the query reply data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _sonar_data(self, data):\n\n        # strip off sysex start and end\n        data = data[1:-1]\n        pin_number = data[0]\n        val = int((data[PrivateConstants.MSB] << 7) +\n                  data[PrivateConstants.LSB])\n        reply_data = []\n\n        sonar_pin_entry = self.active_sonar_map[pin_number]\n\n        if sonar_pin_entry[0] is not None:\n            # check if value changed since last reading\n            if sonar_pin_entry[2] != val:\n                sonar_pin_entry[2] = val\n                self.active_sonar_map[pin_number] = sonar_pin_entry\n                # Do a callback if one is specified in the table\n                if sonar_pin_entry[0]:\n                    # if this is an asyncio callback type\n                    reply_data.append(pin_number)\n                    reply_data.append(val)\n                    if sonar_pin_entry[1]:\n                        await sonar_pin_entry[0](reply_data)\n                    else:\n                        # sonar_pin_entry[0]([pin_number, val])\n                        loop = self.loop\n                        loop.call_soon(sonar_pin_entry[0], reply_data)\n        # update the data in the table with latest value\n        else:\n            sonar_pin_entry[1] = val\n            self.active_sonar_map[pin_number] = sonar_pin_entry\n\n        await asyncio.sleep(self.sleep_tune)", "response": "This method handles the incoming sonar data message and stores the data in the response table."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _discover_port(self):\n        # if MAC get list of ports\n        if sys.platform.startswith('darwin'):\n            locations = glob.glob('/dev/tty.[usb*]*')\n            locations = glob.glob('/dev/tty.[wchusb*]*') + locations\n            locations.append('end')\n        # for everyone else, here is a list of possible ports\n        else:\n            locations = ['/dev/ttyACM0', '/dev/ttyACM1',\n                         '/dev/ttyACM2', '/dev/ttyACM3', '/dev/ttyACM4',\n                         '/dev/ttyACM5', '/dev/ttyUSB0', '/dev/ttyUSB1',\n                         '/dev/ttyUSB2', '/dev/ttyUSB3', '/dev/ttyUSB4',\n                         '/dev/ttyUSB5', '/dev/ttyUSB6', '/dev/ttyUSB7',\n                         '/dev/ttyUSB8', '/dev/ttyUSB9',\n                         '/dev/ttyUSB10',\n                         '/dev/ttyS0', '/dev/ttyS1', '/dev/ttyS2',\n                         '/dev/tty.usbserial', '/dev/tty.usbmodem', 'com2',\n                         'com3', 'com4', 'com5', 'com6', 'com7', 'com8',\n                         'com9', 'com10', 'com11', 'com12', 'com13',\n                         'com14', 'com15', 'com16', 'com17', 'com18',\n                         'com19', 'com20', 'com21', 'com1', 'end'\n                         ]\n\n        detected = None\n        for device in locations:\n            try:\n                serialport = serial.Serial(device, 57600, timeout=0)\n                detected = device\n                serialport.close()\n                break\n            except serial.SerialException:\n                if device == 'end':\n                    if self.log_output:\n                        logging.exception(\n                            'Unable to find Serial Port, Please plug in '\n                            'cable or check cable connections.')\n                    else:\n                        print('Unable to find Serial Port, Please plug in '\n                              'cable or check cable connections.')\n                    sys.exit()\n        if self.log_output:\n            log_string = 'Using COM Port: ' + detected\n            logging.info(log_string)\n        else:\n            print('{}{}\\n'.format('Using COM Port:', detected))\n        return detected", "response": "This method attempts to discover the com port that the arduino is connected to."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def digital_write(self, command):\n        pin = int(command[0])\n        value = int(command[1])\n        await self.core.digital_write(pin, value)", "response": "This method writes a zero or one to a digital pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def disable_analog_reporting(self, command):\n        pin = int(command[0])\n        await self.core.disable_analog_reporting(pin)", "response": "Disable Firmata reporting for an analog pin."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisabling Firmata reporting for a digital pin.", "response": "async def disable_digital_reporting(self, command):\n        \"\"\"\n        Disable Firmata reporting for a digital pin.\n\n        :param command: {\"method\": \"disable_digital_reporting\", \"params\": [PIN]}\n        :returns: No return message.\n        \"\"\"\n        pin = int(command[0])\n        await self.core.disable_digital_reporting(pin)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def enable_analog_reporting(self, command):\n        pin = int(command[0])\n        await self.core.enable_analog_reporting(pin)", "response": "Enable Firmata reporting for an analog pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def enable_digital_reporting(self, command):\n        pin = int(command[0])\n        await self.core.enable_digital_reporting(pin)", "response": "Enable Firmata reporting for a digital pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def encoder_config(self, command):\n        pin_a = int(command[0])\n        pin_b = int(command[1])\n        await self.core.encoder_config(pin_a, pin_b, self.encoder_callback)", "response": "Configure 2 pins for FirmataPlus encoder operation."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def encoder_read(self, command):\n        pin = int(command[0])\n        val = await self.core.encoder_read(pin)\n        reply = json.dumps({\"method\": \"encoder_read_reply\", \"params\": [pin, val]})\n        await self.websocket.send(reply)", "response": "This method is used to read the last cached FirmataPlus encoder value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def get_capability_report(self):\n        value = await self.core.get_capability_report()\n        await asyncio.sleep(.1)\n        if value:\n            reply = json.dumps({\"method\": \"capability_report_reply\", \"params\": value})\n        else:\n            reply = json.dumps({\"method\": \"capability_report_reply\", \"params\": \"None\"})\n        await self.websocket.send(reply)", "response": "This method retrieves the Firmata capability report."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def get_protocol_version(self):\n        value = await self.core.get_protocol_version()\n        if value:\n            reply = json.dumps({\"method\": \"protocol_version_reply\", \"params\": value})\n        else:\n            reply = json.dumps({\"method\": \"protocol_version_reply\", \"params\": \"Unknown\"})\n        await self.websocket.send(reply)", "response": "This method retrieves the Firmata protocol version. It returns the protocol version as a JSON object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def i2c_config(self, command):\n        delay = int(command[0])\n        await self.core.i2c_config(delay)", "response": "This method initializes the I2C and sets the optional read delay."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def i2c_read_data(self, command):\n        address = int(command[0])\n        i2c_data = await self.core.i2c_read_data(address)\n        reply = json.dumps({\"method\": \"i2c_read_data_reply\", \"params\": i2c_data})\n        await self.websocket.send(reply)", "response": "This method retrieves the last value read for an i2c device identified by address."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsends a keep alive message to Arduino.", "response": "async def keep_alive(self, command):\n        \"\"\"\n        Periodically send a keep alive message to the Arduino.\n        Frequency of keep alive transmission is calculated as follows:\n        keep_alive_sent = period - (period * margin)\n\n        :param command:  {\"method\": \"keep_alive\", \"params\": [PERIOD, MARGIN]}\n        Period is time period between keepalives. Range is 0-10 seconds. 0 disables the keepalive mechanism.\n        Margin is a  safety margin to assure keepalives are sent before period expires. Range is 0.1 to 0.9\n        :returns: No return value\n        \"\"\"\n        period = int(command[0])\n        margin = int(command[1])\n        await self.core.keep_alive(period, margin)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def play_tone(self, command):\n        pin = int(command[0])\n        if command[1] == \"TONE_TONE\":\n            tone_command = Constants.TONE_TONE\n        else:\n            tone_command = Constants.TONE_NO_TONE\n        frequency = int(command[2])\n        duration = int(command[3])\n        await self.core.play_tone(pin, tone_command, frequency, duration)", "response": "This method controls a piezo device to play a tone."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def set_digital_latch(self, command):\n        pin = int(command[0])\n        threshold_value = int(command[1])\n        await self.core.set_digital_latch(pin, threshold_value, self.digital_latch_callback)", "response": "This method is used to set the digital latch for a given digital pin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def set_sampling_interval(self, command):\n        sample_interval = int(command[0])\n        await self.core.set_sampling_interval(sample_interval)", "response": "This method sets the Firmata sampling interval in ms."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def sonar_config(self, command):\n        trigger = int(command[0])\n        echo = int(command[1])\n        interval = int(command[2])\n        max_dist = int(command[3])\n        await self.core.sonar_config(trigger, echo, self.sonar_callback, interval, max_dist)", "response": "This method configures 2 pins to support HC - SR04 Ping devices."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pixy_value_update(blocks):\n    if len(blocks) > 0:\n        pan_error = X_CENTER - blocks[0][\"x\"]\n        pan_loop.update(pan_error)\n#         tilt_error = blocks[0][\"y\"] - Y_CENTER  # not used for power over ICSP reasons\n#         tilt_loop.update(tilt_error)\n\n        loop = asyncio.get_event_loop()\n        if loop.is_running():\n            # This is the version that will be used since we are in a callback, but I wanted to show how to\n            # properly protect against calls to board.something when you don't know if you are in the non-async\n            # land vs when you are currently executing code from within async land.\n            asyncio.ensure_future(board.core.pixy_set_servos(int(pan_loop.position), int(PIXY_RCS_CENTER_POS)))\n        else:\n            board.pixy_set_servos(int(pan_loop.position), int(PIXY_RCS_CENTER_POS))", "response": "Prints the Pixy blocks data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef signal_handler(sig, frame):\n    print('\\nYou pressed Ctrl+C')\n    if board is not None:\n        board.send_reset()\n        board.shutdown()\n    sys.exit(0)", "response": "This method is called when a signal is received from the RedBot."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef pin_6_pwm_128():\n    # instantiate the pymata_core API\n    board = PyMata3()\n\n    # set the pin mode\n    board.set_pin_mode(6, Constants.PWM)\n    board.analog_write(6, 128)\n\n    # wait for 3 seconds to see the LED lit\n    board.sleep(3)\n\n    # reset the board and exit\n    board.shutdown()", "response": "This function is used to set the digital pin 6 as a PWM output and set its output value to 128."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fetch_token(self, **kwargs):\n        return super(AsanaOAuth2Session, self).fetch_token(self.token_url, client_secret=self.client_secret, **kwargs)", "response": "Exchange a code and state token for a bearer token"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_by_id(self, tag, params={}, **options): \n        path = \"/tags/%s\" % (tag)\n        return self.client.get(path, params, **options)", "response": "Returns the complete tag record for a single tag."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, tag, params={}, **options): \n        path = \"/tags/%s\" % (tag)\n        return self.client.put(path, params, **options)", "response": "Updates the properties of a tag."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete(self, tag, params={}, **options): \n        path = \"/tags/%s\" % (tag)\n        return self.client.delete(path, params, **options)", "response": "A specific existing tag can be deleted by making a DELETE request on the URL for that tag. Returns an empty data record."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_by_workspace(self, workspace, params={}, **options): \n        path = \"/workspaces/%s/tags\" % (workspace)\n        return self.client.get_collection(path, params, **options)", "response": "Returns the compact tag records for all tags in the workspace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the compact task records for all tasks with the given tag.", "response": "def get_tasks_with_tag(self, tag, params={}, **options): \n        \"\"\"Returns the compact task records for all tasks with the given tag.\n        Tasks can have more than one tag at a time.\n\n        Parameters\n        ----------\n        tag : {Id} The tag to fetch tasks from.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tags/%s/tasks\" % (tag)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn details of a previously - requested Organization export.", "response": "def find_by_id(self, organization_export, params={}, **options): \n        \"\"\"Returns details of a previously-requested Organization export.\n\n        Parameters\n        ----------\n        organization_export : {Id} Globally unique identifier for the Organization export.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/organization_exports/%s\" % (organization_export)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find_by_id(self, custom_field, params={}, **options): \n        path = \"/custom_fields/%s\" % (custom_field)\n        return self.client.get(path, params, **options)", "response": "Returns the complete definition of a custom field s metadata."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef delete(self, custom_field, params={}, **options): \n        path = \"/custom_fields/%s\" % (custom_field)\n        return self.client.delete(path, params, **options)", "response": "A specific custom field can be deleted by making a DELETE request on the URL for that custom field. Returns an empty data record."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_enum_option(self, custom_field, params={}, **options): \n        path = \"/custom_fields/%s/enum_options\" % (custom_field)\n        return self.client.post(path, params, **options)", "response": "Creates an enum option and adds it to this custom field s list of enum options."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_enum_option(self, enum_option, params={}, **options): \n        path = \"/enum_options/%s\" % (enum_option)\n        return self.client.put(path, params, **options)", "response": "Updates an existing enum option."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nmove a particular enum option in the custom field to be either before or after another specified enum option in the custom field.", "response": "def insert_enum_option(self, custom_field, params={}, **options): \n        \"\"\"Moves a particular enum option to be either before or after another specified enum option in the custom field.\n\n        Parameters\n        ----------\n        custom_field : {Id} Globally unique identifier for the custom field.\n        [data] : {Object} Data for the request\n          - enum_option : {Id} The ID of the enum option to relocate.\n          - name : {String} The name of the enum option.\n          - [color] : {String} The color of the enum option. Defaults to 'none'.\n          - [before_enum_option] : {Id} An existing enum option within this custom field before which the new enum option should be inserted. Cannot be provided together with after_enum_option.\n          - [after_enum_option] : {Id} An existing enum option within this custom field after which the new enum option should be inserted. Cannot be provided together with before_enum_option.\n        \"\"\"\n        path = \"/custom_fields/%s/enum_options/insert\" % (custom_field)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_by_project(self, project, params={}, **options): \n        path = \"/projects/%s/project_memberships\" % (project)\n        return self.client.get_collection(path, params, **options)", "response": "Returns the compact project membership records for the project."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_by_id(self, project_membership, params={}, **options): \n        path = \"/project_memberships/%s\" % (project_membership)\n        return self.client.get(path, params, **options)", "response": "Returns the project membership record with the specified id."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the full workspace record for a single workspace.", "response": "def find_by_id(self, workspace, params={}, **options): \n        \"\"\"Returns the full workspace record for a single workspace.\n\n        Parameters\n        ----------\n        workspace : {Id} Globally unique identifier for the workspace or organization.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/workspaces/%s\" % (workspace)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef typeahead(self, workspace, params={}, **options): \n        path = \"/workspaces/%s/typeahead\" % (workspace)\n        return self.client.get_collection(path, params, **options)", "response": "This method returns a list of objects in the workspace based on a typeahead search algorithm. This method will return a single page of results for each object in the workspace."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nadding a user to a workspace. Returns the full user record for the user.", "response": "def add_user(self, workspace, params={}, **options): \n        \"\"\"The user can be referenced by their globally unique user ID or their email address.\n        Returns the full user record for the invited user.\n\n        Parameters\n        ----------\n        workspace : {Id} The workspace or organization to invite the user to.\n        [data] : {Object} Data for the request\n          - user : {String} An identifier for the user. Can be one of an email address,\n          the globally unique identifier for the user, or the keyword `me`\n          to indicate the current user making the request.\n        \"\"\"\n        path = \"/workspaces/%s/addUser\" % (workspace)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef remove_user(self, workspace, params={}, **options): \n        path = \"/workspaces/%s/removeUser\" % (workspace)\n        return self.client.post(path, params, **options)", "response": "This method removes a user from a workspace."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef find_by_id(self, attachment, params={}, **options): \n        path = \"/attachments/%s\" % (attachment)\n        return self.client.get(path, params, **options)", "response": "Returns the full record for a single attachment."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_by_task(self, task, params={}, **options): \n        path = \"/tasks/%s/attachments\" % (task)\n        return self.client.get_collection(path, params, **options)", "response": "Returns the compact records for all attachments on the task."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nuploads an attachment for a task. Accepts a file object or string file name and optional file Content - Type. Returns the full record of the attachment.", "response": "def create_on_task(self, task_id, file_content, file_name, file_content_type=None, **options):\n        \"\"\"Upload an attachment for a task. Accepts a file object or string, file name, and optional file Content-Type\"\"\"\n        path = '/tasks/%d/attachments' % (task_id)\n        return self.client.request('post', path, files=[('file', (file_name, file_content, file_content_type))], **options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the full record for a single team.", "response": "def find_by_id(self, team, params={}, **options): \n        \"\"\"Returns the full record for a single team.\n\n        Parameters\n        ----------\n        team : {Id} Globally unique identifier for the team.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/teams/%s\" % (team)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the compact records for all teams in the organization visible to the authorized user.", "response": "def find_by_organization(self, organization, params={}, **options): \n        \"\"\"Returns the compact records for all teams in the organization visible to\n        the authorized user.\n\n        Parameters\n        ----------\n        organization : {Id} Globally unique identifier for the workspace or organization.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/organizations/%s/teams\" % (organization)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the compact records for all teams to which the user is assigned.", "response": "def find_by_user(self, user, params={}, **options): \n        \"\"\"Returns the compact records for all teams to which user is assigned.\n\n        Parameters\n        ----------\n        user : {String} An identifier for the user. Can be one of an email address,\n        the globally unique identifier for the user, or the keyword `me`\n        to indicate the current user making the request.\n        [params] : {Object} Parameters for the request\n          - [organization] : {Id} The workspace or organization to filter teams on.\n        \"\"\"\n        path = \"/users/%s/teams\" % (user)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef users(self, team, params={}, **options): \n        path = \"/teams/%s/users\" % (team)\n        return self.client.get_collection(path, params, **options)", "response": "Returns the compact records for all users that are members of the team."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a user to a team. Returns the full user record for the added user.", "response": "def add_user(self, team, params={}, **options): \n        \"\"\"The user making this call must be a member of the team in order to add others.\n        The user to add must exist in the same organization as the team in order to be added.\n        The user to add can be referenced by their globally unique user ID or their email address.\n        Returns the full user record for the added user.\n\n        Parameters\n        ----------\n        team : {Id} Globally unique identifier for the team.\n        [data] : {Object} Data for the request\n          - user : {String} An identifier for the user. Can be one of an email address,\n          the globally unique identifier for the user, or the keyword `me`\n          to indicate the current user making the request.\n        \"\"\"\n        path = \"/teams/%s/addUser\" % (team)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a user from a team.", "response": "def remove_user(self, team, params={}, **options): \n        \"\"\"The user to remove can be referenced by their globally unique user ID or their email address.\n        Removes the user from the specified team. Returns an empty data record.\n\n        Parameters\n        ----------\n        team : {Id} Globally unique identifier for the team.\n        [data] : {Object} Data for the request\n          - user : {String} An identifier for the user. Can be one of an email address,\n          the globally unique identifier for the user, or the keyword `me`\n          to indicate the current user making the request.\n        \"\"\"\n        path = \"/teams/%s/removeUser\" % (team)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_parent(self, task_id, params={}, **options):\n        path = '/tasks/%s/setParent' % (task_id)\n        return self.client.post(path, params, **options)", "response": "Changes the parent of a task. Returns an empty data block."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_in_project(self, project, params={}, **options): \n        path = \"/projects/%s/sections\" % (project)\n        return self.client.post(path, params, **options)", "response": "Creates a new section in a project. Returns the full record of the newly created section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef find_by_project(self, project, params={}, **options): \n        path = \"/projects/%s/sections\" % (project)\n        return self.client.get(path, params, **options)", "response": "Returns the compact records for all sections in the specified project."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_by_id(self, section, params={}, **options): \n        path = \"/sections/%s\" % (section)\n        return self.client.get(path, params, **options)", "response": "Returns the complete record for a single section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insert_in_project(self, project, params={}, **options): \n        path = \"/projects/%s/sections/insert\" % (project)\n        return self.client.post(path, params, **options)", "response": "Inserts a new section in a project."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef find_by_id(self, story, params={}, **options): \n        path = \"/stories/%s\" % (story)\n        return self.client.get(path, params, **options)", "response": "Returns the full record for a single story."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a comment to a task. Returns the full record for the newly added comment.", "response": "def create_on_task(self, task, params={}, **options): \n        \"\"\"Adds a comment to a task. The comment will be authored by the\n        currently authenticated user, and timestamped when the server receives\n        the request.\n        \n        Returns the full record for the new story added to the task.\n\n        Parameters\n        ----------\n        task : {Id} Globally unique identifier for the task.\n        [data] : {Object} Data for the request\n          - text : {String} The plain text of the comment to add.\n        \"\"\"\n        path = \"/tasks/%s/stories\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef update(self, story, params={}, **options): \n        path = \"/stories/%s\" % (story)\n        return self.client.put(path, params, **options)", "response": "Updates the story and returns the full record for the updated story."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef delete(self, story, params={}, **options): \n        path = \"/stories/%s\" % (story)\n        return self.client.delete(path, params, **options)", "response": "Deletes a story. A user can only delete stories they have created. Returns an empty data record."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef create_in_workspace(self, workspace, params={}, **options): \n        path = \"/workspaces/%s/tasks\" % (workspace)\n        return self.client.post(path, params, **options)", "response": "Creates a new task in a workspace."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the complete task record for a single task.", "response": "def find_by_id(self, task, params={}, **options): \n        \"\"\"Returns the complete task record for a single task.\n\n        Parameters\n        ----------\n        task : {Id} The task to get.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tasks/%s\" % (task)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the compact task records for all tasks within the given project ordered by their priority within the project.", "response": "def find_by_project(self, project_id, params={}, **options): \n        \"\"\"Returns the compact task records for all tasks within the given project,\n        ordered by their priority within the project.\n\n        Parameters\n        ----------\n        projectId : {Id} The project in which to search for tasks.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/projects/%s/tasks\" % (project_id)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the compact task records for all tasks with the given tag.", "response": "def find_by_tag(self, tag, params={}, **options): \n        \"\"\"Returns the compact task records for all tasks with the given tag.\n\n        Parameters\n        ----------\n        tag : {Id} The tag in which to search for tasks.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tags/%s/tasks\" % (tag)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef find_by_section(self, section, params={}, **options): \n        path = \"/sections/%s/tasks\" % (section)\n        return self.client.get_collection(path, params, **options)", "response": "Returns the compact section records for all tasks within the given section."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dependencies(self, task, params={}, **options): \n        path = \"/tasks/%s/dependencies\" % (task)\n        return self.client.get(path, params, **options)", "response": "Returns the compact representations of all of the dependencies of a task."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the compact representations of all of the dependents of a task.", "response": "def dependents(self, task, params={}, **options): \n        \"\"\"Returns the compact representations of all of the dependents of a task.\n\n        Parameters\n        ----------\n        task : {Id} The task to get dependents on.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tasks/%s/dependents\" % (task)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_dependencies(self, task, params={}, **options): \n        path = \"/tasks/%s/addDependencies\" % (task)\n        return self.client.post(path, params, **options)", "response": "Marks a set of tasks as dependencies of this task."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmarks a set of tasks as dependents of this task.", "response": "def add_dependents(self, task, params={}, **options): \n        \"\"\"Marks a set of tasks as dependents of this task, if they are not already\n        dependents. *A task can have at most 30 dependents.*\n\n        Parameters\n        ----------\n        task : {Id} The task to add dependents to.\n        [data] : {Object} Data for the request\n          - dependents : {Array} An array of task IDs that should depend on this task.\n        \"\"\"\n        path = \"/tasks/%s/addDependents\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the set of dependencies from this task.", "response": "def remove_dependencies(self, task, params={}, **options): \n        \"\"\"Unlinks a set of dependencies from this task.\n\n        Parameters\n        ----------\n        task : {Id} The task to remove dependencies from.\n        [data] : {Object} Data for the request\n          - dependencies : {Array} An array of task IDs to remove as dependencies.\n        \"\"\"\n        path = \"/tasks/%s/removeDependencies\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all of the dependents from a task.", "response": "def remove_dependents(self, task, params={}, **options): \n        \"\"\"Unlinks a set of dependents from this task.\n\n        Parameters\n        ----------\n        task : {Id} The task to remove dependents from.\n        [data] : {Object} Data for the request\n          - dependents : {Array} An array of task IDs to remove as dependents.\n        \"\"\"\n        path = \"/tasks/%s/removeDependents\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_followers(self, task, params={}, **options): \n        path = \"/tasks/%s/addFollowers\" % (task)\n        return self.client.post(path, params, **options)", "response": "Adds each of the specified followers to the task. Returns the complete updated record for the affected task."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef remove_followers(self, task, params={}, **options): \n        path = \"/tasks/%s/removeFollowers\" % (task)\n        return self.client.post(path, params, **options)", "response": "Removes each of the specified followers from the task if they are\n        following. Returns the complete updated record for the affected task."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef projects(self, task, params={}, **options): \n        path = \"/tasks/%s/projects\" % (task)\n        return self.client.get_collection(path, params, **options)", "response": "Returns a compact representation of all of the projects the task is in."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd the specified task to the specified project in the optional location specified.", "response": "def add_project(self, task, params={}, **options): \n        \"\"\"Adds the task to the specified project, in the optional location\n        specified. If no location arguments are given, the task will be added to\n        the end of the project.\n        \n        `addProject` can also be used to reorder a task within a project or section that\n        already contains it.\n        \n        At most one of `insert_before`, `insert_after`, or `section` should be\n        specified. Inserting into a section in an non-order-dependent way can be\n        done by specifying `section`, otherwise, to insert within a section in a\n        particular place, specify `insert_before` or `insert_after` and a task\n        within the section to anchor the position of this task.\n        \n        Returns an empty data block.\n\n        Parameters\n        ----------\n        task : {Id} The task to add to a project.\n        [data] : {Object} Data for the request\n          - project : {Id} The project to add the task to.\n          - [insert_after] : {Id} A task in the project to insert the task after, or `null` to\n          insert at the beginning of the list.\n          - [insert_before] : {Id} A task in the project to insert the task before, or `null` to\n          insert at the end of the list.\n          - [section] : {Id} A section in the project to insert the task into. The task will be\n          inserted at the bottom of the section.\n        \"\"\"\n        path = \"/tasks/%s/addProject\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_project(self, task, params={}, **options): \n        path = \"/tasks/%s/removeProject\" % (task)\n        return self.client.post(path, params, **options)", "response": "Removes the specified task from the specified project. Returns an empty data block."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a compact representation of all of the tags that the task has.", "response": "def tags(self, task, params={}, **options): \n        \"\"\"Returns a compact representation of all of the tags the task has.\n\n        Parameters\n        ----------\n        task : {Id} The task to get tags on.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tasks/%s/tags\" % (task)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a tag to a task. Returns an empty data block.", "response": "def add_tag(self, task, params={}, **options): \n        \"\"\"Adds a tag to a task. Returns an empty data block.\n\n        Parameters\n        ----------\n        task : {Id} The task to add a tag to.\n        [data] : {Object} Data for the request\n          - tag : {Id} The tag to add to the task.\n        \"\"\"\n        path = \"/tasks/%s/addTag\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a tag from the task. Returns an empty data block.", "response": "def remove_tag(self, task, params={}, **options): \n        \"\"\"Removes a tag from the task. Returns an empty data block.\n\n        Parameters\n        ----------\n        task : {Id} The task to remove a tag from.\n        [data] : {Object} Data for the request\n          - tag : {Id} The tag to remove from the task.\n        \"\"\"\n        path = \"/tasks/%s/removeTag\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a compact representation of all of the subtasks of a task.", "response": "def subtasks(self, task, params={}, **options): \n        \"\"\"Returns a compact representation of all of the subtasks of a task.\n\n        Parameters\n        ----------\n        task : {Id} The task to get the subtasks of.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/tasks/%s/subtasks\" % (task)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_subtask(self, task, params={}, **options): \n        path = \"/tasks/%s/subtasks\" % (task)\n        return self.client.post(path, params, **options)", "response": "Creates a new subtask and adds it to the parent task. Returns the full record\n        for the newly created subtask."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef stories(self, task, params={}, **options): \n        path = \"/tasks/%s/stories\" % (task)\n        return self.client.get_collection(path, params, **options)", "response": "Returns a compact representation of all of the stories on the task."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a comment to a task. Returns the full record for the comment added to the task.", "response": "def add_comment(self, task, params={}, **options): \n        \"\"\"Adds a comment to a task. The comment will be authored by the\n        currently authenticated user, and timestamped when the server receives\n        the request.\n        \n        Returns the full record for the new story added to the task.\n\n        Parameters\n        ----------\n        task : {Id} Globally unique identifier for the task.\n        [data] : {Object} Data for the request\n          - text : {String} The plain text of the comment to add.\n        \"\"\"\n        path = \"/tasks/%s/stories\" % (task)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the complete record for a single status update.", "response": "def find_by_id(self, project_status, params={}, **options): \n        \"\"\"Returns the complete record for a single status update.\n\n        Parameters\n        ----------\n        project-status : {Id} The project status update to get.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/project_statuses/%s\" % (project_status)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef delete(self, project_status, params={}, **options): \n        path = \"/project_statuses/%s\" % (project_status)\n        return self.client.delete(path, params, **options)", "response": "Deletes a specific existing project status update. Returns an empty data record."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch a request to the Asana HTTP API.", "response": "def request(self, method, path, **options):\n        \"\"\"Dispatches a request to the Asana HTTP API\"\"\"\n        options = self._merge_options(options)\n        url = options['base_url'] + path\n        retry_count = 0\n        request_options = self._parse_request_options(options)\n        self._add_version_header(request_options)\n        while True:\n            try:\n                response = getattr(self.session, method)(\n                    url, auth=self.auth, **request_options)\n                if response.status_code in STATUS_MAP:\n                    raise STATUS_MAP[response.status_code](response)\n                elif 500 <= response.status_code < 600:\n                    # Any unhandled 500 is a server error.\n                    raise error.ServerError(response)\n                else:\n                    if options['full_payload']:\n                        return response.json()\n                    else:\n                        return response.json()['data']\n            except error.RetryableAsanaError as e:\n                if retry_count < options['max_retries']:\n                    self._handle_retryable_error(e, retry_count)\n                    retry_count += 1\n                else:\n                    raise e"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsleep based on the type of RetryableAsanaError.", "response": "def _handle_retryable_error(self, e, retry_count):\n        \"\"\"Sleep based on the type of :class:`RetryableAsanaError`\"\"\"\n        if isinstance(e, error.RateLimitEnforcedError):\n            time.sleep(e.retry_after)\n        else:\n            time.sleep(self.RETRY_DELAY * (self.RETRY_BACKOFF ** retry_count))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, path, query, **options):\n        api_options = self._parse_api_options(options, query_string=True)\n        query_options = self._parse_query_options(options)\n        parameter_options = self._parse_parameter_options(options)\n\n        # options in the query takes precendence\n        query = _merge(query_options, api_options, parameter_options, query)\n        return self.request('get', path, params=query, **options)", "response": "Parses GET request options and dispatches a request."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_collection(self, path, query, **options):\n        options = self._merge_options(options)\n        if options['iterator_type'] == 'items':\n            return CollectionPageIterator(self, path, query, options).items()\n        if options['iterator_type'] is None:\n            return self.get(path, query, **options)\n        raise Exception('Unknown value for \"iterator_type\" option: {}'.format(\n            str(options['iterator_type'])))", "response": "Get a collection from a collection endpoint."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing PUT request options and dispatches a request.", "response": "def put(self, path, data, **options):\n        \"\"\"Parses PUT request options and dispatches a request.\"\"\"\n        parameter_options = self._parse_parameter_options(options)\n        body = {\n            # values in the data body takes precendence\n            'data': _merge(parameter_options, data),\n            'options': self._parse_api_options(options)\n        }\n        headers = _merge(\n            {'content-type': 'application/json'},\n            options.pop('headers', {})\n        )\n        return self.request('put', path, data=body, headers=headers, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the parameter options.", "response": "def _parse_parameter_options(self, options):\n        \"\"\"Select all unknown options.\n\n        Select all unknown options (not query string, API, or request\n        options)\n\n        \"\"\"\n        return self._select_options(options, self.ALL_OPTIONS, invert=True)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nselect API options out of the provided options object and formats for either request body or query string.", "response": "def _parse_api_options(self, options, query_string=False):\n        \"\"\"Select API options out of the provided options object.\n\n        Selects API string options out of the provided options object and\n        formats for either request body (default) or query string.\n\n        \"\"\"\n        api_options = self._select_options(options, self.API_OPTIONS)\n        if query_string:\n            # Prefix all options with \"opt_\"\n            query_api_options = {}\n            for key in api_options:\n                # Transform list/tuples into comma separated list\n                if isinstance(api_options[key], (list, tuple)):\n                    query_api_options[\n                        'opt_' + key] = ','.join(api_options[key])\n                else:\n                    query_api_options[\n                        'opt_' + key] = api_options[key]\n            return query_api_options\n        else:\n            return api_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the request options from the provided options object.", "response": "def _parse_request_options(self, options):\n        \"\"\"Select request options out of the provided options object.\n\n\n        Select and formats options to be passed to the 'requests' library's\n        request methods.\n\n        \"\"\"\n        request_options = self._select_options(options, self.REQUEST_OPTIONS)\n        if 'params' in request_options:\n            params = request_options['params']\n            for key in params:\n                if isinstance(params[key], bool):\n                    params[key] = json.dumps(params[key])\n        if 'data' in request_options:\n            # remove empty 'options':\n            if 'options' in request_options['data'] and (\n                    len(request_options['data']['options']) == 0):\n                del request_options['data']['options']\n            # serialize 'data' to JSON, requests doesn't do this automatically:\n            request_options['data'] = json.dumps(request_options['data'])\n\n        headers = self.headers.copy()\n        headers.update(request_options.get('headers', {}))\n        request_options['headers'] = headers\n        return request_options"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nselects the provided keys out of an options object.", "response": "def _select_options(self, options, keys, invert=False):\n        \"\"\"Select the provided keys out of an options object.\n\n\n        Selects the provided keys (or everything except the provided keys) out\n        of an options object.\n\n        \"\"\"\n        options = self._merge_options(options)\n        result = {}\n        for key in options:\n            if (invert and key not in keys) or (not invert and key in keys):\n                result[key] = options[key]\n        return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates the client version header to send on each request.", "response": "def _version_header(self):\n        \"\"\"Generate the client version header to send on each request.\"\"\"\n        if not self._cached_version_header:\n            self._cached_version_header = urlparse.urlencode(\n                self._version_values())\n        return self._cached_version_header"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_by_id(self, webhook, params={}, **options): \n        path = \"/webhooks/%s\" % (webhook)\n        return self.client.get(path, params, **options)", "response": "Returns the full record for the given webhook."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef delete_by_id(self, webhook, params={}, **options): \n        path = \"/webhooks/%s\" % (webhook)\n        return self.client.delete(path, params, **options)", "response": "This method permanently removes a webhook. This method permanently removes a webhook."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndispatch a GET request to the events API to get a set of recent changes to a resource.", "response": "def get(self, params, **options):\n        \"\"\"Dispatches a GET request to /events of the API to get a set of recent changes to a resource.\"\"\"\n        options = self.client._merge_options({ 'full_payload': True })\n        return self.client.get('/events', params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_next(self, query, **options):\n        iterator = EventsPageIterator(self.client, '/events', query, options)\n        result = iterator.next()\n        return (result, iterator.sync)", "response": "Returns the next page of events and a sync token for the given query"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning an event iterator for the given query and optional sync token", "response": "def get_iterator(self, query, **options):\n        \"\"\"Returns an event iterator for the given query (and optional 'sync' token)\"\"\"\n        return EventsPageIterator(self.client, '/events', query, options).items()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a project shared with the given team. Returns the full record of the newly created project.", "response": "def create_in_team(self, team, params={}, **options): \n        \"\"\"Creates a project shared with the given team.\n        \n        Returns the full record of the newly created project.\n\n        Parameters\n        ----------\n        team : {Id} The team to create the project in.\n        [data] : {Object} Data for the request\n        \"\"\"\n        path = \"/teams/%s/projects\" % (team)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the complete project record for a single project.", "response": "def find_by_id(self, project, params={}, **options): \n        \"\"\"Returns the complete project record for a single project.\n\n        Parameters\n        ----------\n        project : {Id} The project to get.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/projects/%s\" % (project)\n        return self.client.get(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef update(self, project, params={}, **options): \n        path = \"/projects/%s\" % (project)\n        return self.client.put(path, params, **options)", "response": "A specific existing project can be updated by making a PUT request on the the\n        URL for that project. Returns the updated project record."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef delete(self, project, params={}, **options): \n        path = \"/projects/%s\" % (project)\n        return self.client.delete(path, params, **options)", "response": "A specific existing project can be deleted by making a DELETE request on the URL for that project. Returns an empty data record."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the compact project records for all projects in the team.", "response": "def find_by_team(self, team, params={}, **options): \n        \"\"\"Returns the compact project records for all projects in the team.\n\n        Parameters\n        ----------\n        team : {Id} The team to find projects in.\n        [params] : {Object} Parameters for the request\n          - [archived] : {Boolean} Only return projects whose `archived` field takes on the value of\n          this parameter.\n        \"\"\"\n        path = \"/teams/%s/projects\" % (team)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the compact task records for all tasks within the given project ordered by their priority within the given project.", "response": "def tasks(self, project, params={}, **options): \n        \"\"\"Returns the compact task records for all tasks within the given project,\n        ordered by their priority within the project. Tasks can exist in more than one project at a time.\n\n        Parameters\n        ----------\n        project : {Id} The project in which to search for tasks.\n        [params] : {Object} Parameters for the request\n        \"\"\"\n        path = \"/projects/%s/tasks\" % (project)\n        return self.client.get_collection(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding the specified list of users as followers to the project. Returns the updated project record.", "response": "def add_followers(self, project, params={}, **options): \n        \"\"\"Adds the specified list of users as followers to the project. Followers are a subset of members, therefore if\n        the users are not already members of the project they will also become members as a result of this operation.\n        Returns the updated project record.\n\n        Parameters\n        ----------\n        project : {Id} The project to add followers to.\n        [data] : {Object} Data for the request\n          - followers : {Array} An array of followers to add to the project.\n        \"\"\"\n        path = \"/projects/%s/addFollowers\" % (project)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the specified list of users from following the project. Returns the updated project record.", "response": "def remove_followers(self, project, params={}, **options): \n        \"\"\"Removes the specified list of users from following the project, this will not affect project membership status.\n        Returns the updated project record.\n\n        Parameters\n        ----------\n        project : {Id} The project to remove followers from.\n        [data] : {Object} Data for the request\n          - followers : {Array} An array of followers to remove from the project.\n        \"\"\"\n        path = \"/projects/%s/removeFollowers\" % (project)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_members(self, project, params={}, **options): \n        path = \"/projects/%s/addMembers\" % (project)\n        return self.client.post(path, params, **options)", "response": "Adds the specified list of users as members of the project. Returns the updated project record."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_members(self, project, params={}, **options): \n        path = \"/projects/%s/removeMembers\" % (project)\n        return self.client.post(path, params, **options)", "response": "Removes the specified list of members from the project. Returns the updated project record."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new custom field setting on the project.", "response": "def add_custom_field_setting(self, project, params={}, **options): \n        \"\"\"Create a new custom field setting on the project.\n\n        Parameters\n        ----------\n        project : {Id} The project to associate the custom field with\n        [data] : {Object} Data for the request\n          - custom_field : {Id} The id of the custom field to associate with this project.\n          - [is_important] : {Boolean} Whether this field should be considered important to this project.\n          - [insert_before] : {Id} An id of a Custom Field Settings on this project, before which the new Custom Field Settings will be added.\n          `insert_before` and `insert_after` parameters cannot both be specified.\n          - [insert_after] : {Id} An id of a Custom Field Settings on this project, after which the new Custom Field Settings will be added.\n          `insert_before` and `insert_after` parameters cannot both be specified.\n        \"\"\"\n        path = \"/projects/%s/addCustomFieldSetting\" % (project)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nremoving a custom field setting on the project.", "response": "def remove_custom_field_setting(self, project, params={}, **options): \n        \"\"\"Remove a custom field setting on the project.\n\n        Parameters\n        ----------\n        project : {Id} The project to associate the custom field with\n        [data] : {Object} Data for the request\n          - [custom_field] : {Id} The id of the custom field to remove from this project.\n        \"\"\"\n        path = \"/projects/%s/removeCustomFieldSetting\" % (project)\n        return self.client.post(path, params, **options)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_by_id(self, user, params={}, **options): \n        path = \"/users/%s\" % (user)\n        return self.client.get(path, params, **options)", "response": "Returns the full user record for the specified user."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef shipping_cost(request):\n    try:\n        code = request.query_params.get('country_code')\n    except AttributeError:\n        return Response(data={\"message\": \"No country code supplied\"},\n                        status=status.HTTP_400_BAD_REQUEST)\n\n    option = request.query_params.get('shipping_rate_name', 'standard')\n    try:\n        settings = Configuration.for_site(request.site)\n        data = utils.get_shipping_cost(settings, code, option)\n        response = Response(data=data, status=status.HTTP_200_OK)\n    except utils.InvalidShippingRate:\n        response = Response(data={\"message\": \"Shipping option {} is invalid\".format(option)},\n                            status=status.HTTP_400_BAD_REQUEST)\n    except utils.InvalidShippingCountry:\n        response = Response(data={\"message\": \"Shipping to {} is not available\".format(code)},\n                            status=status.HTTP_400_BAD_REQUEST)\n\n    return response", "response": "Returns the shipping cost for a given country"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all shipping countries", "response": "def shipping_countries(request):\n    \"\"\" Get all shipping countries\n    \"\"\"\n    queryset = models.Country.objects.exclude(shippingrate=None)\n    serializer = serializers.CountrySerializer(queryset, many=True)\n    return Response(data=serializer.data, status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shipping_options(request, country):\n    qrs = models.ShippingRate.objects.filter(countries__in=[country])\n    serializer = serializers.ShippingRateSerializer(qrs, many=True)\n    return Response(\n        data=serializer.data,\n        status=status.HTTP_200_OK\n    )", "response": "Returns a list of shipping options for a given country"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the shipping cost for a given country code and shipping option.", "response": "def get_shipping_cost(settings, country_code=None, name=None):\n    \"\"\"Return the shipping cost for a given country code and shipping option (shipping rate name)\n    \"\"\"\n    shipping_rate = None\n    if settings.default_shipping_enabled:\n        shipping_rate = {\n            \"rate\": settings.default_shipping_rate,\n            \"description\": \"Standard shipping to rest of world\",\n            \"carrier\": settings.default_shipping_carrier\n        }\n    elif not country_code:\n        raise InvalidShippingCountry\n\n    if country_code:\n        qrs = models.ShippingRate.objects.filter(countries__in=[country_code], name=name)\n        count = qrs.count()\n        if count == 1:\n            shipping_rate_qrs = qrs[0]\n        else:\n            raise InvalidShippingRate()\n        shipping_rate = {\n            \"rate\": shipping_rate_qrs.rate,\n            \"description\": shipping_rate_qrs.description,\n            \"carrier\": shipping_rate_qrs.carrier}\n    return shipping_rate"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new item in the basket", "response": "def create(self, request):\r\n        \"\"\"\r\n        Add an item to the basket\r\n        \"\"\"\r\n        variant_id = request.data.get(\"variant_id\", None)\r\n\r\n        if variant_id is not None:\r\n            variant = ProductVariant.objects.get(id=variant_id)\r\n\r\n            quantity = int(request.data.get(\"quantity\", 1))\r\n            items, bid = utils.get_basket_items(request)\r\n\r\n            # Check if the variant is already in the basket\r\n            in_basket = False\r\n            for item in items:\r\n                if item.variant.id == variant.id:\r\n                    item.increase_quantity(quantity)\r\n                    in_basket = True\r\n                    break\r\n            if not in_basket:\r\n                item = BasketItem(variant=variant, quantity=quantity, basket_id=bid)\r\n                item.save()\r\n\r\n            serializer = BasketItemSerializer(self.get_queryset(request), many=True)\r\n            response = Response(data=serializer.data,\r\n                                status=status.HTTP_201_CREATED)\r\n\r\n        else:\r\n            response = Response(\r\n                {\"message\": \"Missing 'variant_id'\"},\r\n                status=status.HTTP_400_BAD_REQUEST)\r\n\r\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef bulk_update(self, request):\r\n        # Delete everything in the basket\r\n        bid = utils.destroy_basket(request)\r\n\r\n        for item_data in request.data:\r\n            item = BasketItem(basket_id=bid, **item_data)\r\n            item.save()\r\n\r\n        serializer = BasketItemSerializer(self.get_queryset(request), many=True)\r\n        response = Response(data=serializer.data,\r\n                            status=status.HTTP_200_OK)\r\n        return response", "response": "Put multiple items in the basket remove anything that already exists\r\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves an item from the basket", "response": "def destroy(self, request, variant_id=None):\r\n        \"\"\"\r\n        Remove an item from the basket\r\n        \"\"\"\r\n        variant = ProductVariant.objects.get(id=variant_id)\r\n        quantity = int(request.data.get(\"quantity\", 1))\r\n        try:\r\n            item = BasketItem.objects.get(\r\n                basket_id=utils.basket_id(request), variant=variant)\r\n            item.decrease_quantity(quantity)\r\n        except BasketItem.DoesNotExist:\r\n            pass\r\n\r\n        serializer = BasketItemSerializer(self.get_queryset(request), many=True)\r\n        return Response(data=serializer.data,\r\n                        status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the total number of items in the basket", "response": "def total_items(self, request):\r\n        \"\"\"\r\n        Get total number of items in the basket\r\n        \"\"\"\r\n        n_total = 0\r\n        for item in self.get_queryset(request):\r\n            n_total += item.quantity\r\n\r\n        return Response(data={\"quantity\": n_total}, status=status.HTTP_200_OK)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef item_count(self, request, variant_id=None):\r\n        bid = utils.basket_id(request)\r\n        item = ProductVariant.objects.get(id=variant_id)\r\n        try:\r\n            count = BasketItem.objects.get(basket_id=bid, variant=item).quantity\r\n        except BasketItem.DoesNotExist:\r\n            count = 0\r\n        return Response(data={\"quantity\": count}, status=status.HTTP_200_OK)", "response": "Returns the number of items in the basket"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef compile_assets(self):\n        try:\n            # Move into client dir\n            curdir = os.path.abspath(os.curdir)\n            client_path = os.path.join(os.path.dirname(__file__), 'longclaw', 'client')\n            os.chdir(client_path)\n            subprocess.check_call(['npm', 'install'])\n            subprocess.check_call(['npm', 'run', 'build'])\n            os.chdir(curdir)\n        except (OSError, subprocess.CalledProcessError) as err:\n            print('Error compiling assets:  {}'.format(err))\n            raise SystemExit(1)", "response": "Compile the front end assets"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef requests_admin(request, pk):\n    page = Page.objects.get(pk=pk).specific\n    if hasattr(page, 'variants'):\n        requests = ProductRequest.objects.filter(\n            variant__in=page.variants.all()\n        )\n    else:\n        requests = ProductRequest.objects.filter(variant=page)\n    return render(\n        request,\n        \"productrequests/requests_admin.html\",\n        {'page': page, 'requests': requests}\n    )", "response": "Display the list of requests for a given product."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef refund_order(self, request, pk):\n        order = Order.objects.get(id=pk)\n        order.refund()\n        return Response(status=status.HTTP_204_NO_CONTENT)", "response": "Refund the order specified by the pk"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef fulfill_order(self, request, pk):\n        order = Order.objects.get(id=pk)\n        order.fulfill()\n        return Response(status=status.HTTP_204_NO_CONTENT)", "response": "Mark the order identified by pk as fulfilled"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrender a list of product requests button on the page index showing the number of times the product has been requested.", "response": "def product_requests_button(page, page_perms, is_parent=False):\n    \"\"\"Renders a 'requests' button on the page index showing the number\n    of times the product has been requested.\n\n    Attempts to only show such a button for valid product/variant pages\n    \"\"\"\n    # Is this page the 'product' model?\n    # It is generally safe to assume either the page will have a 'variants'\n    #  member or will be an instance of longclaw.utils.ProductVariant\n    if hasattr(page, 'variants') or isinstance(page, ProductVariant):\n        yield widgets.PageListingButton(\n            'View Requests',\n            reverse('productrequests_admin', kwargs={'pk': page.id}),\n            priority=40\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gateway_client_js():\n    javascripts = GATEWAY.client_js()\n    if isinstance(javascripts, (tuple, list)):\n        tags = []\n        for js in javascripts:\n            tags.append('<script type=\"text/javascript\" src=\"{}\"></script>'.format(js))\n        return tags\n    else:\n        raise TypeError(\n            'function client_js of {} must return a list or tuple'.format(GATEWAY.__name__))", "response": "Returns a list of javascript tags that provides a script tag for each javascript item required by the payment gateway"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets all items in the basket", "response": "def get_basket_items(request):\r\n    \"\"\"\r\n    Get all items in the basket\r\n    \"\"\"\r\n    bid = basket_id(request)\r\n    return BasketItem.objects.filter(basket_id=bid), bid"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting all items in the basket", "response": "def destroy_basket(request):\r\n    \"\"\"Delete all items in the basket\r\n    \"\"\"\r\n    items, bid = get_basket_items(request)\r\n    for item in items:\r\n        item.delete()\r\n    return bid"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shipping_rate(context, **kwargs):\n    settings = Configuration.for_site(context[\"request\"].site)\n    code = kwargs.get('code', None)\n    name = kwargs.get('name', None)\n    return get_shipping_cost(settings, code, name)", "response": "Returns the shipping rate for a country & shipping option name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the price range of the products variants", "response": "def price_range(self):\n        \"\"\" Calculate the price range of the products variants\n        \"\"\"\n        ordered = self.variants.order_by('base_price')\n        if ordered:\n            return ordered.first().price, ordered.last().price\n        else:\n            return None, None"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncreates a new django project using the longclaw template", "response": "def create_project(args):\n    \"\"\"\n    Create a new django project using the longclaw template\n    \"\"\"\n\n    # Make sure given name is not already in use by another python package/module.\n    try:\n        __import__(args.project_name)\n    except ImportError:\n        pass\n    else:\n        sys.exit(\"'{}' conflicts with the name of an existing \"\n                 \"Python module and cannot be used as a project \"\n                 \"name. Please try another name.\".format(args.project_name))\n\n    # Get the longclaw template path\n    template_path = path.join(path.dirname(longclaw.__file__), 'project_template')\n\n    utility = ManagementUtility((\n        'django-admin.py',\n        'startproject',\n        '--template={}'.format(template_path),\n        '--extension=html,css,js,py,txt',\n        args.project_name\n    ))\n    utility.execute()\n    print(\"{} has been created.\".format(args.project_name))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nbuilds the longclaw assets", "response": "def build_assets(args):\n    \"\"\"\n    Build the longclaw assets\n    \"\"\"\n    # Get the path to the JS directory\n    asset_path = path.join(path.dirname(longclaw.__file__), 'client')\n    try:\n        # Move into client dir\n        curdir = os.path.abspath(os.curdir)\n        os.chdir(asset_path)\n        print('Compiling assets....')\n        subprocess.check_call(['npm', 'install'])\n        subprocess.check_call(['npm', 'run', 'build'])\n        os.chdir(curdir)\n        print('Complete!')\n    except (OSError, subprocess.CalledProcessError) as err:\n        print('Error compiling assets:  {}'.format(err))\n        raise SystemExit(1)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    parser = argparse.ArgumentParser(description='Longclaw CLI')\n    subparsers = parser.add_subparsers()\n    start = subparsers.add_parser('start', help='Create a Wagtail+Longclaw project')\n    start.add_argument('project_name', help='Name of the project')\n    start.set_defaults(func=create_project)\n\n    build = subparsers.add_parser('build', help='Build the front-end assets for Longclaw')\n    build.set_defaults(func=build_assets)\n\n    args = parser.parse_args()\n\n    # Python 3 lost the default behaviour to fall back to printing\n    # help if a subparser is not selected.\n    # See: https://bugs.python.org/issue16308\n    # So we must explicitly catch the error thrown on py3 if\n    # no commands given to longclaw\n    try:\n        args.func(args)\n    except AttributeError:\n        parser.print_help()\n        sys.exit(0)", "response": "Main function for longclaw command line"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget all sales for a given time period", "response": "def sales_for_time_period(from_date, to_date):\n    \"\"\"\n    Get all sales for a given time period\n    \"\"\"\n    sales = Order.objects.filter(\n        Q(payment_date__lte=to_date) & Q(payment_date__gte=from_date)\n    ).exclude(status=Order.CANCELLED)\n\n    return sales"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef create_token(request):\n    token = GATEWAY.get_token(request)\n    return Response({'token': token}, status=status.HTTP_200_OK)", "response": "Create a payment token from the current backend"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_order_with_token(request):\n    # Get the request data\n    try:\n        address = request.data['address']\n        shipping_option = request.data.get('shipping_option', None)\n        email = request.data['email']\n        transaction_id = request.data['transaction_id']\n    except KeyError:\n        return Response(data={\"message\": \"Missing parameters from request data\"},\n                        status=status.HTTP_400_BAD_REQUEST)\n\n    # Create the order\n    order = create_order(\n        email,\n        request,\n        addresses=address,\n        shipping_option=shipping_option,\n    )\n\n    order.payment_date = timezone.now()\n    order.transaction_id = transaction_id\n    order.save()\n    # Once the order has been successfully taken, we can empty the basket\n    destroy_basket(request)\n\n    return Response(data={\"order_id\": order.id}, status=status.HTTP_201_CREATED)", "response": "Create an order using an existing transaction ID"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncaptures the payment for a basket and create an order", "response": "def capture_payment(request):\n    \"\"\"\n    Capture the payment for a basket and create an order\n\n    request.data should contain:\n\n    'address': Dict with the following fields:\n        shipping_name\n        shipping_address_line1\n        shipping_address_city\n        shipping_address_zip\n        shipping_address_country\n        billing_name\n        billing_address_line1\n        billing_address_city\n        billing_address_zip\n        billing_address_country\n\n    'email': Email address of the customer\n    'shipping': The shipping rate (in the sites' currency)\n    \"\"\"\n    # get request data\n    address = request.data['address']\n    email = request.data.get('email', None)\n    shipping_option = request.data.get('shipping_option', None)\n\n    # Capture the payment\n    order = create_order(\n        email,\n        request,\n        addresses=address,\n        shipping_option=shipping_option,\n        capture_payment=True\n    )\n    response = Response(data={\"order_id\": order.id},\n                        status=status.HTTP_201_CREATED)\n\n    return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_order(email,\n                 request,\n                 addresses=None,\n                 shipping_address=None,\n                 billing_address=None,\n                 shipping_option=None,\n                 capture_payment=False):\n    \"\"\"\n    Create an order from a basket and customer infomation\n    \"\"\"\n    basket_items, _ = get_basket_items(request)\n    if addresses:\n        # Longclaw < 0.2 used 'shipping_name', longclaw > 0.2 uses a consistent\n        # prefix (shipping_address_xxxx)\n        try:\n            shipping_name = addresses['shipping_name']\n        except KeyError:\n            shipping_name = addresses['shipping_address_name']\n\n        shipping_country = addresses['shipping_address_country']\n        if not shipping_country:\n            shipping_country = None\n        shipping_address, _ = Address.objects.get_or_create(name=shipping_name,\n                                                            line_1=addresses[\n                                                                'shipping_address_line1'],\n                                                            city=addresses[\n                                                                'shipping_address_city'],\n                                                            postcode=addresses[\n                                                                'shipping_address_zip'],\n                                                            country=shipping_country)\n        shipping_address.save()\n        try:\n            billing_name = addresses['billing_name']\n        except KeyError:\n            billing_name = addresses['billing_address_name']\n        billing_country = addresses['shipping_address_country']\n        if not billing_country:\n            billing_country = None\n        billing_address, _ = Address.objects.get_or_create(name=billing_name,\n                                                           line_1=addresses[\n                                                               'billing_address_line1'],\n                                                           city=addresses[\n                                                               'billing_address_city'],\n                                                           postcode=addresses[\n                                                               'billing_address_zip'],\n                                                           country=billing_country)\n        billing_address.save()\n    else:\n        shipping_country = shipping_address.country\n\n    ip_address = get_real_ip(request)\n    if shipping_country and shipping_option:\n        site_settings = Configuration.for_site(request.site)\n        shipping_rate = get_shipping_cost(\n            site_settings,\n            shipping_address.country.pk,\n            shipping_option)['rate']\n    else:\n        shipping_rate = Decimal(0)\n\n    order = Order(\n        email=email,\n        ip_address=ip_address,\n        shipping_address=shipping_address,\n        billing_address=billing_address,\n        shipping_rate=shipping_rate\n    )\n    order.save()\n\n    # Create the order items & compute total\n    total = 0\n    for item in basket_items:\n        total += item.total()\n        order_item = OrderItem(\n            product=item.variant,\n            quantity=item.quantity,\n            order=order\n        )\n        order_item.save()\n\n    if capture_payment:\n        desc = 'Payment from {} for order id #{}'.format(email, order.id)\n        try:\n            transaction_id = GATEWAY.create_payment(request,\n                                                    total + shipping_rate,\n                                                    description=desc)\n            order.payment_date = timezone.now()\n            order.transaction_id = transaction_id\n            # Once the order has been successfully taken, we can empty the basket\n            destroy_basket(request)\n        except PaymentError:\n            order.status = order.FAILURE\n\n        order.save()\n\n    return order", "response": "Create an order from a basket and customer infomation"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create(self, request):\n\n        variant_id = request.data.get(\"variant_id\", None)\n        if variant_id is not None:\n            variant = ProductVariant.objects.get(id=variant_id)\n            product_request = ProductRequest(variant=variant)\n            product_request.save()\n            serializer = self.serializer_class(product_request)\n            response = Response(data=serializer.data, status=status.HTTP_201_CREATED)\n        else:\n            response = Response(\n                {\"message\": \"Missing 'variant_id'\"},\n                status=status.HTTP_400_BAD_REQUEST)\n\n        return response", "response": "Create a new product request"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef requests_for_variant(self, request, variant_id=None):\n        requests = ProductRequest.objects.filter(variant__id=variant_id)\n        serializer = self.serializer_class(requests, many=True)\n        return Response(data=serializer.data, status=status.HTTP_200_OK)", "response": "Get all the requests for a single variant"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef clean(self):\r\n        if self.request:\r\n            if not self.request.session.test_cookie_worked():\r\n                raise forms.ValidationError(\"Cookies must be enabled.\")\r\n        return self.cleaned_data", "response": "Check user has cookies enabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef detail_view(self, request, instance_pk):\n        kwargs = {'model_admin': self, 'instance_pk': instance_pk}\n        view_class = self.detail_view_class\n        return view_class.as_view(**kwargs)(request)", "response": "Instantiates a class - based view to provide detail functionality for the assigned model."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_admin_urls_for_registration(self):\n        urls = super(OrderModelAdmin, self).get_admin_urls_for_registration()\n        urls = urls + (\n            url(self.url_helper.get_action_url_pattern('detail'),\n                self.detail_view,\n                name=self.url_helper.get_action_url_name('detail')),\n        )\n        return urls", "response": "This method is used by Wagtail s register_admin_urls hook to register urls for the order model admin."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_token(self, request):\n        return stripe.Token.create(\n            card={\n                \"number\": request.data[\"number\"],\n                \"exp_month\": request.data[\"exp_month\"],\n                \"exp_year\": request.data[\"exp_year\"],\n                \"cvc\": request.data[\"cvc\"]\n\n            }\n        )", "response": "Create a stripe token for a card"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef total(self):\n        total = 0\n        for item in self.items.all():\n            total += item.total\n        return total", "response": "Total cost of the order\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nissues a full refund for this order", "response": "def refund(self):\n        \"\"\"Issue a full refund for this order\n        \"\"\"\n        from longclaw.utils import GATEWAY\n        now = datetime.strftime(datetime.now(), \"%b %d %Y %H:%M:%S\")\n        if GATEWAY.issue_refund(self.transaction_id, self.total):\n            self.status = self.REFUNDED\n            self.status_note = \"Refunded on {}\".format(now)\n        else:\n            self.status_note = \"Refund failed on {}\".format(now)\n        self.save()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cancel(self, refund=True):\n        if refund:\n            self.refund()\n        self.status = self.CANCELLED\n        self.save()", "response": "Cancel this order optionally refunding it\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef attribute_name(self, attribute_name):\n\n        if attribute_name is None:\n            raise ValueError(\"Invalid value for `attribute_name`, must not be `None`\")\n        if len(attribute_name) < 1:\n            raise ValueError(\"Invalid value for `attribute_name`, length must be greater than or equal to `1`\")\n\n        self._attribute_name = attribute_name", "response": "Sets the attribute_name of this CatalogQueryRange."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the idempotency_key of this BatchUpsertCatalogObjectsRequest.", "response": "def idempotency_key(self, idempotency_key):\n        \"\"\"\n        Sets the idempotency_key of this BatchUpsertCatalogObjectsRequest.\n        A value you specify that uniquely identifies this request among all your requests. A common way to create a valid idempotency key is to use a Universally unique identifier (UUID).  If you're unsure whether a particular request was successful, you can reattempt it with the same idempotency key without worrying about creating duplicate objects.  See [Idempotency](/basics/api101/idempotency) for more information.\n\n        :param idempotency_key: The idempotency_key of this BatchUpsertCatalogObjectsRequest.\n        :type: str\n        \"\"\"\n\n        if idempotency_key is None:\n            raise ValueError(\"Invalid value for `idempotency_key`, must not be `None`\")\n        if len(idempotency_key) < 1:\n            raise ValueError(\"Invalid value for `idempotency_key`, length must be greater than or equal to `1`\")\n\n        self._idempotency_key = idempotency_key"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef start_of_day_local_time(self, start_of_day_local_time):\n\n        if start_of_day_local_time is None:\n            raise ValueError(\"Invalid value for `start_of_day_local_time`, must not be `None`\")\n        if len(start_of_day_local_time) < 1:\n            raise ValueError(\"Invalid value for `start_of_day_local_time`, length must be greater than or equal to `1`\")\n\n        self._start_of_day_local_time = start_of_day_local_time", "response": "Sets the start_of_day_local_time of this WorkweekConfig."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef request(self, method, url, query_params=None, headers=None,\n                body=None, post_params=None):\n        \"\"\"\n        :param method: http request method\n        :param url: http request url\n        :param query_params: query parameters in the url\n        :param headers: http request headers\n        :param body: request json body, for `application/json`\n        :param post_params: request post parameters,\n                            `application/x-www-form-urlencode`\n                            and `multipart/form-data`\n        \"\"\"\n        method = method.upper()\n        assert method in ['GET', 'HEAD', 'DELETE', 'POST', 'PUT', 'PATCH', 'OPTIONS']\n\n        if post_params and body:\n            raise ValueError(\n                \"body parameter cannot be used with post_params parameter.\"\n            )\n\n        post_params = post_params or {}\n        headers = headers or {}\n\n        if 'Content-Type' not in headers:\n            headers['Content-Type'] = 'application/json'\n\n        try:\n            # For `POST`, `PUT`, `PATCH`, `OPTIONS`, `DELETE`\n            if method in ['POST', 'PUT', 'PATCH', 'OPTIONS', 'DELETE']:\n                if query_params:\n                    url += '?' + urlencode(query_params)\n                if headers['Content-Type'] == 'application/json':\n                    request_body = None\n                    if body is not None:\n                        request_body = json.dumps(body)\n                    r = self.pool_manager.request(method, url,\n                                                  body=request_body,\n                                                  headers=headers)\n                if headers['Content-Type'] == 'application/x-www-form-urlencoded':\n                    r = self.pool_manager.request(method, url,\n                                                  fields=post_params,\n                                                  encode_multipart=False,\n                                                  headers=headers)\n                if headers['Content-Type'] == 'multipart/form-data':\n                    # must del headers['Content-Type'], or the correct Content-Type\n                    # which generated by urllib3 will be overwritten.\n                    del headers['Content-Type']\n                    r = self.pool_manager.request(method, url,\n                                                  fields=post_params,\n                                                  encode_multipart=True,\n                                                  headers=headers)\n            # For `GET`, `HEAD`\n            else:\n                r = self.pool_manager.request(method, url,\n                                              fields=query_params,\n                                              headers=headers,\n                                              preload_content=False)\n\n        except urllib3.exceptions.SSLError as e:\n            msg = \"{0}\\n{1}\".format(type(e).__name__, str(e))\n            raise ApiException(status=0, reason=msg)\n\n        r = RESTResponse(r, method)\n\n        # log response body\n        logger.debug(\"response body: %s\" % r.data)\n\n        if r.status not in range(200, 206):\n            raise ApiException(http_resp=r)\n\n        return r", "response": "This method is used to make a request to the specified url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef catalog_object_id(self, catalog_object_id):\n\n        if catalog_object_id is None:\n            raise ValueError(\"Invalid value for `catalog_object_id`, must not be `None`\")\n        if len(catalog_object_id) > 192:\n            raise ValueError(\"Invalid value for `catalog_object_id`, length must be less than `192`\")\n\n        self._catalog_object_id = catalog_object_id", "response": "Sets the catalog_object_id of this CreateOrderRequestModifier."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the domain_name of this RegisterDomainRequest.", "response": "def domain_name(self, domain_name):\n        \"\"\"\n        Sets the domain_name of this RegisterDomainRequest.\n        A domain name as described in RFC-1034 that will be registered with ApplePay\n\n        :param domain_name: The domain_name of this RegisterDomainRequest.\n        :type: str\n        \"\"\"\n\n        if domain_name is None:\n            raise ValueError(\"Invalid value for `domain_name`, must not be `None`\")\n        if len(domain_name) > 255:\n            raise ValueError(\"Invalid value for `domain_name`, length must be less than `255`\")\n        if len(domain_name) < 1:\n            raise ValueError(\"Invalid value for `domain_name`, length must be greater than or equal to `1`\")\n\n        self._domain_name = domain_name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef attribute_prefix(self, attribute_prefix):\n\n        if attribute_prefix is None:\n            raise ValueError(\"Invalid value for `attribute_prefix`, must not be `None`\")\n        if len(attribute_prefix) < 1:\n            raise ValueError(\"Invalid value for `attribute_prefix`, length must be greater than or equal to `1`\")\n\n        self._attribute_prefix = attribute_prefix", "response": "Sets the attribute_prefix of this CatalogQueryPrefix."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef id(self, id):\n\n        if id is None:\n            raise ValueError(\"Invalid value for `id`, must not be `None`\")\n        if len(id) > 255:\n            raise ValueError(\"Invalid value for `id`, length must be less than `255`\")\n\n        self._id = id", "response": "Sets the id of this Shift.\n        UUID for this object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef employee_id(self, employee_id):\n\n        if employee_id is None:\n            raise ValueError(\"Invalid value for `employee_id`, must not be `None`\")\n        if len(employee_id) < 1:\n            raise ValueError(\"Invalid value for `employee_id`, length must be greater than or equal to `1`\")\n\n        self._employee_id = employee_id", "response": "Sets the employee_id of this Shift."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the start_at of this Shift.", "response": "def start_at(self, start_at):\n        \"\"\"\n        Sets the start_at of this Shift.\n        RFC 3339; shifted to location timezone + offset. Precision up to the minute is respected; seconds are truncated.\n\n        :param start_at: The start_at of this Shift.\n        :type: str\n        \"\"\"\n\n        if start_at is None:\n            raise ValueError(\"Invalid value for `start_at`, must not be `None`\")\n        if len(start_at) < 1:\n            raise ValueError(\"Invalid value for `start_at`, length must be greater than or equal to `1`\")\n\n        self._start_at = start_at"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef percentage(self, percentage):\n\n        if percentage is None:\n            raise ValueError(\"Invalid value for `percentage`, must not be `None`\")\n        if len(percentage) > 10:\n            raise ValueError(\"Invalid value for `percentage`, length must be less than `10`\")\n\n        self._percentage = percentage", "response": "Sets the percentage of the order line entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef modifier_list_id(self, modifier_list_id):\n\n        if modifier_list_id is None:\n            raise ValueError(\"Invalid value for `modifier_list_id`, must not be `None`\")\n        if len(modifier_list_id) < 1:\n            raise ValueError(\"Invalid value for `modifier_list_id`, length must be greater than or equal to `1`\")\n\n        self._modifier_list_id = modifier_list_id", "response": "Sets the modifier_list_id of this CatalogItemModifierListInfo."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the location_id of this Order.", "response": "def location_id(self, location_id):\n        \"\"\"\n        Sets the location_id of this Order.\n        The ID of the merchant location this order is associated with.\n\n        :param location_id: The location_id of this Order.\n        :type: str\n        \"\"\"\n\n        if location_id is None:\n            raise ValueError(\"Invalid value for `location_id`, must not be `None`\")\n        if len(location_id) < 1:\n            raise ValueError(\"Invalid value for `location_id`, length must be greater than or equal to `1`\")\n\n        self._location_id = location_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the reference_id of this Order.", "response": "def reference_id(self, reference_id):\n        \"\"\"\n        Sets the reference_id of this Order.\n        A client specified identifier to associate an entity in another system with this order.\n\n        :param reference_id: The reference_id of this Order.\n        :type: str\n        \"\"\"\n\n        if reference_id is None:\n            raise ValueError(\"Invalid value for `reference_id`, must not be `None`\")\n        if len(reference_id) > 40:\n            raise ValueError(\"Invalid value for `reference_id`, length must be less than `40`\")\n\n        self._reference_id = reference_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the note of this OrderFulfillmentPickupDetails.", "response": "def note(self, note):\n        \"\"\"\n        Sets the note of this OrderFulfillmentPickupDetails.\n        A general note about the pickup fulfillment.  Notes are useful for providing additional instructions and are displayed in Square apps.\n\n        :param note: The note of this OrderFulfillmentPickupDetails.\n        :type: str\n        \"\"\"\n\n        if note is None:\n            raise ValueError(\"Invalid value for `note`, must not be `None`\")\n        if len(note) > 500:\n            raise ValueError(\"Invalid value for `note`, length must be less than `500`\")\n\n        self._note = note"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the cancel_reason of this OrderFulfillmentPickupDetails.", "response": "def cancel_reason(self, cancel_reason):\n        \"\"\"\n        Sets the cancel_reason of this OrderFulfillmentPickupDetails.\n        A description of why the pickup was canceled. Max length is 100 characters.\n\n        :param cancel_reason: The cancel_reason of this OrderFulfillmentPickupDetails.\n        :type: str\n        \"\"\"\n\n        if cancel_reason is None:\n            raise ValueError(\"Invalid value for `cancel_reason`, must not be `None`\")\n        if len(cancel_reason) > 100:\n            raise ValueError(\"Invalid value for `cancel_reason`, length must be less than `100`\")\n\n        self._cancel_reason = cancel_reason"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nset the modifier_id of this CatalogModifierOverride.", "response": "def modifier_id(self, modifier_id):\n        \"\"\"\n        Sets the modifier_id of this CatalogModifierOverride.\n        The ID of the [CatalogModifier](#type-catalogmodifier) whose default behavior is being overridden.\n\n        :param modifier_id: The modifier_id of this CatalogModifierOverride.\n        :type: str\n        \"\"\"\n\n        if modifier_id is None:\n            raise ValueError(\"Invalid value for `modifier_id`, must not be `None`\")\n        if len(modifier_id) < 1:\n            raise ValueError(\"Invalid value for `modifier_id`, length must be greater than or equal to `1`\")\n\n        self._modifier_id = modifier_id"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the merchant_support_email of this CreateCheckoutRequest.", "response": "def merchant_support_email(self, merchant_support_email):\n        \"\"\"\n        Sets the merchant_support_email of this CreateCheckoutRequest.\n        The email address to display on the Square Checkout confirmation page and confirmation email that the buyer can use to contact the merchant.  If this value is not set, the confirmation page and email will display the primary email address associated with the merchant's Square account.  Default: none; only exists if explicitly set.\n\n        :param merchant_support_email: The merchant_support_email of this CreateCheckoutRequest.\n        :type: str\n        \"\"\"\n\n        if merchant_support_email is None:\n            raise ValueError(\"Invalid value for `merchant_support_email`, must not be `None`\")\n        if len(merchant_support_email) > 254:\n            raise ValueError(\"Invalid value for `merchant_support_email`, length must be less than `254`\")\n\n        self._merchant_support_email = merchant_support_email"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pre_populate_buyer_email(self, pre_populate_buyer_email):\n\n        if pre_populate_buyer_email is None:\n            raise ValueError(\"Invalid value for `pre_populate_buyer_email`, must not be `None`\")\n        if len(pre_populate_buyer_email) > 254:\n            raise ValueError(\"Invalid value for `pre_populate_buyer_email`, length must be less than `254`\")\n\n        self._pre_populate_buyer_email = pre_populate_buyer_email", "response": "Sets the pre_populate_buyer_email of this CreateCheckoutRequest."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the redirect_url of this CreateCheckoutRequest.", "response": "def redirect_url(self, redirect_url):\n        \"\"\"\n        Sets the redirect_url of this CreateCheckoutRequest.\n        The URL to redirect to after checkout is completed with `checkoutId`, Square's `orderId`, `transactionId`, and `referenceId` appended as URL parameters. For example, if the provided redirect_url is `http://www.example.com/order-complete`, a successful transaction redirects the customer to:  `http://www.example.com/order-complete?checkoutId=xxxxxx&orderId=xxxxxx&referenceId=xxxxxx&transactionId=xxxxxx`  If you do not provide a redirect URL, Square Checkout will display an order confirmation page on your behalf; however Square strongly recommends that you provide a redirect URL so you can verify the transaction results and finalize the order through your existing/normal confirmation workflow.  Default: none; only exists if explicitly set.\n\n        :param redirect_url: The redirect_url of this CreateCheckoutRequest.\n        :type: str\n        \"\"\"\n\n        if redirect_url is None:\n            raise ValueError(\"Invalid value for `redirect_url`, must not be `None`\")\n        if len(redirect_url) > 800:\n            raise ValueError(\"Invalid value for `redirect_url`, length must be less than `800`\")\n\n        self._redirect_url = redirect_url"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef description(self, description):\n\n        if description is None:\n            raise ValueError(\"Invalid value for `description`, must not be `None`\")\n        if len(description) > 100:\n            raise ValueError(\"Invalid value for `description`, length must be less than `100`\")\n        if len(description) < 1:\n            raise ValueError(\"Invalid value for `description`, length must be greater than or equal to `1`\")\n\n        self._description = description", "response": "Sets the description of this AdditionalRecipient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the break_type_id of this ModelBreak.", "response": "def break_type_id(self, break_type_id):\n        \"\"\"\n        Sets the break_type_id of this ModelBreak.\n        The `BreakType` this `Break` was templated on.\n\n        :param break_type_id: The break_type_id of this ModelBreak.\n        :type: str\n        \"\"\"\n\n        if break_type_id is None:\n            raise ValueError(\"Invalid value for `break_type_id`, must not be `None`\")\n        if len(break_type_id) < 1:\n            raise ValueError(\"Invalid value for `break_type_id`, length must be greater than or equal to `1`\")\n\n        self._break_type_id = break_type_id"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the expected_duration of this ModelBreak.", "response": "def expected_duration(self, expected_duration):\n        \"\"\"\n        Sets the expected_duration of this ModelBreak.\n        Format: RFC-3339 P[n]Y[n]M[n]DT[n]H[n]M[n]S. The expected length of the break.\n\n        :param expected_duration: The expected_duration of this ModelBreak.\n        :type: str\n        \"\"\"\n\n        if expected_duration is None:\n            raise ValueError(\"Invalid value for `expected_duration`, must not be `None`\")\n        if len(expected_duration) < 1:\n            raise ValueError(\"Invalid value for `expected_duration`, length must be greater than or equal to `1`\")\n\n        self._expected_duration = expected_duration"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef limit(self, limit):\n\n        if limit is None:\n            raise ValueError(\"Invalid value for `limit`, must not be `None`\")\n        if limit > 200:\n            raise ValueError(\"Invalid value for `limit`, must be a value less than or equal to `200`\")\n        if limit < 1:\n            raise ValueError(\"Invalid value for `limit`, must be a value greater than or equal to `1`\")\n\n        self._limit = limit", "response": "Sets the limit of this ListEmployeeWagesRequest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef receivable_id(self, receivable_id):\n\n        if receivable_id is None:\n            raise ValueError(\"Invalid value for `receivable_id`, must not be `None`\")\n        if len(receivable_id) < 1:\n            raise ValueError(\"Invalid value for `receivable_id`, length must be greater than or equal to `1`\")\n\n        self._receivable_id = receivable_id", "response": "Sets the receivable_id of this AdditionalRecipientReceivableRefund. The receivable_id of this AdditionalRecipientReceivableRefund."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef refund_id(self, refund_id):\n\n        if refund_id is None:\n            raise ValueError(\"Invalid value for `refund_id`, must not be `None`\")\n        if len(refund_id) < 1:\n            raise ValueError(\"Invalid value for `refund_id`, length must be greater than or equal to `1`\")\n\n        self._refund_id = refund_id", "response": "Sets the refund_id of this AdditionalRecipientReceivableRefund. The ID of the refund that is associated to this receivable refund."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the transaction_location_id of this AdditionalRecipientReceivableRefund. The location ID of the receivable that created the receivable.", "response": "def transaction_location_id(self, transaction_location_id):\n        \"\"\"\n        Sets the transaction_location_id of this AdditionalRecipientReceivableRefund.\n        The ID of the location that created the receivable. This is the location ID on the associated transaction.\n\n        :param transaction_location_id: The transaction_location_id of this AdditionalRecipientReceivableRefund.\n        :type: str\n        \"\"\"\n\n        if transaction_location_id is None:\n            raise ValueError(\"Invalid value for `transaction_location_id`, must not be `None`\")\n        if len(transaction_location_id) < 1:\n            raise ValueError(\"Invalid value for `transaction_location_id`, length must be greater than or equal to `1`\")\n\n        self._transaction_location_id = transaction_location_id"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef card_nonce(self, card_nonce):\n\n        if card_nonce is None:\n            raise ValueError(\"Invalid value for `card_nonce`, must not be `None`\")\n        if len(card_nonce) > 192:\n            raise ValueError(\"Invalid value for `card_nonce`, length must be less than `192`\")\n\n        self._card_nonce = card_nonce", "response": "Sets the card_nonce of this ChargeRequest."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsetting the customer_card_id of this ChargeRequest.", "response": "def customer_card_id(self, customer_card_id):\n        \"\"\"\n        Sets the customer_card_id of this ChargeRequest.\n        The ID of the customer card on file to charge. Do not provide a value for this field if you provide a value for `card_nonce`.  If you provide this value, you _must_ also provide a value for `customer_id`.\n\n        :param customer_card_id: The customer_card_id of this ChargeRequest.\n        :type: str\n        \"\"\"\n\n        if customer_card_id is None:\n            raise ValueError(\"Invalid value for `customer_card_id`, must not be `None`\")\n        if len(customer_card_id) > 192:\n            raise ValueError(\"Invalid value for `customer_card_id`, length must be less than `192`\")\n\n        self._customer_card_id = customer_card_id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the customer_id of this ChargeRequest.", "response": "def customer_id(self, customer_id):\n        \"\"\"\n        Sets the customer_id of this ChargeRequest.\n        The ID of the customer to associate this transaction with. This field is required if you provide a value for `customer_card_id`, and optional otherwise.\n\n        :param customer_id: The customer_id of this ChargeRequest.\n        :type: str\n        \"\"\"\n\n        if customer_id is None:\n            raise ValueError(\"Invalid value for `customer_id`, must not be `None`\")\n        if len(customer_id) > 50:\n            raise ValueError(\"Invalid value for `customer_id`, length must be less than `50`\")\n\n        self._customer_id = customer_id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef order_id(self, order_id):\n\n        if order_id is None:\n            raise ValueError(\"Invalid value for `order_id`, must not be `None`\")\n        if len(order_id) > 192:\n            raise ValueError(\"Invalid value for `order_id`, length must be less than `192`\")\n\n        self._order_id = order_id", "response": "Sets the order_id of this ChargeRequest."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the quantity of this OrderLineItem.", "response": "def quantity(self, quantity):\n        \"\"\"\n        Sets the quantity of this OrderLineItem.\n        The quantity purchased, as a string representation of a number.  This string must have a positive integer value.\n\n        :param quantity: The quantity of this OrderLineItem.\n        :type: str\n        \"\"\"\n\n        if quantity is None:\n            raise ValueError(\"Invalid value for `quantity`, must not be `None`\")\n        if len(quantity) > 5:\n            raise ValueError(\"Invalid value for `quantity`, length must be less than `5`\")\n        if len(quantity) < 1:\n            raise ValueError(\"Invalid value for `quantity`, length must be greater than or equal to `1`\")\n\n        self._quantity = quantity"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsets the variation_name of this OrderLineItem.", "response": "def variation_name(self, variation_name):\n        \"\"\"\n        Sets the variation_name of this OrderLineItem.\n        The name of the variation applied to this line item.\n\n        :param variation_name: The variation_name of this OrderLineItem.\n        :type: str\n        \"\"\"\n\n        if variation_name is None:\n            raise ValueError(\"Invalid value for `variation_name`, must not be `None`\")\n        if len(variation_name) > 255:\n            raise ValueError(\"Invalid value for `variation_name`, length must be less than `255`\")\n\n        self._variation_name = variation_name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transaction_id(self, transaction_id):\n\n        if transaction_id is None:\n            raise ValueError(\"Invalid value for `transaction_id`, must not be `None`\")\n        if len(transaction_id) < 1:\n            raise ValueError(\"Invalid value for `transaction_id`, length must be greater than or equal to `1`\")\n\n        self._transaction_id = transaction_id", "response": "Sets the transaction_id of this AdditionalRecipientReceivable."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef page_index(self, page_index):\n\n        if page_index is None:\n            raise ValueError(\"Invalid value for `page_index`, must not be `None`\")\n        if page_index > 6:\n            raise ValueError(\"Invalid value for `page_index`, must be a value less than or equal to `6`\")\n        if page_index < 0:\n            raise ValueError(\"Invalid value for `page_index`, must be a value greater than or equal to `0`\")\n\n        self._page_index = page_index", "response": "Sets the page_index of this V1Page."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the break_name of this BreakType.", "response": "def break_name(self, break_name):\n        \"\"\"\n        Sets the break_name of this BreakType.\n        A human-readable name for this type of break. Will be displayed to employees in Square products.\n\n        :param break_name: The break_name of this BreakType.\n        :type: str\n        \"\"\"\n\n        if break_name is None:\n            raise ValueError(\"Invalid value for `break_name`, must not be `None`\")\n        if len(break_name) < 1:\n            raise ValueError(\"Invalid value for `break_name`, length must be greater than or equal to `1`\")\n\n        self._break_name = break_name"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the display_name of this OrderFulfillmentRecipient.", "response": "def display_name(self, display_name):\n        \"\"\"\n        Sets the display_name of this OrderFulfillmentRecipient.\n        The display name of the fulfillment recipient.  If provided, overrides the value from customer profile indicated by customer_id.\n\n        :param display_name: The display_name of this OrderFulfillmentRecipient.\n        :type: str\n        \"\"\"\n\n        if display_name is None:\n            raise ValueError(\"Invalid value for `display_name`, must not be `None`\")\n        if len(display_name) > 255:\n            raise ValueError(\"Invalid value for `display_name`, length must be less than `255`\")\n\n        self._display_name = display_name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef email_address(self, email_address):\n\n        if email_address is None:\n            raise ValueError(\"Invalid value for `email_address`, must not be `None`\")\n        if len(email_address) > 255:\n            raise ValueError(\"Invalid value for `email_address`, length must be less than `255`\")\n\n        self._email_address = email_address", "response": "Sets the email_address of this OrderFulfillmentRecipient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef phone_number(self, phone_number):\n\n        if phone_number is None:\n            raise ValueError(\"Invalid value for `phone_number`, must not be `None`\")\n        if len(phone_number) > 16:\n            raise ValueError(\"Invalid value for `phone_number`, length must be less than `16`\")\n\n        self._phone_number = phone_number", "response": "Sets the phone_number of this OrderFulfillmentRecipient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the amount of money in the smallest denomination of the currency indicated by currency.", "response": "def amount(self, amount):\n        \"\"\"\n        Sets the amount of this Money.\n        The amount of money, in the smallest denomination of the currency indicated by `currency`. For example, when `currency` is `USD`, `amount` is in cents.\n\n        :param amount: The amount of this Money.\n        :type: int\n        \"\"\"\n\n        if amount is None:\n            raise ValueError(\"Invalid value for `amount`, must not be `None`\")\n        if amount < 0:\n            raise ValueError(\"Invalid value for `amount`, must be a value greater than or equal to `0`\")\n\n        self._amount = amount"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef tender_id(self, tender_id):\n\n        if tender_id is None:\n            raise ValueError(\"Invalid value for `tender_id`, must not be `None`\")\n        if len(tender_id) > 192:\n            raise ValueError(\"Invalid value for `tender_id`, length must be less than `192`\")\n        if len(tender_id) < 1:\n            raise ValueError(\"Invalid value for `tender_id`, length must be greater than or equal to `1`\")\n\n        self._tender_id = tender_id", "response": "Sets the tender_id of this CreateRefundRequest. The ID of the tender that this CreateRefundRequest is associated with."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the reason of this CreateRefundRequest.", "response": "def reason(self, reason):\n        \"\"\"\n        Sets the reason of this CreateRefundRequest.\n        A description of the reason for the refund.  Default value: `Refund via API`\n\n        :param reason: The reason of this CreateRefundRequest.\n        :type: str\n        \"\"\"\n\n        if reason is None:\n            raise ValueError(\"Invalid value for `reason`, must not be `None`\")\n        if len(reason) > 192:\n            raise ValueError(\"Invalid value for `reason`, length must be less than `192`\")\n\n        self._reason = reason"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntakes value and turn it into a string suitable for inclusion in the path by url - encoding.", "response": "def to_path_value(self, obj):\n        \"\"\"\n        Takes value and turn it into a string suitable for inclusion in\n        the path, by url-encoding.\n\n        :param obj: object or string value.\n\n        :return string: quoted value.\n        \"\"\"\n        if type(obj) == list:\n            return ','.join(obj)\n        else:\n            return str(obj)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsanitizes the data for serialization.", "response": "def sanitize_for_serialization(self, obj):\n        \"\"\"\n        Builds a JSON POST object.\n\n        If obj is None, return None.\n        If obj is str, int, float, bool, return directly.\n        If obj is datetime.datetime, datetime.date\n            convert to string in iso8601 format.\n        If obj is list, sanitize each element in the list.\n        If obj is dict, return the dict.\n        If obj is swagger model, return the properties dict.\n\n        :param obj: The data to serialize.\n        :return: The serialized form of data.\n        \"\"\"\n        types = (str, int, float, bool, tuple)\n        if sys.version_info < (3,0):\n            types = types + (unicode,)\n        if isinstance(obj, type(None)):\n            return None\n        elif isinstance(obj, types):\n            return obj\n        elif isinstance(obj, list):\n            return [self.sanitize_for_serialization(sub_obj)\n                    for sub_obj in obj]\n        elif isinstance(obj, (datetime, date)):\n            return obj.isoformat()\n        else:\n            if isinstance(obj, dict):\n                obj_dict = obj\n            else:\n                # Convert model obj to dict except\n                # attributes `swagger_types`, `attribute_map`\n                # and attributes which value is not None.\n                # Convert attribute name to json key in\n                # model definition for request.\n                obj_dict = {obj.attribute_map[attr]: getattr(obj, attr)\n                            for attr, _ in iteritems(obj.swagger_types)\n                            if getattr(obj, attr) is not None}\n\n            return {key: self.sanitize_for_serialization(val)\n                    for key, val in iteritems(obj_dict)}"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef deserialize(self, response, response_type):\n        # handle file downloading\n        # save response body into a tmp file and return the instance\n        if \"file\" == response_type:\n            return self.__deserialize_file(response)\n\n        # fetch data from response object\n        try:\n            data = json.loads(response.data)\n        except ValueError:\n            data = response.data\n\n        return self.__deserialize(data, response_type)", "response": "Deserializes a RESTResponse object into an object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nselect the Accept header based on an array of accepts.", "response": "def select_header_accept(self, accepts):\n        \"\"\"\n        Returns `Accept` based on an array of accepts provided.\n\n        :param accepts: List of headers.\n        :return: Accept (e.g. application/json).\n        \"\"\"\n        if not accepts:\n            return\n\n        accepts = list(map(lambda x: x.lower(), accepts))\n\n        if 'application/json' in accepts:\n            return 'application/json'\n        else:\n            return ', '.join(accepts)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __deserialize_primitive(self, data, klass):\n        try:\n            value = klass(data)\n        except UnicodeEncodeError:\n            value = unicode(data)\n        except TypeError:\n            value = data\n        return value", "response": "Deserializes string to primitive type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\naligning the AST so that the argument with the highest cardinality is on the left.", "response": "def _align_ast(self, a):\n        \"\"\"\n        Aligns the AST so that the argument with the highest cardinality is on the left.\n\n        :return: a new AST.\n        \"\"\"\n\n        try:\n            if isinstance(a, BV):\n                return self._align_bv(a)\n            elif isinstance(a, Bool) and len(a.args) == 2 and a.args[1].cardinality > a.args[0].cardinality:\n                return self._reverse_comparison(a)\n            else:\n                return a\n        except ClaripyBalancerError:\n            return a"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _doit(self):\n\n        while len(self._truisms):\n            truism = self._truisms.pop()\n\n            if truism in self._processed_truisms:\n                continue\n\n            unpacked_truisms = self._unpack_truisms(truism)\n            self._processed_truisms.add(truism)\n            if len(unpacked_truisms):\n                self._queue_truisms(unpacked_truisms, check_true=True)\n                continue\n\n            if not self._handleable_truism(truism):\n                continue\n\n            truism = self._adjust_truism(truism)\n\n            assumptions = self._get_assumptions(truism)\n            if truism not in self._identified_assumptions and len(assumptions):\n                l.debug(\"Queued assumptions %s for truism %s.\", assumptions, truism)\n                self._truisms.extend(assumptions)\n                self._identified_assumptions.update(assumptions)\n\n            l.debug(\"Processing truism %s\", truism)\n            balanced_truism = self._balance(truism)\n            l.debug(\"... handling\")\n            self._handle(balanced_truism)", "response": "This function processes the list of truisms and processes the bounds for ASTs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _handleable_truism(t):\n        if len(t.args) < 2:\n            l.debug(\"can't do anything with an unop bool\")\n        elif t.args[0].cardinality > 1 and t.args[1].cardinality > 1:\n            l.debug(\"can't do anything because we have multiple multivalued guys\")\n            return False\n        else:\n            return True", "response": "Checks whether we can handle this truism."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _adjust_truism(t):\n        if t.args[0].cardinality == 1 and t.args[1].cardinality > 1:\n            swapped = Balancer._reverse_comparison(t)\n            return swapped\n        return t", "response": "Swap the operands of the truism so that the concrete value is on the right side."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngive a constraint _get_assumptions() returns a set of constraints that are implicitly set to be true.", "response": "def _get_assumptions(t):\n        \"\"\"\n        Given a constraint, _get_assumptions() returns a set of constraints that are implicitly\n        assumed to be true. For example, `x <= 10` would return `x >= 0`.\n        \"\"\"\n\n        if t.op in ('__le__', '__lt__', 'ULE', 'ULT'):\n            return [ t.args[0] >= 0 ]\n        elif t.op in ('__ge__', '__gt__', 'UGE', 'UGT'):\n            return [ t.args[0] <= 2**len(t.args[0])-1 ]\n        elif t.op in ('SLE', 'SLT'):\n            return [ _all_operations.SGE(t.args[0], -(1 << (len(t.args[0])-1))) ]\n        elif t.op in ('SGE', 'SGT'):\n            return [ _all_operations.SLE(t.args[0], (1 << (len(t.args[0])-1)) - 1) ]\n        else:\n            return [ ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef consume_assignment_list(self):\n        self.expect('(')\n        self.expect('model')\n        \"\"\"Parses a list of expressions from the tokens\"\"\"\n\n        assignments = []\n        while True:\n            next_token = self.tokens.consume()\n            self.tokens.add_extra_token(next_token)  # push it back\n            if next_token == ')':\n                break\n\n            assignments.append(self.expect_assignment_tuple())\n\n        self.expect(')')\n\n        return assignments", "response": "Consumes a list of assignment tuples from the tokens."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copy(self):\n\n        vs = ValueSet(bits=self.bits)\n        vs._regions = self._regions.copy()\n        vs._region_base_addrs = self._region_base_addrs.copy()\n        vs._reversed = self._reversed\n        vs._si = self._si.copy()\n\n        return vs", "response": "Make a copy of self and return."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\napply a new annotation onto the current object and return a new object.", "response": "def apply_annotation(self, annotation):\n        \"\"\"\n        Apply a new annotation onto self, and return a new ValueSet object.\n\n        :param RegionAnnotation annotation: The annotation to apply.\n        :return: A new ValueSet object\n        :rtype: ValueSet\n        \"\"\"\n\n        vs = self.copy()\n        vs._merge_si(annotation.region_id, annotation.region_base_addr, annotation.offset)\n        return vs"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef min(self):\n\n        if len(self.regions) != 1:\n            raise ClaripyVSAOperationError(\"'min()' onlly works on single-region value-sets.\")\n\n        return self.get_si(next(iter(self.regions))).min", "response": "Returns the minimum integer value of a value - set."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef max(self):\n\n        if len(self.regions) != 1:\n            raise ClaripyVSAOperationError(\"'max()' onlly works on single-region value-sets.\")\n\n        return self.get_si(next(iter(self.regions))).max", "response": "Returns the maximum integer value of a value - set."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nextracts a value set or StridedInterval from a given high bit and low bit value.", "response": "def extract(self, high_bit, low_bit):\n        \"\"\"\n        Operation extract\n\n        - A cheap hack is implemented: a copy of self is returned if (high_bit - low_bit + 1 == self.bits), which is a\n            ValueSet instance. Otherwise a StridedInterval is returned.\n\n        :param high_bit:\n        :param low_bit:\n        :return: A ValueSet or a StridedInterval\n        \"\"\"\n\n        if high_bit - low_bit + 1 == self.bits:\n            return self.copy()\n\n        if ('global' in self._regions and len(self._regions.keys()) > 1) or \\\n            len(self._regions.keys()) > 0:\n            si_ret = StridedInterval.top(high_bit - low_bit + 1)\n\n        else:\n            if 'global' in self._regions:\n                si = self._regions['global']\n                si_ret = si.extract(high_bit, low_bit)\n\n            else:\n                si_ret = StridedInterval.empty(high_bit - low_bit + 1)\n\n        return si_ret"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn True if they are exactly same False otherwise.", "response": "def identical(self, o):\n        \"\"\"\n        Used to make exact comparisons between two ValueSets.\n\n        :param o:   The other ValueSet to compare with.\n        :return:    True if they are exactly same, False otherwise.\n        \"\"\"\n        if self._reversed != o._reversed:\n            return False\n\n        for region, si in self.regions.items():\n            if region in o.regions:\n                o_si = o.regions[region]\n                if not si.identical(o_si):\n                    return False\n            else:\n                return False\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates expression e returning the results in the form of concrete ASTs.", "response": "def eval_to_ast(self, e, n, extra_constraints=(), exact=None):\n        \"\"\"\n        Evaluates expression e, returning the results in the form of concrete ASTs.\n        \"\"\"\n        return [ ast.bv.BVV(v, e.size()) for v in self.eval(e, n, extra_constraints=extra_constraints, exact=exact) ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _split_constraints(constraints, concrete=True):\n\n        splitted = [ ]\n        for i in constraints:\n            splitted.extend(i.split(['And']))\n\n        l.debug(\"... splitted of size %d\", len(splitted))\n\n        concrete_constraints = [ ]\n        variable_connections = { }\n        constraint_connections = { }\n        for n,s in enumerate(splitted):\n            l.debug(\"... processing constraint with %d variables\", len(s.variables))\n\n            connected_variables = set(s.variables)\n            connected_constraints = { n }\n\n            if len(connected_variables) == 0:\n                concrete_constraints.append(s)\n\n            for v in s.variables:\n                if v in variable_connections:\n                    connected_variables |= variable_connections[v]\n                if v in constraint_connections:\n                    connected_constraints |= constraint_connections[v]\n\n            for v in connected_variables:\n                variable_connections[v] = connected_variables\n                constraint_connections[v] = connected_constraints\n\n        unique_constraint_sets = set()\n        for v in variable_connections:\n            unique_constraint_sets.add((frozenset(variable_connections[v]), frozenset(constraint_connections[v])))\n\n        results = [ ]\n        for v,c_indexes in unique_constraint_sets:\n            results.append((set(v), [ splitted[c] for c in c_indexes ]))\n\n        if concrete and len(concrete_constraints) > 0:\n            results.append(({ 'CONCRETE' }, concrete_constraints))\n\n        return results", "response": "Returns independent constraints split from this Frontend s constraints."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef BoolS(name, explicit_name=None):\n    n = _make_name(name, -1, False if explicit_name is None else explicit_name)\n    return Bool('BoolS', (n,), variables={n}, symbolic=True)", "response": "Creates a boolean symbol."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef constraint_to_si(expr):\n\n    satisfiable = True\n    replace_list = [ ]\n\n    satisfiable, replace_list = backends.vsa.constraint_to_si(expr)\n\n    # Make sure the replace_list are all ast.bvs\n    for i in xrange(len(replace_list)):\n        ori, new = replace_list[i]\n        if not isinstance(new, Base):\n            new = BVS(new.name, new._bits, min=new._lower_bound, max=new._upper_bound, stride=new._stride, explicit_name=True)\n            replace_list[i] = (ori, new)\n\n    return satisfiable, replace_list", "response": "Convert a constraint to SI if possible."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _make_expr_ops(self, op_list, op_dict=None, op_class=None):\n        for o in op_list:\n            if op_dict is not None:\n                if o in op_dict:\n                    self._op_expr[o] = op_dict[o]\n                else:\n                    l.warning(\"Operation %s not in op_dict.\", o)\n            else:\n                if hasattr(op_class, o):\n                    self._op_expr[o] = getattr(op_class, o)\n                else:\n                    l.warning(\"Operation %s not in op_class %s.\", o, op_class)", "response": "Fill up self. _op_expr dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef downsize(self):\n        self._object_cache.clear()\n        self._true_cache.clear()\n        self._false_cache.clear()", "response": "Clears all caches associated with this backend."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresolving a claripy. ast. Base into something usable by the backend.", "response": "def convert(self, expr): #pylint:disable=R0201\n        \"\"\"\n        Resolves a claripy.ast.Base into something usable by the backend.\n\n        :param expr:    The expression.\n        :param save:    Save the result in the expression's object cache\n        :return:        A backend object.\n        \"\"\"\n        ast_queue = [[expr]]\n        arg_queue = []\n        op_queue = []\n\n        try:\n            while ast_queue:\n                args_list = ast_queue[-1]\n\n                if args_list:\n                    ast = args_list.pop(0)\n\n                    if type(ast) in {bool, int, str, float} or not isinstance(ast, Base):\n                        converted = self._convert(ast)\n                        arg_queue.append(converted)\n                        continue\n\n                    if self in ast._errored:\n                        raise BackendError(\"%s can't handle operation %s (%s) due to a failed \"\n                                           \"conversion on a child node\" % (self, ast.op, ast.__class__.__name__))\n\n                    if self._cache_objects:\n                        cached_obj = self._object_cache.get(ast._cache_key, None)\n                        if cached_obj is not None:\n                            arg_queue.append(cached_obj)\n                            continue\n\n                    op_queue.append(ast)\n                    if ast.op in self._op_expr:\n                        ast_queue.append(None)\n                    else:\n                        ast_queue.append(list(ast.args))\n\n                else:\n                    ast_queue.pop()\n\n                    if op_queue:\n                        ast = op_queue.pop()\n\n                        op = self._op_expr.get(ast.op, None)\n                        if op is not None:\n                            r = op(ast)\n\n                        else:\n                            args = arg_queue[-len(ast.args):]\n                            del arg_queue[-len(ast.args):]\n\n                            try:\n                                r = self._call(ast.op, args)\n                            except BackendUnsupportedError:\n                                r = self.default_op(ast)\n\n                        for a in ast.annotations:\n                            r = self.apply_annotation(r, a)\n\n                        if self._cache_objects:\n                            self._object_cache[ast._cache_key] = r\n\n                        arg_queue.append(r)\n\n        except (RuntimeError, ctypes.ArgumentError) as e:\n            raise ClaripyRecursionError(\"Recursion limit reached. Sorry about that.\") from e\n\n        except BackendError:\n            for ast in op_queue:\n                ast._errored.add(self)\n            if isinstance(expr, Base):\n                expr._errored.add(self)\n            raise\n\n        # Note: Uncomment the following assertions if you are touching the above implementation\n        # assert len(op_queue) == 0, \"op_queue is not empty\"\n        # assert len(ast_queue) == 0, \"ast_queue is not empty\"\n        # assert len(arg_queue) == 1, (\"arg_queue has unexpected length\", len(arg_queue))\n\n        return arg_queue.pop()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef call(self, op, args):\n        converted = self.convert_list(args)\n        return self._call(op, converted)", "response": "Calls operation op on args with this backend."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _call(self, op, args):\n        if op in self._op_raw:\n            # the raw ops don't get the model, cause, for example, Z3 stuff can't take it\n            obj = self._op_raw[op](*args)\n        elif not op.startswith(\"__\"):\n            l.debug(\"backend has no operation %s\", op)\n            raise BackendUnsupportedError\n        else:\n            obj = NotImplemented\n\n            # first, try the operation with the first guy\n            try:\n                obj = getattr(operator, op)(*args)\n            except (TypeError, ValueError):\n                pass\n\n        if obj is NotImplemented:\n            l.debug(\"received NotImplemented in %s.call() for operation %s\", self, op)\n            raise BackendUnsupportedError\n\n        return obj", "response": "Internal method to call the internal method of the internal method."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef is_true(self, e, extra_constraints=(), solver=None, model_callback=None): #pylint:disable=unused-argument\n\n        #if self._solver_required and solver is None:\n        #   raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n        if not isinstance(e, Base):\n            return self._is_true(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)\n\n        try:\n            return self._true_cache[e.cache_key]\n        except KeyError:\n            t = self._is_true(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)\n            self._true_cache[e.cache_key] = t\n            if t is True:\n                self._false_cache[e.cache_key] = False\n            return t", "response": "Returns True if e can be easily found to be True."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_false(self, e, extra_constraints=(), solver=None, model_callback=None): #pylint:disable=unused-argument\n        #if self._solver_required and solver is None:\n        #   raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n        if not isinstance(e, Base):\n            return self._is_false(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)\n\n        try:\n            return self._false_cache[e.cache_key]\n        except KeyError:\n            f = self._is_false(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)\n            self._false_cache[e.cache_key] = f\n            if f is True:\n                self._true_cache[e.cache_key] = False\n            return f", "response": "Returns True if e can be easily found to be False."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef has_true(self, e, extra_constraints=(), solver=None, model_callback=None): #pylint:disable=unused-argument\n\n        #if self._solver_required and solver is None:\n        #   raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n\n        return self._has_true(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)", "response": "Returns True if e can be True."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning True if e can possibly be False.", "response": "def has_false(self, e, extra_constraints=(), solver=None, model_callback=None): #pylint:disable=unused-argument\n        \"\"\"\n        Should return False if `e` can possibly be False.\n\n        :param e:                   The AST.\n        :param extra_constraints:   Extra constraints (as ASTs) to add to the solver for this solve.\n        :param solver:              A solver, for backends that require it.\n        :param model_callback:      a function that will be executed with recovered models (if any)\n        :return:                   A boolean.\n        \"\"\"\n\n        #if self._solver_required and solver is None:\n        #   raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n\n        return self._has_false(self.convert(e), extra_constraints=extra_constraints, solver=solver, model_callback=model_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add(self, s, c, track=False):\n        return self._add(s, self.convert_list(c), track=track)", "response": "This function adds constraints to the backend solver."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef unsat_core(self, s):\n\n        return [ self._abstract(core) for core in self._unsat_core(s) ]", "response": "This function returns the unsatisfiable core from the backend solver."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nevaluates one or multiple expressions.", "response": "def batch_eval(self, exprs, n, extra_constraints=(), solver=None, model_callback=None):\n        \"\"\"\n        Evaluate one or multiple expressions.\n\n        :param exprs:               A list of expressions to evaluate.\n        :param n:                   Number of different solutions to return.\n        :param extra_constraints:   Extra constraints (as ASTs) to add to the solver for this solve.\n        :param solver:              A solver object, native to the backend, to assist in the evaluation.\n        :param model_callback:      a function that will be executed with recovered models (if any)\n        :return:                    A list of up to n tuples, where each tuple is a solution for all expressions.\n        \"\"\"\n        if self._solver_required and solver is None:\n            raise BackendError(\"%s requires a solver for batch evaluation\" % self.__class__.__name__)\n\n        converted_exprs = [ self.convert(ex) for ex in exprs ]\n\n        return self._batch_eval(\n            converted_exprs, n, extra_constraints=self.convert_list(extra_constraints),\n            solver=solver, model_callback=model_callback\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef min(self, expr, extra_constraints=(), solver=None, model_callback=None):\n        if self._solver_required and solver is None:\n            raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n\n        return self._min(self.convert(expr), extra_constraints=self.convert_list(extra_constraints), solver=solver, model_callback=model_callback)", "response": "Evaluate the minimum possible value of expr."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nevaluates the maximum value of expr.", "response": "def max(self, expr, extra_constraints=(), solver=None, model_callback=None):\n        \"\"\"\n        Return the maximum value of expr.\n\n        :param expr: expression (an AST) to evaluate\n        :param solver: a solver object, native to the backend, to assist in\n                       the evaluation (for example, a z3.Solver)\n        :param extra_constraints: extra constraints (as ASTs) to add to the solver for this solve\n        :param model_callback:      a function that will be executed with recovered models (if any)\n        :return: the maximum possible value of expr (backend object)\n        \"\"\"\n        if self._solver_required and solver is None:\n            raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n\n        return self._max(self.convert(expr), extra_constraints=self.convert_list(extra_constraints), solver=solver, model_callback=model_callback)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef satisfiable(self, extra_constraints=(), solver=None, model_callback=None):\n        return self._satisfiable(extra_constraints=self.convert_list(extra_constraints), solver=solver, model_callback=model_callback)", "response": "This function checks if the solver is in a sat state."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating the expression and evaluate the solution of v.", "response": "def solution(self, expr, v, extra_constraints=(), solver=None, model_callback=None):\n        \"\"\"\n        Return True if `v` is a solution of `expr` with the extra constraints, False otherwise.\n\n        :param expr:                An expression (an AST) to evaluate\n        :param v:                   The proposed solution (an AST)\n        :param solver:              A solver object, native to the backend, to assist in the evaluation (for example,\n                                    a z3.Solver).\n        :param extra_constraints:   Extra constraints (as ASTs) to add to the solver for this solve.\n        :param model_callback:      a function that will be executed with recovered models (if any)\n        :return:                    True if `v` is a solution of `expr`, False otherwise\n        \"\"\"\n        if self._solver_required and solver is None:\n            raise BackendError(\"%s requires a solver for evaluation\" % self.__class__.__name__)\n\n        return self._solution(self.convert(expr), self.convert(v), extra_constraints=self.convert_list(extra_constraints), solver=solver, model_callback=model_callback)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef identical(self, a, b):\n        return self._identical(self.convert(a), self.convert(b))", "response": "Returns whether two nodes are identical."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef CreateStridedInterval(name=None, bits=0, stride=None, lower_bound=None, upper_bound=None, uninitialized=False,\n                          to_conv=None, discrete_set=False, discrete_set_max_cardinality=None):\n    \"\"\"\n    :param name:\n    :param bits:\n    :param stride:\n    :param lower_bound:\n    :param upper_bound:\n    :param to_conv:\n    :param bool discrete_set:\n    :param int discrete_set_max_cardinality:\n    :return:\n    \"\"\"\n    if to_conv is not None:\n        if isinstance(to_conv, Base):\n            to_conv = to_conv._model_vsa\n        if isinstance(to_conv, StridedInterval):\n            # No conversion will be done\n            return to_conv\n\n        if not isinstance(to_conv, (numbers.Number, BVV)):\n            raise ClaripyOperationError('Unsupported to_conv type %s' % type(to_conv))\n\n        if (stride is not None\n            or lower_bound is not None\n            or upper_bound is not None):\n            raise ClaripyOperationError('You cannot specify both to_conv and other parameters at the same time.')\n\n        if isinstance(to_conv, BVV):\n            bits = to_conv.bits\n            to_conv_value = to_conv.value\n        else:\n            bits = bits\n            to_conv_value = to_conv\n\n        stride = 0\n        lower_bound = to_conv_value\n        upper_bound = to_conv_value\n\n    bi = StridedInterval(name=name,\n                         bits=bits,\n                         stride=stride,\n                         lower_bound=lower_bound,\n                         upper_bound=upper_bound,\n                         uninitialized=uninitialized)\n    if not discrete_set:\n        return bi\n    else:\n        dsis = DiscreteStridedIntervalSet(\n            name=name,\n            bits=bits,\n            si_set={ bi },\n            max_cardinality=discrete_set_max_cardinality\n        )\n\n        return dsis", "response": "Creates a StridedInterval object."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the minimum value of the OR operation of two - intervals.", "response": "def min_or(a, b, c, d, w):\n        \"\"\"\n        Lower bound of result of ORing 2-intervals.\n\n        :param a: Lower bound of first interval\n        :param b: Upper bound of first interval\n        :param c: Lower bound of second interval\n        :param d: Upper bound of second interval\n        :param w: bit width\n        :return: Lower bound of ORing 2-intervals\n        \"\"\"\n        m = (1 << (w - 1))\n        while m != 0:\n            if ((~a) & c & m) != 0:\n                temp = (a | m) & -m\n                if temp <= b:\n                    a = temp\n                    break\n            elif (a & (~c) & m) != 0:\n                temp = (c | m) & -m\n                if temp <= d:\n                    c = temp\n                    break\n            m >>= 1\n        return a | c"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef max_or(a, b, c, d, w):\n        m = (1 << (w - 1))\n        while m != 0:\n            if (b & d & m) != 0:\n                temp = (b - m) | (m - 1)\n                if temp >= a:\n                    b = temp\n                    break\n                temp = (d - m) | (m - 1)\n                if temp >= c:\n                    d = temp\n                    break\n            m >>= 1\n        return b | d", "response": "Return the maximum OR of two - intervals."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef min_and(a, b, c, d, w):\n        m = (1 << (w - 1))\n        while m != 0:\n            if (~a & ~c & m) != 0:\n                temp = (a | m) & -m\n                if temp <= b:\n                    a = temp\n                    break\n                temp = (c | m) & -m\n                if temp <= d:\n                    c = temp\n                    break\n            m >>= 1\n        return a & c", "response": "Return the minimum AND of two intervals."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the maximum AND result of ANDing 2 - intervals.", "response": "def max_and(a, b, c, d, w):\n        \"\"\"\n        Upper bound of result of ANDing 2-intervals.\n\n        :param a: Lower bound of first interval\n        :param b: Upper bound of first interval\n        :param c: Lower bound of second interval\n        :param d: Upper bound of second interval\n        :param w: bit width\n        :return: Upper bound of ANDing 2-intervals\n        \"\"\"\n        m = (1 << (w - 1))\n        while m != 0:\n            if ((~d) & b & m) != 0:\n                temp = (b & ~m) | (m - 1)\n                if temp >= a:\n                    b = temp\n                    break\n            elif (d & (~b) & m) != 0:\n                temp = (d & ~m) | (m - 1)\n                if temp >= c:\n                    d = temp\n                    break\n            m >>= 1\n        return b & d"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the minimum XOR of two - intervals.", "response": "def min_xor(a, b, c, d, w):\n        \"\"\"\n        Lower bound of result of XORing 2-intervals.\n\n        :param a: Lower bound of first interval\n        :param b: Upper bound of first interval\n        :param c: Lower bound of second interval\n        :param d: Upper bound of second interval\n        :param w: bit width\n        :return: Lower bound of XORing 2-intervals\n        \"\"\"\n        m = (1 << (w - 1))\n        while m != 0:\n            if ((~a) & c & m) != 0:\n                temp = (a | m) & -m\n                if temp <= b:\n                    a = temp\n            elif (a & (~c) & m) != 0:\n                temp = (c | m) & -m\n                if temp <= d:\n                    c = temp\n            m >>= 1\n        return a ^ c"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the maximum XOR of two - intervals.", "response": "def max_xor(a, b, c, d, w):\n        \"\"\"\n        Upper bound of result of XORing 2-intervals.\n\n        :param a: Lower bound of first interval\n        :param b: Upper bound of first interval\n        :param c: Lower bound of second interval\n        :param d: Upper bound of second interval\n        :param w: bit width\n        :return: Upper bound of XORing 2-intervals\n        \"\"\"\n        m = (1 << (w - 1))\n        while m != 0:\n            if (b & d & m) != 0:\n                temp = (b - m) | (m - 1)\n                if temp >= a:\n                    b = temp\n                else:\n                    temp = (d - m) | (m - 1)\n                    if temp >= c:\n                        d = temp\n            m >>= 1\n        return b ^ d"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nevaluates this StridedInterval to obtain a list of concrete integers.", "response": "def eval(self, n, signed=False):\n        \"\"\"\n        Evaluate this StridedInterval to obtain a list of concrete integers.\n\n        :param n: Upper bound for the number of concrete integers\n        :param signed: Treat this StridedInterval as signed or unsigned\n        :return: A list of at most `n` concrete integers\n        \"\"\"\n\n        if self.is_empty:\n            # no value is available\n            return [ ]\n\n        if self._reversed:\n            return self._reverse().eval(n, signed=signed)\n\n        results = [ ]\n\n        if self.stride == 0 and n > 0:\n            results.append(self.lower_bound)\n        else:\n            if signed:\n                # View it as a signed integer\n                bounds = self._signed_bounds()\n\n            else:\n                # View it as an unsigned integer\n                bounds = self._unsigned_bounds()\n\n            for lb, ub in bounds:\n                while len(results) < n and lb <= ub:\n                    results.append(lb)\n                    lb += self.stride # It will not overflow\n\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks whether an integer is solution of the current strided Interval", "response": "def solution(self, b):\n        \"\"\"\n        Checks whether an integer is solution of the current strided Interval\n        :param b: integer to check\n        :return: True if b belongs to the current Strided Interval, False otherwhise\n        \"\"\"\n\n        if isinstance(b, numbers.Number):\n            b = StridedInterval(lower_bound=b, upper_bound=b, stride=0, bits=self.bits)\n        else:\n            raise ClaripyOperationError('Oops, Strided intervals cannot be passed as \"'\n                                        'parameter to function solution. To implement')\n\n        if self.intersection(b).is_empty:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsplit self at the south pole and return two StridedIntervals.", "response": "def _ssplit(self):\n        \"\"\"\n        Split `self` at the south pole, which is the same as in unsigned arithmetic.\n        When returning two StridedIntervals (which means a splitting occurred), it is guaranteed that the first\n        StridedInterval is on the right side of the south pole.\n\n        :return: a list of split StridedIntervals, that contains either one or two StridedIntervals\n        \"\"\"\n\n        south_pole_right = self.max_int(self.bits) # 111...1\n        # south_pole_left = 0\n\n        # Is `self` straddling the south pole?\n        if self.upper_bound < self.lower_bound:\n            # It straddles the south pole!\n\n            a_upper_bound = south_pole_right - ((south_pole_right - self.lower_bound) % self.stride)\n            a = StridedInterval(bits=self.bits, stride=self.stride, lower_bound=self.lower_bound,\n                                upper_bound=a_upper_bound, uninitialized=self.uninitialized)\n\n            b_lower_bound = self._modular_add(a_upper_bound, self.stride, self.bits)\n            b = StridedInterval(bits=self.bits, stride=self.stride, lower_bound=b_lower_bound,\n                                upper_bound=self.upper_bound, uninitialized=self.uninitialized)\n\n            return [ a, b ]\n\n        else:\n            return [ self.copy() ]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsplits self at the north pole which is the same as in signed arithmetic.", "response": "def _nsplit(self):\n        \"\"\"\n        Split `self` at the north pole, which is the same as in signed arithmetic.\n\n        :return: A list of split StridedIntervals\n        \"\"\"\n\n        north_pole_left = self.max_int(self.bits - 1) # 01111...1\n        north_pole_right = 2 ** (self.bits - 1) # 1000...0\n\n        # Is `self` straddling the north pole?\n        straddling = False\n        if self.upper_bound >= north_pole_right:\n            if self.lower_bound > self.upper_bound:\n                # Yes it does!\n                straddling = True\n            elif self.lower_bound <= north_pole_left:\n                straddling = True\n\n        else:\n            if self.lower_bound > self.upper_bound and self.lower_bound <= north_pole_left:\n                straddling = True\n\n        if straddling:\n            a_upper_bound = north_pole_left - ((north_pole_left - self.lower_bound) % self.stride)\n            a = StridedInterval(bits=self.bits, stride=self.stride, lower_bound=self.lower_bound,\n                                upper_bound=a_upper_bound, uninitialized=self.uninitialized)\n\n            b_lower_bound = a_upper_bound + self.stride\n            b = StridedInterval(bits=self.bits, stride=self.stride, lower_bound=b_lower_bound,\n                                upper_bound=self.upper_bound, uninitialized=self.uninitialized)\n\n            return [ a, b ]\n\n        else:\n            return [ self.copy() ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _psplit(self):\n\n        nsplit_list = self._nsplit()\n        psplit_list = [ ]\n\n        for si in nsplit_list:\n            psplit_list.extend(si._ssplit())\n\n        return psplit_list", "response": "Split self at both north and south poles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _signed_bounds(self):\n\n        nsplit = self._nsplit()\n        if len(nsplit) == 1:\n            lb = nsplit[0].lower_bound\n            ub = nsplit[0].upper_bound\n\n            lb = self._unsigned_to_signed(lb, self.bits)\n            ub = self._unsigned_to_signed(ub, self.bits)\n\n            return [(lb, ub)]\n\n        elif len(nsplit) == 2:\n            # nsplit[0] is on the left hemisphere, and nsplit[1] is on the right hemisphere\n\n            # The left one\n            lb_1 = nsplit[0].lower_bound\n            ub_1 = nsplit[0].upper_bound\n\n            # The right one\n            lb_2 = nsplit[1].lower_bound\n            ub_2 = nsplit[1].upper_bound\n            # Then convert them to negative numbers\n            lb_2 = self._unsigned_to_signed(lb_2, self.bits)\n            ub_2 = self._unsigned_to_signed(ub_2, self.bits)\n\n            return [ (lb_1, ub_1), (lb_2, ub_2) ]\n        else:\n            raise Exception('WTF')", "response": "Get lower bound and upper bound for self in signed arithmetic."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _unsigned_bounds(self):\n\n        ssplit = self._ssplit()\n        if len(ssplit) == 1:\n            lb = ssplit[0].lower_bound\n            ub = ssplit[0].upper_bound\n\n            return [ (lb, ub) ]\n        elif len(ssplit) == 2:\n            # ssplit[0] is on the left hemisphere, and ssplit[1] is on the right hemisphere\n\n            lb_1 = ssplit[0].lower_bound\n            ub_1 = ssplit[0].upper_bound\n\n            lb_2 = ssplit[1].lower_bound\n            ub_2 = ssplit[1].upper_bound\n\n            return [ (lb_1, ub_1), (lb_2, ub_2) ]\n        else:\n            raise Exception('WTF')", "response": "Get lower bound and upper bound for self in unsigned arithmetic."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef identical(self, o):\n        return self.bits == o.bits and self.stride == o.stride and self.lower_bound == o.lower_bound and self.upper_bound == o.upper_bound", "response": "Returns True if they are exactly same."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef SLT(self, o):\n\n        signed_bounds_1 = self._signed_bounds()\n        signed_bounds_2 = o._signed_bounds()\n\n        ret = [ ]\n        for lb_1, ub_1 in signed_bounds_1:\n            for lb_2, ub_2 in signed_bounds_2:\n                if ub_1 < lb_2:\n                    ret.append(TrueResult())\n                elif lb_1 >= ub_2:\n                    ret.append(FalseResult())\n                else:\n                    ret.append(MaybeResult())\n\n        if all(r.identical(TrueResult()) for r in ret):\n            return TrueResult()\n        elif all(r.identical(FalseResult()) for r in ret):\n            return FalseResult()\n        else:\n            return MaybeResult()", "response": "Returns True if the other is signed less than the current one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef eq(self, o):\n\n        if (self.is_integer\n            and o.is_integer\n            ):\n            # Two integers\n            if self.lower_bound == o.lower_bound:\n                # They are equal\n                return TrueResult()\n            else:\n                # They are not equal\n                return FalseResult()\n\n        else:\n            if self.name == o.name:\n                return TrueResult() # They are the same guy\n\n            si_intersection = self.intersection(o)\n            if si_intersection.is_empty:\n                return FalseResult()\n\n            else:\n                return MaybeResult()", "response": "Returns True if self and o are equal False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the complement of the interval.", "response": "def complement(self):\n        \"\"\"\n        Return the complement of the interval\n        Refer section 3.1 augmented for managing strides\n\n        :return:\n        \"\"\"\n        # case 1\n        if self.is_empty:\n            return StridedInterval.top(self.bits)\n        # case 2\n        if self.is_top:\n            return StridedInterval.empty(self.bits)\n        # case 3\n        y_plus_1 = StridedInterval._modular_add(self.upper_bound, 1, self.bits)\n        x_minus_1 = StridedInterval._modular_sub(self.lower_bound, 1, self.bits)\n\n        # the new stride has to be the GCD between the old stride and the distance\n        # between the new lower bound and the new upper bound. This assure that in\n        # the new interval the boundaries are valid solution when the SI is\n        # evaluated.\n        dist = StridedInterval._wrapped_cardinality(y_plus_1, x_minus_1, self.bits) - 1\n\n        # the new SI is an integer\n        if dist < 0:\n            new_stride = 0\n        elif self._stride == 0:\n            new_stride = 1\n        else:\n            new_stride = fractions.gcd(self._stride, dist)\n        return StridedInterval(lower_bound=y_plus_1,\n                               upper_bound=x_minus_1,\n                               bits=self.bits,\n                               stride=new_stride,\n                               uninitialized=self.uninitialized)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_top(self):\n        return (self.stride == 1 and\n                self.lower_bound == self._modular_add(self.upper_bound, 1, self.bits)\n                )", "response": "Return True if this is a TOP value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the gap between two intervals src_interval and tar_interval.", "response": "def _gap(src_interval, tar_interval):\n        \"\"\"\n        Refer section 3.1; gap function.\n\n        :param src_interval: first argument or interval 1\n        :param tar_interval: second argument or interval 2\n        :return: Interval representing gap between two intervals\n        \"\"\"\n        assert src_interval.bits == tar_interval.bits, \"Number of bits should be same for operands\"\n        # use the same variable names as in paper\n        s = src_interval\n        t = tar_interval\n        (_, b) = (s.lower_bound, s.upper_bound)\n        (c, _) = (t.lower_bound, t.upper_bound)\n\n        w = s.bits\n        # case 1\n        if (not t._surrounds_member(b)) and (not s._surrounds_member(c)):\n            #FIXME: maybe we can do better here and to not fix the stride to 1\n            #FIXME: found the first common integer for more precision\n            return StridedInterval(lower_bound=c, upper_bound=b, bits=w, stride=1).complement\n        # otherwise\n        return StridedInterval.empty(w)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef top(bits, name=None, uninitialized=False):\n        return StridedInterval(name=name,\n                               bits=bits,\n                               stride=1,\n                               lower_bound=0,\n                               upper_bound=StridedInterval.max_int(bits),\n                               uninitialized=uninitialized)", "response": "Get a TOP StridedInterval."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the cardinality of a set of number x y on the wrapped - interval domain.", "response": "def _wrapped_cardinality(x, y, bits):\n        \"\"\"\n        Return the cardinality for a set of number (| x, y |) on the wrapped-interval domain.\n\n        :param x: The first operand (an integer)\n        :param y: The second operand (an integer)\n        :return: The cardinality\n        \"\"\"\n\n        if x == ((y + 1) % (2 ** bits)):\n            return 2 ** bits\n\n        else:\n            return ((y - x) + 1) & (2 ** bits - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting an unsigned integer to a signed integer.", "response": "def _unsigned_to_signed(v, bits):\n        \"\"\"\n        Convert an unsigned integer to a signed integer.\n\n        :param v: The unsigned integer\n        :param bits: How many bits this integer should be\n        :return: The converted signed integer\n        \"\"\"\n        if StridedInterval._is_msb_zero(v, bits):\n            return v\n        else:\n            return -(2 ** bits - v)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _wrapped_overflow_add(a, b):\n\n        if a.is_integer and a.lower_bound == 0:\n            # Special case: if `a` or `b` is a zero\n            card_self = 0\n        else:\n            card_self = StridedInterval._wrapped_cardinality(a.lower_bound, a.upper_bound, a.bits)\n\n        if b.is_integer and b.lower_bound == 0:\n            # Special case: if `a` or `b` is a zero\n            card_b = 0\n        else:\n            card_b = StridedInterval._wrapped_cardinality(b.lower_bound, b.upper_bound, b.bits)\n\n        return (card_self + card_b) > (StridedInterval.max_int(a.bits) + 1)", "response": "Determines if an overflow occurs during the addition of a and b."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _wrapped_unsigned_mul(a, b):\n        if a.bits != b.bits:\n            logger.warning(\"Signed mul: two parameters have different bit length\")\n\n        bits = max(a.bits, b.bits)\n        lb = a.lower_bound * b.lower_bound\n        ub = a.upper_bound * b.upper_bound\n        uninit_flag = a.uninitialized | b.uninitialized\n\n        if (ub - lb) < (2 ** bits):\n            if b.is_integer:\n                # Multiplication with an integer, and it does not overflow!\n                stride = abs(a.stride * b.lower_bound)\n            elif a.is_integer:\n                stride = abs(a.lower_bound * b.stride)\n            else:\n                stride = fractions.gcd(a.stride, b.stride)\n            return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)\n        else:\n            # Overflow occurred\n            return StridedInterval.top(bits, uninitialized=False)", "response": "Perform wrapped unsigned multiplication on two StridedIntervals."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nperform wrapped signed multiplication on two StridedIntervals.", "response": "def _wrapped_signed_mul(a, b):\n        \"\"\"\n        Perform wrapped signed multiplication on two StridedIntervals.\n\n        :param a: The first operand (StridedInterval)\n        :param b: The second operand (StridedInterval)\n        :return: The product\n        \"\"\"\n\n        #NOTE: interval here should never straddle poles\n        #FIXME: add assert to be sure of it!\n\n        if a.bits != b.bits:\n            logger.warning(\"Signed mul: two parameters have different bit length\")\n\n        bits = max(a.bits, b.bits)\n\n        # shorter SI\n        a_lb_positive = StridedInterval._is_msb_zero(a.lower_bound, bits)\n        a_ub_positive = StridedInterval._is_msb_zero(a.upper_bound, bits)\n        b_lb_positive = StridedInterval._is_msb_zero(b.lower_bound, bits)\n        b_ub_positive = StridedInterval._is_msb_zero(b.upper_bound, bits)\n        uninit_flag = a.uninitialized | b.uninitialized\n\n        if b.is_integer:\n            if b_lb_positive:\n                stride = abs(a.stride * b.lower_bound)\n            else:\n                # if the number is negative we have to get its value first\n                stride = abs(a.stride * StridedInterval._unsigned_to_signed(b.lower_bound, bits))\n        elif a.is_integer:\n            if a_lb_positive:\n                stride = abs(b.stride * a.lower_bound)\n            else:\n                # if the number is negative we have to get its value first:\n                stride = abs(b.stride * StridedInterval._unsigned_to_signed(a.lower_bound, bits))\n        else:\n            stride = fractions.gcd(a.stride, b.stride)\n\n        if a_lb_positive and a_ub_positive and b_lb_positive and b_ub_positive:\n            # [2, 5] * [10, 20] = [20, 100]\n            lb = a.lower_bound * b.lower_bound\n            ub = a.upper_bound * b.upper_bound\n\n            if ub - lb < (2 ** bits):\n                return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)\n            else:\n                return StridedInterval.top(bits, uninitialized=uninit_flag)\n\n        elif not a_lb_positive and not a_ub_positive and not b_lb_positive and not b_ub_positive:\n            # [-5, -2] * [-20, -10] = [20, 100]\n            lb = (\n                StridedInterval._unsigned_to_signed(a.upper_bound, bits) *\n                StridedInterval._unsigned_to_signed(b.upper_bound, bits)\n            )\n            ub = (\n                StridedInterval._unsigned_to_signed(a.lower_bound, bits) *\n                StridedInterval._unsigned_to_signed(b.lower_bound, bits)\n            )\n\n            if ub - lb < (2 ** bits):\n                return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)\n            else:\n                return StridedInterval.top(bits, uninitialized=uninit_flag)\n\n        elif not a_lb_positive and not a_ub_positive and b_lb_positive and b_ub_positive:\n            # [-10, -2] * [2, 5] = [-50, -4]\n            lb = StridedInterval._unsigned_to_signed(a.lower_bound, bits) * b.upper_bound\n            ub = StridedInterval._unsigned_to_signed(a.upper_bound, bits) * b.lower_bound\n            # since the intervals do not straddle the poles, ub is greater than lb\n            if ub - lb < (2 ** bits):\n                lb &= (2 ** bits - 1)\n                ub &= (2 ** bits - 1)\n                return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)\n            else:\n                return StridedInterval.top(bits, uninitialized=uninit_flag)\n\n        elif a_lb_positive and a_ub_positive and not b_lb_positive and not b_ub_positive:\n            # [2, 10] * [-5, -2] = [-50, -4]\n            lb = a.upper_bound * StridedInterval._unsigned_to_signed(b.lower_bound, bits)\n            ub = a.lower_bound * StridedInterval._unsigned_to_signed(b.upper_bound, bits)\n            # since the intervals do not straddle the poles, ub is greater than lb\n            if ub - lb < (2 ** bits):\n                lb &= (2 ** bits - 1)\n                ub &= (2 ** bits - 1)\n                return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)\n            else:\n                return StridedInterval.top(bits, uninitialized=uninit_flag)\n\n        else:\n            raise Exception('We shouldn\\'t see this case: %s * %s' % (a, b))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _wrapped_unsigned_div(a, b):\n\n        bits = max(a.bits, b.bits)\n\n        divisor_lb, divisor_ub = b.lower_bound, b.upper_bound\n        uninit_flag = a.uninitialized | b.uninitialized\n\n        # Make sure divisor_lb and divisor_ub is not 0\n        if divisor_lb == 0:\n            # Can we increment it?\n            if divisor_ub == 0:\n                # We can't :-(\n                return StridedInterval.empty(bits)\n            else:\n                divisor_lb += 1\n        # If divisor_ub is 0, decrement it to get last but one element\n        if divisor_ub == 0:\n            divisor_ub = (divisor_ub - 1) & (2 ** bits - 1)\n\n        lb = a.lower_bound // divisor_ub\n        ub = a.upper_bound // divisor_lb\n\n        # TODO: Can we make a more precise estimate of the stride?\n        stride = 1\n\n        return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)", "response": "Perform wrapped unsigned division on two StridedIntervals."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nperforming wrapped unsigned division on two StridedIntervals.", "response": "def _wrapped_signed_div(a, b):\n        \"\"\"\n        Perform wrapped unsigned division on two StridedIntervals.\n\n        :param a: The dividend (StridedInterval)\n        :param b: The divisor (StridedInterval)\n        :return: The quotient\n        \"\"\"\n\n        bits = max(a.bits, b.bits)\n\n        # Make sure the divisor is not 0\n        divisor_lb = b.lower_bound\n        divisor_ub = b.upper_bound\n        uninit_flag = a.uninitialized | b.uninitialized\n\n        if divisor_lb == 0:\n            # Try to increment it\n            if divisor_ub == 0:\n                return StridedInterval.empty(bits)\n            else:\n                divisor_lb = 1\n        # If divisor_ub is 0, decrement it to get last but one element\n        if divisor_ub == 0:\n            divisor_ub = (divisor_ub - 1) & (2 ** bits - 1)\n\n        dividend_positive = StridedInterval._is_msb_zero(a.lower_bound, bits)\n        divisor_positive = StridedInterval._is_msb_zero(b.lower_bound, bits)\n\n        # TODO: Can we make a more precise estimate of the stride?\n        stride = 1\n        if dividend_positive and divisor_positive:\n            # They are all positive numbers!\n            lb = a.lower_bound // divisor_ub\n            ub = a.upper_bound // divisor_lb\n\n        elif dividend_positive and not divisor_positive:\n            # + / -\n            lb = a.upper_bound // StridedInterval._unsigned_to_signed(divisor_ub, bits)\n            ub = a.lower_bound // StridedInterval._unsigned_to_signed(divisor_lb, bits)\n\n        elif not dividend_positive and divisor_positive:\n            # - / +\n            lb = StridedInterval._unsigned_to_signed(a.lower_bound, bits) // divisor_lb\n            ub = StridedInterval._unsigned_to_signed(a.upper_bound, bits) // divisor_ub\n\n        else:\n            # - / -\n            lb = StridedInterval._unsigned_to_signed(a.upper_bound, bits) // \\\n                 StridedInterval._unsigned_to_signed(b.lower_bound, bits)\n            ub = StridedInterval._unsigned_to_signed(a.lower_bound, bits) // \\\n                 StridedInterval._unsigned_to_signed(b.upper_bound, bits)\n\n        return StridedInterval(bits=bits, stride=stride, lower_bound=lb, upper_bound=ub, uninitialized=uninit_flag)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _is_surrounded(self, b):\n\n        a = self\n        if a.is_empty:\n            return True\n\n        if a.is_top and b.is_top:\n            return True\n\n        elif a.is_top:\n            return False\n\n        elif b.is_top:\n            return True\n\n        if b._surrounds_member(a.lower_bound) and b._surrounds_member(a.upper_bound):\n            if ((b.lower_bound == a.lower_bound and b.upper_bound == a.upper_bound)\n                or not a._surrounds_member(b.lower_bound) or not a._surrounds_member(b.upper_bound)):\n                return True\n        return False", "response": "Perform a wrapped LTE comparison only considering the SI bounds"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef mul(self, o):\n        if self.is_integer and o.is_integer:\n            # Two integers!\n            a, b = self.lower_bound, o.lower_bound\n            ret = StridedInterval(bits=self.bits,\n                                  stride=0,\n                                  lower_bound=a * b,\n                                  upper_bound=a * b\n                                  )\n\n            if a * b > (2 ** self.bits - 1):\n                logger.warning('Overflow in multiplication detected.')\n\n            return ret.normalize()\n\n        else:\n            # All other cases\n\n            # Cut from both north pole and south pole\n            si1_psplit = self._psplit()\n            si2_psplit = o._psplit()\n            all_resulting_intervals = list()\n\n            for si1 in si1_psplit:\n                for si2 in si2_psplit:\n                    tmp_unsigned_mul = self._wrapped_unsigned_mul(si1, si2)\n                    tmp_signed_mul = self._wrapped_signed_mul(si1, si2)\n                    for tmp_meet in tmp_unsigned_mul._multi_valued_intersection(tmp_signed_mul):\n                        all_resulting_intervals.append(tmp_meet)\n        return StridedInterval.least_upper_bound(*all_resulting_intervals).normalize()", "response": "Binary operation for multiplication of two base - level elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sdiv(self, o):\n        # TODO: copy the code from wrapped interval\n        splitted_dividends = self._psplit()\n        splitted_divisors = o._psplit()\n\n        resulting_intervals = set()\n        for dividend in splitted_dividends:\n            for divisor in splitted_divisors:\n                tmp = self._wrapped_signed_div(dividend, divisor)\n                resulting_intervals.add(tmp)\n\n        return StridedInterval.least_upper_bound(*resulting_intervals).normalize()", "response": "Binary operation for division of two sets of items."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef udiv(self, o):\n        #FIXME: copy the code fromm wrapped interval\n        splitted_dividends = self._ssplit()\n        splitted_divisors = o._ssplit()\n\n        resulting_intervals = set()\n        for dividend in splitted_dividends:\n            for divisor in splitted_divisors:\n                tmp = self._wrapped_unsigned_div(dividend, divisor)\n                resulting_intervals.add(tmp)\n\n        return StridedInterval.least_upper_bound(*resulting_intervals).normalize()", "response": "Binary operation for division of two sets of elements."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef bitwise_not(self):\n        splitted_si = self._ssplit()\n        if len(splitted_si) == 0:\n            return StridedInterval.empty(self.bits)\n\n        result_interval = list()\n        for si in splitted_si:\n            lb = ~si.upper_bound\n            ub = ~si.lower_bound\n            stride = self.stride\n\n            tmp = StridedInterval(bits=self.bits, stride=stride, lower_bound=lb, upper_bound=ub)\n            result_interval.append(tmp)\n\n        si = StridedInterval.least_upper_bound(*result_interval).normalize()\n        # preserve the uninitialized flag\n        si.uninitialized = self.uninitialized\n        return si", "response": "Unary operation for the no - set version of the object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bitwise_xor(self, t):\n\n        # Using same variables as in paper\n        s = self\n        new_interval = (s.bitwise_not().bitwise_or(t)).bitwise_not().bitwise_or(s.bitwise_or(t.bitwise_not()).bitwise_not())\n        return new_interval.normalize()", "response": "A bitwise XOR operation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nshift the set of entries in the set by the given amount.", "response": "def rshift_logical(self, shift_amount):\n        \"\"\"\n        Logical shift right.\n\n        :param StridedInterval shift_amount: The amount of shifting\n        :return: The shifted StridedInterval\n        :rtype: StridedInterval\n        \"\"\"\n\n        lower, upper = self._pre_shift(shift_amount)\n\n        # Shift the lower_bound and upper_bound by all possible amounts, and union all possible results\n\n        ret = None\n\n        for amount in xrange(lower, upper + 1):\n            si_ = self._rshift_logical(amount)\n\n            ret = si_ if ret is None else ret.union(si_)\n\n        ret.normalize()\n        ret.uninitialized = self.uninitialized\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rshift_arithmetic(self, shift_amount):\n\n        lower, upper = self._pre_shift(shift_amount)\n\n        # Shift the lower_bound and upper_bound by all possible amounts, and union all possible results\n\n        ret = None\n\n        for amount in xrange(lower, upper + 1):\n            si_ = self._rshift_arithmetic(amount)\n\n            ret = si_ if ret is None else ret.union(si_)\n\n        ret.normalize()\n        ret.uninitialized = self.uninitialized\n        return ret", "response": "Arithmetic shift right.\n\n        :param StridedInterval shift_amount: The amount of shifting\n        :return: The shifted StridedInterval\n        :rtype: StridedInterval"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef zero_extend(self, new_length):\n        si = self.copy()\n        si._bits = new_length\n\n        return si", "response": "ZeroExtend the set of bits to new_length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef sign_extend(self, new_length):\n\n        msb = self.extract(self.bits - 1, self.bits - 1).eval(2)\n        if msb == [ 0 ]:\n            # All positive numbers\n            return self.zero_extend(new_length)\n        if msb == [ 1 ]:\n            # All negative numbers\n            si = self.copy()\n            si._bits = new_length\n            mask = (2 ** new_length - 1) - (2 ** self.bits - 1)\n            si._lower_bound |= mask\n            si._upper_bound |= mask\n\n        else:\n            # Both positive numbers and negative numbers\n            numbers = self._nsplit()\n            # Since there are both positive and negative numbers, there must be two bounds after nsplit\n            # assert len(numbers) == 2\n\n            all_resulting_intervals = list()\n\n            assert len(numbers) > 0\n\n            for n in numbers:\n                a, b = n.lower_bound, n.upper_bound\n                mask_a = 0\n                mask_b = 0\n                mask_n = ((1 << (new_length - n.bits)) - 1) << n.bits\n\n                if StridedInterval._get_msb(a, n.bits) == 1:\n                    mask_a = mask_n\n                if StridedInterval._get_msb(b, n.bits) == 1:\n                    mask_b = mask_n\n\n                si_ = StridedInterval(bits=new_length, stride=n.stride, lower_bound=a | mask_a, upper_bound=b | mask_b)\n                all_resulting_intervals.append(si_)\n            si = StridedInterval.least_upper_bound(*all_resulting_intervals).normalize()\n\n        si.uninitialized = self.uninitialized\n        return si", "response": "Sign - extend the current StridedInterval with a new length."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef union(self, b):\n\n        if not allow_dsis:\n            return StridedInterval.least_upper_bound(self, b)\n\n        else:\n            if self.cardinality > discrete_strided_interval_set.DEFAULT_MAX_CARDINALITY_WITHOUT_COLLAPSING or \\\n                    b.cardinality > discrete_strided_interval_set.DEFAULT_MAX_CARDINALITY_WITHOUT_COLLAPSING:\n                return StridedInterval.least_upper_bound(self, b)\n\n            else:\n                dsis = DiscreteStridedIntervalSet(bits=self._bits, si_set={ self })\n                return dsis.union(b)", "response": "This method returns a DiscreteStridedIntervalSet or StridedIntervalSet that is the union of two OperandQuickIntervals."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns interval with bigger cardinality", "response": "def _bigger(interval1, interval2):\n        \"\"\"\n        Return interval with bigger cardinality\n        Refer Section 3.1\n\n        :param interval1: first interval\n        :param interval2: second interval\n        :return: Interval or interval2 whichever has greater cardinality\n        \"\"\"\n        if interval2.cardinality > interval1.cardinality:\n            return interval2.copy()\n        return interval1.copy()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the number of consecutive zeros in a log - level set.", "response": "def _ntz(x):\n        \"\"\"\n        Get the number of consecutive zeros\n        :param x:\n        :return:\n        \"\"\"\n        if x == 0:\n            return 0\n        y = (~x) & (x - 1)    # There is actually a bug in BAP until 0.8\n\n        def bits(y):\n            n = 0\n            while y != 0:\n                n += 1\n                y >>= 1\n            return n\n        return bits(y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the pseudo - least upper bound of the given set of intervals.", "response": "def least_upper_bound(*intervals_to_join):\n        \"\"\"\n        Pseudo least upper bound.\n        Join the given set of intervals into a big interval. The resulting strided interval is the one which in\n        all the possible joins of the presented SI, presented the least number of values.\n\n        The number of joins to compute is linear with the number of intervals to join.\n\n        Draft of proof:\n        Considering  three generic SI (a,b, and c) ordered from their lower bounds, such that\n        a.lower_bund <= b.lower_bound <= c.lower_bound, where <= is the lexicographic less or equal.\n        The only joins which have sense to compute are:\n        * a U b U c\n        * b U c U a\n        * c U a U b\n\n        All the other combinations fall in either one of these cases. For example: b U a U c does not make make sense\n        to be calculated. In fact, if one draws this union, the result is exactly either (b U c U a) or (a U b U c) or\n        (c U a U b).\n        :param intervals_to_join: Intervals to join\n        :return: Interval that contains all intervals\n        \"\"\"\n        assert len(intervals_to_join) > 0, \"No intervals to join\"\n        # Check if all intervals are of same width\n        all_same = all(x.bits == intervals_to_join[0].bits for x in intervals_to_join)\n        assert all_same, \"All intervals to join should be same\"\n\n        # Optimization: If we have only one interval, then return that interval as result\n        if len(intervals_to_join) == 1:\n            return intervals_to_join[0].copy()\n        # Optimization: If we have only two intervals, the pseudo-join is fine and more precise\n        if len(intervals_to_join) == 2:\n            return StridedInterval.pseudo_join(intervals_to_join[0], intervals_to_join[1])\n\n        # sort the intervals in increasing left bound\n        sorted_intervals = sorted(intervals_to_join, key=lambda x: x.lower_bound)\n        # Fig 3 of the paper\n        ret = None\n\n        # we try all possible joins (linear with the number of SI to join)\n        # and we return the one with the least number of values.\n        for i in xrange(len(sorted_intervals)):\n            # let's join all of them\n            si = reduce(lambda x, y: StridedInterval.pseudo_join(x, y, False), sorted_intervals[i:] + sorted_intervals[0:i])\n\n            if ret is None or ret.n_values > si.n_values:\n                ret = si\n\n        if any([x for x in intervals_to_join if x.uninitialized]):\n            ret.uninitialized = True\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate the minimal integer that appears in both StridedIntervals.", "response": "def _minimal_common_integer(si_0, si_1):\n        \"\"\"\n        Calculates the minimal integer that appears in both StridedIntervals.\n        As a wrapper method of _minimal_common_integer_splitted(), this method takes arbitrary StridedIntervals.\n        For more information, please refer to the comment of _minimal_common_integer_splitted().\n\n        :param si_0:   the first StridedInterval\n        :type  si_0:   StridedInterval\n        :param si_1:   the second StridedInterval\n        :type  si_1:   StridedInterval\n\n        :return: the minimal common integer, or None if there is no common integer\n        \"\"\"\n\n        si_0_splitted = si_0._ssplit()\n        si_1_splitted = si_1._ssplit()\n\n        len_0, len_1 = len(si_0_splitted), len(si_1_splitted)\n\n        if len_0 == 1 and len_1 == 2:\n            # Swap them so we don't have to handle dual\n            si_0_splitted, si_1_splitted = si_1_splitted, si_0_splitted\n            len_0, len_1 = len_1, len_0\n\n        if len_0 == 1 and len_1 == 1:\n            # No splitting was necessary\n            return StridedInterval._minimal_common_integer_splitted(si_0, si_1)\n\n        if len_0 == 2 and len_1 == 1:\n            int_0 = StridedInterval._minimal_common_integer_splitted(si_0_splitted[0], si_1_splitted[0])\n            int_1 = StridedInterval._minimal_common_integer_splitted(si_0_splitted[1], si_1_splitted[0])\n\n        else:\n            # len_0 == 2 and len_1 == 2\n            int_0 = StridedInterval._minimal_common_integer_splitted(si_0_splitted[0], si_1_splitted[0])\n            int_1 = StridedInterval._minimal_common_integer_splitted(si_0_splitted[1], si_1_splitted[1])\n\n        if int_0 is None:\n            return int_1\n        elif int_1 is None:\n            return int_0\n        else:\n            return int_0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef igcd(a, b):\n        a = int(round(a))\n        b = int(round(b))\n        if b < 0:\n            b = -b\n        while b:\n            a, b = b, a % b\n        if a == 1 or b == 1:\n            return 1\n        return a", "response": "Calculates the integer GCD between two integer names."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef diop_natural_solution_linear(c, a, b):\n        def get_intersection(a, b, a_dir, b_dir):\n            # Do the intersection between two\n            # ranges.\n            if (a_dir, b_dir) == (\">=\", \">=\"):\n                lb = a if a > b else b\n                ub = float('inf')\n            elif (a_dir, b_dir) == (\"<=\", \">=\"):\n                if a > b:\n                    lb = b\n                    ub = a\n                else:\n                    lb = None\n                    ub = None\n            elif (a_dir, b_dir) == (\">=\", \"<=\"):\n                if b > a:\n                    lb = a\n                    ub = b\n                else:\n                    lb = None\n                    ub = None\n            elif (a_dir, b_dir) == (\"<=\", \"<=\"):\n                ub = a if a < b else b\n                lb = float('-inf')\n\n            return lb, ub\n\n        d = StridedInterval.igcd(a, StridedInterval.igcd(b, c))\n        a = a // d\n        b = b // d\n        c = c // d\n\n        if c == 0:\n            return (0, 0)\n        else:\n            x0, y0, d = StridedInterval.extended_euclid(int(abs(a)), int(abs(b)))\n            x0 = x0 * StridedInterval.sign(a)\n            y0 = y0 * StridedInterval.sign(b)\n\n            if c % d == 0:\n                \"\"\"\n                Integer solutions are: (c*x0 + b*t, c*y0 - a*t)\n                we have to get the first positive solution, which means\n                that we have to solve the following disequations for t:\n                c*x0 + b*t >= 0 and c*y0 - a*t >= 0.\n                \"\"\"\n                assert b != 0\n                assert a != 0\n\n                t0 = (-c * x0) / float(b)\n                t1 = (c * y0) / float(a)\n                # direction of the disequation depends on b and a sign\n                if b < 0:\n                    t0_dir = '<='\n                else:\n                    t0_dir = '>='\n                if a < 0:\n                    t1_dir = '>='\n                else:\n                    t1_dir = '<='\n\n                # calculate the intersection between the found\n                # solution intervals to get the common solutions\n                # for t.\n                lb, ub = get_intersection(t0, t1, t0_dir, t1_dir)\n\n                # Given that we are looking for the first value\n                # which solve the diophantine equation, we have to\n                # select the value of t closer to 0.\n                if lb <= 0 and ub >= 0:\n                    t = ub if abs(ub) < abs(lb) else lb\n                elif lb == float('inf') or lb == float(\"-inf\"):\n                    t = ub\n                elif ub == float('inf') or ub == float(\"-inf\"):\n                    t = lb\n                else:\n                    t = ub if abs(ub) < abs(lb) else lb\n                # round the value of t\n                if t == ub:\n                    t = int(math.floor(t))\n                else:\n                    t = int(math.ceil(t))\n\n                return (c*x0 + b*t, c*y0 - a*t)\n            else:\n                return (None, None)", "response": "This function finds the first natural solution of the diophantine equation a + b = c."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the minimal integer that appears in both StridedIntervals. It's equivalent to finding an integral solution for equation `ax + b = cy + d` that makes `ax + b` minimal si_0.stride, si_1.stride being a and c, and si_0.lower_bound, si_1.lower_bound being b and d, respectively. Upper bounds are used to check whether the minimal common integer exceeds the bound or not. None is returned if no minimal common integers can be found within the range. Some assumptions: # - None of the StridedIntervals straddles the south pole. Consequently, we have x <= max_int(si.bits) and y <= # max_int(si.bits) # - a, b, c, d are all positive integers # - x >= 0, y >= 0 :param StridedInterval si_0: the first StridedInterval :param StridedInterval si_1: the second StrideInterval :return: the minimal common integer, or None if there is no common integer", "response": "def _minimal_common_integer_splitted(si_0, si_1):\n        \"\"\"\n        Calculates the minimal integer that appears in both StridedIntervals.\n        It's equivalent to finding an integral solution for equation `ax + b = cy + d` that makes `ax + b` minimal\n        si_0.stride, si_1.stride being a and c, and si_0.lower_bound, si_1.lower_bound being b and d, respectively.\n        Upper bounds are used to check whether the minimal common integer exceeds the bound or not. None is returned\n        if no minimal common integers can be found within the range.\n\n        Some assumptions:\n        # - None of the StridedIntervals straddles the south pole. Consequently, we have x <= max_int(si.bits) and y <=\n        #   max_int(si.bits)\n        # - a, b, c, d are all positive integers\n        # - x >= 0, y >= 0\n\n        :param StridedInterval si_0: the first StridedInterval\n        :param StridedInterval si_1: the second StrideInterval\n        :return: the minimal common integer, or None if there is no common integer\n        \"\"\"\n\n        a, c = si_0.stride, si_1.stride\n        b, d = si_0.lower_bound, si_1.lower_bound\n\n        # if any of them is an integer\n        if si_0.is_integer:\n            if si_1.is_integer:\n                return None if si_0.lower_bound != si_1.lower_bound else si_0.lower_bound\n            elif si_0.lower_bound >= si_1.lower_bound and \\\n                    si_0.lower_bound <= si_1.upper_bound and \\\n                    (si_0.lower_bound - si_1.lower_bound) % si_1.stride == 0:\n                return si_0.lower_bound\n            else:\n                return None\n        elif si_1.is_integer:\n            return StridedInterval._minimal_common_integer_splitted(si_1, si_0)\n\n        # shortcut\n        if si_0.upper_bound < si_1.lower_bound or si_1.upper_bound < si_0.lower_bound:\n            # They don't overlap at all\n            return None\n\n        if (d - b) % StridedInterval.gcd(a, c) != 0:\n            # They don't overlap\n            return None\n\n        \"\"\"\n        Given two strided intervals a = sa[lba, uba] and b = sb[lbb, ubb], the first integer shared\n        by them is found by finding the minimum values of ka and kb which solve the equation:\n            ka * sa + lba = kb * sb + lbb\n        In particular one can solve the above diophantine equation and find the parameterized solutions\n        of ka and kb, with respect to a parameter t.\n        The minimum natural value of the parameter t which gives two positive natural values of ka and kb\n        is used to resolve ka and kb, and finally to solve the above equation and get the minimum shared integer.\n        \"\"\"\n        x, y = StridedInterval.diop_natural_solution_linear(-(b-d), a, -c)\n        if a is None or b is None:\n            return None\n        first_integer = x * a + b\n        assert first_integer == y*c + d\n        if first_integer >= si_0.lower_bound and first_integer <= si_0.upper_bound and \\\n            first_integer >= si_1.lower_bound and first_integer <= si_1.upper_bound:\n            return first_integer\n\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef reverse(self):\n        if self.bits == 8:\n            # We cannot reverse a one-byte value\n            return self\n\n        si = self.copy()\n        si._reversed = not si._reversed\n\n        return si", "response": "This is a delayed reversing function."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _reverse(self):\n        o = self.copy()\n        # Clear ok reversed flag\n        o._reversed = not o._reversed\n\n        if o.bits == 8:\n            # No need for reversing\n            return o.copy()\n\n        if o.is_top:\n            # A TOP is still a TOP after reversing\n            si = o.copy()\n            return si\n\n        else:\n            if not o.is_integer:\n                # We really don't want to do that... but well, sometimes it just happens...\n                logger.warning('Reversing a real strided-interval %s is bad', self)\n\n            # Reversing an integer is easy\n            rounded_bits = ((o.bits + 7) // 8) * 8\n            list_bytes = [ ]\n            si = None\n\n            for i in xrange(0, rounded_bits, 8):\n                b = o._unrev_extract(min(i + 7, o.bits - 1), i)\n                list_bytes.append(b)\n\n            for b in list_bytes:\n                si = b if si is None else si.concat(b)\n            si.uninitialized = self.uninitialized\n            si._reversed = o._reversed\n            return si", "response": "This method reverses the StridedInterval object for real."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _involuted_reverse(self):\n        def inv_is_top(si):\n            return (si.stride == 1 and\n                self._lower_bound == StridedInterval._modular_add(self._upper_bound, 1, self.bits)\n                )\n\n        o = self.copy()\n        # Clear the reversed flag\n        o._reversed = not o._reversed\n\n        if o.bits == 8:\n            # No need for reversing\n            return o.copy()\n\n        if inv_is_top(o):\n            # A TOP is still a TOP after reversing\n            si = o.copy()\n            return si\n\n        else:\n            lb = o._lower_bound\n            ub = o._upper_bound\n\n            rounded_bits = ((o.bits + 7) // 8) * 8\n            lb_r = []\n            ub_r = []\n\n            for i in xrange(0, rounded_bits, 8):\n                if i != 0:\n                    lb = lb >> 8\n                    ub = ub >> 8\n\n                lb_r.append(lb & 0xff)\n                ub_r.append(ub & 0xff)\n\n            si_lb = None\n            si_ub = None\n            for b in lb_r:\n                if si_lb is None:\n                    si_lb = b\n                else:\n                    si_lb <<= 8\n                    si_lb |= b\n            for b in ub_r:\n                if si_ub is None:\n                    si_ub = b\n                else:\n                    si_ub <<= 8\n                    si_ub |= b\n\n            si = StridedInterval(bits=o.bits,\n                                 lower_bound=si_lb,\n                                 upper_bound=si_ub,\n                                 stride=o._stride,\n                                 uninitialized=o.uninitialized)\n\n            si._reversed = o._reversed\n            if not o.is_integer:\n                # We really don't want to do that... but well, sometimes it just happens...\n                logger.warning('Reversing a real strided-interval %s is bad', self)\n\n            return si", "response": "This method reverses the StridedInterval object for real."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the smt - lib script that check the satisfiability of the current constraints and extra_variables.", "response": "def get_smtlib_script_satisfiability(self, extra_constraints=(), extra_variables=()):\n        \"\"\"\n        Return an smt-lib script that check the satisfiability of the current constraints\n\n        :return string: smt-lib script\n        \"\"\"\n        try:\n            e_csts = self._solver_backend.convert_list(extra_constraints + tuple(self.constraints))\n            e_variables = self._solver_backend.convert_list(extra_variables)\n\n            variables, csts = self._solver_backend._get_all_vars_and_constraints(e_c=e_csts, e_v=e_variables)\n            return self._solver_backend._get_satisfiability_smt_script(csts, variables)\n        except BackendError as e:\n            raise ClaripyFrontendError(\"Backend error during smtlib script generation\") from e"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_annotation(self, bo, annotation):\n\n        # Currently we only support RegionAnnotation\n\n        if not isinstance(annotation, RegionAnnotation):\n            return bo\n\n        if not isinstance(bo, ValueSet):\n            # Convert it to a ValueSet first\n            # Note that the original value is not kept at all. If you want to convert a StridedInterval to a ValueSet,\n            # you gotta do the conversion by calling AST.annotate() from outside.\n            bo = ValueSet.empty(bo.bits)\n\n        return bo.apply_annotation(annotation)", "response": "Applies an annotation on the backend object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a Z3 model to a name - > primitive dict.", "response": "def _generic_model(self, z3_model):\n        \"\"\"\n        Converts a Z3 model to a name->primitive dict.\n        \"\"\"\n        model = { }\n        for m_f in z3_model:\n            n = _z3_decl_name_str(m_f.ctx.ctx, m_f.ast).decode()\n            m = m_f()\n            me = z3_model.eval(m)\n            model[n] = self._abstract_to_primitive(me.ctx.ctx, me.ast)\n\n        return model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _calc_hash(op, args, keywords):\n        args_tup = tuple(a if type(a) in (int, float) else hash(a) for a in args)\n        # HASHCONS: these attributes key the cache\n        # BEFORE CHANGING THIS, SEE ALL OTHER INSTANCES OF \"HASHCONS\" IN THIS FILE\n        to_hash = (\n            op, args_tup,\n            str(keywords.get('length', None)),\n            hash(keywords['variables']),\n            keywords['symbolic'],\n            hash(keywords.get('annotations', None)),\n        )\n\n        # Why do we use md5 when it's broken? Because speed is more important\n        # than cryptographic integrity here. Then again, look at all those\n        # allocations we're doing here... fast python is painful.\n        hd = hashlib.md5(pickle.dumps(to_hash, -1)).digest()\n        return md5_unpacker.unpack(hd)[0]", "response": "Calculates the hash of an AST given the operation args and keywords."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves an annotation from this AST.", "response": "def remove_annotation(self, a):\n        \"\"\"\n        Removes an annotation from this AST.\n\n        :param a: the annotation to remove\n        :returns: a new AST, with the annotation removed\n        \"\"\"\n        return self._apply_to_annotations(lambda alist: tuple(oa for oa in alist if oa != a))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves several annotations from this AST.", "response": "def remove_annotations(self, remove_sequence):\n        \"\"\"\n        Removes several annotations from this AST.\n\n        :param remove_sequence: a sequence/set of the annotations to remove\n        :returns: a new AST, with the annotations removed\n        \"\"\"\n        return self._apply_to_annotations(lambda alist: tuple(oa for oa in alist if oa not in remove_sequence))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef shallow_repr(self, max_depth=8, explicit_length=False, details=LITE_REPR):\n        ast_queue = [(0, iter([self]))]\n        arg_queue = []\n        op_queue = []\n\n        while ast_queue:\n            try:\n                depth, args_iter = ast_queue[-1]\n                arg = next(args_iter)\n\n                if not isinstance(arg, Base):\n                    arg_queue.append(arg)\n                    continue\n\n                if max_depth is not None:\n                    if depth >= max_depth:\n                        arg_queue.append('<...>')\n                        continue\n\n                if arg.op in operations.reversed_ops:\n                    op_queue.append((depth + 1, operations.reversed_ops[arg.op], len(arg.args), arg.length))\n                    ast_queue.append((depth + 1, reversed(arg.args)))\n\n                else:\n                    op_queue.append((depth + 1, arg.op, len(arg.args), arg.length))\n                    ast_queue.append((depth + 1, iter(arg.args)))\n\n            except StopIteration:\n                ast_queue.pop()\n\n                if op_queue:\n                    depth, op, num_args, length = op_queue.pop()\n\n                    args_repr = arg_queue[-num_args:]\n                    del arg_queue[-num_args:]\n\n                    length = length if explicit_length else None\n                    inner_repr = self._op_repr(op, args_repr, depth > 1, length, details)\n\n                    arg_queue.append(inner_repr)\n\n        assert len(op_queue) == 0, \"op_queue is not empty\"\n        assert len(ast_queue) == 0, \"arg_queue is not empty\"\n        assert len(arg_queue) == 1, (\"repr_queue has unexpected length\", len(arg_queue))\n\n        return \"<{} {}>\".format(self._type_name(), arg_queue.pop())", "response": "Returns a string representation of this AST but with a maximum depth to prevent floods of text being printed."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef children_asts(self):\n        ast_queue = deque([iter(self.args)])\n        while ast_queue:\n\n            try:\n                ast = next(ast_queue[-1])\n            except StopIteration:\n                ast_queue.pop()\n                continue\n\n            if isinstance(ast, Base):\n                ast_queue.append(iter(ast.args))\n\n                l.debug(\"Yielding AST %s with hash %s with %d children\", ast, hash(ast), len(ast.args))\n                yield ast", "response": "Yields the nested children ASTs."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an iterator over the leaf ASTs.", "response": "def leaf_asts(self):\n        \"\"\"\n        Return an iterator over the leaf ASTs.\n        \"\"\"\n        seen = set()\n\n        ast_queue = deque([self])\n        while ast_queue:\n\n            ast = ast_queue.pop()\n            if isinstance(ast, Base) and id(ast.cache_key) not in seen:\n                seen.add(id(ast.cache_key))\n\n                if ast.depth == 1:\n                    yield ast\n                    continue\n\n                ast_queue.extend(ast.args)\n                continue"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef split(self, split_on):\n        if self.op in split_on: return list(self.args)\n        else: return [ self ]", "response": "Splits the AST into a list of lists."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef structurally_match(self, o):\n\n        # TODO: Convert a and b into canonical forms\n\n        if self.op != o.op:\n            return False\n\n        if len(self.args) != len(o.args):\n            return False\n\n        for arg_a, arg_b in zip(self.args, o.args):\n            if not isinstance(arg_a, Base):\n                if type(arg_a) != type(arg_b):\n                    return False\n                # They are not ASTs\n                if arg_a != arg_b:\n                    return False\n                else:\n                    continue\n\n            if arg_a.op in operations.leaf_operations:\n                if arg_a is not arg_b:\n                    return False\n\n            else:\n                if not arg_a.structurally_match(arg_b):\n                    return False\n\n        return True", "response": "Structurally compares two claripy A objects and checks if their corresponding leaves are definitely the same A object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef replace_dict(self, replacements, variable_set=None, leaf_operation=None):\n        if variable_set is None:\n            variable_set = set()\n\n        if leaf_operation is None:\n            leaf_operation = lambda x: x\n\n        arg_queue = [iter([self])]\n        rep_queue = []\n        ast_queue = []\n\n        while arg_queue:\n            try:\n                ast = next(arg_queue[-1])\n                repl = ast\n\n                if not isinstance(ast, Base):\n                    rep_queue.append(repl)\n                    continue\n\n                elif ast.cache_key in replacements:\n                    repl = replacements[ast.cache_key]\n\n                elif ast.variables >= variable_set:\n\n                    if ast.op in operations.leaf_operations:\n                        repl = leaf_operation(ast)\n                        if repl is not ast:\n                            replacements[ast.cache_key] = repl\n\n                    elif ast.depth > 1:\n                        arg_queue.append(iter(ast.args))\n                        ast_queue.append(ast)\n                        continue\n\n                rep_queue.append(repl)\n                continue\n\n            except StopIteration:\n                arg_queue.pop()\n\n                if ast_queue:\n                    ast = ast_queue.pop()\n                    repl = ast\n\n                    args = rep_queue[-len(ast.args):]\n                    del rep_queue[-len(ast.args):]\n\n                    # Check if replacement occurred.\n                    if any((a is not b for a, b in zip(ast.args, args))):\n                        repl = ast.make_like(ast.op, tuple(args))\n                        replacements[ast.cache_key] = repl\n\n                    rep_queue.append(repl)\n\n        assert len(arg_queue) == 0, \"arg_queue is not empty\"\n        assert len(ast_queue) == 0, \"ast_queue is not empty\"\n        assert len(rep_queue) == 1, (\"rep_queue has unexpected length\", len(rep_queue))\n\n        return rep_queue.pop()", "response": "Returns an AST with all subexpressions replaced by those that can be found in replacements dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef replace(self, old, new, variable_set=None, leaf_operation=None):   # pylint:disable=unused-argument\n        self._check_replaceability(old, new)\n        replacements = {old.cache_key: new}\n        return self.replace_dict(replacements, variable_set=old.variables)", "response": "Returns this AST but with the old replaced with new in its subexpressions."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef ite_burrowed(self):\n        if self._burrowed is None:\n            self._burrowed = self._burrow_ite()  # pylint:disable=attribute-defined-outside-init\n            self._burrowed._burrowed = self._burrowed  # pylint:disable=attribute-defined-outside-init\n        return self._burrowed", "response": "Returns an AST that burrows the ITE expressions as deep as possible into the ast for simpler\n        printing."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn an equivalent AST that excavates the ITE expressions out as far as possible toward the root of the ITE expression.", "response": "def ite_excavated(self):\n        \"\"\"\n        Returns an equivalent AST that \"excavates\" the ITE expressions out as far as possible toward the root of the\n        AST, for processing in static analyses.\n        \"\"\"\n        if self._excavated is None:\n            self._excavated = self._excavate_ite()  # pylint:disable=attribute-defined-outside-init\n\n            # we set the flag for the children so that we avoid re-excavating during\n            # VSA backend evaluation (since the backend evaluation recursively works on\n            # the excavated ASTs)\n            self._excavated._excavated = self._excavated\n        return self._excavated"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nhandling the following case: ((A << a) | (A >> (_N - a))) & mask, where A being a BVS, a being a integer that is less than _N, _N is either 32 or 64, and mask can be evaluated to 0xffffffff (64-bit) or 0xffff (32-bit) after reversing the rotate-shift operation. It will be simplified to: (A & (mask >>> a)) <<< a", "response": "def rotate_shift_mask_simplifier(a, b):\n        \"\"\"\n        Handles the following case:\n            ((A << a) | (A >> (_N - a))) & mask, where\n                A being a BVS,\n                a being a integer that is less than _N,\n                _N is either 32 or 64, and\n                mask can be evaluated to 0xffffffff (64-bit) or 0xffff (32-bit) after reversing the rotate-shift\n                operation.\n\n        It will be simplified to:\n            (A & (mask >>> a)) <<< a\n        \"\"\"\n\n        # is the second argument a BVV?\n        if b.op != 'BVV':\n            return None\n\n        # is it a rotate-shift?\n        if a.op != '__or__' or len(a.args) != 2:\n            return None\n        a_0, a_1 = a.args\n\n        if a_0.op != '__lshift__':\n            return None\n        if a_1.op != 'LShR':\n            return None\n        a_00, a_01 = a_0.args\n        a_10, a_11 = a_1.args\n        if not a_00 is a_10:\n            return None\n        if a_01.op != 'BVV' or a_11.op != 'BVV':\n            return None\n        lshift_ = a_01.args[0]\n        rshift_ = a_11.args[0]\n        bitwidth = lshift_ + rshift_\n        if bitwidth not in (32, 64):\n            return None\n\n        # is the second argument a mask?\n        # Note: the following check can be further loosen if we want to support more masks.\n        if bitwidth == 32:\n            m = ((b.args[0] << rshift_) & 0xffffffff) | (b.args[0] >> lshift_)\n            if m != 0xffff:\n                return None\n        else: # bitwidth == 64\n            m = ((b.args[0] << rshift_) & 0xffffffffffffffff) | (b.args[0] >> lshift_)\n            if m != 0xffffffff:\n                return None\n\n        # Show our power!\n        masked_a = (a_00 & m)\n        expr = (masked_a << lshift_) | (masked_a >> rshift_)\n        return expr"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef FPS(name, sort, explicit_name=None):\n\n    n = _make_name(name, sort.length, False if explicit_name is None else explicit_name, prefix='FP_')\n    return FP('FPS', (n, sort), variables={n}, symbolic=True, length=sort.length)", "response": "Creates a floating - point symbol."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert this float to a different FP AST", "response": "def to_fp(self, sort, rm=None):\n        \"\"\"\n        Convert this float to a different sort\n\n        :param sort:    The sort to convert to\n        :param rm:      Optional: The rounding mode to use\n        :return:        An FP AST\n        \"\"\"\n        if rm is None:\n            rm = fp.RM.default()\n\n        return fpToFP(rm, self, sort)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert this floating point value to an integer.", "response": "def val_to_bv(self, size, signed=True, rm=None):\n        \"\"\"\n        Convert this floating point value to an integer.\n\n        :param size:    The size of the bitvector to return\n        :param signed:  Optional: Whether the target integer is signed\n        :param rm:      Optional: The rounding mode to use\n        :return:        A bitvector whose value is the rounded version of this FP's value\n        \"\"\"\n        if rm is None:\n            rm = fp.RM.default()\n\n        op = fpToSBV if signed else fpToUBV\n        return op(rm, self, size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the cardinality of this DSIS.", "response": "def cardinality(self):\n        \"\"\"\n        This is an over-approximation of the cardinality of this DSIS.\n\n        :return:\n        \"\"\"\n        cardinality = 0\n        for si in self._si_set:\n            cardinality += si.cardinality\n        return cardinality"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncollapsing into a StridedInterval instance.", "response": "def collapse(self):\n        \"\"\"\n        Collapse into a StridedInterval instance.\n\n        :return: A new StridedInterval instance.\n        \"\"\"\n\n        if self.cardinality:\n            r = None\n            for si in self._si_set:\n                r = r._union(si) if r is not None else si\n\n            return r\n\n        else:\n            # This is an empty StridedInterval...\n            return StridedInterval.empty(self._bits)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalize(self):\n        if self.should_collapse(): return self.collapse()\n        elif self.number_of_values == 1: return list(self._si_set)[0]\n        else:\n            for si in self._si_set:\n                self._update_bits(si)\n            return self", "response": "Normalizes the DiscreteStridedIntervalSet object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef extract(self, high_bit, low_bit):\n        # TODO: This method can be optimized\n\n        ret = set()\n        bits = high_bit - low_bit + 1\n\n        for si in self._si_set:\n            ret.add(si.extract(high_bit, low_bit))\n\n        if len(ret) > 1:\n            return DiscreteStridedIntervalSet(bits=bits, si_set=ret)\n\n        else:\n            return list(ret)[0]", "response": "Extract the set of entries from the set of entries."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _intersection_with_si(self, si):\n\n        new_si_set = set()\n        for si_ in self._si_set:\n            r = si_.intersection(si)\n            new_si_set.add(r)\n\n        if len(new_si_set):\n            ret = DiscreteStridedIntervalSet(bits=self.bits, si_set=new_si_set)\n\n            if ret.should_collapse(): return ret.collapse()\n            else: return ret\n\n        else:\n            # There is no intersection between two operands\n            return StridedInterval.empty(self.bits)", "response": "Return the intersection with another : class : StridedInterval."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _intersection_with_dsis(self, dsis):\n\n        new_si_set = set()\n        for si in dsis._si_set:\n            r = self._intersection_with_si(si)\n\n            if isinstance(r, StridedInterval):\n                if not r.is_empty:\n                    new_si_set.add(r)\n\n            else: # r is a DiscreteStridedIntervalSet\n                new_si_set |= r._si_set\n\n        if len(new_si_set):\n            ret = DiscreteStridedIntervalSet(bits=self.bits, si_set=new_si_set)\n\n            return ret.normalize()\n\n        else:\n            return StridedInterval.empty(self.bits)", "response": "Intersection with another DiscreteStridedIntervalSet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndumping the symbol in smt - format depending on its type", "response": "def _expr_to_smtlib(e, daggify=True):\n    \"\"\"\n    Dump the symbol in its smt-format depending on its type\n\n    :param e: symbol to dump\n    :param daggify: The daggify parameter can be used to switch from a linear-size representation that uses \u2018let\u2019\n                    operators to represent the formula as a dag or a simpler (but possibly exponential) representation\n                    that expands the formula as a tree\n\n    :return string: smt-lib representation of the symbol\n    \"\"\"\n    if e.is_symbol():\n        return \"(declare-fun %s %s)\" % (e.symbol_name(), e.symbol_type().as_smtlib())\n    else:\n        return \"(assert %s)\" % e.to_smtlib(daggify=daggify)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes the arguments of the expression to be integers.", "response": "def _normalize_arguments(expr_left, expr_rigth):\n    \"\"\"\n    Since we decided to emulate integer with bitvector, this method transform their\n    concrete value (if any) in the corresponding integer\n    \"\"\"\n    if expr_left.is_str_op() and expr_rigth.is_bv_constant():\n        return expr_left, Int(expr_rigth.bv_signed_value())\n    elif expr_left.is_bv_constant() and expr_rigth.is_str_op():\n        return expr_rigth, Int(expr_left.bv_signed_value())\n    return expr_left, expr_rigth"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a SMT script that declare all the symbols constraint and checks their satisfiability", "response": "def _get_satisfiability_smt_script(self, constraints=(), variables=()):\n        \"\"\"\n        Returns a SMT script that declare all the symbols and constraint and checks\n        their satisfiability (check-sat)\n\n        :param extra-constraints: list of extra constraints that we want to evaluate only\n                                 in the scope of this call\n                                \n        :return string: smt-lib representation of the script that checks the satisfiability\n        \"\"\"\n        smt_script = '(set-logic ALL)\\n'\n        smt_script += self._smtlib_exprs(variables)\n        smt_script += self._smtlib_exprs(constraints)\n        smt_script += '(check-sat)\\n'\n        return smt_script"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_full_model_smt_script(self, constraints=(), variables=()):\n        smt_script = '(set-logic ALL)\\n'\n        smt_script += '(set-option :produce-models true)\\n'\n        smt_script += self._smtlib_exprs(variables)\n        smt_script += self._smtlib_exprs(constraints)\n        smt_script += '(check-sat)\\n'\n        smt_script += '(get-model)\\n'\n        return smt_script", "response": "Returns a full SMT script that declares all the symbols constraint and checks\n        their satisfiability"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef StringS(name, size, uninitialized=False, explicit_name=False, **kwargs):\n    n = _make_name(String.STRING_TYPE_IDENTIFIER + name, size, False if explicit_name is None else explicit_name)\n    result = String(\"StringS\", (n, uninitialized), length=size, symbolic=True, eager_backends=None, uninitialized=uninitialized, variables={n}, **kwargs)\n    return result", "response": "Creates a new symbolic string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a concrete string from a constant value.", "response": "def StringV(value, length=None, **kwargs):\n    \"\"\"\n    Create a new Concrete string (analogous to z3.StringVal())\n\n    :param value: The constant value of the concrete string\n\n    :returns:                    The String object representing the concrete string\n    \"\"\"\n\n    if length is None:\n        length = len(value)\n\n    if length < len(value):\n        raise ValueError(\"Can't make a concrete string value longer than the specified length!\")\n\n    result = String(\"StringV\", (value, len(value)), length=length, **kwargs)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the start index of the pattern inside the input string in a Bitvector representation otherwise - 1.", "response": "def indexOf(self, pattern, start_idx, bitlength):\n        \"\"\"\n        Return the start index of the pattern inside the input string in a\n        Bitvector representation, otherwise it returns -1 (always using a BitVector)\n\n        :param bitlength: size of the biitvector holding the result\n        \"\"\"\n        return StrIndexOf(self, pattern, start_idx, bitlength)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef raw_to_bv(self):\n        if self.symbolic:\n            return BVS(next(iter(self.variables)).replace(self.STRING_TYPE_IDENTIFIER, self.GENERATED_BVS_IDENTIFIER), self.length)\n        else:\n            return BVV(ord(self.args[0]), self.length)", "response": "A counterpart to FP. raw_to_bv - does nothing and returns itself."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a concrete version of the concatenated string", "response": "def StrConcat(*args):\n    \"\"\"\n    Create a concrete version of the concatenated string\n    :param args: List of string that has to be concatenated\n\n    :return : a concrete version of the concatenated string\n    \"\"\"\n    new_value = ''.join([arg.value for arg in args])\n    return StringV(new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef StrSubstr(start_idx, count, initial_string):\n    new_value = initial_string.value[start_idx.value:start_idx.value + count.value]\n    return StringV(new_value)", "response": "Substr returns a new string that is a substring of the given string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a concrete version of the replaced string (replace ONLY th efirst occurrence of the pattern) :param initial_string: string in which the pattern needs to be replaced :param pattern_to_be_replaced: substring that has to be replaced inside initial_string :param replacement_poattern: pattern that has to be inserted in initial_string t replace pattern_to_be_replaced :return: a concrete representation of the replaced string", "response": "def StrReplace(initial_string, pattern_to_be_replaced, replacement_pattern):\n    \"\"\"\n    Create a concrete version of the replaced string\n    (replace ONLY th efirst occurrence of the pattern)\n\n    :param initial_string: string in which the pattern needs to be replaced\n    :param pattern_to_be_replaced: substring that has to be replaced inside initial_string\n    :param replacement_poattern: pattern that has to be inserted in initial_string t replace\n                                 pattern_to_be_replaced\n    :return: a concrete representation of the replaced string\n    \"\"\"\n    new_value = initial_string.value.replace(pattern_to_be_replaced.value,\n                                             replacement_pattern.value,\n                                             1)\n    return StringV(new_value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef StrPrefixOf(prefix, input_string):\n    return re.match(r'^' + prefix.value, input_string.value) is not None", "response": "Checks if the concrete value of the input_string starts with prefix otherwise false."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if the concrete value of the input_string ends with suffix otherwise false.", "response": "def StrSuffixOf(suffix, input_string):\n    \"\"\"\n    Return True if the concrete value of the input_string ends with suffix\n    otherwise false.\n\n    :param suffix: suffix we want to check\n    :param input_string: the string we want to check\n\n    :return : True if the input_string ends with suffix else false\n    \"\"\"\n    return re.match(r'.*' + suffix.value + '$', input_string.value) is not None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef StrIndexOf(input_string, substring, startIndex, bitlength):\n    try:\n        s = input_string.value\n        t = substring.value\n        i = startIndex.value\n        return BVV(i + s[i:].index(t), bitlength)\n    except ValueError:\n        return BVV(-1, bitlength)", "response": "Return True if the concrete value of the input_string ends with suffix\n    otherwise false."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns True if the concrete value of the input_string ends with suffix otherwise false.", "response": "def StrToInt(input_string, bitlength):\n    \"\"\"\n    Return True if the concrete value of the input_string ends with suffix\n    otherwise false.\n\n    :param input_string: the string we want to transform in an integer\n    :param bitlength: bitlength of the bitvector representing the index of the substring\n\n    :return BVV: bit-vector representation of the integer resulting from ythe string or -1 in bitvector representation\n                 if the string cannot be transformed into an integer\n    \"\"\"\n    try:\n        return BVV(int(input_string.value), bitlength)\n    except ValueError:\n        return BVV(-1, bitlength)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a sequence of the solvers that self and others share.", "response": "def _shared_solvers(self, others):\n        \"\"\"\n        Returns a sequence of the solvers that self and others share.\n        \"\"\"\n\n        solvers_by_id = { id(s): s for s in self._solver_list }\n        common_solvers = set(solvers_by_id.keys())\n        other_sets = [ { id(s) for s in cs._solver_list } for cs in others ]\n        for o in other_sets: common_solvers &= o\n\n        return [ solvers_by_id[s] for s in common_solvers ]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncreates a bit - vector symbol.", "response": "def BVS(name, size, min=None, max=None, stride=None, uninitialized=False,  #pylint:disable=redefined-builtin\n        explicit_name=None, discrete_set=False, discrete_set_max_card=None, **kwargs):\n    \"\"\"\n    Creates a bit-vector symbol (i.e., a variable).\n\n    If you want to specify the maximum or minimum value of a normal symbol that is not part of value-set analysis, you\n    should manually add constraints to that effect. **Do not use ``min`` and ``max`` for symbolic execution.**\n\n    :param name:            The name of the symbol.\n    :param size:            The size (in bits) of the bit-vector.\n    :param min:             The minimum value of the symbol, used only for value-set analysis\n    :param max:             The maximum value of the symbol, used only for value-set analysis\n    :param stride:          The stride of the symbol, used only for value-set analysis\n    :param uninitialized:   Whether this value should be counted as an \"uninitialized\" value in the course of an\n                            analysis.\n    :param bool explicit_name:   If False, an identifier is appended to the name to ensure uniqueness.\n    :param bool discrete_set: If True, a DiscreteStridedIntervalSet will be used instead of a normal StridedInterval.\n    :param int discrete_set_max_card: The maximum cardinality of the discrete set. It is ignored if discrete_set is set\n                                      to False or None.\n\n    :returns:               a BV object representing this symbol.\n    \"\"\"\n\n    if stride == 0 and max != min:\n        raise ClaripyValueError(\"BVSes of stride 0 should have max == min\")\n\n    encoded_name = None\n    if type(name) is bytes:\n        encoded_name = name\n        name = name.decode()\n    if type(name) is not str:\n        raise TypeError(\"Name value for BVS must be a str, got %r\" % type(name))\n\n    n = _make_name(name, size, False if explicit_name is None else explicit_name)\n\n    if not discrete_set:\n        discrete_set_max_card = None\n\n    return BV('BVS', (n, min, max, stride, uninitialized, discrete_set, discrete_set_max_card), variables={n},\n              length=size, symbolic=True, eager_backends=None, uninitialized=uninitialized, encoded_name=encoded_name,\n              **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef BVV(value, size=None, **kwargs):\n\n    if type(value) in (bytes, str):\n        if type(value) is str:\n            l.warning(\"BVV value is a unicode string, encoding as utf-8\")\n            value = value.encode('utf-8')\n\n        if size is None:\n            size = len(value)*8\n        elif type(size) is not int:\n            raise TypeError(\"Bitvector size  must be either absent (implicit) or an integer\")\n        elif size != len(value)*8:\n            raise ClaripyValueError('string/size mismatch for BVV creation')\n\n        value = int(binascii.hexlify(value), 16) if value != b\"\" else 0\n\n    elif size is None or (type(value) is not int and value is not None):\n        raise TypeError('BVV() takes either an integer value and a size or a string of bytes')\n\n    # ensure the 0 <= value < (1 << size)\n    # FIXME hack to handle None which is used for an Empty Strided Interval (ESI)\n    if value is not None:\n        value &= (1 << size) -1\n\n    if not kwargs:\n        try: return _bvv_cache[(value, size)]\n        except KeyError: pass\n\n    result = BV('BVV', (value, size), length=size, **kwargs)\n    _bvv_cache[(value, size)] = result\n    return result", "response": "Creates a bit - vector value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of consecutive bitvectors in a given number of bits.", "response": "def chop(self, bits=1):\n        \"\"\"\n        Chops a BV into consecutive sub-slices. Obviously, the length of this BV must be a multiple of bits.\n\n        :returns:   A list of smaller bitvectors, each ``bits`` in length. The first one will be the left-most (i.e.\n                    most significant) bits.\n        \"\"\"\n        s = len(self)\n        if s % bits != 0:\n            raise ValueError(\"expression length (%d) should be a multiple of 'bits' (%d)\" % (len(self), bits))\n        elif s == bits:\n            return [ self ]\n        else:\n            return list(reversed([ self[(n+1)*bits - 1:n*bits] for n in range(0, s // bits) ]))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_byte(self, index):\n        pos = self.size() // 8 - 1 - index\n        return self[pos * 8 + 7 : pos * 8]", "response": "Extracts a byte from a BV where the index refers to the byte in a big - endian order\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_bytes(self, index, size):\n        pos = self.size() // 8 - 1 - index\n        return self[pos * 8 + 7 : (pos - size + 1) * 8]", "response": "Extracts several bytes from a bitvector where the index refers to the byte in a big - endian order\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ninterprets this bitvector as an integer and return the floating - point representation of that integer.", "response": "def val_to_fp(self, sort, signed=True, rm=None):\n        \"\"\"\n        Interpret this bitvector as an integer, and return the floating-point representation of that integer.\n\n        :param sort:    The sort of floating point value to return\n        :param signed:  Optional: whether this value is a signed integer\n        :param rm:      Optional: the rounding mode to use\n        :return:        An FP AST whose value is the same as this BV\n        \"\"\"\n        if rm is None:\n            rm = fp.fp.RM.default()\n        if sort is None:\n            sort = fp.fp.FSort.from_size(self.length)\n\n        op = fp.fpToFP if signed else fp.fpToFPUnsigned\n        return op(rm, self, sort)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef raw_to_fp(self):\n        sort = fp.fp.FSort.from_size(self.length)\n        return fp.fpToFP(self, sort)", "response": "Interpret the bits of this bitvector as an IEEE754 floating point number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef convert(self, expr):\n        if type(expr) is BV:\n            if expr.op == \"BVV\":\n                cached_obj = self._object_cache.get(expr._cache_key, None)\n                if cached_obj is None:\n                    cached_obj = self.BVV(*expr.args)\n                    self._object_cache[expr._cache_key] = cached_obj\n                return cached_obj\n        if type(expr) is Bool and expr.op == \"BoolV\":\n            return expr.args[0]\n        return super().convert(expr)", "response": "Override the base conversion method to add fast paths for BVVs and BoolVs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nevaluate the ast with the last value replaced by their last value in the model.", "response": "def eval_ast(self, ast):\n        \"\"\"Eval the ast, replacing symbols by their last value in the model.\n        \"\"\"\n        # If there was no last value, it was not constrained, so we can use\n        # anything.\n        new_ast = ast.replace_dict(self.replacements, leaf_operation=self._leaf_op)\n        return backends.concrete.eval(new_ast, 1)[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef eval_constraints(self, constraints):\n        # eval_ast is concretizing symbols and evaluating them, this can raise\n        # exceptions.\n        try:\n            return all(self.eval_ast(c) for c in constraints)\n        except errors.ClaripyZeroDivisionError:\n            return False", "response": "Returns whether the constraints are satisfied trivially by using the\n        last model."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef update(self, other):\n\n        acceptable_models = [ m for m in other._models if set(m.model.keys()) == self.variables ]\n        self._models.update(acceptable_models)\n        self._eval_exhausted.update(other._eval_exhausted)\n        self._max_exhausted.update(other._max_exhausted)\n        self._min_exhausted.update(other._min_exhausted)", "response": "Updates this cache mixin with results discovered by the other split off one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef kpath_from_seekpath(cls, seekpath, point_coords):\n        # convert from seekpath format e.g. [(l1, l2), (l2, l3), (l4, l5)]\n        # to our preferred representation [[l1, l2, l3], [l4, l5]]\n        path = [[seekpath[0][0]]]\n        for (k1, k2) in seekpath:\n            if path[-1] and path[-1][-1] == k1:\n                path[-1].append(k2)\n            else:\n                path.append([k1, k2])\n\n        # Rebuild kpoints dictionary skipping any positions not on path\n        # (chain(*list) flattens nested list; set() removes duplicates.)\n        kpoints = {p: point_coords[p] for p in set(chain(*path))}\n\n        # Every path should include Gamma-point. Change the label to \\Gamma\n        assert 'GAMMA' in kpoints\n        kpoints[r'\\Gamma'] = kpoints.pop('GAMMA')\n        path = [[label.replace('GAMMA', r'\\Gamma') for label in subpath]\n                for subpath in path]\n\n        return {'kpoints': kpoints, 'path': path}", "response": "r Convert seekpath - formatted k - points path to sumo - preferred format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading Bradley - Cracknell k - points path from data file.", "response": "def _get_bradcrack_data(bravais):\n        r\"\"\"Read Bradley--Cracknell k-points path from data file\n\n        Args:\n            bravais (str): Lattice code including orientation e.g. 'trig_p_c'\n\n        Returns:\n            dict: kpoint path and special point locations, formatted as e.g.::\n\n              {'kpoints': {'\\Gamma': [0., 0., 0.], 'X': [0., 0.5, 0.], ...},\n               'path': [['\\Gamma', 'X', ..., 'P'], ['H', 'N', ...]]}\n\n        \"\"\"\n        json_file = pkg_resources.resource_filename(__name__, 'bradcrack.json')\n        with open(json_file, 'r') as f:\n            bradcrack_data = load_json(f)\n            return bradcrack_data[bravais]"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the Bravais lattice symbol from symmetry data", "response": "def _get_bravais_lattice(spg_symbol, lattice_type, a, b, c, unique):\n        \"\"\"Get Bravais lattice symbol from symmetry data\"\"\"\n\n        if lattice_type == 'triclinic':\n            return('triclinic')\n\n        elif lattice_type == 'monoclinic':\n            if 'P' in spg_symbol:\n                if unique == 0:\n                    return('mon_p_a')\n                elif unique == 1:\n                    return('mon_p_b')\n                elif unique == 2:\n                    return('mon_p_c')\n\n            elif 'C' in spg_symbol:\n                if unique == 0:\n                    return('mon_c_a')\n                elif unique == 1:\n                    return('mon_c_b')\n                elif unique == 2:\n                    return('mon_c_c')\n\n        elif lattice_type == 'orthorhombic':\n            if 'P' in spg_symbol:\n                return('orth_p')\n\n            elif 'A' in spg_symbol or 'C' in spg_symbol:\n                if a > b:\n                    return('orth_c_a')\n                elif b > a:\n                    return('orth_c_b')\n\n            elif 'F' in spg_symbol:\n                if (1/a**2 < 1/b**2 + 1/c**2 and 1/b**2 < 1/c**2 + 1/a**2 and\n                        1/c**2 < 1/a**2 + 1/b**2):\n                    return('orth_f_1')\n                elif 1/c**2 > 1/a**2 + 1/b**2:\n                    return('orth_f_2')\n                elif 1/b**2 > 1/a**2 + 1/c**2:\n                    return('orth_f_3')\n                elif 1/a**2 > 1/c**2 + 1/b**2:\n                    return('orth_f_4')\n\n            elif 'I' in spg_symbol:\n                if a > b and a > c:\n                    return('orth_i_a')\n                elif b > a and b > c:\n                    return('orth_i_b')\n                elif c > a and c > b:\n                    return('orth_i_c')\n\n        elif lattice_type == 'tetragonal':\n            if 'P' in spg_symbol:\n                return('tet_p')\n\n            elif 'I' in spg_symbol:\n                if a > c:\n                    return('tet_i_a')\n                else:\n                    return('tet_i_c')\n\n        elif (lattice_type == 'trigonal' or lattice_type == 'hexagonal'\n                or lattice_type == 'rhombohedral'):\n            if 'R' in spg_symbol:\n                if a > np.sqrt(2) * c:\n                    return('trig_r_a')\n                else:\n                    return('trig_r_c')\n\n            elif 'P' in spg_symbol:\n                if unique == 0:\n                    return('trig_p_a')\n                elif unique == 2:\n                    return('trig_p_c')\n\n        elif lattice_type == \"cubic\":\n            if 'P' in spg_symbol:\n                return('cubic_p')\n            elif 'I' in spg_symbol:\n                return('cubic_i')\n            elif 'F' in spg_symbol:\n                return('cubic_f')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a colour for a particular elemental and orbital combination.", "response": "def get_cached_colour(element, orbital, colours=None, cache=None):\n    \"\"\"Get a colour for a particular elemental and orbital combination.\n\n    If the element is not specified in the colours dictionary, the cache is\n    checked. If this element-orbital combination has not been chached before,\n    a new colour is drawn from the current matplotlib colour cycle and cached.\n\n    The default cache is sumo.plotting.colour_cache. To reset this cache, use\n    ``sumo.plotting.colour_cache.clear()``.\n\n    Args:\n        element (:obj:`str`): The element.\n        orbital (:obj:`str`): The orbital.\n        colours (:obj:`dict`, optional): Use custom colours for specific\n            element and orbital combinations. Specified as a :obj:`dict` of\n            :obj:`dict` of the colours. For example::\n\n                {\n                    'Sn': {'s': 'r', 'p': 'b'},\n                    'O': {'s': '#000000'}\n                }\n\n            The colour can be a hex code, series of rgb value, or any other\n            format supported by matplotlib.\n        cache (:obj:`dict`, optional): Cache of colour values already\n            assigned. The format is the same as the custom colours dict. If\n            None, the module-level cache ``sumo.plotting.colour_cache`` is\n            used.\n\n    Returns:\n        tuple: (colour, cache)\n    \"\"\"\n\n    if cache is None:\n        cache = colour_cache\n\n    def _get_colour_with_cache(element, orbital, cache, colour_series):\n        \"\"\"Return cached colour if available, or fetch and cache from cycle\"\"\"\n        from itertools import chain\n        if element in cache and orbital in cache[element]:\n            return cache[element][orbital], cache\n        else:\n            # Iterate through colours to find one which is unused\n            for colour in colour_series:\n                # Iterate through cache to check if colour already used\n                if colour not in chain(*[[col for _, col in orb.items()]\n                                         for _, orb in cache.items()]):\n                    break\n            else:\n                raise Exception('Not enough colours available for orbitals! '\n                                'Try a different theme.')\n\n            if element not in cache:\n                cache[element] = {}\n            cache[element].update({orbital: colour})\n            return colour, cache\n\n    colour_series = matplotlib.rcParams['axes.prop_cycle'].by_key()['color']\n\n    if isinstance(colours, configparser.ConfigParser):\n        try:\n            return colours.get(element, orbital), cache\n        except(configparser.NoSectionError, configparser.NoOptionError):\n            return _get_colour_with_cache(element, orbital,\n                                          cache, colour_series)\n\n    elif isinstance(colours, dict):\n        try:\n            return colours[element][orbital]\n        except KeyError:\n            return _get_colour_with_cache(element, orbital,\n                                          cache, colour_series)\n\n    elif colours is None:\n        return _get_colour_with_cache(element, orbital, cache, colour_series)\n\n    else:\n        raise TypeError('Argument \"colours\" should be dict, '\n                        'ConfigParser or None.')"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the plotting data for the specified object.", "response": "def dos_plot_data(self, yscale=1, xmin=-6., xmax=6., colours=None,\n                      plot_total=True, legend_cutoff=3, subplot=False,\n                      zero_to_efermi=True, cache=None):\n        \"\"\"Get the plotting data.\n\n        Args:\n            yscale (:obj:`float`, optional): Scaling factor for the y-axis.\n            xmin (:obj:`float`, optional): The minimum energy to mask the\n                energy and density of states data (reduces plotting load).\n            xmax (:obj:`float`, optional): The maximum energy to mask the\n                energy and density of states data (reduces plotting load).\n            colours (:obj:`dict`, optional): Use custom colours for specific\n                element and orbital combinations. Specified as a :obj:`dict` of\n                :obj:`dict` of the colours. For example::\n\n                    {\n                        'Sn': {'s': 'r', 'p': 'b'},\n                        'O': {'s': '#000000'}\n                    }\n\n                The colour can be a hex code, series of rgb value, or any other\n                format supported by matplotlib.\n            plot_total (:obj:`bool`, optional): Plot the total density of\n                states. Defaults to ``True``.\n            legend_cutoff (:obj:`float`, optional): The cut-off (in % of the\n                maximum density of states within the plotting range) for an\n                elemental orbital to be labelled in the legend. This prevents\n                the legend from containing labels for orbitals that have very\n                little contribution in the plotting range.\n            subplot (:obj:`bool`, optional): Plot the density of states for\n                each element on separate subplots. Defaults to ``False``.\n            zero_to_efermi (:obj:`bool`, optional): Normalise the plot such\n                that the Fermi level is set as 0 eV.\n            cache (:obj:`dict`, optional): Cache object tracking how colours\n                have been assigned to orbitals. The format is the same as the\n                \"colours\" dict. This defaults to the module-level\n                sumo.plotting.colour_cache object, but an empty dict can be\n                used as a fresh cache. This object will be modified in-place.\n\n        Returns:\n            dict: The plotting data. Formatted with the following keys:\n\n                \"energies\" (:obj:`numpy.ndarray`)\n                    The energies.\n\n                \"mask\" (:obj:`numpy.ndarray`)\n                    A mask used to trim the density of states data and\n                    prevent unwanted data being included in the output file.\n\n                \"lines\" (:obj:`list`)\n                    A :obj:`list` of :obj:`dict` containing the density data\n                    and some metadata. Each line :obj:`dict` contains the keys:\n\n                        \"label\" (:obj:`str`)\n                            The label for the legend.\n\n                        \"dens\" (:obj:`numpy.ndarray`)\n                            The density of states data.\n\n                        \"colour\" (:obj:`str`)\n                            The colour of the line.\n\n                        \"alpha\" (:obj:`float`)\n                            The alpha value for line fill.\n\n                \"ymin\" (:obj:`float`)\n                    The minimum y-axis limit.\n\n                \"ymax\" (:obj:`float`)\n                    The maximum y-axis limit.\n        \"\"\"\n        if cache is None:\n            cache = colour_cache\n\n        # mask needed to prevent unwanted data in pdf and for finding y limit\n        dos = self._dos\n        pdos = self._pdos\n        eners = dos.energies - dos.efermi if zero_to_efermi else dos.energies\n        mask = (eners >= xmin - 0.05) & (eners <= xmax + 0.05)\n        plot_data = {'mask': mask, 'energies': eners}\n        spins = dos.densities.keys()\n        ymax = 0\n\n        if plot_total:\n            if 'text.color' in matplotlib.rcParams:\n                tdos_colour = matplotlib.rcParams['text.color']\n                if tdos_colour is None:\n                    tdos_colour = 'k'\n            else:\n                tdos_colour = 'k'\n            lines = []\n            tdos = {'label': 'Total DOS', 'dens': dos.densities,\n                    'colour': tdos_colour, 'alpha': 0.15}\n\n            # subplot data formatted as a list of lists of dicts, with each\n            # list of dicts being plotted on a separate graph, if only one list\n            # then solo plot\n            lines.append([tdos])\n            dmax = max([max(d[mask]) for d in dos.densities.values()])\n            ymax = dmax if dmax > ymax else ymax\n        elif not subplot:\n            lines = [[]]  # need a blank list to add lines into\n        else:\n            lines = []\n\n        # TODO: Fix broken behaviour if plot_total is off\n        cutoff = (legend_cutoff / 100.) * (ymax / 1.05)\n\n        for el, el_pdos in pdos.items():\n            el_lines = []\n            for orb in sort_orbitals(el_pdos):\n                dmax = max([max(d[mask])\n                            for d in el_pdos[orb].densities.values()])\n                ymax = dmax if dmax > ymax else ymax\n                label = None if dmax < cutoff else '{} ({})'.format(el, orb)\n                colour, cache = get_cached_colour(el, orb, colours,\n                                                  cache=cache)\n                el_lines.append({'label': label, 'alpha': 0.25,\n                                 'colour': colour,\n                                 'dens': el_pdos[orb].densities})\n            if subplot:\n                lines.append(el_lines)\n            else:\n                lines[0].extend(el_lines)\n\n        ymax = ymax * empty_space / yscale\n        ymin = 0 if len(spins) == 1 else -ymax\n        plot_data.update({'lines': lines, 'ymax': ymax, 'ymin': ymin})\n        return plot_data"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_plot(self, subplot=False, width=None, height=None, xmin=-6.,\n                 xmax=6., yscale=1, colours=None, plot_total=True,\n                 legend_on=True, num_columns=2, legend_frame_on=False,\n                 legend_cutoff=3, xlabel='Energy (eV)', ylabel='Arb. units',\n                 zero_to_efermi=True, dpi=400, fonts=None, plt=None,\n                 style=None, no_base_style=False):\n        \"\"\"Get a :obj:`matplotlib.pyplot` object of the density of states.\n\n        Args:\n            subplot (:obj:`bool`, optional): Plot the density of states for\n                each element on separate subplots. Defaults to ``False``.\n            width (:obj:`float`, optional): The width of the plot.\n            height (:obj:`float`, optional): The height of the plot.\n            xmin (:obj:`float`, optional): The minimum energy on the x-axis.\n            xmax (:obj:`float`, optional): The maximum energy on the x-axis.\n            yscale (:obj:`float`, optional): Scaling factor for the y-axis.\n            colours (:obj:`dict`, optional): Use custom colours for specific\n                element and orbital combinations. Specified as a :obj:`dict` of\n                :obj:`dict` of the colours. For example::\n\n                    {\n                        'Sn': {'s': 'r', 'p': 'b'},\n                        'O': {'s': '#000000'}\n                    }\n\n                The colour can be a hex code, series of rgb value, or any other\n                format supported by matplotlib.\n            plot_total (:obj:`bool`, optional): Plot the total density of\n                states. Defaults to ``True``.\n            legend_on (:obj:`bool`, optional): Plot the graph legend. Defaults\n                to ``True``.\n            num_columns (:obj:`int`, optional): The number of columns in the\n                legend.\n            legend_frame_on (:obj:`bool`, optional): Plot a frame around the\n                graph legend. Defaults to ``False``.\n            legend_cutoff (:obj:`float`, optional): The cut-off (in % of the\n                maximum density of states within the plotting range) for an\n                elemental orbital to be labelled in the legend. This prevents\n                the legend from containing labels for orbitals that have very\n                little contribution in the plotting range.\n            xlabel (:obj:`str`, optional): Label/units for x-axis (i.e. energy)\n            ylabel (:obj:`str`, optional): Label/units for y-axis (i.e. DOS)\n            zero_to_efermi (:obj:`bool`, optional): Normalise the plot such\n                that the Fermi level is set as 0 eV.\n            dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n                the image.\n            fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n                a single font, specified as a :obj:`str`, or several fonts,\n                specified as a :obj:`list` of :obj:`str`.\n            plt (:obj:`matplotlib.pyplot`, optional): A\n                :obj:`matplotlib.pyplot` object to use for plotting.\n            style (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n                style specifications, to be composed on top of Sumo base\n                style.\n            no_base_style (:obj:`bool`, optional): Prevent use of sumo base\n                style. This can make alternative styles behave more\n                predictably.\n\n        Returns:\n            :obj:`matplotlib.pyplot`: The density of states plot.\n        \"\"\"\n        plot_data = self.dos_plot_data(yscale=yscale, xmin=xmin, xmax=xmax,\n                                       colours=colours, plot_total=plot_total,\n                                       legend_cutoff=legend_cutoff,\n                                       subplot=subplot,\n                                       zero_to_efermi=zero_to_efermi)\n\n        if subplot:\n            nplots = len(plot_data['lines'])\n            plt = pretty_subplot(nplots, 1, width=width, height=height,\n                                 dpi=dpi, plt=plt)\n        else:\n            plt = pretty_plot(width=width, height=height, dpi=dpi, plt=plt)\n\n        mask = plot_data['mask']\n        energies = plot_data['energies'][mask]\n        fig = plt.gcf()\n        lines = plot_data['lines']\n        spins = [Spin.up] if len(lines[0][0]['dens']) == 1 else \\\n            [Spin.up, Spin.down]\n\n        for i, line_set in enumerate(plot_data['lines']):\n            if subplot:\n                ax = fig.axes[i]\n            else:\n                ax = plt.gca()\n\n            for line, spin in itertools.product(line_set, spins):\n                if spin == Spin.up:\n                    label = line['label']\n                    densities = line['dens'][spin][mask]\n                elif spin == Spin.down:\n                    label = \"\"\n                    densities = -line['dens'][spin][mask]\n                ax.fill_between(energies, densities, lw=0,\n                                facecolor=line['colour'],\n                                alpha=line['alpha'])\n                ax.plot(energies, densities, label=label,\n                        color=line['colour'])\n\n            ax.set_ylim(plot_data['ymin'], plot_data['ymax'])\n            ax.set_xlim(xmin, xmax)\n\n            ax.tick_params(axis='y', labelleft='off')\n            ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n            ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n\n            loc = 'upper right' if subplot else 'best'\n            ncol = 1 if subplot else num_columns\n            if legend_on:\n                ax.legend(loc=loc, frameon=legend_frame_on, ncol=ncol)\n\n        # no add axis labels and sort out ticks\n        if subplot:\n            ax.set_xlabel(xlabel)\n            fig.subplots_adjust(hspace=0)\n            plt.setp([a.get_xticklabels() for a in fig.axes[:-1]],\n                     visible=False)\n\n            if 'axes.labelcolor' in matplotlib.rcParams:\n                ylabelcolor = matplotlib.rcParams['axes.labelcolor']\n            else:\n                ylabelcolor = None\n\n            fig.text(0.08, 0.5, ylabel, ha='left', color=ylabelcolor,\n                     va='center', rotation='vertical', transform=ax.transAxes)\n        else:\n            ax.set_xlabel(xlabel)\n            ax.set_ylabel(ylabel)\n\n        return plt", "response": "Returns a matplotlib. pyplot object for the density of states for the specific\n               ."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_projections_by_branches(bs, selection, normalise=None):\n    spins = bs.bands.keys()\n    projections = get_projections(bs, selection, normalise=normalise)\n\n    branches = []\n    for b in bs.branches:\n        s = b['start_index']\n        e = b['end_index'] + 1\n\n        branch_proj = deepcopy(projections)\n        for spin, i in it.product(spins, range(len(projections))):\n            branch_proj[i][spin] = projections[i][spin][:, s:e]\n\n        branches.append(branch_proj)\n    return branches", "response": "Returns the orbital projections for each branch of a band structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_projections(bs, selection, normalise=None):\n    spins = bs.bands.keys()\n    nbands = bs.nb_bands\n    nkpts = len(bs.kpoints)\n\n    # if we are to normalise the data later we need access to all projections\n    elements = bs.structure.symbol_set\n    all_orbitals = ['s', 'p', 'd', 'f']\n\n    # dictio has the form: {'el1': [s, p, d, f], 'el2': [s, p, d, f]...}\n    dictio = dict(zip(elements, [all_orbitals] * len(elements)))\n\n    # bs.get_projection_on_elements_and_orbitals() returns the data in a\n    # really frustrating format, namely:\n    #     {spin: [band_index][kpoint_index]{element: {orbital: projection}}}\n    all_proj = bs.get_projections_on_elements_and_orbitals(dictio)\n\n    # Make a defaultdict of defaultdicts\n    dict_proj = defaultdict(lambda: defaultdict(dict))\n    sum_proj = dict(zip(spins, [np.zeros((nbands, nkpts))] * len(spins)))\n\n    # store the projections for all elements and orbitals in a useable format\n    for spin, element, orbital in it.product(spins, elements, all_orbitals):\n\n        # convert data to [nb][nk][projection]\n        el_orb_proj = [[all_proj[spin][nb][nk][element][orbital]\n                        for nk in range(nkpts)] for nb in range(nbands)]\n\n        dict_proj[element][orbital][spin] = np.array(el_orb_proj)\n\n        if normalise == 'all':\n            sum_proj[spin] += el_orb_proj\n\n    # now go through the selected orbitals and extract what's needed\n    spec_proj = []\n    for spec in selection:\n\n        if isinstance(spec, str):\n            # spec is just an element type, therefore sum all orbitals\n            element = spec\n            orbitals = all_orbitals\n        else:\n            element, orbitals = spec\n            # even if there is only one orbital, make sure we can loop over it\n            orbitals = tuple(orbitals)\n\n        proj = dict(zip(spins, [np.zeros((nbands, nkpts))] * len(spins)))\n        for spin, orbital in it.product(spins, orbitals):\n            proj[spin] += dict_proj[element][orbital][spin]\n\n            if normalise == 'select':\n                sum_proj[spin] += dict_proj[element][orbital][spin]\n\n        spec_proj.append(proj)\n\n    if normalise:\n        # to prevent warnings/errors relating to divide by zero,\n        # catch warnings and surround divide with np.nan_to_num\n        with np.errstate(divide='ignore', invalid='ignore'):\n            for spin, i in it.product(spins, range(len(spec_proj))):\n                spec_proj[i][spin] = np.nan_to_num(spec_proj[i][spin] /\n                                                   sum_proj[spin])\n    return spec_proj", "response": "Returns the orbital projections from a band structure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plot(self, zero_to_efermi=True, ymin=-6., ymax=6.,\n                 width=None, height=None, vbm_cbm_marker=False,\n                 ylabel='Energy (eV)',\n                 dpi=None, plt=None,\n                 dos_plotter=None, dos_options=None, dos_label=None,\n                 dos_aspect=3, aspect=None, fonts=None, style=None,\n                 no_base_style=False):\n        \"\"\"Get a :obj:`matplotlib.pyplot` object of the band structure.\n\n        If the system is spin polarised, orange lines are spin up, dashed\n        blue lines are spin down. For metals, all bands are coloured blue. For\n        semiconductors, blue lines indicate valence bands and orange lines\n        indicates conduction bands.\n\n        Args:\n            zero_to_efermi (:obj:`bool`): Normalise the plot such that the\n                valence band maximum is set as 0 eV.\n            ymin (:obj:`float`, optional): The minimum energy on the y-axis.\n            ymax (:obj:`float`, optional): The maximum energy on the y-axis.\n            width (:obj:`float`, optional): The width of the plot.\n            height (:obj:`float`, optional): The height of the plot.\n            vbm_cbm_marker (:obj:`bool`, optional): Plot markers to indicate\n                the VBM and CBM locations.\n            ylabel (:obj:`str`, optional): y-axis (i.e. energy) label/units\n            dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n                the image.\n            plt (:obj:`matplotlib.pyplot`, optional): A\n                :obj:`matplotlib.pyplot` object to use for plotting.\n            dos_plotter (:obj:`~sumo.plotting.dos_plotter.SDOSPlotter`, \\\n                optional): Plot the density of states alongside the band\n                structure. This should be a\n                :obj:`~sumo.plotting.dos_plotter.SDOSPlotter` object\n                initialised with the data to plot.\n            dos_options (:obj:`dict`, optional): The options for density of\n                states plotting. This should be formatted as a :obj:`dict`\n                containing any of the following keys:\n\n                    \"yscale\" (:obj:`float`)\n                        Scaling factor for the y-axis.\n                    \"xmin\" (:obj:`float`)\n                        The minimum energy to mask the energy and density of\n                        states data (reduces plotting load).\n                    \"xmax\" (:obj:`float`)\n                        The maximum energy to mask the energy and density of\n                        states data (reduces plotting load).\n                    \"colours\" (:obj:`dict`)\n                        Use custom colours for specific element and orbital\n                        combinations. Specified as a :obj:`dict` of\n                        :obj:`dict` of the colours. For example::\n\n                            {\n                                'Sn': {'s': 'r', 'p': 'b'},\n                                'O': {'s': '#000000'}\n                            }\n\n                        The colour can be a hex code, series of rgb value, or\n                        any other format supported by matplotlib.\n                    \"plot_total\" (:obj:`bool`)\n                        Plot the total density of states. Defaults to ``True``.\n                    \"legend_cutoff\" (:obj:`float`)\n                        The cut-off (in % of the maximum density of states\n                        within the plotting range) for an elemental orbital to\n                        be labelled in the legend. This prevents the legend\n                        from containing labels for orbitals that have very\n                        little contribution in the plotting range.\n                    \"subplot\" (:obj:`bool`)\n                        Plot the density of states for each element on separate\n                        subplots. Defaults to ``False``.\n\n            dos_label (:obj:`str`, optional): DOS axis label/units\n            dos_aspect (:obj:`float`, optional): Aspect ratio for the band\n                structure and density of states subplot. For example,\n                ``dos_aspect = 3``, results in a ratio of 3:1, for the band\n                structure:dos plots.\n            aspect (:obj:`float`, optional): The aspect ratio of the band\n                structure plot. By default the dimensions of the figure size\n                are used to determine the aspect ratio. Set to ``1`` to force\n                the plot to be square.\n            fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n                a single font, specified as a :obj:`str`, or several fonts,\n                specified as a :obj:`list` of :obj:`str`.\n            style (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n                style specifications, to be composed on top of Sumo base\n                style.\n            no_base_style (:obj:`bool`, optional): Prevent use of sumo base\n                style. This can make alternative styles behave more\n                predictably.\n\n        Returns:\n            :obj:`matplotlib.pyplot`: The electronic band structure plot.\n        \"\"\"\n        if dos_plotter:\n            plt = pretty_subplot(1, 2, width=width, height=height,\n                                 sharex=False, dpi=dpi,\n                                 plt=plt,\n                                 gridspec_kw={'width_ratios': [dos_aspect, 1],\n                                              'wspace': 0})\n            ax = plt.gcf().axes[0]\n        else:\n            plt = pretty_plot(width=width, height=height,\n                              dpi=dpi, plt=plt)\n            ax = plt.gca()\n\n        data = self.bs_plot_data(zero_to_efermi)\n        dists = data['distances']\n        eners = data['energy']\n\n        if self._bs.is_spin_polarized or self._bs.is_metal():\n            is_vb = [True]\n        else:\n            is_vb = self._bs.bands[Spin.up] <= self._bs.get_vbm()['energy']\n\n        # nd is branch index, nb is band index, nk is kpoint index\n        for nd, nb in it.product(range(len(data['distances'])),\n                                 range(self._nb_bands)):\n            e = eners[nd][str(Spin.up)][nb]\n\n            # For closed-shell calculations with a bandgap, colour valence\n            # bands blue (C0) and conduction bands orange (C1)\n            #\n            # For closed-shell calculations with no bandgap, colour with C0\n            #\n            # For spin-polarized calculations, colour spin up channel with C1\n            # and overlay with C0 (dashed) spin down channel\n\n            if self._bs.is_spin_polarized:\n                c = 'C1'\n            elif self._bs.is_metal() or np.all(is_vb[nb]):\n                c = 'C0'\n            else:\n                c = 'C1'\n\n            # plot band data\n            ax.plot(dists[nd], e, ls='-', c=c, zorder=1)\n\n        # Plot second spin channel if it exists\n        if self._bs.is_spin_polarized:\n            for nd, nb in it.product(range(len(data['distances'])),\n                                     range(self._nb_bands)):\n                e = eners[nd][str(Spin.down)][nb]\n                ax.plot(dists[nd], e, c='C0', linestyle='--', zorder=2)\n\n        self._maketicks(ax, ylabel=ylabel)\n        self._makeplot(ax, plt.gcf(), data, zero_to_efermi=zero_to_efermi,\n                       vbm_cbm_marker=vbm_cbm_marker, width=width,\n                       height=height, ymin=ymin, ymax=ymax,\n                       dos_plotter=dos_plotter, dos_options=dos_options,\n                       dos_label=dos_label, aspect=aspect)\n        return plt", "response": "Returns a Matplotlib. pyplot object for the given object of the band structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a matplotlib. pyplot object for the projected band structure.", "response": "def get_projected_plot(self, selection, mode='rgb', interpolate_factor=4,\n                           circle_size=150, projection_cutoff=0.001,\n                           zero_to_efermi=True, ymin=-6., ymax=6., width=None,\n                           height=None, vbm_cbm_marker=False,\n                           ylabel='Energy (eV)',\n                           dpi=400, plt=None,\n                           dos_plotter=None, dos_options=None, dos_label=None,\n                           dos_aspect=3, aspect=None, fonts=None, style=None,\n                           no_base_style=False):\n        \"\"\"Get a :obj:`matplotlib.pyplot` of the projected band structure.\n\n        If the system is spin polarised and ``mode = 'rgb'`` spin up and spin\n        down bands are differentiated by solid and dashed lines, respectively.\n        For the other modes, spin up and spin down are plotted separately.\n\n        Args:\n            selection (list): A list of :obj:`tuple` or :obj:`string`\n                identifying which elements and orbitals to project on to the\n                band structure. These can be specified by both element and\n                orbital, for example, the following will project the Bi s, p\n                and S p orbitals::\n\n                    [('Bi', 's'), ('Bi', 'p'), ('S', 'p')]\n\n                If just the element is specified then all the orbitals of\n                that element are combined. For example, to sum all the S\n                orbitals::\n\n                    [('Bi', 's'), ('Bi', 'p'), 'S']\n\n                You can also choose to sum particular orbitals by supplying a\n                :obj:`tuple` of orbitals. For example, to sum the S s, p, and\n                d orbitals into a single projection::\n\n                  [('Bi', 's'), ('Bi', 'p'), ('S', ('s', 'p', 'd'))]\n\n                If ``mode = 'rgb'``, a maximum of 3 orbital/element\n                combinations can be plotted simultaneously (one for red, green\n                and blue), otherwise an unlimited number of elements/orbitals\n                can be selected.\n            mode (:obj:`str`, optional): Type of projected band structure to\n                plot. Options are:\n\n                    \"rgb\"\n                        The band structure line color depends on the character\n                        of the band. Each element/orbital contributes either\n                        red, green or blue with the corresponding line colour a\n                        mixture of all three colours. This mode only supports\n                        up to 3 elements/orbitals combinations. The order of\n                        the ``selection`` :obj:`tuple` determines which colour\n                        is used for each selection.\n                    \"stacked\"\n                        The element/orbital contributions are drawn as a\n                        series of stacked circles, with the colour depending on\n                        the composition of the band. The size of the circles\n                        can be scaled using the ``circle_size`` option.\n\n            interpolate_factor (:obj:`int`, optional): The factor by which to\n                interpolate the band structure (necessary to make smooth\n                lines). A larger number indicates greater interpolation.\n            circle_size (:obj:`float`, optional): The area of the circles used\n                when ``mode = 'stacked'``.\n            projection_cutoff (:obj:`float`): Don't plot projections with\n                intensities below this number. This option is useful for\n                stacked plots, where small projections clutter the plot.\n            zero_to_efermi (:obj:`bool`): Normalise the plot such that the\n                valence band maximum is set as 0 eV.\n            ymin (:obj:`float`, optional): The minimum energy on the y-axis.\n            ymax (:obj:`float`, optional): The maximum energy on the y-axis.\n            width (:obj:`float`, optional): The width of the plot.\n            height (:obj:`float`, optional): The height of the plot.\n            vbm_cbm_marker (:obj:`bool`, optional): Plot markers to indicate\n                the VBM and CBM locations.\n            ylabel (:obj:`str`, optional): y-axis (i.e. energy) label/units\n            dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n                the image.\n            plt (:obj:`matplotlib.pyplot`, optional): A\n                :obj:`matplotlib.pyplot` object to use for plotting.\n            dos_plotter (:obj:`~sumo.plotting.dos_plotter.SDOSPlotter`, \\\n                optional): Plot the density of states alongside the band\n                structure. This should be a\n                :obj:`~sumo.plotting.dos_plotter.SDOSPlotter` object\n                initialised with the data to plot.\n            dos_options (:obj:`dict`, optional): The options for density of\n                states plotting. This should be formatted as a :obj:`dict`\n                containing any of the following keys:\n\n                    \"yscale\" (:obj:`float`)\n                        Scaling factor for the y-axis.\n                    \"xmin\" (:obj:`float`)\n                        The minimum energy to mask the energy and density of\n                        states data (reduces plotting load).\n                    \"xmax\" (:obj:`float`)\n                        The maximum energy to mask the energy and density of\n                        states data (reduces plotting load).\n                    \"colours\" (:obj:`dict`)\n                        Use custom colours for specific element and orbital\n                        combinations. Specified as a :obj:`dict` of\n                        :obj:`dict` of the colours. For example::\n\n                           {\n                                'Sn': {'s': 'r', 'p': 'b'},\n                                'O': {'s': '#000000'}\n                            }\n\n                        The colour can be a hex code, series of rgb value, or\n                        any other format supported by matplotlib.\n                    \"plot_total\" (:obj:`bool`)\n                        Plot the total density of states. Defaults to ``True``.\n                    \"legend_cutoff\" (:obj:`float`)\n                        The cut-off (in % of the maximum density of states\n                        within the plotting range) for an elemental orbital to\n                        be labelled in the legend. This prevents the legend\n                        from containing labels for orbitals that have very\n                        little contribution in the plotting range.\n                    \"subplot\" (:obj:`bool`)\n                        Plot the density of states for each element on separate\n                        subplots. Defaults to ``False``.\n\n            dos_label (:obj:`str`, optional): DOS axis label/units\n            dos_aspect (:obj:`float`, optional): Aspect ratio for the band\n                structure and density of states subplot. For example,\n                ``dos_aspect = 3``, results in a ratio of 3:1, for the band\n                structure:dos plots.\n            aspect (:obj:`float`, optional): The aspect ratio of the band\n                structure plot. By default the dimensions of the figure size\n                are used to determine the aspect ratio. Set to ``1`` to force\n                the plot to be square.\n            fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n                a single font, specified as a :obj:`str`, or several fonts,\n                specified as a :obj:`list` of :obj:`str`.\n            style (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n                style specifications, to be composed on top of Sumo base\n                style.\n            no_base_style (:obj:`bool`, optional): Prevent use of sumo base\n                style. This can make alternative styles behave more\n                predictably.\n\n        Returns:\n            :obj:`matplotlib.pyplot`: The projected electronic band structure\n            plot.\n        \"\"\"\n        if mode == 'rgb' and len(selection) > 3:\n            raise ValueError('Too many elements/orbitals specified (max 3)')\n        elif mode == 'solo' and dos_plotter:\n            raise ValueError('Solo mode plotting with DOS not supported')\n\n        if dos_plotter:\n            plt = pretty_subplot(1, 2, width, height, sharex=False, dpi=dpi,\n                                 plt=plt,\n                                 gridspec_kw={'width_ratios': [dos_aspect, 1],\n                                              'wspace': 0})\n            ax = plt.gcf().axes[0]\n        else:\n            plt = pretty_plot(width, height, dpi=dpi, plt=plt)\n            ax = plt.gca()\n\n        data = self.bs_plot_data(zero_to_efermi)\n        nbranches = len(data['distances'])\n\n        # Ensure we do spin up first, then spin down\n        spins = sorted(self._bs.bands.keys(), key=lambda s: -s.value)\n\n        proj = get_projections_by_branches(self._bs, selection,\n                                           normalise='select')\n\n        # nd is branch index\n        for spin, nd in it.product(spins, range(nbranches)):\n\n            # mask data to reduce plotting load\n            bands = np.array(data['energy'][nd][str(spin)])\n            mask = np.where(np.any(bands > ymin - 0.05, axis=1) &\n                            np.any(bands < ymax + 0.05, axis=1))\n            distances = data['distances'][nd]\n            bands = bands[mask]\n            weights = [proj[nd][i][spin][mask] for i in range(len(selection))]\n\n            # interpolate band structure to improve smoothness\n            dx = (distances[1] - distances[0]) / interpolate_factor\n            temp_dists = np.arange(distances[0], distances[-1], dx)\n            bands = interp1d(distances, bands, axis=1)(temp_dists)\n            weights = interp1d(distances, weights, axis=2)(temp_dists)\n            distances = temp_dists\n\n            # sometimes VASP produces very small negative weights\n            weights[weights < 0] = 0\n\n            if mode == 'rgb':\n\n                # colours aren't used now but needed later for legend\n                colours = ['#ff0000', '#00ff00', '#0000ff']\n\n                # if only two orbitals then just use red and blue\n                if len(weights) == 2:\n                    weights = np.insert(weights, 1, np.zeros(weights[0].shape),\n                                        axis=0)\n                    colours = ['#ff0000', '#0000ff']\n\n                ls = '-' if spin == Spin.up else '--'\n                lc = rgbline(distances, bands, weights[0], weights[1],\n                             weights[2], alpha=1, linestyles=ls,\n                             linewidth=(rcParams['lines.linewidth'] * 1.25))\n                ax.add_collection(lc)\n\n            elif mode == 'stacked':\n                # TODO: Handle spin\n\n                # use some nice custom colours first, then default colours\n                colours = ['#3952A3', '#FAA41A', '#67BC47', '#6ECCDD',\n                           '#ED2025']\n                colour_series = rcParams['axes.prop_cycle'].by_key()['color']\n                colours.extend(colour_series)\n\n                # very small circles look crap\n                weights[weights < projection_cutoff] = 0\n\n                distances = list(distances) * len(bands)\n                bands = bands.flatten()\n                zorders = range(-len(weights), 0)\n                for w, c, z in zip(weights, colours, zorders):\n                    ax.scatter(distances, bands, c=c, s=circle_size * w ** 2,\n                               zorder=z, rasterized=True)\n\n        # plot the legend\n        for c, spec in zip(colours, selection):\n            if isinstance(spec, str):\n                label = spec\n            else:\n                label = '{} ({})'.format(spec[0], \" + \".join(spec[1]))\n            ax.scatter([-10000], [-10000], c=c, s=50, label=label,\n                       edgecolors='none')\n\n        if dos_plotter:\n            loc = 1\n            anchor_point = (-0.2, 1)\n        else:\n            loc = 2\n            anchor_point = (0.95, 1)\n\n        ax.legend(bbox_to_anchor=anchor_point, loc=loc, frameon=False,\n                  handletextpad=0.1, scatterpoints=1)\n\n        # finish and tidy plot\n        self._maketicks(ax, ylabel=ylabel)\n        self._makeplot(ax, plt.gcf(), data, zero_to_efermi=zero_to_efermi,\n                       vbm_cbm_marker=vbm_cbm_marker, width=width,\n                       height=height, ymin=ymin, ymax=ymax,\n                       dos_plotter=dos_plotter, dos_options=dos_options,\n                       dos_label=dos_label, aspect=aspect)\n        return plt"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _makeplot(self, ax, fig, data, zero_to_efermi=True,\n                  vbm_cbm_marker=False, ymin=-6., ymax=6.,\n                  height=None, width=None,\n                  dos_plotter=None, dos_options=None, dos_label=None,\n                  aspect=None):\n        \"\"\"Tidy the band structure & add the density of states if required.\"\"\"\n        # draw line at Fermi level if not zeroing to e-Fermi\n        if not zero_to_efermi:\n            ytick_color = rcParams['ytick.color']\n            ef = self._bs.efermi\n            ax.axhline(ef, color=ytick_color)\n\n        # set x and y limits\n        ax.set_xlim(0, data['distances'][-1][-1])\n        if self._bs.is_metal() and not zero_to_efermi:\n            ax.set_ylim(self._bs.efermi + ymin, self._bs.efermi + ymax)\n        else:\n            ax.set_ylim(ymin, ymax)\n\n        if vbm_cbm_marker:\n            for cbm in data['cbm']:\n                ax.scatter(cbm[0], cbm[1], color='C2', marker='o', s=100)\n            for vbm in data['vbm']:\n                ax.scatter(vbm[0], vbm[1], color='C3', marker='o', s=100)\n\n        if dos_plotter:\n            ax = fig.axes[1]\n\n            if not dos_options:\n                dos_options = {}\n\n            dos_options.update({'xmin': ymin, 'xmax': ymax})\n            self._makedos(ax, dos_plotter, dos_options, dos_label=dos_label)\n        else:\n            # keep correct aspect ratio for axes based on canvas size\n            x0, x1 = ax.get_xlim()\n            y0, y1 = ax.get_ylim()\n            if width is None:\n                width = rcParams['figure.figsize'][0]\n            if height is None:\n                height = rcParams['figure.figsize'][1]\n\n            if not aspect:\n                aspect = height / width\n\n            ax.set_aspect(aspect * ((x1 - x0) / (y1 - y0)))", "response": "Make the band structure and add the density of states if required."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _sanitise_label_group(cls, labelgroup):\n\n        if r'$\\mid$' in labelgroup:\n            label_components = labelgroup.split(r'$\\mid$')\n            good_labels = [l for l in\n                           map(cls._sanitise_label, label_components)\n                           if l is not None]\n            if len(good_labels) == 0:\n                return None\n            else:\n                return r'$\\mid$'.join(good_labels)\n        else:\n            return cls._sanitise_label(labelgroup)", "response": "Implement label hacks for label groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_plot(self, width=None, height=None, xmin=0., xmax=None, ymin=0,\n                 ymax=None, colours=None, dpi=400, plt=None, fonts=None,\n                 style=None, no_base_style=False):\n        \"\"\"Get a :obj:`matplotlib.pyplot` object of the optical spectra.\n\n        Args:\n            width (:obj:`float`, optional): The width of the plot.\n            height (:obj:`float`, optional): The height of the plot.\n            xmin (:obj:`float`, optional): The minimum energy on the x-axis.\n            xmax (:obj:`float`, optional): The maximum energy on the x-axis.\n            ymin (:obj:`float`, optional): The minimum absorption intensity on\n                the y-axis.\n            ymax (:obj:`float`, optional): The maximum absorption intensity on\n                the y-axis.\n            colours (:obj:`list`, optional): A :obj:`list` of colours to use in\n                the plot. The colours can be specified as a hex code, set of\n                rgb values, or any other format supported by matplotlib.\n            dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n                the image.\n            plt (:obj:`matplotlib.pyplot`, optional): A\n                :obj:`matplotlib.pyplot` object to use for plotting.\n            fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n                a single font, specified as a :obj:`str`, or several fonts,\n                specified as a :obj:`list` of :obj:`str`.\n            style (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n                style specifications, to be composed on top of Sumo base\n                style.\n            no_base_style (:obj:`bool`, optional): Prevent use of sumo base\n                style. This can make alternative styles behave more\n                predictably.\n\n        Returns:\n            :obj:`matplotlib.pyplot`: The plot of optical spectra.\n        \"\"\"\n        n_plots = len(self._spec_data)\n        plt = pretty_subplot(n_plots, 1, sharex=True, sharey=False,\n                             width=width, height=height,\n                             dpi=dpi, plt=plt)\n        fig = plt.gcf()\n\n        optics_colours = rcParams['axes.prop_cycle'].by_key()['color']\n        if colours is not None:\n            optics_colours = colours + optics_colours\n\n        standard_ylabels = {\n            'absorption': r'Absorption (cm$^\\mathregular{-1}$)',\n            'loss': r'Energy-loss',\n            'eps_real': r'Re($\\epsilon$)',\n            'eps_imag': r'Im($\\epsilon$)',\n            'n_real': r'Re(n)',\n            'n_imag': r'Im(n)'}\n\n        if ymax is None:\n            ymax_series = [None] * n_plots\n        elif isinstance(ymax, float) or isinstance(ymax, int):\n            ymax_series = [ymax] * n_plots\n        elif not isinstance(ymax, list):\n            raise ValueError()\n        else:\n            ymax_series = ymax\n\n        if ymin is None:\n            ymin_series = [None] * n_plots\n        elif isinstance(ymin, float) or isinstance(ymin, int):\n            ymin_series = [ymin] * n_plots\n        elif not isinstance(ymin, list):\n            raise ValueError()\n        else:\n            ymin_series = ymin\n\n        for i, (spectrum_key, data), ymin, ymax in zip(range(n_plots),\n                                                       self._spec_data.items(),\n                                                       ymin_series,\n                                                       ymax_series):\n            ax = fig.axes[i]\n            _plot_spectrum(data, self._label, self._band_gap,\n                           ax, optics_colours)\n\n            xmax = xmax if xmax else self._xmax\n            ax.set_xlim(xmin, xmax)\n\n            if ymin is None and spectrum_key in ('absorption', 'loss',\n                                                 'eps_imag', 'n_imag'):\n                ymin = 0\n            elif ymin is None:\n                ymin = ax.get_ylim()[0]\n\n            if ymax is None and spectrum_key in ('absorption',):\n                ymax = 1e5\n            elif ymax is None:\n                ymax = ax.get_ylim()[1]\n\n            ax.set_ylim(ymin, ymax)\n\n            if spectrum_key == 'absorption':\n                font = findfont(FontProperties(family=['sans-serif']))\n                if 'Whitney' in font:\n                    times_sign = 'x'\n                else:\n                    times_sign = r'\\times'\n                ax.yaxis.set_major_formatter(\n                    FuncFormatter(curry_power_tick(times_sign=times_sign)))\n\n            ax.yaxis.set_major_locator(MaxNLocator(5))\n            ax.xaxis.set_major_locator(MaxNLocator(3))\n            ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n            ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n\n            ax.set_ylabel(standard_ylabels.get(spectrum_key, spectrum_key))\n\n            if i == 0:\n                if (not np.all(np.array(self._label) == '') or\n                        len(np.array(next(iter(\n                            self._spec_data.items()))[1][0][1]).shape) > 1):\n                    ax.legend(loc='best', frameon=False, ncol=1)\n\n        ax.set_xlabel('Energy (eV)')\n\n        # If only one plot, fix aspect ratio to match canvas\n        if len(self._spec_data) == 1:\n            x0, x1 = ax.get_xlim()\n            y0, y1 = ax.get_ylim()\n            if width is None:\n                width = rcParams['figure.figsize'][0]\n            if height is None:\n                height = rcParams['figure.figsize'][1]\n            ax.set_aspect((height/width) * ((x1-x0)/(y1-y0)))\n\n        # Otherwise, rely only on tight_layout and hope for the best\n        plt.tight_layout()\n        return plt", "response": "Returns a matplotlib. pyplot object that can be used to plot the optical spectra."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef correct_structure(self, atol=1e-8):\n        return np.allclose(self.structure.lattice.matrix,\n                           self.prim.lattice.matrix, atol=atol)", "response": "Determine if the structure matches the standard primitive structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of k - points along the high - symmetry path and labels along the high - symmetry path.", "response": "def get_kpoints(self, line_density=20, cart_coords=False, phonopy=False):\n        r\"\"\"Return a list of k-points and labels along the high-symmetry path.\n\n        The format of the returned data will be different if phonopy is\n        ``True`` or ``False``. This is because phonopy requires the labels and\n        kpoints to be provided in a different format than kgen.\n\n        Adapted from\n        :obj:`pymatgen.symmetry.bandstructure.HighSymmKpath.get_kpoints`.\n\n        Args:\n            line_density (:obj:`int`, optional): Density of k-points along the\n                path.\n            cart_coords (:obj:`bool`, optional): Whether the k-points are\n                returned in cartesian or reciprocal coordinates. Defaults to\n                ``False`` (fractional coordinates).\n            phonopy (:obj:`bool`, optional): Format the k-points and labels for\n                use with phonopy. Defaults to ``False``.\n\n        Returns:\n            tuple: A :obj:`tuple` of the k-points along the high-symmetry path,\n            and k-point labels. Returned as ``(kpoints, labels)``.\n\n            If ``phonopy == False``, then:\n\n                * ``kpoints`` is a :obj:`numpy.ndarray` of the k-point\n                  coordinates along the high-symmetry path. For example::\n\n                      [[0, 0, 0], [0.25, 0, 0], [0.5, 0, 0], [0.5, 0, 0.25],\n                       [0.5, 0, 0.5]]\n\n                * ``labels`` is a :obj:`list` of the high symmetry labels for\n                  each k-point (will be an empty :obj:`str` if the k-point has\n                  no label). For example::\n\n                      ['\\Gamma', '', 'X', '', 'Y']\n\n            If ``phonopy == True``, then:\n\n                * ``kpoints`` is a :obj:`list` of :obj:`numpy.ndarray`\n                  containing the k-points for each branch of the band\n                  structure. This means that the first and last k-points of a\n                  particular branch may be repeated. For example::\n\n                      [[[0, 0, 0], [0.25, 0, 0], [0.5, 0, 0]],\n                       [[0.5, 0, 0], [0.5, 0, 0.25], [0.5, 0, 0.5]]]\n\n                * ``labels`` is a :obj:`list` of the high symmetry labels.\n                  For example::\n\n                      ['\\Gamma', 'X', 'Y']\n        \"\"\"\n        list_k_points = []\n        sym_point_labels = []\n        recip_lattice = self.structure.lattice.reciprocal_lattice\n        for b in self.path:\n            for i in range(1, len(b)):\n                start = np.array(self.kpoints[b[i - 1]])\n                end = np.array(self.kpoints[b[i]])\n                distance = np.linalg.norm(\n                    recip_lattice.get_cartesian_coords(start) -\n                    recip_lattice.get_cartesian_coords(end))\n                nb = int(np.ceil(distance * line_density))\n                sym_point_labels.extend([b[i - 1]] + [''] * (nb - 1))\n\n                limit = nb + 1 if phonopy else nb\n                kpts = [recip_lattice.get_cartesian_coords(start)\n                        + float(i) / float(nb) *\n                        (recip_lattice.get_cartesian_coords(end)\n                        - recip_lattice.get_cartesian_coords(start))\n                        for i in range(0, limit)]\n\n                if phonopy:\n                    list_k_points.append(kpts)\n                else:\n                    list_k_points.extend(kpts)\n\n            # append last k-point to avoid repetition as in pymatgen\n            if not phonopy:\n                # for VASP we label every k-point. If a k-point has no\n                # high-symmetry label then just use an empty string.\n                sym_point_labels.append(b[-1])\n                list_k_points.append(recip_lattice.get_cartesian_coords(end))\n\n        if phonopy:\n            # For phonopy, the labels for any discontinuities should be\n            # combined. For example if the route is  X -> Y | Z -> R, the path\n            # will be [['X', 'Y'], ['Z', 'R']], and the labels should be\n            # ['X', 'Z', 'R']\n\n            sym_point_labels = []\n            for i, path_branch in enumerate(self.path):\n                for n, label in enumerate(path_branch):\n                    if i != 0 and n == 0:\n                        sym_point_labels[-1] += \" | {}\".format(label)\n                    else:\n                        sym_point_labels.append(label)\n\n        if cart_coords:\n            return list_k_points, sym_point_labels\n        else:\n            if phonopy:\n                frac_k_points = [[recip_lattice.get_fractional_coords(k)\n                                 for k in p] for p in list_k_points]\n                frac_k_points = frac_k_points\n            else:\n                frac_k_points = [recip_lattice.get_fractional_coords(k)\n                                 for k in list_k_points]\n            return frac_k_points, sym_point_labels"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_lattice_type(number):\n        f = lambda i, j: i <= number <= j\n        cs = {'triclinic': (1, 2), 'monoclinic': (3, 15),\n              'orthorhombic': (16, 74), 'tetragonal': (75, 142),\n              'trigonal': (143, 167), 'hexagonal': (168, 194),\n              'cubic': (195, 230)}\n\n        crystal_system = None\n        for k, v in cs.items():\n            if f(*v):\n                crystal_system = k\n                break\n\n        if number in [146, 148, 155, 160, 161, 166, 167]:\n            return \"rhombohedral\"\n        elif crystal_system == \"trigonal\":\n            return \"hexagonal\"\n        else:\n            return crystal_system", "response": "Return the crystal system type of the international space group number."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nextract fitting data for a specific band extrema.", "response": "def get_fitting_data(bs, spin, band_id, kpoint_id, num_sample_points=3):\n    \"\"\"Extract fitting data for band extrema based on spin, kpoint and band.\n\n    Searches forward and backward from the extrema point, but will only sample\n    there data if there are enough points in that direction.\n\n    Args:\n        bs (:obj:`~pymatgen.electronic_structure.bandstructure.BandStructureSymmLine`):\n            The band structure.\n        spin (:obj:`~pymatgen.electronic_structure.core.Spin`): Which spin\n            channel to sample.\n        band_id (int): Index of the band to sample.\n        kpoint_id (int): Index of the kpoint to sample.\n\n    Returns:\n        list: The data necessary to calculate the effective mass, along with\n        some metadata. Formatted as a :obj:`list` of :obj:`dict`, each with the\n        keys:\n\n        'energies' (:obj:`numpy.ndarray`)\n            Band eigenvalues in eV.\n\n        'distances' (:obj:`numpy.ndarray`)\n            Distances of the k-points in reciprocal space.\n\n        'band_id' (:obj:`int`)\n            The index of the band,\n\n        'spin' (:obj:`~pymatgen.electronic_structure.core.Spin`)\n            The spin channel\n\n        'start_kpoint' (:obj:`int`)\n            The index of the k-point at which the band extrema occurs\n\n        'end_kpoint' (:obj:`int`)\n            The k-point towards which the data has been sampled.\n    \"\"\"\n    # branch data provides data about the start and end points\n    # of specific band paths\n    branch_data = [b for b in bs.get_branch(kpoint_id)\n                   if b['index'] == kpoint_id][0]\n    start_kpoint = bs.kpoints[kpoint_id]\n\n    fitting_data = []\n\n    # check to see if there are enough points to sample from first\n    # check in the forward direction\n    if kpoint_id + num_sample_points <= branch_data['end_index']:\n\n        # calculate sampling limits\n        start_id = kpoint_id\n        end_id = kpoint_id + num_sample_points + 1\n\n        energies = np.array(bs.bands[spin][band_id][start_id:end_id].copy())\n        dists = np.array(bs.distance[start_id:end_id].copy())\n\n        # normalise eigenvalues and distances to starting point\n        energies -= bs.bands[spin][band_id][kpoint_id]\n        dists -= bs.distance[kpoint_id]\n\n        # symmetrise the data to make fitting more reliable\n        energies = np.concatenate([energies[::-1], energies[1:]])\n        dists = np.concatenate([-dists[::-1], dists[1:]])\n\n        end_kpoint = bs.kpoints[branch_data['end_index']]\n        data = {'energies': energies, 'distances': dists, 'band_id': band_id,\n                'spin': spin, 'start_kpoint': start_kpoint,\n                'end_kpoint': end_kpoint}\n        fitting_data.append(data)\n\n    # check in the backward direction\n    if kpoint_id - num_sample_points >= branch_data['start_index']:\n\n        # calculate sampling limits\n        start_id = kpoint_id - num_sample_points\n        end_id = kpoint_id + 1\n\n        energies = bs.bands[spin][band_id][start_id:end_id].copy()\n        dists = bs.distance[start_id:end_id].copy()\n\n        # normalise eigenvalues and distances to starting point\n        energies -= bs.bands[spin][band_id][kpoint_id]\n        dists -= bs.distance[kpoint_id]\n\n        # symmetrise the data to make fitting more reliable\n        energies = np.concatenate([energies[:-1], energies[::-1]])\n        dists = np.concatenate([dists[:-1], -dists[::-1]])\n\n        end_kpoint = bs.kpoints[branch_data['start_index']]\n        data = {'energies': energies, 'distances': dists, 'band_id': band_id,\n                'spin': spin, 'start_kpoint': start_kpoint,\n                'end_kpoint': end_kpoint}\n        fitting_data.append(data)\n\n    return fitting_data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nfitting the effective masses of the k - points in the current band to the k - points in the given energies.", "response": "def fit_effective_mass(distances, energies, parabolic=True):\n    \"\"\"Fit the effective masses using either a parabolic or nonparabolic fit.\n\n    Args:\n        distances (:obj:`numpy.ndarray`): The x-distances between k-points in\n            reciprocal Angstroms, normalised to the band extrema.\n        energies (:obj:`numpy.ndarray`): The band eigenvalues normalised to the\n            eigenvalue of the band extrema.\n        parabolic (:obj:`bool`, optional): Use a parabolic fit of the band\n            edges. If ``False`` then nonparabolic fitting will be attempted.\n            Defaults to ``True``.\n\n    Returns:\n        float: The effective mass in units of electron rest mass, :math:`m_0`.\n    \"\"\"\n    if parabolic:\n        fit = np.polyfit(distances, energies, 2)\n        c = 2 * fit[0]  # curvature therefore 2 * the exponent on the ^2 term\n\n    else:\n        # Use non parabolic description of the bands\n        def f(x, alpha, d):\n            top = np.sqrt(4 * alpha * d * x**2 + 1) - 1\n            bot = 2 * alpha\n            return top / bot\n\n        # set boundaries for curve fitting: alpha > 1e-8\n        # as alpha = 0 causes an error\n        bounds = ((1e-8, -np.inf), (np.inf, np.inf))\n        popt, _ = curve_fit(f, distances, energies, p0=[1., 1.],\n                            bounds=bounds)\n        c = 2 * popt[1]\n\n    # coefficient is currently in eV/Angstrom^2/h_bar^2\n    # want it in atomic units so Hartree/bohr^2/h_bar^2\n    eff_mass = (angstrom_to_bohr**2 / eV_to_hartree) / c\n    return eff_mass"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_path_data(structure, mode='bradcrack', symprec=0.01, spg=None,\n                  line_density=60, cart_coords=False, kpt_list=None,\n                  labels=None, phonopy=False):\n    r\"\"\"Get the k-point path, coordinates and symmetry labels for a structure.\n\n    If a manual :obj:`list` of kpoints is supplied using the ``kpt_list``\n    variable, the ``mode`` option will be ignored.\n\n    The format of the returned data will be different if phonopy is ``True`` or\n    ``False``. This is because phonopy requires the labels and kpoints to be\n    provided in a different format than kgen.\n\n    Args:\n        structure (:obj:`~pymatgen.core.structure.Structure`): The structure.\n        mode (:obj:`str`, optional): Method used for calculating the\n            high-symmetry path. The options are:\n\n            bradcrack\n                Use the paths from Bradley and Cracknell. See [brad]_.\n\n            pymatgen\n                Use the paths from pymatgen. See [curt]_.\n\n            seekpath\n                Use the paths from SeeK-path. See [seek]_.\n\n        symprec (:obj:`float`, optional): The tolerance for determining the\n            crystal symmetry.\n        spg (:obj:`~pymatgen.symmetry.groups.SpaceGroup`, optional): Space\n            group used to override the symmetry determined by spglib. This is\n            not recommended and only provided for testing purposes.\n            This option will only take effect when ``mode = 'bradcrack'``.\n        line_density (:obj:`int`, optional): Density of k-points along the\n            path.\n        cart_coords (:obj:`bool`, optional): Whether the k-points are returned\n            in cartesian or reciprocal coordinates. Defaults to ``False``\n            (fractional coordinates).\n        kpt_list (:obj:`list`, optional): List of k-points to use, formatted as\n            a list of subpaths, each containing a list of fractional k-points.\n            For example::\n\n                [ [[0., 0., 0.], [0., 0., 0.5]],\n                  [[0.5, 0., 0.], [0.5, 0.5, 0.]] ]\n\n            Will return points along ``0 0 0 -> 0 0 1/2 | 1/2 0 0\n            -> 1/2 1/2 0``\n        path_labels (:obj:`list`, optional): The k-point labels. These should\n            be provided as a :obj:`list` of :obj:`str` for each subpath of the\n            overall path. For example::\n\n                [ ['Gamma', 'Z'], ['X', 'M'] ]\n\n            combined with the above example for ``kpt_list`` would indicate the\n            path: Gamma -> Z | X -> M. If no labels are provided, letters from\n            A -> Z will be used instead.\n        phonopy (:obj:`bool`, optional): Format the k-points and labels for\n            use with phonopy. Defaults to ``False``.\n\n    Returns:\n        tuple: A tuple of a :obj:`~sumo.symmetry.kpath` object, the k-points\n        along the high-symmetry path, and the k-point labels. Returned as\n        ``(kpath, kpoints, labels)``.\n\n        The type of ``kpath`` object will depend on the value of ``mode`` and\n        whether ``kpt_list`` is set.\n\n        If ``phonopy == False``, then:\n\n            * ``kpoints`` is a :obj:`numpy.ndarray` of the k-point\n                coordinates along the high-symmetry path. For example::\n\n                    [[0, 0, 0], [0.25, 0, 0], [0.5, 0, 0], [0.5, 0, 0.25],\n                    [0.5, 0, 0.5]]\n\n            * ``labels`` is a :obj:`list` of the high symmetry labels for\n                each k-point (will be an empty :obj:`str` if the k-point has\n                no label). For example::\n\n                    ['\\Gamma', '', 'X', '', 'Y']\n\n        If ``phonopy == True``, then:\n\n            * ``kpoints`` is a :obj:`list` of :obj:`numpy.ndarray`\n                containing the k-points for each branch of the band\n                structure. This means that the first and last k-points of a\n                particular branch may be repeated. For example::\n\n                    [[[0, 0, 0], [0.25, 0, 0], [0.5, 0, 0]],\n                    [[0.5, 0, 0], [0.5, 0, 0.25], [0.5, 0, 0.5]]]\n\n            * ``labels`` is a :obj:`list` of the high symmetry labels.\n                For example::\n\n                    ['\\Gamma', 'X', 'Y']\n    \"\"\"\n    from sumo.symmetry import (BradCrackKpath, SeekpathKpath, PymatgenKpath,\n                               CustomKpath)\n    spg = _get_space_group_object(spg, mode)\n\n    if kpt_list:\n        kpath = CustomKpath(structure, kpt_list, labels, symprec=symprec)\n    elif mode == 'bradcrack':\n        kpath = BradCrackKpath(structure, symprec=symprec, spg=spg)\n    elif mode == 'seekpath':\n        kpath = SeekpathKpath(structure, symprec=symprec)\n    elif mode == 'pymatgen':\n        kpath = PymatgenKpath(structure, symprec=symprec)\n\n    kpoints, labels = kpath.get_kpoints(line_density=line_density,\n                                        phonopy=phonopy)\n    path_str = kpath.path_string\n    kpt_dict = kpath.kpoints\n\n    logging.info('Structure information:')\n    logging.info('\\tSpace group number: {}'.format(kpath._spg_data['number']))\n\n    logging.info('\\tInternational symbol: {}'.format(kpath.spg_symbol))\n    logging.info('\\tLattice type: {}'.format(kpath.lattice_type))\n\n    logging.info('\\nk-point path:\\n\\t{}'.format(path_str))\n    logging.info('\\nk-points:')\n\n    for label, kpoint in iter(kpt_dict.items()):\n        coord_str = ' '.join(['{}'.format(c) for c in kpoint])\n        logging.info('\\t{}: {}'.format(label, coord_str))\n\n    return kpath, kpoints, labels", "response": "r Returns the data for a high - symmetry path in a structure."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a decorator that will apply matplotlib style sheets to a single object.", "response": "def styled_plot(*style_sheets):\n    \"\"\"Return a decorator that will apply matplotlib style sheets to a plot.\n\n    ``style_sheets`` is a base set of styles, which will be ignored if\n    ``no_base_style`` is set in the decorated function arguments.\n\n    The style will further be overwritten by any styles in the ``style``\n    optional argument of the decorated function.\n\n    Args:\n        style_sheets (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n            supported definition of a style sheet. Can be a list of style of\n            style sheets.\n    \"\"\"\n\n    def decorator(get_plot):\n\n        def wrapper(*args, fonts=None, style=None, no_base_style=False,\n                    **kwargs):\n\n            if no_base_style:\n                list_style = []\n            else:\n                list_style = list(style_sheets)\n\n            if style is not None:\n                if isinstance(style, list):\n                    list_style += style\n                else:\n                    list_style += [style]\n\n            if fonts is not None:\n                list_style += [{'font.family': 'sans-serif',\n                               'font.sans-serif': fonts}]\n\n            matplotlib.pyplot.style.use(list_style)\n            return get_plot(*args, **kwargs)\n\n        return wrapper\n    return decorator"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pretty_plot(width=None, height=None, plt=None, dpi=None):\n\n    if plt is None:\n        plt = matplotlib.pyplot\n        if width is None:\n            width = matplotlib.rcParams['figure.figsize'][0]\n        if height is None:\n            height = matplotlib.rcParams['figure.figsize'][1]\n\n        if dpi is not None:\n            matplotlib.rcParams['figure.dpi'] = dpi\n\n        fig = plt.figure(figsize=(width, height))\n        fig.add_subplot(1, 1, 1)\n\n    return plt", "response": "Returns a matplotlib. pyplot object with the specified width height and figure."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pretty_subplot(nrows, ncols, width=None, height=None, sharex=True,\n                   sharey=True, dpi=None, plt=None, gridspec_kw=None):\n    \"\"\"Get a :obj:`matplotlib.pyplot` subplot object with pretty defaults.\n\n    Args:\n        nrows (int): The number of rows in the subplot.\n        ncols (int): The number of columns in the subplot.\n        width (:obj:`float`, optional): The width of the plot.\n        height (:obj:`float`, optional): The height of the plot.\n        sharex (:obj:`bool`, optional): All subplots share the same x-axis.\n            Defaults to ``True``.\n        sharey (:obj:`bool`, optional): All subplots share the same y-axis.\n            Defaults to ``True``.\n        dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n            the plot.\n        plt (:obj:`matplotlib.pyplot`, optional): A :obj:`matplotlib.pyplot`\n            object to use for plotting.\n        gridspec_kw (:obj:`dict`, optional): Gridspec parameters. Please see:\n            :obj:`matplotlib.pyplot.subplot` for more information. Defaults\n            to ``None``.\n\n    Returns:\n        :obj:`matplotlib.pyplot`: A :obj:`matplotlib.pyplot` subplot object\n        with publication ready defaults set.\n    \"\"\"\n\n    if width is None:\n        width = rcParams['figure.figsize'][0]\n    if height is None:\n        height = rcParams['figure.figsize'][1]\n\n    # TODO: Make this work if plt is already set...\n    if plt is None:\n        plt = matplotlib.pyplot\n        plt.subplots(nrows, ncols, sharex=sharex, sharey=sharey, dpi=dpi,\n                     figsize=(width, height), facecolor='w',\n                     gridspec_kw=gridspec_kw)\n\n    return plt", "response": "Returns a matplotlib. pyplot. subplot object with pretty defaults set."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef power_tick(val, pos, times_sign=r'\\times'):\n    if val == 0:\n        return r'$\\mathregular{0}$'\n    elif val < 0:\n        exponent = int(np.log10(-val))\n    else:\n        exponent = int(np.log10(val))\n    coeff = val / 10**exponent\n\n    return r'$\\mathregular{{{:.1f} {} 10^{:2d}}}$'.format(coeff,\n                                                          times_sign,\n                                                          exponent)", "response": "Custom power ticker function."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef rgbline(x, y, red, green, blue, alpha=1, linestyles=\"solid\",\n            linewidth=2.5):\n    \"\"\"Get a RGB coloured line for plotting.\n\n    Args:\n        x (list): x-axis data.\n        y (list): y-axis data (can be multidimensional array).\n        red (list): Red data (must have same shape as ``y``).\n        green (list): Green data (must have same shape as ``y``).\n        blue (list): blue data (must have same shape as ``y``).\n        alpha (:obj:`list` or :obj:`int`, optional): Alpha (transparency)\n            data (must have same shape as ``y`` or be an :obj:`int`).\n        linestyles (:obj:`str`, optional): Linestyle for plot. Options are\n            ``\"solid\"`` or ``\"dotted\"``.\n    \"\"\"\n    y = np.array(y)\n    if len(y.shape) == 1:\n        y = np.array([y])\n        red = np.array([red])\n        green = np.array([green])\n        blue = np.array([blue])\n        alpha = np.array([alpha])\n    elif isinstance(alpha, int):\n        alpha = [alpha] * len(y)\n\n    seg = []\n    colours = []\n    for yy, rr, gg, bb, aa in zip(y, red, green, blue, alpha):\n        pts = np.array([x, yy]).T.reshape(-1, 1, 2)\n        seg.extend(np.concatenate([pts[:-1], pts[1:]], axis=1))\n\n        nseg = len(x) - 1\n        r = [0.5 * (rr[i] + rr[i + 1]) for i in range(nseg)]\n        g = [0.5 * (gg[i] + gg[i + 1]) for i in range(nseg)]\n        b = [0.5 * (bb[i] + bb[i + 1]) for i in range(nseg)]\n        a = np.ones(nseg, np.float) * aa\n        colours.extend(list(zip(r, g, b, a)))\n\n    lc = LineCollection(seg, colors=colours, rasterized=True,\n                        linewidth=linewidth, linestyles=linestyles)\n    return lc", "response": "Returns a list of colors for a color line for plotting."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef broaden_eps(dielectric, sigma):\n    e = dielectric[0]\n    diff = [e[i + 1] - e[i] for i in range(len(e) - 1)]\n    diff_avg = sum(diff) / len(diff)\n    real = [gaussian_filter1d(np.array(dielectric[1])[:, x], sigma / diff_avg)\n            for x in range(6)]\n    imag = [gaussian_filter1d(np.array(dielectric[2])[:, x], sigma / diff_avg)\n            for x in range(6)]\n\n    return (e, np.array(real).T, np.array(imag).T)", "response": "Apply gaussian broadening to the dielectric response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting the absorption or loss spectra to a file.", "response": "def write_files(abs_data, basename='absorption', prefix=None, directory=None):\n    \"\"\"Write the absorption or loss spectra to a file.\n\n    Note that this function expects to receive an iterable series of spectra.\n\n    Args:\n        abs_data (tuple): Series (either :obj:`list` or :obj:`tuple`) of\n            optical absorption or loss spectra. Each spectrum should be\n            formatted as a :obj:`tuple` of :obj:`list` of :obj:`float`. If the\n            data has been averaged, each spectrum should be::\n\n                ([energies], [alpha])\n\n            Else, if the data has not been averaged, each spectrum should be::\n\n                ([energies], [alpha_xx, alpha_yy, alpha_zz]).\n\n        prefix (:obj:`str`, optional): Prefix for file names.\n        directory (:obj:`str`, optional): The directory in which to save files.\n    \"\"\"\n\n    for i, absorption in enumerate(abs_data):\n        num_txt = '_{}'.format(i + 1) if len(abs_data) > 1 else ''\n        prefix_txt = '{}_'.format(prefix) if prefix else ''\n        filename = prefix_txt + basename + num_txt + '.dat'\n\n        if directory:\n            filename = os.path.join(directory, filename)\n\n        header = 'energy(eV)'\n        if len(absorption[1].shape) == 2:\n            header += ' alpha_xx alpha_yy alpha_zz'\n            data = np.concatenate((absorption[0][:, None], absorption[1]),\n                                  axis=1)\n        else:\n            header += ' alpha'\n            data = np.stack((absorption[0], absorption[1]), axis=1)\n\n        np.savetxt(filename, data, header=header)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef optplot(modes=('absorption',), filenames=None, prefix=None, directory=None,\n            gaussian=None, band_gaps=None, labels=None, average=True, height=6,\n            width=6, xmin=0, xmax=None, ymin=0, ymax=1e5, colours=None,\n            style=None, no_base_style=None,\n            image_format='pdf', dpi=400, plt=None, fonts=None):\n    \"\"\"A script to plot optical absorption spectra from VASP calculations.\n\n    Args:\n        modes (:obj:`list` or :obj:`tuple`):\n            Ordered list of :obj:`str` determining properties to plot.\n            Accepted options are 'absorption' (default), 'eps', 'eps-real',\n                'eps-im', 'n', 'n-real', 'n-im', 'loss' (equivalent to n-im).\n        filenames (:obj:`str` or :obj:`list`, optional): Path to vasprun.xml\n            file (can be gzipped). Alternatively, a list of paths can be\n            provided, in which case the absorption spectra for each will be\n            plotted concurrently.\n        prefix (:obj:`str`, optional): Prefix for file names.\n        directory (:obj:`str`, optional): The directory in which to save files.\n        gaussian (:obj:`float`): Standard deviation for gaussian broadening.\n        band_gaps (:obj:`float` or :obj:`list`, optional): The band gap as a\n            :obj:`float`, plotted as a dashed line. If plotting multiple\n            spectra then a :obj:`list` of band gaps can be provided.\n        labels (:obj:`str` or :obj:`list`): A label to identify the spectra.\n            If plotting multiple spectra then a :obj:`list` of labels can\n            be provided.\n        average (:obj:`bool`, optional): Average the dielectric response across\n            all lattice directions. Defaults to ``True``.\n        height (:obj:`float`, optional): The height of the plot.\n        width (:obj:`float`, optional): The width of the plot.\n        xmin (:obj:`float`, optional): The minimum energy on the x-axis.\n        xmax (:obj:`float`, optional): The maximum energy on the x-axis.\n        ymin (:obj:`float`, optional): The minimum absorption intensity on the\n            y-axis.\n        ymax (:obj:`float`, optional): The maximum absorption intensity on the\n            y-axis.\n        colours (:obj:`list`, optional): A :obj:`list` of colours to use in the\n            plot. The colours can be specified as a hex code, set of rgb\n            values, or any other format supported by matplotlib.\n        style (:obj:`list` or :obj:`str`, optional): (List of) matplotlib style\n            specifications, to be composed on top of Sumo base style.\n        no_base_style (:obj:`bool`, optional): Prevent use of sumo base style.\n            This can make alternative styles behave more predictably.\n        image_format (:obj:`str`, optional): The image file format. Can be any\n            format supported by matplotlib, including: png, jpg, pdf, and svg.\n            Defaults to pdf.\n        dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n            the image.\n        plt (:obj:`matplotlib.pyplot`, optional): A\n            :obj:`matplotlib.pyplot` object to use for plotting.\n        fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n            a single font, specified as a :obj:`str`, or several fonts,\n            specified as a :obj:`list` of :obj:`str`.\n\n    Returns:\n        A matplotlib pyplot object.\n    \"\"\"\n    if not filenames:\n        if os.path.exists('vasprun.xml'):\n            filenames = ['vasprun.xml']\n        elif os.path.exists('vasprun.xml.gz'):\n            filenames = ['vasprun.xml.gz']\n        else:\n            logging.error('ERROR: No vasprun.xml found!')\n            sys.exit()\n\n    elif isinstance(filenames, str):\n        filenames = [filenames]\n\n    vrs = [Vasprun(f) for f in filenames]\n    dielectrics = [vr.dielectric for vr in vrs]\n\n    if gaussian:\n        dielectrics = [broaden_eps(d, gaussian)\n                       for d in dielectrics]\n\n    # initialize spectrum data ready to append from each dataset\n    abs_data = OrderedDict()\n\n    for mode in modes:\n        abs_data.update({mode: []})\n\n    # for each calculation, get all required properties and append to data\n    for d in dielectrics:\n        for mode, spectrum in calculate_dielectric_properties(\n                d, set(modes), average=average).items():\n            abs_data[mode].append(spectrum)\n\n    if isinstance(band_gaps, list) and not band_gaps:\n        # empty list therefore get bandgap from vasprun files\n        band_gaps = [vr.get_band_structure().get_band_gap()['energy']\n                     for vr in vrs]\n    elif isinstance(band_gaps, list) and 'vasprun' in band_gaps[0]:\n        # band_gaps contains list of vasprun files\n        bg_vrs = [Vasprun(f) for f in band_gaps]\n        band_gaps = [vr.get_band_structure().get_band_gap()['energy']\n                     for vr in bg_vrs]\n    elif isinstance(band_gaps, list):\n        # band_gaps is non empty list w. no vaspruns; presume floats\n        band_gaps = [float(i) for i in band_gaps]\n\n    save_files = False if plt else True\n\n    if len(abs_data) > 1 and not labels:\n        labels = [latexify(vr.final_structure.composition.reduced_formula).\n                  replace('$_', '$_\\mathregular') for vr in vrs]\n\n    plotter = SOpticsPlotter(abs_data, band_gap=band_gaps, label=labels)\n    plt = plotter.get_plot(width=width, height=height, xmin=xmin,\n                           xmax=xmax, ymin=ymin, ymax=ymax,\n                           colours=colours, dpi=dpi, plt=plt, fonts=fonts,\n                           style=style, no_base_style=no_base_style)\n\n    if save_files:\n        basename = 'absorption'\n        if prefix:\n            basename = '{}_{}'.format(prefix, basename)\n        image_filename = '{}.{}'.format(basename, image_format)\n\n        if directory:\n            image_filename = os.path.join(directory, image_filename)\n        plt.savefig(image_filename, format=image_format, dpi=dpi)\n        for mode, data in abs_data.items():\n            basename = 'absorption' if mode == 'abs' else mode\n            write_files(data, basename=basename,\n                        prefix=prefix, directory=directory)\n    else:\n        return plt", "response": "A script to plot optical absorption spectra for a single entry in a VASP file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload a phonopy file and return an object containing the base class of the effective .", "response": "def load_phonopy(filename, structure, dim, symprec=0.01, primitive_matrix=None,\n                 factor=VaspToTHz, symmetrise=True, born=None, write_fc=False):\n    \"\"\"Load phonopy output and return an ``phonopy.Phonopy`` object.\n\n    Args:\n        filename (str): Path to phonopy output. Can be any of ``FORCE_SETS``,\n            ``FORCE_CONSTANTS``, or ``force_constants.hdf5``.\n        structure (:obj:`~pymatgen.core.structure.Structure`): The unitcell\n            structure.\n        dim (list): The supercell size, as a :obj:`list` of :obj:`float`.\n        symprec (:obj:`float`, optional): The tolerance for determining the\n            crystal symmetry.\n        primitive_matrix (:obj:`list`, optional): The transformation matrix\n            from the conventional to primitive cell. Only required when the\n            conventional cell was used as the starting structure. Should be\n            provided as a 3x3 :obj:`list` of :obj:`float`.\n        factor (:obj:`float`, optional): The conversion factor for phonon\n            frequency. Defaults to :obj:`phonopy.units.VaspToTHz`.\n        symmetrise (:obj:`bool`, optional): Symmetrise the force constants.\n            Defaults to ``True``.\n        born (:obj:`str`, optional): Path to file containing Born effective\n            charges. Should be in the same format as the file produced by the\n            ``phonopy-vasp-born`` script provided by phonopy.\n        write_fc (:obj:`bool` or :obj:`str`,  optional): Write the force\n            constants to disk. If ``True``, a ``FORCE_CONSTANTS`` file will be\n            written. Alternatively, if set to ``\"hdf5\"``, a\n            ``force_constants.hdf5`` file will be written. Defaults to\n            ``False`` (force constants not written).\n    \"\"\"\n    unitcell = get_phonopy_structure(structure)\n    num_atom = unitcell.get_number_of_atoms()\n    num_satom = determinant(dim) * num_atom\n\n    phonon = Phonopy(unitcell, dim, primitive_matrix=primitive_matrix,\n                     factor=factor, symprec=symprec)\n\n    if 'FORCE_CONSTANTS' == filename or '.hdf5' in filename:\n        # if force constants exist, use these to avoid recalculating them\n        if '.hdf5' in filename:\n            fc = file_IO.read_force_constants_hdf5(filename)\n\n        elif 'FORCE_CONSTANTS' == filename:\n            fc = file_IO.parse_FORCE_CONSTANTS(filename=filename)\n\n        if fc.shape[0] != num_satom:\n            msg = (\"\\nNumber of atoms in supercell is not consistent with the \"\n                   \"matrix shape of\\nforce constants read from {}.\\nPlease\"\n                   \"carefully check --dim.\")\n            logging.error(msg.format(filename))\n            sys.exit()\n\n        phonon.set_force_constants(fc)\n\n    elif 'FORCE_SETS' == filename:\n        # load the force sets from file and calculate force constants\n        fs = file_IO.parse_FORCE_SETS()\n\n        if fs['natom'] != num_satom:\n            msg = (\"\\nNumber of atoms in supercell is not consistent with the \"\n                   \"the data in FORCE_SETS\\nPlease carefully check --dim.\")\n            logging.error(msg.format(filename))\n            sys.exit()\n\n        phonon.set_displacement_dataset(fs)\n\n        logging.info(\"Calculating force constants...\")\n        phonon.produce_force_constants()\n\n    if born:\n        # load born parameters from a file\n        nac_params = file_IO.parse_BORN(unitcell, filename=born)\n\n        # set the nac unit conversion factor manual,  specific to VASP\n        nac_params['factor'] = Hartree * Bohr\n        phonon.set_nac_params(nac_params)\n\n    if symmetrise:\n        phonon.symmetrize_force_constants()\n\n    if write_fc == 'hdf5':\n        file_IO.write_force_constants_to_hdf5(phonon.get_force_constants())\n        logging.info(\"Force constants written to force_constants.hdf5.\")\n\n    elif write_fc:\n        file_IO.write_FORCE_CONSTANTS(phonon.get_force_constants())\n        logging.info(\"Force constants written to FORCE_CONSTANTS.\")\n\n    return phonon"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _auto_kpath_labels(kpt_list):\n\n        # Build dict of labels\n        label_i = 1\n        kpt_labels = {}\n        for kpt in chain(*kpt_list):\n            if tuple(kpt) in kpt_labels:\n                continue\n            else:\n                kpt_labels.update({tuple(kpt): '({})'.format(label_i)})\n                label_i += 1\n\n        # Read out into nested lists\n        kpath_labels = [[kpt_labels[tuple(kpt)] for kpt in segment]\n                        for segment in kpt_list]\n\n        return kpath_labels", "response": "Get a default set of labels for a k - point path segment."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload a vasprun and extract the total and projected density of states.", "response": "def load_dos(vasprun, elements=None, lm_orbitals=None, atoms=None,\n             gaussian=None, total_only=False, log=False,\n             adjust_fermi=True):\n    \"\"\"Load a vasprun and extract the total and projected density of states.\n\n    Args:\n        vasprun (str): Path to a vasprun.xml or vasprun.xml.gz file or\n            a :obj:`pymatgen.io.vasp.outputs.Vasprun` object.\n        elements (:obj:`dict`, optional): The elements and orbitals to extract\n            from the projected density of states. Should be provided as a\n            :obj:`dict` with the keys as the element names and corresponding\n            values as a :obj:`tuple` of orbitals. For example, the following\n            would extract the Bi s, px, py and d orbitals::\n\n                {'Bi': ('s', 'px', 'py', 'd')}\n\n            If an element is included with an empty :obj:`tuple`, all orbitals\n            for that species will be extracted. If ``elements`` is not set or\n            set to ``None``, all elements for all species will be extracted.\n        lm_orbitals (:obj:`dict`, optional): The orbitals to decompose into\n            their lm contributions (e.g. p -> px, py, pz). Should be provided\n            as a :obj:`dict`, with the elements names as keys and a\n            :obj:`tuple` of orbitals as the corresponding values. For example,\n            the following would be used to decompose the oxygen p and d\n            orbitals::\n\n                {'O': ('p', 'd')}\n\n        atoms (:obj:`dict`, optional): Which atomic sites to use when\n            calculating the projected density of states. Should be provided as\n            a :obj:`dict`, with the element names as keys and a :obj:`tuple` of\n            :obj:`int` specifying the atomic indices as the corresponding\n            values. The elemental projected density of states will be summed\n            only over the atom indices specified. If an element is included\n            with an empty :obj:`tuple`, then all sites for that element will\n            be included. The indices are 0 based for each element specified in\n            the POSCAR. For example, the following will calculate the density\n            of states for the first 4 Sn atoms and all O atoms in the\n            structure::\n\n                {'Sn': (1, 2, 3, 4), 'O': (, )}\n\n            If ``atoms`` is not set or set to ``None`` then all atomic sites\n            for all elements will be considered.\n        gaussian (:obj:`float`, optional): Broaden the density of states using\n            convolution with a gaussian function. This parameter controls the\n            sigma or standard deviation of the gaussian distribution.\n        total_only (:obj:`bool`, optional): Only extract the total density of\n            states. Defaults to ``False``.\n        log (:obj:`bool`): Print logging messages. Defaults to ``False``.\n        adjust_fermi (:obj:`bool`, optional): Shift the Fermi level to sit at\n            the valence band maximum (does not affect metals).\n\n    Returns:\n        dict: The total and projected density of states. Formatted as a\n        :obj:`tuple` of ``(dos, pdos)``, where ``dos`` is a\n        :obj:`~pymatgen.electronic_structure.dos.Dos` object containing the\n        total density of states and ``pdos`` is a :obj:`dict` of\n        :obj:`dict` mapping the elements and their orbitals to\n        :obj:`~pymatgen.electronic_structure.dos.Dos` objects. For example::\n\n            {\n                'Bi': {'s': Dos, 'p': Dos ... },\n                'S': {'s': Dos}\n            }\n    \"\"\"\n    if isinstance(vasprun, str):\n        vr = Vasprun(vasprun)\n    else:\n        vr = vasprun\n\n    band = vr.get_band_structure()\n    dos = vr.complete_dos\n\n    if band.is_metal():\n        if log:\n            logging.info('System is metallic')\n        zero_point = vr.efermi\n    else:\n        if log:\n            logging.info('Band gap: {:.3f}'.\n                         format(band.get_band_gap()['energy']))\n            logging.info('DOS band gap: {:.3f}'.format(dos.get_gap()))\n        zero_point = band.get_vbm()['energy']\n\n    if adjust_fermi:\n        dos.efermi -= dos.efermi - zero_point\n\n    if vr.parameters['ISMEAR'] in [-1, 0, 1]:\n        dos.energies -= vr.parameters['SIGMA']\n\n    if gaussian:\n        dos.densities = dos.get_smeared_densities(gaussian)\n        for site in dos.pdos:\n            for orbital in dos.pdos[site]:\n                dos.pdos[site][orbital] = dos.get_site_orbital_dos(\n                    site, orbital).get_smeared_densities(gaussian)\n\n    if vr.parameters['LSORBIT']:\n        # pymatgen includes the spin down channel for SOC calculations, even\n        # though there is no density here. We remove this channel so the\n        # plotting is easier later on.\n        del dos.densities[Spin.down]\n        for site in dos.pdos:\n            for orbital in dos.pdos[site]:\n                del dos.pdos[site][orbital][Spin.down]\n\n    pdos = {}\n    if not total_only:\n        pdos = get_pdos(dos, lm_orbitals=lm_orbitals, atoms=atoms,\n                        elements=elements)\n    return dos, pdos"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the projected density of states from a CompleteDos object.", "response": "def get_pdos(dos, lm_orbitals=None, atoms=None, elements=None):\n    \"\"\"Extract the projected density of states from a CompleteDos object.\n\n    Args:\n        dos (:obj:`~pymatgen.electronic_structure.dos.CompleteDos`): The\n            density of states.\n        elements (:obj:`dict`, optional): The elements and orbitals to extract\n            from the projected density of states. Should be provided as a\n            :obj:`dict` with the keys as the element names and corresponding\n            values as a :obj:`tuple` of orbitals. For example, the following\n            would extract the Bi s, px, py and d orbitals::\n\n                {'Bi': ('s', 'px', 'py', 'd')}\n\n            If an element is included with an empty :obj:`tuple`, all orbitals\n            for that species will be extracted. If ``elements`` is not set or\n            set to ``None``, all elements for all species will be extracted.\n        lm_orbitals (:obj:`dict`, optional): The orbitals to decompose into\n            their lm contributions (e.g. p -> px, py, pz). Should be provided\n            as a :obj:`dict`, with the elements names as keys and a\n            :obj:`tuple` of orbitals as the corresponding values. For example,\n            the following would be used to decompose the oxygen p and d\n            orbitals::\n\n                {'O': ('p', 'd')}\n\n        atoms (:obj:`dict`, optional): Which atomic sites to use when\n            calculating the projected density of states. Should be provided as\n            a :obj:`dict`, with the element names as keys and a :obj:`tuple` of\n            :obj:`int` specifying the atomic indices as the corresponding\n            values. The elemental projected density of states will be summed\n            only over the atom indices specified. If an element is included\n            with an empty :obj:`tuple`, then all sites for that element will\n            be included. The indices are 0 based for each element specified in\n            the POSCAR. For example, the following will calculate the density\n            of states for the first 4 Sn atoms and all O atoms in the\n            structure::\n\n                {'Sn': (1, 2, 3, 4), 'O': (, )}\n\n            If ``atoms`` is not set or set to ``None`` then all atomic sites\n            for all elements will be considered.\n\n    Returns:\n        dict: The projected density of states. Formatted as a :obj:`dict` of\n        :obj:`dict` mapping the elements and their orbitals to\n        :obj:`~pymatgen.electronic_structure.dos.Dos` objects. For example::\n\n            {\n                'Bi': {'s': Dos, 'p': Dos ... },\n                'S': {'s': Dos}\n            }\n    \"\"\"\n    if not elements:\n        symbols = dos.structure.symbol_set\n        elements = dict(zip(symbols, [None] * len(symbols)))\n    pdos = {}\n    for el in elements:\n        if atoms and el not in atoms:\n            continue\n\n        # select which sites to consider, if no sites were specified then\n        # select all. Make a list of the sites of particular elements first\n        # due to the dosplot atoms list specification (e.g. starts at 0 for\n        # each element\n        element_sites = [site for site in dos.structure.sites\n                         if site.specie == get_el_sp(el)]\n        sites = [site for i, site in enumerate(element_sites)\n                 if not atoms or (el in atoms and i in atoms[el])]\n        lm = lm_orbitals[el] if (lm_orbitals and el in lm_orbitals) else None\n        orbitals = elements[el] if elements and el in elements else None\n\n        pdos[el] = get_element_pdos(dos, el, sites, lm, orbitals)\n    return pdos"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the projected density of states for an element in the given Dos.", "response": "def get_element_pdos(dos, element, sites, lm_orbitals=None, orbitals=None):\n    \"\"\"Get the projected density of states for an element.\n\n    Args:\n        dos (:obj:`~pymatgen.electronic_structure.dos.CompleteDos`): The\n            density of states.\n        element (str): Element symbol. E.g. 'Zn'.\n        sites (tuple): The atomic indices over which to sum the density of\n            states, as a :obj:`tuple`. Indices are zero based for each\n            element. For example, ``(0, 1, 2)`` will sum the density of states\n            for the 1st, 2nd and 3rd sites of the element specified.\n        lm_orbitals (:obj:`tuple`, optional): The orbitals to decompose into\n            their lm contributions (e.g. p -> px, py, pz). Should be provided\n            as a :obj:`tuple` of :obj:`str`. For example, ``('p')``, will\n            extract the projected density of states for the px, py, and pz\n            orbitals. Defaults to ``None``.\n        orbitals (:obj:`tuple`, optional): The orbitals to extract from the\n            projected density of states. Should be provided as a :obj:`tuple`\n            of :obj:`str`. For example, ``('s', 'px', 'dx2')`` will extract the\n            s, px, and dx2 orbitals, only. If ``None``, all orbitals will be\n            extracted. Defaults to ``None``.\n\n    Returns:\n        dict: The projected density of states. Formatted as a :obj:`dict`\n        mapping the orbitals to :obj:`~pymatgen.electronic_structure.dos.Dos`\n        objects. For example::\n\n            {\n                's': Dos,\n                'p': Dos\n            }\n    \"\"\"\n    el_dos = {}\n    for site in sites:\n        # build a list of which orbitals we are after\n        # start with s, p, and d orbitals only\n        spd = [orb for orb in dos.get_element_spd_dos(element).keys() if\n               ((orbitals and orb.name in orbitals) or not orbitals) and\n               ((lm_orbitals and orb.name not in lm_orbitals) or\n                not lm_orbitals)]\n\n        # now add any lm decomposed orbitals\n        lm = [orb for orb in Orbital\n              if lm_orbitals and orb.name[0] in lm_orbitals]\n\n        # extract the data\n        for orb in spd:\n            pdos = dos.get_site_spd_dos(site)[orb]\n            el_dos[orb.name] = (el_dos[orb.name] + pdos if orb.name in el_dos\n                                else pdos)\n\n        for orb in lm:\n            pdos = dos.get_site_orbital_dos(site, orb)\n            el_dos[orb.name] = (el_dos[orb.name] + pdos if orb.name in el_dos\n                                else pdos)\n    return el_dos"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite the total Dos data to disk.", "response": "def write_files(dos, pdos, prefix=None, directory=None, zero_to_efermi=True):\n    \"\"\"Write the density of states data to disk.\n\n    Args:\n        dos (:obj:`~pymatgen.electronic_structure.dos.Dos` or \\\n             :obj:`~pymatgen.electronic_structure.dos.CompleteDos`): The total\n            density of states.\n        pdos (dict): The projected density of states. Formatted as a\n            :obj:`dict` of :obj:`dict` mapping the elements and their orbitals\n            to :obj:`~pymatgen.electronic_structure.dos.Dos` objects. For\n            example::\n\n                {\n                    'Bi': {'s': Dos, 'p': Dos},\n                    'S': {'s': Dos}\n                }\n\n        prefix (:obj:`str`, optional): A prefix for file names.\n        directory (:obj:`str`, optional): The directory in which to save files.\n        zero_to_efermi (:obj:`bool`, optional): Normalise the energy such\n             that the Fermi level is set as 0 eV.\n    \"\"\"\n    # defining these cryptic lists makes formatting the data much easier later\n    if len(dos.densities) == 1:\n        sdata = [[Spin.up, 1, '']]\n    else:\n        sdata = [[Spin.up, 1, '(up)'], [Spin.down, -1, '(down)']]\n\n    header = ['energy']\n    eners = dos.energies - dos.efermi if zero_to_efermi else dos.energies\n    tdos_data = [eners]\n    for spin, sign, label in sdata:\n        header.append('dos{}'.format(label))\n        tdos_data.append(dos.densities[spin] * sign)\n    tdos_data = np.stack(tdos_data, axis=1)\n\n    filename = \"{}_total_dos.dat\".format(prefix) if prefix else 'total_dos.dat'\n    if directory:\n        filename = os.path.join(directory, filename)\n    np.savetxt(filename, tdos_data, header=\" \".join(header))\n\n    spin = len(dos.densities)\n    for el, el_pdos in pdos.items():\n        header = ['energy']\n        pdos_data = [eners]\n        for orb in sort_orbitals(el_pdos):\n            for spin, sign, label in sdata:\n                header.append('{}{}'.format(orb, label))\n                pdos_data.append(el_pdos[orb].densities[spin] * sign)\n        pdos_data = np.stack(pdos_data, axis=1)\n\n        if prefix:\n            filename = '{}_{}_dos.dat'.format(prefix, el)\n        else:\n            filename = '{}_dos.dat'.format(el)\n        if directory:\n            filename = os.path.join(directory, filename)\n        np.savetxt(filename, pdos_data, header=\" \".join(header))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsort the orbitals of an element s projected density of states based on a standard format.", "response": "def sort_orbitals(element_pdos):\n    \"\"\"Sort the orbitals of an element's projected density of states.\n\n    Sorts the orbitals based on a standard format. E.g. s < p < d.\n    Will also sort lm decomposed orbitals. This is useful for plotting/saving.\n\n    Args:\n        element_pdos (dict): An element's pdos. Should be formatted as a\n            :obj:`dict` of ``{orbital: dos}``. Where dos is a\n            :obj:`~pymatgen.electronic_structure.dos.Dos` object. For example::\n\n                {'s': dos, 'px': dos}\n\n    Returns:\n        list: The sorted orbitals.\n    \"\"\"\n    sorted_orbitals = ['s', 'p', 'py', 'pz', 'px',\n                       'd', 'dxy', 'dyz', 'dz2', 'dxz', 'dx2',\n                       'f', 'f_3', 'f_2', 'f_1', 'f_0', 'f1', 'f2', 'f3']\n    unsorted_keys = element_pdos.keys()\n\n    sorted_keys = []\n    for key in sorted_orbitals:\n        if key in unsorted_keys:\n            sorted_keys.append(key)\n\n    return sorted_keys"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bandstats(filenames=None, num_sample_points=3, temperature=None,\n              degeneracy_tol=1e-4, parabolic=True):\n    \"\"\"Calculate the effective masses of the bands of a semiconductor.\n\n    Args:\n        filenames (:obj:`str` or :obj:`list`, optional): Path to vasprun.xml\n            or vasprun.xml.gz file. If no filenames are provided, the code\n            will search for vasprun.xml or vasprun.xml.gz files in folders\n            named 'split-0*'. Failing that, the code will look for a vasprun in\n            the current directory. If a :obj:`list` of vasprun files is\n            provided, these will be combined into a single band structure.\n        num_sample_points (:obj:`int`, optional): Number of k-points to sample\n            when fitting the effective masses.\n        temperature (:obj:`int`, optional): Find band edges within kB * T of\n            the valence band maximum and conduction band minimum. Not currently\n            implemented.\n        degeneracy_tol (:obj:`float`, optional): Tolerance for determining the\n            degeneracy of the valence band maximum and conduction band minimum.\n        parabolic (:obj:`bool`, optional): Use a parabolic fit of the band\n            edges. If ``False`` then nonparabolic fitting will be attempted.\n            Defaults to ``True``.\n\n    Returns:\n        dict: The hole and electron effective masses. Formatted as a\n        :obj:`dict` with keys: ``'hole_data'`` and ``'electron_data'``. The\n        data is a :obj:`list` of :obj:`dict` with the keys:\n\n        'effective_mass' (:obj:`float`)\n            The effective mass in units of electron rest mass, :math:`m_0`.\n\n        'energies' (:obj:`numpy.ndarray`)\n            Band eigenvalues in eV.\n\n        'distances' (:obj:`numpy.ndarray`)\n            Distances of the k-points in reciprocal space.\n\n        'band_id' (:obj:`int`)\n            The index of the band,\n\n        'spin' (:obj:`~pymatgen.electronic_structure.core.Spin`)\n            The spin channel\n\n        'start_kpoint' (:obj:`int`)\n            The index of the k-point at which the band extrema occurs\n\n        'end_kpoint' (:obj:`int`)\n    \"\"\"\n    if not filenames:\n        filenames = find_vasprun_files()\n    elif isinstance(filenames, str):\n        filenames = [filenames]\n\n    bandstructures = []\n    for vr_file in filenames:\n        vr = BSVasprun(vr_file, parse_projected_eigen=False)\n        bs = vr.get_band_structure(line_mode=True)\n        bandstructures.append(bs)\n    bs = get_reconstructed_band_structure(bandstructures)\n\n    if bs.is_metal():\n        logging.error('ERROR: System is metallic!')\n        sys.exit()\n\n    _log_band_gap_information(bs)\n\n    vbm_data = bs.get_vbm()\n    cbm_data = bs.get_cbm()\n\n    logging.info('\\nValence band maximum:')\n    _log_band_edge_information(bs, vbm_data)\n\n    logging.info('\\nConduction band minimum:')\n    _log_band_edge_information(bs, cbm_data)\n\n    if parabolic:\n        logging.info('\\nUsing parabolic fitting of the band edges')\n    else:\n        logging.info('\\nUsing nonparabolic fitting of the band edges')\n\n    if temperature:\n        logging.error('ERROR: This feature is not yet supported!')\n\n    else:\n        # Work out where the hole and electron band edges are.\n        # Fortunately, pymatgen does this for us. Points at which to calculate\n        # the effective mass are identified as a tuple of:\n        # (spin, band_index, kpoint_index)\n        hole_extrema = []\n        for spin, bands in vbm_data['band_index'].items():\n            hole_extrema.extend([(spin, band, kpoint) for band in bands\n                                 for kpoint in vbm_data['kpoint_index']])\n\n        elec_extrema = []\n        for spin, bands in cbm_data['band_index'].items():\n            elec_extrema.extend([(spin, band, kpoint) for band in bands\n                                 for kpoint in cbm_data['kpoint_index']])\n\n        # extract the data we need for fitting from the band structure\n        hole_data = []\n        for extrema in hole_extrema:\n            hole_data.extend(get_fitting_data(bs, *extrema,\n                             num_sample_points=num_sample_points))\n\n        elec_data = []\n        for extrema in elec_extrema:\n            elec_data.extend(get_fitting_data(bs, *extrema,\n                             num_sample_points=num_sample_points))\n\n    # calculate the effective masses and log the information\n    logging.info('\\nHole effective masses:')\n    for data in hole_data:\n        eff_mass = fit_effective_mass(data['distances'], data['energies'],\n                                      parabolic=parabolic)\n        data['effective_mass'] = eff_mass\n        _log_effective_mass_data(data, bs.is_spin_polarized, mass_type='m_h')\n\n    logging.info('\\nElectron effective masses:')\n    for data in elec_data:\n        eff_mass = fit_effective_mass(data['distances'], data['energies'],\n                                      parabolic=parabolic)\n        data['effective_mass'] = eff_mass\n        _log_effective_mass_data(data, bs.is_spin_polarized)\n\n    return {'hole_data': hole_data, 'electron_data': elec_data}", "response": "Return a dictionary of the effective masses and electrons of the vasprun. xml file."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _log_band_gap_information(bs):\n    bg_data = bs.get_band_gap()\n    if not bg_data['direct']:\n        logging.info('Indirect band gap: {:.3f} eV'.format(bg_data['energy']))\n\n    direct_data = bs.get_direct_band_gap_dict()\n    if bs.is_spin_polarized:\n        direct_bg = min((spin_data['value']\n                         for spin_data in direct_data.values()))\n        logging.info('Direct band gap: {:.3f} eV'.format(direct_bg))\n\n        for spin, spin_data in direct_data.items():\n            direct_kindex = spin_data['kpoint_index']\n            direct_kpoint = bs.kpoints[direct_kindex].frac_coords\n            direct_kpoint = kpt_str.format(k=direct_kpoint)\n            eq_kpoints = bs.get_equivalent_kpoints(direct_kindex)\n            k_indices = ', '.join(map(str, eq_kpoints))\n\n            # add 1 to band indices to be consistent with VASP band numbers.\n            b_indices = ', '.join([str(i+1) for i in spin_data['band_indices']])\n\n            logging.info('  {}:'.format(spin.name.capitalize()))\n            logging.info('    k-point: {}'.format(direct_kpoint))\n            logging.info('    k-point indices: {}'.format(k_indices))\n            logging.info('    Band indices: {}'.format(b_indices))\n\n    else:\n        direct_bg = direct_data[Spin.up]['value']\n        logging.info('Direct band gap: {:.3f} eV'.format(direct_bg))\n\n        direct_kindex = direct_data[Spin.up]['kpoint_index']\n        direct_kpoint = kpt_str.format(k=bs.kpoints[direct_kindex].frac_coords)\n        k_indices = ', '.join(map(str,\n                                  bs.get_equivalent_kpoints(direct_kindex)))\n        b_indices = ', '.join([str(i+1) for i in\n                               direct_data[Spin.up]['band_indices']])\n\n        logging.info('  k-point: {}'.format(direct_kpoint))\n        logging.info('  k-point indices: {}'.format(k_indices))\n        logging.info('  Band indices: {}'.format(b_indices))", "response": "Log data about the direct and indirect band gaps."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlogging data about the valence band maximum or conduction band minimum.", "response": "def _log_band_edge_information(bs, edge_data):\n    \"\"\"Log data about the valence band maximum or conduction band minimum.\n\n    Args:\n        bs (:obj:`~pymatgen.electronic_structure.bandstructure.BandStructureSymmLine`):\n            The band structure.\n        edge_data (dict): The :obj:`dict` from ``bs.get_vbm()`` or\n            ``bs.get_cbm()``\n    \"\"\"\n    if bs.is_spin_polarized:\n        spins = edge_data['band_index'].keys()\n        b_indices = [', '.join([str(i+1) for i in\n                                edge_data['band_index'][spin]])\n                     + '({})'.format(spin.name.capitalize()) for spin in spins]\n        b_indices = ', '.join(b_indices)\n    else:\n        b_indices = ', '.join([str(i+1) for i in\n                               edge_data['band_index'][Spin.up]])\n\n    kpoint = edge_data['kpoint']\n    kpoint_str = kpt_str.format(k=kpoint.frac_coords)\n    k_indices = ', '.join(map(str, edge_data['kpoint_index']))\n\n    if kpoint.label:\n        k_loc = kpoint.label\n    else:\n        branch = bs.get_branch(edge_data['kpoint_index'][0])[0]\n        k_loc = 'between {}'.format(branch['name'])\n\n    logging.info('  Energy: {:.3f} eV'.format(edge_data['energy']))\n    logging.info('  k-point: {}'.format(kpoint_str))\n    logging.info('  k-point location: {}'.format(k_loc))\n    logging.info('  k-point indices: {}'.format(k_indices))\n    logging.info('  Band indices: {}'.format(b_indices))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nlogs data about the effective masses and their directions.", "response": "def _log_effective_mass_data(data, is_spin_polarized, mass_type='m_e'):\n    \"\"\"Log data about the effective masses and their directions.\n\n    Args:\n        data (dict): The effective mass data. Formatted as a :obj:`dict` with\n            the keys:\n\n            'effective_mass' (:obj:`float`)\n                The effective mass in units of electron rest mass, :math:`m_0`.\n\n            'energies' (:obj:`numpy.ndarray`)\n                Band eigenvalues in eV.\n\n            'band_id' (:obj:`int`)\n                The index of the band,\n\n            'spin' (:obj:`~pymatgen.electronic_structure.core.Spin`)\n                The spin channel\n\n            'start_kpoint' (:obj:`int`)\n                The index of the k-point at which the band extrema occurs\n\n            'end_kpoint' (:obj:`int`)\n                The k-point towards which the data has been sampled.\n\n        is_spin_polarized (bool): Whether the system is spin polarized.\n    \"\"\"\n    s = ' ({})'.format(data['spin'].name) if is_spin_polarized else ''\n\n    # add 1 to band id to be consistent with VASP\n    band_str = 'band {}{}'.format(data['band_id'] + 1, s)\n\n    start_kpoint = data['start_kpoint']\n    end_kpoint = data['end_kpoint']\n    eff_mass = data['effective_mass']\n\n    kpoint_str = kpt_str.format(k=start_kpoint.frac_coords)\n    if start_kpoint.label:\n        kpoint_str += ' ({})'.format(start_kpoint.label)\n    kpoint_str += ' -> '\n    kpoint_str += kpt_str.format(k=end_kpoint.frac_coords)\n    if end_kpoint.label:\n        kpoint_str += ' ({})'.format(end_kpoint.label)\n\n    logging.info('  {}: {:.3f} | {} | {}'.format(mass_type, eff_mass,\n                                                 band_str, kpoint_str))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a matplotlib. pyplot object of the phonon band structure plot.", "response": "def get_plot(self, units='THz', ymin=None, ymax=None, width=None,\n                 height=None, dpi=None, plt=None, fonts=None, dos=None,\n                 dos_aspect=3, color=None, style=None, no_base_style=False):\n        \"\"\"Get a :obj:`matplotlib.pyplot` object of the phonon band structure.\n\n        Args:\n            units (:obj:`str`, optional): Units of phonon frequency. Accepted\n                (case-insensitive) values are Thz, cm-1, eV, meV.\n            ymin (:obj:`float`, optional): The minimum energy on the y-axis.\n            ymax (:obj:`float`, optional): The maximum energy on the y-axis.\n            width (:obj:`float`, optional): The width of the plot.\n            height (:obj:`float`, optional): The height of the plot.\n            dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n                the image.\n            fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n                a single font, specified as a :obj:`str`, or several fonts,\n                specified as a :obj:`list` of :obj:`str`.\n            plt (:obj:`matplotlib.pyplot`, optional): A\n                :obj:`matplotlib.pyplot` object to use for plotting.\n            dos (:obj:`np.ndarray`): 2D Numpy array of total DOS data\n            dos_aspect (float): Width division for vertical DOS\n            color (:obj:`str` or :obj:`tuple`, optional): Line/fill colour in\n                any matplotlib-accepted format\n            style (:obj:`list`, :obj:`str`, or :obj:`dict`): Any matplotlib\n                style specifications, to be composed on top of Sumo base\n                style.\n            no_base_style (:obj:`bool`, optional): Prevent use of sumo base\n                style. This can make alternative styles behave more\n                predictably.\n\n        Returns:\n            :obj:`matplotlib.pyplot`: The phonon band structure plot.\n        \"\"\"\n        if color is None:\n            color = 'C0'  # Default to first colour in matplotlib series\n\n        if dos is not None:\n            plt = pretty_subplot(1, 2, width=width, height=height,\n                                 sharex=False, sharey=True, dpi=dpi, plt=plt,\n                                 gridspec_kw={'width_ratios': [dos_aspect, 1],\n                                              'wspace': 0})\n            ax = plt.gcf().axes[0]\n        else:\n            plt = pretty_plot(width, height, dpi=dpi, plt=plt)\n            ax = plt.gca()\n\n        data = self.bs_plot_data()\n        dists = data['distances']\n        freqs = data['frequency']\n\n        # nd is branch index, nb is band index, nk is kpoint index\n        for nd, nb in itertools.product(range(len(data['distances'])),\n                                        range(self._nb_bands)):\n            f = freqs[nd][nb]\n\n            # plot band data\n            ax.plot(dists[nd], f, ls='-', c=color, zorder=1)\n\n        self._maketicks(ax, units=units)\n        self._makeplot(ax, plt.gcf(), data, width=width, height=height,\n                       ymin=ymin, ymax=ymax, dos=dos, color=color)\n        plt.tight_layout()\n        plt.subplots_adjust(wspace=0)\n\n        return plt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _makeplot(self, ax, fig, data, ymin=None, ymax=None, height=6,\n                  width=6, dos=None, color=None):\n        \"\"\"Utility method to tidy phonon band structure diagrams. \"\"\"\n        # Define colours\n        if color is None:\n            color = 'C0'  # Default to first colour in matplotlib series\n\n        # set x and y limits\n        tymax = ymax if (ymax is not None) else max(flatten(data['frequency']))\n        tymin = ymin if (ymin is not None) else min(flatten(data['frequency']))\n        pad = (tymax - tymin) * 0.05\n\n        if ymin is None:\n            ymin = 0 if tymin >= self.imag_tol else tymin - pad\n        ymax = ymax if ymax else tymax + pad\n\n        ax.set_ylim(ymin, ymax)\n        ax.set_xlim(0, data['distances'][-1][-1])\n\n        if ymin < 0:\n            dashline = True\n            ax.axhline(0, color=rcParams['grid.color'], linestyle='--',\n                       dashes=dashes,\n                       zorder=0,\n                       linewidth=rcParams['ytick.major.width'])\n        else:\n            dashline = False\n\n        if dos is not None:\n            self._plot_phonon_dos(dos, ax=fig.axes[1], color=color,\n                                  dashline=dashline)\n        else:\n\n            # keep correct aspect ratio; match axis to canvas\n            x0, x1 = ax.get_xlim()\n            y0, y1 = ax.get_ylim()\n\n            if width is None:\n                width = rcParams['figure.figsize'][0]\n            if height is None:\n                height = rcParams['figure.figsize'][1]\n            ax.set_aspect((height/width) * ((x1-x0)/(y1-y0)))", "response": "Utility method to make a phonon band structure diagram."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _maketicks(self, ax, units='THz'):\n        # set y-ticks\n        ax.yaxis.set_major_locator(MaxNLocator(6))\n        ax.yaxis.set_minor_locator(AutoMinorLocator(2))\n        ax.xaxis.set_minor_locator(AutoMinorLocator(2))\n\n        # set x-ticks; only plot the unique tick labels\n        ticks = self.get_ticks()\n        unique_d = []\n        unique_l = []\n        if ticks['distance']:\n            temp_ticks = list(zip(ticks['distance'], ticks['label']))\n            unique_d.append(temp_ticks[0][0])\n            unique_l.append(temp_ticks[0][1])\n            for i in range(1, len(temp_ticks)):\n                if unique_l[-1] != temp_ticks[i][1]:\n                    unique_d.append(temp_ticks[i][0])\n                    unique_l.append(temp_ticks[i][1])\n\n        logging.info('\\nLabel positions:')\n        for dist, label in list(zip(unique_d, unique_l)):\n            logging.info('\\t{:.4f}: {}'.format(dist, label))\n\n        ax.set_xticks(unique_d)\n        ax.set_xticklabels(unique_l)\n        ax.xaxis.grid(True, ls='-')\n\n        trans_xdata_yaxes = blended_transform_factory(ax.transData,\n                                                      ax.transAxes)\n        ax.vlines(unique_d, 0, 1,\n                  transform=trans_xdata_yaxes,\n                  colors=rcParams['grid.color'],\n                  linewidth=rcParams['grid.linewidth'])\n\n        # Use a text hyphen instead of a minus sign because some nice fonts\n        # like Whitney don't come with a real minus\n        labels = {'thz': 'THz', 'cm-1': r'cm$^{\\mathrm{-}\\mathregular{1}}$',\n                  'ev': 'eV', 'mev': 'meV'}\n        ax.set_ylabel('Frequency ({0})'.format(labels[units.lower()]))", "response": "Utility method to add tick marks to a band structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nplots electronic band structure diagrams from the specified files.", "response": "def bandplot(filenames=None, prefix=None, directory=None, vbm_cbm_marker=False,\n             projection_selection=None, mode='rgb',\n             interpolate_factor=4, circle_size=150, dos_file=None,\n             ylabel='Energy (eV)', dos_label=None,\n             elements=None, lm_orbitals=None, atoms=None,\n             total_only=False, plot_total=True, legend_cutoff=3, gaussian=None,\n             height=None, width=None, ymin=-6., ymax=6., colours=None,\n             yscale=1, style=None, no_base_style=False,\n             image_format='pdf', dpi=400, plt=None, fonts=None):\n    \"\"\"Plot electronic band structure diagrams from vasprun.xml files.\n\n    Args:\n        filenames (:obj:`str` or :obj:`list`, optional): Path to vasprun.xml\n            or vasprun.xml.gz file. If no filenames are provided, the code\n            will search for vasprun.xml or vasprun.xml.gz files in folders\n            named 'split-0*'. Failing that, the code will look for a vasprun in\n            the current directory. If a :obj:`list` of vasprun files is\n            provided, these will be combined into a single band structure.\n        prefix (:obj:`str`, optional): Prefix for file names.\n        directory (:obj:`str`, optional): The directory in which to save files.\n        vbm_cbm_marker (:obj:`bool`, optional): Plot markers to indicate the\n            VBM and CBM locations.\n        projection_selection (list): A list of :obj:`tuple` or :obj:`string`\n            identifying which elements and orbitals to project on to the\n            band structure. These can be specified by both element and\n            orbital, for example, the following will project the Bi s, p\n            and S p orbitals::\n\n                [('Bi', 's'), ('Bi', 'p'), ('S', 'p')]\n\n            If just the element is specified then all the orbitals of\n            that element are combined. For example, to sum all the S\n            orbitals::\n\n                [('Bi', 's'), ('Bi', 'p'), 'S']\n\n            You can also choose to sum particular orbitals by supplying a\n            :obj:`tuple` of orbitals. For example, to sum the S s, p, and\n            d orbitals into a single projection::\n\n                [('Bi', 's'), ('Bi', 'p'), ('S', ('s', 'p', 'd'))]\n\n            If ``mode = 'rgb'``, a maximum of 3 orbital/element\n            combinations can be plotted simultaneously (one for red, green\n            and blue), otherwise an unlimited number of elements/orbitals\n            can be selected.\n        mode (:obj:`str`, optional): Type of projected band structure to\n            plot. Options are:\n\n                \"rgb\"\n                    The band structure line color depends on the character\n                    of the band. Each element/orbital contributes either\n                    red, green or blue with the corresponding line colour a\n                    mixture of all three colours. This mode only supports\n                    up to 3 elements/orbitals combinations. The order of\n                    the ``selection`` :obj:`tuple` determines which colour\n                    is used for each selection.\n                \"stacked\"\n                    The element/orbital contributions are drawn as a\n                    series of stacked circles, with the colour depending on\n                    the composition of the band. The size of the circles\n                    can be scaled using the ``circle_size`` option.\n        circle_size (:obj:`float`, optional): The area of the circles used\n            when ``mode = 'stacked'``.\n        dos_file (:obj:'str', optional): Path to vasprun.xml file from which to\n            read the density of states information. If set, the density of\n            states will be plotted alongside the bandstructure.\n        elements (:obj:`dict`, optional): The elements and orbitals to extract\n            from the projected density of states. Should be provided as a\n            :obj:`dict` with the keys as the element names and corresponding\n            values as a :obj:`tuple` of orbitals. For example, the following\n            would extract the Bi s, px, py and d orbitals::\n\n                {'Bi': ('s', 'px', 'py', 'd')}\n\n            If an element is included with an empty :obj:`tuple`, all orbitals\n            for that species will be extracted. If ``elements`` is not set or\n            set to ``None``, all elements for all species will be extracted.\n        lm_orbitals (:obj:`dict`, optional): The orbitals to decompose into\n            their lm contributions (e.g. p -> px, py, pz). Should be provided\n            as a :obj:`dict`, with the elements names as keys and a\n            :obj:`tuple` of orbitals as the corresponding values. For example,\n            the following would be used to decompose the oxygen p and d\n            orbitals::\n\n                {'O': ('p', 'd')}\n\n        atoms (:obj:`dict`, optional): Which atomic sites to use when\n            calculating the projected density of states. Should be provided as\n            a :obj:`dict`, with the element names as keys and a :obj:`tuple` of\n            :obj:`int` specifying the atomic indices as the corresponding\n            values. The elemental projected density of states will be summed\n            only over the atom indices specified. If an element is included\n            with an empty :obj:`tuple`, then all sites for that element will\n            be included. The indices are 0 based for each element specified in\n            the POSCAR. For example, the following will calculate the density\n            of states for the first 4 Sn atoms and all O atoms in the\n            structure::\n\n                {'Sn': (1, 2, 3, 4), 'O': (, )}\n\n            If ``atoms`` is not set or set to ``None`` then all atomic sites\n            for all elements will be considered.\n        total_only (:obj:`bool`, optional): Only extract the total density of\n            states. Defaults to ``False``.\n        plot_total (:obj:`bool`, optional): Plot the total density of states.\n            Defaults to ``True``.\n        legend_cutoff (:obj:`float`, optional): The cut-off (in % of the\n            maximum density of states within the plotting range) for an\n            elemental orbital to be labelled in the legend. This prevents\n            the legend from containing labels for orbitals that have very\n            little contribution in the plotting range.\n        gaussian (:obj:`float`, optional): Broaden the density of states using\n            convolution with a gaussian function. This parameter controls the\n            sigma or standard deviation of the gaussian distribution.\n        height (:obj:`float`, optional): The height of the plot.\n        width (:obj:`float`, optional): The width of the plot.\n        ymin (:obj:`float`, optional): The minimum energy on the y-axis.\n        ymax (:obj:`float`, optional): The maximum energy on the y-axis.\n        style (:obj:`list` or :obj:`str`, optional): (List of) matplotlib style\n            specifications, to be composed on top of Sumo base style.\n        no_base_style (:obj:`bool`, optional): Prevent use of sumo base style.\n            This can make alternative styles behave more predictably.\n        colours (:obj:`dict`, optional): Use custom colours for specific\n            element and orbital combinations. Specified as a :obj:`dict` of\n            :obj:`dict` of the colours. For example::\n\n                {\n                    'Sn': {'s': 'r', 'p': 'b'},\n                    'O': {'s': '#000000'}\n                }\n\n            The colour can be a hex code, series of rgb value, or any other\n            format supported by matplotlib.\n        yscale (:obj:`float`, optional): Scaling factor for the y-axis.\n        image_format (:obj:`str`, optional): The image file format. Can be any\n            format supported by matplotlib, including: png, jpg, pdf, and svg.\n            Defaults to pdf.\n        dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n            the image.\n        plt (:obj:`matplotlib.pyplot`, optional): A\n            :obj:`matplotlib.pyplot` object to use for plotting.\n        fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n            a single font, specified as a :obj:`str`, or several fonts,\n            specified as a :obj:`list` of :obj:`str`.\n\n    Returns:\n        If ``plt`` set then the ``plt`` object will be returned. Otherwise, the\n        method will return a :obj:`list` of filenames written to disk.\n    \"\"\"\n    if not filenames:\n        filenames = find_vasprun_files()\n    elif isinstance(filenames, str):\n        filenames = [filenames]\n\n    # only load the orbital projects if we definitely need them\n    parse_projected = True if projection_selection else False\n\n    # now load all the vaspruns and combine them together using the\n    # get_reconstructed_band_structure function from pymatgen\n    bandstructures = []\n    for vr_file in filenames:\n        vr = BSVasprun(vr_file, parse_projected_eigen=parse_projected)\n        bs = vr.get_band_structure(line_mode=True)\n        bandstructures.append(bs)\n    bs = get_reconstructed_band_structure(bandstructures)\n\n    # currently not supported as it is a pain to make subplots within subplots,\n    # although need to check this is still the case\n    if 'split' in mode and dos_file:\n        logging.error('ERROR: Plotting split projected band structure with DOS'\n                      ' not supported.\\nPlease use --projected-rgb or '\n                      '--projected-stacked options.')\n        sys.exit()\n\n    if (projection_selection and mode == 'rgb'\n            and len(projection_selection) > 3):\n        logging.error('ERROR: RGB projected band structure only '\n                      'supports up to 3 elements/orbitals.'\n                      '\\nUse alternative --mode setting.')\n        sys.exit()\n\n    # don't save if pyplot object provided\n    save_files = False if plt else True\n\n    dos_plotter = None\n    dos_opts = None\n    if dos_file:\n        dos, pdos = load_dos(dos_file, elements, lm_orbitals, atoms, gaussian,\n                             total_only)\n        dos_plotter = SDOSPlotter(dos, pdos)\n        dos_opts = {'plot_total': plot_total, 'legend_cutoff': legend_cutoff,\n                    'colours': colours, 'yscale': yscale}\n\n    plotter = SBSPlotter(bs)\n    if projection_selection:\n        plt = plotter.get_projected_plot(\n            projection_selection, mode=mode,\n            interpolate_factor=interpolate_factor, circle_size=circle_size,\n            zero_to_efermi=True, ymin=ymin, ymax=ymax, height=height,\n            width=width, vbm_cbm_marker=vbm_cbm_marker, ylabel=ylabel,\n            plt=plt, dos_plotter=dos_plotter, dos_options=dos_opts,\n            dos_label=dos_label, fonts=fonts, style=style,\n            no_base_style=no_base_style)\n    else:\n        plt = plotter.get_plot(\n            zero_to_efermi=True, ymin=ymin, ymax=ymax, height=height,\n            width=width, vbm_cbm_marker=vbm_cbm_marker, ylabel=ylabel,\n            plt=plt, dos_plotter=dos_plotter, dos_options=dos_opts,\n            dos_label=dos_label, fonts=fonts, style=style,\n            no_base_style=no_base_style)\n\n    if save_files:\n        basename = 'band.{}'.format(image_format)\n        filename = '{}_{}'.format(prefix, basename) if prefix else basename\n        if directory:\n            filename = os.path.join(directory, filename)\n        plt.savefig(filename, format=image_format, dpi=dpi,\n                    bbox_inches='tight')\n\n        written = [filename]\n        written += save_data_files(vr, bs, prefix=prefix,\n                                   directory=directory)\n        return written\n\n    else:\n        return plt"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find_vasprun_files():\n    folders = glob.glob('split-*')\n    folders = sorted(folders) if folders else ['.']\n\n    filenames = []\n    for fol in folders:\n        vr_file = os.path.join(fol, 'vasprun.xml')\n        vr_file_gz = os.path.join(fol, 'vasprun.xml.gz')\n\n        if os.path.exists(vr_file):\n            filenames.append(vr_file)\n        elif os.path.exists(vr_file_gz):\n            filenames.append(vr_file_gz)\n        else:\n            logging.error('ERROR: No vasprun.xml found in {}!'.format(fol))\n            sys.exit()\n\n    return filenames", "response": "Search for vasprun files from the current directory."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_data_files(vr, bs, prefix=None, directory=None):\n    filename = '{}_band.dat'.format(prefix) if prefix else 'band.dat'\n    directory = directory if directory else '.'\n    filename = os.path.join(directory, filename)\n\n    if bs.is_metal():\n        zero = vr.efermi\n    else:\n        zero = bs.get_vbm()['energy']\n\n    with open(filename, 'w') as f:\n        header = '#k-distance eigenvalue[eV]\\n'\n        f.write(header)\n\n        # write the spin up eigenvalues\n        for band in bs.bands[Spin.up]:\n            for d, e in zip(bs.distance, band):\n                f.write('{:.8f} {:.8f}\\n'.format(d, e - zero))\n            f.write('\\n')\n\n        # calculation is spin polarised, write spin down bands at end of file\n        if bs.is_spin_polarized:\n            for band in bs.bands[Spin.down]:\n                for d, e in zip(bs.distance, band):\n                    f.write('{:.8f} {:.8f}\\n'.format(d, e - zero))\n                f.write('\\n')\n    return filename", "response": "Write the data files for the current object vs and bs to disk."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _el_orb_tuple(string):\n    el_orbs = []\n    for split in string.split(','):\n        splits = split.split('.')\n        el = splits[0]\n        if len(splits) == 1:\n            el_orbs.append(el)\n        else:\n            el_orbs.append((el, tuple(splits[1:])))\n    return el_orbs", "response": "Parse the element and orbital argument strings."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef phonon_bandplot(filename, poscar=None, prefix=None, directory=None,\n                    dim=None, born=None, qmesh=None, spg=None,\n                    primitive_axis=None, line_density=60, units='THz',\n                    symprec=0.01, mode='bradcrack', kpt_list=None,\n                    eigenvectors=False, labels=None, height=6., width=6.,\n                    style=None, no_base_style=False,\n                    ymin=None, ymax=None, image_format='pdf', dpi=400,\n                    plt=None, fonts=None, dos=None):\n    \"\"\"A script to plot phonon band structure diagrams.\n\n    Args:\n        filename (str): Path to phonopy output. Can be a band structure yaml\n            file, ``FORCE_SETS``, ``FORCE_CONSTANTS``, or\n            ``force_constants.hdf5``.\n        poscar (:obj:`str`, optional): Path to POSCAR file of unitcell. Not\n            required if plotting the phonon band structure from a yaml file. If\n            not specified, the script will search for a POSCAR file in the\n            current directory.\n        prefix (:obj:`str`, optional): Prefix for file names.\n        directory (:obj:`str`, optional): The directory in which to save files.\n        born (:obj:`str`, optional): Path to file containing Born effective\n            charges. Should be in the same format as the file produced by the\n            ``phonopy-vasp-born`` script provided by phonopy.\n        qmesh (:obj:`list` of :obj:`int`, optional): Q-point mesh to use for\n            calculating the density of state. Formatted as a 3x1 :obj:`list` of\n            :obj:`int`.\n        spg (:obj:`str` or :obj:`int`, optional): The space group international\n            number or symbol to override the symmetry determined by spglib.\n            This is not recommended and only provided for testing purposes.\n            This option will only take effect when ``mode = 'bradcrack'``.\n        primitive_matrix (:obj:`list`, optional): The transformation matrix\n            from the conventional to primitive cell. Only required when the\n            conventional cell was used as the starting structure. Should be\n            provided as a 3x3 :obj:`list` of :obj:`float`.\n        line_density (:obj:`int`, optional): Density of k-points along the\n            path.\n        units (:obj:`str`, optional): Units of phonon frequency. Accepted\n            (case-insensitive) values are Thz, cm-1, eV, meV.\n        symprec (:obj:`float`, optional): Tolerance for space-group-finding\n            operations\n        mode (:obj:`str`, optional): Method used for calculating the\n            high-symmetry path. The options are:\n\n            bradcrack\n                Use the paths from Bradley and Cracknell. See [brad]_.\n\n            pymatgen\n                Use the paths from pymatgen. See [curt]_.\n\n            seekpath\n                Use the paths from SeeK-path. See [seek]_.\n\n        kpt_list (:obj:`list`, optional): List of k-points to use, formatted as\n            a list of subpaths, each containing a list of fractional k-points.\n            For example::\n\n                [ [[0., 0., 0.], [0., 0., 0.5]],\n                  [[0.5, 0., 0.], [0.5, 0.5, 0.]] ]\n\n            Will return points along ``0 0 0 -> 0 0 1/2 | 1/2 0 0\n            -> 1/2 1/2 0``\n        path_labels (:obj:`list`, optional): The k-point labels. These should\n            be provided as a :obj:`list` of :obj:`str` for each subpath of the\n            overall path. For example::\n\n                [ ['Gamma', 'Z'], ['X', 'M'] ]\n\n            combined with the above example for ``kpt_list`` would indicate the\n            path: Gamma -> Z | X -> M. If no labels are provided, letters from\n            A -> Z will be used instead.\n        eigenvectors (:obj:`bool`, optional): Write the eigenvectors to the\n            yaml file.\n        dos (str): Path to Phonopy total dos .dat file\n        height (:obj:`float`, optional): The height of the plot.\n        width (:obj:`float`, optional): The width of the plot.\n        ymin (:obj:`float`, optional): The minimum energy on the y-axis.\n        ymax (:obj:`float`, optional): The maximum energy on the y-axis.\n        style (:obj:`list` or :obj:`str`, optional): (List of) matplotlib style\n            specifications, to be composed on top of Sumo base style.\n        no_base_style (:obj:`bool`, optional): Prevent use of sumo base style.\n            This can make alternative styles behave more predictably.\n        image_format (:obj:`str`, optional): The image file format. Can be any\n            format supported by matplotlib, including: png, jpg, pdf, and svg.\n            Defaults to pdf.\n        dpi (:obj:`int`, optional): The dots-per-inch (pixel density) for\n            the image.\n        plt (:obj:`matplotlib.pyplot`, optional): A\n            :obj:`matplotlib.pyplot` object to use for plotting.\n        fonts (:obj:`list`, optional): Fonts to use in the plot. Can be a\n            a single font, specified as a :obj:`str`, or several fonts,\n            specified as a :obj:`list` of :obj:`str`.\n\n    Returns:\n        A matplotlib pyplot object.\n    \"\"\"\n    if '.yaml' in filename:\n        yaml_file = filename\n    elif ('FORCE_SETS' == filename or 'FORCE_CONSTANTS' == filename or\n            '.hdf5' in filename):\n        try:\n            poscar = poscar if poscar else 'POSCAR'\n            poscar = Poscar.from_file(poscar)\n        except IOError:\n            msg = \"Cannot find POSCAR file, cannot generate symmetry path.\"\n            logging.error(\"\\n {}\".format(msg))\n            sys.exit()\n\n        if not dim:\n            logging.info(\"Supercell size (--dim option) not provided.\\n\"\n                         \"Attempting to guess supercell dimensions.\\n\")\n            try:\n                sposcar = Poscar.from_file(\"SPOSCAR\")\n            except IOError:\n                msg = \"Could not determine supercell size (use --dim flag).\"\n                logging.error(\"\\n {}\".format(msg))\n                sys.exit()\n\n            dim = (sposcar.structure.lattice.matrix *\n                   poscar.structure.lattice.inv_matrix)\n\n            # round due to numerical noise error\n            dim = np.around(dim, 5)\n\n        elif len(dim) == 9:\n            dim = np.array(dim).reshape(3, 3)\n\n        elif np.array(dim).shape != (3, 3):\n            dim = np.diagflat(dim)\n\n        logging.info(\"Using supercell with dimensions:\")\n        logging.info('\\t' + str(dim).replace('\\n', '\\n\\t')+'\\n')\n\n        factors = {'ev': VaspToEv, 'thz': VaspToTHz, 'mev': VaspToEv * 1000,\n                   'cm-1': VaspToCm}\n\n        phonon = load_phonopy(filename, poscar.structure, dim, symprec=symprec,\n                              primitive_matrix=primitive_axis,\n                              factor=factors[units.lower()],\n                              symmetrise=True, born=born,\n                              write_fc=False)\n\n        # calculate band structure\n        kpath, kpoints, labels = get_path_data(poscar.structure, mode=mode,\n                                               symprec=symprec, spg=spg,\n                                               kpt_list=kpt_list,\n                                               labels=labels, phonopy=True)\n\n        # todo: calculate dos and plot also\n        # phonon.set_mesh(mesh, is_gamma_center=False, is_eigenvectors=True,\n        #                 is_mesh_symmetry=False)\n        # phonon.set_partial_DOS()\n\n        phonon.set_band_structure(kpoints, is_eigenvectors=eigenvectors)\n        yaml_file = 'sumo_band.yaml'\n        phonon._band_structure.write_yaml(labels=labels, filename=yaml_file)\n\n    else:\n        msg = \"Do not recognise file type of {}\".format(filename)\n        logging.error(\"\\n {}\".format(msg))\n        sys.exit()\n\n    save_files = False if plt else True  # don't save if pyplot object provided\n\n    bs = get_ph_bs_symm_line(yaml_file, has_nac=False,\n                             labels_dict=kpath.kpoints)\n\n    # Replace dos filename with data array\n    if dos is not None:\n        if isfile(dos):\n            dos = np.genfromtxt(dos, comments='#')\n        elif dos:\n            phonon.set_mesh(qmesh, is_gamma_center=False, is_eigenvectors=True,\n                            is_mesh_symmetry=False)\n            phonon.set_total_DOS()\n            dos_freq, dos_val = phonon.get_total_DOS()\n            dos = np.zeros((len(dos_freq), 2))\n            dos[:, 0], dos[:, 1] = dos_freq, dos_val\n\n    plotter = SPhononBSPlotter(bs)\n    plt = plotter.get_plot(units=units, ymin=ymin, ymax=ymax, height=height,\n                           width=width, plt=plt, fonts=fonts, dos=dos)\n\n    if save_files:\n        basename = 'phonon_band.{}'.format(image_format)\n        filename = '{}_{}'.format(prefix, basename) if prefix else basename\n\n        if directory:\n            filename = os.path.join(directory, filename)\n\n        if dpi is None:\n            dpi = rcParams['figure.dpi']\n        plt.savefig(filename, format=image_format, dpi=dpi,\n                    bbox_inches='tight')\n\n        filename = save_data_files(bs, prefix=prefix, directory=directory)\n    else:\n        return plt", "response": "A script to plot phonon band structure diagrams for a single entry in the current directory."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef save_data_files(bs, prefix=None, directory=None):\n    filename = 'phonon_band.dat'\n    filename = '{}_phonon_band.dat'.format(prefix) if prefix else filename\n    directory = directory if directory else '.'\n    filename = os.path.join(directory, filename)\n\n    with open(filename, 'w') as f:\n        header = '#k-distance frequency[THz]\\n'\n        f.write(header)\n\n        for band in bs.bands:\n            for d, e in zip(bs.distance, band):\n                f.write('{:.8f} {:.8f}\\n'.format(d, e))\n            f.write('\\n')\n\n    return filename", "response": "Writes the phonon band structure data files to disk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate KPOINTS files for VASP band structure calculations. This script provides a wrapper around several frameworks used to generate k-points along a high-symmetry path. The paths found in Bradley and Cracknell, SeeK-path, and pymatgen are all supported. It is important to note that the standard primitive cell symmetry is different between SeeK-path and pymatgen. If the correct the structure is not used, the high-symmetry points (and band path) may be invalid. Args: filename (:obj:`str`, optional): Path to VASP structure file. Default is ``POSCAR``. directory (:obj:`str`, optional): The output file directory. make_folders (:obj:`bool`, optional): Generate folders and copy in required files (INCAR, POTCAR, POSCAR, and possibly CHGCAR) from the current directory. symprec (:obj:`float`, optional): The precision used for determining the cell symmetry. kpts_per_split (:obj:`int`, optional): If set, the k-points are split into separate k-point files (or folders) each containing the number of k-points specified. This is useful for hybrid band structure calculations where it is often intractable to calculate all k-points in the same calculation. ibzkpt (:obj:`str`, optional): Path to IBZKPT file. If set, the generated k-points will be appended to the k-points in this file and given a weight of 0. This is necessary for hybrid band structure calculations. spg (:obj:`str` or :obj:`int`, optional): The space group international number or symbol to override the symmetry determined by spglib. This is not recommended and only provided for testing purposes. This option will only take effect when ``mode = 'bradcrack'``. line_density (:obj:`int`, optional): Density of k-points along the path. mode (:obj:`str`, optional): Method used for calculating the high-symmetry path. The options are: bradcrack Use the paths from Bradley and Cracknell. See [brad]_. pymatgen Use the paths from pymatgen. See [curt]_. seekpath Use the paths from SeeK-path. See [seek]_. cart_coords (:obj:`bool`, optional): Whether the k-points are returned in cartesian or reciprocal coordinates. Defaults to ``False`` (fractional coordinates). kpt_list (:obj:`list`, optional): List of k-points to use, formatted as a list of subpaths, each containing a list of fractional k-points. For example:: [ [[0., 0., 0.], [0., 0., 0.5]], [[0.5, 0., 0.], [0.5, 0.5, 0.]] ] Will return points along ``0 0 0 -> 0 0 1/2 | 1/2 0 0 -> 1/2 1/2 0`` path_labels (:obj:`list`, optional): The k-point labels. These should be provided as a :obj:`list` of :obj:`str` for each subpath of the overall path. For example:: [ ['Gamma', 'Z'], ['X', 'M'] ] combined with the above example for ``kpt_list`` would indicate the path: Gamma -> Z | X -> M. If no labels are provided, letters from A -> Z will be used instead. If a label begins with '@' it will be concealed when plotting with sumo-bandplot.", "response": "def kgen(filename='POSCAR', directory=None, make_folders=False, symprec=0.01,\n         kpts_per_split=None, ibzkpt=None, spg=None, density=60,\n         mode='bradcrack', cart_coords=False, kpt_list=None, labels=None):\n    \"\"\"Generate KPOINTS files for VASP band structure calculations.\n\n    This script provides a wrapper around several frameworks used to generate\n    k-points along a high-symmetry path. The paths found in Bradley and\n    Cracknell, SeeK-path, and pymatgen are all supported.\n\n    It is important to note that the standard primitive cell symmetry is\n    different between SeeK-path and pymatgen. If the correct the structure\n    is not used, the high-symmetry points (and band path) may be invalid.\n\n    Args:\n        filename (:obj:`str`, optional): Path to VASP structure file. Default\n            is ``POSCAR``.\n        directory (:obj:`str`, optional): The output file directory.\n        make_folders (:obj:`bool`, optional): Generate folders and copy in\n            required files (INCAR, POTCAR, POSCAR, and possibly CHGCAR) from\n            the current directory.\n        symprec (:obj:`float`, optional): The precision used for determining\n            the cell symmetry.\n        kpts_per_split (:obj:`int`, optional): If set, the k-points are split\n            into separate k-point files (or folders) each containing the number\n            of k-points specified. This is useful for hybrid band structure\n            calculations where it is often intractable to calculate all\n            k-points in the same calculation.\n        ibzkpt (:obj:`str`, optional): Path to IBZKPT file. If set, the\n            generated k-points will be appended to the k-points in this file\n            and given a weight of 0. This is necessary for hybrid band\n            structure calculations.\n        spg (:obj:`str` or :obj:`int`, optional): The space group international\n            number or symbol to override the symmetry determined by spglib.\n            This is not recommended and only provided for testing purposes.\n            This option will only take effect when ``mode = 'bradcrack'``.\n        line_density (:obj:`int`, optional): Density of k-points along the\n            path.\n        mode (:obj:`str`, optional): Method used for calculating the\n            high-symmetry path. The options are:\n\n            bradcrack\n                Use the paths from Bradley and Cracknell. See [brad]_.\n\n            pymatgen\n                Use the paths from pymatgen. See [curt]_.\n\n            seekpath\n                Use the paths from SeeK-path. See [seek]_.\n\n        cart_coords (:obj:`bool`, optional): Whether the k-points are returned\n            in cartesian or reciprocal coordinates. Defaults to ``False``\n            (fractional coordinates).\n        kpt_list (:obj:`list`, optional): List of k-points to use, formatted as\n            a list of subpaths, each containing a list of fractional k-points.\n            For example::\n\n                [ [[0., 0., 0.], [0., 0., 0.5]],\n                  [[0.5, 0., 0.], [0.5, 0.5, 0.]] ]\n\n            Will return points along ``0 0 0 -> 0 0 1/2 | 1/2 0 0\n            -> 1/2 1/2 0``\n        path_labels (:obj:`list`, optional): The k-point labels. These should\n            be provided as a :obj:`list` of :obj:`str` for each subpath of the\n            overall path. For example::\n\n                [ ['Gamma', 'Z'], ['X', 'M'] ]\n\n            combined with the above example for ``kpt_list`` would indicate the\n            path: Gamma -> Z | X -> M. If no labels are provided, letters from\n            A -> Z will be used instead. If a label begins with '@' it will be\n            concealed when plotting with sumo-bandplot.\n    \"\"\"\n    poscar = Poscar.from_file(filename)\n    kpath, kpoints, labels = get_path_data(poscar.structure, mode=mode,\n                                           symprec=symprec, kpt_list=kpt_list,\n                                           labels=labels, spg=spg,\n                                           line_density=density)\n\n    logging.info('\\nk-point label indices:')\n    for i, label in enumerate(labels):\n        if label:\n            logging.info('\\t{}: {}'.format(label, i+1))\n\n    if not kpt_list and not np.allclose(poscar.structure.lattice.matrix,\n                                        kpath.prim.lattice.matrix):\n        prim_filename = '{}_prim'.format(os.path.basename(filename))\n        kpath.prim.to(filename=prim_filename)\n\n        logging.error(\"\\nWARNING: The input structure does not match the \"\n                      \"expected standard\\nprimitive symmetry, the path may be \"\n                      \"incorrect! Use at your own risk.\\n\\nThe correct \"\n                      \"symmetry primitive structure has been saved as {}.\".\n                      format(prim_filename))\n\n    ibz = _parse_ibzkpt(ibzkpt)\n\n    if make_folders and ibz and kpts_per_split is None:\n        logging.info(\"\\nFound {} total kpoints in path, do you want to \"\n                     \"split them up? (y/n)\".format(len(kpoints)))\n        if input()[0].lower() == 'y':\n            logging.info(\"How many kpoints per file?\")\n            kpts_per_split = int(input())\n\n    write_kpoint_files(filename, kpoints, labels, make_folders=make_folders,\n                       ibzkpt=ibz, kpts_per_split=kpts_per_split,\n                       directory=directory, cart_coords=cart_coords)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _el_orb(string):\n    el_orbs = {}\n    for split in string.split(','):\n        orbs = split.split('.')\n        orbs = [orbs[0], 's', 'p', 'd', 'f'] if len(orbs) == 1 else orbs\n        el_orbs[orbs.pop(0)] = orbs\n    return el_orbs", "response": "Parse the element and orbital argument strings."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nparse the atom string and return a dictionary of atomic indices.", "response": "def _atoms(atoms_string):\n    \"\"\"Parse the atom string.\n\n    Args:\n        atoms_string (str): The atoms to plot, in the form ``\"C.1.2.3,\"``.\n\n    Returns:\n        dict: The atomic indices over which to sum the DOS. Formatted as::\n\n            {Element: [atom_indices]}.\n\n        Indices are zero indexed for each atomic species. If an element symbol\n        is included with an empty list, then all sites for that species are\n        considered.\n    \"\"\"\n    atoms = {}\n    for split in atoms_string.split(','):\n        sites = split.split('.')\n        el = sites.pop(0)\n        sites = list(map(int, sites))\n        atoms[el] = np.array(sites) - 1\n    return atoms"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nformat a string using appropriate globals and locals.", "response": "def f(s):\n    \"\"\"\n    Basic support for 3.6's f-strings, in 3.5!\n\n    Formats \"s\" using appropriate globals and locals\n    dictionaries.  This f-string:\n        f\"hello a is {a}\"\n    simply becomes\n        f(\"hello a is {a}\")\n    In other words, just throw parentheses around the\n    string, and you're done!\n\n    Implemented internally using str.format_map().\n    This means it doesn't support expressions:\n        f(\"two minus three is {2-3}\")\n    And it doesn't support function calls:\n        f(\"how many elements? {len(my_list)}\")\n    But most other f-string features work.\n    \"\"\"\n    frame = sys._getframe(1)\n    d = dict(builtins.__dict__)\n    d.update(frame.f_globals)\n    d.update(frame.f_locals)\n    return s.format_map(d)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef textwrap_body(body, *, subsequent_indent=''):\n    if isinstance(body, str):\n        text = body\n    else:\n        text = \"\\n\".join(body).rstrip()\n\n    # textwrap merges paragraphs, ARGH\n\n    # step 1: remove trailing whitespace from individual lines\n    #   (this means that empty lines will just have \\n, no invisible whitespace)\n    lines = []\n    for line in text.split(\"\\n\"):\n        lines.append(line.rstrip())\n    text = \"\\n\".join(lines)\n    # step 2: break into paragraphs and wrap those\n    paragraphs = text.split(\"\\n\\n\")\n    paragraphs2 = []\n    kwargs = {'break_long_words': False, 'break_on_hyphens': False}\n    if subsequent_indent:\n        kwargs['subsequent_indent'] = subsequent_indent\n    dont_reflow = False\n    for paragraph in paragraphs:\n        # don't reflow bulleted / numbered lists\n        dont_reflow = dont_reflow or paragraph.startswith((\"* \", \"1. \", \"#. \"))\n        if dont_reflow:\n            initial = kwargs.get(\"initial_indent\", \"\")\n            subsequent = kwargs.get(\"subsequent_indent\", \"\")\n            if initial or subsequent:\n                lines = [line.rstrip() for line in paragraph.split(\"\\n\")]\n                indents = itertools.chain(\n                    itertools.repeat(initial, 1),\n                    itertools.repeat(subsequent),\n                    )\n                lines = [indent + line for indent, line in zip(indents, lines)]\n                paragraph = \"\\n\".join(lines)\n            paragraphs2.append(paragraph)\n        else:\n            # Why do we reflow the text twice?  Because it can actually change\n            # between the first and second reflows, and we want the text to\n            # be stable.  The problem is that textwrap.wrap is deliberately\n            # dumb about how many spaces follow a period in prose.\n            #\n            # We're reflowing at 76 columns, but let's pretend it's 30 for\n            # illustration purposes.  If we give textwrap.wrap the following\n            # text--ignore the line of 30 dashes, that's just to help you\n            # with visualization:\n            #\n            #  ------------------------------\n            #  xxxx xxxx xxxx xxxx xxxx.  xxxx\n            #\n            # The first textwrap.wrap will return this:\n            #  \"xxxx xxxx xxxx xxxx xxxx.\\nxxxx\"\n            #\n            # If we reflow it again, textwrap will rejoin the lines, but\n            # only with one space after the period!  So this time it'll\n            # all fit on one line, behold:\n            #  ------------------------------\n            #  xxxx xxxx xxxx xxxx xxxx. xxxx\n            # and so it now returns:\n            #  \"xxxx xxxx xxxx xxxx xxxx. xxxx\"\n            #\n            # textwrap.wrap supports trying to add two spaces after a peroid:\n            #    https://docs.python.org/3/library/textwrap.html#textwrap.TextWrapper.fix_sentence_endings\n            # But it doesn't work all that well, because it's not smart enough\n            # to do a really good job.\n            #\n            # Since blurbs are eventually turned into ReST and rendered anyway,\n            # and since the Zen says \"In the face of ambiguity, refuse the\n            # temptation to guess\", I don't sweat it.  I run textwrap.wrap\n            # twice, so it's stable, and this means occasionally it'll\n            # convert two spaces to one space, no big deal.\n\n            paragraph = \"\\n\".join(textwrap.wrap(paragraph.strip(), width=76, **kwargs)).rstrip()\n            paragraph = \"\\n\".join(textwrap.wrap(paragraph.strip(), width=76, **kwargs)).rstrip()\n            paragraphs2.append(paragraph)\n        # don't reflow literal code blocks (I hope)\n        dont_reflow = paragraph.endswith(\"::\")\n        if subsequent_indent:\n            kwargs['initial_indent'] = subsequent_indent\n    text = \"\\n\\n\".join(paragraphs2).rstrip()\n    if not text.endswith(\"\\n\"):\n        text += \"\\n\"\n    return text", "response": "Wraps the given text into a single line of text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef which(cmd, path=\"PATH\"):\n    if os.path.exists(cmd):\n        return cmd\n    if cmd[0] == '/':\n        return None\n    for segment in os.getenv(path).split(\":\"):\n        program = os.path.normpath(os.path.join(segment, cmd))\n        if os.path.exists(program):\n            return program\n    return None", "response": "Find cmd on PATH."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nprinting help text for all subcommands.", "response": "def help(subcommand=None):\n    \"\"\"\nPrint help for subcommands.\n\nPrints the help text for the specified subcommand.\nIf subcommand is not specified, prints one-line summaries for every command.\n    \"\"\"\n\n    if not subcommand:\n        print(\"blurb version\", __version__)\n        print()\n        print(\"Management tool for CPython Misc/NEWS and Misc/NEWS.d entries.\")\n        print()\n        print(\"Usage:\")\n        print(\"    blurb [subcommand] [options...]\")\n        print()\n\n        # print list of subcommands\n        summaries = []\n        longest_name_len = -1\n        for name, fn in subcommands.items():\n            if name.startswith('-'):\n                continue\n            longest_name_len = max(longest_name_len, len(name))\n            if not fn.__doc__:\n                error(\"help is broken, no docstring for \" + fn.__name__)\n            fields = fn.__doc__.lstrip().split(\"\\n\")\n            if not fields:\n                first_line = \"(no help available)\"\n            else:\n                first_line = fields[0]\n            summaries.append((name, first_line))\n        summaries.sort()\n\n        print(\"Available subcommands:\")\n        print()\n        for name, summary in summaries:\n            print(\" \", name.ljust(longest_name_len), \" \", summary)\n\n        print()\n        print(\"If blurb is run without any arguments, this is equivalent to 'blurb add'.\")\n\n        sys.exit(0)\n\n    fn = get_subcommand(subcommand)\n    doc = fn.__doc__.strip()\n    if not doc:\n        error(\"help is broken, no docstring for \" + subcommand)\n\n    options = []\n    positionals = []\n\n    nesting = 0\n    for name, p in inspect.signature(fn).parameters.items():\n        if p.kind == inspect.Parameter.KEYWORD_ONLY:\n            short_option = name[0]\n            options.append(f(\" [-{short_option}|--{name}]\"))\n        elif p.kind == inspect.Parameter.POSITIONAL_OR_KEYWORD:\n            positionals.append(\" \")\n            has_default = (p.default != inspect._empty)\n            if has_default:\n                positionals.append(\"[\")\n                nesting += 1\n            positionals.append(f(\"<{name}>\"))\n    positionals.append(\"]\" * nesting)\n\n\n    parameters = \"\".join(options + positionals)\n    print(f(\"blurb {subcommand}{parameters}\"))\n    print()\n    print(doc)\n    sys.exit(0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a blurb to the current CPython repo.", "response": "def add():\n    \"\"\"\nAdd a blurb (a Misc/NEWS entry) to the current CPython repo.\n    \"\"\"\n\n    editor = find_editor()\n\n    handle, tmp_path = tempfile.mkstemp(\".rst\")\n    os.close(handle)\n    atexit.register(lambda : os.unlink(tmp_path))\n\n    def init_tmp_with_template():\n        with open(tmp_path, \"wt\", encoding=\"utf-8\") as file:\n            # hack:\n            # my editor likes to strip trailing whitespace from lines.\n            # normally this is a good idea.  but in the case of the template\n            # it's unhelpful.\n            # so, manually ensure there's a space at the end of the bpo line.\n            text = template\n\n            bpo_line = \".. bpo:\"\n            without_space = \"\\n\" + bpo_line + \"\\n\"\n            with_space = \"\\n\" + bpo_line + \" \\n\"\n            if without_space not in text:\n                sys.exit(\"Can't find BPO line to ensure there's a space on the end!\")\n            text = text.replace(without_space, with_space)\n            file.write(text)\n\n    init_tmp_with_template()\n\n    # We need to be clever about EDITOR.\n    # On the one hand, it might be a legitimate path to an\n    #   executable containing spaces.\n    # On the other hand, it might be a partial command-line\n    #   with options.\n    if shutil.which(editor):\n        args = [editor]\n    else:\n        args = list(shlex.split(editor))\n        if not shutil.which(args[0]):\n            sys.exit(f(\"Invalid GIT_EDITOR / EDITOR value: {editor}\"))\n    args.append(tmp_path)\n\n    while True:\n        subprocess.run(args)\n\n        failure = None\n        blurb = Blurbs()\n        try:\n            blurb.load(tmp_path)\n        except BlurbError as e:\n            failure = str(e)\n\n        if not failure:\n            assert len(blurb) # if parse_blurb succeeds, we should always have a body\n            if len(blurb) > 1:\n                failure = \"Too many entries!  Don't specify '..' on a line by itself.\"\n\n        if failure:\n            print()\n            print(f(\"Error: {failure}\"))\n            print()\n            try:\n                prompt(\"Hit return to retry (or Ctrl-C to abort)\")\n            except KeyboardInterrupt:\n                print()\n                return\n            print()\n            continue\n        break\n\n    path = blurb.save_next()\n    git_add_files.append(path)\n    flush_git_add_files()\n    print(\"Ready for commit.\")"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef release(version):\n    if version == \".\":\n        # harvest version number from dirname of repo\n        # I remind you, we're in the Misc subdir right now\n        version = os.path.basename(root)\n\n    existing_filenames = glob_blurbs(version)\n    if existing_filenames:\n        error(\"Sorry, can't handle appending 'next' files to an existing version (yet).\")\n\n    output = f(\"Misc/NEWS.d/{version}.rst\")\n    filenames = glob_blurbs(\"next\")\n    blurbs = Blurbs()\n    date = current_date()\n\n    if not filenames:\n        print(f(\"No blurbs found.  Setting {version} as having no changes.\"))\n        body = f(\"There were no new changes in version {version}.\\n\")\n        metadata = {\"no changes\": \"True\", \"bpo\": \"0\", \"section\": \"Library\", \"date\": date, \"nonce\": nonceify(body)}\n        blurbs.append((metadata, body))\n    else:\n        no_changes = None\n        count = len(filenames)\n        print(f('Merging {count} blurbs to \"{output}\".'))\n\n        for filename in filenames:\n            if not filename.endswith(\".rst\"):\n                continue\n            blurbs.load_next(filename)\n\n        metadata = blurbs[0][0]\n\n    metadata['release date'] = date\n    print(\"Saving.\")\n\n    blurbs.save(output)\n    git_add_files.append(output)\n    flush_git_add_files()\n\n    how_many = len(filenames)\n    print(f(\"Removing {how_many} 'next' files from git.\"))\n    git_rm_files.extend(filenames)\n    flush_git_rm_files()\n\n    # sanity check: ensuring that saving/reloading the merged blurb file works.\n    blurbs2 = Blurbs()\n    blurbs2.load(output)\n    assert blurbs2 == blurbs, f(\"Reloading {output} isn't reproducible?!\")\n\n    print()\n    print(\"Ready for commit.\")", "response": "Move all new blurbs to a single blurb file for the release."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nmerging all blurbs together into a single Misc file.", "response": "def merge(output=None, *, forced=False):\n    \"\"\"\nMerge all blurbs together into a single Misc/NEWS file.\n\nOptional output argument specifies where to write to.\nDefault is <cpython-root>/Misc/NEWS.\n\nIf overwriting, blurb merge will prompt you to make sure it's okay.\nTo force it to overwrite, use -f.\n    \"\"\"\n    if output:\n        output = os.path.join(original_dir, output)\n    else:\n        output = \"Misc/NEWS\"\n\n    versions = glob_versions()\n    if not versions:\n        sys.exit(\"You literally don't have ANY blurbs to merge together!\")\n\n    if os.path.exists(output) and not forced:\n        builtins.print(\"You already have a\", repr(output), \"file.\")\n        require_ok(\"Type ok to overwrite\")\n\n    news = open(output, \"wt\", encoding=\"utf-8\")\n\n    def print(*a, sep=\" \"):\n        s = sep.join(str(x) for x in a)\n        return builtins.print(s, file=news)\n\n    print (\"\"\"\n+++++++++++\nPython News\n+++++++++++\n\n\"\"\".strip())\n\n    for version in versions:\n        filenames = glob_blurbs(version)\n\n        blurbs = Blurbs()\n        if version == \"next\":\n            for filename in filenames:\n                if os.path.basename(filename) == \"README.rst\":\n                    continue\n                blurbs.load_next(filename)\n            if not blurbs:\n                continue\n            metadata = blurbs[0][0]\n            metadata['release date'] = \"XXXX-XX-XX\"\n        else:\n            assert len(filenames) == 1\n            blurbs.load(filenames[0])\n\n        header = \"What's New in Python \" + printable_version(version) + \"?\"\n        print()\n        print(header)\n        print(\"=\" * len(header))\n        print()\n\n\n        metadata, body = blurbs[0]\n        release_date = metadata[\"release date\"]\n\n        print(f(\"*Release date: {release_date}*\"))\n        print()\n\n        if \"no changes\" in metadata:\n            print(body)\n            print()\n            continue\n\n        last_section = None\n        for metadata, body in blurbs:\n            section = metadata['section']\n            if last_section != section:\n                last_section = section\n                print(section)\n                print(\"-\" * len(section))\n                print()\n\n            bpo = metadata['bpo']\n            if int(bpo):\n                body = \"bpo-\" + bpo + \": \" + body\n            body = \"- \" + body\n            text = textwrap_body(body, subsequent_indent='  ')\n            print(text)\n    print()\n    print(\"**(For information about older versions, consult the HISTORY file.)**\")\n    news.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\npopulate the Misc directory tree with the contents of the README. rst file.", "response": "def populate():\n    \"\"\"\nCreates and populates the Misc/NEWS.d directory tree.\n    \"\"\"\n    os.chdir(\"Misc\")\n    safe_mkdir(\"NEWS.d/next\")\n\n    for section in sections:\n        dir_name = sanitize_section(section)\n        dir_path = f(\"NEWS.d/next/{dir_name}\")\n        safe_mkdir(dir_path)\n        readme_path = f(\"NEWS.d/next/{dir_name}/README.rst\")\n        with open(readme_path, \"wt\", encoding=\"utf-8\") as readme:\n            readme.write(f(\"Put news entry ``blurb`` files for the *{section}* section in this directory.\\n\"))\n        git_add_files.append(dir_path)\n        git_add_files.append(readme_path)\n    flush_git_add_files()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split(*, released=False):\n\n    # note: populate also does chdir $python_root/Misc for you\n    populate()\n\n    if not os.path.isfile(\"NEWS\"):\n        error(\"You don't have a Misc/NEWS file!\")\n\n    def global_sections():\n        global sections\n        return sections\n\n    sections = set(global_sections())\n    release_date_marker = \"Release date:\"\n    whats_new_marker = \"What's New in Python \"\n\n    blurbs = Blurbs()\n\n    accumulator = []\n    bpo = \"0\"\n    serial_number = 9999\n    version = None\n    release_date = None\n    section = None\n    see_also = None\n    no_changes = None\n    security = None\n    blurb_count = 0\n    version_count = 0\n\n\n    def flush_blurb():\n        nonlocal accumulator\n        nonlocal serial_number\n        nonlocal bpo\n        nonlocal release_date\n        nonlocal see_also\n        nonlocal no_changes\n        nonlocal blurb_count\n        nonlocal security\n\n        if accumulator:\n            if version:\n                # strip trailing blank lines\n                while accumulator:\n                    line = accumulator.pop()\n                    if not line.rstrip():\n                        continue\n                    accumulator.append(line)\n                    break\n                if see_also:\n                    fields = []\n                    see_also = see_also.replace(\" and \", \",\")\n                    for field in see_also.split(\",\"):\n                        field = field.strip()\n                        if not field:\n                            continue\n                        if field.startswith(\"and \"):\n                            field = field[5:].lstrip()\n                        if field.lower().startswith(\"issue\"):\n                            field = field[5:].strip()\n                        if field.startswith(\"#\"):\n                            field = field[1:]\n                        try:\n                            int(field)\n                            field = \"bpo-\" + field\n                        except ValueError:\n                            pass\n                        fields.append(field)\n                    see_also = \", \".join(fields)\n                    # print(\"see_also: \", repr(see_also))\n                    accumulator.append(f(\"(See also: {see_also})\"))\n                    see_also = None\n                if not accumulator:\n                    return\n                if not (section or no_changes):\n                    error(\"No section for line \" + str(line_number) + \"!\")\n\n                body = \"\\n\".join(accumulator) + \"\\n\"\n                metadata = {}\n                metadata[\"bpo\"] = bpo\n                metadata[\"date\"] = str(serial_number)\n                if section:\n                    metadata[\"section\"] = section\n                else:\n                    assert no_changes\n                metadata[\"nonce\"] = nonceify(body)\n                if security:\n                    # retroactively change section to \"Security\"\n                    assert section\n                    metadata[\"original section\"] = metadata[\"section\"]\n                    metadata[\"section\"] = \"Security\"\n\n                if release_date is not None:\n                    assert not len(blurbs)\n                    metadata[\"release date\"] = release_date\n                    release_date = None\n                if no_changes is not None:\n                    assert not len(blurbs)\n                    metadata[\"no changes\"] = \"True\"\n                    no_changes = None\n                blurbs.append((metadata, body))\n                blurb_count += 1\n\n            bpo = \"0\"\n            serial_number -= 1\n            accumulator.clear()\n\n    def flush_version():\n        global git_add_files\n        nonlocal released\n        nonlocal version_count\n\n        flush_blurb()\n        if version is None:\n            assert not blurbs, \"version should only be None initially, we shouldn't have blurbs yet\"\n            return\n        assert blurbs, f(\"No blurbs defined when flushing version {version}!\")\n        output = f(\"NEWS.d/{version}.rst\")\n\n        if released:\n            # saving merged blurb file for version, e.g. Misc/NEWS.d/3.7.0a1.rst\n            blurbs.save(output)\n            git_add_files.append(output)\n        else:\n            # saving a million old-school blurb next files\n            # with serial numbers instead of dates\n            # e.g. Misc/NEWS.d/next/IDLE/094.bpo-25514.882pXa.rst\n            filenames = blurbs.save_split_next()\n            git_add_files.extend(filenames)\n            released = True\n        blurbs.clear()\n        version_count += 1\n\n    with open(\"NEWS\", \"rt\", encoding=\"utf-8\") as file:\n        for line_number, line in enumerate(file):\n            line = line.rstrip()\n\n            if line.startswith(\"\\ufeff\"):\n                line = line[1:]\n\n            # clean the slightly dirty data:\n            # 1. inconsistent names for sections, etc\n            for old, new in (\n                (\"C-API\", \"C API\"),\n                (\"Core and builtins\", \"Core and Builtins\"),\n                (\"Tools\", \"Tools/Demos\"),\n                (\"Tools / Demos\", \"Tools/Demos\"),\n                (\"Misc\", \"Windows\"), # only used twice, both were really Windows\n                (\"Mac\", \"macOS\"),\n                (\"Mac OS X\", \"macOS\"),\n                (\"Extension Modules\", \"Library\"),\n                (\"Whats' New in Python 2.7.6?\", \"What's New in Python 2.7.6?\"),\n                ):\n                if line == old:\n                    line = new\n            # 2. unusual indenting\n            _line = line.lstrip()\n            if _line.startswith((\"- Issue #\", \"- bpo-\")):\n                line = _line\n            if _line == \".characters() and ignorableWhitespace() methods.  Original patch by Sebastian\":\n                line = \" \" + line\n            # 3. fix version for What's New\n            if line.startswith(whats_new_marker):\n                flush_version()\n                version = line[len(whats_new_marker):].strip().lower()\n                for old, new in (\n                    (\"?\", \"\"),\n                    (\" alpha \", \"a\"),\n                    (\" beta \", \"b\"),\n                    (\" release candidate \", \"rc\"),\n                    (\" final\", \"\"),\n                    (\"3.5a\", \"3.5.0a\"),\n                    ):\n                    version = version.replace(old, new)\n                section = None\n                continue\n            # 3.a. fix specific precious little snowflakes\n            # who can't be bothered to follow our stifling style conventions\n            # and like, did their own *thing*, man.\n            if line.startswith(\"- Issue #27181 remove statistics.geometric_mean\"):\n                line = line.replace(\" remove\", \": remove\")\n            elif line.startswith(\"* bpo-30357: test_thread: setUp()\"):\n                line = line.replace(\"* bpo-30357\", \"- bpo-30357\")\n            elif line.startswith(\"- Issue #25262. Added support for BINBYTES8\"):\n                line = line.replace(\"#25262.\", \"#25262:\")\n            elif line.startswith(\"- Issue #21032. Fixed socket leak if\"):\n                line = line.replace(\"#21032.\", \"#21032:\")\n            elif line.startswith(\"- Issue ##665194: Update \"):\n                line = line.replace(\"##665194\", \"#665194\")\n            elif line.startswith(\"- Issue #13449 sched.scheduler.run()\"):\n                line = line.replace(\"#13449 sched\", \"#13449: sched\")\n            elif line.startswith(\"- Issue #8684 sched.scheduler class\"):\n                line = line.replace(\"#8684 sched\", \"#8684: sched\")\n            elif line.startswith(\" bpo-29243: Prevent unnecessary rebuilding\"):\n                line = line.replace(\" bpo-29243:\", \"- bpo-29243:\")\n            elif line.startswith((\n                \"- Issue #11603 (again): Setting\",\n                \"- Issue #15801 (again): With string\",\n                )):\n                line = line.replace(\" (again):\", \":\")\n            elif line.startswith(\"- Issue #1665206 (partially): \"):\n                line = line.replace(\" (partially):\", \":\")\n            elif line.startswith(\"- Issue #2885 (partial): The\"):\n                line = line.replace(\" (partial):\", \":\")\n            elif line.startswith(\"- Issue #2885 (partial): The\"):\n                line = line.replace(\" (partial):\", \":\")\n            elif line.startswith(\"- Issue #1797 (partial fix):\"):\n                line = line.replace(\" (partial fix):\", \":\")\n            elif line.startswith(\"- Issue #5828 (Invalid behavior of unicode.lower): Fixed bogus logic in\"):\n                line = line.replace(\" (Invalid behavior of unicode.lower):\", \":\")\n            elif line.startswith(\"- Issue #4512 (part 2): Promote ``ZipImporter._get_filename()`` to be a public\"):\n                line = line.replace(\" (part 2):\", \":\")\n            elif line.startswith(\"- Revert bpo-26293 for zipfile breakage. See also bpo-29094.\"):\n                line = \"- bpo-26293, bpo-29094: Change resulted because of zipfile breakage.\"\n            elif line.startswith(\"- Revert a37cc3d926ec (Issue #5322).\"):\n                line = \"- Issue #5322: Revert a37cc3d926ec.\"\n            elif line.startswith(\"- Patch #1970 by Antoine Pitrou: Speedup unicode whitespace and\"):\n                line = \"- Issue #1970: Speedup unicode whitespace and\"\n            elif line.startswith(\"  linebreak detection\"):\n                line = \"  linebreak detection.  (Patch by Antoine Pitrou.)\"\n            elif line.startswith(\"- Patch #1182394 from Shane Holloway: speed up HMAC.hexdigest.\"):\n                line = \"- Issue #1182394: Speed up ``HMAC.hexdigest``.  (Patch by Shane Holloway.)\"\n            elif line.startswith(\"- Variant of patch #697613: don't exit the interpreter on a SystemExit\"):\n                line = \"- Issue #697613: Don't exit the interpreter on a SystemExit\"\n            elif line.startswith(\"- Bugs #1668596/#1720897: distutils now copies data files even if\"):\n                line = \"- Issue #1668596, #1720897: distutils now copies data files even if\"\n            elif line.startswith(\"- Reverted patch #1504333 to sgmllib because it introduced an infinite\"):\n                line = \"- Issue #1504333: Reverted change to sgmllib because it introduced an infinite\"\n            elif line.startswith(\"- PEP 465 and Issue #21176: Add the '@' operator for matrix multiplication.\"):\n                line = \"- Issue #21176: PEP 465: Add the '@' operator for matrix multiplication.\"\n            elif line.startswith(\"- Issue: #15138: base64.urlsafe_{en,de}code() are now 3-4x faster.\"):\n                line = \"- Issue #15138: base64.urlsafe_{en,de}code() are now 3-4x faster.\"\n            elif line.startswith(\"- Issue #9516: Issue #9516: avoid errors in sysconfig when MACOSX_DEPLOYMENT_TARGET\"):\n                line = \"- Issue #9516 and Issue #9516: avoid errors in sysconfig when MACOSX_DEPLOYMENT_TARGET\"\n            elif line.title().startswith((\"- Request #\", \"- Bug #\", \"- Patch #\", \"- Patches #\")):\n                # print(f(\"FIXING LINE {line_number}: {line!r}\"))\n                line = \"- Issue #\" + line.partition('#')[2]\n                # print(f(\"FIXED LINE {line_number}: {line!r}\"))\n            # else:\n            #     print(f(\"NOT FIXING LINE {line_number}: {line!r}\"))\n\n\n            # 4. determine the actual content of the line\n\n            # 4.1 section declaration\n            if line in sections:\n                flush_blurb()\n                section = line\n                continue\n\n            # 4.2 heading ReST marker\n            if line.startswith((\n                \"===\",\n                \"---\",\n                \"---\",\n                \"+++\",\n                \"Python News\",\n                \"**(For information about older versions, consult the HISTORY file.)**\",\n                )):\n                continue\n\n            # 4.3 version release date declaration\n            if line.startswith(release_date_marker) or (\n                line.startswith(\"*\") and release_date_marker in line):\n                while line.startswith(\"*\"):\n                    line = line[1:]\n                while line.endswith(\"*\"):\n                    line = line[:-1]\n                release_date = line[len(release_date_marker):].strip()\n                continue\n\n            # 4.4 no changes declaration\n            if line.strip() in (\n                '- No changes since release candidate 2',\n                'No changes from release candidate 2.',\n                'There were no code changes between 3.5.3rc1 and 3.5.3 final.',\n                'There were no changes between 3.4.6rc1 and 3.4.6 final.',\n                ):\n                no_changes = True\n                if line.startswith(\"- \"):\n                    line = line[2:]\n                accumulator.append(line)\n                continue\n\n            # 4.5 start of new blurb\n            if line.startswith(\"- \"):\n                flush_blurb()\n                line = line[2:]\n                security = line.startswith(\"[Security]\")\n                if security:\n                    line = line[10:].lstrip()\n\n                if line.startswith(\"Issue\"):\n                    line = line[5:].lstrip()\n                    if line.startswith(\"s\"):\n                        line = line[1:]\n                    line = line.lstrip()\n                    if line.startswith(\"#\"):\n                        line = line[1:].lstrip()\n                    parse_bpo = True\n                elif line.startswith(\"bpo-\"):\n                    line = line[4:]\n                    parse_bpo = True\n                else:\n                    # print(f(\"[[{line_number:8} no bpo]] {line}\"))\n                    parse_bpo = False\n                if parse_bpo:\n                    # GAAAH\n                    if line == \"17500, and https://github.com/python/pythondotorg/issues/945: Remove\":\n                        line = \"Remove\"\n                        bpo = \"17500\"\n                        see_also = \"https://github.com/python/pythondotorg/issues/945\"\n                    else:\n                        bpo, colon, line = line.partition(\":\")\n                        line = line.lstrip()\n                        bpo, comma, see_also = bpo.partition(\",\")\n                        if comma:\n                            see_also = see_also.strip()\n                            # if it's just an integer, add bpo- to the front\n                            try:\n                                int(see_also)\n                                see_also = \"bpo-\" + see_also\n                            except ValueError:\n                                pass\n                        else:\n                            # - Issue #21529 (CVE-2014-4616)\n                            bpo, space_paren, see_also = bpo.partition(\" (\")\n                            if space_paren:\n                                see_also = see_also.rstrip(\")\")\n                            else:\n                                # - Issue #19544 and Issue #1180:\n                                bpo, space_and, see_also = bpo.partition(\" and \")\n                                if not space_and:\n                                    bpo, space_and, see_also = bpo.partition(\" & \")\n                                if space_and:\n                                    see_also = see_also.replace(\"Issue #\", \"bpo-\").strip()\n                                else:\n                                    # - Issue #5258/#10642: if site.py\n                                    bpo, slash, see_also = bpo.partition(\"/\")\n                                    if space_and:\n                                        see_also = see_also.replace(\"#\", \"bpo-\").strip()\n                    try:\n                        int(bpo) # this will throw if it's not a legal int\n                    except ValueError:\n                        sys.exit(f(\"Couldn't convert bpo number to int on line {line_number}! {bpo!r}\"))\n                    if see_also == \"partially\":\n                        sys.exit(f(\"What the hell on line {line_number}! {bpo!r}\"))\n\n            # 4.6.1 continuation of blurb\n            elif line.startswith(\"  \"):\n                line = line[2:]\n            # 4.6.2 continuation of blurb\n            elif line.startswith(\" * \"):\n                line = line[3:]\n            elif line:\n                sys.exit(f(\"Didn't recognize line {line_number}! {line!r}\"))\n            # only add blank lines if we have an initial line in the accumulator\n            if line or accumulator:\n                accumulator.append(line)\n\n    flush_version()\n\n    assert git_add_files\n    flush_git_add_files()\n    git_rm_files.append(\"NEWS\")\n    flush_git_rm_files()\n\n    print(f(\"Wrote {blurb_count} news items across {version_count} versions.\"))\n    print()\n    print(\"Ready for commit.\")", "response": "Split the current Misc and NEWS into zillion little blurb files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse(self, text, *, metadata=None, filename=\"input\"):\n\n        metadata = metadata or {}\n        body = []\n        in_metadata = True\n\n        line_number = None\n\n        def throw(s):\n            raise BlurbError(f(\"Error in {filename}:{line_number}:\\n{s}\"))\n\n        def finish_entry():\n            nonlocal body\n            nonlocal in_metadata\n            nonlocal metadata\n            nonlocal self\n\n            if not body:\n                throw(\"Blurb 'body' text must not be empty!\")\n            text = textwrap_body(body)\n            for naughty_prefix in (\"- \", \"Issue #\", \"bpo-\"):\n                if text.startswith(naughty_prefix):\n                    throw(\"Blurb 'body' can't start with \" + repr(naughty_prefix) + \"!\")\n\n            no_changes = metadata.get('no changes')\n            section = metadata.get('section')\n\n            if not no_changes:\n                if not section:\n                    throw(\"No 'section' specified.  You must provide one!\")\n                elif section not in sections:\n                    throw(\"Invalid 'section'!  You must use one of the predefined sections.\")\n\n            bpo = None\n            try:\n                bpo = int(metadata.get('bpo'))\n            except (TypeError, ValueError):\n                throw(\"Invalid bpo issue number! (\" + repr(bpo) + \")\")\n\n            self.append((metadata, text))\n            metadata = {}\n            body = []\n            in_metadata = True\n\n        for line_number, line in enumerate(text.split(\"\\n\")):\n            line = line.rstrip()\n            if in_metadata:\n                if line.startswith('..'):\n                    line = line[2:].strip()\n                    name, colon, value = line.partition(\":\")\n                    assert colon\n                    name = name.strip()\n                    value = value.strip()\n                    if name in metadata:\n                        throw(\"Blurb metadata sets \" + repr(name) + \" twice!\")\n                    metadata[name] = value\n                    continue\n                if line.startswith(\"#\") or not line:\n                    continue\n                in_metadata = False\n\n            if line == \"..\":\n                finish_entry()\n                continue\n            body.append(line)\n\n        finish_entry()", "response": "Parses a string and appends a list of blurb ENTRIES to self."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef load(self, filename, *, metadata=None):\n        with open(filename, \"rt\", encoding=\"utf-8\") as file:\n            text = file.read()\n        self.parse(text, metadata=metadata, filename=filename)", "response": "Load a single object from a blurb file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a next filename into its equivalent blurb metadata. Returns a dict.", "response": "def _parse_next_filename(filename):\n        \"\"\"\nParses a \"next\" filename into its equivalent blurb metadata.\nReturns a dict.\n        \"\"\"\n        components = filename.split(os.sep)\n        section, filename = components[-2:]\n        section = unsanitize_section(section)\n        assert section in sections, f(\"Unknown section {section}\")\n\n        fields = [x.strip() for x in filename.split(\".\")]\n        assert len(fields) >= 4, f(\"Can't parse 'next' filename! filename {filename!r} fields {fields}\")\n        assert fields[-1] == \"rst\"\n\n        metadata = {\"date\": fields[0], \"nonce\": fields[-2], \"section\": section}\n\n        for field in fields[1:-2]:\n            for name in (\"bpo\",):\n                _, got, value = field.partition(name + \"-\")\n                if got:\n                    metadata[name] = value.strip()\n                    break\n            else:\n                assert False, \"Found unparsable field in 'next' filename: \" + repr(field)\n\n        return metadata"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _extract_next_filename(self):\n        self.ensure_metadata()\n        metadata, body = self[-1]\n        metadata['section'] = sanitize_section(metadata['section'])\n        metadata['root'] = root\n        path = \"{root}/Misc/NEWS.d/next/{section}/{date}.bpo-{bpo}.{nonce}.rst\".format_map(metadata)\n        for name in \"root section date bpo nonce\".split():\n            del metadata[name]\n        return path", "response": "extract next filename from metadata"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef save_split_next(self):\n        filenames = []\n        # the \"date\" MUST have a leading zero.\n        # this ensures these files sort after all\n        # newly created blurbs.\n        width = int(math.ceil(math.log(len(self), 10))) + 1\n        i = 1\n        blurb = Blurbs()\n        while self:\n            metadata, body = self.pop()\n            metadata['date'] = str(i).rjust(width, '0')\n            if 'release date' in metadata:\n                del metadata['release date']\n            blurb.append((metadata, body))\n            filename = blurb._extract_next_filename()\n            blurb.save(filename)\n            blurb.clear()\n            filenames.append(filename)\n            i += 1\n        return filenames", "response": "Save out the next file in the split."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef cherry_pick_cli(\n    ctx, dry_run, pr_remote, abort, status, push, config_path, commit_sha1, branches\n):\n    \"\"\"cherry-pick COMMIT_SHA1 into target BRANCHES.\"\"\"\n\n    click.echo(\"\\U0001F40D \\U0001F352 \\u26CF\")\n\n    chosen_config_path, config = load_config(config_path)\n\n    try:\n        cherry_picker = CherryPicker(\n            pr_remote,\n            commit_sha1,\n            branches,\n            dry_run=dry_run,\n            push=push,\n            config=config,\n            chosen_config_path=chosen_config_path,\n        )\n    except InvalidRepoException:\n        click.echo(f\"You're not inside a {config['repo']} repo right now! \\U0001F645\")\n        sys.exit(-1)\n    except ValueError as exc:\n        ctx.fail(exc)\n\n    if abort is not None:\n        if abort:\n            cherry_picker.abort_cherry_pick()\n        else:\n            cherry_picker.continue_cherry_pick()\n\n    elif status:\n        click.echo(cherry_picker.status())\n    else:\n        try:\n            cherry_picker.backport()\n        except BranchCheckoutException:\n            sys.exit(-1)\n        except CherryPickException:\n            sys.exit(-1)", "response": "Cherry - pick COMMIT_SHA1 into target BRANCHES."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_base_branch(cherry_pick_branch):\n    prefix, sha, base_branch = cherry_pick_branch.split(\"-\", 2)\n\n    if prefix != \"backport\":\n        raise ValueError(\n            'branch name is not prefixed with \"backport-\".  Is this a cherry_picker branch?'\n        )\n\n    if not re.match(\"[0-9a-f]{7,40}\", sha):\n        raise ValueError(f\"branch name has an invalid sha: {sha}\")\n\n    # Validate that the sha refers to a valid commit within the repo\n    # Throws a ValueError if the sha is not present in the repo\n    validate_sha(sha)\n\n    # Subject the parsed base_branch to the same tests as when we generated it\n    # This throws a ValueError if the base_branch doesn't meet our requirements\n    version_from_branch(base_branch)\n\n    return base_branch", "response": "Returns the base branch from the specified branch name."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nvalidates that a hexdigest sha is a valid commit in the repo", "response": "def validate_sha(sha):\n    \"\"\"\n    Validate that a hexdigest sha is a valid commit in the repo\n\n    raises ValueError if the sha does not reference a commit within the repo\n    \"\"\"\n    cmd = [\"git\", \"log\", \"-r\", sha]\n    try:\n        subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n    except subprocess.SubprocessError:\n        raise ValueError(\n            f\"The sha listed in the branch name, {sha}, is not present in the repository\"\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning version information from a git branch name.", "response": "def version_from_branch(branch):\n    \"\"\"\n    return version information from a git branch name\n    \"\"\"\n    try:\n        return tuple(\n            map(\n                int,\n                re.match(r\"^.*(?P<version>\\d+(\\.\\d+)+).*$\", branch)\n                .groupdict()[\"version\"]\n                .split(\".\"),\n            )\n        )\n    except AttributeError as attr_err:\n        raise ValueError(\n            f\"Branch {branch} seems to not have a version in its name.\"\n        ) from attr_err"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_current_branch():\n    cmd = [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"]\n    output = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n    return output.strip().decode(\"utf-8\")", "response": "Return the current branch of the git repository"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a tuple of title and body from the commit message", "response": "def normalize_commit_message(commit_message):\n    \"\"\"\n    Return a tuple of title and body from the commit message\n    \"\"\"\n    split_commit_message = commit_message.split(\"\\n\")\n    title = split_commit_message[0]\n    body = \"\\n\".join(split_commit_message[1:])\n    return title, body.lstrip(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef is_git_repo():\n    cmd = \"git\", \"rev-parse\", \"--git-dir\"\n    try:\n        subprocess.run(cmd, stdout=subprocess.DEVNULL, check=True)\n        return True\n    except subprocess.CalledProcessError:\n        return False", "response": "Check whether the current folder is a Git repo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef find_config(revision):\n    if not is_git_repo():\n        return None\n\n    cfg_path = f\"{revision}:.cherry_picker.toml\"\n    cmd = \"git\", \"cat-file\", \"-t\", cfg_path\n\n    try:\n        output = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n        path_type = output.strip().decode(\"utf-8\")\n        return cfg_path if path_type == \"blob\" else None\n    except subprocess.CalledProcessError:\n        return None", "response": "Locate and return the default config for current revison."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef load_config(path=None):\n    # NOTE: Initially I wanted to inherit Path to encapsulate Git access\n    # there but there's no easy way to subclass pathlib.Path :(\n    head_sha = get_sha1_from(\"HEAD\")\n    revision = head_sha\n    saved_config_path = load_val_from_git_cfg(\"config_path\")\n    if not path and saved_config_path is not None:\n        path = saved_config_path\n\n    if path is None:\n        path = find_config(revision=revision)\n    else:\n        if \":\" not in path:\n            path = f\"{head_sha}:{path}\"\n\n            revision, _col, _path = path.partition(\":\")\n            if not revision:\n                revision = head_sha\n\n    config = DEFAULT_CONFIG\n\n    if path is not None:\n        config_text = from_git_rev_read(path)\n        d = toml.loads(config_text)\n        config = config.new_child(d)\n\n    return path, config", "response": "Choose and return the config path and it s contents as dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_cfg_vals_to_git_cfg(**cfg_map):\n    for cfg_key_suffix, cfg_val in cfg_map.items():\n        cfg_key = f'cherry-picker.{cfg_key_suffix.replace(\"_\", \"-\")}'\n        cmd = \"git\", \"config\", \"--local\", cfg_key, cfg_val\n        subprocess.check_call(cmd, stderr=subprocess.STDOUT)", "response": "Save a set of options into Git config."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wipe_cfg_vals_from_git_cfg(*cfg_opts):\n    for cfg_key_suffix in cfg_opts:\n        cfg_key = f'cherry-picker.{cfg_key_suffix.replace(\"_\", \"-\")}'\n        cmd = \"git\", \"config\", \"--local\", \"--unset-all\", cfg_key\n        subprocess.check_call(cmd, stderr=subprocess.STDOUT)", "response": "Remove a set of options from Git config."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve one option from Git config.", "response": "def load_val_from_git_cfg(cfg_key_suffix):\n    \"\"\"Retrieve one option from Git config.\"\"\"\n    cfg_key = f'cherry-picker.{cfg_key_suffix.replace(\"_\", \"-\")}'\n    cmd = \"git\", \"config\", \"--local\", \"--get\", cfg_key\n    try:\n        return (\n            subprocess.check_output(cmd, stderr=subprocess.DEVNULL)\n            .strip()\n            .decode(\"utf-8\")\n        )\n    except subprocess.CalledProcessError:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_git_rev_read(path):\n    if \":\" not in path:\n        raise ValueError(\"Path identifier must start with a revision hash.\")\n\n    cmd = \"git\", \"show\", \"-t\", path\n    try:\n        return subprocess.check_output(cmd).rstrip().decode(\"utf-8\")\n    except subprocess.CalledProcessError:\n        raise ValueError", "response": "Retrieve given file path contents of certain Git revision."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsaves paused state into Git config.", "response": "def set_paused_state(self):\n        \"\"\"Save paused progress state into Git config.\"\"\"\n        if self.chosen_config_path is not None:\n            save_cfg_vals_to_git_cfg(config_path=self.chosen_config_path)\n        set_state(WORKFLOW_STATES.BACKPORT_PAUSED)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the remote name to use for upstream branches", "response": "def upstream(self):\n        \"\"\"Get the remote name to use for upstream branches\n        Uses \"upstream\" if it exists, \"origin\" otherwise\n        \"\"\"\n        cmd = [\"git\", \"remote\", \"get-url\", \"upstream\"]\n        try:\n            subprocess.check_output(cmd, stderr=subprocess.DEVNULL)\n        except subprocess.CalledProcessError:\n            return \"origin\"\n        return \"upstream\""}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef checkout_branch(self, branch_name):\n        cmd = [\n            \"git\",\n            \"checkout\",\n            \"-b\",\n            self.get_cherry_pick_branch(branch_name),\n            f\"{self.upstream}/{branch_name}\",\n        ]\n        try:\n            self.run_cmd(cmd)\n        except subprocess.CalledProcessError as err:\n            click.echo(\n                f\"Error checking out the branch {self.get_cherry_pick_branch(branch_name)}.\"\n            )\n            click.echo(err.output)\n            raise BranchCheckoutException(\n                f\"Error checking out the branch {self.get_cherry_pick_branch(branch_name)}.\"\n            )", "response": "git checkout -b <branch_name>"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the commit message for the current commit hash", "response": "def get_commit_message(self, commit_sha):\n        \"\"\"\n        Return the commit message for the current commit hash,\n        replace #<PRID> with GH-<PRID>\n        \"\"\"\n        cmd = [\"git\", \"show\", \"-s\", \"--format=%B\", commit_sha]\n        output = subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n        message = output.strip().decode(\"utf-8\")\n        if self.config[\"fix_commit_msg\"]:\n            return message.replace(\"#\", \"GH-\")\n        else:\n            return message"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\namend the commit message with X. Y", "response": "def amend_commit_message(self, cherry_pick_branch):\n        \"\"\" prefix the commit message with (X.Y) \"\"\"\n\n        commit_prefix = \"\"\n        if self.prefix_commit:\n            commit_prefix = f\"[{get_base_branch(cherry_pick_branch)}] \"\n        updated_commit_message = f\"\"\"{commit_prefix}{self.get_commit_message(self.commit_sha1)}\n(cherry picked from commit {self.commit_sha1})\n\n\nCo-authored-by: {get_author_info_from_short_sha(self.commit_sha1)}\"\"\"\n        if self.dry_run:\n            click.echo(f\"  dry-run: git commit --amend -m '{updated_commit_message}'\")\n        else:\n            cmd = [\"git\", \"commit\", \"--amend\", \"-m\", updated_commit_message]\n            try:\n                subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n            except subprocess.CalledProcessError as cpe:\n                click.echo(\"Failed to amend the commit message \\u2639\")\n                click.echo(cpe.output)\n        return updated_commit_message"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef push_to_remote(self, base_branch, head_branch, commit_message=\"\"):\n        set_state(WORKFLOW_STATES.PUSHING_TO_REMOTE)\n\n        cmd = [\"git\", \"push\", self.pr_remote, f\"{head_branch}:{head_branch}\"]\n        try:\n            self.run_cmd(cmd)\n            set_state(WORKFLOW_STATES.PUSHED_TO_REMOTE)\n        except subprocess.CalledProcessError:\n            click.echo(f\"Failed to push to {self.pr_remote} \\u2639\")\n            set_state(WORKFLOW_STATES.PUSHING_TO_REMOTE_FAILED)\n        else:\n            gh_auth = os.getenv(\"GH_AUTH\")\n            if gh_auth:\n                set_state(WORKFLOW_STATES.PR_CREATING)\n                self.create_gh_pr(\n                    base_branch,\n                    head_branch,\n                    commit_message=commit_message,\n                    gh_auth=gh_auth,\n                )\n            else:\n                set_state(WORKFLOW_STATES.PR_OPENING)\n                self.open_pr(self.get_pr_url(base_branch, head_branch))", "response": "Pushes the current branch to the remote."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_gh_pr(self, base_branch, head_branch, *, commit_message, gh_auth):\n        request_headers = sansio.create_headers(self.username, oauth_token=gh_auth)\n        title, body = normalize_commit_message(commit_message)\n        if not self.prefix_commit:\n            title = f\"[{base_branch}] {title}\"\n        data = {\n            \"title\": title,\n            \"body\": body,\n            \"head\": f\"{self.username}:{head_branch}\",\n            \"base\": base_branch,\n            \"maintainer_can_modify\": True,\n        }\n        url = CREATE_PR_URL_TEMPLATE.format(config=self.config)\n        response = requests.post(url, headers=request_headers, json=data)\n        if response.status_code == requests.codes.created:\n            click.echo(f\"Backport PR created at {response.json()['html_url']}\")\n        else:\n            click.echo(response.status_code)\n            click.echo(response.text)", "response": "Create a new PR in GitHub."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef open_pr(self, url):\n        if self.dry_run:\n            click.echo(f\"  dry-run: Create new PR: {url}\")\n        else:\n            click.echo(\"Backport PR URL:\")\n            click.echo(url)\n            webbrowser.open_new_tab(url)", "response": "Open url in the web browser"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the temporary backport branch. Switch to the default branch before that.", "response": "def cleanup_branch(self, branch):\n        \"\"\"Remove the temporary backport branch.\n\n        Switch to the default branch before that.\n        \"\"\"\n        set_state(WORKFLOW_STATES.REMOVING_BACKPORT_BRANCH)\n        self.checkout_default_branch()\n        try:\n            self.delete_branch(branch)\n        except subprocess.CalledProcessError:\n            click.echo(f\"branch {branch} NOT deleted.\")\n            set_state(WORKFLOW_STATES.REMOVING_BACKPORT_BRANCH_FAILED)\n        else:\n            click.echo(f\"branch {branch} has been deleted.\")\n            set_state(WORKFLOW_STATES.REMOVED_BACKPORT_BRANCH)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef abort_cherry_pick(self):\n        if self.initial_state != WORKFLOW_STATES.BACKPORT_PAUSED:\n            raise ValueError(\"One can only abort a paused process.\")\n\n        cmd = [\"git\", \"cherry-pick\", \"--abort\"]\n        try:\n            set_state(WORKFLOW_STATES.ABORTING)\n            self.run_cmd(cmd)\n            set_state(WORKFLOW_STATES.ABORTED)\n        except subprocess.CalledProcessError as cpe:\n            click.echo(cpe.output)\n            set_state(WORKFLOW_STATES.ABORTING_FAILED)\n        # only delete backport branch created by cherry_picker.py\n        if get_current_branch().startswith(\"backport-\"):\n            self.cleanup_branch(get_current_branch())\n\n        reset_stored_config_ref()\n        reset_state()", "response": "Abort the current cherry - pick branch and clean up the branch."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef continue_cherry_pick(self):\n        if self.initial_state != WORKFLOW_STATES.BACKPORT_PAUSED:\n            raise ValueError(\"One can only continue a paused process.\")\n\n        cherry_pick_branch = get_current_branch()\n        if cherry_pick_branch.startswith(\"backport-\"):\n            set_state(WORKFLOW_STATES.CONTINUATION_STARTED)\n            # amend the commit message, prefix with [X.Y]\n            base = get_base_branch(cherry_pick_branch)\n            short_sha = cherry_pick_branch[\n                cherry_pick_branch.index(\"-\") + 1 : cherry_pick_branch.index(base) - 1\n            ]\n            full_sha = get_full_sha_from_short(short_sha)\n            commit_message = self.get_commit_message(short_sha)\n            co_author_info = (\n                f\"Co-authored-by: {get_author_info_from_short_sha(short_sha)}\"\n            )\n            updated_commit_message = f\"\"\"[{base}] {commit_message}.\n(cherry picked from commit {full_sha})\n\n\n{co_author_info}\"\"\"\n            if self.dry_run:\n                click.echo(\n                    f\"  dry-run: git commit -a -m '{updated_commit_message}' --allow-empty\"\n                )\n            else:\n                cmd = [\n                    \"git\",\n                    \"commit\",\n                    \"-a\",\n                    \"-m\",\n                    updated_commit_message,\n                    \"--allow-empty\",\n                ]\n                subprocess.check_output(cmd, stderr=subprocess.STDOUT)\n\n            self.push_to_remote(base, cherry_pick_branch)\n\n            self.cleanup_branch(cherry_pick_branch)\n\n            click.echo(\"\\nBackport PR:\\n\")\n            click.echo(updated_commit_message)\n            set_state(WORKFLOW_STATES.BACKPORTING_CONTINUATION_SUCCEED)\n\n        else:\n            click.echo(\n                f\"Current branch ({cherry_pick_branch}) is not a backport branch.  Will not continue. \\U0001F61B\"\n            )\n            set_state(WORKFLOW_STATES.CONTINUATION_FAILED)\n\n        reset_stored_config_ref()\n        reset_state()", "response": "Continue the cherry pick process."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the run progress state stored in the Git config. Raises ValueError if the state is not in the allowed state.", "response": "def get_state_and_verify(self):\n        \"\"\"Return the run progress state stored in the Git config.\n\n        Raises ValueError if the retrieved state is not of a form that\n                          cherry_picker would have stored in the config.\n        \"\"\"\n        try:\n            state = get_state()\n        except KeyError as ke:\n\n            class state:\n                name = str(ke.args[0])\n\n        if state not in self.ALLOWED_STATES:\n            raise ValueError(\n                f\"Run state cherry-picker.state={state.name} in Git config \"\n                \"is not known.\\nPerhaps it has been set by a newer \"\n                \"version of cherry-picker. Try upgrading.\\n\"\n                \"Valid states are: \"\n                f'{\", \".join(s.name for s in self.ALLOWED_STATES)}. '\n                \"If this looks suspicious, raise an issue at \"\n                \"https://github.com/python/core-workflow/issues/new.\\n\"\n                \"As the last resort you can reset the runtime state \"\n                \"stored in Git config using the following command: \"\n                \"`git config --local --remove-section cherry-picker`\"\n            )\n        return state"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef openDatFile(datpath):\n    '''\n    Open a file-like object using a pkg relative path.\n\n    Example:\n\n        fd = openDatFile('foopkg.barpkg/wootwoot.bin')\n    '''\n    pkgname, filename = datpath.split('/', 1)\n\n    pkgmod = s_dyndeps.getDynMod(pkgname)\n\n    # are we a regular file?\n    pkgfile = os.path.abspath(pkgmod.__file__)\n    if os.path.isfile(pkgfile):\n        dirname = os.path.dirname(pkgfile)\n        datname = os.path.join(dirname, filename)\n        return open(datname, 'rb')", "response": "Open a file - like object using a pkg relative path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scrape(text, ptype=None):\n    '''\n    Scrape types from a blob of text and return node tuples.\n\n    Args:\n        text (str): Text to scrape.\n        ptype (str): Optional ptype to scrape. If present, only scrape rules which match the provided type.\n\n    Returns:\n        (str, str): Yield tuples of type, valu strings.\n    '''\n\n    for ruletype, rule, info in scrape_types:\n        if ptype and ptype != ruletype:\n            continue\n        regx = regexes.get(ruletype)\n        for valu in regx.findall(text):\n            yield (ruletype, valu)", "response": "Scrape types from a blob of text and return node tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef en(item):\n    '''\n    Use msgpack to serialize a compatible python object.\n\n    Args:\n        item (obj): The object to serialize\n\n    Notes:\n        String objects are encoded using utf8 encoding.  In order to handle\n        potentially malformed input, ``unicode_errors='surrogatepass'`` is set\n        to allow encoding bad input strings.\n\n    Returns:\n        bytes: The serialized bytes in msgpack format.\n    '''\n    if pakr is None:  # pragma: no cover\n        return msgpack.packb(item, use_bin_type=True, unicode_errors='surrogatepass')\n    try:\n        return pakr.pack(item)\n    except Exception:\n        pakr.reset()\n        raise", "response": "Serialize a compatible python object into a byte string."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef un(byts):\n    '''\n    Use msgpack to de-serialize a python object.\n\n    Args:\n        byts (bytes): The bytes to de-serialize\n\n    Notes:\n        String objects are decoded using utf8 encoding.  In order to handle\n        potentially malformed input, ``unicode_errors='surrogatepass'`` is set\n        to allow decoding bad input strings.\n\n    Returns:\n        obj: The de-serialized object\n    '''\n    # This uses a subset of unpacker_kwargs\n    return msgpack.loads(byts, use_list=False, raw=False, unicode_errors='surrogatepass')", "response": "Use msgpack to de - serialize a python object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iterfd(fd):\n    '''\n    Generator which unpacks a file object of msgpacked content.\n\n    Args:\n        fd: File object to consume data from.\n\n    Notes:\n        String objects are decoded using utf8 encoding.  In order to handle\n        potentially malformed input, ``unicode_errors='surrogatepass'`` is set\n        to allow decoding bad input strings.\n\n    Yields:\n        Objects from a msgpack stream.\n    '''\n    unpk = msgpack.Unpacker(fd, **unpacker_kwargs)\n    for mesg in unpk:\n        yield mesg", "response": "Generator which unpacks a file object of msgpacked content."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef iterfile(path, since=-1):\n    '''\n    Generator which yields msgpack objects from a file path.\n\n    Args:\n        path: File path to open and consume data from.\n\n    Notes:\n        String objects are decoded using utf8 encoding.  In order to handle\n        potentially malformed input, ``unicode_errors='surrogatepass'`` is set\n        to allow decoding bad input strings.\n\n    Yields:\n        Objects from a msgpack stream.\n    '''\n    with io.open(path, 'rb') as fd:\n\n        unpk = msgpack.Unpacker(fd, **unpacker_kwargs)\n\n        for i, mesg in enumerate(unpk):\n            if i <= since:\n                continue\n\n            yield mesg", "response": "Generator which yields msgpack objects from a file path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef dumpfile(item, path):\n    '''\n    Dump an object to a file by path.\n\n    Args:\n        item (object): The object to serialize.\n        path (str): The file path to save.\n\n    Returns:\n        None\n    '''\n    with io.open(path, 'wb') as fd:\n        fd.write(en(item))", "response": "Dump an object to a file by path."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef feed(self, byts):\n        '''\n        Feed bytes to the unpacker and return completed objects.\n\n        Args:\n            byts (bytes): Bytes to unpack.\n\n        Notes:\n            It is intended that this function is called multiple times with\n            bytes from some sort of a stream, as it will unpack and return\n            objects as they are available.\n\n        Returns:\n            list: List of tuples containing the item size and the unpacked item.\n        '''\n        self.unpk.feed(byts)\n\n        retn = []\n\n        while True:\n\n            try:\n                item = self.unpk.unpack()\n                tell = self.unpk.tell()\n                retn.append((tell - self.size, item))\n                self.size = tell\n\n            except msgpack.exceptions.OutOfData:\n                break\n\n        return retn", "response": "Feeds the given bytes to the unpacker and returns completed objects."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _onCoreModuleLoad(self, event):\n        '''\n        Clear the cached model rows and rebuild them only if they have been loaded already.\n        '''\n        if not self._modelRuntsByBuid:\n            return\n        # Discard previously cached data. It will be computed upon the next\n        # lift that needs it.\n        self._modelRuntsByBuid = {}\n        self._modelRuntsByPropValu = collections.defaultdict(list)", "response": "Called when the core module is loaded."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef encodeMsg(self, mesg):\n        '''Get byts for a message'''\n\n        fmt = self.locs.get('log:fmt')\n        if fmt == 'jsonl':\n            s = json.dumps(mesg, sort_keys=True) + '\\n'\n            buf = s.encode()\n            return buf\n\n        elif fmt == 'mpk':\n            buf = s_msgpack.en(mesg)\n            return buf\n\n        mesg = f'Unknown encoding format: {fmt}'\n        raise s_exc.SynErr(mesg=mesg)", "response": "Get byts for a message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef imeicsum(text):\n    '''\n    Calculate the imei check byte.\n    '''\n    digs = []\n    for i in range(14):\n\n        v = int(text[i])\n        if i % 2:\n            v *= 2\n\n        [digs.append(int(x)) for x in str(v)]\n\n    chek = 0\n    valu = sum(digs)\n    remd = valu % 10\n    if remd != 0:\n        chek = 10 - remd\n\n    return str(chek)", "response": "Calculate the imei check byte."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nexecuting a function in an executor thread.", "response": "async def executor(func, *args, **kwargs):\n    '''\n    Execute a function in an executor thread.\n\n    Args:\n        todo ((func,args,kwargs)): A todo tuple.\n    '''\n    def syncfunc():\n        return func(*args, **kwargs)\n\n    loop = asyncio.get_running_loop()\n    return await loop.run_in_executor(None, syncfunc)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dict of all task - local variables that are set for testing purposes", "response": "def varinit(task=None):\n    '''\n    Initializes (or re-initializes for testing purposes) all of a task's task-local variables\n\n    Precondition:\n        If task is None, this must be called from task context\n    '''\n    if task is None:\n        task = asyncio.current_task()\n    taskvars = {}\n    task._syn_taskvars = taskvars\n    return taskvars"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary of the task s variables.", "response": "def _taskdict(task):\n    '''\n    Note: No locking is provided.  Under normal circumstances, like the other task is not running (e.g. this is running\n    from the same event loop as the task) or task is the current task, this is fine.\n    '''\n    if task is None:\n        task = asyncio.current_task()\n\n    assert task\n    taskvars = getattr(task, '_syn_taskvars', None)\n\n    if taskvars is None:\n        taskvars = varinit(task)\n\n    return taskvars"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef varget(name, defval=None, task=None):\n    '''\n    Access a task local variable by name\n\n    Precondition:\n        If task is None, this must be called from task context\n    '''\n    taskdict = _taskdict(task)\n    retn = taskdict.get(name, s_common.NoValu)\n    if retn is not s_common.NoValu:\n        return retn\n\n    func = _TaskDictCtors.get(name)\n    if func is None:\n        return defval\n\n    item = func()\n    taskdict[name] = item\n\n    return item", "response": "Access a task local variable by name"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the best - match info for a given phone number.", "response": "def getPhoneInfo(numb):\n    '''\n    Walk the phone info tree to find the best-match info for the given number.\n\n    Example:\n\n        info = getPhoneInfo(17035551212)\n        country = info.get('cc')\n\n    '''\n    text = str(numb)\n\n    info = {}\n    node = phonetree\n\n    # make decisions down the tree (but only keep info for\n    # nodes where it's populated) and return the last info\n    for c in text:\n        chld = node[2].get(c)\n        if chld is None:\n            break\n\n        if chld[1]:\n            info = chld[1]\n\n        node = chld\n\n    return info"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def dict(self, full):\n        '''\n        Open a HiveDict at the given full path.\n        '''\n        node = await self.open(full)\n        return await HiveDict.anit(self, node)", "response": "Open a HiveDict at the given full path."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _loadNodeValu(self, full, valu):\n        '''\n        Load a node from storage into the tree.\n        ( used by initialization routines to build the tree)\n        '''\n        node = self.root\n        for path in iterpath(full):\n\n            name = path[-1]\n\n            step = node.kids.get(name)\n            if step is None:\n                step = await self._initNodePath(node, path, None)\n\n            node = step\n\n        node.valu = valu\n        return node", "response": "Load a node from storage into the tree."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def add(self, full, valu):\n        '''\n        Atomically increments a node's value.\n        '''\n        node = await self.open(full)\n\n        oldv = node.valu\n        newv = oldv + valu\n\n        node.valu = await self.storNodeValu(full, node.valu + valu)\n\n        await node.fire('hive:set', path=full, valu=valu, oldv=oldv)\n\n        return newv", "response": "Atomically increments a node s value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove and return the value for the given node.", "response": "async def pop(self, full):\n        '''\n        Remove and return the value for the given node.\n        '''\n        node = self.nodes.get(full)\n        if node is None:\n            return\n\n        valu = await self._popHiveNode(node)\n\n        return valu"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds the structured data from items to the CryoTank.", "response": "async def puts(self, items, seqn=None):\n        '''\n        Add the structured data from items to the CryoTank.\n\n        Args:\n            items (list):  A list of objects to store in the CryoTank.\n            seqn (iden, offs): An iden / offset pair to record.\n\n        Returns:\n            int: The ending offset of the items or seqn.\n        '''\n        size = 0\n\n        for chunk in s_common.chunks(items, 1000):\n            metrics = self._items.save(chunk)\n            self._metrics.add(metrics)\n            await self.fire('cryotank:puts', numrecords=len(chunk))\n            size += len(chunk)\n            await asyncio.sleep(0)\n\n        if seqn is not None:\n            iden, offs = seqn\n            self.setOffset(iden, offs + size)\n\n        return size"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding the metrics rows starting at offset.", "response": "async def metrics(self, offs, size=None):\n        '''\n        Yield metrics rows starting at offset.\n\n        Args:\n            offs (int): The index offset.\n            size (int): The maximum number of records to yield.\n\n        Yields:\n            ((int, dict)): An index offset, info tuple for metrics.\n        '''\n        for i, (indx, item) in enumerate(self._metrics.iter(offs)):\n\n            if size is not None and i >= size:\n                return\n\n            yield indx, item"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield a number of items from the CryoTank starting at a given offset.", "response": "async def slice(self, offs, size=None, iden=None):\n        '''\n        Yield a number of items from the CryoTank starting at a given offset.\n\n        Args:\n            offs (int): The index of the desired datum (starts at 0)\n            size (int): The max number of items to yield.\n\n        Yields:\n            ((index, object)): Index and item values.\n        '''\n        if iden is not None:\n            self.setOffset(iden, offs)\n\n        for i, (indx, item) in enumerate(self._items.iter(offs)):\n\n            if size is not None and i >= size:\n                return\n\n            yield indx, item"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nyield a number of raw items from the CryoTank starting at a given offset.", "response": "async def rows(self, offs, size=None, iden=None):\n        '''\n        Yield a number of raw items from the CryoTank starting at a given offset.\n\n        Args:\n            offs (int): The index of the desired datum (starts at 0)\n            size (int): The max number of items to yield.\n\n        Yields:\n            ((indx, bytes)): Index and msgpacked bytes.\n        '''\n        if iden is not None:\n            self.setOffset(iden, offs)\n\n        for i, (indx, byts) in enumerate(self._items.rows(offs)):\n\n            if size is not None and i >= size:\n                return\n\n            yield indx, byts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning information about the CryoTank instance.", "response": "async def info(self):\n        '''\n        Returns information about the CryoTank instance.\n\n        Returns:\n            dict: A dict containing items and metrics indexes.\n        '''\n        stat = self._items.stat()\n        return {'indx': self._items.index(), 'metrics': self._metrics.index(), 'stat': stat}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ngenerate a new CryoTank with a given name or get an existing CryoTank instance.", "response": "async def init(self, name, conf=None):\n        '''\n        Generate a new CryoTank with a given name or get an reference to an existing CryoTank.\n\n        Args:\n            name (str): Name of the CryoTank.\n\n        Returns:\n            CryoTank: A CryoTank instance.\n        '''\n        tank = self.tanks.get(name)\n        if tank is not None:\n            return tank\n\n        iden = s_common.guid()\n\n        logger.info('Creating new tank: %s', name)\n\n        path = s_common.genpath(self.dirn, 'tanks', iden)\n\n        tank = await CryoTank.anit(path, conf)\n\n        node = await self.names.open((name,))\n        await node.set((iden, conf))\n\n        self.tanks.put(name, tank)\n\n        return tank"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nexit the current process.", "response": "def exit(self, status=0, message=None):\n        '''\n        Argparse expects exit() to be a terminal function and not return.\n        As such, this function must raise an exception which will be caught\n        by Cmd.hasValidOpts.\n        '''\n        self.exited = True\n        if message is not None:\n            self.mesgs.extend(message.split('\\n'))\n        raise s_exc.BadSyntax(mesg=message, prog=self.prog, status=status)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprint a message to the log.", "response": "def _print_message(self, text, fd=None):\n        '''\n        Note:  this overrides an existing method in ArgumentParser\n        '''\n        # Since we have the async->sync->async problem, queue up and print at exit\n        self.root.mesgs.extend(text.split('\\n'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef hashitem(item):\n    '''\n    Generate a uniq hash for the JSON compatible primitive data structure.\n    '''\n    norm = normitem(item)\n    byts = s_msgpack.en(norm)\n    return hashlib.md5(byts).hexdigest()", "response": "Generate a uniq hash for the JSON compatible primitive data structure."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getVolInfo(*paths):\n    '''\n    Retrieve volume usage info for the given path.\n    '''\n    path = os.path.join(*paths)\n    path = os.path.expanduser(path)\n\n    st = os.statvfs(path)\n\n    free = st.f_bavail * st.f_frsize\n    total = st.f_blocks * st.f_frsize\n\n    return {\n        'free': free,\n        'used': total - free,\n        'total': total,\n    }", "response": "Retrieve volume usage info for the given paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nom(txt, off, cset, trim=True):\n    '''\n    Consume chars in set from the string and return (subtxt,offset).\n\n    Example:\n\n        text = \"foo(bar)\"\n        chars = set('abcdefghijklmnopqrstuvwxyz')\n\n        name,off = nom(text,0,chars)\n\n    '''\n    if trim:\n        while len(txt) > off and txt[off] in whites:\n            off += 1\n\n    r = ''\n    while len(txt) > off and txt[off] in cset:\n        r += txt[off]\n        off += 1\n\n    if trim:\n        while len(txt) > off and txt[off] in whites:\n            off += 1\n\n    return r, off", "response": "Consume chars in set from the string and return the nominal version of the object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a list from a command line input.", "response": "def parse_list(text, off=0, trim=True):\n    '''\n    Parse a list (likely for comp type) coming from a command line input.\n\n    The string elements within the list may optionally be quoted.\n    '''\n\n    if not nextchar(text, off, '('):\n        raise s_exc.BadSyntax(at=off, mesg='expected open paren for list')\n\n    off += 1\n\n    valus = []\n    while off < len(text):\n\n        _, off = nom(text, off, whites)\n\n        valu, off = parse_valu(text, off)\n\n        _, off = nom(text, off, whites)\n\n        # check for foo=bar kw tuple syntax\n        if nextchar(text, off, '='):\n\n            _, off = nom(text, off + 1, whites)\n\n            vval, off = parse_valu(text, off)\n\n            _, off = nom(text, off, whites)\n\n            valu = (valu, vval)\n\n        valus.append(valu)\n\n        _, off = nom_whitespace(text, off)\n\n        if nextchar(text, off, ')'):\n            return valus, off + 1\n\n        if not nextchar(text, off, ','):\n            raise s_exc.BadSyntax(at=off, text=text, mesg='expected comma in list')\n\n        off += 1\n\n    raise s_exc.BadSyntax(at=off, mesg='unexpected and of text during list')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse a command line string.", "response": "def parse_cmd_string(text, off, trim=True):\n    '''\n    Parse in a command line string which may be quoted.\n    '''\n    if trim:\n        _, off = nom(text, off, whites)\n\n    if isquote(text, off):\n        return parse_string(text, off, trim=trim)\n\n    if nextchar(text, off, '('):\n        return parse_list(text, off)\n\n    return meh(text, off, whites)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_valu(text, off=0):\n    '''\n    Special syntax for the right side of equals in a macro\n    '''\n    _, off = nom(text, off, whites)\n\n    if nextchar(text, off, '('):\n        return parse_list(text, off)\n\n    if isquote(text, off):\n        return parse_string(text, off)\n\n    # since it's not quoted, we can assume we are bound by both\n    # white space and storm syntax chars ( ) , =\n    valu, off = meh(text, off, valmeh)\n\n    # for now, give it a shot as an int...  maybe eventually\n    # we'll be able to disable this completely, but for now\n    # lets maintain backward compatibility...\n    try:\n        # NOTE: this is ugly, but faster than parsing the string\n        valu = int(valu, 0)\n    except ValueError:\n        pass\n\n    return valu, off", "response": "Parse a value from a string."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse a foo = bar = valu kwarg into prop valu off", "response": "def parse_cmd_kwarg(text, off=0):\n    '''\n    Parse a foo:bar=<valu> kwarg into (prop,valu),off\n    '''\n    _, off = nom(text, off, whites)\n\n    prop, off = nom(text, off, varset)\n\n    _, off = nom(text, off, whites)\n\n    if not nextchar(text, off, '='):\n        raise s_exc.BadSyntax(expected='= for kwarg ' + prop, at=off)\n\n    _, off = nom(text, off + 1, whites)\n\n    valu, off = parse_cmd_string(text, off)\n    return (prop, valu), off"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_cmd_kwlist(text, off=0):\n    '''\n    Parse a foo:bar=<valu>[,...] kwarg list into (prop,valu),off\n    '''\n    kwlist = []\n\n    _, off = nom(text, off, whites)\n\n    while off < len(text):\n\n        (p, v), off = parse_cmd_kwarg(text, off=off)\n\n        kwlist.append((p, v))\n\n        _, off = nom(text, off, whites)\n        if not nextchar(text, off, ','):\n            break\n\n    _, off = nom(text, off, whites)\n    return kwlist, off", "response": "Parse a foo bar=<valu > kwarg list into a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef stormcmd(self):\n        '''\n        A storm sub-query aware command line splitter.\n        ( not for storm commands, but for commands which may take storm )\n        '''\n        argv = []\n        while self.more():\n            self.ignore(whitespace)\n            if self.nextstr('{'):\n                self.offs += 1\n                start = self.offs\n                self.query()\n                argv.append('{' + self.text[start:self.offs] + '}')\n                self.nextmust('}')\n                continue\n\n            argv.append(self.cmdvalu(until=whitespace))\n        return argv", "response": "A storm sub - query aware command line splitter."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef cmdvalu(self, until=cmdquote):\n        '''\n        Consume and return one command argument, stopping when it hits a character (not in a quotation) in `until`.\n        '''\n        self.ignore(whitespace)\n        if self.nextstr('\"'):\n            return self.quoted()\n        if self.nextstr(\"'\"):\n            return self.singlequoted()\n        return self.noms(until=until)", "response": "Consume and return one command argument starting when it hits a character in a quotation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse an editnodeadd statement", "response": "def editnodeadd(self):\n        '''\n        foo:bar = hehe\n        '''\n\n        self.ignore(whitespace)\n\n        absp = self.absprop()\n\n        self.ignore(whitespace)\n\n        if not self.nextstr('='):\n            self._raiseSyntaxExpects('=')\n\n        self.offs += 1\n\n        self.ignore(whitespace)\n\n        valu = self.valu()\n\n        return s_ast.EditNodeAdd(kids=(absp, valu))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef editpropset(self):\n        '''\n        :foo=10\n        '''\n\n        self.ignore(whitespace)\n\n        if not self.nextstr(':'):\n            self._raiseSyntaxExpects(':')\n\n        relp = self.relprop()\n        self.ignore(whitespace)\n\n        self.nextmust('=')\n\n        self.ignore(whitespace)\n\n        valu = self.valu()\n        return s_ast.EditPropSet(kids=(relp, valu))", "response": "parse an editpropset node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses an edit - attribute - set expression", "response": "def editunivset(self):\n        '''\n        .foo = bar\n        '''\n        self.ignore(whitespace)\n\n        if not self.nextstr('.'):\n            self._raiseSyntaxExpects('.')\n\n        univ = self.univprop()\n        self.ignore(whitespace)\n\n        self.nextmust('=')\n\n        self.ignore(whitespace)\n\n        valu = self.valu()\n        return s_ast.EditPropSet(kids=(univ, valu))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef formpivotin(self):\n        '''\n        <- * / <- prop\n        '''\n\n        self.ignore(whitespace)\n\n        self.nextmust('<-')\n\n        self.ignore(whitespace)\n\n        if self.nextchar() == '*':\n            self.offs += 1\n            return s_ast.PivotIn()\n\n        prop = self.absprop()\n        return s_ast.PivotInFrom(kids=(prop,))", "response": "parse a PivotIn expression"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nparsing the ISO 3166 - 1 1. 1 PivotInFrom expression.", "response": "def formjoinin(self):\n        '''\n        <+- * / <+- prop\n        '''\n\n        self.ignore(whitespace)\n\n        self.nextmust('<+-')\n\n        self.ignore(whitespace)\n\n        if self.nextchar() == '*':\n            self.offs += 1\n            return s_ast.PivotIn(isjoin=True)\n\n        prop = self.absprop()\n        return s_ast.PivotInFrom(kids=(prop,), isjoin=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the next tag and return a form pivot.", "response": "def formpivot(self):\n        '''\n        -> *\n        -> #tag.match\n        -> form:prop\n        -> form\n        '''\n\n        self.ignore(whitespace)\n\n        self.nextmust('->')\n\n        self.ignore(whitespace)\n\n        if self.nextchar() == '#':\n            match = self.tagmatch()\n            return s_ast.PivotToTags(kids=(match,))\n\n        # check for pivot out syntax\n        if self.nextchar() == '*':\n            self.offs += 1\n            return s_ast.PivotOut()\n\n        prop = self.absprop()\n        return s_ast.FormPivot(kids=(prop,))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nignores whitespace as well as comment syntax.", "response": "def ignorespace(self):\n        '''\n        Ignore whitespace as well as comment syntax ``//`` and ``/* ... */``\n        '''\n\n        while True:\n\n            self.ignore(whitespace)\n\n            if self.nextstr('//'):\n                self.noms(until='\\n')\n                continue\n\n            if self.nextstr('/*'):\n                self.expect('*/')\n                continue\n\n            break"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef proppivot(self, prop):\n        '''\n        :foo:bar -> baz:faz\n        '''\n        pval = s_ast.RelPropValue(kids=(prop,))\n\n        self.ignore(whitespace)\n\n        self.nextmust('->')\n\n        self.ignore(whitespace)\n\n        if self.nextchar() == '*':\n            self.offs += 1\n            return s_ast.PropPivotOut(kids=(prop,))\n\n        dest = self.absprop()\n        return s_ast.PropPivot(kids=(pval, dest))", "response": "parse a pivot property"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef propjoin(self, prop):\n        '''\n        :foo:bar -+> baz:faz\n        '''\n        pval = s_ast.RelPropValue(kids=(prop,))\n\n        self.ignore(whitespace)\n\n        self.nextmust('-+>')\n\n        self.ignore(whitespace)\n\n        dest = self.absprop()\n        return s_ast.PropPivot(kids=(pval, dest), isjoin=True)", "response": "Return a new s_ast. PropPivot object with the value of the given property."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses an absolute property.", "response": "def absprop(self):\n        '''\n        foo:bar\n        '''\n        self.ignore(whitespace)\n\n        name = self.noms(varset)\n\n        if not name:\n            mesg = 'Expected a form/prop name.'\n            self._raiseSyntaxError(mesg=mesg)\n\n        if not isPropName(name):\n            self._raiseSyntaxError(f'invalid property: {name!r}')\n\n        return s_ast.AbsProp(name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses relative property name", "response": "def relprop(self):\n        '''\n        :foo:bar\n        '''\n        self.ignore(whitespace)\n\n        self.nextmust(':')\n\n        name = self.noms(varset)\n        if not name:\n            self._raiseSyntaxError('empty relative property name')\n\n        return s_ast.RelProp(name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef univprop(self):\n        '''\n        .foo\n        '''\n        self.ignore(whitespace)\n\n        if not self.nextstr('.'):\n            self._raiseSyntaxError('universal property expected .')\n\n        name = self.noms(varset)\n        if not name:\n            mesg = 'Expected a univeral property name.'\n            self._raiseSyntaxError(mesg=mesg)\n\n        if not isUnivName(name):\n            self._raiseSyntaxError(f'no such universal property: {name!r}')\n\n        return s_ast.UnivProp(name)", "response": "Parse an universal property."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef varvalu(self, varn=None):\n        '''\n        $foo\n        $foo.bar\n        $foo.bar()\n        $foo[0]\n        $foo.bar(10)\n        '''\n\n        self.ignore(whitespace)\n\n        if varn is None:\n            varn = self.varname()\n\n        varv = s_ast.VarValue(kids=[varn])\n\n        # handle derefs and calls...\n        while self.more():\n\n            if self.nextstr('.'):\n                varv = self.varderef(varv)\n                continue\n\n            if self.nextstr('('):\n                varv = self.varcall(varv)\n                continue\n\n            #if self.nextstr('['):\n                #varv = self.varslice(varv)\n\n            break\n\n        return varv", "response": "Parse a varvalue from the current token and return it."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the command line arguments", "response": "def cmdargv(self):\n        '''\n        cmdargv *must* have leading whitespace to prevent\n        foo@bar from becoming cmdname foo with argv=[@bar]\n        '''\n\n        argv = []\n        while self.more():\n\n            # cmdargv *requires* whitespace\n            if not self.ignore(whitespace):\n                break\n\n            # if we hit a | or a } we're done\n            if self.nextstr('|'):\n                break\n\n            if self.nextstr('}'):\n                break\n\n            if not self.nextstr('{'):\n                valu = self.cmdvalu()\n                argv.append(valu)\n                continue\n\n            start = self.offs\n            self.subquery()\n\n            text = self.text[start:self.offs]\n\n            argv.append(text)\n\n        return s_ast.Const(tuple(argv))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse(text, base=None, chop=False):\n    '''\n    Parse a time string into an epoch millis value.\n    '''\n    #TODO: use base to facilitate relative time offsets\n    text = text.strip().lower()\n    text = (''.join([c for c in text if c.isdigit()]))\n\n    if chop:\n        text = text[:17]\n\n    # TODO: support relative time offsets here...\n\n    tlen = len(text)\n    if tlen == 4:\n        dt = datetime.datetime.strptime(text, '%Y')\n\n    elif tlen == 6:\n        dt = datetime.datetime.strptime(text, '%Y%m')\n\n    elif tlen == 8:\n        dt = datetime.datetime.strptime(text, '%Y%m%d')\n\n    elif tlen == 10:\n        dt = datetime.datetime.strptime(text, '%Y%m%d%H')\n\n    elif tlen == 12:\n        dt = datetime.datetime.strptime(text, '%Y%m%d%H%M')\n\n    elif tlen == 14:\n        dt = datetime.datetime.strptime(text, '%Y%m%d%H%M%S')\n\n    elif tlen in (15, 16, 17):\n        dt = datetime.datetime.strptime(text, '%Y%m%d%H%M%S%f')\n\n    else:\n        raise s_exc.BadTypeValu(valu=text, name='time',\n                                mesg='Unknown time format')\n\n    epoch = datetime.datetime(1970, 1, 1)\n    return int((dt - epoch).total_seconds() * 1000)", "response": "Parse a time string into an epoch millis value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef repr(tick, pack=False):\n    '''\n    Return a date string for an epoch-millis timestamp.\n\n    Args:\n        tick (int): The timestamp in milliseconds since the epoch.\n\n    Returns:\n        (str):  A date time string\n    '''\n    if tick == 0x7fffffffffffffff:\n        return '?'\n\n    dt = datetime.datetime(1970, 1, 1) + datetime.timedelta(milliseconds=tick)\n    millis = dt.microsecond / 1000\n    if pack:\n        return '%d%.2d%.2d%.2d%.2d%.2d%.3d' % (dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, millis)\n    return '%d/%.2d/%.2d %.2d:%.2d:%.2d.%.3d' % (dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, millis)", "response": "Return a date string for an epoch - millis timestamp."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses a simple time delta string and return the delta.", "response": "def delta(text):\n    '''\n    Parse a simple time delta string and return the delta.\n    '''\n    text = text.strip().lower()\n\n    _, offs = _noms(text, 0, ' \\t\\r\\n')\n\n    sign = '+'\n    if text and text[0] in ('+', '-'):\n        sign = text[0]\n        offs += 1\n\n    _, offs = _noms(text, offs, ' \\t\\r\\n')\n\n    sizetext, offs = _noms(text, offs, '0123456789')\n\n    _, offs = _noms(text, offs, ' \\t\\r\\n')\n\n    unittext = text[offs:]\n\n    size = int(sizetext, 0)\n\n    if sign == '-':\n        size = -size\n\n    base = timeunits.get(unittext)\n    if base is None:\n        mesg = f'unknown time delta units: {unittext}'\n        raise s_exc.BadTypeValu(name='time', valu=text, mesg=mesg)\n\n    return size * base"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nencrypting the given bytes and returns an envelope dict in msgpack form.", "response": "def enc(self, byts, asscd=None):\n        '''\n        Encrypt the given bytes and return an envelope dict in msgpack form.\n\n        Args:\n            byts (bytes): The message to be encrypted.\n            asscd (bytes): Extra data that needs to be authenticated (but not encrypted).\n\n        Returns:\n            bytes: The encrypted message. This is a msgpacked dictionary\n            containing the IV, ciphertext, and associated data.\n        '''\n        iv = os.urandom(16)\n        encryptor = AESGCM(self.ekey)\n        byts = encryptor.encrypt(iv, byts, asscd)\n        envl = {'iv': iv, 'data': byts, 'asscd': asscd}\n        return s_msgpack.en(envl)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes an envelope dict and decrypt the given bytes.", "response": "def dec(self, byts):\n        '''\n        Decode an envelope dict and decrypt the given bytes.\n\n        Args:\n            byts (bytes): Bytes to decrypt.\n\n        Returns:\n            bytes: Decrypted message.\n        '''\n        envl = s_msgpack.un(byts)\n        iv = envl.get('iv', b'')\n        asscd = envl.get('asscd', b'')\n        data = envl.get('data', b'')\n\n        decryptor = AESGCM(self.ekey)\n\n        try:\n            data = decryptor.decrypt(iv, data, asscd)\n        except Exception:\n            logger.exception('Error decrypting data')\n            return None\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef encrypt(self, mesg):\n        '''\n        Wrap a message with a sequence number and encrypt it.\n\n        Args:\n            mesg: The mesg to encrypt.\n\n        Returns:\n            bytes: The encrypted message.\n        '''\n        seqn = next(self._tx_sn)\n        rv = self._tx_tinh.enc(s_msgpack.en((seqn, mesg)))\n        return rv", "response": "Wrap a message with a sequence number and encrypt it."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef decrypt(self, ciphertext):\n        '''\n        Decrypt a message, validating its sequence number is as we expect.\n\n        Args:\n            ciphertext (bytes): The message to decrypt and verify.\n\n        Returns:\n            mesg: A mesg.\n\n        Raises:\n            s_exc.CryptoErr: If the message decryption fails or the sequence number was unexpected.\n        '''\n\n        plaintext = self._rx_tinh.dec(ciphertext)\n        if plaintext is None:\n            logger.error('Message decryption failure')\n            raise s_exc.CryptoErr(mesg='Message decryption failure')\n\n        seqn = next(self._rx_sn)\n\n        sn, mesg = s_msgpack.un(plaintext)\n        if sn != seqn:\n            logger.error('Message out of sequence: got %d expected %d', sn, seqn)\n            raise s_exc.CryptoErr(mesg='Message out of sequence', expected=seqn, got=sn)\n\n        return mesg", "response": "Decrypt a message validating its sequence number is as we expect."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseSemver(text):\n    '''\n    Parse a Semantic Version string into is component parts.\n\n    Args:\n        text (str): A text string to parse into semver components. This string has whitespace and leading 'v'\n        characters stripped off of it.\n\n    Examples:\n        Parse a string into it semvar parts::\n\n            parts = parseSemver('v1.2.3')\n\n    Returns:\n        dict: The dictionary will contain the keys 'major', 'minor' and 'patch' pointing to integer values.\n        The dictionary may also contain keys for 'build' and 'pre' information if that data is parsed out\n        of a semver string. None is returned if the string is not a valid Semver string.\n    '''\n    # eat whitespace and leading chars common on version strings\n    txt = text.strip().lstrip('vV')\n    ret = {}\n\n    m = semver_re.match(txt)\n    if not m:\n        return None\n    d = m.groupdict()\n    ret['major'] = int(d.get('maj'))\n    ret['minor'] = int(d.get('min'))\n    ret['patch'] = int(d.get('pat'))\n\n    pre = d.get('pre')\n    bld = d.get('bld')\n\n    if pre:\n        # Validate pre\n        parts = pre.split('.')\n        for part in parts:\n            if not part:\n                return None\n            try:\n                int(part)\n            except ValueError:\n                continue\n            else:\n                if part[0] == '0' and len(part) > 1:\n                    return None\n        ret['pre'] = pre\n\n    if bld:\n        # Validate bld\n        parts = bld.split('.')\n        for part in parts:\n            if not part:\n                return None\n        ret['build'] = bld\n\n    return ret", "response": "Parses a string into is component parts."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef packVersion(major, minor=0, patch=0):\n    '''\n    Pack a set of major/minor/patch integers into a single integer for storage.\n\n    Args:\n        major (int): Major version level integer.\n        minor (int): Minor version level integer.\n        patch (int): Patch version level integer.\n\n    Returns:\n        int:  System normalized integer value to represent a software version.\n    '''\n\n    ret = patch & mask20\n    ret = ret | (minor & mask20) << 20\n    ret = ret | (major & mask20) << 20 * 2\n    return ret", "response": "Pack a set of major minor and patch integers into a single integer for storage."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nunpacks a system normalized integer representing a softare version into its component parts.", "response": "def unpackVersion(ver):\n    '''\n    Unpack a system normalized integer representing a softare version into its component parts.\n\n    Args:\n        ver (int): System normalized integer value to unpack into a tuple.\n\n    Returns:\n        (int, int, int): A tuple containing the major, minor and patch values shifted out of the integer.\n    '''\n    major = (ver >> 20 * 2) & mask20\n    minor = (ver >> 20) & mask20\n    patch = ver & mask20\n    return major, minor, patch"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef fmtVersion(*vsnparts):\n    '''\n    Join a string of parts together with a . separator.\n\n    Args:\n        *vsnparts:\n\n    Returns:\n\n    '''\n    if len(vsnparts) < 1:\n        raise s_exc.BadTypeValu(valu=repr(vsnparts), name='fmtVersion',\n                                mesg='Not enough version parts to form a version string with.',)\n    ret = '.'.join([str(part).lower() for part in vsnparts])\n    return ret", "response": "Returns a string of parts together with a. separator."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseVersionParts(text, seps=vseps):\n    '''\n    Extract a list of major/minor/version integer strings from a string.\n\n    Args:\n        text (str): String to parse\n        seps (tuple): A tuple or list of separators to use when parsing the version string.\n\n    Examples:\n        Parse a simple version string into a major and minor parts::\n\n            parts = parseVersionParts('1.2')\n\n        Parse a complex version string into a major and minor parts::\n\n            parts = parseVersionParts('wowsoft_1.2')\n\n        Parse a simple version string into a major, minor and patch parts.  Parts after the \"3.\" are dropped from the\n        results::\n\n            parts = parseVersionParts('1.2.3.4.5')\n\n    Notes:\n        This attempts to brute force out integers from the version string by stripping any leading ascii letters and\n        part separators, and then regexing out numeric parts optionally followed by part separators.  It will stop at\n        the first mixed-character part encountered.  For example, \"1.2-3a\" would only parse out the \"1\" and \"2\" from\n        the string.\n\n    Returns:\n        dict: Either a empty dictionary or dictionary containing up to three keys, 'major', 'minor' and 'patch'.\n    '''\n    # Join seps together\n    seps = ''.join(seps)\n    # Strip whitespace\n    text = text.strip()\n    # Strip off leading chars\n    text = text.lstrip(string.ascii_letters)\n    # Strip off any leading separator which may be present\n    text = text.lstrip(seps)\n    pattern = r'^(\\d+)([{}]+|$)'.format(regex.escape(seps))\n    parts = []\n    ret = {}\n    off = 0\n    while True:\n        m = regex.search(pattern, text[off:])\n        if not m:\n            break\n        off += m.end()\n        p, s = m.groups()\n        parts.append(int(p))\n    if not parts:\n        return None\n    keys = ('major', 'minor', 'patch')\n    ret.update(zip(keys, parts))\n    return ret", "response": "Parses a string containing a list of major minor and patch integers from a version string."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets a name in the SlabDict.", "response": "def set(self, name, valu):\n        '''\n        Set a name in the SlabDict.\n\n        Args:\n            name (str): The key name.\n            valu (obj): A msgpack compatible value.\n\n        Returns:\n            None\n        '''\n        byts = s_msgpack.en(valu)\n        lkey = self.pref + name.encode('utf8')\n        self.slab.put(lkey, byts, db=self.db)\n        self.info[name] = valu"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef pop(self, name, defval=None):\n        '''\n        Pop a name from the SlabDict.\n\n        Args:\n            name (str): The name to remove.\n            defval (obj): The default value to return if the name is not present.\n\n        Returns:\n            object: The object stored in the SlabDict, or defval if the object was not present.\n        '''\n        valu = self.info.pop(name, defval)\n        lkey = self.pref + name.encode('utf8')\n        self.slab.pop(lkey, db=self.db)\n        return valu", "response": "Remove a name from the SlabDict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnote This method may raise a MapFullError", "response": "def _finiCoXact(self):\n        '''\n        Note:\n            This method may raise a MapFullError\n        '''\n\n        assert s_glob.iAmLoop()\n\n        [scan.bump() for scan in self.scans]\n\n        # Readonly or self.xact has already been closed\n        if self.xact is None:\n            return\n\n        self.xact.commit()\n\n        self.xactops.clear()\n\n        del self.xact\n        self.xact = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dropdb(self, name):\n        '''\n        Deletes an **entire database** (i.e. a table), losing all data.\n        '''\n        if self.readonly:\n            raise s_exc.IsReadOnly()\n\n        while True:\n            try:\n                if not self.dbexists(name):\n                    return\n                db = self.initdb(name)\n                self.dirty = True\n                self.xact.drop(db.db, delete=True)\n                self.forcecommit()\n                return\n\n            except lmdb.MapFullError:\n                self._handle_mapfull()", "response": "Drop an entire database."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the last key value pair from the given db.", "response": "def last(self, db=_DefaultDB):\n        '''\n        Return the last key/value pair from the given db.\n        '''\n        self._acqXactForReading()\n        try:\n            with self.xact.cursor(db=db.db) as curs:\n                if not curs.last():\n                    return None\n                return curs.key(), curs.value()\n        finally:\n            self._relXactForReading()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nputs multiple items into a single item.", "response": "def putmulti(self, kvpairs, dupdata=False, append=False, db=_DefaultDB):\n        '''\n        Returns:\n            Tuple of number of items consumed, number of items added\n        '''\n        if self.readonly:\n            raise s_exc.IsReadOnly()\n\n        # Log playback isn't compatible with generators\n        if not isinstance(kvpairs, list):\n            kvpairs = list(kvpairs)\n\n        try:\n            self.dirty = True\n\n            if not self.recovering:\n                self._logXactOper(self.putmulti, kvpairs, dupdata=dupdata, append=append, db=db)\n\n            with self.xact.cursor(db=db.db) as curs:\n                return curs.putmulti(kvpairs, dupdata=dupdata, append=append)\n\n        except lmdb.MapFullError:\n            return self._handle_mapfull()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef copydb(self, sourcedb, destslab, destdbname=None, progresscb=None):\n        '''\n        Copy an entire database in this slab to a new database in potentially another slab.\n\n        Args:\n            sourcedb (LmdbDatabase): which database in this slab to copy rows from\n            destslab (LmdbSlab): which slab to copy rows to\n            destdbname (str): the name of the database to copy rows to in destslab\n            progresscb (Callable[int]):  if not None, this function will be periodically called with the number of rows\n                                         completed\n\n        Returns:\n            (int): the number of rows copied\n\n        Note:\n            If any rows already exist in the target database, this method returns an error.  This means that one cannot\n            use destdbname=None unless there are no explicit databases in the destination slab.\n        '''\n        destdb = destslab.initdb(destdbname, sourcedb.dupsort)\n\n        statdict = destslab.stat(db=destdb)\n        if statdict['entries'] > 0:\n            raise s_exc.DataAlreadyExists()\n\n        rowcount = 0\n\n        for chunk in s_common.chunks(self.scanByFull(db=sourcedb), COPY_CHUNKSIZE):\n            ccount, acount = destslab.putmulti(chunk, dupdata=True, append=True, db=destdb)\n            if ccount != len(chunk) or acount != len(chunk):\n                raise s_exc.BadCoreStore(mesg='Unexpected number of values written')  # pragma: no cover\n\n            rowcount += len(chunk)\n            if progresscb is not None and 0 == (rowcount % PROGRESS_PERIOD):\n                progresscb(rowcount)\n\n        return rowcount", "response": "Copy an entire database in this slab to another slab."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nliking put but returns the previous value if existed", "response": "def replace(self, lkey, lval, db=None):\n        '''\n        Like put, but returns the previous value if existed\n        '''\n        return self._xact_action(self.replace, lmdb.Transaction.replace, lkey, lval, db=db)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef forcecommit(self):\n        '''\n        Note:\n            This method may raise a MapFullError\n        '''\n        if not self.dirty:\n            return False\n\n        # ok... lets commit and re-open\n        self._finiCoXact()\n        self._initCoXact()\n        return True", "response": "Force a commit of the current state of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef hostaddr(dest='8.8.8.8'):\n    '''\n    Retrieve the ipv4 address for this host ( optionally as seen from dest ).\n    Example:\n        addr = s_socket.hostaddr()\n    '''\n    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n\n    # doesn't actually send any packets!\n    sock.connect((dest, 80))\n    addr, port = sock.getsockname()\n\n    sock.close()\n\n    return addr", "response": "Retrieve the ipv4 address for this host optionally as seen from dest."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _match_idens(self, core, prefix):\n        '''\n        Returns the iden that starts with prefix.  Prints out error and returns None if it doesn't match\n        exactly one.\n        '''\n        idens = [iden for iden, trig in await core.listTriggers()]\n        matches = [iden for iden in idens if iden.startswith(prefix)]\n        if len(matches) == 1:\n            return matches[0]\n        elif len(matches) == 0:\n            self.printf('Error: provided iden does not match any valid authorized triggers')\n        else:\n            self.printf('Error: provided iden matches more than one trigger')\n        return None", "response": "Returns the iden that starts with prefix. Prints out error and returns None if it doesn t match exactly one."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef decode(name, byts, **opts):\n    '''\n    Decode the given byts with the named decoder.\n    If name is a comma separated list of decoders,\n    loop through and do them all.\n\n    Example:\n\n        byts = s_encoding.decode('base64',byts)\n\n    Note: Decoder names may also be prefixed with +\n          to *encode* for that name/layer.\n\n    '''\n    for name in name.split(','):\n\n        if name.startswith('+'):\n            byts = encode(name[1:], byts, **opts)\n            continue\n\n        func = decoders.get(name)\n        if func is None:\n            raise s_exc.NoSuchDecoder(name=name)\n\n        byts = func(byts, **opts)\n\n    return byts", "response": "Decode the given byts with the named decoder."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds an additional ingest file format", "response": "def addFormat(name, fn, opts):\n    '''\n    Add an additional ingest file format\n    '''\n    fmtyielders[name] = fn\n    fmtopts[name] = opts"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\niterating through the data provided by a file like object.", "response": "def iterdata(fd, close_fd=True, **opts):\n    '''\n    Iterate through the data provided by a file like object.\n\n    Optional parameters may be used to control how the data\n    is deserialized.\n\n    Examples:\n        The following example show use of the iterdata function.::\n\n            with open('foo.csv','rb') as fd:\n                for row in iterdata(fd, format='csv', encoding='utf8'):\n                    dostuff(row)\n\n    Args:\n        fd (file) : File like object to iterate over.\n        close_fd (bool) : Default behavior is to close the fd object.\n                          If this is not true, the fd will not be closed.\n        **opts (dict): Ingest open directive.  Causes the data in the fd\n                       to be parsed according to the 'format' key and any\n                       additional arguments.\n\n    Yields:\n        An item to process. The type of the item is dependent on the format\n        parameters.\n    '''\n    fmt = opts.get('format', 'lines')\n    fopts = fmtopts.get(fmt, {})\n\n    # set default options for format\n    for opt, val in fopts.items():\n        opts.setdefault(opt, val)\n\n    ncod = opts.get('encoding')\n    if ncod is not None:\n        fd = codecs.getreader(ncod)(fd)\n\n    fmtr = fmtyielders.get(fmt)\n    if fmtr is None:\n        raise s_exc.NoSuchImpl(name=fmt, knowns=fmtyielders.keys())\n\n    for item in fmtr(fd, opts):\n        yield item\n\n    if close_fd:\n        fd.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef migrate_v0_rules(self):\n        '''\n        Remove any v0 (i.e. pre-010) rules from storage and replace them with v1 rules.\n\n        Notes:\n            v0 had two differences user was a username.  Replaced with iden of user as 'iden' field.\n            Also 'iden' was storage as binary.  Now it is stored as hex string.\n        '''\n        for iden, valu in self.core.slab.scanByFull(db=self.trigdb):\n            ruledict = s_msgpack.un(valu)\n            ver = ruledict.get('ver')\n            if ver != 0:\n                continue\n\n            user = ruledict.pop('user')\n            if user is None:\n                logger.warning('Username missing in stored trigger rule %r', iden)\n                continue\n\n            # In v0, stored user was username, in >0 user is useriden\n            user = self.core.auth.getUserByName(user).iden\n            if user is None:\n                logger.warning('Unrecognized username in stored trigger rule %r', iden)\n                continue\n\n            ruledict['ver'] = 1\n            ruledict['useriden'] = user\n            newiden = s_common.ehex(iden)\n            self.core.slab.pop(iden, db=self.trigdb)\n            self.core.slab.put(newiden.encode(), s_msgpack.en(ruledict), db=self.trigdb)", "response": "Migrate any v0 rules from storage to v1 rules."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfolding a list of values into a new interval tuple.", "response": "def fold(*vals):\n    '''\n    Initialize a new (min,max) tuple interval from values.\n\n    Args:\n        *vals ([int,...]):  A list of values (or Nones)\n\n    Returns:\n        ((int,int)):    A (min,max) interval tuple or None\n\n    '''\n    vals = [v for v in vals if v is not None]\n    if not vals:\n        return None\n    return min(vals), max(vals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef overlap(ival0, ival1):\n    '''\n    Determine if two interval tuples have overlap.\n\n    Args:\n        iv0 ((int,int)):    An interval tuple\n        iv1 ((int,int));    An interval tuple\n\n    Returns:\n        (bool): True if the intervals overlap, otherwise False\n\n    '''\n    min0, max0 = ival0\n    min1, max1 = ival1\n    return max(0, min(max0, max1) - max(min0, min1)) > 0", "response": "Determines if two intervals overlap."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nparse an interval time string and return a ( min max ) tuple.", "response": "def parsetime(text):\n    '''\n    Parse an interval time string and return a (min,max) tuple.\n\n    Args:\n        text (str): A time interval string\n\n    Returns:\n        ((int,int)):    A epoch millis epoch time string\n\n    '''\n    mins, maxs = text.split('-', 1)\n    minv = s_time.parse(mins)\n    maxv = s_time.parse(maxs, base=minv)\n    return minv, maxv"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def getTempCortex(mods=None):\n    '''\n    Get a proxy to a cortex backed by a temporary directory.\n\n    Args:\n        mods (list): A list of modules which are loaded into the cortex.\n\n    Notes:\n        The cortex and temporary directory are town down on exit.\n        This should only be called from synchronous code.\n\n    Returns:\n        Proxy to the cortex.\n    '''\n    with s_common.getTempDir() as dirn:\n\n        async with await Cortex.anit(dirn) as core:\n            if mods:\n                for mod in mods:\n                    await core.loadCoreModule(mod)\n            async with core.getLocalProxy() as prox:\n                yield prox", "response": "Get a proxy to a cortex backed by a temporary directory."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the view layers from a list of idens.", "response": "async def setLayers(self, layers):\n        '''\n        Set the view layers from a list of idens.\n        NOTE: view layers are stored \"top down\" ( write is layers[0] )\n        '''\n        layrs = []\n\n        for iden in layers:\n            layr = self.core.layers.get(iden)\n            if layr is None:\n                raise s_exc.NoSuchLayer(iden=iden)\n            if not layrs and layr.readonly:\n                raise s_exc.ReadOnlyLayer(mesg=f'First layer {layr.iden} must not be read-only')\n\n            layrs.append(layr)\n\n        self.borked = None\n        self.layers = layrs\n\n        await self.info.set('layers', layers)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nyield a list of Node. pack tuples which match the query.", "response": "async def getNodesBy(self, full, valu, cmpr='='):\n        '''\n        Yield Node.pack() tuples which match the query.\n        '''\n        async for node in self.cell.getNodesBy(full, valu, cmpr=cmpr):\n            yield node.pack()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a trigger to the cortex", "response": "async def addTrigger(self, condition, query, info):\n        '''\n        Adds a trigger to the cortex\n        '''\n        iden = self.cell.triggers.add(self.user.iden, condition, query, info=info)\n        return iden"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _trig_auth_check(self, useriden):\n        ''' Check that, as a non-admin, may only manipulate resources created by you. '''\n        if not self.user.admin and useriden != self.user.iden:\n            raise s_exc.AuthDeny(user=self.user.name, mesg='As non-admin, may only manipulate triggers created by you')", "response": "Check that as a non - admin may only manipulate resources created by you."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a trigger from the cortex", "response": "async def delTrigger(self, iden):\n        '''\n        Deletes a trigger from the cortex\n        '''\n        trig = self.cell.triggers.get(iden)\n        self._trig_auth_check(trig.get('useriden'))\n        self.cell.triggers.delete(iden)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def updateTrigger(self, iden, query):\n        '''\n        Change an existing trigger's query\n        '''\n        trig = self.cell.triggers.get(iden)\n        self._trig_auth_check(trig.get('useriden'))\n        self.cell.triggers.mod(iden, query)", "response": "Update an existing trigger s query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def listTriggers(self):\n        '''\n        Lists all the triggers that the current user is authorized to access\n        '''\n        trigs = []\n        for (iden, trig) in self.cell.triggers.list():\n            useriden = trig['useriden']\n            if not (self.user.admin or useriden == self.user.iden):\n                continue\n            user = self.cell.auth.user(useriden)\n            trig['username'] = '<unknown>' if user is None else user.name\n            trigs.append((iden, trig))\n\n        return trigs", "response": "Lists all the triggers that the current user is authorized to access."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a cron job to the cortex.", "response": "async def addCronJob(self, query, reqs, incunit=None, incval=1):\n        '''\n        Add a cron job to the cortex\n\n        A cron job is a persistently-stored item that causes storm queries to be run in the future.  The specification\n        for the times that the queries run can be one-shot or recurring.\n\n        Args:\n            query (str):  The storm query to execute in the future\n            reqs (Union[Dict[str, Union[int, List[int]]], List[Dict[...]]]):\n                Either a dict of the fixed time fields or a list of such dicts.  The keys are in the set ('year',\n                'month', 'dayofmonth', 'dayofweek', 'hour', 'minute'.  The values must be positive integers, except for\n                the key of 'dayofmonth' in which it may also be a negative integer which represents the number of days\n                from the end of the month with -1 representing the last day of the month.  All values may also be lists\n                of valid values.\n            incunit (Optional[str]):\n                A member of the same set as above, with an additional member 'day'.  If is None (default), then the\n                appointment is one-shot and will not recur.\n            incval (Union[int, List[int]):\n                A integer or a list of integers of the number of units\n\n        Returns (bytes):\n            An iden that can be used to later modify, query, and delete the job.\n\n        Notes:\n            reqs must have fields present or incunit must not be None (or both)\n            The incunit if not None it must be larger in unit size than all the keys in all reqs elements.\n        '''\n\n        def _convert_reqdict(reqdict):\n            return {s_agenda.TimeUnit.fromString(k): v for (k, v) in reqdict.items()}\n\n        try:\n            if incunit is not None:\n                if isinstance(incunit, (list, tuple)):\n                    incunit = [s_agenda.TimeUnit.fromString(i) for i in incunit]\n                else:\n                    incunit = s_agenda.TimeUnit.fromString(incunit)\n            if isinstance(reqs, Mapping):\n                newreqs = _convert_reqdict(reqs)\n            else:\n                newreqs = [_convert_reqdict(req) for req in reqs]\n\n        except KeyError:\n            raise s_exc.BadConfValu('Unrecognized time unit')\n\n        return await self.cell.agenda.add(self.user.iden, query, newreqs, incunit, incval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a cron job with the given iden.", "response": "async def delCronJob(self, iden):\n        '''\n        Delete a cron job\n\n        Args:\n            iden (bytes):  The iden of the cron job to be deleted\n        '''\n        cron = self.cell.agenda.appts.get(iden)\n        if cron is None:\n            raise s_exc.NoSuchIden()\n        self._trig_auth_check(cron.useriden)\n        await self.cell.agenda.delete(iden)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def updateCronJob(self, iden, query):\n        '''\n        Change an existing cron job's query\n\n        Args:\n            iden (bytes):  The iden of the cron job to be changed\n        '''\n        cron = self.cell.agenda.appts.get(iden)\n        if cron is None:\n            raise s_exc.NoSuchIden()\n        self._trig_auth_check(cron.useriden)\n        await self.cell.agenda.mod(iden, query)", "response": "Update an existing cron job s query"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget information about all the cron jobs accessible to the current user.", "response": "async def listCronJobs(self):\n        '''\n        Get information about all the cron jobs accessible to the current user\n        '''\n        crons = []\n        for iden, cron in self.cell.agenda.list():\n            useriden = cron['useriden']\n            if not (self.user.admin or useriden == self.user.iden):\n                continue\n            user = self.cell.auth.user(useriden)\n            cron['username'] = '<unknown>' if user is None else user.name\n            crons.append((iden, cron))\n\n        return crons"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nadding a tag to a node specified by iden.", "response": "async def addNodeTag(self, iden, tag, valu=(None, None)):\n        '''\n        Add a tag to a node specified by iden.\n\n        Args:\n            iden (str): A hex encoded node BUID.\n            tag (str):  A tag string.\n            valu (tuple):  A time interval tuple or (None, None).\n        '''\n        buid = s_common.uhex(iden)\n\n        parts = tag.split('.')\n        self._reqUserAllowed('tag:add', *parts)\n\n        async with await self.cell.snap(user=self.user) as snap:\n            with s_provenance.claim('coreapi', meth='tag:add', user=snap.user.iden):\n\n                node = await snap.getNodeByBuid(buid)\n                if node is None:\n                    raise s_exc.NoSuchIden(iden=iden)\n\n                await node.addTag(tag, valu=valu)\n                return node.pack()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def addNodes(self, nodes):\n        '''\n        Add a list of packed nodes to the cortex.\n\n        Args:\n            nodes (list): [ ( (form, valu), {'props':{}, 'tags':{}}), ... ]\n\n        Yields:\n            (tuple): Packed node tuples ((form,valu), {'props': {}, 'tags':{}})\n\n        '''\n\n        # First check that that user may add each form\n\n        done = {}\n        for node in nodes:\n\n            formname = node[0][0]\n            if done.get(formname):\n                continue\n\n            self._reqUserAllowed('node:add', formname)\n            done[formname] = True\n\n        async with await self.cell.snap(user=self.user) as snap:\n            with s_provenance.claim('coreapi', meth='node:add', user=snap.user.iden):\n\n                snap.strict = False\n\n                async for node in snap.addNodes(nodes):\n\n                    if node is not None:\n                        node = node.pack()\n\n                    yield node", "response": "Add a list of packed nodes to the cortex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncounting the number of nodes which result from a storm query.", "response": "async def count(self, text, opts=None):\n        '''\n        Count the number of nodes which result from a storm query.\n\n        Args:\n            text (str): Storm query text.\n            opts (dict): Storm query options.\n\n        Returns:\n            (int): The number of nodes resulting from the query.\n        '''\n        i = 0\n        async for _ in self.cell.eval(text, opts=opts, user=self.user):\n            i += 1\n        return i"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def eval(self, text, opts=None):\n        '''\n        Evalute a storm query and yield packed nodes.\n        '''\n        async for pode in self.cell.iterStormPodes(text, opts=opts, user=self.user):\n            yield pode", "response": "Evalute a storm query and yield packed nodes."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def storm(self, text, opts=None):\n        '''\n        Evaluate a storm query and yield result messages.\n        Yields:\n            ((str,dict)): Storm messages.\n        '''\n        async for mesg in self.cell.streamstorm(text, opts, user=self.user):\n            yield mesg", "response": "Evaluate a storm query and yield result messages."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the list of splices at the given offset.", "response": "async def splices(self, offs, size):\n        '''\n        Return the list of splices at the given offset.\n        '''\n        count = 0\n        async for mesg in self.cell.view.layers[0].splices(offs, size):\n            count += 1\n            if not count % 1000:\n                await asyncio.sleep(0)\n            yield mesg"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def provStacks(self, offs, size):\n        '''\n        Return stream of (iden, provenance stack) tuples at the given offset.\n        '''\n        count = 0\n        for iden, stack in self.cell.provstor.provStacks(offs, size):\n            count += 1\n            if not count % 1000:\n                await asyncio.sleep(0)\n            yield s_common.ehex(iden), stack", "response": "Return stream of tuples at the given offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def getProvStack(self, iden: str):\n        '''\n        Return the providence stack associated with the given iden.\n\n        Args:\n            iden (str):  the iden from splice\n\n        Note: the iden appears on each splice entry as the 'prov' property\n        '''\n        return self.cell.provstor.getProvStack(s_common.uhex(iden))", "response": "Return the providence stack associated with the given iden."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _initStormCmds(self):\n        '''\n        Registration for built-in Storm commands.\n        '''\n        self.addStormCmd(s_storm.MaxCmd)\n        self.addStormCmd(s_storm.MinCmd)\n        self.addStormCmd(s_storm.HelpCmd)\n        self.addStormCmd(s_storm.IdenCmd)\n        self.addStormCmd(s_storm.SpinCmd)\n        self.addStormCmd(s_storm.SudoCmd)\n        self.addStormCmd(s_storm.UniqCmd)\n        self.addStormCmd(s_storm.CountCmd)\n        self.addStormCmd(s_storm.GraphCmd)\n        self.addStormCmd(s_storm.LimitCmd)\n        self.addStormCmd(s_storm.SleepCmd)\n        self.addStormCmd(s_storm.DelNodeCmd)\n        self.addStormCmd(s_storm.MoveTagCmd)\n        self.addStormCmd(s_storm.ReIndexCmd)", "response": "Register built - in Storm commands."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _initSplicers(self):\n        '''\n        Registration for splice handlers.\n        '''\n        splicers = {\n            'tag:add': self._onFeedTagAdd,\n            'tag:del': self._onFeedTagDel,\n            'node:add': self._onFeedNodeAdd,\n            'node:del': self._onFeedNodeDel,\n            'prop:set': self._onFeedPropSet,\n            'prop:del': self._onFeedPropDel,\n        }\n        self.splicers.update(**splicers)", "response": "Registration for splice handlers.\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninitializes the list of built - in Layer ctors.", "response": "def _initLayerCtors(self):\n        '''\n        Registration for built-in Layer ctors\n        '''\n        ctors = {\n            'lmdb': s_lmdblayer.LmdbLayer,\n            'remote': s_remotelayer.RemoteLayer,\n        }\n        self.layrctors.update(**ctors)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nregister for built - in Cortex feed functions.", "response": "def _initFeedFuncs(self):\n        '''\n        Registration for built-in Cortex feed functions.\n        '''\n        self.setFeedFunc('syn.nodes', self._addSynNodes)\n        self.setFeedFunc('syn.splice', self._addSynSplice)\n        self.setFeedFunc('syn.ingest', self._addSynIngest)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister built - in Cortex httpapi endpoints", "response": "def _initCortexHttpApi(self):\n        '''\n        Registration for built-in Cortex httpapi endpoints\n        '''\n        self.addHttpApi('/api/v1/storm', s_httpapi.StormV1, {'cell': self})\n        self.addHttpApi('/api/v1/storm/nodes', s_httpapi.StormNodesV1, {'cell': self})\n        self.addHttpApi('/api/v1/model/norm', s_httpapi.ModelNormV1, {'cell': self})"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def _calcFormCounts(self):\n        '''\n        Recalculate form counts from scratch.\n        '''\n        logger.info('Calculating form counts from scratch.')\n        self.counts.clear()\n\n        nameforms = list(self.model.forms.items())\n        fairiter = 5\n        tcount = 0\n        for i, (name, form) in enumerate(nameforms, 1):\n            logger.info('Calculating form counts for [%s] [%s/%s]',\n                        name, i, len(nameforms))\n            count = 0\n\n            async for buid, valu in self.view.layers[0].iterFormRows(name):\n\n                count += 1\n                tcount += 1\n\n                if count % fairiter == 0:\n                    await asyncio.sleep(0)\n                    # identity check for small integer\n                    if fairiter == 5 and tcount > 100000:\n                        fairiter = 1000\n\n            self.counts[name] = count\n\n        for name, valu in self.counts.items():\n            byts = s_common.int64en(valu)\n            self.slab.put(name.encode('utf8'), byts, db=self.formcountdb)\n        logger.info('Done calculating form counts.')", "response": "Calculate form counts for all the forms in the model."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister a callback for tag addition.", "response": "def onTagAdd(self, name, func):\n        '''\n        Register a callback for tag addition.\n\n        Args:\n            name (str): The name of the tag or tag glob.\n            func (function): The callback func(node, tagname, tagval).\n\n        '''\n        # TODO allow name wild cards\n        if '*' in name:\n            self.ontagaddglobs.add(name, func)\n        else:\n            self.ontagadds[name].append(func)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef offTagAdd(self, name, func):\n        '''\n        Unregister a callback for tag addition.\n\n        Args:\n            name (str): The name of the tag or tag glob.\n            func (function): The callback func(node, tagname, tagval).\n\n        '''\n        if '*' in name:\n            self.ontagaddglobs.rem(name, func)\n            return\n\n        cblist = self.ontagadds.get(name)\n        if cblist is None:\n            return\n        try:\n            cblist.remove(func)\n        except ValueError:\n            pass", "response": "Unregister a callback for tag addition."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nregisters a callback for tag deletion.", "response": "def onTagDel(self, name, func):\n        '''\n        Register a callback for tag deletion.\n\n        Args:\n            name (str): The name of the tag or tag glob.\n            func (function): The callback func(node, tagname, tagval).\n\n        '''\n        if '*' in name:\n            self.ontagdelglobs.add(name, func)\n        else:\n            self.ontagdels[name].append(func)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef offTagDel(self, name, func):\n        '''\n        Unregister a callback for tag deletion.\n\n        Args:\n            name (str): The name of the tag or tag glob.\n            func (function): The callback func(node, tagname, tagval).\n\n        '''\n        if '*' in name:\n            self.ontagdelglobs.rem(name, func)\n            return\n\n        cblist = self.ontagdels.get(name)\n        if cblist is None:\n            return\n        try:\n            cblist.remove(func)\n        except ValueError:\n            pass", "response": "Unregister a callback for tag deletion."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def runRuntLift(self, full, valu=None, cmpr=None):\n        '''\n        Execute a runt lift function.\n\n        Args:\n            full (str): Property to lift by.\n            valu:\n            cmpr:\n\n        Returns:\n            bytes, list: Yields bytes, list tuples where the list contains a series of\n                key/value pairs which are used to construct a Node object.\n\n        '''\n        func = self._runtLiftFuncs.get(full)\n        if func is None:\n            raise s_exc.NoSuchLift(mesg='No runt lift implemented for requested property.',\n                                   full=full, valu=valu, cmpr=cmpr)\n\n        async for buid, rows in func(full, valu, cmpr):\n            yield buid, rows", "response": "Execute a runt lift function."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndeleting a cortex view by iden.", "response": "async def delView(self, iden):\n        '''\n        Delete a cortex view by iden.\n        '''\n        if iden == self.iden:\n            raise s_exc.SynErr(mesg='cannot delete the main view')\n\n        view = self.views.pop(iden, None)\n        if view is None:\n            raise s_exc.NoSuchView(iden=iden)\n\n        await self.hive.pop(('cortex', 'views', iden))\n        await view.fini()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the top - down list of layers for the view with the given iden.", "response": "async def setViewLayers(self, layers, iden=None):\n        '''\n        Args:\n            layers ([str]): A top-down list of of layer guids\n            iden (str): The view iden ( defaults to default view ).\n        '''\n        if iden is None:\n            iden = self.iden\n\n        view = self.views.get(iden)\n        if view is None:\n            raise s_exc.NoSuchView(iden=iden)\n\n        view.setLayers(layers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def addLayer(self, **info):\n        '''\n        Add a Layer to the cortex.\n\n        Notes:\n\n            The addLayer ``**info`` arg is expected to be shaped like the following::\n\n                info = {\n                    'iden': <str>, ( optional iden. default guid() )\n                    'type': <str>, ( optional type. default lmdb )\n                    'owner': <str>, ( optional owner. default root )\n                    'config': {}, # type specific config options.\n                }\n\n        '''\n        iden = info.pop('iden', None)\n        if iden is None:\n            iden = s_common.guid()\n\n        node = await self.hive.open(('cortex', 'layers', iden))\n\n        layrinfo = await node.dict()\n        layrconf = await (await node.open(('config',))).dict()\n\n        await layrinfo.set('type', info.get('type', 'lmdb'))\n        await layrinfo.set('owner', info.get('owner', 'root'))\n        await layrinfo.set('name', info.get('name', '??'))\n\n        for name, valu in info.get('config', {}).items():\n            await layrconf.set(name, valu)\n\n        return await self._layrFromNode(node)", "response": "Add a Layer to the cortex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def joinTeleLayer(self, url, indx=None):\n        '''\n        Convenience function to join a remote telepath layer\n        into this cortex and default view.\n        '''\n        info = {\n            'type': 'remote',\n            'owner': 'root',\n            'config': {\n                'url': url\n            }\n        }\n\n        layr = await self.addLayer(**info)\n        await self.view.addLayer(layr, indx=indx)\n        return layr.iden", "response": "Convenience function to join a remote telepath layer into this cortex and default view."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addStormCmd(self, ctor):\n        '''\n        Add a synapse.lib.storm.Cmd class to the cortex.\n        '''\n        if not s_syntax.isCmdName(ctor.name):\n            raise s_exc.BadCmdName(name=ctor.name)\n\n        self.stormcmds[ctor.name] = ctor", "response": "Add a synapse. lib. storm. Cmd class to the cortex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninitializing the feed loops.", "response": "def _initFeedLoops(self):\n        '''\n        feeds:\n            - cryotank: tcp://cryo.vertex.link/cryo00/tank01\n              type: syn.splice\n        '''\n        feeds = self.conf.get('feeds', ())\n        if not feeds:\n            return\n\n        for feed in feeds:\n\n            # do some validation before we fire tasks...\n            typename = feed.get('type')\n            if self.getFeedFunc(typename) is None:\n                raise s_exc.NoSuchType(name=typename)\n\n            self.schedCoro(self._runFeedLoop(feed))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _getSynIngestNodes(self, item):\n        '''\n        Get a list of packed nodes from a ingest definition.\n        '''\n        pnodes = []\n        seen = item.get('seen')\n        # Track all the ndefs we make so we can make sources\n        ndefs = []\n\n        # Make the form nodes\n        tags = item.get('tags', {})\n        forms = item.get('forms', {})\n        for form, valus in forms.items():\n            for valu in valus:\n                ndef = [form, valu]\n                ndefs.append(ndef)\n                obj = [ndef, {'tags': tags}]\n                if seen:\n                    obj[1]['props'] = {'.seen': seen}\n                pnodes.append(obj)\n\n        # Make the packed nodes\n        nodes = item.get('nodes', ())\n        for pnode in nodes:\n            ndefs.append(pnode[0])\n            pnode[1].setdefault('tags', {})\n            for tag, valu in tags.items():\n                # Tag in the packed node has a higher predecence\n                # than the tag in the whole ingest set of data.\n                pnode[1]['tags'].setdefault(tag, valu)\n            if seen:\n                pnode[1].setdefault('props', {})\n                pnode[1]['props'].setdefault('.seen', seen)\n            pnodes.append(pnode)\n\n        # Make edges\n        for srcdef, etyp, destndefs in item.get('edges', ()):\n            for destndef in destndefs:\n                ndef = [etyp, [srcdef, destndef]]\n                ndefs.append(ndef)\n                obj = [ndef, {}]\n                if seen:\n                    obj[1]['props'] = {'.seen': seen}\n                if tags:\n                    obj[1]['tags'] = tags.copy()\n                pnodes.append(obj)\n\n        # Make time based edges\n        for srcdef, etyp, destndefs in item.get('time:edges', ()):\n            for destndef, time in destndefs:\n                ndef = [etyp, [srcdef, destndef, time]]\n                ndefs.append(ndef)\n                obj = [ndef, {}]\n                if seen:\n                    obj[1]['props'] = {'.seen': seen}\n                if tags:\n                    obj[1]['tags'] = tags.copy()\n                pnodes.append(obj)\n\n        # Make the source node and links\n        source = item.get('source')\n        if source:\n            # Base object\n            obj = [['meta:source', source], {}]\n            pnodes.append(obj)\n\n            # Subsequent links\n            for ndef in ndefs:\n                obj = [['meta:seen', (source, ndef)],\n                       {'props': {'.seen': seen}}]\n                pnodes.append(obj)\n        return pnodes", "response": "Get a list of packed nodes from a ingest definition."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nevaluate a storm query and yield Nodes only.", "response": "async def eval(self, text, opts=None, user=None):\n        '''\n        Evaluate a storm query and yield Nodes only.\n        '''\n        if user is None:\n            user = self.auth.getUserByName('root')\n\n        await self.boss.promote('storm', user=user, info={'query': text})\n        async with await self.snap(user=user) as snap:\n            async for node in snap.eval(text, opts=opts, user=user):\n                yield node"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def storm(self, text, opts=None, user=None):\n        '''\n        Evaluate a storm query and yield (node, path) tuples.\n        Yields:\n            (Node, Path) tuples\n        '''\n        if user is None:\n            user = self.auth.getUserByName('root')\n\n        await self.boss.promote('storm', user=user, info={'query': text})\n        async with await self.snap(user=user) as snap:\n            async for mesg in snap.storm(text, opts=opts, user=user):\n                yield mesg", "response": "Evaluate a storm query and yield a list of Messages"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def streamstorm(self, text, opts=None, user=None):\n        '''\n        Evaluate a storm query and yield result messages.\n        Yields:\n            ((str,dict)): Storm messages.\n        '''\n        if opts is None:\n            opts = {}\n\n        MSG_QUEUE_SIZE = 1000\n        chan = asyncio.Queue(MSG_QUEUE_SIZE, loop=self.loop)\n\n        if user is None:\n            user = self.auth.getUserByName('root')\n\n        # promote ourself to a synapse task\n        synt = await self.boss.promote('storm', user=user, info={'query': text})\n\n        show = opts.get('show')\n\n        async def runStorm():\n            cancelled = False\n            tick = s_common.now()\n            count = 0\n            try:\n                # First, try text parsing. If this fails, we won't be able to get\n                # a storm runtime in the snap, so catch and pass the `err` message\n                # before handing a `fini` message along.\n                self.getStormQuery(text)\n\n                await chan.put(('init', {'tick': tick, 'text': text, 'task': synt.iden}))\n\n                shownode = (show is None or 'node' in show)\n                async with await self.snap(user=user) as snap:\n\n                    if show is None:\n                        snap.link(chan.put)\n\n                    else:\n                        [snap.on(n, chan.put) for n in show]\n\n                    if shownode:\n                        async for pode in snap.iterStormPodes(text, opts=opts, user=user):\n                            await chan.put(('node', pode))\n                            count += 1\n\n                    else:\n                        async for item in snap.storm(text, opts=opts, user=user):\n                            count += 1\n\n            except asyncio.CancelledError:\n                logger.warning('Storm runtime cancelled.')\n                cancelled = True\n                raise\n\n            except Exception as e:\n                logger.exception('Error during storm execution')\n                enfo = s_common.err(e)\n                enfo[1].pop('esrc', None)\n                enfo[1].pop('ename', None)\n                await chan.put(('err', enfo))\n\n            finally:\n                if cancelled:\n                    return\n                tock = s_common.now()\n                took = tock - tick\n                await chan.put(('fini', {'tock': tock, 'took': took, 'count': count}))\n\n        await synt.worker(runStorm())\n\n        while True:\n\n            mesg = await chan.get()\n\n            yield mesg\n\n            if mesg[0] == 'fini':\n                break", "response": "Stream storms in a task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getStormQuery(self, text):\n        '''\n        Parse storm query text and return a Query object.\n        '''\n        query = s_syntax.Parser(text).query()\n        query.init(self)\n        return query", "response": "Parse storm query text and return a Query object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _logStormQuery(self, text, user):\n        '''\n        Log a storm query.\n        '''\n        if self.conf.get('storm:log'):\n            lvl = self.conf.get('storm:log:level')\n            logger.log(lvl, 'Executing storm query {%s} as [%s]', text, user.name)", "response": "Log a storm query."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def getNodeByNdef(self, ndef):\n        '''\n        Return a single Node() instance by (form,valu) tuple.\n        '''\n        name, valu = ndef\n\n        form = self.model.forms.get(name)\n        if form is None:\n            raise s_exc.NoSuchForm(name=name)\n\n        norm, info = form.type.norm(valu)\n\n        buid = s_common.buid((form.name, norm))\n\n        async with await self.snap() as snap:\n            return await snap.getNodeByBuid(buid)", "response": "Return a single Node instance by ndef tuple."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget nodes by a property value or lift syntax.", "response": "async def getNodesBy(self, full, valu, cmpr='='):\n        '''\n        Get nodes by a property value or lift syntax.\n\n        Args:\n            full (str): The full name of a property <form>:<prop>.\n            valu (obj): A value that the type knows how to lift by.\n            cmpr (str): The comparison operator you are lifting by.\n\n        Some node property types allow special syntax here.\n\n        Examples:\n\n            # simple lift by property equality\n            core.getNodesBy('file:bytes:size', 20)\n\n            # The inet:ipv4 type knows about cidr syntax\n            core.getNodesBy('inet:ipv4', '1.2.3.0/24')\n        '''\n        async with await self.snap() as snap:\n            async for node in snap.getNodesBy(full, valu, cmpr=cmpr):\n                yield node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def addNodes(self, nodedefs):\n        '''\n        Quickly add/modify a list of nodes from node definition tuples.\n        This API is the simplest/fastest way to add nodes, set node props,\n        and add tags to nodes remotely.\n\n        Args:\n\n            nodedefs (list): A list of node definition tuples. See below.\n\n        A node definition tuple is defined as:\n\n            ( (form, valu), {'props':{}, 'tags':{})\n\n        The \"props\" or \"tags\" keys may be omitted.\n\n        '''\n        async with await self.snap() as snap:\n            snap.strict = False\n            async for node in snap.addNodes(nodedefs):\n                yield node", "response": "Quickly add nodes from node definition tuples."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds data using a feed / parser function.", "response": "async def addFeedData(self, name, items, seqn=None):\n        '''\n        Add data using a feed/parser function.\n\n        Args:\n            name (str): The name of the feed record format.\n            items (list): A list of items to ingest.\n            seqn ((str,int)): An (iden, offs) tuple for this feed chunk.\n\n        Returns:\n            (int): The next expected offset (or None) if seqn is None.\n        '''\n        async with await self.snap() as snap:\n            snap.strict = False\n            return await snap.addFeedData(name, items, seqn=seqn)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a transaction object for the default view.", "response": "async def snap(self, user=None, view=None):\n        '''\n        Return a transaction object for the default view.\n\n        Args:\n            write (bool): Set to True for a write transaction.\n\n        Returns:\n            (synapse.lib.snap.Snap)\n\n        NOTE: This must be used in a with block.\n        '''\n\n        if view is None:\n            view = self.view\n\n        if user is None:\n            user = self.auth.getUserByName('root')\n\n        snap = await view.snap(user)\n\n        return snap"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def loadCoreModule(self, ctor, conf=None):\n        '''\n        Load a single cortex module with the given ctor and conf.\n\n        Args:\n            ctor (str): The python module class path\n            conf (dict):Config dictionary for the module\n        '''\n        if conf is None:\n            conf = {}\n\n        modu = self._loadCoreModule(ctor, conf=conf)\n\n        try:\n            await s_coro.ornot(modu.preCoreModule)\n        except asyncio.CancelledError:  # pragma: no cover\n            raise\n        except Exception:\n            logger.exception(f'module preCoreModule failed: {ctor}')\n            self.modules.pop(ctor, None)\n            return\n\n        mdefs = modu.getModelDefs()\n        self.model.addDataModels(mdefs)\n\n        cmds = modu.getStormCmds()\n        [self.addStormCmd(c) for c in cmds]\n\n        try:\n            await s_coro.ornot(modu.initCoreModule)\n        except asyncio.CancelledError:  # pragma: no cover\n            raise\n        except Exception:\n            logger.exception(f'module initCoreModule failed: {ctor}')\n            self.modules.pop(ctor, None)\n            return\n\n        await self.fire('core:module:load', module=ctor)\n\n        return modu", "response": "Load a single cortex module with the given class path and configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the normalized property value based on the Cortex data model.", "response": "async def getPropNorm(self, prop, valu):\n        '''\n        Get the normalized property value based on the Cortex data model.\n\n        Args:\n            prop (str): The property to normalize.\n            valu: The value to normalize.\n\n        Returns:\n            (tuple): A two item tuple, containing the normed value and the info dictionary.\n\n        Raises:\n            s_exc.NoSuchProp: If the prop does not exist.\n            s_exc.BadTypeValu: If the value fails to normalize.\n        '''\n        pobj = self.model.prop(prop)\n        if pobj is None:\n            raise s_exc.NoSuchProp(mesg=f'The property {prop} does not exist.',\n                                   prop=prop)\n        norm, info = pobj.type.norm(valu)\n        return norm, info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the normalized value based on the Cortex data model.", "response": "async def getTypeNorm(self, name, valu):\n        '''\n        Get the normalized type value based on the Cortex data model.\n\n        Args:\n            name (str): The type to normalize.\n            valu: The value to normalize.\n\n        Returns:\n            (tuple): A two item tuple, containing the normed value and the info dictionary.\n\n        Raises:\n            s_exc.NoSuchType: If the type does not exist.\n            s_exc.BadTypeValu: If the value fails to normalize.\n        '''\n        tobj = self.model.type(name)\n        if tobj is None:\n            raise s_exc.NoSuchType(mesg=f'The type {name} does not exist.',\n                                   name=name)\n        norm, info = tobj.norm(valu)\n        return norm, info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def stor(self, sops, splices=None):\n        '''\n        Execute a series of storage operations.\n\n        Overrides implementation in layer.py to avoid unnecessary async calls.\n        '''\n        for oper in sops:\n            func = self._stor_funcs.get(oper[0])\n            if func is None:  # pragma: no cover\n                raise s_exc.NoSuchStor(name=oper[0])\n            func(oper)\n\n        if splices:\n            self._storSplicesSync(splices)\n            self.spliced.set()\n            self.spliced.clear()", "response": "Execute a series of storage operations."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _migrate_db_pre010(self, dbname, newslab):\n        '''\n        Check for any pre-010 entries in 'dbname' in my slab and migrate those to the new slab.\n\n        Once complete, drop the database from me with the name 'dbname'\n\n        Returns (bool): True if a migration occurred, else False\n        '''\n        donekey = f'migrdone:{dbname}'\n\n        if self.metadict.get(donekey, False):\n            return\n\n        if not self.layrslab.dbexists(dbname):\n            self.metadict.set(donekey, True)\n            return False\n\n        oldslab = self.layrslab\n        olddb = oldslab.initdb(dbname)\n\n        entries = oldslab.stat(olddb)['entries']\n        if not entries:\n            self.metadict.set(donekey, True)\n            return False\n\n        if newslab.dbexists(dbname):\n            logger.warning('Incomplete migration detected.  Dropping new splices to restart.')\n            newslab.dropdb(dbname)\n            logger.info('New splice dropping complete.')\n\n        logger.info('Pre-010 %s migration starting.  Total rows: %d...', dbname, entries)\n\n        def progfunc(count):\n            logger.info('Progress %d/%d (%2.2f%%)', count, entries, count / entries * 100)\n\n        oldslab.copydb(olddb, newslab, destdbname=dbname, progresscb=progfunc)\n        logger.info('Pre-010 %s migration copying done.  Deleting from old location...', dbname)\n        oldslab.dropdb(dbname)\n        logger.info('Pre-010 %s migration completed.', dbname)\n\n        self.metadict.set(donekey, True)\n\n        return True", "response": "Check for any pre - 010 entries in dbname in my slab and migrate them to new slab. If any pre - 010 entries in dbname in my slab and migrate them to new slab."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmigrating all pre - 010 provstacks to the new slab.", "response": "def migrateProvPre010(self, newslab):\n        '''\n        Check for any pre-010 provstacks and migrate those to the new slab.\n        '''\n        did_migrate = self._migrate_db_pre010('prov', newslab)\n        if not did_migrate:\n            return\n\n        self._migrate_db_pre010('provs', newslab)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nedits a node s ndef.", "response": "async def editNodeNdef(self, oldv, newv):\n        '''\n        Migration-only method\n\n        Notes:\n            Precondition: buid cache must be disabled\n        '''\n        assert self.buidcache.disabled\n\n        oldb = s_common.buid(oldv)\n        newb = s_common.buid(newv)\n\n        pvoldval = s_msgpack.en((oldb,))\n        pvnewval = s_msgpack.en((newb,))\n\n        oldfenc = oldv[0].encode() + b'\\x00'\n        newfenc = newv[0].encode() + b'\\x00'\n\n        newprel = b'*' + newv[0].encode()\n\n        newnindx = self.core.model.prop(newv[0]).type.indx(newv[1])\n\n        # avoid any potential iter/edit issues...\n        todo = list(self.layrslab.scanByPref(oldb, db=self.bybuid))\n\n        for lkey, lval in todo:\n\n            proputf8 = lkey[32:]\n            valu, indx = s_msgpack.un(lval)\n\n            # for the *<form> prop, the byprop index has <form><00><00><indx>\n            if proputf8[0] == 42:\n\n                newpropkey = newfenc + b'\\x00' + newnindx\n\n                if indx is not None:\n                    oldpropkey = oldfenc + b'\\x00' + indx\n                    if not self.layrslab.delete(oldpropkey, pvoldval, db=self.byprop): # pragma: no cover\n                        logger.warning(f'editNodeNdef del byprop missing for {repr(oldv)} {repr(oldpropkey)}')\n\n                self.layrslab.put(newpropkey, pvnewval, dupdata=True, db=self.byprop)\n\n                byts = s_msgpack.en((newv[1], newnindx))\n                self.layrslab.put(newb + newprel, byts, db=self.bybuid)\n\n            else:\n\n                # <prop><00><indx>\n                propindx = proputf8 + b'\\x00' + indx\n\n                if proputf8[0] in (46, 35): # \".univ\" or \"#tag\"\n                    self.layrslab.put(propindx, pvnewval, dupdata=True, db=self.byuniv)\n                    self.layrslab.delete(propindx, pvoldval, db=self.byuniv)\n\n                oldpropkey = oldfenc + propindx\n                newpropkey = newfenc + propindx\n\n                if not self.layrslab.delete(oldpropkey, pvoldval, db=self.byprop): # pragma: no cover\n                    logger.warning(f'editNodeNdef del byprop missing for {repr(oldv)} {repr(oldpropkey)}')\n\n                self.layrslab.put(newpropkey, pvnewval, dupdata=True, db=self.byprop)\n                self.layrslab.put(newb + proputf8, lval, db=self.bybuid)\n\n            self.layrslab.delete(lkey, db=self.bybuid)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def storPropSet(self, buid, prop, valu):\n        '''\n        Migration-only function\n        '''\n        assert self.buidcache.disabled\n\n        indx = prop.type.indx(valu)\n        if indx is not None and len(indx) > MAX_INDEX_LEN:\n            mesg = 'index bytes are too large'\n            raise s_exc.BadIndxValu(mesg=mesg, prop=prop, valu=valu)\n\n        univ = prop.utf8name[0] in (46, 35) # leading . or #\n        bpkey = buid + prop.utf8name\n\n        self._storPropSetCommon(buid, prop.utf8name, bpkey, prop.pref, univ, valu, indx)", "response": "Set the value of a property in the cache."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def iterFormRows(self, form):\n        '''\n        Iterate (buid, valu) rows for the given form in this layer.\n        '''\n\n        # <form> 00 00 (no prop...)\n        pref = form.encode() + b'\\x00\\x00'\n        penc = b'*' + form.encode()\n\n        for _, pval in self.layrslab.scanByPref(pref, db=self.byprop):\n\n            buid = s_msgpack.un(pval)[0]\n\n            byts = self.layrslab.get(buid + penc, db=self.bybuid)\n            if byts is None:\n                continue\n\n            valu, indx = s_msgpack.un(byts)\n\n            yield buid, valu", "response": "Iterate over the rows of the given form in this layer."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\niterates over all rows for the given form and prop in this layer.", "response": "async def iterPropRows(self, form, prop):\n        '''\n        Iterate (buid, valu) rows for the given form:prop in this layer.\n        '''\n        # iterate byprop and join bybuid to get to value\n\n        penc = prop.encode()\n        pref = form.encode() + b'\\x00' + penc + b'\\x00'\n\n        for _, pval in self.layrslab.scanByPref(pref, db=self.byprop):\n\n            buid = s_msgpack.un(pval)[0]\n\n            byts = self.layrslab.get(buid + penc, db=self.bybuid)\n            if byts is None:\n                continue\n\n            valu, indx = s_msgpack.un(byts)\n\n            yield buid, valu"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def iterUnivRows(self, prop):\n        '''\n        Iterate (buid, valu) rows for the given universal prop\n        '''\n        penc = prop.encode()\n        pref = penc + b'\\x00'\n\n        for _, pval in self.layrslab.scanByPref(pref, db=self.byuniv):\n            buid = s_msgpack.un(pval)[0]\n\n            byts = self.layrslab.get(buid + penc, db=self.bybuid)\n            if byts is None:\n                continue\n\n            valu, indx = s_msgpack.un(byts)\n\n            yield buid, valu", "response": "Iterate over the rows for the given universal property."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nresolve a telepath alias via ~/.syn / aliases. yaml", "response": "def alias(name):\n    '''\n    Resolve a telepath alias via ~/.syn/aliases.yaml\n\n    Args:\n        name (str): Name of the alias to resolve.\n\n    Notes:\n        An exact match against the aliases will always be returned first.\n        If no exact match is found and the name contains a '/' in it, the\n        value before the slash is looked up and the remainder of the path\n        is joined to any result. This is done to support dynamic Telepath\n        share names.\n\n    Returns:\n        str: The url string, if present in the alias.  None will be returned\n        if there are no matches.\n    '''\n    path = s_common.getSynPath('aliases.yaml')\n    if not os.path.isfile(path):\n        return None\n\n    conf = s_common.yamlload(path)\n\n    # Is there an exact match - if so, return it.\n    url = conf.get(name)\n    if url:\n        return url\n\n    # Since telepath supports dynamic shared object access,\n    # slice a name at the first '/', look up using that value\n    # and then append the second value to it.\n    dynname = None\n    if '/' in name:\n        name, dynname = name.split('/', 1)\n    url = conf.get(name)\n    if url and dynname:\n        url = '/'.join([url, dynname])\n\n    return url"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nopening a URL to a remote telepath object.", "response": "async def openurl(url, **opts):\n    '''\n    Open a URL to a remote telepath object.\n\n    Args:\n        url (str): A telepath URL.\n        **opts (dict): Telepath connect options.\n\n    Returns:\n        (synapse.telepath.Proxy): A telepath proxy object.\n\n    The telepath proxy may then be used for sync or async calls:\n\n        proxy = openurl(url)\n        value = proxy.getFooThing()\n\n    ... or ...\n\n        proxy = await openurl(url)\n        valu = await proxy.getFooThing()\n\n    ... or ...\n\n        async with await openurl(url) as proxy:\n            valu = await proxy.getFooThing()\n    '''\n    if url.find('://') == -1:\n        newurl = alias(url)\n        if newurl is None:\n            raise s_exc.BadUrl(f':// not found in [{url}] and no alias found!')\n        url = newurl\n\n    info = s_urlhelp.chopurl(url)\n    info.update(opts)\n\n    host = info.get('host')\n    port = info.get('port')\n\n    auth = None\n\n    user = info.get('user')\n    if user is not None:\n        passwd = info.get('passwd')\n        auth = (user, {'passwd': passwd})\n\n    scheme = info.get('scheme')\n\n    if scheme == 'cell':\n        # cell:///path/to/celldir:share\n        # cell://rel/path/to/celldir:share\n        path = info.get('path')\n        name = info.get('name', '*')\n\n        # support cell://<relpath>/<to>/<cell>\n        # by detecting host...\n        host = info.get('host')\n        if host:\n            path = path.strip('/')\n            path = os.path.join(host, path)\n\n        if ':' in path:\n            path, name = path.split(':')\n\n        full = os.path.join(path, 'sock')\n        link = await s_link.unixconnect(full)\n\n    elif scheme == 'unix':\n        # unix:///path/to/sock:share\n        path, name = info.get('path').split(':')\n        link = await s_link.unixconnect(path)\n\n    else:\n\n        path = info.get('path')\n        name = info.get('name', path[1:])\n\n        sslctx = None\n        if scheme == 'ssl':\n            certpath = info.get('certdir')\n            certdir = s_certdir.CertDir(certpath)\n            sslctx = certdir.getClientSSLContext()\n\n        link = await s_link.connect(host, port, ssl=sslctx)\n\n    prox = await Proxy.anit(link, name)\n    prox.onfini(link)\n\n    try:\n        await prox.handshake(auth=auth)\n\n    except Exception:\n        await prox.fini()\n        raise\n\n    return prox"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling a remote method by name. Args: methname (str): The name of the remote method. *args: Arguments to the method call. **kwargs: Keyword arguments to the method call. Most use cases will likely use the proxy methods directly: The following two are effectively the same: valu = proxy.getFooBar(x, y) valu = proxy.call('getFooBar', x, y)", "response": "async def call(self, methname, *args, **kwargs):\n        '''\n        Call a remote method by name.\n\n        Args:\n            methname (str): The name of the remote method.\n            *args: Arguments to the method call.\n            **kwargs: Keyword arguments to the method call.\n\n        Most use cases will likely use the proxy methods directly:\n\n        The following two are effectively the same:\n\n            valu = proxy.getFooBar(x, y)\n            valu = proxy.call('getFooBar', x, y)\n        '''\n        todo = (methname, args, kwargs)\n        return await self.task(todo)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef allows(self):\n        '''\n        Returns True if the rate limit has not been reached.\n\n        Example:\n\n            if not rlimit.allows():\n                rasie RateExceeded()\n\n            # ok to go...\n\n        '''\n        tick = time.time()\n        passed = tick - self.lasttick\n\n        self.allowance = min(self.rate, self.allowance + (passed * self.persec))\n\n        self.lasttick = tick\n\n        if self.allowance < 1.0:\n            return False\n\n        self.allowance -= 1.0\n        return True", "response": "Returns True if the rate limit has not been reached."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndisabling and invalidate the layer buid cache for migration", "response": "def disablingBuidCache(self):\n        '''\n        Disable and invalidate the layer buid cache for migration\n        '''\n        self.buidcache = s_cache.LruDict(0)\n        yield\n        self.buidcache = s_cache.LruDict(BUID_CACHE_SIZE)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield a stream of tuples containing buid and properties.", "response": "async def getLiftRows(self, lops):\n        '''\n        Returns:\n            Iterable[Tuple[bytes, Dict[str, Any]]]:  yield a stream of tuple (buid, propdict)\n        '''\n        for oper in lops:\n\n            func = self._lift_funcs.get(oper[0])\n            if func is None:\n                raise s_exc.NoSuchLift(name=oper[0])\n\n            async for row in func(oper):\n                buid = row[0]\n                props = await self.getBuidProps(buid)\n                yield (buid, props)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of fully qualified class names for an instance.", "response": "def getClsNames(item):\n    '''\n    Return a list of \"fully qualified\" class names for an instance.\n\n    Example:\n\n        for name in getClsNames(foo):\n            print(name)\n\n    '''\n    mro = inspect.getmro(item.__class__)\n    mro = [c for c in mro if c not in clsskip]\n    return ['%s.%s' % (c.__module__, c.__name__) for c in mro]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getMethName(meth):\n    '''\n    Return a fully qualified string for the <mod>.<class>.<func> name\n    of a given method.\n    '''\n    item = meth.__self__\n    mname = item.__module__\n    cname = item.__class__.__name__\n    fname = meth.__func__.__name__\n    return '.'.join((mname, cname, fname))", "response": "Return a fully qualified string for the class and function name of a given method."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getItemLocals(item):\n    '''\n    Iterate the locals of an item and yield (name,valu) pairs.\n\n    Example:\n\n        for name,valu in getItemLocals(item):\n            dostuff()\n\n    '''\n    for name in dir(item):\n        try:\n            valu = getattr(item, name, None)\n            yield name, valu\n        except Exception:\n            pass", "response": "Iterate the locals of an item and yield name and value pairs."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getShareInfo(item):\n    '''\n    Get a dictionary of special annotations for a Telepath Proxy.\n\n    Args:\n        item:  Item to inspect.\n\n    Notes:\n        This will set the ``_syn_telemeth`` attribute on the item\n        and the items class, so this data is only computed once.\n\n    Returns:\n        dict: A dictionary of methods requiring special handling by the proxy.\n    '''\n    key = f'_syn_sharinfo_{item.__class__.__module__}_{item.__class__.__qualname__}'\n    info = getattr(item, key, None)\n    if info is not None:\n        return info\n\n    meths = {}\n    info = {'meths': meths}\n\n    for name in dir(item):\n\n        if name.startswith('_'):\n            continue\n\n        attr = getattr(item, name, None)\n        if not callable(attr):\n            continue\n\n        # We know we can cleanly unwrap these functions\n        # for asyncgenerator inspection.\n        wrapped = getattr(attr, '__syn_wrapped__', None)\n        if wrapped in unwraps:\n            real = inspect.unwrap(attr)\n            if inspect.isasyncgenfunction(real):\n                meths[name] = {'genr': True}\n                continue\n\n        if inspect.isasyncgenfunction(attr):\n            meths[name] = {'genr': True}\n\n    try:\n        setattr(item, key, info)\n    except Exception as e:  # pragma: no cover\n        logger.exception(f'Failed to set magic on {item}')\n\n    try:\n        setattr(item.__class__, key, info)\n    except Exception as e:  # pragma: no cover\n        logger.exception(f'Failed to set magic on {item.__class__}')\n\n    return info", "response": "Get a dictionary of special annotations for a Telepath Proxy."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nswitch to another user.", "response": "def setCellUser(self, iden):\n        '''\n        Switch to another user (admin only).\n\n        This API allows remote admin/service accounts\n        to impersonate a user.  Used mostly by services\n        that manage their own authentication/sessions.\n        '''\n        if not self.user.admin:\n            mesg = 'setCellUser() caller must be admin.'\n            raise s_exc.AuthDeny(mesg=mesg)\n\n        user = self.cell.auth.user(iden)\n        if user is None:\n            raise s_exc.NoSuchUser(iden=iden)\n\n        self.user = user\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def getHiveKey(self, path):\n        ''' Get the value of a key in the cell default hive '''\n        perm = ('hive:get',) + path\n        self.user.allowed(perm)\n        return await self.cell.hive.get(path)", "response": "Get the value of a key in the default hive"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nset or change the value of a key in the default hive", "response": "async def setHiveKey(self, path, value):\n        ''' Set or change the value of a key in the cell default hive '''\n        perm = ('hive:set',) + path\n        self.user.allowed(perm)\n        return await self.cell.hive.set(path, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove and return the value of a key in the default hive", "response": "async def popHiveKey(self, path):\n        ''' Remove and return the value of a key in the cell default hive '''\n        perm = ('hive:pop',) + path\n        self.user.allowed(perm)\n        return await self.cell.hive.pop(path)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def setAuthAdmin(self, name, admin):\n        '''\n        Set the admin status of the given user/role.\n        '''\n        item = self._getAuthItem(name)\n        await item.setAdmin(admin)", "response": "Set the admin status of the given user or role."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _asynciostacks(*args, **kwargs):  # pragma: no cover\n    '''\n    A signal handler used to print asyncio task stacks and thread stacks.\n    '''\n    print(80 * '*')\n    print('Asyncio tasks stacks:')\n    tasks = asyncio.all_tasks(_glob_loop)\n    for task in tasks:\n        task.print_stack()\n    print(80 * '*')\n    print('Faulthandler stack frames per thread:')\n    faulthandler.dump_traceback()\n    print(80 * '*')", "response": "A signal handler used to print asyncio task stacks and thread stacks."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscheduling a coroutine to run on the global loop and return it s result.", "response": "def sync(coro, timeout=None):\n    '''\n    Schedule a coroutine to run on the global loop and return it's result.\n\n    Args:\n        coro (coroutine): The coroutine instance.\n\n    Notes:\n        This API is thread safe and should only be called by non-loop threads.\n    '''\n    loop = initloop()\n    return asyncio.run_coroutine_threadsafe(coro, loop).result(timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _parse_weekday(val):\n        ''' Try to match a day-of-week abbreviation, then try a day-of-week full name '''\n        val = val.title()\n        try:\n            return list(calendar.day_abbr).index(val)\n        except ValueError:\n            try:\n                return list(calendar.day_name).index(val)\n            except ValueError:\n                return None", "response": "Try to match a day - of - week abbreviation then try a day - of - week full name then return the index of the first occurrence of the weekday."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_incval(incunit, incval):\n        ''' Parse a non-day increment value. Should be an integer or a comma-separated integer list. '''\n        try:\n            retn = [int(val) for val in incval.split(',')]\n        except ValueError:\n            return None\n\n        return retn[0] if len(retn) == 1 else retn", "response": "Parse a non - day increment value. Should be an integer or a comma - separated integer list."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nparses a non - day fixed value.", "response": "def _parse_req(requnit, reqval):\n        ''' Parse a non-day fixed value '''\n        assert reqval[0] != '='\n\n        try:\n            retn = []\n            for val in reqval.split(','):\n                if requnit == 'month':\n                    if reqval[0].isdigit():\n                        retn.append(int(reqval))  # must be a month (1-12)\n                    else:\n                        try:\n                            retn.append(list(calendar.month_abbr).index(val.title()))\n                        except ValueError:\n                            retn.append(list(calendar.month_name).index(val.title()))\n                else:\n                    retn.append(int(val))\n        except ValueError:\n            return None\n\n        if not retn:\n            return None\n\n        return retn[0] if len(retn) == 1 else retn"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_day(optval):\n        ''' Parse a --day argument '''\n        isreq = not optval.startswith('+')\n        if not isreq:\n            optval = optval[1:]\n\n        try:\n            retnval = []\n            unit = None\n            for val in optval.split(','):\n                if not val:\n                    raise ValueError\n                if val[-1].isdigit():\n                    newunit = 'dayofmonth' if isreq else 'day'\n                    if unit is None:\n                        unit = newunit\n                    elif newunit != unit:\n                        raise ValueError\n                    retnval.append(int(val))\n                else:\n                    newunit = 'dayofweek'\n                    if unit is None:\n                        unit = newunit\n                    elif newunit != unit:\n                        raise ValueError\n\n                    weekday = Cron._parse_weekday(val)\n                    if weekday is None:\n                        raise ValueError\n                    retnval.append(weekday)\n            if len(retnval) == 0:\n                raise ValueError\n        except ValueError:\n            return None, None\n        if len(retnval) == 1:\n            retnval = retnval[0]\n        return unit, retnval", "response": "Parse a -- day argument."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _handle_stat(self, core, opts):\n        ''' Prints details about a particular cron job. Not actually a different API call '''\n        prefix = opts.prefix\n        crons = await core.listCronJobs()\n        idens = [cron[0] for cron in crons]\n        matches = [iden for iden in idens if iden.startswith(prefix)]\n        if len(matches) == 0:\n            self.printf('Error: provided iden does not match any valid authorized cron job')\n            return\n        elif len(matches) > 1:\n            self.printf('Error: provided iden matches more than one cron job')\n            return\n\n        iden = matches[0]\n        cron = [cron[1] for cron in crons if cron[0] == iden][0]\n\n        user = cron.get('username') or '<None>'\n        query = cron.get('query') or '<missing>'\n        isrecur = 'Yes' if cron.get('recur') else 'No'\n        startcount = cron.get('startcount') or 0\n        recs = cron.get('recs', [])\n        laststart = cron.get('laststarttime')\n        lastend = cron.get('lastfinishtime')\n        laststart = 'Never' if laststart is None else self._format_timestamp(laststart)\n        lastend = 'Never' if lastend is None else self._format_timestamp(lastend)\n        lastresult = cron.get('lastresult') or '<None>'\n\n        self.printf(f'iden:            {iden}')\n        self.printf(f'user:            {user}')\n        self.printf(f'recurring:       {isrecur}')\n        self.printf(f'# starts:        {startcount}')\n        self.printf(f'last start time: {laststart}')\n        self.printf(f'last end time:   {lastend}')\n        self.printf(f'last result:     {lastresult}')\n        self.printf(f'query:           {query}')\n        if not recs:\n            self.printf(f'entries:         <None>')\n        else:\n            self.printf(f'entries:         {\"incunit\":10} {\"incval\":6} {\"required\"}')\n            for reqdict, incunit, incval in recs:\n                reqdict = reqdict or '<None>'\n                incunit = incunit or '<None>'\n                incval = incval or '<None>'\n                self.printf(f'                 {incunit:10} {incval:6} {reqdict}')", "response": "Prints details about a particular authorized cron job. Not actually a different API call."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def promote(self, name, user, info=None):\n        '''\n        Promote the currently running task.\n        '''\n        task = asyncio.current_task()\n\n        synt = getattr(task, '_syn_task', None)\n\n        if synt is not None:\n\n            if synt.root is None:\n                return synt\n\n            synt.root.kids.pop(synt.iden)\n            synt.root = None\n            return synt\n\n        return await s_task.Task.anit(self, task, name, user, info=info)", "response": "Promote the currently running task."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def execute(self, coro, name, user, info=None):\n        '''\n        Create a synapse task from the given coroutine.\n        '''\n        task = self.schedCoro(coro)\n        return await s_task.Task.anit(self, task, name, user, info=info)", "response": "Execute a synapse task from a given coroutine."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef onfini(self, func):\n        '''\n        Add a function/coroutine/Base to be called on fini().\n        '''\n        if isinstance(func, Base):\n            self.tofini.add(func)\n            return\n\n        assert self.anitted\n        self._fini_funcs.append(func)", "response": "Add a function to be called on fini."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef unlink(self, func):\n        '''\n        Remove a callback function previously added with link()\n\n        Example:\n\n            base.unlink( callback )\n\n        '''\n        if func in self._syn_links:\n            self._syn_links.remove(func)", "response": "Remove a callback function previously added with link"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef on(self, evnt, func, base=None):\n        '''\n        Add an base function callback for a specific event with optional filtering.  If the function returns a\n        coroutine, it will be awaited.\n\n        Args:\n            evnt (str):         An event name\n            func (function):    A callback function to receive event tufo\n\n        Examples:\n\n            Add a callback function and fire it:\n\n                async def baz(event):\n                    x = event[1].get('x')\n                    y = event[1].get('y')\n                    return x + y\n\n                d.on('foo', baz)\n\n                # this fire triggers baz...\n                await d.fire('foo', x=10, y=20)\n\n        Returns:\n            None:\n        '''\n        funcs = self._syn_funcs[evnt]\n        if func in funcs:\n            return\n\n        funcs.append(func)\n\n        if base is not None:\n\n            def fini():\n                self.off(evnt, func)\n\n            base.onfini(fini)", "response": "Add a callback function to receive an event."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef off(self, evnt, func):\n        '''\n        Remove a previously registered event handler function.\n\n        Example:\n\n            base.off( 'foo', onFooFunc )\n\n        '''\n        funcs = self._syn_funcs.get(evnt)\n        if funcs is None:\n            return\n\n        try:\n            funcs.remove(func)\n        except ValueError:\n            pass", "response": "Remove a previously registered event handler function."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def fire(self, evtname, **info):\n        '''\n        Fire the given event name on the Base.\n        Returns a list of the return values of each callback.\n\n        Example:\n\n            for ret in d.fire('woot',foo='asdf'):\n                print('got: %r' % (ret,))\n\n        '''\n        event = (evtname, info)\n        if self.isfini:\n            return event\n\n        await self.dist(event)\n        return event", "response": "Fire an event on the Base."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndistributes an existing event tuple.", "response": "async def dist(self, mesg):\n        '''\n        Distribute an existing event tuple.\n\n        Args:\n            mesg ((str,dict)):  An event tuple.\n\n        Example:\n\n            await base.dist( ('foo',{'bar':'baz'}) )\n\n        '''\n        if self.isfini:\n            return ()\n\n        ret = []\n        for func in self._syn_funcs.get(mesg[0], ()):\n\n            try:\n                ret.append(await s_coro.ornot(func, mesg))\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception('base %s error with mesg %s', self, mesg)\n\n        for func in self._syn_links:\n            try:\n                ret.append(await func(mesg))\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception('base %s error with mesg %s', self, mesg)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def fini(self):\n        '''\n        Shut down the object and notify any onfini() coroutines.\n\n        Returns:\n            Remaining ref count\n        '''\n        assert self.anitted, f'{self.__class__.__name__} initialized improperly.  Must use Base.anit class method.'\n\n        if self.isfini:\n            return\n\n        if __debug__:\n            import synapse.lib.threads as s_threads  # avoid import cycle\n            assert s_threads.iden() == self.tid\n\n        self._syn_refs -= 1\n        if self._syn_refs > 0:\n            return self._syn_refs\n\n        self.isfini = True\n\n        fevt = self.finievt\n\n        if fevt is not None:\n            fevt.set()\n\n        for base in list(self.tofini):\n            await base.fini()\n\n        try:\n            await self._kill_active_tasks()\n        except:\n            logger.exception(f'{self} - Exception during _kill_active_tasks')\n\n        for fini in self._fini_funcs:\n            try:\n                await s_coro.ornot(fini)\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception(f'{self} - fini function failed: {fini}')\n\n        self._syn_funcs.clear()\n        self._fini_funcs.clear()\n        return 0", "response": "Mark the object as fini and notify any onfini coroutines."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef onWith(self, evnt, func):\n        '''\n        A context manager which can be used to add a callback and remove it when\n        using a ``with`` statement.\n\n        Args:\n            evnt (str):         An event name\n            func (function):    A callback function to receive event tufo\n        '''\n        self.on(evnt, func)\n        # Allow exceptions to propagate during the context manager\n        # but ensure we cleanup our temporary callback\n        try:\n            yield self\n        finally:\n            self.off(evnt, func)", "response": "A context manager which can be used to add a callback function to receive a specific event."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def waitfini(self, timeout=None):\n        '''\n        Wait for the base to fini()\n\n        Returns:\n            None if timed out, True if fini happened\n\n        Example:\n\n            base.waitfini(timeout=30)\n\n        '''\n\n        if self.isfini:\n            return True\n\n        if self.finievt is None:\n            self.finievt = asyncio.Event()\n\n        return await s_coro.event_wait(self.finievt, timeout)", "response": "Wait for the base to fini returns True if successful False otherwise"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef schedCoro(self, coro):\n        '''\n        Schedules a free-running coroutine to run on this base's event loop.  Kills the coroutine if Base is fini'd.\n        It does not pend on coroutine completion.\n\n        Precondition:\n            This function is *not* threadsafe and must be run on the Base's event loop\n\n        Returns:\n            asyncio.Task: An asyncio.Task object.\n\n        '''\n        import synapse.lib.provenance as s_provenance  # avoid import cycle\n\n        if __debug__:\n            assert s_coro.iscoro(coro)\n            import synapse.lib.threads as s_threads  # avoid import cycle\n            assert s_threads.iden() == self.tid\n\n        task = self.loop.create_task(coro)\n\n        # In rare cases, (Like this function being triggered from call_soon_threadsafe), there's no task context\n        if asyncio.current_task():\n            s_provenance.dupstack(task)\n\n        def taskDone(task):\n            self._active_tasks.remove(task)\n            try:\n                task.result()\n            except asyncio.CancelledError:\n                pass\n            except Exception:\n                logger.exception('Task scheduled through Base.schedCoro raised exception')\n\n        self._active_tasks.add(task)\n        task.add_done_callback(taskDone)\n\n        return task", "response": "Schedules a free - running coroutine to run on this base s event loop."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nscheduling a coroutine to run as soon as possible on the same event loop as this Base is running on", "response": "def schedCoroSafePend(self, coro):\n        '''\n        Schedules a coroutine to run as soon as possible on the same event loop that this Base is running on\n\n        Note:\n            This method may *not* be run inside an event loop\n        '''\n        if __debug__:\n            import synapse.lib.threads as s_threads  # avoid import cycle\n            assert s_threads.iden() != self.tid\n\n        task = asyncio.run_coroutine_threadsafe(coro, self.loop)\n        return task.result()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nregister SIGTERM and SIGINT signal handlers with the ioloop to fini this object.", "response": "async def addSignalHandlers(self):\n        '''\n        Register SIGTERM/SIGINT signal handlers with the ioloop to fini this object.\n        '''\n\n        def sigterm():\n            print('Caught SIGTERM, shutting down.')\n            asyncio.create_task(self.fini())\n\n        def sigint():\n            print('Caught SIGINT, shutting down.')\n            asyncio.create_task(self.fini())\n\n        loop = asyncio.get_running_loop()\n        loop.add_signal_handler(signal.SIGINT, sigint)\n        loop.add_signal_handler(signal.SIGTERM, sigterm)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconstructing and return a Waiter for events on this base.", "response": "def waiter(self, count, *names):\n        '''\n        Construct and return a new Waiter for events on this base.\n\n        Example:\n\n            # wait up to 3 seconds for 10 foo:bar events...\n\n            waiter = base.waiter(10,'foo:bar')\n\n            # .. fire thread that will cause foo:bar events\n\n            events = waiter.wait(timeout=3)\n\n            if events == None:\n                # handle the timout case...\n\n            for event in events:\n                # parse the events if you need...\n\n        NOTE: use with caution... it's easy to accidentally construct\n              race conditions with this mechanism ;)\n\n        '''\n        return Waiter(self, count, self.loop, *names)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def wait(self, timeout=None):\n        '''\n        Wait for the required number of events and return them or None on timeout.\n\n        Example:\n\n            evnts = waiter.wait(timeout=30)\n\n            if evnts == None:\n                handleTimedOut()\n                return\n\n            for evnt in evnts:\n                doStuff(evnt)\n\n        '''\n        try:\n\n            retn = await s_coro.event_wait(self.event, timeout)\n            if not retn:\n                return None\n\n            return self.events\n\n        finally:\n            self.fini()", "response": "Wait for the required number of events and return them or None on timeout."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef put(self, name, base):\n        '''\n        Add a Base (or sub-class) to the BaseRef by name.\n\n        Args:\n            name (str): The name/iden of the Base\n            base (Base): The Base instance\n\n        Returns:\n            (None)\n        '''\n        async def fini():\n            if self.base_by_name.get(name) is base:\n                self.base_by_name.pop(name, None)\n\n        # Remove myself from BaseRef when I fini\n        base.onfini(fini)\n        self.base_by_name[name] = base", "response": "Add a Base to the BaseRef by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef guid(valu=None):\n    '''\n    Get a 16 byte guid value.\n\n    By default, this is a random guid value.\n\n    Args:\n        valu: Object used to construct the guid valu from.  This must be able\n            to be msgpack'd.\n\n    Returns:\n        str: 32 character, lowercase ascii string.\n    '''\n    if valu is None:\n        return binascii.hexlify(os.urandom(16)).decode('utf8')\n    # Generate a \"stable\" guid from the given item\n    byts = s_msgpack.en(valu)\n    return hashlib.md5(byts).hexdigest()", "response": "Generate a 16 byte guid value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef buid(valu=None):\n    '''\n    A binary GUID like sequence of 32 bytes.\n\n    Args:\n        valu (object): Optional, if provided, the hash of the msgpack\n        encoded form of the object is returned. This can be used to\n        create stable buids.\n\n    Notes:\n        By default, this returns a random 32 byte value.\n\n    Returns:\n        bytes: A 32 byte value.\n    '''\n    if valu is None:\n        return os.urandom(32)\n\n    byts = s_msgpack.en(valu)\n    return hashlib.sha256(byts).digest()", "response": "Returns a 32 byte binary GUID like sequence of 32 bytes."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef intify(x):\n    '''\n    Ensure ( or coerce ) a value into being an integer or None.\n\n    Args:\n        x (obj):    An object to intify\n\n    Returns:\n        (int):  The int value ( or None )\n    '''\n    if isinstance(x, int):\n        return x\n\n    try:\n        return int(x, 0)\n    except (TypeError, ValueError):\n        return None", "response": "Ensures that a value into being an integer or None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a file - object for read or write.", "response": "def genfile(*paths):\n    '''\n    Create or open ( for read/write ) a file path join.\n\n    Args:\n        *paths: A list of paths to join together to make the file.\n\n    Notes:\n        If the file already exists, the fd returned is opened in ``r+b`` mode.\n        Otherwise, the fd is opened in ``w+b`` mode.\n\n    Returns:\n        io.BufferedRandom: A file-object which can be read/written too.\n    '''\n    path = genpath(*paths)\n    gendir(os.path.dirname(path))\n    if not os.path.isfile(path):\n        return io.open(path, 'w+b')\n    return io.open(path, 'r+b')"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef listdir(*paths, glob=None):\n    '''\n    List the (optionally glob filtered) full paths from a dir.\n\n    Args:\n        *paths ([str,...]): A list of path elements\n        glob (str): An optional fnmatch glob str\n    '''\n    path = genpath(*paths)\n\n    names = os.listdir(path)\n    if glob is not None:\n        names = fnmatch.filter(names, glob)\n\n    retn = [os.path.join(path, name) for name in names]\n    return retn", "response": "Returns a list of full paths from a dir."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncombining a yaml file and creates a yaml file and combines with obj.", "response": "def yamlmod(obj, *paths):\n    '''\n    Combines/creates a yaml file and combines with obj.  obj and file must be maps/dict or empty.\n    '''\n    oldobj = yamlload(*paths)\n    if obj is not None:\n        if oldobj:\n            yamlsave({**oldobj, **obj}, *paths)\n        else:\n            yamlsave(obj, *paths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets an err tufo from an exception.", "response": "def getexcfo(e):\n    '''\n    Get an err tufo from an exception.\n\n    Args:\n        e (Exception): An Exception (or Exception subclass).\n\n    Notes:\n        This can be called outside of the context of an exception handler,\n        however details such as file, line, function name and source may be\n        missing.\n\n    Returns:\n        ((str, dict)):\n    '''\n    tb = sys.exc_info()[2]\n    tbinfo = traceback.extract_tb(tb)\n    path, line, name, src = '', '', '', None\n    if tbinfo:\n        path, line, name, sorc = tbinfo[-1]\n    retd = {\n        'msg': str(e),\n        'file': path,\n        'line': line,\n        'name': name,\n        'src': src\n    }\n\n    if isinstance(e, s_exc.SynErr):\n        retd['syn:err'] = e.errinfo\n\n    return (e.__class__.__name__, retd)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\npopulating err errmsg errtrace info from exc.", "response": "def excinfo(e):\n    '''\n    Populate err,errmsg,errtrace info from exc.\n    '''\n    tb = sys.exc_info()[2]\n    path, line, name, sorc = traceback.extract_tb(tb)[-1]\n    ret = {\n        'err': e.__class__.__name__,\n        'errmsg': str(e),\n        'errfile': path,\n        'errline': line,\n    }\n\n    if isinstance(e, s_exc.SynErr):\n        ret['errinfo'] = e.errinfo\n\n    return ret"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndividing an iterable into chunks.", "response": "def chunks(item, size):\n    '''\n    Divide an iterable into chunks.\n\n    Args:\n        item: Item to slice\n        size (int): Maximum chunk size.\n\n    Notes:\n        This supports Generator objects and objects which support calling\n        the __getitem__() method with a slice object.\n\n    Yields:\n        Slices of the item containing up to \"size\" number of items.\n    '''\n    # use islice if it's a generator\n    if isinstance(item, types.GeneratorType):\n\n        while True:\n\n            chunk = tuple(itertools.islice(item, size))\n            if not chunk:\n                return\n\n            yield chunk\n\n    # The sequence item is empty, yield a empty slice from it.\n    # This will also catch mapping objects since a slice should\n    # be an unhashable type for a mapping and the __getitem__\n    # method would not be present on a set object\n    if not item:\n        yield item[0:0]\n        return\n\n    # otherwise, use normal slicing\n    off = 0\n\n    while True:\n\n        chunk = item[off:off + size]\n        if not chunk:\n            return\n\n        yield chunk\n\n        off += size"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setlogging(mlogger, defval=None):\n    '''\n    Configure synapse logging.\n\n    Args:\n        mlogger (logging.Logger): Reference to a logging.Logger()\n        defval (str): Default log level\n\n    Notes:\n        This calls logging.basicConfig and should only be called once per process.\n\n    Returns:\n        None\n    '''\n    log_level = os.getenv('SYN_LOG_LEVEL',\n                          defval)\n    if log_level:  # pragma: no cover\n        log_level = log_level.upper()\n        if log_level not in s_const.LOG_LEVEL_CHOICES:\n            raise ValueError('Invalid log level provided: {}'.format(log_level))\n        logging.basicConfig(level=log_level, format=s_const.LOG_FORMAT)\n        mlogger.info('log level set to %s', log_level)", "response": "Configure synapse logging.\n\n    Args:\n        mlogger (logging.Logger): Reference to a logging.Logger()\n        defval (str): Default log level\n\n    Notes:\n        This calls logging.basicConfig and should only be called once per process.\n\n    Returns:\n        None"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a value or raise an exception from a retn tuple.", "response": "def result(retn):\n    '''\n    Return a value or raise an exception from a retn tuple.\n    '''\n    ok, valu = retn\n\n    if ok:\n        return valu\n\n    name, info = valu\n\n    ctor = getattr(s_exc, name, None)\n    if ctor is not None:\n        raise ctor(**info)\n\n    info['errx'] = name\n    raise s_exc.SynErr(**info)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninitialize a config dict using the given confdef tuples.", "response": "def config(conf, confdefs):\n    '''\n    Initialize a config dict using the given confdef tuples.\n    '''\n    conf = conf.copy()\n\n    # for now just populate defval\n    for name, info in confdefs:\n        conf.setdefault(name, info.get('defval'))\n\n    return conf"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmigrates cell Auth data into a HiveAuth.", "response": "async def cellAuthToHive(dirn, auth):\n    '''\n    Migrate old cell Auth() data into a HiveAuth().\n    '''\n    logger.warning('migrating old cell auth to hive')\n\n    path = os.path.join(dirn, 'auth.lmdb')\n\n    lenv = lmdb.open(path, max_dbs=128)\n\n    userdb = lenv.open_db(b'users')\n    roledb = lenv.open_db(b'roles')\n\n    migrated_roles = False\n    migrated_users = False\n\n    with lenv.begin() as xact:\n\n        with xact.cursor(db=roledb) as curs:\n\n            for lkey, lval in curs.iternext():\n\n                name = lkey.decode('utf8')\n                info = s_msgpack.un(lval)\n\n                logger.info(f'Migrating role: {name}')\n\n                role = auth.getRoleByName(name)\n                if role is None:\n                    logger.info(f'Creating role: {name}')\n                    role = await auth.addRole(name)\n\n                rules = info.get('rules', ())\n\n                await role.setRules(rules)\n\n                migrated_roles = True\n\n        if not migrated_roles:  # pragma: no cover\n            logger.info('No roles were migrated.')\n\n        with xact.cursor(db=userdb) as curs:\n\n            for lkey, lval in curs.iternext():\n\n                name = lkey.decode('utf8')\n                info = s_msgpack.un(lval)\n\n                logger.info(f'Migrating user: {name}')\n\n                user = auth.getUserByName(name)\n                if user is None:\n                    logger.info(f'Creating user: {name}')\n                    user = await auth.addUser(name)\n\n                if info.get('admin', False):\n                    await user.setAdmin(True)\n\n                if info.get('locked', False):\n                    await user.setLocked(True)\n\n                # set this directly since we only have the shadow\n                shadow = info.get('shadow')\n                if shadow is not None:\n                    await user.info.set('passwd', shadow)\n\n                rules = info.get('rules', ())\n                await user.setRules(rules)\n\n                for name in info.get('roles', ()):\n                    await user.grant(name)\n\n                migrated_users = True\n\n        if not migrated_users:  # pragma: no cover\n            logger.info('No users were migrated.')\n\n    lenv.sync()\n    lenv.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def wasSet(self, node, oldv):\n        '''\n        Fire the onset() handlers for this property.\n\n        Args:\n            node (synapse.lib.node.Node): The node whose property was set.\n            oldv (obj): The previous value of the property.\n        '''\n        for func in self.onsets:\n            try:\n                await s_coro.ornot(func, node, oldv)\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception('onset() error for %s' % (self.full,))", "response": "Fire the onset handlers for this property."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getDelOps(self, buid):\n        '''\n        Get a list of storage operations to delete this property from the buid.\n\n        Args:\n            buid (bytes): The node buid.\n\n        Returns:\n            (tuple): The storage operations\n        '''\n        return (\n            ('prop:del', (buid, self.form.name, self.name, self.storinfo)),\n        )", "response": "Get a list of storage operations to delete this property from the buid."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling when a node is added to the tree.", "response": "async def wasAdded(self, node):\n        '''\n        Fire the onAdd() callbacks for node creation.\n        '''\n        for func in self.onadds:\n            try:\n                retn = func(node)\n                if s_coro.iscoro(retn):\n                    await retn\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception('error on onadd for %s' % (self.name,))\n\n        await node.snap.core.triggers.runNodeAdd(node)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalls when a node is deleted.", "response": "async def wasDeleted(self, node):\n        '''\n        Fire the onDel() callbacks for node deletion.\n        '''\n        for func in self.ondels:\n            try:\n                retn = func(node)\n                if s_coro.iscoro(retn):\n                    await retn\n            except asyncio.CancelledError:\n                raise\n            except Exception:\n                logger.exception('error on ondel for %s' % (self.name,))\n\n        await node.snap.core.triggers.runNodeDel(node)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getLiftOps(self, valu, cmpr='='):\n        '''\n        Get a set of lift operations for use with an Xact.\n        '''\n        if valu is None:\n            iops = (('pref', b''),)\n            return (\n                ('indx', ('byprop', self.pref, iops)),\n            )\n\n        # TODO: In an ideal world, this would get smashed down into the self.type.getLiftOps\n        # but since doing so breaks existing types, and fixing those could cause a cascade\n        # of fun failures, we'll put this off until another flag day\n        if cmpr == '~=':\n            return (\n                ('form:re', (self.name, valu, {})),\n            )\n\n        lops = self.type.getLiftOps('form', cmpr, (None, self.name, valu))\n        if lops is not None:\n            return lops\n\n        iops = self.type.getIndxOps(valu, cmpr)\n        return (\n            ('indx', ('byprop', self.pref, iops)),\n        )", "response": "Get a set of lift operations for use with an Xact."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addDataModels(self, mods):\n        '''\n        Adds a model definition (same format as input to Model.addDataModels and output of Model.getModelDef).\n        '''\n        # Load all the universal properties\n        for _, mdef in mods:\n            for univname, _, _ in mdef.get('univs', ()):\n                self.addUnivName(univname)\n\n        # Load all the forms\n        for _, mdef in mods:\n            for formname, formopts, propdefs in mdef.get('forms', ()):\n\n                self.formnames.add(formname)\n                self.propnames.add(formname)\n\n                for univname in self.univnames:\n                    full = f'{formname}{univname}'\n                    self.propnames.add(full)\n\n                for propname, _, _ in propdefs:\n                    full = f'{formname}:{propname}'\n                    self.propnames.add(full)", "response": "Adds a model definition to the internal list of data models."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef addDataModels(self, mods):\n        '''\n        Add a list of (name, mdef) tuples.\n\n        A model definition (mdef) is structured as follows::\n\n            {\n                \"ctors\":(\n                    ('name', 'class.path.ctor', {}, {'doc': 'The foo thing.'}),\n                ),\n\n                \"types\":(\n                    ('name', ('basetype', {typeopts}), {info}),\n                ),\n\n                \"forms\":(\n                    (formname, (typename, typeopts), {info}, (\n                        (propname, (typename, typeopts), {info}),\n                    )),\n                ),\n                \"univs\":(\n                    (propname, (typename, typeopts), {info}),\n                )\n            }\n\n        Args:\n            mods (list):  The list of tuples.\n\n        Returns:\n            None\n\n        '''\n\n        # load all the base type ctors in order...\n        for modlname, mdef in mods:\n\n            for name, ctor, opts, info in mdef.get('ctors', ()):\n                item = s_dyndeps.tryDynFunc(ctor, self, name, info, opts)\n                self.types[name] = item\n                self._modeldef['ctors'].append((name, ctor, opts, info))\n\n        # load all the types in order...\n        for modlname, mdef in mods:\n\n            for typename, (basename, opts), info in mdef.get('types', ()):\n\n                base = self.types.get(basename)\n                if base is None:\n                    raise s_exc.NoSuchType(name=basename)\n\n                self.types[typename] = base.extend(typename, opts, info)\n                self._modeldef['types'].append((typename, (basename, opts), info))\n\n        # Load all the universal properties\n        for modlname, mdef in mods:\n            for univname, typedef, univinfo in mdef.get('univs', ()):\n                self.addUnivProp(univname, typedef, univinfo)\n\n        # now we can load all the forms...\n        for modlname, mdef in mods:\n\n            for formname, forminfo, propdefs in mdef.get('forms', ()):\n\n                if not s_syntax.isFormName(formname):\n                    mesg = f'Invalid form name {formname}'\n                    raise s_exc.BadFormDef(name=formname, mesg=mesg)\n\n                _type = self.types.get(formname)\n                if _type is None:\n                    raise s_exc.NoSuchType(name=formname)\n\n                self._modeldef['forms'].append((formname, forminfo, propdefs))\n\n                form = Form(self, formname, forminfo)\n\n                self.forms[formname] = form\n                self.props[formname] = form\n\n                for univname, typedef, univinfo in self.univs:\n                    self._addFormUniv(form, univname, typedef, univinfo)\n\n                for propdef in propdefs:\n\n                    if len(propdef) != 3:\n                        raise s_exc.BadPropDef(valu=propdef)\n\n                    propname, typedef, propinfo = propdef\n\n                    prop = Prop(self, form, propname, typedef, propinfo)\n\n                    full = f'{formname}:{propname}'\n                    self.props[full] = prop\n                    self.props[(formname, propname)] = prop\n\n        self._modelinfo.addDataModels(mods)", "response": "Adds a list of tuples."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a Type instance to the data model.", "response": "def addBaseType(self, item):\n        '''\n        Add a Type instance to the data model.\n        '''\n        ctor = '.'.join([item.__class__.__module__, item.__class__.__qualname__])\n        self._modeldef['ctors'].append(((item.name, ctor, dict(item.opts), dict(item.info))))\n        self.types[item.name] = item"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def listen(self, url, **opts):\n        '''\n        Bind and listen on the given host/port with possible SSL.\n\n        Args:\n            host (str): A hostname or IP address.\n            port (int): The TCP port to bind.\n        '''\n        info = s_urlhelp.chopurl(url, **opts)\n        info.update(opts)\n\n        scheme = info.get('scheme')\n\n        if scheme == 'unix':\n            path = info.get('path')\n            try:\n                server = await s_link.unixlisten(path, self._onLinkInit)\n            except Exception as e:\n                if 'path too long' in str(e):\n                    logger.error(f'unix:// exceeds OS supported UNIX socket path length: {path}')\n                raise\n\n        else:\n\n            host = info.get('host')\n            port = info.get('port')\n\n            sslctx = None\n            if scheme == 'ssl':\n                sslctx = self.certdir.getServerSSLContext(hostname=host)\n\n            server = await s_link.listen(host, port, self._onLinkInit, ssl=sslctx)\n\n        self.listenservers.append(server)\n        ret = server.sockets[0].getsockname()\n\n        if self.addr is None:\n            self.addr = ret\n\n        return ret", "response": "Bind and listen on the given url."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef share(self, name, item):\n        '''\n        Share an object via the telepath protocol.\n\n        Args:\n            name (str): Name of the shared object\n            item (object): The object to share over telepath.\n        '''\n\n        try:\n\n            if isinstance(item, s_telepath.Aware):\n                item.onTeleShare(self, name)\n\n            self.shared[name] = item\n\n        except Exception:\n            logger.exception(f'onTeleShare() error for: {name}')", "response": "Share an object via the telepath protocol."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _dayofmonth(hardday, month, year):\n    '''\n    Returns a valid day of the month given the desired value.\n\n    Negative values are interpreted as offset backwards from the last day of the month, with -1 representing the\n    last day of the month.  Out-of-range values are clamped to the first or last day of the month.\n    '''\n    newday = hardday\n    daysinmonth = calendar.monthrange(year, month)[1]\n    if newday < 0:\n        newday = daysinmonth + hardday + 1\n    newday = max(1, min(newday, daysinmonth))\n    return newday", "response": "Returns a valid day of the month given the desired value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack(self):\n        '''\n        Make ApptRec json/msgpack-friendly\n        '''\n        reqdictf = {k.name.lower(): v for (k, v) in self.reqdict.items()}\n        incunitf = None if self.incunit is None else self.incunit.name.lower()\n        return (reqdictf, incunitf, self.incval)", "response": "Make ApptRec json / msgpack - friendly\n       "}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting from json / msgpack - friendly to a new object.", "response": "def unpack(cls, val):\n        '''\n        Convert from json/msgpack-friendly\n        '''\n        reqdictf, incunitf, incval = val\n        reqdict = {TimeUnit[k.upper()]: v for (k, v) in reqdictf.items()}\n        incunit = None if incunitf is None else TimeUnit[incunitf.upper()]\n        return cls(reqdict, incunit, incval)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef nexttime(self, lastts):\n        '''\n        Returns next timestamp that meets requirements, incrementing by (self.incunit * incval) if not increasing, or\n        0.0 if there are no future matches\n        '''\n        lastdt = datetime.datetime.fromtimestamp(lastts, tz.utc)\n        newvals = {}  # all the new fields that will be changed in datetime of lastts\n\n        # Truncate the seconds part\n        newdt = lastdt.replace(second=0)\n\n        for unit, newval in self.reqdict.items():\n            dtkey = _TimeunitToDatetime[unit]\n            if unit is TimeUnit.DAYOFWEEK:\n                newdt = newdt.replace(**newvals)\n                newvals = {}\n                newval = newdt.day + (6 + newval - newdt.weekday()) % 7 + 1\n                if newval > calendar.monthrange(newdt.year, newdt.month)[1]:\n                    newval -= 7\n            elif unit is TimeUnit.MONTH:\n                # As we change the month, clamp the day of the month to a valid value\n                newdt = newdt.replace(**newvals)\n                newvals = {}\n                dayval = _dayofmonth(newdt.day, newval, newdt.year)\n                newvals['day'] = dayval\n            elif unit is TimeUnit.DAYOFMONTH:\n                newdt = newdt.replace(**newvals)\n                newvals = {}\n                newval = _dayofmonth(newval, newdt.month, newdt.year)\n\n            newvals[dtkey] = newval\n\n        newdt = newdt.replace(**newvals)\n\n        # Then move forward if we have to\n        if newdt <= lastdt or \\\n                self.incunit == TimeUnit.DAYOFWEEK and newdt.weekday() != self.incval:\n            if self.incunit is None:\n                largest_req = min(self.reqdict.keys())\n                tmpunit = _NextUnitMap[largest_req]\n                if tmpunit is None:  # required a year and we're already there\n                    return 0.0\n                # Unless we're going to the next day of week, increment by 1 unit of the next larger unit\n                tmpincval = self.reqdict.get(TimeUnit.DAYOFWEEK, 1)\n            else:\n                tmpunit = self.incunit\n                tmpincval = self.incval\n            newdt = self._inc(tmpunit, tmpincval, self.reqdict, lastdt, newdt)\n            assert newdt > lastdt\n        return newdt.timestamp()", "response": "Returns the next time that meets the requirements and incrementing by incval."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _inc(self, incunit, incval, reqdict, origdt, dt):\n        '''\n        Return a datetime incremented by incunit * incval\n        '''\n        if incunit == TimeUnit.YEAR:\n            return dt.replace(year=dt.year + incval)\n        if incunit == TimeUnit.MONTH:\n            newyear = dt.year\n            absmonth = dt.month + incval - 1\n            newmonth = absmonth % 12 + 1\n            newyear += absmonth // 12\n            daysinmonth = calendar.monthrange(newyear, newmonth)[1]\n            dayofmonthreq = reqdict.get(TimeUnit.DAYOFMONTH)\n            if dayofmonthreq is not None:\n                newday = _dayofmonth(dayofmonthreq, newmonth, newyear)\n            else:\n                newday = min(daysinmonth, dt.day)\n            return dt.replace(day=newday, month=newmonth, year=newyear)\n        if incunit == TimeUnit.DAY:\n            return dt + datetime.timedelta(days=incval)\n        if incunit == TimeUnit.DAYOFWEEK:\n            # incval in this case means next day of week whose weekday matches incval (0-6)\n            days = (6 + incval - dt.weekday()) % 7 + 1\n            newdt = dt + datetime.timedelta(days=days)\n            assert newdt.weekday() == incval\n            return newdt\n        if incunit == TimeUnit.HOUR:\n            return dt + datetime.timedelta(hours=incval)\n        if incunit == TimeUnit.MINUTE:\n            return dt + datetime.timedelta(minutes=incval)\n        else:\n            assert 0, 'Invalid incunit'", "response": "Return a datetime incremented by incval."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef updateNexttime(self, now):\n        '''\n        Find the next time this appointment should be scheduled.\n\n        Delete any nonrecurring record that just happened.\n        '''\n        if self._recidxnexttime is not None and not self.recur:\n            del self.recs[self._recidxnexttime]\n\n        while self.recs and self.nexttime <= now:\n\n            lowtime = 999999999999.9\n\n            # Find the lowest next time of all of our recs (backwards, so we can delete)\n            for i in range(len(self.recs) - 1, -1, -1):\n                rec = self.recs[i]\n                nexttime = rec.nexttime(self.nexttime)\n                if nexttime == 0.0:\n                    # We blew by and missed a fixed-year appointment, either due to clock shenanigans, this query going\n                    # really long, or the initial requirement being in the past\n                    logger.warning(f'Missed an appointment: {rec}')\n                    del self.recs[i]\n                    continue\n                if nexttime < lowtime:\n                    lowtime = nexttime\n                    lowidx = i\n\n            if not self.recs:\n                break\n\n            self._recidxnexttime = lowidx\n            self.nexttime = lowtime\n\n        if not self.recs:\n            self._recidxnexttime = None\n            self.nexttime = None\n            return", "response": "Update the next time of the next appointment."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def enable(self):\n        '''\n        Enable cron jobs to start running, start the scheduler loop\n\n        Go through all the appointments, making sure the query is valid, and remove the ones that aren't.  (We can't\n        evaluate queries until enabled because not all the modules are loaded yet.)\n        '''\n        if self.enabled:\n            return\n\n        to_delete = []\n        for iden, appt in self.appts.items():\n            try:\n                self.core.getStormQuery(appt.query)\n            except Exception as e:\n                logger.warning('Invalid appointment %r found in storage: %r.  Disabling.', iden, e)\n                appt.enabled = False\n\n        for iden in to_delete:\n            await self.delete(iden)\n\n        self._schedtask = self.schedCoro(self._scheduleLoop())\n        self.enabled = True", "response": "Enable the scheduler loop for all the appointments that match the query."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _load_all(self):\n        '''\n        Load all the appointments from persistent storage\n        '''\n        to_delete = []\n        for iden, val in self._hivedict.items():\n            try:\n                appt = _Appt.unpack(val)\n                if appt.iden != iden:\n                    raise s_exc.InconsistentStorage(mesg='iden inconsistency')\n                self._addappt(iden, appt)\n                self._next_indx = max(self._next_indx, appt.indx + 1)\n            except (s_exc.InconsistentStorage, s_exc.BadStorageVersion, s_exc.BadTime, TypeError, KeyError,\n                    UnicodeDecodeError) as e:\n                logger.warning('Invalid appointment %r found in storage: %r.  Removing.', iden, e)\n                to_delete.append(iden)\n                continue\n\n        for iden in to_delete:\n            await self._hivedict.pop(iden)\n\n        # Make sure we don't assign the same index to 2 appointments\n        if self.appts:\n            maxindx = max(appt.indx for appt in self.appts.values())\n            self._next_indx = maxindx + 1", "response": "Load all the appointments from persistent storage."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding an appointment to the internal list of appointments.", "response": "def _addappt(self, iden, appt):\n        '''\n        Updates the data structures to add an appointment\n        '''\n        if appt.nexttime:\n            heapq.heappush(self.apptheap, appt)\n        self.appts[iden] = appt\n        if self.apptheap and self.apptheap[0] is appt:\n            self._wake_event.set()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nstore a single appointment in the cache.", "response": "async def _storeAppt(self, appt):\n        ''' Store a single appointment '''\n        await self._hivedict.set(appt.iden, appt.pack())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nyield a series of dicts that cover all multiple - value values remaining the same.", "response": "def _dictproduct(rdict):\n        '''\n        Yields a series of dicts that cover the combination of all multiple-value (e.g. lists or tuples) values, with\n        non-multiple-value values remaining the same.\n        '''\n        multkeys = [k for k, v in rdict.items() if isinstance(v, Iterable)]\n        if not multkeys:\n            yield rdict\n            return\n\n        multvals = [rdict[k] for k in multkeys]\n\n        for combo in itertools.product(*multvals):\n            newdict = rdict.copy()\n            for i, k in enumerate(multkeys):\n                newdict[k] = combo[i]\n            yield newdict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd an appointment to the appointment store.", "response": "async def add(self, useriden, query: str, reqs, incunit=None, incvals=None):\n        '''\n        Persistently adds an appointment\n\n        Args:\n            query (str):\n                storm query to run\n            reqs (Union[None, Dict[TimeUnit, Union[int, Tuple[int]], List[...]):\n                one or more dicts of the fixed aspects of the appointment.  dict value may be a single or multiple.\n                May be an empty dict or None.\n            incunit (Union[None, TimeUnit]):\n                the unit that changes for recurring, or None for non-recurring.  It is an error for this value to match\n                a key in reqdict.\n            incvals (Union[None, int, Iterable[int]): count of units of incunit or explicit day of week or day of month.\n                Not allowed for incunit == None, required for others (1 would be a typical\n                value)\n\n        Notes:\n            For values in reqs that are lists and incvals if a list, all combinations of all values (the product) are\n            used\n\n        Returns:\n            iden of new appointment\n        '''\n        iden = s_common.guid()\n        recur = incunit is not None\n        indx = self._next_indx\n        self._next_indx += 1\n\n        if reqs is None:\n            reqs = {}\n\n        if not query:\n            raise ValueError('empty query')\n\n        if not reqs and incunit is None:\n            raise ValueError('at least one of reqs and incunit must be non-empty')\n\n        if incunit is not None and incvals is None:\n            raise ValueError('incvals must be non-None if incunit is non-None')\n\n        if isinstance(reqs, Mapping):\n            reqs = [reqs]\n\n        # Find all combinations of values in reqdict values and incvals values\n        recs = []\n        for req in reqs:\n\n            reqdicts = self._dictproduct(req)\n            if not isinstance(incvals, Iterable):\n                incvals = (incvals, )\n            recs.extend(ApptRec(rd, incunit, v) for (rd, v) in itertools.product(reqdicts, incvals))\n\n        appt = _Appt(iden, recur, indx, query, useriden, recs)\n        self._addappt(iden, appt)\n\n        await self._storeAppt(appt)\n\n        return iden"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def mod(self, iden, query):\n        '''\n        Change the query of an appointment\n        '''\n        appt = self.appts.get(iden)\n        if appt is None:\n            raise s_exc.NoSuchIden()\n\n        if not query:\n            raise ValueError('empty query')\n\n        if self.enabled:\n            self.core.getStormQuery(query)\n\n        appt.query = query\n        appt.enabled = True  # in case it was disabled for a bad query\n\n        await self._storeAppt(appt)", "response": "Change the query of an appointment"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def delete(self, iden):\n        '''\n        Delete an appointment\n        '''\n        appt = self.appts.get(iden)\n        if appt is None:\n            raise s_exc.NoSuchIden()\n\n        try:\n            heappos = self.apptheap.index(appt)\n        except ValueError:\n            pass  # this is OK, just a non-recurring appt that has no more records\n        else:\n            # If we're already the last item, just delete it\n            if heappos == len(self.apptheap) - 1:\n                del self.apptheap[heappos]\n            else:\n                # put the last item at the current position and reheap\n                self.apptheap[heappos] = self.apptheap.pop()\n                heapq.heapify(self.apptheap)\n\n        del self.appts[iden]\n        await self._hivedict.pop(iden)", "response": "Delete an appointment with the given iden."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ntasks loop to issue query tasks at the right times.", "response": "async def _scheduleLoop(self):\n        '''\n        Task loop to issue query tasks at the right times.\n        '''\n        while True:\n            try:\n                timeout = None if not self.apptheap else self.apptheap[0].nexttime - time.time()\n                if timeout is None or timeout >= 0.0:\n                    await asyncio.wait_for(self._wake_event.wait(), timeout=timeout)\n            except asyncio.TimeoutError:\n                pass\n            if self.isfini:\n                return\n            self._wake_event.clear()\n\n            now = time.time()\n            while self.apptheap and self.apptheap[0].nexttime <= now:\n                appt = heapq.heappop(self.apptheap)\n                appt.updateNexttime(now)\n                if appt.nexttime:\n                    heapq.heappush(self.apptheap, appt)\n                if not appt.enabled:\n                    continue\n                if appt.isrunning:\n                    logger.warning(\n                        'Appointment %s is still running from previous time when scheduled to run.  Skipping.',\n                        appt.iden)\n                else:\n                    await self._execute(appt)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def _execute(self, appt):\n        '''\n        Fire off the task to make the storm query\n        '''\n        user = self.core.auth.user(appt.useriden)\n        if user is None:\n            logger.warning('Unknown user %s in stored appointment', appt.useriden)\n            await self._markfailed(appt)\n            return\n        await self.core.boss.execute(self._runJob(user, appt), f'Agenda {appt.iden}', user)", "response": "Fire off the task to make the storm query"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(name, defval=None):\n    '''\n    Return an object from the embedded synapse data folder.\n\n    Example:\n\n        for tld in syanpse.data.get('iana.tlds'):\n            dostuff(tld)\n\n    NOTE: Files are named synapse/data/<name>.mpk\n    '''\n    with s_datfile.openDatFile('synapse.data/%s.mpk' % name) as fd:\n        return s_msgpack.un(fd.read())", "response": "Return an object from the embedded synapse data folder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the valu of a given property on the node.", "response": "def prop(pode, prop):\n    '''\n    Return the valu of a given property on the node.\n\n    Args:\n        pode (tuple): A packed node.\n        prop (str): Property to retrieve.\n\n    Notes:\n        The prop argument may be the full property name (foo:bar:baz), relative property name (:baz) , or the unadorned\n        property name (baz).\n\n    Returns:\n\n    '''\n    form = pode[0][0]\n    if prop.startswith(form):\n        prop = prop[len(form):]\n    if prop[0] == ':':\n        prop = prop[1:]\n    return pode[1]['props'].get(prop)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of all the tags for a given node.", "response": "def tags(pode, leaf=False):\n    '''\n    Get all the tags for a given node.\n\n    Args:\n        pode (tuple): A packed node.\n        leaf (bool): If True, only return the full tags.\n\n    Returns:\n        list: A list of tag strings.\n    '''\n    fulltags = [tag for tag in pode[1]['tags']]\n    if not leaf:\n        return fulltags\n\n    # longest first\n    retn = []\n\n    # brute force rather than build a tree.  faster in small sets.\n    for size, tag in sorted([(len(t), t) for t in fulltags], reverse=True):\n        look = tag + '.'\n        if any([r.startswith(look) for r in retn]):\n            continue\n        retn.append(tag)\n    return retn"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef tagged(pode, tag):\n    '''\n    Check if a packed node has a given tag.\n\n    Args:\n        pode (tuple): A packed node.\n        tag (str): The tag to check.\n\n    Examples:\n        Check if a node is tagged with \"woot\" and dostuff if it is.\n\n            if s_node.tagged(node,'woot'):\n                dostuff()\n\n    Notes:\n        If the tag starts with `#`, this is removed prior to checking.\n\n    Returns:\n        bool: True if the tag is present. False otherwise.\n    '''\n    if tag.startswith('#'):\n        tag = tag[1:]\n    return pode[1]['tags'].get(tag) is not None", "response": "Check if a packed node has a given tag."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nyielding the storm of the given text.", "response": "async def storm(self, text, opts=None, user=None, path=None):\n        '''\n        Args:\n            path (Path):\n                If set, then vars from path are copied into the new runtime, and vars are copied back out into path\n                at the end\n\n        Note:\n            If opts is not None and opts['vars'] is set and path is not None, then values of path vars take precedent\n        '''\n        query = self.snap.core.getStormQuery(text)\n\n        # Merge vars from path into opts.vars\n        pathvars = path.vars if path is not None else None\n        if opts is None:\n            if pathvars is None:\n                newopts = None\n            else:\n                newopts = {'vars': pathvars}\n        else:\n            vars = opts.get('vars')\n            if pathvars is None:\n                newopts = opts\n            elif vars is None:\n                newopts = {**opts, **{'vars': pathvars}}\n            else:\n                newopts = {**opts, **{'vars': {**vars, **pathvars}}}\n\n        with self.snap.getStormRuntime(opts=newopts, user=user) as runt:\n            runt.addInput(self)\n            async for item in runt.iterStormQuery(query):\n                yield item\n            if path:\n                path.vars.update(runt.vars)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pack(self, dorepr=False):\n        '''\n        Return the serializable/packed version of the node.\n\n        Returns:\n            (tuple): An (iden, info) node tuple.\n        '''\n        node = (self.ndef, {\n            'iden': self.iden(),\n            'tags': self.tags,\n            'props': self.props,\n        })\n\n        if dorepr:\n            node[1]['repr'] = self.repr()\n            node[1]['reprs'] = self.reprs()\n\n        return node", "response": "Return the serializable version of the node."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nupdates the. seen interval and optionally a source specific seen node.", "response": "async def seen(self, tick, source=None):\n        '''\n        Update the .seen interval and optionally a source specific seen node.\n        '''\n        await self.set('.seen', tick)\n\n        if source is not None:\n            seen = await self.snap.addNode('meta:seen', (source, self.ndef))\n            await seen.set('.seen', tick)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getNodeRefs(self):\n        '''\n        Return a list of (prop, (form, valu)) refs out for the node.\n        '''\n        retn = []\n\n        for name, valu in self.props.items():\n\n            pobj = self.form.props.get(name)\n\n            if isinstance(pobj.type, s_types.Ndef):\n                retn.append((name, valu))\n                continue\n\n            if self.snap.model.forms.get(pobj.type.name) is None:\n                continue\n\n            ndef = (pobj.type.name, valu)\n            if ndef == self.ndef:\n                continue\n\n            retn.append((name, ndef))\n\n        return retn", "response": "Return a list of ( prop form valu ) refs out for the node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a property on the node.", "response": "async def set(self, name, valu, init=False):\n        '''\n        Set a property on the node.\n\n        Args:\n            name (str): The name of the property.\n            valu (obj): The value of the property.\n            init (bool): Set to True to disable read-only enforcement\n\n        Returns:\n            (bool): True if the property was changed.\n        '''\n        with s_editatom.EditAtom(self.snap.core.bldgbuids) as editatom:\n            retn = await self._setops(name, valu, editatom, init)\n            if not retn:\n                return False\n            await editatom.commit(self.snap)\n            return True"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def _setops(self, name, valu, editatom, init=False):\n        '''\n        Generate operations to set a property on a node.\n        '''\n        prop = self.form.prop(name)\n        if prop is None:\n\n            if self.snap.strict:\n                raise s_exc.NoSuchProp(name=name)\n\n            await self.snap.warn(f'NoSuchProp: name={name}')\n            return False\n\n        if self.isrunt:\n            if prop.info.get('ro'):\n                raise s_exc.IsRuntForm(mesg='Cannot set read-only props on runt nodes',\n                                       form=self.form.full, prop=name, valu=valu)\n            return await self.snap.core.runRuntPropSet(self, prop, valu)\n\n        curv = self.props.get(name)\n\n        # normalize the property value...\n        try:\n            norm, info = prop.type.norm(valu)\n\n        except Exception as e:\n            mesg = f'Bad property value: {prop.full}={valu!r}'\n            return await self.snap._raiseOnStrict(s_exc.BadPropValu, mesg, name=prop.name, valu=valu, emesg=str(e))\n\n        # do we already have the value?\n        if curv == norm:\n            return False\n\n        if curv is not None and not init:\n\n            if prop.info.get('ro'):\n\n                if self.snap.strict:\n                    raise s_exc.ReadOnlyProp(name=prop.full)\n\n                # not setting a set-once prop unless we are init...\n                await self.snap.warn(f'ReadOnlyProp: name={prop.full}')\n                return False\n\n            # check for type specific merging...\n            norm = prop.type.merge(curv, norm)\n            if curv == norm:\n                return False\n\n        sops = prop.getSetOps(self.buid, norm)\n\n        editatom.sops.extend(sops)\n\n        # self.props[prop.name] = norm\n        editatom.npvs.append((self, prop, curv, norm))\n\n        # do we have any auto nodes to add?\n        auto = self.snap.model.form(prop.type.name)\n        if auto is not None:\n            buid = s_common.buid((auto.name, norm))\n            await self.snap._addNodeFnibOps((auto, norm, info, buid), editatom)\n\n        # does the type think we have special auto nodes to add?\n        # ( used only for adds which do not meet the above block )\n        for autoname, autovalu in info.get('adds', ()):\n            auto = self.snap.model.form(autoname)\n            autonorm, autoinfo = auto.type.norm(autovalu)\n            buid = s_common.buid((auto.name, autonorm))\n            await self.snap._addNodeFnibOps((auto, autovalu, autoinfo, buid), editatom)\n\n        # do we need to set any sub props?\n        subs = info.get('subs')\n        if subs is not None:\n\n            for subname, subvalu in subs.items():\n\n                full = prop.name + ':' + subname\n\n                subprop = self.form.prop(full)\n                if subprop is None:\n                    continue\n\n                await self._setops(full, subvalu, editatom, init=init)\n\n        return True", "response": "Generate operations to set a property on a runt node."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, name):\n        '''\n        Return a secondary property value from the Node.\n\n        Args:\n            name (str): The name of a secondary property.\n\n        Returns:\n            (obj): The secondary property value or None.\n        '''\n        if name.startswith('#'):\n            return self.tags.get(name[1:])\n        return self.props.get(name)", "response": "Return a secondary property value from the Node."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving a property from a node and return the value.", "response": "async def pop(self, name, init=False):\n        '''\n        Remove a property from a node and return the value\n        '''\n        prop = self.form.prop(name)\n        if prop is None:\n            if self.snap.strict:\n                raise s_exc.NoSuchProp(name=name)\n            await self.snap.warn(f'No Such Property: {name}')\n            return False\n\n        if self.isrunt:\n            if prop.info.get('ro'):\n                raise s_exc.IsRuntForm(mesg='Cannot delete read-only props on runt nodes',\n                                       form=self.form.full, prop=name)\n            return await self.snap.core.runRuntPropDel(self, prop)\n\n        if not init:\n\n            if prop.info.get('ro'):\n                if self.snap.strict:\n                    raise s_exc.ReadOnlyProp(name=name)\n                await self.snap.warn(f'Property is read-only: {name}')\n                return False\n\n        curv = self.props.pop(name, s_common.novalu)\n        if curv is s_common.novalu:\n            return False\n\n        sops = prop.getDelOps(self.buid)\n        splice = self.snap.splice('prop:del', ndef=self.ndef, prop=prop.name, valu=curv)\n        await self.snap.stor(sops, [splice])\n\n        await prop.wasDel(self, curv)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def delTag(self, tag, init=False):\n        '''\n        Delete a tag from the node.\n        '''\n        path = s_chop.tagpath(tag)\n\n        name = '.'.join(path)\n\n        if self.isrunt:\n            raise s_exc.IsRuntForm(mesg='Cannot delete tags from runt nodes.',\n                                   form=self.form.full, tag=tag)\n\n        curv = self.tags.pop(name, s_common.novalu)\n        if curv is s_common.novalu:\n            return False\n\n        pref = name + '.'\n\n        subtags = [(len(t), t) for t in self.tags.keys() if t.startswith(pref)]\n        subtags.sort(reverse=True)\n\n        removed = []\n\n        for sublen, subtag in subtags:\n            valu = self.tags.pop(subtag, None)\n            removed.append((subtag, valu))\n\n        removed.append((name, curv))\n\n        info = {'univ': True}\n        sops = [('prop:del', (self.buid, self.form.name, '#' + t, info)) for (t, v) in removed]\n\n        # fire all the splices\n        splices = [self.snap.splice('tag:del', ndef=self.ndef, tag=t, valu=v) for (t, v) in removed]\n        await self.snap.stor(sops, splices)\n\n        # fire all the handlers / triggers\n        [await self.snap.core.runTagDel(self, t, v) for (t, v) in removed]", "response": "Delete a tag from the node."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def delete(self, force=False):\n        '''\n        Delete a node from the cortex.\n\n        The following tear-down operations occur in order:\n\n            * validate that you have permissions to delete the node\n            * validate that you have permissions to delete all tags\n            * validate that there are no remaining references to the node.\n\n            * delete all the tags (bottom up)\n                * fire onDelTag() handlers\n                * delete tag properties from storage\n                * log tag:del splices\n\n            * delete all secondary properties\n                * fire onDelProp handler\n                * delete secondary property from storage\n                * log prop:del splices\n\n            * delete the primary property\n                * fire onDel handlers for the node\n                * delete primary property from storage\n                * log node:del splices\n        '''\n\n        formname, formvalu = self.ndef\n\n        if self.isrunt:\n            raise s_exc.IsRuntForm(mesg='Cannot delete runt nodes',\n                                   form=formname, valu=formvalu)\n\n        tags = [(len(t), t) for t in self.tags.keys()]\n\n        # check for tag permissions\n        # TODO\n\n        # check for any nodes which reference us...\n        if not force:\n\n            # refuse to delete tag nodes with existing tags\n            if self.form.name == 'syn:tag':\n\n                async for _ in self.snap._getNodesByTag(self.ndef[1]):  # NOQA\n                    mesg = 'Nodes still have this tag.'\n                    return await self.snap._raiseOnStrict(s_exc.CantDelNode, mesg, form=formname)\n\n            async for refr in self.snap._getNodesByType(formname, formvalu, addform=False):\n\n                if refr.buid == self.buid:\n                    continue\n\n                mesg = 'Other nodes still refer to this node.'\n                return await self.snap._raiseOnStrict(s_exc.CantDelNode, mesg, form=formname)\n\n        for size, tag in sorted(tags, reverse=True):\n            await self.delTag(tag, init=True)\n\n        for name in list(self.props.keys()):\n            await self.pop(name, init=True)\n\n        sops = self.form.getDelOps(self.buid)\n\n        splice = self.snap.splice('node:del', ndef=self.ndef)\n        await self.snap.stor(sops, [splice])\n\n        self.snap.livenodes.pop(self.buid)\n        self.snap.core.pokeFormCount(formname, -1)\n\n        await self.form.wasDeleted(self)", "response": "Delete a node from the cortex."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a regular expression string with ** and * interpreted as tag globs", "response": "def regexizeTagGlob(tag):\n    '''\n    Returns:\n        a regular expression string with ** and * interpreted as tag globs\n\n    Precondition:\n        tag is a valid tagmatch\n\n    Notes:\n        A single asterisk will replace exactly one dot-delimited component of a tag\n        A double asterisk will replace one or more of any character.\n\n        The returned string does not contain a starting '^' or trailing '$'.\n    '''\n    return ReRegex.sub(lambda m: r'[^.]+?' if m.group(1) is None else r'.+', regex.escape(tag))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a key from the cache.", "response": "def get(self, key, default=None):\n        '''\n        Note:  we override default impl from parent to avoid costly KeyError\n        '''\n        valu = self.data.get(key, default)\n        if key in self.data:\n            self.data.move_to_end(key)\n        return valu"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the base and base hash of the given index value.", "response": "def _getIndxChop(self, indx):\n        '''\n        A helper method for Type subclasses to use for a simple way to truncate\n        indx bytes.\n        '''\n        # cut down an index value to 256 bytes...\n        if len(indx) <= 256:\n            return indx\n\n        base = indx[:248]\n        sufx = xxhash.xxh64(indx).digest()\n        return base + sufx"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef cmpr(self, val1, name, val2):\n        '''\n        Compare the two values using the given type specific comparator.\n        '''\n        ctor = self.getCmprCtor(name)\n        if ctor is None:\n            raise s_exc.NoSuchCmpr(cmpr=name, name=self.name)\n\n        norm1 = self.norm(val1)[0]\n        norm2 = self.norm(val2)[0]\n\n        return ctor(norm2)(norm1)", "response": "Compare the two values using the given type specific comparator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes the value for a given type.", "response": "def norm(self, valu):\n        '''\n        Normalize the value for a given type.\n\n        Args:\n            valu (obj): The value to normalize.\n\n        Returns:\n            ((obj,dict)): The normalized valu, info tuple.\n\n        Notes:\n            The info dictionary uses the following key conventions:\n                subs (dict): The normalized sub-fields as name: valu entries.\n        '''\n        func = self._type_norms.get(type(valu))\n        if func is None:\n            raise s_exc.NoSuchFunc(name=self.name, mesg='no norm for type: %r' % (type(valu),))\n\n        return func(valu)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the index bytes for the given normalized value.", "response": "def indx(self, norm):\n        '''\n        Return the property index bytes for the given *normalized* value.\n        '''\n        name = self.__class__.__name__\n        raise s_exc.NoSuchImpl(name='%s.indx' % name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextends this type to construct a new sub - type.", "response": "def extend(self, name, opts, info):\n        '''\n        Extend this type to construct a sub-type.\n\n        Args:\n            name (str): The name of the new sub-type.\n            opts (dict): The type options for the sub-type.\n            info (dict): The type info for the sub-type.\n\n        Returns:\n            (synapse.types.Type): A new sub-type instance.\n        '''\n        tifo = self.info.copy()\n        tifo.update(info)\n\n        topt = self.opts.copy()\n        topt.update(opts)\n\n        tobj = self.__class__(self.modl, name, tifo, topt)\n        tobj.subof = self.name\n        return tobj"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a new instance of this type with the specified options.", "response": "def clone(self, opts):\n        '''\n        Create a new instance of this type with the specified options.\n\n        Args:\n            opts (dict): The type specific options for the new instance.\n        '''\n        topt = self.opts.copy()\n        topt.update(opts)\n        return self.__class__(self.modl, self.name, self.info, topt)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a list of index operations to lift values in a table.", "response": "def getIndxOps(self, valu, cmpr='='):\n        '''\n        Return a list of index operation tuples to lift values in a table.\n\n        Valid index operations include:\n            ('eq', <indx>)\n            ('pref', <indx>)\n            ('range', (<minindx>, <maxindx>))\n        '''\n        func = self.indxcmpr.get(cmpr)\n\n        if func is None:\n            raise s_exc.NoSuchCmpr(name=self.name, cmpr=cmpr)\n\n        return func(valu)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getTickTock(self, vals):\n        '''\n        Get a tick, tock time pair.\n\n        Args:\n            vals (list): A pair of values to norm.\n\n        Returns:\n            (int, int): A ordered pair of integers.\n        '''\n        val0, val1 = vals\n\n        try:\n            _tick = self._getLiftValu(val0)\n        except ValueError as e:\n            raise s_exc.BadTypeValu(name=self.name, valu=val0,\n                                    mesg='Unable to process the value for val0 in getTickTock.')\n\n        sortval = False\n        if isinstance(val1, str):\n            if val1.startswith(('+-', '-+')):\n                sortval = True\n                delt = s_time.delta(val1[2:])\n                # order matters\n                _tock = _tick + delt\n                _tick = _tick - delt\n            elif val1.startswith('-'):\n                sortval = True\n                _tock = self._getLiftValu(val1, relto=_tick)\n            else:\n                _tock = self._getLiftValu(val1, relto=_tick)\n        else:\n            _tock = self._getLiftValu(val1, relto=_tick)\n\n        if sortval and _tick >= _tock:\n            tick = min(_tick, _tock)\n            tock = max(_tick, _tock)\n            return tick, tock\n\n        return _tick, _tock", "response": "Get a tick tock time pair."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef indxByRange(self, valu):\n        '''\n        Override default ``*range=`` handler to account for relative computation.\n        '''\n\n        if not isinstance(valu, (list, tuple)):\n            raise s_exc.BadCmprValu(valu=valu, cmpr='*range=')\n\n        if len(valu) != 2:\n            raise s_exc.BadCmprValu(valu=valu, cmpr='*range=')\n\n        tick, tock = self.getTickTock(valu)\n\n        if tick > tock:\n            # User input has requested a nullset\n            return ()\n\n        return self._indxTimeRange(tick, tock)", "response": "Return the index of the first occurrence of a set of entries in the specified time range."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _ctorCmprRange(self, vals):\n        '''\n        Override default *range= handler to account for relative computation.\n        '''\n\n        if not isinstance(vals, (list, tuple)):\n            raise s_exc.BadCmprValu(valu=vals, cmpr='*range=')\n\n        if len(vals) != 2:\n            raise s_exc.BadCmprValu(valu=vals, cmpr='*range=')\n\n        tick, tock = self.getTickTock(vals)\n\n        if tick > tock:\n            # User input has requested a nullset\n            def cmpr(valu):\n                return False\n\n            return cmpr\n\n        def cmpr(valu):\n            return tick <= valu <= tock\n\n        return cmpr", "response": "Override default range = handler to account for relative computation."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlistens on the given host and fire onlink. onlink is a function that takes a Link and a coroutine that will fire the listening sockets.", "response": "async def listen(host, port, onlink, ssl=None):\n    '''\n    Listen on the given host/port and fire onlink(Link).\n\n    Returns a server object that contains the listening sockets\n    '''\n    async def onconn(reader, writer):\n        link = await Link.anit(reader, writer)\n        link.schedCoro(onlink(link))\n\n    server = await asyncio.start_server(onconn, host=host, port=port, ssl=ssl)\n    return server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nstarts an PF_UNIX server listening on the given path.", "response": "async def unixlisten(path, onlink):\n    '''\n    Start an PF_UNIX server listening on the given path.\n    '''\n    info = {'path': path, 'unix': True}\n    async def onconn(reader, writer):\n        link = await Link.anit(reader, writer, info=info)\n        link.schedCoro(onlink(link))\n    return await asyncio.start_unix_server(onconn, path=path)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def unixconnect(path):\n    '''\n    Connect to a PF_UNIX server listening on the given path.\n    '''\n    reader, writer = await asyncio.open_unix_connection(path=path)\n    info = {'path': path, 'unix': True}\n    return await Link.anit(reader, writer, info=info)", "response": "Connect to a PF_UNIX server listening on the given path."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def tx(self, mesg):\n        '''\n        Async transmit routine which will wait for writer drain().\n        '''\n        if self.isfini:\n            raise s_exc.IsFini()\n\n        byts = s_msgpack.en(mesg)\n        try:\n\n            self.writer.write(byts)\n\n            # Avoid Python bug.  See https://bugs.python.org/issue29930\n            async with self._drain_lock:\n                await self.writer.drain()\n\n        except Exception as e:\n\n            await self.fini()\n\n            einfo = s_common.retnexc(e)\n            logger.debug('link.tx connection trouble %s', einfo)\n\n            raise", "response": "Async transmit routine which will wait for writer drain."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sibling(self, offs=1):\n        '''\n        Return sibling node by relative offset from self.\n        '''\n        indx = self.pindex + offs\n\n        if indx < 0:\n            return None\n\n        if indx >= len(self.parent.kids):\n            return None\n\n        return self.parent.kids[indx]", "response": "Return sibling node by relative offset from self. pindex"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nyield the rightward siblings until None.", "response": "def iterright(self):\n        '''\n        Yield \"rightward\" siblings until None.\n        '''\n        offs = 1\n        while True:\n\n            sibl = self.sibling(offs)\n            if sibl is None:\n                break\n\n            yield sibl\n            offs += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nexecuting a coroutine function in the executor pool.", "response": "def executor(func, *args, **kwargs):\n    '''\n    Execute a non-coroutine function in the ioloop executor pool.\n\n    Args:\n        func: Function to execute.\n        *args: Args for the function.\n        **kwargs: Kwargs for the function.\n\n    Examples:\n\n        Execute a blocking API call in the executor pool::\n\n            import requests\n\n            def block(url, params=None):\n                return requests.get(url, params=params).json()\n\n            fut = s_coro.executor(block, 'http://some.tld/thign')\n            resp = await fut\n\n    Returns:\n        asyncio.Future: An asyncio future.\n    '''\n\n    def real():\n        return func(*args, **kwargs)\n\n    return asyncio.get_running_loop().run_in_executor(None, real)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwaiting on an asyncio event with an optional timeout Returns True if the event got set False otherwise", "response": "async def event_wait(event: asyncio.Event, timeout=None):\n    '''\n    Wait on an an asyncio event with an optional timeout\n\n    Returns:\n        true if the event got set, None if timed out\n    '''\n    if timeout is None:\n        await event.wait()\n        return True\n\n    try:\n        await asyncio.wait_for(event.wait(), timeout)\n    except asyncio.TimeoutError:\n        return False\n    return True"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncall func and awaits it if a returns a coroutine. Note: This is useful for implementing a function that might take a telepath proxy object or a local object, and you must call a non-async method on that object. This is also useful when calling a callback that might either be a coroutine function or a regular function. Usage: ok = await s_coro.ornot(maybeproxy.allowed, 'path')", "response": "async def ornot(func, *args, **kwargs):\n    '''\n    Calls func and awaits it if a returns a coroutine.\n\n    Note:\n        This is useful for implementing a function that might take a telepath proxy object or a local object, and you\n        must call a non-async method on that object.\n\n        This is also useful when calling a callback that might either be a coroutine function or a regular function.\n    Usage:\n        ok = await s_coro.ornot(maybeproxy.allowed, 'path')\n    '''\n\n    retn = func(*args, **kwargs)\n    if iscoro(retn):\n        return await retn\n    return retn"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nensure a string is valid hex.", "response": "def hexstr(text):\n    '''\n    Ensure a string is valid hex.\n\n    Args:\n        text (str): String to normalize.\n\n    Examples:\n        Norm a few strings:\n\n            hexstr('0xff00')\n            hexstr('ff00')\n\n    Notes:\n        Will accept strings prefixed by '0x' or '0X' and remove them.\n\n    Returns:\n        str: Normalized hex string.\n    '''\n    text = text.strip().lower()\n    if text.startswith(('0x', '0X')):\n        text = text[2:]\n\n    if not text:\n        raise s_exc.BadTypeValu(valu=text, name='hexstr',\n                                mesg='No string left after stripping')\n\n    try:\n        # checks for valid hex width and does character\n        # checking in C without using regex\n        s_common.uhex(text)\n    except (binascii.Error, ValueError) as e:\n        raise s_exc.BadTypeValu(valu=text, name='hexstr', mesg=str(e))\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tags(norm):\n    '''\n    Divide a normalized tag string into hierarchical layers.\n    '''\n    # this is ugly for speed....\n    parts = norm.split('.')\n    return ['.'.join(parts[:i]) for i in range(1, len(parts) + 1)]", "response": "Divide a normalized tag string into hierarchical layers."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nretrieve and return an unbound method by python path.", "response": "def getDynMeth(name):\n    '''\n    Retrieve and return an unbound method by python path.\n    '''\n    cname, fname = name.rsplit('.', 1)\n\n    clas = getDynLocal(cname)\n    if clas is None:\n        return None\n\n    return getattr(clas, fname, None)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tryDynLocal(name):\n    '''\n    Dynamically import a module and return a module local or raise an exception.\n    '''\n    if name.find('.') == -1:\n        raise s_exc.NoSuchDyn(name=name)\n\n    modname, objname = name.rsplit('.', 1)\n    mod = tryDynMod(modname)\n    item = getattr(mod, objname, s_common.novalu)\n    if item is s_common.novalu:\n        raise s_exc.NoSuchDyn(name=name)\n    return item", "response": "Dynamically import a module and return a module local or raise an exception."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef runDynTask(task):\n    '''\n    Run a dynamic task and return the result.\n\n    Example:\n\n        foo = runDynTask( ('baz.faz.Foo', (), {} ) )\n\n    '''\n    func = getDynLocal(task[0])\n    if func is None:\n        raise s_exc.NoSuchFunc(name=task[0])\n    return func(*task[1], **task[2])", "response": "Run a dynamic task and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelay secondary properties processing until the end.", "response": "async def delayNdefProps(self):\n        '''\n        Hold this during a series of renames to delay ndef\n        secondary property processing until the end....\n        '''\n        async with self.getTempSlab() as slab:\n\n            seqn = s_slabseqn.SlabSeqn(slab, 'ndef')\n\n            self.ndefdelay = seqn\n\n            yield\n\n            self.ndefdelay = None\n\n            logger.info(f'Processing {seqn.index()} delayed values.')\n\n            # process them all now...\n            for i, (oldv, newv) in seqn.iter(0):\n                await self.editNdefProps(oldv, newv)\n\n                if i and i % _progress == 0:\n                    logger.info(f'Processed {i} delayed values.')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nrenames a form within all the layers.", "response": "async def setFormName(self, oldn, newn):\n        '''\n        Rename a form within all the layers.\n        '''\n        logger.info(f'Migrating [{oldn}] to [{newn}]')\n\n        async with self.getTempSlab():\n\n            i = 0\n            async for buid, valu in self.getFormTodo(oldn):\n\n                await self.editNodeNdef((oldn, valu), (newn, valu))\n\n                i = i + 1\n                if i and i % _progress == 0:\n                    logger.info(f'Migrated {i} buids.')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def editNdefProps(self, oldndef, newndef):\n        '''\n        Change all props as a result of an ndef change.\n        '''\n        oldbuid = s_common.buid(oldndef)\n\n        oldname, oldvalu = oldndef\n        newname, newvalu = newndef\n\n        rename = newname != oldname\n\n        # we only need to update secondary props if they have diff vals\n        # ( vs for example a pure rename )\n        if oldvalu != newvalu:\n\n            # get the indx bytes for the *value* of the ndef\n            indx = self.slab.get(oldbuid, db=self.oldb2indx)\n            if indx is not None:\n\n                # the only way for indx to be None is if we dont have the node...\n                for prop in self.core.model.getPropsByType(newname):\n\n                    coff = prop.getCompOffs()\n\n                    for layr in self.layers:\n\n                        async for buid, valu in layr.iterPropIndx(prop.form.name, prop.name, indx):\n\n                            await layr.storPropSet(buid, prop, newvalu)\n\n                            # for now, assume any comp sub is on the same layer as it's form prop\n                            if coff is not None:\n\n                                ndef = await layr.getNodeNdef(buid)\n\n                                edit = list(ndef[1])\n                                edit[coff] = newvalu\n\n                                await self.editNodeNdef(ndef, (ndef[0], edit))\n\n        for prop in self.core.model.getPropsByType('ndef'):\n\n            formsub = self.core.model.prop(prop.full + ':' + 'form')\n\n            coff = prop.getCompOffs()\n\n            for layr in self.layers:\n\n                async for buid, valu in layr.iterPropIndx(prop.form.name, prop.name, oldbuid):\n\n                    await layr.storPropSet(buid, prop, newndef)\n\n                    if rename and formsub is not None:\n                        await layr.storPropSet(buid, formsub, newname)\n\n                    if coff is not None:\n\n                        # for now, assume form and prop on the same layer...\n                        ndef = await layr.getNodeNdef(buid)\n\n                        edit = list(ndef[1])\n                        edit[coff] = newndef\n\n                        await self.editNodeNdef(ndef, (ndef[0], edit))", "response": "Edit all props as a result of an ndef change."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def getFormTodo(self, name):\n        '''\n        Produce a deconflicted list of form values across layers\n        as a *copy* to avoid iter vs edit issues in the indexes.\n        '''\n        size = 0\n        logger.warning(f'MIGRATION: calculating form todo: {name}')\n        async with self.getTempSlab() as slab:\n\n            for layr in self.layers:\n\n                async for buid, valu in layr.iterFormRows(name):\n                    slab.put(buid, s_msgpack.en(valu), overwrite=False)\n                    size += 1\n\n            logger.warning(f'MIGRATION: {name} todo size: {size}')\n\n            for buid, byts in slab.scanByFull():\n                yield buid, s_msgpack.un(byts)", "response": "Generates a deconflicted list of form values across layers\n            and yields a list of form values for each element in the todo."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def iterStormPodes(self, text, opts=None, user=None):\n        '''\n        Yield packed node tuples for the given storm query text.\n        '''\n        if user is None:\n            user = self.user\n\n        dorepr = False\n        dopath = False\n\n        self.core._logStormQuery(text, user)\n\n        if opts is not None:\n            dorepr = opts.get('repr', False)\n            dopath = opts.get('path', False)\n\n        async for node, path in self.storm(text, opts=opts, user=user):\n            pode = node.pack(dorepr=dorepr)\n            pode[1]['path'] = path.pack(path=dopath)\n            yield pode", "response": "Iterate over packed node tuples for the given storm query text."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def storm(self, text, opts=None, user=None):\n        '''\n        Execute a storm query and yield (Node(), Path()) tuples.\n        '''\n        if user is None:\n            user = self.user\n\n        query = self.core.getStormQuery(text)\n        with self.getStormRuntime(opts=opts, user=user) as runt:\n            async for x in runt.iterStormQuery(query):\n                yield x", "response": "Execute a storm query and yield a tuple of nodes and paths."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def eval(self, text, opts=None, user=None):\n        '''\n        Run a storm query and yield Node() objects.\n        '''\n        if user is None:\n            user = self.user\n\n        # maintained for backward compatibility\n        query = self.core.getStormQuery(text)\n        with self.getStormRuntime(opts=opts, user=user) as runt:\n            async for node, path in runt.iterStormQuery(query):\n                yield node", "response": "Run a storm query and yield Node objects."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nretrieve a node by binary id.", "response": "async def getNodeByBuid(self, buid):\n        '''\n        Retrieve a node tuple by binary id.\n\n        Args:\n            buid (bytes): The binary ID for the node.\n\n        Returns:\n            Optional[s_node.Node]: The node object or None.\n\n        '''\n        node = self.livenodes.get(buid)\n        if node is not None:\n            return node\n\n        props = {}\n        proplayr = {}\n        for layr in self.layers:\n            layerprops = await layr.getBuidProps(buid)\n            props.update(layerprops)\n            proplayr.update({k: layr for k in layerprops})\n\n        node = s_node.Node(self, buid, props.items(), proplayr=proplayr)\n\n        # Give other tasks a chance to run\n        await asyncio.sleep(0)\n\n        if node.ndef is None:\n            return None\n\n        # Add node to my buidcache\n        self.buidcache.append(node)\n        self.livenodes[buid] = node\n        return node"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def getNodeByNdef(self, ndef):\n        '''\n        Return a single Node by (form,valu) tuple.\n\n        Args:\n            ndef ((str,obj)): A (form,valu) ndef tuple.  valu must be\n            normalized.\n\n        Returns:\n            (synapse.lib.node.Node): The Node or None.\n        '''\n        buid = s_common.buid(ndef)\n        return await self.getNodeByBuid(buid)", "response": "Return a single Node by ndef tuple."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def addNode(self, name, valu, props=None):\n        '''\n        Add a node by form name and value with optional props.\n\n        Args:\n            name (str): The form of node to add.\n            valu (obj): The value for the node.\n            props (dict): Optional secondary properties for the node.\n        '''\n\n        try:\n\n            fnib = self._getNodeFnib(name, valu)\n            retn = await self._addNodeFnib(fnib, props=props)\n            return retn\n\n        except asyncio.CancelledError:\n            raise\n\n        except Exception:\n\n            mesg = f'Error adding node: {name} {valu!r} {props!r}'\n            logger.exception(mesg)\n            if self.strict:\n                raise\n\n            return None", "response": "Add a node by form name and value with optional props."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a feed record type to the feed.", "response": "async def addFeedNodes(self, name, items):\n        '''\n        Call a feed function and return what it returns (typically yields Node()s).\n\n        Args:\n            name (str): The name of the feed record type.\n            items (list): A list of records of the given feed type.\n\n        Returns:\n            (object): The return value from the feed function. Typically Node() generator.\n\n        '''\n        func = self.core.getFeedFunc(name)\n        if func is None:\n            raise s_exc.NoSuchName(name=name)\n\n        logger.info(f'adding feed nodes ({name}): {len(items)}')\n\n        async for node in func(self, items):\n            yield node"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a node via fnib and add ops to editatom and return the new node s properties.", "response": "async def _addNodeFnibOps(self, fnib, editatom, props=None):\n        '''\n        Add a node via (form, norm, info, buid) and add ops to editatom\n        '''\n        form, norm, info, buid = fnib\n\n        if form.isrunt:\n            raise s_exc.IsRuntForm(mesg='Cannot make runt nodes.',\n                                   form=form.full, prop=norm)\n\n        if props is None:\n            props = {}\n        # Check if this buid is already under construction\n        node = editatom.getNodeBeingMade(buid)\n        if node is not None:\n            return node\n\n        # Check if this buid is already fully made\n        node = await self.getNodeByBuid(buid)\n        if node is not None:\n            return node\n\n        # Another editatom might have created in another task during the above call, so check again\n        node = editatom.getNodeBeingMade(buid)\n        if node is not None:\n            return node\n\n        if props is None:\n            props = {}\n\n        # lets build a node...\n        node = s_node.Node(self, None)\n\n        node.buid = buid\n        node.form = form\n        node.ndef = (form.name, norm)\n\n        sops = form.getSetOps(buid, norm)\n        editatom.sops.extend(sops)\n\n        editatom.addNode(node)\n\n        # update props with any subs from form value\n        subs = info.get('subs')\n        if subs is not None:\n            for name, valu in subs.items():\n                if form.prop(name) is not None:\n                    props[name] = valu\n\n        # update props with any defvals we are missing\n        for name, valu in form.defvals.items():\n            props.setdefault(name, valu)\n\n        # set all the properties with init=True\n        for name, valu in props.items():\n            await node._setops(name, valu, editatom, init=True)\n\n        # set our global properties\n        tick = s_common.now()\n        await node._setops('.created', tick, editatom, init=True)\n\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _getNodeFnib(self, name, valu):\n        '''\n        return a form, norm, info, buid tuple\n        '''\n        form = self.model.form(name)\n        if form is None:\n            raise s_exc.NoSuchForm(name=name)\n\n        try:\n            norm, info = form.type.norm(valu)\n        except Exception as e:\n            raise s_exc.BadPropValu(prop=form.name, valu=valu, mesg=str(e))\n\n        buid = s_common.buid((form.name, norm))\n        return form, norm, info, buid", "response": "return a form norm info buid tuple\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def addNodes(self, nodedefs):\n        '''\n        Add/merge nodes in bulk.\n\n        The addNodes API is designed for bulk adds which will\n        also set properties and add tags to existing nodes.\n        Nodes are specified as a list of the following tuples:\n\n            ( (form, valu), {'props':{}, 'tags':{}})\n\n        Args:\n            nodedefs (list): A list of nodedef tuples.\n\n        Returns:\n            (list): A list of xact messages.\n        '''\n\n        for (formname, formvalu), forminfo in nodedefs:\n\n            props = forminfo.get('props')\n\n            # remove any universal created props...\n            if props is not None:\n                props.pop('.created', None)\n\n            node = await self.addNode(formname, formvalu, props=props)\n            if node is not None:\n                tags = forminfo.get('tags')\n                if tags is not None:\n                    for tag, asof in tags.items():\n                        await node.addTag(tag, valu=asof)\n\n            yield node", "response": "Add nodes in bulk."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nyield row tuples from a series of lift operations.", "response": "async def getLiftRows(self, lops):\n        '''\n        Yield row tuples from a series of lift operations.\n\n        Row tuples only requirement is that the first element\n        be the binary id of a node.\n\n        Args:\n            lops (list): A list of lift operations.\n\n        Yields:\n            (tuple): (layer_indx, (buid, ...)) rows.\n        '''\n        for layeridx, layr in enumerate(self.layers):\n            async for x in layr.getLiftRows(lops):\n                yield layeridx, x"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\njoin a row generator into (row, Node()) tuples. A row generator yields tuples of node buid, rawprop dict Args: rows: A generator of (layer_idx, (buid, ...)) tuples. rawprop(str): \"raw\" propname e.g. if a tag, starts with \"#\". Used for filtering so that we skip the props for a buid if we're asking from a higher layer than the row was from (and hence, we'll presumable get/have gotten the row when that layer is lifted. cmpf (func): A comparison function used to filter nodes. Yields: (tuple): (row, node)", "response": "async def getRowNodes(self, rows, rawprop, cmpf=None):\n        '''\n        Join a row generator into (row, Node()) tuples.\n\n        A row generator yields tuples of node buid, rawprop dict\n\n        Args:\n            rows: A generator of (layer_idx, (buid, ...)) tuples.\n            rawprop(str):  \"raw\" propname e.g. if a tag, starts with \"#\".  Used\n                for filtering so that we skip the props for a buid if we're\n                asking from a higher layer than the row was from (and hence,\n                we'll presumable get/have gotten the row when that layer is\n                lifted.\n            cmpf (func): A comparison function used to filter nodes.\n        Yields:\n            (tuple): (row, node)\n        '''\n        count = 0\n        async for origlayer, row in rows:\n            count += 1\n            if not count % 5:\n                await asyncio.sleep(0)  # give other tasks some time\n\n            buid, rawprops = row\n            node = self.livenodes.get(buid)\n\n            if node is None:\n                props = {}     # rawprop: valu\n                proplayr = {}  # rawprop: layr\n\n                for layeridx, layr in enumerate(self.layers):\n\n                    if layeridx == origlayer:\n                        layerprops = rawprops\n                    else:\n                        layerprops = await layr.getBuidProps(buid)\n\n                    props.update(layerprops)\n                    proplayr.update({k: layr for k in layerprops})\n\n                node = s_node.Node(self, buid, props.items(), proplayr=proplayr)\n                if node.ndef is None:\n                    continue\n\n                # Add node to my buidcache\n                self.buidcache.append(node)\n                self.livenodes[buid] = node\n\n            # If the node's prop I'm filtering on came from a different layer, skip it\n            rawrawprop = ('*' if rawprop == node.form.name else '') + rawprop\n            if node.proplayr[rawrawprop] != self.layers[origlayer]:\n                continue\n\n            if cmpf:\n                if rawprop == node.form.name:\n                    valu = node.ndef[1]\n                else:\n                    valu = node.get(rawprop)\n                if valu is None:\n                    # cmpr required to evaluate something; cannot know if this\n                    # node is valid or not without the prop being present.\n                    continue\n                if not cmpf(valu):\n                    continue\n\n            yield row, node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the lowercased name of this module.", "response": "def getModName(self):\n        '''\n        Return the lowercased name of this module.\n\n        Notes:\n            This pulls the ``mod_name`` attribute on the class. This allows\n            an implementer to set a arbitrary name for the module.  If this\n            attribute is not set, it defaults to\n            ``self.__class__.__name__.lower()`` and sets ``mod_name`` to\n            that value.\n\n        Returns:\n            (str): The module name.\n        '''\n        ret = self.mod_name\n        if ret is None:\n            ret = self.__class__.__name__\n        return ret.lower()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconstruct a path relative to this module s working directory.", "response": "def getModPath(self, *paths):\n        '''\n        Construct a path relative to this module's working directory.\n\n        Args:\n            *paths: A list of path strings\n\n        Notes:\n            This creates the module specific directory if it does not exist.\n\n        Returns:\n            (str): The full path (or None if no cortex dir is configured).\n        '''\n        dirn = self.getModDir()\n        return s_common.genpath(dirn, *paths)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a ctor callback to the global scope.", "response": "def ctor(name, func, *args, **kwargs):\n    '''\n    Add a ctor callback to the global scope.\n    '''\n    return globscope.ctor(name, func, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves a value from the closest scope frame.", "response": "def get(self, name, defval=None):\n        '''\n        Retrieve a value from the closest scope frame.\n        '''\n        for frame in reversed(self.frames):\n            valu = frame.get(name, s_common.novalu)\n            if valu != s_common.novalu:\n                return valu\n\n        task = self.ctors.get(name)\n        if task is not None:\n            func, args, kwargs = task\n            item = func(*args, **kwargs)\n            self.frames[-1][name] = item\n            return item\n\n        return defval"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds values as iter() compatible items in the current scope frame.", "response": "def add(self, name, *vals):\n        '''\n        Add values as iter() compatible items in the current scope frame.\n        '''\n        item = self.frames[-1].get(name)\n        if item is None:\n            self.frames[-1][name] = item = []\n        item.extend(vals)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a constructor to be called when a specific property is not present.", "response": "def ctor(self, name, func, *args, **kwargs):\n        '''\n        Add a constructor to be called when a specific property is not present.\n\n        Example:\n\n            scope.ctor('foo',FooThing)\n            ...\n            foo = scope.get('foo')\n\n        '''\n        self.ctors[name] = (func, args, kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\niterating through values added with add() from each scope frame.", "response": "def iter(self, name):\n        '''\n        Iterate through values added with add() from each scope frame.\n        '''\n        for frame in self.frames:\n            vals = frame.get(name)\n            if vals is None:\n                continue\n            for valu in vals:\n                yield valu"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef put(self, item):\n        '''\n        Add an item to the queue.\n        '''\n        if self.isfini:\n            return False\n\n        self.fifo.append(item)\n\n        if len(self.fifo) == 1:\n            self.event.set()\n\n        return True", "response": "Add an item to the queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a node if it is currently being made mark as a dependency else None.", "response": "def getNodeBeingMade(self, buid):\n        '''\n        Return a node if it is currently being made, mark as a dependency, else None if none found\n        '''\n        nodeevnt = self.allbldgbuids.get(buid)\n        if nodeevnt is None:\n            return None\n        if buid not in self.mybldgbuids:\n            self.otherbldgbuids.add(buid)\n        return nodeevnt[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addNode(self, node):\n        '''\n        Update the shared map with my in-construction node\n        '''\n        self.mybldgbuids[node.buid] = node\n        self.allbldgbuids[node.buid] = (node, self.doneevent)", "response": "Update the shared map with the node s my in - construction node s doneevent"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnotifies that all editatoms have completed", "response": "def _notifyDone(self):\n        '''\n        Allow any other editatoms waiting on me to complete to resume\n        '''\n        if self.notified:\n            return\n\n        self.doneevent.set()\n\n        for buid in self.mybldgbuids:\n            del self.allbldgbuids[buid]\n\n        self.notified = True"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def _wait(self):\n        '''\n        Wait on the other editatoms who are constructing nodes my new nodes refer to\n        '''\n        for buid in self.otherbldgbuids:\n            nodeevnt = self.allbldgbuids.get(buid)\n            if nodeevnt is None:\n                continue\n            await nodeevnt[1].wait()", "response": "Wait on the other editatoms who are constructing nodes my new nodes refer to\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def commit(self, snap):\n        '''\n        Push the recorded changes to disk, notify all the listeners\n        '''\n        if not self.npvs:  # nothing to do\n            return\n\n        for node, prop, _, valu in self.npvs:\n            node.props[prop.name] = valu\n            node.proplayr[prop.name] = snap.wlyr\n\n        splices = [snap.splice('node:add', ndef=node.ndef) for node in self.mybldgbuids.values()]\n        for node, prop, oldv, valu in self.npvs:\n            info = {'ndef': node.ndef, 'prop': prop.name, 'valu': valu}\n            if oldv is not None:\n                info['oldv'] = oldv\n            splices.append(snap.splice('prop:set', **info))\n\n        await snap.stor(self.sops, splices)\n\n        for node in self.mybldgbuids.values():\n            snap.core.pokeFormCount(node.form.name, 1)\n            snap.buidcache.append(node)\n            snap.livenodes[node.buid] = node\n\n        await self.rendevous()\n\n        for node in self.mybldgbuids.values():\n            await node.form.wasAdded(node)\n\n        # fire all his prop sets\n        for node, prop, oldv, valu in self.npvs:\n            await prop.wasSet(node, oldv)\n\n            if prop.univ:\n                univ = snap.model.prop(prop.univ)\n                await univ.wasSet(node, oldv)\n\n        # Finally, fire all the triggers\n        for node, prop, oldv, _ in self.npvs:\n            await snap.core.triggers.runPropSet(node, prop, oldv)", "response": "Commit the changes to disk and notify all the listeners of the new ones."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def getItemCmdr(cell, outp=None, **opts):\n    '''\n    Construct and return a cmdr for the given remote cell.\n\n    Example:\n\n        cmdr = await getItemCmdr(foo)\n\n    '''\n    cmdr = await s_cli.Cli.anit(cell, outp=outp)\n    typename = await cell.getCellType()\n\n    for ctor in cmdsbycell.get(typename, ()):\n        cmdr.addCmdClass(ctor)\n\n    return cmdr", "response": "Construct and return a cmdr for the given remote cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def runItemCmdr(item, outp=None, **opts):\n    '''\n    Create a cmdr for the given item and run the cmd loop.\n\n    Example:\n\n        runItemCmdr(foo)\n\n    '''\n    cmdr = await getItemCmdr(item, outp=outp, **opts)\n    await cmdr.runCmdLoop()", "response": "Create a cmdr for the given item and run the cmd loop."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef getDocPath(fn, root=None):\n    '''\n    Helper for getting a documentation data file paths.\n\n    Args:\n        fn (str): Name of the file to retrieve the full path for.\n        root (str): Optional root path to look for a docdata in.\n\n    Notes:\n        Defaults to looking for the ``docdata`` directory in the current\n        working directory. This behavior works fine for notebooks nested\n        in the docs directory of synapse; but this root directory that\n        is looked for may be overridden by providing an alternative root.\n\n    Returns:\n        str: A file path.\n\n    Raises:\n        ValueError if the file does not exist or directory traversal attempted..\n    '''\n    cwd = pathlib.Path(os.getcwd())\n    if root:\n        cwd = pathlib.Path(root)\n    # Walk up a directory until you find '...d./data'\n    while True:\n        dpath = cwd.joinpath('docdata')\n        if dpath.is_dir():\n            break\n        parent = cwd.parent\n        if parent == cwd:\n            raise ValueError(f'Unable to find data directory from {os.getcwd()}.')\n        cwd = parent\n\n    # Protect against traversal\n    fpath = os.path.abspath(os.path.join(dpath.as_posix(), fn))\n    if not fpath.startswith(dpath.as_posix()):\n        raise ValueError(f'Path escaping detected: {fn}')\n\n    # Existence\n    if not os.path.isfile(fpath):\n        raise ValueError(f'File does not exist: {fn}')\n\n    return fpath", "response": "Helper for getting a full path for a documentation data file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a temporary cortex proxy.", "response": "async def genTempCoreProxy(mods=None):\n    '''Get a temporary cortex proxy.'''\n    with s_common.getTempDir() as dirn:\n        async with await s_cortex.Cortex.anit(dirn) as core:\n            if mods:\n                for mod in mods:\n                    await core.loadCoreModule(mod)\n            async with core.getLocalProxy() as prox:\n                # Use object.__setattr__ to hulk smash and avoid proxy getattr magick\n                object.__setattr__(prox, '_core', core)\n                yield prox"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a Cmdr instance with prepopulated locs", "response": "async def getItemCmdr(prox, outp=None, locs=None):\n    '''Get a Cmdr instance with prepopulated locs'''\n    cmdr = await s_cmdr.getItemCmdr(prox, outp=outp)\n    cmdr.echoline = True\n    if locs:\n        cmdr.locs.update(locs)\n    return cmdr"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def getTempCoreProx(mods=None):\n    '''\n    Get a Telepath Proxt to a Cortex instance which is backed by a temporary Cortex.\n\n    Args:\n        mods (list): A list of additional CoreModules to load in the Cortex.\n\n    Notes:\n        The Proxy returned by this should be fini()'d to tear down the temporary Cortex.\n\n    Returns:\n        s_telepath.Proxy\n    '''\n    acm = genTempCoreProxy(mods)\n    prox = await acm.__aenter__()\n    # Use object.__setattr__ to hulk smash and avoid proxy getattr magick\n    object.__setattr__(prox, '_acm', acm)\n    async def onfini():\n        await prox._acm.__aexit__(None, None, None)\n    prox.onfini(onfini)\n    return prox", "response": "Returns a Telepath Proxt to a Cortex instance which is backed by a temporary Cortex."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\nasync def getTempCoreCmdr(mods=None, outp=None):\n    '''\n    Get a CmdrCore instance which is backed by a temporary Cortex.\n\n    Args:\n        mods (list): A list of additional CoreModules to load in the Cortex.\n        outp: A output helper.  Will be used for the Cmdr instance.\n\n    Notes:\n        The CmdrCore returned by this should be fini()'d to tear down the temporary Cortex.\n\n    Returns:\n        CmdrCore: A CmdrCore instance.\n    '''\n    acm = genTempCoreProxy(mods)\n    prox = await acm.__aenter__()\n    cmdrcore = await CmdrCore.anit(prox, outp=outp)\n    cmdrcore.acm = acm\n    return cmdrcore", "response": "Returns a CmdrCore instance which is backed by a temporary Cortex."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def addFeedData(self, name, items, seqn=None):\n        '''\n        Add feed data to the cortex.\n        '''\n        return await self.core.addFeedData(name, items, seqn)", "response": "Add feed data to the cortex."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _inputrc_enables_vi_mode():\n    '''\n    Emulate a small bit of readline behavior.\n\n    Returns:\n        (bool) True if current user enabled vi mode (\"set editing-mode vi\") in .inputrc\n    '''\n    for filepath in (os.path.expanduser('~/.inputrc'), '/etc/inputrc'):\n        try:\n            with open(filepath) as f:\n                for line in f:\n                    if _setre.fullmatch(line):\n                        return True\n        except IOError:\n            continue\n    return False", "response": "Emulate a small bit of readline behavior."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nexecuting a line of command input for this command.", "response": "async def runCmdLine(self, line):\n        '''\n        Run a line of command input for this command.\n\n        Args:\n            line (str): Line to execute\n\n        Examples:\n            Run the foo command with some arguments:\n\n                await foo.runCmdLine('foo --opt baz woot.com')\n\n        '''\n        opts = self.getCmdOpts(line)\n        return await self.runCmdOpts(opts)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the command line and return a dictionary of options and the command line.", "response": "def getCmdOpts(self, text):\n        '''\n        Use the _cmd_syntax def to split/parse/normalize the cmd line.\n\n        Args:\n            text (str): Command to process.\n\n        Notes:\n            This is implemented independent of argparse (et al) due to the\n            need for syntax aware argument splitting. Also, allows different\n            split per command type\n\n        Returns:\n            dict: An opts dictionary.\n        '''\n        off = 0\n\n        _, off = s_syntax.nom(text, off, s_syntax.whites)\n\n        name, off = s_syntax.meh(text, off, s_syntax.whites)\n\n        _, off = s_syntax.nom(text, off, s_syntax.whites)\n\n        opts = {}\n\n        args = collections.deque([synt for synt in self._cmd_syntax if not synt[0].startswith('-')])\n\n        switches = {synt[0]: synt for synt in self._cmd_syntax if synt[0].startswith('-')}\n\n        # populate defaults and lists\n        for synt in self._cmd_syntax:\n            snam = synt[0].strip('-')\n\n            defval = synt[1].get('defval')\n            if defval is not None:\n                opts[snam] = defval\n\n            if synt[1].get('type') in ('list', 'kwlist'):\n                opts[snam] = []\n\n        def atswitch(t, o):\n            # check if we are at a recognized switch.  if not\n            # assume the data is part of regular arguments.\n            if not text.startswith('-', o):\n                return None, o\n\n            name, x = s_syntax.meh(t, o, s_syntax.whites)\n            swit = switches.get(name)\n            if swit is None:\n                return None, o\n\n            return swit, x\n\n        while off < len(text):\n\n            _, off = s_syntax.nom(text, off, s_syntax.whites)\n\n            swit, off = atswitch(text, off)\n            if swit is not None:\n\n                styp = swit[1].get('type', 'flag')\n                snam = swit[0].strip('-')\n\n                if styp == 'valu':\n                    valu, off = s_syntax.parse_cmd_string(text, off)\n                    opts[snam] = valu\n\n                elif styp == 'list':\n                    valu, off = s_syntax.parse_cmd_string(text, off)\n                    if not isinstance(valu, list):\n                        valu = valu.split(',')\n                    opts[snam].extend(valu)\n\n                elif styp == 'enum':\n                    vals = swit[1].get('enum:vals')\n                    valu, off = s_syntax.parse_cmd_string(text, off)\n                    if valu not in vals:\n                        raise s_exc.BadSyntax(mesg='%s (%s)' % (swit[0], '|'.join(vals)),\n                                                   text=text)\n\n                    opts[snam] = valu\n\n                else:\n                    opts[snam] = True\n\n                continue\n\n            if not args:\n                raise s_exc.BadSyntax(mesg='trailing text: [%s]' % (text[off:],),\n                                           text=text)\n\n            synt = args.popleft()\n            styp = synt[1].get('type', 'valu')\n\n            # a glob type eats the remainder of the string\n            if styp == 'glob':\n                opts[synt[0]] = text[off:]\n                break\n\n            # eat the remainder of the string as separate vals\n            if styp == 'list':\n                valu = []\n\n                while off < len(text):\n                    item, off = s_syntax.parse_cmd_string(text, off)\n                    valu.append(item)\n\n                opts[synt[0]] = valu\n                break\n\n            if styp == 'kwlist':\n                kwlist, off = s_syntax.parse_cmd_kwlist(text, off)\n                opts[snam] = kwlist\n                break\n\n            valu, off = s_syntax.parse_cmd_string(text, off)\n            opts[synt[0]] = valu\n\n        return opts"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def addSignalHandlers(self):\n        '''\n        Register SIGINT signal handler with the ioloop to cancel the currently running cmdloop task.\n        '''\n\n        def sigint():\n            self.printf('<ctrl-c>')\n            if self.cmdtask is not None:\n                self.cmdtask.cancel()\n\n        self.loop.add_signal_handler(signal.SIGINT, sigint)", "response": "Register SIGINT signal handler with the ioloop to cancel the currently running cmdloop task."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nprompts for user input from stdin.", "response": "async def prompt(self, text=None):\n        '''\n        Prompt for user input from stdin.\n        '''\n        if self.sess is None:\n            hist = FileHistory(s_common.getSynPath('cmdr_history'))\n            self.sess = PromptSession(history=hist)\n\n        if text is None:\n            text = self.cmdprompt\n\n        with patch_stdout():\n            retn = await self.sess.prompt(text, async_=True, vi_mode=self.vi_mode, enable_open_in_editor=True)\n            return retn"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a Cmd subclass to this cli.", "response": "def addCmdClass(self, ctor, **opts):\n        '''\n        Add a Cmd subclass to this cli.\n        '''\n        item = ctor(self, **opts)\n        name = item.getCmdName()\n        self.cmds[name] = item"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def runCmdLoop(self):\n        '''\n        Run commands from a user in an interactive fashion until fini() or EOFError is raised.\n        '''\n        while not self.isfini:\n\n            # FIXME completion\n\n            self.cmdtask = None\n\n            try:\n\n                line = await self.prompt()\n                if not line:\n                    continue\n\n                line = line.strip()\n                if not line:\n                    continue\n\n                coro = self.runCmdLine(line)\n                self.cmdtask = self.schedCoro(coro)\n                await self.cmdtask\n\n            except KeyboardInterrupt:\n\n                if self.isfini:\n                    return\n\n                self.printf('<ctrl-c>')\n\n            except (s_exc.CliFini, EOFError):\n                await self.fini()\n\n            except Exception:\n                s = traceback.format_exc()\n                self.printf(s)\n\n            finally:\n                if self.cmdtask is not None:\n                    self.cmdtask.cancel()\n                    try:\n                        self.cmdtask.result()\n                    except asyncio.CancelledError:\n                        # Wait a beat to let any remaining nodes to print out before we print the prompt\n                        await asyncio.sleep(1)\n                    except Exception:\n                        pass", "response": "Run commands from a user in an interactive fashion until fini is raised."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nexecute a single command line.", "response": "async def runCmdLine(self, line):\n        '''\n        Run a single command line.\n\n        Args:\n            line (str): Line to execute.\n\n        Examples:\n            Execute the 'woot' command with the 'help' switch:\n\n                await cli.runCmdLine('woot --help')\n\n        Returns:\n            object: Arbitrary data from the cmd class.\n        '''\n        if self.echoline:\n            self.outp.printf(f'{self.cmdprompt}{line}')\n\n        ret = None\n\n        name = line.split(None, 1)[0]\n\n        cmdo = self.getCmdByName(name)\n        if cmdo is None:\n            self.printf('cmd not found: %s' % (name,))\n            return\n\n        try:\n\n            ret = await cmdo.runCmdLine(line)\n\n        except s_exc.CliFini:\n            await self.fini()\n\n        except asyncio.CancelledError:\n            self.printf('Cmd cancelled')\n\n        except Exception as e:\n            exctxt = traceback.format_exc()\n            self.printf(exctxt)\n            self.printf('error: %s' % e)\n\n        return ret"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates a new CA keypair.", "response": "def genCaCert(self, name, signas=None, outp=None, save=True):\n        '''\n        Generates a CA keypair.\n\n        Args:\n            name (str): The name of the CA keypair.\n            signas (str): The CA keypair to sign the new CA with.\n            outp (synapse.lib.output.Output): The output buffer.\n\n        Examples:\n            Make a CA named \"myca\":\n\n                mycakey, mycacert = cdir.genCaCert('myca')\n\n        Returns:\n            ((OpenSSL.crypto.PKey, OpenSSL.crypto.X509)): Tuple containing the private key and certificate objects.\n        '''\n        pkey, cert = self._genBasePkeyCert(name)\n        ext0 = crypto.X509Extension(b'basicConstraints', False, b'CA:TRUE')\n        cert.add_extensions([ext0])\n\n        if signas is not None:\n            self.signCertAs(cert, signas)\n        else:\n            self.selfSignCert(cert, pkey)\n\n        if save:\n\n            keypath = self._savePkeyTo(pkey, 'cas', '%s.key' % name)\n            if outp is not None:\n                outp.printf('key saved: %s' % (keypath,))\n\n            crtpath = self._saveCertTo(cert, 'cas', '%s.crt' % name)\n            if outp is not None:\n                outp.printf('cert saved: %s' % (crtpath,))\n\n        return pkey, cert"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef genHostCert(self, name, signas=None, outp=None, csr=None, sans=None):\n        '''\n        Generates a host keypair.\n\n        Args:\n            name (str): The name of the host keypair.\n            signas (str): The CA keypair to sign the new host keypair with.\n            outp (synapse.lib.output.Output): The output buffer.\n            csr (OpenSSL.crypto.PKey): The CSR public key when generating the keypair from a CSR.\n            sans (list): List of subject alternative names.\n\n        Examples:\n            Make a host keypair named \"myhost\":\n\n                myhostkey, myhostcert = cdir.genHostCert('myhost')\n\n        Returns:\n            ((OpenSSL.crypto.PKey, OpenSSL.crypto.X509)): Tuple containing the private key and certificate objects.\n        '''\n        pkey, cert = self._genBasePkeyCert(name, pkey=csr)\n\n        ext_sans = {'DNS:' + name}\n        if isinstance(sans, str):\n            ext_sans = ext_sans.union(sans.split(','))\n        ext_sans = ','.join(sorted(ext_sans))\n\n        cert.add_extensions([\n            crypto.X509Extension(b'nsCertType', False, b'server'),\n            crypto.X509Extension(b'keyUsage', False, b'digitalSignature,keyEncipherment'),\n            crypto.X509Extension(b'extendedKeyUsage', False, b'serverAuth'),\n            crypto.X509Extension(b'basicConstraints', False, b'CA:FALSE'),\n            crypto.X509Extension(b'subjectAltName', False, ext_sans.encode('utf-8')),\n        ])\n\n        if signas is not None:\n            self.signCertAs(cert, signas)\n        else:\n            self.selfSignCert(cert, pkey)\n\n        if not pkey._only_public:\n            keypath = self._savePkeyTo(pkey, 'hosts', '%s.key' % name)\n            if outp is not None:\n                outp.printf('key saved: %s' % (keypath,))\n\n        crtpath = self._saveCertTo(cert, 'hosts', '%s.crt' % name)\n        if outp is not None:\n            outp.printf('cert saved: %s' % (crtpath,))\n\n        return pkey, cert", "response": "Generates a new host keypair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new user keypair.", "response": "def genUserCert(self, name, signas=None, outp=None, csr=None):\n        '''\n        Generates a user keypair.\n\n        Args:\n            name (str): The name of the user keypair.\n            signas (str): The CA keypair to sign the new user keypair with.\n            outp (synapse.lib.output.Output): The output buffer.\n            csr (OpenSSL.crypto.PKey): The CSR public key when generating the keypair from a CSR.\n\n        Examples:\n            Generate a user cert for the user \"myuser\":\n\n                myuserkey, myusercert = cdir.genUserCert('myuser')\n\n        Returns:\n            ((OpenSSL.crypto.PKey, OpenSSL.crypto.X509)): Tuple containing the key and certificate objects.\n        '''\n        pkey, cert = self._genBasePkeyCert(name, pkey=csr)\n\n        cert.add_extensions([\n            crypto.X509Extension(b'nsCertType', False, b'client'),\n            crypto.X509Extension(b'keyUsage', False, b'digitalSignature'),\n            crypto.X509Extension(b'extendedKeyUsage', False, b'clientAuth'),\n            crypto.X509Extension(b'basicConstraints', False, b'CA:FALSE'),\n        ])\n\n        if signas is not None:\n            self.signCertAs(cert, signas)\n        else:\n            self.selfSignCert(cert, pkey)\n\n        crtpath = self._saveCertTo(cert, 'users', '%s.crt' % name)\n        if outp is not None:\n            outp.printf('cert saved: %s' % (crtpath,))\n\n        if not pkey._only_public:\n            keypath = self._savePkeyTo(pkey, 'users', '%s.key' % name)\n            if outp is not None:\n                outp.printf('key saved: %s' % (keypath,))\n\n        return pkey, cert"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ngenerate a user PKCS #12 file for the user keypair.", "response": "def genClientCert(self, name, outp=None):\n        '''\n        Generates a user PKCS #12 archive.\n        Please note that the resulting file will contain private key material.\n\n        Args:\n            name (str): The name of the user keypair.\n            outp (synapse.lib.output.Output): The output buffer.\n\n        Examples:\n            Make the PKC12 object for user \"myuser\":\n\n                myuserpkcs12 = cdir.genClientCert('myuser')\n\n        Returns:\n            OpenSSL.crypto.PKCS12: The PKCS #12 archive.\n        '''\n        ucert = self.getUserCert(name)\n        if not ucert:\n            raise s_exc.NoSuchFile('missing User cert')\n\n        cacert = self._loadCertPath(self._getCaPath(ucert))\n        if not cacert:\n            raise s_exc.NoSuchFile('missing CA cert')\n\n        ukey = self.getUserKey(name)\n        if not ukey:\n            raise s_exc.NoSuchFile('missing User private key')\n\n        ccert = crypto.PKCS12()\n        ccert.set_friendlyname(name.encode('utf-8'))\n        ccert.set_ca_certificates([cacert])\n        ccert.set_certificate(ucert)\n        ccert.set_privatekey(ukey)\n\n        crtpath = self._saveP12To(ccert, 'users', '%s.p12' % name)\n        if outp is not None:\n            outp.printf('client cert saved: %s' % (crtpath,))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nvalidating the PEM encoded x509 user certificate bytes and return it.", "response": "def valUserCert(self, byts, cacerts=None):\n        '''\n        Validate the PEM encoded x509 user certificate bytes and return it.\n\n        Args:\n            byts (bytes): The bytes for the User Certificate.\n            cacerts (tuple): A tuple of OpenSSL.crypto.X509 CA Certificates.\n\n        Raises:\n            OpenSSL.crypto.X509StoreContextError: If the certificate is not valid.\n\n        Returns:\n            OpenSSL.crypto.X509: The certificate, if it is valid.\n\n        '''\n        cert = crypto.load_certificate(crypto.FILETYPE_PEM, byts)\n\n        if cacerts is None:\n            cacerts = self.getCaCerts()\n\n        store = crypto.X509Store()\n        [store.add_cert(cacert) for cacert in cacerts]\n\n        ctx = crypto.X509StoreContext(store, cert)\n        ctx.verify_certificate()  # raises X509StoreContextError if unable to verify\n        return cert"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a list of CA certs from the CertDir.", "response": "def getCaCerts(self):\n        '''\n        Return a list of CA certs from the CertDir.\n\n        Returns:\n            [OpenSSL.crypto.X509]: List of CA certificates.\n        '''\n        retn = []\n\n        path = s_common.genpath(self.certdir, 'cas')\n\n        for name in os.listdir(path):\n            if not name.endswith('.crt'):\n                continue\n\n            full = s_common.genpath(self.certdir, 'cas', name)\n            retn.append(self._loadCertPath(full))\n\n        return retn"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the path to the CA certificate that issued a given host keypair.", "response": "def getHostCaPath(self, name):\n        '''\n        Gets the path to the CA certificate that issued a given host keypair.\n\n        Args:\n            name (str): The name of the host keypair.\n\n        Examples:\n            Get the path to the CA cert which issue the cert for \"myhost\":\n\n                mypath = cdir.getHostCaPath('myhost')\n\n        Returns:\n            str: The path if exists.\n        '''\n        cert = self.getHostCert(name)\n        if cert is None:\n            return None\n\n        return self._getCaPath(cert)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the path to a host certificate.", "response": "def getHostCertPath(self, name):\n        '''\n        Gets the path to a host certificate.\n\n        Args:\n            name (str): The name of the host keypair.\n\n        Examples:\n            Get the path to the host certificate for the host \"myhost\":\n\n                mypath = cdir.getHostCertPath('myhost')\n\n        Returns:\n            str: The path if exists.\n        '''\n        path = s_common.genpath(self.certdir, 'hosts', '%s.crt' % name)\n        if not os.path.isfile(path):\n            return None\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getUserCaPath(self, name):\n        '''\n        Gets the path to the CA certificate that issued a given user keypair.\n\n        Args:\n            name (str): The name of the user keypair.\n\n        Examples:\n            Get the path to the CA cert which issue the cert for \"myuser\":\n\n                mypath = cdir.getUserCaPath('myuser')\n\n        Returns:\n            str: The path if exists.\n        '''\n        cert = self.getUserCert(name)\n        if cert is None:\n            return None\n\n        return self._getCaPath(cert)", "response": "Gets the path to the CA certificate that issued a given user keypair."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the name of the first existing user cert for a given user and host.", "response": "def getUserForHost(self, user, host):\n        '''\n        Gets the name of the first existing user cert for a given user and host.\n\n        Args:\n            user (str): The name of the user.\n            host (str): The name of the host.\n\n        Examples:\n            Get the name for the \"myuser\" user cert at \"cool.vertex.link\":\n\n                usercertname = cdir.getUserForHost('myuser', 'cool.vertex.link')\n\n        Returns:\n            str: The cert name, if exists.\n        '''\n        for name in iterFqdnUp(host):\n            usercert = '%s@%s' % (user, name)\n            if self.isUserCert(usercert):\n                return usercert"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nimport certs and keys into the Synapse cert directory.", "response": "def importFile(self, path, mode, outp=None):\n        '''\n        Imports certs and keys into the Synapse cert directory\n\n        Args:\n            path (str): The path of the file to be imported.\n            mode (str): The certdir subdirectory to import the file into.\n\n        Examples:\n            Import CA certifciate 'mycoolca.crt' to the 'cas' directory.\n\n                certdir.importFile('mycoolca.crt', 'cas')\n\n        Notes:\n            importFile does not perform any validation on the files it imports.\n\n        Returns:\n            None\n        '''\n        if not os.path.isfile(path):\n            raise s_exc.NoSuchFile('File does not exist')\n\n        fname = os.path.split(path)[1]\n        parts = fname.rsplit('.', 1)\n        ext = parts[1] if len(parts) is 2 else None\n\n        if not ext or ext not in ('crt', 'key', 'p12'):\n            mesg = 'importFile only supports .crt, .key, .p12 extensions'\n            raise s_exc.BadFileExt(mesg=mesg, ext=ext)\n\n        newpath = s_common.genpath(self.certdir, mode, fname)\n        if os.path.isfile(newpath):\n            raise s_exc.FileExists('File already exists')\n\n        shutil.copy(path, newpath)\n        if outp is not None:\n            outp.printf('copied %s to %s' % (path, newpath))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks if a CA certificate exists.", "response": "def isCaCert(self, name):\n        '''\n        Checks if a CA certificate exists.\n\n        Args:\n            name (str): The name of the CA keypair.\n\n        Examples:\n            Check if the CA certificate for \"myca\" exists:\n\n                exists = cdir.isCaCert('myca')\n\n        Returns:\n            bool: True if the certificate is present, False otherwise.\n        '''\n        crtpath = self._getPathJoin('cas', '%s.crt' % name)\n        return os.path.isfile(crtpath)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nchecking if a user client certificate exists.", "response": "def isClientCert(self, name):\n        '''\n        Checks if a user client certificate (PKCS12) exists.\n\n        Args:\n            name (str): The name of the user keypair.\n\n        Examples:\n            Check if the client certificate \"myuser\" exists:\n\n                exists = cdir.isClientCert('myuser')\n\n        Returns:\n            bool: True if the certificate is present, False otherwise.\n        '''\n        crtpath = self._getPathJoin('users', '%s.p12' % name)\n        return os.path.isfile(crtpath)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef isHostCert(self, name):\n        '''\n        Checks if a host certificate exists.\n\n        Args:\n            name (str): The name of the host keypair.\n\n        Examples:\n            Check if the host cert \"myhost\" exists:\n\n                exists = cdir.isUserCert('myhost')\n\n        Returns:\n            bool: True if the certificate is present, False otherwise.\n        '''\n        crtpath = self._getPathJoin('hosts', '%s.crt' % name)\n        return os.path.isfile(crtpath)", "response": "Checks if a host certificate exists."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nchecking if a user certificate exists.", "response": "def isUserCert(self, name):\n        '''\n        Checks if a user certificate exists.\n\n        Args:\n            name (str): The name of the user keypair.\n\n        Examples:\n            Check if the user cert \"myuser\" exists:\n\n                exists = cdir.isUserCert('myuser')\n\n        Returns:\n            bool: True if the certificate is present, False otherwise.\n        '''\n        crtpath = self._getPathJoin('users', '%s.crt' % name)\n        return os.path.isfile(crtpath)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsigning a certificate with a CA keypair.", "response": "def signCertAs(self, cert, signas):\n        '''\n        Signs a certificate with a CA keypair.\n\n        Args:\n            cert (OpenSSL.crypto.X509): The certificate to sign.\n            signas (str): The CA keypair name to sign the new keypair with.\n\n        Examples:\n            Sign a certificate with the CA \"myca\":\n\n                cdir.signCertAs(mycert, 'myca')\n\n        Returns:\n            None\n        '''\n        cakey = self.getCaKey(signas)\n        if cakey is None:\n            raise s_exc.NoCertKey('Missing .key for %s' % signas)\n        cacert = self.getCaCert(signas)\n        if cacert is None:\n            raise s_exc.NoCertKey('Missing .crt for %s' % signas)\n\n        cert.set_issuer(cacert.get_subject())\n        cert.sign(cakey, self.signing_digest)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsigns a host CSR with a CA keypair.", "response": "def signHostCsr(self, xcsr, signas, outp=None, sans=None):\n        '''\n        Signs a host CSR with a CA keypair.\n\n        Args:\n            cert (OpenSSL.crypto.X509Req): The certificate signing request.\n            signas (str): The CA keypair name to sign the CSR with.\n            outp (synapse.lib.output.Output): The output buffer.\n            sans (list): List of subject alternative names.\n\n        Examples:\n            Sign a host key with the CA \"myca\":\n\n                cdir.signHostCsr(mycsr, 'myca')\n\n        Returns:\n            ((OpenSSL.crypto.PKey, OpenSSL.crypto.X509)):  Tuple containing the public key and certificate objects.\n        '''\n        pkey = xcsr.get_pubkey()\n        name = xcsr.get_subject().CN\n        return self.genHostCert(name, csr=pkey, signas=signas, outp=outp, sans=sans)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef selfSignCert(self, cert, pkey):\n        '''\n        Self-sign a certificate.\n\n        Args:\n            cert (OpenSSL.crypto.X509): The certificate to sign.\n            pkey (OpenSSL.crypto.PKey): The PKey with which to sign the certificate.\n\n        Examples:\n            Sign a given certificate with a given private key:\n\n                cdir.selfSignCert(mycert, myotherprivatekey)\n\n        Returns:\n            None\n        '''\n        cert.set_issuer(cert.get_subject())\n        cert.sign(pkey, self.signing_digest)", "response": "Self - sign a certificate."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef signUserCsr(self, xcsr, signas, outp=None):\n        '''\n        Signs a user CSR with a CA keypair.\n\n        Args:\n            cert (OpenSSL.crypto.X509Req): The certificate signing request.\n            signas (str): The CA keypair name to sign the CSR with.\n            outp (synapse.lib.output.Output): The output buffer.\n\n        Examples:\n            cdir.signUserCsr(mycsr, 'myca')\n\n        Returns:\n            ((OpenSSL.crypto.PKey, OpenSSL.crypto.X509)): Tuple containing the public key and certificate objects.\n        '''\n        pkey = xcsr.get_pubkey()\n        name = xcsr.get_subject().CN\n        return self.genUserCert(name, csr=pkey, signas=signas, outp=outp)", "response": "Signs a user CSR with a CA keypair."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an ssl. SSLContext appropriate for initiating a TLS session Returns an ssl. SSLContext appropriate for initiating a TLS session", "response": "def getClientSSLContext(self):\n        '''\n        Returns an ssl.SSLContext appropriate for initiating a TLS session\n        '''\n        sslctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n        self._loadCasIntoSSLContext(sslctx)\n\n        return sslctx"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getServerSSLContext(self, hostname=None):\n        '''\n        Returns an ssl.SSLContext appropriate to listen on a socket\n\n        Args:\n            hostname:  if None, the value from socket.gethostname is used to find the key in the servers directory.\n            This name should match the not-suffixed part of two files ending in .key and .crt in the hosts subdirectory\n\n        '''\n        sslctx = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)\n        if hostname is None:\n            hostname = socket.gethostname()\n        certfile = self.getHostCertPath(hostname)\n        if certfile is None:\n            raise s_exc.NoCertKey('Missing .crt for %s' % hostname)\n        keyfile = self.getHostKeyPath(hostname)\n        if keyfile is None:\n            raise s_exc.NoCertKey('Missing .key for %s' % hostname)\n\n        sslctx.load_cert_chain(certfile, keyfile)\n\n        return sslctx", "response": "Returns an ssl. SSLContext appropriate to listen on a socket."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef saveCertPem(self, cert, path):\n        '''\n        Save a certificate in PEM format to a file outside the certdir.\n        '''\n        with s_common.genfile(path) as fd:\n            fd.write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert))", "response": "Save a certificate in PEM format to a file outside the certdir."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave a private key in PEM format to a file outside the certdir.", "response": "def savePkeyPem(self, pkey, path):\n        '''\n        Save a private key in PEM format to a file outside the certdir.\n        '''\n        with s_common.genfile(path) as fd:\n            fd.write(crypto.dump_privatekey(crypto.FILETYPE_PEM, pkey))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nperforming one side of an Ecliptic Curve Diffie Hellman Ephemeral key exchange.", "response": "def doECDHE(statprv_u, statpub_v, ephmprv_u, ephmpub_v,\n            length=64,\n            salt=None,\n            info=None):\n    '''\n    Perform one side of an Ecliptic Curve Diffie Hellman Ephemeral key exchange.\n\n    Args:\n        statprv_u (PriKey): Static Private Key for U\n        statpub_v (PubKey: Static Public Key for V\n        ephmprv_u (PriKey): Ephemeral Private Key for U\n        ephmpub_v (PubKey): Ephemeral Public Key for V\n        length (int): Number of bytes to return\n        salt (bytes): Salt to use when computing the key.\n        info (bytes): Additional information to use when computing the key.\n\n    Notes:\n        This makes no assumption about the reuse of the Ephemeral keys passed\n        to the function. It is the caller's responsibility to destroy the keys\n        after they are used for doing key generation. This implementation is\n        the dhHybrid1 scheme described in NIST 800-56A Revision 2.\n\n    Returns:\n        bytes: The derived key.\n    '''\n    zs = statprv_u.exchange(statpub_v)\n    ze = ephmprv_u.exchange(ephmpub_v)\n    z = ze + zs\n    kdf = c_hkdf.HKDF(c_hashes.SHA256(),\n                      length=length,\n                      salt=salt,\n                      info=info,\n                      backend=default_backend())\n    k = kdf.derive(z)\n    return k"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the ECC signature for the given bytes.", "response": "def sign(self, byts):\n        '''\n        Compute the ECC signature for the given bytestream.\n\n        Args:\n            byts (bytes): The bytes to sign.\n\n        Returns:\n            bytes: The RSA Signature bytes.\n        '''\n        chosen_hash = c_hashes.SHA256()\n        hasher = c_hashes.Hash(chosen_hash, default_backend())\n        hasher.update(byts)\n        digest = hasher.finalize()\n        return self.priv.sign(digest,\n                              c_ec.ECDSA(c_utils.Prehashed(chosen_hash))\n                              )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef exchange(self, pubkey):\n        '''\n        Perform a ECDH key exchange with a public key.\n\n        Args:\n            pubkey (PubKey): A PubKey to perform the ECDH with.\n\n        Returns:\n            bytes: The ECDH bytes. This is deterministic for a given pubkey\n            and private key.\n        '''\n        try:\n            return self.priv.exchange(c_ec.ECDH(), pubkey.publ)\n        except ValueError as e:\n            raise s_exc.BadEccExchange(mesg=str(e))", "response": "Perform a ECDH key exchange with a public key."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the private key bytes in DER format.", "response": "def dump(self):\n        '''\n        Get the private key bytes in DER/PKCS8 format.\n\n        Returns:\n            bytes: The DER/PKCS8 encoded private key.\n        '''\n        return self.priv.private_bytes(\n            encoding=c_ser.Encoding.DER,\n            format=c_ser.PrivateFormat.PKCS8,\n            encryption_algorithm=c_ser.NoEncryption())"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef dump(self):\n        '''\n        Get the public key bytes in DER/SubjectPublicKeyInfo format.\n\n        Returns:\n            bytes: The DER/SubjectPublicKeyInfo encoded public key.\n        '''\n        return self.publ.public_bytes(\n            encoding=c_ser.Encoding.DER,\n            format=c_ser.PublicFormat.SubjectPublicKeyInfo)", "response": "Dump the public key in DER format."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef verify(self, byts, sign):\n        '''\n        Verify the signature for the given bytes using the ECC\n        public key.\n\n        Args:\n            byts (bytes): The data bytes.\n            sign (bytes): The signature bytes.\n\n        Returns:\n            bool: True if the data was verified, False otherwise.\n        '''\n        try:\n            chosen_hash = c_hashes.SHA256()\n            hasher = c_hashes.Hash(chosen_hash, default_backend())\n            hasher.update(byts)\n            digest = hasher.finalize()\n            self.publ.verify(sign,\n                             digest,\n                             c_ec.ECDSA(c_utils.Prehashed(chosen_hash))\n                             )\n            return True\n        except InvalidSignature:\n            logger.exception('Error in publ.verify')\n            return False", "response": "Verify the signature for the given bytes using the ECC\n        public key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chopurl(url):\n    '''\n    A sane \"stand alone\" url parser.\n\n    Example:\n\n        info = chopurl(url)\n    '''\n    ret = {}\n    if url.find('://') == -1:\n        raise s_exc.BadUrl(':// not found in [{}]!'.format(url))\n\n    scheme, remain = url.split('://', 1)\n    ret['scheme'] = scheme.lower()\n\n    # carve query params from the end\n    if remain.find('?') != -1:\n        query = {}\n        remain, queryrem = remain.split('?', 1)\n\n        for qkey in queryrem.split('&'):\n            qval = None\n            if qkey.find('=') != -1:\n                qkey, qval = qkey.split('=', 1)\n\n            query[qkey] = qval\n\n        ret['query'] = query\n\n    pathrem = ''\n    slashoff = remain.find('/')\n    if slashoff != -1:\n        pathrem = remain[slashoff:]\n        remain = remain[:slashoff]\n\n    # detect user[:passwd]@netloc syntax\n    if remain.find('@') != -1:\n        user, remain = remain.rsplit('@', 1)\n        if user.find(':') != -1:\n            user, passwd = user.split(':', 1)\n            ret['passwd'] = passwd\n\n        ret['user'] = user\n\n    # remain should be down to host[:port]\n\n    # detect ipv6 [addr]:port syntax\n    if remain.startswith('['):\n        hostrem, portstr = remain.rsplit(':', 1)\n        ret['port'] = int(portstr)\n        ret['host'] = hostrem[1:-1]\n\n    # detect ipv6 without port syntax\n    elif remain.count(':') > 1:\n        ret['host'] = remain\n\n    # regular old host or host:port syntax\n    else:\n\n        if remain.find(':') != -1:\n            remain, portstr = remain.split(':', 1)\n            ret['port'] = int(portstr)\n\n        ret['host'] = remain\n\n    ret['path'] = pathrem\n    return ret", "response": "A sane \"stand alone\" url parser."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef guid(self):\n        '''\n        Use elements from this hash set to create a unique\n        (re)identifier.\n        '''\n        iden = hashlib.md5()\n        props = {'size': self.size}\n\n        for name, item in self.hashes:\n            iden.update(item.digest())\n            props[name] = item.hexdigest()\n\n        return iden.hexdigest(), props", "response": "Return a unique identifier for this object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconsume all the bytes from a file like object.", "response": "def eatfd(self, fd):\n        '''\n        Consume all the bytes from a file like object.\n\n        Example:\n\n            hset = HashSet()\n            hset.eatfd(fd)\n\n        '''\n        fd.seek(0)\n        byts = fd.read(10000000)\n        while byts:\n            self.update(byts)\n            byts = fd.read(10000000)\n\n        return self.guid()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, byts):\n        '''\n        Update all the hashes in the set with the given bytes.\n        '''\n        self.size += len(byts)\n        [h[1].update(byts) for h in self.hashes]", "response": "Update all the hashes in the set with the given bytes."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef claim(typ, **info):\n    '''\n    Add an entry to the provenance stack for the duration of the context\n    '''\n    stack = s_task.varget('provstack')\n\n    if len(stack) > 256:  # pragma: no cover\n        raise s_exc.RecursionLimitHit(mesg='Hit global recursion limit')\n\n    stack.push(typ, **info)\n\n    try:\n        yield\n    finally:\n        stack.pop()", "response": "A context manager that claims a particular type of object in the provenance stack."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nduplicates the current provenance stack onto another task", "response": "def dupstack(newtask):\n    '''\n    Duplicate the current provenance stack onto another task\n    '''\n    stack = s_task.varget('provstack')\n    s_task.varset('provstack', stack.copy(), newtask)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the provenance stack given the iden to it", "response": "def getProvStack(self, iden: bytes):\n        '''\n        Returns the provenance stack given the iden to it\n        '''\n        retn = self.slab.get(iden, db=self.db)\n        if retn is None:\n            return None\n\n        return s_msgpack.un(retn)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef provStacks(self, offs, size):\n        '''\n        Returns a stream of provenance stacks at the given offset\n        '''\n        for _, iden in self.provseq.slice(offs, size):\n            stack = self.getProvStack(iden)\n            if stack is None:\n                continue\n            yield (iden, stack)", "response": "Returns a generator of provenance stacks at the given offset and size."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the iden corresponding to a provenance stack and stores if it hasn t seen it before", "response": "def getProvIden(self, provstack):\n        '''\n        Returns the iden corresponding to a provenance stack and stores if it hasn't seen it before\n        '''\n        iden = _providen(provstack)\n        misc, frames = provstack\n        # Convert each frame back from (k, v) tuples to a dict\n        dictframes = [(typ, {k: v for (k, v) in info}) for (typ, info) in frames]\n        bytz = s_msgpack.en((misc, dictframes))\n        didwrite = self.slab.put(iden, bytz, overwrite=False, db=self.db)\n        if didwrite:\n            self.provseq.save([iden])\n\n        return iden"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef commit(self):\n        '''\n        Writes the current provenance stack to storage if it wasn't already there and returns it\n\n        Returns (Tuple[bool, str, List[]]):\n            Whether the stack was not cached, the iden of the prov stack, and the provstack\n        '''\n        providen, provstack = get()\n        wasnew = (providen is None)\n        if wasnew:\n            providen = self.getProvIden(provstack)\n            setiden(providen)\n        return wasnew, s_common.ehex(providen), provstack", "response": "Writes the current provenance stack to storage if it wasn t already there and returns it"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsave a series of items into a sequence.", "response": "def save(self, items):\n        '''\n        Save a series of items to a sequence.\n\n        Args:\n            items (tuple): The series of items to save into the sequence.\n\n        Returns:\n            The index of the first item\n        '''\n        rows = []\n        indx = self.indx\n\n        size = 0\n        tick = s_common.now()\n\n        for item in items:\n\n            byts = s_msgpack.en(item)\n\n            size += len(byts)\n\n            lkey = s_common.int64en(indx)\n            indx += 1\n\n            rows.append((lkey, byts))\n\n        self.slab.putmulti(rows, append=True, db=self.db)\n        took = s_common.now() - tick\n\n        origindx = self.indx\n        self.indx = indx\n        return {'indx': indx, 'size': size, 'count': len(items), 'time': tick, 'took': took}\n\n        return origindx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndetermining the next insert offset according to storage.", "response": "def nextindx(self):\n        '''\n        Determine the next insert offset according to storage.\n\n        Returns:\n            int: The next insert offset.\n        '''\n        indx = 0\n        with s_lmdbslab.Scan(self.slab, self.db) as curs:\n            last_key = curs.last_key()\n            if last_key is not None:\n                indx = s_common.int64un(last_key) + 1\n        return indx"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter(self, offs):\n        '''\n        Iterate over items in a sequence from a given offset.\n\n        Args:\n            offs (int): The offset to begin iterating from.\n\n        Yields:\n            (indx, valu): The index and valu of the item.\n        '''\n        startkey = s_common.int64en(offs)\n\n        for lkey, lval in self.slab.scanByRange(startkey, db=self.db):\n            indx = s_common.int64un(lkey)\n            valu = s_msgpack.un(lval)\n            yield indx, valu", "response": "Iterate over items in a sequence from a given offset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef rows(self, offs):\n        '''\n        Iterate over raw indx, bytes tuples from a given offset.\n        '''\n        lkey = s_common.int64en(offs)\n        for lkey, byts in self.slab.scanByRange(lkey, db=self.db):\n            indx = s_common.int64un(lkey)\n            yield indx, byts", "response": "Iterate over raw indx bytes tuples from a given offset."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef latlong(text):\n    '''\n    Chop a latlong string and return (float,float).\n    Does not perform validation on the coordinates.\n\n    Args:\n        text (str):  A longitude,latitude string.\n\n    Returns:\n        (float,float): A longitude, latitude float tuple.\n    '''\n    nlat, nlon = text.split(',')\n    return (float(nlat), float(nlon))", "response": "Chop a latlong string and return a tuple of the latitude and longitude of the object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndetermining if the given point is within dist of any of the given points.", "response": "def near(point, dist, points):\n    '''\n    Determine if the given point is within dist of any of points.\n\n    Args:\n        point ((float,float)): A latitude, longitude float tuple.\n        dist (int): A distance in mm ( base units )\n        points (list): A list of latitude, longitude float tuples to compare against.\n    '''\n    for cmpt in points:\n        if haversine(point, cmpt) <= dist:\n            return True\n    return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef haversine(px, py, r=r_mm):\n    '''\n    Calculate the haversine distance between two points\n    defined by (lat,lon) tuples.\n\n    Args:\n        px ((float,float)): lat/long position 1\n        py ((float,float)): lat/long position 2\n        r (float): Radius of sphere\n\n    Returns:\n        (int):  Distance in mm.\n    '''\n    lat1, lon1 = px\n    lat2, lon2 = py\n\n    dlat = math.radians(lat2 - lat1)\n    dlon = math.radians(lon2 - lon1)\n    lat1 = math.radians(lat1)\n    lat2 = math.radians(lat2)\n\n    a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n    c = 2 * math.asin(math.sqrt(a))\n\n    return c * r", "response": "Calculate the haversine distance between two points."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate a min max bounding box for the specified latitude and longitude.", "response": "def bbox(lat, lon, dist):\n    '''\n    Calculate a min/max bounding box for the circle defined by lalo/dist.\n\n    Args:\n        lat (float): The latitude in degrees\n        lon (float): The longitude in degrees\n        dist (int): A distance in geo:dist base units (mm)\n\n    Returns:\n        (float,float,float,float): (latmin, latmax, lonmin, lonmax)\n    '''\n    latr = math.radians(lat)\n    lonr = math.radians(lon)\n\n    rad = r_mm\n    prad = rad * math.cos(latr)\n\n    latd = dist / rad\n    lond = dist / prad\n\n    latmin = math.degrees(latr - latd)\n    latmax = math.degrees(latr + latd)\n    lonmin = math.degrees(lonr - lond)\n    lonmax = math.degrees(lonr + lond)\n\n    return (latmin, latmax, lonmin, lonmax)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _get_endpoint(self):\n        self.endpoint = 'https://api.sumologic.com/api/v1'\n        self.response = self.session.get('https://api.sumologic.com/api/v1/collectors')  # Dummy call to get endpoint\n        endpoint = self.response.url.replace('/collectors', '')  # dirty hack to sanitise URI and retain domain\n        return endpoint", "response": "Get the endpoint for the SumoLogic REST API"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef search_metrics(self, query, fromTime=None, toTime=None, requestedDataPoints=600, maxDataPoints=800):\n        '''Perform a single Sumo metrics query'''\n        def millisectimestamp(ts):\n            '''Convert UNIX timestamp to milliseconds'''\n            if ts > 10**12:\n                ts = ts/(10**(len(str(ts))-13))\n            else:\n                ts = ts*10**(12-len(str(ts)))\n            return int(ts)\n\n        params = {'query': [{\"query\":query, \"rowId\":\"A\"}],\n                  'startTime': millisectimestamp(fromTime),\n                  'endTime': millisectimestamp(toTime),\n                  'requestedDataPoints': requestedDataPoints,\n                  'maxDataPoints': maxDataPoints}\n        r = self.post('/metrics/results', params)\n        return json.loads(r.text)", "response": "Perform a single Sumo metrics query"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef connect(self, protocol=None, mode=None, disposition=None):\n        self.component.connect(protocol, mode, disposition)", "response": "connect to the base component"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translateprotocolmask(protocol):\n    pcscprotocol = 0\n    if None != protocol:\n        if CardConnection.T0_protocol & protocol:\n            pcscprotocol |= SCARD_PROTOCOL_T0\n        if CardConnection.T1_protocol & protocol:\n            pcscprotocol |= SCARD_PROTOCOL_T1\n        if CardConnection.RAW_protocol & protocol:\n            pcscprotocol |= SCARD_PROTOCOL_RAW\n        if CardConnection.T15_protocol & protocol:\n            pcscprotocol |= SCARD_PROTOCOL_T15\n    return pcscprotocol", "response": "Translate CardConnection protocol mask into PCSC protocol mask."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef translateprotocolheader(protocol):\n    pcscprotocol = 0\n    if None != protocol:\n        if CardConnection.T0_protocol == protocol:\n            pcscprotocol = SCARD_PCI_T0\n        if CardConnection.T1_protocol == protocol:\n            pcscprotocol = SCARD_PCI_T1\n        if CardConnection.RAW_protocol == protocol:\n            pcscprotocol = SCARD_PCI_RAW\n    return pcscprotocol", "response": "Translate protocol into PCSC protocol header."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconnect to the card.", "response": "def connect(self, protocol=None, mode=None, disposition=None):\n        \"\"\"Connect to the card.\n\n        If protocol is not specified, connect with the default\n        connection protocol.\n\n        If mode is not specified, connect with SCARD_SHARE_SHARED.\"\"\"\n        CardConnection.connect(self, protocol)\n        pcscprotocol = translateprotocolmask(protocol)\n        if 0 == pcscprotocol:\n            pcscprotocol = self.getProtocol()\n\n        if mode == None:\n            mode = SCARD_SHARE_SHARED\n\n        # store the way to dispose the card\n        if disposition == None:\n            disposition = SCARD_UNPOWER_CARD\n        self.disposition = disposition\n\n        hresult, self.hcard, dwActiveProtocol = SCardConnect(\n            self.hcontext, str(self.reader), mode, pcscprotocol)\n        if hresult != 0:\n            self.hcard = None\n            if hresult in (SCARD_W_REMOVED_CARD, SCARD_E_NO_SMARTCARD):\n                raise NoCardException('Unable to connect', hresult=hresult)\n            else:\n                raise CardConnectionException(\n                    'Unable to connect with protocol: ' + \\\n                    dictProtocol[pcscprotocol] + '. ' + \\\n                    SCardGetErrorMessage(hresult))\n\n        protocol = 0\n        if dwActiveProtocol == SCARD_PROTOCOL_T0 | SCARD_PROTOCOL_T1:\n            # special case for T0 | T1\n            # this happen when mode=SCARD_SHARE_DIRECT and no protocol is\n            # then negociated with the card\n            protocol = CardConnection.T0_protocol | CardConnection.T1_protocol\n        else:\n            for p in dictProtocol:\n                if p == dwActiveProtocol:\n                    protocol = eval(\"CardConnection.%s_protocol\" % dictProtocol[p])\n        PCSCCardConnection.setProtocol(self, protocol)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndisconnect from the card.", "response": "def disconnect(self):\n        \"\"\"Disconnect from the card.\"\"\"\n\n        # when __del__() is invoked in response to a module being deleted,\n        # e.g., when execution of the program is done, other globals referenced\n        # by the __del__() method may already have been deleted.\n        # this causes CardConnection.disconnect to except with a TypeError\n        try:\n            CardConnection.disconnect(self)\n        except TypeError:\n            pass\n        if None != self.hcard:\n            hresult = SCardDisconnect(self.hcard, self.disposition)\n            if hresult != 0:\n                raise CardConnectionException(\n                    'Failed to disconnect: ' + \\\n                    SCardGetErrorMessage(hresult))\n            self.hcard = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the ATR of the current card.", "response": "def getATR(self):\n        \"\"\"Return card ATR\"\"\"\n        CardConnection.getATR(self)\n        if None == self.hcard:\n            raise CardConnectionException('Card not connected')\n        hresult, reader, state, protocol, atr = SCardStatus(self.hcard)\n        if hresult != 0:\n            raise CardConnectionException(\n                'Failed to get status: ' + \\\n                SCardGetErrorMessage(hresult))\n        return atr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ntransmit an apdu to the card and return the response bytes.", "response": "def doTransmit(self, bytes, protocol=None):\n        \"\"\"Transmit an apdu to the card and return response apdu.\n\n        @param bytes:    command apdu to transmit (list of bytes)\n\n        @param protocol: the transmission protocol, from\n            CardConnection.T0_protocol, CardConnection.T1_protocol, or\n            CardConnection.RAW_protocol\n\n        @return:     a tuple (response, sw1, sw2) where\n                    sw1 is status word 1, e.g. 0x90\n                    sw2 is status word 2, e.g. 0x1A\n                    response are the response bytes excluding status words\n        \"\"\"\n        if None == protocol:\n            protocol = self.getProtocol()\n        CardConnection.doTransmit(self, bytes, protocol)\n        pcscprotocolheader = translateprotocolheader(protocol)\n        if 0 == pcscprotocolheader:\n            raise CardConnectionException(\n                'Invalid protocol in transmit: must be ' + \\\n                'CardConnection.T0_protocol, ' + \\\n                'CardConnection.T1_protocol, or ' + \\\n                'CardConnection.RAW_protocol')\n        if None == self.hcard:\n            raise CardConnectionException('Card not connected')\n        hresult, response = SCardTransmit(\n            self.hcard, pcscprotocolheader, bytes)\n        if hresult != 0:\n            raise CardConnectionException(\n                'Failed to transmit with protocol ' + \\\n                dictProtocolHeader[pcscprotocolheader] + '. ' + \\\n                SCardGetErrorMessage(hresult))\n\n        sw1 = (response[-2] + 256) % 256\n        sw2 = (response[-1] + 256) % 256\n\n        data = [(x + 256) % 256 for x in response[:-2]]\n        return list(data), sw1, sw2"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ntransmitting a control command to the reader and return the response.", "response": "def doControl(self, controlCode, bytes=[]):\n        \"\"\"Transmit a control command to the reader and return response.\n\n        controlCode: control command\n\n        bytes:       command data to transmit (list of bytes)\n\n        return:      response are the response bytes (if any)\n        \"\"\"\n        CardConnection.doControl(self, controlCode, bytes)\n        hresult, response = SCardControl(self.hcard, controlCode, bytes)\n        if hresult != 0:\n            raise SmartcardException(\n                'Failed to control ' + SCardGetErrorMessage(hresult))\n\n        data = [(x + 256) % 256 for x in response]\n        return list(data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting an attribute from the card", "response": "def doGetAttrib(self, attribId):\n        \"\"\"get an attribute\n\n        attribId: Identifier for the attribute to get\n\n        return:   response are the attribute byte array\n        \"\"\"\n        CardConnection.doGetAttrib(self, attribId)\n        hresult, response = SCardGetAttrib(self.hcard, attribId)\n        if hresult != 0:\n            raise SmartcardException(\n                'Failed to getAttrib ' + SCardGetErrorMessage(hresult))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getATR(reader):\n    connection = reader.createConnection()\n    atr = \"\"\n    try:\n        connection.connect()\n        atr = smartcard.util.toHexString(connection.getATR())\n        connection.disconnect()\n    except smartcard.Exceptions.NoCardException:\n        atr = \"no card inserted\"\n    return atr", "response": "Return the ATR of the card inserted into the reader."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef module_path():\n\n    if we_are_frozen():\n        return os.path.dirname(\n                unicode(sys.executable, sys.getfilesystemencoding()))\n\n    return os.path.dirname(unicode(__file__, sys.getfilesystemencoding()))", "response": "This will get us the module s directory"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove a reader group from the set.", "response": "def removereadergroup(self, group):\n        \"\"\"Remove a reader group\"\"\"\n        if not isinstance(group, type(\"\")):\n            raise BadReaderGroupException\n        self.remove(group)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect to the current card.", "response": "def connect(self, protocol=None, mode=None, disposition=None):\n        \"\"\"Connect to card.\n        @param protocol: a bit mask of the protocols to use, from\n        L{CardConnection.T0_protocol}, L{CardConnection.T1_protocol},\n        L{CardConnection.RAW_protocol}, L{CardConnection.T15_protocol}\n\n        @param mode: SCARD_SHARE_SHARED (default), SCARD_SHARE_EXCLUSIVE or\n        SCARD_SHARE_DIRECT\n\n        @param disposition: SCARD_LEAVE_CARD (default), SCARD_RESET_CARD,\n        SCARD_UNPOWER_CARD or SCARD_EJECT_CARD\n        \"\"\"\n        Observable.setChanged(self)\n        Observable.notifyObservers(self, CardConnectionEvent('connect'))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef transmit(self, bytes, protocol=None):\n        Observable.setChanged(self)\n        Observable.notifyObservers(self,\n                                   CardConnectionEvent(\n                                       'command',\n                                       [bytes, protocol]))\n        data, sw1, sw2 = self.doTransmit(bytes, protocol)\n        Observable.setChanged(self)\n        Observable.notifyObservers(self,\n                                   CardConnectionEvent(\n                                       'response',\n                                       [data, sw1, sw2]))\n        if self.errorcheckingchain is not None:\n            self.errorcheckingchain[0](data, sw1, sw2)\n        return data, sw1, sw2", "response": "Transmit an apdu. Internally calls doTransmit() class method\n        and notify observers upon command/response APDU events.\n        Subclasses must override the doTransmit() class method.\n\n        @param bytes:      list of bytes to transmit\n\n        @param protocol:   the transmission protocol, from\n                    CardConnection.T0_protocol,\n                    CardConnection.T1_protocol, or\n                    CardConnection.RAW_protocol"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a control command and buffer.", "response": "def control(self, controlCode, bytes=[]):\n        \"\"\"Send a control command and buffer.  Internally calls doControl()\n        class method and notify observers upon command/response events.\n        Subclasses must override the doControl() class method.\n\n        @param controlCode: command code\n\n        @param bytes:       list of bytes to transmit\n        \"\"\"\n        Observable.setChanged(self)\n        Observable.notifyObservers(self,\n                                   CardConnectionEvent(\n                                       'command',\n                                       [controlCode, bytes]))\n        data = self.doControl(controlCode, bytes)\n        Observable.setChanged(self)\n        Observable.notifyObservers(self,\n                                   CardConnectionEvent(\n                                       'response',\n                                       data))\n        if self.errorcheckingchain is not None:\n            self.errorcheckingchain[0](data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the requested attribute", "response": "def getAttrib(self, attribId):\n        \"\"\"return the requested attribute\n\n        @param attribId: attribute id like SCARD_ATTR_VENDOR_NAME\n        \"\"\"\n        Observable.setChanged(self)\n        Observable.notifyObservers(self,\n                                   CardConnectionEvent(\n                                       'attrib',\n                                       [attribId]))\n        data = self.doGetAttrib(attribId)\n        if self.errorcheckingchain is not None:\n            self.errorcheckingchain[0](data)\n        return data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef createConnection(self):\n        uri = self.reader.createConnection()\n        return Pyro.core.getAttrProxyForURI(uri)", "response": "Return a card connection thru a remote reader."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnActivateCard(self, card):\n        SimpleSCardAppEventObserver.OnActivateCard(self, card)\n        self.feedbacktext.SetLabel('Activated card: ' + repr(card))\n        self.transmitbutton.Enable()", "response": "Called when a card is activated by double - clicking\n        on the reader tree control or toolbar."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncalling when a card is deselected by clicking on the card or reader tree control or toolbar.", "response": "def OnDeselectCard(self, card):\n        \"\"\"Called when a card is selected by clicking on the\n        card or reader tree control or toolbar.\"\"\"\n        SimpleSCardAppEventObserver.OnSelectCard(self, card)\n        self.feedbacktext.SetLabel('Deselected card: ' + repr(card))\n        self.transmitbutton.Disable()"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncall when a card is selected by clicking on the card or reader tree control or toolbar.", "response": "def OnSelectCard(self, card):\n        \"\"\"Called when a card is selected by clicking on the\n        card or reader tree control or toolbar.\"\"\"\n        SimpleSCardAppEventObserver.OnSelectCard(self, card)\n        self.feedbacktext.SetLabel('Selected card: ' + repr(card))\n        if hasattr(self.selectedcard, 'connection'):\n            self.transmitbutton.Enable()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnSelectReader(self, reader):\n        SimpleSCardAppEventObserver.OnSelectReader(self, reader)\n        self.feedbacktext.SetLabel('Selected reader: ' + repr(reader))\n        self.transmitbutton.Disable()", "response": "Called when a reader is selected by clicking on the\n        reader tree control or toolbar."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating and display application frame.", "response": "def OnInit(self):\n        \"\"\"Create and display application frame.\"\"\"\n        self.frame = SimpleSCardAppFrame(\n            self.appname,\n            self.apppanel,\n            self.appstyle,\n            self.appicon,\n            self.pos,\n            self.size)\n        self.frame.Show(True)\n        self.SetTopWindow(self.frame)\n\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning command line arguments for shutting down the server ; this command line is built from the name server startup arguments.", "response": "def getShutdownArgs(self):\n        \"\"\"return command line arguments for shutting down the\n        server; this command line is built from the name server\n        startup arguments.\"\"\"\n        shutdownArgs = []\n        if self.host:\n            shutdownArgs += ['-h', self.host]\n        if self.bcport:\n            shutdownArgs += ['-p', self.bcport]\n        if self.bcaddr:\n            shutdownArgs += ['-c', self.bcaddr]\n        if self.identification:\n            shutdownArgs += ['-i', self.identification]\n\n        return shutdownArgs"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef run(self):\n        args = []\n        for arg in self.args:\n            args.append(arg)\n        Pyro.naming.main(args)", "response": "Starts Pyro naming server with command line arguments."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef stop(self):\n        args = self.getShutdownArgs() + ['shutdown']\n        Pyro.nsc.main(args)\n        self.join()", "response": "Shutdown pyro naming server."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef waitStarted(self):\n        ns = None\n        while not ns:\n            try:\n                time.sleep(3)\n                ns = Pyro.naming.NameServerLocator(\n                    identification=self.identification).getNS()\n            except Pyro.errors.NamingError as er:\n                pass", "response": "wait until name server is started."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef createConnection(self):\n        readerobj = None\n        if isinstance(self.reader, Reader):\n            readerobj = self.reader\n        elif type(self.reader) == str:\n            for reader in readers():\n                if self.reader == str(reader):\n                    readerobj = reader\n\n        if readerobj:\n            return readerobj.createConnection()\n        else:\n            # raise CardConnectionException(\n            # 'not a valid reader: ' + str(self.reader))\n            return None", "response": "Return a CardConnection to the Card object."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getreadergroups(self):\n        innerreadergroups.getreadergroups(self)\n\n        hresult, hcontext = SCardEstablishContext(SCARD_SCOPE_USER)\n        if hresult != 0:\n            raise EstablishContextException(hresult)\n        hresult, readers = SCardListReaderGroups(hcontext)\n        if hresult != 0:\n            raise ListReadersException(hresult)\n        hresult = SCardReleaseContext(hcontext)\n        if hresult != 0:\n            raise ReleaseContextException(hresult)\n        return readers", "response": "Returns the list of smartcard reader groups."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a reader group to the reader group list.", "response": "def addreadergroup(self, newgroup):\n        \"\"\"Add a reader group\"\"\"\n\n        hresult, hcontext = SCardEstablishContext(SCARD_SCOPE_USER)\n        if 0 != hresult:\n            raise error(\n                'Failed to establish context: ' + \\\n                SCardGetErrorMessage(hresult))\n        try:\n            hresult = SCardIntroduceReaderGroup(hcontext, newgroup)\n            if 0 != hresult:\n                raise error(\n                    'Unable to introduce reader group: ' + \\\n                    SCardGetErrorMessage(hresult))\n            else:\n                innerreadergroups.addreadergroup(self, newgroup)\n\n        finally:\n            hresult = SCardReleaseContext(hcontext)\n            if 0 != hresult:\n                raise error(\n                    'Failed to release context: ' + \\\n                    SCardGetErrorMessage(hresult))"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves a reader group from the reader.", "response": "def removereadergroup(self, group):\n        \"\"\"Remove a reader group\"\"\"\n\n        hresult, hcontext = SCardEstablishContext(SCARD_SCOPE_USER)\n        if 0 != hresult:\n            raise error(\n                'Failed to establish context: ' + \\\n                SCardGetErrorMessage(hresult))\n        try:\n            hresult = SCardForgetReaderGroup(hcontext, group)\n            if hresult != 0:\n                raise error(\n                    'Unable to forget reader group: ' + \\\n                    SCardGetErrorMessage(hresult))\n            else:\n                innerreadergroups.removereadergroup(self, group)\n\n        finally:\n            hresult = SCardReleaseContext(hcontext)\n            if 0 != hresult:\n                raise error(\n                    'Failed to release context: ' + \\\n                    SCardGetErrorMessage(hresult))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseFeatureRequest(response):\n    features = []\n    while (len(response) > 0):\n        tag = response[0]\n        control = ((((((response[2] << 8) +\n                        response[3]) << 8) +\n                        response[4]) << 8) +\n                        response[5])\n        try:\n            features.append([Features[tag], control])\n        except KeyError:\n            pass\n        del response[:6]\n    return features", "response": "Parse the response from the CM_IOCTL_GET_FEATURE_REQUEST commmand into a list of Part10 features."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hasFeature(featureList, feature):\n    for f in featureList:\n        if f[0] == feature or Features[f[0]] == feature:\n            return f[1]", "response": "returns the controlCode for a feature or None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef getPinProperties(cardConnection, featureList=None, controlCode=None):\n    if controlCode is None:\n        if featureList is None:\n            featureList = getFeatureRequest(cardConnection)\n        controlCode = hasFeature(featureList, FEATURE_IFD_PIN_PROPERTIES)\n\n    if controlCode is None:\n        return {'raw': []}\n\n    response = cardConnection.control(controlCode, [])\n    d = {\n            'raw': response,\n            'LcdLayoutX': response[0],\n            'LcdLayoutY': response[1],\n            'EntryValidationCondition': response[2],\n            'TimeOut2': response[3]}\n\n    return d", "response": "get the PIN_PROPERTIES structure"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the GET_TLV_PROPERTIES response from the cardConnection", "response": "def getTlvProperties(cardConnection, featureList=None, controlCode=None):\n    \"\"\" return the GET_TLV_PROPERTIES structure\n\n    @param cardConnection: L{CardConnection} object\n    @param featureList: feature list as returned by L{getFeatureRequest()}\n    @param controlCode: control code for L{FEATURE_GET_TLV_PROPERTIES}\n\n    @rtype: dict\n    @return: a dict \"\"\"\n    if controlCode is None:\n        if featureList is None:\n            featureList = getFeatureRequest(cardConnection)\n        controlCode = hasFeature(featureList, FEATURE_GET_TLV_PROPERTIES)\n\n    if controlCode is None:\n        return {'raw': []}\n\n    response = cardConnection.control(controlCode, [])\n    return parseTlvProperties(response)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef parseTlvProperties(response):\n    d = {\n            'raw': response,\n        }\n\n    # create a new list to consume it\n    tmp = list(response)\n    while tmp:\n        tag = tmp[0]\n        len = tmp[1]\n        data = tmp[2:2 + len]\n\n        if PCSCv2_PART10_PROPERTY_sFirmwareID == tag:\n            # convert to a string\n            data = \"\".join([chr(c) for c in data])\n        # we now suppose the value is an integer\n        elif 1 == len:\n            # byte\n            data = data[0]\n        elif 2 == len:\n            # 16 bits value\n            data = data[1] * 256 + data[0]\n        elif 4 == len:\n            # 32 bits value\n            data = ((data[3] * 256 + data[2]) * 256 + data[1]) * 256 + data[0]\n\n        # store the value in the dictionnary\n        try:\n            d[Properties[tag]] = data\n        except KeyError:\n            d[\"UNKNOWN\"] = data\n\n        del tmp[0:2 + len]\n\n    return d", "response": "parse the GET_TLV_PROPERTIES response from the PCSCv2_PART10_PROPERTY_sFirmwareID command and return the dict"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a card connection thru the reader.", "response": "def createConnection(self):\n        \"\"\"Return a card connection thru the reader.\"\"\"\n        connection = RemoteCardConnection(self.readerobj.createConnection())\n        daemon = PyroDaemon.PyroDaemon()\n        uri = daemon.connect(connection)\n        return uri"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef update(self, observable, actions):\n        (addedreaders, removedreaders) = actions\n        for reader in addedreaders:\n            remotereader = RemoteReader(reader)\n            self.remotereaders[reader.name] = remotereader\n            name = \"\".join(reader.name.split(' '))\n            name = \":pyscard.smartcard.readers.\" + \"\".join(name.split('.'))\n            uri = self.daemon.connect(remotereader, name)\n        for reader in removedreaders:\n            remotereader = self.remotereaders[reader.name]\n            self.daemon.disconnect(remotereader)\n            del self.remotereaders[reader.name]\n        self.pn.listall()", "response": "Called when a local reader is added or removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef addObserver(self, observer):\n        Observable.addObserver(self, observer)\n\n        # If self.startOnDemand is True, the reader monitoring\n        # thread only runs when there are observers.\n        if self.startOnDemand:\n            if 0 < self.countObservers():\n                if not self.rmthread:\n                    self.rmthread = ReaderMonitoringThread(\n                        self,\n                        self.readerProc, self.period)\n\n                    # start reader monitoring thread in another thread to\n                    # avoid a deadlock; addObserver and notifyObservers called\n                    # in the ReaderMonitoringThread run() method are\n                    # synchronized\n                    try:\n                        # Python 3.x\n                        import _thread\n                        _thread.start_new_thread(self.rmthread.start, ())\n                    except:\n                        # Python 2.x\n                        import thread\n                        thread.start_new_thread(self.rmthread.start, ())\n        else:\n            observer.update(self, (self.rmthread.readers, []))", "response": "Add an observer to the list of observers."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef deleteObserver(self, observer):\n        Observable.deleteObserver(self, observer)\n        # If self.startOnDemand is True, the reader monitoring\n        # thread is stopped when there are no more observers.\n        if self.startOnDemand:\n            if 0 == self.countObservers():\n                self.rmthread.stop()\n                del self.rmthread\n                self.rmthread = None", "response": "Removes an observer from the manager."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef run(self):\n        while not self.stopEvent.isSet():\n            try:\n                # no need to monitor if no observers\n                if 0 < self.observable.countObservers():\n                    currentReaders = self.readerProc()\n                    addedReaders = []\n                    removedReaders = []\n\n                    if currentReaders != self.readers:\n                        for reader in currentReaders:\n                            if reader not in self.readers:\n                                addedReaders.append(reader)\n                        for reader in self.readers:\n                            if reader not in currentReaders:\n                                removedReaders.append(reader)\n\n                        if addedReaders or removedReaders:\n                            # Notify observers\n                            self.readers = []\n                            for r in currentReaders:\n                                self.readers.append(r)\n                            self.observable.setChanged()\n                            self.observable.notifyObservers((addedReaders,\n                                                            removedReaders))\n\n                # wait every second on stopEvent\n                self.stopEvent.wait(self.period)\n\n            except Exception:\n                # FIXME Tighten the exceptions caught by this block\n                traceback.print_exc()\n                # Most likely raised during interpreter shutdown due\n                # to unclean exit which failed to remove all observers.\n                # To solve this, we set the stop event and pass the\n                # exception to let the thread finish gracefully.\n                self.stopEvent.set()", "response": "Runs until stopEvent is notified and notify observers of all reader insertion and removal."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove from other items already in list.", "response": "def __remove_duplicates(self, _other):\n        \"\"\"Remove from other items already in list.\"\"\"\n        if not isinstance(_other, type(self)) \\\n           and not isinstance(_other, type(list)) \\\n           and not isinstance(_other, type([])):\n            other = [_other]\n        else:\n            other = list(_other)\n\n        # remove items already in self\n        newother = []\n        for i in range(0, len(other)):\n            item = other.pop(0)\n            if not list.__contains__(self, item):\n                newother.append(item)\n\n        # remove duplicate items in other\n        other = []\n        if newother != []:\n            other.append(newother[0])\n            for i in range(1, len(newother)):\n                item = newother.pop()\n                if not other.__contains__(item):\n                    other.append(item)\n        return other"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nstarts Pyro naming server with command line arguments", "response": "def run(self):\n        \"\"\"Starts Pyro naming server with command line arguments (see\n        pyro documentation) \"\"\"\n        args = []\n        for arg in self.args:\n            args.append(arg)\n        Args = Pyro.util.ArgParser()\n        Args.parse(args, 'hkmrvxn:p:b:c:d:s:i:1:2:')\n\n        hostname = Args.getOpt('n', None)\n        identification = Args.getOpt('i', None)\n        port = None\n        useNameServer = True\n\n        if port:\n            port = int(port)\n        norange = (port == 0)\n\n        self.starter = Pyro.EventService.Server.EventServiceStarter(\n            identification=identification)\n        self.starter.start(\n            hostname, port, useNameServer=useNameServer, norange=norange)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwaits until name server is started.", "response": "def waitStarted(self):\n        \"\"\"wait until name server is started.\"\"\"\n        started = False\n        while not started:\n            if self.starter != None:\n                started = self.starter.waitUntilStarted(0.5)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsynchronizing methods in the given class.", "response": "def synchronize(klass, names=None):\n    \"\"\"Synchronize methods in the given class.\n    Only synchronize the methods whose names are\n    given, or all methods if names=None.\"\"\"\n\n    # basestring does not exist on Python 3\n    try:\n        basestring\n    except NameError:\n        basestring = (str, bytes)\n\n    if isinstance(names, basestring):\n        names = names.split()\n    for (name, val) in list(klass.__dict__.items()):\n        if callable(val) and name != '__init__' and \\\n                (names is None or name in names):\n            # print(\"synchronizing\", name)\n            setattr(klass, name, synchronized(val))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef lock(self):\n        '''Lock card with SCardBeginTransaction.'''\n\n        component = self.component\n        while True:\n            if isinstance(\n                    component,\n                    smartcard.pcsc.PCSCCardConnection.PCSCCardConnection):\n                hresult = SCardBeginTransaction(component.hcard)\n                if 0 != hresult:\n                    raise CardConnectionException(\n                        'Failed to lock with SCardBeginTransaction: ' +\n                        SCardGetErrorMessage(hresult))\n                else:\n                    # print('locked')\n                    pass\n                break\n            if hasattr(component, 'component'):\n                component = component.component\n            else:\n                break", "response": "Lock card with SCardBeginTransaction."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nunlocking card with SCardEndTransaction.", "response": "def unlock(self):\n        '''Unlock card with SCardEndTransaction.'''\n        component = self.component\n        while True:\n            if isinstance(\n                    component,\n                    smartcard.pcsc.PCSCCardConnection.PCSCCardConnection):\n                hresult = SCardEndTransaction(component.hcard,\n                                              SCARD_LEAVE_CARD)\n                if 0 != hresult:\n                    raise CardConnectionException(\n                        'Failed to unlock with SCardEndTransaction: ' +\n                        SCardGetErrorMessage(hresult))\n                else:\n                    # print('unlocked')\n                    pass\n                break\n            if hasattr(component, 'component'):\n                component = component.component\n            else:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef transmit(self, bytes, protocol=None):\n        '''Gain exclusive access to card during APDU transmission for if this\n        decorator decorates a PCSCCardConnection.'''\n        data, sw1, sw2 = CardConnectionDecorator.transmit(\n            self, bytes, protocol)\n        return data, sw1, sw2", "response": "Gain exclusive access to card during APDU transmission for if this\n            decorator decorates a PCSCCardConnection."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update(self, observable, handlers):\n        addedreaders, removedreaders = handlers\n        for reader in addedreaders:\n            item = self.Append(str(reader))\n            self.SetClientData(item, reader)\n        for reader in removedreaders:\n            item = self.FindString(str(reader))\n            if wx.NOT_FOUND != item:\n                self.Delete(item)\n        selection = self.GetSelection()", "response": "Toolbar ReaderObserver callback that is notified when readers are added or removed."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends an APDU command to the connected smartcard.", "response": "def sendCommandAPDU(self, command):\n        \"\"\"Send an APDU command to the connected smartcard.\n\n        @param command: list of APDU bytes, e.g. [0xA0, 0xA4, 0x00, 0x00, 0x02]\n\n        @return: a tuple (response, sw1, sw2) where\n                response is the APDU response\n                sw1, sw2 are the two status words\n        \"\"\"\n\n        response, sw1, sw2 = self.cs.connection.transmit(command)\n\n        if len(response) > 2:\n            response.append(sw1)\n            response.append(sw2)\n        return response, sw1, sw2"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the next error checking strategy.", "response": "def next(self):\n        \"\"\"Returns next error checking strategy.\"\"\"\n        # Where this link is in the chain:\n        location = self.chain.index(self)\n        if not self.end():\n            return self.chain[location + 1]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addFilterException(self, exClass):\n\n        self.excludes.append(exClass)\n        if self.end():\n            return\n        self.next().addFilterException(exClass)", "response": "Add an exception filter to the error checking chain."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef addtoreadergroup(self, groupname):\n\n        hresult, hcontext = SCardEstablishContext(SCARD_SCOPE_USER)\n        if 0 != hresult:\n            raise EstablishContextException(hresult)\n        try:\n            hresult = SCardIntroduceReader(hcontext, self.name, self.name)\n            if 0 != hresult and SCARD_E_DUPLICATE_READER != hresult:\n                raise IntroduceReaderException(hresult, self.name)\n            hresult = SCardAddReaderToGroup(hcontext, self.name, groupname)\n            if 0 != hresult:\n                raise AddReaderToGroupException(hresult, self.name, groupname)\n        finally:\n            hresult = SCardReleaseContext(hcontext)\n            if 0 != hresult:\n                raise ReleaseContextException(hresult)", "response": "Add a reader to a reader group."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a reader from a reader group", "response": "def removefromreadergroup(self, groupname):\n        \"\"\"Remove a reader from a reader group\"\"\"\n\n        hresult, hcontext = SCardEstablishContext(SCARD_SCOPE_USER)\n        if 0 != hresult:\n            raise EstablishContextException(hresult)\n        try:\n            hresult = SCardRemoveReaderFromGroup(hcontext, self.name,\n                groupname)\n            if 0 != hresult:\n                raise RemoveReaderFromGroupException(hresult, self.name,\n                    groupname)\n        finally:\n            hresult = SCardReleaseContext(hcontext)\n            if 0 != hresult:\n                raise ReleaseContextException(hresult)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when the user activates a reader in the tree.", "response": "def OnActivateReader(self, event):\n        \"\"\"Called when the user activates a reader in the tree.\"\"\"\n        item = event.GetItem()\n        if item:\n            itemdata = self.readertreepanel.readertreectrl.GetItemPyData(item)\n            if isinstance(itemdata, smartcard.Card.Card):\n                self.ActivateCard(itemdata)\n            elif isinstance(itemdata, smartcard.reader.Reader.Reader):\n                self.dialogpanel.OnActivateReader(itemdata)\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnCardRightClick(self, event):\n        item = event.GetItem()\n        if item:\n            itemdata = self.readertreepanel.cardtreectrl.GetItemPyData(item)\n            if isinstance(itemdata, smartcard.Card.Card):\n                self.selectedcard = itemdata\n                if not hasattr(self, \"connectID\"):\n                    self.connectID = wx.NewId()\n                    self.disconnectID = wx.NewId()\n\n                    self.Bind(wx.EVT_MENU, self.OnConnect, id=self.connectID)\n                    self.Bind(\n                        wx.EVT_MENU, self.OnDisconnect, id=self.disconnectID)\n\n                menu = wx.Menu()\n                if not hasattr(self.selectedcard, 'connection'):\n                    menu.Append(self.connectID, \"Connect\")\n                else:\n                    menu.Append(self.disconnectID, \"Disconnect\")\n                self.PopupMenu(menu)\n                menu.Destroy()", "response": "Called when user right - clicks a node in the card tree control."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall when the user selects a card in the tree.", "response": "def OnSelectCard(self, event):\n        \"\"\"Called when the user selects a card in the tree.\"\"\"\n        item = event.GetItem()\n        if item:\n            itemdata = self.readertreepanel.cardtreectrl.GetItemPyData(item)\n            if isinstance(itemdata, smartcard.Card.Card):\n                self.dialogpanel.OnSelectCard(itemdata)\n            else:\n                self.dialogpanel.OnDeselectCard(itemdata)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef OnSelectReader(self, event):\n        item = event.GetItem()\n        if item:\n            itemdata = self.readertreepanel.readertreectrl.GetItemPyData(item)\n            if isinstance(itemdata, smartcard.Card.Card):\n                self.dialogpanel.OnSelectCard(itemdata)\n            elif isinstance(itemdata, smartcard.reader.Reader.Reader):\n                self.dialogpanel.OnSelectReader(itemdata)\n            else:\n                self.dialogpanel.OnDeselectCard(itemdata)", "response": "Called when the user selects a reader in the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef OnReaderComboBox(self, event):\n        cb = event.GetEventObject()\n        reader = cb.GetClientData(cb.GetSelection())\n        if isinstance(reader, smartcard.reader.Reader.Reader):\n            self.treeuserpanel.dialogpanel.OnActivateReader(reader)", "response": "Called when the user activates a reader in the toolbar combo box."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_func(fullFuncName):\n\n    # Parse out the path, module, and function\n    lastDot = fullFuncName.rfind(u\".\")\n    funcName = fullFuncName[lastDot + 1:]\n    modPath = fullFuncName[:lastDot]\n\n    aMod = get_mod(modPath)\n    aFunc = getattr(aMod, funcName)\n\n    # Assert that the function is a *callable* attribute.\n    assert callable(aFunc), u\"%s is not callable.\" % fullFuncName\n\n    # Return a reference to the function itself,\n    # not the results of the function.\n    return aFunc", "response": "Retrieve a function object from a full dotted - package name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading a module and retrieve a class.", "response": "def get_class(fullClassName, parentClass=None):\n    \"\"\"Load a module and retrieve a class (NOT an instance).\n\n    If the parentClass is supplied, className must be of parentClass\n    or a subclass of parentClass (or None is returned).\n    \"\"\"\n    aClass = get_func(fullClassName)\n\n    # Assert that the class is a subclass of parentClass.\n    if parentClass is not None:\n        if not issubclass(aClass, parentClass):\n            raise TypeError(u\"%s is not a subclass of %s\" %\n                            (fullClassName, parentClass))\n\n    # Return a reference to the class itself, not an instantiated object.\n    return aClass"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getReaderNames(self):\n\n        # get inserted readers\n        hresult, pcscreaders = SCardListReaders(self.hcontext, [])\n        if 0 != hresult and SCARD_E_NO_READERS_AVAILABLE != hresult:\n            raise ListReadersException(hresult)\n\n        readers = []\n\n        # if no readers asked, use all inserted readers\n        if None == self.readersAsked:\n            readers = pcscreaders\n\n        # otherwise use only the asked readers that are inserted\n        else:\n            for reader in self.readersAsked:\n                if not isinstance(reader, type(\"\")):\n                    reader = str(reader)\n                if reader in pcscreaders:\n                    readers = readers + [reader]\n\n        return readers", "response": "Returns the list or PCSC readers on which to wait for cards."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef waitforcard(self):\n        AbstractCardRequest.waitforcard(self)\n        cardfound = False\n\n        # for non infinite timeout, a timer will signal\n        # the end of the time-out by setting the evt event\n        evt = threading.Event()\n        if INFINITE == self.timeout:\n            timertimeout = 1\n        else:\n            timertimeout = self.timeout\n        timer = threading.Timer(\n            timertimeout, signalEvent, [evt, INFINITE == self.timeout])\n\n        # create a dictionary entry for new readers\n        readerstates = {}\n        readernames = self.getReaderNames()\n        for reader in readernames:\n            if not reader in readerstates:\n                readerstates[reader] = (reader, SCARD_STATE_UNAWARE)\n\n        # remove dictionary entry for readers that disappeared\n        for oldreader in list(readerstates.keys()):\n            if oldreader not in readernames:\n                del readerstates[oldreader]\n\n        # call SCardGetStatusChange only if we have some readers\n        if {} != readerstates:\n            hresult, newstates = SCardGetStatusChange(\n                self.hcontext, 0, list(readerstates.values()))\n        else:\n            hresult = 0\n            newstates = []\n\n        # we can expect normally time-outs or reader\n        # disappearing just before the call\n        # otherwise, raise execption on error\n        if 0 != hresult and \\\n            SCARD_E_TIMEOUT != hresult and \\\n            SCARD_E_UNKNOWN_READER != hresult:\n                raise CardRequestException(\n                    'Failed to SCardGetStatusChange ' + \\\n                    SCardGetErrorMessage(hresult))\n\n        # in case of timeout or reader disappearing,\n        # the content of the states is useless\n        # in which case we clear the changed bit\n        if SCARD_E_TIMEOUT == hresult or SCARD_E_UNKNOWN_READER == hresult:\n            for state in newstates:\n                state[1] = state[1] & (0xFFFFFFFF ^ SCARD_STATE_CHANGED)\n\n        # update readerstate\n        for state in newstates:\n            readername, eventstate, atr = state\n            readerstates[readername] = (readername, eventstate)\n\n        # if a new card is not requested, just return the first available\n        if not self.newcardonly:\n            for state in newstates:\n                readername, eventstate, atr = state\n                if eventstate & SCARD_STATE_PRESENT:\n                    reader = PCSCReader(readername)\n                    if self.cardType.matches(atr, reader):\n                        if self.cardServiceClass.supports('dummy'):\n                            cardfound = True\n                            return self.cardServiceClass(\n                                    reader.createConnection())\n\n        timerstarted = False\n        while not evt.isSet() and not cardfound:\n\n            if not timerstarted:\n                timerstarted = True\n                timer.start()\n\n            time.sleep(self.pollinginterval)\n\n            # create a dictionary entry for new readers\n            readernames = self.getReaderNames()\n            for reader in readernames:\n                if not reader in readerstates:\n                    readerstates[reader] = (reader, SCARD_STATE_UNAWARE)\n\n            # remove dictionary entry for readers that disappeared\n            for oldreader in list(readerstates.keys()):\n                if oldreader not in readernames:\n                    del readerstates[oldreader]\n\n            # wait for card insertion\n            if {} != readerstates:\n                hresult, newstates = SCardGetStatusChange(\n                    self.hcontext, 0, list(readerstates.values()))\n            else:\n                hresult = SCARD_E_TIMEOUT\n                newstates = []\n\n            # time-out\n            if SCARD_E_TIMEOUT == hresult:\n                if evt.isSet():\n                    raise CardRequestTimeoutException()\n\n            # reader vanished before or during the call\n            elif SCARD_E_UNKNOWN_READER == hresult:\n                pass\n\n            # some error happened\n            elif 0 != hresult:\n                timer.cancel()\n                raise CardRequestException(\n                    'Failed to get status change ' + \\\n                    SCardGetErrorMessage(hresult))\n\n            # something changed!\n            else:\n\n                # check if we have to return a match, i.e.\n                # if no new card in inserted and there is a card found\n                # or if a new card is requested, and there is a change+present\n                for state in newstates:\n                    readername, eventstate, atr = state\n                    r, oldstate = readerstates[readername]\n\n                    # the status can change on a card already inserted, e.g.\n                    # unpowered, in use, ...\n                    # if a new card is requested, clear the state changed bit\n                    # if the card was already inserted and is still inserted\n                    if self.newcardonly:\n                        if oldstate & SCARD_STATE_PRESENT and \\\n                            eventstate & \\\n                                (SCARD_STATE_CHANGED | SCARD_STATE_PRESENT):\n                            eventstate = eventstate & \\\n                                (0xFFFFFFFF ^ SCARD_STATE_CHANGED)\n\n                    if (self.newcardonly and \\\n                            eventstate & SCARD_STATE_PRESENT and \\\n                            eventstate & SCARD_STATE_CHANGED) or \\\n                        (not self.newcardonly and \\\n                         eventstate & SCARD_STATE_PRESENT):\n                        reader = PCSCReader(readername)\n                        if self.cardType.matches(atr, reader):\n                            if self.cardServiceClass.supports('dummy'):\n                                cardfound = True\n                                timer.cancel()\n                                return self.cardServiceClass(\n                                        reader.createConnection())\n\n                    # update state dictionary\n                    readerstates[readername] = (readername, eventstate)\n\n            if evt.isSet():\n                raise CardRequestTimeoutException()", "response": "Wait for a card insertion and returns a card service."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef waitforcardevent(self):\n        AbstractCardRequest.waitforcardevent(self)\n        presentcards = []\n        evt = threading.Event()\n\n        # for non infinite timeout, a timer will signal the end of the time-out\n        if INFINITE == self.timeout:\n            timertimeout = 1\n        else:\n            timertimeout = self.timeout\n        timer = threading.Timer(\n            timertimeout, signalEvent, [evt, INFINITE == self.timeout])\n\n        # get status change until time-out, e.g. evt is set\n        readerstates = {}\n        timerstarted = False\n\n        while not evt.isSet():\n\n            if not timerstarted:\n                timerstarted = True\n                timer.start()\n\n            time.sleep(self.pollinginterval)\n\n            # reinitialize at each iteration just in case a new reader appeared\n            readernames = self.getReaderNames()\n            for reader in readernames:\n                # create a dictionary entry for new readers\n                if not reader in readerstates:\n                    readerstates[reader] = (reader, SCARD_STATE_UNAWARE)\n            # remove dictionary entry for readers that disappeared\n            for oldreader in list(readerstates.keys()):\n                if oldreader not in readernames:\n                    del readerstates[oldreader]\n\n            # get status change\n            if {} != readerstates:\n                hresult, newstates = SCardGetStatusChange(\n                    self.hcontext, 0, list(readerstates.values()))\n            else:\n                hresult = 0\n                newstates = []\n\n            # time-out\n            if SCARD_E_TIMEOUT == hresult:\n                if evt.isSet():\n                    raise CardRequestTimeoutException()\n\n            # the reader was unplugged during the loop\n            elif SCARD_E_UNKNOWN_READER == hresult:\n                pass\n\n            # some error happened\n            elif 0 != hresult:\n                timer.cancel()\n                raise CardRequestException(\n                    'Failed to get status change ' + \\\n                    SCardGetErrorMessage(hresult))\n\n            # something changed!\n            else:\n                timer.cancel()\n                for state in newstates:\n                    readername, eventstate, atr = state\n                    r, oldstate = readerstates[readername]\n\n                    # the status can change on a card already inserted, e.g.\n                    # unpowered, in use, ... Clear the state changed bit if\n                    # the card was already inserted and is still inserted\n                    if oldstate & SCARD_STATE_PRESENT and \\\n                        eventstate & \\\n                            (SCARD_STATE_CHANGED | SCARD_STATE_PRESENT):\n                        eventstate = eventstate & \\\n                            (0xFFFFFFFF ^ SCARD_STATE_CHANGED)\n\n                    if eventstate & SCARD_STATE_PRESENT and \\\n                       eventstate & SCARD_STATE_CHANGED:\n                        presentcards.append(Card.Card(readername, atr))\n                return presentcards\n\n        if evt.isSet():\n            raise CardRequestTimeoutException()", "response": "Wait for card insertion or removal or timeout."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconvert a GUID string into a list of bytes.", "response": "def strToGUID(s):\n    \"\"\"Converts a GUID string into a list of bytes.\n\n    >>> strToGUID('{AD4F1667-EA75-4124-84D4-641B3B197C65}')\n    [103, 22, 79, 173, 117, 234, 36, 65, 132, 212, 100, 27, 59, 25, 124, 101]\n    \"\"\"\n    dat = uuid.UUID(hex=s)\n    if isinstance(dat.bytes_le, str):\n        # Python 2\n        dat = [ord(e) for e in dat.bytes_le]\n    else:\n        # Python 3\n        dat = list(dat.bytes_le)\n    return dat"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert a GUID sequence of bytes into a string.", "response": "def GUIDToStr(g):\n    \"\"\"Converts a GUID sequence of bytes into a string.\n\n    >>> GUIDToStr([103,22,79,173,  117,234,  36,65,\n    ...            132, 212, 100, 27, 59, 25, 124, 101])\n    '{AD4F1667-EA75-4124-84D4-641B3B197C65}'\n    \"\"\"\n    try:\n        dat = uuid.UUID(bytes_le=bytes(g))\n    except:\n        dat = uuid.UUID(bytes_le=''.join(map(chr, g)))\n    return '{' + str(dat).upper() + '}'"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notifyObservers(self, arg=None):\n        '''If 'changed' indicates that this object\n        has changed, notify all its observers, then\n        call clearChanged(). Each observer has its\n        update() called with two arguments: this\n        observable object and the generic 'arg'.'''\n\n        self.mutex.acquire()\n        try:\n            if not self.changed:\n                    return\n            # Make a local copy in case of synchronous\n            # additions of observers:\n            localArray = self.obs[:]\n            self.clearChanged()\n        finally:\n            self.mutex.release()\n        # Update observers\n        for observer in localArray:\n            observer.update(self, arg)", "response": "Notify all observers of this object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef matches(self, atr, reader=None):\n\n        if len(atr) != len(self.atr):\n            return not True\n\n        if self.mask is not None:\n            maskedatr = list(map(lambda x, y: x & y, list(atr), self.mask))\n        else:\n            maskedatr = atr\n        return self.maskedatr == maskedatr", "response": "Returns true if the given ATR matches the masked CardType ATR."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntransmits APDUs to the card.", "response": "def transmit(self, bytes, protocol=None):\n        \"\"\"Cypher/uncypher APDUs before transmission\"\"\"\n        cypheredbytes = self.cypher(bytes)\n        data, sw1, sw2 = CardConnectionDecorator.transmit(\n            self, cypheredbytes, protocol)\n        if [] != data:\n            data = self.uncypher(data)\n        return data, sw1, sw2"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalls when a reader is activated by double - clicking on the reader tree control or toolbar.", "response": "def OnActivateReader(self, reader):\n        \"\"\"Called when a reader is activated by double-clicking on the\n        reader tree control or toolbar.\"\"\"\n        SimpleSCardAppEventObserver.OnActivateReader(self, reader)\n        self.feedbacktext.SetLabel('Activated reader: ' + repr(reader))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a card is deactivated in the reader tree control or toolbar.", "response": "def OnDeactivateCard(self, card):\n        \"\"\"Called when a card is deactivated in the reader tree control\n        or toolbar.\"\"\"\n        SimpleSCardAppEventObserver.OnActivateCard(self, card)\n        self.feedbacktext.SetLabel('Deactivated card: ' + repr(card))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef OnSelectCard(self, card):\n        SimpleSCardAppEventObserver.OnSelectCard(self, card)\n        self.feedbacktext.SetLabel('Selected card: ' + repr(card))", "response": "Called when a card is selected by clicking on the reader tree control or toolbar."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncall when a reader is selected by clicking on the reader tree control or toolbar.", "response": "def OnSelectReader(self, reader):\n        \"\"\"Called when a reader is selected by clicking on the reader\n        tree control or toolbar.\"\"\"\n        SimpleSCardAppEventObserver.OnSelectReader(self, reader)\n        self.feedbacktext.SetLabel('Selected reader: ' + repr(reader))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef getSupportedProtocols(self):\n        protocols = {}\n        for td in self.TD:\n            if td is not None:\n                strprotocol = \"T=%d\" % (td & 0x0F)\n                protocols[strprotocol] = True\n        if not self.hasTD[0]:\n            protocols['T=0'] = True\n        return protocols", "response": "Returns a dictionnary of supported protocols."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef dump(self):\n\n        for i in range(0, len(self.TA)):\n            if self.TA[i] is not None:\n                print(\"TA%d: %x\" % (i + 1, self.TA[i]))\n            if self.TB[i] is not None:\n                print(\"TB%d: %x\" % (i + 1, self.TB[i]))\n            if self.TC[i] is not None:\n                print(\"TC%d: %x\" % (i + 1, self.TC[i]))\n            if self.TD[i] is not None:\n                print(\"TD%d: %x\" % (i + 1, self.TD[i]))\n\n        print('supported protocols ' + ','.join(self.getSupportedProtocols()))\n        print('T=0 supported: ' + str(self.isT0Supported()))\n        print('T=1 supported: ' + str(self.isT1Supported()))\n\n        if self.getChecksum():\n            print('checksum: %d' % self.getChecksum())\n\n        print('\\tclock rate conversion factor: ' +\n              str(self.getClockRateConversion()))\n        print('\\tbit rate adjustment factor: ' + str(self.getBitRateFactor()))\n\n        print('\\tmaximum programming current: ' +\n              str(self.getProgrammingCurrent()))\n        print('\\tprogramming voltage: ' + str(self.getProgrammingVoltage()))\n\n        print('\\tguard time: ' + str(self.getGuardTime()))\n\n        print('nb of interface bytes: %d' % self.getInterfaceBytesCount())\n        print('nb of historical bytes: %d' % self.getHistoricalBytesCount())", "response": "Dump the details of an ATR."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling when a card is inserted. Adds a smart card to the smartcards tree.", "response": "def OnAddCards(self, addedcards):\n        \"\"\"Called when a card is inserted.\n        Adds a smart card to the smartcards tree.\"\"\"\n        parentnode = self.root\n        for cardtoadd in addedcards:\n            childCard = self.AppendItem(parentnode, toHexString(cardtoadd.atr))\n            self.SetItemText(childCard, toHexString(cardtoadd.atr))\n            self.SetPyData(childCard, cardtoadd)\n            self.SetItemImage(\n                childCard, self.cardimageindex, wx.TreeItemIcon_Normal)\n            self.SetItemImage(\n                childCard, self.cardimageindex, wx.TreeItemIcon_Expanded)\n            self.Expand(childCard)\n        self.Expand(self.root)\n        self.EnsureVisible(self.root)\n        self.Repaint()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OnRemoveCards(self, removedcards):\n        parentnode = self.root\n        for cardtoremove in removedcards:\n            (childCard, cookie) = self.GetFirstChild(parentnode)\n            while childCard.IsOk():\n                if self.GetItemText(childCard) == \\\n                        toHexString(cardtoremove.atr):\n                    self.Delete(childCard)\n                (childCard, cookie) = self.GetNextChild(parentnode, cookie)\n        self.Expand(self.root)\n        self.EnsureVisible(self.root)\n        self.Repaint()", "response": "Called when a card is removed. Removes a card from the tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef AddATR(self, readernode, atr):\n        capchild = self.AppendItem(readernode, atr)\n        self.SetPyData(capchild, None)\n        self.SetItemImage(\n            capchild, self.cardimageindex, wx.TreeItemIcon_Normal)\n        self.SetItemImage(\n            capchild, self.cardimageindex, wx.TreeItemIcon_Expanded)\n        self.Expand(capchild)\n        return capchild", "response": "Add an ATR to a reader node."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the ATR of the card inserted into the reader.", "response": "def GetATR(self, reader):\n        \"\"\"Return the ATR of the card inserted into the reader.\"\"\"\n        atr = \"no card inserted\"\n        try:\n            if not type(reader) is str:\n                connection = reader.createConnection()\n                connection.connect()\n                atr = toHexString(connection.getATR())\n                connection.disconnect()\n        except NoCardException:\n            pass\n        except CardConnectionException:\n            pass\n        return atr"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling when a card is inserted. Adds the smart card child to the reader node.", "response": "def OnAddCards(self, addedcards):\n        \"\"\"Called when a card is inserted.\n        Adds the smart card child to the reader node.\"\"\"\n        self.mutex.acquire()\n        try:\n            parentnode = self.root\n            for cardtoadd in addedcards:\n                (childReader, cookie) = self.GetFirstChild(parentnode)\n                found = False\n                while childReader.IsOk() and not found:\n                    if self.GetItemText(childReader) == str(cardtoadd.reader):\n                        (childCard, cookie2) = self.GetFirstChild(childReader)\n                        self.SetItemText(childCard, toHexString(cardtoadd.atr))\n                        self.SetPyData(childCard, cardtoadd)\n                        found = True\n                    else:\n                        (childReader, cookie) = self.GetNextChild(\n                            parentnode, cookie)\n\n                # reader was not found, add reader node\n                # this happens when card monitoring thread signals\n                # added cards before reader monitoring thread signals\n                # added readers\n                if not found:\n                    childReader = self.AppendItem(\n                        parentnode, str(cardtoadd.reader))\n                    self.SetPyData(childReader, cardtoadd.reader)\n                    self.SetItemImage(\n                        childReader,\n                        self.readerimageindex,\n                        wx.TreeItemIcon_Normal)\n                    self.SetItemImage(\n                        childReader,\n                        self.readerimageindex,\n                        wx.TreeItemIcon_Expanded)\n                    childCard = self.AddATR(\n                        childReader, toHexString(cardtoadd.atr))\n                    self.SetPyData(childCard, cardtoadd)\n                    self.Expand(childReader)\n\n            self.Expand(self.root)\n        finally:\n            self.mutex.release()\n        self.EnsureVisible(self.root)\n        self.Repaint()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef OnAddReaders(self, addedreaders):\n        self.mutex.acquire()\n\n        try:\n            parentnode = self.root\n            for readertoadd in addedreaders:\n                # is the reader already here?\n                found = False\n                (childReader, cookie) = self.GetFirstChild(parentnode)\n                while childReader.IsOk() and not found:\n                    if self.GetItemText(childReader) == str(readertoadd):\n                        found = True\n                    else:\n                        (childReader, cookie) = self.GetNextChild(\n                                                    parentnode, cookie)\n                if not found:\n                    childReader = self.AppendItem(parentnode, str(readertoadd))\n                    self.SetPyData(childReader, readertoadd)\n                    self.SetItemImage(\n                        childReader,\n                        self.readerimageindex,\n                        wx.TreeItemIcon_Normal)\n                    self.SetItemImage(\n                        childReader,\n                        self.readerimageindex,\n                        wx.TreeItemIcon_Expanded)\n                    self.AddATR(\n                        childReader,\n                        self.GetATR(readertoadd))\n                    self.Expand(childReader)\n            self.Expand(self.root)\n        finally:\n            self.mutex.release()\n        self.EnsureVisible(self.root)\n        self.Repaint()", "response": "Called when a reader is inserted. Adds the smart card reader to the readers tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef OnRemoveCards(self, removedcards):\n        self.mutex.acquire()\n        try:\n            parentnode = self.root\n            for cardtoremove in removedcards:\n                (childReader, cookie) = self.GetFirstChild(parentnode)\n                found = False\n                while childReader.IsOk() and not found:\n                    if self.GetItemText(childReader) == \\\n                            str(cardtoremove.reader):\n                        (childCard, cookie2) = self.GetFirstChild(childReader)\n                        self.SetItemText(childCard, 'no card inserted')\n                        found = True\n                    else:\n                        (childReader, cookie) = \\\n                            self.GetNextChild(parentnode, cookie)\n            self.Expand(self.root)\n        finally:\n            self.mutex.release()\n        self.EnsureVisible(self.root)\n        self.Repaint()", "response": "Called when a card is removed. Removes the card from the tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef OnRemoveReaders(self, removedreaders):\n        self.mutex.acquire()\n        try:\n            parentnode = self.root\n            for readertoremove in removedreaders:\n                (childReader, cookie) = self.GetFirstChild(parentnode)\n                while childReader.IsOk():\n                    if self.GetItemText(childReader) == str(readertoremove):\n                        self.Delete(childReader)\n                    else:\n                        (childReader, cookie) = \\\n                            self.GetNextChild(parentnode, cookie)\n            self.Expand(self.root)\n        finally:\n            self.mutex.release()\n        self.EnsureVisible(self.root)\n        self.Repaint()", "response": "Called when a reader is removed. Removes the reader from the smartcard readers tree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncalling on panel destruction.", "response": "def OnDestroy(self, event):\n        \"\"\"Called on panel destruction.\"\"\"\n        # deregister observers\n        if hasattr(self, 'cardmonitor'):\n            self.cardmonitor.deleteObserver(self.cardtreecardobserver)\n        if hasattr(self, 'readermonitor'):\n            self.readermonitor.deleteObserver(self.readertreereaderobserver)\n            self.cardmonitor.deleteObserver(self.readertreecardobserver)\n        event.Skip()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndisconnecting and reconnect in exclusive mode PCSCCardconnections.", "response": "def connect(self, protocol=None, mode=None, disposition=None):\n        '''Disconnect and reconnect in exclusive mode PCSCCardconnections.'''\n        CardConnectionDecorator.connect(self, protocol, mode, disposition)\n        component = self.component\n        while True:\n            if isinstance(component,\n                          smartcard.pcsc.PCSCCardConnection.PCSCCardConnection):\n                pcscprotocol = PCSCCardConnection.translateprotocolmask(\n                    protocol)\n                if 0 == pcscprotocol:\n                    pcscprotocol = component.getProtocol()\n\n                if component.hcard is not None:\n                    hresult = SCardDisconnect(component.hcard,\n                                              SCARD_LEAVE_CARD)\n                    if hresult != 0:\n                        raise CardConnectionException(\n                                'Failed to disconnect: ' +\n                                SCardGetErrorMessage(hresult))\n                hresult, component.hcard, dwActiveProtocol = SCardConnect(\n                    component.hcontext, str(component.reader),\n                    SCARD_SHARE_EXCLUSIVE, pcscprotocol)\n                if hresult != 0:\n                    raise CardConnectionException(\n                        'Failed to connect with SCARD_SHARE_EXCLUSIVE' +\n                        SCardGetErrorMessage(hresult))\n                # print('reconnected exclusive')\n                break\n            if hasattr(component, 'component'):\n                component = component.component\n            else:\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nbuilds a new module from a list of objects.", "response": "def build_module(name, objs, doc='', source=None, mode='ignore'):\n    \"\"\"Create a module from imported objects.\n\n    Parameters\n    ----------\n    name : str\n      New module name.\n    objs : dict\n      Dictionary of the objects (or their name) to import into the module,\n      keyed by the name they will take in the created module.\n    doc : str\n      Docstring of the new module.\n    source : Module object\n      Module where objects are defined if not explicitly given.\n    mode : {'raise', 'warn', 'ignore'}\n      How to deal with missing objects.\n\n\n    Returns\n    -------\n    ModuleType\n      A module built from a list of objects' name.\n\n    \"\"\"\n    import types\n    import warnings\n    import logging\n\n    logging.captureWarnings(capture=True)\n\n    try:\n        out = types.ModuleType(name, doc)\n    except TypeError:\n        msg = \"Module '{}' is not properly formatted\".format(name)\n        raise TypeError(msg)\n\n    for key, obj in objs.items():\n        if isinstance(obj, str) and source is not None:\n            module_mappings = getattr(source, obj, None)\n        else:\n            module_mappings = obj\n\n        if module_mappings is None:\n            msg = \"{} has not been implemented.\".format(obj)\n            if mode == 'raise':\n                raise NotImplementedError(msg)\n            elif mode == 'warn':\n                warnings.warn(msg)\n            else:\n                logging.info(msg)\n\n        else:\n            out.__dict__[key] = module_mappings\n            try:\n                module_mappings.__module__ = name\n            except AttributeError:\n                msg = \"{} is not a function\".format(module_mappings)\n                raise AttributeError(msg)\n\n    sys.modules[name] = out\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef base_flow_index(q, freq='YS'):\n\n    m7 = q.rolling(time=7, center=True).mean().resample(time=freq)\n    mq = q.resample(time=freq)\n\n    m7m = m7.min(dim='time')\n    return m7m / mq.mean(dim='time')", "response": "r Base flow index"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef cold_spell_days(tas, thresh='-10 degC', window=5, freq='AS-JUL'):\n    t = utils.convert_units_to(thresh, tas)\n    over = tas < t\n    group = over.resample(time=freq)\n\n    return group.apply(rl.windowed_run_count, window=window, dim='time')", "response": "r Returns the number of days that are part of a cold spell."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef consecutive_frost_days(tasmin, freq='AS-JUL'):\n    tu = units.parse_units(tasmin.attrs['units'].replace('-', '**-'))\n    fu = 'degC'\n    frz = 0\n    if fu != tu:\n        frz = units.convert(frz, fu, tu)\n    group = (tasmin < frz).resample(time=freq)\n    return group.apply(rl.longest_run, dim='time')", "response": "r Returns a sequence of consecutive frost days."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef daily_freezethaw_cycles(tasmax, tasmin, freq='YS'):\n    frz = utils.convert_units_to('0 degC', tasmax)\n    ft = (tasmin < frz) * (tasmax > frz) * 1\n    out = ft.resample(time=freq).sum(dim='time')\n    return out", "response": "r Returns the number of days with a diurnal freeze - thaw cycle."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef daily_temperature_range(tasmax, tasmin, freq='YS'):\n\n    dtr = tasmax - tasmin\n    out = dtr.resample(time=freq).mean(dim='time', keep_attrs=True)\n    out.attrs['units'] = tasmax.units\n    return out", "response": "r Mean of daily temperature range."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef daily_temperature_range_variability(tasmax, tasmin, freq=\"YS\"):\n\n    vdtr = abs((tasmax - tasmin).diff(dim='time'))\n    out = vdtr.resample(time=freq).mean(dim='time')\n    out.attrs['units'] = tasmax.units\n    return out", "response": "r Mean absolute day - to - day variation in daily temperature range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef freshet_start(tas, thresh='0 degC', window=5, freq='YS'):\n    thresh = utils.convert_units_to(thresh, tas)\n    over = (tas > thresh)\n    group = over.resample(time=freq)\n    return group.apply(rl.first_run_ufunc, window=window, index='dayofyear')", "response": "r First day consistently exceeding threshold temperature."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef frost_days(tasmin, freq='YS'):\n    tu = units.parse_units(tasmin.attrs['units'].replace('-', '**-'))\n    fu = 'degC'\n    frz = 0\n    if fu != tu:\n        frz = units.convert(frz, fu, tu)\n    f = (tasmin < frz) * 1\n    return f.resample(time=freq).sum(dim='time')", "response": "r Returns the number of days where daily minimum temperatures are below 0."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef growing_season_length(tas, thresh='5.0 degC', window=6, freq='YS'):\n\n    # i = xr.DataArray(np.arange(tas.time.size), dims='time')\n    # ind = xr.broadcast(i, tas)[0]\n    #\n    # c = ((tas > thresh) * 1).rolling(time=window).sum()\n    # i1 = ind.where(c == window).resample(time=freq).min(dim='time')\n    #\n    # # Resample sets the time to T00:00.\n    # i11 = i1.reindex_like(c, method='ffill')\n    #\n    # # TODO: Adjust for southern hemisphere\n    #\n    # #i2 = ind.where(c == 0).where(tas.time.dt.month >= 7)\n    # # add check to make sure indice of end of growing season is after growing season start\n    # i2 = ind.where((c==0) & (ind > i11)).where(tas.time.dt.month >= 7)\n    #\n    # d = i2 - i11\n    #\n    # # take min value (first occurence after july)\n    # gsl = d.resample(time=freq).min(dim='time')\n    #\n    # # turn nan into 0\n    # gsl = xr.where(np.isnan(gsl), 0, gsl)\n\n    # compute growth season length on resampled data\n    thresh = utils.convert_units_to(thresh, tas)\n\n    c = ((tas > thresh) * 1).rolling(time=window).sum().chunk(tas.chunks)\n\n    def compute_gsl(c):\n        nt = c.time.size\n        i = xr.DataArray(np.arange(nt), dims='time').chunk({'time': 1})\n        ind = xr.broadcast(i, c)[0].chunk(c.chunks)\n        i1 = ind.where(c == window).min(dim='time')\n        i1 = xr.where(np.isnan(i1), nt, i1)\n        i11 = i1.reindex_like(c, method='ffill')\n        i2 = ind.where((c == 0) & (ind > i11)).where(c.time.dt.month >= 7)\n        i2 = xr.where(np.isnan(i2), nt, i2)\n        d = (i2 - i1).min(dim='time')\n        return d\n\n    gsl = c.resample(time=freq).apply(compute_gsl)\n\n    return gsl", "response": "r Growing season length."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef heating_degree_days(tas, thresh='17.0 degC', freq='YS'):\n    thresh = utils.convert_units_to(thresh, tas)\n\n    return tas.pipe(lambda x: thresh - x) \\\n        .clip(0) \\\n        .resample(time=freq) \\\n        .sum(dim='time')", "response": "r Heating degree days"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef liquid_precip_ratio(pr, prsn=None, tas=None, freq='QS-DEC'):\n\n    if prsn is None:\n        tu = units.parse_units(tas.attrs['units'].replace('-', '**-'))\n        fu = 'degC'\n        frz = 0\n        if fu != tu:\n            frz = units.convert(frz, fu, tu)\n        prsn = pr.where(tas < frz, 0)\n\n    tot = pr.resample(time=freq).sum(dim='time')\n    rain = tot - prsn.resample(time=freq).sum(dim='time')\n    ratio = rain / tot\n    return ratio", "response": "r Returns the ratio of total liquid precipitation over the total precipitation."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tx_days_above(tasmax, thresh='25.0 degC', freq='YS'):\n    thresh = utils.convert_units_to(thresh, tasmax)\n    f = (tasmax > (thresh)) * 1\n    return f.resample(time=freq).sum(dim='time')", "response": "r Returns the number of days where daily maximum temperature is above threshold."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a sequence of rain on frozen ground events per period.", "response": "def rain_on_frozen_ground_days(pr, tas, thresh='1 mm/d', freq='YS'):\n    \"\"\"Number of rain on frozen ground events\n\n    Number of days with rain above a threshold after a series of seven days below freezing temperature.\n    Precipitation is assumed to be rain when the temperature is above 0\u2103.\n\n    Parameters\n    ----------\n    pr : xarray.DataArray\n      Mean daily precipitation flux [Kg m-2 s-1] or [mm]\n    tas : xarray.DataArray\n      Mean daily temperature [\u2103] or [K]\n    thresh : str\n      Precipitation threshold to consider a day as a rain event. Default : '1 mm/d'\n    freq : str, optional\n      Resampling frequency\n\n    Returns\n    -------\n    xarray.DataArray\n      The number of rain on frozen ground events per period [days]\n\n    Notes\n    -----\n    Let :math:`PR_i` be the mean daily precipitation and :math:`TG_i` be the mean daily temperature of day :math:`i`.\n    Then for a period :math:`j`, rain on frozen grounds days are counted where:\n\n    .. math::\n\n        PR_{i} > Threshold [mm]\n\n    and where\n\n    .. math::\n\n        TG_{i} \u2264 0\u2103\n\n    is true for continuous periods where :math:`i \u2265 7`\n\n    \"\"\"\n    t = utils.convert_units_to(thresh, pr)\n    frz = utils.convert_units_to('0 C', tas)\n\n    def func(x, axis):\n        \"\"\"Check that temperature conditions are below 0 for seven days and above after.\"\"\"\n        frozen = x == np.array([0, 0, 0, 0, 0, 0, 0, 1], bool)\n        return frozen.all(axis=axis)\n\n    tcond = (tas > frz).rolling(time=8).reduce(func)\n    pcond = (pr > t)\n\n    return (tcond * pcond * 1).resample(time=freq).sum(dim='time')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tg_mean(tas, freq='YS'):\n\n    arr = tas.resample(time=freq) if freq else tas\n    return arr.mean(dim='time', keep_attrs=True)", "response": "r Mean of daily average temperature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tg_min(tas, freq='YS'):\n\n    return tas.resample(time=freq).min(dim='time', keep_attrs=True)", "response": "r Lowest mean temperature and minimum of daily temperature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef tn_max(tasmin, freq='YS'):\n\n    return tasmin.resample(time=freq).max(dim='time', keep_attrs=True)", "response": "r Highest minimum temperature."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tn_min(tasmin, freq='YS'):\n\n    return tasmin.resample(time=freq).min(dim='time', keep_attrs=True)", "response": "r Lowest minimum temperature"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef tropical_nights(tasmin, thresh='20.0 degC', freq='YS'):\n    thresh = utils.convert_units_to(thresh, tasmin)\n    return tasmin.pipe(lambda x: (tasmin > thresh) * 1) \\\n        .resample(time=freq) \\\n        .sum(dim='time')", "response": "r Tropical nights filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef tx_max(tasmax, freq='YS'):\n\n    return tasmax.resample(time=freq).max(dim='time', keep_attrs=True)", "response": "r Highest max temperature"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tx_tn_days_above(tasmin, tasmax, thresh_tasmin='22 degC',\n                     thresh_tasmax='30 degC', freq='YS'):\n    r\"\"\"Number of days with both hot maximum and minimum daily temperatures.\n\n    The number of days per period with tasmin above a threshold and tasmax above another threshold.\n\n    Parameters\n    ----------\n    tasmin : xarray.DataArray\n      Minimum daily temperature [\u2103] or [K]\n    tasmax : xarray.DataArray\n      Maximum daily temperature [\u2103] or [K]\n    thresh_tasmin : str\n      Threshold temperature for tasmin on which to base evaluation [\u2103] or [K]. Default : '22 degC'\n    thresh_tasmax : str\n      Threshold temperature for tasmax on which to base evaluation [\u2103] or [K]. Default : '30 degC'\n    freq : str, optional\n      Resampling frequency\n\n    Returns\n    -------\n    xarray.DataArray\n      the number of days with tasmin > thresh_tasmin and\n      tasmax > thresh_tasamax per period\n\n\n    Notes\n    -----\n    Let :math:`TX_{ij}` be the maximum temperature at day :math:`i` of period :math:`j`, :math:`TN_{ij}`\n    the daily minimum temperature at day :math:`i` of period :math:`j`, :math:`TX_{thresh}` the threshold for maximum\n    daily temperature, and :math:`TN_{thresh}` the threshold for minimum daily temperature. Then counted is the number\n    of days where:\n\n    .. math::\n\n        TX_{ij} > TX_{thresh} [\u2103]\n\n    and where:\n\n    .. math::\n\n        TN_{ij} > TN_{thresh} [\u2103]\n\n    \"\"\"\n    thresh_tasmax = utils.convert_units_to(thresh_tasmax, tasmax)\n    thresh_tasmin = utils.convert_units_to(thresh_tasmin, tasmin)\n    events = ((tasmin > (thresh_tasmin)) & (tasmax > (thresh_tasmax))) * 1\n    return events.resample(time=freq).sum(dim='time')", "response": "r Returns the number of days with both hot maximum and minimum daily temperatures above a threshold and tasmax above another threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nratios of total precipitation over the total precipitation over the winter months.", "response": "def winter_rain_ratio(pr, prsn=None, tas=None):\n    \"\"\"Ratio of rainfall to total precipitation during winter\n\n    The ratio of total liquid precipitation over the total precipitation over the winter months (DJF. If solid\n    precipitation is not provided, then precipitation is assumed solid if the temperature is below 0\u00b0C.\n\n    Parameters\n    ----------\n    pr : xarray.DataArray\n      Mean daily precipitation flux [Kg m-2 s-1] or [mm].\n    prsn : xarray.DataArray\n      Mean daily solid precipitation flux [Kg m-2 s-1] or [mm].\n    tas : xarray.DataArray\n      Mean daily temperature [\u2103] or [K]\n    freq : str\n      Resampling frequency\n\n    Returns\n    -------\n    xarray.DataArray\n      Ratio of rainfall to total precipitation during winter months (DJF)\n    \"\"\"\n    ratio = liquid_precip_ratio(pr, prsn, tas, freq='QS-DEC')\n    winter = ratio.indexes['time'].month == 12\n    return ratio[winter]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nselect entries according to a time period.", "response": "def select_time(da, **indexer):\n    \"\"\"Select entries according to a time period.\n\n    Parameters\n    ----------\n    da : xarray.DataArray\n      Input data.\n    **indexer : {dim: indexer, }, optional\n      Time attribute and values over which to subset the array. For example, use season='DJF' to select winter values,\n      month=1 to select January, or month=[6,7,8] to select summer months. If not indexer is given, all values are\n      considered.\n\n    Returns\n    -------\n    xr.DataArray\n      Selected input values.\n    \"\"\"\n    if not indexer:\n        selected = da\n    else:\n        key, val = indexer.popitem()\n        time_att = getattr(da.time.dt, key)\n        selected = da.sel(time=time_att.isin(val)).dropna(dim='time')\n\n    return selected"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\napply operation over each period that is part of the index selection. Parameters ---------- da : xarray.DataArray Input data. op : str {'min', 'max', 'mean', 'std', 'var', 'count', 'sum', 'argmax', 'argmin'} or func Reduce operation. Can either be a DataArray method or a function that can be applied to a DataArray. freq : str Resampling frequency defining the periods defined in http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling. **indexer : {dim: indexer, }, optional Time attribute and values over which to subset the array. For example, use season='DJF' to select winter values, month=1 to select January, or month=[6,7,8] to select summer months. If not indexer is given, all values are considered. Returns ------- xarray.DataArray The maximum value for each period.", "response": "def select_resample_op(da, op, freq=\"YS\", **indexer):\n    \"\"\"Apply operation over each period that is part of the index selection.\n\n    Parameters\n    ----------\n    da : xarray.DataArray\n      Input data.\n    op : str {'min', 'max', 'mean', 'std', 'var', 'count', 'sum', 'argmax', 'argmin'} or func\n      Reduce operation. Can either be a DataArray method or a function that can be applied to a DataArray.\n    freq : str\n      Resampling frequency defining the periods\n      defined in http://pandas.pydata.org/pandas-docs/stable/timeseries.html#resampling.\n    **indexer : {dim: indexer, }, optional\n      Time attribute and values over which to subset the array. For example, use season='DJF' to select winter values,\n      month=1 to select January, or month=[6,7,8] to select summer months. If not indexer is given, all values are\n      considered.\n\n    Returns\n    -------\n    xarray.DataArray\n      The maximum value for each period.\n    \"\"\"\n    da = select_time(da, **indexer)\n    r = da.resample(time=freq, keep_attrs=True)\n    if isinstance(op, str):\n        return getattr(r, op)(dim='time', keep_attrs=True)\n\n    return r.apply(op)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef doymax(da):\n    i = da.argmax(dim='time')\n    out = da.time.dt.dayofyear[i]\n    out.attrs['units'] = ''\n    return out", "response": "Return the day of year of the maximum value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef fit(arr, dist='norm'):\n    # Get the distribution\n    dc = get_dist(dist)\n\n    # Fit the parameters (lazy computation)\n    data = dask.array.apply_along_axis(dc.fit, arr.get_axis_num('time'), arr)\n\n    # Count the number of values used for the fit.\n    # n = arr.count(dim='time')\n\n    # Create a view to a DataArray with the desired dimensions to copy them over to the parameter array.\n    mean = arr.mean(dim='time', keep_attrs=True)\n\n    # Create coordinate for the distribution parameters\n    coords = dict(mean.coords.items())\n    coords['dparams'] = ([] if dc.shapes is None else dc.shapes.split(',')) + ['loc', 'scale']\n\n    # TODO: add time and time_bnds coordinates (Low will work on this)\n    # time.attrs['climatology'] = 'climatology_bounds'\n    # coords['time'] =\n    # coords['climatology_bounds'] =\n\n    out = xr.DataArray(data=data, coords=coords, dims=(u'dparams',) + mean.dims)\n    out.attrs = arr.attrs\n    out.attrs['original_name'] = getattr(arr, 'standard_name', '')\n    out.attrs['standard_name'] = '{0} distribution parameters'.format(dist)\n    out.attrs['long_name'] = '{0} distribution parameters for {1}'.format(dist, getattr(arr, 'standard_name', ''))\n    out.attrs['estimator'] = 'Maximum likelihood'\n    out.attrs['cell_methods'] = (out.attrs.get('cell_methods', '') + ' time: fit').strip()\n    out.attrs['units'] = ''\n    msg = '\\nData fitted with {0} statistical distribution using a Maximum Likelihood Estimator'\n    out.attrs['history'] = out.attrs.get('history', '') + msg.format(dist)\n\n    return out", "response": "Fit an array to a univariate distribution along the time dimension."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the value corresponding to the given return period.", "response": "def fa(arr, t, dist='norm', mode='high'):\n    \"\"\"Return the value corresponding to the given return period.\n\n    Parameters\n    ----------\n    arr : xarray.DataArray\n      Maximized/minimized input data with a `time` dimension.\n    t : int or sequence\n      Return period. The period depends on the resolution of the input data. If the input array's resolution is\n      yearly, then the return period is in years.\n    dist : str\n      Name of the univariate distribution, such as beta, expon, genextreme, gamma, gumbel_r, lognorm, norm\n      (see scipy.stats).\n    mode : {'min', 'max}\n      Whether we are looking for a probability of exceedance (max) or a probability of non-exceedance (min).\n\n    Returns\n    -------\n    xarray.DataArray\n      An array of values with a 1/t probability of exceedance (if mode=='max').\n    \"\"\"\n    t = np.atleast_1d(t)\n\n    # Get the distribution\n    dc = get_dist(dist)\n\n    # Fit the parameters of the distribution\n    p = fit(arr, dist)\n\n    # Create a lambda function to facilitate passing arguments to dask. There is probably a better way to do this.\n    if mode in ['max', 'high']:\n        def func(x):\n            return dc.isf(1./t, *x)\n    elif mode in ['min', 'low']:\n        def func(x):\n            return dc.ppf(1./t, *x)\n    else:\n        raise ValueError(\"mode `{}` should be either 'max' or 'min'\".format(mode))\n\n    data = dask.array.apply_along_axis(func, p.get_axis_num('dparams'), p)\n\n    # Create coordinate for the return periods\n    coords = dict(p.coords.items())\n    coords.pop('dparams')\n    coords['return_period'] = t\n\n    # Create dimensions\n    dims = list(p.dims)\n    dims.remove('dparams')\n    dims.insert(0, u'return_period')\n\n    # TODO: add time and time_bnds coordinates (Low will work on this)\n    # time.attrs['climatology'] = 'climatology_bounds'\n    # coords['time'] =\n    # coords['climatology_bounds'] =\n\n    out = xr.DataArray(data=data, coords=coords, dims=dims)\n    out.attrs = p.attrs\n    out.attrs['standard_name'] = '{0} quantiles'.format(dist)\n    out.attrs['long_name'] = '{0} return period values for {1}'.format(dist, getattr(arr, 'standard_name', ''))\n    out.attrs['cell_methods'] = (out.attrs.get('cell_methods', '') + ' dparams: ppf').strip()\n    out.attrs['units'] = arr.attrs.get('units', '')\n    out.attrs['mode'] = mode\n    out.attrs['history'] = out.attrs.get('history', '') + \"Compute values corresponding to return periods.\"\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the value corresponding to a return period.", "response": "def frequency_analysis(da, mode, t, dist, window=1, freq=None, **indexer):\n    \"\"\"Return the value corresponding to a return period.\n\n    Parameters\n    ----------\n    da : xarray.DataArray\n      Input data.\n    t : int or sequence\n      Return period. The period depends on the resolution of the input data. If the input array's resolution is\n      yearly, then the return period is in years.\n    dist : str\n      Name of the univariate distribution, such as beta, expon, genextreme, gamma, gumbel_r, lognorm, norm\n      (see scipy.stats).\n    mode : {'min', 'max'}\n      Whether we are looking for a probability of exceedance (high) or a probability of non-exceedance (low).\n    window : int\n      Averaging window length (days).\n    freq : str\n      Resampling frequency. If None, the frequency is assumed to be 'YS' unless the indexer is season='DJF',\n      in which case `freq` would be set to `YS-DEC`.\n    **indexer : {dim: indexer, }, optional\n      Time attribute and values over which to subset the array. For example, use season='DJF' to select winter values,\n      month=1 to select January, or month=[6,7,8] to select summer months. If not indexer is given, all values are\n      considered.\n\n    Returns\n    -------\n    xarray.DataArray\n      An array of values with a 1/t probability of exceedance or non-exceedance when mode is high or low respectively.\n\n    \"\"\"\n    # Apply rolling average\n    if window > 1:\n        da = da.rolling(time=window, center=False).mean()\n\n    # Assign default resampling frequency if not provided\n    freq = freq or default_freq(**indexer)\n\n    # Extract the time series of min or max over the period\n    sel = select_resample_op(da, op=mode, freq=freq, **indexer).dropna(dim='time')\n\n    # Frequency analysis\n    return fa(sel, t, dist, mode)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the default frequency.", "response": "def default_freq(**indexer):\n    \"\"\"Return the default frequency.\"\"\"\n    freq = 'AS-JAN'\n    if indexer:\n        if 'DJF' in indexer.values():\n            freq = 'AS-DEC'\n        if 'month' in indexer and sorted(indexer.values()) != indexer.values():\n            raise (NotImplementedError)\n\n    return freq"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_dist(dist):\n    from scipy import stats\n\n    dc = getattr(stats, dist, None)\n    if dc is None:\n        e = \"Statistical distribution `{}` is not in scipy.stats.\".format(dist)\n        raise ValueError(e)\n    return dc", "response": "Return a distribution object from scipy. stats.\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef missing(self, *args, **kwds):\n        from functools import reduce\n\n        indexer = kwds['indexer']\n        freq = kwds['freq'] or generic.default_freq(**indexer)\n\n        miss = (checks.missing_any(generic.select_time(da, **indexer), freq) for da in args)\n        return reduce(np.logical_or, miss)", "response": "Return whether an output is considered missing or not."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the children of the modules or classes that are instances of xclim. utils. Indicator.", "response": "def _get_indicators(modules):\n    \"\"\"For all modules or classes listed, return the children that are instances of xclim.utils.Indicator.\n\n    modules : sequence\n      Sequence of modules to inspect.\n    \"\"\"\n    out = []\n    for obj in modules:\n        for key, val in obj.__dict__.items():\n            if isinstance(val, xcu.Indicator):\n                out.append(val)\n\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a sequence of dicts storing metadata about all available indices.", "response": "def _indicator_table():\n    \"\"\"Return a sequence of dicts storing metadata about all available indices.\"\"\"\n    from xclim import temperature, precip\n    import inspect\n\n    inds = _get_indicators([temperature, precip])\n    table = []\n    for ind in inds:\n        # Apply default values\n        args = {name: p.default for (name, p) in ind._sig.parameters.items() if p.default != inspect._empty}\n        table.append(ind.json(args))\n    return table"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef longest_run(da, dim='time'):\n\n    d = rle(da, dim=dim)\n    rl_long = d.max(dim=dim)\n\n    return rl_long", "response": "Return the length of the longest consecutive run of True values along the specified dimension."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of runs of a minimum length.", "response": "def windowed_run_events(da, window, dim='time'):\n    \"\"\"Return the number of runs of a minimum length.\n\n        Parameters\n        ----------\n        da: N-dimensional Xarray data array  (boolean)\n          Input data array\n        window : int\n          Minimum run length.\n        dim : Xarray dimension (default = 'time')\n          Dimension along which to calculate consecutive run\n\n        Returns\n        -------\n        out : N-dimensional xarray data array (int)\n          Number of distinct runs of a minimum length.\n        \"\"\"\n    d = rle(da, dim=dim)\n    out = (d >= window).sum(dim=dim)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef windowed_run_count(da, window, dim='time'):\n    d = rle(da, dim=dim)\n    out = d.where(d >= window, 0).sum(dim=dim)\n    return out", "response": "Return the number of consecutive true values in array for runs at least as long as given duration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef first_run(da, window, dim='time'):\n    dims = list(da.dims)\n    if 'time' not in dims:\n        da['time'] = da[dim]\n        da.swap_dims({dim: 'time'})\n    da = da.astype('int')\n    i = xr.DataArray(np.arange(da[dim].size), dims=dim).chunk({'time': 1})\n    ind = xr.broadcast(i, da)[0].chunk(da.chunks)\n    wind_sum = da.rolling(time=window).sum()\n    out = ind.where(wind_sum >= window).min(dim=dim) - (\n        window - 1)  # remove window -1 as rolling result index is last element of the moving window\n    return out", "response": "Return the index of the first item in a run of at least a given duration."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef rle_1d(arr):\n    ia = np.asarray(arr)\n    n = len(ia)\n\n    if n == 0:\n        e = 'run length array empty'\n        warn(e)\n        return None, None, None\n\n    y = np.array(ia[1:] != ia[:-1])  # pairwise unequal (string safe)\n    i = np.append(np.where(y), n - 1)  # must include last element position\n    rl = np.diff(np.append(-1, i))  # run lengths\n    pos = np.cumsum(np.append(0, rl))[:-1]  # positions\n    return ia[i], rl, pos", "response": "Return the length starting position and value of consecutive identical values."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the number of true values in array for runs at least as long as given duration.", "response": "def windowed_run_count_1d(arr, window):\n    \"\"\"Return the number of consecutive true values in array for runs at least as long as given duration.\n\n    Parameters\n    ----------\n    arr : bool array\n      Input array\n    window : int\n      Minimum duration of consecutive run to accumulate values.\n\n    Returns\n    -------\n    int\n      Total number of true values part of a consecutive run at least `window` long.\n    \"\"\"\n    v, rl = rle_1d(arr)[:2]\n    return np.where(v * rl >= window, rl, 0).sum()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the index of the first item in a run of at least a given duration.", "response": "def first_run_1d(arr, window):\n    \"\"\"Return the index of the first item of a run of at least a given length.\n\n    Parameters\n    ----------\n    ----------\n    arr : bool array\n      Input array\n    window : int\n      Minimum duration of consecutive run to accumulate values.\n\n    Returns\n    -------\n    int\n      Index of first item in first valid run. Returns np.nan if there are no valid run.\n    \"\"\"\n    v, rl, pos = rle_1d(arr)\n    ind = np.where(v * rl >= window, pos, np.inf).min()\n\n    if np.isinf(ind):\n        return np.nan\n    return ind"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the length of the longest consecutive run of identical values.", "response": "def longest_run_1d(arr):\n    \"\"\"Return the length of the longest consecutive run of identical values.\n\n    Parameters\n    ----------\n    arr : bool array\n      Input array\n\n    Returns\n    -------\n    int\n      Length of longest run.\n    \"\"\"\n    v, rl = rle_1d(arr)[:2]\n    return np.where(v, rl, 0).max()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef windowed_run_events_1d(arr, window):\n    v, rl, pos = rle_1d(arr)\n    return (v * rl >= window).sum()", "response": "Return the number of runs of a minimum length."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef windowed_run_events_ufunc(x, window):\n    return xr.apply_ufunc(windowed_run_events_1d,\n                          x,\n                          input_core_dims=[['time'], ],\n                          vectorize=True,\n                          dask='parallelized',\n                          output_dtypes=[np.int, ],\n                          keep_attrs=True,\n                          kwargs={'window': window})", "response": "Dask - parallel version of windowed_run_events_1d ie the number of runs at least as long as given duration."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef check_valid(var, key, expected):\n\n    att = getattr(var, key, None)\n    if att is None:\n        e = 'Variable does not have a `{}` attribute.'.format(key)\n        warn(e)\n    elif att != expected:\n        e = 'Variable has a non-conforming {}. Got `{}`, expected `{}`'.format(key, att, expected)\n        warn(e)", "response": "r Check that a variable s attribute has the expected value. Warn user otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef assert_daily(var):\n\n    t0, t1 = var.time[:2]\n\n    # This won't work for non-standard calendars. Needs to be implemented in xarray. Comment for now\n    if isinstance(t0.values, np.datetime64):\n        if pd.infer_freq(var.time.to_pandas()) != 'D':\n            raise ValueError(\"time series is not recognized as daily.\")\n\n    # Check that the first time step is one day.\n    if np.timedelta64(dt.timedelta(days=1)) != (t1 - t0).data:\n        raise ValueError(\"time series is not daily.\")\n\n    # Check that the series has the same time step throughout\n    if not var.time.to_pandas().is_monotonic_increasing:\n        raise ValueError(\"time index is not monotonically increasing.\")", "response": "r Assert that the time series is daily and monotonic. A ValueError is raised otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_daily_mean_temperature(comp, units='K'):\n\n    @wraps(comp)\n    def func(tas, *args, **kwds):\n        check_valid_temperature(tas, units)\n        check_valid(tas, 'cell_methods', 'time: mean within days')\n        return comp(tas, *args, **kwds)\n\n    return func", "response": "rDecorator to check that a computation runs on a valid temperature dataset."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_daily_max_min_temperature(comp, units='K'):\n\n    @wraps(comp)\n    def func(tasmax, tasmin, **kwds):\n        valid_daily_max_temperature(tasmax, units)\n        valid_daily_min_temperature(tasmin, units)\n\n        return comp(tasmax, tasmin, **kwds)\n\n    return func", "response": "rDecorator to check that a computation runs on valid max and min temperature datasets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef valid_daily_mean_discharge(comp):\n\n    @wraps(comp)\n    def func(q, **kwds):\n        check_valid_discharge(q)\n        return comp(q, **kwds)\n\n    return func", "response": "r Decorator to check that a computation runs on valid discharge data."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef check_is_dataarray(comp):\n\n    @wraps(comp)\n    def func(data_array, *args, **kwds):\n        assert isinstance(data_array, xr.DataArray)\n        return comp(data_array, *args, **kwds)\n\n    return func", "response": "r Decorator to check that a computation has an instance of xarray. DataArray\n     as first argument."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef missing_any(da, freq, **kwds):\n    c = da.notnull().resample(time=freq).sum(dim='time')\n\n    if '-' in freq:\n        pfreq, anchor = freq.split('-')\n    else:\n        pfreq = freq\n\n    if pfreq.endswith('S'):\n        start_time = c.indexes['time']\n        end_time = start_time.shift(1, freq=freq)\n    else:\n        end_time = c.indexes['time']\n        start_time = end_time.shift(-1, freq=freq)\n\n    n = (end_time - start_time).days\n    nda = xr.DataArray(n.values, coords={'time': c.time}, dims='time')\n    return c != nda", "response": "r Returns a boolean array indicating whether there are missing days in the resampled array."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef rstjinja(app, docname, source):\n    # Make sure we're outputting HTML\n    if app.builder.format != 'html':\n        return\n    src = source[0]\n    rendered = app.builder.templates.render_string(\n        src, app.config.html_context\n    )\n    source[0] = rendered", "response": "Render our pages as a jinja template for fancy templating goodness."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef units2pint(value):\n\n    def _transform(s):\n        \"\"\"Convert a CF-unit string to a pint expression.\"\"\"\n        return re.subn(r'\\^?(-?\\d)', r'**\\g<1>', s)[0]\n\n    if isinstance(value, str):\n        unit = value\n    elif isinstance(value, xr.DataArray):\n        unit = value.attrs['units']\n    elif isinstance(value, units.Quantity):\n        return value.units\n    else:\n        raise NotImplementedError(\"Value of type {} not supported.\".format(type(value)))\n\n    try:  # Pint compatible\n        return units.parse_expression(unit).units\n    except (pint.UndefinedUnitError, pint.DimensionalityError):  # Convert from CF-units to pint-compatible\n        return units.parse_expression(_transform(unit)).units", "response": "Convert CF - units to pint units."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pint2cfunits(value):\n    # Print units using abbreviations (millimeter -> mm)\n    s = \"{:~}\".format(value)\n\n    # Search and replace patterns\n    pat = r'(?P<inverse>/ )?(?P<unit>\\w+)(?: \\*\\* (?P<pow>\\d))?'\n\n    def repl(m):\n        i, u, p = m.groups()\n        p = p or (1 if i else '')\n        neg = '-' if i else ('^' if p else '')\n\n        return \"{}{}{}\".format(u, neg, p)\n\n    out, n = re.subn(pat, repl, s)\n    return out", "response": "Return a CF - Convention unit string from a pint. Unit object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmultiply xarray. DataArray by pint. Quantity.", "response": "def pint_multiply(da, q, out_units=None):\n    \"\"\"Multiply xarray.DataArray by pint.Quantity.\n\n    Parameters\n    ----------\n    da : xr.DataArray\n      Input array.\n    q : pint.Quantity\n      Multiplicating factor.\n    out_units : str\n      Units the output array should be converted into.\n    \"\"\"\n    a = 1 * units2pint(da)\n    f = a * q.to_base_units()\n    if out_units:\n        f = f.to(out_units)\n    out = da * f.magnitude\n    out.attrs['units'] = pint2cfunits(f.units)\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a mathematical expression into a value with the same units as a DataArray.", "response": "def convert_units_to(source, target, context=None):\n    \"\"\"\n    Convert a mathematical expression into a value with the same units as a DataArray.\n\n    Parameters\n    ----------\n    source : str, pint.Quantity or xr.DataArray\n      The value to be converted, e.g. '4C' or '1 mm/d'.\n    target : str, pint.Unit or DataArray\n      Target array of values to which units must conform.\n    context : str\n\n\n    Returns\n    -------\n    out\n      The source value converted to target's units.\n    \"\"\"\n    # Target units\n    if isinstance(target, units.Unit):\n        tu = target\n    elif isinstance(target, (str, xr.DataArray)):\n        tu = units2pint(target)\n    else:\n        raise NotImplementedError\n\n    if isinstance(source, str):\n        q = units.parse_expression(source)\n\n        # Return magnitude of converted quantity. This is going to fail if units are not compatible.\n        return q.to(tu).m\n\n    if isinstance(source, units.Quantity):\n        return source.to(tu).m\n\n    if isinstance(source, xr.DataArray):\n        fu = units2pint(source)\n\n        if fu == tu:\n            return source\n\n        tu_u = pint2cfunits(tu)\n        with units.context(context or 'none'):\n            out = units.convert(source, fu, tu)\n            out.attrs['units'] = tu_u\n            return out\n\n    # TODO remove backwards compatibility of int/float thresholds after v1.0 release\n    if isinstance(source, (float, int)):\n        if context == 'hydro':\n            fu = units.mm / units.day\n        else:\n            fu = units.degC\n        warnings.warn(\"Future versions of XCLIM will require explicit unit specifications.\", FutureWarning)\n        return (source * fu).to(tu).m\n\n    raise NotImplementedError(\"source of type {} is not supported.\".format(type(source)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a decorator that checks the units of the passed in arguments.", "response": "def declare_units(out_units, **units_by_name):\n    \"\"\"Create a decorator to check units of function arguments.\"\"\"\n\n    def dec(func):\n        # Match the signature of the function to the arguments given to the decorator\n        sig = signature(func)\n        bound_units = sig.bind_partial(**units_by_name)\n\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            # Match all passed in value to their proper arguments so we can check units\n            bound_args = sig.bind(*args, **kwargs)\n            for name, val in bound_args.arguments.items():\n                _check_units(val, bound_units.arguments.get(name, None))\n\n            out = func(*args, **kwargs)\n\n            # In the generic case, we use the default units that should have been propagated by the computation.\n            if '[' in out_units:\n                _check_units(out, out_units)\n\n            # Otherwise, we specify explicitly the units.\n            else:\n                out.attrs['units'] = out_units\n            return out\n\n        return wrapper\n\n    return dec"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating an xarray datset of ensemble of climate simulation from a list of netcdf files.", "response": "def create_ensemble(ncfiles, mf_flag=False):\n    \"\"\"Create an xarray datset of ensemble of climate simulation from a list of netcdf files. Input data is\n    concatenated along a newly created data dimension ('realization')\n\n    Returns a xarray dataset object containing input data from the list of netcdf files concatenated along\n    a new dimension (name:'realization'). In the case where input files have unequal time dimensions output\n    ensemble dataset is created for overlapping time-steps common to all input files\n\n    Parameters\n    ----------\n    ncfiles : sequence\n      List of netcdf file paths. If mf_flag is true ncfiles should be a list of lists where\n    each sublist contains input .nc files of a multifile dataset\n\n    mf_flag : Boolean . If true climate simulations are treated as multifile datasets before concatenation\n\n    Returns\n    -------\n    xarray dataset containing concatenated data from all input files\n\n    Notes\n    -----\n    Input netcdf files require equal spatial dimension size (e.g. lon, lat dimensions)\n    If input data contains multiple cftime calendar types they must be at monthly or coarser frequency\n\n    Examples\n    --------\n    >>> from xclim import utils\n    >>> import glob\n    >>> ncfiles = glob.glob('/*.nc')\n    >>> ens = utils.create_ensemble(ncfiles)\n    >>> print(ens)\n    Using multifile datasets:\n    simulation 1 is a list of .nc files (e.g. separated by time)\n    >>> ncfiles = glob.glob('dir/*.nc')\n    simulation 2 is also a list of .nc files\n    >>> ens = utils.create_ensemble(ncfiles)\n    \"\"\"\n    dim = 'realization'\n    ds1 = []\n    start_end_flag = True\n    print('finding common time-steps')\n    for n in ncfiles:\n        if mf_flag:\n            ds = xr.open_mfdataset(n, concat_dim='time', decode_times=False, chunks={'time': 10})\n            ds['time'] = xr.open_mfdataset(n).time\n        else:\n            ds = xr.open_dataset(n, decode_times=False)\n            ds['time'] = xr.decode_cf(ds).time\n        # get times - use common\n        time1 = pd.to_datetime({'year': ds.time.dt.year, 'month': ds.time.dt.month, 'day': ds.time.dt.day})\n        if start_end_flag:\n            start1 = time1.values[0]\n            end1 = time1.values[-1]\n            start_end_flag = False\n        if time1.values.min() > start1:\n            start1 = time1.values.min()\n        if time1.values.max() < end1:\n            end1 = time1.values.max()\n\n    for n in ncfiles:\n        print('accessing file ', ncfiles.index(n) + 1, ' of ', len(ncfiles))\n        if mf_flag:\n            ds = xr.open_mfdataset(n, concat_dim='time', decode_times=False, chunks={'time': 10})\n            ds['time'] = xr.open_mfdataset(n).time\n        else:\n            ds = xr.open_dataset(n, decode_times=False, chunks={'time': 10})\n            ds['time'] = xr.decode_cf(ds).time\n\n        ds['time'].values = pd.to_datetime({'year': ds.time.dt.year, 'month': ds.time.dt.month, 'day': ds.time.dt.day})\n\n        ds = ds.where((ds.time >= start1) & (ds.time <= end1), drop=True)\n\n        ds1.append(ds.drop('time'))\n    print('concatenating files : adding dimension ', dim, )\n    ens = xr.concat(ds1, dim=dim)\n    # assign time coords\n    ens = ens.assign_coords(time=ds.time.values)\n    return ens"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef ensemble_percentiles(ens, values=(10, 50, 90), time_block=None):\n\n    ds_out = ens.drop(ens.data_vars)\n    dims = list(ens.dims)\n    for v in ens.data_vars:\n        # Percentile calculation requires load to memory : automate size for large ensemble objects\n        if not time_block:\n            time_block = round(2E8 / (ens[v].size / ens[v].shape[dims.index('time')]), -1)  # 2E8\n\n        if time_block > len(ens[v].time):\n            out = calc_percentiles_simple(ens, v, values)\n\n        else:\n            # loop through blocks\n            Warning('large ensemble size detected : statistics will be calculated in blocks of ', int(time_block),\n                    ' time-steps')\n            out = calc_percentiles_blocks(ens, v, values, time_block)\n        for vv in out.data_vars:\n            ds_out[vv] = out[vv]\n    return ds_out", "response": "Calculate ensemble percentiles between a results from an ensemble of climate simulations and return a dataset containing the ensemble statistics between a results from an ensemble of climate simulations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef ensemble_mean_std_max_min(ens):\n    dsOut = ens.drop(ens.data_vars)\n    for v in ens.data_vars:\n\n        dsOut[v + '_mean'] = ens[v].mean(dim='realization')\n        dsOut[v + '_stdev'] = ens[v].std(dim='realization')\n        dsOut[v + '_max'] = ens[v].max(dim='realization')\n        dsOut[v + '_min'] = ens[v].min(dim='realization')\n        for vv in dsOut.data_vars:\n            dsOut[vv].attrs = ens[v].attrs\n\n            if 'description' in dsOut[vv].attrs.keys():\n                vv.split()\n                dsOut[vv].attrs['description'] = dsOut[vv].attrs['description'] + ' : ' + vv.split('_')[\n                    -1] + ' of ensemble'\n\n    return dsOut", "response": "Calculate ensemble statistics between a results from an ensemble of climate simulations\n    Returns a dataset containing ensemble mean standard - deviation minimum and maximum for input climate simulations\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef threshold_count(da, op, thresh, freq):\n    from xarray.core.ops import get_op\n\n    if op in binary_ops:\n        op = binary_ops[op]\n    elif op in binary_ops.values():\n        pass\n    else:\n        raise ValueError(\"Operation `{}` not recognized.\".format(op))\n\n    func = getattr(da, '_binary_op')(get_op(op))\n    c = func(da, thresh) * 1\n    return c.resample(time=freq).sum(dim='time')", "response": "Count the number of days above or below threshold."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the climatological percentile over a moving window around each day of the year.", "response": "def percentile_doy(arr, window=5, per=.1):\n    \"\"\"Percentile value for each day of the year\n\n    Return the climatological percentile over a moving window around each day of the year.\n\n    Parameters\n    ----------\n    arr : xarray.DataArray\n      Input data.\n    window : int\n      Number of days around each day of the year to include in the calculation.\n    per : float\n      Percentile between [0,1]\n\n    Returns\n    -------\n    xarray.DataArray\n      The percentiles indexed by the day of the year.\n    \"\"\"\n    # TODO: Support percentile array, store percentile in coordinates.\n    #  This is supported by DataArray.quantile, but not by groupby.reduce.\n    rr = arr.rolling(min_periods=1, center=True, time=window).construct('window')\n\n    # Create empty percentile array\n    g = rr.groupby('time.dayofyear')\n\n    p = g.reduce(np.nanpercentile, dim=('time', 'window'), q=per * 100)\n\n    # The percentile for the 366th day has a sample size of 1/4 of the other days.\n    # To have the same sample size, we interpolate the percentile from 1-365 doy range to 1-366\n    if p.dayofyear.max() == 366:\n        p = adjust_doy_calendar(p.loc[p.dayofyear < 366], arr)\n\n    p.attrs.update(arr.attrs.copy())\n    return p"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef infer_doy_max(arr):\n    cal = arr.time.encoding.get('calendar', None)\n    if cal in calendars:\n        doy_max = calendars[cal]\n    else:\n        # If source is an array with no calendar information and whose length is not at least of full year,\n        # then this inference could be wrong (\n        doy_max = arr.time.dt.dayofyear.max().data\n        if len(arr.time) < 360:\n            raise ValueError(\"Cannot infer the calendar from a series less than a year long.\")\n        if doy_max not in [360, 365, 366]:\n            raise ValueError(\"The target array's calendar is not recognized\")\n\n    return doy_max", "response": "Infer the doy max of the calendar from the source array."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _interpolate_doy_calendar(source, doy_max):\n    if 'dayofyear' not in source.coords.keys():\n        raise AttributeError(\"source should have dayofyear coordinates.\")\n\n    # Interpolation of source to target dayofyear range\n    doy_max_source = source.dayofyear.max()\n\n    # Interpolate to fill na values\n    tmp = source.interpolate_na(dim='dayofyear')\n\n    # Interpolate to target dayofyear range\n    tmp.coords['dayofyear'] = np.linspace(start=1, stop=doy_max, num=doy_max_source)\n\n    return tmp.interp(dayofyear=range(1, doy_max + 1))", "response": "Interpolate from one set of dayofyear range to another set of dayofyear range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef adjust_doy_calendar(source, target):\n    doy_max_source = source.dayofyear.max()\n\n    doy_max = infer_doy_max(target)\n    if doy_max_source == doy_max:\n        return source\n\n    return _interpolate_doy_calendar(source, doy_max)", "response": "Interpolate from one set of dayofyear range to another calendar."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef subset_bbox(da, lon_bnds=None, lat_bnds=None, start_yr=None, end_yr=None):\n\n    if lon_bnds:\n\n        lon_bnds = np.asarray(lon_bnds)\n        if np.all(da.lon > 0) and np.any(lon_bnds < 0):\n            lon_bnds[lon_bnds < 0] += 360\n        da = da.where((da.lon >= lon_bnds.min()) & (da.lon <= lon_bnds.max()), drop=True)\n\n    if lat_bnds:\n        lat_bnds = np.asarray(lat_bnds)\n        da = da.where((da.lat >= lat_bnds.min()) & (da.lat <= lat_bnds.max()), drop=True)\n\n    if start_yr or end_yr:\n        if not start_yr:\n            start_yr = da.time.dt.year.min()\n        if not end_yr:\n            end_yr = da.time.dt.year.max()\n\n        year_bnds = np.asarray([start_yr, end_yr])\n        da = da.where((da.time.dt.year >= year_bnds.min()) & (da.time.dt.year <= year_bnds.max()), drop=True)\n\n    return da", "response": "Subset a datarray or dataset spatially using a lat lon bounding box and years selection."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef subset_gridpoint(da, lon, lat, start_yr=None, end_yr=None):\n\n    g = Geod(ellps='WGS84')  # WGS84 ellipsoid - decent globaly\n    # adjust for files with all postive longitudes if necessary\n    if np.all(da.lon > 0) and lon < 0:\n        lon += 360\n\n    if len(da.lon.shape) == 1 & len(da.lat.shape) == 1:\n        # create a 2d grid of lon, lat values\n        lon1, lat1 = np.meshgrid(np.asarray(da.lon.values), np.asarray(da.lat.values))\n\n    else:\n        lon1 = da.lon.values\n        lat1 = da.lat.values\n    shp_orig = lon1.shape\n    lon1 = np.reshape(lon1, lon1.size)\n    lat1 = np.reshape(lat1, lat1.size)\n    # calculate geodesic distance between grid points and point of interest\n    az12, az21, dist = g.inv(lon1, lat1, np.broadcast_to(lon, lon1.shape), np.broadcast_to(lat, lat1.shape))\n    dist = dist.reshape(shp_orig)\n\n    iy, ix = np.unravel_index(np.argmin(dist, axis=None), dist.shape)\n    xydims = [x for x in da.dims if 'time' not in x]\n    args = dict()\n    args[xydims[0]] = iy\n    args[xydims[1]] = ix\n    out = da.isel(**args)\n    if start_yr or end_yr:\n        if not start_yr:\n            start_yr = da.time.dt.year.min()\n        if not end_yr:\n            end_yr = da.time.dt.year.max()\n        year_bnds = np.asarray([start_yr, end_yr])\n\n        if len(year_bnds) == 1:\n            time_cond = da.time.dt.year == year_bnds\n        else:\n            time_cond = (da.time.dt.year >= year_bnds.min()) & (da.time.dt.year <= year_bnds.max())\n        out = out.where(time_cond, drop=True)\n\n    return out", "response": "Extract a nearest gridpoint from datarray based on lat lon coordinate."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef daily_downsampler(da, freq='YS'):\n\n    # generate tags from da.time and freq\n    if isinstance(da.time.values[0], np.datetime64):\n        years = ['{:04d}'.format(y) for y in da.time.dt.year.values]\n        months = ['{:02d}'.format(m) for m in da.time.dt.month.values]\n    else:\n        # cannot use year, month, season attributes, not available for all calendars ...\n        years = ['{:04d}'.format(v.year) for v in da.time.values]\n        months = ['{:02d}'.format(v.month) for v in da.time.values]\n    seasons = ['DJF DJF MAM MAM MAM JJA JJA JJA SON SON SON DJF'.split()[int(m) - 1] for m in months]\n\n    n_t = da.time.size\n    if freq == 'YS':\n        # year start frequency\n        l_tags = years\n    elif freq == 'MS':\n        # month start frequency\n        l_tags = [years[i] + months[i] for i in range(n_t)]\n    elif freq == 'QS-DEC':\n        # DJF, MAM, JJA, SON seasons\n        # construct tags from list of season+year, increasing year for December\n        ys = []\n        for i in range(n_t):\n            m = months[i]\n            s = seasons[i]\n            y = years[i]\n            if m == '12':\n                y = str(int(y) + 1)\n            ys.append(y + s)\n        l_tags = ys\n    else:\n        raise RuntimeError('freqency {:s} not implemented'.format(freq))\n\n    # add tags to buffer DataArray\n    buffer = da.copy()\n    buffer.coords['tags'] = ('time', l_tags)\n\n    # return groupby according to tags\n    return buffer.groupby('tags')", "response": "Daily climate data downsampler for a single object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef walk_map(d, func):\n    out = {}\n    for k, v in d.items():\n        if isinstance(v, (dict, defaultdict)):\n            out[k] = walk_map(v, func)\n        else:\n            out[k] = func(v)\n    return out", "response": "Apply a function recursively to values of dictionary d."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef format_kwargs(attrs, params):\n    attrs_mapping = {'cell_methods': {'YS': 'years', 'MS': 'months'},\n                     'long_name': {'YS': 'Annual', 'MS': 'Monthly'}}\n\n    for key, val in attrs.items():\n        mba = {}\n        # Add formatting {} around values to be able to replace them with _attrs_mapping using format.\n        for k, v in params.items():\n            if isinstance(v, six.string_types) and v in attrs_mapping.get(key, {}).keys():\n                mba[k] = '{' + v + '}'\n            else:\n                mba[k] = v\n\n        attrs[key] = val.format(**mba).format(**attrs_mapping.get(key, {}))", "response": "Modify attribute with argument values."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a dictionary representation of the class.", "response": "def json(self, args=None):\n        \"\"\"Return a dictionary representation of the class.\n\n        Notes\n        -----\n        This is meant to be used by a third-party library wanting to wrap this class into another interface.\n\n        \"\"\"\n        names = ['identifier', 'abstract', 'keywords']\n        out = {key: getattr(self, key) for key in names}\n        out.update(self.cf_attrs)\n        out = self.format(out, args)\n\n        out['notes'] = self.notes\n\n        out['parameters'] = str({key: {'default': p.default if p.default != p.empty else None, 'desc': ''}\n                                 for (key, p) in self._sig.parameters.items()})\n\n        if six.PY2:\n            out = walk_map(out, lambda x: x.decode('utf8') if isinstance(x, six.string_types) else x)\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nformats attributes including {} tags with arguments.", "response": "def format(self, attrs, args=None):\n        \"\"\"Format attributes including {} tags with arguments.\"\"\"\n        if args is None:\n            return attrs\n\n        out = {}\n        for key, val in attrs.items():\n            mba = {'indexer': 'annual'}\n            # Add formatting {} around values to be able to replace them with _attrs_mapping using format.\n            for k, v in args.items():\n                if isinstance(v, six.string_types) and v in self._attrs_mapping.get(key, {}).keys():\n                    mba[k] = '{{{}}}'.format(v)\n                elif isinstance(v, dict):\n                    if v:\n                        dk, dv = v.copy().popitem()\n                        if dk == 'month':\n                            dv = 'm{}'.format(dv)\n                        mba[k] = '{{{}}}'.format(dv)\n                else:\n                    mba[k] = int(v) if (isinstance(v, float) and v % 1 == 0) else v\n\n            out[key] = val.format(**mba).format(**self._attrs_mapping.get(key, {}))\n\n        return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn whether an output is considered missing or not.", "response": "def missing(*args, **kwds):\n        \"\"\"Return whether an output is considered missing or not.\"\"\"\n        from functools import reduce\n\n        freq = kwds.get('freq')\n        miss = (checks.missing_any(da, freq) for da in args)\n        return reduce(np.logical_or, miss)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a subclass from the attributes dictionary.", "response": "def factory(cls, attrs):\n        \"\"\"Create a subclass from the attributes dictionary.\"\"\"\n        name = attrs['identifier'].capitalize()\n        return type(name, (cls,), attrs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nprovide a wrapper for python string map byte to str", "response": "def Text(text):\n    \"\"\" provide a wrapper for python string\n    map byte to str (python 3)\n    all string in utf-8 encoding\n    normalize string to NFC\n    \"\"\"\n    if not is_unicode(text):\n        text = text.decode(\"utf-8\")\n    text = unicodedata.normalize(\"NFC\", text)\n    return text"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef template2features(sent, i, token_syntax, debug=True):\n    columns = []\n    for j in range(len(sent[0])):\n        columns.append([t[j] for t in sent])\n    matched = re.match(\n        \"T\\[(?P<index1>\\-?\\d+)(\\,(?P<index2>\\-?\\d+))?\\](\\[(?P<column>.*)\\])?(\\.(?P<function>.*))?\",\n        token_syntax)\n    column = matched.group(\"column\")\n    column = int(column) if column else 0\n    index1 = int(matched.group(\"index1\"))\n    index2 = matched.group(\"index2\")\n    index2 = int(index2) if index2 else None\n    func = matched.group(\"function\")\n    if debug:\n        prefix = \"%s=\" % token_syntax\n    else:\n        prefix = \"\"\n    if i + index1 < 0:\n        return [\"%sBOS\" % prefix]\n    if i + index1 >= len(sent):\n        return [\"%sEOS\" % prefix]\n    if index2 is not None:\n        if i + index2 >= len(sent):\n            return [\"%sEOS\" % prefix]\n        word = \" \".join(columns[column][i + index1: i + index2 + 1])\n    else:\n        word = sent[i + index1][column]\n    if func is not None:\n        result = apply_function(func, word)\n    else:\n        result = word\n    return [\"%s%s\" % (prefix, result)]", "response": "returns a list of features that are used in the template"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nextracting features in a sentence by using word2features", "response": "def sent2features(sentence, template):\n    \"\"\" extract features in a sentence\n\n    :type sentence: list of token, each token is a list of tag\n    \"\"\"\n    return [word2features(sentence, i, template) for i in range(len(sentence))]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef tokenize(text, format=None):\n    text = Text(text)\n    text = text.replace(\"\\t\", \" \")\n    tokens = re.findall(patterns, text)\n    tokens = [token[0] for token in tokens]\n    if format == \"text\":\n        return \" \".join(tokens)\n    else:\n        return tokens", "response": "tokenize text for word segmentation"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of tuples with word pos and tagged tokens.", "response": "def pos_tag(sentence, format=None):\n    \"\"\"\n    Vietnamese POS tagging\n\n    Parameters\n    ==========\n\n    sentence: {unicode, str}\n        Raw sentence\n\n    Returns\n    =======\n    tokens: list of tuple with word, pos tag\n        tagged sentence\n    Examples\n    --------\n    >>> # -*- coding: utf-8 -*-\n    >>> from underthesea import pos_tag\n    >>> sentence = \"Ch\u1ee3 th\u1ecbt ch\u00f3 n\u1ed5i ti\u1ebfng \u1edf TPHCM b\u1ecb truy qu\u00e9t\"\n    >>> pos_tag(sentence)\n    [('Ch\u1ee3', 'N'),\n    ('th\u1ecbt', 'N'),\n    ('ch\u00f3', 'N'),\n    ('n\u1ed5i ti\u1ebfng', 'A'),\n    ('\u1edf', 'E'),\n    ('TPHCM', 'Np'),\n    ('b\u1ecb', 'V'),\n    ('truy qu\u00e9t', 'V')]\n    \"\"\"\n    sentence = word_tokenize(sentence)\n    crf_model = CRFPOSTagPredictor.Instance()\n    result = crf_model.predict(sentence, format)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save(self, folder, format):\n        try:\n            mkdir(folder)\n        except Exception:\n            pass\n        for document in self.documents:\n            f = join(folder, document.id)\n            content = u\"\\n\".join(document.sentences)\n            write(f, content)", "response": "save wscorpus to files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ner(sentence, format=None):\n    sentence = chunk(sentence)\n    crf_model = CRFNERPredictor.Instance()\n    result = crf_model.predict(sentence, format)\n    return result", "response": "Returns a list of tuples with word pos tag chunking tag and tagged sentence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nload public RSA key with work - around for keys using incorrect header and footer format.", "response": "def load_key(pubkey):\n    \"\"\"Load public RSA key, with work-around for keys using\n    incorrect header/footer format.\n\n    Read more about RSA encryption with cryptography:\n    https://cryptography.io/latest/hazmat/primitives/asymmetric/rsa/\n    \"\"\"\n    try:\n        return load_pem_public_key(pubkey.encode(), default_backend())\n    except ValueError:\n        # workaround for https://github.com/travis-ci/travis-api/issues/196\n        pubkey = pubkey.replace('BEGIN RSA', 'BEGIN').replace('END RSA', 'END')\n        return load_pem_public_key(pubkey.encode(), default_backend())"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nencrypt password using given RSA public key and encode it with base64.", "response": "def encrypt(pubkey, password):\n    \"\"\"Encrypt password using given RSA public key and encode it with base64.\n\n    The encrypted password can only be decrypted by someone with the\n    private key (in this case, only Travis).\n    \"\"\"\n    key = load_key(pubkey)\n    encrypted_password = key.encrypt(password, PKCS1v15())\n    return base64.b64encode(encrypted_password)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef prepend_line(filepath, line):\n    with open(filepath) as f:\n        lines = f.readlines()\n\n    lines.insert(0, line)\n\n    with open(filepath, 'w') as f:\n        f.writelines(lines)", "response": "Rewrite a file adding a line to its beginning."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the singleton instance of the class.", "response": "def Instance(self):\n        \"\"\"\n        Returns the singleton instance. Upon its first call, it creates a\n        new instance of the decorated class and calls its `__init__` method.\n        On all subsequent calls, the already created instance is returned.\n\n        \"\"\"\n        try:\n            return self._instance\n        except AttributeError:\n            self._instance = self._decorated()\n            return self._instance"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef chunk(sentence, format=None):\n    sentence = pos_tag(sentence)\n    crf_model = CRFChunkingPredictor.Instance()\n    result = crf_model.predict(sentence, format)\n    return result", "response": "Returns a list of tokens in a sentence in a chunking fashion."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef word_tokenize(sentence, format=None):\n    tokens = tokenize(sentence)\n    crf_model = CRFModel.instance()\n    output = crf_model.predict(tokens, format)\n    tokens = [token[0] for token in output]\n    tags = [token[1] for token in output]\n    output = []\n    for tag, token in zip(tags, tokens):\n        if tag == \"I-W\":\n            output[-1] = output[-1] + u\" \" + token\n        else:\n            output.append(token)\n    if format == \"text\":\n        output = u\" \".join([item.replace(\" \", \"_\") for item in output])\n    return output", "response": "A word segmentation of the sentence."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef transform(self, text):\n        if type(text) is not unicode:\n            text = unicode(text, 'utf-8')\n        return text", "response": "transform unicode text to unicode"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfit FastText according to X y", "response": "def fit(self, X, y, model_filename=None):\n        \"\"\"Fit FastText according to X, y\n\n        Parameters:\n        ----------\n        X : list of text\n            each item is a text\n        y: list\n           each item is either a label (in multi class problem) or list of\n           labels (in multi label problem)\n        \"\"\"\n        train_file = \"temp.train\"\n        X = [x.replace(\"\\n\", \" \") for x in X]\n        y = [item[0] for item in y]\n        y = [_.replace(\" \", \"-\") for _ in y]\n        lines = [\"__label__{} , {}\".format(j, i) for i, j in zip(X, y)]\n        content = \"\\n\".join(lines)\n        write(train_file, content)\n        if model_filename:\n            self.estimator = fasttext.supervised(train_file, model_filename)\n        else:\n            self.estimator = fasttext.supervised(train_file)\n        os.remove(train_file)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a selenium driver using specified config properties", "response": "def create_driver(self):\n        \"\"\"Create a selenium driver using specified config properties\n\n        :returns: a new selenium driver\n        :rtype: selenium.webdriver.remote.webdriver.WebDriver\n        \"\"\"\n        driver_type = self.config.get('Driver', 'type')\n        try:\n            if self.config.getboolean_optional('Server', 'enabled'):\n                self.logger.info(\"Creating remote driver (type = %s)\", driver_type)\n                driver = self._create_remote_driver()\n            else:\n                self.logger.info(\"Creating local driver (type = %s)\", driver_type)\n                driver = self._create_local_driver()\n        except Exception as exc:\n            error_message = get_error_message_from_exception(exc)\n            self.logger.error(\"%s driver can not be launched: %s\", driver_type.capitalize(), error_message)\n            raise\n\n        return driver"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a new remote selenium driver in a remote server.", "response": "def _create_remote_driver(self):\n        \"\"\"Create a driver in a remote server\n        View valid capabilities in https://github.com/SeleniumHQ/selenium/wiki/DesiredCapabilities\n\n        :returns: a new remote selenium driver\n        \"\"\"\n        # Get server url\n        server_url = '{}/wd/hub'.format(self.utils.get_server_url())\n\n        # Get driver capabilities\n        driver_type = self.config.get('Driver', 'type')\n        driver_name = driver_type.split('-')[0]\n        capabilities = self._get_capabilities_from_driver_type(driver_name)\n\n        # Add driver version\n        try:\n            capabilities['version'] = driver_type.split('-')[1]\n        except IndexError:\n            pass\n\n        # Add platform capability\n        try:\n            platforms_list = {'xp': 'XP',\n                              'windows_7': 'VISTA',\n                              'windows_8': 'WIN8',\n                              'windows_10': 'WIN10',\n                              'linux': 'LINUX',\n                              'android': 'ANDROID',\n                              'mac': 'MAC'}\n            capabilities['platform'] = platforms_list.get(driver_type.split('-')[3], driver_type.split('-')[3])\n        except IndexError:\n            pass\n\n        if driver_name == 'opera':\n            capabilities['opera.autostart'] = True\n            capabilities['opera.arguments'] = '-fullscreen'\n        elif driver_name == 'firefox':\n            capabilities['firefox_profile'] = self._create_firefox_profile().encoded\n        elif driver_name == 'chrome':\n            chrome_capabilities = self._create_chrome_options().to_capabilities()\n            try:\n                capabilities['goog:chromeOptions'] = chrome_capabilities[\"goog:chromeOptions\"]\n            except KeyError:\n                # Selenium 3.5.3 and older\n                capabilities['chromeOptions'] = chrome_capabilities[\"chromeOptions\"]\n\n        # Add custom driver capabilities\n        self._add_capabilities_from_properties(capabilities, 'Capabilities')\n\n        if driver_name in ('android', 'ios', 'iphone'):\n            # Create remote appium driver\n            self._add_capabilities_from_properties(capabilities, 'AppiumCapabilities')\n            return appiumdriver.Remote(command_executor=server_url, desired_capabilities=capabilities)\n        else:\n            # Create remote web driver\n            return webdriver.Remote(command_executor=server_url, desired_capabilities=capabilities)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a local selenium driver in local machine", "response": "def _create_local_driver(self):\n        \"\"\"Create a driver in local machine\n\n        :returns: a new local selenium driver\n        \"\"\"\n        driver_type = self.config.get('Driver', 'type')\n        driver_name = driver_type.split('-')[0]\n\n        if driver_name in ('android', 'ios', 'iphone'):\n            # Create local appium driver\n            driver = self._setup_appium()\n        else:\n            driver_setup = {\n                'firefox': self._setup_firefox,\n                'chrome': self._setup_chrome,\n                'safari': self._setup_safari,\n                'opera': self._setup_opera,\n                'iexplore': self._setup_explorer,\n                'edge': self._setup_edge,\n                'phantomjs': self._setup_phantomjs\n            }\n            driver_setup_method = driver_setup.get(driver_name)\n            if not driver_setup_method:\n                raise Exception('Unknown driver {0}'.format(driver_name))\n\n            # Get driver capabilities\n            capabilities = self._get_capabilities_from_driver_type(driver_name)\n            self._add_capabilities_from_properties(capabilities, 'Capabilities')\n\n            # Create local selenium driver\n            driver = driver_setup_method(capabilities)\n\n        return driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_capabilities_from_driver_type(driver_name):\n        if driver_name == 'firefox':\n            return DesiredCapabilities.FIREFOX.copy()\n        elif driver_name == 'chrome':\n            return DesiredCapabilities.CHROME.copy()\n        elif driver_name == 'safari':\n            return DesiredCapabilities.SAFARI.copy()\n        elif driver_name == 'opera':\n            return DesiredCapabilities.OPERA.copy()\n        elif driver_name == 'iexplore':\n            return DesiredCapabilities.INTERNETEXPLORER.copy()\n        elif driver_name == 'edge':\n            return DesiredCapabilities.EDGE.copy()\n        elif driver_name == 'phantomjs':\n            return DesiredCapabilities.PHANTOMJS.copy()\n        elif driver_name in ('android', 'ios', 'iphone'):\n            return {}\n        raise Exception('Unknown driver {0}'.format(driver_name))", "response": "Create initial capabilities dictionary from driver type."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_capabilities_from_properties(self, capabilities, section):\n        cap_type = {'Capabilities': 'server', 'AppiumCapabilities': 'Appium server'}\n        try:\n            for cap, cap_value in dict(self.config.items(section)).items():\n                self.logger.debug(\"Added %s capability: %s = %s\", cap_type[section], cap, cap_value)\n                capabilities[cap] = cap_value if cap == 'version' else self._convert_property_type(cap_value)\n        except NoSectionError:\n            pass", "response": "Add capabilities from properties file\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _create_firefox_profile(self):\n        # Get Firefox profile\n        profile_directory = self.config.get_optional('Firefox', 'profile')\n        if profile_directory:\n            self.logger.debug(\"Using firefox profile: %s\", profile_directory)\n\n        # Create Firefox profile\n        profile = webdriver.FirefoxProfile(profile_directory=profile_directory)\n        profile.native_events_enabled = True\n\n        # Add Firefox preferences\n        try:\n            for pref, pref_value in dict(self.config.items('FirefoxPreferences')).items():\n                self.logger.debug(\"Added firefox preference: %s = %s\", pref, pref_value)\n                profile.set_preference(pref, self._convert_property_type(pref_value))\n            profile.update_preferences()\n        except NoSectionError:\n            pass\n\n        # Add Firefox extensions\n        try:\n            for pref, pref_value in dict(self.config.items('FirefoxExtensions')).items():\n                self.logger.debug(\"Added firefox extension: %s = %s\", pref, pref_value)\n                profile.add_extension(pref_value)\n        except NoSectionError:\n            pass\n\n        return profile", "response": "Create and configure a firefox profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting the string value in a boolean integer or string", "response": "def _convert_property_type(value):\n        \"\"\"Converts the string value in a boolean, integer or string\n\n        :param value: string value\n        :returns: boolean, integer or string value\n        \"\"\"\n        if value in ('true', 'True'):\n            return True\n        elif value in ('false', 'False'):\n            return False\n        elif str(value).startswith('{') and str(value).endswith('}'):\n            return ast.literal_eval(value)\n        else:\n            try:\n                return int(value)\n            except ValueError:\n                return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate and configure a chrome options object", "response": "def _create_chrome_options(self):\n        \"\"\"Create and configure a chrome options object\n\n        :returns: chrome options object\n        \"\"\"\n        # Create Chrome options\n        options = webdriver.ChromeOptions()\n\n        if self.config.getboolean_optional('Driver', 'headless'):\n            self.logger.debug(\"Running Chrome in headless mode\")\n            options.add_argument('--headless')\n            if os.name == 'nt':  # Temporarily needed if running on Windows.\n                options.add_argument('--disable-gpu')\n\n        # Add Chrome preferences, mobile emulation options and chrome arguments\n        self._add_chrome_options(options, 'prefs')\n        self._add_chrome_options(options, 'mobileEmulation')\n        self._add_chrome_arguments(options)\n\n        return options"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd Chrome options from properties file", "response": "def _add_chrome_options(self, options, option_name):\n        \"\"\"Add Chrome options from properties file\n\n        :param options: chrome options object\n        :param option_name: chrome option name\n        \"\"\"\n        options_conf = {'prefs': {'section': 'ChromePreferences', 'message': 'preference'},\n                        'mobileEmulation': {'section': 'ChromeMobileEmulation', 'message': 'mobile emulation option'}}\n        option_value = dict()\n        try:\n            for key, value in dict(self.config.items(options_conf[option_name]['section'])).items():\n                self.logger.debug(\"Added chrome %s: %s = %s\", options_conf[option_name]['message'], key, value)\n                option_value[key] = self._convert_property_type(value)\n            if len(option_value) > 0:\n                options.add_experimental_option(option_name, option_value)\n        except NoSectionError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_chrome_arguments(self, options):\n        try:\n            for pref, pref_value in dict(self.config.items('ChromeArguments')).items():\n                pref_value = '={}'.format(pref_value) if pref_value else ''\n                self.logger.debug(\"Added chrome argument: %s%s\", pref, pref_value)\n                options.add_argument('{}{}'.format(pref, self._convert_property_type(pref_value)))\n        except NoSectionError:\n            pass", "response": "Add Chrome arguments from properties file\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setup_edge(self, capabilities):\n        edge_driver = self.config.get('Driver', 'edge_driver_path')\n        self.logger.debug(\"Edge driver path given in properties: %s\", edge_driver)\n        return webdriver.Edge(edge_driver, capabilities=capabilities)", "response": "Setup Edge webdriver\n\n        :param capabilities: capabilities object\n        :returns: a new local Edge driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _setup_appium(self):\n        self.config.set('Server', 'host', '127.0.0.1')\n        self.config.set('Server', 'port', '4723')\n        return self._create_remote_driver()", "response": "Setup Appium webdriver\n\n        :returns: a new remote Appium driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_implicitly_wait(self):\n        implicitly_wait = self.driver_wrapper.config.get_optional('Driver', 'implicitly_wait')\n        if implicitly_wait:\n            self.driver_wrapper.driver.implicitly_wait(implicitly_wait)", "response": "Read implicitly timeout from configuration properties and configure driver implicitly wait"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef capture_screenshot(self, name):\n        filename = '{0:0=2d}_{1}'.format(DriverWrappersPool.screenshots_number, name)\n        filename = '{}.png'.format(get_valid_filename(filename))\n        filepath = os.path.join(DriverWrappersPool.screenshots_directory, filename)\n        if not os.path.exists(DriverWrappersPool.screenshots_directory):\n            os.makedirs(DriverWrappersPool.screenshots_directory)\n        if self.driver_wrapper.driver.get_screenshot_as_file(filepath):\n            self.logger.info('Screenshot saved in %s', filepath)\n            DriverWrappersPool.screenshots_number += 1\n            return filepath\n        return None", "response": "Capture screenshot and save it in screenshots folder"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting webdriver logs and write them to log files = > log_types of the webdriver", "response": "def save_webdriver_logs(self, test_name):\n        \"\"\"Get webdriver logs and write them to log files\n\n        :param test_name: test that has generated these logs\n        \"\"\"\n        try:\n            log_types = self.driver_wrapper.driver.log_types\n        except Exception:\n            # geckodriver does not implement log_types, but it implements get_log for client and server\n            log_types = ['client', 'server']\n\n        self.logger.debug(\"Reading logs from '%s' and writing them to log files\", ', '.join(log_types))\n        for log_type in log_types:\n            try:\n                self.save_webdriver_logs_by_type(log_type, test_name)\n            except Exception:\n                # Capture exceptions to avoid errors in teardown method\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef save_webdriver_logs_by_type(self, log_type, test_name):\n        try:\n            logs = self.driver_wrapper.driver.get_log(log_type)\n        except Exception:\n            return\n\n        if len(logs) > 0:\n            log_file_name = '{}_{}.txt'.format(get_valid_filename(test_name), log_type)\n            log_file_name = os.path.join(DriverWrappersPool.logs_directory, log_file_name)\n            with open(log_file_name, 'a+', encoding='utf-8') as log_file:\n                driver_type = self.driver_wrapper.config.get('Driver', 'type')\n                log_file.write(\n                    u\"\\n{} '{}' test logs with driver = {}\\n\\n\".format(datetime.now(), test_name, driver_type))\n                for entry in logs:\n                    timestamp = datetime.fromtimestamp(float(entry['timestamp']) / 1000.).strftime(\n                        '%Y-%m-%d %H:%M:%S.%f')\n                    log_file.write(u'{}\\t{}\\t{}\\n'.format(timestamp, entry['level'], entry['message'].rstrip()))", "response": "Save webdriver logs of the specified type to a log file."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndiscard previous logcat logs", "response": "def discard_logcat_logs(self):\n        \"\"\"Discard previous logcat logs\"\"\"\n        if self.driver_wrapper.is_android_test():\n            try:\n                self.driver_wrapper.driver.get_log('logcat')\n            except Exception:\n                pass"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to find the element but does not thrown an exception if the element is not found", "response": "def _expected_condition_find_element(self, element):\n        \"\"\"Tries to find the element, but does not thrown an exception if the element is not found\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :returns: the web element if it has been found or False\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        \"\"\"\n        from toolium.pageelements.page_element import PageElement\n        web_element = False\n        try:\n            if isinstance(element, PageElement):\n                # Use _find_web_element() instead of web_element to avoid logging error message\n                element._web_element = None\n                element._find_web_element()\n                web_element = element._web_element\n            elif isinstance(element, tuple):\n                web_element = self.driver_wrapper.driver.find_element(*element)\n        except NoSuchElementException:\n            pass\n        return web_element"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ntry to find the element and checks that it is visible but does not thrown an exception if the element is not visible or False otherwise.", "response": "def _expected_condition_find_element_visible(self, element):\n        \"\"\"Tries to find the element and checks that it is visible, but does not thrown an exception if the element is\n            not found\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :returns: the web element if it is visible or False\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        \"\"\"\n        web_element = self._expected_condition_find_element(element)\n        try:\n            return web_element if web_element and web_element.is_displayed() else False\n        except StaleElementReferenceException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntrying to find the element and checks that it is not visible but does not thrown an exception if the element is not found or is not visible", "response": "def _expected_condition_find_element_not_visible(self, element):\n        \"\"\"Tries to find the element and checks that it is visible, but does not thrown an exception if the element is\n            not found\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :returns: True if the web element is not found or it is not visible\n        \"\"\"\n        web_element = self._expected_condition_find_element(element)\n        try:\n            return True if not web_element or not web_element.is_displayed() else False\n        except StaleElementReferenceException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ntries to find sequentially the elements of the list and return the first element found or None", "response": "def _expected_condition_find_first_element(self, elements):\n        \"\"\"Try to find sequentially the elements of the list and return the first element found\n\n        :param elements: list of PageElements or element locators as a tuple (locator_type, locator_value) to be found\n                         sequentially\n        :returns: first element found or None\n        :rtype: toolium.pageelements.PageElement or tuple\n        \"\"\"\n        from toolium.pageelements.page_element import PageElement\n        element_found = None\n        for element in elements:\n            try:\n                if isinstance(element, PageElement):\n                    element._web_element = None\n                    element._find_web_element()\n                else:\n                    self.driver_wrapper.driver.find_element(*element)\n                element_found = element\n                break\n            except (NoSuchElementException, TypeError):\n                pass\n        return element_found"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntrying to find the element and checks that it is clickable but does not thrown an exception if the element is not found", "response": "def _expected_condition_find_element_clickable(self, element):\n        \"\"\"Tries to find the element and checks that it is clickable, but does not thrown an exception if the element\n            is not found\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :returns: the web element if it is clickable or False\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        \"\"\"\n        web_element = self._expected_condition_find_element_visible(element)\n        try:\n            return web_element if web_element and web_element.is_enabled() else False\n        except StaleElementReferenceException:\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _expected_condition_find_element_stopped(self, element_times):\n        element, times = element_times\n        web_element = self._expected_condition_find_element(element)\n        try:\n            locations_list = [tuple(web_element.location.values()) for i in range(int(times)) if not time.sleep(0.001)]\n            return web_element if set(locations_list) == set(locations_list[-1:]) else False\n        except StaleElementReferenceException:\n            return False", "response": "Tries to find the element and checks that it has stopped moving and does not thrown an exception if it is not clickable or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _expected_condition_find_element_containing_text(self, element_text_pair):\n        element, text = element_text_pair\n        web_element = self._expected_condition_find_element(element)\n        try:\n            return web_element if web_element and text in web_element.text else False\n        except StaleElementReferenceException:\n            return False", "response": "Tries to find the element and checks that it contains the specified text and returns the element if it contains the specified text or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _expected_condition_value_in_element_attribute(self, element_attribute_value):\n        element, attribute, value = element_attribute_value\n        web_element = self._expected_condition_find_element(element)\n        try:\n            return web_element if web_element and web_element.get_attribute(attribute) == value else False\n        except StaleElementReferenceException:\n            return False", "response": "Tries to find the element and checks that it contains the requested attribute with the expected value and returns the element if it contains the expected value or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _wait_until(self, condition_method, condition_input, timeout=None):\n        # Remove implicitly wait timeout\n        self.driver_wrapper.driver.implicitly_wait(0)\n        # Get explicitly wait timeout\n        timeout = timeout if timeout else self.get_explicitly_wait()\n        # Wait for condition\n        condition_response = WebDriverWait(self.driver_wrapper.driver, timeout).until(\n            lambda s: condition_method(condition_input))\n        # Restore implicitly wait timeout from properties\n        self.set_implicitly_wait()\n        return condition_response", "response": "Common method to wait until condition met\n        is met"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef wait_until_element_present(self, element, timeout=None):\n        return self._wait_until(self._expected_condition_find_element, element, timeout)", "response": "Search element and wait until it is present"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef wait_until_element_visible(self, element, timeout=None):\n        return self._wait_until(self._expected_condition_find_element_visible, element, timeout)", "response": "Search element and wait until it is visible"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsearch element and wait until it is not visible", "response": "def wait_until_element_not_visible(self, element, timeout=None):\n        \"\"\"Search element and wait until it is not visible\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :param timeout: max time to wait\n        :returns: the web element if it exists but is not visible\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        :raises TimeoutException: If the element is still visible after the timeout\n        \"\"\"\n        return self._wait_until(self._expected_condition_find_element_not_visible, element, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsearching list of elements and wait until one of them is found", "response": "def wait_until_first_element_is_found(self, elements, timeout=None):\n        \"\"\"Search list of elements and wait until one of them is found\n\n        :param elements: list of PageElements or element locators as a tuple (locator_type, locator_value) to be found\n                         sequentially\n        :param timeout: max time to wait\n        :returns: first element found\n        :rtype: toolium.pageelements.PageElement or tuple\n        :raises TimeoutException: If no element in the list is found after the timeout\n        \"\"\"\n        try:\n            return self._wait_until(self._expected_condition_find_first_element, elements, timeout)\n        except TimeoutException as exception:\n            msg = 'None of the page elements has been found after %s seconds'\n            timeout = timeout if timeout else self.get_explicitly_wait()\n            self.logger.error(msg, timeout)\n            exception.msg += \"\\n  {}\".format(msg % timeout)\n            raise exception"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nsearch element and wait until it is clickable", "response": "def wait_until_element_clickable(self, element, timeout=None):\n        \"\"\"Search element and wait until it is clickable\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :param timeout: max time to wait\n        :returns: the web element if it is clickable\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        :raises TimeoutException: If the element is not clickable after the timeout\n        \"\"\"\n        return self._wait_until(self._expected_condition_find_element_clickable, element, timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_until_element_stops(self, element, times=1000, timeout=None):\n        return self._wait_until(self._expected_condition_find_element_stopped, (element, times), timeout)", "response": "Search element and wait until it has stopped"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nsearches element and wait until it contains the expected text", "response": "def wait_until_element_contains_text(self, element, text, timeout=None):\n        \"\"\"Search element and wait until it contains the expected text\n\n        :param element: PageElement or element locator as a tuple (locator_type, locator_value) to be found\n        :param text: text expected to be contained into the element\n        :param timeout: max time to wait\n        :returns: the web element if it contains the expected text\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        :raises TimeoutException: If the element does not contain the expected text after the timeout\n        \"\"\"\n        return self._wait_until(self._expected_condition_find_element_containing_text, (element, text), timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_until_element_not_contain_text(self, element, text, timeout=None):\n        return self._wait_until(self._expected_condition_find_element_not_containing_text, (element, text), timeout)", "response": "Search element and wait until the element contains the expected text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef wait_until_element_attribute_is(self, element, attribute, value, timeout=None):\n        return self._wait_until(self._expected_condition_value_in_element_attribute, (element, attribute, value), timeout)", "response": "Search element and wait until the requested attribute contains the expected value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the remote node that it s executing the actual test session", "response": "def get_remote_node(self):\n        \"\"\"Return the remote node that it's executing the actual test session\n\n        :returns: tuple with server type (local, grid, ggr, selenium) and remote node name\n        \"\"\"\n        logging.getLogger(\"requests\").setLevel(logging.WARNING)\n        remote_node = None\n        server_type = 'local'\n        if self.driver_wrapper.config.getboolean_optional('Server', 'enabled'):\n            # Request session info from grid hub\n            session_id = self.driver_wrapper.driver.session_id\n            self.logger.debug(\"Trying to identify remote node\")\n            try:\n                # Request session info from grid hub and extract remote node\n                url = '{}/grid/api/testsession?session={}'.format(self.get_server_url(),\n                                                                  session_id)\n                proxy_id = requests.get(url).json()['proxyId']\n                remote_node = urlparse(proxy_id).hostname if urlparse(proxy_id).hostname else proxy_id\n                server_type = 'grid'\n                self.logger.debug(\"Test running in remote node %s\", remote_node)\n            except (ValueError, KeyError):\n                try:\n                    # Request session info from GGR and extract remote node\n                    from toolium.selenoid import Selenoid\n                    remote_node = Selenoid(self.driver_wrapper).get_selenoid_info()['Name']\n                    server_type = 'ggr'\n                    self.logger.debug(\"Test running in a GGR remote node %s\", remote_node)\n                except Exception:\n                    try:\n                        # The remote node is a Selenoid node\n                        url = '{}/status'.format(self.get_server_url())\n                        requests.get(url).json()['total']\n                        remote_node = self.driver_wrapper.config.get('Server', 'host')\n                        server_type = 'selenoid'\n                        self.logger.debug(\"Test running in a Selenoid node %s\", remote_node)\n                    except Exception:\n                        # The remote node is not a grid node or the session has been closed\n                        remote_node = self.driver_wrapper.config.get('Server', 'host')\n                        server_type = 'selenium'\n                        self.logger.debug(\"Test running in a Selenium node %s\", remote_node)\n\n        return server_type, remote_node"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the configured server url", "response": "def get_server_url(self):\n        \"\"\"Return the configured server url\n\n        :returns: server url\n        \"\"\"\n        server_host = self.driver_wrapper.config.get('Server', 'host')\n        server_port = self.driver_wrapper.config.get('Server', 'port')\n        server_username = self.driver_wrapper.config.get_optional('Server', 'username')\n        server_password = self.driver_wrapper.config.get_optional('Server', 'password')\n        server_auth = '{}:{}@'.format(server_username, server_password) if server_username and server_password else ''\n        server_url = 'http://{}{}:{}'.format(server_auth, server_host, server_port)\n        return server_url"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndownload the video recorded in the remote node during the specified test session and save it in videos folder .", "response": "def download_remote_video(self, remote_node, session_id, video_name):\n        \"\"\"Download the video recorded in the remote node during the specified test session and save it in videos folder\n\n        :param remote_node: remote node name\n        :param session_id: test session id\n        :param video_name: video name\n        \"\"\"\n        try:\n            video_url = self._get_remote_video_url(remote_node, session_id)\n        except requests.exceptions.ConnectionError:\n            self.logger.warning(\"Remote server seems not to have video capabilities\")\n            return\n\n        if not video_url:\n            self.logger.warning(\"Test video not found in node '%s'\", remote_node)\n            return\n\n        self._download_video(video_url, video_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_remote_node_url(self, remote_node):\n        logging.getLogger(\"requests\").setLevel(logging.WARNING)\n        gridextras_port = 3000\n        return 'http://{}:{}'.format(remote_node, gridextras_port)", "response": "Get the grid - extras url of a node"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget remote video url to download videos from", "response": "def _get_remote_video_url(self, remote_node, session_id):\n        \"\"\"Get grid-extras url to download videos\n\n        :param remote_node: remote node name\n        :param session_id: test session id\n        :returns: grid-extras url to download videos\n        \"\"\"\n        url = '{}/video'.format(self._get_remote_node_url(remote_node))\n        timeout = time.time() + 5  # 5 seconds from now\n\n        # Requests videos list until timeout or the video url is found\n        video_url = None\n        while time.time() < timeout:\n            response = requests.get(url).json()\n            try:\n                video_url = response['available_videos'][session_id]['download_url']\n                break\n            except KeyError:\n                time.sleep(1)\n        return video_url"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndownloading a video from the remote node", "response": "def _download_video(self, video_url, video_name):\n        \"\"\"Download a video from the remote node\n\n        :param video_url: video url\n        :param video_name: video name\n        \"\"\"\n        filename = '{0:0=2d}_{1}'.format(DriverWrappersPool.videos_number, video_name)\n        filename = '{}.mp4'.format(get_valid_filename(filename))\n        filepath = os.path.join(DriverWrappersPool.videos_directory, filename)\n        if not os.path.exists(DriverWrappersPool.videos_directory):\n            os.makedirs(DriverWrappersPool.videos_directory)\n        response = requests.get(video_url)\n        open(filepath, 'wb').write(response.content)\n        self.logger.info(\"Video saved in '%s'\", filepath)\n        DriverWrappersPool.videos_number += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchecks if the remote node has the video recorder enabled", "response": "def is_remote_video_enabled(self, remote_node):\n        \"\"\"Check if the remote node has the video recorder enabled\n\n        :param remote_node: remote node name\n        :returns: true if it has the video recorder enabled\n        \"\"\"\n        enabled = False\n        if remote_node:\n            url = '{}/config'.format(self._get_remote_node_url(remote_node))\n            try:\n                response = requests.get(url, timeout=5).json()\n                record_videos = response['config_runtime']['theConfigMap']['video_recording_options'][\n                    'record_test_videos']\n            except (requests.exceptions.ConnectionError, requests.exceptions.ReadTimeout, KeyError):\n                record_videos = 'false'\n            if record_videos == 'true':\n                # Wait to the video recorder start\n                time.sleep(1)\n                enabled = True\n        return enabled"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets center coordinates of an element", "response": "def get_center(self, element):\n        \"\"\"Get center coordinates of an element\n\n        :param element: either a WebElement, PageElement or element locator as a tuple (locator_type, locator_value)\n        :returns: dict with center coordinates\n        \"\"\"\n        web_element = self.get_web_element(element)\n        location = web_element.location\n        size = web_element.size\n        return {'x': location['x'] + (size['width'] / 2), 'y': location['y'] + (size['height'] / 2)}"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the height of Safari navigation bar.", "response": "def get_safari_navigation_bar_height(self):\n        \"\"\"Get the height of Safari navigation bar\n\n        :returns: height of navigation bar\n        \"\"\"\n        status_bar_height = 0\n        if self.driver_wrapper.is_ios_test() and self.driver_wrapper.is_web_test():\n            # ios 7.1, 8.3\n            status_bar_height = 64\n        return status_bar_height"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_window_size(self):\n        if not self._window_size:\n            if self.driver_wrapper.is_android_web_test() and self.driver_wrapper.driver.current_context != 'NATIVE_APP':\n                window_width = self.driver_wrapper.driver.execute_script(\"return window.innerWidth\")\n                window_height = self.driver_wrapper.driver.execute_script(\"return window.innerHeight\")\n                self._window_size = {'width': window_width, 'height': window_height}\n            else:\n                self._window_size = self.driver_wrapper.driver.get_window_size()\n        return self._window_size", "response": "Generic method to get window size using a javascript workaround for Android web tests"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconverts web coords into native coords.", "response": "def get_native_coords(self, coords):\n        \"\"\"Convert web coords into native coords. Assumes that the initial context is WEBVIEW and switches to\n         NATIVE_APP context.\n\n        :param coords: dict with web coords, e.g. {'x': 10, 'y': 10}\n        :returns: dict with native coords\n        \"\"\"\n        web_window_size = self.get_window_size()\n        self.driver_wrapper.driver.switch_to.context('NATIVE_APP')\n        native_window_size = self.driver_wrapper.driver.get_window_size()\n        scale = native_window_size['width'] / web_window_size['width']\n        offset_y = self.get_safari_navigation_bar_height()\n        native_coords = {'x': coords['x'] * scale, 'y': coords['y'] * scale + offset_y}\n        self.logger.debug('Converted web coords %s into native coords %s', coords, native_coords)\n        return native_coords"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nswipes over an element", "response": "def swipe(self, element, x, y, duration=None):\n        \"\"\"Swipe over an element\n\n        :param element: either a WebElement, PageElement or element locator as a tuple (locator_type, locator_value)\n        :param x: horizontal movement\n        :param y: vertical movement\n        :param duration: time to take the swipe, in ms\n        \"\"\"\n        if not self.driver_wrapper.is_mobile_test():\n            raise Exception('Swipe method is not implemented in Selenium')\n\n        # Get center coordinates of element\n        center = self.get_center(element)\n        initial_context = self.driver_wrapper.driver.current_context\n        if self.driver_wrapper.is_web_test() or initial_context != 'NATIVE_APP':\n            center = self.get_native_coords(center)\n\n        # Android needs absolute end coordinates and ios needs movement\n        end_x = x if self.driver_wrapper.is_ios_test() else center['x'] + x\n        end_y = y if self.driver_wrapper.is_ios_test() else center['y'] + y\n        self.driver_wrapper.driver.swipe(center['x'], center['y'], end_x, end_y, duration)\n\n        if self.driver_wrapper.is_web_test() or initial_context != 'NATIVE_APP':\n            self.driver_wrapper.driver.switch_to.context(initial_context)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_web_element(self, element):\n        from toolium.pageelements.page_element import PageElement\n        if isinstance(element, WebElement):\n            web_element = element\n        elif isinstance(element, PageElement):\n            web_element = element.web_element\n        elif isinstance(element, tuple):\n            web_element = self.driver_wrapper.driver.find_element(*element)\n        else:\n            web_element = None\n        return web_element", "response": "Return the web element from a page element or its locator as a tuple"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns the first WEBVIEW context or raise an exception", "response": "def get_first_webview_context(self):\n        \"\"\"Return the first WEBVIEW context or raise an exception if it is not found\n\n        :returns: first WEBVIEW context\n        \"\"\"\n        for context in self.driver_wrapper.driver.contexts:\n            if context.startswith('WEBVIEW'):\n                return context\n        raise Exception('No WEBVIEW context has been found')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the default driver wrapper for the given class", "response": "def get_default_wrapper(cls):\n        \"\"\"Returns the default (first) driver wrapper\n\n        :returns: default driver wrapper\n        :rtype: toolium.driver_wrapper.DriverWrapper\n        \"\"\"\n        if cls.is_empty():\n            # Create a new driver wrapper if the pool is empty\n            from toolium.driver_wrapper import DriverWrapper\n            DriverWrapper()\n        return cls.driver_wrappers[0]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef capture_screenshots(cls, name):\n        screenshot_name = '{}_driver{}' if len(cls.driver_wrappers) > 1 else '{}'\n        driver_index = 1\n        for driver_wrapper in cls.driver_wrappers:\n            if not driver_wrapper.driver:\n                continue\n            from toolium.jira import add_attachment\n            try:\n                add_attachment(driver_wrapper.utils.capture_screenshot(screenshot_name.format(name, driver_index)))\n            except Exception:\n                # Capture exceptions to avoid errors in teardown method due to session timeouts\n                pass\n            driver_index += 1", "response": "Capture a screenshot in each driver in each driver"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_default_driver_wrapper(cls, config_files=None):\n        driver_wrapper = cls.get_default_wrapper()\n        if not driver_wrapper.driver:\n            config_files = DriverWrappersPool.initialize_config_files(config_files)\n            driver_wrapper.configure(config_files)\n            driver_wrapper.connect()\n        return driver_wrapper", "response": "Get default driver wrapper configure it and connect it"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef close_drivers(cls, scope, test_name, test_passed=True, context=None):\n        if scope == 'function':\n            # Capture screenshot on error\n            if not test_passed:\n                cls.capture_screenshots(test_name)\n            # Execute behave dynamic environment\n            if context and hasattr(context, 'dyn_env'):\n                context.dyn_env.execute_after_scenario_steps(context)\n            # Save webdriver logs on error or if it is enabled\n            cls.save_all_webdriver_logs(test_name, test_passed)\n\n        # Close browser and stop driver if it must not be reused\n        reuse_driver = cls.get_default_wrapper().should_reuse_driver(scope, test_passed, context)\n        cls.stop_drivers(reuse_driver)\n        cls.download_videos(test_name, test_passed, reuse_driver)\n        cls.save_all_ggr_logs(test_name, test_passed)\n        cls.remove_drivers(reuse_driver)", "response": "Close all drivers capture screenshots copy webdriver and GGR logs and download saved videos if it is not reused."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef stop_drivers(cls, maintain_default=False):\n        # Exclude first wrapper if the driver must be reused\n        driver_wrappers = cls.driver_wrappers[1:] if maintain_default else cls.driver_wrappers\n\n        for driver_wrapper in driver_wrappers:\n            if not driver_wrapper.driver:\n                continue\n            try:\n                driver_wrapper.driver.quit()\n            except Exception as e:\n                driver_wrapper.logger.warn(\n                    \"Capture exceptions to avoid errors in teardown method due to session timeouts: \\n %s\" % e)", "response": "Stop all drivers except default if it should not be closed\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndownloads saved videos if video is enabled or test fails", "response": "def download_videos(cls, name, test_passed=True, maintain_default=False):\n        \"\"\"Download saved videos if video is enabled or if test fails\n\n        :param name: destination file name\n        :param test_passed: True if the test has passed\n        :param maintain_default: True if the default driver should not be closed\n        \"\"\"\n        # Exclude first wrapper if the driver must be reused\n        driver_wrappers = cls.driver_wrappers[1:] if maintain_default else cls.driver_wrappers\n        video_name = '{}_driver{}' if len(driver_wrappers) > 1 else '{}'\n        video_name = video_name if test_passed else 'error_{}'.format(video_name)\n        driver_index = 1\n\n        for driver_wrapper in driver_wrappers:\n            if not driver_wrapper.driver:\n                continue\n            try:\n                # Download video if necessary (error case or enabled video)\n                if (not test_passed or driver_wrapper.config.getboolean_optional('Server', 'video_enabled', False)) \\\n                        and driver_wrapper.remote_node_video_enabled:\n                    if driver_wrapper.server_type in ['ggr', 'selenoid']:\n                        name = get_valid_filename(video_name.format(name, driver_index))\n                        Selenoid(driver_wrapper).download_session_video(name)\n                    elif driver_wrapper.server_type == 'grid':\n                        # Download video from Grid Extras\n                        driver_wrapper.utils.download_remote_video(driver_wrapper.remote_node,\n                                                                   driver_wrapper.session_id,\n                                                                   video_name.format(name, driver_index))\n            except Exception as exc:\n                # Capture exceptions to avoid errors in teardown method due to session timeouts\n                driver_wrapper.logger.warn('Error downloading videos: %s' % exc)\n            driver_index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsave all webdriver logs of each driver and write them to log files", "response": "def save_all_webdriver_logs(cls, test_name, test_passed):\n        \"\"\"Get all webdriver logs of each driver and write them to log files\n\n        :param test_name: test that has generated these logs\n        :param test_passed: True if the test has passed\n        \"\"\"\n        log_name = '{} [driver {}]' if len(cls.driver_wrappers) > 1 else '{}'\n        driver_index = 1\n        for driver_wrapper in cls.driver_wrappers:\n            if not driver_wrapper.driver or driver_wrapper.server_type in ['ggr', 'selenoid']:\n                continue\n            if driver_wrapper.config.getboolean_optional('Server', 'logs_enabled') or not test_passed:\n                try:\n                    driver_wrapper.utils.save_webdriver_logs(log_name.format(test_name, driver_index))\n                except Exception as exc:\n                    # Capture exceptions to avoid errors in teardown method due to session timeouts\n                    driver_wrapper.logger.warn('Error downloading webdriver logs: %s' % exc)\n            driver_index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget all GGR logs of each driver and write them to log files", "response": "def save_all_ggr_logs(cls, test_name, test_passed):\n        \"\"\"Get all GGR logs of each driver and write them to log files\n\n        :param test_name: test that has generated these logs\n        :param test_passed: True if the test has passed\n        \"\"\"\n        log_name = '{} [driver {}]' if len(cls.driver_wrappers) > 1 else '{}'\n        driver_index = 1\n        for driver_wrapper in cls.driver_wrappers:\n            if not driver_wrapper.driver or driver_wrapper.server_type not in ['ggr', 'selenoid']:\n                continue\n            try:\n                if driver_wrapper.config.getboolean_optional('Server', 'logs_enabled') or not test_passed:\n                    name = get_valid_filename(log_name.format(test_name, driver_index))\n                    Selenoid(driver_wrapper).download_session_log(name)\n            except Exception as exc:\n                # Capture exceptions to avoid errors in teardown method due to session timeouts\n                driver_wrapper.logger.warn('Error downloading GGR logs: %s' % exc)\n            driver_index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the configured value from system properties method parameters or default value.", "response": "def get_configured_value(system_property_name, specific_value, default_value):\n        \"\"\"Get configured value from system properties, method parameters or default value\n\n        :param system_property_name: system property name\n        :param specific_value: test case specific value\n        :param default_value: default value\n        :returns: configured value\n        \"\"\"\n        try:\n            return os.environ[system_property_name]\n        except KeyError:\n            return specific_value if specific_value else default_value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring common config and output folders for all tests .", "response": "def configure_common_directories(cls, tc_config_files):\n        \"\"\"Configure common config and output folders for all tests\n\n        :param tc_config_files: test case specific config files\n        \"\"\"\n        if cls.config_directory is None:\n            # Get config directory from properties\n            config_directory = cls.get_configured_value('Config_directory', tc_config_files.config_directory, 'conf')\n            prop_filenames = cls.get_configured_value('Config_prop_filenames',\n                                                      tc_config_files.config_properties_filenames, 'properties.cfg')\n            cls.config_directory = cls._find_parent_directory(config_directory, prop_filenames.split(';')[0])\n\n            # Get output directory from properties and create it\n            cls.output_directory = cls.get_configured_value('Output_directory', tc_config_files.output_directory,\n                                                            'output')\n            if not os.path.isabs(cls.output_directory):\n                # If output directory is relative, we use the same path as config directory\n                cls.output_directory = os.path.join(os.path.dirname(cls.config_directory), cls.output_directory)\n            if not os.path.exists(cls.output_directory):\n                os.makedirs(cls.output_directory)\n\n            # Get visual baseline directory from properties\n            default_baseline = os.path.join(cls.output_directory, 'visualtests', 'baseline')\n            cls.visual_baseline_directory = cls.get_configured_value('Visual_baseline_directory',\n                                                                     tc_config_files.visual_baseline_directory,\n                                                                     default_baseline)\n            if not os.path.isabs(cls.visual_baseline_directory):\n                # If baseline directory is relative, we use the same path as config directory\n                cls.visual_baseline_directory = os.path.join(os.path.dirname(cls.config_directory),\n                                                             cls.visual_baseline_directory)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn default config directory based in the actual test path", "response": "def get_default_config_directory():\n        \"\"\"Return default config directory, based in the actual test path\n\n        :returns: default config directory\n        \"\"\"\n        test_path = os.path.dirname(os.path.realpath(inspect.getouterframes(inspect.currentframe())[2][1]))\n        return os.path.join(test_path, 'conf')"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nfinding a directory in parent tree with a specific filename", "response": "def _find_parent_directory(directory, filename):\n        \"\"\"Find a directory in parent tree with a specific filename\n\n        :param directory: directory name to find\n        :param filename: filename to find\n        :returns: absolute directory path\n        \"\"\"\n        parent_directory = directory\n        absolute_directory = '.'\n        while absolute_directory != os.path.abspath(parent_directory):\n            absolute_directory = os.path.abspath(parent_directory)\n            if os.path.isfile(os.path.join(absolute_directory, filename)):\n                return absolute_directory\n            if os.path.isabs(parent_directory):\n                parent_directory = os.path.join(os.path.dirname(parent_directory), '..',\n                                                os.path.basename(parent_directory))\n            else:\n                parent_directory = os.path.join('..', parent_directory)\n        return os.path.abspath(directory)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure screenshots videos and visual directories.", "response": "def configure_visual_directories(cls, driver_info):\n        \"\"\"Configure screenshots, videos and visual directories\n\n        :param driver_info: driver property value to name folders\n        \"\"\"\n        if cls.screenshots_directory is None:\n            # Unique screenshots and videos directories\n            date = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n            folder_name = '%s_%s' % (date, driver_info) if driver_info else date\n            folder_name = get_valid_filename(folder_name)\n            cls.screenshots_directory = os.path.join(cls.output_directory, 'screenshots', folder_name)\n            cls.screenshots_number = 1\n            cls.videos_directory = os.path.join(cls.output_directory, 'videos', folder_name)\n            cls.logs_directory = os.path.join(cls.output_directory, 'logs', folder_name)\n            cls.videos_number = 1\n\n            # Unique visualtests directories\n            cls.visual_output_directory = os.path.join(cls.output_directory, 'visualtests', folder_name)\n            cls.visual_number = 1"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninitialize config files and update properties and log files names with the environment", "response": "def initialize_config_files(tc_config_files=None):\n        \"\"\"Initialize config files and update config files names with the environment\n\n        :param tc_config_files: test case specific config files\n        :returns: initialized config files object\n        \"\"\"\n        # Initialize config files\n        if tc_config_files is None:\n            tc_config_files = ConfigFiles()\n\n        # Update properties and log file names if an environment is configured\n        env = DriverWrappersPool.get_configured_value('Config_environment', None, None)\n        if env:\n            # Update config properties filenames\n            prop_filenames = tc_config_files.config_properties_filenames\n            new_prop_filenames_list = prop_filenames.split(';') if prop_filenames else ['properties.cfg']\n            base, ext = os.path.splitext(new_prop_filenames_list[0])\n            new_prop_filenames_list.append('{}-{}{}'.format(env, base, ext))\n            new_prop_filenames_list.append('local-{}-{}{}'.format(env, base, ext))\n            tc_config_files.set_config_properties_filenames(*new_prop_filenames_list)\n\n            # Update output log filename\n            output_log_filename = tc_config_files.output_log_filename\n            base, ext = os.path.splitext(output_log_filename) if output_log_filename else ('toolium', '.log')\n            tc_config_files.set_output_log_filename('{}_{}{}'.format(base, env, ext))\n\n        return tc_config_files"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef before_feature(context, feature):\n    context.global_status = {'test_passed': True}\n\n    # Read @no_driver tag\n    no_driver = 'no_driver' in feature.tags\n\n    # Start driver if it should be reused in feature\n    context.reuse_driver_from_tags = 'reuse_driver' in feature.tags\n    if context.toolium_config.getboolean_optional('Driver', 'reuse_driver') or context.reuse_driver_from_tags:\n        start_driver(context, no_driver)\n\n    # Behave dynamic environment\n    context.dyn_env.get_steps_from_feature_description(feature.description)\n    context.dyn_env.execute_before_feature_steps(context)", "response": "Execute before feature initialization"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nruns the before scenario steps.", "response": "def before_scenario(context, scenario):\n    \"\"\"Scenario initialization\n\n    :param context: behave context\n    :param scenario: running scenario\n    \"\"\"\n    # Configure reset properties from behave tags\n    if 'no_reset_app' in scenario.tags:\n        os.environ[\"AppiumCapabilities_noReset\"] = 'true'\n        os.environ[\"AppiumCapabilities_fullReset\"] = 'false'\n    elif 'reset_app' in scenario.tags:\n        os.environ[\"AppiumCapabilities_noReset\"] = 'false'\n        os.environ[\"AppiumCapabilities_fullReset\"] = 'false'\n    elif 'full_reset_app' in scenario.tags:\n        os.environ[\"AppiumCapabilities_noReset\"] = 'false'\n        os.environ[\"AppiumCapabilities_fullReset\"] = 'true'\n\n    # Force to reset driver before each scenario if it has @reset_driver tag\n    if 'reset_driver' in scenario.tags:\n        DriverWrappersPool.stop_drivers()\n        DriverWrappersPool.download_videos('multiple tests', context.global_status['test_passed'])\n        DriverWrappersPool.save_all_ggr_logs('multiple tests', context.global_status['test_passed'])\n        DriverWrappersPool.remove_drivers()\n        context.global_status['test_passed'] = True\n\n    # Skip android_only or ios_only scenarios\n    if 'android_only' in scenario.tags and context.driver_wrapper.is_ios_test():\n        scenario.skip('Android scenario')\n        return\n    elif 'ios_only' in scenario.tags and context.driver_wrapper.is_android_test():\n        scenario.skip('iOS scenario')\n        return\n\n    # Read @no_driver tag\n    no_driver = 'no_driver' in scenario.tags or 'no_driver' in scenario.feature.tags\n\n    bdd_common_before_scenario(context, scenario, no_driver)\n\n    # Behave dynamic environment\n    context.dyn_env.execute_before_scenario_steps(context)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bdd_common_before_scenario(context_or_world, scenario, no_driver=False):\n    # Initialize and connect driver wrapper\n    start_driver(context_or_world, no_driver)\n\n    # Add assert screenshot methods with scenario configuration\n    add_assert_screenshot_methods(context_or_world, scenario)\n\n    # Configure Jira properties\n    save_jira_conf()\n\n    context_or_world.logger.info(\"Running new scenario: %s\", scenario.name)", "response": "Common scenario initialization in behave or lettuce."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef create_and_configure_wrapper(context_or_world):\n    # Create default driver wrapper\n    context_or_world.driver_wrapper = DriverWrappersPool.get_default_wrapper()\n    context_or_world.utils = context_or_world.driver_wrapper.utils\n\n    # Get behave userdata properties to override config properties\n    try:\n        behave_properties = context_or_world.config.userdata\n    except AttributeError:\n        behave_properties = None\n\n    # Configure wrapper\n    context_or_world.driver_wrapper.configure(context_or_world.config_files, behave_properties=behave_properties)\n\n    # Copy config object\n    context_or_world.toolium_config = context_or_world.driver_wrapper.config\n\n    # Configure logger\n    context_or_world.logger = logging.getLogger(__name__)", "response": "Create and configure driver wrapper in behave or lettuce tests\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef connect_wrapper(context_or_world):\n    # Create driver if it is not already created\n    if context_or_world.driver_wrapper.driver:\n        context_or_world.driver = context_or_world.driver_wrapper.driver\n    else:\n        context_or_world.driver = context_or_world.driver_wrapper.connect()\n\n    # Copy app_strings object\n    context_or_world.app_strings = context_or_world.driver_wrapper.app_strings", "response": "Connect driver in behave or lettuce tests"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_assert_screenshot_methods(context_or_world, scenario):\n    file_suffix = scenario.name\n\n    def assert_screenshot(element_or_selector, filename, threshold=0, exclude_elements=[], driver_wrapper=None,\n                          force=False):\n        VisualTest(driver_wrapper, force).assert_screenshot(element_or_selector, filename, file_suffix, threshold,\n                                                            exclude_elements)\n\n    def assert_full_screenshot(filename, threshold=0, exclude_elements=[], driver_wrapper=None, force=False):\n        VisualTest(driver_wrapper, force).assert_screenshot(None, filename, file_suffix, threshold, exclude_elements)\n\n    # Monkey patching assert_screenshot method in PageElement to use the correct test name\n    def assert_screenshot_page_element(self, filename, threshold=0, exclude_elements=[], force=False):\n        VisualTest(self.driver_wrapper, force).assert_screenshot(self.web_element, filename, file_suffix, threshold,\n                                                                 exclude_elements)\n\n    context_or_world.assert_screenshot = assert_screenshot\n    context_or_world.assert_full_screenshot = assert_full_screenshot\n    PageElement.assert_screenshot = assert_screenshot_page_element", "response": "Add assert screenshot methods to behave or lettuce object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncleaning method that will be executed after each scenario in behave or lettuce.", "response": "def bdd_common_after_scenario(context_or_world, scenario, status):\n    \"\"\"Clean method that will be executed after each scenario in behave or lettuce\n\n    :param context_or_world: behave context or lettuce world\n    :param scenario: running scenario\n    :param status: scenario status (passed, failed or skipped)\n    \"\"\"\n    if status == 'skipped':\n        return\n    elif status == 'passed':\n        test_status = 'Pass'\n        test_comment = None\n        context_or_world.logger.info(\"The scenario '%s' has passed\", scenario.name)\n    else:\n        test_status = 'Fail'\n        test_comment = \"The scenario '%s' has failed\" % scenario.name\n        context_or_world.logger.error(\"The scenario '%s' has failed\", scenario.name)\n        context_or_world.global_status['test_passed'] = False\n\n    # Close drivers\n    DriverWrappersPool.close_drivers(scope='function', test_name=scenario.name, test_passed=status == 'passed',\n                                     context=context_or_world)\n\n    # Save test status to be updated later\n    add_jira_status(get_jira_key_from_scenario(scenario), test_status, test_comment)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nextracts Jira Test Case key from scenario tags.", "response": "def get_jira_key_from_scenario(scenario):\n    \"\"\"Extract Jira Test Case key from scenario tags.\n    Two tag formats are allowed:\n    @jira('PROJECT-32')\n    @jira=PROJECT-32\n\n    :param scenario: behave scenario\n    :returns: Jira test case key\n    \"\"\"\n    jira_regex = re.compile('jira[=\\(\\']*([A-Z]+\\-[0-9]+)[\\'\\)]*$')\n    for tag in scenario.tags:\n        match = jira_regex.search(tag)\n        if match:\n            return match.group(1)\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef after_feature(context, feature):\n    # Behave dynamic environment\n    context.dyn_env.execute_after_feature_steps(context)\n\n    # Close drivers\n    DriverWrappersPool.close_drivers(scope='module', test_name=feature.name,\n                                     test_passed=context.global_status['test_passed'])", "response": "Clean method that will be executed after each feature"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef bdd_common_after_all(context_or_world):\n    # Close drivers\n    DriverWrappersPool.close_drivers(scope='session', test_name='multiple_tests',\n                                     test_passed=context_or_world.global_status['test_passed'])\n\n    # Update tests status in Jira\n    change_all_jira_status()", "response": "Common after all method in behave or lettuce\n   "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure_logger(self, tc_config_log_filename=None, tc_output_log_filename=None):\n        # Get config logger filename\n        config_log_filename = DriverWrappersPool.get_configured_value('Config_log_filename', tc_config_log_filename,\n                                                                      'logging.conf')\n        config_log_filename = os.path.join(DriverWrappersPool.config_directory, config_log_filename)\n\n        # Configure logger only if logging filename has changed\n        if self.config_log_filename != config_log_filename:\n            # Get output logger filename\n            output_log_filename = DriverWrappersPool.get_configured_value('Output_log_filename', tc_output_log_filename,\n                                                                          'toolium.log')\n            output_log_filename = os.path.join(DriverWrappersPool.output_directory, output_log_filename)\n            output_log_filename = output_log_filename.replace('\\\\', '\\\\\\\\')\n\n            try:\n                logging.config.fileConfig(config_log_filename, {'logfilename': output_log_filename}, False)\n            except Exception as exc:\n                print(\"[WARN] Error reading logging config file '{}': {}\".format(config_log_filename, exc))\n            self.config_log_filename = config_log_filename\n            self.output_log_filename = output_log_filename\n            self.logger = logging.getLogger(__name__)", "response": "Configure selenium instance logger with the specified config file and output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures selenium instance properties with properties from file.", "response": "def configure_properties(self, tc_config_prop_filenames=None, behave_properties=None):\n        \"\"\"Configure selenium instance properties\n\n        :param tc_config_prop_filenames: test case specific properties filenames\n        :param behave_properties: dict with behave user data properties\n        \"\"\"\n        prop_filenames = DriverWrappersPool.get_configured_value('Config_prop_filenames', tc_config_prop_filenames,\n                                                                 'properties.cfg;local-properties.cfg')\n        prop_filenames = [os.path.join(DriverWrappersPool.config_directory, filename) for filename in\n                          prop_filenames.split(';')]\n        prop_filenames = ';'.join(prop_filenames)\n\n        # Configure config only if properties filename has changed\n        if self.config_properties_filenames != prop_filenames:\n            # Initialize the config object\n            self.config = ExtendedConfigParser.get_config_from_file(prop_filenames)\n            self.config_properties_filenames = prop_filenames\n\n        # Override properties with system properties\n        self.config.update_properties(os.environ)\n\n        # Override properties with behave userdata properties\n        if behave_properties:\n            self.config.update_properties(behave_properties)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures visual baseline directory", "response": "def configure_visual_baseline(self):\n        \"\"\"Configure baseline directory\"\"\"\n        # Get baseline name\n        baseline_name = self.config.get_optional('VisualTests', 'baseline_name', '{Driver_type}')\n        for section in self.config.sections():\n            for option in self.config.options(section):\n                option_value = self.config.get(section, option)\n                baseline_name = baseline_name.replace('{{{0}_{1}}}'.format(section, option), option_value)\n\n        # Configure baseline directory if baseline name has changed\n        if self.baseline_name != baseline_name:\n            self.baseline_name = baseline_name\n            self.visual_baseline_directory = os.path.join(DriverWrappersPool.visual_baseline_directory,\n                                                          get_valid_filename(baseline_name))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure baseline directory after driver is created", "response": "def update_visual_baseline(self):\n        \"\"\"Configure baseline directory after driver is created\"\"\"\n        # Update baseline with real platformVersion value\n        if '{PlatformVersion}' in self.baseline_name:\n            try:\n                platform_version = self.driver.desired_capabilities['platformVersion']\n            except KeyError:\n                platform_version = None\n            self.baseline_name = self.baseline_name.replace('{PlatformVersion}', str(platform_version))\n            self.visual_baseline_directory = os.path.join(DriverWrappersPool.visual_baseline_directory,\n                                                          self.baseline_name)\n\n        # Update baseline with real version value\n        if '{Version}' in self.baseline_name:\n            try:\n                splitted_version = self.driver.desired_capabilities['version'].split('.')\n                version = '.'.join(splitted_version[:2])\n            except KeyError:\n                version = None\n            self.baseline_name = self.baseline_name.replace('{Version}', str(version))\n            self.visual_baseline_directory = os.path.join(DriverWrappersPool.visual_baseline_directory,\n                                                          self.baseline_name)\n\n        # Update baseline with remote node value\n        if '{RemoteNode}' in self.baseline_name:\n            self.baseline_name = self.baseline_name.replace('{RemoteNode}', str(self.remote_node))\n            self.visual_baseline_directory = os.path.join(DriverWrappersPool.visual_baseline_directory,\n                                                          self.baseline_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef configure(self, tc_config_files, is_selenium_test=True, behave_properties=None):\n        # Configure config and output directories\n        DriverWrappersPool.configure_common_directories(tc_config_files)\n\n        # Configure logger\n        self.configure_logger(tc_config_files.config_log_filename, tc_config_files.output_log_filename)\n\n        # Initialize the config object\n        self.configure_properties(tc_config_files.config_properties_filenames, behave_properties)\n\n        # Configure visual directories\n        if is_selenium_test:\n            driver_info = self.config.get('Driver', 'type')\n            DriverWrappersPool.configure_visual_directories(driver_info)\n            self.configure_visual_baseline()", "response": "Configure the selenium instance using the specified config files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef connect(self, maximize=True):\n        if not self.config.get('Driver', 'type') or self.config.get('Driver', 'type') in ['api', 'no_driver']:\n            return None\n\n        self.driver = ConfigDriver(self.config, self.utils).create_driver()\n\n        # Save session id and remote node to download video after the test execution\n        self.session_id = self.driver.session_id\n        self.server_type, self.remote_node = self.utils.get_remote_node()\n        if self.server_type == 'grid':\n            self.remote_node_video_enabled = self.utils.is_remote_video_enabled(self.remote_node)\n        else:\n            self.remote_node_video_enabled = True if self.server_type in ['ggr', 'selenoid'] else False\n\n            # Save app_strings in mobile tests\n        if self.is_mobile_test() and not self.is_web_test() and self.config.getboolean_optional('Driver',\n                                                                                                'appium_app_strings'):\n            self.app_strings = self.driver.app_strings()\n\n        if self.is_maximizable():\n            # Bounds and screen\n            bounds_x, bounds_y = self.get_config_window_bounds()\n            self.driver.set_window_position(bounds_x, bounds_y)\n            self.logger.debug('Window bounds: %s x %s', bounds_x, bounds_y)\n\n            # Maximize browser\n            if maximize:\n                # Set window size or maximize\n                window_width = self.config.get_optional('Driver', 'window_width')\n                window_height = self.config.get_optional('Driver', 'window_height')\n                if window_width and window_height:\n                    self.driver.set_window_size(window_width, window_height)\n                else:\n                    self.driver.maximize_window()\n\n        # Log window size\n        window_size = self.utils.get_window_size()\n        self.logger.debug('Window size: %s x %s', window_size['width'], window_size['height'])\n\n        # Update baseline\n        self.update_visual_baseline()\n\n        # Discard previous logcat logs\n        self.utils.discard_logcat_logs()\n\n        # Set implicitly wait timeout\n        self.utils.set_implicitly_wait()\n\n        return self.driver", "response": "Connect to the server and return the new selenium driver."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nread bounds from config and modify the values to match with the specified monitor", "response": "def get_config_window_bounds(self):\n        \"\"\"Reads bounds from config and, if monitor is specified, modify the values to match with the specified monitor\n\n        :return: coords X and Y where set the browser window.\n        \"\"\"\n        bounds_x = int(self.config.get_optional('Driver', 'bounds_x') or 0)\n        bounds_y = int(self.config.get_optional('Driver', 'bounds_y') or 0)\n\n        monitor_index = int(self.config.get_optional('Driver', 'monitor') or -1)\n        if monitor_index > -1:\n            try:\n                monitor = screeninfo.get_monitors()[monitor_index]\n                bounds_x += monitor.x\n                bounds_y += monitor.y\n            except NotImplementedError:\n                self.logger.warn('Current environment doesn\\'t support get_monitors')\n\n        return bounds_x, bounds_y"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncheck if the driver should be reused based on the test passed and context.", "response": "def should_reuse_driver(self, scope, test_passed, context=None):\n        \"\"\"Check if the driver should be reused\n\n        :param scope: execution scope (function, module, class or session)\n        :param test_passed: True if the test has passed\n        :param context: behave context\n        :returns: True if the driver should be reused\n        \"\"\"\n        reuse_driver = self.config.getboolean_optional('Driver', 'reuse_driver')\n        reuse_driver_session = self.config.getboolean_optional('Driver', 'reuse_driver_session')\n        restart_driver_after_failure = (self.config.getboolean_optional('Driver', 'restart_driver_after_failure') or\n                                        self.config.getboolean_optional('Driver', 'restart_driver_fail'))\n        if context and scope == 'function':\n            reuse_driver = reuse_driver or (hasattr(context, 'reuse_driver_from_tags')\n                                            and context.reuse_driver_from_tags)\n        return (((reuse_driver and scope == 'function') or (reuse_driver_session and scope != 'session'))\n                and (test_passed or not restart_driver_after_failure))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting driver platform where tests are running", "response": "def get_driver_platform(self):\n        \"\"\"\n        Get driver platform where tests are running\n        :return: platform name\n        \"\"\"\n        platform = ''\n        if 'platform' in self.driver.desired_capabilities:\n            platform = self.driver.desired_capabilities['platform']\n        elif 'platformName' in self.driver.desired_capabilities:\n            platform = self.driver.desired_capabilities['platformName']\n        return platform"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the given string converted to a string that can be used for a clean filename.", "response": "def get_valid_filename(s, max_length=FILENAME_MAX_LENGTH):\n    \"\"\"\n    Returns the given string converted to a string that can be used for a clean filename.\n    Removes leading and trailing spaces; converts anything that is not an alphanumeric,\n    dash or underscore to underscore; converts behave examples separator ` -- @` to underscore.\n    It also cuts the resulting name to `max_length`.\n\n    @see https://github.com/django/django/blob/master/django/utils/text.py\n    \"\"\"\n    s = str(s).strip().replace(' -- @', '_')\n    s = re.sub(r'(?u)[^-\\w]', '_', s).strip('_')\n    return s[:max_length]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_long_description():\n    # Get readme content\n    readme = read_file('README.rst')\n\n    # Change rst urls to ReadTheDocs html urls\n    docs_url = 'http://toolium.readthedocs.org/en/latest'\n    description = readme.replace('/CHANGELOG.rst', '{}/changelog.html'.format(docs_url))\n    for doc in ['driver_configuration', 'page_objects', 'bdd_integration', 'visual_testing', 'tests_result_analysis']:\n        description = description.replace('/docs/{}.rst'.format(doc), '{}/{}.html'.format(docs_url, doc))\n    return description", "response": "Get README content and update rst urls\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef save_jira_conf():\n    global enabled, execution_url, summary_prefix, labels, comments, fix_version, build, only_if_changes, attachments\n    config = DriverWrappersPool.get_default_wrapper().config\n    enabled = config.getboolean_optional('Jira', 'enabled')\n    execution_url = config.get_optional('Jira', 'execution_url')\n    summary_prefix = config.get_optional('Jira', 'summary_prefix')\n    labels = config.get_optional('Jira', 'labels')\n    comments = config.get_optional('Jira', 'comments')\n    fix_version = config.get_optional('Jira', 'fixversion')\n    build = config.get_optional('Jira', 'build')\n    only_if_changes = config.getboolean_optional('Jira', 'onlyifchanges')\n    attachments = []", "response": "Read Jira configuration from properties file and save it"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_jira_status(test_key, test_status, test_comment):\n    global attachments\n    if test_key and enabled:\n        if test_key in jira_tests_status:\n            # Merge data with previous test status\n            previous_status = jira_tests_status[test_key]\n            test_status = 'Pass' if previous_status[1] == 'Pass' and test_status == 'Pass' else 'Fail'\n            if previous_status[2] and test_comment:\n                test_comment = '{}\\n{}'.format(previous_status[2], test_comment)\n            elif previous_status[2] and not test_comment:\n                test_comment = previous_status[2]\n            attachments += previous_status[3]\n        # Add or update test status\n        jira_tests_status[test_key] = (test_key, test_status, test_comment, attachments)", "response": "Add or update test status and comments to Jira later"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nupdate the status of a JIRA test case in Jira.", "response": "def change_jira_status(test_key, test_status, test_comment, test_attachments):\n    \"\"\"Update test status in Jira\n\n    :param test_key: test case key in Jira\n    :param test_status: test case status\n    :param test_comment: test case comments\n    :param test_attachments: test case attachments\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    if not execution_url:\n        logger.warning(\"Test Case '%s' can not be updated: execution_url is not configured\", test_key)\n        return\n\n    logger.info(\"Updating Test Case '%s' in Jira with status %s\", test_key, test_status)\n    composed_comments = comments\n    if test_comment:\n        composed_comments = '{}\\n{}'.format(comments, test_comment) if comments else test_comment\n    payload = {'jiraTestCaseId': test_key, 'jiraStatus': test_status, 'summaryPrefix': summary_prefix,\n               'labels': labels, 'comments': composed_comments, 'version': fix_version, 'build': build}\n    if only_if_changes:\n        payload['onlyIfStatusChanges'] = 'true'\n    try:\n        if test_attachments and len(test_attachments) > 0:\n            files = dict()\n            for index in range(len(test_attachments)):\n                files['attachments{}'.format(index)] = open(test_attachments[index], 'rb')\n        else:\n            files = None\n        response = requests.post(execution_url, data=payload, files=files)\n    except Exception as e:\n        logger.warning(\"Error updating Test Case '%s': %s\", test_key, e)\n        return\n\n    if response.status_code >= 400:\n        logger.warning(\"Error updating Test Case '%s': [%s] %s\", test_key, response.status_code,\n                       get_error_message(response.content))\n    else:\n        logger.debug(\"%s\", response.content.decode().splitlines()[0])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_error_message(response_content):\n    apache_regex = re.compile('.*<u>(.*)</u></p><p>.*')\n    match = apache_regex.search(response_content)\n    if match:\n        error_message = match.group(1)\n    else:\n        local_regex = re.compile('.*<title>(.*)</title>.*')\n        match = local_regex.search(response_content)\n        if match:\n            error_message = match.group(1)\n        else:\n            error_message = response_content\n    return error_message", "response": "Extract error message from the HTTP response from the test case execution API."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nclick the element and wait until it has changed.", "response": "def click(self):\n        \"\"\"Click the element\n\n        :returns: page element instance\n        \"\"\"\n        try:\n            self.wait_until_clickable().web_element.click()\n        except StaleElementReferenceException:\n            # Retry if element has changed\n            self.web_element.click()\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nresets all page elements object with the given driver wrapper.", "response": "def reset_object(self, driver_wrapper=None):\n        \"\"\"Reset each page element object\n\n        :param driver_wrapper: driver wrapper instance\n        \"\"\"\n        if driver_wrapper:\n            self.driver_wrapper = driver_wrapper\n        self.app_strings = self.driver_wrapper.app_strings  #: mobile application strings\n        for element in self._get_page_elements():\n            element.reset_object(driver_wrapper)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns list of page elements and page objects of this page object", "response": "def _get_page_elements(self):\n        \"\"\"Return page elements and page objects of this page object\n\n        :returns: list of page elements and page objects\n        \"\"\"\n        page_elements = []\n        for attribute, value in list(self.__dict__.items()) + list(self.__class__.__dict__.items()):\n            if attribute != 'parent' and isinstance(value, CommonObject):\n                page_elements.append(value)\n        return page_elements"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwait until page object is loaded by calling wait_until_visible method on all page elements.", "response": "def wait_until_loaded(self, timeout=None):\n        \"\"\"Wait until page object is loaded\n        Search all page elements configured with wait=True\n\n        :param timeout: max time to wait\n        :returns: this page object instance\n        \"\"\"\n        for element in self._get_page_elements():\n            if hasattr(element, 'wait') and element.wait:\n                from toolium.pageelements.page_element import PageElement\n                if isinstance(element, PageElement):\n                    # Pageelement and Group\n                    element.wait_until_visible(timeout)\n                if isinstance(element, PageObject):\n                    # PageObject and Group\n                    element.wait_until_loaded(timeout)\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting an option value for a given section and option.", "response": "def get_optional(self, section, option, default=None):\n        \"\"\" Get an option value for a given section\n        If the section or the option are not found, the default value is returned\n\n        :param section: config section\n        :param option: config option\n        :param default: default value\n        :returns: config value\n        \"\"\"\n        try:\n            return self.get(section, option)\n        except (configparser.NoSectionError, configparser.NoOptionError):\n            return default"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getboolean_optional(self, section, option, default=False):\n        try:\n            return self.getboolean(section, option)\n        except (configparser.NoSectionError, configparser.NoOptionError):\n            return default", "response": "Get an option boolean value for a given section and option."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a deep copy of the config object", "response": "def deepcopy(self):\n        \"\"\"Returns a deep copy of config object\n\n        :returns: a copy of the config object\n        \"\"\"\n        # Save actual config to a string\n        config_string = StringIO()\n        self.write(config_string)\n\n        # We must reset the buffer ready for reading.\n        config_string.seek(0)\n\n        # Create a new config object\n        config_copy = ExtendedConfigParser()\n        config_copy.readfp(config_string)\n\n        return config_copy"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_properties(self, new_properties):\n        [self._update_property_from_dict(section, option, new_properties)\n         for section in self.sections() for option in self.options(section)]", "response": "Update config properties values\n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nupdating a config property value with a new value from a dictionary.", "response": "def _update_property_from_dict(self, section, option, new_properties):\n        \"\"\" Update a config property value with a new property value\n        Property name must be equal to 'Section_option' of config property\n\n        :param section: config section\n        :param option: config option\n        :param new_properties: dict with new properties values\n        \"\"\"\n        try:\n            property_name = \"{0}_{1}\".format(section, option)\n            self.set(section, option, new_properties[property_name])\n        except KeyError:\n            pass"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread properties files and saves them to a config object", "response": "def get_config_from_file(conf_properties_files):\n        \"\"\"Reads properties files and saves them to a config object\n\n        :param conf_properties_files: comma-separated list of properties files\n        :returns: config object\n        \"\"\"\n        # Initialize the config object\n        config = ExtendedConfigParser()\n        logger = logging.getLogger(__name__)\n\n        # Configure properties (last files could override properties)\n        found = False\n        files_list = conf_properties_files.split(';')\n        for conf_properties_file in files_list:\n            result = config.read(conf_properties_file)\n            if len(result) == 0:\n                message = 'Properties config file not found: %s'\n                if len(files_list) == 1:\n                    logger.error(message, conf_properties_file)\n                    raise Exception(message % conf_properties_file)\n                else:\n                    logger.debug(message, conf_properties_file)\n            else:\n                logger.debug('Reading properties from file: %s', conf_properties_file)\n                found = True\n        if not found:\n            message = 'Any of the properties config files has been found'\n            logger.error(message)\n            raise Exception(message)\n\n        return config"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_driver(scenario):\n    if not hasattr(world, 'config_files'):\n        world.config_files = ConfigFiles()\n\n    # By default config directory is located in terrain path\n    if not world.config_files.config_directory:\n        world.config_files.set_config_directory(DriverWrappersPool.get_default_config_directory())\n\n    world.global_status = {'test_passed': True}\n    bdd_common_before_scenario(world, scenario)", "response": "Setup the driver for the current scenario"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nresets each page element object to empty.", "response": "def reset_object(self, driver_wrapper=None):\n        \"\"\"Reset each page element object\n\n        :param driver_wrapper: driver wrapper instance\n        \"\"\"\n        if driver_wrapper:\n            self.driver_wrapper = driver_wrapper\n        for element in self._page_elements:\n            element.reset_object(driver_wrapper)\n        self._web_elements = []\n        self._page_elements = []"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding multiple WebElements using element locator", "response": "def web_elements(self):\n        \"\"\"Find multiple WebElements using element locator\n\n        :returns: list of web element objects\n        :rtype: list of selenium.webdriver.remote.webelement.WebElement\n                or list of appium.webdriver.webelement.WebElement\n        \"\"\"\n        if not self._web_elements or not self.config.getboolean_optional('Driver', 'save_web_element'):\n            if self.parent:\n                self._web_elements = self.utils.get_web_element(self.parent).find_elements(*self.locator)\n            else:\n                self._web_elements = self.driver.find_elements(*self.locator)\n        return self._web_elements"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind multiple PageElements using element locator", "response": "def page_elements(self):\n        \"\"\"Find multiple PageElement using element locator\n\n        :returns: list of page element objects\n        :rtype: list of toolium.pageelements.PageElement\n        \"\"\"\n        if not self._page_elements or not self.config.getboolean_optional('Driver', 'save_web_element'):\n            self._page_elements = []\n            for order, web_element in enumerate(self.web_elements):\n                # Create multiple PageElement with original locator and order\n                page_element = self.page_element_class(self.locator[0], self.locator[1], parent=self.parent,\n                                                       order=order)\n                page_element.reset_object(self.driver_wrapper)\n                page_element._web_element = web_element\n                self._page_elements.append(page_element)\n        return self._page_elements"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfinding WebElement using element locator .", "response": "def web_element(self):\n        \"\"\"Find WebElement using element locator\n\n        :returns: web element object\n        :rtype: selenium.webdriver.remote.webelement.WebElement or appium.webdriver.webelement.WebElement\n        \"\"\"\n        try:\n            self._find_web_element()\n        except NoSuchElementException as exception:\n            parent_msg = \" and parent locator '{}'\".format(self.parent) if self.parent else ''\n            msg = \"Page element of type '%s' with locator %s%s not found\"\n            self.logger.error(msg, type(self).__name__, self.locator, parent_msg)\n            exception.msg += \"\\n  {}\".format(msg % (type(self).__name__, self.locator, parent_msg))\n            raise exception\n        return self._web_element"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _find_web_element(self):\n        if not self._web_element or not self.config.getboolean_optional('Driver', 'save_web_element'):\n            # If the element is encapsulated we use the shadowroot tag in yaml (eg. Shadowroot: root_element_name)\n            if self.shadowroot:\n                if self.locator[0] != By.CSS_SELECTOR:\n                    raise Exception('Locator type should be CSS_SELECTOR using shadowroot but found: '\n                                    '%s'.format(self.locator[0]))\n                # querySelector only support CSS SELECTOR locator\n                self._web_element = self.driver.execute_script('return document.querySelector(\"%s\").shadowRoot.'\n                                                               'querySelector(\"%s\")' % (self.shadowroot,\n                                                                                        self.locator[1]))\n            else:\n                # Element will be finded from parent element or from driver\n                base = self.utils.get_web_element(self.parent) if self.parent else self.driver\n                # Find elements and get the correct index or find a single element\n                self._web_element = base.find_elements(*self.locator)[self.order] if self.order else base.find_element(\n                    *self.locator)", "response": "Find WebElement using element locator and save it in _web_element attribute"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef scroll_element_into_view(self):\n        x = self.web_element.location['x']\n        y = self.web_element.location['y']\n        self.driver.execute_script('window.scrollTo({0}, {1})'.format(x, y))\n        return self", "response": "Scroll element into view"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch element and wait until it is visible.", "response": "def wait_until_visible(self, timeout=None):\n        \"\"\"Search element and wait until it is visible\n\n        :param timeout: max time to wait\n        :returns: page element instance\n        \"\"\"\n        try:\n            self.utils.wait_until_element_visible(self, timeout)\n        except TimeoutException as exception:\n            parent_msg = \" and parent locator '{}'\".format(self.parent) if self.parent else ''\n            msg = \"Page element of type '%s' with locator %s%s not found or is not visible after %s seconds\"\n            timeout = timeout if timeout else self.utils.get_explicitly_wait()\n            self.logger.error(msg, type(self).__name__, self.locator, parent_msg, timeout)\n            exception.msg += \"\\n  {}\".format(msg % (type(self).__name__, self.locator, parent_msg, timeout))\n            raise exception\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsearching element and wait until it is not visible.", "response": "def wait_until_not_visible(self, timeout=None):\n        \"\"\"Search element and wait until it is not visible\n\n        :param timeout: max time to wait\n        :returns: page element instance\n        \"\"\"\n        try:\n            self.utils.wait_until_element_not_visible(self, timeout)\n        except TimeoutException as exception:\n            parent_msg = \" and parent locator '{}'\".format(self.parent) if self.parent else ''\n            msg = \"Page element of type '%s' with locator %s%s is still visible after %s seconds\"\n            timeout = timeout if timeout else self.utils.get_explicitly_wait()\n            self.logger.error(msg, type(self).__name__, self.locator, parent_msg, timeout)\n            exception.msg += \"\\n  {}\".format(msg % (type(self).__name__, self.locator, parent_msg, timeout))\n            raise exception\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch element and wait until it is clickable.", "response": "def wait_until_clickable(self, timeout=None):\n        \"\"\"Search element and wait until it is clickable\n\n        :param timeout: max time to wait\n        :returns: page element instance\n        \"\"\"\n        try:\n            self.utils.wait_until_element_clickable(self, timeout)\n        except TimeoutException as exception:\n            parent_msg = \" and parent locator '{}'\".format(self.parent) if self.parent else ''\n            msg = \"Page element of type '%s' with locator %s%s not found or is not clickable after %s seconds\"\n            timeout = timeout if timeout else self.utils.get_explicitly_wait()\n            self.logger.error(msg, type(self).__name__, self.locator, parent_msg, timeout)\n            exception.msg += \"\\n  {}\".format(msg % (type(self).__name__, self.locator, parent_msg, timeout))\n            raise exception\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nasserting that a screenshot of the element is the same as a screenshot on disk within a given threshold.", "response": "def assert_screenshot(self, filename, threshold=0, exclude_elements=[], force=False):\n        \"\"\"Assert that a screenshot of the element is the same as a screenshot on disk, within a given threshold.\n\n        :param filename: the filename for the screenshot, which will be appended with ``.png``\n        :param threshold: percentage threshold for triggering a test failure (value between 0 and 1)\n        :param exclude_elements: list of WebElements, PageElements or element locators as a tuple (locator_type,\n                                 locator_value) that must be excluded from the assertion\n        :param force: if True, the screenshot is compared even if visual testing is disabled by configuration\n        \"\"\"\n        VisualTest(self.driver_wrapper, force).assert_screenshot(self.web_element, filename, self.__class__.__name__,\n                                                                 threshold, exclude_elements)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_selenoid_info(self):\n        host_url = '{}/host/{}'.format(self.server_url, self.session_id)\n        try:\n            selenoid_info = requests.get(host_url).json()\n        except Exception:\n            return None\n        self.driver_wrapper.logger.info('Selenoid host info: \\n %s' % selenoid_info)\n        return selenoid_info", "response": "retrieve the current selenoid host info"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn True if the GGR session is still active.", "response": "def is_the_session_still_active(self):\n        \"\"\"\n        Is the GGR session still active? Associated to a browser and the sessionId\n        Example of GGR status:\n        {\"browsers\":{\"MicrosoftEdge\":{\"latest\":{}},\"android\":{\"8.1\":{}},\"chrome\":{\"70.0\":{},\"latest\":{\"test_tef\":{\"count\":1,\"sessions\":[{\"caps\":{\"browserName\":\"chrome\",\"enableVNC\":true,\"enableVideo\":true,\"platform\":\"ANY\",\"screenResolution\":\"1280x1024x24\",\"version\":\"latest\",\"videoName\":\"selenoide952e551bb9395e16d060f28c54e5d31.mp4\",\"videoScreenSize\":\"1280x1024\"},\"container\":\"8489205e28c9781472e99c3921a6240de3894a3603ed9e187ad6360b6b013b8b\",\"containerInfo\":{\"id\":\"8489205e28c9781472e99c3921a6240de3894a3603ed9e187ad6360b6b013b8b\",\"ip\":\"172.17.0.4\"},\"id\":\"1345506093dfed8dbcef610da476911a228ca315978e5464ae49fb1142bbc49b\",\"screen\":\"1280x1024x24\",\"vnc\":true}]}}},\"firefox\":{\"59.0\":{},\"63.0\":{},\"64.0\":{},\"latest\":{}},\"internet explorer\":{\"11\":{}},\"opera\":{\"56.0\":{},\"latest\":{}},\"safari\":{\"latest\":{}}},\"pending\":0,\"queued\":0,\"total\":30,\"used\":1}\n        :return boolean (although in case of error in the request will be returned None)\n        \"\"\"\n        server_url_splitted = self.server_url.split(\":\")\n        host_url = \"{}:{}:{}:{}/status\".format(server_url_splitted[0], server_url_splitted[1], server_url_splitted[2], STATUS_PORT)\n\n        try:\n            response = requests.get(host_url).json()[\"browsers\"][self.browser]\n        except Exception as e:\n            self.driver_wrapper.logger.warn(\"the GGR status request has failed: \\nResponse:  %s \\nError message: %s\\n\" % (response.content, e))\n            return None\n        for browser in response:\n            if response[browser] != {}:\n                sessions = response[browser][server_url_splitted[1].split(\"@\")[0].replace(\"//\", \"\")][\"sessions\"]\n                for session in sessions:\n                    if session[\"id\"] == self.session_id:\n                        return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload the execution video file if the scenario fails or the video is enabled and remove the video file in the server.", "response": "def download_session_video(self, scenario_name, timeout=5):\n        \"\"\"\n        download the execution video file if the scenario fails or the video is enabled,\n        renaming the file to scenario name and removing the video file in the server.\n             GGR request: http://<username>:<password>@<ggr_host>:<ggr_port>/video/<session_id>\n        selenoid request: http://<username>:<password>@<ggr_host>:<ggr_port>/video/<session_id>.mp4\n        :param scenario_name: scenario name\n        :param timeout: threshold until the video file is downloaded\n        \"\"\"\n        # Download video only in linux nodes with video enabled\n        if (self.driver_wrapper.get_driver_platform().lower() != 'linux' or\n                not self.driver_wrapper.config.getboolean_optional('Capabilities', 'enableVideo')):\n            return\n\n        path_file = os.path.join(self.videos_directory, '%s.%s' % (scenario_name, MP4_EXTENSION))\n        if self.driver_wrapper.server_type == 'selenoid':\n            filename = '%s.%s' % (self.session_id, MP4_EXTENSION)\n        else:\n            filename = self.session_id\n        video_url = '{}/video/{}'.format(self.server_url, filename)\n        # download the execution video file\n        if self.browser_remote:\n            self.__download_file(video_url, path_file, timeout)\n        # remove the video file if it does exist\n        self.__remove_file(video_url)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndownload the session log file from remote selenoid and remove the video file in the server.", "response": "def download_session_log(self, scenario_name, timeout=5):\n        \"\"\"\n        download the session log file from remote selenoid,\n        renaming the file to scenario name and removing the video file in the server.\n             GGR request: http://<username>:<password>@<ggr_host>:<ggr_port>/logs/<ggr_session_id>\n        selenoid request: http://<username>:<password>@<ggr_host>:<ggr_port>/logs/<ggr_session_id>.log\n        :param scenario_name: scenario name\n        :param timeout: threshold until the video file is downloaded\n        \"\"\"\n        # Download logs only in linux nodes with logs enabled\n        if (self.driver_wrapper.get_driver_platform().lower() != 'linux' or\n                not self.driver_wrapper.config.getboolean_optional('Capabilities', 'enableLog')):\n            return\n\n        path_file = os.path.join(self.logs_directory, '%s_ggr.%s' % (scenario_name, LOG_EXTENSION))\n        if self.driver_wrapper.server_type == 'selenoid':\n            filename = '%s.%s' % (self.session_id, LOG_EXTENSION)\n        else:\n            filename = self.session_id\n        logs_url = '{}/logs/{}'.format(self.server_url, filename)\n        # download the session log file\n        if self.browser_remote:\n            self.__download_file(logs_url, path_file, timeout)\n        # remove the log file if it does exist\n        self.__remove_file(logs_url)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_file(self, filename, timeout=5):\n        path_file = os.path.join(self.output_directory, DOWNLOADS_PATH, self.session_id[-8:], filename)\n        file_url = '{}/download/{}/{}'.format(self.server_url, self.session_id, filename)\n        # download the file\n        if self.browser_remote:\n            self.__download_file(file_url, path_file, timeout)\n            return path_file\n        return None", "response": "download a file from remote selenoid and remove the file in the server"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nlogs a warning message", "response": "def warn(self, exc):\n        \"\"\"\n        log a warning message:\n        :param exc: exception message\n        \"\"\"\n        msg = 'trying to execute a step in the environment: \\n' \\\n              '           - Exception: %s' % exc\n        if self.logger is not None:\n            self.logger.warn(msg)\n        self.by_console('      WARN - %s' % msg)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef error(self, exc):\n        msg = 'trying to execute a step in the environment: \\n' \\\n              '           - Exception: %s' % exc\n        if self.logger is not None:\n            self.logger.error(msg)\n        self.by_console('      ERROR - %s' % msg)", "response": "log an error message"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nprinting text to console by printing it to stdout", "response": "def by_console(self, text_to_print):\n        \"\"\"\n        print in console avoiding output buffering\n        :param text_to_print: Text to print by console\n        \"\"\"\n        if self.show:\n            sys.stdout.write(\"%s\\n\" % text_to_print)\n            sys.stdout.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets all steps defined in the feature description", "response": "def get_steps_from_feature_description(self, description):\n        \"\"\"\n        get all steps defined in the feature description associated to each action\n        :param description: feature description\n        \"\"\"\n        self.init_actions()\n        label_exists = EMPTY\n        for row in description:\n            if label_exists != EMPTY:\n                # in case of a line with a comment, it is removed\n                if \"#\" in row:\n                    row = row[0:row.find(\"#\")].strip()\n\n                if any(row.startswith(x) for x in KEYWORDS):\n                    self.actions[label_exists].append(row)\n                elif row.find(TABLE_SEPARATOR) >= 0:\n                    self.actions[label_exists][-1] = \"%s\\n      %s\" % (self.actions[label_exists][-1], row)\n                else:\n                    label_exists = EMPTY\n            for action_label in self.actions:\n                if row.lower().find(action_label) >= 0:\n                    label_exists = action_label"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove the step prefix to be replaced by Given", "response": "def __remove_prefix(self, step):\n        \"\"\"\n        remove the step prefix to will be replaced by Given\n        :param step: step text\n        \"\"\"\n        step_length = len(step)\n        for k in KEYWORDS:\n            step = step.lstrip(k)\n            if len(step) < step_length:\n                break\n        return step"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __print_step_by_console(self, step):\n        step_list = step.split(u'\\n')\n        for s in step_list:\n            self.logger.by_console(u'    %s' % repr(s).replace(\"u'\", \"\").replace(\"'\", \"\"))", "response": "print the step by console if the show variable is enabled\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __execute_steps_by_action(self, context, action):\n        if len(self.actions[action]) > 0:\n            if action in [ACTIONS_BEFORE_FEATURE, ACTIONS_BEFORE_SCENARIO, ACTIONS_AFTER_FEATURE]:\n                self.logger.by_console('\\n')\n                if action == ACTIONS_BEFORE_SCENARIO:\n                    self.scenario_counter += 1\n                    self.logger.by_console(\n                        \"  ------------------ Scenario N\u00ba: %d ------------------\" % self.scenario_counter)\n                self.logger.by_console('  %s:' % action)\n            for item in self.actions[action]:\n                self.scenario_error = False\n                try:\n                    self.__print_step_by_console(item)\n                    context.execute_steps(u'''%s%s''' % (GIVEN_PREFIX, self.__remove_prefix(item)))\n                    self.logger.debug(u'step defined in pre-actions: %s' % repr(item))\n                except Exception as exc:\n                    if action in [ACTIONS_BEFORE_FEATURE]:\n                        self.feature_error = True\n                    elif action in [ACTIONS_BEFORE_SCENARIO]:\n                        self.scenario_error = True\n                    self.logger.error(exc)\n                    break", "response": "Execute a list of steps that are set by action."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef reset_error_status(self):\n        try:\n            return self.feature_error or self.scenario_error\n        finally:\n            self.feature_error = False\n            self.scenario_error = False", "response": "Check if any exception has been raised when executing steps and restore the value of status to False."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef execute_before_feature_steps(self, context):\n        self.__execute_steps_by_action(context, ACTIONS_BEFORE_FEATURE)\n\n        if context.dyn_env.feature_error:\n            # Mark this Feature as skipped. Steps will not be executed.\n            context.feature.mark_skipped()", "response": "Execute the actions before the feature."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef execute_before_scenario_steps(self, context):\n        if not self.feature_error:\n            self.__execute_steps_by_action(context, ACTIONS_BEFORE_SCENARIO)\n\n        if context.dyn_env.scenario_error:\n            # Mark this Scenario as skipped. Steps will not be executed.\n            context.scenario.mark_skipped()", "response": "Execute the actions before each scenario."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes the actions after each scenario.", "response": "def execute_after_scenario_steps(self, context):\n        \"\"\"\n        actions after each scenario\n        :param context: It\u2019s a clever place where you and behave can store information to share around, automatically managed by behave.\n        \"\"\"\n        if not self.feature_error and not self.scenario_error:\n            self.__execute_steps_by_action(context, ACTIONS_AFTER_SCENARIO)\n\n        # Behave dynamic environment: Fail all steps if dyn_env has got any error and reset it\n        if self.reset_error_status():\n            context.scenario.reset()\n            context.dyn_env.fail_first_step_precondition_exception(context.scenario)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute the actions after the feature has been completed.", "response": "def execute_after_feature_steps(self, context):\n        \"\"\"\n        actions after the feature\n        :param context: It\u2019s a clever place where you and behave can store information to share around, automatically managed by behave.\n        \"\"\"\n        if not self.feature_error:\n            self.__execute_steps_by_action(context, ACTIONS_AFTER_FEATURE)\n\n        # Behave dynamic environment: Fail all steps if dyn_env has got any error and reset it\n        if self.reset_error_status():\n            context.feature.reset()\n            for scenario in context.feature.walk_scenarios():\n                context.dyn_env.fail_first_step_precondition_exception(scenario)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfail first step in the given Scenario and add exception message for the output.", "response": "def fail_first_step_precondition_exception(self, scenario):\n        \"\"\"\n        Fail first step in the given Scenario and add exception message for the output.\n        This is needed because xUnit exporter in Behave fails if there are not failed steps.\n        :param scenario: Behave's Scenario\n        \"\"\"\n\n        try:\n            import behave\n            if parse_version(behave.__version__) < parse_version('1.2.6'):\n                status = 'failed'\n            else:\n                status = behave.model_core.Status.failed\n        except ImportError as exc:\n            self.logger.error(exc)\n            raise\n\n        scenario.steps[0].status = status\n        scenario.steps[0].exception = Exception(\"Preconditions failed\")\n        scenario.steps[0].error_message = \"Failing steps due to precondition exceptions\""}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the value on the element", "response": "def text(self, value):\n        \"\"\"Set value on the element\n\n        :param value: value to be set\n        \"\"\"\n        if self.driver_wrapper.is_ios_test() and not self.driver_wrapper.is_web_test():\n            self.web_element.set_value(value)\n        elif self.shadowroot:\n            self.driver.execute_script('return document.querySelector(\"%s\")'\n                                       '.shadowRoot.querySelector(\"%s\")'\n                                       '.value = \"%s\"' % (self.shadowroot, self.locator[1], value))\n        else:\n            self.web_element.send_keys(value)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef reset_object(self, driver_wrapper=None):\n        from toolium.pageelements.page_elements import PageElements\n        if driver_wrapper:\n            self.driver_wrapper = driver_wrapper\n        self._web_element = None\n        for element in self._get_page_elements():\n            element.reset_object(driver_wrapper)\n            if isinstance(element, (PageElement, PageElements)):\n                # If element is not a page object, update element parent\n                element.parent = self", "response": "Reset each page element object with the given driver wrapper."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninstalls the example notebooks for litho1pt0 in the given location.", "response": "def install_documentation(path=\"./Litho1pt0-Notebooks\"):\n    \"\"\"Install the example notebooks for litho1pt0 in the given location\n\n    WARNING: If the path exists, the Notebook files will be written into the path\n    and will overwrite any existing files with which they collide. The default\n    path (\"./Litho1pt0-Notebooks\") is chosen to make collision less likely / problematic\n\n    The documentation for litho1pt0 is in the form of jupyter notebooks.\n\n    Some dependencies exist for the notebooks to be useful:\n\n       - matplotlib: for some diagrams\n       - cartopy: for plotting map examples\n\n    litho1pt0 dependencies are explicitly imported into the notebooks including:\n\n       - stripy (for interpolating on the sphere)\n       - numpy\n       - scipy (for k-d tree point location)\n\n    \"\"\"\n\n    ## Question - overwrite or not ? shutils fails if directory exists.\n\n    Notebooks_Path = _pkg_resources.resource_filename('litho1pt0', 'Notebooks')\n\n    ct = _dir_util.copy_tree(Notebooks_Path, path, preserve_mode=1, preserve_times=1, preserve_symlinks=1, update=0, verbose=1, dry_run=0)\n\n    return"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving duplicates rows from N equally - sized arrays", "response": "def remove_duplicates(vector_tuple):\n    \"\"\"\n    Remove duplicates rows from N equally-sized arrays\n    \"\"\"\n    array = np.column_stack(vector_tuple)\n    a = np.ascontiguousarray(array)\n    unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n    b = unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))\n    return list(b.T)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_collinear(self, x, y):\n        pts = np.column_stack([x[:3], y[:3], np.ones(3)])\n        return np.linalg.det(pts) == 0.0", "response": "Checks if first three points are collinear"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _shuffle_field(self, *args):\n\n        p = self._permutation\n\n        fields = []\n        for arg in args:\n            fields.append( arg[p] )\n\n        if len(fields) == 1:\n            return fields[0]\n        else:\n            return fields", "response": "Shuffle the field of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _deshuffle_field(self, *args):\n\n        ip = self._invpermutation\n\n        fields = []\n        for arg in args:\n            fields.append( arg[ip] )\n\n        if len(fields) == 1:\n            return fields[0]\n        else:\n            return fields", "response": "Return the original ordering of the fields in the order that they are passed to the _deshuffle_method."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the gradient of a n - dimensional array.", "response": "def gradient(self, f, nit=3, tol=1e-3, guarantee_convergence=False):\n        \"\"\"\n        Return the gradient of an n-dimensional array.\n\n        The method consists of minimizing a quadratic functional Q(G) over\n        gradient vectors (in x and y directions), where Q is an approximation\n        to the linearized curvature over the triangulation of a C-1 bivariate\n        function F(x,y) which interpolates the nodal values and gradients.\n\n        Parameters\n        ----------\n         f : array of floats, shape (n,)\n            field over which to evaluate the gradient\n         nit: int (default: 3)\n            number of iterations to reach a convergence tolerance, tol\n            nit >= 1\n         tol: float (default: 1e-3)\n            maximum change in gradient between iterations.\n            convergence is reached when this condition is met.\n\n        Returns\n        -------\n         dfdx : array of floats, shape (n,)\n            derivative of f in the x direction\n         dfdy : array of floats, shape (n,)\n            derivative of f in the y direction\n\n        Notes\n        -----\n         For SIGMA = 0, optimal efficiency was achieved in testing with\n         tol = 0, and nit = 3 or 4.\n\n         The restriction of F to an arc of the triangulation is taken to be\n         the Hermite interpolatory tension spline defined by the data values\n         and tangential gradient components at the endpoints of the arc, and\n         Q is the sum over the triangulation arcs, excluding interior\n         constraint arcs, of the linearized curvatures of F along the arcs --\n         the integrals over the arcs of D2F(T)**2, where D2F(T) is the second\n         derivative of F with respect to distance T along the arc.\n        \"\"\"\n        if f.size != self.npoints:\n            raise ValueError('f should be the same size as mesh')\n\n        gradient = np.zeros((2,self.npoints), order='F', dtype=np.float32)\n        sigma = 0\n        iflgs = 0\n\n        f = self._shuffle_field(f)\n\n        ierr = 1\n        while ierr == 1:\n            ierr = _srfpack.gradg(self._x, self._y, f, self.lst, self.lptr, self.lend,\\\n                                  iflgs, sigma, gradient, nit=nit, dgmax=tol)\n            if not guarantee_convergence:\n                break\n\n        if ierr < 0:\n            raise ValueError('ierr={} in gradg\\n{}'.format(ierr, _ier_codes[ierr]))\n\n        return self._deshuffle_field(gradient[0], gradient[1])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the gradient at a specified node.", "response": "def gradient_local(self, f, index):\n        \"\"\"\n        Return the gradient at a specified node.\n\n        This routine employs a local method, in which values depend only on nearby\n        data points, to compute an estimated gradient at a node.\n\n        gradient_local() is more efficient than gradient() only if it is unnecessary\n        to compute gradients at all of the nodes. Both routines have similar accuracy.\n\n        Parameters\n        ----------\n        \"\"\"\n        if f.size != self.npoints:\n            raise ValueError('f should be the same size as mesh')\n\n        f = self._shuffle_field(f)\n\n\n        gradX, gradY, l = _srfpack.gradl(index + 1, self._x, self._y, f,\\\n                                         self.lst, self.lptr, self.lend)\n\n        return gradX, gradY"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpolate(self, xi, yi, zdata, order=1):\n\n        if order == 0:\n            zierr = np.zeros_like(xi, dtype=np.int)\n            return self.interpolate_nearest(xi, yi, zdata), zierr\n        elif order == 1:\n            return self.interpolate_linear(xi, yi, zdata)\n        elif order == 3:\n            return self.interpolate_cubic(xi, yi, zdata)\n        else:\n            raise ValueError(\"order must be 0, 1, or 3\")", "response": "This method interpolates the value at the given xi yi coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ninterpolating nearest - neighbour to xi yi in zdata.", "response": "def interpolate_nearest(self, xi, yi, zdata):\n        \"\"\"\n        Nearest-neighbour interpolation.\n        Calls nearnd to find the index of the closest neighbours to xi,yi\n\n        Parameters\n        ----------\n         xi : float / array of floats, shape (l,)\n            x coordinates on the Cartesian plane\n         yi : float / array of floats, shape (l,)\n            y coordinates on the Cartesian plane\n\n        Returns\n        -------\n         zi : float / array of floats, shape (l,)\n            nearest-neighbour interpolated value(s) of (xi,yi)\n        \"\"\"\n        if zdata.size != self.npoints:\n            raise ValueError('zdata should be same size as mesh')\n\n        zdata = self._shuffle_field(zdata)\n\n        ist = np.ones_like(xi, dtype=np.int32)\n        ist, dist = _tripack.nearnds(xi, yi, ist, self._x, self._y,\n                                     self.lst, self.lptr, self.lend)\n        return zdata[ist - 1]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate_cubic(self, xi, yi, zdata, gradz=None, derivatives=False):\n\n        if zdata.size != self.npoints:\n            raise ValueError('zdata should be same size as mesh')\n\n        if type(gradz) == type(None):\n            gradX, gradY = self.gradient(zdata)\n            gradX, gradY = self._shuffle_field(gradX, gradY)\n        elif np.array(gradz).shape == (2,self.npoints):\n            gradX, gradY = self._shuffle_field(gradz[0], gradz[1])\n        else:\n            raise ValueError(\"gradz must be of shape {}\".format((2,self.npoints)))\n\n        iflgs = 0\n        dflag = 1\n        sigma = 0.0\n\n\n        xi = np.array(xi)\n        yi = np.array(yi)\n\n        size = xi.size\n\n        zi = np.empty(size)\n        dzx = np.empty(size)\n        dzy = np.empty(size)\n        zierr = np.empty(size, dtype=np.int)\n\n        gradZ = np.vstack([gradX, gradY])\n        zdata = self._shuffle_field(zdata)\n\n        for i in range(0, size):\n            ist = np.abs(self._x - xi[i]).argmin() + 1\n            zi[i], dzx[i], dzy[i], zierr[i] = _srfpack.intrc1(xi[i], yi[i], self._x, self._y, zdata,\\\n                               self.lst, self.lptr, self.lend, iflgs, sigma, gradZ, dflag, ist)\n\n        if derivatives:\n            return zi, zierr, (dzx, dzy)\n        else:\n            return zi, zierr", "response": "This method interpolate the value at a given point in the triangulation using cubic interpolation."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef neighbour_and_arc_simplices(self):\n        nt, ltri, lct, ierr = _tripack.trlist(self.lst, self.lptr, self.lend, nrow=9)\n        if ierr != 0:\n            raise ValueError('ierr={} in trlist\\n{}'.format(ierr, _ier_codes[ierr]))\n        ltri = ltri.T[:nt] - 1\n        return ltri[:,3:6], ltri[:,6:]", "response": "Get indices of neighbour simplices for each simplex and arc indices."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nearest_vertex(self, xi, yi):\n        n = np.array(xi).size\n        xi = np.array(xi).reshape(n)\n        yi = np.array(yi).reshape(n)\n\n        idx  = np.empty_like(xi, dtype=np.int)\n        dist = np.empty_like(xi, dtype=np.float)\n\n        for pt in range(0, n):\n            # i is the node at which we start the search\n            # the closest x coordinate is a good place\n            i = np.abs(self._x - xi[pt]).argmin()\n\n            idx[pt], dist[pt] = _tripack.nearnd(xi[pt], yi[pt], i, self._x, self._y,\\\n                                                self.lst, self.lptr, self.lend)\n        idx -= 1 # return to C ordering\n\n        return self._deshuffle_simplices(idx), dist", "response": "Locate the index of the nearest vertex to points xi yi and return the squared distance between the nearest vertex to each of the supplied points yi and the nearest neighbour to each of the supplied points yi."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef containing_triangle(self, xi, yi):\n        p = self._permutation\n        pts = np.column_stack([xi, yi])\n\n        sorted_simplices = np.sort(self._simplices, axis=1)\n\n        triangles = []\n        for pt in pts:\n            t = _tripack.trfind(3, pt[0], pt[1], self._x, self._y, self.lst, self.lptr, self.lend)\n            tri = np.sort(t) - 1\n\n            triangles.extend(np.where(np.all(p[sorted_simplices]==p[tri], axis=1))[0])\n\n        return np.array(triangles).ravel()", "response": "Returns indices of the triangles containing xi yi"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the simplex and barycentric coordinates of the local system.", "response": "def containing_simplex_and_bcc(self, xi, yi):\n        \"\"\"\n        Returns the simplices containing (xi,yi)\n        and the local barycentric, normalised coordinates.\n\n        Parameters\n        ----------\n         xi : float / array of floats, shape (l,)\n            Cartesian coordinates in the x direction\n         yi : float / array of floats, shape (l,)\n            Cartesian coordinates in the y direction\n\n        Returns\n        -------\n         bcc : normalised barycentric coordinates\n         tri : simplices containing (xi,yi)\n\n        Notes\n        -----\n         The ordering of the vertices may differ from that stored in\n         self.simplices array but will still be a loop around the simplex.\n        \"\"\"\n\n        pts = np.column_stack([xi,yi])\n\n        tri = np.empty((pts.shape[0], 3), dtype=np.int) # simplices\n        bcc = np.empty_like(tri, dtype=np.float) # barycentric coords\n\n        for i, pt in enumerate(pts):\n            t = _tripack.trfind(3, pt[0], pt[1], self._x, self._y, self.lst, self.lptr, self.lend)\n            tri[i] = t\n\n            vert = self._points[tri[i] - 1]\n            v0 = vert[1] - vert[0]\n            v1 = vert[2] - vert[0]\n            v2 = pt - vert[0]\n\n            d00 = v0.dot(v0)\n            d01 = v0.dot(v1)\n            d11 = v1.dot(v1)\n            d20 = v2.dot(v0)\n            d21 = v2.dot(v1)\n            denom = d00*d11 - d01*d01\n\n            v = (d11 * d20 - d01 * d21) / denom\n            w = (d00 * d21 - d01 * d20) / denom\n            u = 1.0 - v - w\n\n            bcc[i] = [u, v, w]\n\n        tri -= 1 # return to C ordering\n\n        bcc /= bcc.sum(axis=1).reshape(-1,1)\n\n        return bcc, self._deshuffle_simplices(tri)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef identify_vertex_neighbours(self, vertex):\n        simplices = self.simplices\n        ridx, cidx = np.where(simplices == vertex)\n        neighbour_array = np.unique(np.hstack([simplices[ridx]])).tolist()\n        neighbour_array.remove(vertex)\n        return neighbour_array", "response": "Identify the neighbour - vertices in the triangulation for the given vertex"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef identify_vertex_triangles(self, vertices):\n\n        triangles = []\n\n        for vertex in np.array(vertices).reshape(-1):\n            triangles.append(np.where(self.simplices == vertex)[0])\n\n        return np.unique(np.concatenate(triangles))", "response": "Identify all the triangles which own any of the vertices in the provided list."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nidentifying all the segments in the triangulation and return an array of vertices where n1 < n2 where n1 < n2 where n2 < n3", "response": "def identify_segments(self):\n        \"\"\"\n        Find all the segments in the triangulation and return an\n        array of vertices (n1,n2) where n1 < n2\n        \"\"\"\n\n        i1 = np.sort([self._simplices[:,0], self._simplices[:,1]], axis=0)\n        i2 = np.sort([self._simplices[:,0], self._simplices[:,2]], axis=0)\n        i3 = np.sort([self._simplices[:,1], self._simplices[:,2]], axis=0)\n\n        a = np.hstack([i1, i2, i3]).T\n\n        # find unique rows in numpy array\n        # <http://stackoverflow.com/questions/16970982/find-unique-rows-in-numpy-array>\n        b = np.ascontiguousarray(a).view(np.dtype((np.void, a.dtype.itemsize * a.shape[1])))\n        segments = np.unique(b).view(a.dtype).reshape(-1, a.shape[1])\n\n        return self._deshuffle_simplices(segments)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef face_midpoints(self, simplices=None):\n\n        if type(simplices) == type(None):\n            simplices = self.simplices\n\n        mids = self.points[simplices].mean(axis=1)\n        mid_xpt, mid_ypt = mids[:,0], mids[:,1]\n\n        return mid_xpt, mid_ypt", "response": "Identify the center of every simplex in the triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the midpoints of every line segment in the triangulation.", "response": "def segment_midpoints(self, segments=None):\n        \"\"\"\n        Identify the midpoints of every line segment in the triangulation.\n        If an array of segments of shape (no_of_segments,2) is given,\n        then the midpoints of only those segments is returned.\n\n        Notes\n        -----\n         Segments in the array must not be duplicates or the re-triangulation\n         will fail. Take care not to miss that (n1,n2) is equivalent to (n2,n1).\n        \"\"\"\n\n        if type(segments) == type(None):\n            segments = self.identify_segments()\n        points = self.points\n\n        mids = (points[segments[:,0]] + points[segments[:,1]]) * 0.5\n        mid_xpt, mid_ypt = mids[:,0], mids[:,1]\n\n        return mid_xpt, mid_ypt"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef segment_tripoints(self, ratio=0.33333):\n\n        segments = self.identify_segments()\n        points = self.points\n\n        mids1 = ratio*points[segments[:,0]] + (1.0-ratio)*points[segments[:,1]]\n        mids2 = (1.0-ratio)*points[segments[:,0]] + ratio*points[segments[:,1]]\n\n        mids = np.vstack((mids1,mids2))\n        mid_xpt, mid_ypt = mids[:,0], mids[:,1]\n\n        return mid_xpt, mid_ypt", "response": "Identify the trisection points of every line segment in the triangulation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfinding the convex hull of the internal set of x y points.", "response": "def convex_hull(self):\n        \"\"\"\n        Find the Convex Hull of the internal set of x,y points.\n\n        Returns\n        -------\n         bnodes : array of ints\n            indices corresponding to points on the convex hull\n        \"\"\"\n        bnodes, nb, na, nt = _tripack.bnodes(self.lst, self.lptr, self.lend, self.npoints)\n        return self._deshuffle_simplices(bnodes[:nb] - 1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompute the area of each triangle within the triangulation of points.", "response": "def areas(self):\n        \"\"\"\n        Compute the area of each triangle within the triangulation of points.\n\n        Returns\n        -------\n         area : array of floats, shape (nt,)\n            area of each triangle in self.simplices where nt\n            is the number of triangles.\n\n        \"\"\"\n        v1 = self.points[self.simplices[:,1]] - self.points[self.simplices[:,0]]\n        v2 = self.points[self.simplices[:,2]] - self.points[self.simplices[:,1]]\n\n        area = 0.5*(v1[:,0]*v2[:,1] - v1[:,1]*v2[:,0])\n        return area"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncomputing the edge - lengths of each triangle in the triangulation.", "response": "def edge_lengths(self):\n        \"\"\"\n        Compute the edge-lengths of each triangle in the triangulation.\n        \"\"\"\n        simplex = self.simplices.T\n\n        # simplex is vectors a, b, c defining the corners\n        a = self.points[simplex[0]]\n        b = self.points[simplex[1]]\n        c = self.points[simplex[2]]\n\n        # norm to calculate length\n        ab = np.linalg.norm(b - a, axis=1)\n        bc = np.linalg.norm(c - a, axis=1)\n        ac = np.linalg.norm(a - c, axis=1)\n\n        return ab, bc, ac"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef uniformly_refine_triangulation(self, faces=False, trisect=False):\n\n        if faces:\n            x_v1, y_v1 = self._add_face_centroids()\n\n        else:\n            if not trisect:\n                x_v1, y_v1 = self._add_midpoints()\n            else:\n                x_v1, y_v1 = self._add_tripoints(ratio=0.333333)\n\n        return x_v1, y_v1", "response": "This method returns the uniformly refined triangulation of the current triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef midpoint_refine_triangulation_by_vertices(self, vertices):\n\n        xi, yi = self.segment_midpoints_by_vertices(vertices=vertices)\n\n        x_v1 = np.concatenate((self.x, xi), axis=0)\n        y_v1 = np.concatenate((self.y, yi), axis=0)\n\n        return x_v1, y_v1", "response": "Return the midpoints defining a refined triangulation obtained by bisection of all edges in the triangulation connected to any of the vertices in the list provided."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning points defining a refined triangulation obtained by bisection of all edges in the triangulation that are associated with the triangles in the list of indices provided. Notes ----- The triangles are here represented as a single index. The vertices of triangle i are given by self.simplices[i].", "response": "def edge_refine_triangulation_by_triangles(self, triangles):\n        \"\"\"\n        return points defining a refined triangulation obtained by bisection of all edges\n        in the triangulation that are associated with the triangles in the list\n        of indices provided.\n\n        Notes\n        -----\n         The triangles are here represented as a single index.\n         The vertices of triangle i are given by self.simplices[i].\n        \"\"\"\n\n        ## Note there should be no duplicates in the list of triangles\n        ## but because we remove duplicates from the list of all segments,\n        ## there is no pressing need to check this.\n\n        # identify the segments\n\n        simplices = self.simplices\n        segments = set()\n\n        for index in np.array(triangles).reshape(-1):\n            tri = simplices[index]\n            segments.add( min( tuple((tri[0], tri[1])), tuple((tri[0], tri[1]))) )\n            segments.add( min( tuple((tri[1], tri[2])), tuple((tri[2], tri[1]))) )\n            segments.add( min( tuple((tri[0], tri[2])), tuple((tri[2], tri[0]))) )\n\n        segs = np.array(list(segments))\n\n        xi, yi = self.segment_midpoints(segs)\n\n        x_v1 = np.concatenate((self.x, xi), axis=0)\n        y_v1 = np.concatenate((self.y, yi), axis=0)\n\n        return x_v1, y_v1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a list of points defining a refined triangulation obtained by bisection of all edges that are connected to any of the vertices in the list provided.", "response": "def edge_refine_triangulation_by_vertices(self, vertices):\n        \"\"\"\n        return points defining a refined triangulation obtained by bisection of all edges\n        in the triangulation connected to any of the vertices in the list provided\n        \"\"\"\n\n        triangles = self.identify_vertex_triangles(vertices)\n\n        return self.edge_refine_triangulation_by_triangles(triangles)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef centroid_refine_triangulation_by_triangles(self, triangles):\n\n        # Remove duplicates from the list of triangles\n\n        triangles = np.unique(np.array(triangles))\n\n        xi, yi = self.face_midpoints(simplices=self.simplices[triangles])\n\n        x_v1 = np.concatenate((self.x, xi), axis=0)\n        y_v1 = np.concatenate((self.y, yi), axis=0)\n\n        return x_v1, y_v1", "response": "Return the centroid of a refined triangulation obtained by bisection of all edges in the triangulation that are associated with the given triangles."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef centroid_refine_triangulation_by_vertices(self, vertices):\n\n        triangles = self.identify_vertex_triangles(vertices)\n\n        return self.centroid_refine_triangulation_by_triangles(triangles)", "response": "Returns the centroid of a refined triangulation obtained by bisection of all edges that are connected to any of the vertices in the provided list of vertices."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef join(self, t2, unique=False):\n\n        x_v1 = np.concatenate((self.x, t2.x), axis=0)\n        y_v1 = np.concatenate((self.y, t2.y), axis=0)\n\n        ## remove any duplicates\n\n        if not unique:\n            a = np.ascontiguousarray(np.vstack((x_v1, y_v1)).T)\n            unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n            unique_coords = unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))\n\n            x_v1 = unique_coords[:,0]\n            y_v1 = unique_coords[:,1]\n\n        return x_v1, y_v1", "response": "Join this triangulation with another triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef nearest_vertices(self, x, y, k=1, max_distance=np.inf ):\n\n        if self.tree == False or self.tree == None:\n            return 0, 0\n\n        xy = np.column_stack([x, y])\n\n        dxy, vertices = self._cKDtree.query(xy, k=k, distance_upper_bound=max_distance)\n\n\n        if k == 1:   # force this to be a 2D array\n            vertices = np.reshape(vertices, (-1, 1))\n\n        return dxy, vertices", "response": "Query the cKDtree for the nearest neighbours and Euclidean distance between each point and their nearest neighbours."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the layer depth at a given latitude and longitude.", "response": "def layer_depth( lat, lon, layerID=\"LID-BOTTOM\"):\n    \"\"\"Returns layer depth at lat / lon (degrees)\n    where lat/lon may be arrays (of equal size).\n    Depths are returned in metres.\n    \"\"\"\n\n    ## Must wrap longitude from 0 to 360 ...\n\n    lon1 = np.array(lon)%360.0\n    lat1 = np.array(lat)\n\n    # ## Must wrap longitude from -180 to 180 ...\n    #\n    # lon1[np.where(lon1 > 180.0)] = 360.0 - lon1[np.where(lon1 > 180.0)]\n    #\n    data, err = _interpolator.interpolate( np.radians(lon1), np.radians(lat1),\n                                      _litho_data[l1_layer_decode[layerID], l1_data_decode[\"DEPTH\"]], order=1 )\n\n    return data"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef crust_type_at(lat=None, lon=None):\n    # Get lon into appropriate format\n\n    lats = np.array(lat)\n    lons = np.array(lon%360)\n\n    iVals = ((90.0-lats)%180).astype(np.int)\n    jVals = (lons%360.0).astype(int)\n\n    # i = int((-lat+90.0)%180)\n    # j = int(lon)\n\n    t = _c1_crust_type_lat_lon[iVals,jVals]\n\n    # t = _c1_crust_type_lat_lon[i,j]\n    # des = litho.c1_region_descriptor[t]\n\n    return t\n\n\n\n\n\n    return t", "response": "Get the type of crust at a given latitude and longitude."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef property_at_lat_lon_depth_points(lat, lon, depth, quantity_ID=\"DENSITY\"):\n\n    nlayers = len(l1_layer_decode)\n    shape = np.array(lon).shape\n\n    lon1   = np.array(lon).reshape(-1)\n    lat1   = np.array(lat).reshape(-1)\n    depth1 = np.array(depth).reshape(-1)\n    point_properties = np.empty_like(depth1)\n\n    layer_depths     = np.empty((nlayers, lat1.shape[0]))\n    layer_properties = np.ones((nlayers+1, lat1.shape[0])) * -99999.0  # if the point is not found it will end up in the overshoot !\n\n    # should assert here that the three arrays are equal size\n\n    for i in range(0, nlayers, 1 ):\n        layer_depths[i], err = _interpolator.interpolate( lon1 * np.pi / 180.0, lat1 * np.pi / 180.0,\n                                      _litho_data[i,l1_data_decode[\"DEPTH\"]], order=1)\n        layer_properties[i], err = _interpolator.interpolate( lon1 * np.pi / 180.0, lat1 * np.pi / 180.0,\n                                      _litho_data[i,l1_data_decode[quantity_ID]], order=1)\n\n\n    A = -layer_depths\n    B = -depth1 * 1000.0\n    C = divmod(np.searchsorted(A.ravel(), B), A.shape[1])[0] # YEP - this seems to be the best way !!\n\n    # point_properties = np.diag(layer_properties[C[:],:])\n\n    point_properties = np.empty_like(depth1)\n    for i,layer in enumerate(C):\n\n        point_properties[i] = layer_properties[layer,i]\n\n    return C, point_properties.reshape(shape)", "response": "This function returns the properties of the points at the given latitude and longitude."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef property_on_depth_profile(lat, lon, depths, quantity_ID=\"DENSITY\"):\n\n    lon1 = np.array((lon,))\n    lat1 = np.array((lat,))\n    depths1 = np.array(depths)\n\n    nlayers = len(l1_layer_decode)\n    point_properties = np.empty_like(depths)\n\n    layer_depths     = np.empty((nlayers))\n    layer_properties = np.ones((nlayers+1)) * -99999.0  # if the point is not found it will end up in the overshoot !\n\n    # should assert here that the three arrays are equal size\n\n    for i in range(0, nlayers, 1 ):\n        layer_depths[i], err = _interpolator.interpolate( np.radians(lon1), np.radians(lat1),\n                                      _litho_data[i,l1_data_decode[\"DEPTH\"]], order=1)\n        layer_properties[i], err = _interpolator.interpolate( np.radians(lon1), np.radians(lat1),\n                                      _litho_data[i,l1_data_decode[quantity_ID]], order=1)\n\n\n    A = -layer_depths\n    B = -depths1 * 1000.0\n    C = np.searchsorted(A, B)\n\n    point_properties = np.empty_like(depths)\n    for i,layer in enumerate(C):\n\n        point_properties[i] = layer_properties[layer]\n\n    return C, point_properties", "response": "This function returns the layer properties and point properties of a depth profile."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreading the raw Litho1 data from a model file.", "response": "def process_raw_litho1_data(model_path):\n    \"\"\"\n    Don't forget to strip the model data first\n    truncate_raw_litho1_data(model path, truncated_model_path)\n    \"\"\"\n\n    npoints = 40962\n    nlayers = len(l1_layer_decode)\n    nentries = 9\n\n    litho_data = np.ones((nlayers, nentries, npoints)) * -99999.0\n\n    for model in range(0,npoints):\n        model_name = \"node\"+str(model+1)+\".model_tr\"\n        file = path.join(model_path, model_name)\n\n        thisnodedata  = np.loadtxt(file, usecols=np.arange(0,9), comments=\"nlayer\")\n        thisnodeident = np.loadtxt(file, usecols=(9,), dtype=str, comments=\"nlayer\")\n\n        if (model % 1000 == 0):\n            print (\"Reading node \", model)\n\n        for i, ident in enumerate(thisnodeident):\n            litho_data[l1_layer_decode[ident], :,  model] = thisnodedata[i,:]\n\n        ## Post process - not all layers in the model are populated (gives -99999 which is always illegal)\n        ## For depth, it makes more sense to have the layer simply have no thickness but appear in the default order\n\n        for layer in range(9,nlayers):\n            missing_entries = np.where(litho_data[layer, l1_data_decode[\"DEPTH\"]] == -99999)\n            litho_data[layer, l1_data_decode[\"DEPTH\"], missing_entries] = litho_data[layer-1, l1_data_decode[\"DEPTH\"], missing_entries]\n\n    grid_points_location = path.join(model_path,\"Icosahedron_Level7_LatLon_mod.txt\")\n    litho_points = np.loadtxt( grid_points_location )\n\n    return litho_data, litho_points"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_processed_litho_data(filename, litho_data, litho_points):\n\n    np.savez_compressed(filename, litho1_all_data=litho_data, litho1_mesh_coords=litho_points)\n\n    return", "response": "Writes the processed litho data to a file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nweight average of scattered data to the nodal points of a given triangulation", "response": "def weighted_average_to_nodes(x1, x2, data, interpolator ):\n    \"\"\" Weighted average of scattered data to the nodal points\n    of a triangulation using the barycentric coordinates as\n    weightings.\n\n    Parameters\n    ----------\n     x1, x2 : 1D arrays arrays of x,y or lon, lat (radians)\n     data :   1D array of data to be lumped to the node locations\n     interpolator : a stripy.Triangulation or stripy.sTriangulation object\n     which defines the node locations and their triangulation\n\n    Returns\n    -------\n     grid  : 1D array containing the results of the weighted average\n     norm  : 1D array of the normalisation used to compute `grid`\n     count : 1D int array of number of points that contribute anything to a given node\n\n    \"\"\"\n\n    import numpy as np\n\n    gridded_data = np.zeros(interpolator.npoints)\n    norm         = np.zeros(interpolator.npoints)\n    count        = np.zeros(interpolator.npoints, dtype=np.int)\n\n    bcc, nodes = interpolator.containing_simplex_and_bcc(x1, x2)\n\n    # Beware vectorising the reduction operation !!\n\n    for i in range(0, len(data)):\n\n        grid[nodes[i][0]] += bcc[i][0] * data[i]\n        grid[nodes[i][1]] += bcc[i][1] * data[i]\n        grid[nodes[i][2]] += bcc[i][2] * data[i]\n\n        norm[nodes[i][0]] += bcc[i][0]\n        norm[nodes[i][1]] += bcc[i][1]\n        norm[nodes[i][2]] += bcc[i][2]\n\n        count[nodes[i][0]] += 1\n        count[nodes[i][1]] += 1\n        count[nodes[i][2]] += 1\n\n\n    grid[np.where(norm > 0.0)] /= norm[np.where(norm > 0.0)]\n\n    return grid, norm, count"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves duplicates from an array of lon lat points", "response": "def remove_duplicate_lonlat(lon, lat):\n    \"\"\"\n    remove duplicates from an array of lon / lat points\n    \"\"\"\n\n    a = np.ascontiguousarray(np.vstack((lon, lat)).T)\n    unique_a = np.unique(a.view([('', a.dtype)]*a.shape[1]))\n    llunique = unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))\n\n    lon1 = llunique[:,0]\n    lat1 = llunique[:,1]\n\n    return lon1, lat1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef lonlat2xyz(lon, lat):\n\n    lons = np.array(lon)\n    lats = np.array(lat)\n\n    xs = np.cos(lats) * np.cos(lons)\n    ys = np.cos(lats) * np.sin(lons)\n    zs = np.sin(lats)\n\n    return xs, ys, zs", "response": "Convert lon lat to x y z"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts x y z representation of points on the unit sphere of the spherical triangulation to lon lat.", "response": "def xyz2lonlat(x,y,z):\n    \"\"\"\n    Convert x,y,z representation of points *on the unit sphere* of the\n    spherical triangulation to lon / lat (radians).\n\n    Note - no check is made here that (x,y,z) are unit vectors\n    \"\"\"\n\n    xs = np.array(x)\n    ys = np.array(y)\n    zs = np.array(z)\n\n    lons = np.arctan2(ys, xs)\n    lats = np.arcsin(zs)\n\n    return lons, lats"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ntaking stripack df x y z format and convert to surface gradients df / dx df / dy df / dz format and convert to surface gradients df / dlon df / dlat", "response": "def dxyz2dlonlat(x,y,z, dfx, dfy, dfz):\n    \"\"\"\n    Take stripack df/dx, df/dy, df/dz format and convert to\n    surface gradients df/dlon, df/dlat\n\n    Notes\n\n    \"\"\"\n\n    xs = np.array(x)\n    ys = np.array(y)\n    zs = np.array(z)\n\n    lons = np.arctan2(ys, xs)\n    lats = np.arcsin(zs)\n\n    dfxs = np.array(dfx)\n    dfys = np.array(dfy)\n    dfzs = np.array(dfz)\n\n    dlon = -dfxs * np.cos(lats) * np.sin(lons) + dfys * np.cos(lats) * np.cos(lons) # no z dependence\n    dlat = -dfxs * np.sin(lats) * np.cos(lons) - dfys * np.sin(lats) * np.sin(lons) + dfzs * np.cos(lats)\n\n    corr = np.sqrt((1.0-zs**2))\n    valid = ~np.isclose(corr,0.0)\n\n    dlon[valid] = dlon[valid] / corr[valid]\n\n    return dlon, dlat"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef great_circle_Npoints(lonlat1r, lonlat2r, N):\n\n    ratio = np.linspace(0.0,1.0, N).reshape(-1,1)\n\n\n    xyz1 = lonlat2xyz(lonlat1r[0], lonlat1r[1])\n    xyz2 = lonlat2xyz(lonlat2r[0], lonlat2r[1])\n\n    mids = ratio * xyz2 + (1.0-ratio) * xyz1\n    norm = np.sqrt((mids**2).sum(axis=1))\n    xyzN = mids / norm.reshape(-1,1)\n\n    lonlatN = xyz2lonlat( xyzN[:,0], xyzN[:,1], xyzN[:,2])\n\n    return lonlatN", "response": "Returns a new array of lonlat values that are in the great circle."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute the angular separation between two lon lat points p1 and p2 given in radians.", "response": "def angular_separation(lonp1, latp1, lonp2, latp2):\n    \"\"\"\n    Compute the angles between lon / lat points p1 and p2 given in radians.\n    On the unit sphere, this also corresponds to the great circle distance.\n    p1 and p2 can be numpy arrays of the same length.\n    \"\"\"\n\n    xp1, yp1, zp1 = lonlat2xyz(lonp1, latp1)\n    xp2, yp2, zp2 = lonlat2xyz(lonp2, latp2)\n\n    ## dot products to obtain angles\n\n    angles = np.arccos((xp1 * xp2 + yp1 * yp2 + zp1 * zp2))\n\n    ## As this is a unit sphere, angle = length\n\n    return angles"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _is_collinear(self, lons, lats):\n\n        x, y, z = lonlat2xyz(lons[:3], lats[:3])\n        pts = np.column_stack([x, y, z])\n\n        collinearity = (np.linalg.det(pts.T) == 0.0)\n\n        return collinearity", "response": "Checks if the first three points are collinear."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncomputes the gradient of a single nodal field on the unit sphere.", "response": "def gradient_lonlat(self, data, nit=3, tol=1.0e-3, guarantee_convergence=False):\n        \"\"\"\n        Return the lon / lat components of the gradient\n        of a scalar field on the surface of the sphere.\n\n\n        The method consists of minimizing a quadratic functional Q(G) over\n        gradient vectors, where Q is an approximation to the linearized\n        curvature over the triangulation of a C-1 bivariate function F(x,y)\n        which interpolates the nodal values and gradients.\n\n        Parameters\n        ----------\n         data : array of floats, shape (n,)\n            field over which to evaluate the gradient\n         nit: int (default: 3)\n            number of iterations to reach a convergence tolerance, tol\n            nit >= 1\n         tol: float (default: 1e-3)\n            maximum change in gradient between iterations.\n            convergence is reached when this condition is met.\n\n        Returns\n        -------\n         dfdlon : array of floats, shape (n,)\n            derivative of f in the longitudinal direction\n         dfdlat : array of floats, shape (n,)\n            derivative of f in the lattitudinal direction\n\n        Notes\n        -----\n\n        The gradient is computed via the Cartesian components using\n        spherical.sTriangulation.gradient_xyz and the iteration parameters\n        controling the spline interpolation are passed directly to this\n        routine (See notes for gradient_xyz for more details).\n\n        The gradient operator in this geometry is not well defined at the poles\n        even if the scalar field is smooth and the Cartesian gradient is well defined.\n\n        The routine spherical.dxyz2dlonlat is available to convert the Cartesian\n        to lon/lat coordinates at any point on the unit sphere. This is helpful\n        to avoid recalculation if you need both forms.\n        \"\"\"\n\n        dfxs, dfys, dfzs = self.gradient_xyz(data, nit=nit, tol=tol, guarantee_convergence=guarantee_convergence)\n\n        # get deshuffled versions\n        lons = self.lons\n        lats = self.lats\n        z = self.z\n\n        dlon = -dfxs * np.cos(lats) * np.sin(lons) + dfys * np.cos(lats) * np.cos(lons) # no z dependence\n        dlat = -dfxs * np.sin(lats) * np.cos(lons) - dfys * np.sin(lats) * np.sin(lons) + dfzs * np.cos(lats)\n\n        corr = np.sqrt((1.0-z**2))\n        valid = ~np.isclose(corr,0.0)\n\n        dlon[valid] = dlon[valid] / corr[valid]\n\n        return dlon, dlat"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gradient_xyz(self, f, nit=3, tol=1e-3, guarantee_convergence=False):\n\n        if f.size != self.npoints:\n            raise ValueError('f should be the same size as mesh')\n\n        # gradient = np.zeros((3,self.npoints), order='F', dtype=np.float32)\n        sigma = 0\n        iflgs = 0\n\n        f = self._shuffle_field(f)\n\n        ierr = 1\n        while ierr == 1:\n            grad, ierr = _ssrfpack.gradg(self._x, self._y, self._z, f, self.lst, self.lptr, self.lend,\\\n                                   iflgs, sigma, nit, tol)\n            if not guarantee_convergence:\n                break\n\n        if ierr < 0:\n            raise ValueError('ierr={} in gradg\\n{}'.format(ierr, _ier_codes[ierr]))\n\n        return self._deshuffle_field(grad[0], grad[1], grad[2])", "response": "Returns the cartesian components of the gradient of a single nodal field."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smoothing(self, f, w, sm, smtol, gstol):\n\n        if f.size != self.npoints or f.size != w.size:\n            raise ValueError('f and w should be the same size as mesh')\n\n        f, w = self._shuffle_field(f, w)\n\n        sigma = 0\n        iflgs = 0\n        prnt = -1\n\n        f_smooth, df, ierr = _ssrfpack.smsurf(self._x, self._y, self._z, f, self.lst, self.lptr, self.lend,\\\n                                             iflgs, sigma, w, sm, smtol, gstol, prnt)\n\n        if ierr < 0:\n            raise ValueError('ierr={} in gradg\\n{}'.format(ierr, _ier_codes[ierr]))\n        if ierr == 1:\n            raise RuntimeWarning(\"No errors were encountered but the constraint is not active --\\n\\\n                  F, FX, and FY are the values and partials of a linear function \\\n                  which minimizes Q2(F), and Q1 = 0.\")\n        if ierr == 2:\n            raise RuntimeWarning(\"The constraint could not be satisfied to within SMTOL\\\n                  due to ill-conditioned linear systems.\")\n\n        return self._deshuffle_field(f_smooth), self._deshuffle_field(df[0], df[1], df[2])", "response": "Smooth a surface f by choosing the linearized curvature of F and gradients to minimize the linearized curvature of F."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nchecks integrity of the given lons and lats.", "response": "def _check_integrity(self, lons, lats):\n        \"\"\"\n        Ensure lons and lats are:\n         - 1D numpy arrays\n         - equal size\n         - within the appropriate range in radians\n        \"\"\"\n\n        lons = np.array(lons).ravel()\n        lats = np.array(lats).ravel()\n\n        if len(lons.shape) != 1 or len(lats.shape) != 1:\n            raise ValueError('lons and lats must be 1D')\n        if lats.size != lons.size:\n            raise ValueError('lons and lats must have same length')\n        if (np.abs(lons)).max() > 2.*np.pi:\n            raise ValueError(\"lons must be in radians (-2*pi <= lon <= 2*pi)\")\n        if (np.abs(lats)).max() > 0.5*np.pi:\n            raise ValueError(\"lats must be in radians (-pi/2 <= lat <= pi/2)\")\n        return lons, lats"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef interpolate(self, lons, lats, zdata, order=1):\n\n\n        shape = lons.shape\n\n        lons, lats = self._check_integrity(lons, lats)\n\n        if order not in [0,1,3]:\n            raise ValueError(\"order must be 0, 1, or 3\")\n        if zdata.size != self.npoints:\n            raise ValueError(\"data must be of size {}\".format(self.npoints))\n\n        zdata = self._shuffle_field(zdata)\n\n        zi, zierr, ierr = _stripack.interp_n(order, lats, lons,\\\n                                      self._x, self._y, self._z, zdata,\\\n                                      self.lst, self.lptr, self.lend)\n\n        if ierr != 0:\n            print('Warning some points may have errors - check error array\\n'.format(ierr))\n            zi[zierr < 0] = np.nan\n\n        return zi.reshape(shape), zierr.reshape(shape)", "response": "This method interpolates the value at a given longitude and latitude."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpolate_nearest(self, lons, lats, data):\n        return self.interpolate(lons, lats, data, order=0)", "response": "Interpolate using nearest - neighbour approximation"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ninterpolate using linear approximation", "response": "def interpolate_linear(self, lons, lats, data):\n        \"\"\"\n        Interpolate using linear approximation\n        Returns the same as interpolate(lons,lats,data,order=1)\n        \"\"\"\n        return self.interpolate(lons, lats, data, order=1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef interpolate_cubic(self, lons, lats, data):\n        return self.interpolate(lons, lats, data, order=3)", "response": "Interpolate using cubic spline approximation"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlocate the index of the nearest vertex to points ( lons lats ) and return the squared great circle distance between each point and each nearest neighbour.", "response": "def nearest_vertex(self, lons, lats):\n        \"\"\"\n        Locate the index of the nearest vertex to points (lons,lats)\n        and return the squared great circle distance between (lons,lats) and\n        each nearest neighbour.\n\n        Parameters\n        ----------\n         lons : float / array of floats, shape (l,)\n            longitudinal coordinate(s) on the sphere\n         lats : float / array of floats, shape (l,)\n            latitudinal coordinate(s) on the sphere\n\n        Returns\n        -------\n         index : array of ints\n            the nearest vertex to each of the supplied points\n         dist : array of floats\n            great circle distance (angle) on the unit sphere to the closest\n            vertex identified.\n\n\n        Notes\n        -----\n         Faster searches can be obtained using a k-d tree.\n         See sTriangulation.nearest_vertices() for details.\n         There is an additional overhead associated with building and storing the k-d tree.\n\n        \"\"\"\n\n        # translate to unit sphere\n\n        xi = np.array(_stripack.trans(lats, lons))\n        idx = np.empty_like(xi[0,:], dtype=np.int)\n        dist = np.empty_like(xi[0,:], dtype=np.float)\n\n        for pt in range(0, xi.shape[1]):\n            xi0 = xi[:,pt]\n\n            # i is the node at which we start the search\n            # the closest x coordinate is a good place\n            i = ((self._x - xi0[0])**2).argmin() + 1\n\n            idx[pt], dist[pt] = _stripack.nearnd((xi0[0],xi0[1],xi0[2]), self._x, self._y, self._z, self.lst, self.lptr, self.lend, i)\n\n        idx -= 1 # return to C ordering\n\n        return self._deshuffle_simplices(idx), dist"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef containing_triangle(self, lons, lats):\n        p = self._permutation\n        pts = np.array(lonlat2xyz(lons,lats)).T\n\n        sorted_simplices = np.sort(self._simplices, axis=1)\n\n        triangles = []\n        for pt in pts:\n            t = _stripack.trfind(3, pt, self._x, self._y, self._z, self.lst, self.lptr, self.lend )\n            tri = np.sort(t[3:6]) - 1\n\n            triangles.append(np.where(np.all(p[sorted_simplices]==p[tri], axis=1))[0])\n\n        return np.array(triangles).reshape(-1)", "response": "Returns indices of the triangles containing lons and lats."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef containing_simplex_and_bcc(self, lons, lats):\n\n        pts = np.array(lonlat2xyz(lons,lats)).T\n\n        tri = np.empty((pts.shape[0], 3), dtype=np.int) # simplices\n        bcc = np.empty_like(tri, dtype=np.float) # barycentric coords\n\n        for i, pt in enumerate(pts):\n            t = _stripack.trfind(3, pt, self._x, self._y, self._z, self.lst, self.lptr, self.lend )\n            tri[i] = t[3:6]\n            bcc[i] = t[0:3]\n\n        tri -= 1 # return to C ordering\n\n        bcc /= bcc.sum(axis=1).reshape(-1,1)\n\n        return bcc, self._deshuffle_simplices(tri)", "response": "Returns the simplices containing the simplex and the local barycentric coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef identify_vertex_neighbours(self, vertex):\n        vertex = self._permutation[vertex]\n\n        lpl = self.lend[vertex-1]\n        lp = lpl\n\n        neighbours = []\n\n        while True:\n            lp = self.lptr[lp-1]\n            neighbours.append(self.lst[lp-1]-1)\n            if (lp == lpl):\n                break\n\n        return self._deshuffle_simplices(neighbours)", "response": "Identify the neighbour - vertices in the triangulation for the given vertex."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nidentifying all the segments in the triangulation and return an array of vertices where n1 < n2 where n1 < n2", "response": "def identify_segments(self):\n        \"\"\"\n        Find all the segments in the triangulation and return an\n        array of vertices (n1,n2) where n1 < n2\n        \"\"\"\n\n        lst  = self.lst\n        lend = self.lend\n        lptr = self.lptr\n\n        segments_array = np.empty((len(lptr),2),dtype=np.int)\n        segments_array[:,0] = lst[:] - 1\n        segments_array[:,1] = lst[lptr[:]-1] - 1\n\n        valid = np.where(segments_array[:,0] < segments_array[:,1])[0]\n        segments = segments_array[valid,:]\n\n        return self._deshuffle_simplices(segments)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef segment_midpoints_by_vertices(self, vertices):\n\n        segments = set()\n\n        for vertex in vertices:\n            neighbours = self.identify_vertex_neighbours(vertex)\n            segments.update( min( tuple((vertex, n1)), tuple((n1, vertex))) for n1 in neighbours )\n\n        segs = np.array(list(segments))\n\n        new_midpoint_lonlats = self.segment_midpoints(segments=segs)\n\n        return new_midpoint_lonlats", "response": "Given a list of vertices return a list of midpoints that are connected to the vertices."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef face_midpoints(self, simplices=None):\n\n        if type(simplices) == type(None):\n            simplices = self.simplices\n\n        mids = self.points[simplices].mean(axis=1)\n        mids /= np.linalg.norm(mids, axis=1).reshape(-1,1)\n\n        midlons, midlats = xyz2lonlat(mids[:,0], mids[:,1], mids[:,2])\n\n        return midlons, midlats", "response": "Identify the midpoints of every simplex in the triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef segment_midpoints(self, segments=None):\n\n        if type(segments) == type(None):\n            segments = self.identify_segments()\n        points = self.points\n\n        mids = (points[segments[:,0]] + points[segments[:,1]]) * 0.5\n        mids /= np.linalg.norm(mids, axis=1).reshape(-1,1)\n\n        lons, lats = xyz2lonlat(mids[:,0], mids[:,1], mids[:,2])\n\n        return lons, lats", "response": "Identify the midpoints of every line segment in the triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nidentifies the trisection points of every line segment in the triangulation", "response": "def segment_tripoints(self, ratio=0.33333):\n        \"\"\"\n        Identify the trisection points of every line segment in the triangulation\n        \"\"\"\n\n        segments = self.identify_segments()\n        points = self.points\n\n        mids1 = ratio * points[segments[:,0]] + (1.0-ratio) * points[segments[:,1]]\n        mids1 /= np.linalg.norm(mids1, axis=1).reshape(-1,1)\n\n        mids2 = (1.0-ratio) *  points[segments[:,0]] + ratio * points[segments[:,1]]\n        mids2 /= np.linalg.norm(mids2, axis=1).reshape(-1,1)\n\n        mids = np.vstack((mids1,mids2))\n\n        midlls = xyz2lonlat(mids[:,0], mids[:,1], mids[:,2])\n\n        return midlls"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef tri_area(self, lons, lats):\n        lons, lats = self._check_integrity(lons, lats)\n\n        # translate to unit sphere\n        x, y, z = _stripack.trans(lats, lons)\n\n        # compute area\n        area = _stripack.areas(x, y, z)\n\n        return area", "response": "Calculate the area enclosed by 3 points on the unit sphere."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the area each triangle within the triangulation of points on the unit sphere.", "response": "def areas(self):\n        \"\"\"\n        Compute the area each triangle within the triangulation of points\n        on the unit sphere.\n\n        Returns\n        -------\n         area : array of floats, shape (nt,)\n            area of each triangle in self.simplices where nt\n            is the number of triangles.\n\n        Notes\n        -----\n         This uses a Fortran 90 subroutine that wraps the AREA function\n         to iterate over many points.\n        \"\"\"\n\n        return _stripack.triareas(self.x, self.y, self.z, self.simplices.T+1)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef edge_lengths(self):\n\n        simplex = self.simplices.T\n\n        # simplex is vectors a, b, c defining the corners\n        a = self.points[simplex[0]]\n        b = self.points[simplex[1]]\n        c = self.points[simplex[2]]\n\n        ## dot products to obtain angles\n        ab = np.arccos((a * b).sum(axis=1))\n        bc = np.arccos((b * c).sum(axis=1))\n        ac = np.arccos((a * c).sum(axis=1))\n\n        ## As this is a unit sphere, angle = length so ...\n\n        return ab, bc, ac", "response": "Compute the edge - lengths of each triangle in the triangulation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncomputing the angular separation between two points.", "response": "def angular_separation(self, lonp1, latp1, lonp2, latp2):\n        \"\"\"\n        Compute the angles between lon / lat points p1 and p2 given in radians.\n        On the unit sphere, this also corresponds to the great circle distance.\n        p1 and p2 can be numpy arrays of the same length.\n\n        This method simply calls the module-level function of the same name.\n        Consider using the module function instead, as this method may be\n        deprecated in favor of that function. For now, this method is\n        retained to avoid issues with the Jupyter notebooks.\n        \"\"\"\n        # Call the module-level function\n        return angular_separation(lonp1, latp1, lonp2, latp2)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef uniformly_refine_triangulation(self, faces=False, trisect=False):\n\n        if faces:\n            lonv1, latv1 = self._add_face_centroids()\n\n        else:\n            if not trisect:\n                lonv1, latv1 = self._add_spherical_midpoints()\n            else:\n                lonv1, latv1 = self._add_spherical_tripoints(ratio=0.333333)\n\n\n        return lonv1, latv1", "response": "This method returns a tuple of lon latv1 lonv2 lonv1 latv1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the midpoints defining a refined triangulation obtained by bisection of all edges in the triangulation connected to any of the vertices in the list provided.", "response": "def midpoint_refine_triangulation_by_vertices(self, vertices):\n        \"\"\"\n        return points defining a refined triangulation obtained by bisection of all edges\n        in the triangulation connected to any of the vertices in the list provided\n        \"\"\"\n\n        mlons, mlats = self.segment_midpoints_by_vertices(vertices=vertices)\n\n        lonv1 = np.concatenate((self.lons, mlons), axis=0)\n        latv1 = np.concatenate((self.lats, mlats), axis=0)\n\n        return lonv1, latv1"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn points defining a refined triangulation obtained by bisection of all edges in the triangulation that are associated with the triangles in the list of indices provided. Notes ----- The triangles are here represented as a single index. The vertices of triangle i are given by self.simplices[i].", "response": "def edge_refine_triangulation_by_triangles(self, triangles):\n        \"\"\"\n        return points defining a refined triangulation obtained by bisection of all edges\n        in the triangulation that are associated with the triangles in the list\n        of indices provided.\n\n        Notes\n        -----\n         The triangles are here represented as a single index.\n         The vertices of triangle i are given by self.simplices[i].\n        \"\"\"\n\n        ## Note there should be no duplicates in the list of triangles\n        ## but because we remove duplicates from the list of all segments,\n        ## there is no pressing need to check this.\n\n        # identify the segments\n\n        simplices = self.simplices\n        segments = set()\n\n        for index in np.array(triangles).reshape(-1):\n            tri = simplices[index]\n            segments.add( min( tuple((tri[0], tri[1])), tuple((tri[1], tri[0]))) )\n            segments.add( min( tuple((tri[1], tri[2])), tuple((tri[2], tri[1]))) )\n            segments.add( min( tuple((tri[0], tri[2])), tuple((tri[2], tri[0]))) )\n\n        segs = np.array(list(segments))\n\n        mlons, mlats = self.segment_midpoints(segs)\n\n        lonv1 = np.concatenate((self.lons, mlons), axis=0)\n        latv1 = np.concatenate((self.lats, mlats), axis=0)\n\n        return lonv1, latv1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef centroid_refine_triangulation_by_triangles(self, triangles):\n\n        # Remove duplicates from the list of triangles\n\n        triangles = np.unique(np.array(triangles))\n\n        mlons, mlats = self.face_midpoints(simplices=self.simplices[triangles])\n\n        lonv1 = np.concatenate((self.lons, mlons), axis=0)\n        latv1 = np.concatenate((self.lats, mlats), axis=0)\n\n        return lonv1, latv1", "response": "Return the centroid of a refined triangulation obtained by bisection of all edges in the triangulation that are associated with the given triangles."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\njoin this triangulation with another triangulation.", "response": "def join(self, t2, unique=False):\n        \"\"\"\n        Join this triangulation with another. If the points are known to have no duplicates, then\n        set unique=True to skip the testing and duplicate removal\n        \"\"\"\n\n        lonv1 = np.concatenate((self.lons, t2.lons), axis=0)\n        latv1 = np.concatenate((self.lats, t2.lats), axis=0)\n\n        ## remove any duplicates\n\n        if not unique:\n            lonv1, latv1 = remove_duplicate_lonlat(lonv1, latv1)\n\n        return lonv1, latv1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef nearest_vertices(self, lon, lat, k=1, max_distance=2.0 ):\n\n        if self.tree == False or self.tree == None:\n            return 0, 0\n\n        lons = np.array(lon).reshape(-1,1)\n        lats = np.array(lat).reshape(-1,1)\n\n        xyz = np.empty((lons.shape[0],3))\n        x,y,z = lonlat2xyz(lons, lats)\n\n        xyz[:,0] = x[:].reshape(-1)\n        xyz[:,1] = y[:].reshape(-1)\n        xyz[:,2] = z[:].reshape(-1)\n\n        dxyz, vertices = self._cKDtree.query(xyz, k=k, distance_upper_bound=max_distance)\n\n\n        if k == 1:   # force this to be a 2D array\n            vertices = np.reshape(vertices, (-1, 1))\n\n        ## Now find the angular separation / great circle distance: dlatlon\n\n\n        vertxyz = self.points[vertices].transpose(0,2,1)\n        extxyz  = np.repeat(xyz, k, axis=1).reshape(vertxyz.shape)\n\n        angles = np.arccos((extxyz * vertxyz).sum(axis=1))\n\n        return angles, vertices", "response": "Query the cKDtree for nearest neighbours and return the nearest vertices."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfetching the request sent for a given batch.", "response": "def get_query_batch_request(self, batch_id, job_id=None):\n        \"\"\" Fetch the request sent for the batch. Note should only used for query batches \"\"\"\n        if not job_id:\n            job_id = self.lookup_job_id(batch_id)\n\n        url = self.endpoint + \"/job/{}/batch/{}/request\".format(job_id, batch_id)\n        resp = requests.get(url, headers=self.headers())\n        self.check_status(resp)\n        return resp.text"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef abort_job(self, job_id):\n        doc = self.create_abort_job_doc()\n        url = self.endpoint + \"/job/%s\" % job_id\n        resp = requests.post(\n            url,\n            headers=self.headers(),\n            data=doc\n        )\n        self.check_status(resp)", "response": "Abort a given bulk job"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_all_results_for_query_batch(self, batch_id, job_id=None, chunk_size=2048):\n        result_ids = self.get_query_batch_result_ids(batch_id, job_id=job_id)\n        if not result_ids:\n            raise RuntimeError('Batch is not complete')\n        for result_id in result_ids:\n            yield self.get_query_batch_results(\n                batch_id,\n                result_id,\n                job_id=job_id,\n                chunk_size=chunk_size\n            )", "response": "Gets all results from a batch and returns it as a generator"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef matchlist_by_account(\n        self,\n        region,\n        encrypted_account_id,\n        queue=None,\n        begin_time=None,\n        end_time=None,\n        begin_index=None,\n        end_index=None,\n        season=None,\n        champion=None,\n    ):\n        \"\"\"\n        Get matchlist for ranked games played on given account ID and platform ID\n        and filtered using given filter parameters, if any\n\n        A number of optional parameters are provided for filtering. It is up to the caller to\n        ensure that the combination of filter parameters provided is valid for the requested\n        account, otherwise, no matches may be returned.\n\n        Note that if either beginIndex or endIndex are specified, then both must be specified and\n        endIndex must be greater than beginIndex.\n\n        If endTime is specified, but not beginTime, then beginTime is effectively the start of the\n        account's match history.\n\n        If beginTime is specified, but not endTime, then endTime is effectively the current time.\n\n        Note that endTime should be greater than beginTime if both are specified, although there is\n        no maximum limit on their range.\n\n        :param string region:               The region to execute this request on\n        :param string encrypted_account_id: The account ID.\n        :param Set[int] queue:              Set of queue IDs for which to filtering matchlist.\n        :param long begin_time:             The begin time to use for filtering matchlist specified as\n                                            epoch milliseconds.\n        :param long end_time:               The end time to use for filtering matchlist specified as epoch\n                                            milliseconds.\n        :param int begin_index:             The begin index to use for filtering matchlist.\n        :param int end_index:               The end index to use for filtering matchlist.\n        :param Set[int] season:             Set of season IDs for which to filtering matchlist.\n        :param Set[int] champion:           Set of champion IDs for which to filtering matchlist.\n\n        :returns: MatchlistDto\n        \"\"\"\n        url, query = MatchApiV4Urls.matchlist_by_account(\n            region=region,\n            encrypted_account_id=encrypted_account_id,\n            queue=queue,\n            beginTime=begin_time,\n            endTime=end_time,\n            beginIndex=begin_index,\n            endIndex=end_index,\n            season=season,\n            champion=champion,\n        )\n        return self._raw_request(self.matchlist_by_account.__name__, region, url, query)", "response": "Returns a dictionary of all matchlists for a given account ID and optionally filtered by the given parameters."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting match timeline by match ID.", "response": "def timeline_by_match(self, region, match_id):\n        \"\"\"\n        Get match timeline by match ID.\n\n        Not all matches have timeline data.\n\n        :param string region: The region to execute this request on\n        :param long match_id: The match ID.\n\n        :returns: MatchTimelineDto\n        \"\"\"\n        url, query = MatchApiV4Urls.timeline_by_match(region=region, match_id=match_id)\n        return self._raw_request(self.timeline_by_match.__name__, region, url, query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef preview_request(self, region, endpoint_name, method_name, url, query_params):\n        wait_until = max(\n            [\n                (\n                    limiter.wait_until(region, endpoint_name, method_name),\n                    limiter.friendly_name,\n                )\n                for limiter in self._limiters\n            ],\n            key=lambda lim_pair: lim_pair[0]\n            if lim_pair[0]\n            else datetime.datetime(datetime.MINYEAR, 1, 1),\n        )\n\n        if wait_until[0] is not None and wait_until[0] > datetime.datetime.now():\n            to_wait = wait_until[0] - datetime.datetime.now()\n\n            logging.info(\n                \"waiting for %s seconds due to %s limit...\",\n                to_wait.total_seconds(),\n                wait_until[1],\n            )\n            time.sleep(to_wait.total_seconds())", "response": "This method is called before a request is processed."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncall by the API when a response is received from the Requests library.", "response": "def after_request(self, region, endpoint_name, method_name, url, response):\n        \"\"\"\n        Called after a response is received and before it is returned to the user.\n\n        :param string region: the region of this request\n        :param string endpoint_name: the name of the endpoint that was requested\n        :param string method_name: the name of the method that was requested\n        :param url: The url that was requested\n        :param response: the response received. This is a response from the Requests library\n        \"\"\"\n        for limiter in self._limiters:\n            limiter.update_limiter(region, endpoint_name, method_name, response)\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef shard_data(self, region):\n        url, query = LolStatusApiV3Urls.shard_data(region=region)\n        return self._raw_request(self.shard_data.__name__, region, url, query)", "response": "Get League of Legends status for the given shard."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef preview_request(self, region, endpoint_name, method_name, url, query_params):\n        if query_params is not None:\n            for key, value in query_params.items():\n                if isinstance(value, bool):\n                    query_params[key] = str(value).lower()\n\n                # check to see if we have a list/tuple, but not a string\n                if (\n                    not hasattr(value, \"strip\")\n                    and hasattr(value, \"__getitem__\")\n                    or hasattr(value, \"__iter__\")\n                ):\n                    for idx, val in enumerate(value):\n                        if isinstance(val, bool):\n                            value[idx] = str(val).lower()", "response": "This method is called before a request is processed."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_summoner_by_champion(self, region, encrypted_summoner_id, champion_id):\n        url, query = ChampionMasteryApiV4Urls.by_summoner_by_champion(\n            region=region,\n            encrypted_summoner_id=encrypted_summoner_id,\n            champion_id=champion_id,\n        )\n        return self._raw_request(\n            self.by_summoner_by_champion.__name__, region, url, query\n        )", "response": "Get a Champion Mastery by player and champion ID."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a summoner by account ID.", "response": "def by_account(self, region, encrypted_account_id):\n        \"\"\"\n        Get a summoner by account ID.\n\n        :param string region:               The region to execute this request on\n        :param string encrypted_account_id: The account ID.\n\n        :returns: SummonerDTO: represents a summoner\n        \"\"\"\n        url, query = SummonerApiV4Urls.by_account(\n            region=region, encrypted_account_id=encrypted_account_id\n        )\n        return self._raw_request(self.by_account.__name__, region, url, query)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef by_name(self, region, summoner_name):\n        url, query = SummonerApiV4Urls.by_name(\n            region=region, summoner_name=summoner_name\n        )\n        return self._raw_request(self.by_name.__name__, region, url, query)", "response": "Get a summoner by summoner name"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef by_puuid(self, region, encrypted_puuid):\n        url, query = SummonerApiV4Urls.by_puuid(\n            region=region, encrypted_puuid=encrypted_puuid\n        )\n        return self._raw_request(self.by_puuid.__name__, region, url, query)", "response": "Get a summoner by PUUID."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a summoner by summoner ID.", "response": "def by_id(self, region, encrypted_summoner_id):\n        \"\"\"\n        Get a summoner by summoner ID.\n\n        :param string region:                   The region to execute this request on\n        :param string encrypted_summoner_id:    Summoner ID\n\n        :returns: SummonerDTO: represents a summoner\n        \"\"\"\n        url, query = SummonerApiV4Urls.by_id(\n            region=region, encrypted_summoner_id=encrypted_summoner_id\n        )\n        return self._raw_request(self.by_id.__name__, region, url, query)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting list of featured games in a given region", "response": "def featured_games(self, region):\n        \"\"\"\n        Get list of featured games.\n\n        :param string region: The region to execute this request on\n\n        :returns: FeaturedGames\n        \"\"\"\n        url, query = SpectatorApiV4Urls.featured_games(region=region)\n        return self._raw_request(self.featured_games.__name__, region, url, query)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef by_summoner(self, region, encrypted_summoner_id):\n        url, query = ThirdPartyCodeApiV4Urls.by_summoner(\n            region=region, encrypted_summoner_id=encrypted_summoner_id\n        )\n\n        return self._raw_request(self.by_summoner.__name__, region, url, query)", "response": "This method returns a list of the Third Parties API V4 resources that are associated with a given summoner."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a request through the BaseApi instance provided injecting the endpoint_name and url into the HTTP request.", "response": "def _raw_request(self, method_name, region, url, query_params):\n        \"\"\"\n        Sends a request through the BaseApi instance provided, injecting the provided endpoint_name\n        into the method call, so the caller doesn't have to.\n\n        :param string method_name:  The name of the calling method\n        :param string region:       The region to execute this request on\n        :param string url:          The full URL to the method being requested.\n        :param dict query_params:   Query parameters to be provided in the HTTP request\n        \"\"\"\n        return self._base_api.raw_request(\n            self._endpoint_name, method_name, region, url, query_params\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef challenger_by_queue(self, region, queue):\n        url, query = LeagueApiV4Urls.challenger_by_queue(region=region, queue=queue)\n        return self._raw_request(self.challenger_by_queue.__name__, region, url, query)", "response": "Get the challenger league for a given queue"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the master league for a given queue", "response": "def masters_by_queue(self, region, queue):\n        \"\"\"\n        Get the master league for a given queue.\n\n        :param string region:   the region to execute this request on\n        :param string queue:    the queue to get the master players for\n\n        :returns: LeagueListDTO\n        \"\"\"\n        url, query = LeagueApiV4Urls.master_by_queue(region=region, queue=queue)\n        return self._raw_request(self.masters_by_queue.__name__, region, url, query)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef by_id(self, region, league_id):\n        url, query = LeagueApiV4Urls.by_id(region=region, league_id=league_id)\n        return self._raw_request(self.by_id.__name__, region, url, query)", "response": "Get a specific league list from the API."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef entries(self, region, queue, tier, division):\n        url, query = LeagueApiV4Urls.entries(\n            region=region, queue=queue, tier=tier, division=division\n        )\n        return self._raw_request(self.entries.__name__, region, url, query)", "response": "Get all the league entries for a given queue tier and division"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef rotations(self, region):\n        url, query = ChampionApiV3Urls.rotations(region=region)\n        return self._raw_request(self.rotations.__name__, region, url, query)", "response": "Returns a ChampionInfo object containing all available champion rotations for a given region."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the response Body", "response": "def get_body(self):\n        '''Get the response Body\n\n        :returns Body: A Body object containing the response.\n        '''\n        if self._body is None:\n            resp = self._dispatcher._dispatch(self.request)\n            self._body = self._create_body(resp)\n        return self._body"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads the last - modified header as a datetime if present.", "response": "def last_modified(self):\n        '''Read the last-modified header as a datetime, if present.'''\n        lm = self.response.headers.get('last-modified', None)\n        return datetime.strptime(lm, '%a, %d %b %Y %H:%M:%S GMT') if lm \\\n            else None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef write(self, file=None, callback=None):\n        '''Write the contents of the body to the optionally provided file and\n        providing progress to the optional callback. The callback will be\n        invoked 3 different ways:\n\n        * First as ``callback(start=self)``\n        * For each chunk of data written as\n          ``callback(wrote=chunk_size_in_bytes, total=all_byte_cnt)``\n        * Upon completion as ``callback(finish=self)``\n\n        :param file: file name or file-like object\n        :param callback: optional progress callback\n        '''\n        if not file:\n            file = self.name\n        if not file:\n            raise ValueError('no file name provided or discovered in response')\n        if hasattr(file, 'write'):\n            self._write(file, callback)\n        else:\n            with atomic_open(file, 'wb') as fp:\n                self._write(fp, callback)", "response": "Writes the contents of the object to the optionally provided file and optionally provides progress to the optional callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef iter(self, pages=None):\n        '''Get an iterator of pages.\n\n        :param int pages: optional limit to number of pages\n        :return: iter of this and subsequent pages\n        '''\n        i = self._pages()\n        if pages is not None:\n            i = itertools.islice(i, pages)\n        return i", "response": "Get an iterator of pages."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef json_encode(self, out, limit=None, sort_keys=False, indent=None):\n        '''Encode the results of this paged response as JSON writing to the\n        provided file-like `out` object. This function will iteratively read\n        as many pages as present, streaming the contents out as JSON.\n\n        :param file-like out: an object with a `write` function\n        :param int limit: optional maximum number of items to write\n        :param bool sort_keys: if True, output keys sorted, default is False\n        :param bool indent: if True, indent output, default is False\n        '''\n        stream = self._json_stream(limit)\n        enc = json.JSONEncoder(indent=indent, sort_keys=sort_keys)\n        for chunk in enc.iterencode(stream):\n            out.write(u'%s' % chunk)", "response": "Encode the results of this paged response as JSON writing to the file - like out object."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef items_iter(self, limit):\n        '''Get an iterator of the 'items' in each page. Instead of a feature\n        collection from each page, the iterator yields the features.\n\n        :param int limit: The number of 'items' to limit to.\n        :return: iter of items in page\n        '''\n\n        pages = (page.get() for page in self._pages())\n        items = itertools.chain.from_iterable(\n            (p[self.ITEM_KEY] for p in pages)\n        )\n        if limit is not None:\n            items = itertools.islice(items, limit)\n        return items", "response": "Get an iterator of the items in each page. Instead of a feature\n        collection from each page the iterator yields the features."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncreate a Downloader with the provided client.", "response": "def create(client, mosaic=False, **kw):\n    '''Create a Downloader with the provided client.\n\n    :param mosaic bool: If True, the Downloader will fetch mosaic quads.\n    :returns: :py:Class:`planet.api.downloader.Downloader`\n    '''\n    if mosaic:\n        return _MosaicDownloader(client, **kw)\n    else:\n        return _Downloader(client, **kw)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quick_search(limit, pretty, sort, **kw):\n    '''Execute a quick search.'''\n    req = search_req_from_opts(**kw)\n    cl = clientv1()\n    page_size = min(limit, 250)\n    echo_json_response(call_and_wrap(\n        cl.quick_search, req, page_size=page_size, sort=sort\n    ), pretty, limit)", "response": "Execute a quick search."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncreating a saved search", "response": "def create_search(pretty, **kw):\n    '''Create a saved search'''\n    req = search_req_from_opts(**kw)\n    cl = clientv1()\n    echo_json_response(call_and_wrap(cl.create_search, req), pretty)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexecutes a saved search", "response": "def saved_search(search_id, sort, pretty, limit):\n    '''Execute a saved search'''\n    sid = read(search_id)\n    cl = clientv1()\n    page_size = min(limit, 250)\n    echo_json_response(call_and_wrap(\n        cl.saved_search, sid, page_size=page_size, sort=sort\n    ), limit=limit, pretty=pretty)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef download(asset_type, dest, limit, sort, search_id, dry_run, activate_only,\n             quiet, **kw):\n    '''Activate and download'''\n    cl = clientv1()\n    page_size = min(limit or 250, 250)\n    asset_type = list(chain.from_iterable(asset_type))\n    # even though we're using functionality from click.Path, this was needed\n    # to detect inability to write on Windows in a read-only vagrant mount...\n    # @todo check/report upstream\n    if not activate_only and not check_writable(dest):\n        raise click.ClickException(\n            'download destination \"%s\" is not writable' % dest)\n    if search_id:\n        if dry_run:\n            raise click.ClickException(\n                'dry-run not supported with saved search')\n        if any(kw[s] for s in kw):\n            raise click.ClickException(\n                'search options not supported with saved search')\n        search, search_arg = cl.saved_search, search_id\n    else:\n        # any requested asset-types should be used as permission filters\n        kw['asset_type'] = [AssetTypePerm.to_permissions(asset_type)]\n        req = search_req_from_opts(**kw)\n        if dry_run:\n            req['interval'] = 'year'\n            stats = cl.stats(req).get()\n            item_cnt = sum([b['count'] for b in stats['buckets']])\n            asset_cnt = item_cnt * len(asset_type)\n            click.echo(\n                'would download approximately %d assets from %s items' %\n                (asset_cnt, item_cnt)\n            )\n            return\n        else:\n            search, search_arg = cl.quick_search, req\n\n    dl = downloader.create(cl)\n    output = downloader_output(dl, disable_ansi=quiet)\n    # delay initial item search until downloader output initialized\n    output.start()\n    try:\n        items = search(search_arg, page_size=page_size, sort=sort)\n    except Exception as ex:\n        output.cancel()\n        click_exception(ex)\n    func = dl.activate if activate_only else dl.download\n    args = [items.items_iter(limit), asset_type]\n    if not activate_only:\n        args.append(dest)\n    # invoke the function within an interrupt handler that will shut everything\n    # down properly\n    handle_interrupt(dl.shutdown, func, *args)", "response": "Download assets from the specified asset - type to the specified destination."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsearch mosaics by name", "response": "def search_mosaics(name, bbox, rbox, limit, pretty):\n    '''Get quad IDs and information for a mosaic'''\n    bbox = bbox or rbox\n    cl = clientv1()\n    mosaic, = cl.get_mosaic_by_name(name).items_iter(1)\n    response = call_and_wrap(cl.get_quads, mosaic, bbox)\n    echo_json_response(response, pretty, limit)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting information for a specific mosaic", "response": "def mosaic_info(name, pretty):\n    '''Get information for a specific mosaic'''\n    cl = clientv1()\n    echo_json_response(call_and_wrap(cl.get_mosaic_by_name, name), pretty)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef quad_info(name, quad, pretty):\n    '''Get information for a specific mosaic quad'''\n    cl = clientv1()\n    mosaic, = cl.get_mosaic_by_name(name).items_iter(1)\n    echo_json_response(call_and_wrap(cl.get_quad_by_id, mosaic, quad), pretty)", "response": "Get information for a specific mosaic quad"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef quad_contributions(name, quad, pretty):\n    '''Get contributing scenes for a mosaic quad'''\n    cl = clientv1()\n    mosaic, = cl.get_mosaic_by_name(name).items_iter(1)\n    quad = cl.get_quad_by_id(mosaic, quad).get()\n    response = call_and_wrap(cl.get_quad_contributions, quad)\n    echo_json_response(response, pretty)", "response": "Get contributing scenes for a mosaic quad"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndownloading quads from a mosaic", "response": "def download_quads(name, bbox, rbox, quiet, dest, limit):\n    '''Download quads from a mosaic'''\n    bbox = bbox or rbox\n    cl = clientv1()\n\n    dl = downloader.create(cl, mosaic=True)\n    output = downloader_output(dl, disable_ansi=quiet)\n    output.start()\n    try:\n        mosaic, = cl.get_mosaic_by_name(name).items_iter(1)\n        items = cl.get_quads(mosaic, bbox).items_iter(limit)\n    except Exception as ex:\n        output.cancel()\n        click_exception(ex)\n    # invoke the function within an interrupt handler that will shut everything\n    # down properly\n    handle_interrupt(dl.shutdown, dl.download, items, [], dest)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure logging via verbosity level of between 0 and 2 corresponding to log levels warning info and debug respectfully.", "response": "def configure_logging(verbosity):\n    '''configure logging via verbosity level of between 0 and 2 corresponding\n    to log levels warning, info and debug respectfully.'''\n    log_level = max(logging.DEBUG, logging.WARNING - logging.DEBUG*verbosity)\n    logging.basicConfig(\n        stream=sys.stderr, level=log_level,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n\n    urllib3_logger = logging.getLogger(\n        'requests.packages.urllib3')\n    urllib3_logger.setLevel(log_level)\n\n    # if debug level set then its nice to see the headers of the request\n    if log_level == logging.DEBUG:\n        try:\n            import http.client as http_client\n        except ImportError:\n            # Python 2\n            import httplib as http_client\n        http_client.HTTPConnection.debuglevel = 1"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef init(email, password):\n    '''Login using email/password'''\n    response = call_and_wrap(clientv1().login, email, password)\n    write_planet_json({'key': response['api_key']})\n    click.echo('initialized')", "response": "Login using email and password"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ntries to find a geometry in the provided JSON object", "response": "def geometry_from_json(obj):\n    '''try to find a geometry in the provided JSON object'''\n    obj_type = obj.get('type', None)\n    if not obj_type:\n        return None\n    if obj_type == 'FeatureCollection':\n        features = obj.get('features', [])\n        if len(features):\n            obj = obj['features'][0]\n            obj_type = obj.get('type', None)\n        else:\n            return None\n    if obj_type == 'Feature':\n        geom = obj['geometry']\n    else:\n        geom = obj\n    # @todo we're just assuming it's a geometry at this point\n    if 'coordinates' in geom:\n        return geom"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef check_status(response):\n    '''check the status of the response and if needed raise an APIException'''\n    status = response.status_code\n    if status < 300:\n        return\n    exception = {\n        400: exceptions.BadQuery,\n        401: exceptions.InvalidAPIKey,\n        403: exceptions.NoPermission,\n        404: exceptions.MissingResource,\n        429: exceptions.TooManyRequests,\n        500: exceptions.ServerError\n    }.get(status, None)\n\n    # differentiate between over quota and rate-limiting\n    if status == 429 and 'quota' in response.text.lower():\n        exception = exceptions.OverQuota\n\n    if exception:\n        raise exception(response.text)\n\n    raise exceptions.APIException('%s: %s' % (status, response.text))", "response": "check the status of the response and if needed raise an APIException"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_filename(response):\n    name = (get_filename_from_headers(response.headers) or\n            get_filename_from_url(response.url) or\n            get_random_filename(response.headers.get('content-type')))\n    return name", "response": "Derive a filename from the given response."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_filename_from_headers(headers):\n    cd = headers.get('content-disposition', '')\n    match = re.search('filename=\"?([^\"]+)\"?', cd)\n    return match.group(1) if match else None", "response": "Get a filename from the Content - Disposition header if available."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget a filename from a URL.", "response": "def get_filename_from_url(url):\n    \"\"\"Get a filename from a URL.\n\n    >>> from planet.api import utils\n    >>> urls = [\n    ...     'https://planet.com/',\n    ...     'https://planet.com/path/to/',\n    ...     'https://planet.com/path/to/example.tif',\n    ...     'https://planet.com/path/to/example.tif?foo=f6f1&bar=baz',\n    ...     'https://planet.com/path/to/example.tif?foo=f6f1&bar=baz#quux'\n    ... ]\n    >>> for url in urls:\n    ...     print('{} -> {}'.format(url, utils.get_filename_from_url(url)))\n    ...\n    https://planet.com/ -> None\n    https://planet.com/path/to/ -> None\n    https://planet.com/path/to/example.tif -> example.tif\n    https://planet.com/path/to/example.tif?foo=f6f1&bar=baz -> example.tif\n    https://planet.com/path/to/example.tif?foo=f6f1&bar=baz#quux -> example.tif\n    >>>\n\n    :returns: a filename (i.e. ``basename``)\n    :rtype: str or None\n    \"\"\"\n    path = urlparse(url).path\n    name = path[path.rfind('/')+1:]\n    return name or None"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_random_filename(content_type=None):\n    extension = mimetypes.guess_extension(content_type or '') or ''\n    characters = string.ascii_letters + '0123456789'\n    letters = ''.join(random.sample(characters, 8))\n    name = 'planet-{}{}'.format(letters, extension)\n    return name", "response": "Get a pseudo - random Planet - lookinging filename."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_to_file(directory=None, callback=None, overwrite=True):\n    '''Create a callback handler for asynchronous Body handling.\n\n    If provided, the callback will be invoked as described in\n    :py:meth:`planet.api.models.Body.write`. In addition, if the download\n    is skipped because the destination exists, the callback will be invoked\n    with ``callback(skip=body)``.\n\n    The name of the file written to will be determined from the Body.name\n    property.\n\n    :param directory str: The optional directory to write to.\n    :param callback func: An optional callback to receive notification of\n                          write progress.\n    :param overwrite bool: Overwrite any existing files. Defaults to True.\n    '''\n\n    def writer(body):\n        file = os.path.join(directory or '.', body.name)\n        if overwrite or not os.path.exists(file):\n            body.write(file, callback)\n        else:\n            if callback:\n                callback(skip=body)\n            body.response.close()\n    return writer", "response": "Create a callback handler for asynchronous Body handling."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef probably_geojson(input):\n    '''A quick check to see if this input looks like GeoJSON. If not a dict\n    JSON-like object, attempt to parse input as JSON. If the resulting object\n    has a type property that looks like GeoJSON, return that object or None'''\n    valid = False\n    if not isinstance(input, dict):\n        try:\n            input = json.loads(input)\n        except ValueError:\n            return None\n    typename = input.get('type', None)\n    supported_types = set([\n        'Point', 'LineString', 'Polygon', 'MultiPoint', 'MultiLineString',\n        'MultiPolygon', 'GeometryCollection', 'Feature', 'FeatureCollection'\n    ])\n    valid = typename in supported_types\n    return input if valid else None", "response": "A quick check to see if this input looks like GeoJSON. If not a dict\n    attempt to parse input as JSON and return that object or None."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nexecutes a function f with a KeyboardInterrupt and if there is an interrupt in the sequence return the result.", "response": "def handle_interrupt(cancel, f, *a, **kw):\n    '''Execute a function f(*a, **kw) listening for KeyboardInterrupt and if\n    handled, invoke the cancel function. Blocks until f is complete or the\n    interrupt is handled.\n    '''\n    res = []\n\n    def run():\n        res.append(f(*a, **kw))\n    t = threading.Thread(target=run)\n    t.start()\n    # poll (or we miss the interrupt) and await completion\n    try:\n        while t.isAlive():\n            t.join(.1)\n    except KeyboardInterrupt:\n        cancel()\n        raise\n    return res and res.pop()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _patch_stats_request(request):\n    '''If the request has no filter config, add one that should do what is\n    expected (include all items)\n    see: PE-11813\n    '''\n    filt = request.get('filter', {})\n    if not filt.get('config', None):\n        request['filter'] = filters.date_range('acquired',\n                                               gt='1970-01-01T00:00:00Z')\n    return request", "response": "Patch the request to include the items that have not been marked as acquired"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef login(self, identity, credentials):\n        '''Login using email identity and credentials. Returns a JSON\n        object containing an `api_key` property with the user's API_KEY.\n        :param str identity: email\n        :param str credentials: password\n        :returns: JSON object (Python dict)\n        '''\n        result = self.dispatcher.session.post(self._url('v0/auth/login'),\n                                              json={\n                                                  'email': identity,\n                                                  'password': credentials\n                                              })\n        status = result.status_code\n        if status == 400:\n            raise APIException('invalid parameters, login process has changed')\n        elif status == 401:\n            # do our best to get something out to the user\n            msg = result.text\n            try:\n                msg = json.loads(result.text)['message']\n            finally:\n                raise InvalidIdentity(msg)\n        elif status != 200:\n            raise APIException('%s: %s' % (status, result.text))\n        jwt = result.text\n        payload = jwt.split('.')[1]\n        rem = len(payload) % 4\n        if rem > 0:\n            payload += '=' * (4 - rem)\n        payload = base64.urlsafe_b64decode(payload.encode('utf-8'))\n        return json.loads(payload.decode('utf-8'))", "response": "Login using email identity and credentials. Returns a JSON object containing an API_KEY property with the user s API_KEY property with the user s API_KEY property."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nexecute a quick search with the specified request.", "response": "def quick_search(self, request, **kw):\n        '''Execute a quick search with the specified request.\n\n        :param request: see :ref:`api-search-request`\n        :param **kw: See Options below\n        :returns: :py:class:`planet.api.models.Items`\n        :raises planet.api.exceptions.APIException: On API error.\n\n        :Options:\n\n        * page_size (int): Size of response pages\n        * sort (string): Sorting order in the form `field (asc|desc)`\n\n        '''\n        body = json.dumps(request)\n        params = self._params(kw)\n        return self.dispatcher.response(models.Request(\n            self._url('data/v1/quick-search'), self.auth, params=params,\n            body_type=models.Items, data=body, method='POST')).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nexecutes a saved search by search id.", "response": "def saved_search(self, sid, **kw):\n        '''Execute a saved search by search id.\n\n        :param sid string: The id of the search\n        :returns: :py:class:`planet.api.models.Items`\n        :raises planet.api.exceptions.APIException: On API error.\n\n        :Options:\n\n        * page_size (int): Size of response pages\n        * sort (string): Sorting order in the form `field (asc|desc)`\n\n        '''\n        path = 'data/v1/searches/%s/results' % sid\n        params = self._params(kw)\n        return self._get(self._url(path), body_type=models.Items,\n                         params=params).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_searches(self, quick=False, saved=True):\n        '''Get searches listing.\n\n        :param quick bool: Include quick searches (default False)\n        :param quick saved: Include saved searches (default True)\n        :returns: :py:class:`planet.api.models.Searches`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        params = {}\n        if saved and not quick:\n            params['search_type'] = 'saved'\n        elif quick:\n            params['search_type'] = 'quick'\n        return self._get(self._url('data/v1/searches/'),\n                         body_type=models.Searches, params=params).get_body()", "response": "Get searches listing.\n\n        :param quick bool: Include quick searches (default False)\n        :param quick saved: Include saved searches (default True)\n        :returns: :py:class:`planet.api.models.Searches`\n        :raises planet.api.exceptions.APIException: On API error."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef stats(self, request):\n        '''Get stats for the provided request.\n\n        :param request dict: A search request that also contains the 'interval'\n                             property.\n        :returns: :py:class:`planet.api.models.JSON`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        # work-around for API bug\n        request = _patch_stats_request(request)\n        body = json.dumps(request)\n        return self.dispatcher.response(models.Request(\n            self._url('data/v1/stats'), self.auth,\n            body_type=models.JSON, data=body, method='POST')).get_body()", "response": "Get stats for the provided request."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrequesting activation of the specified asset representation.", "response": "def activate(self, asset):\n        '''Request activation of the specified asset representation.\n\n        Asset representations are obtained from :py:meth:`get_assets`.\n\n        :param request dict: An asset representation from the API.\n        :returns: :py:class:`planet.api.models.Body` with no response content\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        activate_url = asset['_links']['activate']\n        return self._get(activate_url, body_type=models.Body).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef download(self, asset, callback=None):\n        '''Download the specified asset. If provided, the callback will be\n        invoked asynchronously. Otherwise it is up to the caller to handle the\n        response Body.\n\n        :param asset dict: An asset representation from the API\n        :param callback: An optional function to aysnchronsously handle the\n                         download. See :py:func:`planet.api.write_to_file`\n        :returns: :py:Class:`planet.api.models.Response` containing a\n                  :py:Class:`planet.api.models.Body` of the asset.\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        download_url = asset['location']\n        return self._get(download_url, models.Body, callback=callback)", "response": "Download the specified asset."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_item(self, item_type, id):\n        '''Get the an item response for the given item_type and id\n\n        :param item_type str: A valid item-type\n        :param id str: The id of the item\n        :returns: :py:Class:`planet.api.models.JSON`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        url = 'data/v1/item-types/%s/items/%s' % (item_type, id)\n        return self._get(url).get_body()", "response": "Get the an item response for the given item_type and id"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting an item s asset response for the given item_type and id", "response": "def get_assets_by_id(self, item_type, id):\n        '''Get an item's asset response for the given item_type and id\n\n        :param item_type str: A valid item-type\n        :param id str: The id of the item\n        :returns: :py:Class:`planet.api.models.JSON`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        url = 'data/v1/item-types/%s/items/%s/assets' % (item_type, id)\n        return self._get(url).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting information for all mosaics accessible by the current user.", "response": "def get_mosaics(self):\n        '''Get information for all mosaics accessible by the current user.\n\n        :returns: :py:Class:`planet.api.models.Mosaics`\n        '''\n        url = self._url('basemaps/v1/mosaics')\n        return self._get(url, models.Mosaics).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_mosaic_by_name(self, name):\n        '''Get the API representation of a mosaic by name.\n\n        :param name str: The name of the mosaic\n        :returns: :py:Class:`planet.api.models.Mosaics`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        params = {'name__is': name}\n        url = self._url('basemaps/v1/mosaics')\n        return self._get(url, models.Mosaics, params=params).get_body()", "response": "Get the API representation of a mosaic by name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_quads(self, mosaic, bbox=None):\n        '''Search for quads from a mosaic that are inside the specified\n        bounding box.  Will yield all quads if no bounding box is specified.\n\n        :param mosaic dict: A mosaic representation from the API\n        :param bbox tuple: A lon_min, lat_min, lon_max, lat_max area to search\n        :returns: :py:Class:`planet.api.models.MosaicQuads`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        if bbox is None:\n            # Some bboxes can slightly exceed backend min/max latitude bounds\n            xmin, ymin, xmax, ymax = mosaic['bbox']\n            bbox = (max(-180, xmin), max(-85, ymin),\n                    min(180, xmax), min(85, ymax))\n        url = mosaic['_links']['quads']\n        url = url.format(lx=bbox[0], ly=bbox[1], ux=bbox[2], uy=bbox[3])\n        return self._get(url, models.MosaicQuads).get_body()", "response": "Search for quads from a mosaic that are inside the specified bounding box. Will yield all quads."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a specific mosaic and quad.", "response": "def get_quad_by_id(self, mosaic, quad_id):\n        '''Get a quad response for a specific mosaic and quad.\n\n        :param mosaic dict: A mosaic representation from the API\n        :param quad_id str: A quad id (typically <xcoord>-<ycoord>)\n        :returns: :py:Class:`planet.api.models.JSON`\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        path = 'basemaps/v1/mosaics/{}/quads/{}'.format(mosaic['id'], quad_id)\n        return self._get(self._url(path)).get_body()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef download_quad(self, quad, callback=None):\n        '''Download the specified mosaic quad. If provided, the callback will\n        be invoked asynchronously.  Otherwise it is up to the caller to handle\n        the response Body.\n\n        :param asset dict: A mosaic quad representation from the API\n        :param callback: An optional function to aysnchronsously handle the\n                         download. See :py:func:`planet.api.write_to_file`\n        :returns: :py:Class:`planet.api.models.Response` containing a\n                  :py:Class:`planet.api.models.Body` of the asset.\n        :raises planet.api.exceptions.APIException: On API error.\n        '''\n        download_url = quad['_links']['download']\n        return self._get(download_url, models.Body, callback=callback)", "response": "Download the specified mosaic quad."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef and_filter_from_opts(opts):\n    '''build an AND filter from the provided opts dict as passed to a command\n    from the filter_options decorator. Assumes all dict values are lists of\n    filter dict constructs.'''\n    return filters.and_filter(*list(chain.from_iterable([\n        o for o in opts.values() if o]\n    )))", "response": "build an AND filter from the provided opts dict as passed to a command\n    from the filter_options decorator. Assumes all dict values are lists of\n    filter dict constructs."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef filter_from_opts(**kw):\n    '''Build a AND filter from the provided kwargs defaulting to an\n    empty 'and' filter (@todo: API workaround) if nothing is provided.\n\n    If the 'filter_json' argument is provided, this will be assumed to contain\n    a filter specification and will be anded with other filters. If the\n    'filter_json' is a search, the search filter value will be used.\n\n    All kw values should be tuple or list\n    '''\n    filter_in = kw.pop('filter_json', None)\n    active = and_filter_from_opts(kw)\n    if filter_in:\n        filter_in = filter_in.get('filter', filter_in)\n        if len(active['config']) > 0:\n            active = filters.and_filter(active, filter_in)\n        else:\n            active = filter_in\n    return active", "response": "Build an AND filter from the provided kwargs"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncalling the provided function and wrap any API exception with a click_exception exception", "response": "def call_and_wrap(func, *args, **kw):\n    '''call the provided function and wrap any API exception with a click\n    exception. this means no stack trace is visible to the user but instead\n    a (hopefully) nice message is provided.\n    note: could be a decorator but didn't play well with click\n    '''\n    try:\n        return func(*args, **kw)\n    except api.exceptions.APIException as ex:\n        click_exception(ex)\n    except urllib3exc.SSLError:\n        # see monkey patch above re InsecurePlatformWarning\n        if _insecure_warning:\n            click.echo(click.style(str(_insecure_warning[0]), fg='red'))\n        raise"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwrapping to echo JSON with optional pretty printing.", "response": "def echo_json_response(response, pretty, limit=None, ndjson=False):\n    '''Wrapper to echo JSON with optional 'pretty' printing. If pretty is not\n    provided explicity and stdout is a terminal (and not redirected or piped),\n    the default will be to indent and sort keys'''\n    indent = None\n    sort_keys = False\n    nl = False\n    if not ndjson and (pretty or (pretty is None and sys.stdout.isatty())):\n        indent = 2\n        sort_keys = True\n        nl = True\n    try:\n        if ndjson and hasattr(response, 'items_iter'):\n            items = response.items_iter(limit)\n            for item in items:\n                click.echo(json.dumps(item))\n        elif not ndjson and hasattr(response, 'json_encode'):\n            response.json_encode(click.get_text_stream('stdout'), limit=limit,\n                                 indent=indent, sort_keys=sort_keys)\n        else:\n            res = response.get_raw()\n            res = json.dumps(json.loads(res), indent=indent,\n                             sort_keys=sort_keys)\n            click.echo(res)\n        if nl:\n            click.echo()\n    except IOError as ioe:\n        # hide scary looking broken pipe stack traces\n        raise click.ClickException(str(ioe))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef read(value, split=False):\n    '''Get the value of an option interpreting as a file implicitly or\n    explicitly and falling back to the value if not explicitly specified.\n    If the value is '@name', then a file must exist with name and the returned\n    value will be the contents of that file. If the value is '@-' or '-', then\n    stdin will be read and returned as the value. Finally, if a file exists\n    with the provided value, that file will be read. Otherwise, the value\n    will be returned.\n    '''\n    v = str(value)\n    retval = value\n    if v[0] == '@' or v == '-':\n        fname = '-' if v == '-' else v[1:]\n        try:\n            with click.open_file(fname) as fp:\n                if not fp.isatty():\n                    retval = fp.read()\n                else:\n                    retval = None\n        # @todo better to leave as IOError and let caller handle it\n        # to better report in context of call (e.g. the option/type)\n        except IOError as ioe:\n            # if explicit and problems, raise\n            if v[0] == '@':\n                raise click.ClickException(str(ioe))\n    elif path.exists(v) and path.isfile(v):\n        with click.open_file(v) as fp:\n            retval = fp.read()\n    if retval and split and type(retval) != tuple:\n        retval = _split(retval.strip())\n    return retval", "response": "Get the value of an option interpreting as a file implicitly or explicitly specified falling back to the value if not explicitly specified."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef build_search_request(filter_like, item_types, name=None, interval=None):\n    '''Build a data-api search request body for the specified item_types.\n    If 'filter_like' is a request, item_types will be merged and, if name or\n    interval is provided, will replace any existing values.\n\n    :param dict filter_like: a filter or request with a filter\n    :param sequence(str) item_types: item-types to specify in the request\n    :param str name: optional name\n    :param str interval: optional interval [year, month, week, day]\n    '''\n    filter_spec = filter_like.get('filter', filter_like)\n    all_items = list(set(filter_like.get('item_types', [])).union(item_types))\n    name = filter_like.get('name', name)\n    interval = filter_like.get('interval', interval)\n    req = {'item_types': all_items, 'filter': filter_spec}\n    if name:\n        req['name'] = name\n    if interval:\n        req['interval'] = interval\n    return req", "response": "Build a data - api search request body for the specified item_types."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef date_range(field_name, **kwargs):\n    '''Build a DateRangeFilter.\n\n    Predicate arguments accept a value str that in ISO-8601 format or a value\n    that has a `isoformat` callable that returns an ISO-8601 str.\n\n    :raises: ValueError if predicate value does not parse\n\n    >>> date_range('acquired', gt='2017') == \\\n    {'config': {'gt': '2017-01-01T00:00:00Z'}, \\\n    'field_name': 'acquired', 'type': 'DateRangeFilter'}\n    True\n    '''\n    for k, v in kwargs.items():\n        dt = v\n        if not hasattr(v, 'isoformat'):\n            dt = strp_lenient(str(v))\n            if dt is None:\n                raise ValueError(\"unable to use provided time: \" + str(v))\n        kwargs[k] = dt.isoformat() + 'Z'\n    return _filter('DateRangeFilter', config=kwargs, field_name=field_name)", "response": "Build a DateRangeFilter.\n\n    Predicate arguments accept a value str that in ISO-8601 format or a value\n    that has a `isoformat` callable that returns an ISO-8601 str.\n\n    :raises: ValueError if predicate value does not parse\n\n    >>> date_range('acquired', gt='2017') == \\\n    {'config': {'gt': '2017-01-01T00:00:00Z'}, \\\n    'field_name': 'acquired', 'type': 'DateRangeFilter'}\n    True"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, value):\n        config = self.get_block('vrf definition %s' % value)\n        if not config:\n            return None\n        response = dict(vrf_name=value)\n        response.update(self._parse_rd(config))\n        response.update(self._parse_description(config))\n        config = self.get_block('no ip routing vrf %s' % value)\n        if config:\n            response['ipv4_routing'] = False\n        else:\n            response['ipv4_routing'] = True\n        config = self.get_block('no ipv6 unicast-routing vrf %s' % value)\n        if config:\n            response['ipv6_routing'] = False\n        else:\n            response['ipv6_routing'] = True\n\n        return response", "response": "Returns the VRF configuration as a resource dict."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning the provided configuration block and extracts the vrf rd from the resource dict.", "response": "def _parse_rd(self, config):\n        \"\"\" _parse_rd scans the provided configuration block and extracts\n        the vrf rd. The return dict is intended to be merged into the response\n        dict.\n\n        Args:\n            config (str): The vrf configuration block from the nodes running\n                configuration\n\n        Returns:\n            dict: resource dict attribute\n        \"\"\"\n        match = RD_RE.search(config)\n        if match:\n            value = match.group('value')\n        else:\n            value = match\n        return dict(rd=value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscan the provided configuration block and extracts the vrf description value from the resource dict.", "response": "def _parse_description(self, config):\n        \"\"\" _parse_description scans the provided configuration block and\n        extracts the vrf description value. The return dict is intended to\n        be merged into the response dict.\n\n        Args:\n            config (str): The vrf configuration block from the nodes\n                running configuration\n\n        Returns:\n            dict: resource dict attribute\n        \"\"\"\n        value = DESCRIPTION_RE.search(config).group('value')\n        return dict(description=value)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef getall(self):\n        vrfs_re = re.compile(r'(?<=^vrf definition\\s)(\\w+)', re.M)\n\n        response = dict()\n        for vrf in vrfs_re.findall(self.config):\n            response[vrf] = self.get(vrf)\n        return response", "response": "Returns a dict object of all VRFs in the running - config"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create(self, vrf_name, rd=None):\n        commands = ['vrf definition %s' % vrf_name]\n        if rd:\n            commands.append('rd %s' % rd)\n        return self.configure(commands)", "response": "Creates a new VRF resource."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef configure_vrf(self, vrf_name, commands):\n        commands = make_iterable(commands)\n        commands.insert(0, 'vrf definition %s' % vrf_name)\n        return self.configure(commands)", "response": "Configure the specified VRF using commands\n           "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_rd(self, vrf_name, rd):\n        cmds = self.command_builder('rd', value=rd)\n        return self.configure_vrf(vrf_name, cmds)", "response": "Configures the RD of the specified VRF."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconfiguring the VRF description to be the specified string", "response": "def set_description(self, vrf_name, description=None, default=False,\n                        disable=False):\n        \"\"\" Configures the VRF description\n\n        Args:\n            vrf_name (str): The VRF name to configure\n            description(str): The string to set the vrf description to\n            default (bool): Configures the vrf description to its default value\n            disable (bool): Negates the vrf description\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        cmds = self.command_builder('description', value=description,\n                                    default=default, disable=disable)\n        return self.configure_vrf(vrf_name, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the ipv4 routing for the given VRF.", "response": "def set_ipv4_routing(self, vrf_name, default=False, disable=False):\n        \"\"\" Configures ipv4 routing for the vrf\n\n        Args:\n            vrf_name (str): The VRF name to configure\n            default (bool): Configures ipv4 routing for the vrf value to\n                default if this value is true\n            disable (bool): Negates the ipv4 routing for the vrf if set to true\n\n        Returns:\n            True if the operation was successful otherwise False\n\n        \"\"\"\n        cmd = 'ip routing vrf %s' % vrf_name\n        if default:\n            cmd = 'default %s' % cmd\n        elif disable:\n            cmd = 'no %s' % cmd\n        cmd = make_iterable(cmd)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a VRF to an existing interface", "response": "def set_interface(self, vrf_name, interface, default=False, disable=False):\n        \"\"\" Adds a VRF to an interface\n\n        Notes:\n            Requires interface to be in routed mode. Must apply ip address\n            after VRF has been applied. This feature can also be accessed\n            through the interfaces api.\n\n        Args:\n            vrf_name (str): The VRF name to configure\n            interface (str): The interface to add the VRF too\n            default (bool): Set interface VRF forwarding to default\n            disable (bool): Negate interface VRF forwarding\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        cmds = ['interface %s' % interface]\n        cmds.append(self.command_builder('vrf forwarding', value=vrf_name,\n                                         default=default, disable=disable))\n        return self.configure(cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self, name):\n\n        # Validate the interface and vrid are specified\n        interface = name\n        if not interface:\n            raise ValueError(\"Vrrp.get(): interface must contain a value.\")\n\n        # Get the config for the interface. Return None if the\n        # interface is not defined\n        config = self.get_block('interface %s' % interface)\n        if config is None:\n            return config\n\n        # Find all occurrences of vrids in this interface and make\n        # a set of the unique vrid numbers\n        match = set(re.findall(r'^\\s+(?:no |)vrrp (\\d+)', config, re.M))\n        if not match:\n            return None\n\n        # Initialize the result dict\n        result = dict()\n\n        for vrid in match:\n            subd = dict()\n\n            # Parse the vrrp configuration for the vrid(s) in the list\n            subd.update(self._parse_delay_reload(config, vrid))\n            subd.update(self._parse_description(config, vrid))\n            subd.update(self._parse_enable(config, vrid))\n            subd.update(self._parse_ip_version(config, vrid))\n            subd.update(self._parse_mac_addr_adv_interval(config, vrid))\n            subd.update(self._parse_preempt(config, vrid))\n            subd.update(self._parse_preempt_delay_min(config, vrid))\n            subd.update(self._parse_preempt_delay_reload(config, vrid))\n            subd.update(self._parse_primary_ip(config, vrid))\n            subd.update(self._parse_priority(config, vrid))\n            subd.update(self._parse_secondary_ip(config, vrid))\n            subd.update(self._parse_timers_advertise(config, vrid))\n            subd.update(self._parse_track(config, vrid))\n            subd.update(self._parse_bfd_ip(config, vrid))\n\n            result.update({int(vrid): subd})\n\n        # If result dict is empty, return None, otherwise return result\n        return result if result else None", "response": "Get the vrrp configurations for a single node interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the vrrp configurations for all interfaces on a node", "response": "def getall(self):\n        \"\"\"Get the vrrp configurations for all interfaces on a node\n\n        Returns:\n            A dictionary containing the vrrp configurations on the node,\n            keyed by interface.\n        \"\"\"\n\n        vrrps = dict()\n\n        # Find the available interfaces\n        interfaces = re.findall(r'^interface\\s(\\S+)', self.config, re.M)\n\n        # Get the vrrps defined for each interface\n        for interface in interfaces:\n            vrrp = self.get(interface)\n            # Only add those interfaces that have vrrps defined\n            if vrrp:\n                vrrps.update({interface: vrrp})\n\n        return vrrps"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, interface, vrid, **kwargs):\n\n        if 'enable' not in kwargs:\n            kwargs['enable'] = False\n\n        return self._vrrp_set(interface, vrid, **kwargs)", "response": "Creates a vrrp instance from an interface and vrid number."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndeletes a vrrp instance from an interface", "response": "def delete(self, interface, vrid):\n        \"\"\"Deletes a vrrp instance from an interface\n\n        Note:\n            This method will attempt to delete the vrrp from the node's\n            operational config. If the vrrp does not exist on the\n            interface then this method will not perform any changes\n            but still return True\n\n        Args:\n            interface (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be deleted.\n\n        Returns:\n            True if the vrrp could be deleted otherwise False (see Node)\n\n        \"\"\"\n\n        vrrp_str = \"no vrrp %d\" % vrid\n        return self.configure_interface(interface, vrrp_str)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default(self, interface, vrid):\n\n        vrrp_str = \"default vrrp %d\" % vrid\n        return self.configure_interface(interface, vrrp_str)", "response": "Default the vrrp instance on the node with the specified vrid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_enable(self, name, vrid, value=False, run=True):\n\n        if value is False:\n            cmd = \"vrrp %d shutdown\" % vrid\n        elif value is True:\n            cmd = \"no vrrp %d shutdown\" % vrid\n        else:\n            raise ValueError(\"vrrp property 'enable' must be \"\n                             \"True or False\")\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmd)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmd", "response": "Set the enable property of the vrrp with the given vrid."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_primary_ip(self, name, vrid, value=None, disable=False,\n                       default=False, run=True):\n        \"\"\"Set the primary_ip property of the vrrp\n\n        Args:\n            name (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be managed.\n            value (string): IP address to be set.\n            disable (boolean): Unset primary ip if True.\n            default (boolean): Set primary ip to default if True.\n            run (boolean): Set to True to execute the command, False to\n                return a string with the formatted command.\n\n        Returns:\n            If run is True, returns True if the command executed successfully,\n            error if failure.\n\n            If run is False, returns the formatted command string which can\n            be passed to the node\n\n        \"\"\"\n\n        if default is True:\n            vrrps = self.get(name)\n            primary_ip = vrrps[vrid]['primary_ip']\n            cmd = \"default vrrp %d ip %s\" % (vrid, primary_ip)\n        elif disable is True or value is None:\n            vrrps = self.get(name)\n            primary_ip = vrrps[vrid]['primary_ip']\n            cmd = \"no vrrp %d ip %s\" % (vrid, primary_ip)\n        elif re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', str(value)):\n            cmd = \"vrrp %d ip %s\" % (vrid, value)\n        else:\n            raise ValueError(\"vrrp property 'primary_ip' must be \"\n                             \"a properly formatted IP address\")\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmd)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmd", "response": "Set the primary ip property of the vrrp with the given vrid."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_priority(self, name, vrid, value=None, disable=False,\n                     default=False, run=True):\n        \"\"\"Set the primary_ip property of the vrrp\n\n        Args:\n            name (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be managed.\n            value (integer): Priority to assign to the vrrp.\n            disable (boolean): Unset priority if True.\n            default (boolean): Set priority to default if True.\n            run (boolean): Set to True to execute the command, False to\n                return a string with the formatted command.\n\n        Returns:\n            If run is True, returns True if the command executed successfully,\n            error if failure.\n\n            If run is False, returns the formatted command string which can\n            be passed to the node\n\n        \"\"\"\n\n        if not default and not disable:\n            if not str(value).isdigit() or value < 1 or value > 254:\n                raise ValueError(\"vrrp property 'priority' must be \"\n                                 \"an integer in the range 1-254\")\n\n        cmd = self.command_builder('vrrp %d priority' % vrid, value=value,\n                                   default=default, disable=disable)\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmd)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmd", "response": "Set the primary IP property of the vrrp to the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_secondary_ips(self, name, vrid, secondary_ips, run=True):\n\n        cmds = []\n\n        # Get the current set of tracks defined for the vrrp\n        curr_sec_ips = []\n        vrrps = self.get(name)\n        if vrrps and vrid in vrrps:\n            curr_sec_ips = vrrps[vrid]['secondary_ip']\n\n        # Validate the list of ip addresses\n        for sec_ip in secondary_ips:\n            if type(sec_ip) is not str or \\\n                    not re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', sec_ip):\n                raise ValueError(\"vrrp property 'secondary_ip' must be a list \"\n                                 \"of properly formatted ip address strings\")\n\n        intersection = list(set(curr_sec_ips) & set(secondary_ips))\n\n        # Delete the intersection from both lists to determine which\n        # addresses need to be added or removed from the vrrp\n        remove = list(set(curr_sec_ips) - set(intersection))\n        add = list(set(secondary_ips) - set(intersection))\n\n        # Build the commands to add and remove the secondary ip addresses\n        for sec_ip in remove:\n            cmds.append(\"no vrrp %d ip %s secondary\" % (vrid, sec_ip))\n\n        for sec_ip in add:\n            cmds.append(\"vrrp %d ip %s secondary\" % (vrid, sec_ip))\n\n        cmds = sorted(cmds)\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmds)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmds", "response": "This function sets the secondary ip addresses of the vrrp that are used to connect to the virtual router."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the mac - address advertisement - interval property of the vrrp.", "response": "def set_mac_addr_adv_interval(self, name, vrid, value=None, disable=False,\n                                  default=False, run=True):\n        \"\"\"Set the mac_addr_adv_interval property of the vrrp\n\n        Args:\n            name (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be managed.\n            value (integer): mac-address advertisement-interval value to\n                assign to the vrrp.\n            disable (boolean): Unset mac-address advertisement-interval\n                if True.\n            default (boolean): Set mac-address advertisement-interval to\n                default if True.\n            run (boolean): Set to True to execute the command, False to\n                return a string with the formatted command.\n\n        Returns:\n            If run is True, returns True if the command executed successfully,\n            error if failure.\n\n            If run is False, returns the formatted command string which can\n            be passed to the node\n\n        \"\"\"\n\n        if not default and not disable:\n            if not int(value) or int(value) < 1 or int(value) > 3600:\n                raise ValueError(\"vrrp property 'mac_addr_adv_interval' must \"\n                                 \"be in the range 1-3600\")\n\n        cmd = self.command_builder('vrrp %d mac-address advertisement-interval'\n                                   % vrid, value=value, default=default,\n                                   disable=disable)\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmd)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nconfiguring the track property of the vrrp with the given list of tracks.", "response": "def set_tracks(self, name, vrid, tracks, run=True):\n        \"\"\"Configure the track property of the vrrp\n\n        Notes:\n            set_tracks takes a list of tracked objects which are\n            to be set on the virtual router. An empty list will remove\n            any existing tracked objects from the vrrp. A list containing\n            track entries configures the virtual router to track only the\n            objects specified in the list - any existing tracked objects\n            on the vrrp not included in the list will be removed.\n\n        Args:\n            name (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be managed.\n            tracks (list): A list of track definition dictionaries. Each\n                dictionary is a definition of a tracked object in one\n                of the two formats::\n\n                    {'name': tracked_object_name,\n                     'action': 'shutdown'}\n                    {'name': tracked_object_name,\n                     'action': 'decrement',\n                     'amount': amount_of_decrement}\n\n            run (boolean): Set to True to execute the command, False to\n                return a string with the formatted command.\n\n        Returns:\n            If run is True, returns True if the command executed successfully,\n            error if failure.\n\n            If run is False, returns the formatted command string which can\n            be passed to the node\n\n        \"\"\"\n\n        cmds = []\n\n        # Get the current set of tracks defined for the vrrp\n        curr_tracks = []\n        vrrps = self.get(name)\n        if vrrps and vrid in vrrps:\n            curr_tracks = vrrps[vrid]['track']\n\n        # Determine which tracked objects are in both lists using\n        # sets of temporary strings built from the track specifications\n        unset = '_none_'\n        tracks_set = []\n        for track in tracks:\n            keys = track.keys()\n\n            # Validate no extraneous keys in track definition\n            err_keys = set(keys).difference(('name', 'action', 'amount'))\n            if err_keys:\n                err_keys = ', '.join(err_keys)\n                raise ValueError(\"Error found in vrrp property 'track': \"\n                                 \"unknown key(s) '%s' found. Valid keys are \"\n                                 \"name, action, and amount\" % err_keys)\n\n            # Validate required keys in track definition\n            if not set(keys).issuperset(('name', 'action')):\n                raise ValueError(\"Error found in vrrp property 'track': \"\n                                 \"track definition must contain 'name' and \"\n                                 \"'action' keys\")\n\n            tr_obj = track['name']\n            action = track['action']\n            amount = track['amount'] if 'amount' in track else unset\n\n            # Validate values in track definition\n            error = False\n            if action not in ('shutdown', 'decrement'):\n                error = True\n            if action == 'shutdown' and amount != unset:\n                error = True\n            if amount != unset and not str(amount).isdigit():\n                error = True\n            if error:\n                raise ValueError(\"Error found in vrrp property 'track'. \"\n                                 \"See documentation for format specification.\")\n\n            tid = \"%s   %s   %s\" % (tr_obj, action, amount)\n            tracks_set.append(tid)\n\n        curr_set = []\n        for track in curr_tracks:\n            tr_obj = track['name']\n            action = track['action']\n            amount = track['amount'] if 'amount' in track else unset\n\n            # Validate track definition\n            error = False\n            if action not in ('shutdown', 'decrement'):\n                error = True\n            if action == 'shutdown' and amount != unset:\n                error = True\n            if amount != unset and not str(amount).isdigit():\n                error = True\n            if error:\n                raise ValueError(\"Error found in vrrp property 'track'. \"\n                                 \"See documentation for format specification.\")\n\n            tid = \"%s   %s   %s\" % (tr_obj, action, amount)\n            curr_set.append(tid)\n\n        intersection = list(set(tracks_set) & set(curr_set))\n\n        # Delete the intersection from both lists to determine which\n        # track definitions need to be added or removed from the vrrp\n        remove = list(set(curr_set) - set(intersection))\n        add = list(set(tracks_set) - set(intersection))\n\n        # Build the commands to add and remove the tracked objects\n        for track in remove:\n            match = re.match(r'(\\S+)\\s+(\\S+)\\s+(\\S+)', track)\n            if match:\n                (tr_obj, action, amount) = \\\n                    (match.group(1), match.group(2), match.group(3))\n\n                if amount == unset:\n                    amount = ''\n                t_cmd = (\"no vrrp %d track %s %s %s\"\n                         % (vrid, tr_obj, action, amount))\n                cmds.append(t_cmd.rstrip())\n\n        for track in add:\n            match = re.match(r'(\\S+)\\s+(\\S+)\\s+(\\S+)', track)\n            if match:\n                (tr_obj, action, amount) = \\\n                    (match.group(1), match.group(2), match.group(3))\n\n                if amount == unset:\n                    amount = ''\n                t_cmd = (\"vrrp %d track %s %s %s\"\n                         % (vrid, tr_obj, action, amount))\n                cmds.append(t_cmd.rstrip())\n\n        cmds = sorted(cmds)\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmds)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmds"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the bfd ip address of the vrrp to be managed by the vrrp.", "response": "def set_bfd_ip(self, name, vrid, value=None, disable=False,\n                   default=False, run=True):\n        \"\"\"Set the bfd_ip property of the vrrp\n\n        Args:\n            name (string): The interface to configure.\n            vrid (integer): The vrid number for the vrrp to be managed.\n            value (string): The bfd ip address to be set.\n            disable (boolean): Unset bfd ip if True.\n            default (boolean): Set bfd ip to default if True.\n            run (boolean): Set to True to execute the command, False to\n                return a string with the formatted command.\n\n        Returns:\n            If run is True, returns True if the command executed successfully,\n            error if failure.\n\n            If run is False, returns the formatted command string which can\n            be passed to the node\n\n        \"\"\"\n        if not default and not disable:\n            if not re.match(r'^\\d+\\.\\d+\\.\\d+\\.\\d+$', str(value)):\n                raise ValueError(\"vrrp property 'bfd_ip' must be \"\n                                 \"a properly formatted IP address\")\n        cmd = self.command_builder('vrrp %d bfd ip' % vrid, value=value,\n                                   default=default, disable=disable)\n\n        # Run the command if requested\n        if run:\n            result = self.configure_interface(name, cmd)\n            # And verify the command succeeded\n            if result is False:\n                return self.error\n            return result\n\n        # Otherwise return the formatted command\n        return cmd"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef vrconf_format(self, vrconfig):\n\n        fixed = dict(vrconfig)\n\n        # primary_ip: default, no, None results in address of 0.0.0.0\n        if fixed['primary_ip'] in ('no', 'default', None):\n            fixed['primary_ip'] = '0.0.0.0'\n        # priority: default, no, None results in priority of 100\n        if fixed['priority'] in ('no', 'default', None):\n            fixed['priority'] = 100\n        # description: default, no, None results in None\n        if fixed['description'] in ('no', 'default', None):\n            fixed['description'] = None\n        # secondary_ip: list should be exactly what is required,\n        # just sort it for easier comparison\n        if 'secondary_ip' in fixed:\n            fixed['secondary_ip'] = sorted(fixed['secondary_ip'])\n        # ip_version: default, no, None results in value of 2\n        if fixed['ip_version'] in ('no', 'default', None):\n            fixed['ip_version'] = 2\n        # timers_advertise: default, no, None results in value of 1\n        if fixed['timers_advertise'] in ('no', 'default', None):\n            fixed['timers_advertise'] = 1\n        # mac_address_advertisement_interaval:\n        #    default, no, None results in value of 30\n        if fixed['mac_addr_adv_interval'] in \\\n                ('no', 'default', None):\n            fixed['mac_addr_adv_interval'] = 30\n        # preempt: default, no results in value of False\n        if fixed['preempt'] in ('no', 'default'):\n            fixed['preempt'] = False\n        # preempt_delay_min: default, no, None results in value of 0\n        if fixed['preempt_delay_min'] in ('no', 'default', None):\n            fixed['preempt_delay_min'] = 0\n        # preempt_delay_reload: default, no, None results in value of 0\n        if fixed['preempt_delay_reload'] in ('no', 'default', None):\n            fixed['preempt_delay_reload'] = 0\n        # delay_reload: default, no, None results in value of 0\n        if fixed['delay_reload'] in ('no', 'default', None):\n            fixed['delay_reload'] = 0\n        # track: list should be exactly what is required,\n        # just sort it for easier comparison\n        if 'track' in fixed:\n            fixed['track'] = \\\n                sorted(fixed['track'], key=lambda k: (k['name'], k['action']))\n        # bfd_ip: default, no, None results in ''\n        if fixed['bfd_ip'] in ('no', 'default', None):\n            fixed['bfd_ip'] = ''\n\n        return fixed", "response": "Formats a vrrp configuration dictionary to match the current vrrp configuration dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef prefixlen_to_mask(prefixlen):\n    prefixlen = prefixlen or '32'\n    addr = '0.0.0.0/%s' % prefixlen\n    return str(netaddr.IPNetwork(addr).netmask)", "response": "Converts a prefix length value to a dotted decimal subnet mask"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef getall(self):\n        acl_re = re.compile(r'^ip access-list (?:(standard) )?(.+)$', re.M)\n        response = {'standard': {}, 'extended': {}}\n        for acl_type, name in acl_re.findall(self.config):\n            acl = self.get(name)\n            if acl_type and acl_type == 'standard':\n                response['standard'][name] = acl\n            else:\n                response['extended'][name] = acl\n        return response", "response": "Returns all ACLs in a dict object."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get(self):\n        resource = dict()\n        resource.update(self._parse_config())\n        resource.update(self._parse_interfaces())\n\n        return resource", "response": "Returns the Mlag configuration as a resource dict"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_config(self):\n        config = self.get_block('mlag configuration')\n        cfg = dict()\n        cfg.update(self._parse_domain_id(config))\n        cfg.update(self._parse_local_interface(config))\n        cfg.update(self._parse_peer_address(config))\n        cfg.update(self._parse_peer_link(config))\n        cfg.update(self._parse_shutdown(config))\n        return dict(config=cfg)", "response": "Parses the mlag global configuration and returns a dict object that is intended to be merged into the\n            resource dict"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _parse_domain_id(self, config):\n        match = re.search(r'domain-id (.+)$', config)\n        value = match.group(1) if match else None\n        return dict(domain_id=value)", "response": "Scans the config block and parses the domain - id value and returns a dict object that is intended to be merged into the\n            resource dict"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans the config block and parses the local - interface value and returns a dict object that is intended to be merged into the resource dict", "response": "def _parse_local_interface(self, config):\n        \"\"\"Scans the config block and parses the local-interface value\n\n        Args:\n            config (str): The config block to scan\n\n        Returns:\n            dict: A dict object that is intended to be merged into the\n                resource dict\n        \"\"\"\n        match = re.search(r'local-interface (\\w+)', config)\n        value = match.group(1) if match else None\n        return dict(local_interface=value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning the config block and parses the peer - address value and returns a dict object that is intended to be merged into the resource dict", "response": "def _parse_peer_address(self, config):\n        \"\"\"Scans the config block and parses the peer-address value\n\n        Args:\n            config (str): The config block to scan\n\n        Returns:\n            dict: A dict object that is intended to be merged into the\n                resource dict\n        \"\"\"\n        match = re.search(r'peer-address ([^\\s]+)', config)\n        value = match.group(1) if match else None\n        return dict(peer_address=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_peer_link(self, config):\n        match = re.search(r'peer-link (\\S+)', config)\n        value = match.group(1) if match else None\n        return dict(peer_link=value)", "response": "Scans the config block and parses the peer - link value and returns a dict object that is intended to be merged into the\n            resource dict"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning the global config and returns the configured interfaces", "response": "def _parse_interfaces(self):\n        \"\"\"Scans the global config and returns the configured interfaces\n\n        Returns:\n            dict: A dict object that is intended to be merged into the\n                resource dict.\n        \"\"\"\n        interfaces = dict()\n        names = re.findall(r'^interface (Po.+)$', self.config, re.M)\n        for name in names:\n            config = self.get_block('interface %s' % name)\n            match = re.search(r'mlag (\\d+)', config)\n            if match:\n                interfaces[name] = dict(mlag_id=match.group(1))\n        return dict(interfaces=interfaces)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures the mlag domain - id value", "response": "def set_domain_id(self, value=None, default=False, disable=False):\n        \"\"\"Configures the mlag domain-id value\n\n        Args:\n            value (str): The value to configure the domain-id\n            default (bool): Configures the domain-id using the default keyword\n            disable (bool): Negates the domain-id using the no keyword\n\n        Returns:\n            bool: Returns True if the commands complete successfully\n        \"\"\"\n        return self._configure_mlag('domain-id', value, default, disable)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_local_interface(self, value=None, default=False, disable=False):\n        return self._configure_mlag('local-interface', value, default, disable)", "response": "Configures the mlag local - interface value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures the mlag peer - address value", "response": "def set_peer_address(self, value=None, default=False, disable=False):\n        \"\"\"Configures the mlag peer-address value\n\n        Args:\n            value (str): The value to configure the peer-address\n            default (bool): Configures the peer-address using the\n                default keyword\n            disable (bool): Negates the peer-address using the no keyword\n\n        Returns:\n            bool: Returns True if the commands complete successfully\n        \"\"\"\n        return self._configure_mlag('peer-address', value, default, disable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_peer_link(self, value=None, default=False, disable=False):\n        return self._configure_mlag('peer-link', value, default, disable)", "response": "Configures the mlag peer - link value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the mlag shutdown value", "response": "def set_shutdown(self, default=False, disable=True):\n        \"\"\"Configures the mlag shutdown value\n\n        Default setting for set_shutdown is disable=True, meaning\n        'no shutdown'. Setting both default and disable to False will\n        effectively enable shutdown.\n\n        Args:\n            default (bool): Configures the shutdown using the\n                default keyword\n            disable (bool): Negates shutdown using the no keyword\n\n        Returns:\n            bool: Returns True if the commands complete successfully\n        \"\"\"\n        return self._configure_mlag('shutdown', True, default, disable)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure the mlag value for the specified interface", "response": "def set_mlag_id(self, name, value=None, default=False, disable=False):\n        \"\"\"Configures the interface mlag value for the specified interface\n\n        Args:\n            name (str): The interface to configure.  Valid values for the\n                name arg include Port-Channel*\n            value (str): The mlag identifier to cofigure on the interface\n            default (bool): Configures the interface mlag value using the\n                default keyword\n            disable (bool): Negates the interface mlag value using the\n                no keyword\n\n        Returns:\n            bool: Returns True if the commands complete successfully\n        \"\"\"\n        cmd = self.command_builder('mlag', value=value, default=default,\n                                   disable=disable)\n        return self.configure_interface(name, cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the bgp routing configuration as a dict object", "response": "def get(self):\n        \"\"\"Returns the bgp routing configuration as a dict object\n        \"\"\"\n        config = self.get_block('^router bgp .*')\n        if not config:\n            return None\n\n        response = dict()\n        response.update(self._parse_bgp_as(config))\n        response.update(self._parse_router_id(config))\n        response.update(self._parse_max_paths(config))\n        response.update(self._parse_shutdown(config))\n        response.update(self._parse_networks(config))\n\n        response['neighbors'] = self.neighbors.getall()\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, vrf=None):\n        match = '^router ospf .*'\n        if vrf:\n            match += ' vrf %s' % vrf\n        config = self.get_block(match)\n        if not config:\n            return None\n\n        response = dict()\n        response.update(self._parse_router_id(config))\n        response.update(self._parse_vrf(config))\n        response.update(self._parse_networks(config))\n        response.update(self._parse_ospf_process_id(config))\n        response.update(self._parse_redistribution(config))\n        response.update(self._parse_shutdown(config))\n\n        return response", "response": "Returns the OSPF routing configuration for the specified vrf"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _parse_ospf_process_id(self, config):\n        match = re.search(r'^router ospf (\\d+)', config)\n        return dict(ospf_process_id=int(match.group(1)))", "response": "Parses the config file for the OSPF proc ID"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_vrf(self, config):\n        match = re.search(r'^router ospf \\d+ vrf (\\w+)', config)\n        if match:\n            return dict(vrf=match.group(1))\n        return dict(vrf='default')", "response": "Parses the config file for the OSPF vrf name and returns a dictionary with key = vrf name"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_networks(self, config):\n\n        networks = list()\n        regexp = r'network (.+)/(\\d+) area (\\d+\\.\\d+\\.\\d+\\.\\d+)'\n        matches = re.findall(regexp, config)\n        for (network, netmask, area) in matches:\n            networks.append(dict(network=network, netmask=netmask, area=area))\n        return dict(networks=networks)", "response": "Parses the config file for the networks advertised by the OSPF process\nElems"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nparses the redistribution file for the OSPF router ID.", "response": "def _parse_redistribution(self, config):\n        \"\"\"Parses config file for the OSPF router ID\n\n           Args:\n               config (str):  Running configuration\n           Returns:\n               list: dict:\n                         keys: protocol (str)\n                               route-map (optional) (str)\n        \"\"\"\n        redistributions = list()\n        regexp = r'redistribute .*'\n        matches = re.findall(regexp, config)\n        for line in matches:\n            ospf_redist = line.split()\n            if len(ospf_redist) == 2:\n                # simple redist: eg 'redistribute bgp'\n                protocol = ospf_redist[1]\n                redistributions.append(dict(protocol=protocol))\n            if len(ospf_redist) == 4:\n                # complex redist eg 'redistribute bgp route-map NYSE-RP-MAP'\n                protocol = ospf_redist[1]\n                route_map_name = ospf_redist[3]\n                redistributions.append(dict(protocol=protocol,\n                                       route_map=route_map_name))\n        return dict(redistributions=redistributions)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves the entire ospf process from the running configuration", "response": "def delete(self):\n        \"\"\"Removes the entire ospf process from the running configuration\n\n           Args:\n               None\n           Returns:\n               bool: True if the command completed succssfully\n        \"\"\"\n        config = self.get()\n        if not config:\n            return True\n        command = 'no router ospf {}'.format(config['ospf_process_id'])\n        return self.configure(command)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating a new OSPF process in the specified VRF or the default VRF.", "response": "def create(self, ospf_process_id, vrf=None):\n        \"\"\"Creates a OSPF process in the specified VRF or the default VRF.\n\n           Args:\n                ospf_process_id (str): The OSPF process Id value\n                vrf (str): The VRF to apply this OSPF process to\n           Returns:\n                bool: True if the command completed successfully\n           Exception:\n                ValueError: If the ospf_process_id passed in less\n                            than 0 or greater than 65536\n        \"\"\"\n        value = int(ospf_process_id)\n        if not 0 < value < 65536:\n            raise ValueError('ospf as must be between 1 and 65535')\n        command = 'router ospf {}'.format(ospf_process_id)\n        if vrf:\n            command += ' vrf %s' % vrf\n        return self.configure(command)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nallowing for a list of OSPF subcommands to be configured", "response": "def configure_ospf(self, cmd):\n        \"\"\"Allows for a list of OSPF subcommands to be configured\"\n\n           Args:\n               cmd: (list or str): Subcommand to be entered\n           Returns:\n               bool: True if all the commands completed successfully\n        \"\"\"\n        config = self.get()\n        cmds = ['router ospf {}'.format(config['ospf_process_id'])]\n        cmds.extend(make_iterable(cmd))\n        return super(Ospf, self).configure(cmds)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncontrol the router id property for the OSPF Proccess racrac prefetch", "response": "def set_router_id(self, value=None, default=False, disable=False):\n        \"\"\"Controls the router id property for the OSPF Proccess\n\n           Args:\n               value (str): The router-id value\n               default (bool): Controls the use of the default keyword\n               disable (bool): Controls the use of the no keyword\n           Returns:\n               bool: True if the commands are completed successfully\n        \"\"\"\n        cmd = self.command_builder('router-id', value=value,\n                                   default=default, disable=disable)\n        return self.configure_ospf(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a network to be advertised by OSPF", "response": "def add_network(self, network, netmask, area=0):\n        \"\"\"Adds a network to be advertised by OSPF\n\n           Args:\n               network (str):  The network to be advertised in dotted decimal\n                               notation\n               netmask (str):  The netmask to configure\n               area (str):  The area the network belongs to.\n                            By default this value is 0\n           Returns:\n               bool: True if the command completes successfully\n           Exception:\n               ValueError: This will get raised if network or netmask\n                           are not passed to the method\n        \"\"\"\n        if network == '' or netmask == '':\n            raise ValueError('network and mask values '\n                             'may not be empty')\n        cmd = 'network {}/{} area {}'.format(network, netmask, area)\n        return self.configure_ospf(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_redistribution(self, protocol, route_map_name=None):\n        protocols = ['bgp', 'rip', 'static', 'connected']\n        if protocol not in protocols:\n            raise ValueError('redistributed protocol must be'\n                             'bgp, connected, rip or static')\n        if route_map_name is None:\n            cmd = 'redistribute {}'.format(protocol)\n        else:\n            cmd = 'redistribute {} route-map {}'.format(protocol,\n                                                        route_map_name)\n        return self.configure_ospf(cmd)", "response": "Adds a protocol redistribution to the OSPF object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef remove_redistribution(self, protocol):\n\n        protocols = ['bgp', 'rip', 'static', 'connected']\n        if protocol not in protocols:\n            raise ValueError('redistributed protocol must be'\n                             'bgp, connected, rip or static')\n        cmd = 'no redistribute {}'.format(protocol)\n        return self.configure_ospf(cmd)", "response": "Removes a protocol redistribution to OSPF\nTracingEnabled"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns all static routes configured on the switch as a resource dict", "response": "def getall(self):\n        \"\"\"Return all ip routes configured on the switch as a resource dict\n\n        Returns:\n            dict: An dict object of static route entries in the form::\n\n                { ip_dest:\n                    { next_hop:\n                        { next_hop_ip:\n                            { distance:\n                                { 'tag': tag,\n                                  'route_name': route_name\n                                }\n                            }\n                        }\n                    }\n                }\n\n            If the ip address specified does not have any associated\n            static routes, then None is returned.\n\n        Notes:\n            The keys ip_dest, next_hop, next_hop_ip, and distance in\n            the returned dictionary are the values of those components\n            of the ip route specification. If a route does not contain\n            a next_hop_ip, then that key value will be set as 'None'.\n        \"\"\"\n\n        # Find all the ip routes in the config\n        matches = ROUTES_RE.findall(self.config)\n\n        # Parse the routes and add them to the routes dict\n        routes = dict()\n        for match in matches:\n\n            # Get the four identifying components\n            ip_dest = match[0]\n            next_hop = match[1]\n            next_hop_ip = None if match[2] is '' else match[2]\n            distance = int(match[3])\n\n            # Create the data dict with the remaining components\n            data = {}\n            data['tag'] = None if match[4] is '' else int(match[4])\n            data['route_name'] = None if match[5] is '' else match[5]\n\n            # Build the complete dict entry from the four components\n            # and the data.\n            # temp_dict = parent_dict[key] = parent_dict.get(key, {})\n            # This creates the keyed dict in the parent_dict if it doesn't\n            # exist, or reuses the existing keyed dict.\n            # The temp_dict is used to make things more readable.\n            ip_dict = routes[ip_dest] = routes.get(ip_dest, {})\n            nh_dict = ip_dict[next_hop] = ip_dict.get(next_hop, {})\n            nhip_dict = nh_dict[next_hop_ip] = nh_dict.get(next_hop_ip, {})\n            nhip_dict[distance] = data\n\n        return routes"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef create(self, ip_dest, next_hop, **kwargs):\n\n        # Call _set_route with delete and default set to False\n        return self._set_route(ip_dest, next_hop, **kwargs)", "response": "Create a static route in the catalyger module"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndeletes a static route in the log.", "response": "def delete(self, ip_dest, next_hop, **kwargs):\n        \"\"\"Delete a static route\n\n        Args:\n            ip_dest (string): The ip address of the destination in the\n                form of A.B.C.D/E\n            next_hop (string): The next hop interface or ip address\n            **kwargs['next_hop_ip'] (string): The next hop address on\n                destination interface\n            **kwargs['distance'] (string): Administrative distance for this\n                route\n            **kwargs['tag'] (string): Route tag\n            **kwargs['route_name'] (string): Route name\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n\n        # Call _set_route with the delete flag set to True\n        kwargs.update({'delete': True})\n        return self._set_route(ip_dest, next_hop, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef default(self, ip_dest, next_hop, **kwargs):\n\n        # Call _set_route with the default flag set to True\n        kwargs.update({'default': True})\n        return self._set_route(ip_dest, next_hop, **kwargs)", "response": "Set a static route to default"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_tag(self, ip_dest, next_hop, **kwargs):\n\n        # Call _set_route with the new tag information\n        return self._set_route(ip_dest, next_hop, **kwargs)", "response": "Set the tag value for the specified route_name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the route_name value for the specified route_name", "response": "def set_route_name(self, ip_dest, next_hop, **kwargs):\n        \"\"\"Set the route_name value for the specified route\n\n        Args:\n            ip_dest (string): The ip address of the destination in the\n                form of A.B.C.D/E\n            next_hop (string): The next hop interface or ip address\n            **kwargs['next_hop_ip'] (string): The next hop address on\n                destination interface\n            **kwargs['distance'] (string): Administrative distance for this\n                route\n            **kwargs['tag'] (string): Route tag\n            **kwargs['route_name'] (string): Route name\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n\n        Notes:\n            Any existing tag value must be included in call to\n                set_route_name, otherwise the tag will be reset\n                by the call to EOS.\n        \"\"\"\n\n        # Call _set_route with the new route_name information\n        return self._set_route(ip_dest, next_hop, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _build_commands(self, ip_dest, next_hop, **kwargs):\n\n        commands = \"ip route %s %s\" % (ip_dest, next_hop)\n\n        next_hop_ip = kwargs.get('next_hop_ip', None)\n        distance = kwargs.get('distance', None)\n        tag = kwargs.get('tag', None)\n        route_name = kwargs.get('route_name', None)\n\n        if next_hop_ip is not None:\n            commands += \" %s\" % next_hop_ip\n        if distance is not None:\n            commands += \" %s\" % distance\n        if tag is not None:\n            commands += \" tag %s\" % tag\n        if route_name is not None:\n            commands += \" name %s\" % route_name\n\n        return commands", "response": "Builds the EOS command string for ip route interactions."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring a static route in the specified routeon the specified routeon the specified next hop.", "response": "def _set_route(self, ip_dest, next_hop, **kwargs):\n        \"\"\"Configure a static route\n\n        Args:\n            ip_dest (string): The ip address of the destination in the\n                form of A.B.C.D/E\n            next_hop (string): The next hop interface or ip address\n            **kwargs['next_hop_ip'] (string): The next hop address on\n                destination interface\n            **kwargs['distance'] (string): Administrative distance for this\n                route\n            **kwargs['tag'] (string): Route tag\n            **kwargs['route_name'] (string): Route name\n            **kwargs['delete'] (boolean): If true, deletes the specified route\n                instead of creating or setting values for the route\n            **kwargs['default'] (boolean): If true, defaults the specified\n                route instead of creating or setting values for the route\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n\n        commands = self._build_commands(ip_dest, next_hop, **kwargs)\n\n        delete = kwargs.get('delete', False)\n        default = kwargs.get('default', False)\n\n        # Prefix with 'no' if delete is set\n        if delete:\n            commands = \"no \" + commands\n        # Or with 'default' if default is setting\n        else:\n            if default:\n                commands = \"default \" + commands\n\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the VLAN configuration as a resource dict.", "response": "def get(self, value):\n        \"\"\"Returns the VLAN configuration as a resource dict.\n\n        Args:\n            vid (string): The vlan identifier to retrieve from the\n                running configuration.  Valid values are in the range\n                of 1 to 4095\n\n        Returns:\n            A Python dict object containing the VLAN attributes as\n                key/value pairs.\n\n        \"\"\"\n        config = self.get_block('vlan %s' % value)\n        if not config:\n            return None\n\n        response = dict(vlan_id=value)\n        response.update(self._parse_name(config))\n        response.update(self._parse_state(config))\n        response.update(self._parse_trunk_groups(config))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nparse the name of the node running and return the name of the node running", "response": "def _parse_name(self, config):\n        \"\"\" _parse_name scans the provided configuration block and extracts\n        the vlan name.  The config block is expected to always return the\n        vlan name.  The return dict is intended to be merged into the response\n        dict.\n\n        Args:\n            config (str): The vlan configuration block from the nodes running\n                configuration\n\n        Returns:\n            dict: resource dict attribute\n        \"\"\"\n        value = NAME_RE.search(config).group('value')\n        return dict(name=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_state(self, config):\n        value = STATE_RE.search(config).group('value')\n        return dict(state=value)", "response": "Parse the state block and returns the state value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_trunk_groups(self, config):\n        values = TRUNK_GROUP_RE.findall(config)\n        return dict(trunk_groups=values)", "response": "Scans the provided configuration block and extracts all the vlan trunk groups from it and returns a resource dict with the trunk_groups key as the key and the value as the value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef getall(self):\n        vlans_re = re.compile(r'(?<=^vlan\\s)(\\d+)', re.M)\n\n        response = dict()\n        for vid in vlans_re.findall(self.config):\n            response[vid] = self.get(vid)\n        return response", "response": "Returns a dict object of all Vlans in the running - config"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new VLAN resource", "response": "def create(self, vid):\n        \"\"\" Creates a new VLAN resource\n\n        Args:\n            vid (str): The VLAN ID to create\n\n        Returns:\n            True if create was successful otherwise False\n        \"\"\"\n        command = 'vlan %s' % vid\n        return self.configure(command) if isvlan(vid) else False"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndeletes a VLAN from the running configuration", "response": "def delete(self, vid):\n        \"\"\" Deletes a VLAN from the running configuration\n\n        Args:\n            vid (str): The VLAN ID to delete\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        command = 'no vlan %s' % vid\n        return self.configure(command) if isvlan(vid) else False"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef default(self, vid):\n        command = 'default vlan %s' % vid\n        return self.configure(command) if isvlan(vid) else False", "response": "Default the VLAN configuration"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef configure_vlan(self, vid, commands):\n        commands = make_iterable(commands)\n        commands.insert(0, 'vlan %s' % vid)\n        return self.configure(commands)", "response": "Configure the specified VLAN using commands\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures the name of the specified VLAN", "response": "def set_name(self, vid, name=None, default=False, disable=False):\n        \"\"\" Configures the VLAN name\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            vid (str): The VLAN ID to Configures\n            name (str): The value to configure the vlan name\n            default (bool): Defaults the VLAN ID name\n            disable (bool): Negates the VLAN ID name\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        cmds = self.command_builder('name', value=name, default=default,\n                                    disable=disable)\n        return self.configure_vlan(vid, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the state of a specific VLAN", "response": "def set_state(self, vid, value=None, default=False, disable=False):\n        \"\"\" Configures the VLAN state\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            vid (str): The VLAN ID to configure\n            value (str): The value to set the vlan state to\n            default (bool): Configures the vlan state to its default value\n            disable (bool): Negates the vlan state\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        cmds = self.command_builder('state', value=value, default=default,\n                                    disable=disable)\n        return self.configure_vlan(vid, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_trunk_groups(self, vid, value=None, default=False, disable=False):\n        if default:\n            return self.configure_vlan(vid, 'default trunk group')\n        if disable:\n            return self.configure_vlan(vid, 'no trunk group')\n\n        current_value = self.get(vid)['trunk_groups']\n        failure = False\n\n        value = make_iterable(value)\n\n        for name in set(value).difference(current_value):\n            if not self.add_trunk_group(vid, name):\n                failure = True\n\n        for name in set(current_value).difference(value):\n            if not self.remove_trunk_group(vid, name):\n                failure = True\n\n        return not failure", "response": "Configures the list of trunk groups support on a vlan"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nconfigure the user authentication for eAPI.", "response": "def authentication(self, username, password):\n        \"\"\"Configures the user authentication for eAPI\n\n        This method configures the username and password combination to use\n        for authenticating to eAPI.\n\n        Args:\n            username (str): The username to use to authenticate the eAPI\n                connection with\n            password (str): The password in clear text to use to authenticate\n                the eAPI connection with\n\n        \"\"\"\n        _auth_text = '{}:{}'.format(username, password)\n\n        # Work around for Python 2.7/3.x compatibility\n        if int(sys.version[0]) > 2:\n            # For Python 3.x\n            _auth_bin = base64.encodebytes(_auth_text.encode())\n            _auth = _auth_bin.decode()\n            _auth = _auth.replace('\\n', '')\n            self._auth = _auth\n        else:\n            # For Python 2.7\n            _auth = base64.encodestring(_auth_text)\n            self._auth = str(_auth).replace('\\n', '')\n\n        _LOGGER.debug('Autentication string is: {}:***'.format(username))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngenerates an eAPI request object This method will take a list of EOS commands and generate a valid eAPI request object form them. The eAPI request object is then JSON encoding and returned to the caller. eAPI Request Object .. code-block:: json { \"jsonrpc\": \"2.0\", \"method\": \"runCmds\", \"params\": { \"version\": 1, \"cmds\": [ <commands> ], \"format\": [json, text], } \"id\": <reqid> } Args: commands (list): A list of commands to include in the eAPI request object encoding (string): The encoding method passed as the `format` parameter in the eAPI request reqid (string): A custom value to assign to the request ID field. This value is automatically generated if not passed **kwargs: Additional keyword arguments for expanded eAPI functionality. Only supported eAPI params are used in building the request Returns: A JSON encoding request structure that can be send over eAPI", "response": "def request(self, commands, encoding=None, reqid=None, **kwargs):\n        \"\"\"Generates an eAPI request object\n\n        This method will take a list of EOS commands and generate a valid\n        eAPI request object form them.  The eAPI request object is then\n        JSON encoding and returned to the caller.\n\n        eAPI Request Object\n\n        .. code-block:: json\n\n            {\n                \"jsonrpc\": \"2.0\",\n                \"method\": \"runCmds\",\n                \"params\": {\n                    \"version\": 1,\n                    \"cmds\": [\n                        <commands>\n                    ],\n                    \"format\": [json, text],\n                }\n                \"id\": <reqid>\n            }\n\n        Args:\n            commands (list): A list of commands to include in the eAPI\n                request object\n            encoding (string): The encoding method passed as the `format`\n                parameter in the eAPI request\n            reqid (string): A custom value to assign to the request ID\n                field.  This value is automatically generated if not passed\n            **kwargs: Additional keyword arguments for expanded eAPI\n                functionality. Only supported eAPI params are used in building\n                the request\n\n        Returns:\n            A JSON encoding request structure that can be send over eAPI\n\n        \"\"\"\n        commands = make_iterable(commands)\n        reqid = id(self) if reqid is None else reqid\n        params = {'version': 1, 'cmds': commands, 'format': encoding}\n        if 'autoComplete' in kwargs:\n            params['autoComplete'] = kwargs['autoComplete']\n        if 'expandAliases' in kwargs:\n            params['expandAliases'] = kwargs['expandAliases']\n        return json.dumps({'jsonrpc': '2.0', 'method': 'runCmds',\n                           'params': params, 'id': str(reqid)})"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send(self, data):\n        try:\n            _LOGGER.debug('Request content: {}'.format(data))\n            # debug('eapi_request: %s' % data)\n\n            self.transport.putrequest('POST', '/command-api')\n\n            self.transport.putheader('Content-type', 'application/json-rpc')\n            self.transport.putheader('Content-length', '%d' % len(data))\n\n            if self._auth:\n                self.transport.putheader('Authorization',\n                                         'Basic %s' % self._auth)\n\n            if int(sys.version[0]) > 2:\n                # For Python 3.x compatibility\n                data = data.encode()\n\n            self.transport.endheaders(message_body=data)\n\n            try:  # Python 2.7: use buffering of HTTP responses\n                response = self.transport.getresponse(buffering=True)\n            except TypeError:  # Python 2.6: older, and 3.x on\n                response = self.transport.getresponse()\n\n            response_content = response.read()\n            _LOGGER.debug('Response: status:{status}, reason:{reason}'.format(\n                          status=response.status,\n                          reason=response.reason))\n            _LOGGER.debug('Response content: {}'.format(response_content))\n\n            if response.status == 401:\n                raise ConnectionError(str(self), '%s. %s' % (response.reason,\n                                                             response_content))\n\n            # Work around for Python 2.7/3.x compatibility\n            if not type(response_content) == str:\n                # For Python 3.x - decode bytes into string\n                response_content = response_content.decode()\n            decoded = json.loads(response_content)\n            _LOGGER.debug('eapi_response: %s' % decoded)\n\n            if 'error' in decoded:\n                (code, msg, err, out) = self._parse_error_message(decoded)\n                pattern = \"unexpected keyword argument '(.*)'\"\n                match = re.search(pattern, msg)\n                if match:\n                    auto_msg = ('%s parameter is not supported in this'\n                                ' version of EOS.' % match.group(1))\n                    _LOGGER.error(auto_msg)\n                    msg = msg + '. ' + auto_msg\n                raise CommandError(code, msg, command_error=err, output=out)\n\n            return decoded\n\n        # socket.error is deprecated in python 3 and replaced with OSError.\n        except (socket.error, OSError) as exc:\n            _LOGGER.exception(exc)\n            self.socket_error = exc\n            self.error = exc\n            error_msg = 'Socket error during eAPI connection: %s' % str(exc)\n            raise ConnectionError(str(self), error_msg)\n        except ValueError as exc:\n            _LOGGER.exception(exc)\n            self.socket_error = None\n            self.error = exc\n            raise ConnectionError(str(self), 'unable to connect to eAPI')\n        finally:\n            self.transport.close()", "response": "Sends the eAPI request to the destination node and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nparse the error message from an eAPI failure response and returns the error code message error text output list of all output from all commands that generated the necesary n", "response": "def _parse_error_message(self, message):\n        \"\"\"Parses the eAPI failure response message\n\n        This method accepts an eAPI failure message and parses the necesary\n        parts in order to generate a CommandError.\n\n        Args:\n            message (str): The error message to parse\n\n        Returns:\n            tuple: A tuple that consists of the following:\n                * code: The error code specified in the failure message\n                * message: The error text specified in the failure message\n                * error: The error text from the command that generated the\n                    error (the last command that ran)\n                * output: A list of all output from all commands\n        \"\"\"\n        msg = message['error']['message']\n        code = message['error']['code']\n\n        err = None\n        out = None\n\n        if 'data' in message['error']:\n            err = ' '.join(message['error']['data'][-1]['errors'])\n            out = message['error']['data']\n\n        return code, msg, err, out"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef execute(self, commands, encoding='json', **kwargs):\n        if encoding not in ('json', 'text'):\n            raise TypeError('encoding must be one of [json, text]')\n\n        try:\n            self.error = None\n            request = self.request(commands, encoding=encoding, **kwargs)\n            response = self.send(request)\n            return response\n\n        except(ConnectionError, CommandError, TypeError) as exc:\n            exc.commands = commands\n            self.error = exc\n            raise", "response": "Executes the list of commands on the destination node and returns the response."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the current VARP configuration of the specified node.", "response": "def get(self):\n        \"\"\"Returns the current VARP configuration\n\n        The Varp resource returns the following:\n\n            * mac_address (str): The virtual-router mac address\n            * interfaces (dict): A list of the interfaces that have a\n                                 virtual-router address configured.\n\n        Return:\n            A Python dictionary object of key/value pairs that represents\n            the current configuration of the node.  If the specified\n            interface does not exist then None is returned::\n\n                {\n                    \"mac_address\": \"aa:bb:cc:dd:ee:ff\",\n                    \"interfaces\": {\n                        \"Vlan100\": {\n                            \"addresses\": [ \"1.1.1.1\", \"2.2.2.2\"]\n                        },\n                        \"Vlan200\": [...]\n                    }\n                }\n        \"\"\"\n        resource = dict()\n        resource.update(self._parse_mac_address())\n        resource.update(self._parse_interfaces())\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_mac_address(self, mac_address=None, default=False, disable=False):\n        base_command = 'ip virtual-router mac-address'\n        if not default and not disable:\n            if mac_address is not None:\n                # Check to see if mac_address matches expected format\n                if not re.match(r'(?:[a-f0-9]{2}:){5}[a-f0-9]{2}',\n                                mac_address):\n                    raise ValueError('mac_address must be formatted like:'\n                                     'aa:bb:cc:dd:ee:ff')\n            else:\n                raise ValueError('mac_address must be a properly formatted '\n                                 'address string')\n        if default or disable and not mac_address:\n            current_mac = self._parse_mac_address()\n            if current_mac['mac_address']:\n                base_command = base_command + ' ' + current_mac['mac_address']\n        commands = self.command_builder(base_command, value=mac_address,\n                                        default=default, disable=disable)\n        return self.configure(commands)", "response": "This method will set the virtual - router mac address for the switch."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsearch the config and returns a block of code", "response": "def get_block(self, parent, config='running_config'):\n        \"\"\" Scans the config and returns a block of code\n\n        Args:\n            parent (str): The parent string to search the config for and\n                return the block\n            config (str): A text config string to be searched. Default\n                is to search the running-config of the Node.\n\n        Returns:\n            A string object that represents the block from the config.  If\n            the parent string is not found, then this method will\n            return None.\n\n        \"\"\"\n        try:\n            parent = r'^%s$' % parent\n            return self.node.section(parent, config=config)\n        except TypeError:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nsend the commands list to the node in config mode returning True if the commands are successfully configured False otherwise", "response": "def configure(self, commands):\n        \"\"\"Sends the commands list to the node in config mode\n\n        This method performs configuration the node using the array of\n        commands specified.   This method wraps the configuration commands\n        in a try/except block and stores any exceptions in the error\n        property.\n\n        Note:\n            If the return from this method is False, use the error property\n            to investigate the exception\n\n        Args:\n            commands (list): A list of commands to be sent to the node in\n                config mode\n\n        Returns:\n            True if the commands are executed without exception otherwise\n                False is returned\n        \"\"\"\n        try:\n            self.node.config(commands)\n            return True\n        except (CommandError, ConnectionError):\n            return False"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nbuild a command string that can be used to configure the node s node - level properties.", "response": "def command_builder(self, string, value=None, default=None, disable=None):\n        \"\"\"Builds a command with keywords\n\n        Notes:\n            Negating a command string by overriding 'value' with None or an\n                assigned value that evalutates to false has been deprecated.\n                Please use 'disable' to negate a command.\n\n            Parameters are evaluated in the order 'default', 'disable', 'value'\n\n        Args:\n            string (str): The command string\n            value (str): The configuration setting to subsititue into the\n                command string. If value is a boolean and True, just the\n                command string is used\n            default (bool): Specifies the command should use the default\n                keyword argument. Default preempts disable and value.\n            disable (bool): Specifies the command should use the no\n                keyword argument. Disable preempts value.\n\n        Returns:\n            A command string that can be used to configure the node\n        \"\"\"\n        if default:\n            return 'default %s' % string\n        elif disable:\n            return 'no %s' % string\n        elif value is True:\n            return string\n        elif value:\n            return '%s %s' % (string, value)\n        else:\n            return 'no %s' % string"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the specified interface with the commands", "response": "def configure_interface(self, name, commands):\n        \"\"\"Configures the specified interface with the commands\n\n        Args:\n            name (str): The interface name to configure\n            commands: The commands to configure in the interface\n\n        Returns:\n            True if the commands completed successfully\n        \"\"\"\n        commands = make_iterable(commands)\n        commands.insert(0, 'interface %s' % name)\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self):\n        config = self.config\n        if not config:\n            return None\n\n        response = dict()\n        response.update(self._parse_source_interface(config))\n        response.update(self._parse_servers(config))\n\n        return response", "response": "Returns the current NTP configuration of the node"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes the NTP source entry from the node.", "response": "def delete(self):\n        \"\"\"Delete the NTP source entry from the node.\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n        cmd = self.command_builder('ntp source', disable=True)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ndefaulting the NTP source entry from the node.", "response": "def default(self):\n        \"\"\"Default the NTP source entry from the node.\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n        cmd = self.command_builder('ntp source', default=True)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_source_interface(self, name):\n        cmd = self.command_builder('ntp source', value=name)\n        return self.configure(cmd)", "response": "Assign the NTP source on the node."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_server(self, name, prefer=False):\n        if not name or re.match(r'^[\\s]+$', name):\n            raise ValueError('ntp server name must be specified')\n        if prefer:\n            name = '%s prefer' % name\n        cmd = self.command_builder('ntp server', value=name)\n        return self.configure(cmd)", "response": "Add or update an NTP server entry to the node config"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove an NTP server entry from the node config", "response": "def remove_server(self, name):\n        \"\"\"Remove an NTP server entry from the node config\n\n        Args:\n            name (string): The IP address or FQDN of the NTP server.\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n        cmd = self.command_builder('no ntp server', value=name)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove all NTP server entries from the node config", "response": "def remove_all_servers(self):\n        \"\"\"Remove all NTP server entries from the node config\n\n        Returns:\n            True if the operation succeeds, otherwise False.\n        \"\"\"\n        # 'no ntp' removes all server entries.\n        # For command_builder, disable command 'ntp' gives the desired command\n        cmd = self.command_builder('ntp', disable=True)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the system configuration abstraction", "response": "def get(self):\n        \"\"\"Returns the system configuration abstraction\n\n        The System resource returns the following:\n\n            * hostname (str): The hostname value\n\n        Returns:\n            dict: Represents the node's system configuration\n        \"\"\"\n        resource = dict()\n        resource.update(self._parse_hostname())\n        resource.update(self._parse_iprouting())\n        resource.update(self._parse_banners())\n\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing the global config and returns the hostname value", "response": "def _parse_hostname(self):\n        \"\"\"Parses the global config and returns the hostname value\n\n        Returns:\n            dict: The configured value for hostname.  The returned dict\n                object is intended to be merged into the resource dict\n        \"\"\"\n        value = 'localhost'\n        match = re.search(r'^hostname ([^\\s]+)$', self.config, re.M)\n        if match:\n            value = match.group(1)\n        return dict(hostname=value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nparses the global config and returns the value for both motd and login banners.", "response": "def _parse_banners(self):\n        \"\"\"Parses the global config and returns the value for both motd\n            and login banners.\n\n        Returns:\n           dict: The configure value for modtd and login banners. If the\n                  banner is not set it will return a value of None for that\n                  key. The returned dict object is intendd to be merged\n                  into the resource dict\n        \"\"\"\n        motd_value = login_value = None\n        matches = re.findall('^banner\\s+(login|motd)\\s?$\\n(.*?)$\\nEOF$\\n',\n                             self.config, re.DOTALL | re.M)\n        for match in matches:\n            if match[0].strip() == \"motd\":\n                motd_value = match[1]\n            elif match[0].strip() == \"login\":\n                login_value = match[1]\n\n        return dict(banner_motd=motd_value, banner_login=login_value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconfiguring the global system hostname setting", "response": "def set_hostname(self, value=None, default=False, disable=False):\n        \"\"\"Configures the global system hostname setting\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            value (str): The hostname value\n            default (bool): Controls use of the default keyword\n            disable (bool): Controls the use of the no keyword\n\n        Returns:\n            bool: True if the commands are completed successfully\n        \"\"\"\n        cmd = self.command_builder('hostname', value=value, default=default,\n                                   disable=disable)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the state of global ip routing", "response": "def set_iprouting(self, value=None, default=False, disable=False):\n        \"\"\"Configures the state of global ip routing\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            value(bool): True if ip routing should be enabled or False if\n                ip routing should be disabled\n            default (bool): Controls the use of the default keyword\n            disable (bool): Controls the use of the no keyword\n\n        Returns:\n            bool: True if the commands completed successfully otherwise False\n        \"\"\"\n        if value is False:\n            disable = True\n        cmd = self.command_builder('ip routing', value=value, default=default,\n                                   disable=disable)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_banner(self, banner_type, value=None, default=False,\n                   disable=False):\n        \"\"\"Configures system banners\n\n        Args:\n            banner_type(str): banner to be changed (likely login or motd)\n            value(str): value to set for the banner\n            default (bool): Controls the use of the default keyword\n            disable (bool): Controls the use of the no keyword`\n\n        Returns:\n            bool: True if the commands completed successfully otherwise False\n        \"\"\"\n\n        command_string = \"banner %s\" % banner_type\n        if default is True or disable is True:\n            cmd = self.command_builder(command_string, value=None,\n                                       default=default, disable=disable)\n            return self.configure(cmd)\n        else:\n            if not value.endswith(\"\\n\"):\n                value = value + \"\\n\"\n            command_input = dict(cmd=command_string, input=value)\n            return self.configure([command_input])", "response": "Configures system banners\n\n        Args:\n            banner_type(str): banner to be changed (likely login or motd)\n            value(str): value to set for the banner\n            default (bool): Controls the use of the default keyword\n            disable (bool): Controls the use of the no keyword`\n\n        Returns:\n            bool: True if the commands completed successfully otherwise False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get(self, name):\n        config = self.get_block('interface %s' % name)\n\n        if name[0:2] in ['Et', 'Po'] and not SWITCHPORT_RE.search(config,\n                                                                  re.M):\n            return None\n\n        resource = dict(name=name)\n        resource.update(self._parse_address(config))\n        resource.update(self._parse_mtu(config))\n        return resource", "response": "Returns the specific IP interface properties"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_address(self, config):\n        match = re.search(r'ip address ([^\\s]+)', config)\n        value = match.group(1) if match else None\n        return dict(address=value)", "response": "Parses the config block and returns the IP address value"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _parse_mtu(self, config):\n        match = re.search(r'mtu (\\d+)', config)\n        return dict(mtu=int(match.group(1)))", "response": "Parses the provided configuration block and returns the configured IP MTU value"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nconfigures the interface IP address", "response": "def set_address(self, name, value=None, default=False, disable=False):\n        \"\"\" Configures the interface IP address\n\n        Args:\n            name (string): The interface identifier to apply the interface\n                config to\n\n            value (string): The IP address and mask to set the interface to.\n                The value should be in the format of A.B.C.D/E\n\n            default (bool): Configures the address parameter to its default\n                value using the EOS CLI default command\n\n            disable (bool): Negates the address parameter value using the\n                EOS CLI no command\n\n        Returns:\n            True if the operation succeeds otherwise False.\n\n        \"\"\"\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('ip address', value=value,\n                                             default=default, disable=disable))\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_mtu(self, name, value=None, default=False, disable=False):\n        if value is not None:\n            value = int(value)\n            if not 68 <= value <= 65535:\n                raise ValueError('invalid mtu value')\n\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('mtu', value=value,\n                                             default=default, disable=disable))\n        return self.configure(commands)", "response": "Configures the MTU value for the specified interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the spanning - tree configuration as a dictionary object", "response": "def get(self):\n        \"\"\"Returns the spanning-tree configuration as a dict object\n\n        The dictionary object represents the entire spanning-tree\n        configuration derived from the nodes running config.  This\n        includes both globally configuration attributes as well as\n        interfaces and instances.  See the StpInterfaces and StpInstances\n        classes for the key/value pair definitions.\n\n        Note:\n            See the individual classes for detailed message structures\n\n        Returns:\n            A Python dictionary object of key/value pairs the represent\n            the entire supported spanning-tree configuration::\n\n                {\n                    \"mode\": [mstp, none],\n                    \"interfaces\": {...},\n                    \"instances\": {...}\n                }\n        \"\"\"\n        return dict(interfaces=self.interfaces.getall(),\n                    instances=self.instances.getall())"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconfigure the global spanning - tree mode of the specified resource.", "response": "def set_mode(self, value=None, default=False, disable=False):\n        \"\"\"Configures the global spanning-tree mode\n\n        Note:\n            This configuration parameter is not defaultable\n\n        Args:\n            value (string): The value to configure the global spanning-tree\n                mode of operation.  Valid values include 'mstp', 'none'\n            default (bool): Set the global spanning-tree mode to default.\n            disable (bool): Negate the global spanning-tree mode.\n\n        Returns:\n            True if the configuration operation succeeds otherwise False\n\n        Raises:\n            ValueError if the value is not in the accepted range\n        \"\"\"\n        if not default and not disable:\n            if value not in ['mstp', 'none']:\n                raise ValueError(\"Specified value must be one of \"\n                                 \"'mstp', 'none'\")\n        cmds = self.command_builder('spanning-tree mode', value=value,\n                                    default=default, disable=disable)\n        return self.configure(cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, name):\n        if not isvalidinterface(name):\n            return None\n\n        config = self.get_block(r'^interface\\s%s$' % name)\n        resp = dict()\n        resp.update(self._parse_bpduguard(config))\n        resp.update(self._parse_portfast(config))\n        resp.update(self._parse_portfast_type(config))\n        return resp", "response": "Returns the specified interfaces STP configuration resource object that represents the specified interfaces."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nconfigures the portfast type for the specified interface.", "response": "def set_portfast_type(self, name, value='normal'):\n        \"\"\"Configures the portfast value for the specified interface\n\n        Args:\n            name (string): The interface identifier to configure.  The name\n                must be the full interface name (eg Ethernet1, not Et1).\n\n            value (string): The value to configure the portfast setting to.\n                Valid values include \"edge\", \"network\", \"normal\".  The\n                default value is \"normal\"\n\n        Returns:\n            True if the command succeeds, otherwise False\n\n        Raises:\n            ValueError: Raised if an invalid interface name or value is\n                specified\n\n        \"\"\"\n        if value not in ['network', 'edge', 'normal', None]:\n            raise ValueError('invalid portfast type value specified')\n\n        cmds = ['spanning-tree portfast %s' % value]\n        if value == 'edge':\n            cmds.append('spanning-tree portfast auto')\n        return self.configure_interface(name, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconfigure the portfast value for the specified interface.", "response": "def set_portfast(self, name, value=None, default=False, disable=False):\n        \"\"\"Configures the portfast value for the specified interface\n\n        Args:\n            name (string): The interface identifier to configure.  The name\n                must be the full interface name (eg Ethernet1, not Et1)\n\n            value (bool): True if portfast is enabled otherwise False\n\n            default (bool): Configures the portfast parameter to its default\n                value using the EOS CLI default config command\n\n            disable (bool): Negates the portfast parameter using the EOS\n                CLI no config command\n\n        Returns:\n            True if the command succeeds, otherwise False\n\n        Raises:\n            ValueError: Rasied if an invalid interface name is specified\n\n            TypeError: Raised if the value keyword argument does not evaluate\n                to a valid boolean\n\n        \"\"\"\n        if value is False:\n            disable = True\n        string = 'spanning-tree portfast'\n        cmds = self.command_builder(string, value=value, default=default,\n                                    disable=disable)\n        return self.configure_interface(name, cmds)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_bpduguard(self, name, value=False, default=False, disable=False):\n        value = 'enable' if value else 'disable'\n        string = 'spanning-tree bpduguard'\n        cmds = self.command_builder(string, value=value, default=default,\n                                    disable=disable)\n        return self.configure_interface(name, cmds)", "response": "Configures the bpduguard value for the specified interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a list of module names in a directory.", "response": "def get_module_names(p):\n    '''Accepts a path to search for modules. The method will filter on files\n    that end in .pyc or files that start with __.\n\n    Arguments:\n        p (string): The path to search\n    Returns:\n        list of file names\n    '''\n    mods = list()\n    mods = [f.split('.')[0] for f in listdir(p)\n            if isfile(join(p, f)) and not f.endswith('.pyc') and not f.startswith('__')]\n    print len(mods)\n    return mods"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef process_modules(modules):\n    '''Accepts dictionary of 'client' and 'api' modules and creates\n    the corresponding files.\n    '''\n    for mod in modules['client']:\n        directory = '%s/client_modules' % HERE\n        if not exists(directory):\n            makedirs(directory)\n        write_module_file(mod, directory, 'pyeapi')\n\n    for mod in modules['api']:\n        directory = '%s/api_modules' % HERE\n        if not exists(directory):\n            makedirs(directory)\n        write_module_file(mod, directory, 'pyeapi.api')\n\n    create_index(modules)", "response": "Takes dictionary of client and api modules and creates\n    the corresponding files."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_module_file(name, path, package):\n    '''Creates an RST file for the module name passed in. It places it in the\n    path defined\n    '''\n    file_path = join(path, '%s.rst' % name)\n    mod_file = open(file_path, 'w')\n\n    mod_file.write('%s\\n' % AUTOGEN)\n    mod_file.write('%s\\n' % name.title())\n    mod_file.write('=' * len(name))\n    mod_file.write('\\n\\n')\n    mod_file.write('.. toctree::\\n')\n    mod_file.write('   :maxdepth: 1\\n\\n')\n    mod_file.write('.. automodule:: %s.%s\\n' % (package, name))\n    mod_file.write('   :members:\\n')\n    mod_file.write('   :undoc-members:\\n')\n    mod_file.write('   :show-inheritance:\\n')", "response": "Creates an RST file for the module name passed in."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef import_module(name):\n    parts = name.split('.')\n    path = None\n    module_name = ''\n    fhandle = None\n\n    for index, part in enumerate(parts):\n        module_name = part if index == 0 else '%s.%s' % (module_name, part)\n        path = [path] if path is not None else path\n\n        try:\n            fhandle, path, descr = imp.find_module(part, path)\n            if module_name in sys.modules:\n                # since imp.load_module works like reload, need to be sure not\n                # to reload a previously loaded module\n                mod = sys.modules[module_name]\n            else:\n                mod = imp.load_module(module_name, fhandle, path, descr)\n        finally:\n            # lets be sure to clean up after ourselves\n            if fhandle:\n                fhandle.close()\n\n    return mod", "response": "Imports a module into the current runtime environment."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nattempting to load a module into the current environment", "response": "def load_module(name):\n    \"\"\" Attempts to load a module into the current environment\n\n    This function will load a module specified by name.  The module\n    name is first checked to see if it is already loaded and will return\n    the module if it is.   If the module hasn't been previously loaded\n    it will attempt to import it\n\n    Args:\n        name (str): Specifies the full name of the module.  For instance\n            pyeapi.api.vlans\n\n    Returns:\n        The module that has been imported or retrieved from the sys modules\n\n    \"\"\"\n    try:\n        mod = None\n        mod = sys.modules[name]\n    except KeyError:\n        mod = import_module(name)\n    finally:\n        if not mod:\n            raise ImportError('unable to import module %s' % name)\n        return mod"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef debug(text):\n    frame = inspect.currentframe().f_back\n    module = frame.f_globals['__name__']\n    func = frame.f_code.co_name\n    msg = \"%s.%s: %s\" % (module, func, text)\n    _LOGGER.debug(msg)", "response": "Log a message to syslog and stderr"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts the supplied value to a list object", "response": "def make_iterable(value):\n    \"\"\"Converts the supplied value to a list object\n\n    This function will inspect the supplied value and return an\n    iterable in the form of a list.\n\n    Args:\n        value (object): An valid Python object\n\n    Returns:\n        An iterable object of type list\n    \"\"\"\n    if sys.version_info <= (3, 0):\n        # Convert unicode values to strings for Python 2\n        if isinstance(value, unicode):\n            value = str(value)\n    if isinstance(value, str) or isinstance(value, dict):\n        value = [value]\n\n    if not isinstance(value, collections.Iterable):\n        raise TypeError('value must be an iterable object')\n\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nexpanding a delimited string of ranged integers into a list of strings", "response": "def expand_range(arg, value_delimiter=',', range_delimiter='-'):\n    \"\"\"\n    Expands a delimited string of ranged integers into a list of strings\n\n    :param arg: The string range to expand\n    :param value_delimiter: The delimiter that separates values\n    :param range_delimiter: The delimiter that signifies a range of values\n\n    :return: An array of expanded string values\n    :rtype: list\n    \"\"\"\n    values = list()\n    expanded = arg.split(value_delimiter)\n    for item in expanded:\n        if range_delimiter in item:\n            start, end = item.split(range_delimiter)\n            _expand = range(int(start), int(end) + 1)\n            values.extend([str(x) for x in _expand])\n        else:\n            values.extend([item])\n    return [str(x) for x in values]"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef collapse_range(arg, value_delimiter=',', range_delimiter='-'):\n    values = list()\n    expanded = arg.split(value_delimiter)\n    range_start = None\n\n    for v1, v2 in lookahead(expanded):\n        if v2:\n            v1 = int(v1)\n            v2 = int(v2)\n            if (v1 + 1) == v2:\n                if not range_start:\n                    range_start = v1\n            elif range_start:\n                item = '{}{}{}'.format(range_start, range_delimiter, v1)\n                values.extend([item])\n                range_start = None\n            else:\n                values.extend([v1])\n        elif range_start:\n            item = '{}{}{}'.format(range_start, range_delimiter, v1)\n            values.extend([item])\n            range_start = None\n        else:\n            values.extend([v1])\n    return [str(x) for x in values]", "response": "Collapses a list of values into a range set"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dictionary object that represents a switchport", "response": "def get(self, name):\n        \"\"\"Returns a dictionary object that represents a switchport\n\n        The Switchport resource returns the following:\n\n            * name (str): The name of the interface\n            * mode (str): The switchport mode value\n            * access_vlan (str): The switchport access vlan value\n            * trunk_native_vlan (str): The switchport trunk native vlan vlaue\n            * trunk_allowed_vlans (str): The trunk allowed vlans value\n            * trunk_groups (list): The list of trunk groups configured\n\n        Args:\n            name (string): The interface identifier to get.  Note: Switchports\n                are only supported on Ethernet and Port-Channel interfaces\n\n        Returns:\n            dict: A Python dictionary object of key/value pairs that represent\n                the switchport configuration for the interface specified  If\n                the specified argument is not a switchport then None\n                is returned\n        \"\"\"\n        config = self.get_block('interface %s' % name)\n        if 'no switchport\\n' in config:\n            return\n\n        resource = dict(name=name)\n        resource.update(self._parse_mode(config))\n        resource.update(self._parse_access_vlan(config))\n        resource.update(self._parse_trunk_native_vlan(config))\n        resource.update(self._parse_trunk_allowed_vlans(config))\n        resource.update(self._parse_trunk_groups(config))\n        return resource"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _parse_mode(self, config):\n        value = re.search(r'switchport mode (\\w+)', config, re.M)\n        return dict(mode=value.group(1))", "response": "Scans the specified config and parses the switchport mode value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans the specified config and parses the trunk group values into a dict of the trunk group values that can be merged into the resource dict COOKIE", "response": "def _parse_trunk_groups(self, config):\n        \"\"\"Scans the specified config and parses the trunk group values\n\n        Args:\n            config (str): The interface configuraiton blcok\n\n        Returns:\n            A dict object with the trunk group values that can be merged\n                into the resource dict\n        \"\"\"\n        values = re.findall(r'switchport trunk group ([^\\s]+)', config, re.M)\n        return dict(trunk_groups=values)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_access_vlan(self, config):\n        value = re.search(r'switchport access vlan (\\d+)', config)\n        return dict(access_vlan=value.group(1))", "response": "Scans the specified config and parses the access - vlan value and returns a dict object with the value of the switchport access - vlan value."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nscan the specified config and parses the trunk native vlan value", "response": "def _parse_trunk_native_vlan(self, config):\n        \"\"\"Scans the specified config and parse the trunk native vlan value\n\n        Args:\n            config (str): The interface configuration block to scan\n\n        Returns:\n            dict: A Python dict object with the value of switchport trunk\n                native vlan value.  The dict returned is intended to be\n                merged into the resource dict\n        \"\"\"\n        match = re.search(r'switchport trunk native vlan (\\d+)', config)\n        return dict(trunk_native_vlan=match.group(1))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _parse_trunk_allowed_vlans(self, config):\n        match = re.search(r'switchport trunk allowed vlan (.+)$', config, re.M)\n        return dict(trunk_allowed_vlans=match.group(1))", "response": "Scans the specified config and parses the trunk allowed vlans value\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a dictionary object to all Switchports", "response": "def getall(self):\n        \"\"\"Returns a dict object to all Switchports\n\n        This method will return all of the configured switchports as a\n        dictionary object keyed by the interface identifier.\n\n        Returns:\n            A Python dictionary object that represents all configured\n                switchports in the current running configuration\n        \"\"\"\n        interfaces_re = re.compile(r'(?<=^interface\\s)([Et|Po].+)$', re.M)\n\n        response = dict()\n        for name in interfaces_re.findall(self.config):\n            interface = self.get(name)\n            if interface:\n                response[name] = interface\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconfigures the switchport mode for the specified logical layer 2 switchport.", "response": "def set_mode(self, name, value=None, default=False, disable=False):\n        \"\"\"Configures the switchport mode\n\n        Args:\n            name (string): The interface identifier to create the logical\n                layer 2 switchport for.  The name must be the full interface\n                name and not an abbreviated interface name (eg Ethernet1, not\n                Et1)\n\n            value (string): The value to set the mode to.  Accepted values\n                for this argument are access or trunk\n\n            default (bool): Configures the mode parameter to its default\n                value using the EOS CLI\n\n            disable (bool): Negate the mode parameter using the EOS CLI\n\n        Returns:\n            True if the create operation succeeds otherwise False.\n        \"\"\"\n        string = 'switchport mode'\n        command = self.command_builder(string, value=value, default=default,\n                                       disable=disable)\n        return self.configure_interface(name, command)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_trunk_groups(self, intf, value=None, default=False, disable=False):\n        if default:\n            cmd = 'default switchport trunk group'\n            return self.configure_interface(intf, cmd)\n\n        if disable:\n            cmd = 'no switchport trunk group'\n            return self.configure_interface(intf, cmd)\n\n        current_value = self.get(intf)['trunk_groups']\n        failure = False\n\n        value = make_iterable(value)\n\n        for name in set(value).difference(current_value):\n            if not self.add_trunk_group(intf, name):\n                failure = True\n\n        for name in set(current_value).difference(value):\n            if not self.remove_trunk_group(intf, name):\n                failure = True\n\n        return not failure", "response": "Configures the switchport trunk group value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_trunk_group(self, intf, value):\n        string = 'switchport trunk group {}'.format(value)\n        return self.configure_interface(intf, string)", "response": "Adds the specified trunk group to the interface\n           "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef remove_trunk_group(self, intf, value):\n        string = 'no switchport trunk group {}'.format(value)\n        return self.configure_interface(intf, string)", "response": "Removes a specified trunk group from the interface\n           "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, name):\n        config = self.get_block('^interface %s' % name)\n        if not config:\n            return None\n\n        resource = dict(name=name, type='generic')\n        resource.update(self._parse_shutdown(config))\n        resource.update(self._parse_description(config))\n        return resource", "response": "Returns a generic interface as a set of key value pairs that represents the specified interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nscan the specified config block and returns the description value", "response": "def _parse_description(self, config):\n        \"\"\"Scans the specified config block and returns the description value\n\n        Args:\n            config (str): The interface config block to scan\n\n        Returns:\n            dict: Returns a dict object with the description value retrieved\n                from the config block.  If the description value is not\n                configured, None is returned as the value.  The returned dict\n                is intended to be merged into the interface resource dict.\n        \"\"\"\n        value = None\n        match = re.search(r'description (.+)$', config, re.M)\n        if match:\n            value = match.group(1)\n        return dict(description=value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_encapsulation(self, name, vid, default=False, disable=False):\n        if '.' not in name:\n            raise NotImplementedError('parameter encapsulation can only be'\n                                      ' set on subinterfaces')\n        if name[0:2] not in ['Et', 'Po']:\n            raise NotImplementedError('parameter encapsulation can only be'\n                                      ' set on Ethernet and Port-Channel'\n                                      ' subinterfaces')\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('encapsulation dot1q vlan',\n                                             str(vid), default=default,\n                                             disable=disable))\n        return self.configure(commands)", "response": "Configures the encapsulation value for the specified subinterface."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef set_description(self, name, value=None, default=False, disable=False):\n        string = 'description'\n        commands = self.command_builder(string, value=value, default=default,\n                                        disable=disable)\n        return self.configure_interface(name, commands)", "response": "Configures the description of the specified nicely identified interface."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconfiguring the shutdown state for the specified resource store.", "response": "def set_shutdown(self, name, default=False, disable=True):\n        \"\"\"Configures the interface shutdown state\n\n        Default configuration for set_shutdown is disable=True, meaning\n        'no shutdown'. Setting both default and disable to False will\n        effectively enable shutdown on the interface.\n\n        Args:\n            name (string): The interface identifier.  It must be a full\n                interface name (ie Ethernet, not Et)\n\n            default (boolean): Specifies to default the interface shutdown\n\n            disable (boolean): Specifies to disable interface shutdown, i.e.\n                disable=True => no shutdown\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('shutdown', value=True,\n                                             default=default, disable=disable))\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, name):\n        config = self.get_block('^interface %s' % name)\n\n        if not config:\n            return None\n\n        resource = super(EthernetInterface, self).get(name)\n        resource.update(dict(name=name, type='ethernet'))\n        resource.update(self._parse_sflow(config))\n        resource.update(self._parse_flowcontrol_send(config))\n        resource.update(self._parse_flowcontrol_receive(config))\n        return resource", "response": "Returns an interface as a set of key - value pairs that represent\n            the current configuration for the specified node."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nscanning the config block and returns the flowcontrol send value", "response": "def _parse_flowcontrol_send(self, config):\n        \"\"\"Scans the config block and returns the flowcontrol send value\n\n        Args:\n            config (str): The interface config block to scan\n\n        Returns:\n            dict: Returns a dict object with the flowcontrol send value\n                retrieved from the config block.  The returned dict object\n                is intended to be merged into the interface resource dict\n        \"\"\"\n        value = 'off'\n        match = re.search(r'flowcontrol send (\\w+)$', config, re.M)\n        if match:\n            value = match.group(1)\n        return dict(flowcontrol_send=value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _parse_flowcontrol_receive(self, config):\n        value = 'off'\n        match = re.search(r'flowcontrol receive (\\w+)$', config, re.M)\n        if match:\n            value = match.group(1)\n        return dict(flowcontrol_receive=value)", "response": "Scans the config block and returns the flowcontrol receive value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_flowcontrol_send(self, name, value=None, default=False,\n                             disable=False):\n        \"\"\"Configures the interface flowcontrol send value\n\n        Args:\n            name (string): The interface identifier.  It must be a full\n                interface name (ie Ethernet, not Et)\n\n            value (boolean): True if the interface should enable sending flow\n                control packets, otherwise False\n\n            default (boolean): Specifies to default the interface flow\n                control send value\n\n            disable (boolean): Specifies to disable the interface flow\n                control send value\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        return self.set_flowcontrol(name, 'send', value, default, disable)", "response": "Configures the flowcontrol send value for the specified nicely identified interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_flowcontrol_receive(self, name, value=None, default=False,\n                                disable=False):\n        \"\"\"Configures the interface flowcontrol receive value\n\n        Args:\n            name (string): The interface identifier.  It must be a full\n                interface name (ie Ethernet, not Et)\n\n            value (boolean): True if the interface should enable receiving\n                flow control packets, otherwise False\n\n            default (boolean): Specifies to default the interface flow\n                control receive value\n\n            disable (boolean): Specifies to disable the interface flow\n                control receive value\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        return self.set_flowcontrol(name, 'receive', value, default, disable)", "response": "Configures the flowcontrol receive value for the specified nicely identified interface."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef set_flowcontrol(self, name, direction, value=None, default=False,\n                        disable=False):\n        \"\"\"Configures the interface flowcontrol value\n\n        Args:\n            name (string): The interface identifier.  It must be a full\n                interface name (ie Ethernet, not Et)\n\n            direction (string): one of either 'send' or 'receive'\n\n            value (boolean): True if the interface should enable flow control\n                packet handling, otherwise False\n\n            default (boolean): Specifies to default the interface flow control\n                send or receive value\n\n            disable (boolean): Specifies to disable the interface flow control\n                send or receive value\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        if value is not None:\n            if value not in ['on', 'off']:\n                raise ValueError('invalid flowcontrol value')\n\n        if direction not in ['send', 'receive']:\n            raise ValueError('invalid direction specified')\n\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('flowcontrol %s' % direction,\n                                             value=value, default=default,\n                                             disable=disable))\n        return self.configure(commands)", "response": "Configures the flow control value of the specified interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the sFlow state on the interface with the specified name.", "response": "def set_sflow(self, name, value=None, default=False, disable=False):\n        \"\"\"Configures the sFlow state on the interface\n\n        Args:\n            name (string): The interface identifier.  It must be a full\n                interface name (ie Ethernet, not Et)\n\n            value (boolean): True if sFlow should be enabled otherwise False\n\n            default (boolean): Specifies the default value for sFlow\n\n            disable (boolean): Specifies to disable sFlow\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        if value not in [True, False, None]:\n            raise ValueError\n\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('sflow enable', value=value,\n                                             default=default, disable=disable))\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef set_vrf(self, name, vrf, default=False, disable=False):\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('vrf forwarding', vrf,\n                                             default=default, disable=disable))\n        return self.configure(commands)", "response": "Applies a VRF to the interface"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a Port - Channel interface as a set of key - value pairs that represents the specified interface.", "response": "def get(self, name):\n        \"\"\"Returns a Port-Channel interface as a set of key/value pairs\n\n        Args:\n            name (str): The interface identifier to retrieve from the\n                running-configuration\n\n        Returns:\n            A Python dictionary object of key/value pairs that represents\n            the interface configuration.  If the specified interface\n            does not exist, then None is returned::\n\n                {\n                    \"name\": <string>,\n                    \"type\": \"portchannel\",\n                    \"members\": <arrary of interface names>,\n                    \"minimum_links: <integer>,\n                    \"lacp_mode\": [on, active, passive]\n                }\n\n        \"\"\"\n        config = self.get_block('^interface %s' % name)\n        if not config:\n            return None\n\n        response = super(PortchannelInterface, self).get(name)\n        response.update(dict(name=name, type='portchannel'))\n\n        response['members'] = self.get_members(name)\n        response['lacp_mode'] = self.get_lacp_mode(name)\n        response.update(self._parse_minimum_links(config))\n        response.update(self._parse_lacp_timeout(config))\n        response.update(self._parse_lacp_fallback(config))\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_lacp_mode(self, name):\n        members = self.get_members(name)\n        if not members:\n            return DEFAULT_LACP_MODE\n\n        for member in self.get_members(name):\n            match = re.search(r'channel-group\\s\\d+\\smode\\s(?P<value>.+)',\n                              self.get_block('^interface %s' % member))\n            return match.group('value')", "response": "Returns the LACP mode for the specified Port - Channel interface."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_members(self, name):\n        grpid = re.search(r'(\\d+)', name).group()\n        command = 'show port-channel %s all-ports' % grpid\n        config = self.node.enable(command, 'text')\n        return re.findall(r'\\b(?!Peer)Ethernet[\\d/]*\\b',\n                          config[0]['result']['output'])", "response": "Returns the list of member interfaces for the specified Port - Channel"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_members(self, name, members, mode=None):\n        commands = list()\n        grpid = re.search(r'(\\d+)', name).group()\n        current_members = self.get_members(name)\n        lacp_mode = self.get_lacp_mode(name)\n        if mode and mode != lacp_mode:\n            lacp_mode = mode\n            self.set_lacp_mode(grpid, lacp_mode)\n\n        # remove members from the current port-channel interface\n        for member in set(current_members).difference(members):\n            commands.append('interface %s' % member)\n            commands.append('no channel-group %s' % grpid)\n\n        # add new member interfaces to the port-channel interface\n        for member in set(members).difference(current_members):\n            commands.append('interface %s' % member)\n            commands.append('channel-group %s mode %s' % (grpid, lacp_mode))\n\n        return self.configure(commands) if commands else True", "response": "Configures the array of member interfaces for the Port - Channel"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_lacp_mode(self, name, mode):\n        if mode not in ['on', 'passive', 'active']:\n            return False\n\n        grpid = re.search(r'(\\d+)', name).group()\n\n        remove_commands = list()\n        add_commands = list()\n\n        for member in self.get_members(name):\n            remove_commands.append('interface %s' % member)\n            remove_commands.append('no channel-group %s' % grpid)\n            add_commands.append('interface %s' % member)\n            add_commands.append('channel-group %s mode %s' % (grpid, mode))\n\n        return self.configure(remove_commands + add_commands)", "response": "Configures the LACP mode of the member interfaces of the Port - Channel interface."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_lacp_fallback(self, name, mode=None):\n        if mode not in ['disabled', 'static', 'individual']:\n            return False\n        disable = True if mode == 'disabled' else False\n        commands = ['interface %s' % name]\n        commands.append(self.command_builder('port-channel lacp fallback',\n                                             value=mode, disable=disable))\n        return self.configure(commands)", "response": "Configures the Port - Channel LACP fallback to the specified LACP interface."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nconfigure the Port - Channel LACP fallback timeout in seconds.", "response": "def set_lacp_timeout(self, name, value=None):\n        \"\"\"Configures the Port-Channel LACP fallback timeout\n           The fallback timeout configures the period an interface in\n           fallback mode remains in LACP mode without receiving a PDU.\n\n        Args:\n            name(str): The Port-Channel interface name\n\n            value(int): port-channel lacp fallback timeout in seconds\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        commands = ['interface %s' % name]\n        string = 'port-channel lacp fallback timeout'\n        commands.append(self.command_builder(string, value=value))\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a Vxlan interface as a set of key - value pairs that represents the specified Vxlan interface.", "response": "def get(self, name):\n        \"\"\"Returns a Vxlan interface as a set of key/value pairs\n\n        The Vxlan interface resource returns the following:\n\n            * name (str): The name of the interface\n            * type (str): Always returns 'vxlan'\n            * source_interface (str): The vxlan source-interface value\n            * multicast_group (str): The vxlan multicast-group value\n            * udp_port (int): The vxlan udp-port value\n            * vlans (dict): The vlan to vni mappings\n            * flood_list (list): The list of global VTEP flood list\n            * multicast_decap (bool): If the mutlicast decap\n                                      feature is configured\n\n        Args:\n            name (str): The interface identifier to retrieve from the\n                running-configuration\n\n        Returns:\n            A Python dictionary object of key/value pairs that represents\n                the interface configuration.  If the specified interface\n                does not exist, then None is returned\n        \"\"\"\n        config = self.get_block('^interface %s' % name)\n        if not config:\n            return None\n\n        response = super(VxlanInterface, self).get(name)\n        response.update(dict(name=name, type='vxlan'))\n\n        response.update(self._parse_source_interface(config))\n        response.update(self._parse_multicast_group(config))\n        response.update(self._parse_udp_port(config))\n        response.update(self._parse_vlans(config))\n        response.update(self._parse_flood_list(config))\n        response.update(self._parse_multicast_decap(config))\n\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _parse_source_interface(self, config):\n        match = re.search(r'vxlan source-interface ([^\\s]+)', config)\n        value = match.group(1) if match else self.DEFAULT_SRC_INTF\n        return dict(source_interface=value)", "response": "Parses the provided config block and returns the vxlan source - interface value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_vtep(self, name, vtep, vlan=None):\n        if not vlan:\n            cmd = 'vxlan flood vtep add {}'.format(vtep)\n        else:\n            cmd = 'vxlan vlan {} flood vtep add {}'.format(vlan, vtep)\n        return self.configure_interface(name, cmd)", "response": "Adds a new VTEP endpoint to the global or local flood list\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves a VTEP endpoint from the global or local flood list.", "response": "def remove_vtep(self, name, vtep, vlan=None):\n        \"\"\"Removes a VTEP endpoint from the global or local flood list\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            name (str): The name of the interface to configure\n            vtep (str): The IP address of the remote VTEP endpoint to add\n            vlan (str): The VLAN ID associated with this VTEP.  If the VLAN\n            keyword is used, then the VTEP is configured as a local flood\n            endpoing\n\n        Returns:\n            True if the command completes successfully\n        \"\"\"\n        if not vlan:\n            cmd = 'vxlan flood vtep remove {}'.format(vtep)\n        else:\n            cmd = 'vxlan vlan {} flood vtep remove {}'.format(vlan, vtep)\n        return self.configure_interface(name, cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd a new vlan to the vni mapping for the interface", "response": "def update_vlan(self, name, vid, vni):\n        \"\"\"Adds a new vlan to vni mapping for the interface\n\n        EosVersion:\n            4.13.7M\n\n        Args:\n            vlan (str, int): The vlan id to map to the vni\n            vni (str, int): The vni value to use\n\n        Returns:\n            True if the command completes successfully\n\n        \"\"\"\n        cmd = 'vxlan vlan %s vni %s' % (vid, vni)\n        return self.configure_interface(name, cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns all local users configuration as a nested resource dict object", "response": "def getall(self):\n        \"\"\"Returns all local users configuration as a resource dict\n\n        Returns:\n            dict: A dict of usernames with a nested resource dict object\n        \"\"\"\n        users = self.users_re.findall(self.config, re.M)\n        resources = dict()\n        for user in users:\n            resources.update(self._parse_username(user))\n        return resources"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscans the config block and returns the username as a dict", "response": "def _parse_username(self, config):\n        \"\"\"Scans the config block and returns the username as a dict\n\n        Args:\n            config (str): The config block to parse\n\n        Returns:\n            dict: A resource dict that is intended to be merged into the\n                user resource\n        \"\"\"\n        (username, priv, role, nopass, fmt, secret, sshkey) = config\n        resource = dict()\n        resource['privilege'] = priv\n        resource['role'] = role\n        resource['nopassword'] = nopass == 'nopassword'\n        resource['format'] = fmt\n        resource['secret'] = secret\n        resource['sshkey'] = sshkey\n        return {username: resource}"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ncreating a new user on the local system.", "response": "def create(self, name, nopassword=None, secret=None, encryption=None):\n        \"\"\"Creates a new user on the local system.\n\n        Creating users requires either a secret (password) or the nopassword\n        keyword to be specified.\n\n        Args:\n            name (str): The name of the user to craete\n\n            nopassword (bool): Configures the user to be able to authenticate\n                without a password challenage\n\n            secret (str): The secret (password) to assign to this user\n\n            encryption (str): Specifies how the secret is encoded.  Valid\n                values are \"cleartext\", \"md5\", \"sha512\".  The default is\n                \"cleartext\"\n\n        Returns:\n            True if the operation was successful otherwise False\n\n        Raises:\n            TypeError: if the required arguments are not satisfied\n        \"\"\"\n        if secret is not None:\n            return self.create_with_secret(name, secret, encryption)\n        elif nopassword is True:\n            return self.create_with_nopassword(name)\n        else:\n            raise TypeError('either \"nopassword\" or \"secret\" must be '\n                            'specified to create a user')"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates a new user on the local node with the given secret.", "response": "def create_with_secret(self, name, secret, encryption):\n        \"\"\"Creates a new user on the local node\n\n        Args:\n            name (str): The name of the user to craete\n\n            secret (str): The secret (password) to assign to this user\n\n            encryption (str): Specifies how the secret is encoded.  Valid\n                values are \"cleartext\", \"md5\", \"sha512\".  The default is\n                \"cleartext\"\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        try:\n            encryption = encryption or DEFAULT_ENCRYPTION\n            enc = ENCRYPTION_MAP[encryption]\n        except KeyError:\n            raise TypeError('encryption must be one of \"cleartext\", \"md5\"'\n                            ' or \"sha512\"')\n\n        cmd = 'username %s secret %s %s' % (name, enc, secret)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_privilege(self, name, value=None):\n        cmd = 'username %s' % name\n        if value is not None:\n            if not isprivilege(value):\n                raise TypeError('priviledge value must be between 0 and 15')\n            cmd += ' privilege %s' % value\n        else:\n            cmd += ' privilege 1'\n        return self.configure(cmd)", "response": "Configures the user privilege value in EOS\n           "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconfigure the user role vale in EOS", "response": "def set_role(self, name, value=None, default=False, disable=False):\n        \"\"\"Configures the user role vale in EOS\n\n        Args:\n            name (str): The name of the user to create\n\n            value (str): The value to configure for the user role\n\n            default (bool): Configure the user role using the EOS CLI\n                default command\n\n            disable (bool): Negate the user role using the EOS CLI no command\n\n        Returns:\n            True if the operation was successful otherwise False\n        \"\"\"\n        cmd = self.command_builder('username %s role' % name, value=value,\n                                   default=default, disable=disable)\n        return self.configure(cmd)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_connection(transport, **kwargs):\n    if transport not in TRANSPORTS:\n        raise TypeError('invalid transport specified')\n    klass = TRANSPORTS[transport]\n    return klass(**kwargs)", "response": "Creates an EapiConnection object based on the transport keyword."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef connect(transport=None, host='localhost', username='admin',\n            password='', port=None, timeout=60, return_node=False, **kwargs):\n    \"\"\" Creates a connection using the supplied settings\n\n    This function will create a connection to an Arista EOS node using\n    the arguments.  All arguments are optional with default values.\n\n    Args:\n        transport (str): Specifies the type of connection transport to use.\n            Valid values for the connection are socket, http_local, http, and\n            https.  The default value is specified in DEFAULT_TRANSPORT\n        host (str): The IP addres or DNS host name of the connection device.\n            The default value is 'localhost'\n        username (str): The username to pass to the device to authenticate\n            the eAPI connection.   The default value is 'admin'\n        password (str): The password to pass to the device to authenticate\n            the eAPI connection.  The default value is ''\n        port (int): The TCP port of the endpoint for the eAPI connection.  If\n            this keyword is not specified, the default value is automatically\n            determined by the transport type. (http=80, https=443)\n        return_node (bool): Returns a Node object if True, otherwise\n            returns an EapiConnection object.\n\n\n    Returns:\n        An instance of an EapiConnection object for the specified transport.\n\n    \"\"\"\n    transport = transport or DEFAULT_TRANSPORT\n    connection = make_connection(transport, host=host, username=username,\n                                 password=password, port=port, timeout=timeout)\n    if return_node:\n        return Node(connection, transport=transport, host=host,\n                    username=username, password=password, port=port, **kwargs)\n    return connection", "response": "Creates a connection to Arista EOS node using the supplied settings"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate a Node instance based on an entry from the config file.", "response": "def connect_to(name):\n    \"\"\"Creates a node instance based on an entry from the config\n\n    This function will retrieve the settings for the specified connection\n    from the config and return a Node instance.  The configuration must\n    be loaded prior to calling this function.\n\n    Args:\n        name (str): The name of the connection to load from the config.  The\n            name argument should be the connection name (everything right of\n            the colon from the INI file)\n\n    Returns:\n        This function will return an instance of Node with the settings\n            from the config instance.\n\n    Raises:\n        AttributeError: raised if the specified configuration name is not\n            found in the loaded configuration\n\n    \"\"\"\n    kwargs = config_for(name)\n\n    if not kwargs:\n        raise AttributeError('connection profile not found in config')\n\n    node = connect(return_node=True, **kwargs)\n    return node"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning all of the loaded connections names as a list", "response": "def connections(self):\n        \"\"\"\n        Returns all of the loaded connections names as a list\n        \"\"\"\n        conn = lambda x: str(x).replace('connection:', '')\n        return [conn(name) for name in self.sections()]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nloading the eapi. conf file and returns the entry number.", "response": "def autoload(self):\n        \"\"\" Loads the eapi.conf file\n\n        This method will use the module variable CONFIG_SEARCH_PATH to\n        attempt to locate a valid eapi.conf file if a filename is not already\n        configured.   This method will load the first eapi.conf file it\n        finds and then return.\n\n        The CONFIG_SEARCH_PATH can be overridden using an environment variable\n        by setting EAPI_CONF.\n\n        \"\"\"\n        path = list(CONFIG_SEARCH_PATH)\n        if 'EAPI_CONF' in os.environ:\n            path = os.environ['EAPI_CONF']\n        elif self.filename:\n            path = self.filename\n\n        path = make_iterable(path)\n\n        for filename in path:\n            filename = os.path.expanduser(filename)\n            if os.path.exists(filename):\n                self.filename = filename\n                return self.read(filename)\n\n        self._add_default_connection()"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read(self, filename):\n\n        try:\n            SafeConfigParser.read(self, filename)\n        except SafeConfigParserError as exc:\n            # Ignore file and syslog a message on SafeConfigParser errors\n            msg = (\"%s: parsing error in eapi conf file: %s\" %\n                   (type(exc).__name__, filename))\n            debug(msg)\n\n        self._add_default_connection()\n\n        for name in self.sections():\n            if name.startswith('connection:') and \\\n               'host' not in dict(self.items(name)):\n\n                self.set(name, 'host', name.split(':')[1])\n        self.generate_tags()", "response": "Reads the file specified by filename into the internal dictionary."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating the tags with collection with hosts", "response": "def generate_tags(self):\n        \"\"\" Generates the tags with collection with hosts\n        \"\"\"\n        self.tags = dict()\n        for section in self.sections():\n            if self.has_option(section, 'tags'):\n                tags = self.get(section, 'tags')\n                for tag in [str(t).strip() for t in tags.split(',')]:\n                    if tag not in self.tags:\n                        self.tags[tag] = list()\n                    self.tags[tag].append(section.split(':')[1])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreloading the configuration instance using the last available configuration file.", "response": "def reload(self):\n        \"\"\"Reloades the configuration\n\n        This method will reload the configuration instance using the last\n        known filename.  Note this method will initially clear the\n        configuration and reload all entries.\n\n        \"\"\"\n        for section in self.sections():\n            self.remove_section(section)\n        self.autoload()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_connection(self, name):\n        name = 'connection:{}'.format(name)\n        if not self.has_section(name):\n            return None\n        return dict(self.items(name))", "response": "Returns the properties for a connection name"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds a connection to the configuration", "response": "def add_connection(self, name, **kwargs):\n        \"\"\"Adds a connection to the configuration\n\n        This method will add a connection to the configuration.  The connection\n        added is only available for the lifetime of the object and is not\n        persisted.\n\n        Note:\n            If a call is made to load() or reload(), any connections added\n            with this method must be re-added to the config instance\n\n        Args:\n            name (str): The name of the connection to add to the config.  The\n                name provided will automatically be prepended with the string\n                connection:\n            **kwargs (dict); The set of properties used to provide the node\n                configuration\n\n        \"\"\"\n        name = 'connection:{}'.format(name)\n        self.add_section(name)\n        for key, value in list(kwargs.items()):\n            self.set(name, key, value)\n        self.generate_tags()"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nparse version and model information out of show version output and uses the output to populate class properties.", "response": "def _get_version_properties(self):\n        \"\"\"Parses version and model information out of 'show version' output\n        and uses the output to populate class properties.\n        \"\"\"\n        # Parse out version info\n        output = self.enable('show version')\n        self._version = str(output[0]['result']['version'])\n        match = re.match('[\\d.\\d]+', output[0]['result']['version'])\n        if match:\n            self._version_number = str(match.group(0))\n        else:\n            self._version_number = str(output[0]['result']['version'])\n        # Parse out model number\n        match = re.search('\\d\\d\\d\\d', output[0]['result']['modelName'])\n        if match:\n            self._model = str(match.group(0))\n        else:\n            self._model = str(output[0]['result']['modelName'])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef config(self, commands, **kwargs):\n        commands = make_iterable(commands)\n        commands = list(commands)\n\n        # push the configure command onto the command stack\n        commands.insert(0, 'configure terminal')\n        response = self.run_commands(commands, **kwargs)\n\n        if self.autorefresh:\n            self.refresh()\n\n        # pop the configure command output off the stack\n        response.pop(0)\n\n        return response", "response": "This method will configure the node with the specified commands and returns the response from the commands"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a section of the config file.", "response": "def section(self, regex, config='running_config'):\n        \"\"\"Returns a section of the config\n\n        Args:\n            regex (str): A valid regular expression used to select sections\n                of configuration to return\n            config (str): The configuration to return.  Valid values for config\n                are \"running_config\" or \"startup_config\".  The default value\n                is \"running_config\"\n\n        Returns:\n            The configuration section as a string object.\n        \"\"\"\n        if config in ['running_config', 'startup_config']:\n            config = getattr(self, config)\n        match = re.search(regex, config, re.M)\n        if not match:\n            raise TypeError('config section not found')\n        block_start, line_end = match.regs[0]\n\n        match = re.search(r'^[^\\s]', config[line_end:], re.M)\n        if not match:\n            raise TypeError('could not find end block')\n        _, block_end = match.regs[0]\n\n        block_end = line_end + block_end\n        return config[block_start:block_end]"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enable(self, commands, encoding='json', strict=False,\n               send_enable=True, **kwargs):\n        \"\"\"Sends the array of commands to the node in enable mode\n\n        This method will send the commands to the node and evaluate\n        the results.  If a command fails due to an encoding error,\n        then the command set will be re-issued individual with text\n        encoding.\n\n        Args:\n            commands (list): The list of commands to send to the node\n\n            encoding (str): The requested encoding of the command output.\n                Valid values for encoding are JSON or text\n\n            strict (bool): If False, this method will attempt to run a\n                command with text encoding if JSON encoding fails\n            send_enable (bool): If True the enable command will be\n                               prepended to the command list automatically.\n            **kwargs: Additional keyword arguments for expanded eAPI\n                functionality. Only supported eAPI params are used in building\n                the request\n\n        Returns:\n            A dict object that includes the response for each command along\n                with the encoding\n\n        Raises:\n            TypeError:\n                This method does not support sending configure\n                commands and will raise a TypeError if configuration commands\n                are found in the list of commands provided\n\n                This method will also raise a TypeError if the specified\n                encoding is not one of 'json' or 'text'\n\n            CommandError: This method will raise a CommandError if any one\n                of the commands fails.\n        \"\"\"\n        commands = make_iterable(commands)\n\n        if 'configure' in commands:\n            raise TypeError('config mode commands not supported')\n\n        results = list()\n        # IMPORTANT: There are two keys (response, result) that both\n        # return the same value. 'response' was originally placed\n        # there in error and both are now present to avoid breaking\n        # existing scripts. 'response' will be removed in a future release.\n        if strict:\n            responses = self.run_commands(commands, encoding, send_enable,\n                                          **kwargs)\n            for index, response in enumerate(responses):\n                results.append(dict(command=commands[index],\n                                    result=response,\n                                    response=response,\n                                    encoding=encoding))\n        else:\n            for command in commands:\n                try:\n                    resp = self.run_commands(command, encoding, send_enable,\n                                             **kwargs)\n                    results.append(dict(command=command,\n                                        result=resp[0],\n                                        encoding=encoding))\n                except CommandError as exc:\n                    if exc.error_code == 1003:\n                        resp = self.run_commands(command, 'text', send_enable,\n                                                 **kwargs)\n                        results.append(dict(command=command,\n                                            result=resp[0],\n                                            encoding='text'))\n                    else:\n                        raise\n        return results", "response": "Sends the array of commands to the node in enable mode and evaluates the results."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsending the commands over the device and returns the response.", "response": "def run_commands(self, commands, encoding='json', send_enable=True,\n                     **kwargs):\n        \"\"\"Sends the commands over the transport to the device\n\n        This method sends the commands to the device using the nodes\n        transport.  This is a lower layer function that shouldn't normally\n        need to be used, preferring instead to use config() or enable().\n\n        Args:\n            commands (list): The ordered list of commands to send to the\n                device using the transport\n            encoding (str): The encoding method to use for the request and\n                excpected response.\n            send_enable (bool): If True the enable command will be\n                               prepended to the command list automatically.\n            **kwargs: Additional keyword arguments for expanded eAPI\n                functionality. Only supported eAPI params are used in building\n                the request\n\n        Returns:\n            This method will return the raw response from the connection\n                which is a Python dictionary object.\n        \"\"\"\n        commands = make_iterable(commands)\n\n        # Some commands are multiline commands. These are banner commands and\n        # SSL commands. So with this two lines we\n        # can support those by passing commands by doing:\n        # banner login MULTILINE: This is my banner.\\nAnd I even support\n        # multiple lines.\n        # Why this? To be able to read a configuration from a file, split it\n        # into lines and pass it as it is\n        # to pyeapi without caring about multiline commands.\n        commands = [{'cmd': c.split('MULTILINE:')[0],\n                     'input': '%s\\n' % (c.split('MULTILINE:')[1].strip())}\n                    if 'MULTILINE:' in c else c for c in commands]\n\n        if send_enable:\n            if self._enablepwd:\n                commands.insert(0, {'cmd': 'enable', 'input': self._enablepwd})\n            else:\n                commands.insert(0, 'enable')\n\n        response = self._connection.execute(commands, encoding, **kwargs)\n\n        # pop enable command from the response only if we sent enable\n        if send_enable:\n            response['result'].pop(0)\n\n        return response['result']"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nload the specified API module.", "response": "def api(self, name, namespace='pyeapi.api'):\n        \"\"\"Loads the specified api module\n\n        This method is the API autoload mechanism that will load the API\n        module specified by the name argument.  The API module will be loaded\n        and look first for an initialize() function and secondly for an\n        instance() function.  In both cases, the node object is passed to\n        the module.\n\n        Args:\n            name (str): The name of the module to load.  The name should be\n                the name of the python file to import\n            namespace (str): The namespace to use to load the module.  The\n                default value is 'pyeapi.api'\n\n        Returns:\n            The API module loaded with the node instance.\n        \"\"\"\n        module = load_module('{}.{}'.format(namespace, name))\n        if hasattr(module, 'initialize'):\n            module.initialize(self)\n        if hasattr(module, 'instance'):\n            return module.instance(self)\n        return module"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get(self, name):\n        if not self.get_block(r'route-map\\s%s\\s\\w+\\s\\d+' % name):\n            return None\n\n        return self._parse_entries(name)", "response": "Provides a method to retrieve all routemap configuration related to the specified name attribute."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create(self, name, action, seqno):\n        return self.configure('route-map %s %s %s' % (name, action, seqno))", "response": "Creates a new routemap on the node"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef delete(self, name, action, seqno):\n        return self.configure('no route-map %s %s %s' % (name, action, seqno))", "response": "This method deletes the routemap from the node"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef default(self, name, action, seqno):\n        return self.configure('default route-map %s %s %s'\n                              % (name, action, seqno))", "response": "Default route - map configuration"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef set_match_statements(self, name, action, seqno, statements):\n        try:\n            current_statements = self.get(name)[action][seqno]['match']\n        except:\n            current_statements = []\n\n        commands = list()\n\n        # remove set statements from current routemap\n        for entry in set(current_statements).difference(statements):\n            commands.append('route-map %s %s %s' % (name, action, seqno))\n            commands.append('no match %s' % entry)\n\n        # add new set statements to the routemap\n        for entry in set(statements).difference(current_statements):\n            commands.append('route-map %s %s %s' % (name, action, seqno))\n            commands.append('match %s' % entry)\n\n        return self.configure(commands) if commands else True", "response": "Configures the match statements within the routemap clause."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconfigures the routemap continue value for a specific entry in the routemap.", "response": "def set_continue(self, name, action, seqno, value=None, default=False,\n                     disable=False):\n        \"\"\"Configures the routemap continue value\n\n        Args:\n            name (string): The full name of the routemap.\n            action (string): The action to take for this routemap clause.\n            seqno (integer): The sequence number for the routemap clause.\n            value (integer): The value to configure for the routemap continue\n            default (bool): Specifies to default the routemap continue value\n            disable (bool): Specifies to negate the routemap continue value\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        commands = ['route-map %s %s %s' % (name, action, seqno)]\n        if default:\n            commands.append('default continue')\n        elif disable:\n            commands.append('no continue')\n        else:\n            if not str(value).isdigit() or value < 1:\n                raise ValueError('seqno must be a positive integer unless '\n                                 'default or disable is specified')\n            commands.append('continue %s' % value)\n\n        return self.configure(commands)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef set_description(self, name, action, seqno, value=None, default=False,\n                        disable=False):\n        \"\"\"Configures the routemap description\n\n        Args:\n            name (string): The full name of the routemap.\n            action (string): The action to take for this routemap clause.\n            seqno (integer): The sequence number for the routemap clause.\n            value (string): The value to configure for the routemap description\n            default (bool): Specifies to default the routemap description value\n            disable (bool): Specifies to negate the routemap description\n\n        Returns:\n            True if the operation succeeds otherwise False is returned\n        \"\"\"\n        commands = ['route-map %s %s %s' % (name, action, seqno)]\n        if value is not None:\n            # Before assigning a new description, clear any existing desc\n            commands.append(self.command_builder('description', disable=True))\n        commands.append(self.command_builder('description', value=value,\n                                             default=default, disable=disable))\n        return self.configure(commands)", "response": "Configures the routemap description for a specific entry in the cluster."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _calc_obs_local(self,parensemble):\n        '''\n        propagate the ensemble forward using sweep.\n        '''\n        self.logger.log(\"evaluating ensemble of size {0} locally with sweep\".\\\n                        format(parensemble.shape[0]))\n        parensemble.to_csv(self.sweep_in_csv)\n        if self.num_slaves > 0:\n            master_thread = self._get_master_thread()\n            pyemu.utils.start_slaves(self.slave_dir,\"pestpp-swp\",self.pst.filename,\n                                     self.num_slaves,slave_root='..',port=self.port)\n            master_thread.join()\n        else:\n            os.system(\"pestpp-swp {0}\".format(self.pst.filename))\n\n        self.logger.log(\"evaluating ensemble of size {0} locally with sweep\".\\\n                        format(parensemble.shape[0]))", "response": "calculate the local ensemble"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef save_coo(x, row_names, col_names,  filename, chunk=None):\n\n    f = open(filename, 'wb')\n    # print(\"counting nnz\")\n    # write the header\n    header = np.array((x.shape[1], x.shape[0], x.nnz),\n                      dtype=Matrix.binary_header_dt)\n    header.tofile(f)\n\n    data = np.core.records.fromarrays([x.row, x.col, x.data], dtype=Matrix.coo_rec_dt)\n    data.tofile(f)\n\n    for name in col_names:\n        if len(name) > Matrix.new_par_length:\n            name = name[:Matrix.new_par_length - 1]\n        elif len(name) < Matrix.new_par_length:\n            for i in range(len(name), Matrix.new_par_length):\n                name = name + ' '\n        f.write(name.encode())\n    for name in row_names:\n        if len(name) > Matrix.new_obs_length:\n            name = name[:Matrix.new_obs_length - 1]\n        elif len(name) < Matrix.new_obs_length:\n            for i in range(len(name), Matrix.new_obs_length):\n                name = name + ' '\n        f.write(name.encode())\n    f.close()", "response": "Save a PEST - compatible binary file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef concat(mats):\n    for mat in mats:\n        if mat.isdiagonal:\n            raise NotImplementedError(\"concat not supported for diagonal mats\")\n\n    row_match = True\n    col_match = True\n    for mat in mats[1:]:\n        if sorted(mats[0].row_names) != sorted(mat.row_names):\n            row_match = False\n        if sorted(mats[0].col_names) != sorted(mat.col_names):\n            col_match = False\n    if not row_match and not col_match:\n        raise Exception(\"mat_handler.concat(): all Matrix objects\"+\\\n                        \"must share either rows or cols\")\n\n    if row_match and col_match:\n        raise Exception(\"mat_handler.concat(): all Matrix objects\"+\\\n                        \"share both rows and cols\")\n\n    if row_match:\n        row_names = copy.deepcopy(mats[0].row_names)\n        col_names = []\n        for mat in mats:\n            col_names.extend(copy.deepcopy(mat.col_names))\n        x = mats[0].newx.copy()\n        for mat in mats[1:]:\n            mat.align(mats[0].row_names, axis=0)\n            other_x = mat.newx\n            x = np.append(x, other_x, axis=1)\n\n    else:\n        col_names = copy.deepcopy(mats[0].col_names)\n        row_names = []\n        for mat in mats:\n            row_names.extend(copy.deepcopy(mat.row_names))\n        x = mats[0].newx.copy()\n        for mat in mats[1:]:\n            mat.align(mats[0].col_names, axis=1)\n            other_x = mat.newx\n            x = np.append(x, other_x, axis=0)\n    return Matrix(x=x, row_names=row_names, col_names=col_names)", "response": "Concatenate list of Matrix objects."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_common_elements(list1, list2):\n    #result = []\n    #for item in list1:\n    #    if item in list2:\n    #        result.append(item)\n    #Return list(set(list1).intersection(set(list2)))\n    set2 = set(list2)\n    result = [item for item in list1 if item in set2]\n    return result", "response": "find the common elements in two lists"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nresetting self. __x private attribute", "response": "def reset_x(self,x,copy=True):\n        \"\"\"reset self.__x private attribute\n\n        Parameters\n        ----------\n        x : numpy.ndarray\n        copy : bool\n            flag to make a copy of 'x'. Defaule is True\n        \n        Note\n        ----\n        makes a copy of 'x' argument\n        \n        \"\"\"\n        assert x.shape == self.shape\n        if copy:\n            self.__x = x.copy()\n        else:\n            self.__x = x"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef hadamard_product(self, other):\n        if np.isscalar(other):\n            return type(self)(x=self.x * other)\n\n        if isinstance(other,pd.DataFrame):\n            other = Matrix.from_dataframe(other)\n\n        if isinstance(other, np.ndarray):\n            assert self.shape == other.shape, \\\n                \"Matrix.hadamard_product(): shape mismatch: \" + \\\n                str(self.shape) + ' ' + str(other.shape)\n            if self.isdiagonal:\n                raise NotImplementedError(\"Matrix.hadamard_product() not supported for\" +\n                                          \"diagonal self\")\n            else:\n                return type(self)(x=self.x * other, row_names=self.row_names,\n                                  col_names=self.col_names)\n        elif isinstance(other, Matrix):\n            if self.autoalign and other.autoalign \\\n                    and not self.element_isaligned(other):\n                common_rows = get_common_elements(self.row_names,\n                                                  other.row_names)\n                common_cols = get_common_elements(self.col_names,\n                                                  other.col_names)\n                if len(common_rows) == 0:\n                    raise Exception(\"Matrix.hadamard_product error: no common rows\")\n\n                if len(common_cols) == 0:\n                    raise Exception(\"Matrix.hadamard_product error: no common cols\")\n\n                first = self.get(row_names=common_rows, col_names=common_cols)\n                second = other.get(row_names=common_rows, col_names=common_cols)\n            else:\n                assert self.shape == other.shape, \\\n                    \"Matrix.hadamard_product(): shape mismatch: \" + \\\n                    str(self.shape) + ' ' + str(other.shape)\n                first = self\n                second = other\n\n            if first.isdiagonal and second.isdiagonal:\n                return type(self)(x=first.x * second.x, isdiagonal=True,\n                                  row_names=first.row_names,\n                                  col_names=first.col_names)\n            # elif first.isdiagonal:\n            #     #ox = second.as_2d\n            #     #for j in range(first.shape[0]):\n            #     #    ox[j, j] *= first.__x[j]\n            #     return type(self)(x=first.as_2d * second.as_2d, row_names=first.row_names,\n            #                       col_names=first.col_names)\n            # elif second.isdiagonal:\n            #     #x = first.as_2d\n            #     #for j in range(second.shape[0]):\n            #     #    x[j, j] *= second.x[j]\n            #     return type(self)(x=first.x * second.as_2d, row_names=first.row_names,\n            #                       col_names=first.col_names)\n            else:\n                return type(self)(x=first.as_2d * second.as_2d,\n                                  row_names=first.row_names,\n                                  col_names=first.col_names)\n        else:\n            raise Exception(\"Matrix.hadamard_product(): unrecognized type for \" +\n                            \"other: \" + str(type(other)))", "response": "Overload of numpy. ndarray. __mult__ that handles element - wise multiplication."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __set_svd(self):\n        if self.isdiagonal:\n            x = np.diag(self.x.flatten())\n        else:\n            # just a pointer to x\n            x = self.x\n        try:\n\n            u, s, v = la.svd(x, full_matrices=True)\n            v = v.transpose()\n        except Exception as e:\n            print(\"standard SVD failed: {0}\".format(str(e)))\n            try:\n                v, s, u = la.svd(x.transpose(), full_matrices=True)\n                u = u.transpose()\n            except Exception as e:\n                np.savetxt(\"failed_svd.dat\",x,fmt=\"%15.6E\")\n                raise Exception(\"Matrix.__set_svd(): \" +\n                                \"unable to compute SVD of self.x, \" +\n                                \"saved matrix to 'failed_svd.dat' -- {0}\".\\\n                                format(str(e)))\n\n        col_names = [\"left_sing_vec_\" + str(i + 1) for i in range(u.shape[1])]\n        self.__u = Matrix(x=u, row_names=self.row_names,\n                          col_names=col_names, autoalign=False)\n\n        sing_names = [\"sing_val_\" + str(i + 1) for i in range(s.shape[0])]\n        self.__s = Matrix(x=np.atleast_2d(s).transpose(), row_names=sing_names,\n                          col_names=sing_names, isdiagonal=True,\n                          autoalign=False)\n\n        col_names = [\"right_sing_vec_\" + str(i + 1) for i in range(v.shape[0])]\n        self.__v = Matrix(v, row_names=self.col_names, col_names=col_names,\n                          autoalign=False)", "response": "private method to set the SVD components of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef element_isaligned(self, other):\n        assert isinstance(other, Matrix), \\\n            \"Matrix.isaligned(): other argument must be type Matrix, not: \" +\\\n            str(type(other))\n        if self.row_names == other.row_names \\\n                and self.col_names == other.col_names:\n            return True\n        else:\n            return False", "response": "check if matrices are aligned for element - wise operations"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting a 2D representation of self. x", "response": "def as_2d(self):\n        \"\"\" get a 2D representation of x.  If not self.isdiagonal, simply\n        return reference to self.x, otherwise, constructs and returns\n        a 2D, diagonal ndarray\n\n        Returns\n        -------\n        numpy.ndarray : numpy.ndarray\n\n        \"\"\"\n        if not self.isdiagonal:\n            return self.x\n        return np.diag(self.x.flatten())"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef shape(self):\n        if self.__x is not None:\n            if self.isdiagonal:\n                return (max(self.__x.shape), max(self.__x.shape))\n            if len(self.__x.shape) == 1:\n                raise Exception(\"Matrix.shape: Matrix objects must be 2D\")\n            return self.__x.shape\n        return None", "response": "get the implied 2D shape of self\n            Returns None if self. isdiagonal is False"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new Matrix containing the transpose of the current object.", "response": "def transpose(self):\n        \"\"\"transpose operation of self\n\n        Returns\n        -------\n        Matrix : Matrix\n            transpose of self\n\n        \"\"\"\n        if not self.isdiagonal:\n            return type(self)(x=self.__x.copy().transpose(),\n                              row_names=self.col_names,\n                              col_names=self.row_names,\n                              autoalign=self.autoalign)\n        else:\n            return type(self)(x=self.__x.copy(), row_names=self.row_names,\n                              col_names=self.col_names,\n                              isdiagonal=True, autoalign=self.autoalign)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_maxsing(self,eigthresh=1.0e-5):\n        #sthresh =np.abs((self.s.x / self.s.x[0]) - eigthresh)\n        sthresh = self.s.x.flatten()/self.s.x[0]\n        ising = 0\n        for i,st in enumerate(sthresh):\n            if st > eigthresh:\n                ising += 1\n                #return max(1,i)\n            else:\n                break\n        #return max(1,np.argmin(sthresh))\n        return max(1,ising)", "response": "Get the number of singular components with a singular value ratio greater than or equal to eigthresh."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the pseudo - inv components of the current set of SVD components.", "response": "def pseudo_inv_components(self,maxsing=None,eigthresh=1.0e-5,truncate=True):\n        \"\"\" Get the (optionally) truncated SVD components\n\n        Parameters\n        ----------\n        maxsing : int\n            the number of singular components to use.  If None,\n            maxsing is calculated using Matrix.get_maxsing() and eigthresh\n        eigthresh : float\n            the ratio of largest to smallest singular components to use\n            for truncation.  Ignored if maxsing is not None\n        truncate : bool\n            flag to truncate components. If False, U, s, and V will be zeroed out instead of truncated.\n            Default is True\n\n        Returns\n        -------\n        u : Matrix\n            (optionally) truncated left singular vectors\n        s : Matrix\n            (optionally) truncated singular value matrix\n        v : Matrix\n            (optionally) truncated right singular vectors\n\n        \"\"\"\n\n        if maxsing is None:\n            maxsing = self.get_maxsing(eigthresh=eigthresh)\n        else:\n             maxsing = min(self.get_maxsing(eigthresh=eigthresh),maxsing)\n\n        s = self.full_s.copy()\n        v = self.v.copy()\n        u = self.u.copy()\n        if truncate:\n\n            s = s[:maxsing,:maxsing]\n            v = v[:,:maxsing]\n            u = u[:,:maxsing]\n        else:\n            new_s = self.full_s.copy()\n            s = new_s\n            s.x[maxsing:, maxsing:] = 0.0\n            v.x[:, maxsing:] = 0.0\n            u.x[:, maxsing:] = 0.0\n\n        return u,s,v"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef sqrt(self):\n        if self.isdiagonal:\n            return type(self)(x=np.sqrt(self.__x), isdiagonal=True,\n                              row_names=self.row_names,\n                              col_names=self.col_names,\n                              autoalign=self.autoalign)\n        elif self.shape[1] == 1: #a vector\n            return type(self)(x=np.sqrt(self.__x), isdiagonal=False,\n                              row_names=self.row_names,\n                              col_names=self.col_names,\n                              autoalign=self.autoalign)\n        else:\n            return type(self)(x=la.sqrtm(self.__x), row_names=self.row_names,\n                              col_names=self.col_names,\n                              autoalign=self.autoalign)", "response": "Returns the square root of the matrix."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the full singular value matrix of self Returns ------- Matrix", "response": "def full_s(self):\n        \"\"\" Get the full singular value matrix of self\n\n        Returns\n        -------\n        Matrix : Matrix\n\n        \"\"\"\n        x = np.zeros((self.shape),dtype=np.float32)\n\n        x[:self.s.shape[0],:self.s.shape[0]] = self.s.as_2d\n        s = Matrix(x=x, row_names=self.row_names,\n                          col_names=self.col_names, isdiagonal=False,\n                          autoalign=False)\n        return s"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef zero2d(self):\n        return type(self)(x=np.atleast_2d(np.zeros((self.shape[0],self.shape[1]))),\n                   row_names=self.row_names,\n                   col_names=self.col_names,\n                   isdiagonal=False)", "response": "get an 2D instance of self with all zeros"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef indices(self, names, axis=None):\n        return Matrix.find_rowcol_indices(names,self.row_names,self.col_names,axis=axis)", "response": "get the row and col indices of names for each axis"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef old_indices(self, names, axis=None):\n        warnings.warn(\"Matrix.old_indices() is deprecated - only here for testing. Use Matrix.indices()\",PyemuWarning)\n        row_idxs, col_idxs = [], []\n        for name in names:\n            if name.lower() not in self.col_names \\\n                    and name.lower() not in self.row_names:\n                raise Exception('Matrix.indices(): name not found: ' + name)\n            if name.lower() in self.col_names:\n                col_idxs.append(self.col_names.index(name))\n            if name.lower() in self.row_names:\n                row_idxs.append(self.row_names.index(name))\n        if axis is None:\n            return np.array(row_idxs, dtype=np.int32),\\\n                np.array(col_idxs, dtype=np.int32)\n        elif axis == 0:\n            if len(row_idxs) != len(names):\n                raise Exception(\"Matrix.indices(): \" +\n                                \"not all names found in row_names\")\n            return np.array(row_idxs, dtype=np.int32)\n        elif axis == 1:\n            if len(col_idxs) != len(names):\n                raise Exception(\"Matrix.indices(): \" +\n                                \"not all names found in col_names\")\n            return np.array(col_idxs, dtype=np.int32)\n        else:\n            raise Exception(\"Matrix.indices(): \" +\n                            \"axis argument must 0 or 1, not:\" + str(axis))", "response": "get the row and col indices of names for each axis"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncreates a pyemu. Matrix from the Ensemble. COOKIE", "response": "def as_pyemu_matrix(self,typ=Matrix):\n        \"\"\"\n        Create a pyemu.Matrix from the Ensemble.\n\n        Parameters\n        ----------\n            typ : pyemu.Matrix or derived type\n                the type of matrix to return\n\n        Returns\n        -------\n        pyemu.Matrix : pyemu.Matrix\n\n        \"\"\"\n        x = self.values.copy().astype(np.float)\n        return typ(x=x,row_names=list(self.index),\n                      col_names=list(self.columns))"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\noverload of pandas. DataFrame. drop", "response": "def drop(self,arg):\n        \"\"\" overload of pandas.DataFrame.drop()\n\n        Parameters\n        ----------\n        arg : iterable\n            argument to pass to pandas.DataFrame.drop()\n\n        Returns\n        -------\n        Ensemble : Ensemble\n        \n        \"\"\"\n        df = super(Ensemble,self).drop(arg)\n        return type(self)(data=df,pst=self.pst)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverload of pandas. DataFrame. dropna", "response": "def dropna(self,*args,**kwargs):\n        \"\"\"overload of pandas.DataFrame.dropna()\n\n        Parameters\n        ----------\n        *args : list\n            positional args to pass to pandas.DataFrame.dropna()\n        **kwargs : dict\n            keyword args to pass to pandas.DataFrame.dropna()\n\n        Returns\n        -------\n        Ensemble : Ensemble\n        \n        \"\"\"\n        df = super(Ensemble,self).dropna(*args,**kwargs)\n        return type(self)(data=df,pst=self.pst)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ndraw random realizations from a multivariate Gaussian distribution of the current object", "response": "def draw(self,cov,num_reals=1,names=None):\n        \"\"\" draw random realizations from a multivariate\n            Gaussian distribution\n\n        Parameters\n        ----------    \n        cov: pyemu.Cov\n            covariance structure to draw from\n        num_reals: int\n            number of realizations to generate\n        names : list\n            list of columns names to draw for.  If None, values all names\n            are drawn\n\n        \"\"\"\n        real_names = np.arange(num_reals,dtype=np.int64)\n\n        # make sure everything is cool WRT ordering\n        if names is not None:\n            vals = self.mean_values.loc[names]\n            cov = cov.get(names)\n        elif self.names != cov.row_names:\n            names = get_common_elements(self.names,\n                                        cov.row_names)\n            vals = self.mean_values.loc[names]\n            cov = cov.get(names)\n        else:\n            vals = self.mean_values\n            names = self.names\n\n        # generate random numbers\n        if cov.isdiagonal: #much faster\n            val_array = np.array([np.random.normal(mu,std,size=num_reals) for\\\n                                  mu,std in zip(vals,np.sqrt(cov.x))]).transpose()\n        else:\n            val_array = np.random.multivariate_normal(vals, cov.as_2d,num_reals)\n\n        self.loc[:,:] = np.NaN\n        self.dropna(inplace=True)\n\n        # this sucks - can only set by enlargement one row at a time\n        for rname,vals in zip(real_names,val_array):\n            self.loc[rname, names] = vals\n            # set NaNs to mean_values\n            idx = pd.isnull(self.loc[rname,:])\n            self.loc[rname,idx] = self.mean_values[idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the ensemble histograms to multipage pdf", "response": "def plot(self,bins=10,facecolor='0.5',plot_cols=None,\n                    filename=\"ensemble.pdf\",func_dict = None,\n                    **kwargs):\n        \"\"\"plot ensemble histograms to multipage pdf\n\n        Parameters\n        ----------\n        bins : int\n            number of bins\n        facecolor : str\n            color\n        plot_cols : list of str\n            subset of ensemble columns to plot.  If None, all are plotted.\n            Default is None\n        filename : str\n            pdf filename. Default is \"ensemble.pdf\"\n        func_dict : dict\n            a dict of functions to apply to specific columns (e.g., np.log10)\n\n        **kwargs : dict\n            keyword args to pass to plot_utils.ensemble_helper()\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        ensemble_helper(self,bins=bins,facecolor=facecolor,plot_cols=plot_cols,\n                        filename=filename)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_dataframe(cls,**kwargs):\n        df = kwargs.pop(\"df\")\n        assert isinstance(df,pd.DataFrame)\n        df.columns = [c.lower() for c in df.columns]\n\n        mean_values = kwargs.pop(\"mean_values\",df.mean(axis=0))\n        e = cls(data=df,index=df.index,columns=df.columns,\n                mean_values=mean_values,**kwargs)\n\n        return e", "response": "class method to create an Ensemble from a pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef copy(self):\n        df = super(Ensemble,self).copy()\n        return type(self).from_dataframe(df=df)", "response": "make a deep copy of self Returns\n        -------"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the approximate covariance matrix implied by the ensemble using 69 - 1.", "response": "def covariance_matrix(self,localizer=None):\n        \"\"\"calculate the approximate covariance matrix implied by the ensemble using\n        mean-differencing operation at the core of EnKF\n\n        Parameters\n        ----------\n            localizer : pyemu.Matrix\n                covariance localizer to apply\n\n        Returns\n        -------\n            cov : pyemu.Cov\n                covariance matrix\n\n        \"\"\"\n\n\n\n\n        mean = np.array(self.mean(axis=0))\n        delta = self.as_pyemu_matrix(typ=Cov)\n        for i in range(self.shape[0]):\n            delta.x[i, :] -= mean\n        delta *= (1.0 / np.sqrt(float(self.shape[0] - 1.0)))\n\n        if localizer is not None:\n            delta = delta.T * delta\n            return delta.hadamard_product(localizer)\n\n        return delta.T * delta"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the deviations of the ensemble from the mean vector", "response": "def get_deviations(self):\n        \"\"\"get the deviations of the ensemble value from the mean vector\n\n        Returns\n        -------\n            en : pyemu.Ensemble\n                Ensemble of deviations from the mean\n        \"\"\"\n\n        mean_vec = self.mean()\n\n        df = self.loc[:,:].copy()\n        for col in df.columns:\n            df.loc[:,col] -= mean_vec[col]\n        return type(self).from_dataframe(pst=self.pst,df=df)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\noverloading of Ensemble. copy", "response": "def copy(self):\n        \"\"\"overload of Ensemble.copy()\n\n        Returns\n        -------\n        ObservationEnsemble : ObservationEnsemble\n\n        \"\"\"\n        df = super(Ensemble,self).copy()\n        return type(self).from_dataframe(df=df,pst=self.pst.get())"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef draw(self,cov,num_reals):\n        super(ObservationEnsemble,self).draw(cov,num_reals,\n                                             names=self.pst.nnz_obs_names)\n        self.loc[:,self.names] += self.pst.observation_data.obsval", "response": "draw realizations of observation noise and add to mean_values\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_base(self):\n        if \"base\" in self.index:\n            raise Exception(\"'base' already in index\")\n        self.loc[\"base\",:] = self.pst.observation_data.loc[self.columns,\"obsval\"]", "response": "add base control file values as a realization"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\noverload of pandas. DataFrame. dropna", "response": "def dropna(self, *args, **kwargs):\n        \"\"\"overload of pandas.DataFrame.dropna()\n\n        Parameters\n        ----------\n        *args : list\n            positional args to pass to pandas.DataFrame.dropna()\n        **kwargs : dict\n            keyword args to pass to pandas.DataFrame.dropna()\n\n        Returns\n        -------\n        Ensemble : Ensemble\n\n        \"\"\"\n        df = super(Ensemble, self).dropna(*args, **kwargs)\n        if df is not None:\n            pe = ParameterEnsemble.from_dataframe(df=df,pst=self.pst)\n            pe.__istransformed = self.istransformed\n            return pe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\noverload of Ensemble. copy", "response": "def copy(self):\n        \"\"\" overload of Ensemble.copy()\n\n        Returns\n        -------\n        ParameterEnsemble : ParameterEnsemble\n\n        \"\"\"\n        df = super(Ensemble,self).copy()\n        pe = ParameterEnsemble.from_dataframe(df=df,pst=self.pst.get())\n        pe.__istransformed = self.istransformed\n        return pe"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the names of adjustable parameters in the ParameterEnsemble .", "response": "def adj_names(self):\n        \"\"\" Get the names of adjustable parameters in the ParameterEnsemble\n\n        Returns\n        -------\n        list : list\n            adjustable parameter names\n\n        \"\"\"\n        return list(self.pst.parameter_data.parnme.loc[~self.fixed_indexer])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef lbnd(self):\n        if not self.istransformed:\n            return self.pst.parameter_data.parlbnd.copy()\n        else:\n            lb = self.pst.parameter_data.parlbnd.copy()\n            lb[self.log_indexer] = np.log10(lb[self.log_indexer])\n            return lb", "response": "the lower bound vector while respecting log transform\n        Returns ------- lbnd - pandas. Series"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fixed_indexer(self):\n        #isfixed = self.pst.parameter_data.partrans == \"fixed\"\n        isfixed = self.pst.parameter_data.partrans.\\\n            apply(lambda x : x in [\"fixed\",\"tied\"])\n        return isfixed.values", "response": "indexer for fixed status\n        Returns ------- fixed_indexer"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ndrawing realizations of the parameters of the current object", "response": "def draw(self,cov,num_reals=1,how=\"normal\",enforce_bounds=None):\n        \"\"\"draw realizations of parameter values\n\n        Parameters\n        ----------\n        cov : pyemu.Cov\n            covariance matrix that describes the support around\n            the mean parameter values\n        num_reals : int\n            number of realizations to generate\n        how : str\n            distribution to use to generate realizations.  Options are\n            'normal' or 'uniform'.  Default is 'normal'.  If 'uniform',\n            cov argument is ignored\n        enforce_bounds : str\n            how to enforce parameter bound violations.  Options are\n            'reset' (reset individual violating values), 'drop' (drop realizations\n            that have one or more violating values.  Default is None (no bounds enforcement)\n\n        \"\"\"\n        how = how.lower().strip()\n        if not self.istransformed:\n                self._transform()\n        if how == \"uniform\":\n            self._draw_uniform(num_reals=num_reals)\n        else:\n            super(ParameterEnsemble,self).draw(cov,num_reals=num_reals)\n            # replace the realizations for fixed parameters with the original\n            # parval1 in the control file\n            self.pst.parameter_data.index = self.pst.parameter_data.parnme\n            fixed_vals = self.pst.parameter_data.loc[self.fixed_indexer,\"parval1\"]\n            for fname,fval in zip(fixed_vals.index,fixed_vals.values):\n                #if fname not in self.columns:\n                #    continue\n                self.loc[:,fname] = fval\n        istransformed = self.pst.parameter_data.loc[:,\"partrans\"] == \"log\"\n        self.loc[:,istransformed] = 10.0**self.loc[:,istransformed]\n        self.__istransformed = False\n\n        #self._applied_tied()\n\n\n        self.enforce(enforce_bounds)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _draw_uniform(self,num_reals=1):\n        if not self.istransformed:\n            self._transform()\n        self.loc[:,:] = np.NaN\n        self.dropna(inplace=True)\n        ub = self.ubnd\n        lb = self.lbnd\n        for pname in self.names:\n            if pname in self.adj_names:\n                self.loc[:,pname] = np.random.uniform(lb[pname],\n                                                      ub[pname],\n                                                      size=num_reals)\n            else:\n                self.loc[:,pname] = np.zeros((num_reals)) + \\\n                                    self.pst.parameter_data.\\\n                                         loc[pname,\"parval1\"]", "response": "Draw uniform distribution of the parameter realizations from a log10 uniform distribution of the parameter bounds."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_sparse_gaussian_draw(cls,pst,cov,num_reals):\n\n\n        assert isinstance(cov,SparseMatrix)\n        real_names = np.arange(num_reals, dtype=np.int64)\n\n        li = pst.parameter_data.partrans == \"log\"\n        vals = pst.parameter_data.parval1.copy()\n        vals.loc[li] = vals.loc[li].apply(np.log10)\n\n\n        par_cov = pst.parameter_data.loc[cov.row_names, :]\n        par_cov.loc[:, \"idxs\"] = np.arange(cov.shape[0])\n        # print(\"algning cov\")\n        # cov.align(list(par_cov.parnme))\n        pargps = par_cov.pargp.unique()\n        print(\"reserving reals matrix\")\n        reals = np.zeros((num_reals, cov.shape[0]))\n\n        for ipg, pargp in enumerate(pargps):\n            pnames = list(par_cov.loc[par_cov.pargp == pargp, \"parnme\"])\n            idxs = par_cov.loc[par_cov.pargp == pargp, \"idxs\"]\n            print(\"{0} of {1} drawing for par group '{2}' with {3} pars \"\n                  .format(ipg + 1, len(pargps), pargp, len(idxs)))\n\n            snv = np.random.randn(num_reals, len(pnames))\n\n            print(\"...extracting cov from sparse matrix\")\n            cov_pg = cov.get_matrix(col_names=pnames,row_names=pnames)\n            if len(pnames) == 1:\n                std = np.sqrt(cov_pg.x)\n                reals[:, idxs] = vals[pnames].values[0] + (snv * std)\n            else:\n                try:\n                    cov_pg.inv\n                except:\n                    covname = \"trouble_{0}.cov\".format(pargp)\n                    print('saving toubled cov matrix to {0}'.format(covname))\n                    cov_pg.to_ascii(covname)\n                    print(cov_pg.get_diagonal_vector())\n                    raise Exception(\"error inverting cov for par group '{0}',\" + \\\n                                    \"saved trouble cov to {1}\".\n                                    format(pargp, covname))\n                v, w = np.linalg.eigh(cov_pg.as_2d)\n                # check for near zero eig values\n\n                # vdiag = np.diag(v)\n                for i in range(v.shape[0]):\n                    if v[i] > 1.0e-10:\n                        pass\n                    else:\n                        print(\"near zero eigen value found\", v[i], \\\n                              \"at index\", i, \" of \", v.shape[0])\n                        v[i] = 0.0\n                vsqrt = np.sqrt(v)\n                vsqrt[i:] = 0.0\n                v = np.diag(vsqrt)\n                a = np.dot(w, v)\n                pg_vals = vals[pnames]\n                for i in range(num_reals):\n                    # v = snv[i,:]\n                    # p = np.dot(a,v)\n                    reals[i, idxs] = pg_vals + np.dot(a, snv[i, :])\n\n        df = pd.DataFrame(reals, columns=cov.row_names, index=real_names)\n        df.loc[:, li] = 10.0 ** df.loc[:, li]\n\n        # replace the realizations for fixed parameters with the original\n        # parval1 in the control file\n        print(\"handling fixed pars\")\n        # pe.pst.parameter_data.index = pe.pst.parameter_data.parnme\n        par = pst.parameter_data\n        fixed_vals = par.loc[par.partrans == \"fixed\", \"parval1\"]\n        for fname, fval in zip(fixed_vals.index, fixed_vals.values):\n            # print(fname)\n            df.loc[:, fname] = fval\n\n        # print(\"apply tied\")\n        new_pe = cls.from_dataframe(pst=pst, df=df)\n\n        return new_pe", "response": "instantiate a parameter ensemble from a sparse matrix"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_gaussian_draw(cls,pst,cov,num_reals=1,use_homegrown=True,group_chunks=False,\n                           fill_fixed=True,enforce_bounds=False):\n        \"\"\" instantiate a parameter ensemble from a covariance matrix\n\n        Parameters\n        ----------\n        pst : pyemu.Pst\n            a control file instance\n        cov : (pyemu.Cov)\n            covariance matrix to use for drawing\n        num_reals : int\n            number of realizations to generate\n        use_homegrown : bool\n            flag to use home-grown full cov draws...much faster\n            than numpy...\n        group_chunks : bool\n            flag to break up draws by par groups.  Only applies\n            to homegrown, full cov case. Default is False\n        fill_fixed : bool\n            flag to fill in fixed parameters from the pst into the\n            ensemble using the parval1 from the pst.  Default is True\n        enforce_bounds : bool\n            flag to enforce parameter bounds from the pst.  realized\n            parameter values that violate bounds are simply changed to the\n            value of the violated bound.  Default is False\n\n        Returns\n        -------\n        ParameterEnsemble : ParameterEnsemble\n\n\n        \"\"\"\n\n        # set up some column names\n        #real_names = [\"{0:d}\".format(i)\n        #              for i in range(num_reals)]\n        real_names = np.arange(num_reals,dtype=np.int64)\n\n        li = pst.parameter_data.partrans == \"log\"\n        vals = pst.parameter_data.parval1.copy()\n        vals[li] = vals.loc[li].apply(np.log10)\n\n        # make sure everything is cool WRT ordering\n        if list(vals.index.values) != cov.row_names:\n            common_names = get_common_elements(vals.index.values,\n                                               cov.row_names)\n            if len(common_names) == 0:\n                raise Exception(\"ParameterEnsemble::from_gaussian_draw() error: cov and pst share no common names\")\n            vals = vals.loc[common_names]\n            cov = cov.get(common_names)\n        else:\n            common_names = cov.row_names\n\n        li = pst.parameter_data.partrans.loc[common_names] == \"log\"\n        if cov.isdiagonal:\n            #print(\"making diagonal cov draws\")\n            #print(\"building mean and std dicts\")\n            arr = np.zeros((num_reals,len(vals)))\n            stds = {pname:std for pname,std in zip(common_names,np.sqrt(cov.x.flatten()))}\n            means = {pname:val for pname,val in zip(common_names,vals)}\n            #print(\"numpy draw\")\n            arr = np.random.randn(num_reals,len(common_names))\n            #print(\"post-processing\")\n            adj_pars = set(pst.adj_par_names)\n            for i,pname in enumerate(common_names):\n                if pname in adj_pars:\n                    #s = stds[pname]\n                    #v = means[pname]\n                    #arr[:,i] = np.random.normal(means[pname],stds[pname],\n                    #                            size=num_reals)\n                    arr[:,i] = (arr[:,i] * stds[pname]) + means[pname]\n                else:\n                    arr[:,i] = means[pname]\n            #print(\"build df\")\n            df = pd.DataFrame(data=arr,columns=common_names,index=real_names)\n        else:\n            if use_homegrown:\n                print(\"making full cov draws with home-grown goodness\")\n                # generate standard normal vectors\n\n\n                # jwhite - 18-dec-17: the cholesky version is giving significantly diff\n                # results compared to eigen solve, so turning this off for now - need to\n                # learn more about this...\n                # use_chol = False\n                # if use_chol:\n                #     a = np.linalg.cholesky(cov.as_2d)\n                #\n                # else:\n                # decompose...\n                if group_chunks:\n                    par_cov = pst.parameter_data.loc[cov.names,:]\n                    par_cov.loc[:,\"idxs\"] = np.arange(cov.shape[0])\n                    #print(\"algning cov\")\n                    #cov.align(list(par_cov.parnme))\n                    pargps = par_cov.pargp.unique()\n                    #print(\"reserving reals matrix\")\n                    reals = np.zeros((num_reals,cov.shape[0]))\n\n                    for ipg,pargp in enumerate(pargps):\n                        pnames = list(par_cov.loc[par_cov.pargp==pargp,\"parnme\"])\n                        idxs = par_cov.loc[par_cov.pargp == pargp, \"idxs\"]\n                        #print(\"{0} of {1} drawing for par group '{2}' with {3} pars \"\n                        #      .format(ipg+1,len(pargps),pargp, len(idxs)))\n\n                        s,e = idxs[0],idxs[-1]\n                        #print(\"generating snv matrix\")\n                        snv = np.random.randn(num_reals, len(pnames))\n\n                        cov_pg = cov.get(pnames)\n                        if len(pnames) == 1:\n                            std = np.sqrt(cov_pg.x)\n                            reals[:,idxs] = vals[pnames].values[0] + (snv * std)\n                        else:\n                            try:\n                                cov_pg.inv\n                            except:\n                                covname = \"trouble_{0}.cov\".format(pargp)\n                                #print('saving toubled cov matrix to {0}'.format(covname))\n                                cov_pg.to_ascii(covname)\n                                #print(cov_pg.get_diagonal_vector())\n                                raise Exception(\"error inverting cov for par group '{0}',\"+\\\n                                                \"saved trouble cov to {1}\".\n                                                format(pargp,covname))\n                            v, w = np.linalg.eigh(cov_pg.as_2d)\n                            # check for near zero eig values\n\n                            #vdiag = np.diag(v)\n                            for i in range(v.shape[0]):\n                                if v[i] > 1.0e-10:\n                                    pass\n                                else:\n                                    print(\"near zero eigen value found\",v[i],\\\n                                          \"at index\",i,\" of \",v.shape[0])\n                                    v[i] = 0.0\n                            vsqrt = np.sqrt(v)\n                            vsqrt[i:] = 0.0\n                            v = np.diag(vsqrt)\n                            a = np.dot(w, v)\n                            pg_vals = vals[pnames]\n                            for i in range(num_reals):\n                                #v = snv[i,:]\n                                #p = np.dot(a,v)\n                                reals[i,idxs] =  pg_vals + np.dot(a,snv[i,:])\n                else:\n\n                    #print(\"generating snv matrix\")\n                    snv = np.random.randn(num_reals, cov.shape[0])\n\n                    #print(\"eigen solve for full cov\")\n                    v, w = np.linalg.eigh(cov.as_2d)\n                    #w, v, other = np.linalg.svd(cov.as_2d,full_matrices=True,compute_uv=True)\n                    # vdiag = np.diag(v)\n                    for i in range(v.shape[0]):\n                        if v[i] > 1.0e-10:\n                            pass\n                        else:\n                            print(\"near zero eigen value found\", v[i], \\\n                                  \"at index\", i, \" of \", v.shape[0])\n                            v[i] = 0.0\n                    # form projection matrix\n                    #print(\"form projection\")\n                    a = np.dot(w, np.sqrt(np.diag(v)))\n                    #print(a)\n                    # project...\n                    reals = []\n                    for vec in snv:\n                        real = vals + np.dot(a, vec)\n                        reals.append(real)\n\n                df = pd.DataFrame(reals, columns=common_names, index=real_names)\n\n            #vals = pe.mean_values\n            else:\n                #print(\"making full cov draws with numpy\")\n                df = pd.DataFrame(data=np.random.multivariate_normal(vals, cov.as_2d,num_reals),\n                                  columns = common_names,index=real_names)\n            #print(df.shape,cov.shape)\n\n\n        df.loc[:,li] = 10.0**df.loc[:,li]\n\n        # replace the realizations for fixed parameters with the original\n        # parval1 in the control file\n        #print(\"handling fixed pars\")\n        #pe.pst.parameter_data.index = pe.pst.parameter_data.parnme\n        if fill_fixed:\n            par = pst.parameter_data\n            fixed_vals = par.loc[par.partrans.apply(lambda x: x in [\"fixed\",\"tied\"]),\"parval1\"]\n            for fname,fval in zip(fixed_vals.index,fixed_vals.values):\n                #print(fname)\n                df.loc[:,fname] = fval\n\n            #print(\"apply tied\")\n        new_pe = cls.from_dataframe(pst=pst,df=df)\n        if enforce_bounds:\n            new_pe.enforce()\n        return new_pe", "response": "instantiate a parameter ensemble from a covariance matrix"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nproject the ensemble using the null - space Monte Carlo method", "response": "def project(self,projection_matrix,inplace=True,log=None,\n                enforce_bounds=\"reset\"):\n        \"\"\" project the ensemble using the null-space Monte Carlo method\n\n        Parameters\n        ----------\n        projection_matrix : pyemu.Matrix\n            projection operator - must already respect log transform\n\n        inplace : bool\n            project self or return a new ParameterEnsemble instance\n\n        log: pyemu.Logger\n            for logging progress\n\n        enforce_bounds : str\n            parameter bound enforcement flag. 'drop' removes\n            offending realizations, 'reset' resets offending values\n\n        Returns\n        -------\n        ParameterEnsemble : ParameterEnsemble\n            if inplace is False\n\n        \"\"\"\n\n        if self.istransformed:\n            self._back_transform()\n\n        istransformed = self.pst.parameter_data.loc[:,\"partrans\"] == \"log\"\n        self.loc[:,istransformed] = self.loc[:,istransformed].applymap(lambda x: math.log10(x))\n        self.__istransformed = True\n\n        #make sure everything is cool WRT ordering\n        common_names = get_common_elements(self.adj_names,\n                                                 projection_matrix.row_names)\n        base = self.mean_values.loc[common_names]\n        projection_matrix = projection_matrix.get(common_names,common_names)\n\n        if not inplace:\n            new_en = ParameterEnsemble(pst=self.pst.get(),data=self.loc[:,:].copy(),\n                                       columns=self.columns,\n                                       mean_values=self.mean_values.copy(),\n                                       istransformed=self.istransformed)\n\n        for real in self.index:\n            if log is not None:\n                log(\"projecting realization {0}\".format(real))\n\n            # null space projection of difference vector\n            pdiff = self.loc[real,common_names] - base\n            pdiff = np.dot(projection_matrix.x,\n                           (self.loc[real,common_names] - base)\\\n                           .values)\n\n            if inplace:\n                self.loc[real,common_names] = base + pdiff\n            else:\n                new_en.loc[real,common_names] = base + pdiff\n\n            if log is not None:\n                log(\"projecting realization {0}\".format(real))\n        if not inplace:\n            new_en.enforce(enforce_bounds)\n            new_en.loc[:,istransformed] = 10.0**new_en.loc[:,istransformed]\n            new_en.__istransformed = False\n\n            #new_en._back_transform()\n            return new_en\n\n        self.enforce(enforce_bounds)\n        self.loc[:,istransformed] = 10.0**self.loc[:,istransformed]\n        self.__istransformed = False"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef enforce(self,enforce_bounds=\"reset\"):\n        if isinstance(enforce_bounds,bool):\n            import warnings\n            warnings.warn(\"deprecation warning: enforce_bounds should be \"+\\\n                          \"either 'reset', 'drop', 'scale', or None, not bool\"+\\\n                          \"...resetting to None.\",PyemuWarning)\n            enforce_bounds = None\n        if enforce_bounds is None:\n            return\n\n        if enforce_bounds.lower() == \"reset\":\n            self.enforce_reset()\n        elif enforce_bounds.lower() == \"drop\":\n            self.enforce_drop()\n        elif enforce_bounds.lower() == \"scale\":\n            self.enfore_scale()\n        else:\n            raise Exception(\"unrecognized enforce_bounds arg:\"+\\\n                            \"{0}, should be 'reset' or 'drop'\".\\\n                            format(enforce_bounds))", "response": "This function is used to enforce the state of the current entry point for the specified set of realizations."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nenforce parameter bounds on the ensemble by dropping the realizations that violate realizations .", "response": "def enforce_drop(self):\n        \"\"\" enforce parameter bounds on the ensemble by dropping\n        violating realizations\n\n        \"\"\"\n        ub = self.ubnd\n        lb = self.lbnd\n        drop = []\n        for id in self.index:\n            #mx = (ub - self.loc[id,:]).min()\n            #mn = (lb - self.loc[id,:]).max()\n            if (ub - self.loc[id,:]).min() < 0.0 or\\\n                            (lb - self.loc[id,:]).max() > 0.0:\n                drop.append(id)\n        self.loc[drop,:] = np.NaN\n        self.dropna(inplace=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef enforce_reset(self):\n\n        ub = (self.ubnd * (1.0+self.bound_tol)).to_dict()\n        lb = (self.lbnd * (1.0 - self.bound_tol)).to_dict()\n        #for iname,name in enumerate(self.columns):\n            #self.loc[self.loc[:,name] > ub[name],name] = ub[name] * (1.0 + self.bound_tol)\n            #self.loc[self.loc[:,name] < lb[name],name] = lb[name].copy() * (1.0 - self.bound_tol)\n        #    self.loc[self.loc[:,name] > ub[name],name] = ub[name]\n        #    self.loc[self.loc[:,name] < lb[name],name] = lb[name]\n\n        val_arr = self.values\n        for iname, name in enumerate(self.columns):\n            val_arr[val_arr[:,iname] > ub[name],iname] = ub[name]\n            val_arr[val_arr[:, iname] < lb[name],iname] = lb[name]", "response": "enforce parameter bounds on the ensemble by resetting vals to bound\n        violating vals to bound\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef from_parfiles(cls,pst,parfile_names,real_names=None):\n        if isinstance(pst,str):\n            pst = pyemu.Pst(pst)\n        dfs = {}\n        if real_names is not None:\n            assert len(real_names) == len(parfile_names)\n        else:\n            real_names = np.arange(len(parfile_names))\n\n        for rname,pfile in zip(real_names,parfile_names):\n            assert os.path.exists(pfile), \"ParameterEnsemble.read_parfiles() error: \" + \\\n                                          \"file: {0} not found\".format(pfile)\n            df = read_parfile(pfile)\n            #check for scale differences - I don't who is dumb enough\n            #to change scale between par files and pst...\n            diff = df.scale - pst.parameter_data.scale\n            if diff.apply(np.abs).sum() > 0.0:\n                warnings.warn(\"differences in scale detected, applying scale in par file\",\n                              PyemuWarning)\n                #df.loc[:,\"parval1\"] *= df.scale\n\n            dfs[rname] = df.parval1.values\n\n        df_all = pd.DataFrame(data=dfs).T\n        df_all.columns = df.index\n\n\n\n        if len(pst.par_names) != df_all.shape[1]:\n            #if len(pst.par_names) < df_all.shape[1]:\n            #    raise Exception(\"pst is not compatible with par files\")\n            pset = set(pst.par_names)\n            dset = set(df_all.columns)\n            diff = pset.difference(dset)\n            if len(diff) > 0:\n                warnings.warn(\"the following parameters are not in the par files (getting NaNs) :{0}\".\n                             format(','.join(diff)),PyemuWarning)\n                blank_df = pd.DataFrame(index=df_all.index,columns=diff)\n\n                df_all = pd.concat([df_all,blank_df],axis=1)\n\n            diff = dset.difference(pset)\n            if len(diff) > 0:\n                warnings.warn(\"the following par file parameters are not in the control (being dropped):{0}\".\n                              format(','.join(diff)),PyemuWarning)\n                df_all = df_all.loc[:, pst.par_names]\n\n        return ParameterEnsemble.from_dataframe(df=df_all,pst=pst)", "response": "Create a parameter ensemble from a list of parfiles."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\noverloading of pandas. DataFrame. to_csv for parameter transformation so that the saved version of the parameter is not in Log10 space.", "response": "def to_csv(self,*args,**kwargs):\n        \"\"\"overload of pandas.DataFrame.to_csv() to account\n        for parameter transformation so that the saved\n        ParameterEnsemble csv is not in Log10 space\n\n        Parameters\n        ----------\n        *args : list\n            positional arguments to pass to pandas.DataFrame.to_csv()\n        **kwrags : dict\n            keyword arguments to pass to pandas.DataFrame.to_csv()\n\n        Note\n        ----\n        this function back-transforms inplace with respect to\n        log10 before writing\n\n        \"\"\"\n        retrans = False\n        if self.istransformed:\n            self._back_transform(inplace=True)\n            retrans = True\n        if self.isnull().values.any():\n            warnings.warn(\"NaN in par ensemble\",PyemuWarning)\n        super(ParameterEnsemble,self).to_csv(*args,**kwargs)\n        if retrans:\n            self._transform(inplace=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite the parameter ensemble to a jco - style binary file", "response": "def to_binary(self,filename):\n        \"\"\"write the parameter ensemble to a jco-style binary file\n\n        Parameters\n        ----------\n        filename : str\n            the filename to write\n\n        Returns\n        -------\n        None\n\n\n        Note\n        ----\n        this function back-transforms inplace with respect to\n        log10 before writing\n\n        \"\"\"\n\n        retrans = False\n        if self.istransformed:\n            self._back_transform(inplace=True)\n            retrans = True\n        if self.isnull().values.any():\n            warnings.warn(\"NaN in par ensemble\",PyemuWarning)\n        self.as_pyemu_matrix().to_coo(filename)\n        if retrans:\n            self._transform(inplace=True)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_parfiles(self,prefix):\n        if self.isnull().values.any():\n            warnings.warn(\"NaN in par ensemble\",PyemuWarning)\n        if self.istransformed:\n            self._back_transform(inplace=True)\n\n        par_df = self.pst.parameter_data.loc[:,\n                 [\"parnme\",\"parval1\",\"scale\",\"offset\"]].copy()\n\n        for real in self.index:\n            par_file = \"{0}{1}.par\".format(prefix,real)\n            par_df.loc[:,\"parval1\"] =self.loc[real,:]\n            write_parfile(par_df,par_file)", "response": "Write the parameter ensemble to PEST - style parameter files."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd base control file values as a realization", "response": "def add_base(self):\n        \"\"\" add \"base\" control file values as a realization\n\n        \"\"\"\n        if \"base\" in self.index:\n            raise Exception(\"'base' already in index\")\n        self.loc[\"base\",:] = self.pst.parameter_data.loc[self.columns,\"parval1\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the deviations of the ensemble value from the mean vector", "response": "def get_deviations(self):\n        \"\"\"get the deviations of the ensemble value from the mean vector\n\n        Returns\n        -------\n            en : pyemu.Ensemble\n                Ensemble of deviations from the mean\n        \"\"\"\n        bt = False\n        if not self.istransformed:\n            bt = True\n            self._transform()\n        mean_vec = self.mean()\n\n        df = self.loc[:,:].copy()\n        for col in df.columns:\n            df.loc[:,col] -= mean_vec[col]\n        if bt:\n            self._back_transform()\n        return type(self).from_dataframe(pst=self.pst,df=df)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef initialize(self,num_reals=1,enforce_bounds=\"reset\",\n                   parensemble=None,obsensemble=None,restart_obsensemble=None):\n        \"\"\"Initialize.  Depending on arguments, draws or loads\n        initial parameter observations ensembles and runs the initial parameter\n        ensemble\n\n        Parameters\n        ----------\n            num_reals : int\n                the number of realizations to draw.  Ignored if parensemble/obsensemble\n                are not None\n            enforce_bounds : str\n                how to enfore parameter bound transgression.  options are\n                reset, drop, or None\n            parensemble : pyemu.ParameterEnsemble or str\n                a parameter ensemble or filename to use as the initial\n                parameter ensemble.  If not None, then obsenemble must not be\n                None\n            obsensemble : pyemu.ObservationEnsemble or str\n                an observation ensemble or filename to use as the initial\n                observation ensemble.  If not None, then parensemble must\n                not be None\n            restart_obsensemble : pyemu.ObservationEnsemble or str\n                an observation ensemble or filename to use as an\n                evaluated observation ensemble.  If not None, this will skip the initial\n                parameter ensemble evaluation - user beware!\n\n        \"\"\"\n\n        build_empirical_prior = False\n\n        # initialize the phi report csv\n        self.enforce_bounds = enforce_bounds\n\n        self.total_runs = 0\n        # this matrix gets used a lot, so only calc once and store\n        self.obscov_inv_sqrt = self.obscov.get(self.pst.nnz_obs_names).inv.sqrt\n\n        self.logger.log(\"forming inverse sqrt parcov matrix\")\n        self.parcov_inv_sqrt = self.parcov.inv.sqrt\n        self.logger.log(\"forming inverse sqrt parcov matrix\")\n\n        if parensemble is not None and obsensemble is not None:\n            self.logger.log(\"initializing with existing ensembles\")\n            if isinstance(parensemble,str):\n                self.logger.log(\"loading parensemble from file\")\n                if not os.path.exists(obsensemble):\n                    self.logger.lraise(\"can not find parensemble file: {0}\".\\\n                                       format(parensemble))\n                df = pd.read_csv(parensemble,index_col=0)\n                df.columns = df.columns.str.lower()\n                #df.index = [str(i) for i in df.index]\n                self.parensemble_0 = pyemu.ParameterEnsemble.from_dataframe(df=df,pst=self.pst)\n                self.logger.log(\"loading parensemble from file\")\n\n            elif isinstance(parensemble,ParameterEnsemble):\n                self.parensemble_0 = parensemble.copy()\n            else:\n                raise Exception(\"unrecognized arg type for parensemble, \" +\\\n                                \"should be filename or ParameterEnsemble\" +\\\n                                \", not {0}\".format(type(parensemble)))\n            self.parensemble = self.parensemble_0.copy()\n            if isinstance(obsensemble,str):\n                self.logger.log(\"loading obsensemble from file\")\n                if not os.path.exists(obsensemble):\n                    self.logger.lraise(\"can not find obsensemble file: {0}\".\\\n                                       format(obsensemble))\n                df = pd.read_csv(obsensemble,index_col=0)\n                df.columns = df.columns.str.lower()\n                df = df.loc[:,self.pst.nnz_obs_names]\n                #df.index = [str(i) for i in df.index]\n                self.obsensemble_0 = pyemu.ObservationEnsemble.from_dataframe(df=df,pst=self.pst)\n                self.logger.log(\"loading obsensemble from file\")\n\n            elif isinstance(obsensemble,ObservationEnsemble):\n                self.obsensemble_0 = obsensemble.copy()\n            else:\n                raise Exception(\"unrecognized arg type for obsensemble, \" +\\\n                                \"should be filename or ObservationEnsemble\" +\\\n                                \", not {0}\".format(type(obsensemble)))\n\n            assert self.parensemble_0.shape[0] == self.obsensemble_0.shape[0]\n            #self.num_reals = self.parensemble_0.shape[0]\n            num_reals = self.parensemble.shape[0]\n            self.logger.log(\"initializing with existing ensembles\")\n\n            if build_empirical_prior:\n\n                self.reset_parcov(self.parensemble.covariance_matrix())\n                if self.save_mats:\n                    self.parcov.to_binary(self.pst.filename+\".empcov.jcb\")\n\n        else:\n            if build_empirical_prior:\n                self.logger.lraise(\"can't use build_emprirical_prior without parensemble...\")\n            self.logger.log(\"initializing with {0} realizations\".format(num_reals))\n            self.logger.log(\"initializing parensemble\")\n            self.parensemble_0 = pyemu.ParameterEnsemble.from_gaussian_draw(self.pst,\n                                                                            self.parcov,num_reals=num_reals)\n            self.parensemble_0.enforce(enforce_bounds=enforce_bounds)\n            self.logger.log(\"initializing parensemble\")\n            self.parensemble = self.parensemble_0.copy()\n            self.parensemble_0.to_csv(self.pst.filename +\\\n                                      self.paren_prefix.format(0))\n            self.logger.log(\"initializing parensemble\")\n            self.logger.log(\"initializing obsensemble\")\n            self.obsensemble_0 = pyemu.ObservationEnsemble.from_id_gaussian_draw(self.pst,\n                                                                                 num_reals=num_reals)\n            #self.obsensemble = self.obsensemble_0.copy()\n\n            # save the base obsensemble\n            self.obsensemble_0.to_csv(self.pst.filename +\\\n                                      self.obsen_prefix.format(-1))\n            self.logger.log(\"initializing obsensemble\")\n            self.logger.log(\"initializing with {0} realizations\".format(num_reals))\n\n\n        self.enforce_bounds = enforce_bounds\n\n        if restart_obsensemble is not None:\n            self.logger.log(\"loading restart_obsensemble {0}\".format(restart_obsensemble))\n            #failed_runs,self.obsensemble = self._load_obs_ensemble(restart_obsensemble)\n            df = pd.read_csv(restart_obsensemble, index_col=0)\n            df.columns = df.columns.str.lower()\n            #df = df.loc[:, self.pst.nnz_obs_names]\n            # df.index = [str(i) for i in df.index]\n            self.obsensemble = pyemu.ObservationEnsemble.from_dataframe(df=df, pst=self.pst)\n            assert self.obsensemble.shape[0] == self.obsensemble_0.shape[0]\n            assert list(self.obsensemble.columns) == list(self.obsensemble_0.columns)\n            self.logger.log(\"loading restart_obsensemble {0}\".format(restart_obsensemble))\n\n        else:\n            # run the initial parameter ensemble\n            self.logger.log(\"evaluating initial ensembles\")\n            self.obsensemble = self.forecast()\n            self.logger.log(\"evaluating initial ensembles\")\n\n        #if not self.parensemble.istransformed:\n        self.parensemble._transform(inplace=True)\n        #if not self.parensemble_0.istransformed:\n        self.parensemble_0._transform(inplace=True)\n        self._initialized = True", "response": "Initializes the internal state of the object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef forecast(self,parensemble=None):\n        if parensemble is None:\n            parensemble = self.parensemble\n        self.logger.log(\"evaluating ensemble\")\n        failed_runs, obsensemble = self._calc_obs(parensemble)\n\n\n        if failed_runs is not None:\n            self.logger.warn(\"dropping failed realizations\")\n            parensemble.loc[failed_runs, :] = np.NaN\n            parensemble = parensemble.dropna()\n            obsensemble.loc[failed_runs, :] = np.NaN\n            obsensemble = obsensemble.dropna()\n        self.logger.log(\"evaluating ensemble\")\n\n        return obsensemble", "response": "for the enkf formulation this simply moves the ensemble forward by running the model\n            once for each realization"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self):\n        parensemble = self.analysis_evensen()\n        obsensemble  = self.forecast(parensemble=parensemble)\n        # todo: check for phi improvement\n        if True:\n            self.obsensemble = obsensemble\n            self.parensemble = parensemble\n\n        self.iter_num += 1", "response": "runs the analysis then runs the forecast using the updated self. parensemble.\n        This can be called repeatedly to iterate..."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nloop over time windows and apply da", "response": "def enkf(self):\n        \"\"\"\n        Loop over time windows and apply da\n        :return:\n        \"\"\"\n\n        for cycle_index, time_point in enumerate(self.timeline):\n            if cycle_index >= len(self.timeline) - 1:\n                # Logging : Last Update cycle has finished\n                break\n\n            print(\"Print information about this assimilation Cycle ???\")  # should be handeled in Logger\n\n            # each cycle should have a dictionary of template files and instruction files to update the model inout\n            # files\n            # get current cycle update information\n            current_cycle_files = self.cycle_update_files[cycle_index]\n\n            #  (1)  update model input files for this cycle\n            self.model_temporal_evolotion(cycle_index, current_cycle_files)\n\n            # (2) generate new Pst object for the current time cycle\n            current_pst = copy.deepcopy(self.pst)\n            # update observation dataframe\n            # update parameter dataframe\n            # update in/out files if needed\n\n            # At this stage the problem is equivalent to smoother problem\n            self.smoother(current_pst)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _istextfile(filename, blocksize=512):\n\n\n    \"\"\"\n        Function found from:\n        https://eli.thegreenplace.net/2011/10/19/perls-guess-if-file-is-text-or-binary-implemented-in-python\n        Returns True if file is most likely a text file\n        Returns False if file is most likely a binary file\n        Uses heuristics to guess whether the given file is text or binary,\n        by reading a single block of bytes from the file.\n        If more than 30% of the chars in the block are non-text, or there\n        are NUL ('\\x00') bytes in the block, assume this is a binary file.\n    \"\"\"\n\n    import sys\n    PY3 = sys.version_info[0] == 3\n\n    # A function that takes an integer in the 8-bit range and returns\n    # a single-character byte object in py3 / a single-character string\n    # in py2.\n    #\n    int2byte = (lambda x: bytes((x,))) if PY3 else chr\n\n    _text_characters = (\n        b''.join(int2byte(i) for i in range(32, 127)) +\n        b'\\n\\r\\t\\f\\b')\n    block = open(filename,'rb').read(blocksize)\n    if b'\\x00' in block:\n        # Files with null bytes are binary\n        return False\n    elif not block:\n        # An empty file is considered a valid text file\n        return True\n\n    # Use translate's 'deletechars' argument to efficiently remove all\n    # occurrences of _text_characters from the block\n    nontext = block.translate(None, _text_characters)\n    return float(len(nontext)) / len(block) <= 0.30", "response": "Returns True if the given file is most likely a text file False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nstarting a group of slaves on the local machine", "response": "def start_slaves(slave_dir,exe_rel_path,pst_rel_path,num_slaves=None,slave_root=\"..\",\n                 port=4004,rel_path=None,local=True,cleanup=True,master_dir=None,\n                 verbose=False,silent_master=False):\n    \"\"\" start a group of pest(++) slaves on the local machine\n\n    Parameters\n    ----------\n    slave_dir :  str\n        the path to a complete set of input files\n    exe_rel_path : str\n        the relative path to the pest(++) executable from within the slave_dir\n    pst_rel_path : str\n        the relative path to the pst file from within the slave_dir\n    num_slaves : int\n        number of slaves to start. defaults to number of cores\n    slave_root : str\n        the root to make the new slave directories in\n    rel_path: str\n        the relative path to where pest(++) should be run from within the\n        slave_dir, defaults to the uppermost level of the slave dir\n    local: bool\n        flag for using \"localhost\" instead of hostname on slave command line\n    cleanup: bool\n        flag to remove slave directories once processes exit\n    master_dir: str\n        name of directory for master instance.  If master_dir\n        exists, then it will be removed.  If master_dir is None,\n        no master instance will be started\n    verbose : bool\n        flag to echo useful information to stdout\n    silent_master : bool\n        flag to pipe master output to devnull.  This is only for\n        pestpp Travis testing. Default is False\n\n    Note\n    ----\n    if all slaves (and optionally master) exit gracefully, then the slave\n    dirs will be removed unless cleanup is false\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    start 10 slaves using the directory \"template\" as the base case and\n    also start a master instance in a directory \"master\".\n\n    ``>>>pyemu.helpers.start_slaves(\"template\",\"pestpp\",\"pest.pst\",10,master_dir=\"master\")``\n\n    \"\"\"\n\n    assert os.path.isdir(slave_dir)\n    assert os.path.isdir(slave_root)\n    if num_slaves is None:\n        num_slaves = mp.cpu_count()\n    else:\n        num_slaves = int(num_slaves)\n    #assert os.path.exists(os.path.join(slave_dir,rel_path,exe_rel_path))\n    exe_verf = True\n\n    if rel_path:\n        if not os.path.exists(os.path.join(slave_dir,rel_path,exe_rel_path)):\n            #print(\"warning: exe_rel_path not verified...hopefully exe is in the PATH var\")\n            exe_verf = False\n    else:\n        if not os.path.exists(os.path.join(slave_dir,exe_rel_path)):\n            #print(\"warning: exe_rel_path not verified...hopefully exe is in the PATH var\")\n            exe_verf = False\n    if rel_path is not None:\n        assert os.path.exists(os.path.join(slave_dir,rel_path,pst_rel_path))\n    else:\n        assert os.path.exists(os.path.join(slave_dir,pst_rel_path))\n    if local:\n        hostname = \"localhost\"\n    else:\n        hostname = socket.gethostname()\n\n    base_dir = os.getcwd()\n    port = int(port)\n\n    if os.path.exists(os.path.join(slave_dir,exe_rel_path)):\n        if \"window\" in platform.platform().lower():\n            if not exe_rel_path.lower().endswith(\"exe\"):\n                exe_rel_path = exe_rel_path + \".exe\"\n        else:\n            if not exe_rel_path.startswith('./'):\n                exe_rel_path = \"./\" + exe_rel_path\n\n    if master_dir is not None:\n        if master_dir != '.' and os.path.exists(master_dir):\n            try:\n                shutil.rmtree(master_dir,onerror=remove_readonly)#, onerror=del_rw)\n            except Exception as e:\n                raise Exception(\"unable to remove existing master dir:\" + \\\n                                \"{0}\\n{1}\".format(master_dir,str(e)))\n        if master_dir != '.':\n            try:\n                shutil.copytree(slave_dir,master_dir)\n            except Exception as e:\n                raise Exception(\"unable to copy files from base slave dir: \" + \\\n                                \"{0} to master dir: {1}\\n{2}\".\\\n                                format(slave_dir,master_dir,str(e)))\n\n        args = [exe_rel_path, pst_rel_path, \"/h\", \":{0}\".format(port)]\n        if rel_path is not None:\n            cwd = os.path.join(master_dir,rel_path)\n        else:\n            cwd = master_dir\n        if verbose:\n            print(\"master:{0} in {1}\".format(' '.join(args),cwd))\n        stdout=None\n        if silent_master:\n            stdout = open(os.devnull,'w')\n        try:\n            os.chdir(cwd)\n            master_p = sp.Popen(args,stdout=stdout)#,stdout=sp.PIPE,stderr=sp.PIPE)\n            os.chdir(base_dir)\n        except Exception as e:\n            raise Exception(\"error starting master instance: {0}\".\\\n                            format(str(e)))\n        time.sleep(1.5) # a few cycles to let the master get ready\n\n\n    tcp_arg = \"{0}:{1}\".format(hostname,port)\n    procs = []\n    slave_dirs = []\n    for i in range(num_slaves):\n        new_slave_dir = os.path.join(slave_root,\"slave_{0}\".format(i))\n        if os.path.exists(new_slave_dir):\n            try:\n                shutil.rmtree(new_slave_dir,onerror=remove_readonly)#, onerror=del_rw)\n            except Exception as e:\n                raise Exception(\"unable to remove existing slave dir:\" + \\\n                                \"{0}\\n{1}\".format(new_slave_dir,str(e)))\n        try:\n            shutil.copytree(slave_dir,new_slave_dir)\n        except Exception as e:\n            raise Exception(\"unable to copy files from slave dir: \" + \\\n                            \"{0} to new slave dir: {1}\\n{2}\".format(slave_dir,new_slave_dir,str(e)))\n        try:\n            if exe_verf:\n                # if rel_path is not None:\n                #     exe_path = os.path.join(rel_path,exe_rel_path)\n                # else:\n                exe_path = exe_rel_path\n            else:\n                exe_path = exe_rel_path\n            args = [exe_path, pst_rel_path, \"/h\", tcp_arg]\n            #print(\"starting slave in {0} with args: {1}\".format(new_slave_dir,args))\n            if rel_path is not None:\n                cwd = os.path.join(new_slave_dir,rel_path)\n            else:\n                cwd = new_slave_dir\n\n            os.chdir(cwd)\n            if verbose:\n                print(\"slave:{0} in {1}\".format(' '.join(args),cwd))\n            with open(os.devnull,'w') as f:\n                p = sp.Popen(args,stdout=f,stderr=f)\n            procs.append(p)\n            os.chdir(base_dir)\n        except Exception as e:\n            raise Exception(\"error starting slave: {0}\".format(str(e)))\n        slave_dirs.append(new_slave_dir)\n\n    if master_dir is not None:\n        # while True:\n        #     line = master_p.stdout.readline()\n        #     if line != '':\n        #         print(str(line.strip())+'\\r',end='')\n        #     if master_p.poll() is not None:\n        #         print(master_p.stdout.readlines())\n        #         break\n        if silent_master:\n            # this keeps travis from thinking something is wrong...\n            while True:\n                rv = master_p.poll()\n                if master_p.poll() is not None:\n                    break\n                print(datetime.now(), \"still running\")\n                time.sleep(5)\n        else:\n            master_p.wait()\n            time.sleep(1.5) # a few cycles to let the slaves end gracefully\n        # kill any remaining slaves\n        for p in procs:\n            p.kill()\n    # this waits for sweep to finish, but pre/post/model (sub)subprocs may take longer\n    for p in procs:\n        p.wait()\n    if cleanup:\n        cleanit=0\n        while len(slave_dirs)>0 and cleanit<100000: # arbitrary 100000 limit\n            cleanit=cleanit+1\n            for d in slave_dirs:\n                try:\n                    shutil.rmtree(d,onerror=remove_readonly)\n                    slave_dirs.pop(slave_dirs.index(d)) #if successfully removed\n                except Exception as e:\n                    warnings.warn(\"unable to remove slavr dir{0}:{1}\".format(d,str(e)),PyemuWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the regularization section to an open file handle", "response": "def write(self,f):\n        \"\"\" write the regularization section to an open\n        file handle\n\n        Parameters\n        ----------\n        f : file handle\n\n        \"\"\"\n        f.write(\"* regularization\\n\")\n        for vline in REG_VARIABLE_LINES:\n            vraw = vline.strip().split()\n            for v in vraw:\n                v = v.replace(\"[\",'').replace(\"]\",'')\n                if v not in self.optional_dict.keys():\n                    raise Exception(\"RegData missing attribute {0}\".format(v))\n                f.write(\"{0} \".format(self.__getattribute__(v)))\n            f.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrite an SVD section to a file handle", "response": "def write(self,f):\n        \"\"\" write an SVD section to a file handle\n\n        Parameters\n        ----------\n        f : file handle\n\n        \"\"\"\n        f.write(\"* singular value decomposition\\n\")\n        f.write(IFMT(self.svdmode)+'\\n')\n        f.write(IFMT(self.maxsing)+' '+FFMT(self.eigthresh)+\"\\n\")\n        f.write('{0}\\n'.format(self.eigwrite))"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef parse_values_from_lines(self,lines):\n        assert len(lines) == 3,\"SvdData.parse_values_from_lines: expected \" + \\\n                               \"3 lines, not {0}\".format(len(lines))\n        try:\n            self.svdmode = int(lines[0].strip().split()[0])\n        except Exception as e:\n            raise Exception(\"SvdData.parse_values_from_lines: error parsing\" + \\\n                            \" svdmode from line {0}: {1} \\n\".format(lines[0],str(e)))\n        try:\n            raw = lines[1].strip().split()\n            self.maxsing = int(raw[0])\n            self.eigthresh = float(raw[1])\n        except Exception as e:\n            raise Exception(\"SvdData.parse_values_from_lines: error parsing\" + \\\n                            \" maxsing and eigthresh from line {0}: {1} \\n\"\\\n                            .format(lines[1],str(e)))\n        # try:\n        #     self.eigwrite = int(lines[2].strip())\n        # except Exception as e:\n        #     raise Exception(\"SvdData.parse_values_from_lines: error parsing\" + \\\n        #                     \" eigwrite from line {0}: {1} \\n\".format(lines[2],str(e)))\n        self.eigwrite = lines[2].strip()", "response": "parse values from lines of the SVD section"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_dataframe():\n        names = []\n        [names.extend(line.split()) for line in CONTROL_VARIABLE_LINES]\n\n        defaults = []\n        [defaults.extend(line.split()) for line in CONTROL_DEFAULT_LINES]\n\n        types, required,cast_defaults,formats = [],[],[],[]\n        for name,default in zip(names,defaults):\n            if '[' in name or ']' in name:\n                required.append(False)\n            else:\n                required.append(True)\n            v,t,f = ControlData._parse_value(default)\n            types.append(t)\n            formats.append(f)\n            cast_defaults.append(v)\n        return pandas.DataFrame({\"name\":names,\"type\":types,\n                                     \"value\":cast_defaults,\"required\":required,\n                                    \"format\":formats})", "response": "get a generic ( default ) control section dataframe\n        \n       "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nparsing the lines of a pest control file into a list of values.", "response": "def parse_values_from_lines(self,lines,iskeyword=False):\n        \"\"\" cast the string lines for a pest control file into actual inputs\n\n        Parameters\n        ----------\n        lines : list\n            strings from pest control file\n\n        \"\"\"\n\n        if iskeyword:\n            extra = {}\n            for line in lines:\n                raw = line.strip().split()\n                if len(raw) == 0 or raw[0] == \"#\":\n                    continue\n                name = raw[0].strip().lower()\n\n                value = raw[1].strip()\n                v,t,f = self._parse_value(value)\n                if name not in self._df.index:\n                    extra[name] = v\n                else:\n                    # if the parsed values type isn't right\n                    if t != self._df.loc[name, \"type\"]:\n\n                        # if a float was expected and int return, not a problem\n                        if t == np.int32 and self._df.loc[name, \"type\"] == np.float64:\n                            self._df.loc[name, \"value\"] = np.float64(v)\n\n\n                        # if this is a required input, throw\n                        elif self._df.loc[name, \"required\"]:\n                            raise Exception(\"wrong type found for variable \" + name + \":\" + str(t))\n                        else:\n\n                            # else, since this problem is usually a string, check for acceptable values\n                            found = False\n                            for nname, avalues in self.accept_values.items():\n                                if v in avalues:\n                                    if t == self._df.loc[nname, \"type\"]:\n                                        self._df.loc[nname, \"value\"] = v\n                                        found = True\n                                        break\n                            if not found:\n                                warnings.warn(\"non-conforming value found for \" + \\\n                                              name + \":\" + str(v) + \"...ignoring\", PyemuWarning)\n\n\n                    else:\n                        self._df.loc[name, \"value\"] = v\n            return extra\n\n\n\n\n        assert len(lines) == len(CONTROL_VARIABLE_LINES),\\\n        \"ControlData error: len of lines not equal to \" +\\\n        str(len(CONTROL_VARIABLE_LINES))\n\n        for iline,line in enumerate(lines):\n            vals = line.strip().split()\n            names = CONTROL_VARIABLE_LINES[iline].strip().split()\n            for name,val in zip(names,vals):\n                v,t,f = self._parse_value(val)\n                name = name.replace('[','').replace(']','')\n                \n                #if the parsed values type isn't right\n                if t != self._df.loc[name,\"type\"]:\n\n                    # if a float was expected and int return, not a problem\n                    if t == np.int32 and self._df.loc[name,\"type\"] == np.float64:\n                        self._df.loc[name,\"value\"] = np.float64(v)\n\n\n                    # if this is a required input, throw\n                    elif self._df.loc[name,\"required\"]:\n                        raise Exception(\"wrong type found for variable \" + name + \":\" + str(t))\n                    else:\n                        \n                        #else, since this problem is usually a string, check for acceptable values\n                        found = False\n                        for nname,avalues in self.accept_values.items():\n                            if v in avalues:\n                                if t == self._df.loc[nname,\"type\"]:\n                                    self._df.loc[nname,\"value\"] = v\n                                    found = True\n                                    break\n                        if not found:\n                            warnings.warn(\"non-conforming value found for \" +\\\n                                  name + \":\" + str(v) + \"...ignoring\",PyemuWarning)\n\n\n                else:\n                    self._df.loc[name,\"value\"] = v"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nlists the entries and current values in the control data section", "response": "def formatted_values(self):\n        \"\"\" list the entries and current values in the control data section\n\n        Returns\n        -------\n        formatted_values : pandas.Series\n\n        \"\"\"\n        return self._df.apply(lambda x: self.formatters[x[\"type\"]](x[\"value\"]),axis=1)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite control data section to a file", "response": "def write(self,f):\n        \"\"\" write control data section to a file\n        \n        Parameters\n        ----------\n        f: file handle or string filename\n\n        \"\"\"\n        if isinstance(f,str):\n            f = open(f,'w')\n            f.write(\"pcf\\n\")\n            f.write(\"* control data\\n\")\n        for line in CONTROL_VARIABLE_LINES:\n            [f.write(self.formatted_values[name.replace('[','').replace(']','')]) for name in line.split()]\n            f.write('\\n')"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef read_struct_file(struct_file,return_type=GeoStruct):\n\n    VARTYPE = {1:SphVario,2:ExpVario,3:GauVario,4:None}\n    assert os.path.exists(struct_file)\n    structures = []\n    variograms = []\n    with open(struct_file,'r') as f:\n        while True:\n            line = f.readline()\n            if line == '':\n                break\n            line = line.strip().lower()\n            if line.startswith(\"structure\"):\n                name = line.strip().split()[1]\n                nugget,transform,variogram_info = _read_structure_attributes(f)\n                s = return_type(nugget=nugget,transform=transform,name=name)\n                s.variogram_info = variogram_info\n                # not sure what is going on, but if I don't copy s here,\n                # all the structures end up sharing all the variograms later\n                structures.append(copy.deepcopy(s))\n            elif line.startswith(\"variogram\"):\n                name = line.strip().split()[1].lower()\n                vartype,bearing,a,anisotropy = _read_variogram(f)\n                if name in variogram_info:\n                    v = VARTYPE[vartype](variogram_info[name],a,anisotropy=anisotropy,\n                                         bearing=bearing,name=name)\n                    variograms.append(v)\n\n    for i,st in enumerate(structures):\n        for vname in st.variogram_info:\n            vfound = None\n            for v in variograms:\n                if v.name == vname:\n                    vfound = v\n                    break\n            if vfound is None:\n                raise Exception(\"variogram {0} not found for structure {1}\".\\\n                                format(vname,s.name))\n\n            st.variograms.append(vfound)\n    if len(structures) == 1:\n        return structures[0]\n    return structures", "response": "Reads an existing PEST - type structure file into a GeoStruct instance."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _read_variogram(f):\n\n    line = ''\n    vartype = None\n    bearing = 0.0\n    a = None\n    anisotropy = 1.0\n    while \"end variogram\" not in line:\n        line = f.readline()\n        if line == '':\n            raise Exception(\"EOF while read variogram\")\n        line = line.strip().lower().split()\n        if line[0].startswith('#'):\n            continue\n        if line[0] == \"vartype\":\n            vartype = int(line[1])\n        elif line[0] == \"bearing\":\n            bearing = float(line[1])\n        elif line[0] == \"a\":\n            a = float(line[1])\n        elif line[0] == \"anisotropy\":\n            anisotropy = float(line[1])\n        elif line[0] == \"end\":\n            break\n        else:\n            raise Exception(\"unrecognized arg in variogram:{0}\".format(line[0]))\n    return vartype,bearing,a,anisotropy", "response": "Function to instantiate a Vario2d from a PEST - style structure file."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _read_structure_attributes(f):\n\n    line = ''\n    variogram_info = {}\n    while \"end structure\" not in line:\n        line = f.readline()\n        if line == '':\n            raise Exception(\"EOF while reading structure\")\n        line = line.strip().lower().split()\n        if line[0].startswith('#'):\n            continue\n        if line[0] == \"nugget\":\n            nugget = float(line[1])\n        elif line[0] == \"transform\":\n            transform = line[1]\n        elif line[0] == \"numvariogram\":\n            numvariograms = int(line[1])\n        elif line[0] == \"variogram\":\n            variogram_info[line[1]] = float(line[2])\n        elif line[0] == \"end\":\n            break\n        elif line[0] == \"mean\":\n            warnings.warn(\"'mean' attribute not supported, skipping\",PyemuWarning)\n        else:\n            raise Exception(\"unrecognized line in structure definition:{0}\".\\\n                            format(line[0]))\n    assert numvariograms == len(variogram_info)\n    return nugget,transform,variogram_info", "response": "function to read information from a PEST - style structure file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to read an SGEMS - type variogram XML file into a GeoStruct", "response": "def read_sgems_variogram_xml(xml_file,return_type=GeoStruct):\n    \"\"\" function to read an SGEMS-type variogram XML file into\n    a GeoStruct\n\n    Parameters\n    ----------\n    xml_file : (str)\n        SGEMS variogram XML file\n    return_type :  (object)\n        the instance type to return.  Default is GeoStruct\n\n    Returns\n    -------\n    GeoStruct : GeoStruct\n\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    ``>>>gs = pyemu.utils.geostats.read_sgems_variogram_xml(\"sgems.xml\")``\n\n    \"\"\"\n    try:\n        import xml.etree.ElementTree as ET\n\n    except Exception as e:\n        print(\"error import elementtree, skipping...\")\n    VARTYPE = {1: SphVario, 2: ExpVario, 3: GauVario, 4: None}\n    assert os.path.exists(xml_file)\n    tree = ET.parse(xml_file)\n    gs_model = tree.getroot()\n    structures = []\n    variograms = []\n    nugget = 0.0\n    num_struct = 0\n    for key,val in gs_model.items():\n        #print(key,val)\n        if str(key).lower() == \"nugget\":\n            if len(val) > 0:\n                nugget = float(val)\n        if str(key).lower() == \"structures_count\":\n            num_struct = int(val)\n    if num_struct == 0:\n        raise Exception(\"no structures found\")\n    if num_struct != 1:\n        raise NotImplementedError()\n    for structure in gs_model:\n        vtype, contribution = None, None\n        mx_range,mn_range = None, None\n        x_angle,y_angle = None,None\n        #struct_name = structure.tag\n        for key,val in structure.items():\n            key = str(key).lower()\n            if key == \"type\":\n                vtype = str(val).lower()\n                if vtype.startswith(\"sph\"):\n                    vtype = SphVario\n                elif vtype.startswith(\"exp\"):\n                    vtype = ExpVario\n                elif vtype.startswith(\"gau\"):\n                    vtype = GauVario\n                else:\n                    raise Exception(\"unrecognized variogram type:{0}\".format(vtype))\n\n            elif key == \"contribution\":\n                contribution = float(val)\n            for item in structure:\n                if item.tag.lower() == \"ranges\":\n                    mx_range = float(item.attrib[\"max\"])\n                    mn_range = float(item.attrib[\"min\"])\n                elif item.tag.lower() == \"angles\":\n                    x_angle = float(item.attrib[\"x\"])\n                    y_angle = float(item.attrib[\"y\"])\n\n        assert contribution is not None\n        assert mn_range is not None\n        assert mx_range is not None\n        assert x_angle is not None\n        assert y_angle is not None\n        assert vtype is not None\n        v = vtype(contribution=contribution,a=mx_range,\n                  anisotropy=mx_range/mn_range,bearing=(180.0/np.pi)*np.arctan2(x_angle,y_angle),\n                  name=structure.tag)\n        return GeoStruct(nugget=nugget,variograms=[v])"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef gslib_2_dataframe(filename,attr_name=None,x_idx=0,y_idx=1):\n    with open(filename,'r') as f:\n        title = f.readline().strip()\n        num_attrs = int(f.readline().strip())\n        attrs = [f.readline().strip() for _ in range(num_attrs)]\n        if attr_name is not None:\n            assert attr_name in attrs,\"{0} not in attrs:{1}\".format(attr_name,','.join(attrs))\n        else:\n            assert len(attrs) == 3,\"propname is None but more than 3 attrs in gslib file\"\n            attr_name = attrs[2]\n        assert len(attrs) > x_idx\n        assert len(attrs) > y_idx\n        a_idx = attrs.index(attr_name)\n        x,y,a = [],[],[]\n        while True:\n            line = f.readline()\n            if line == '':\n                break\n            raw = line.strip().split()\n            try:\n                x.append(float(raw[x_idx]))\n                y.append(float(raw[y_idx]))\n                a.append(float(raw[a_idx]))\n            except Exception as e:\n                raise Exception(\"error paring line {0}: {1}\".format(line,str(e)))\n    df = pd.DataFrame({\"x\":x,\"y\":y,\"value\":a})\n    df.loc[:,\"name\"] = [\"pt{0}\".format(i) for i in range(df.shape[0])]\n    df.index = df.name\n    return df", "response": "function to read a GSLIB point data file into a pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef load_sgems_exp_var(filename):\n\n    assert os.path.exists(filename)\n    import xml.etree.ElementTree as etree\n    tree = etree.parse(filename)\n    root = tree.getroot()\n    dfs = {}\n    for variogram in root:\n        #print(variogram.tag)\n        for attrib in variogram:\n\n            #print(attrib.tag,attrib.text)\n            if attrib.tag == \"title\":\n                title = attrib.text.split(',')[0].split('=')[-1]\n            elif attrib.tag == \"x\":\n                x = [float(i) for i in attrib.text.split()]\n            elif attrib.tag == \"y\":\n                y = [float(i) for i in attrib.text.split()]\n            elif attrib.tag == \"pairs\":\n                pairs = [int(i) for i in attrib.text.split()]\n\n            for item in attrib:\n                print(item,item.tag)\n        df = pd.DataFrame({\"x\":x,\"y\":y,\"pairs\":pairs})\n        df.loc[df.y<0.0,\"y\"] = np.NaN\n        dfs[title] = df\n    return dfs", "response": "read an SGEMS experimental variogram XML file into a sequence of pandas. DataFrames"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef fac2real(pp_file=None,factors_file=\"factors.dat\",out_file=\"test.ref\",\n             upper_lim=1.0e+30,lower_lim=-1.0e+30,fill_value=1.0e+30):\n    \"\"\"A python replication of the PEST fac2real utility for creating a\n    structure grid array from previously calculated kriging factors (weights)\n\n    Parameters\n    ----------\n    pp_file : (str)\n        PEST-type pilot points file\n    factors_file : (str)\n        PEST-style factors file\n    out_file : (str)\n        filename of array to write.  If None, array is returned, else\n        value of out_file is returned.  Default is \"test.ref\".\n    upper_lim : (float)\n        maximum interpolated value in the array.  Values greater than\n        upper_lim are set to fill_value\n    lower_lim : (float)\n        minimum interpolated value in the array.  Values less than lower_lim\n        are set to fill_value\n    fill_value : (float)\n        the value to assign array nodes that are not interpolated\n\n\n    Returns\n    -------\n    arr : numpy.ndarray\n        if out_file is None\n    out_file : str\n        if out_file it not None\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    ``>>>pyemu.utils.geostats.fac2real(\"hkpp.dat\",out_file=\"hk_layer_1.ref\")``\n\n    \"\"\"\n\n    if pp_file is not None and isinstance(pp_file,str):\n        assert os.path.exists(pp_file)\n        # pp_data = pd.read_csv(pp_file,delim_whitespace=True,header=None,\n        #                       names=[\"name\",\"parval1\"],usecols=[0,4])\n        pp_data = pp_file_to_dataframe(pp_file)\n        pp_data.loc[:,\"name\"] = pp_data.name.apply(lambda x: x.lower())\n    elif pp_file is not None and isinstance(pp_file,pd.DataFrame):\n        assert \"name\" in pp_file.columns\n        assert \"parval1\" in pp_file.columns\n        pp_data = pp_file\n    else:\n        raise Exception(\"unrecognized pp_file arg: must be str or pandas.DataFrame, not {0}\"\\\n                        .format(type(pp_file)))\n    assert os.path.exists(factors_file)\n    f_fac = open(factors_file,'r')\n    fpp_file = f_fac.readline()\n    if pp_file is None and pp_data is None:\n        pp_data = pp_file_to_dataframe(fpp_file)\n        pp_data.loc[:, \"name\"] = pp_data.name.apply(lambda x: x.lower())\n\n    fzone_file = f_fac.readline()\n    ncol,nrow = [int(i) for i in f_fac.readline().strip().split()]\n    npp = int(f_fac.readline().strip())\n    pp_names = [f_fac.readline().strip().lower() for _ in range(npp)]\n\n    # check that pp_names is sync'd with pp_data\n    diff = set(list(pp_data.name)).symmetric_difference(set(pp_names))\n    if len(diff) > 0:\n        raise Exception(\"the following pilot point names are not common \" +\\\n                        \"between the factors file and the pilot points file \" +\\\n                        ','.join(list(diff)))\n\n    arr = np.zeros((nrow,ncol),dtype=np.float) + fill_value\n    pp_dict = {int(name):val for name,val in zip(pp_data.index,pp_data.parval1)}\n    try:\n        pp_dict_log = {name:np.log10(val) for name,val in zip(pp_data.index,pp_data.parval1)}\n    except:\n        pp_dict_log = {}\n    #for i in range(nrow):\n    #    for j in range(ncol):\n    while True:\n        line = f_fac.readline()\n        if len(line) == 0:\n            #raise Exception(\"unexpected EOF in factors file\")\n            break\n        try:\n            inode,itrans,fac_data = parse_factor_line(line)\n        except Exception as e:\n            raise Exception(\"error parsing factor line {0}:{1}\".format(line,str(e)))\n        #fac_prods = [pp_data.loc[pp,\"value\"]*fac_data[pp] for pp in fac_data]\n        if itrans == 0:\n            fac_sum = sum([pp_dict[pp] * fac_data[pp] for pp in fac_data])\n        else:\n            fac_sum = sum([pp_dict_log[pp] * fac_data[pp] for pp in fac_data])\n        if itrans != 0:\n            fac_sum = 10**fac_sum\n        #col = ((inode - 1) // nrow) + 1\n        #row = inode - ((col - 1) * nrow)\n        row = ((inode-1) // ncol) + 1\n        col = inode - ((row - 1) * ncol)\n        #arr[row-1,col-1] = np.sum(np.array(fac_prods))\n        arr[row - 1, col - 1] = fac_sum\n    arr[arr<lower_lim] = lower_lim\n    arr[arr>upper_lim] = upper_lim\n\n    #print(out_file,arr.min(),pp_data.parval1.min(),lower_lim)\n\n    if out_file is not None:\n        np.savetxt(out_file,arr,fmt=\"%15.6E\",delimiter='')\n        return out_file\n    return arr", "response": "A python replication of the PEST fac2real utility for creating a new avec of the same size as the previous kriging factors."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_factor_line(line):\n\n    raw = line.strip().split()\n    inode,itrans,nfac = [int(i) for i in raw[:3]]\n    fac_data = {int(raw[ifac])-1:float(raw[ifac+1]) for ifac in range(4,4+nfac*2,2)}\n    # fac_data = {}\n    # for ifac in range(4,4+nfac*2,2):\n    #     pnum = int(raw[ifac]) - 1 #zero based to sync with pandas\n    #     fac = float(raw[ifac+1])\n    #     fac_data[pnum] = fac\n    return inode,itrans,fac_data", "response": "function to parse a factor line from a factor file"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites a PEST - style structure file containing the current state of the object", "response": "def to_struct_file(self, f):\n        \"\"\" write a PEST-style structure file\n\n        Parameters\n        ----------\n        f : (str or file handle)\n            file to write the GeoStruct information to\n\n        \"\"\"\n        if isinstance(f, str):\n            f = open(f,'w')\n        f.write(\"STRUCTURE {0}\\n\".format(self.name))\n        f.write(\"  NUGGET {0}\\n\".format(self.nugget))\n        f.write(\"  NUMVARIOGRAM {0}\\n\".format(len(self.variograms)))\n        for v in self.variograms:\n            f.write(\"  VARIOGRAM {0} {1}\\n\".format(v.name,v.contribution))\n        f.write(\"  TRANSFORM {0}\\n\".format(self.transform))\n        f.write(\"END STRUCTURE\\n\\n\")\n        for v in self.variograms:\n            v.to_struct_file(f)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbuild a sparse matrix from a set of x y pairs and names", "response": "def sparse_covariance_matrix(self,x,y,names):\n        \"\"\"build a pyemu.Cov instance from GeoStruct\n\n                Parameters\n                ----------\n                x : (iterable of floats)\n                    x-coordinate locations\n                y : (iterable of floats)\n                    y-coordinate locations\n                names : (iterable of str)\n                   (parameter) names of locations.\n\n                Returns\n                -------\n                sparse : pyemu.SparseMatrix\n                    the sparse covariance matrix implied by this GeoStruct for the x,y pairs.\n\n                Example\n                -------\n                ``>>>pp_df = pyemu.pp_utils.pp_file_to_dataframe(\"hkpp.dat\")``\n\n                ``>>>cov = gs.covariance_matrix(pp_df.x,pp_df.y,pp_df.name)``\n\n\n                \"\"\"\n\n        if not isinstance(x, np.ndarray):\n            x = np.array(x)\n        if not isinstance(y, np.ndarray):\n            y = np.array(y)\n        assert x.shape[0] == y.shape[0]\n        assert x.shape[0] == len(names)\n\n        iidx = [i for i in range(len(names))]\n        jidx = list(iidx)\n        data = list(np.zeros(x.shape[0])+self.nugget)\n\n        for v in self.variograms:\n            v.add_sparse_covariance_matrix(x,y,names,iidx,jidx,data)\n        coo = scipy.sparse.coo_matrix((data,(iidx,jidx)),shape=(len(names),len(names)))\n        coo.eliminate_zeros()\n        coo.sum_duplicates()\n        return SparseMatrix(coo,row_names=names,col_names=names)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef covariance_matrix(self,x,y,names=None,cov=None):\n\n        if not isinstance(x,np.ndarray):\n            x = np.array(x)\n        if not isinstance(y,np.ndarray):\n            y = np.array(y)\n        assert x.shape[0] == y.shape[0]\n\n        if names is not None:\n            assert x.shape[0] == len(names)\n            c = np.zeros((len(names),len(names)))\n            np.fill_diagonal(c,self.nugget)\n            cov = Cov(x=c,names=names)\n        elif cov is not None:\n            assert cov.shape[0] == x.shape[0]\n            names = cov.row_names\n            c = np.zeros((len(names),1))\n            c += self.nugget\n            cont = Cov(x=c,names=names,isdiagonal=True)\n            cov += cont\n\n        else:\n            raise Exception(\"GeoStruct.covariance_matrix() requires either \" +\n                            \"names or cov arg\")\n        for v in self.variograms:\n            v.covariance_matrix(x,y,cov=cov)\n        return cov", "response": "build a covariance matrix from a set of x and y pairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the covariance between two points implied by the GeoStruct.", "response": "def covariance(self,pt0,pt1):\n        \"\"\"get the covariance between two points implied by the GeoStruct.\n        This is used during the ordinary kriging process to get the RHS\n\n        Parameters\n        ----------\n        pt0 : (iterable length 2 of floats)\n        pt1 : (iterable length 2 of floats)\n\n        Returns\n        -------\n        covariance : float\n            the covariance between pt0 and pt1 implied by the GeoStruct\n\n        \"\"\"\n        #raise Exception()\n        cov = self.nugget\n        for vario in self.variograms:\n            cov += vario.covariance(pt0,pt1)\n        return cov"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef covariance_points(self,x0,y0,xother,yother):\n\n        cov = np.zeros((len(xother))) + self.nugget\n        for v in self.variograms:\n            cov += v.covariance_points(x0,y0,xother,yother)\n        return cov", "response": "Returns the covariance between point x0 y0 and the pointsxother yother."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef sill(self):\n        sill = self.nugget\n        for v in self.variograms:\n            sill += v.contribution\n        return sill", "response": "get the sill of the nugget and contribution\n            from each variogram"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a cheap plot of the GeoStruct", "response": "def plot(self,**kwargs):\n        \"\"\" make a cheap plot of the GeoStruct\n\n        Parameters\n        ----------\n        **kwargs : (dict)\n            keyword arguments to use for plotting.\n\n        Returns\n        -------\n        ax : matplotlib.pyplot.axis\n            the axis with the GeoStruct plot\n\n        Note\n        ----\n        optional arguments include \"ax\" (an existing axis),\n        \"individuals\" (plot each variogram on a separate axis),\n        \"legend\" (add a legend to the plot(s)).  All other kwargs\n        are passed to matplotlib.pyplot.plot()\n\n        \"\"\"\n        #\n        if \"ax\" in kwargs:\n            ax = kwargs.pop(\"ax\")\n        else:\n            try:\n                import matplotlib.pyplot as plt\n            except Exception as e:\n                raise Exception(\"error importing matplotlib: {0}\".format(str(e)))\n\n            ax = plt.subplot(111)\n        legend = kwargs.pop(\"legend\",False)\n        individuals = kwargs.pop(\"individuals\",False)\n        xmx = max([v.a*3.0 for v in self.variograms])\n        x = np.linspace(0,xmx,100)\n        y = np.zeros_like(x)\n        for v in self.variograms:\n            yv = v.inv_h(x)\n            if individuals:\n                ax.plot(x,yv,label=v.name,**kwargs)\n            y += yv\n        y += self.nugget\n        ax.plot(x,y,label=self.name,**kwargs)\n        if legend:\n            ax.legend()\n        ax.set_xlabel(\"distance\")\n        ax.set_ylabel(\"$\\gamma$\")\n        return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef check_point_data_dist(self, rectify=False):\n\n        ptx_array = self.point_data.x.values\n        pty_array = self.point_data.y.values\n        ptnames = self.point_data.name.values\n        drop = []\n        for i in range(self.point_data.shape[0]):\n            ix,iy,iname = ptx_array[i],pty_array[i],ptnames[i]\n            dist = pd.Series((ptx_array[i+1:] - ix) ** 2 + (pty_array[i+1:] - iy) ** 2, ptnames[i+1:])\n            if dist.min() < EPSILON**2:\n                print(iname,ix,iy)\n                warnings.warn(\"points {0} and {1} are too close. This will cause a singular kriging matrix \".\\\n                              format(iname,dist.idxmin()),PyemuWarning)\n                drop_idxs = dist.loc[dist<=EPSILON**2]\n                drop.extend([pt for pt in list(drop_idxs.index) if pt not in drop])\n        if rectify and len(drop) > 0:\n            print(\"rectifying point data by removing the following points: {0}\".format(','.join(drop)))\n            print(self.point_data.shape)\n            self.point_data = self.point_data.loc[self.point_data.index.map(lambda x: x not in drop),:]\n            print(self.point_data.shape)", "response": "check for point_data entries that are closer than EPSILON distance"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ncalculates the kriging factors for a given grid node.", "response": "def calc_factors_grid(self,spatial_reference,zone_array=None,minpts_interp=1,\n                          maxpts_interp=20,search_radius=1.0e+10,verbose=False,\n                          var_filename=None, forgive=False):\n        \"\"\" calculate kriging factors (weights) for a structured grid.\n\n        Parameters\n        ----------\n        spatial_reference : (flopy.utils.reference.SpatialReference)\n            a spatial reference that describes the orientation and\n            spatail projection of the the structured grid\n        zone_array : (numpy.ndarray)\n            an integer array of zones to use for kriging.  If not None,\n            then point_data must also contain a \"zone\" column.  point_data\n            entries with a zone value not found in zone_array will be skipped.\n            If None, then all point_data will (potentially) be used for\n            interpolating each grid node. Default is None\n        minpts_interp : (int)\n            minimum number of point_data entires to use for interpolation at\n            a given grid node.  grid nodes with less than minpts_interp\n            point_data found will be skipped (assigned np.NaN).  Defaut is 1\n        maxpts_interp : (int)\n            maximum number of point_data entries to use for interpolation at\n            a given grid node.  A larger maxpts_interp will yield \"smoother\"\n            interplation, but using a large maxpts_interp will slow the\n            (already) slow kriging solution process and may lead to\n            memory errors. Default is 20.\n        search_radius : (float)\n            the size of the region around a given grid node to search for\n            point_data entries. Default is 1.0e+10\n        verbose : (boolean)\n            a flag to  echo process to stdout during the interpolatino process.\n            Default is False\n        var_filename : (str)\n            a filename to save the kriging variance for each interpolated grid node.\n            Default is None.\n        forgive : (boolean)\n            flag to continue if inversion of the kriging matrix failes at one or more\n            grid nodes.  Inversion usually fails if the kriging matrix is singular,\n            resulting from point_data entries closer than EPSILON distance.  If True,\n            warnings are issued for each failed inversion.  If False, an exception\n            is raised for failed matrix inversion.\n\n        Returns\n        -------\n        df : pandas.DataFrame\n            a dataframe with information summarizing the ordinary kriging\n            process for each grid node\n\n        Note\n        ----\n        this method calls OrdinaryKrige.calc_factors()\n\n\n        Example\n        -------\n        ``>>>import flopy``\n\n        ``>>>import pyemu``\n\n        ``>>>v = pyemu.utils.geostats.ExpVario(a=1000,contribution=1.0)``\n\n        ``>>>gs = pyemu.utils.geostats.GeoStruct(variograms=v,nugget=0.5)``\n\n        ``>>>pp_df = pyemu.pp_utils.pp_file_to_dataframe(\"hkpp.dat\")``\n\n        ``>>>ok = pyemu.utils.geostats.OrdinaryKrige(gs,pp_df)``\n\n        ``>>>m = flopy.modflow.Modflow.load(\"mymodel.nam\")``\n\n        ``>>>df = ok.calc_factors_grid(m.sr,zone_array=m.bas6.ibound[0].array,``\n\n        ``>>>                          var_filename=\"ok_var.dat\")``\n\n        ``>>>ok.to_grid_factor_file(\"factors.dat\")``\n\n        \"\"\"\n\n        self.spatial_reference = spatial_reference\n        self.interp_data = None\n        #assert isinstance(spatial_reference,SpatialReference)\n        try:\n            x = self.spatial_reference.xcentergrid.copy()\n            y = self.spatial_reference.ycentergrid.copy()\n        except Exception as e:\n            raise Exception(\"spatial_reference does not have proper attributes:{0}\"\\\n                            .format(str(e)))\n\n        if var_filename is not None:\n                arr = np.zeros((self.spatial_reference.nrow,\n                                self.spatial_reference.ncol)) - 1.0e+30\n\n        # the simple case of no zone array: ignore point_data zones\n        if zone_array is None:\n            df = self.calc_factors(x.ravel(),y.ravel(),\n                               minpts_interp=minpts_interp,\n                               maxpts_interp=maxpts_interp,\n                               search_radius=search_radius,\n                               verbose=verbose, forgive=forgive)\n            if var_filename is not None:\n                arr = df.err_var.values.reshape(x.shape)\n                np.savetxt(var_filename,arr,fmt=\"%15.6E\")\n\n        if zone_array is not None:\n            assert zone_array.shape == x.shape\n            if \"zone\" not in self.point_data.columns:\n                warnings.warn(\"'zone' columns not in point_data, assigning generic zone\",PyemuWarning)\n                self.point_data.loc[:,\"zone\"] = 1\n            pt_data_zones = self.point_data.zone.unique()\n            dfs = []\n            for pt_data_zone in pt_data_zones:\n                if pt_data_zone not in zone_array:\n                    warnings.warn(\"pt zone {0} not in zone array {1}, skipping\".\\\n                                  format(pt_data_zone,np.unique(zone_array)),PyemuWarning)\n                    continue\n                xzone,yzone = x.copy(),y.copy()\n                xzone[zone_array!=pt_data_zone] = np.NaN\n                yzone[zone_array!=pt_data_zone] = np.NaN\n                df = self.calc_factors(xzone.ravel(),yzone.ravel(),\n                                       minpts_interp=minpts_interp,\n                                       maxpts_interp=maxpts_interp,\n                                       search_radius=search_radius,\n                                       verbose=verbose,pt_zone=pt_data_zone,\n                                       forgive=forgive)\n                dfs.append(df)\n                if var_filename is not None:\n                    a = df.err_var.values.reshape(x.shape)\n                    na_idx = np.isfinite(a)\n                    arr[na_idx] = a[na_idx]\n            if self.interp_data is None or self.interp_data.dropna().shape[0] == 0:\n                raise Exception(\"no interpolation took place...something is wrong\")\n            df = pd.concat(dfs)\n        if var_filename is not None:\n            np.savetxt(var_filename,arr,fmt=\"%15.6E\")\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the ordinary kriging factors for the given x and y.", "response": "def calc_factors(self,x,y,minpts_interp=1,maxpts_interp=20,\n                     search_radius=1.0e+10,verbose=False,\n                     pt_zone=None,forgive=False):\n        \"\"\" calculate ordinary kriging factors (weights) for the points\n        represented by arguments x and y\n\n        Parameters\n        ----------\n        x : (iterable of floats)\n            x-coordinates to calculate kriging factors for\n        y : (iterable of floats)\n            y-coordinates to calculate kriging factors for\n        minpts_interp : (int)\n            minimum number of point_data entires to use for interpolation at\n            a given x,y interplation point.  interpolation points with less\n            than minpts_interp point_data found will be skipped\n            (assigned np.NaN).  Defaut is 1\n        maxpts_interp : (int)\n            maximum number of point_data entries to use for interpolation at\n            a given x,y interpolation point.  A larger maxpts_interp will\n            yield \"smoother\" interplation, but using a large maxpts_interp\n            will slow the (already) slow kriging solution process and may\n            lead to memory errors. Default is 20.\n        search_radius : (float)\n            the size of the region around a given x,y interpolation point to search for\n            point_data entries. Default is 1.0e+10\n        verbose : (boolean)\n            a flag to  echo process to stdout during the interpolatino process.\n            Default is False\n        forgive : (boolean)\n            flag to continue if inversion of the kriging matrix failes at one or more\n            interpolation points.  Inversion usually fails if the kriging matrix is singular,\n            resulting from point_data entries closer than EPSILON distance.  If True,\n            warnings are issued for each failed inversion.  If False, an exception\n            is raised for failed matrix inversion.\n\n        Returns\n        -------\n        df : pandas.DataFrame\n            a dataframe with information summarizing the ordinary kriging\n            process for each interpolation points\n\n\n        \"\"\"\n\n        assert len(x) == len(y)\n\n        # find the point data to use for each interp point\n        sqradius = search_radius**2\n        df = pd.DataFrame(data={'x':x,'y':y})\n        inames,idist,ifacts,err_var = [],[],[],[]\n        sill = self.geostruct.sill\n        if pt_zone is None:\n            ptx_array = self.point_data.x.values\n            pty_array = self.point_data.y.values\n            ptnames = self.point_data.name.values\n        else:\n            pt_data = self.point_data\n            ptx_array = pt_data.loc[pt_data.zone==pt_zone,\"x\"].values\n            pty_array = pt_data.loc[pt_data.zone==pt_zone,\"y\"].values\n            ptnames = pt_data.loc[pt_data.zone==pt_zone,\"name\"].values\n        #if verbose:\n        print(\"starting interp point loop for {0} points\".format(df.shape[0]))\n        start_loop = datetime.now()\n        for idx,(ix,iy) in enumerate(zip(df.x,df.y)):\n            if np.isnan(ix) or np.isnan(iy): #if nans, skip\n                inames.append([])\n                idist.append([])\n                ifacts.append([])\n                err_var.append(np.NaN)\n                continue\n            if verbose:\n                istart = datetime.now()\n                print(\"processing interp point:{0} of {1}\".format(idx,df.shape[0]))\n            # if verbose == 2:\n            #     start = datetime.now()\n            #     print(\"calc ipoint dist...\",end='')\n\n            #  calc dist from this interp point to all point data...slow\n            dist = pd.Series((ptx_array-ix)**2 + (pty_array-iy)**2,ptnames)\n            dist.sort_values(inplace=True)\n            dist = dist.loc[dist <= sqradius]\n\n            # if too few points were found, skip\n            if len(dist) < minpts_interp:\n                inames.append([])\n                idist.append([])\n                ifacts.append([])\n                err_var.append(sill)\n                continue\n\n            # only the maxpts_interp points\n            dist = dist.iloc[:maxpts_interp].apply(np.sqrt)\n            pt_names = dist.index.values\n            # if one of the points is super close, just use it and skip\n            if dist.min() <= EPSILON:\n                ifacts.append([1.0])\n                idist.append([EPSILON])\n                inames.append([dist.idxmin()])\n                err_var.append(self.geostruct.nugget)\n                continue\n            # if verbose == 2:\n            #     td = (datetime.now()-start).total_seconds()\n            #     print(\"...took {0}\".format(td))\n            #     start = datetime.now()\n            #     print(\"extracting pt cov...\",end='')\n\n            #vextract the point-to-point covariance matrix\n            point_cov = self.point_cov_df.loc[pt_names,pt_names]\n            # if verbose == 2:\n            #     td = (datetime.now()-start).total_seconds()\n            #     print(\"...took {0}\".format(td))\n            #     print(\"forming ipt-to-point cov...\",end='')\n\n            # calc the interp point to points covariance\n            interp_cov = self.geostruct.covariance_points(ix,iy,self.point_data.loc[pt_names,\"x\"],\n                                                          self.point_data.loc[pt_names,\"y\"])\n\n            if verbose == 2:\n                td = (datetime.now()-start).total_seconds()\n                print(\"...took {0} seconds\".format(td))\n                print(\"forming lin alg components...\",end='')\n\n            # form the linear algebra parts and solve\n            d = len(pt_names) + 1 # +1 for lagrange mult\n            A = np.ones((d,d))\n            A[:-1,:-1] = point_cov.values\n            A[-1,-1] = 0.0 #unbiaised constraint\n            rhs = np.ones((d,1))\n            rhs[:-1,0] = interp_cov\n            # if verbose == 2:\n            #     td = (datetime.now()-start).total_seconds()\n            #     print(\"...took {0}\".format(td))\n            #     print(\"solving...\",end='')\n            # # solve\n            try:\n                facs = np.linalg.solve(A,rhs)\n            except Exception as e:\n                print(\"error solving for factors: {0}\".format(str(e)))\n                print(\"point:\",ix,iy)\n                print(\"dist:\",dist)\n                print(\"A:\", A)\n                print(\"rhs:\", rhs)\n                if forgive:\n                    inames.append([])\n                    idist.append([])\n                    ifacts.append([])\n                    err_var.append(np.NaN)\n                    continue\n                else:\n                    raise Exception(\"error solving for factors:{0}\".format(str(e)))\n            assert len(facs) - 1 == len(dist)\n\n            err_var.append(float(sill + facs[-1] - sum([f*c for f,c in zip(facs[:-1],interp_cov)])))\n            inames.append(pt_names)\n\n            idist.append(dist.values)\n            ifacts.append(facs[:-1,0])\n            # if verbose == 2:\n            #     td = (datetime.now()-start).total_seconds()\n            #     print(\"...took {0}\".format(td))\n            if verbose:\n                td = (datetime.now()-istart).total_seconds()\n                print(\"point took {0}\".format(td))\n        df[\"idist\"] = idist\n        df[\"inames\"] = inames\n        df[\"ifacts\"] = ifacts\n        df[\"err_var\"] = err_var\n        if pt_zone is None:\n            self.interp_data = df\n        else:\n            if self.interp_data is None:\n                self.interp_data = df\n            else:\n                self.interp_data = self.interp_data.append(df)\n        td = (datetime.now() - start_loop).total_seconds()\n        print(\"took {0} seconds\".format(td))\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef to_grid_factors_file(self, filename,points_file=\"points.junk\",\n                             zone_file=\"zone.junk\"):\n        \"\"\" write a grid-based PEST-style factors file.  This file can be used with\n        the fac2real() method to write an interpolated structured array\n\n        Parameters\n        ----------\n        filename : (str)\n            factor filename\n        points_file : (str)\n            points filename to add to the header of the factors file.\n            Not used by fac2real() method.  Default is \"points.junk\"\n        zone_file : (str)\n            zone filename to add to the header of the factors file.\n            Not used by fac2real() method.  Default is \"zone.junk\"\n\n        Note\n        ----\n        this method should be called after OrdinaryKirge.calc_factors_grid()\n\n        \"\"\"\n        if self.interp_data is None:\n            raise Exception(\"ok.interp_data is None, must call calc_factors_grid() first\")\n        if self.spatial_reference is None:\n            raise Exception(\"ok.spatial_reference is None, must call calc_factors_grid() first\")\n        with open(filename, 'w') as f:\n            f.write(points_file + '\\n')\n            f.write(zone_file + '\\n')\n            f.write(\"{0} {1}\\n\".format(self.spatial_reference.ncol, self.spatial_reference.nrow))\n            f.write(\"{0}\\n\".format(self.point_data.shape[0]))\n            [f.write(\"{0}\\n\".format(name)) for name in self.point_data.name]\n            t = 0\n            if self.geostruct.transform == \"log\":\n                t = 1\n            pt_names = list(self.point_data.name)\n            for idx,names,facts in zip(self.interp_data.index,self.interp_data.inames,self.interp_data.ifacts):\n                if len(facts) == 0:\n                    continue\n                n_idxs = [pt_names.index(name) for name in names]\n                f.write(\"{0} {1} {2} {3:8.5e} \".format(idx+1, t, len(names), 0.0))\n                [f.write(\"{0} {1:12.8g} \".format(i+1, w)) for i, w in zip(n_idxs, facts)]\n                f.write(\"\\n\")", "response": "This method writes a PEST - style PEST - style factors file."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nwrites the Vario2d item to a PEST - style structure file", "response": "def to_struct_file(self, f):\n        \"\"\" write the Vario2d to a PEST-style structure file\n\n        Parameters\n        ----------\n        f : (str or file handle)\n            item to write to\n\n        \"\"\"\n        if isinstance(f, str):\n            f = open(f,'w')\n        f.write(\"VARIOGRAM {0}\\n\".format(self.name))\n        f.write(\"  VARTYPE {0}\\n\".format(self.vartype))\n        f.write(\"  A {0}\\n\".format(self.a))\n        f.write(\"  ANISOTROPY {0}\\n\".format(self.anisotropy))\n        f.write(\"  BEARING {0}\\n\".format(self.bearing))\n        f.write(\"END VARIOGRAM\\n\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rotation_coefs(self):\n        return [np.cos(self.bearing_rads),\n                np.sin(self.bearing_rads),\n                -1.0*np.sin(self.bearing_rads),\n                np.cos(self.bearing_rads)]", "response": "get the rotation coefficients in radians\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot(self,**kwargs):\n        try:\n            import matplotlib.pyplot as plt\n        except Exception as e:\n            raise Exception(\"error importing matplotlib: {0}\".format(str(e)))\n\n        ax = kwargs.pop(\"ax\",plt.subplot(111))\n        x = np.linspace(0,self.a*3,100)\n        y = self.inv_h(x)\n        ax.set_xlabel(\"distance\")\n        ax.set_ylabel(\"$\\gamma$\")\n        ax.plot(x,y,**kwargs)\n        return ax", "response": "get a cheap plot of the Vario2d\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_sparse_covariance_matrix(self,x,y,names,iidx,jidx,data):\n\n        \"\"\"build a pyemu.SparseMatrix instance implied by Vario2d\n\n        Parameters\n        ----------\n        x : (iterable of floats)\n            x-coordinate locations\n        y : (iterable of floats)\n            y-coordinate locations\n        names : (iterable of str)\n            names of locations. If None, cov must not be None\n        iidx : 1-D ndarray\n            i row indices\n        jidx : 1-D ndarray\n            j col indices\n        data : 1-D ndarray\n            nonzero entries\n\n\n        Returns\n        -------\n        None\n\n        \"\"\"\n        if not isinstance(x, np.ndarray):\n            x = np.array(x)\n        if not isinstance(y, np.ndarray):\n            y = np.array(y)\n        assert x.shape[0] == y.shape[0]\n\n\n        assert x.shape[0] == len(names)\n        #     c = np.zeros((len(names), len(names)))\n        #     np.fill_diagonal(c, self.contribution)\n        #     cov = Cov(x=c, names=names)\n        # elif cov is not None:\n        #     assert cov.shape[0] == x.shape[0]\n        #     names = cov.row_names\n        #     c = np.zeros((len(names), 1)) + self.contribution\n        #     cont = Cov(x=c, names=names, isdiagonal=True)\n        #     cov += cont\n        #\n        # else:\n        #     raise Exception(\"Vario2d.covariance_matrix() requires either\" +\n        #                     \"names or cov arg\")\n        # rc = self.rotation_coefs\n        for i,name in enumerate(names):\n            iidx.append(i)\n            jidx.append(i)\n            data.append(self.contribution)\n\n        for i1, (n1, x1, y1) in enumerate(zip(names, x, y)):\n            dx = x1 - x[i1 + 1:]\n            dy = y1 - y[i1 + 1:]\n            dxx, dyy = self._apply_rotation(dx, dy)\n            h = np.sqrt(dxx * dxx + dyy * dyy)\n\n            h[h < 0.0] = 0.0\n            cv = self._h_function(h)\n            if np.any(np.isnan(cv)):\n                raise Exception(\"nans in cv for i1 {0}\".format(i1))\n            #cv[h>self.a] = 0.0\n            j = list(np.arange(i1+1,x.shape[0]))\n            i = [i1] * len(j)\n            iidx.extend(i)\n            jidx.extend(j)\n            data.extend(list(cv))\n            # replicate across the diagonal\n            iidx.extend(j)\n            jidx.extend(i)\n            data.extend(list(cv))", "response": "add a sparse matrix to the Vario2d object"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nbuilds a covariance matrix for a set of locations x and y.", "response": "def covariance_matrix(self,x,y,names=None,cov=None):\n        \"\"\"build a pyemu.Cov instance implied by Vario2d\n\n        Parameters\n        ----------\n        x : (iterable of floats)\n            x-coordinate locations\n        y : (iterable of floats)\n            y-coordinate locations\n        names : (iterable of str)\n            names of locations. If None, cov must not be None\n        cov : (pyemu.Cov)\n            an existing Cov instance.  Vario2d contribution is added to cov\n\n        Returns\n        -------\n        cov : pyemu.Cov\n\n        Note\n        ----\n        either names or cov must not be None.\n\n        \"\"\"\n        if not isinstance(x,np.ndarray):\n            x = np.array(x)\n        if not isinstance(y,np.ndarray):\n            y = np.array(y)\n        assert x.shape[0] == y.shape[0]\n\n        if names is not None:\n            assert x.shape[0] == len(names)\n            c = np.zeros((len(names),len(names)))\n            np.fill_diagonal(c,self.contribution)\n            cov = Cov(x=c,names=names)\n        elif cov is not None:\n            assert cov.shape[0] == x.shape[0]\n            names = cov.row_names\n            c = np.zeros((len(names),1)) + self.contribution\n            cont = Cov(x=c,names=names,isdiagonal=True)\n            cov += cont\n\n        else:\n            raise Exception(\"Vario2d.covariance_matrix() requires either\" +\n                            \"names or cov arg\")\n        rc = self.rotation_coefs\n        for i1,(n1,x1,y1) in enumerate(zip(names,x,y)):\n            dx = x1 - x[i1+1:]\n            dy = y1 - y[i1+1:]\n            dxx,dyy = self._apply_rotation(dx,dy)\n            h = np.sqrt(dxx*dxx + dyy*dyy)\n\n            h[h<0.0] = 0.0\n            h = self._h_function(h)\n            if np.any(np.isnan(h)):\n                raise Exception(\"nans in h for i1 {0}\".format(i1))\n            cov.x[i1,i1+1:] += h\n        for i in range(len(names)):\n            cov.x[i+1:,i] = cov.x[i,i+1:]\n        return cov"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef covariance_points(self,x0,y0,xother,yother):\n        dx = x0 - xother\n        dy = y0 - yother\n        dxx,dyy = self._apply_rotation(dx,dy)\n        h = np.sqrt(dxx*dxx + dyy*dyy)\n        return self._h_function(h)", "response": "get the covariance between base point x0 y0 and other points xother yother implied by Vario2d\n Vario2d."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef covariance(self,pt0,pt1):\n\n        x = np.array([pt0[0],pt1[0]])\n        y = np.array([pt0[1],pt1[1]])\n        names = [\"n1\",\"n2\"]\n        return self.covariance_matrix(x,y,names=names).x[0,1]", "response": "get the covariance between two points implied by Vario2d\n           "}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _h_function(self,h):\n        return self.contribution * np.exp(-1.0 * h / self.a)", "response": "private method exponential variogram h function"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _h_function(self,h):\n\n        hh = -1.0 * (h * h) / (self.a * self.a)\n        return self.contribution * np.exp(hh)", "response": "private method for the gaussian variogram h function"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _h_function(self,h):\n\n        hh = h / self.a\n        h = self.contribution * (1.0 - (hh * (1.5 - (0.5 * hh * hh))))\n        h[hh > 1.0] = 0.0\n        return h", "response": "private method for the spherical variogram h function"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nlog a one time statement", "response": "def statement(self,phrase):\n        \"\"\" log a one time statement\n\n        Parameters\n        ----------\n        phrase : str\n            statement to log\n\n        \"\"\"\n        t = datetime.now()\n        s = str(t) + ' ' + str(phrase) + '\\n'\n        if self.echo:\n            print(s,end='')\n        if self.filename:\n            self.f.write(s)\n            self.f.flush()"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef log(self,phrase):\n        pass\n        t = datetime.now()\n        if phrase in self.items.keys():\n            s = str(t) + ' finished: ' + str(phrase) + \" took: \" + \\\n                str(t - self.items[phrase]) + '\\n'\n            if self.echo:\n                print(s,end='')\n            if self.filename:\n                self.f.write(s)\n                self.f.flush()\n            self.items.pop(phrase)\n        else:\n            s = str(t) + ' starting: ' + str(phrase) + '\\n'\n            if self.echo:\n                print(s,end='')\n            if self.filename:\n                self.f.write(s)\n                self.f.flush()\n            self.items[phrase] = copy.deepcopy(t)", "response": "log something that happened"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a warning to the log file.", "response": "def warn(self,message):\n        \"\"\"write a warning to the log file.\n\n        Parameters\n        ----------\n        message : str\n            the warning text\n        \"\"\"\n        s = str(datetime.now()) + \" WARNING: \" + message + '\\n'\n        if self.echo:\n            print(s,end='')\n        if self.filename:\n            self.f.write(s)\n            self.f.flush\n        warnings.warn(s,PyemuWarning)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef lraise(self,message):\n        s = str(datetime.now()) + \" ERROR: \" + message + '\\n'\n        print(s,end='')\n        if self.filename:\n            self.f.write(s)\n            self.f.flush\n            self.f.close()\n        raise Exception(message)", "response": "log an exception close the log file then raise the exception"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a template file for a modflow parameter value file.", "response": "def modflow_pval_to_template_file(pval_file,tpl_file=None):\n    \"\"\"write a template file for a modflow parameter value file.\n    Uses names in the first column in the pval file as par names.\n\n    Parameters\n    ----------\n    pval_file : str\n        parameter value file\n    tpl_file : str, optional\n        template file to write.  If None, use <pval_file>.tpl.\n        Default is None\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        pandas DataFrame with control file parameter information\n    \"\"\"\n\n    if tpl_file is None:\n        tpl_file = pval_file + \".tpl\"\n    pval_df = pd.read_csv(pval_file,delim_whitespace=True,\n                          header=None,skiprows=2,\n                          names=[\"parnme\",\"parval1\"])\n    pval_df.index = pval_df.parnme\n    pval_df.loc[:,\"tpl\"] = pval_df.parnme.apply(lambda x: \" ~   {0:15s}   ~\".format(x))\n    with open(tpl_file,'w') as f:\n        f.write(\"ptf ~\\n#pval template file from pyemu\\n\")\n        f.write(\"{0:10d} #NP\\n\".format(pval_df.shape[0]))\n        f.write(pval_df.loc[:,[\"parnme\",\"tpl\"]].to_string(col_space=0,\n                                                          formatters=[SFMT,SFMT],\n                                                          index=False,\n                                                          header=False,\n                                                          justify=\"left\"))\n    return pval_df"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite an instruction file for a modflow head observation file", "response": "def modflow_hob_to_instruction_file(hob_file):\n    \"\"\"write an instruction file for a modflow head observation file\n\n    Parameters\n    ----------\n    hob_file : str\n        modflow hob file\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        pandas DataFrame with control file observation information\n    \"\"\"\n\n    hob_df = pd.read_csv(hob_file,delim_whitespace=True,skiprows=1,\n                         header=None,names=[\"simval\",\"obsval\",\"obsnme\"])\n\n    hob_df.loc[:,\"obsnme\"] = hob_df.obsnme.apply(str.lower)\n    hob_df.loc[:,\"ins_line\"] = hob_df.obsnme.apply(lambda x:\"l1 !{0:s}!\".format(x))\n    hob_df.loc[0,\"ins_line\"] = hob_df.loc[0,\"ins_line\"].replace('l1','l2')\n\n    ins_file = hob_file + \".ins\"\n    f_ins = open(ins_file, 'w')\n    f_ins.write(\"pif ~\\n\")\n    f_ins.write(hob_df.loc[:,[\"ins_line\"]].to_string(col_space=0,\n                                                     columns=[\"ins_line\"],\n                                                     header=False,\n                                                     index=False,\n                                                     formatters=[SFMT]) + '\\n')\n    hob_df.loc[:,\"weight\"] = 1.0\n    hob_df.loc[:,\"obgnme\"] = \"obgnme\"\n    f_ins.close()\n    return hob_df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef modflow_hydmod_to_instruction_file(hydmod_file):\n\n    hydmod_df, hydmod_outfile = modflow_read_hydmod_file(hydmod_file)\n\n\n    hydmod_df.loc[:,\"ins_line\"] = hydmod_df.obsnme.apply(lambda x:\"l1 w !{0:s}!\".format(x))\n\n    ins_file = hydmod_outfile + \".ins\"\n\n    with open(ins_file, 'w') as f_ins:\n        f_ins.write(\"pif ~\\nl1\\n\")\n        f_ins.write(hydmod_df.loc[:,[\"ins_line\"]].to_string(col_space=0,\n                                                     columns=[\"ins_line\"],\n                                                     header=False,\n                                                     index=False,\n                                                     formatters=[SFMT]) + '\\n')\n    hydmod_df.loc[:,\"weight\"] = 1.0\n    hydmod_df.loc[:,\"obgnme\"] = \"obgnme\"\n\n    try:\n        os.system(\"inschek {0}.ins {0}\".format(hydmod_outfile))\n    except:\n        print(\"error running inschek\")\n\n    obs_obf = hydmod_outfile + \".obf\"\n    if os.path.exists(obs_obf):\n        df = pd.read_csv(obs_obf,delim_whitespace=True,header=None,names=[\"obsnme\",\"obsval\"])\n        df.loc[:,\"obgnme\"] = df.obsnme.apply(lambda x: x[:-9])\n        df.to_csv(\"_setup_\"+os.path.split(hydmod_outfile)[-1]+'.csv',index=False)\n        df.index = df.obsnme\n        return df\n\n\n    return hydmod_df", "response": "write an instruction file for a modflow hydmod file"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef modflow_read_hydmod_file(hydmod_file, hydmod_outfile=None):\n    try:\n        import flopy.utils as fu\n    except Exception as e:\n        print('flopy is not installed - cannot read {0}\\n{1}'.format(hydmod_file, e))\n        return\n    #print('Starting to read HYDMOD data from {0}'.format(hydmod_file))\n    obs = fu.HydmodObs(hydmod_file)\n    hyd_df = obs.get_dataframe()\n\n    hyd_df.columns = [i[2:] if i.lower() != 'totim' else i for i in hyd_df.columns]\n    #hyd_df.loc[:,\"datetime\"] = hyd_df.index\n    hyd_df['totim'] = hyd_df.index.map(lambda x: x.strftime(\"%Y%m%d\"))\n\n    hyd_df.rename(columns={'totim': 'datestamp'}, inplace=True)\n\n\n    # reshape into a single column\n    hyd_df = pd.melt(hyd_df, id_vars='datestamp')\n\n    hyd_df.rename(columns={'value': 'obsval'}, inplace=True)\n\n    hyd_df['obsnme'] = [i.lower() + '_' + j.lower() for i, j in zip(hyd_df.variable, hyd_df.datestamp)]\n\n    vc = hyd_df.obsnme.value_counts().sort_values()\n    vc = list(vc.loc[vc>1].index.values)\n    if len(vc) > 0:\n        hyd_df.to_csv(\"hyd_df.duplciates.csv\")\n        obs.get_dataframe().to_csv(\"hyd_org.duplicates.csv\")\n        raise Exception(\"duplicates in obsnme:{0}\".format(vc))\n    #assert hyd_df.obsnme.value_counts().max() == 1,\"duplicates in obsnme\"\n\n    if not hydmod_outfile:\n        hydmod_outfile = hydmod_file + '.dat'\n    hyd_df.to_csv(hydmod_outfile, columns=['obsnme','obsval'], sep=' ',index=False)\n    #hyd_df = hyd_df[['obsnme','obsval']]\n    return hyd_df[['obsnme','obsval']], hydmod_outfile", "response": "read in a modflow hydmod file and return a dataframe of the results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef setup_pilotpoints_grid(ml=None,sr=None,ibound=None,prefix_dict=None,\n                           every_n_cell=4,\n                           use_ibound_zones=False,\n                           pp_dir='.',tpl_dir='.',\n                           shapename=\"pp.shp\"):\n    \"\"\" setup regularly-spaced (gridded) pilot point parameterization\n\n    Parameters\n    ----------\n    ml : flopy.mbase\n        a flopy mbase dervied type.  If None, sr must not be None.\n    sr : flopy.utils.reference.SpatialReference\n        a spatial reference use to locate the model grid in space.  If None,\n        ml must not be None.  Default is None\n    ibound : numpy.ndarray\n        the modflow ibound integer array.  Used to set pilot points only in active areas.\n        If None and ml is None, then pilot points are set in all rows and columns according to\n        every_n_cell.  Default is None.\n    prefix_dict : dict\n        a dictionary of pilot point parameter prefix, layer pairs.  example : {\"hk\":[0,1,2,3]} would\n        setup pilot points with the prefix \"hk\" for model layers 1 - 4 (zero based). If None, a generic set\n        of pilot points with the \"pp\" prefix are setup for a generic nrowXncol grid. Default is None\n    use_ibound_zones : bool\n        a flag to use the greater-than-zero values in the ibound as pilot point zones.  If False,ibound\n        values greater than zero are treated as a single zone.  Default is False.\n    pp_dir : str\n        directory to write pilot point files to.  Default is '.'\n    tpl_dir : str\n        directory to write pilot point template file to.  Default is '.'\n    shapename : str\n        name of shapefile to write that containts pilot point information. Default is \"pp.shp\"\n\n    Returns\n    -------\n        pp_df : pandas.DataFrame\n            a dataframe summarizing pilot point information (same information\n            written to shapename\n\n    \"\"\"\n    from . import pp_utils\n    warnings.warn(\"setup_pilotpoint_grid has moved to pp_utils...\",PyemuWarning)\n    return pp_utils.setup_pilotpoints_grid(ml=ml,sr=sr,ibound=ibound,\n                                           prefix_dict=prefix_dict,\n                                           every_n_cell=every_n_cell,\n                                           use_ibound_zones=use_ibound_zones,\n                                           pp_dir=pp_dir,tpl_dir=tpl_dir,\n                                           shapename=shapename)", "response": "setup regularly - spaced pilot point parameterization"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef setup_mtlist_budget_obs(list_filename,gw_filename=\"mtlist_gw.dat\",sw_filename=\"mtlist_sw.dat\",\n                            start_datetime=\"1-1-1970\",gw_prefix='gw',sw_prefix=\"sw\",\n                            save_setup_file=False):\n    \"\"\" setup observations of gw (and optionally sw) mass budgets from mt3dusgs list file.  writes\n        an instruction file and also a _setup_.csv to use when constructing a pest\n        control file\n\n        Parameters\n        ----------\n        list_filename : str\n                modflow list file\n        gw_filename : str\n            output filename that will contain the gw budget observations. Default is\n            \"mtlist_gw.dat\"\n        sw_filename : str\n            output filename that will contain the sw budget observations. Default is\n            \"mtlist_sw.dat\"\n        start_datetime : str\n            an str that can be parsed into a pandas.TimeStamp.  used to give budget\n            observations meaningful names\n        gw_prefix : str\n            a prefix to add to the GW budget observations.  Useful if processing\n            more than one list file as part of the forward run process. Default is 'gw'.\n        sw_prefix : str\n            a prefix to add to the SW budget observations.  Useful if processing\n            more than one list file as part of the forward run process. Default is 'sw'.\n        save_setup_file : (boolean)\n            a flag to save _setup_<list_filename>.csv file that contains useful\n            control file information\n\n        Returns\n        -------\n        frun_line, ins_filenames, df :str, list(str), pandas.DataFrame\n            the command to add to the forward run script, the names of the instruction\n            files and a dataframe with information for constructing a control file.  If INSCHEK fails\n            to run, df = None\n\n        Note\n        ----\n        This function uses INSCHEK to get observation values; the observation values are\n        the values of the list file list_filename.  If INSCHEK fails to run, the obseravtion\n        values are set to 1.0E+10\n\n        the instruction files are named <out_filename>.ins\n\n        It is recommended to use the default value for gw_filename or sw_filename.\n\n        \"\"\"\n    gw,sw = apply_mtlist_budget_obs(list_filename, gw_filename, sw_filename, start_datetime)\n    gw_ins = gw_filename + \".ins\"\n    _write_mtlist_ins(gw_ins, gw, gw_prefix)\n    ins_files = [gw_ins]\n    try:\n        run(\"inschek {0}.ins {0}\".format(gw_filename))\n    except:\n        print(\"error running inschek\")\n    if sw is not None:\n        sw_ins = sw_filename + \".ins\"\n        _write_mtlist_ins(sw_ins, sw, sw_prefix)\n        ins_files.append(sw_ins)\n        try:\n            run(\"inschek {0}.ins {0}\".format(sw_filename))\n        except:\n            print(\"error running inschek\")\n    frun_line = \"pyemu.gw_utils.apply_mtlist_budget_obs('{0}')\".format(list_filename)\n    gw_obf = gw_filename + \".obf\"\n    df_gw = None\n    if os.path.exists(gw_obf):\n        df_gw = pd.read_csv(gw_obf, delim_whitespace=True, header=None, names=[\"obsnme\", \"obsval\"])\n        df_gw.loc[:, \"obgnme\"] = df_gw.obsnme.apply(lambda x: x[:-9])\n        sw_obf = sw_filename + \".obf\"\n        if os.path.exists(sw_obf):\n            df_sw = pd.read_csv(sw_obf, delim_whitespace=True, header=None, names=[\"obsnme\", \"obsval\"])\n            df_sw.loc[:, \"obgnme\"] = df_sw.obsnme.apply(lambda x: x[:-9])\n            df_gw = df_gw.append(df_sw)\n\n        if save_setup_file:\n            df_gw.to_csv(\"_setup_\" + os.path.split(list_filename)[-1] + '.csv', index=False)\n        df_gw.index = df_gw.obsnme\n    return frun_line,ins_files,df_gw", "response": "setup observations of the modflow list file and the instructions of the modflow list file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nwrite an instruction file for a MODFLOW list file", "response": "def _write_mtlist_ins(ins_filename,df,prefix):\n    \"\"\" write an instruction file for a MODFLOW list file\n\n    Parameters\n    ----------\n    ins_filename : str\n        name of the instruction file to write\n    df : pandas.DataFrame\n        the dataframe of list file entries\n    prefix : str\n        the prefix to add to the column names to form\n        obseravtions names\n\n    \"\"\"\n    try:\n        dt_str = df.index.map(lambda x: x.strftime(\"%Y%m%d\"))\n    except:\n        dt_str = df.index.map(lambda x: \"{0:08.1f}\".format(x).strip())\n    if prefix == '':\n        name_len = 11\n    else:\n        name_len = 11 - (len(prefix)+1)\n    with open(ins_filename,'w') as f:\n        f.write('pif ~\\nl1\\n')\n\n        for dt in dt_str:\n            f.write(\"l1 \")\n            for col in df.columns:\n                col = col.replace(\"(\",'').replace(\")\",'')\n                raw = col.split('_')\n                name = ''.join([r[:2] for r in raw[:-2]])[:6] + raw[-2] + raw[-1][0]\n                #raw[0] = raw[0][:6]\n                #name = ''.join(raw)\n                if prefix == '':\n                    obsnme = \"{1}_{2}\".format(prefix,name[:name_len],dt)\n                else:\n                    obsnme = \"{0}_{1}_{2}\".format(prefix, name[:name_len], dt)\n                f.write(\" w !{0}!\".format(obsnme))\n            f.write(\"\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_mtlist_budget_obs(list_filename,gw_filename=\"mtlist_gw.dat\",\n                            sw_filename=\"mtlist_sw.dat\",\n                            start_datetime=\"1-1-1970\"):\n    \"\"\" process an MT3D list file to extract mass budget entries.\n\n    Parameters\n    ----------\n    list_filename : str\n        the mt3d list file\n    gw_filename : str\n        the name of the output file with gw mass budget information.\n        Default is \"mtlist_gw.dat\"\n    sw_filename : str\n        the name of the output file with sw mass budget information.\n        Default is \"mtlist_sw.dat\"\n    start_datatime : str\n        an str that can be cast to a pandas.TimeStamp.  Used to give\n        observations a meaningful name\n\n    Returns\n    -------\n    gw : pandas.DataFrame\n        the gw mass dataframe\n    sw : pandas.DataFrame (optional)\n        the sw mass dataframe\n\n    Note\n    ----\n    requires flopy\n\n    if SFT is not active, no SW mass budget will be returned\n\n    \"\"\"\n    try:\n        import flopy\n    except Exception as e:\n        raise Exception(\"error import flopy: {0}\".format(str(e)))\n    mt = flopy.utils.MtListBudget(list_filename)\n    gw, sw = mt.parse(start_datetime=start_datetime, diff=True)\n    gw = gw.drop([col for col in gw.columns\n                  for drop_col in [\"kper\", \"kstp\", \"tkstp\"]\n                  if (col.lower().startswith(drop_col))], axis=1)\n    gw.to_csv(gw_filename, sep=' ', index_label=\"datetime\", date_format=\"%Y%m%d\")\n    if sw is not None:\n        sw = sw.drop([col for col in sw.columns\n                      for drop_col in [\"kper\", \"kstp\", \"tkstp\"]\n                      if (col.lower().startswith(drop_col))], axis=1)\n        sw.to_csv(sw_filename, sep=' ', index_label=\"datetime\", date_format=\"%Y%m%d\")\n    return gw, sw", "response": "process an MT3D list file to extract the mass budget entries and apply them to the appropriate MtListBudget object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprocess a MODFLOW list file to extract flux and volume water budget entries", "response": "def apply_mflist_budget_obs(list_filename,flx_filename=\"flux.dat\",\n                            vol_filename=\"vol.dat\",\n                            start_datetime=\"1-1-1970\"):\n    \"\"\" process a MODFLOW list file to extract flux and volume water budget entries.\n\n    Parameters\n    ----------\n    list_filename : str\n        the modflow list file\n    flx_filename : str\n        the name of the output file with water budget flux information.\n        Default is \"flux.dat\"\n    vol_filename : str\n        the name of the output file with water budget volume information.\n        Default is \"vol.dat\"\n    start_datatime : str\n        an str that can be cast to a pandas.TimeStamp.  Used to give\n        observations a meaningful name\n\n    Returns\n    -------\n    flx : pandas.DataFrame\n        the flux dataframe\n    vol : pandas.DataFrame\n        the volume dataframe\n\n    Note\n    ----\n    requires flopy\n\n    \"\"\"\n    try:\n        import flopy\n    except Exception as e:\n        raise Exception(\"error import flopy: {0}\".format(str(e)))\n    mlf = flopy.utils.MfListBudget(list_filename)\n    flx,vol = mlf.get_dataframes(start_datetime=start_datetime,diff=True)\n    flx.to_csv(flx_filename,sep=' ',index_label=\"datetime\",date_format=\"%Y%m%d\")\n    vol.to_csv(vol_filename,sep=' ',index_label=\"datetime\",date_format=\"%Y%m%d\")\n    return flx,vol"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _write_mflist_ins(ins_filename,df,prefix):\n\n    dt_str = df.index.map(lambda x: x.strftime(\"%Y%m%d\"))\n    name_len = 11 - (len(prefix)+1)\n    with open(ins_filename,'w') as f:\n        f.write('pif ~\\nl1\\n')\n\n        for dt in dt_str:\n            f.write(\"l1 \")\n            for col in df.columns:\n                obsnme = \"{0}_{1}_{2}\".format(prefix,col[:name_len],dt)\n                f.write(\" w !{0}!\".format(obsnme))\n            f.write(\"\\n\")", "response": "write an instruction file for a MODFLOW list file"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _setup_postprocess_hds_timeseries(hds_file, df, config_file, prefix=None, model=None):\n    warnings.warn(\n        \"Setting up post processing of hds or ucn timeseries obs. \"\n        \"Prepending 'pp' to obs name may cause length to exceed 20 chars\", PyemuWarning)\n    if model is not None:\n        t_str = df.index.map(lambda x: x.strftime(\"%Y%m%d\"))\n    else:\n        t_str = df.index.map(lambda x: \"{0:08.2f}\".format(x))\n    if prefix is not None:\n        prefix = \"pp{0}\".format(prefix)\n    else:\n        prefix = \"pp\"\n    ins_file = hds_file+\"_timeseries.post_processed.ins\"\n    print(\"writing instruction file to {0}\".format(ins_file))\n    with open(ins_file,'w') as f:\n        f.write('pif ~\\n')\n        f.write(\"l1 \\n\")\n        for t in t_str:\n            f.write(\"l1 w \")\n            for site in df.columns:\n                obsnme = \"{0}{1}_{2}\".format(prefix, site, t)\n                f.write(\" !{0}!\".format(obsnme))\n            f.write('\\n')\n    frun_line = \"pyemu.gw_utils._apply_postprocess_hds_timeseries('{0}')\\n\".format(config_file)\n    return frun_line", "response": "Setup post processing of hds or ucn time series."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nfunction to find the last time step in a modflow head save file that is greater than or equal to the given kper time step.", "response": "def last_kstp_from_kper(hds,kper):\n    \"\"\" function to find the last time step (kstp) for a\n    give stress period (kper) in a modflow head save file.\n\n\n    Parameters\n    ----------\n    hds : flopy.utils.HeadFile\n\n    kper : int\n        the zero-index stress period number\n\n    Returns\n    -------\n    kstp : int\n        the zero-based last time step during stress period\n        kper in the head save file\n\n\n    \"\"\"\n    #find the last kstp with this kper\n    kstp = -1\n    for kkstp,kkper in hds.kstpkper:\n        if kkper == kper+1 and kkstp > kstp:\n            kstp = kkstp\n    if kstp == -1:\n        raise Exception(\"kstp not found for kper {0}\".format(kper))\n    kstp -= 1\n    return kstp"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef setup_sft_obs(sft_file,ins_file=None,start_datetime=None,times=None,ncomp=1):\n\n    df = pd.read_csv(sft_file,skiprows=1,delim_whitespace=True)\n    df.columns = [c.lower().replace(\"-\",\"_\") for c in df.columns]\n    if times is None:\n        times = df.time.unique()\n    missing = []\n    utimes = df.time.unique()\n    for t in times:\n        if t not in utimes:\n            missing.append(str(t))\n    if len(missing) > 0:\n        print(df.time)\n        raise Exception(\"the following times are missing:{0}\".format(','.join(missing)))\n    with open(\"sft_obs.config\",'w') as f:\n        f.write(sft_file+'\\n')\n        [f.write(\"{0:15.6E}\\n\".format(t)) for t in times]\n    df = apply_sft_obs()\n    utimes = df.time.unique()\n    for t in times:\n        assert t in utimes,\"time {0} missing in processed dataframe\".format(t)\n    idx = df.time.apply(lambda x: x in times)\n    if start_datetime is not None:\n        start_datetime = pd.to_datetime(start_datetime)\n        df.loc[:,\"time_str\"] = pd.to_timedelta(df.time,unit='d') + start_datetime\n        df.loc[:,\"time_str\"] = df.time_str.apply(lambda x: datetime.strftime(x,\"%Y%m%d\"))\n    else:\n        df.loc[:,\"time_str\"] = df.time.apply(lambda x: \"{0:08.2f}\".format(x))\n    df.loc[:,\"ins_str\"] = \"l1\\n\"\n    # check for multiple components\n    df_times = df.loc[idx,:]\n    df.loc[:,\"icomp\"] = 1\n    icomp_idx = list(df.columns).index(\"icomp\")\n    for t in times:\n        df_time = df.loc[df.time==t,:]\n        vc = df_time.sfr_node.value_counts()\n        ncomp = vc.max()\n        assert np.all(vc.values==ncomp)\n        nstrm = df_time.shape[0] / ncomp\n        for icomp in range(ncomp):\n            s = int(nstrm*(icomp))\n            e = int(nstrm*(icomp+1))\n            idxs = df_time.iloc[s:e,:].index\n            #df_time.iloc[nstrm*(icomp):nstrm*(icomp+1),icomp_idx.loc[\"icomp\"] = int(icomp+1)\n            df_time.loc[idxs,\"icomp\"] = int(icomp+1)\n\n        df.loc[df_time.index,\"ins_str\"] = df_time.apply(lambda x: \"l1 w w !sfrc{0}_{1}_{2}! !swgw{0}_{1}_{2}! !gwcn{0}_{1}_{2}!\\n\".\\\n                                         format(x.sfr_node,x.icomp,x.time_str),axis=1)\n    df.index = np.arange(df.shape[0])\n    if ins_file is None:\n        ins_file = sft_file+\".processed.ins\"\n\n    with open(ins_file,'w') as f:\n        f.write(\"pif ~\\nl1\\n\")\n        [f.write(i) for i in df.ins_str]\n    #df = _try_run_inschek(ins_file,sft_file+\".processed\")\n    df = try_process_ins_file(ins_file,sft_file+\".processed\")\n    if df is not None:\n        return df\n    else:\n        return None", "response": "writes an instruction file for a mt3d - usgs sft output file and creates an observation file for each time."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\napplying the SFR segement multiplier parameters to the base modflow s fr object.", "response": "def apply_sfr_seg_parameters(seg_pars=True, reach_pars=False):\n    \"\"\"apply the SFR segement multiplier parameters.  Expected to be run in the same dir\n    as the model exists\n\n    Parameters\n    ----------\n        reach_pars : bool\n            if reach paramters need to be applied\n\n    Returns\n    -------\n        sfr : flopy.modflow.ModflowSfr instance\n\n    Note\n    ----\n        expects \"sfr_seg_pars.config\" to exist\n        expects <nam_file>+\"_backup_.sfr\" to exist\n\n\n    \"\"\"\n\n    if not seg_pars and not reach_pars:\n        raise Exception(\"gw_utils.apply_sfr_pars() error: both seg_pars and reach_pars are False\")\n    #if seg_pars and reach_pars:\n    #    raise Exception(\"gw_utils.apply_sfr_pars() error: both seg_pars and reach_pars are True\")\n\n    import flopy\n    bak_sfr_file,pars = None,None\n\n    # if seg_pars:\n    #     config_file = \"sfr_seg_pars.config\"\n    #     idx_cols = ['nseg', 'icalc', 'outseg', 'iupseg', 'iprior', 'nstrpts']\n    # else:\n    #     config_file = \"sfr_reach_pars.config\"\n    #     idx_cols = [\"node\", \"k\", \"i\", \"j\", \"iseg\", \"ireach\", \"reachID\", \"outreach\"]\n    #\n    # assert os.path.exists(config_file),\"gw_utils.apply_sfr_pars() error: config file {0} missing\".format(config_file)\n    # with open(config_file, 'r') as f:\n    #     pars = {}\n    #     for line in f:\n    #         line = line.strip().split()\n    #         pars[line[0]] = line[1]\n    #\n    # m = flopy.modflow.Modflow.load(pars[\"nam_file\"], load_only=[], check=False)\n    # bak_sfr_file = pars[\"nam_file\"] + \"_backup_.sfr\"\n    # sfr = flopy.modflow.ModflowSfr2.load(os.path.join(bak_sfr_file), m)\n    # sfrfile = pars[\"sfr_filename\"]\n    #\n    #\n    # mlt_df = pd.read_csv(pars[\"mult_file\"], delim_whitespace=False, index_col=0)\n    # present_cols = [c for c in idx_cols if c in mlt_df.columns]\n    # mlt_cols = mlt_df.columns.drop(present_cols)\n    #\n    # if seg_pars:\n    #     for key, val in m.sfr.segment_data.items():\n    #         df = pd.DataFrame.from_records(val)\n    #         df.loc[:, mlt_cols] *= mlt_df.loc[:, mlt_cols]\n    #         val = df.to_records(index=False)\n    #         sfr.segment_data[key] = val\n    # else:\n    #     df = pd.DataFrame.from_records(m.sfr.reach_data)\n    #     df.loc[:, mlt_cols] *= mlt_df.loc[:, mlt_cols]\n    #     sfr.reach_data = df.to_records(index=False)\n    #\n    #\n    # if \"time_mult_file\" in pars:\n    #     time_mult_file = pars[\"time_mult_file\"]\n    #     time_mlt_df = pd.read_csv(pars[\"time_mult_file\"], delim_whitespace=False, index_col=0)\n    #     for kper,sdata in m.sfr.segment_data.items():\n    #         assert kper in time_mlt_df.index,\"gw_utils.apply_sfr_seg_parameters() error: kper \"+\\\n    #                                          \"{0} not in time_mlt_df index\".format(kper)\n    #         for col in time_mlt_df.columns:\n    #             sdata[col] *= time_mlt_df.loc[kper,col]\n    #\n    #\n    # sfr.write_file(filename=sfrfile)\n    # return sfr\n\n    if seg_pars:\n        assert os.path.exists(\"sfr_seg_pars.config\")\n\n        with open(\"sfr_seg_pars.config\",'r') as f:\n            pars = {}\n            for line in f:\n                line = line.strip().split()\n                pars[line[0]] = line[1]\n        bak_sfr_file = pars[\"nam_file\"]+\"_backup_.sfr\"\n        #m = flopy.modflow.Modflow.load(pars[\"nam_file\"],model_ws=pars[\"model_ws\"],load_only=[\"sfr\"],check=False)\n        m = flopy.modflow.Modflow.load(pars[\"nam_file\"], load_only=[], check=False)\n        sfr = flopy.modflow.ModflowSfr2.load(os.path.join(bak_sfr_file), m)\n        sfrfile = pars[\"sfr_filename\"]\n        mlt_df = pd.read_csv(pars[\"mult_file\"], delim_whitespace=False, index_col=0)\n        time_mlt_df = None\n        if \"time_mult_file\" in pars:\n            time_mult_file = pars[\"time_mult_file\"]\n            time_mlt_df = pd.read_csv(pars[\"time_mult_file\"], delim_whitespace=False,index_col=0)\n\n        idx_cols = ['nseg', 'icalc', 'outseg', 'iupseg', 'iprior', 'nstrpts']\n        present_cols = [c for c in idx_cols if c in mlt_df.columns]\n        mlt_cols = mlt_df.columns.drop(present_cols)\n        for key, val in m.sfr.segment_data.items():\n            df = pd.DataFrame.from_records(val)\n            df.loc[:, mlt_cols] *= mlt_df.loc[:, mlt_cols]\n            val = df.to_records(index=False)\n            sfr.segment_data[key] = val\n    if reach_pars:\n        assert os.path.exists(\"sfr_reach_pars.config\")\n        with open(\"sfr_reach_pars.config\", 'r') as f:\n            r_pars = {}\n            for line in f:\n                line = line.strip().split()\n                r_pars[line[0]] = line[1]\n        if bak_sfr_file is None:  # will be the case is seg_pars is false\n            bak_sfr_file = r_pars[\"nam_file\"]+\"_backup_.sfr\"\n            #m = flopy.modflow.Modflow.load(pars[\"nam_file\"],model_ws=pars[\"model_ws\"],load_only=[\"sfr\"],check=False)\n            m = flopy.modflow.Modflow.load(r_pars[\"nam_file\"], load_only=[], check=False)\n            sfr = flopy.modflow.ModflowSfr2.load(os.path.join(bak_sfr_file), m)\n            sfrfile = r_pars[\"sfr_filename\"]\n        r_mlt_df = pd.read_csv(r_pars[\"mult_file\"],sep=',',index_col=0)\n        r_idx_cols = [\"node\", \"k\", \"i\", \"j\", \"iseg\", \"ireach\", \"reachID\", \"outreach\"]\n        r_mlt_cols = r_mlt_df.columns.drop(r_idx_cols)\n        r_df = pd.DataFrame.from_records(m.sfr.reach_data)\n        r_df.loc[:, r_mlt_cols] *= r_mlt_df.loc[:, r_mlt_cols]\n        sfr.reach_data = r_df.to_records(index=False)\n\n\n    #m.remove_package(\"sfr\")\n    if pars is not None and \"time_mult_file\" in pars:\n        time_mult_file = pars[\"time_mult_file\"]\n        time_mlt_df = pd.read_csv(time_mult_file, delim_whitespace=False, index_col=0)\n        for kper, sdata in m.sfr.segment_data.items():\n            assert kper in time_mlt_df.index, \"gw_utils.apply_sfr_seg_parameters() error: kper \" + \\\n                                              \"{0} not in time_mlt_df index\".format(kper)\n            for col in time_mlt_df.columns:\n                sdata[col] *= time_mlt_df.loc[kper, col]\n\n    sfr.write_file(filename=sfrfile)\n    return sfr"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef apply_sfr_obs():\n    assert os.path.exists(\"sfr_obs.config\")\n    df_key = pd.read_csv(\"sfr_obs.config\",index_col=0)\n\n    assert df_key.iloc[0,0] == \"sfr_out_file\",df_key.iloc[0,:]\n    sfr_out_file = df_key.iloc[0,1]\n    df_key = df_key.iloc[1:,:]\n    df_key.loc[:, \"segment\"] = df_key.segment.apply(np.int)\n    df_key.index = df_key.segment\n    seg_group_dict = df_key.groupby(df_key.obs_base).groups\n\n    sfr_kper = load_sfr_out(sfr_out_file)\n    kpers = list(sfr_kper.keys())\n    kpers.sort()\n    #results = {o:[] for o in seg_group_dict.keys()}\n    results = []\n    for kper in kpers:\n        df = sfr_kper[kper]\n        for obs_base,segs in seg_group_dict.items():\n            agg = df.loc[segs.values,:].sum()  # still agg flout where seg groups are passed!\n            #print(obs_base,agg)\n            results.append([kper,obs_base,agg[\"flaqx\"],agg[\"flout\"]])\n    df = pd.DataFrame(data=results,columns=[\"kper\",\"obs_base\",\"flaqx\",\"flout\"])\n    df.sort_values(by=[\"kper\",\"obs_base\"],inplace=True)\n    df.to_csv(sfr_out_file+\".processed\",sep=' ',index=False)\n    return df", "response": "apply the sfr observation process - pairs with setup_sfr_obs."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nload an ASCII SFR output file into a dictionary of kper and dataframe.", "response": "def load_sfr_out(sfr_out_file, selection=None):\n    \"\"\"load an ASCII SFR output file into a dictionary of kper: dataframes.  aggregates\n    flow to aquifer for segments and returns and flow out at downstream end of segment.\n\n    Parameters\n    ----------\n    sfr_out_file : str\n        SFR ASCII output file\n\n    Returns\n    -------\n        sfr_dict : dict\n            dictionary of {kper:dataframe}\n\n    \"\"\"\n    assert os.path.exists(sfr_out_file),\"couldn't find sfr out file {0}\".\\\n        format(sfr_out_file)\n    tag = \" stream listing\"\n    lcount = 0\n    sfr_dict = {}\n    if selection is None:\n        pass\n    elif isinstance(selection, str):\n        assert selection == 'all', \"If string passed as selection only 'all' allowed: {}\".format(selection)\n    else:\n        assert isinstance(\n            selection, pd.DataFrame), \"'selection needs to be pandas Dataframe. Type {} passed.\".format(type(selection))\n        assert np.all([sr in selection.columns for sr in ['segment', 'reach']]\n                      ), \"Either 'segment' or 'reach' not in selection columns\"\n    with open(sfr_out_file) as f:\n        while True:\n            line = f.readline().lower()\n            lcount += 1\n            if line == '':\n                break\n            if line.startswith(tag):\n                raw = line.strip().split()\n                kper = int(raw[3]) - 1\n                kstp = int(raw[5]) - 1\n                [f.readline() for _ in range(4)] #skip to where the data starts\n                lcount += 4\n                dlines = []\n                while True:\n                    dline = f.readline()\n                    lcount += 1\n                    if dline.strip() == '':\n                        break\n                    draw = dline.strip().split()\n                    dlines.append(draw)\n                df = pd.DataFrame(data=np.array(dlines)).iloc[:, [3, 4, 6, 7]]\n                df.columns = [\"segment\", \"reach\", \"flaqx\", \"flout\"]\n                df.loc[:, \"segment\"] = df.segment.apply(np.int)\n                df.loc[:, \"reach\"] = df.reach.apply(np.int)\n                df.loc[:, \"flaqx\"] = df.flaqx.apply(np.float)\n                df.loc[:, \"flout\"] = df.flout.apply(np.float)\n                df.index = df.apply(lambda x: \"{0:03d}_{1:03d}\".format(int(x.segment), int(x.reach)), axis=1)\n                if selection is None:  # setup for all segs, aggregate\n                    gp = df.groupby(df.segment)\n                    bot_reaches = gp[['reach']].max().apply(\n                        lambda x: \"{0:03d}_{1:03d}\".format(int(x.name), int(x.reach)), axis=1)\n                    df2 = pd.DataFrame(index=gp.groups.keys(), columns=['flaqx', 'flout'])\n                    df2['flaqx'] = gp.flaqx.sum()  # only sum distributed output\n                    df2['flout'] = df.loc[bot_reaches, 'flout'].values  # take flow out of seg\n                    # df = df.groupby(df.segment).sum()\n                    df2.loc[:,\"segment\"] = df2.index\n                elif isinstance(selection, str) and selection == 'all':\n                    df2 = df\n                else:\n                    seg_reach_id = selection.apply(lambda x: \"{0:03d}_{1:03d}\".\n                                                   format(int(x.segment), int(x.reach)), axis=1).values\n                    for sr in seg_reach_id:\n                        if sr not in df.index:\n                            s, r = [x.lstrip('0') for x in sr.split('_')]\n                            warnings.warn(\"Requested segment reach pair ({0},{1}) is not in sfr output. Dropping...\".\n                                          format(int(r), int(s)), PyemuWarning)\n                            seg_reach_id = np.delete(seg_reach_id, np.where(seg_reach_id == sr), axis=0)\n                    df2 = df.loc[seg_reach_id].copy()\n                if kper in sfr_dict.keys():\n                    print(\"multiple entries found for kper {0}, replacing...\".format(kper))\n                sfr_dict[kper] = df2\n    return sfr_dict"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_sfr_reach_obs(sfr_out_file,seg_reach=None,ins_file=None,model=None,\n                        include_path=False):\n    \"\"\"setup observations using the sfr ASCII output file.  Setups\n    sfr point observations using segment and reach numbers.\n\n    Parameters\n    ----------\n    sft_out_file : str\n        the existing SFR output file\n    seg_reach : dict, list or pandas.DataFrame\n        a dict, or list of SFR [segment,reach] pairs identifying observation locations.\n        If dict the key value in the dict is the base observation name.\n        If None, all reaches are used as individual observations. Default is None - THIS MAY SET UP A LOT OF OBS!\n    model : flopy.mbase\n        a flopy model.  If passed, the observation names will have the datetime of the\n        observation appended to them.  If None, the observation names will have the\n        stress period appended to them. Default is None.\n    include_path : bool\n        flag to prepend sfr_out_file path to sfr_obs.config.  Useful for setting up\n        process in separate directory for where python is running.\n\n\n    Returns\n    -------\n    df : pd.DataFrame\n        dataframe of obsnme, obsval and obgnme if inschek run was successful.  Else None\n\n    Note\n    ----\n    This function writes \"sfr_reach_obs.config\" which must be kept in the dir where\n    \"apply_sfr_reach_obs()\" is being called during the forward run\n\n    \"\"\"\n    if seg_reach is None:\n        warnings.warn(\"Obs will be set up for every reach\", PyemuWarning)\n        seg_reach = 'all'\n    elif isinstance(seg_reach, list) or isinstance(seg_reach, np.ndarray):\n        if np.ndim(seg_reach) == 1:\n            seg_reach = [seg_reach]\n        assert np.shape(\n            seg_reach)[1] == 2, \"varible seg_reach expected shape (n,2), received {0}\".format(np.shape(seg_reach))\n        seg_reach = pd.DataFrame(seg_reach, columns=['segment', 'reach'])\n        seg_reach.index = seg_reach.apply(lambda x: \"s{0:03d}r{1:03d}\".format(int(x.segment), int(x.reach)), axis=1)\n    elif isinstance(seg_reach, dict):\n        seg_reach = pd.DataFrame.from_dict(seg_reach, orient='index', columns=['segment', 'reach'])\n    else:\n        assert isinstance(\n            seg_reach, pd.DataFrame), \"'selection needs to be pandas Dataframe. Type {} passed.\".format(type(seg_reach))\n        assert np.all([sr in seg_reach.columns for sr in ['segment', 'reach']]\n                      ), \"Either 'segment' or 'reach' not in selection columns\"\n\n    sfr_dict = load_sfr_out(sfr_out_file, selection=seg_reach)\n    kpers = list(sfr_dict.keys())\n    kpers.sort()\n\n    if isinstance(seg_reach, str) and seg_reach == 'all':\n        seg_reach = sfr_dict[kpers[0]][['segment', 'reach']]\n        seg_reach.index = seg_reach.apply(lambda x: \"s{0:03d}r{1:03d}\".format(int(x.segment), int(x.reach)), axis=1)\n    keys = [\"sfr_out_file\"]\n    if include_path:\n        values = [os.path.split(sfr_out_file)[-1]]\n    else:\n        values = [sfr_out_file]\n    diff = seg_reach.loc[seg_reach.apply(lambda x: \"{0:03d}_{1:03d}\".format(int(x.segment), int(x.reach))\n                                         not in sfr_dict[list(sfr_dict.keys())[0]].index, axis=1)]\n\n    if len(diff) > 0:\n        for ob in diff.itertuples():\n            warnings.warn(\"segs,reach pair listed with onames {0} was not found: {1}\".\n                          format(ob.Index, \"({},{})\".format(ob.segment, ob.reach)), PyemuWarning)\n    seg_reach = seg_reach.drop(diff.index)\n    seg_reach['obs_base'] = seg_reach.index\n    df_key = pd.DataFrame({\"obs_base\": keys, \"segment\": 0, 'reach': values})\n    df_key = pd.concat([df_key, seg_reach], sort=True).reset_index(drop=True)\n    if include_path:\n        pth = os.path.join(*[p for p in os.path.split(sfr_out_file)[:-1]])\n        config_file = os.path.join(pth,\"sfr_reach_obs.config\")\n    else:\n        config_file = \"sfr_reach_obs.config\"\n    print(\"writing 'sfr_reach_obs.config' to {0}\".format(config_file))\n    df_key.to_csv(config_file)\n\n    bd = '.'\n    if include_path:\n        bd = os.getcwd()\n        os.chdir(pth)\n    try:\n        df = apply_sfr_reach_obs()\n    except Exception as e:\n        os.chdir(bd)\n        raise Exception(\"error in apply_sfr_reach_obs(): {0}\".format(str(e)))\n    os.chdir(bd)\n    if model is not None:\n        dts = (pd.to_datetime(model.start_datetime) + pd.to_timedelta(np.cumsum(model.dis.perlen.array), unit='d')).date\n        df.loc[:, \"datetime\"] = df.kper.apply(lambda x: dts[x])\n        df.loc[:, \"time_str\"] = df.datetime.apply(lambda x: x.strftime(\"%Y%m%d\"))\n    else:\n        df.loc[:, \"time_str\"] = df.kper.apply(lambda x: \"{0:04d}\".format(x))\n    df.loc[:, \"flaqx_obsnme\"] = df.apply(lambda x: \"{0}_{1}_{2}\".format(\"fa\", x.obs_base, x.time_str), axis=1)\n    df.loc[:, \"flout_obsnme\"] = df.apply(lambda x: \"{0}_{1}_{2}\".format(\"fo\", x.obs_base, x.time_str), axis=1)\n\n    if ins_file is None:\n        ins_file = sfr_out_file + \".reach_processed.ins\"\n\n    with open(ins_file, 'w') as f:\n        f.write(\"pif ~\\nl1\\n\")\n        for fla, flo in zip(df.flaqx_obsnme, df.flout_obsnme):\n            f.write(\"l1 w w !{0}! !{1}!\\n\".format(fla, flo))\n\n    df = None\n    pth = os.path.split(ins_file)[:-1]\n    pth = os.path.join(*pth)\n    if pth == '':\n        pth = '.'\n    bd = os.getcwd()\n    os.chdir(pth)\n    try:\n        #df = _try_run_inschek(os.path.split(ins_file)[-1],os.path.split(sfr_out_file+\".processed\")[-1])\n        df = try_process_ins_file(os.path.split(ins_file)[-1], os.path.split(sfr_out_file+\".reach_processed\")[-1])\n    except Exception as e:\n        pass\n    os.chdir(bd)\n    if df is not None:\n        df.loc[:, \"obsnme\"] = df.index.values\n        df.loc[:, \"obgnme\"] = df.obsnme.apply(lambda x: \"flaqx\" if x.startswith(\"fa\") else \"flout\")\n        return df", "response": "setup observations using the sfr ASCII output file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef apply_sfr_reach_obs():\n    assert os.path.exists(\"sfr_reach_obs.config\")\n    df_key = pd.read_csv(\"sfr_reach_obs.config\", index_col=0)\n\n    assert df_key.iloc[0, 0] == \"sfr_out_file\", df_key.iloc[0, :]\n    sfr_out_file = df_key.iloc[0].reach\n    df_key = df_key.iloc[1:, :].copy()\n    df_key.loc[:, \"segment\"] = df_key.segment.apply(np.int)\n    df_key.loc[:, \"reach\"] = df_key.reach.apply(np.int)\n    df_key = df_key.set_index('obs_base')\n\n    sfr_kper = load_sfr_out(sfr_out_file, df_key)\n    kpers = list(sfr_kper.keys())\n    kpers.sort()\n\n    results = []\n    for kper in kpers:\n        df = sfr_kper[kper]\n        for sr in df_key.itertuples():\n            ob = df.loc[\"{0:03d}_{1:03d}\".format(sr.segment, sr.reach), :]\n            results.append([kper, sr.Index, ob[\"flaqx\"], ob[\"flout\"]])\n    df = pd.DataFrame(data=results, columns=[\"kper\", \"obs_base\", \"flaqx\", \"flout\"])\n    df.sort_values(by=[\"kper\", \"obs_base\"], inplace=True)\n    df.to_csv(sfr_out_file+\".reach_processed\", sep=' ', index=False)\n    return df", "response": "Apply the sfr reach observation process - pairs with setup_sfr_reach_obs."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite an instruction file for an SFR gage output file to read Flow only at all times", "response": "def modflow_sfr_gag_to_instruction_file(gage_output_file, ins_file=None, parse_filename=False):\n    \"\"\"writes an instruction file for an SFR gage output file to read Flow only at all times\n\n        Parameters\n        ----------\n            gage_output_file : str\n                the gage output filename (ASCII).\n\n            ins_file : str\n                the name of the instruction file to create.  If None, the name\n                is <gage_output_file>.ins.  Default is None\n\n            parse_filename : bool\n                if True, get the gage_num parameter by parsing the gage output file filename\n                if False, get the gage number from the file itself\n\n        Returns\n        -------\n            df : pandas.DataFrame\n                a dataframe with obsnme and obsval for the sfr simulated flows.\n                If inschek was not successfully run, then returns None\n            ins_file : str\n                file name of instructions file relating to gage output.\n            obs_file : str\n                file name of processed gage output for all times\n\n\n        Note\n        ----\n            sets up observations for gage outputs only for the Flow column.\n\n            if parse_namefile is true, only text up to first '.' is used as the gage_num\n\n        TODO : allow other observation types and align explicitly with times - now returns all values\n        \"\"\"\n\n    if ins_file is None:\n        ins_file = gage_output_file + '.ins'\n\n    # navigate the file to be sure the header makes sense\n    indat = [line.strip() for line in open(gage_output_file, 'r').readlines()]\n    header = [i for i in indat if i.startswith('\"')]\n    # yank out the gage number to identify the observation names\n    if parse_filename:\n        gage_num = os.path.basename(gage_output_file).split('.')[0]\n    else:\n        gage_num = re.sub(\"[^0-9]\", \"\", indat[0].lower().split(\"gage no.\")[-1].strip().split()[0])\n\n    # get the column names\n    cols = [i.lower() for i in header if 'data' in i.lower()][0].lower().replace('\"', '').replace('data:', '').split()\n\n    # make sure \"Flow\" is included in the columns\n    if 'flow' not in cols:\n        raise Exception('Requested field \"Flow\" not in gage output columns')\n\n    # find which column is for  \"Flow\"\n    flowidx = np.where(np.array(cols) == 'flow')[0][0]\n\n    # write out the instruction file lines\n    inslines = ['l1 ' + (flowidx + 1) * 'w ' + '!g{0}_{1:d}!'.format(gage_num, j)\n                for j in range(len(indat) - len(header))]\n    inslines[0] = inslines[0].replace('l1', 'l{0:d}'.format(len(header) + 1))\n\n    # write the instruction file\n    with open(ins_file, 'w') as ofp:\n        ofp.write('pif ~\\n')\n        [ofp.write('{0}\\n'.format(line)) for line in inslines]\n\n    df = _try_run_inschek(ins_file, gage_output_file)\n    if df is not None:\n        return df, ins_file, gage_output_file\n    else:\n        print(\"Inschek didn't run so nothing returned\")\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nwrites an instruction file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output file for a mt3d - usgs sft output", "response": "def setup_gage_obs(gage_file,ins_file=None,start_datetime=None,times=None):\n    \"\"\"writes an instruction file for a mt3d-usgs sft output file\n\n    Parameters\n    ----------\n        gage_file : str\n            the gage output file (ASCII)\n        ins_file : str\n            the name of the instruction file to create.  If None, the name\n            is <gage_file>.processed.ins.  Default is None\n        start_datetime : str\n            a pandas.to_datetime() compatible str.  If not None,\n            then the resulting observation names have the datetime\n            suffix.  If None, the suffix is the output totim.  Default\n            is None\n        times : iterable\n            a container of times to make observations for.  If None, all times are used.\n            Default is None.\n\n\n    Returns\n    -------\n        df : pandas.DataFrame\n            a dataframe with obsnme and obsval for the sft simulated concentrations and flows.\n            If inschek was not successfully run, then returns None\n        ins_file : str\n            file name of instructions file relating to gage output.\n        obs_file : str\n            file name of processed gage output (processed according to times passed above.)\n\n\n    Note\n    ----\n        setups up observations for gage outputs (all columns).\n    \"\"\"\n\n    with open(gage_file, 'r') as f:\n        line1 = f.readline()\n        gage_num = int(re.sub(\"[^0-9]\", \"\", line1.split(\"GAGE No.\")[-1].strip().split()[0]))\n        gage_type = line1.split(\"GAGE No.\")[-1].strip().split()[1].lower()\n        obj_num = int(line1.replace('\"', '').strip().split()[-1])\n        line2 = f.readline()\n        df = pd.read_csv(f, delim_whitespace=True, names=line2.replace('\"', '').split()[1:])\n\n    df.columns = [c.lower().replace(\"-\", \"_\").replace('.', '_').strip('_') for c in df.columns]\n    # get unique observation ids\n    obs_ids = {col:\"\" for col in df.columns[1:]} # empty dictionary for observation ids\n    for col in df.columns[1:]: # exclude column 1 (TIME)\n        colspl = col.split('_')\n        if len(colspl) > 1:\n            # obs name built out of \"g\"(for gage) \"s\" or \"l\"(for gage type) 2 chars from column name - date added later\n            obs_ids[col] = \"g{0}{1}{2}\".format(gage_type[0], colspl[0][0],colspl[-1][0])\n        else:\n            obs_ids[col] = \"g{0}{1}\".format(gage_type[0], col[0:2])\n    with open(\"_gage_obs_ids.csv\", \"w\") as f: # write file relating obs names to meaningfull keys!\n        [f.write('{0},{1}\\n'.format(key, obs)) for key, obs in obs_ids.items()]\n    # find passed times in df\n    if times is None:\n        times = df.time.unique()\n    missing = []\n    utimes = df.time.unique()\n    for t in times:\n        if not np.isclose(t, utimes).any():\n            missing.append(str(t))\n    if len(missing) > 0:\n        print(df.time)\n        raise Exception(\"the following times are missing:{0}\".format(','.join(missing)))\n    # write output times to config file\n    with open(\"gage_obs.config\", 'w') as f:\n        f.write(gage_file+'\\n')\n        [f.write(\"{0:15.10E}\\n\".format(t)) for t in times]\n    # extract data for times: returns dataframe and saves a processed df - read by pest\n    df, obs_file = apply_gage_obs(return_obs_file=True)\n    utimes = df.time.unique()\n    for t in times:\n        assert np.isclose(t, utimes).any(), \"time {0} missing in processed dataframe\".format(t)\n    idx = df.time.apply(lambda x: np.isclose(x, times).any())  # boolean selector of desired times in df\n    if start_datetime is not None:\n        # convert times to usable observation times\n        start_datetime = pd.to_datetime(start_datetime)\n        df.loc[:, \"time_str\"] = pd.to_timedelta(df.time, unit='d') + start_datetime\n        df.loc[:, \"time_str\"] = df.time_str.apply(lambda x: datetime.strftime(x, \"%Y%m%d\"))\n    else:\n        df.loc[:, \"time_str\"] = df.time.apply(lambda x: \"{0:08.2f}\".format(x))\n    # set up instructions (line feed for lines without obs (not in time)\n    df.loc[:, \"ins_str\"] = \"l1\\n\"\n    df_times = df.loc[idx, :]  # Slice by desired times\n    # TODO include GAGE No. in obs name (if permissible)\n    df.loc[df_times.index, \"ins_str\"] = df_times.apply(lambda x: \"l1 w {}\\n\".format(\n        ' w '.join([\"!{0}{1}!\".format(obs, x.time_str) for key,obs in obs_ids.items()])), axis=1)\n    df.index = np.arange(df.shape[0])\n    if ins_file is None:\n        ins_file = gage_file+\".processed.ins\"\n\n    with open(ins_file, 'w') as f:\n        f.write(\"pif ~\\nl1\\n\")\n        [f.write(i) for i in df.ins_str]\n    df = _try_run_inschek(ins_file, gage_file+\".processed\")\n    if df is not None:\n        return df, ins_file, obs_file\n    else:\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_hfb_zone_multipliers_template(m):\n    assert m.hfb6 is not None\n    # find the model file\n    hfb_file = os.path.join(m.model_ws, m.hfb6.file_name[0])\n\n    # this will use multipliers, so need to copy down the original\n    if not os.path.exists(os.path.join(m.model_ws, 'hfb6_org')):\n        os.mkdir(os.path.join(m.model_ws, 'hfb6_org'))\n    # copy down the original file\n    shutil.copy2(os.path.join(m.model_ws, m.hfb6.file_name[0]), os.path.join(m.model_ws,'hfb6_org', m.hfb6.file_name[0]))\n\n    if not os.path.exists(os.path.join(m.model_ws, 'hfb6_mlt')):\n        os.mkdir(os.path.join(m.model_ws, 'hfb6_mlt'))\n\n    # read in the model file\n    hfb_file_contents = open(hfb_file, 'r').readlines()\n\n    # navigate the header\n    skiprows = sum([1 if i.strip().startswith('#') else 0 for i in hfb_file_contents]) + 1\n    header = hfb_file_contents[:skiprows]\n\n    # read in the data\n    names = ['lay', 'irow1','icol1','irow2','icol2', 'hydchr']\n    hfb_in = pd.read_csv(hfb_file, skiprows=skiprows, delim_whitespace=True, names=names).dropna()\n    for cn in names[:-1]:\n        hfb_in[cn] = hfb_in[cn].astype(np.int)\n\n    # set up a multiplier for each unique conductivity value\n    unique_cond = hfb_in.hydchr.unique()\n    hfb_mults = dict(zip(unique_cond, ['hbz_{0:04d}'.format(i) for i in range(len(unique_cond))]))\n    # set up the TPL line for each parameter and assign\n    hfb_in['tpl'] = 'blank'\n    for cn, cg in hfb_in.groupby('hydchr'):\n        hfb_in.loc[hfb_in.hydchr == cn, 'tpl'] = '~{0:^10s}~'.format(hfb_mults[cn])\n\n    assert 'blank' not in hfb_in.tpl\n\n    # write out the TPL file\n    tpl_file = os.path.join(m.model_ws, \"hfb6.mlt.tpl\")\n    with open(tpl_file, 'w') as ofp:\n        ofp.write('ptf ~\\n')\n        [ofp.write('{0}\\n'.format(line.strip())) for line in header]\n        ofp.flush()\n        hfb_in[['lay', 'irow1','icol1','irow2','icol2', 'tpl']].to_csv(ofp, sep=' ', quotechar=' ',\n                header=None, index=None, mode='a')\n\n    # make a lookup for lining up the necessary files to perform multiplication with the\n    # helpers.apply_hfb_pars() function which must be added to the forward run script\n    with open(os.path.join(m.model_ws, 'hfb6_pars.csv'), 'w') as ofp:\n        ofp.write('org_file,mlt_file,model_file\\n')\n        ofp.write('{0},{1},{2}\\n'.format(os.path.join(m.model_ws, 'hfb6_org', m.hfb6.file_name[0]),\n                                         os.path.join(m.model_ws, 'hfb6_mlt', os.path.basename(tpl_file).replace('.tpl','')),\n                                         hfb_file))\n\n    return hfb_mults, tpl_file", "response": "write a template file for an HFB using multipliers per zone"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef write_hfb_template(m):\n\n    assert m.hfb6 is not None\n    hfb_file = os.path.join(m.model_ws,m.hfb6.file_name[0])\n    assert os.path.exists(hfb_file),\"couldn't find hfb_file {0}\".format(hfb_file)\n    f_in = open(hfb_file,'r')\n    tpl_file = hfb_file+\".tpl\"\n    f_tpl = open(tpl_file,'w')\n    f_tpl.write(\"ptf ~\\n\")\n    parnme,parval1,xs,ys = [],[],[],[]\n    iis,jjs,kks = [],[],[]\n    xc = m.sr.xcentergrid\n    yc = m.sr.ycentergrid\n\n    while True:\n        line = f_in.readline()\n        if line == \"\":\n            break\n        f_tpl.write(line)\n        if not line.startswith(\"#\"):\n            raw = line.strip().split()\n            nphfb = int(raw[0])\n            mxfb = int(raw[1])\n            nhfbnp = int(raw[2])\n            if nphfb > 0 or mxfb > 0:\n                raise Exception(\"not supporting terrible HFB pars\")\n            for i in range(nhfbnp):\n                line = f_in.readline()\n                if line == \"\":\n                    raise Exception(\"EOF\")\n                raw = line.strip().split()\n                k = int(raw[0]) - 1\n                i = int(raw[1]) - 1\n                j = int(raw[2]) - 1\n                pn = \"hb{0:02}{1:04d}{2:04}\".format(k,i,j)\n                pv = float(raw[5])\n                raw[5] = \"~ {0}  ~\".format(pn)\n                line = ' '.join(raw)+'\\n'\n                f_tpl.write(line)\n                parnme.append(pn)\n                parval1.append(pv)\n                xs.append(xc[i,j])\n                ys.append(yc[i,j])\n                iis.append(i)\n                jjs.append(j)\n                kks.append(k)\n\n            break\n\n    f_tpl.close()\n    f_in.close()\n    df = pd.DataFrame({\"parnme\":parnme,\"parval1\":parval1,\"x\":xs,\"y\":ys,\n                       \"i\":iis,\"j\":jjs,\"k\":kks},index=parnme)\n    df.loc[:,\"pargp\"] = \"hfb_hydfac\"\n    df.loc[:,\"parubnd\"] = df.parval1.max() * 10.0\n    df.loc[:,\"parlbnd\"] = df.parval1.min() * 0.1\n    return tpl_file,df", "response": "write a template file for an HFB file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a pandas dataframe of prior and posterior uncertainty estimates for all predictions", "response": "def pandas(self):\n        \"\"\"get a pandas dataframe of prior and posterior for all predictions\n\n        Returns:\n            pandas.DataFrame : pandas.DataFrame\n                a dataframe with prior and posterior uncertainty estimates\n                for all forecasts (predictions)\n        \"\"\"\n        names,prior,posterior = [],[],[]\n        for iname,name in enumerate(self.posterior_parameter.row_names):\n            names.append(name)\n            posterior.append(np.sqrt(float(\n                self.posterior_parameter[iname, iname]. x)))\n            iprior = self.parcov.row_names.index(name)\n            prior.append(np.sqrt(float(self.parcov[iprior, iprior].x)))\n        for pred_name, pred_var in self.posterior_prediction.items():\n            names.append(pred_name)\n            posterior.append(np.sqrt(pred_var))\n            prior.append(self.prior_prediction[pred_name])\n        return pd.DataFrame({\"posterior\": posterior, \"prior\": prior},\n                                index=names)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef posterior_parameter(self):\n        if self.__posterior_parameter is not None:\n            return self.__posterior_parameter\n        else:\n            self.clean()\n            self.log(\"Schur's complement\")\n            try:\n                pinv = self.parcov.inv\n                r = self.xtqx + pinv\n                r = r.inv\n            except Exception as e:\n                self.xtqx.to_binary(\"xtqx.err.jcb\")\n                pinv.to_ascii(\"parcov_inv.err.cov\")\n                self.logger.warn(\"error forming schur's complement: {0}\".\n                                format(str(e)))\n                self.logger.warn(\"problemtic xtqx saved to xtqx.err.jcb\")\n                self.logger.warn(\"problematic inverse parcov saved to parcov_inv.err.cov\")\n                raise Exception(\"error forming schur's complement: {0}\".\n                                format(str(e)))\n            assert r.row_names == r.col_names\n            self.__posterior_parameter = Cov(r.x, row_names=r.row_names,\n                                             col_names=r.col_names)\n            self.log(\"Schur's complement\")\n            return self.__posterior_parameter", "response": "get the posterior parameter covariance matrix of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef map_parameter_estimate(self):\n        res = self.pst.res\n        assert res is not None\n        # build the prior expectation parameter vector\n        prior_expt = self.pst.parameter_data.loc[:,[\"parval1\"]].copy()\n        islog = self.pst.parameter_data.partrans == \"log\"\n        prior_expt.loc[islog] = prior_expt.loc[islog].apply(np.log10)\n        prior_expt = Matrix.from_dataframe(prior_expt)\n        prior_expt.col_names = [\"prior_expt\"]\n        # build the residual vector\n        res_vec = Matrix.from_dataframe(res.loc[:,[\"residual\"]])\n\n        # form the terms of Schur's complement\n        b = self.parcov * self.jco.T\n        c = ((self.jco * self.parcov * self.jco.T) + self.obscov).inv\n        bc = Matrix((b * c).x, row_names=b.row_names, col_names=c.col_names)\n\n        # calc posterior expectation\n        upgrade = bc * res_vec\n        upgrade.col_names = [\"prior_expt\"]\n        post_expt = prior_expt + upgrade\n\n        # post processing - back log transform\n        post_expt = pd.DataFrame(data=post_expt.x,index=post_expt.row_names,\n                                 columns=[\"post_expt\"])\n        post_expt.loc[:,\"prior_expt\"] = prior_expt.x.flatten()\n        post_expt.loc[islog,:] = 10.0**post_expt.loc[islog,:]\n        # unc_sum = self.get_parameter_summary()\n        # post_expt.loc[:,\"standard_deviation\"] = unc_sum.post_var.apply(np.sqrt)\n        post_expt.sort_index(inplace=True)\n        return post_expt", "response": "get the posterior expectation for parameters using Bayes linearization"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the prior and posterior forecast ( prediction ) expectations.", "response": "def map_forecast_estimate(self):\n        \"\"\" get the prior and posterior forecast (prediction) expectations.\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            dataframe with prior and posterior forecast expected values\n\n        \"\"\"\n        assert self.forecasts is not None\n        islog = self.pst.parameter_data.partrans == \"log\"\n        par_map = self.map_parameter_estimate\n        par_map.loc[islog,:] = np.log10(par_map.loc[islog,:])\n        par_map = Matrix.from_dataframe(par_map.loc[:,[\"post_expt\"]])\n        posts,priors = [],[]\n        post_expt = (self.predictions.T * par_map).to_dataframe()\n        for fname in self.forecast_names:\n            #fname = forecast.col_names[0]\n            pr = self.pst.res.loc[fname,\"modelled\"]\n            priors.append(pr)\n            posts.append(pr + post_expt.loc[fname,\"post_expt\"])\n        return pd.DataFrame(data=np.array([priors,posts]).transpose(),\n                            columns=[\"prior_expt\",\"post_expt\"],\n                            index=self.forecast_names)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets posterior forecast prediction", "response": "def posterior_prediction(self):\n        \"\"\"get posterior forecast (prediction) variances\n\n        Returns\n        -------\n        dict : dict\n            a dictionary of forecast names, posterior variance pairs\n\n        Note\n        ----\n        This method is not as easy to use as Schur.get_forecast_summary(), please\n        use it instead\n\n        \"\"\"\n        if self.__posterior_prediction is not None:\n            return self.__posterior_prediction\n        else:\n            if self.predictions is not None:\n                self.log(\"propagating posterior to predictions\")\n\n                post_cov = self.predictions.T *\\\n                            self.posterior_parameter * self.predictions\n                self.__posterior_prediction = {n:v for n,v in\n                                          zip(post_cov.row_names,\n                                              np.diag(post_cov.x))}\n                self.log(\"propagating posterior to predictions\")\n            else:\n                self.__posterior_prediction = {}\n            return self.__posterior_prediction"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_parameter_summary(self,include_map=False):\n        prior_mat = self.parcov.get(self.posterior_parameter.col_names)\n        if prior_mat.isdiagonal:\n            prior = prior_mat.x.flatten()\n        else:\n            prior = np.diag(prior_mat.x)\n        post = np.diag(self.posterior_parameter.x)\n        if include_map:\n            par_data = self.map_parameter_estimate\n            prior = pd.DataFrame(data=prior,index=prior_mat.col_names)\n            islog = self.pst.parameter_data.partrans == \"log\"\n            par_data.loc[islog,:] = np.log10(par_data.loc[islog,:])\n            par_data.loc[:,\"prior_stdev\"] = prior\n            post = pd.DataFrame(data=post,index=prior.index)\n            par_data.loc[:,\"post_stdev\"] = post\n            par_data.loc[:,\"is_log\"] = islog\n            return par_data\n        else:\n            ureduce = 100.0 * (1.0 - (post / prior))\n\n            return pd.DataFrame({\"prior_var\":prior,\"post_var\":post,\n                                     \"percent_reduction\":ureduce},\n                                    index=self.posterior_parameter.col_names)", "response": "get a summary of the parameter uncertainty of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_forecast_summary(self, include_map=False):\n        sum = {\"prior_var\":[], \"post_var\":[], \"percent_reduction\":[]}\n        for forecast in self.prior_forecast.keys():\n            pr = self.prior_forecast[forecast]\n            pt = self.posterior_forecast[forecast]\n            ur = 100.0 * (1.0 - (pt/pr))\n            sum[\"prior_var\"].append(pr)\n            sum[\"post_var\"].append(pt)\n            sum[\"percent_reduction\"].append(ur)\n        df = pd.DataFrame(sum,index=self.prior_forecast.keys())\n\n        if include_map:\n            df.loc[:,\"prior_stdev\"] = df.pop(\"prior_var\").apply(np.sqrt)\n            df.loc[:,\"post_stdev\"] = df.pop(\"post_var\").apply(np.sqrt)\n            df.pop(\"percent_reduction\")\n            forecast_map = self.map_forecast_estimate\n            df.loc[:,\"prior_expt\"] = forecast_map.prior_expt\n            df.loc[:,\"post_expt\"] = forecast_map.post_expt\n            return df\n        return pd.DataFrame(sum,index=self.prior_forecast.keys())", "response": "get a summary of the forecast uncertainty of the current object"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __contribution_from_parameters(self, parameter_names):\n\n\n        #get the prior and posterior for the base case\n        bprior,bpost = self.prior_prediction, self.posterior_prediction\n        #get the prior and posterior for the conditioned case\n        la_cond = self.get_conditional_instance(parameter_names)\n        cprior,cpost = la_cond.prior_prediction, la_cond.posterior_prediction\n        return cprior,cpost", "response": "private method get the prior and posterior uncertainty reduction as a result of\n        some parameter being perfectly known\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_conditional_instance(self, parameter_names):\n        if not isinstance(parameter_names, list):\n            parameter_names = [parameter_names]\n\n        for iname, name in enumerate(parameter_names):\n            name = str(name).lower()\n            parameter_names[iname] = name\n            assert name in self.jco.col_names,\\\n                \"contribution parameter \" + name + \" not found jco\"\n        keep_names = []\n        for name in self.jco.col_names:\n            if name not in parameter_names:\n                keep_names.append(name)\n        if len(keep_names) == 0:\n            raise Exception(\"Schur.contribution_from_Parameters \" +\n                            \"atleast one parameter must remain uncertain\")\n        #get the reduced predictions\n        if self.predictions is None:\n            raise Exception(\"Schur.contribution_from_Parameters \" +\n                            \"no predictions have been set\")\n        # cond_preds = []\n        # for pred in self.predictions:\n        #     cond_preds.append(pred.get(keep_names, pred.col_names))\n        cond_preds = self.predictions.get(row_names=keep_names)\n        la_cond = Schur(jco=self.jco.get(self.jco.row_names, keep_names),\n                        parcov=self.parcov.condition_on(parameter_names),\n                        obscov=self.obscov, predictions=cond_preds,verbose=False)\n        return la_cond", "response": "get a new Schur instance that includes conditional update from a set of parameters"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets a dataframe the prior and posterior uncertainty estimates for each adjustable parameter in the parameter list", "response": "def get_par_contribution(self,parlist_dict=None,include_prior_results=False):\n        \"\"\"get a dataframe the prior and posterior uncertainty\n        reduction as a result of some parameter becoming perfectly known\n\n        Parameters\n        ----------\n        parlist_dict : dict\n            a nested dictionary-list of groups of parameters\n            that are to be treated as perfectly known.  key values become\n            row labels in returned dataframe.  If None, each adjustable parameter\n            is sequentially treated as known and the returned dataframe\n            has row labels for each adjustable parameter\n        include_prior_results : bool\n            flag to return a multi-indexed dataframe with both conditional\n            prior and posterior forecast uncertainty estimates.  Default is False\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            a dataframe that summarizes the parameter contribution analysis.\n            The dataframe has index (row labels) of the keys in parlist_dict\n            and a column labels of forecast names.  The values in the dataframe\n            are the posterior variance of the forecast conditional on perfect\n            knowledge of the parameters in the values of parlist_dict.  Varies\n            depending on `include_prior_results`.\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>sc = pyemu.Schur(jco=\"pest.jcb\")``\n\n        ``>>>df = sc.get_par_contribution()``\n\n        \"\"\"\n        self.log(\"calculating contribution from parameters\")\n        if parlist_dict is None:\n            parlist_dict = {}#dict(zip(self.pst.adj_par_names,self.pst.adj_par_names))\n            # make sure all of the adjustable pars are in the jco\n            for pname in self.pst.adj_par_names:\n                if pname in self.jco.col_names:\n                    parlist_dict[pname] = pname\n        else:\n            if type(parlist_dict) == list:\n                parlist_dict = dict(zip(parlist_dict,parlist_dict))\n\n        results = {}\n        names = [\"base\"]\n        for forecast in self.prior_forecast.keys():\n            pr = self.prior_forecast[forecast]\n            pt = self.posterior_forecast[forecast]\n            #reduce = 100.0 * ((pr - pt) / pr)\n            results[(forecast,\"prior\")] = [pr]\n            results[(forecast,\"post\")] = [pt]\n            #results[(forecast,\"percent_reduce\")] = [reduce]\n        for case_name,par_list in parlist_dict.items():\n            if len(par_list) == 0:\n                continue\n            names.append(case_name)\n            self.log(\"calculating contribution from: \" + str(par_list))\n            case_prior,case_post = self.__contribution_from_parameters(par_list)\n            self.log(\"calculating contribution from: \" + str(par_list))\n            for forecast in case_prior.keys():\n                pr = case_prior[forecast]\n                pt = case_post[forecast]\n                #reduce = 100.0 * ((pr - pt) / pr)\n                results[(forecast, \"prior\")].append(pr)\n                results[(forecast, \"post\")].append(pt)\n                #results[(forecast, \"percent_reduce\")].append(reduce)\n\n        df = pd.DataFrame(results,index=names)\n        #base = df.loc[\"base\",df.columns.get_level_values(1)==\"post\"]\n        #df = 1.0 - (df.loc[:,df.columns.get_level_values(1)==\"post\"] / base)\n\n        self.log(\"calculating contribution from parameters\")\n        if include_prior_results:\n            return df\n        else:\n            df = df.xs(\"post\", level=1, drop_level=True, axis=1)\n            return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_par_group_contribution(self, include_prior_results=False):\n        pargrp_dict = {}\n        par = self.pst.parameter_data\n        groups = par.groupby(\"pargp\").groups\n        for grp,idxs in groups.items():\n            #pargrp_dict[grp] = list(par.loc[idxs,\"parnme\"])\n            pargrp_dict[grp] = [pname for pname in list(par.loc[idxs,\"parnme\"])\n                                if pname in self.jco.col_names and pname in self.parcov.row_names]\n        return self.get_par_contribution(pargrp_dict,include_prior_results=include_prior_results)", "response": "get the forecast uncertainty contribution from each parameter group"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a dataframe fo the posterior uncertainty of the added observations in the specified base_obslist", "response": "def get_added_obs_importance(self,obslist_dict=None,base_obslist=None,\n                                 reset_zero_weight=False):\n        \"\"\"get a dataframe fo the posterior uncertainty\n        as a results of added some observations\n\n        Parameters\n        ----------\n        obslist_dict : dict\n            a nested dictionary-list of groups of observations\n            that are to be treated as gained.  key values become\n            row labels in returned dataframe. If None, then every zero-weighted\n            observation is tested sequentially. Default is None\n        base_obslist : list\n            observation names to treat as the \"existing\" observations.\n            The values of obslist_dict will be added to this list during\n            each test.  If None, then the values in obslist_dict will\n            be treated as the entire calibration dataset.  That is, there\n            are no existing data. Default is None.  Standard practice would\n            be to pass this argument as Schur.pst.nnz_obs_names.\n        reset_zero_weight : (boolean or float)\n            a flag to reset observations with zero weight in either\n            obslist_dict or base_obslist. The value of reset_zero_weights\n            can be cast to a float,then that value will be assigned to\n            zero weight obs.  Otherwise, zero weight obs will be given a\n            weight of 1.0.  Default is False.\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            dataframe with row labels (index) of obslist_dict.keys() and\n            columns of forecast_name.  The values in the dataframe are the\n            posterior variance of the forecasts resulting from notional inversion\n            using the observations in obslist_dict[key value] plus the observations\n            in base_obslist (if any)\n\n        Note\n        ----\n        all observations listed in obslist_dict and base_obslist with zero\n        weights will be dropped unless reset_zero_weight is set\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>sc = pyemu.Schur(jco=\"pest.jcb\")``\n\n        ``>>>df = sc.get_added_obs_importance(base_obslist=sc.pst.nnz_obs_names,reset_zero=True)``\n\n\n        \"\"\"\n\n        if obslist_dict is not None:\n            if type(obslist_dict) == list:\n                obslist_dict = dict(zip(obslist_dict,obslist_dict))\n\n        reset = False\n        if reset_zero_weight is not False:\n            if not self.obscov.isdiagonal:\n                raise NotImplementedError(\"cannot reset weights for non-\"+\\\n                                          \"diagonal obscov\")\n            reset = True\n            try:\n                weight = float(reset_zero_weight)\n            except:\n                weight = 1.0\n            self.logger.statement(\"resetting zero weights to {0}\".format(weight))\n            # make copies of the original obscov and pst\n            #org_obscov = self.obscov.get(self.obscov.row_names)\n            org_obscov = self.obscov.copy()\n            org_pst = self.pst.get()\n\n        obs = self.pst.observation_data\n        obs.index = obs.obsnme\n\n        # if we don't care about grouping obs, then just reset all weights at once\n        if base_obslist is None and obslist_dict is None and reset:\n            onames = [name for name in self.pst.zero_weight_obs_names\n                      if name in self.jco.obs_names and name in self.obscov.row_names]\n            obs.loc[onames,\"weight\"] = weight\n\n        # if needed reset the zero-weight obs in base_obslist\n        if base_obslist is not None and reset:\n            # check for zero\n            self.log(\"resetting zero weight obs in base_obslist\")\n            self.pst._adjust_weights_by_list(base_obslist, weight)\n            self.log(\"resetting zero weight obs in base_obslist\")\n\n        if base_obslist is None:\n            base_obslist = []\n        else:\n            if type(base_obslist) != list:\n                self.logger.lraise(\"Schur.get_added_obs)_importance: base_obslist must be\" +\n                                   \" type 'list', not {0}\".format(str(type(base_obslist))))\n        # if needed reset the zero-weight obs in obslist_dict\n        if obslist_dict is not None and reset:\n            z_obs = []\n            for case,obslist in obslist_dict.items():\n                if not isinstance(obslist,list):\n                    obslist_dict[case] = [obslist]\n                    obslist = [obslist]\n                inboth = set(base_obslist).intersection(set(obslist))\n                if len(inboth) > 0:\n                    raise Exception(\"observation(s) listed in both \"+\\\n                                    \"base_obslist and obslist_dict: \"+\\\n                                    ','.join(inboth))\n                z_obs.extend(obslist)\n            self.log(\"resetting zero weight obs in obslist_dict\")\n            self.pst._adjust_weights_by_list(z_obs, weight)\n            self.log(\"resetting zero weight obs in obslist_dict\")\n\n        # for a comprehensive obslist_dict\n        if obslist_dict is None and reset:\n            obs = self.pst.observation_data\n            obs.index = obs.obsnme\n            onames = [name for name in self.pst.zero_weight_obs_names\n                      if name in self.jco.obs_names and name in self.obscov.row_names]\n            obs.loc[onames,\"weight\"] = weight\n\n        if obslist_dict is None:\n            obslist_dict = {name:name for name in self.pst.nnz_obs_names if name\\\n                            in self.jco.obs_names and name in self.obscov.row_names}\n\n        # reset the obs cov from the newly adjusted weights\n        if reset:\n            self.log(\"resetting self.obscov\")\n            self.reset_obscov(self.pst)\n            self.log(\"resetting self.obscov\")\n\n        results = {}\n        names = [\"base\"]\n\n        if base_obslist is None or len(base_obslist) == 0:\n            self.logger.statement(\"no base observation passed, 'base' case\"+\n                                  \" is just the prior of the forecasts\")\n            for forecast,pr in self.prior_forecast.items():\n                results[forecast] = [pr]\n            # reset base obslist for use later\n            base_obslist = []\n\n        else:\n            base_posterior = self.get(par_names=self.jco.par_names,\n                                      obs_names=base_obslist).posterior_forecast\n            for forecast,pt in base_posterior.items():\n                results[forecast] = [pt]\n\n        for case_name,obslist in obslist_dict.items():\n            names.append(case_name)\n            if not isinstance(obslist,list):\n                obslist = [obslist]\n            self.log(\"calculating importance of observations by adding: \" +\n                     str(obslist) + '\\n')\n            # this case is the combination of the base obs plus whatever unique\n            # obs names in obslist\n            case_obslist = list(base_obslist)\n            dedup_obslist = [oname for oname in obslist if oname not in case_obslist]\n            case_obslist.extend(dedup_obslist)\n            #print(self.pst.observation_data.loc[case_obslist,:])\n            case_post = self.get(par_names=self.jco.par_names,\n                                 obs_names=case_obslist).posterior_forecast\n            for forecast,pt in case_post.items():\n                results[forecast].append(pt)\n            self.log(\"calculating importance of observations by adding: \" +\n                     str(obslist) + '\\n')\n        df = pd.DataFrame(results,index=names)\n\n\n        if reset:\n            self.reset_obscov(org_obscov)\n            self.reset_pst(org_pst)\n\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget a dataframe containing posterior uncertainty of some observations that are to be used as lost", "response": "def get_removed_obs_importance(self,obslist_dict=None,\n                                   reset_zero_weight=False):\n        \"\"\"get a dataframe the posterior uncertainty\n        as a result of losing some observations\n\n        Parameters\n        ----------\n        obslist_dict : dict\n            dictionary of groups of observations\n            that are to be treated as lost.  key values become\n            row labels in returned dataframe. If None, then test every\n            (nonzero weight - see reset_zero_weight) observation\n        reset_zero_weight : bool or float\n            a flag to reset observations with zero weight in obslist_dict.\n            If the value of reset_zero_weights can be cast to a float,\n            then that value will be assigned to zero weight obs.  Otherwise,\n            zero weight obs will be given a weight of 1.0\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            a dataframe with index of obslist_dict.keys() and columns\n            of forecast names.  The values in the dataframe are the posterior\n            variances of the forecasts resulting from losing the information\n            contained in obslist_dict[key value]\n\n        Note\n        ----\n        all observations listed in obslist_dict with zero\n        weights will be dropped unless reset_zero_weight is set\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>sc = pyemu.Schur(jco=\"pest.jcb\")``\n\n        ``df = sc.get_removed_obs_importance()``\n\n        \"\"\"\n\n\n        if obslist_dict is not None:\n            if type(obslist_dict) == list:\n                obslist_dict = dict(zip(obslist_dict,obslist_dict))\n\n        elif reset_zero_weight is False and self.pst.nnz_obs == 0:\n            raise Exception(\"not resetting weights and there are no non-zero weight obs to remove\")\n\n        reset = False\n        if reset_zero_weight is not False:\n            if not self.obscov.isdiagonal:\n                raise NotImplementedError(\"cannot reset weights for non-\"+\\\n                                          \"diagonal obscov\")\n            reset = True\n            try:\n                weight = float(reset_zero_weight)\n            except:\n                weight = 1.0\n            self.logger.statement(\"resetting zero weights to {0}\".format(weight))\n            # make copies of the original obscov and pst\n            org_obscov = self.obscov.get(self.obscov.row_names)\n            org_pst = self.pst.get()\n\n        self.log(\"calculating importance of observations\")\n        if reset and obslist_dict is None:\n            obs = self.pst.observation_data\n            onames = [name for name in self.pst.zero_weight_obs_names\n                      if name in self.jco.obs_names and name in self.obscov.row_names]\n            obs.loc[onames,\"weight\"] = weight\n\n        if obslist_dict is None:\n            obslist_dict = dict(zip(self.pst.nnz_obs_names,\n                                        self.pst.nnz_obs_names))\n\n\n        elif reset:\n            self.pst.observation_data.index = self.pst.observation_data.obsnme\n            for name,obslist in obslist_dict.items():\n                self.log(\"resetting weights in obs in group {0}\".format(name))\n                self.pst._adjust_weights_by_list(obslist,weight)\n                self.log(\"resetting weights in obs in group {0}\".format(name))\n\n        for case,obslist in obslist_dict.items():\n            if not isinstance(obslist,list):\n                obslist = [obslist]\n            obslist_dict[case] = obslist\n\n\n        if reset:\n            self.log(\"resetting self.obscov\")\n            self.reset_obscov(self.pst)\n            self.log(\"resetting self.obscov\")\n\n        results = {}\n        names = [\"base\"]\n        for forecast,pt in self.posterior_forecast.items():\n            results[forecast] = [pt]\n        for case_name,obslist in obslist_dict.items():\n            if not isinstance(obslist,list):\n                obslist = [obslist]\n            names.append(case_name)\n            self.log(\"calculating importance of observations by removing: \" +\n                     str(obslist) + '\\n')\n            # check for missing names\n            missing_onames = [oname for oname in obslist if oname not in self.jco.obs_names]\n            if len(missing_onames) > 0:\n                raise Exception(\"case {0} has observation names \".format(case_name) + \\\n                                \"not found: \" + ','.join(missing_onames))\n            # find the set difference between obslist and jco obs names\n            #diff_onames = [oname for oname in self.jco.obs_names if oname not in obslist]\n            diff_onames = [oname for oname in self.nnz_obs_names if oname not in obslist and oname not in self.forecast_names]\n\n\n            # calculate the increase in forecast variance by not using the obs\n            # in obslist\n            case_post = self.get(par_names=self.jco.par_names,\n                                 obs_names=diff_onames).posterior_forecast\n\n            for forecast,pt in case_post.items():\n                results[forecast].append(pt)\n        df = pd.DataFrame(results,index=names)\n        self.log(\"calculating importance of observations by removing: \" +\n                     str(obslist) + '\\n')\n\n        if reset:\n            self.reset_obscov(org_obscov)\n            self.reset_pst(org_pst)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nfind the most important observations from each iteration in the base case and add them to the base case.", "response": "def next_most_important_added_obs(self,forecast=None,niter=3, obslist_dict=None,\n                                      base_obslist=None,\n                                      reset_zero_weight=False):\n        \"\"\"find the most important observation(s) by sequentially evaluating\n        the importance of the observations in obslist_dict. The most important observations\n        from each iteration is added to base_obslist and removed obslist_dict for the\n        next iteration.  In this way, the added observation importance values include\n        the conditional information from the last iteration.\n\n        Parameters\n        ----------\n        forecast : str\n            name of the forecast to use in the ranking process.  If\n            more than one forecast has been listed, this argument is required\n        niter : int\n            number of sequential iterations\n        obslist_dict dict:\n            nested dictionary-list of  groups of observations\n            that are to be treated as gained.  key values become\n            row labels in result dataframe. If None, then test every observation\n            individually\n        base_obslist : list\n            observation names to treat as the \"existing\" observations.\n            The values of obslist_dict will be added to this list during testing.\n            If None, then each list in the values of obslist_dict will be\n            treated as an individual calibration dataset.\n        reset_zero_weight : (boolean or float)\n            a flag to reset observations with zero weight in either\n            obslist_dict or base_obslist. If the value of reset_zero_weights\n            can be cast to a float,then that value will be assigned to\n            zero weight obs.  Otherwise, zero weight obs will be given a weight of 1.0\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            DataFrame with columns of best obslist_dict key for each iteration.\n            Columns of forecast variance percent reduction for this iteration,\n            (percent reduction compared to initial base case)\n\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>sc = pyemu.Schur(jco=\"pest.jcb\")``\n\n        ``>>>df = sc.next_most_added_importance_obs(forecast=\"fore1\",``\n\n        ``>>>      base_obslist=sc.pst.nnz_obs_names,reset_zero=True``\n        \"\"\"\n\n\n        if forecast is None:\n            assert self.forecasts.shape[1] == 1,\"forecast arg list one and only one\" +\\\n                                            \" forecast\"\n            forecast = self.forecasts[0].col_names[0]\n        #elif forecast not in self.prediction_arg:\n        #    raise Exception(\"forecast {0} not found\".format(forecast))\n\n        else:\n            forecast = forecast.lower()\n            found = False\n            for fore in self.forecasts.col_names:\n                if fore == forecast:\n                    found = True\n                    break\n            if not found:\n                raise Exception(\"forecast {0} not found\".format(forecast))\n\n\n\n\n        if base_obslist:\n            obs_being_used = list(base_obslist)\n        else:\n            obs_being_used = []\n\n        best_case, best_results = [],[]\n        for iiter in range(niter):\n            self.log(\"next most important added obs iteration {0}\".format(iiter+1))\n            df = self.get_added_obs_importance(obslist_dict=obslist_dict,\n                                                   base_obslist=obs_being_used,\n                                                   reset_zero_weight=reset_zero_weight)\n\n            if iiter == 0:\n                init_base = df.loc[\"base\",forecast].copy()\n            fore_df = df.loc[:,forecast]\n            fore_diff_df = fore_df - fore_df.loc[\"base\"]\n            fore_diff_df.sort_values(inplace=True)\n            iter_best_name = fore_diff_df.index[0]\n            iter_best_result = df.loc[iter_best_name,forecast]\n            iter_base_result = df.loc[\"base\",forecast]\n            diff_percent_init = 100.0 * (init_base -\n                                              iter_best_result) / init_base\n            diff_percent_iter = 100.0 * (iter_base_result -\n                                              iter_best_result) / iter_base_result\n            self.log(\"next most important added obs iteration {0}\".format(iiter+1))\n\n\n            best_results.append([iter_best_name,iter_best_result,\n                                 diff_percent_iter,diff_percent_init])\n            best_case.append(iter_best_name)\n\n            if iter_best_name.lower() == \"base\":\n                break\n\n            if obslist_dict is None:\n                onames = [iter_best_name]\n            else:\n                onames = obslist_dict.pop(iter_best_name)\n            if not isinstance(onames,list):\n                onames = [onames]\n            obs_being_used.extend(onames)\n        columns = [\"best_obs\",forecast+\"_variance\",\n                   \"unc_reduce_iter_base\",\"unc_reduce_initial_base\"]\n        return pd.DataFrame(best_results,index=best_case,columns=columns)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef next_most_par_contribution(self,niter=3,forecast=None,parlist_dict=None):\n        if forecast is None:\n            assert len(self.forecasts) == 1,\"forecast arg list one and only one\" +\\\n                                            \" forecast\"\n        elif forecast not in self.prediction_arg:\n            raise Exception(\"forecast {0} not found\".format(forecast))\n        org_parcov = self.parcov.get(row_names=self.parcov.row_names)\n        if parlist_dict is None:\n            parlist_dict = dict(zip(self.pst.adj_par_names,self.pst.adj_par_names))\n\n        base_prior,base_post = self.prior_forecast,self.posterior_forecast\n        iter_results = [base_post[forecast].copy()]\n        iter_names = [\"base\"]\n        for iiter in range(niter):\n            iter_contrib = {forecast:[base_post[forecast]]}\n            iter_case_names = [\"base\"]\n            self.log(\"next most par iteration {0}\".format(iiter+1))\n\n            for case,parlist in parlist_dict.items():\n                iter_case_names.append(case)\n                la_cond = self.get_conditional_instance(parlist)\n                iter_contrib[forecast].append(la_cond.posterior_forecast[forecast])\n            df = pd.DataFrame(iter_contrib,index=iter_case_names)\n            df.sort_values(by=forecast,inplace=True)\n            iter_best = df.index[0]\n            self.logger.statement(\"next best iter {0}: {1}\".format(iiter+1,iter_best))\n            self.log(\"next most par iteration {0}\".format(iiter+1))\n            if iter_best.lower() == \"base\":\n                break\n            iter_results.append(df.loc[iter_best,forecast])\n            iter_names.append(iter_best)\n            self.reset_parcov(self.parcov.condition_on(parlist_dict.pop(iter_best)))\n\n        self.reset_parcov(org_parcov)\n        return pd.DataFrame(iter_results,index=iter_names)", "response": "find the largest parameter contribution for prior and posterior"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __load_omitted_parcov(self):\n        if self.omitted_parcov_arg is None and self.omitted_par_arg is None:\n            raise Exception(\"ErrVar.__load_omitted_parcov: \" +\n                            \"both omitted args are None\")\n        # try to set omitted_parcov by extracting from base parcov\n        if self.omitted_parcov_arg is None and self.omitted_par_arg is not None:\n            # check to see if omitted par names are in parcov\n            found = True\n            for par_name in self.omitted_jco.col_names:\n                if par_name not in self.parcov.col_names:\n                    found = False\n                    break\n            if found:\n                # need to access attribute directly, not view of attribute\n                self.__omitted_parcov = \\\n                    self._LinearAnalysis__parcov.extract(\n                        row_names=self.omitted_jco.col_names)\n            else:\n                self.logger.warn(\"ErrVar.__load_omitted_parun: \" +\n                                 \"no omitted parcov arg passed: \" +\n                        \"setting omitted parcov as identity Matrix\")\n                self.__omitted_parcov = Cov(\n                    x=np.ones(self.omitted_jco.shape[1]),\n                    names=self.omitted_jco.col_names, isdiagonal=True)\n        elif self.omitted_parcov_arg is not None:\n            raise NotImplementedError()", "response": "private method to set the omitted_parcov attribute of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the omitted jco", "response": "def omitted_jco(self):\n        \"\"\"get the omitted jco\n\n        Returns\n        -------\n        omitted_jco : pyemu.Jco\n\n        Note\n        ----\n        returns a reference\n        \n        if ErrorVariance.__omitted_jco is None,\n        then dynamically load the attribute before returning\n        \n        \"\"\"\n        if self.__omitted_jco is None:\n            self.log(\"loading omitted_jco\")\n            self.__load_omitted_jco()\n            self.log(\"loading omitted_jco\")\n        return self.__omitted_jco"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef omitted_parcov(self):\n        if self.__omitted_parcov is None:\n            self.log(\"loading omitted_parcov\")\n            self.__load_omitted_parcov()\n            self.log(\"loading omitted_parcov\")\n        return self.__omitted_parcov", "response": "get the omitted prior parameter covariance matrix Returns a reference to the omitted prior parameter covariance matrix"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget a pandas dataframe of error variance results indexed on singular value and ( prediction name errvar term )", "response": "def get_errvar_dataframe(self, singular_values=None):\n        \"\"\"get a pandas dataframe of error variance results indexed\n            on singular value and (prediction name,<errvar term>)\n\n        Parameters\n        ----------\n        singular_values : list\n            singular values to test.  defaults to\n            range(0,min(nnz_obs,nadj_par) + 1)\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n            multi-indexed pandas dataframe\n        \n        \"\"\"\n        if singular_values is None:\n            singular_values = \\\n                np.arange(0, min(self.pst.nnz_obs, self.pst.npar_adj) + 1)\n        if not isinstance(singular_values, list) and \\\n                not isinstance(singular_values, np.ndarray):\n            singular_values = [singular_values]\n        results = {}\n        for singular_value in singular_values:\n            sv_results = self.variance_at(singular_value)\n            for key, val in sv_results.items():\n                if key not in results.keys():\n                    results[key] = []\n                results[key].append(val)\n        return pd.DataFrame(results, index=singular_values)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_identifiability_dataframe(self,singular_value=None,precondition=False):\n        if singular_value is None:\n            singular_value = int(min(self.pst.nnz_obs, self.pst.npar_adj))\n        #v1_df = self.qhalfx.v[:, :singular_value].to_dataframe() ** 2\n        xtqx = self.xtqx\n        if precondition:\n            xtqx = xtqx + self.parcov.inv\n        #v1_df = self.xtqx.v[:, :singular_value].to_dataframe() ** 2\n        v1_df = xtqx.v[:, :singular_value].to_dataframe() ** 2\n        v1_df[\"ident\"] = v1_df.sum(axis=1)\n        return v1_df", "response": "get the parameter identifiability as a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the error variance of all three terms at a singluar value", "response": "def variance_at(self, singular_value):\n        \"\"\"get the error variance of all three terms at a singluar value\n\n        Parameters\n        ----------\n        singular_value : int\n            singular value to test\n\n        Returns\n        -------\n        dict : dict\n            dictionary of (err var term,prediction_name), standard_deviation pairs\n\n        \"\"\"\n        results = {}\n        results.update(self.first_prediction(singular_value))\n        results.update(self.second_prediction(singular_value))\n        results.update(self.third_prediction(singular_value))\n        return results"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef R(self, singular_value):\n        if self.__R is not None and singular_value == self.__R_sv:\n            return self.__R\n\n        elif singular_value > self.jco.ncol:\n            self.__R_sv = self.jco.ncol\n            return self.parcov.identity\n        else:\n            self.log(\"calc R @\" + str(singular_value))\n            #v1 = self.qhalfx.v[:, :singular_value]\n            v1 = self.xtqx.v[:, :singular_value]\n            self.__R = v1 * v1.T\n            self.__R_sv = singular_value\n            self.log(\"calc R @\" + str(singular_value))\n            return self.__R", "response": "get resolution matrix at a singular value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef I_minus_R(self,singular_value):\n        if self.__I_R is not None and singular_value == self.__I_R_sv:\n            return self.__I_R\n        else:\n            if singular_value > self.jco.ncol:\n                return self.parcov.zero\n            else:\n                #v2 = self.qhalfx.v[:, singular_value:]\n                v2 = self.xtqx.v[:, singular_value:]\n                self.__I_R = v2 * v2.T\n                self.__I_R_sv = singular_value\n                return self.__I_R", "response": "get I - R at singular value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef G(self, singular_value):\n        if self.__G is not None and singular_value == self.__G_sv:\n            return self.__G\n\n        if singular_value == 0:\n            self.__G_sv = 0\n            self.__G = Matrix(\n                x=np.zeros((self.jco.ncol,self.jco.nrow)),\n                row_names=self.jco.col_names, col_names=self.jco.row_names)\n            return self.__G\n        mn = min(self.jco.shape)\n        try:\n            mn = min(self.pst.npar_adj, self.pst.nnz_obs)\n        except:\n            pass\n        if singular_value > mn:\n            self.logger.warn(\n                \"ErrVar.G(): singular_value > min(npar,nobs):\" +\n                \"resetting to min(npar,nobs): \" +\n                str(min(self.pst.npar_adj, self.pst.nnz_obs)))\n            singular_value = min(self.pst.npar_adj, self.pst.nnz_obs)\n        self.log(\"calc G @\" + str(singular_value))\n        #v1 = self.qhalfx.v[:, :singular_value]\n        v1 = self.xtqx.v[:, :singular_value]\n        #s1 = ((self.qhalfx.s[:singular_value]) ** 2).inv\n        s1 = (self.xtqx.s[:singular_value]).inv\n        self.__G = v1 * s1 * v1.T * self.jco.T * self.obscov.inv\n        self.__G_sv = singular_value\n        self.__G.row_names = self.jco.col_names\n        self.__G.col_names = self.jco.row_names\n        self.__G.autoalign = True\n        self.log(\"calc G @\" + str(singular_value))\n        return self.__G", "response": "get the parameter solution matrix at a singular value"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef first_prediction(self, singular_value):\n        if not self.predictions:\n            raise Exception(\"ErrVar.first(): no predictions are set\")\n        if singular_value > self.jco.ncol:\n            zero_preds = {}\n            for pred in self.predictions_iter:\n                zero_preds[(\"first\", pred.col_names[0])] = 0.0\n            return zero_preds\n        self.log(\"calc first term parameter @\" + str(singular_value))\n        first_term = self.I_minus_R(singular_value).T * self.parcov *\\\n                     self.I_minus_R(singular_value)\n        if self.predictions:\n            results = {}\n            for prediction in self.predictions_iter:\n                results[(\"first\",prediction.col_names[0])] = \\\n                    float((prediction.T * first_term * prediction).x)\n            self.log(\"calc first term parameter @\" + str(singular_value))\n            return results", "response": "get the null space term contribution to prediction error variance at a singular value"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the null space term at a singular value", "response": "def first_parameter(self, singular_value):\n        \"\"\"get the null space term (first term) contribution to parameter error variance\n            at a singular value\n\n        Parameters\n        ----------\n        singular_value : int\n            singular value to calc first term at\n\n        Returns\n        -------\n        first_term : pyemu.Cov\n            first term contribution to parameter error variance\n\n        \"\"\"\n        self.log(\"calc first term parameter @\" + str(singular_value))\n        first_term = self.I_minus_R(singular_value) * self.parcov * \\\n                     self.I_minus_R(singular_value)\n        self.log(\"calc first term parameter @\" + str(singular_value))\n        return first_term"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the solution space contribution to predictive error variance at a singular value", "response": "def second_prediction(self, singular_value):\n        \"\"\"get the solution space contribution to predictive error variance\n            at a singular value (y^t * G * obscov * G^T * y).  Used to construct\n            error variance dataframe\n\n        Parameters\n        ----------\n        singular_value : int\n            singular value to calc second term at\n\n        Returns\n        -------\n        dict : dict\n            dictionary of (\"second\",prediction_names), error variance\n\n        \"\"\"\n\n        if not self.predictions:\n            raise Exception(\"ErrVar.second(): not predictions are set\")\n        self.log(\"calc second term prediction @\" + str(singular_value))\n\n        mn = min(self.jco.shape)\n        try:\n            mn = min(self.pst.npar_adj, self.pst.nnz_obs)\n        except:\n            pass\n        if singular_value > mn:\n            inf_pred = {}\n            for pred in self.predictions_iter:\n                inf_pred[(\"second\",pred.col_names[0])] = 1.0E+35\n            return inf_pred\n        else:\n            second_term = self.G(singular_value) * self.obscov * \\\n                          self.G(singular_value).T\n            results = {}\n            for prediction in self.predictions_iter:\n                results[(\"second\",prediction.col_names[0])] = \\\n                    float((prediction.T * second_term * prediction).x)\n            self.log(\"calc second term prediction @\" + str(singular_value))\n            return results"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef second_parameter(self, singular_value):\n        self.log(\"calc second term parameter @\" + str(singular_value))\n        result = self.G(singular_value) * self.obscov * self.G(singular_value).T\n        self.log(\"calc second term parameter @\" + str(singular_value))\n        return result", "response": "get the solution space contribution to parameter error variance\n            at a singular value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef third_prediction(self,singular_value):\n        if not self.predictions:\n            raise Exception(\"ErrVar.third(): not predictions are set\")\n        if self.__need_omitted is False:\n            zero_preds = {}\n            for pred in self.predictions_iter:\n                zero_preds[(\"third\", pred.col_names[0])] = 0.0\n            return zero_preds\n        self.log(\"calc third term prediction @\" + str(singular_value))\n        mn = min(self.jco.shape)\n        try:\n            mn = min(self.pst.npar_adj, self.pst.nnz_obs)\n        except:\n            pass\n        if singular_value > mn:\n            inf_pred = {}\n            for pred in self.predictions_iter:\n                inf_pred[(\"third\",pred.col_names[0])] = 1.0E+35\n            return inf_pred\n        else:\n            results = {}\n            for prediction,omitted_prediction in \\\n                    zip(self.predictions_iter, self.omitted_predictions):\n                # comes out as row vector, but needs to be a column vector\n                p = ((prediction.T * self.G(singular_value) * self.omitted_jco)\n                     - omitted_prediction.T).T\n                result = float((p.T * self.omitted_parcov * p).x)\n                results[(\"third\", prediction.col_names[0])] = result\n            self.log(\"calc third term prediction @\" + str(singular_value))\n            return results", "response": "get the omitted parameter contribution to prediction error variance at a singular value. used to construct error variance dataframe at a singular value. used to construct error variance dataframe at a singular value."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef third_parameter(self, singular_value):\n        if self.__need_omitted is False:\n            return 0.0\n        self.log(\"calc third term parameter @\" + str(singular_value))\n        GZo = self.G(singular_value) * self.omitted_jco\n        result = GZo * self.omitted_parcov * GZo.T\n        self.log(\"calc third term parameter @\" + str(singular_value))\n        return result", "response": "get the omitted parameter contribution to parameter error variance\n             at a singular value"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef initialize(self,num_reals=1,init_lambda=None,enforce_bounds=\"reset\",\n                   parensemble=None,obsensemble=None,restart_obsensemble=None,\n                   regul_factor=0.0,use_approx_prior=True,build_empirical_prior=False):\n        \"\"\"Initialize the iES process.  Depending on arguments, draws or loads\n        initial parameter observations ensembles and runs the initial parameter\n        ensemble\n\n        Parameters\n        ----------\n            num_reals : int\n                the number of realizations to draw.  Ignored if parensemble/obsensemble\n                are not None\n            init_lambda : float\n                the initial lambda to use.  During subsequent updates, the lambda is\n                updated according to upgrade success\n            enforce_bounds : str\n                how to enfore parameter bound transgression.  options are\n                reset, drop, or None\n            parensemble : pyemu.ParameterEnsemble or str\n                a parameter ensemble or filename to use as the initial\n                parameter ensemble.  If not None, then obsenemble must not be\n                None\n            obsensemble : pyemu.ObservationEnsemble or str\n                an observation ensemble or filename to use as the initial\n                observation ensemble.  If not None, then parensemble must\n                not be None\n            restart_obsensemble : pyemu.ObservationEnsemble or str\n                an observation ensemble or filename to use as an\n                evaluated observation ensemble.  If not None, this will skip the initial\n                parameter ensemble evaluation - user beware!\n            regul_factor : float\n                the regularization penalty fraction of the composite objective.  The\n                Prurist, MAP solution would be regul_factor = 1.0, yielding equal\n                parts measurement and regularization to the composite objective function.\n                Default is 0.0, which means only seek to minimize the measurement objective\n                function\n            use_approx_prior : bool\n                a flag to use the inverse, square root of the prior ccovariance matrix\n                for scaling the upgrade calculation.  If True, this matrix is not used.\n                Default is True\n            build_empirical_prior : bool\n                flag to build the prior parameter covariance matrix from an existing parensemble.\n                If True and parensemble is None, an exception is raised\n\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>es = pyemu.EnsembleSmoother(pst=\"pest.pst\")``\n\n        ``>>>es.initialize(num_reals=100)``\n\n        \"\"\"\n        '''\n        (re)initialize the process\n        '''\n        # initialize the phi report csv\n        self.enforce_bounds = enforce_bounds\n\n        self.regul_factor = float(regul_factor)\n\n        self.total_runs = 0\n        # this matrix gets used a lot, so only calc once and store\n        self.obscov_inv_sqrt = self.obscov.get(self.pst.nnz_obs_names).inv.sqrt\n\n        if use_approx_prior:\n            self.logger.statement(\"using approximate parcov in solution\")\n            self.parcov_inv_sqrt = 1.0\n        else:\n            self.logger.statement(\"using full parcov in solution\")\n            # Chen and Oliver use a low rank approx here, but so far,\n            # I haven't needed it - not using enough parameters yet\n            self.logger.log(\"forming inverse sqrt parcov matrix\")\n            self.parcov_inv_sqrt = self.parcov.inv.sqrt\n            self.logger.log(\"forming inverse sqrt parcov matrix\")\n\n        if parensemble is not None and obsensemble is not None:\n            self.logger.log(\"initializing with existing ensembles\")\n            if isinstance(parensemble,str):\n                self.logger.log(\"loading parensemble from file\")\n                if not os.path.exists(obsensemble):\n                    self.logger.lraise(\"can not find parensemble file: {0}\".\\\n                                       format(parensemble))\n                df = pd.read_csv(parensemble,index_col=0)\n                #df.index = [str(i) for i in df.index]\n                self.parensemble_0 = ParameterEnsemble.from_dataframe(df=df,pst=self.pst)\n                self.logger.log(\"loading parensemble from file\")\n\n            elif isinstance(parensemble,ParameterEnsemble):\n                self.parensemble_0 = parensemble.copy()\n            else:\n                raise Exception(\"unrecognized arg type for parensemble, \" +\\\n                                \"should be filename or ParameterEnsemble\" +\\\n                                \", not {0}\".format(type(parensemble)))\n            self.parensemble = self.parensemble_0.copy()\n            if isinstance(obsensemble,str):\n                self.logger.log(\"loading obsensemble from file\")\n                if not os.path.exists(obsensemble):\n                    self.logger.lraise(\"can not find obsensemble file: {0}\".\\\n                                       format(obsensemble))\n                df = pd.read_csv(obsensemble,index_col=0).loc[:,self.pst.nnz_obs_names]\n                #df.index = [str(i) for i in df.index]\n                self.obsensemble_0 = ObservationEnsemble.from_dataframe(df=df,pst=self.pst)\n                self.logger.log(\"loading obsensemble from file\")\n\n            elif isinstance(obsensemble,ObservationEnsemble):\n                self.obsensemble_0 = obsensemble.copy()\n            else:\n                raise Exception(\"unrecognized arg type for obsensemble, \" +\\\n                                \"should be filename or ObservationEnsemble\" +\\\n                                \", not {0}\".format(type(obsensemble)))\n\n            assert self.parensemble_0.shape[0] == self.obsensemble_0.shape[0]\n            #self.num_reals = self.parensemble_0.shape[0]\n            num_reals = self.parensemble.shape[0]\n            self.logger.log(\"initializing with existing ensembles\")\n\n            if build_empirical_prior:\n\n                self.reset_parcov(self.parensemble.covariance_matrix())\n                if self.save_mats:\n                    self.parcov.to_binary(self.pst.filename+\".empcov.jcb\")\n\n        else:\n            if build_empirical_prior:\n                self.logger.lraise(\"can't use build_emprirical_prior without parensemble...\")\n            self.logger.log(\"initializing smoother with {0} realizations\".format(num_reals))\n            self.logger.log(\"initializing parensemble\")\n            self.parensemble_0 = pyemu.ParameterEnsemble.from_gaussian_draw(self.pst,\n                                                                            self.parcov,num_reals=num_reals)\n            self.parensemble_0.enforce(enforce_bounds=enforce_bounds)\n            self.logger.log(\"initializing parensemble\")\n            self.parensemble = self.parensemble_0.copy()\n            self.parensemble_0.to_csv(self.pst.filename +\\\n                                      self.paren_prefix.format(0))\n            self.logger.log(\"initializing parensemble\")\n            self.logger.log(\"initializing obsensemble\")\n            self.obsensemble_0 = pyemu.ObservationEnsemble.from_id_gaussian_draw(self.pst,\n                                                                                 num_reals=num_reals)\n            #self.obsensemble = self.obsensemble_0.copy()\n\n            # save the base obsensemble\n            self.obsensemble_0.to_csv(self.pst.filename +\\\n                                      self.obsen_prefix.format(-1))\n            self.logger.log(\"initializing obsensemble\")\n            self.logger.log(\"initializing smoother with {0} realizations\".format(num_reals))\n\n\n        if use_approx_prior:\n            self.logger.statement(\"using approximate parcov in solution\")\n            self.parcov_inv_sqrt = 1.0\n        else:\n            self.logger.statement(\"using full parcov in solution\")\n            # Chen and Oliver use a low rank approx here, but so far,\n            # I haven't needed it - not using enough parameters yet\n            self.logger.log(\"forming inverse sqrt parcov matrix\")\n            self.parcov_inv_sqrt = self.parcov.inv.sqrt\n            self.logger.log(\"forming inverse sqrt parcov matrix\")\n\n        # self.obs0_matrix = self.obsensemble_0.nonzero.as_pyemu_matrix()\n        # self.par0_matrix = self.parensemble_0.as_pyemu_matrix()\n        self.enforce_bounds = enforce_bounds\n\n        if restart_obsensemble is not None:\n            self.logger.log(\"loading restart_obsensemble {0}\".format(restart_obsensemble))\n            failed_runs,self.obsensemble = self._load_obs_ensemble(restart_obsensemble)\n            assert self.obsensemble.shape[0] == self.obsensemble_0.shape[0]\n            assert list(self.obsensemble.columns) == list(self.obsensemble_0.columns)\n            self.logger.log(\"loading restart_obsensemble {0}\".format(restart_obsensemble))\n\n        else:\n            # run the initial parameter ensemble\n            self.logger.log(\"evaluating initial ensembles\")\n            failed_runs, self.obsensemble = self._calc_obs(self.parensemble)\n            self.obsensemble.to_csv(self.pst.filename +\\\n                                      self.obsen_prefix.format(0))\n            if self.raw_sweep_out is not None:\n                self.raw_sweep_out.to_csv(self.pst.filename + \"_sweepraw0.csv\")\n            self.logger.log(\"evaluating initial ensembles\")\n\n        if failed_runs is not None:\n            self.logger.warn(\"dropping failed realizations\")\n            #failed_runs_str = [str(f) for f in failed_runs]\n            #self.parensemble = self.parensemble.drop(failed_runs)\n            #self.obsensemble = self.obsensemble.drop(failed_runs)\n            self.parensemble.loc[failed_runs,:] = np.NaN\n            self.parensemble = self.parensemble.dropna()\n            self.obsensemble.loc[failed_runs,:] = np.NaN\n            self.obsensemble = self.obsensemble.dropna()\n\n        if not self.parensemble.istransformed:\n            self.parensemble._transform(inplace=True)\n        if not self.parensemble_0.istransformed:\n            self.parensemble_0._transform(inplace=True)\n\n        self.phi = Phi(self)\n\n        if self.drop_bad_reals is not None:\n            #drop_idx = np.argwhere(self.current_phi_vec > self.drop_bad_reals).flatten()\n            #comp_phi = self.phi.comp_phi\n            #drop_idx = np.argwhere(self.phi.comp_phi > self.drop_bad_reals).flatten()\n            #meas_phi = self.phi.meas_phi\n            drop_idx = np.argwhere(self.phi.meas_phi > self.drop_bad_reals).flatten()\n            run_ids = self.obsensemble.index.values\n            drop_idx = run_ids[drop_idx]\n            if len(drop_idx) == self.obsensemble.shape[0]:\n                raise Exception(\"dropped all realizations as 'bad'\")\n            if len(drop_idx) > 0:\n                self.logger.warn(\"{0} realizations dropped as 'bad' (indices :{1})\".\\\n                                 format(len(drop_idx),','.join([str(d) for d in drop_idx])))\n                self.parensemble.loc[drop_idx,:] = np.NaN\n                self.parensemble = self.parensemble.dropna()\n                self.obsensemble.loc[drop_idx,:] = np.NaN\n                self.obsensemble = self.obsensemble.dropna()\n\n                self.phi.update()\n\n        self.phi.report(cur_lam=0.0)\n\n        self.last_best_mean = self.phi.comp_phi.mean()\n        self.last_best_std = self.phi.comp_phi.std()\n\n        #self.logger.statement(\"initial phi (mean, std): {0:15.6G},{1:15.6G}\".\\\n        #                      format(self.last_best_mean,self.last_best_std))\n        if init_lambda is not None:\n            self.current_lambda = float(init_lambda)\n        else:\n            #following chen and oliver\n            x = self.last_best_mean / (2.0 * float(self.obsensemble.shape[1]))\n            self.current_lambda = 10.0**(np.floor(np.log10(x)))\n\n        self.logger.statement(\"current lambda:{0:15.6g}\".format(self.current_lambda))\n\n        self.delta_par_prior = self._calc_delta_par(self.parensemble_0)\n        u,s,v = self.delta_par_prior.pseudo_inv_components(eigthresh=self.pst.svd_data.eigthresh)\n        self.Am = u * s.inv\n        if self.save_mats:\n            np.savetxt(self.pst.filename.replace(\".pst\",'.') + \"0.prior_par_diff.dat\", self.delta_par_prior.x, fmt=\"%15.6e\")\n            np.savetxt(self.pst.filename.replace(\".pst\",'.') + \"0.am_u.dat\",u.x,fmt=\"%15.6e\")\n            np.savetxt(self.pst.filename.replace(\".pst\", '.') + \"0.am_v.dat\", v.x, fmt=\"%15.6e\")\n            np.savetxt(self.pst.filename.replace(\".pst\",'.') + \"0.am_s_inv.dat\", s.inv.as_2d, fmt=\"%15.6e\")\n            np.savetxt(self.pst.filename.replace(\".pst\",'.') + \"0.am.dat\", self.Am.x, fmt=\"%15.6e\")\n\n        self._initialized = True", "response": "Initializes the iES process."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets an empty matrix that can be filled", "response": "def get_localizer(self):\n        \"\"\" get an empty/generic localizer matrix that can be filled\n\n        Returns\n        -------\n            localizer : pyemu.Matrix\n                matrix with nnz obs names for rows and adj par names for columns\n\n        \"\"\"\n        onames = self.pst.nnz_obs_names\n        pnames = self.pst.adj_par_names\n        localizer = Matrix(x=np.ones((len(onames),len(pnames))),row_names=onames,col_names=pnames)\n        return localizer"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef update(self,lambda_mults=[1.0],localizer=None,run_subset=None,use_approx=True,\n               calc_only=False):\n        \"\"\"update the iES one GLM cycle\n\n        Parameters\n        ----------\n            lambda_mults : list\n                a list of lambda multipliers to test.  Each lambda mult value will require\n                evaluating (a subset of) the parameter ensemble.\n            localizer : pyemu.Matrix\n                a jacobian localizing matrix\n            run_subset : int\n                the number of realizations to test for each lambda_mult value.  For example,\n                if run_subset = 30 and num_reals=100, the first 30 realizations will be run (in\n                parallel) for each lambda_mult value.  Then the best lambda_mult is selected and the\n                remaining 70 realizations for that lambda_mult value are run (in parallel).\n            use_approx : bool\n                 a flag to use the MLE or MAP upgrade solution.  True indicates use MLE solution\n            calc_only : bool\n                a flag to calculate the upgrade matrix only (not run the ensemble). This is mostly for\n                debugging and testing on travis. Default is False\n\n        Example\n        -------\n\n        ``>>>import pyemu``\n\n        ``>>>es = pyemu.EnsembleSmoother(pst=\"pest.pst\")``\n\n        ``>>>es.initialize(num_reals=100)``\n\n        ``>>>es.update(lambda_mults=[0.1,1.0,10.0],run_subset=30)``\n\n         \"\"\"\n\n        #if not self.parensemble.istransformed:\n        #    self.parensemble._transform(inplace=False)\n\n        if run_subset is not None:\n            if run_subset >= self.obsensemble.shape[0]:\n                self.logger.warn(\"run_subset ({0}) >= num of active reals ({1})...ignoring \".\\\n                                 format(run_subset,self.obsensemble.shape[0]))\n                run_subset = None\n\n        self.iter_num += 1\n        mat_prefix =  self.pst.filename.replace('.pst','')+\".{0}\".format(self.iter_num)\n        self.logger.log(\"iteration {0}\".format(self.iter_num))\n        self.logger.statement(\"{0} active realizations\".format(self.obsensemble.shape[0]))\n        if self.obsensemble.shape[0] < 2:\n            self.logger.lraise(\"at least active 2 realizations (really like 300) are needed to update\")\n        if not self._initialized:\n            #raise Exception(\"must call initialize() before update()\")\n            self.logger.lraise(\"must call initialize() before update()\")\n\n        self.logger.log(\"calculate scaled delta obs\")\n        scaled_delta_obs = self._calc_delta_obs(self.obsensemble)\n        self.logger.log(\"calculate scaled delta obs\")\n        self.logger.log(\"calculate scaled delta par\")\n        scaled_delta_par = self._calc_delta_par(self.parensemble)\n        self.logger.log(\"calculate scaled delta par\")\n\n        self.logger.log(\"calculate pseudo inv comps\")\n        u,s,v = scaled_delta_obs.pseudo_inv_components(eigthresh=self.pst.svd_data.eigthresh)\n        s.col_names = s.row_names\n        self.logger.log(\"calculate pseudo inv comps\")\n\n        self.logger.log(\"calculate obs diff matrix\")\n        #obs_diff = self.obscov_inv_sqrt * self._get_residual_obs_matrix(self.obsensemble).T\n        obs_diff = self.obscov_inv_sqrt * self.phi.get_residual_obs_matrix(self.obsensemble).T\n        self.logger.log(\"calculate obs diff matrix\")\n\n        if self.save_mats:\n            np.savetxt(mat_prefix + \".obs_diff.dat\", scaled_delta_obs.x, fmt=\"%15.6e\")\n            np.savetxt(mat_prefix + \".par_diff.dat\", scaled_delta_par.x, fmt=\"%15.6e\")\n            np.savetxt(mat_prefix + \".u.dat\", u.x, fmt=\"%15.6e\")\n            np.savetxt(mat_prefix + \".s.dat\", s.x, fmt=\"%15.6e\")\n            np.savetxt(mat_prefix + \".v.dat\", v.x, fmt=\"%15.6e\")\n        # here is the math part...calculate upgrade matrices\n        mean_lam,std_lam,paren_lam,obsen_lam = [],[],[],[]\n        lam_vals = []\n        for ilam,cur_lam_mult in enumerate(lambda_mults):\n\n            parensemble_cur_lam = self.parensemble.copy()\n            #print(parensemble_cur_lam.isnull().values.any())\n\n            cur_lam = self.current_lambda * cur_lam_mult\n            lam_vals.append(cur_lam)\n            self.logger.log(\"calcs for  lambda {0}\".format(cur_lam_mult))\n            scaled_ident = Cov.identity_like(s) * (cur_lam+1.0)\n            scaled_ident += s**2\n            scaled_ident = scaled_ident.inv\n\n            # build up this matrix as a single element so we can apply\n            # localization\n            self.logger.log(\"building upgrade_1 matrix\")\n            upgrade_1 = -1.0 * (self.parcov_inv_sqrt * scaled_delta_par) *\\\n                        v * s * scaled_ident * u.T\n            if self.save_mats:\n                np.savetxt(mat_prefix+\".ivec.dat\".format(self.iter_num), scaled_ident.x, fmt=\"%15.6e\")\n            self.logger.log(\"building upgrade_1 matrix\")\n\n            # apply localization\n            if localizer is not None:\n                self.logger.log(\"applying localization\")\n                upgrade_1.hadamard_product(localizer)\n                self.logger.log(\"applying localization\")\n\n            # apply residual information\n            self.logger.log(\"applying residuals\")\n            upgrade_1 *= obs_diff\n            self.logger.log(\"applying residuals\")\n\n            self.logger.log(\"processing upgrade_1\")\n            if self.save_mats:\n                np.savetxt(mat_prefix + \".upgrade_1.dat\", upgrade_1.T.x, fmt=\"%15.6e\")\n            upgrade_1 = upgrade_1.to_dataframe()\n            upgrade_1.index.name = \"parnme\"\n            upgrade_1 = upgrade_1.T\n            upgrade_1.index = [int(i) for i in upgrade_1.index]\n            upgrade_1.to_csv(self.pst.filename+\".upgrade_1.{0:04d}.csv\".\\\n                               format(self.iter_num))\n            if upgrade_1.isnull().values.any():\n                    self.logger.lraise(\"NaNs in upgrade_1\")\n            self.logger.log(\"processing upgrade_1\")\n\n            #print(upgrade_1.isnull().values.any())\n            #print(parensemble_cur_lam.index)\n            #print(upgrade_1.index)\n            parensemble_cur_lam += upgrade_1\n\n            # parameter-based upgrade portion\n            if not use_approx and self.iter_num > 1:\n            #if True:\n                self.logger.log(\"building upgrade_2 matrix\")\n                par_diff = (self.parensemble - self.parensemble_0.loc[self.parensemble.index,:]).\\\n                    as_pyemu_matrix().T\n                x4 = self.Am.T * self.parcov_inv_sqrt * par_diff\n                x5 = self.Am * x4\n                x6 = scaled_delta_par.T * x5\n                x7 = v * scaled_ident * v.T * x6\n                ug2_mat = -1.0 * (self.parcov_inv_sqrt *\n                                   scaled_delta_par * x7)\n                upgrade_2 = ug2_mat.to_dataframe()\n                upgrade_2.index.name = \"parnme\"\n                upgrade_2 = upgrade_2.T\n                upgrade_2.to_csv(self.pst.filename+\".upgrade_2.{0:04d}.csv\".\\\n                                   format(self.iter_num))\n                upgrade_2.index = [int(i) for i in upgrade_2.index]\n\n                if self.save_mats:\n                    np.savetxt(mat_prefix + \".scaled_par_resid.dat\", par_diff.x, fmt=\"%15.6e\")\n                    np.savetxt(mat_prefix + \".x4.dat\", x4.x, fmt=\"%15.6e\")\n                    np.savetxt(mat_prefix + \".x5.dat\", x5.x, fmt=\"%15.6e\")\n                    np.savetxt(mat_prefix + \".x6.dat\", x6.x, fmt=\"%15.6e\")\n                    np.savetxt(mat_prefix + \".x7.dat\", x7.x, fmt=\"%15.6e\")\n                    np.savetxt(mat_prefix + \".upgrade_2.dat\", ug2_mat.T.x, fmt=\"%15.6e\")\n\n                if upgrade_2.isnull().values.any():\n                    self.logger.lraise(\"NaNs in upgrade_2\")\n\n                parensemble_cur_lam += upgrade_2\n                self.logger.log(\"building upgrade_2 matrix\")\n            self.logger.log(\"enforcing bounds\")\n            parensemble_cur_lam.enforce(self.enforce_bounds)\n            self.logger.log(\"enforcing bounds\")\n\n            self.logger.log(\"filling fixed parameters\")\n            #fill in fixed pars with initial values\n            fi = parensemble_cur_lam.fixed_indexer\n            li = parensemble_cur_lam.log_indexer\n            log_values = self.pst.parameter_data.loc[:,\"parval1\"].copy()\n            log_values.loc[li] = log_values.loc[li].apply(np.log10)\n            fixed_vals = log_values.loc[fi]\n\n            for fname, fval in zip(fixed_vals.index, fixed_vals.values):\n                # if fname not in df.columns:\n                #    continue\n                # print(fname)\n                parensemble_cur_lam.loc[:, fname] = fval\n            self.logger.log(\"filling fixed parameters\")\n            # this is for testing failed runs on upgrade testing\n            # works with the 10par_xsec smoother test\n            #parensemble_cur_lam.iloc[:,:] = -1000000.0\n\n            # some hackery - we lose track of the transform flag here, but just\n            # know it is transformed.  Need to create dataframe here because\n            # pd.concat doesn't like par ensembles later\n            paren_lam.append(pd.DataFrame(parensemble_cur_lam.loc[:,:]))\n            self.logger.log(\"calcs for  lambda {0}\".format(cur_lam_mult))\n\n        if calc_only:\n            return\n\n\n        # subset if needed\n        # and combine lambda par ensembles into one par ensemble for evaluation\n        if run_subset is not None and run_subset < self.parensemble.shape[0]:\n            #subset_idx = [\"{0:d}\".format(i) for i in np.random.randint(0,self.parensemble.shape[0]-1,run_subset)]\n            subset_idx = self.parensemble.iloc[:run_subset,:].index.values\n            self.logger.statement(\"subset idxs: \" + ','.join([str(s) for s in subset_idx]))\n\n            # more tracking of transformed - just know it! Creating dataframes...\n            paren_lam_subset = [pe.loc[subset_idx,:] for pe in paren_lam]\n            paren_combine = pd.concat(paren_lam_subset,ignore_index=True)\n            paren_lam_subset = None\n        else:\n            subset_idx = self.parensemble.index.values\n            paren_combine = pd.concat(paren_lam,ignore_index=True)\n\n\n        self.logger.log(\"evaluating ensembles for lambdas : {0}\".\\\n                        format(','.join([\"{0:8.3E}\".format(l) for l in lam_vals])))\n        # back to par ensemble and know it is transformed\n        paren_combine = ParameterEnsemble.from_dataframe(df=paren_combine,pst=self.pst,istransformed=True)\n        failed_runs, obsen_combine = self._calc_obs(paren_combine)\n        self.logger.log(\"evaluating ensembles for lambdas : {0}\".\\\n                        format(','.join([\"{0:8.3E}\".format(l) for l in lam_vals])))\n        paren_combine = None\n\n        if failed_runs is not None and len(failed_runs) == obsen_combine.shape[0]:\n                self.logger.lraise(\"all runs failed - cannot continue\")\n\n\n        # unpack lambda obs ensembles from combined obs ensemble\n        nrun_per_lam = self.obsensemble.shape[0]\n        if run_subset is not None:\n            nrun_per_lam = run_subset\n        obsen_lam = []\n\n        for i in range(len(lam_vals)):\n            sidx = i * nrun_per_lam\n            eidx = sidx + nrun_per_lam\n            oe = ObservationEnsemble.from_dataframe(df=obsen_combine.iloc[sidx:eidx,:].copy(),\n                                                    pst=self.pst)\n            oe.index = subset_idx\n            # check for failed runs in this set - drop failed runs from obs ensembles\n            if failed_runs is not None:\n                failed_runs_this = np.array([f for f in failed_runs if f >= sidx and f < eidx]) - sidx\n                if len(failed_runs_this) > 0:\n                    if len(failed_runs_this) == oe.shape[0]:\n                        self.logger.warn(\"all runs failed for lambda {0}\".format(lam_vals[i]))\n                    else:\n                        self.logger.warn(\"{0} run failed for lambda {1}\".\\\n                                         format(len(failed_runs_this),lam_vals[i]))\n                    oe.iloc[failed_runs_this,:] = np.NaN\n                    oe = oe.dropna()\n                    paren_lam[i].iloc[failed_runs_this,:] = np.NaN\n                    paren_lam[i] = ParameterEnsemble.from_dataframe(df=paren_lam[i].dropna(),pst=self.pst)\n                    paren_lam[i].__instransformed = True\n\n            # don't drop bad reals here, instead, mask bad reals in the lambda\n            # selection and drop later\n            # if self.drop_bad_reals is not None:\n            #     assert isinstance(drop_bad_reals, float)\n            #     drop_idx = np.argwhere(self.current_phi_vec > self.drop_bad_reals).flatten()\n            #     run_ids = self.obsensemble.index.values\n            #     drop_idx = run_ids[drop_idx]\n            #     if len(drop_idx) == self.obsensemble.shape[0]:\n            #         raise Exception(\"dropped all realizations as 'bad'\")\n            #     if len(drop_idx) > 0:\n            #         self.logger.warn(\"{0} realizations dropped as 'bad' (indices :{1})\". \\\n            #                          format(len(drop_idx), ','.join([str(d) for d in drop_idx])))\n            #         self.parensemble.loc[drop_idx, :] = np.NaN\n            #         self.parensemble = self.parensemble.dropna()\n            #         self.obsensemble.loc[drop_idx, :] = np.NaN\n            #         self.obsensemble = self.obsensemble.dropna()\n            #\n            #         self.current_phi_vec = self._calc_phi_vec(self.obsensemble)\n\n            obsen_lam.append(oe)\n        obsen_combine = None\n\n        # here is where we need to select out the \"best\" lambda par and obs\n        # ensembles\n\n        #phi_vecs = [self._calc_phi_vec(obsen) for obsen in obsen_lam]\n        #phi_vecs_reg = [self._calc_regul_phi_vec(paren) for paren in paren_lam]\n        #if self.regul_factor > 0.0:\n        #    for i,(pv,prv) in enumerate(zip(phi_vecs,phi_vecs_reg)):\n        #        phi_vecs[i] = pv + (prv * self.regul_factor)\n        self.logger.log(\"calc lambda phi vectors\")\n        phi_vecs = [self.phi.get_meas_and_regul_phi(oe,pe.loc[oe.index,:]) for oe,pe in zip(obsen_lam,paren_lam)]\n        self.logger.log(\"calc lambda phi vectors\")\n        if self.drop_bad_reals is not None:\n            for i,(meas_pv,regul_pv) in enumerate(phi_vecs):\n                #for testing the drop_bad_reals functionality\n                #pv[[0,3,7]] = self.drop_bad_reals + 1.0\n                regul_pv = regul_pv.copy()\n                regul_pv[meas_pv>self.drop_bad_reals] = np.NaN\n                regul_pv = regul_pv[~np.isnan(regul_pv)]\n                meas_pv[meas_pv>self.drop_bad_reals] = np.NaN\n                meas_pv = meas_pv[~np.isnan(meas_pv)]\n                if len(meas_pv) == 0:\n                    #raise Exception(\"all realization for lambda {0} dropped as 'bad'\".\\\n                    #                format(lam_vals[i]))\n                    self.logger.warn(\"all realizations for lambda {0} marked as 'bad'\")\n                    meas_pv = np.zeros_like(obsen_lam[0].shape[0]) + 1.0e+30\n                    regul_pv = np.zeros_like(obsen_lam[0].shape[0]) + 1.0e+30\n                phi_vecs[i] = (meas_pv,regul_pv)\n        mean_std_meas = [(pv[0].mean(),pv[0].std()) for pv in phi_vecs]\n        mean_std_regul = [(pv[1].mean(), pv[1].std()) for pv in phi_vecs]\n        update_pars = False\n        update_lambda = False\n        self.logger.statement(\"**************************\")\n        # self.logger.statement(str(datetime.now()))\n        self.logger.statement(\"lambda testing summary\")\n        self.logger.statement(\"total runs:{0}\".format(self.total_runs))\n        self.logger.statement(\"iteration: {0}\".format(self.iter_num))\n        self.logger.statement(\"current lambda:{0:15.6G}, mean:{1:15.6G}, std:{2:15.6G}\". \\\n                              format(self.current_lambda,\n                                     self.last_best_mean, self.last_best_std))\n\n        # accept a new best if its within 10%\n        best_mean = self.last_best_mean * 1.1\n        best_std = self.last_best_std * 1.1\n        best_i = 0\n        for i,((mm,ms),(rm,rs)) in enumerate(zip(mean_std_meas,mean_std_regul)):\n            self.logger.statement(\" tested lambda:{0:15.6G}, meas mean:{1:15.6G}, meas std:{2:15.6G}\".\n                                  format(self.current_lambda * lambda_mults[i],mm,ms))\n            self.logger.statement(\"{0:30s}regul mean:{1:15.6G}, regul std:{2:15.6G}\".\\\n                                  format(' ',rm,rs))\n            m = mm + (self.regul_factor * rm)\n            s = ms + (self.regul_factor * rs)\n            if m < best_mean:\n                update_pars = True\n                best_mean = m\n                best_i = i\n                if s < best_std:\n                    update_lambda = True\n                    best_std = s\n        if np.isnan(best_mean):\n            self.logger.lraise(\"best mean = NaN\")\n        if np.isnan(best_std):\n            self.logger.lraise(\"best std = NaN\")\n\n        if not update_pars:\n            self.current_lambda *= max(lambda_mults) * 10.0\n            self.current_lambda = min(self.current_lambda,100000)\n            self.logger.statement(\"not accepting iteration, increased lambda:{0}\".\\\n                  format(self.current_lambda))\n        else:\n            #more transformation status hard coding - ugly\n            self.parensemble = ParameterEnsemble.from_dataframe(df=paren_lam[best_i],pst=self.pst,istransformed=True)\n            if run_subset is not None:\n                failed_runs, self.obsensemble = self._calc_obs(self.parensemble)\n                if failed_runs is not None:\n                    self.logger.warn(\"dropping failed realizations\")\n                    self.parensemble.loc[failed_runs, :] = np.NaN\n                    self.parensemble = self.parensemble.dropna()\n                    self.obsensemble.loc[failed_runs, :] = np.NaN\n                    self.obsensemble = self.obsensemble.dropna()\n\n                self.phi.update()\n                best_mean = self.phi.comp_phi.mean()\n                best_std = self.phi.comp_phi.std()\n            else:\n                self.obsensemble = obsen_lam[best_i]\n                # reindex parensemble in case failed runs\n                self.parensemble = ParameterEnsemble.from_dataframe(df=self.parensemble.loc[self.obsensemble.index],\n                                                                    pst=self.pst,\n                                                                    istransformed=self.parensemble.istransformed)\n                self.phi.update()\n            if self.drop_bad_reals is not None:\n                # for testing drop_bad_reals functionality\n                # self.current_phi_vec[::2] = self.drop_bad_reals + 1.0\n                #drop_idx = np.argwhere(self.current_phi_vec > self.drop_bad_reals).flatten()\n                drop_idx = np.argwhere(self.phi.comp_phi > self.drop_bad_reals).flatten()\n                run_ids = self.obsensemble.index.values\n                drop_idx = run_ids[drop_idx]\n                if len(drop_idx) > self.obsensemble.shape[0] - 3:\n                    raise Exception(\"dropped too many realizations as 'bad'\")\n                if len(drop_idx) > 0:\n                    self.logger.warn(\"{0} realizations dropped as 'bad' (indices :{1})\". \\\n                                     format(len(drop_idx), ','.join([str(d) for d in drop_idx])))\n                    self.parensemble.loc[drop_idx, :] = np.NaN\n                    self.parensemble = self.parensemble.dropna()\n                    self.obsensemble.loc[drop_idx, :] = np.NaN\n                    self.obsensemble = self.obsensemble.dropna()\n\n                    self.phi.update()\n                    best_mean = self.phi.comp_phi.mean()\n                    best_std = self.phi.comp_phi.std()\n\n            self.phi.report(cur_lam=self.current_lambda * lambda_mults[best_i])\n\n            self.logger.statement(\"   best lambda:{0:15.6G}, mean:{1:15.6G}, std:{2:15.6G}\".\\\n                  format(self.current_lambda*lambda_mults[best_i],\n                         best_mean,best_std))\n            #self.logger.statement(\"   actual mean phi: {0:15.6G}\".format(float(self.current_actual_phi.mean())))\n            self.last_best_mean = best_mean\n            self.last_best_std = best_std\n\n\n        if update_lambda:\n            # be aggressive\n            self.current_lambda *= (lambda_mults[best_i] * 0.75)\n            # but don't let lambda get too small\n            self.current_lambda = max(self.current_lambda,0.00001)\n            self.logger.statement(\"updating lambda: {0:15.6G}\".\\\n                  format(self.current_lambda ))\n\n        self.logger.statement(\"**************************\\n\")\n        self.parensemble.to_csv(self.pst.filename+self.paren_prefix.\\\n                                    format(self.iter_num))\n        self.obsensemble.to_csv(self.pst.filename+self.obsen_prefix.\\\n                                    format(self.iter_num))\n        if self.raw_sweep_out is not None:\n            self.raw_sweep_out.to_csv(self.pst.filename+\"_sweepraw{0}.csv\".\\\n                                        format(self.iter_num))\n        self.logger.log(\"iteration {0}\".format(self.iter_num))", "response": "update the iES one GLM cycle"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pp_file_to_dataframe(pp_filename):\n\n    \"\"\" read a pilot point file to a pandas Dataframe\n\n    Parameters\n    ----------\n    pp_filename : str\n        pilot point file\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        a dataframe with pp_utils.PP_NAMES for columns\n\n    \"\"\"\n\n    df = pd.read_csv(pp_filename, delim_whitespace=True,\n                     header=None, names=PP_NAMES,usecols=[0,1,2,3,4])\n    df.loc[:,\"name\"] = df.name.apply(str).apply(str.lower)\n    return df", "response": "read a pilot point file to a pandas Dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pp_tpl_to_dataframe(tpl_filename):\n    inlines = open(tpl_filename, 'r').readlines()\n    header = inlines.pop(0)\n    marker = header.strip().split()[1]\n    assert len(marker) == 1\n    usecols = [0,1,2,3]\n    df = pd.read_csv(tpl_filename, delim_whitespace=True,skiprows=1,\n                     header=None, names=PP_NAMES[:-1],usecols=usecols)\n    df.loc[:,\"name\"] = df.name.apply(str).apply(str.lower)\n    df[\"parnme\"] = [i.split(marker)[1].strip() for i in inlines]\n\n\n    return df", "response": "read a pilot points template file to a pandas dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_pp_shapfile(pp_df,shapename=None):\n    try:\n        import shapefile\n    except Exception as e:\n        raise Exception(\"error importing shapefile: {0}, \\ntry pip install pyshp...\".format(str(e)))\n\n    if not isinstance(pp_df,list):\n        pp_df = [pp_df]\n    dfs = []\n    for pp in pp_df:\n        if isinstance(pp,pd.DataFrame):\n            dfs.append(pp)\n        elif isinstance(pp,str):\n            dfs.append(pp_file_to_dataframe(pp))\n        else:\n            raise Exception(\"unsupported arg type:{0}\".format(type(pp)))\n\n    if shapename is None:\n        shapename = \"pp_locs.shp\"\n    try:\n        shp = shapefile.Writer(shapeType=shapefile.POINT)\n    except:\n        shp = shapefile.Writer(target=shapename, shapeType=shapefile.POINT)\n    for name, dtype in dfs[0].dtypes.iteritems():\n        if dtype == object:\n            shp.field(name=name, fieldType='C', size=50)\n        elif dtype in [int, np.int, np.int64, np.int32]:\n            shp.field(name=name, fieldType='N', size=50, decimal=0)\n        elif dtype in [float, np.float, np.float32, np.float32]:\n            shp.field(name=name, fieldType='N', size=50, decimal=8)\n        else:\n            raise Exception(\"unrecognized field type in pp_df:{0}:{1}\".format(name, dtype))\n\n\n    # some pandas awesomeness..\n    for df in dfs:\n        #df.apply(lambda x: shp.poly([[[x.x, x.y]]]), axis=1)\n        df.apply(lambda x: shp.point(x.x, x.y), axis=1)\n        df.apply(lambda x: shp.record(*x), axis=1)\n\n    try:\n        shp.save(shapename)\n    except:\n        shp.close()", "response": "write a pilot points dataframe to a shapefile"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a pilot points dataframe to a pilot points file", "response": "def write_pp_file(filename,pp_df):\n    \"\"\"write a pilot points dataframe to a pilot points file\n\n    Parameters\n    ----------\n    filename : str\n        pilot points file to write\n    pp_df : pandas.DataFrame\n        a dataframe that has columns \"x\",\"y\",\"zone\", and \"value\"\n\n    \"\"\"\n    with open(filename,'w') as f:\n       f.write(pp_df.to_string(col_space=0,\n                                columns=PP_NAMES,\n                                formatters=PP_FMT,\n                                justify=\"right\",\n                                header=False,\n                                index=False) + '\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nwrites a template file for a pilot points file", "response": "def pilot_points_to_tpl(pp_file,tpl_file=None,name_prefix=None):\n    \"\"\"write a template file for a pilot points file\n\n    Parameters\n    ----------\n    pp_file : str\n        pilot points file\n    tpl_file : str\n        template file name to write.  If None, append \".tpl\" to\n        the pp_file arg. Default is None\n    name_prefix : str\n        name to prepend to parameter names for each pilot point.  For example,\n        if ``name_prefix = \"hk_\"``, then each pilot point parameter will be named\n        \"hk_0001\",\"hk_0002\", etc.  If None, parameter names from pp_df.name\n        are used.  Default is None.\n\n    Returns\n    -------\n        pp_df : pandas.DataFrame\n            a dataframe with pilot point information (name,x,y,zone,parval1)\n             with the parameter information (parnme,tpl_str)\n    \"\"\"\n\n    if isinstance(pp_file,pd.DataFrame):\n        pp_df = pp_file\n        assert tpl_file is not None\n    else:\n        assert os.path.exists(pp_file)\n        pp_df = pd.read_csv(pp_file, delim_whitespace=True,\n                            header=None, names=PP_NAMES)\n\n    if tpl_file is None:\n        tpl_file = pp_file + \".tpl\"\n\n    if name_prefix is not None:\n        digits = str(len(str(pp_df.shape[0])))\n        fmt = \"{0:0\"+digits+\"d}\"\n        names = [name_prefix+fmt.format(i) for i in range(pp_df.shape[0])]\n    else:\n        names = pp_df.name.copy()\n\n    too_long = []\n    for name in names:\n        if len(name) > 12:\n            too_long.append(name)\n    if len(too_long) > 0:\n        raise Exception(\"the following parameter names are too long:\" +\\\n                        \",\".join(too_long))\n\n    tpl_entries = [\"~    {0}    ~\".format(name) for name in names]\n    pp_df.loc[:,\"tpl\"] = tpl_entries\n    pp_df.loc[:,\"parnme\"] = names\n\n\n    f_tpl = open(tpl_file,'w')\n    f_tpl.write(\"ptf ~\\n\")\n    f_tpl.write(pp_df.to_string(col_space=0,\n                              columns=[\"name\",\"x\",\"y\",\"zone\",\"tpl\"],\n                              formatters=PP_FMT,\n                              justify=\"left\",\n                              header=False,\n                              index=False) + '\\n')\n\n    return pp_df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun fieldgen and return a dataframe with the realizations", "response": "def run_fieldgen(m,num_reals,struct_dict,cwd=None):\n    \"\"\"run fieldgen and return a dataframe with the realizations\n\n    Parameters\n    ----------\n    m : flopy.mbase\n        a floy model instance\n    num_reals : int\n        number of realizations to generate\n    struct_dict : dict\n        key-value pairs of pyemu.GeoStruct instances and lists of prefix strings.  Example: {gs1:['hk','ss']}\n    cwd : str\n        working director where to execute fieldgen.  If None, m.model_ws is used.  Default is None\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        a dataframe of realizations.  Columns are named to include structure, prefix and realization number.  Index\n        includes i-j position\n\n    Note\n    ----\n    only Ordinary kriging is supported\n    only a single zone is supported\n\n\n    \"\"\"\n    if cwd is None:\n        cwd = m.model_ws\n    set_file = os.path.join(cwd,\"settings.fig\")\n    if not os.path.exists(set_file):\n        print(\"writing \",set_file)\n        with open(set_file,'w') as f:\n            f.write(\"date=dd/mm/yyyy\\ncolrow=no\\n\")\n\n    m.sr.write_gridSpec(os.path.join(cwd,\"grid.spc\"))\n\n    np.savetxt(os.path.join(cwd,\"zone.dat\"),np.ones((m.nrow,m.ncol),dtype=np.int),fmt=\"%2d\")\n    arrs = {}\n    for struct,prefixes in struct_dict.items():\n        args = [\"grid.spc\",'']\n\n        print(struct)\n        struct.to_struct_file(os.path.join(cwd,\"pyemu_struct.dat\"))\n\n        args.append(\"zone.dat\")\n        args.append(\"f\")\n        args.append(\"pyemu_struct.dat\")\n        args.append(struct.name)\n        args.append(\"o\")\n        args.append(\"10\")\n        args.append(num_reals)\n        for prefix in prefixes:\n            prefix_args = list(args)\n            prefix_args.append(prefix)\n            prefix_args.append(\"f\")\n            prefix_args.append(1.0)\n            prefix_args.append('')\n            rsp_file = \"fieldgen_{0}.in\".format(prefix)\n            with open(os.path.join(cwd,rsp_file),'w') as f:\n                for arg in prefix_args:\n                    f.write(str(arg)+'\\n')\n            pyemu.os_utils.run(\"fieldgen <{0} >{1}\".format(rsp_file,rsp_file.replace(\".in\",\".stdout\")),cwd=cwd)\n            real_files = [\"{0}{1}.ref\".format(prefix,i+1) for i in range(num_reals)]\n\n            for real_file in real_files:\n                assert os.path.exists(os.path.join(cwd,real_file)),\"missing realization file: \"+real_file\n                vals = []\n                with open(os.path.join(cwd,real_file),'r') as f:\n                    [vals.extend(line.strip().split()) for line in f]\n                arr = np.array(vals,dtype=np.float)#.reshape(m.nrow,m.ncol)\n                real_num = int(real_file.split('.')[0].replace(prefix,''))\n                arrs[\"{0}_{1}_{2}\".format(struct.name,prefix,real_num)] = arr\n        ij = []\n        for i in range(m.nrow):\n            for j in range(m.ncol):\n                ij.append(\"{0}_{1}\".format(i,j))\n        df = pd.DataFrame(arrs,index=ij)\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef sparse_geostatistical_prior_builder(pst, struct_dict,sigma_range=4,verbose=False):\n\n    if isinstance(pst,str):\n        pst = pyemu.Pst(pst)\n    assert isinstance(pst,pyemu.Pst),\"pst arg must be a Pst instance, not {0}\".\\\n        format(type(pst))\n    if verbose: print(\"building diagonal cov\")\n    full_cov = pyemu.Cov.from_parameter_data(pst,sigma_range=sigma_range)\n\n    full_cov_dict = {n:float(v) for n,v in zip(full_cov.col_names,full_cov.x)}\n\n    full_cov = None\n    par = pst.parameter_data\n    for gs,items in struct_dict.items():\n        if verbose: print(\"processing \",gs)\n        if isinstance(gs,str):\n            gss = pyemu.geostats.read_struct_file(gs)\n            if isinstance(gss,list):\n                warnings.warn(\"using first geostat structure in file {0}\".\\\n                              format(gs),PyemuWarning)\n                gs = gss[0]\n            else:\n                gs = gss\n        if not isinstance(items,list):\n            items = [items]\n        for item in items:\n            if isinstance(item,str):\n                assert os.path.exists(item),\"file {0} not found\".\\\n                    format(item)\n                if item.lower().endswith(\".tpl\"):\n                    df = pyemu.pp_utils.pp_tpl_to_dataframe(item)\n                elif item.lower.endswith(\".csv\"):\n                    df = pd.read_csv(item)\n            else:\n                df = item\n            for req in ['x','y','parnme']:\n                if req not in df.columns:\n                    raise Exception(\"{0} is not in the columns\".format(req))\n            missing = df.loc[df.parnme.apply(\n                    lambda x : x not in par.parnme),\"parnme\"]\n            if len(missing) > 0:\n                warnings.warn(\"the following parameters are not \" + \\\n                              \"in the control file: {0}\".\\\n                              format(','.join(missing)),PyemuWarning)\n                df = df.loc[df.parnme.apply(lambda x: x not in missing)]\n            if \"zone\" not in df.columns:\n                df.loc[:,\"zone\"] = 1\n            zones = df.zone.unique()\n            aset = set(pst.adj_par_names)\n            for zone in zones:\n                df_zone = df.loc[df.zone==zone,:].copy()\n                df_zone = df_zone.loc[df_zone.parnme.apply(lambda x: x in aset), :]\n                if df_zone.shape[0] == 0:\n                    warnings.warn(\"all parameters in zone {0} tied and/or fixed, skipping...\".format(zone),\n                                  PyemuWarning)\n                    continue\n                #df_zone.sort_values(by=\"parnme\",inplace=True)\n                df_zone.sort_index(inplace=True)\n                if verbose: print(\"build cov matrix\")\n                cov = gs.sparse_covariance_matrix(df_zone.x,df_zone.y,df_zone.parnme)\n                if verbose: print(\"done\")\n\n                if verbose: print(\"getting diag var cov\",df_zone.shape[0])\n                #tpl_var = np.diag(full_cov.get(list(df_zone.parnme)).x).max()\n                tpl_var = max([full_cov_dict[pn] for pn in df_zone.parnme])\n\n                if verbose: print(\"scaling full cov by diag var cov\")\n                cov.x.data *= tpl_var\n\n                if full_cov is None:\n                    full_cov = cov\n                else:\n                    if verbose: print(\"extending SparseMatix\")\n                    full_cov.block_extend_ip(cov)\n\n\n    if verbose: print(\"adding remaining parameters to diagonal\")\n    fset = set(full_cov.row_names)\n    pset = set(pst.adj_par_names)\n    diff = list(pset.difference(fset))\n    diff.sort()\n    vals = np.array([full_cov_dict[d] for d in diff])\n    i = np.arange(vals.shape[0])\n    coo = scipy.sparse.coo_matrix((vals,(i,i)),shape=(vals.shape[0],vals.shape[0]))\n    cov = pyemu.SparseMatrix(x=coo,row_names=diff,col_names=diff)\n    full_cov.block_extend_ip(cov)\n\n    return full_cov", "response": "a helper function to construct a full sparse covariance matrix using a mixture of geostastical structures and parameter bounds information."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef condition_on_par_knowledge(cov,par_knowledge_dict):\n\n    missing = []\n    for parnme in par_knowledge_dict.keys():\n        if parnme not in cov.row_names:\n            missing.append(parnme)\n    if len(missing):\n        raise Exception(\"par knowledge dict parameters not found: {0}\".\\\n                        format(','.join(missing)))\n    # build the selection matrix and sigma epsilon\n    #sel = cov.zero2d\n    #sel = pyemu.Matrix(x=np.zeros((cov.shape[0],1)),row_names=cov.row_names,col_names=['sel'])\n    sel = cov.zero2d\n    sigma_ep = cov.zero2d\n    for parnme,var in par_knowledge_dict.items():\n        idx = cov.row_names.index(parnme)\n        #sel.x[idx,:] = 1.0\n        sel.x[idx,idx] = 1.0\n        sigma_ep.x[idx,idx] = var\n    #print(sigma_ep.x)\n    #q = sigma_ep.inv\n    #cov_inv = cov.inv\n    print(sel)\n    term2 = sel * cov * sel.T\n    #term2 += sigma_ep\n    #term2 = cov\n    print(term2)\n    term2 = term2.inv\n    term2 *= sel\n    term2 *= cov\n\n    new_cov = cov - term2\n\n    return new_cov", "response": "experimental function to include conditional prior information on one or more parameters in a full covariance matrix\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\napply a KL parameterization transform from a file to model input arrays.", "response": "def kl_apply(par_file, basis_file,par_to_file_dict,arr_shape):\n    \"\"\" Applies a KL parameterization transform from basis factors to model\n    input arrays.  Companion function to kl_setup()\n\n    Parameters\n    ----------\n    par_file : str\n        the csv file to get factor values from.  Must contain\n        the following columns: name, new_val, org_val\n    basis_file : str\n        the binary file that contains the reduced basis\n\n    par_to_file_dict : dict\n        a mapping from KL parameter prefixes to array file names.\n\n    Note\n    ----\n    This is the companion function to kl_setup.\n\n    This function should be called during the forward run\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    ``>>>pyemu.helpers.kl_apply(\"kl.dat\",\"basis.dat\",{\"hk\":\"hk_layer_1.dat\",(100,100))``\n\n\n    \"\"\"\n    df = pd.read_csv(par_file)\n    assert \"name\" in df.columns\n    assert \"org_val\" in df.columns\n    assert \"new_val\" in df.columns\n\n    df.loc[:,\"prefix\"] = df.name.apply(lambda x: x[:-4])\n    for prefix in df.prefix.unique():\n        assert prefix in par_to_file_dict.keys(),\"missing prefix:{0}\".\\\n            format(prefix)\n    basis = pyemu.Matrix.from_binary(basis_file)\n    assert basis.shape[1] == arr_shape[0] * arr_shape[1]\n    arr_min = 1.0e-10 # a temp hack\n\n    #means = df.loc[df.name.apply(lambda x: x.endswith(\"mean\")),:]\n    #print(means)\n    df = df.loc[df.name.apply(lambda x: not x.endswith(\"mean\")),:]\n    for prefix,filename in par_to_file_dict.items():\n        factors = pyemu.Matrix.from_dataframe(df.loc[df.prefix==prefix,[\"new_val\"]])\n        factors.autoalign = False\n        basis_prefix = basis[:factors.shape[0],:]\n        arr = (factors.T * basis_prefix).x.reshape(arr_shape)\n        #arr += means.loc[means.prefix==prefix,\"new_val\"].values\n        arr[arr<arr_min] = arr_min\n        np.savetxt(filename,arr,fmt=\"%20.8E\")"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nzeroing - order the prior information attribute of a control file instance.", "response": "def zero_order_tikhonov(pst, parbounds=True,par_groups=None,\n                        reset=True):\n    \"\"\"setup preferred-value regularization\n\n    Parameters\n    ----------\n    pst : pyemu.Pst\n        the control file instance\n    parbounds : bool\n        flag to weight the prior information equations according\n        to parameter bound width - approx the KL transform. Default\n        is True\n    par_groups : list\n        parameter groups to build PI equations for.  If None, all\n        adjustable parameters are used. Default is None\n\n    reset : bool\n        flag to reset the prior_information attribute of the pst\n        instance.  Default is True\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    ``>>>pst = pyemu.Pst(\"pest.pst\")``\n\n    ``>>>pyemu.helpers.zero_order_tikhonov(pst)``\n\n    \"\"\"\n\n    if par_groups is None:\n        par_groups = pst.par_groups\n\n    pilbl, obgnme, weight, equation = [], [], [], []\n    for idx, row in pst.parameter_data.iterrows():\n        pt = row[\"partrans\"].lower()\n        try:\n            pt = pt.decode()\n        except:\n            pass\n        if pt not in [\"tied\", \"fixed\"] and\\\n            row[\"pargp\"] in par_groups:\n            pilbl.append(row[\"parnme\"])\n            weight.append(1.0)\n            ogp_name = \"regul\"+row[\"pargp\"]\n            obgnme.append(ogp_name[:12])\n            parnme = row[\"parnme\"]\n            parval1 = row[\"parval1\"]\n            if pt == \"log\":\n                parnme = \"log(\" + parnme + \")\"\n                parval1 = np.log10(parval1)\n            eq = \"1.0 * \" + parnme + \" ={0:15.6E}\".format(parval1)\n            equation.append(eq)\n\n    if reset:\n        pst.prior_information = pd.DataFrame({\"pilbl\": pilbl,\n                                               \"equation\": equation,\n                                               \"obgnme\": obgnme,\n                                               \"weight\": weight})\n    else:\n        pi = pd.DataFrame({\"pilbl\": pilbl,\n                          \"equation\": equation,\n                          \"obgnme\": obgnme,\n                          \"weight\": weight})\n        pst.prior_information = pst.prior_information.append(pi)\n    if parbounds:\n        regweight_from_parbound(pst)\n    if pst.control_data.pestmode == \"estimation\":\n        pst.control_data.pestmode = \"regularization\""}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef regweight_from_parbound(pst):\n\n    pst.parameter_data.index = pst.parameter_data.parnme\n    pst.prior_information.index = pst.prior_information.pilbl\n    for idx, parnme in enumerate(pst.prior_information.pilbl):\n        if parnme in pst.parameter_data.index:\n            row = pst.parameter_data.loc[parnme, :]\n            lbnd,ubnd = row[\"parlbnd\"], row[\"parubnd\"]\n            if row[\"partrans\"].lower() == \"log\":\n                weight = 1.0 / (np.log10(ubnd) - np.log10(lbnd))\n            else:\n                weight = 1.0 / (ubnd - lbnd)\n            pst.prior_information.loc[parnme, \"weight\"] = weight\n        else:\n            print(\"prior information name does not correspond\" +\\\n                  \" to a parameter: \" + str(parnme))", "response": "sets regularization weights from parameter bounds"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef first_order_pearson_tikhonov(pst,cov,reset=True,abs_drop_tol=1.0e-3):\n    assert isinstance(cov,pyemu.Cov)\n    print(\"getting CC matrix\")\n    cc_mat = cov.get(pst.adj_par_names).to_pearson()\n    #print(pst.parameter_data.dtypes)\n    try:\n        ptrans = pst.parameter_data.partrans.apply(lambda x:x.decode()).to_dict()\n    except:\n        ptrans = pst.parameter_data.partrans.to_dict()\n    pi_num = pst.prior_information.shape[0] + 1\n    pilbl, obgnme, weight, equation = [], [], [], []\n    sadj_names = set(pst.adj_par_names)\n    print(\"processing\")\n    for i,iname in enumerate(cc_mat.row_names):\n        if iname not in sadj_names:\n            continue\n        for j,jname in enumerate(cc_mat.row_names[i+1:]):\n            if jname not in sadj_names:\n                continue\n            #print(i,iname,i+j+1,jname)\n            cc = cc_mat.x[i,j+i+1]\n            if cc < abs_drop_tol:\n                continue\n            pilbl.append(\"pcc_{0}\".format(pi_num))\n            iiname = str(iname)\n            if str(ptrans[iname]) == \"log\":\n                iiname = \"log(\"+iname+\")\"\n            jjname = str(jname)\n            if str(ptrans[jname]) == \"log\":\n                jjname = \"log(\"+jname+\")\"\n            equation.append(\"1.0 * {0} - 1.0 * {1} = 0.0\".\\\n                            format(iiname,jjname))\n            weight.append(cc)\n            obgnme.append(\"regul_cc\")\n            pi_num += 1\n    df = pd.DataFrame({\"pilbl\": pilbl,\"equation\": equation,\n                       \"obgnme\": obgnme,\"weight\": weight})\n    df.index = df.pilbl\n    if reset:\n        pst.prior_information = df\n    else:\n        pst.prior_information = pst.prior_information.append(df)\n\n    if pst.control_data.pestmode == \"estimation\":\n        pst.control_data.pestmode = \"regularization\"", "response": "setup preferred - difference regularization from a Pearson - Tikhonov covariance matrix."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake a template file just assuming a list of parameter names the values of which should be be listed in order in a model input file", "response": "def simple_tpl_from_pars(parnames, tplfilename='model.input.tpl'):\n    \"\"\"\n    Make a template file just assuming a list of parameter names the values of which should be\n    listed in order in a model input file\n    Args:\n        parnames: list of names from which to make a template file\n        tplfilename: filename for TPL file (default: model.input.tpl)\n\n    Returns:\n        writes a file <tplfilename> with each parameter name on a line\n\n    \"\"\"\n    with open(tplfilename, 'w') as ofp:\n        ofp.write('ptf ~\\n')\n        [ofp.write('~{0:^12}~\\n'.format(cname)) for cname in parnames]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreading the values names in obsnames in order writes an instruction file that assumes wanting to read the values names in obsnames in order", "response": "def simple_ins_from_obs(obsnames, insfilename='model.output.ins'):\n    \"\"\"\n    writes an instruction file that assumes wanting to read the values names in obsnames in order\n    one per line from a model output file\n    Args:\n        obsnames: list of obsnames to read in\n        insfilename: filename for INS file (default: model.output.ins)\n\n    Returns:\n        writes a file <insfilename> with each observation read off a line\n\n    \"\"\"\n    with open(insfilename, 'w') as ofp:\n        ofp.write('pif ~\\n')\n        [ofp.write('!{0}!\\n'.format(cob)) for cob in obsnames]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef pst_from_parnames_obsnames(parnames, obsnames,\n                               tplfilename='model.input.tpl', insfilename='model.output.ins'):\n    \"\"\"\n    Creates a Pst object from a list of parameter names and a list of observation names.\n    Default values are provided for the TPL and INS\n    Args:\n        parnames: list of names from which to make a template file\n        obsnames: list of obsnames to read in\n        tplfilename: filename for TPL file (default: model.input.tpl)\n        insfilename: filename for INS file (default: model.output.ins)\n\n    Returns:\n        Pst object\n\n    \"\"\"\n    simple_tpl_from_pars(parnames, tplfilename)\n    simple_ins_from_obs(obsnames, insfilename)\n\n    modelinputfilename = tplfilename.replace('.tpl','')\n    modeloutputfilename = insfilename.replace('.ins','')\n\n    return pyemu.Pst.from_io_files(tplfilename, modelinputfilename, insfilename, modeloutputfilename)", "response": "Create a Pst object from a list of parameter names and a list of observation names."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nstarts a group of slaves on the local machine", "response": "def start_slaves(slave_dir,exe_rel_path,pst_rel_path,num_slaves=None,slave_root=\"..\",\n                 port=4004,rel_path=None,local=True,cleanup=True,master_dir=None,\n                 verbose=False,silent_master=False):\n    \"\"\" start a group of pest(++) slaves on the local machine\n\n    Parameters\n    ----------\n    slave_dir :  str\n        the path to a complete set of input files\n    exe_rel_path : str\n        the relative path to the pest(++) executable from within the slave_dir\n    pst_rel_path : str\n        the relative path to the pst file from within the slave_dir\n    num_slaves : int\n        number of slaves to start. defaults to number of cores\n    slave_root : str\n        the root to make the new slave directories in\n    rel_path: str\n        the relative path to where pest(++) should be run from within the\n        slave_dir, defaults to the uppermost level of the slave dir\n    local: bool\n        flag for using \"localhost\" instead of hostname on slave command line\n    cleanup: bool\n        flag to remove slave directories once processes exit\n    master_dir: str\n        name of directory for master instance.  If master_dir\n        exists, then it will be removed.  If master_dir is None,\n        no master instance will be started\n    verbose : bool\n        flag to echo useful information to stdout\n\n    Note\n    ----\n    if all slaves (and optionally master) exit gracefully, then the slave\n    dirs will be removed unless cleanup is false\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    start 10 slaves using the directory \"template\" as the base case and\n    also start a master instance in a directory \"master\".\n\n    ``>>>pyemu.helpers.start_slaves(\"template\",\"pestpp\",\"pest.pst\",10,master_dir=\"master\")``\n\n    \"\"\"\n\n    warnings.warn(\"start_slaves has moved to pyemu.os_utils\",PyemuWarning)\n    pyemu.os_utils.start_slaves(slave_dir=slave_dir,exe_rel_path=exe_rel_path,pst_rel_path=pst_rel_path\n                      ,num_slaves=num_slaves,slave_root=slave_root,port=port,rel_path=rel_path,\n                      local=local,cleanup=cleanup,master_dir=master_dir,verbose=verbose,\n                      silent_master=silent_master)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads pars and obs from a specific run in a pest ++ serialized run storage file into pandas. DataFrame", "response": "def read_pestpp_runstorage(filename,irun=0,with_metadata=False):\n    \"\"\"read pars and obs from a specific run in a pest++ serialized run storage file into\n    pandas.DataFrame(s)\n\n    Parameters\n    ----------\n    filename : str\n        the name of the run storage file\n    irun : int\n        the run id to process. If 'all', then all runs are read. Default is 0\n    with_metadata : bool\n        flag to return run stats and info txt as well\n\n    Returns\n    -------\n    par_df : pandas.DataFrame\n        parameter information\n    obs_df : pandas.DataFrame\n        observation information\n    metadata : pandas.DataFrame\n        run status and info txt.\n\n    \"\"\"\n\n    header_dtype = np.dtype([(\"n_runs\",np.int64),(\"run_size\",np.int64),(\"p_name_size\",np.int64),\n                      (\"o_name_size\",np.int64)])\n\n    try:\n        irun = int(irun)\n    except:\n        if irun.lower() == \"all\":\n            irun = irun.lower()\n        else:\n            raise Exception(\"unrecognized 'irun': should be int or 'all', not '{0}'\".\n                            format(irun))\n    def status_str(r_status):\n        if r_status == 0:\n            return \"not completed\"\n        if r_status == 1:\n            return \"completed\"\n        if r_status == -100:\n            return \"canceled\"\n        else:\n            return \"failed\"\n    assert os.path.exists(filename)\n    f = open(filename,\"rb\")\n    header = np.fromfile(f,dtype=header_dtype,count=1)\n    p_name_size,o_name_size = header[\"p_name_size\"][0],header[\"o_name_size\"][0]\n    par_names = struct.unpack('{0}s'.format(p_name_size),\n                            f.read(p_name_size))[0].strip().lower().decode().split('\\0')[:-1]\n    obs_names = struct.unpack('{0}s'.format(o_name_size),\n                            f.read(o_name_size))[0].strip().lower().decode().split('\\0')[:-1]\n    n_runs,run_size = header[\"n_runs\"][0],header[\"run_size\"][0]\n    run_start = f.tell()\n\n    def _read_run(irun):\n        f.seek(run_start + (irun * run_size))\n        r_status = np.fromfile(f, dtype=np.int8, count=1)\n        info_txt = struct.unpack(\"41s\", f.read(41))[0].strip().lower().decode()\n        par_vals = np.fromfile(f, dtype=np.float64, count=len(par_names) + 1)[1:]\n        obs_vals = np.fromfile(f, dtype=np.float64, count=len(obs_names) + 1)[:-1]\n        par_df = pd.DataFrame({\"parnme\": par_names, \"parval1\": par_vals})\n\n        par_df.index = par_df.pop(\"parnme\")\n        obs_df = pd.DataFrame({\"obsnme\": obs_names, \"obsval\": obs_vals})\n        obs_df.index = obs_df.pop(\"obsnme\")\n        return r_status,info_txt,par_df,obs_df\n\n    if irun == \"all\":\n        par_dfs,obs_dfs = [],[]\n        r_stats, txts = [],[]\n        for irun in range(n_runs):\n            #print(irun)\n            r_status, info_txt, par_df, obs_df = _read_run(irun)\n            par_dfs.append(par_df)\n            obs_dfs.append(obs_df)\n            r_stats.append(r_status)\n            txts.append(info_txt)\n        par_df = pd.concat(par_dfs,axis=1).T\n        par_df.index = np.arange(n_runs)\n        obs_df = pd.concat(obs_dfs, axis=1).T\n        obs_df.index = np.arange(n_runs)\n        meta_data = pd.DataFrame({\"r_status\":r_stats,\"info_txt\":txts})\n        meta_data.loc[:,\"status\"] = meta_data.r_status.apply(status_str)\n\n    else:\n        assert irun <= n_runs\n        r_status,info_txt,par_df,obs_df = _read_run(irun)\n        meta_data = pd.DataFrame({\"r_status\": [r_status], \"info_txt\": [info_txt]})\n        meta_data.loc[:, \"status\"] = meta_data.r_status.apply(status_str)\n    f.close()\n    if with_metadata:\n        return par_df,obs_df,meta_data\n    else:\n        return par_df,obs_df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread pars and obs from a pest ++ serialized run storage file and return a pyemu. Jco object", "response": "def jco_from_pestpp_runstorage(rnj_filename,pst_filename):\n    \"\"\" read pars and obs from a pest++ serialized run storage file (e.g., .rnj) and return \n    pyemu.Jco.  This can then be passed to Jco.to_binary or Jco.to_coo, etc., to write jco file\n    in a subsequent step to avoid memory resource issues associated with very large problems.\n\n    Parameters\n    ----------\n    rnj_filename : str\n        the name of the run storage file\n    pst_filename : str\n        the name of the pst file\n\n    Returns\n    -------\n    jco_cols : pyemu.Jco\n\n\n    TODO\n    ----\n    Check rnj file contains transformed par vals (i.e., in model input space)\n\n    Currently only returns pyemu.Jco; doesn't write jco file due to memory\n    issues associated with very large problems\n\n    Compare rnj and jco from Freyberg problem in autotests\n\n    \"\"\"\n\n    header_dtype = np.dtype([(\"n_runs\",np.int64),(\"run_size\",np.int64),(\"p_name_size\",np.int64),\n                      (\"o_name_size\",np.int64)])\n\n    pst = pyemu.Pst(pst_filename)\n    par = pst.parameter_data\n    log_pars = set(par.loc[par.partrans==\"log\",\"parnme\"].values)\n    with open(rnj_filename,'rb') as f:\n        header = np.fromfile(f,dtype=header_dtype,count=1)\n        \n    try:\n        base_par,base_obs =  read_pestpp_runstorage(rnj_filename,irun=0)\n    except:\n        raise Exception(\"couldn't get base run...\")\n    par = par.loc[base_par.index,:]\n    li = base_par.index.map(lambda x: par.loc[x,\"partrans\"]==\"log\")\n    base_par.loc[li] = base_par.loc[li].apply(np.log10)\n    jco_cols = {}\n    for irun in range(1,int(header[\"n_runs\"])):\n        par_df,obs_df = read_pestpp_runstorage(rnj_filename,irun=irun)\n        par_df.loc[li] = par_df.loc[li].apply(np.log10)\n        obs_diff = base_obs - obs_df\n        par_diff = base_par - par_df\n        # check only one non-zero element per col(par)\n        if len(par_diff[par_diff.parval1 != 0]) > 1:\n            raise Exception(\"more than one par diff - looks like the file wasn't created during jco filling...\")\n        parnme = par_diff[par_diff.parval1 != 0].index[0]\n        parval = par_diff.parval1.loc[parnme]\n\n        # derivatives\n        jco_col = obs_diff / parval\n        # some tracking, checks\n        print(\"processing par {0}: {1}...\".format(irun, parnme))\n        print(\"%nzsens: {0}%...\".format((jco_col[abs(jco_col.obsval)>1e-8].shape[0] / jco_col.shape[0])*100.))\n\n        jco_cols[parnme] = jco_col.obsval\n\n    jco_cols = pd.DataFrame.from_records(data=jco_cols, index=list(obs_diff.index.values))\n\n    jco_cols = pyemu.Jco.from_dataframe(jco_cols)\n    \n    # write # memory considerations important here for very large matrices - break into chunks...\n    #jco_fnam = \"{0}\".format(filename[:-4]+\".jco\")\n    #jco_cols.to_binary(filename=jco_fnam, droptol=None, chunk=None)\n\n    return jco_cols"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngenerates a Pst instance from the template and instruction files.", "response": "def pst_from_io_files(tpl_files,in_files,ins_files,out_files,pst_filename=None):\n    \"\"\"generate a Pst instance from the model io files.  If 'inschek'\n    is available (either in the current directory or registered\n    with the system variables) and the model output files are available\n    , then the observation values in the control file will be set to the\n    values of the model-simulated equivalents to observations.  This can be\n    useful for testing\n\n    Parameters\n    ----------\n    tpl_files : list\n        list of pest template files\n    in_files : list\n        list of corresponding model input files\n    ins_files : list\n        list of pest instruction files\n    out_files: list\n        list of corresponding model output files\n    pst_filename : str\n        name of file to write the control file to.  If None,\n        control file is not written.  Default is None\n\n    Returns\n    -------\n    pst : pyemu.Pst\n\n\n    Example\n    -------\n    ``>>>import pyemu``\n\n    this will construct a new Pst instance from template and instruction files\n    found in the current directory, assuming that the naming convention follows\n    that listed in parse_dir_for_io_files()\n\n    ``>>>pst = pyemu.helpers.pst_from_io_files(*pyemu.helpers.parse_dir_for_io_files('.'))``\n\n    \"\"\"\n    par_names = set()\n    if not isinstance(tpl_files,list):\n        tpl_files = [tpl_files]\n    if not isinstance(in_files,list):\n        in_files = [in_files]\n    assert len(in_files) == len(tpl_files),\"len(in_files) != len(tpl_files)\"\n\n    for tpl_file in tpl_files:\n        assert os.path.exists(tpl_file),\"template file not found: \"+str(tpl_file)\n        #new_names = [name for name in pyemu.pst_utils.parse_tpl_file(tpl_file) if name not in par_names]\n        #par_names.extend(new_names)\n        new_names = pyemu.pst_utils.parse_tpl_file(tpl_file)\n        par_names.update(new_names)\n\n    if not isinstance(ins_files,list):\n        ins_files = [ins_files]\n    if not isinstance(out_files,list):\n        out_files = [out_files]\n    assert len(ins_files) == len(out_files),\"len(out_files) != len(out_files)\"\n\n\n    obs_names = []\n    for ins_file in ins_files:\n        assert os.path.exists(ins_file),\"instruction file not found: \"+str(ins_file)\n        obs_names.extend(pyemu.pst_utils.parse_ins_file(ins_file))\n\n    new_pst = pyemu.pst_utils.generic_pst(list(par_names),list(obs_names))\n\n    new_pst.template_files = tpl_files\n    new_pst.input_files = in_files\n    new_pst.instruction_files = ins_files\n    new_pst.output_files = out_files\n\n    #try to run inschek to find the observtion values\n    pyemu.pst_utils.try_run_inschek(new_pst)\n\n    if pst_filename:\n        new_pst.write(pst_filename,update_regul=True)\n    return new_pst"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef apply_array_pars(arr_par_file=\"arr_pars.csv\"):\n    df = pd.read_csv(arr_par_file)\n    # for fname in df.model_file:\n    #     try:\n    #         os.remove(fname)\n    #     except:\n    #         print(\"error removing mult array:{0}\".format(fname))\n\n    if 'pp_file' in df.columns:\n        for pp_file,fac_file,mlt_file in zip(df.pp_file,df.fac_file,df.mlt_file):\n            if pd.isnull(pp_file):\n                continue\n            pyemu.geostats.fac2real(pp_file=pp_file,factors_file=fac_file,\n                                    out_file=mlt_file,lower_lim=1.0e-10)\n\n    for model_file in df.model_file.unique():\n        # find all mults that need to be applied to this array\n        df_mf = df.loc[df.model_file==model_file,:]\n        results = []\n        org_file = df_mf.org_file.unique()\n        if org_file.shape[0] != 1:\n            raise Exception(\"wrong number of org_files for {0}\".\n                            format(model_file))\n        org_arr = np.loadtxt(org_file[0])\n\n        for mlt in df_mf.mlt_file:\n            org_arr *= np.loadtxt(mlt)\n        if \"upper_bound\" in df.columns:\n            ub_vals = df_mf.upper_bound.value_counts().dropna().to_dict()\n            if len(ub_vals) == 0:\n                pass\n            elif len(ub_vals) > 1:\n                raise Exception(\"different upper bound values for {0}\".format(org_file))\n            else:\n                ub = list(ub_vals.keys())[0]\n                org_arr[org_arr>ub] = ub\n        if \"lower_bound\" in df.columns:\n            lb_vals = df_mf.lower_bound.value_counts().dropna().to_dict()\n            if len(lb_vals) == 0:\n                pass\n            elif len(lb_vals) > 1:\n                raise Exception(\"different lower bound values for {0}\".format(org_file))\n            else:\n                lb = list(lb_vals.keys())[0]\n                org_arr[org_arr < lb] = lb\n\n        np.savetxt(model_file,np.atleast_2d(org_arr),fmt=\"%15.6E\",delimiter='')", "response": "a function to apply array - based multipliers to a single array - based model"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef apply_list_pars():\n    temp_file = \"temporal_list_pars.dat\"\n    spat_file = \"spatial_list_pars.dat\"\n\n    temp_df,spat_df = None,None\n    if os.path.exists(temp_file):\n        temp_df = pd.read_csv(temp_file, delim_whitespace=True)\n        temp_df.loc[:,\"split_filename\"] = temp_df.filename.apply(lambda x: os.path.split(x)[-1])\n        org_dir = temp_df.list_org.iloc[0]\n        model_ext_path = temp_df.model_ext_path.iloc[0]\n    if os.path.exists(spat_file):\n        spat_df = pd.read_csv(spat_file, delim_whitespace=True)\n        spat_df.loc[:,\"split_filename\"] = spat_df.filename.apply(lambda x: os.path.split(x)[-1])\n        mlt_dir = spat_df.list_mlt.iloc[0]\n        org_dir = spat_df.list_org.iloc[0]\n        model_ext_path = spat_df.model_ext_path.iloc[0]\n    if temp_df is None and spat_df is None:\n        raise Exception(\"apply_list_pars() - no key dfs found, nothing to do...\")\n    # load the spatial mult dfs\n    sp_mlts = {}\n    if spat_df is not None:\n\n        for f in os.listdir(mlt_dir):\n            pak = f.split(\".\")[0].lower()\n            df = pd.read_csv(os.path.join(mlt_dir,f),index_col=0, delim_whitespace=True)\n            #if pak != 'hfb6':\n            df.index = df.apply(lambda x: \"{0:02.0f}{1:04.0f}{2:04.0f}\".format(x.k,x.i,x.j),axis=1)\n            # else:\n            #     df.index = df.apply(lambda x: \"{0:02.0f}{1:04.0f}{2:04.0f}{2:04.0f}{2:04.0f}\".format(x.k, x.irow1, x.icol1,\n            #                                                                      x.irow2, x.icol2), axis = 1)\n            if pak in sp_mlts.keys():\n                raise Exception(\"duplicate multplier csv for pak {0}\".format(pak))\n            if df.shape[0] == 0:\n                raise Exception(\"empty dataframe for spatial list file: {0}\".format(f))\n            sp_mlts[pak] = df\n\n    org_files = os.listdir(org_dir)\n    #for fname in df.filename.unique():\n    for fname in org_files:\n        # need to get the PAK name to handle stupid horrible expceptions for HFB...\n        # try:\n        #     pakspat = sum([True if fname in i else False for i in spat_df.filename])\n        #     if pakspat:\n        #         pak = spat_df.loc[spat_df.filename.str.contains(fname)].pak.values[0]\n        #     else:\n        #         pak = 'notHFB'\n        # except:\n        #     pak = \"notHFB\"\n\n        names = None\n        if temp_df is not None and fname in temp_df.split_filename.values:\n            temp_df_fname = temp_df.loc[temp_df.split_filename==fname,:]\n            if temp_df_fname.shape[0] > 0:\n                names = temp_df_fname.dtype_names.iloc[0].split(',')\n        if spat_df is not None and fname in spat_df.split_filename.values:\n            spat_df_fname = spat_df.loc[spat_df.split_filename == fname, :]\n            if spat_df_fname.shape[0] > 0:\n                names = spat_df_fname.dtype_names.iloc[0].split(',')\n        if names is not None:\n\n            df_list = pd.read_csv(os.path.join(org_dir, fname),\n                                  delim_whitespace=True, header=None, names=names)\n            df_list.loc[:, \"idx\"] = df_list.apply(lambda x: \"{0:02.0f}{1:04.0f}{2:04.0f}\".format(x.k-1, x.i-1, x.j-1), axis=1)\n\n\n            df_list.index = df_list.idx\n            pak_name = fname.split('_')[0].lower()\n            if pak_name in sp_mlts:\n                mlt_df = sp_mlts[pak_name]\n                mlt_df_ri = mlt_df.reindex(df_list.index)\n                for col in df_list.columns:\n                    if col in [\"k\",\"i\",\"j\",\"inode\",'irow1','icol1','irow2','icol2','idx']:\n                        continue\n                    if col in mlt_df.columns:\n                       # print(mlt_df.loc[mlt_df.index.duplicated(),:])\n                       # print(df_list.loc[df_list.index.duplicated(),:])\n                        df_list.loc[:,col] *= mlt_df_ri.loc[:,col].values\n\n            if temp_df is not None and fname in temp_df.split_filename.values:\n                temp_df_fname = temp_df.loc[temp_df.split_filename == fname, :]\n                for col,val in zip(temp_df_fname.col,temp_df_fname.val):\n                     df_list.loc[:,col] *= val\n            fmts = ''\n            for name in names:\n                if name in [\"i\",\"j\",\"k\",\"inode\",'irow1','icol1','irow2','icol2']:\n                    fmts += \" %9d\"\n                else:\n                    fmts += \" %9G\"\n        np.savetxt(os.path.join(model_ext_path, fname), df_list.loc[:, names].values, fmt=fmts)", "response": "a function to apply boundary condition multiplier parameters to a single object"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a constant template file", "response": "def write_const_tpl(name, tpl_file, suffix, zn_array=None, shape=None, spatial_reference=None,\n                    longnames=False):\n    \"\"\" write a constant (uniform) template file\n\n    Parameters\n    ----------\n    name : str\n        the base parameter name\n    tpl_file : str\n        the template file to write - include path\n    zn_array : numpy.ndarray\n        an array used to skip inactive cells\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        a dataframe with parameter information\n\n    \"\"\"\n\n\n    if shape is None and zn_array is None:\n        raise Exception(\"must pass either zn_array or shape\")\n    elif shape is None:\n        shape = zn_array.shape\n\n    parnme = []\n    with open(tpl_file, 'w') as f:\n        f.write(\"ptf ~\\n\")\n        for i in range(shape[0]):\n            for j in range(shape[1]):\n                if zn_array is not None and zn_array[i, j] < 1:\n                    pname = \" 1.0  \"\n                else:\n                    if longnames:\n                        pname = \"const_{0}_{1}\".format(name,suffix)\n                    else:\n                        pname = \"{0}{1}\".format(name, suffix)\n                        if len(pname) > 12:\n                            raise(\"zone pname too long:{0}\". \\\n                                               format(pname))\n                    parnme.append(pname)\n                    pname = \" ~   {0}    ~\".format(pname)\n                f.write(pname)\n            f.write(\"\\n\")\n    df = pd.DataFrame({\"parnme\": parnme}, index=parnme)\n    # df.loc[:,\"pargp\"] = \"{0}{1}\".format(self.cn_suffixname)\n    df.loc[:, \"pargp\"] = \"{0}_{1}\".format(name, suffix.replace('_', ''))\n    df.loc[:, \"tpl\"] = tpl_file\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_grid_tpl(name, tpl_file, suffix, zn_array=None, shape=None,\n                   spatial_reference=None,longnames=False):\n    \"\"\" write a grid-based template file\n    Parameters\n    ----------\n    name : str\n        the base parameter name\n    tpl_file : str\n        the template file to write - include path\n    zn_array : numpy.ndarray\n        an array used to skip inactive cells\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        a dataframe with parameter information\n\n    \"\"\"\n\n    if shape is None and zn_array is None:\n        raise Exception(\"must pass either zn_array or shape\")\n    elif shape is None:\n        shape = zn_array.shape\n\n    parnme, x, y = [], [], []\n    with open(tpl_file, 'w') as f:\n        f.write(\"ptf ~\\n\")\n        for i in range(shape[0]):\n            for j in range(shape[1]):\n                if zn_array is not None and zn_array[i, j] < 1:\n                    pname = ' 1.0 '\n                else:\n                    if longnames:\n                        pname = \"{0}_i:{0}_j:{1}_{2}\".format(name,i,j,suffix)\n                        if spatial_reference is not None:\n                            pname += \"_x:{0:10.2E}_y:{1:10.2E}\".format(sr.xcentergrid[i,j],\n                                                                       sr.ycentergrid[i,j])\n                    else:\n                        pname = \"{0}{1:03d}{2:03d}\".format(name, i, j)\n                        if len(pname) > 12:\n                            raise(\"grid pname too long:{0}\". \\\n                                               format(pname))\n                    parnme.append(pname)\n                    pname = ' ~     {0}   ~ '.format(pname)\n                    if spatial_reference is not None:\n                        x.append(spatial_reference.xcentergrid[i, j])\n                        y.append(spatial_reference.ycentergrid[i, j])\n\n                f.write(pname)\n            f.write(\"\\n\")\n    df = pd.DataFrame({\"parnme\": parnme}, index=parnme)\n    if spatial_reference is not None:\n        df.loc[:,'x'] = x\n        df.loc[:,'y'] = y\n    df.loc[:, \"pargp\"] = \"{0}{1}\".format(suffix.replace('_', ''), name)\n    df.loc[:, \"tpl\"] = tpl_file\n    return df", "response": "write a grid - based template file"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget an x and y numpy. ndarray that spans the + / - 4gaussian distribution with a given mean and standard deviation range", "response": "def gaussian_distribution(mean, stdev, num_pts=50):\n    \"\"\" get an x and y numpy.ndarray that spans the +/- 4\n    standard deviation range of a gaussian distribution with\n    a given mean and standard deviation. useful for plotting\n\n    Parameters\n    ----------\n    mean : float\n        the mean of the distribution\n    stdev : float\n        the standard deviation of the distribution\n    num_pts : int\n        the number of points in the returned ndarrays.\n        Default is 50\n\n    Returns\n    -------\n    x : numpy.ndarray\n        the x-values of the distribution\n    y : numpy.ndarray\n        the y-values of the distribution\n\n    \"\"\"\n    warnings.warn(\"pyemu.helpers.gaussian_distribution() has moved to plot_utils\",PyemuWarning)\n    from pyemu import plot_utils\n    return plot_utils.gaussian_distribution(mean=mean,stdev=stdev,num_pts=num_pts)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_df_tpl(filename,df,sep=',',tpl_marker='~',**kwargs):\n    with open(filename,'w') as f:\n        f.write(\"ptf {0}\\n\".format(tpl_marker))\n        f.flush()\n        df.to_csv(f,sep=sep,mode='a',**kwargs)", "response": "function write a pandas dataframe to a template file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_hfb_pars(self):\n        if self.m.hfb6 is None:\n            self.logger.lraise(\"couldn't find hfb pak\")\n        tpl_file,df = pyemu.gw_utils.write_hfb_template(self.m)\n\n        self.in_files.append(os.path.split(tpl_file.replace(\".tpl\",\"\"))[-1])\n        self.tpl_files.append(os.path.split(tpl_file)[-1])\n        self.par_dfs[\"hfb\"] = df", "response": "setup non - mult parameters for hfb"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef setup_model(self,model,org_model_ws,new_model_ws):\n        split_new_mws = [i for i in os.path.split(new_model_ws) if len(i) > 0]\n        if len(split_new_mws) != 1:\n            self.logger.lraise(\"new_model_ws can only be 1 folder-level deep:{0}\".\n                               format(str(split_new_mws)))\n\n        if isinstance(model,str):\n            self.log(\"loading flopy model\")\n            try:\n                import flopy\n            except:\n                raise Exception(\"from_flopy_model() requires flopy\")\n            # prepare the flopy model\n            self.org_model_ws = org_model_ws\n            self.new_model_ws = new_model_ws\n            self.m = flopy.modflow.Modflow.load(model,model_ws=org_model_ws,\n                                                check=False,verbose=True,forgive=False)\n            self.log(\"loading flopy model\")\n        else:\n            self.m = model\n            self.org_model_ws = str(self.m.model_ws)\n            self.new_model_ws = new_model_ws\n\n        self.log(\"updating model attributes\")\n        self.m.array_free_format = True\n        self.m.free_format_input = True\n        self.m.external_path = '.'\n        self.log(\"updating model attributes\")\n        if os.path.exists(new_model_ws):\n            if not self.remove_existing:\n                self.logger.lraise(\"'new_model_ws' already exists\")\n            else:\n                self.logger.warn(\"removing existing 'new_model_ws\")\n                shutil.rmtree(new_model_ws,onerror=pyemu.os_utils.remove_readonly)\n                time.sleep(1)\n        self.m.change_model_ws(new_model_ws,reset_external=True)\n        self.m.exe_name = self.m.exe_name.replace(\".exe\",'')\n        self.m.exe = self.m.version\n        self.log(\"writing new modflow input files\")\n        self.m.write_input()\n        self.log(\"writing new modflow input files\")", "response": "setup the modflow instance for use with multipler parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the latest count for a certain parameter type", "response": "def get_count(self,name):\n        \"\"\" get the latest counter for a certain parameter type.\n\n        Parameters\n        ----------\n        name : str\n            the parameter type\n\n        Returns\n        -------\n        count : int\n            the latest count for a parameter type\n\n        Note\n        ----\n        calling this function increments the counter for the passed\n        parameter type\n\n        \"\"\"\n        if name not in self.mlt_counter:\n            self.mlt_counter[name] = 1\n            c = 0\n        else:\n            c = self.mlt_counter[name]\n            self.mlt_counter[name] += 1\n            #print(name,c)\n        return c"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef prep_mlt_arrays(self):\n        par_props = [self.pp_props,self.grid_props,\n                         self.zone_props,self.const_props,\n                     self.kl_props]\n        par_suffixs = [self.pp_suffix,self.gr_suffix,\n                       self.zn_suffix,self.cn_suffix,\n                       self.kl_suffix]\n\n        # Need to remove props and suffixes for which no info was provided (e.g. still None)\n        del_idx = []\n        for i,cp in enumerate(par_props):\n            if cp is None:\n                del_idx.append(i)\n        for i in del_idx[::-1]:\n            del(par_props[i])\n            del(par_suffixs[i])\n\n        mlt_dfs = []\n        for par_prop,suffix in zip(par_props,par_suffixs):\n            if len(par_prop) == 2:\n                if not isinstance(par_prop[0],list):\n                    par_prop = [par_prop]\n            if len(par_prop) == 0:\n                continue\n            for pakattr,k_org in par_prop:\n                attr_name = pakattr.split('.')[1]\n                pak,attr = self.parse_pakattr(pakattr)\n                ks = np.arange(self.m.nlay)\n                if isinstance(attr,flopy.utils.Transient2d):\n                    ks = np.arange(self.m.nper)\n                try:\n                    k_parse = self.parse_k(k_org,ks)\n                except Exception as e:\n                    self.logger.lraise(\"error parsing k {0}:{1}\".\n                                       format(k_org,str(e)))\n                org,mlt,mod,layer = [],[],[],[]\n                c = self.get_count(attr_name)\n                mlt_prefix = \"{0}{1}\".format(attr_name,c)\n                mlt_name = os.path.join(self.arr_mlt,\"{0}.dat{1}\"\n                                        .format(mlt_prefix,suffix))\n                for k in k_parse:\n                    # horrible kludge to avoid passing int64 to flopy\n                    # this gift may give again...\n                    if type(k) is np.int64:\n                        k = int(k)\n                    if isinstance(attr,flopy.utils.Util2d):\n                        fname = self.write_u2d(attr)\n\n                        layer.append(k)\n                    elif isinstance(attr,flopy.utils.Util3d):\n                        fname = self.write_u2d(attr[k])\n                        layer.append(k)\n                    elif isinstance(attr,flopy.utils.Transient2d):\n                        fname = self.write_u2d(attr.transient_2ds[k])\n                        layer.append(0) #big assumption here\n                    mod.append(os.path.join(self.m.external_path,fname))\n                    mlt.append(mlt_name)\n                    org.append(os.path.join(self.arr_org,fname))\n                df = pd.DataFrame({\"org_file\":org,\"mlt_file\":mlt,\"model_file\":mod,\"layer\":layer})\n                df.loc[:,\"suffix\"] = suffix\n                df.loc[:,\"prefix\"] = mlt_prefix\n                df.loc[:,\"attr_name\"] = attr_name\n                mlt_dfs.append(df)\n        if len(mlt_dfs) > 0:\n            mlt_df = pd.concat(mlt_dfs,ignore_index=True)\n            return mlt_df", "response": "Prepare multipler arrays. Copies existing model input arrays and writes generic arrays."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef write_u2d(self, u2d):\n        filename = os.path.split(u2d.filename)[-1]\n        np.savetxt(os.path.join(self.m.model_ws,self.arr_org,filename),\n                   u2d.array,fmt=\"%15.6E\")\n        return filename", "response": "write a flopy. utils. Util2D instance to an ASCII text file using the\n            Util2D filename"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef write_const_tpl(self,name,tpl_file,zn_array):\n        parnme = []\n        with open(os.path.join(self.m.model_ws,tpl_file),'w') as f:\n            f.write(\"ptf ~\\n\")\n            for i in range(self.m.nrow):\n                for j in range(self.m.ncol):\n                    if zn_array[i,j] < 1:\n                        pname = \" 1.0  \"\n                    else:\n                        pname = \"{0}{1}\".format(name,self.cn_suffix)\n                        if len(pname) > 12:\n                            self.logger.lraise(\"zone pname too long:{0}\".\\\n                                               format(pname))\n                        parnme.append(pname)\n                        pname = \" ~   {0}    ~\".format(pname)\n                    f.write(pname)\n                f.write(\"\\n\")\n        df = pd.DataFrame({\"parnme\":parnme},index=parnme)\n        #df.loc[:,\"pargp\"] = \"{0}{1}\".format(self.cn_suffixname)\n        df.loc[:,\"pargp\"] = \"{0}_{1}\".format(name,self.cn_suffix.replace('_',''))\n        df.loc[:,\"tpl\"] = tpl_file\n        return df", "response": "write a template file a for a constant multiplier parameter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nwriting a template file a for grid - based multiplier parameters", "response": "def write_grid_tpl(self,name,tpl_file,zn_array):\n        \"\"\" write a template file a for grid-based multiplier parameters\n\n        Parameters\n        ----------\n        name : str\n            the base parameter name\n        tpl_file : str\n            the template file to write\n        zn_array : numpy.ndarray\n            an array used to skip inactive cells\n\n        Returns\n        -------\n        df : pandas.DataFrame\n            a dataframe with parameter information\n\n        \"\"\"\n        parnme,x,y = [],[],[]\n        with open(os.path.join(self.m.model_ws,tpl_file),'w') as f:\n            f.write(\"ptf ~\\n\")\n            for i in range(self.m.nrow):\n                for j in range(self.m.ncol):\n                    if zn_array[i,j] < 1:\n                        pname = ' 1.0 '\n                    else:\n                        pname = \"{0}{1:03d}{2:03d}\".format(name,i,j)\n                        if len(pname) > 12:\n                            self.logger.lraise(\"grid pname too long:{0}\".\\\n                                               format(pname))\n                        parnme.append(pname)\n                        pname = ' ~     {0}   ~ '.format(pname)\n                        x.append(self.m.sr.xcentergrid[i,j])\n                        y.append(self.m.sr.ycentergrid[i,j])\n                    f.write(pname)\n                f.write(\"\\n\")\n        df = pd.DataFrame({\"parnme\":parnme,\"x\":x,\"y\":y},index=parnme)\n        df.loc[:,\"pargp\"] = \"{0}{1}\".format(self.gr_suffix.replace('_',''),name)\n        df.loc[:,\"tpl\"] = tpl_file\n        return df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef grid_prep(self):\n        if len(self.grid_props) == 0:\n            return\n\n        if self.grid_geostruct is None:\n            self.logger.warn(\"grid_geostruct is None,\"\\\n                  \" using ExpVario with contribution=1 and a=(max(delc,delr)*10\")\n            dist = 10 * float(max(self.m.dis.delr.array.max(),\n                                           self.m.dis.delc.array.max()))\n            v = pyemu.geostats.ExpVario(contribution=1.0,a=dist)\n            self.grid_geostruct = pyemu.geostats.GeoStruct(variograms=v)", "response": "prepare grid - based parameterizations\n            = > obj. id"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nprepare pilot point based parameterizations", "response": "def pp_prep(self, mlt_df):\n        \"\"\" prepare pilot point based parameterizations\n\n        Parameters\n        ----------\n        mlt_df : pandas.DataFrame\n            a dataframe with multiplier array information\n\n        Note\n        ----\n        calls pyemu.pp_utils.setup_pilot_points_grid()\n\n\n        \"\"\"\n        if len(self.pp_props) == 0:\n            return\n        if self.pp_space is None:\n            self.logger.warn(\"pp_space is None, using 10...\\n\")\n            self.pp_space=10\n        if self.pp_geostruct is None:\n            self.logger.warn(\"pp_geostruct is None,\"\\\n                  \" using ExpVario with contribution=1 and a=(pp_space*max(delr,delc))\")\n            pp_dist = self.pp_space * float(max(self.m.dis.delr.array.max(),\n                                           self.m.dis.delc.array.max()))\n            v = pyemu.geostats.ExpVario(contribution=1.0,a=pp_dist)\n            self.pp_geostruct = pyemu.geostats.GeoStruct(variograms=v)\n\n        pp_df = mlt_df.loc[mlt_df.suffix==self.pp_suffix,:]\n        layers = pp_df.layer.unique()\n        pp_dict = {l:list(pp_df.loc[pp_df.layer==l,\"prefix\"].unique()) for l in layers}\n        # big assumption here - if prefix is listed more than once, use the lowest layer index\n        for i,l in enumerate(layers):\n            p = set(pp_dict[l])\n            for ll in layers[i+1:]:\n                pp = set(pp_dict[ll])\n                d = pp - p\n                pp_dict[ll] = list(d)\n\n\n        pp_array_file = {p:m for p,m in zip(pp_df.prefix,pp_df.mlt_file)}\n        self.logger.statement(\"pp_dict: {0}\".format(str(pp_dict)))\n\n        self.log(\"calling setup_pilot_point_grid()\")\n        if self.use_pp_zones:\n            # check if k_zone_dict is a dictionary of dictionaries\n            if np.all([isinstance(v, dict) for v in self.k_zone_dict.values()]):\n                ib = {p.split('.')[-1]: k_dict for p, k_dict in self.k_zone_dict.items()}\n                for attr in pp_df.attr_name.unique():\n                    if attr not in [p.split('.')[-1] for p in ib.keys()]:\n                        if 'general_zn' not in ib.keys():\n                            warnings.warn(\"Dictionary of dictionaries passed as zones, {0} not in keys: {1}. \"\n                                          \"Will use ibound for zones\".format(attr, ib.keys()), PyemuWarning)\n                        else:\n                            self.logger.statement(\n                                \"Dictionary of dictionaries passed as pp zones, \"\n                                \"using 'general_zn' for {0}\".format(attr))\n                    if 'general_zn' not in ib.keys():\n                        ib['general_zn'] = {k: self.m.bas6.ibound[k].array for k in range(self.m.nlay)}\n            else:\n                ib = {'general_zn': self.k_zone_dict}\n        else:\n            ib = {}\n            for k in range(self.m.nlay):\n                a = self.m.bas6.ibound[k].array.copy()\n                a[a>0] = 1\n                ib[k] = a\n            for k,i in ib.items():\n                if np.any(i<0):\n                    u,c = np.unique(i[i>0], return_counts=True)\n                    counts = dict(zip(u,c))\n                    mx = -1.0e+10\n                    imx = None\n                    for u,c in counts.items():\n                        if c > mx:\n                            mx = c\n                            imx = u\n                    self.logger.warn(\"resetting negative ibound values for PP zone\"+ \\\n                                     \"array in layer {0} : {1}\".format(k+1,u))\n                    i[i<0] = u\n            ib = {'general_zn': ib}\n        pp_df = pyemu.pp_utils.setup_pilotpoints_grid(self.m,\n                                         ibound=ib,\n                                         use_ibound_zones=self.use_pp_zones,\n                                         prefix_dict=pp_dict,\n                                         every_n_cell=self.pp_space,\n                                         pp_dir=self.m.model_ws,\n                                         tpl_dir=self.m.model_ws,\n                                         shapename=os.path.join(\n                                                 self.m.model_ws,\"pp.shp\"))\n        self.logger.statement(\"{0} pilot point parameters created\".\n                              format(pp_df.shape[0]))\n        self.logger.statement(\"pilot point 'pargp':{0}\".\n                              format(','.join(pp_df.pargp.unique())))\n        self.log(\"calling setup_pilot_point_grid()\")\n\n        # calc factors for each layer\n        pargp = pp_df.pargp.unique()\n        pp_dfs_k = {}\n        fac_files = {}\n        pp_processed = set()\n        pp_df.loc[:,\"fac_file\"] = np.NaN\n        for pg in pargp:\n            ks = pp_df.loc[pp_df.pargp==pg,\"k\"].unique()\n            if len(ks) == 0:\n                self.logger.lraise(\"something is wrong in fac calcs for par group {0}\".format(pg))\n            if len(ks) == 1:\n                if np.all([isinstance(v, dict) for v in ib.values()]):  # check is dict of dicts\n                    if np.any([pg.startswith(p) for p in ib.keys()]):\n                        p = next(p for p in ib.keys() if pg.startswith(p))\n                        # get dict relating to parameter prefix\n                        ib_k = ib[p][ks[0]]\n                    else:\n                        p = 'general_zn'\n                        ib_k = ib[p][ks[0]]\n                else:\n                    ib_k = ib[ks[0]]\n            if len(ks) != 1:  # TODO\n                #self.logger.lraise(\"something is wrong in fac calcs for par group {0}\".format(pg))\n                self.logger.warn(\"multiple k values for {0},forming composite zone array...\".format(pg))\n                ib_k = np.zeros((self.m.nrow,self.m.ncol))\n                for k in ks:\n                    t = ib[k].copy()\n                    t[t<1] = 0\n                    ib_k[t>0] = t[t>0]\n            k = int(ks[0])\n            kattr_id = \"{}_{}\".format(k, p)\n            kp_id = \"{}_{}\".format(k, pg)\n            if kp_id not in pp_dfs_k.keys():\n                self.log(\"calculating factors for p={0}, k={1}\".format(pg, k))\n                fac_file = os.path.join(self.m.model_ws, \"pp_k{0}.fac\".format(kattr_id))\n                var_file = fac_file.replace(\"{0}.fac\", \".var.dat\")\n                pp_df_k = pp_df.loc[pp_df.pargp == pg]\n                if kattr_id not in pp_processed:\n                    self.logger.statement(\"saving krige variance file:{0}\"\n                                          .format(var_file))\n                    self.logger.statement(\"saving krige factors file:{0}\"\n                                          .format(fac_file))\n                    ok_pp = pyemu.geostats.OrdinaryKrige(self.pp_geostruct, pp_df_k)\n                    ok_pp.calc_factors_grid(self.m.sr, var_filename=var_file, zone_array=ib_k)\n                    ok_pp.to_grid_factors_file(fac_file)\n                    pp_processed.add(kattr_id)\n                fac_files[kp_id] = fac_file\n                self.log(\"calculating factors for p={0}, k={1}\".format(pg, k))\n                pp_dfs_k[kp_id] = pp_df_k\n\n        for kp_id, fac_file in fac_files.items():\n            k = int(kp_id.split('_')[0])\n            pp_prefix = kp_id.split('_', 1)[-1]\n            #pp_files = pp_df.pp_filename.unique()\n            fac_file = os.path.split(fac_file)[-1]\n            # pp_prefixes = pp_dict[k]\n            # for pp_prefix in pp_prefixes:\n            self.log(\"processing pp_prefix:{0}\".format(pp_prefix))\n            if pp_prefix not in pp_array_file.keys():\n                self.logger.lraise(\"{0} not in self.pp_array_file.keys()\".\n                                   format(pp_prefix,','.\n                                          join(pp_array_file.keys())))\n\n\n            out_file = os.path.join(self.arr_mlt,os.path.split(pp_array_file[pp_prefix])[-1])\n\n            pp_files = pp_df.loc[pp_df.pp_filename.apply(lambda x: pp_prefix in x),\"pp_filename\"]\n            if pp_files.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of pp_files found:{0}\".format(','.join(pp_files)))\n            pp_file = os.path.split(pp_files.iloc[0])[-1]\n            pp_df.loc[pp_df.pargp==pp_prefix,\"fac_file\"] = fac_file\n            pp_df.loc[pp_df.pargp==pp_prefix,\"pp_file\"] = pp_file\n            pp_df.loc[pp_df.pargp==pp_prefix,\"out_file\"] = out_file\n\n        pp_df.loc[:,\"pargp\"] = pp_df.pargp.apply(lambda x: \"pp_{0}\".format(x))\n        out_files = mlt_df.loc[mlt_df.mlt_file.\n                    apply(lambda x: x.endswith(self.pp_suffix)),\"mlt_file\"]\n        #mlt_df.loc[:,\"fac_file\"] = np.NaN\n        #mlt_df.loc[:,\"pp_file\"] = np.NaN\n        for out_file in out_files:\n            pp_df_pf = pp_df.loc[pp_df.out_file==out_file,:]\n            fac_files = pp_df_pf.fac_file\n            if fac_files.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of fac files:{0}\".format(str(fac_files.unique())))\n            fac_file = fac_files.iloc[0]\n            pp_files = pp_df_pf.pp_file\n            if pp_files.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of pp files:{0}\".format(str(pp_files.unique())))\n            pp_file = pp_files.iloc[0]\n            mlt_df.loc[mlt_df.mlt_file==out_file,\"fac_file\"] = fac_file\n            mlt_df.loc[mlt_df.mlt_file==out_file,\"pp_file\"] = pp_file\n        self.par_dfs[self.pp_suffix] = pp_df\n\n        mlt_df.loc[mlt_df.suffix==self.pp_suffix,\"tpl_file\"] = np.NaN"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nprepares KL based parameterizations for a specific set of attributes.", "response": "def kl_prep(self,mlt_df):\n        \"\"\" prepare KL based parameterizations\n\n        Parameters\n        ----------\n        mlt_df : pandas.DataFrame\n            a dataframe with multiplier array information\n\n        Note\n        ----\n        calls pyemu.helpers.setup_kl()\n\n\n        \"\"\"\n        if len(self.kl_props) == 0:\n            return\n\n        if self.kl_geostruct is None:\n            self.logger.warn(\"kl_geostruct is None,\"\\\n                  \" using ExpVario with contribution=1 and a=(10.0*max(delr,delc))\")\n            kl_dist = 10.0 * float(max(self.m.dis.delr.array.max(),\n                                           self.m.dis.delc.array.max()))\n            v = pyemu.geostats.ExpVario(contribution=1.0,a=kl_dist)\n            self.kl_geostruct = pyemu.geostats.GeoStruct(variograms=v)\n\n        kl_df = mlt_df.loc[mlt_df.suffix==self.kl_suffix,:]\n        layers = kl_df.layer.unique()\n        #kl_dict = {l:list(kl_df.loc[kl_df.layer==l,\"prefix\"].unique()) for l in layers}\n        # big assumption here - if prefix is listed more than once, use the lowest layer index\n        #for i,l in enumerate(layers):\n        #    p = set(kl_dict[l])\n        #    for ll in layers[i+1:]:\n        #        pp = set(kl_dict[ll])\n        #        d = pp - p\n        #        kl_dict[ll] = list(d)\n        kl_prefix = list(kl_df.loc[:,\"prefix\"])\n\n        kl_array_file = {p:m for p,m in zip(kl_df.prefix,kl_df.mlt_file)}\n        self.logger.statement(\"kl_prefix: {0}\".format(str(kl_prefix)))\n\n        fac_file = os.path.join(self.m.model_ws, \"kl.fac\")\n\n        self.log(\"calling kl_setup() with factors file {0}\".format(fac_file))\n\n        kl_df = kl_setup(self.kl_num_eig,self.m.sr,self.kl_geostruct,kl_prefix,\n                         factors_file=fac_file,basis_file=fac_file+\".basis.jcb\",\n                         tpl_dir=self.m.model_ws)\n        self.logger.statement(\"{0} kl parameters created\".\n                              format(kl_df.shape[0]))\n        self.logger.statement(\"kl 'pargp':{0}\".\n                              format(','.join(kl_df.pargp.unique())))\n\n        self.log(\"calling kl_setup() with factors file {0}\".format(fac_file))\n        kl_mlt_df = mlt_df.loc[mlt_df.suffix==self.kl_suffix]\n        for prefix in kl_df.prefix.unique():\n            prefix_df = kl_df.loc[kl_df.prefix==prefix,:]\n            in_file = os.path.split(prefix_df.loc[:,\"in_file\"].iloc[0])[-1]\n            assert prefix in mlt_df.prefix.values,\"{0}:{1}\".format(prefix,mlt_df.prefix)\n            mlt_df.loc[mlt_df.prefix==prefix,\"pp_file\"] = in_file\n            mlt_df.loc[mlt_df.prefix==prefix,\"fac_file\"] = os.path.split(fac_file)[-1]\n\n        print(kl_mlt_df)\n        mlt_df.loc[mlt_df.suffix == self.kl_suffix, \"tpl_file\"] = np.NaN\n        self.par_dfs[self.kl_suffix] = kl_df"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef setup_array_pars(self):\n        mlt_df = self.prep_mlt_arrays()\n        if mlt_df is None:\n            return\n        mlt_df.loc[:,\"tpl_file\"] = mlt_df.mlt_file.apply(lambda x: os.path.split(x)[-1]+\".tpl\")\n        #mlt_df.loc[mlt_df.tpl_file.apply(lambda x:pd.notnull(x.pp_file)),\"tpl_file\"] = np.NaN\n        mlt_files = mlt_df.mlt_file.unique()\n        #for suffix,tpl_file,layer,name in zip(self.mlt_df.suffix,\n        #                                 self.mlt_df.tpl,self.mlt_df.layer,\n        #                                     self.mlt_df.prefix):\n        par_dfs = {}\n        for mlt_file in mlt_files:\n            suffixes = mlt_df.loc[mlt_df.mlt_file==mlt_file,\"suffix\"]\n            if suffixes.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of suffixes for {0}\"\\\n                                   .format(mlt_file))\n            suffix = suffixes.iloc[0]\n\n            tpl_files = mlt_df.loc[mlt_df.mlt_file==mlt_file,\"tpl_file\"]\n            if tpl_files.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of tpl_files for {0}\"\\\n                                   .format(mlt_file))\n            tpl_file = tpl_files.iloc[0]\n            layers = mlt_df.loc[mlt_df.mlt_file==mlt_file,\"layer\"]\n            #if layers.unique().shape[0] != 1:\n            #    self.logger.lraise(\"wrong number of layers for {0}\"\\\n            #                       .format(mlt_file))\n            layer = layers.iloc[0]\n            names = mlt_df.loc[mlt_df.mlt_file==mlt_file,\"prefix\"]\n            if names.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of names for {0}\"\\\n                                   .format(mlt_file))\n            name = names.iloc[0]\n            attr_names = mlt_df.loc[mlt_df.mlt_file == mlt_file, \"attr_name\"]\n            if attr_names.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of attr_names for {0}\".format(mlt_file))\n            attr_name = attr_names.iloc[0]\n\n            #ib = self.k_zone_dict[layer]\n            df = None\n            if suffix == self.cn_suffix:\n                self.log(\"writing const tpl:{0}\".format(tpl_file))\n                #df = self.write_const_tpl(name,tpl_file,self.m.bas6.ibound[layer].array)\n                try:\n                    df = write_const_tpl(name, os.path.join(self.m.model_ws, tpl_file), self.cn_suffix,\n                                    self.m.bas6.ibound[layer].array, (self.m.nrow, self.m.ncol), self.m.sr)\n                except Exception as e:\n                    self.logger.lraise(\"error writing const template: {0}\".format(str(e)))\n                self.log(\"writing const tpl:{0}\".format(tpl_file))\n\n            elif suffix == self.gr_suffix:\n                self.log(\"writing grid tpl:{0}\".format(tpl_file))\n                #df = self.write_grid_tpl(name,tpl_file,self.m.bas6.ibound[layer].array)\n                try:\n                    df = write_grid_tpl(name, os.path.join(self.m.model_ws, tpl_file), self.gr_suffix,\n                                    self.m.bas6.ibound[layer].array, (self.m.nrow, self.m.ncol), self.m.sr)\n                except Exception as e:\n                    self.logger.lraise(\"error writing grid template: {0}\".format(str(e)))\n                self.log(\"writing grid tpl:{0}\".format(tpl_file))\n\n            elif suffix == self.zn_suffix:\n                self.log(\"writing zone tpl:{0}\".format(tpl_file))\n                if np.all([isinstance(v, dict) for v in self.k_zone_dict.values()]):  # check is dict of dicts\n                    if attr_name in [p.split('.')[-1] for p in self.k_zone_dict.keys()]:\n                        k_zone_dict = next(k_dict for p, k_dict in self.k_zone_dict.items()\n                                           if p.split('.')[-1] == attr_name)  # get dict relating to parameter prefix\n                    else:\n                        assert 'general_zn' in self.k_zone_dict.keys(), \\\n                            \"Neither {0} nor 'general_zn' are in k_zone_dict keys: {1}\".format(attr_name,\n                                                                                               k_zone_dict.keys())\n                        k_zone_dict = self.k_zone_dict['general_zn']\n                else:\n                    k_zone_dict = self.k_zone_dict\n                #df = self.write_zone_tpl(self.m, name, tpl_file, self.k_zone_dict[layer], self.zn_suffix, self.logger)\n                try:\n                    df = write_zone_tpl(name, os.path.join(self.m.model_ws, tpl_file), self.zn_suffix,\n                                        k_zone_dict[layer], (self.m.nrow, self.m.ncol), self.m.sr)\n                except Exception as e:\n                    self.logger.lraise(\"error writing zone template: {0}\".format(str(e)))\n                self.log(\"writing zone tpl:{0}\".format(tpl_file))\n\n            if df is None:\n                continue\n            if suffix not in par_dfs:\n                par_dfs[suffix] = [df]\n            else:\n                par_dfs[suffix].append(df)\n        for suf,dfs in par_dfs.items():\n            self.par_dfs[suf] = pd.concat(dfs)\n\n        if self.pp_suffix in mlt_df.suffix.values:\n            self.log(\"setting up pilot point process\")\n            self.pp_prep(mlt_df)\n            self.log(\"setting up pilot point process\")\n\n        if self.gr_suffix in mlt_df.suffix.values:\n            self.log(\"setting up grid process\")\n            self.grid_prep()\n            self.log(\"setting up grid process\")\n\n        if self.kl_suffix in mlt_df.suffix.values:\n            self.log(\"setting up kl process\")\n            self.kl_prep(mlt_df)\n            self.log(\"setting up kl process\")\n\n        mlt_df.to_csv(os.path.join(self.m.model_ws,\"arr_pars.csv\"))\n        ones = np.ones((self.m.nrow,self.m.ncol))\n        for mlt_file in mlt_df.mlt_file.unique():\n            self.log(\"save test mlt array {0}\".format(mlt_file))\n            np.savetxt(os.path.join(self.m.model_ws,mlt_file),\n                       ones,fmt=\"%15.6E\")\n            self.log(\"save test mlt array {0}\".format(mlt_file))\n            tpl_files = mlt_df.loc[mlt_df.mlt_file == mlt_file, \"tpl_file\"]\n            if tpl_files.unique().shape[0] != 1:\n                self.logger.lraise(\"wrong number of tpl_files for {0}\" \\\n                                   .format(mlt_file))\n            tpl_file = tpl_files.iloc[0]\n            if pd.notnull(tpl_file):\n                self.tpl_files.append(tpl_file)\n                self.in_files.append(mlt_file)\n\n        # for tpl_file,mlt_file in zip(mlt_df.tpl_file,mlt_df.mlt_file):\n        #     if pd.isnull(tpl_file):\n        #         continue\n        #     self.tpl_files.append(tpl_file)\n        #     self.in_files.append(mlt_file)\n\n        os.chdir(self.m.model_ws)\n        try:\n            apply_array_pars()\n        except Exception as e:\n            os.chdir(\"..\")\n            self.logger.lraise(\"error test running apply_array_pars():{0}\".\n                               format(str(e)))\n        os.chdir(\"..\")\n        line = \"pyemu.helpers.apply_array_pars()\\n\"\n        self.logger.statement(\"forward_run line:{0}\".format(line))\n        self.frun_pre_lines.append(line)", "response": "setup array multipler parameters"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef draw(self, num_reals=100, sigma_range=6):\n\n        self.log(\"drawing realizations\")\n        struct_dict = {}\n        if self.pp_suffix in self.par_dfs.keys():\n            pp_df = self.par_dfs[self.pp_suffix]\n            pp_dfs = []\n            for pargp in pp_df.pargp.unique():\n                gp_df = pp_df.loc[pp_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                pp_dfs.append(p_df)\n            #pp_dfs = [pp_df.loc[pp_df.pargp==pargp,:].copy() for pargp in pp_df.pargp.unique()]\n            struct_dict[self.pp_geostruct] = pp_dfs\n        if self.gr_suffix in self.par_dfs.keys():\n            gr_df = self.par_dfs[self.gr_suffix]\n            gr_dfs = []\n            for pargp in gr_df.pargp.unique():\n                gp_df = gr_df.loc[gr_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                gr_dfs.append(p_df)\n            #gr_dfs = [gr_df.loc[gr_df.pargp==pargp,:].copy() for pargp in gr_df.pargp.unique()]\n            struct_dict[self.grid_geostruct] = gr_dfs\n        if \"temporal_list\" in self.par_dfs.keys():\n            bc_df = self.par_dfs[\"temporal_list\"]\n            bc_df.loc[:,\"y\"] = 0\n            bc_df.loc[:,\"x\"] = bc_df.timedelta.apply(lambda x: x.days)\n            bc_dfs = []\n            for pargp in bc_df.pargp.unique():\n                gp_df = bc_df.loc[bc_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                #print(p_df)\n                bc_dfs.append(p_df)\n            #bc_dfs = [bc_df.loc[bc_df.pargp==pargp,:].copy() for pargp in bc_df.pargp.unique()]\n            struct_dict[self.temporal_list_geostruct] = bc_dfs\n        if \"spatial_list\" in self.par_dfs.keys():\n            bc_df = self.par_dfs[\"spatial_list\"]\n            bc_dfs = []\n            for pargp in bc_df.pargp.unique():\n                gp_df = bc_df.loc[bc_df.pargp==pargp,:]\n                #p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                #print(p_df)\n                bc_dfs.append(gp_df)\n            struct_dict[self.spatial_list_geostruct] = bc_dfs\n        pe = geostatistical_draws(self.pst,struct_dict=struct_dict,num_reals=num_reals,\n                             sigma_range=sigma_range)\n\n        self.log(\"drawing realizations\")\n        return pe", "response": "draw like a boss!"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nbuilding a prior parameter covariance matrix.", "response": "def build_prior(self, fmt=\"ascii\",filename=None,droptol=None, chunk=None, sparse=False,\n                    sigma_range=6):\n        \"\"\" build a prior parameter covariance matrix.\n\n        Parameters\n        ----------\n            fmt : str\n                the format to save the cov matrix.  Options are \"ascii\",\"binary\",\"uncfile\", \"coo\".\n                default is \"ascii\"\n            filename : str\n                the filename to save the prior cov matrix to.  If None, the name is formed using\n                model nam_file name.  Default is None.\n            droptol : float\n                tolerance for dropping near-zero values when writing compressed binary.\n                Default is None\n            chunk : int\n                chunk size to write in a single pass - for binary only\n            sparse : bool\n                flag to build a pyemu.SparseMatrix format cov matrix.  Default is False\n            sigma_range : float\n                number of standard deviations represented by the parameter bounds.  Default\n                is 6.\n\n        Returns\n        -------\n            cov : pyemu.Cov\n            a full covariance matrix\n\n        \"\"\"\n\n        fmt = fmt.lower()\n        acc_fmts = [\"ascii\",\"binary\",\"uncfile\",\"none\",\"coo\"]\n        if fmt not in acc_fmts:\n            self.logger.lraise(\"unrecognized prior save 'fmt':{0}, options are: {1}\".\n                               format(fmt,','.join(acc_fmts)))\n\n        self.log(\"building prior covariance matrix\")\n        struct_dict = {}\n        if self.pp_suffix in self.par_dfs.keys():\n            pp_df = self.par_dfs[self.pp_suffix]\n            pp_dfs = []\n            for pargp in pp_df.pargp.unique():\n                gp_df = pp_df.loc[pp_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                pp_dfs.append(p_df)\n            #pp_dfs = [pp_df.loc[pp_df.pargp==pargp,:].copy() for pargp in pp_df.pargp.unique()]\n            struct_dict[self.pp_geostruct] = pp_dfs\n        if self.gr_suffix in self.par_dfs.keys():\n            gr_df = self.par_dfs[self.gr_suffix]\n            gr_dfs = []\n            for pargp in gr_df.pargp.unique():\n                gp_df = gr_df.loc[gr_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                gr_dfs.append(p_df)\n            #gr_dfs = [gr_df.loc[gr_df.pargp==pargp,:].copy() for pargp in gr_df.pargp.unique()]\n            struct_dict[self.grid_geostruct] = gr_dfs\n        if \"temporal_list\" in self.par_dfs.keys():\n            bc_df = self.par_dfs[\"temporal_list\"]\n            bc_df.loc[:,\"y\"] = 0\n            bc_df.loc[:,\"x\"] = bc_df.timedelta.apply(lambda x: x.days)\n            bc_dfs = []\n            for pargp in bc_df.pargp.unique():\n                gp_df = bc_df.loc[bc_df.pargp==pargp,:]\n                p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                #print(p_df)\n                bc_dfs.append(p_df)\n            #bc_dfs = [bc_df.loc[bc_df.pargp==pargp,:].copy() for pargp in bc_df.pargp.unique()]\n            struct_dict[self.temporal_list_geostruct] = bc_dfs\n        if \"spatial_list\" in self.par_dfs.keys():\n            bc_df = self.par_dfs[\"spatial_list\"]\n            bc_dfs = []\n            for pargp in bc_df.pargp.unique():\n                gp_df = bc_df.loc[bc_df.pargp==pargp,:]\n                #p_df = gp_df.drop_duplicates(subset=\"parnme\")\n                #print(p_df)\n                bc_dfs.append(gp_df)\n            struct_dict[self.spatial_list_geostruct] = bc_dfs\n        if \"hfb\" in self.par_dfs.keys():\n            if self.spatial_list_geostruct in struct_dict.keys():\n                struct_dict[self.spatial_list_geostruct].append(self.par_dfs[\"hfb\"])\n            else:\n                struct_dict[self.spatial_list_geostruct] = [self.par_dfs[\"hfb\"]]\n\n        if \"sfr\" in self.par_dfs.keys():\n            self.logger.warn(\"geospatial prior not implemented for SFR pars\")\n\n        if len(struct_dict) > 0:\n            if sparse:\n                cov = pyemu.helpers.sparse_geostatistical_prior_builder(self.pst,\n                                                                        struct_dict=struct_dict,\n                                                                        sigma_range=sigma_range)\n\n            else:\n                cov = pyemu.helpers.geostatistical_prior_builder(self.pst,\n                                                             struct_dict=struct_dict,\n                                                             sigma_range=sigma_range)\n        else:\n            cov = pyemu.Cov.from_parameter_data(self.pst,sigma_range=sigma_range)\n\n        if filename is None:\n            filename = os.path.join(self.m.model_ws,self.pst_name+\".prior.cov\")\n        if fmt != \"none\":\n            self.logger.statement(\"saving prior covariance matrix to file {0}\".format(filename))\n        if fmt == 'ascii':\n            cov.to_ascii(filename)\n        elif fmt == 'binary':\n            cov.to_binary(filename,droptol=droptol,chunk=chunk)\n        elif fmt == 'uncfile':\n            cov.to_uncfile(filename)\n        elif fmt == 'coo':\n            cov.to_coo(filename,droptol=droptol,chunk=chunk)\n        self.log(\"building prior covariance matrix\")\n        return cov"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef build_pst(self,filename=None):\n        self.logger.statement(\"changing dir in to {0}\".format(self.m.model_ws))\n        os.chdir(self.m.model_ws)\n        tpl_files = copy.deepcopy(self.tpl_files)\n        in_files = copy.deepcopy(self.in_files)\n        try:\n            files = os.listdir('.')\n            new_tpl_files = [f for f in files if f.endswith(\".tpl\") and f not in tpl_files]\n            new_in_files = [f.replace(\".tpl\",'') for f in new_tpl_files]\n            tpl_files.extend(new_tpl_files)\n            in_files.extend(new_in_files)\n            ins_files = [f for f in files if f.endswith(\".ins\")]\n            out_files = [f.replace(\".ins\",'') for f in ins_files]\n            for tpl_file,in_file in zip(tpl_files,in_files):\n                if tpl_file not in self.tpl_files:\n                    self.tpl_files.append(tpl_file)\n                    self.in_files.append(in_file)\n\n            for ins_file,out_file in zip(ins_files,out_files):\n                if ins_file not in self.ins_files:\n                    self.ins_files.append(ins_file)\n                    self.out_files.append(out_file)\n            self.log(\"instantiating control file from i/o files\")\n            self.logger.statement(\"tpl files: {0}\".format(\",\".join(self.tpl_files)))\n            self.logger.statement(\"ins files: {0}\".format(\",\".join(self.ins_files)))\n            pst = pyemu.Pst.from_io_files(tpl_files=self.tpl_files,\n                                          in_files=self.in_files,\n                                          ins_files=self.ins_files,\n                                          out_files=self.out_files)\n\n            self.log(\"instantiating control file from i/o files\")\n        except Exception as e:\n            os.chdir(\"..\")\n            self.logger.lraise(\"error build Pst:{0}\".format(str(e)))\n        os.chdir('..')\n        # more customization here\n        par = pst.parameter_data\n        for name,df in self.par_dfs.items():\n            if \"parnme\" not in df.columns:\n                continue\n            df.index = df.parnme\n            for col in par.columns:\n                if col in df.columns:\n                    par.loc[df.parnme,col] = df.loc[:,col]\n\n        par.loc[:,\"parubnd\"] = 10.0\n        par.loc[:,\"parlbnd\"] = 0.1\n\n        for name,df in self.par_dfs.items():\n            if \"parnme\" not in df:\n                continue\n            df.index = df.parnme\n            for col in [\"parubnd\",\"parlbnd\",\"pargp\"]:\n                if col in df.columns:\n                    par.loc[df.index,col] = df.loc[:,col]\n\n        for tag,[lw,up] in wildass_guess_par_bounds_dict.items():\n            par.loc[par.parnme.apply(lambda x: x.startswith(tag)),\"parubnd\"] = up\n            par.loc[par.parnme.apply(lambda x: x.startswith(tag)),\"parlbnd\"] = lw\n\n\n        if self.par_bounds_dict is not None:\n            for tag,[lw,up] in self.par_bounds_dict.items():\n                par.loc[par.parnme.apply(lambda x: x.startswith(tag)),\"parubnd\"] = up\n                par.loc[par.parnme.apply(lambda x: x.startswith(tag)),\"parlbnd\"] = lw\n\n\n\n        obs = pst.observation_data\n        for name,df in self.obs_dfs.items():\n            if \"obsnme\" not in df.columns:\n                continue\n            df.index = df.obsnme\n            for col in df.columns:\n                if col in obs.columns:\n                    obs.loc[df.obsnme,col] = df.loc[:,col]\n\n        self.pst_name = self.m.name+\".pst\"\n        pst.model_command = [\"python forward_run.py\"]\n        pst.control_data.noptmax = 0\n        self.log(\"writing forward_run.py\")\n        self.write_forward_run()\n        self.log(\"writing forward_run.py\")\n\n        if filename is None:\n            filename = os.path.join(self.m.model_ws,self.pst_name)\n        self.logger.statement(\"writing pst {0}\".format(filename))\n\n        pst.write(filename)\n        self.pst = pst\n\n        self.log(\"running pestchek on {0}\".format(self.pst_name))\n        os.chdir(self.m.model_ws)\n        try:\n            pyemu.os_utils.run(\"pestchek {0} >pestchek.stdout\".format(self.pst_name))\n        except Exception as e:\n            self.logger.warn(\"error running pestchek:{0}\".format(str(e)))\n        for line in open(\"pestchek.stdout\"):\n            self.logger.statement(\"pestcheck:{0}\".format(line.strip()))\n        os.chdir(\"..\")\n        self.log(\"running pestchek on {0}\".format(self.pst_name))", "response": "build the pest control file using the parameterizations and observations."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd external template files and instrution files to the current instance", "response": "def add_external(self):\n        \"\"\" add external (existing) template files and instrution files to the\n        Pst instance\n\n        \"\"\"\n        if self.external_tpl_in_pairs is not None:\n            if not isinstance(self.external_tpl_in_pairs,list):\n                external_tpl_in_pairs = [self.external_tpl_in_pairs]\n            for tpl_file,in_file in self.external_tpl_in_pairs:\n                if not os.path.exists(tpl_file):\n                    self.logger.lraise(\"couldn't find external tpl file:{0}\".\\\n                                       format(tpl_file))\n                self.logger.statement(\"external tpl:{0}\".format(tpl_file))\n                shutil.copy2(tpl_file,os.path.join(self.m.model_ws,\n                                                   os.path.split(tpl_file)[-1]))\n                if os.path.exists(in_file):\n                    shutil.copy2(in_file,os.path.join(self.m.model_ws,\n                                                   os.path.split(in_file)[-1]))\n\n        if self.external_ins_out_pairs is not None:\n            if not isinstance(self.external_ins_out_pairs,list):\n                external_ins_out_pairs = [self.external_ins_out_pairs]\n            for ins_file,out_file in self.external_ins_out_pairs:\n                if not os.path.exists(ins_file):\n                    self.logger.lraise(\"couldn't find external ins file:{0}\".\\\n                                       format(ins_file))\n                self.logger.statement(\"external ins:{0}\".format(ins_file))\n                shutil.copy2(ins_file,os.path.join(self.m.model_ws,\n                                                   os.path.split(ins_file)[-1]))\n                if os.path.exists(out_file):\n                    shutil.copy2(out_file,os.path.join(self.m.model_ws,\n                                                   os.path.split(out_file)[-1]))\n                    self.logger.warn(\"obs listed in {0} will have values listed in {1}\"\n                                     .format(ins_file,out_file))\n                else:\n                    self.logger.warn(\"obs listed in {0} will have generic values\")"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the forward run script forward_run. py MimeType", "response": "def write_forward_run(self):\n        \"\"\" write the forward run script forward_run.py\n\n        \"\"\"\n        with open(os.path.join(self.m.model_ws,self.forward_run_file),'w') as f:\n            f.write(\"import os\\nimport numpy as np\\nimport pandas as pd\\nimport flopy\\n\")\n            f.write(\"import pyemu\\n\")\n            for ex_imp in self.extra_forward_imports:\n                f.write('import {0}\\n'.format(ex_imp))\n            for tmp_file in self.tmp_files:\n                f.write(\"try:\\n\")\n                f.write(\"   os.remove('{0}')\\n\".format(tmp_file))\n                f.write(\"except Exception as e:\\n\")\n                f.write(\"   print('error removing tmp file:{0}')\\n\".format(tmp_file))\n            for line in self.frun_pre_lines:\n                f.write(line+'\\n')\n            for line in self.frun_model_lines:\n                f.write(line+'\\n')\n            for line in self.frun_post_lines:\n                f.write(line+'\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nparses the iterable of int values from a property or boundary condition argument returns the iterable of int values from the iterable of ints the acceptable values that may contain", "response": "def parse_k(self,k,vals):\n        \"\"\" parse the iterable from a property or boundary condition argument\n\n        Parameters\n        ----------\n        k : int or iterable int\n            the iterable\n        vals : iterable of ints\n            the acceptable values that k may contain\n\n        Returns\n        -------\n        k_vals : iterable of int\n            parsed k values\n\n        \"\"\"\n        try:\n            k = int(k)\n        except:\n            pass\n        else:\n            assert k in vals,\"k {0} not in vals\".format(k)\n            return [k]\n        if k is None:\n            return vals\n        else:\n            try:\n                k_vals = vals[k]\n            except Exception as e:\n                raise Exception(\"error slicing vals with {0}:{1}\".\n                                format(k,str(e)))\n            return k_vals"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef parse_pakattr(self,pakattr):\n\n        raw = pakattr.lower().split('.')\n        if len(raw) != 2:\n            self.logger.lraise(\"pakattr is wrong:{0}\".format(pakattr))\n        pakname = raw[0]\n        attrname = raw[1]\n        pak = self.m.get_package(pakname)\n        if pak is None:\n            if pakname == \"extra\":\n                self.logger.statement(\"'extra' pak detected:{0}\".format(pakattr))\n                ud = flopy.utils.Util3d(self.m,(self.m.nlay,self.m.nrow,self.m.ncol),np.float32,1.0,attrname)\n                return \"extra\",ud\n\n            self.logger.lraise(\"pak {0} not found\".format(pakname))\n        if hasattr(pak,attrname):\n            attr = getattr(pak,attrname)\n            return pak,attr\n        elif hasattr(pak,\"stress_period_data\"):\n            dtype = pak.stress_period_data.dtype\n            if attrname not in dtype.names:\n                self.logger.lraise(\"attr {0} not found in dtype.names for {1}.stress_period_data\".\\\n                                  format(attrname,pakname))\n            attr = pak.stress_period_data\n            return pak,attr,attrname\n        # elif hasattr(pak,'hfb_data'):\n        #     dtype = pak.hfb_data.dtype\n        #     if attrname not in dtype.names:\n        #         self.logger.lraise('attr {0} not found in dtypes.names for {1}.hfb_data. Thanks for playing.'.\\\n        #                            format(attrname,pakname))\n        #     attr = pak.hfb_data\n        #     return pak, attr, attrname\n        else:\n            self.logger.lraise(\"unrecognized attr:{0}\".format(attrname))", "response": "Parse the attribute name of a specific attribute in a property or boundary condition."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef setup_list_pars(self):\n        tdf = self.setup_temporal_list_pars()\n        sdf = self.setup_spatial_list_pars()\n        if tdf is None and sdf is None:\n            return\n        os.chdir(self.m.model_ws)\n        try:\n            apply_list_pars()\n        except Exception as e:\n            os.chdir(\"..\")\n            self.logger.lraise(\"error test running apply_list_pars():{0}\".format(str(e)))\n        os.chdir('..')\n        line = \"pyemu.helpers.apply_list_pars()\\n\"\n        self.logger.statement(\"forward_run line:{0}\".format(line))\n        self.frun_pre_lines.append(line)", "response": "main entry point for setting up list multiplier\n                parameters\n       "}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef list_helper(self,k,pak,attr,col):\n        # special case for horrible HFB6 exception\n        # if type(pak) == flopy.modflow.mfhfb.ModflowHfb:\n        #     filename = pak.file_name[0]\n        # else:\n        filename = attr.get_filename(k)\n        filename_model = os.path.join(self.m.external_path,filename)\n        shutil.copy2(os.path.join(self.m.model_ws,filename_model),\n                     os.path.join(self.m.model_ws,self.list_org,filename))\n        return filename_model", "response": "helper to setup list multiplier parameters for a given set of items"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setup_hob(self):\n\n        if self.m.hob is None:\n            return\n        hob_out_unit = self.m.hob.iuhobsv\n        new_hob_out_fname = os.path.join(self.m.model_ws,self.m.get_output_attribute(unit=hob_out_unit))\n        org_hob_out_fname = os.path.join(self.org_model_ws,self.m.get_output_attribute(unit=hob_out_unit))\n\n        if not os.path.exists(org_hob_out_fname):\n            self.logger.warn(\"could not find hob out file: {0}...skipping\".format(hob_out_fname))\n            return\n        shutil.copy2(org_hob_out_fname,new_hob_out_fname)\n        hob_df = pyemu.gw_utils.modflow_hob_to_instruction_file(new_hob_out_fname)\n        self.obs_dfs[\"hob\"] = hob_df\n        self.tmp_files.append(os.path.split(hob_out_fname))", "response": "setup observations from the MODFLOW HOB package"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef setup_water_budget_obs(self):\n        if self.mflist_waterbudget:\n            org_listfile = os.path.join(self.org_model_ws,self.m.lst.file_name[0])\n            if os.path.exists(org_listfile):\n                shutil.copy2(org_listfile,os.path.join(self.m.model_ws,\n                                                       self.m.lst.file_name[0]))\n            else:\n                self.logger.warn(\"can't find existing list file:{0}...skipping\".\n                                   format(org_listfile))\n                return\n            list_file = os.path.join(self.m.model_ws,self.m.lst.file_name[0])\n            flx_file = os.path.join(self.m.model_ws,\"flux.dat\")\n            vol_file = os.path.join(self.m.model_ws,\"vol.dat\")\n            df = pyemu.gw_utils.setup_mflist_budget_obs(list_file,\n                                                                flx_filename=flx_file,\n                                                                vol_filename=vol_file,\n                                                                start_datetime=self.m.start_datetime)\n            if df is not None:\n                self.obs_dfs[\"wb\"] = df\n            #line = \"try:\\n    os.remove('{0}')\\nexcept:\\n    pass\".format(os.path.split(list_file)[-1])\n            #self.logger.statement(\"forward_run line:{0}\".format(line))\n            #self.frun_pre_lines.append(line)\n            self.tmp_files.append(os.path.split(list_file)[-1])\n            line = \"pyemu.gw_utils.apply_mflist_budget_obs('{0}',flx_filename='{1}',vol_filename='{2}',start_datetime='{3}')\".\\\n                    format(os.path.split(list_file)[-1],\n                           os.path.split(flx_file)[-1],\n                           os.path.split(vol_file)[-1],\n                           self.m.start_datetime)\n            self.logger.statement(\"forward_run line:{0}\".format(line))\n            self.frun_post_lines.append(line)", "response": "setup observations from the MODFLOW list file for the current modflow class and the water buget information"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwriting a template file for a 2D array.", "response": "def write_array_tpl(name, tpl_filename, suffix, par_type, zone_array=None, shape=None,\n                    longnames=False, fill_value=1.0,get_xy=None,input_filename=None):\n    \"\"\" write a template file for a 2D array.\n\n        Parameters\n        ----------\n        name : str\n            the base parameter name\n        tpl_file : str\n            the template file to write - include path\n        zone_array : numpy.ndarray\n            an array used to skip inactive cells.  Values less than 1 are\n            not parameterized and are assigned a value of fill_value.\n            Default is None.\n        fill_value : float\n            value to fill in values that are skipped.  Default is 1.0.\n\n        Returns\n        -------\n        df : pandas.DataFrame\n            a dataframe with parameter information\n\n        \"\"\"\n    if shape is None and zone_array is None:\n        raise Exception(\"write_array_tpl() error: must pass either zone_array or shape\")\n    elif shape is not None and zone_array is not None:\n        if shape != zone_array.shape:\n            raise Exception(\"write_array_tpl() error: passed shape != zone_array.shape\")\n    elif shape is None:\n        shape = zone_array.shape\n    if len(shape) != 2:\n        raise Exception(\"write_array_tpl() error: shape '{0}' not 2D\".format(str(shape)))\n\n    def constant_namer(i,j):\n        if longnames:\n            pname =  \"const_{0}\".format(name)\n            if suffix != '':\n                pname += \"_{0}\".format(suffix)\n        else:\n            pname = \"{0}{1}\".format(name, suffix)\n            if len(pname) > 12:\n                raise (\"constant par name too long:{0}\". \\\n                       format(pname))\n        return pname\n\n    def zone_namer(i,j):\n        zval = 1\n        if zone_array is not None:\n            zval = zone_array[i, j]\n        if longnames:\n            pname = \"{0}_zone:{1}\".format(name, zval)\n            if suffix != '':\n                pname += \"_{0}\".format(suffix)\n        else:\n\n            pname = \"{0}_zn{1}\".format(name, zval)\n            if len(pname) > 12:\n                raise (\"zone par name too long:{0}\". \\\n                       format(pname))\n        return pname\n\n    def grid_namer(i,j):\n        if longnames:\n            pname = \"{0}_i:{1}_j:{2}\".format(name, i, j)\n            if get_xy is not None:\n                pname += \"_x:{0:0.2f}_y:{1:0.2f}\".format(*get_xy(i,j))\n            if zone_array is not None:\n                pname += \"_zone:{0}\".format(zone_array[i,j])\n            if suffix != '':\n                pname += \"_{0}\".format(suffix)\n        else:\n            pname = \"{0}{1:03d}{2:03d}\".format(name, i, j)\n            if len(pname) > 12:\n                raise (\"grid pname too long:{0}\". \\\n                       format(pname))\n        return pname\n\n    if par_type == \"constant\":\n        namer = constant_namer\n    elif par_type == \"zone\":\n        namer = zone_namer\n    elif par_type == \"grid\":\n        namer = grid_namer\n    else:\n        raise Exception(\"write_array_tpl() error: unsupported par_type\"+\n                        \", options are 'constant', 'zone', or 'grid', not\"+\\\n                        \"'{0}'\".format(par_type))\n\n    parnme = []\n    xx,yy,ii,jj = [],[],[],[]\n    with open(tpl_filename, 'w') as f:\n        f.write(\"ptf ~\\n\")\n        for i in range(shape[0]):\n            for j in range(shape[1]):\n                if zone_array is not None and zone_array[i, j] < 1:\n                    pname = \" {0} \".format(fill_value)\n                else:\n                    if get_xy is not None:\n                        x,y = get_xy(i,j)\n                        xx.append(x)\n                        yy.append(y)\n                    ii.append(i)\n                    jj.append(j)\n\n                    pname = namer(i,j)\n                    parnme.append(pname)\n                    pname = \" ~   {0}    ~\".format(pname)\n                f.write(pname)\n            f.write(\"\\n\")\n    df = pd.DataFrame({\"parnme\": parnme}, index=parnme)\n    df.loc[:,'i'] = ii\n    df.loc[:,'j'] = jj\n    if get_xy is not None:\n        df.loc[:,'x'] = xx\n        df.loc[:,'y'] = yy\n    df.loc[:, \"pargp\"] = \"{0}_{1}\".format(name, suffix.replace('_', ''))\n    df.loc[:, \"tpl_filename\"] = tpl_filename\n    df.loc[:,\"input_filename\"] = input_filename\n    if input_filename is not None:\n        arr = np.ones(shape)\n        np.savetxt(input_filename,arr,fmt=\"%2.1f\")\n\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nread a residual file into a pandas. DataFrame", "response": "def read_resfile(resfile):\n        \"\"\"load a residual file into a pandas.DataFrame\n\n        Parameters\n        ----------\n        resfile : str\n            residual file name\n\n        Returns\n        -------\n        pandas.DataFrame : pandas.DataFrame\n\n        \"\"\"\n        assert os.path.exists(resfile),\"read_resfile() error: resfile \" +\\\n                                       \"{0} not found\".format(resfile)\n        converters = {\"name\": str_con, \"group\": str_con}\n        f = open(resfile, 'r')\n        while True:\n            line = f.readline()\n            if line == '':\n                raise Exception(\"Pst.get_residuals: EOF before finding \"+\n                                \"header in resfile: \" + resfile)\n            if \"name\" in line.lower():\n                header = line.lower().strip().split()\n                break\n        res_df = pd.read_csv(f, header=None, names=header, sep=\"\\s+\",\n                                 converters=converters)\n        res_df.index = res_df.name\n        f.close()\n        return res_df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef res_from_en(pst,enfile):\n    converters = {\"name\": str_con, \"group\": str_con}\n    try: #substitute ensemble for res, 'base' if there, otherwise mean\n        obs=pst.observation_data\n        if isinstance(enfile,str):\n            df=pd.read_csv(enfile,converters=converters)\n            df.columns=df.columns.str.lower()\n            df = df.set_index('real_name').T.rename_axis('name').rename_axis(None, 1)\n        else:\n            df = enfile.T\n        if 'base' in df.columns:\n            df['modelled']=df['base']\n            df['std']=df.std(axis=1)\n        else:\n            df['modelled']=df.mean(axis=1)\n            df['std']=df.std(axis=1)\n        #probably a more pandastic way to do this\n        res_df=df[['modelled','std']].copy()\n        res_df['group']=obs.loc[:,'obgnme'].copy()\n        res_df['measured']=obs['obsval'].copy()\n        res_df['weight']=obs['weight'].copy()\n        res_df['residual']=res_df['measured']-res_df['modelled']\n    except Exception as e:\n        raise Exception(\"Pst.res_from_en:{0}\".format(str(e)))\n    return res_df", "response": "load ensemble file for residual into a pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef read_parfile(parfile):\n    assert os.path.exists(parfile), \"Pst.parrep(): parfile not found: \" +\\\n                                    str(parfile)\n    f = open(parfile, 'r')\n    header = f.readline()\n    par_df = pd.read_csv(f, header=None,\n                             names=[\"parnme\", \"parval1\", \"scale\", \"offset\"],\n                             sep=\"\\s+\")\n    par_df.index = par_df.parnme\n    return par_df", "response": "load a pest - compatible. par file into a pandas. DataFrame"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_parfile(df,parfile):\n    columns = [\"parnme\",\"parval1\",\"scale\",\"offset\"]\n    formatters = {\"parnme\":lambda x:\"{0:20s}\".format(x),\n                  \"parval1\":lambda x:\"{0:20.7E}\".format(x),\n                  \"scale\":lambda x:\"{0:20.7E}\".format(x),\n                  \"offset\":lambda x:\"{0:20.7E}\".format(x)}\n\n    for col in columns:\n        assert col in df.columns,\"write_parfile() error: \" +\\\n                                 \"{0} not found in df\".format(col)\n    with open(parfile,'w') as f:\n        f.write(\"single point\\n\")\n        f.write(df.to_string(col_space=0,\n                      columns=columns,\n                      formatters=formatters,\n                      justify=\"right\",\n                      header=False,\n                      index=False,\n                      index_names=False) + '\\n')", "response": "write a pest parameter file from a dataframe"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_tpl_file(tpl_file):\n    par_names = set()\n    with open(tpl_file,'r') as f:\n        try:\n            header = f.readline().strip().split()\n            assert header[0].lower() in [\"ptf\",\"jtf\"],\\\n                \"template file error: must start with [ptf,jtf], not:\" +\\\n                str(header[0])\n            assert len(header) == 2,\\\n                \"template file error: header line must have two entries: \" +\\\n                str(header)\n\n            marker = header[1]\n            assert len(marker) == 1,\\\n                \"template file error: marker must be a single character, not:\" +\\\n                str(marker)\n            for line in f:\n                par_line = set(line.lower().strip().split(marker)[1::2])\n                par_names.update(par_line)\n                #par_names.extend(par_line)\n                #for p in par_line:\n                #    if p not in par_names:\n                #        par_names.append(p)\n        except Exception as e:\n            raise Exception(\"error processing template file \" +\\\n                            tpl_file+\" :\\n\" + str(e))\n    #par_names = [pn.strip().lower() for pn in par_names]\n    #seen = set()\n    #seen_add = seen.add\n    #return [x for x in par_names if not (x in seen or seen_add(x))]\n    return [p.strip() for p in list(par_names)]", "response": "parse a pest template file to get the parameter names\n   "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nwriting parameter values to a model input files using a template files with current parameter values stored in Pst. parameter_data. parval1.", "response": "def write_input_files(pst):\n    \"\"\"write parameter values to a model input files using a template files with\n    current parameter values (stored in Pst.parameter_data.parval1).\n    This is a simple implementation of what PEST does.  It does not\n    handle all the special cases, just a basic function...user beware\n\n    Parameters\n    ----------\n    pst : (pyemu.Pst)\n        a Pst instance\n\n    \"\"\"\n    par = pst.parameter_data\n    par.loc[:,\"parval1_trans\"] = (par.parval1 * par.scale) + par.offset\n    for tpl_file,in_file in zip(pst.template_files,pst.input_files):\n        write_to_template(pst.parameter_data.parval1_trans,tpl_file,in_file)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef write_to_template(parvals,tpl_file,in_file):\n    f_in = open(in_file,'w')\n    f_tpl = open(tpl_file,'r')\n    header = f_tpl.readline().strip().split()\n    assert header[0].lower() in [\"ptf\", \"jtf\"], \\\n        \"template file error: must start with [ptf,jtf], not:\" + \\\n        str(header[0])\n    assert len(header) == 2, \\\n        \"template file error: header line must have two entries: \" + \\\n        str(header)\n\n    marker = header[1]\n    assert len(marker) == 1, \\\n        \"template file error: marker must be a single character, not:\" + \\\n        str(marker)\n    for line in f_tpl:\n        if marker not in line:\n            f_in.write(line)\n        else:\n            line = line.rstrip()\n            par_names = line.lower().split(marker)[1::2]\n            par_names = [name.strip() for name in par_names]\n            start,end = get_marker_indices(marker,line)\n            assert len(par_names) == len(start)\n            new_line = line[:start[0]]\n            between = [line[e:s] for s,e in zip(start[1:],end[:-1])]\n            for i,name in enumerate(par_names):\n                s,e = start[i],end[i]\n                w = e - s\n                if w > 15:\n                    d = 6\n                else:\n                    d = 3\n                fmt = \"{0:\" + str(w)+\".\"+str(d)+\"E}\"\n                val_str = fmt.format(parvals[name])\n                new_line += val_str\n                if i != len(par_names) - 1:\n                    new_line += between[i]\n            new_line += line[end[-1]:]\n            f_in.write(new_line+'\\n')\n    f_tpl.close()\n    f_in.close()", "response": "write parameter values to model input files using template files using parameter names"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_marker_indices(marker,line):\n    indices = [i for i, ltr in enumerate(line) if ltr == marker]\n    start = indices[0:-1:2]\n    end = [i+1 for i in indices[1::2]]\n    assert len(start) == len(end)\n    return start,end", "response": "method to find the start and end indices of a marker in a template file line."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_ins_file(ins_file):\n\n    obs_names = []\n    with open(ins_file,'r') as f:\n        header = f.readline().strip().split()\n        assert header[0].lower() in [\"pif\",\"jif\"],\\\n            \"instruction file error: must start with [pif,jif], not:\" +\\\n            str(header[0])\n        marker = header[1]\n        assert len(marker) == 1,\\\n            \"instruction file error: marker must be a single character, not:\" +\\\n            str(marker)\n        for line in f:\n            line = line.lower()\n            if marker in line:\n                raw = line.lower().strip().split(marker)\n                for item in raw[::2]:\n                    obs_names.extend(parse_ins_string(item))\n            else:\n                obs_names.extend(parse_ins_string(line.strip()))\n    #obs_names = [on.strip().lower() for on in obs_names]\n    return obs_names", "response": "parse a pest instruction file to get observation names"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef parse_ins_string(string):\n    istart_markers = [\"[\",\"(\",\"!\"]\n    iend_markers = [\"]\",\")\",\"!\"]\n\n    obs_names = []\n\n    idx = 0\n    while True:\n        if idx >= len(string) - 1:\n            break\n        char = string[idx]\n        if char in istart_markers:\n            em = iend_markers[istart_markers.index(char)]\n            # print(\"\\n\",idx)\n            # print(string)\n            # print(string[idx+1:])\n            # print(string[idx+1:].index(em))\n            # print(string[idx+1:].index(em)+idx+1)\n            eidx = min(len(string),string[idx+1:].index(em)+idx+1)\n            obs_name = string[idx+1:eidx]\n            if obs_name.lower() != \"dum\":\n                obs_names.append(obs_name)\n            idx = eidx + 1\n        else:\n            idx += 1\n    return obs_names", "response": "split up an instruction file line to get the observation names\n   "}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef populate_dataframe(index,columns, default_dict, dtype):\n    new_df = pd.DataFrame(index=index,columns=columns)\n    for fieldname,dt in zip(columns,dtype.descr):\n        default = default_dict[fieldname]\n        new_df.loc[:,fieldname] = default\n        new_df.loc[:,fieldname] = new_df.loc[:,fieldname].astype(dt[1])\n    return new_df", "response": "This function is called as part of constructing a generic Pst instance with a dataframe attribute."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating a generic pst instance", "response": "def generic_pst(par_names=[\"par1\"],obs_names=[\"obs1\"],addreg=False):\n    \"\"\"generate a generic pst instance.  This can used to later fill in\n    the Pst parts programatically.\n\n    Parameters\n    ----------\n    par_names : (list)\n        parameter names to setup\n    obs_names : (list)\n        observation names to setup\n\n    Returns\n    -------\n    new_pst : pyemu.Pst\n\n    \"\"\"\n    if not isinstance(par_names,list):\n        par_names = list(par_names)\n    if not isinstance(obs_names,list):\n        obs_names = list(obs_names)\n    new_pst = pyemu.Pst(\"pest.pst\",load=False)\n    pargp_data = populate_dataframe([\"pargp\"], new_pst.pargp_fieldnames,\n                                    new_pst.pargp_defaults, new_pst.pargp_dtype)\n    new_pst.parameter_groups = pargp_data\n\n    par_data = populate_dataframe(par_names,new_pst.par_fieldnames,\n                                  new_pst.par_defaults,new_pst.par_dtype)\n    par_data.loc[:,\"parnme\"] = par_names\n    par_data.index = par_names\n    par_data.sort_index(inplace=True)\n    new_pst.parameter_data = par_data\n    obs_data = populate_dataframe(obs_names,new_pst.obs_fieldnames,\n                                  new_pst.obs_defaults,new_pst.obs_dtype)\n    obs_data.loc[:,\"obsnme\"] = obs_names\n    obs_data.index = obs_names\n    obs_data.sort_index(inplace=True)\n    new_pst.observation_data = obs_data\n\n    new_pst.template_files = [\"file.tpl\"]\n    new_pst.input_files = [\"file.in\"]\n    new_pst.instruction_files = [\"file.ins\"]\n    new_pst.output_files = [\"file.out\"]\n    new_pst.model_command = [\"model.bat\"]\n\n    new_pst.prior_information = new_pst.null_prior\n\n    #new_pst.other_lines = [\"* singular value decomposition\\n\",\"1\\n\",\n    #                       \"{0:d} {1:15.6E}\\n\".format(new_pst.npar_adj,1.0E-6),\n    #                       \"1 1 1\\n\"]\n    if addreg:\n        new_pst.zero_order_tikhonov()\n\n    return new_pst"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating a new pyemu. Pst instance from model interface files", "response": "def pst_from_io_files(tpl_files,in_files,ins_files,out_files,pst_filename=None):\n    \"\"\" generate a new pyemu.Pst instance from model interface files.  This\n    function is emulated in the Pst.from_io_files() class method.\n\n    Parameters\n    ----------\n    tpl_files : (list)\n        template file names\n    in_files : (list)\n        model input file names\n    ins_files : (list)\n        instruction file names\n    out_files : (list)\n        model output file names\n    pst_filename : str\n        filename to save new pyemu.Pst.  If None, Pst is not written.\n        default is None\n\n    Returns\n    -------\n    new_pst : pyemu.Pst\n\n    \"\"\"\n\n    warnings.warn(\"pst_from_io_files has moved to pyemu.helpers and is also \"+\\\n                  \"now avaiable as a Pst class method (Pst.from_io_files())\",PyemuWarning)\n    from pyemu import helpers\n    return helpers.pst_from_io_files(tpl_files=tpl_files,in_files=in_files,\n                              ins_files=ins_files,out_files=out_files,\n                              pst_filename=pst_filename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef try_run_inschek(pst):\n    for ins_file,out_file in zip(pst.instruction_files,pst.output_files):\n        df = _try_run_inschek(ins_file,out_file)\n        if df is not None:\n            pst.observation_data.loc[df.index, \"obsval\"] = df.obsval", "response": "try to run INSCHEK for each instruction file model output\n            file pair in a pyemu. Pst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_phi_comps_from_recfile(recfile):\n    iiter = 1\n    iters = {}\n    f = open(recfile,'r')\n    while True:\n        line = f.readline()\n        if line == '':\n            break\n        if \"starting phi for this iteration\" in line.lower() or \\\n            \"final phi\" in line.lower():\n            contributions = {}\n            while True:\n                line = f.readline()\n                if line == '':\n                    break\n                if \"contribution to phi\" not in line.lower():\n                    iters[iiter] = contributions\n                    iiter += 1\n                    break\n                raw = line.strip().split()\n                val = float(raw[-1])\n                group = raw[-3].lower().replace('\\\"', '')\n                contributions[group] = val\n    return iters", "response": "read the phi components from a record file by iteration"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\ncreate a generic residual dataframe filled with np. NaN for missing information", "response": "def res_from_obseravtion_data(observation_data):\n    \"\"\"create a generic residual dataframe filled with np.NaN for\n    missing information\n\n    Parameters\n    ----------\n    observation_data : pandas.DataFrame\n        pyemu.Pst.observation_data\n\n    Returns\n    -------\n    res_df : pandas.DataFrame\n\n    \"\"\"\n    res_df = observation_data.copy()\n    res_df.loc[:, \"name\"] = res_df.pop(\"obsnme\")\n    res_df.loc[:, \"measured\"] = res_df.pop(\"obsval\")\n    res_df.loc[:, \"group\"] = res_df.pop(\"obgnme\")\n    res_df.loc[:, \"modelled\"] = np.NaN\n    res_df.loc[:, \"residual\"] = np.NaN\n    return res_df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfixing the issue where some terrible fortran program may have written a floating point format without the 'e' - like 1.0-3, really?! Parameters ---------- pst_filename : str the pest control file clean_filename : str the new pest control file to write. Default is \"clean.pst\" Returns ------- None", "response": "def clean_missing_exponent(pst_filename,clean_filename=\"clean.pst\"):\n    \"\"\"fixes the issue where some terrible fortran program may have\n    written a floating point format without the 'e' - like 1.0-3, really?!\n\n    Parameters\n    ----------\n    pst_filename : str\n        the pest control file\n    clean_filename : str\n        the new pest control file to write. Default is \"clean.pst\"\n\n    Returns\n    -------\n    None\n\n\n    \"\"\"\n    lines = []\n    with open(pst_filename,'r') as f:\n        for line in f:\n            line = line.lower().strip()\n            if '+' in line:\n                raw = line.split('+')\n                for i,r in enumerate(raw[:-1]):\n                    if r[-1] != 'e':\n                        r = r + 'e'\n                    raw[i] = r\n                lines.append('+'.join(raw))\n            else:\n                lines.append(line)\n    with open(clean_filename,'w') as f:\n        for line in lines:\n            f.write(line+'\\n')"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef phi(self):\n        sum = 0.0\n        for grp, contrib in self.phi_components.items():\n            sum += contrib\n        return sum", "response": "get the weighted total objective function"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the individual components of the total objective function", "response": "def phi_components(self):\n        \"\"\" get the individual components of the total objective function\n\n        Returns\n        -------\n        dict : dict\n            dictionary of observation group, contribution to total phi\n\n        Raises\n        ------\n        Assertion error if Pst.observation_data groups don't match\n        Pst.res groups\n\n        \"\"\"\n\n        # calculate phi components for each obs group\n        components = {}\n        ogroups = self.observation_data.groupby(\"obgnme\").groups\n        rgroups = self.res.groupby(\"group\").groups\n        self.res.index = self.res.name\n        for og,onames in ogroups.items():\n            #assert og in rgroups.keys(),\"Pst.phi_componentw obs group \" +\\\n            #    \"not found: \" + str(og)\n            #og_res_df = self.res.ix[rgroups[og]]\n            og_res_df = self.res.loc[onames,:].dropna()\n            #og_res_df.index = og_res_df.name\n            og_df = self.observation_data.ix[ogroups[og]]\n            og_df.index = og_df.obsnme\n            #og_res_df = og_res_df.loc[og_df.index,:]\n            assert og_df.shape[0] == og_res_df.shape[0],\\\n            \" Pst.phi_components error: group residual dataframe row length\" +\\\n            \"doesn't match observation data group dataframe row length\" + \\\n                str(og_df.shape) + \" vs. \" + str(og_res_df.shape)\n            components[og] = np.sum((og_res_df[\"residual\"] *\n                                     og_df[\"weight\"]) ** 2)\n        if not self.control_data.pestmode.startswith(\"reg\") and \\\n            self.prior_information.shape[0] > 0:\n            ogroups = self.prior_information.groupby(\"obgnme\").groups\n            for og in ogroups.keys():\n                assert og in rgroups.keys(),\"Pst.adjust_weights_res() obs group \" +\\\n                    \"not found: \" + str(og)\n                og_res_df = self.res.ix[rgroups[og]]\n                og_res_df.index = og_res_df.name\n                og_df = self.prior_information.ix[ogroups[og]]\n                og_df.index = og_df.pilbl\n                og_res_df = og_res_df.loc[og_df.index,:]\n                assert og_df.shape[0] == og_res_df.shape[0],\\\n                \" Pst.phi_components error: group residual dataframe row length\" +\\\n                \"doesn't match observation data group dataframe row length\" + \\\n                    str(og_df.shape) + \" vs. \" + str(og_res_df.shape)\n                components[og] = np.sum((og_res_df[\"residual\"] *\n                                         og_df[\"weight\"]) ** 2)\n\n        return components"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the individual components of the total objective function normalized to the total PHI being 1. 0", "response": "def phi_components_normalized(self):\n        \"\"\" get the individual components of the total objective function\n            normalized to the total PHI being 1.0\n\n        Returns\n        -------\n        dict : dict\n            dictionary of observation group, normalized contribution to total phi\n\n        Raises\n        ------\n        Assertion error if self.observation_data groups don't match\n        self.res groups\n\n        \"\"\"\n        # use a dictionary comprehension to go through and normalize each component of phi to the total\n        phi_components_normalized = {i: self.phi_components[i]/self.phi for i in self.phi_components}\n        return phi_components_normalized"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_res(self,res):\n        if isinstance(res,str):\n            res = pst_utils.read_resfile(res)\n        self.__res = res", "response": "reset the private Pst. res attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef res(self):\n        if self.__res is not None:\n            return self.__res\n        else:\n            if self.resfile is not None:\n                assert os.path.exists(self.resfile),\"Pst.res: self.resfile \" +\\\n                    str(self.resfile) + \" does not exist\"\n            else:\n                self.resfile = self.filename.replace(\".pst\", \".res\")\n                if not os.path.exists(self.resfile):\n                    self.resfile = self.resfile.replace(\".res\", \".rei\")\n                    if not os.path.exists(self.resfile):\n                        self.resfile = self.resfile.replace(\".rei\", \".base.rei\")\n                        if not os.path.exists(self.resfile):\n                            if self.new_filename is not None:\n                                self.resfile = self.new_filename.replace(\".pst\",\".res\")\n                                if not os.path.exists(self.resfile):\n                                    self.resfile = self.resfile.replace(\".res\",\"rei\")\n                                    if not os.path.exists(self.resfile):\n                                        raise Exception(\"Pst.res: \" +\n                                                        \"could not residual file case.res\" +\n                                                        \" or case.rei\" + \" or case.base.rei\" +\n                                                        \" or case.obs.csv\")\n\n\n            res = pst_utils.read_resfile(self.resfile)\n            missing_bool = self.observation_data.obsnme.apply\\\n                (lambda x: x not in res.name)\n            missing = self.observation_data.obsnme[missing_bool]\n            if missing.shape[0] > 0:\n                raise Exception(\"Pst.res: the following observations \" +\n                                \"were not found in \" +\n                                \"{0}:{1}\".format(self.resfile,','.join(missing)))\n            self.__res = res\n            return self.__res", "response": "get the residuals dataframe attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef nprior(self):\n        self.control_data.nprior = self.prior_information.shape[0]\n        return self.control_data.nprior", "response": "get the number of prior information equations\n       "}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the number of non - zero weighted observations in the log", "response": "def nnz_obs(self):\n        \"\"\" get the number of non-zero weighted observations\n\n        Returns\n        -------\n        nnz_obs : int\n            the number of non-zeros weighted observations\n\n        \"\"\"\n        nnz = 0\n        for w in self.observation_data.weight:\n            if w > 0.0:\n                nnz += 1\n        return nnz"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef nobs(self):\n        self.control_data.nobs = self.observation_data.shape[0]\n        return self.control_data.nobs", "response": "get the number of observations in the control data"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets the number of adjustable parameters", "response": "def npar_adj(self):\n        \"\"\"get the number of adjustable parameters (not fixed or tied)\n\n        Returns\n        -------\n        npar_adj : int\n            the number of adjustable parameters\n\n        \"\"\"\n        pass\n        np = 0\n        for t in self.parameter_data.partrans:\n            if t not in [\"fixed\", \"tied\"]:\n                np += 1\n        return np"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting number of parameters", "response": "def npar(self):\n        \"\"\"get number of parameters\n\n        Returns\n        -------\n        npar : int\n            the number of parameters\n\n        \"\"\"\n        self.control_data.npar = self.parameter_data.shape[0]\n        return self.control_data.npar"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef pars_in_groups(self):\n        pargp = self.par_groups\n        allpars = dict()\n        for cpg in pargp:\n            allpars[cpg] = [i for i in self.parameter_data.loc[self.parameter_data.pargp == cpg, 'parnme']]\n        return allpars", "response": "Returns a dictionary of all the parameter names in each parameter group."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef forecast_names(self):\n        if \"forecasts\" in self.pestpp_options.keys():\n            return self.pestpp_options[\"forecasts\"].lower().split(',')\n        elif \"predictions\" in self.pestpp_options.keys():\n            return self.pestpp_options[\"predictions\"].lower().split(',')\n        else:\n            return None", "response": "get the forecast names from the pestpp options if any. Returns None if no forecasts are named\n        Returns a list of forecast names."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef obs_groups(self):\n        og = list(self.observation_data.groupby(\"obgnme\").groups.keys())\n        #og = list(map(pst_utils.SFMT, og))\n        return og", "response": "get the observation groups\n           "}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef nnz_obs_groups(self):\n        og = []\n        obs = self.observation_data\n        for g in self.obs_groups:\n            if obs.loc[obs.obgnme==g,\"weight\"].sum() > 0.0:\n                og.append(g)\n        return og", "response": "get the list of observation groups that contain at least one non - zero weighted\n         observation\n           "}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the parameter groups with at least one adjustable parameter Returns ------- list of parameter groups with at least one adjustable parameter", "response": "def adj_par_groups(self):\n        \"\"\"get the parameter groups with atleast one adjustable parameter\n\n        Returns\n        -------\n        adj_par_groups : list\n            a list of parameter groups with  at least one adjustable parameter\n\n        \"\"\"\n        adj_pargp = []\n        for pargp in self.par_groups:\n            ptrans = self.parameter_data.loc[self.parameter_data.pargp==pargp,\"partrans\"].values\n            if \"log\" in ptrans or \"none\" in ptrans:\n                adj_pargp.append(pargp)\n        return adj_pargp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the prior info groups", "response": "def prior_groups(self):\n        \"\"\"get the prior info groups\n\n        Returns\n        -------\n        prior_groups : list\n            a list of prior information groups\n\n        \"\"\"\n        og = list(self.prior_information.groupby(\"obgnme\").groups.keys())\n        #og = list(map(pst_utils.SFMT, og))\n        return og"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the prior information names", "response": "def prior_names(self):\n        \"\"\" get the prior information names\n\n        Returns\n        -------\n        prior_names : list\n            a list of prior information names\n\n        \"\"\"\n        return list(self.prior_information.groupby(\n                self.prior_information.index).groups.keys())"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef adj_par_names(self):\n        adj_names = []\n        for t,n in zip(self.parameter_data.partrans,\n                       self.parameter_data.parnme):\n            if t.lower() not in [\"tied\",\"fixed\"]:\n                adj_names.append(n)\n        return adj_names", "response": "get the adjustable parameter names"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the non - zero weight observation names Returns ------- list a list of non - zero weighted observation names", "response": "def nnz_obs_names(self):\n        \"\"\"get the non-zero weight observation names\n\n        Returns\n        -------\n        nnz_obs_names : list\n            a list of non-zero weighted observation names\n\n        \"\"\"\n        # nz_names = []\n        # for w,n in zip(self.observation_data.weight,\n        #                self.observation_data.obsnme):\n        #     if w > 0.0:\n        #         nz_names.append(n)\n        obs = self.observation_data\n\n        nz_names = list(obs.loc[obs.weight>0.0,\"obsnme\"])\n        return nz_names"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the zero - weighted observation names returns a list of zero - weighted observation names", "response": "def zero_weight_obs_names(self):\n        \"\"\" get the zero-weighted observation names\n\n        Returns\n        -------\n         zero_weight_obs_names : list\n             a list of zero-weighted observation names\n\n        \"\"\"\n        self.observation_data.index = self.observation_data.obsnme\n        groups = self.observation_data.groupby(\n                self.observation_data.weight.apply(lambda x: x==0.0)).groups\n        if True in groups:\n            return list(self.observation_data.loc[groups[True],\"obsnme\"])\n        else:\n            return []"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _load_version2(self,filename):\n        self.lcount  = 0\n        self.comments = {}\n        self.prior_information = self.null_prior\n        assert os.path.exists(filename), \"couldn't find control file {0}\".format(filename)\n        f = open(filename, 'r')\n        last_section = \"\"\n        req_sections = {\"* parameter data\":False, \"* observation data\":False,\n                        \"* model command line\":False,\"* model input\":False, \"* model output\":False}\n        while True:\n\n            next_section, section_lines, comments = self._read_section_comments(f, True)\n\n\n            if \"* control data\" in last_section.lower():\n                req_sections[last_section] = True\n                iskeyword = False\n                if \"keyword\" in last_section.lower():\n                    iskeyword = True\n                self.pestpp_options = self.control_data.parse_values_from_lines(section_lines, iskeyword=iskeyword)\n                if len(self.pestpp_options) > 0:\n                    ppo = self.pestpp_options\n                    svd_opts = [\"svdmode\",\"eigthresh\",\"maxsing\",\"eigwrite\"]\n                    for svd_opt in svd_opts:\n                        if svd_opt in ppo:\n                            self.svd_data.__setattr__(svd_opt, ppo.pop(svd_opt))\n                    for reg_opt in self.reg_data.should_write:\n                        if reg_opt in ppo:\n                            self.reg_data.__setattr__(reg_opt, ppo.pop(reg_opt))\n\n            elif \"* parameter groups\" in last_section.lower():\n                req_sections[last_section] = True\n                self.parameter_groups = self._cast_df_from_lines(next_section, section_lines, self.pargp_fieldnames,\n                                                                self.pargp_converters, self.pargp_defaults)\n                self.parameter_groups.index = self.parameter_groups.pargpnme\n\n            elif \"* parameter data\" in last_section.lower():\n                req_sections[last_section] = True\n                self.parameter_data = self._cast_df_from_lines(next_section, section_lines, self.par_fieldnames,\n                                                               self.par_converters, self.par_defaults)\n                self.parameter_data.index = self.parameter_data.parnme\n\n            elif \"* observation data\" in last_section.lower():\n                req_sections[last_section] = True\n                self.observation_data = self._cast_df_from_lines(next_section, section_lines, self.obs_fieldnames,\n                                                                self.obs_converters, self.obs_defaults)\n                self.observation_data.index = self.observation_data.obsnme\n\n            elif \"* model command line\" in last_section.lower():\n                req_sections[last_section] = True\n                for line in section_lines:\n                    self.model_command.append(line.strip())\n\n            elif \"* model input\" in last_section.lower():\n                req_sections[last_section] = True\n                if section_lines[0].strip().split()[0].lower() == \"external\":\n                    filename = section_lines[0].strip().split()[1]\n                    assert os.path.exists(filename),\"Pst.flex_load() external template data file '{0}' not found\".format(filename)\n                    df = pd.read_csv(filename)\n                    df.columns = df.columns.str.lower()\n                    assert \"pest_file\" in df.columns,\"Pst.flex_load() external template data file must have 'pest_file' in columns\"\n                    assert \"model_file\" in df.columns, \"Pst.flex_load() external template data file must have 'model_file' in columns\"\n                    for pfile,mfile in zip(df.pest_file,df.model_file):\n                        self.template_files.append(pfile)\n                        self.input_files.append(mfile)\n\n                else:\n                    for iline,line in enumerate(section_lines):\n                        raw = line.split()\n                        self.template_files.append(raw[0])\n                        self.input_files.append(raw[1])\n\n            elif \"* model output\" in last_section.lower():\n                req_sections[last_section] = True\n                if section_lines[0].strip().split()[0].lower() == \"external\":\n                    filename = section_lines[0].strip().split()[1]\n                    assert os.path.exists(filename), \"Pst.flex_load() external instruction data file '{0}' not found\".format(\n                        filename)\n                    df = pd.read_csv(filename)\n                    df.columns = df.columns.str.lower()\n                    assert \"pest_file\" in df.columns, \"Pst.flex_load() external instruction data file must have 'pest_file' in columns\"\n                    assert \"model_file\" in df.columns, \"Pst.flex_load() external instruction data file must have 'model_file' in columns\"\n                    for pfile, mfile in zip(df.pest_file, df.model_file):\n                        self.instruction_files.append(pfile)\n                        self.output_files.append(mfile)\n                else:\n                    for iline, line in enumerate(section_lines):\n                        raw = line.split()\n                        self.instruction_files.append(raw[0])\n                        self.output_files.append(raw[1])\n\n            elif \"* prior information\" in last_section.lower():\n                req_sections[last_section] = True\n                self._cast_prior_df_from_lines(section_lines)\n\n            elif len(last_section) > 0:\n                print(\"Pst._load_version2() warning: unrecognized section: \", last_section)\n                self.comments[last_section] = section_lines\n\n            last_section = next_section\n            if next_section == None or len(section_lines) == 0:\n                break\n\n        not_found = []\n        for section,found in req_sections.items():\n            if not found:\n                not_found.append(section)\n        if len(not_found) > 0:\n            raise Exception(\"Pst._load_version2() error: the following required sections were\"+\\\n                    \"not found:{0}\".format(\",\".join(not_found)))", "response": "load a version 2 control file"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef load(self,filename):\n        assert os.path.exists(filename), \"couldn't find control file {0}\".format(filename)\n        f = open(filename, 'r')\n\n        while True:\n            line = f.readline()\n            if line == \"\":\n                raise Exception(\"Pst.load() error: EOF when trying to find first line - #sad\")\n            if line.strip().split()[0].lower() == \"pcf\":\n                break\n        assert line.startswith(\"pcf\"), \"Pst.load() error: first noncomment line must start with 'pcf', not '{0}'\".format(line)\n        raw = line.strip().split()\n\n        if len(raw) > 1 and \"version\" in raw[1].lower():\n            raw = raw[1].split('=')\n            if len(raw) > 1:\n                try:\n                    self._version = int(raw[1])\n                except:\n                    pass\n        if self._version == 1:\n            self._load_version1(filename)\n        elif self._version == 2:\n            self._load_version2(filename)\n        else:\n            raise Exception(\"Pst.load() error: version must be 1 or 2, not '{0}'\".format(version))", "response": "load the pest control file"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nload a version 1 pest control file information", "response": "def _load_version1(self, filename):\n        \"\"\"load a version 1 pest control file information\n\n        Parameters\n        ----------\n        filename : str\n            pst filename\n\n        Raises\n        ------\n            lots of exceptions for incorrect format\n\n        \"\"\"\n\n        f = open(filename, 'r')\n        f.readline()\n\n        #control section\n        line = f.readline()\n\n        assert \"* control data\" in line,\\\n            \"Pst.load() error: looking for control\" +\\\n            \" data section, found:\" + line\n        iskeyword = False\n        if \"keyword\" in line.lower():\n            iskeyword = True\n        control_lines = []\n        while True:\n            line = f.readline()\n            if line == '':\n                raise Exception(\"Pst.load() EOF while \" +\\\n                                \"reading control data section\")\n            if line.startswith('*'):\n                break\n            control_lines.append(line)\n        self.control_data.parse_values_from_lines(control_lines,iskeyword)\n\n\n        #anything between control data and SVD\n        while True:\n            if line == '':\n                raise Exception(\"EOF before parameter groups section found\")\n            if \"* singular value decomposition\" in line.lower() or\\\n                \"* parameter groups\" in line.lower():\n                break\n            self.other_lines.append(line)\n            line = f.readline()\n\n        if \"* singular value decomposition\" in line.lower():\n            svd_lines = []\n            for _ in range(3):\n                line = f.readline()\n                if line == '':\n                    raise Exception(\"EOF while reading SVD section\")\n                svd_lines.append(line)\n            self.svd_data.parse_values_from_lines(svd_lines)\n            line = f.readline()\n        while True:\n            if line == '':\n                raise Exception(\"EOF before parameter groups section found\")\n            if \"* parameter groups\" in line.lower():\n                break\n            self.other_lines.append(line)\n            line = f.readline()\n\n        #parameter data\n        assert \"* parameter groups\" in line.lower(),\\\n            \"Pst.load() error: looking for parameter\" +\\\n            \" group section, found:\" + line\n        #try:\n        self.parameter_groups = self._read_df(f,self.control_data.npargp,\n                                              self.pargp_fieldnames,\n                                              self.pargp_converters,\n                                              self.pargp_defaults)\n        self.parameter_groups.index = self.parameter_groups.pargpnme\n        #except Exception as e:\n        #    raise Exception(\"Pst.load() error reading parameter groups: {0}\".format(str(e)))\n\n        #parameter data\n        line = f.readline()\n        assert \"* parameter data\" in line.lower(),\\\n            \"Pst.load() error: looking for parameter\" +\\\n            \" data section, found:\" + line\n\n        try:\n            self.parameter_data = self._read_df(f,self.control_data.npar,\n                                                self.par_fieldnames,\n                                                self.par_converters,\n                                                self.par_defaults)\n            self.parameter_data.index = self.parameter_data.parnme\n        except Exception as e:\n            raise Exception(\"Pst.load() error reading parameter data: {0}\".format(str(e)))\n\n        # oh the tied parameter bullshit, how do I hate thee\n        counts = self.parameter_data.partrans.value_counts()\n        if \"tied\" in counts.index:\n            # tied_lines = [f.readline().lower().strip().split() for _ in range(counts[\"tied\"])]\n            # self.tied = pd.DataFrame(tied_lines,columns=[\"parnme\",\"partied\"])\n            # self.tied.index = self.tied.pop(\"parnme\")\n            tied = self._read_df(f,counts[\"tied\"],self.tied_fieldnames,\n                                      self.tied_converters)\n            tied.index = tied.parnme\n            self.parameter_data.loc[:,\"partied\"] = np.NaN\n            self.parameter_data.loc[tied.index,\"partied\"] = tied.partied\n\n        # obs groups - just read past for now\n\n        line = f.readline()\n        # assert \"* observation groups\" in line.lower(),\\\n        #     \"Pst.load() error: looking for obs\" +\\\n        #     \" group section, found:\" + line\n        # [f.readline() for _ in range(self.control_data.nobsgp)]\n        if \"* observation groups\" in line:\n            while True:\n                seekpoint = f.tell()\n                line = f.readline()\n                if line == \"\":\n                    raise Exception(\"Pst.load() error: EOF when searching for '* observation data'\")\n                if line.startswith(\"*\"):\n                    f.seek(seekpoint)\n                    break\n            line = f.readline()\n            assert \"* observation data\" in line.lower(), \\\n                \"Pst.load() error: looking for observation\" + \\\n                \" data section, found:\" + line\n        else:\n\n            assert \"* observation data\" in line.lower(),\\\n                \"Pst.load() error: looking for observation\" +\\\n                \" data section, found:\" + line\n\n        try:\n            self.observation_data = self._read_df(f,self.control_data.nobs,\n                                                  self.obs_fieldnames,\n                                                  self.obs_converters)\n            self.observation_data.index = self.observation_data.obsnme\n        except Exception as e:\n            raise Exception(\"Pst.load() error reading observation data: {0}\".format(str(e)))\n        #model command line\n        line = f.readline()\n        assert \"* model command line\" in line.lower(),\\\n            \"Pst.load() error: looking for model \" +\\\n            \"command section, found:\" + line\n        for i in range(self.control_data.numcom):\n            self.model_command.append(f.readline().strip())\n\n        #model io\n        line = f.readline()\n        assert \"* model input/output\" in line.lower(), \\\n            \"Pst.load() error; looking for model \" +\\\n            \" i/o section, found:\" + line\n\n        for i in range(self.control_data.ntplfle):\n            raw = f.readline().strip().split()\n            self.template_files.append(raw[0])\n            self.input_files.append(raw[1])\n        for i in range(self.control_data.ninsfle):\n            raw = f.readline().strip().split()\n            self.instruction_files.append(raw[0])\n            self.output_files.append(raw[1])\n\n        #prior information - sort of hackish\n        if self.control_data.nprior == 0:\n            self.prior_information = self.null_prior\n        else:\n            pilbl, obgnme, weight, equation = [], [], [], []\n            line = f.readline()\n            assert \"* prior information\" in line.lower(), \\\n                \"Pst.load() error; looking for prior \" +\\\n                \" info section, found:\" + line\n            for iprior in range(self.control_data.nprior):\n                line = f.readline()\n                if line == '':\n                    raise Exception(\"EOF during prior information \" +\n                                    \"section\")\n                raw = line.strip().split()\n                pilbl.append(raw[0].lower())\n                obgnme.append(raw[-1].lower())\n                weight.append(float(raw[-2]))\n                eq = ' '.join(raw[1:-2])\n                equation.append(eq)\n            self.prior_information = pd.DataFrame({\"pilbl\": pilbl,\n                                                       \"equation\": equation,\n                                                       \"weight\": weight,\n                                                       \"obgnme\": obgnme})\n            self.prior_information.index = self.prior_information.pilbl\n        if \"regul\" in self.control_data.pestmode:\n            line = f.readline()\n            assert \"* regul\" in line.lower(), \\\n                \"Pst.load() error; looking for regul \" +\\\n                \" section, found:\" + line\n            #[self.regul_lines.append(f.readline()) for _ in range(3)]\n            regul_lines = [f.readline() for _ in range(3)]\n            raw = regul_lines[0].strip().split()\n            self.reg_data.phimlim = float(raw[0])\n            self.reg_data.phimaccept = float(raw[1])\n            raw = regul_lines[1].strip().split()\n            self.wfinit = float(raw[0])\n\n\n        for line in f:\n            if line.strip().startswith(\"++\") and '#' not in line:\n                self._parse_pestpp_line(line)\n        f.close()\n\n        for df in [self.parameter_groups,self.parameter_data,\n                   self.observation_data,self.prior_information]:\n            if \"extra\" in df.columns and df.extra.dropna().shape[0] > 0:\n                self.with_comments = False\n                break\n        return"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_pi_equation(self,par_names,pilbl=None,rhs=0.0,weight=1.0,\n                        obs_group=\"pi_obgnme\",coef_dict={}):\n        \"\"\" a helper to construct a new prior information equation.\n\n        Parameters\n        ----------\n        par_names : list\n            parameter names in the equation\n        pilbl : str\n            name to assign the prior information equation.  If None,\n            a generic equation name is formed. Default is None\n        rhs : (float)\n            the right-hand side of the equation\n        weight : (float)\n            the weight of the equation\n        obs_group : str\n            the observation group for the equation. Default is 'pi_obgnme'\n        coef_dict : dict\n            a dictionary of parameter name, coefficient pairs to assign\n            leading coefficients for one or more parameters in the equation.\n            If a parameter is not listed, 1.0 is used for its coefficients.\n            Default is {}\n\n        \"\"\"\n        if pilbl is None:\n            pilbl = \"pilbl_{0}\".format(self.__pi_count)\n            self.__pi_count += 1\n        missing,fixed = [],[]\n\n        for par_name in par_names:\n            if par_name not in self.parameter_data.parnme:\n                missing.append(par_name)\n            elif self.parameter_data.loc[par_name,\"partrans\"] in [\"fixed\",\"tied\"]:\n                fixed.append(par_name)\n        if len(missing) > 0:\n            raise Exception(\"Pst.add_pi_equation(): the following pars \"+\\\n                            \" were not found: {0}\".format(','.join(missing)))\n        if len(fixed) > 0:\n            raise Exception(\"Pst.add_pi_equation(): the following pars \"+\\\n                            \" were are fixed/tied: {0}\".format(','.join(missing)))\n        eqs_str = ''\n        sign = ''\n        for i,par_name in enumerate(par_names):\n            coef = coef_dict.get(par_name,1.0)\n            if coef < 0.0:\n                sign = '-'\n                coef = np.abs(coef)\n            elif i > 0: sign = '+'\n            if self.parameter_data.loc[par_name,\"partrans\"] == \"log\":\n                par_name = \"log({})\".format(par_name)\n            eqs_str += \" {0} {1} * {2} \".format(sign,coef,par_name)\n        eqs_str += \" = {0}\".format(rhs)\n        self.prior_information.loc[pilbl,\"pilbl\"] = pilbl\n        self.prior_information.loc[pilbl,\"equation\"] = eqs_str\n        self.prior_information.loc[pilbl,\"weight\"] = weight\n        self.prior_information.loc[pilbl,\"obgnme\"] = obs_group", "response": "a helper method to construct a new prior information equation."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rectify_pi(self):\n        if self.prior_information.shape[0] == 0:\n            return\n        self._parse_pi_par_names()\n        adj_names = self.adj_par_names\n        def is_good(names):\n            for n in names:\n                if n not in adj_names:\n                    return False\n            return True\n        keep_idx = self.prior_information.names.\\\n            apply(lambda x: is_good(x))\n        self.prior_information = self.prior_information.loc[keep_idx,:]", "response": "rectify the prior information equation with the current state of the parameter_data dataframe."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite a new pest control file.", "response": "def write(self,new_filename,update_regul=True,version=None):\n        \"\"\"main entry point to write a pest control file.\n\n         Parameters\n        ----------\n        new_filename : str\n            name of the new pest control file\n        update_regul : (boolean)\n            flag to update zero-order Tikhonov prior information\n            equations to prefer the current parameter values\n        version : int\n            flag for which version of control file to write (must be 1 or 2).\n            if None, uses Pst._version, which set in the constructor and modified\n            during the load\n\n        \"\"\"\n        if version is None:\n            version = self._version\n\n        if version == 1:\n            return self._write_version1(new_filename=new_filename,update_regul=update_regul)\n        elif version == 2:\n            return self._write_version2(new_filename=new_filename, update_regul=update_regul)\n        else:\n            raise Exception(\"Pst.write() error: version must be 1 or 2, not '{0}'\".format(version))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_version1(self,new_filename,update_regul=False):\n        self.new_filename = new_filename\n        self.rectify_pgroups()\n        self.rectify_pi()\n        self._update_control_section()\n        self.sanity_checks()\n\n        f_out = open(new_filename, 'w')\n        if self.with_comments:\n            for line in self.comments.get(\"initial\",[]):\n                f_out.write(line+'\\n')\n        f_out.write(\"pcf\\n* control data\\n\")\n        self.control_data.write(f_out)\n\n        # for line in self.other_lines:\n        #     f_out.write(line)\n        if self.with_comments:\n            for line in self.comments.get(\"* singular value decompisition\",[]):\n                f_out.write(line)\n        self.svd_data.write(f_out)\n\n        #f_out.write(\"* parameter groups\\n\")\n\n        # to catch the byte code ugliness in python 3\n        pargpnme = self.parameter_groups.loc[:,\"pargpnme\"].copy()\n        self.parameter_groups.loc[:,\"pargpnme\"] = \\\n            self.parameter_groups.pargpnme.apply(self.pargp_format[\"pargpnme\"])\n\n        self._write_df(\"* parameter groups\", f_out, self.parameter_groups,\n                       self.pargp_format, self.pargp_fieldnames)\n        self.parameter_groups.loc[:,\"pargpnme\"] = pargpnme\n\n        self._write_df(\"* parameter data\",f_out, self.parameter_data,\n                       self.par_format, self.par_fieldnames)\n\n        if self.tied is not None:\n            self._write_df(\"tied parameter data\", f_out, self.tied,\n                           self.tied_format, self.tied_fieldnames)\n\n        f_out.write(\"* observation groups\\n\")\n        for group in self.obs_groups:\n            try:\n                group = group.decode()\n            except:\n                pass\n            f_out.write(pst_utils.SFMT(str(group))+'\\n')\n        for group in self.prior_groups:\n            try:\n                group = group.decode()\n            except:\n                pass\n            f_out.write(pst_utils.SFMT(str(group))+'\\n')\n\n        self._write_df(\"* observation data\", f_out, self.observation_data,\n                       self.obs_format, self.obs_fieldnames)\n\n        f_out.write(\"* model command line\\n\")\n        for cline in self.model_command:\n            f_out.write(cline+'\\n')\n\n        f_out.write(\"* model input/output\\n\")\n        for tplfle,infle in zip(self.template_files,self.input_files):\n            f_out.write(tplfle+' '+infle+'\\n')\n        for insfle,outfle in zip(self.instruction_files,self.output_files):\n            f_out.write(insfle+' '+outfle+'\\n')\n\n        if self.nprior > 0:\n            if self.prior_information.isnull().values.any():\n                #print(\"WARNING: NaNs in prior_information dataframe\")\n                warnings.warn(\"NaNs in prior_information dataframe\",PyemuWarning)\n            f_out.write(\"* prior information\\n\")\n            #self.prior_information.index = self.prior_information.pop(\"pilbl\")\n            max_eq_len = self.prior_information.equation.apply(lambda x:len(x)).max()\n            eq_fmt_str =  \" {0:<\" + str(max_eq_len) + \"s} \"\n            eq_fmt_func = lambda x:eq_fmt_str.format(x)\n            #  17/9/2016 - had to go with a custom writer loop b/c pandas doesn't want to\n            # output strings longer than 100, even with display.max_colwidth\n            #f_out.write(self.prior_information.to_string(col_space=0,\n            #                                  columns=self.prior_fieldnames,\n            #                                  formatters=pi_formatters,\n            #                                  justify=\"right\",\n            #                                  header=False,\n            #                                 index=False) + '\\n')\n            #self.prior_information[\"pilbl\"] = self.prior_information.index\n            # for idx,row in self.prior_information.iterrows():\n            #     f_out.write(pst_utils.SFMT(row[\"pilbl\"]))\n            #     f_out.write(eq_fmt_func(row[\"equation\"]))\n            #     f_out.write(pst_utils.FFMT(row[\"weight\"]))\n            #     f_out.write(pst_utils.SFMT(row[\"obgnme\"]) + '\\n')\n            for idx, row in self.prior_information.iterrows():\n                f_out.write(pst_utils.SFMT(row[\"pilbl\"]))\n                f_out.write(eq_fmt_func(row[\"equation\"]))\n                f_out.write(pst_utils.FFMT(row[\"weight\"]))\n                f_out.write(pst_utils.SFMT(row[\"obgnme\"]))\n                if self.with_comments and 'extra' in row:\n                    f_out.write(\" # {0}\".format(row['extra']))\n                f_out.write('\\n')\n\n        if self.control_data.pestmode.startswith(\"regul\"):\n            #f_out.write(\"* regularisation\\n\")\n            #if update_regul or len(self.regul_lines) == 0:\n            #    f_out.write(self.regul_section)\n            #else:\n            #    [f_out.write(line) for line in self.regul_lines]\n            self.reg_data.write(f_out)\n\n        for line in self.other_lines:\n            f_out.write(line+'\\n')\n\n        for key,value in self.pestpp_options.items():\n            if isinstance(value,list):\n                value  = ','.join([str(v) for v in value])\n            f_out.write(\"++{0}({1})\\n\".format(str(key),str(value)))\n\n        if self.with_comments:\n            for line in self.comments.get(\"final\",[]):\n                f_out.write(line+'\\n')\n\n        f_out.close()", "response": "write a version 1 pest control file containing the current state of the class."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get(self, par_names=None, obs_names=None):\n        pass\n        #if par_names is None and obs_names is None:\n        #    return copy.deepcopy(self)\n        if par_names is None:\n            par_names = self.parameter_data.parnme\n        if obs_names is None:\n            obs_names = self.observation_data.obsnme\n\n        new_par = self.parameter_data.copy()\n        if par_names is not None:\n            new_par.index = new_par.parnme\n            new_par = new_par.loc[par_names, :]\n        new_obs = self.observation_data.copy()\n        new_res = None\n\n        if obs_names is not None:\n            new_obs.index = new_obs.obsnme\n            new_obs = new_obs.loc[obs_names]\n            if self.__res is not None:\n                new_res = copy.deepcopy(self.res)\n                new_res.index = new_res.name\n                new_res = new_res.loc[obs_names, :]\n\n        new_pargp = self.parameter_groups.copy()\n        new_pargp.index = new_pargp.pargpnme.apply(str.strip)\n        new_pargp_names = new_par.pargp.value_counts().index\n        new_pargp = new_pargp.loc[new_pargp_names,:]\n\n        new_pst = Pst(self.filename, resfile=self.resfile, load=False)\n        new_pst.parameter_data = new_par\n        new_pst.observation_data = new_obs\n        new_pst.parameter_groups = new_pargp\n        new_pst.__res = new_res\n        new_pst.prior_information = self.prior_information\n        new_pst.rectify_pi()\n        new_pst.control_data = self.control_data.copy()\n\n        new_pst.model_command = self.model_command\n        new_pst.template_files = self.template_files\n        new_pst.input_files = self.input_files\n        new_pst.instruction_files = self.instruction_files\n        new_pst.output_files = self.output_files\n\n        if self.tied is not None:\n            warnings.warn(\"Pst.get() not checking for tied parameter \" +\n                  \"compatibility in new Pst instance\",PyemuWarning)\n            #new_pst.tied = self.tied.copy()\n        new_pst.other_lines = self.other_lines\n        new_pst.pestpp_options = self.pestpp_options\n        new_pst.regul_lines = self.regul_lines\n\n        return new_pst", "response": "get a new Pst object with subset of parameters and or observations"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreplicate the pest parrep util. replaces the parval1 field in the parameter data section dataframe with the values from the parameter file.", "response": "def parrep(self, parfile=None,enforce_bounds=True):\n        \"\"\"replicates the pest parrep util. replaces the parval1 field in the\n            parameter data section dataframe\n\n        Parameters\n        ----------\n        parfile : str\n            parameter file to use.  If None, try to use\n            a parameter file that corresponds to the case name.\n            Default is None\n        enforce_hounds : bool\n            flag to enforce parameter bounds after parameter values are updated.\n            This is useful because PEST and PEST++ round the parameter values in the\n            par file, which may cause slight bound violations\n\n        \"\"\"\n        if parfile is None:\n            parfile = self.filename.replace(\".pst\", \".par\")\n        par_df = pst_utils.read_parfile(parfile)\n        self.parameter_data.index = self.parameter_data.parnme\n        par_df.index = par_df.parnme\n        self.parameter_data.parval1 = par_df.parval1\n        self.parameter_data.scale = par_df.scale\n        self.parameter_data.offset = par_df.offset\n\n        if enforce_bounds:\n            par = self.parameter_data\n            idx = par.loc[par.parval1 > par.parubnd,\"parnme\"]\n            par.loc[idx,\"parval1\"] = par.loc[idx,\"parubnd\"]\n            idx = par.loc[par.parval1 < par.parlbnd,\"parnme\"]\n            par.loc[idx, \"parval1\"] = par.loc[idx, \"parlbnd\"]"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadjusts the weights of the observations based on the phi components of the observations in a record file", "response": "def adjust_weights_recfile(self, recfile=None,original_ceiling=True):\n        \"\"\"adjusts the weights by group of the observations based on the phi components\n        in a pest record file so that total phi is equal to the number of\n        non-zero weighted observations\n\n        Parameters\n        ----------\n        recfile : str\n            record file name.  If None, try to use a record file\n            with the Pst case name.  Default is None\n        original_ceiling : bool\n            flag to keep weights from increasing - this is generally a good idea.\n            Default is True\n\n        \"\"\"\n        if recfile is None:\n            recfile = self.filename.replace(\".pst\", \".rec\")\n        assert os.path.exists(recfile), \\\n            \"Pst.adjust_weights_recfile(): recfile not found: \" +\\\n            str(recfile)\n        iter_components = pst_utils.get_phi_comps_from_recfile(recfile)\n        iters = iter_components.keys()\n        iters.sort()\n        obs = self.observation_data\n        ogroups = obs.groupby(\"obgnme\").groups\n        last_complete_iter = None\n        for ogroup, idxs in ogroups.iteritems():\n            for iiter in iters[::-1]:\n                incomplete = False\n                if ogroup not in iter_components[iiter]:\n                    incomplete = True\n                    break\n                if not incomplete:\n                    last_complete_iter = iiter\n                    break\n        if last_complete_iter is None:\n            raise Exception(\"Pst.pwtadj2(): no complete phi component\" +\n                            \" records found in recfile\")\n        self._adjust_weights_by_phi_components(\n            iter_components[last_complete_iter],original_ceiling)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef adjust_weights_resfile(self, resfile=None,original_ceiling=True):\n        if resfile is not None:\n            self.resfile = resfile\n            self.__res = None\n        phi_comps = self.phi_components\n        self._adjust_weights_by_phi_components(phi_comps,original_ceiling)", "response": "adjusts the weights by group of the observations based on the phi components of the entry in the residual file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef adjust_weights_discrepancy(self, resfile=None,original_ceiling=True):\n        if resfile is not None:\n            self.resfile = resfile\n            self.__res = None\n        obs = self.observation_data.loc[self.nnz_obs_names,:]\n        swr = (self.res.loc[self.nnz_obs_names,:].residual * obs.weight)**2\n        factors =  (1.0/swr).apply(np.sqrt)\n        if original_ceiling:\n            factors = factors.apply(lambda x: 1.0 if x > 1.0 else x)\n        self.observation_data.loc[self.nnz_obs_names,\"weight\"] *= factors", "response": "adjusts the weights of each non - zero weight observation based\n            on the residual in the pest residual file so each observation based\n            to phi is 1. 0"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _adjust_weights_by_phi_components(self, components,original_ceiling):\n        obs = self.observation_data\n        nz_groups = obs.groupby(obs[\"weight\"].map(lambda x: x == 0)).groups\n        ogroups = obs.groupby(\"obgnme\").groups\n        for ogroup, idxs in ogroups.items():\n            if self.control_data.pestmode.startswith(\"regul\") \\\n                    and \"regul\" in ogroup.lower():\n                continue\n            og_phi = components[ogroup]\n            nz_groups = obs.loc[idxs,:].groupby(obs.loc[idxs,\"weight\"].\\\n                                                map(lambda x: x == 0)).groups\n            og_nzobs = 0\n            if False in nz_groups.keys():\n                og_nzobs = len(nz_groups[False])\n            if og_nzobs == 0 and og_phi > 0:\n                raise Exception(\"Pst.adjust_weights_by_phi_components():\"\n                                \" no obs with nonzero weight,\" +\n                                \" but phi > 0 for group:\" + str(ogroup))\n            if og_phi > 0:\n                factor = np.sqrt(float(og_nzobs) / float(og_phi))\n                if original_ceiling:\n                    factor = min(factor,1.0)\n                obs.loc[idxs,\"weight\"] = obs.weight[idxs] * factor\n        self.observation_data = obs", "response": "adjusts the weights of observations by group to account for\n        residual phi components"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _adjust_weights_by_list(self, obslist, weight):\n\n        obs = self.observation_data\n        if not isinstance(obslist, list):\n            obslist = [obslist]\n        obslist = set([str(i).lower() for i in obslist])\n        # groups = obs.groupby([lambda x:x in obslist,\n        #                     obs.weight.apply(lambda x:x==0.0)]).groups\n        # if (True,True) in groups:\n        #    obs.loc[groups[True,True],\"weight\"] = weight\n        reset_names = obs.loc[obs.apply(lambda x: x.obsnme in obslist and x.weight == 0, axis=1), \"obsnme\"]\n        if len(reset_names) > 0:\n            obs.loc[reset_names, \"weight\"] = weight", "response": "Private method to reset the weight for a list of observation names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef adjust_weights(self,obs_dict=None,\n                              obsgrp_dict=None):\n        \"\"\"reset the weights of observation groups to contribute a specified\n        amount to the composite objective function\n\n        Parameters\n        ----------\n        obs_dict : dict\n            dictionary of obs name,new contribution pairs\n        obsgrp_dict : dict\n            dictionary of obs group name,contribution pairs\n\n        Note\n        ----\n        if all observations in a named obs group have zero weight, they will be\n        assigned a non-zero weight so that the request phi contribution\n        can be met.  Similarly, any observations listed in obs_dict with zero\n        weight will also be reset\n\n        \"\"\"\n\n        self.observation_data.index = self.observation_data.obsnme\n        self.res.index = self.res.name\n\n        if obsgrp_dict is not None:\n            # reset groups with all zero weights\n            obs = self.observation_data\n            for grp in obsgrp_dict.keys():\n                if obs.loc[obs.obgnme==grp,\"weight\"].sum() == 0.0:\n                    obs.loc[obs.obgnme==grp,\"weight\"] = 1.0\n            res_groups = self.res.groupby(\"group\").groups\n            obs_groups = self.observation_data.groupby(\"obgnme\").groups\n            self.__reset_weights(obsgrp_dict, res_groups, obs_groups)\n        if obs_dict is not None:\n            # reset obs with zero weight\n            obs = self.observation_data\n            for oname in obs_dict.keys():\n                if obs.loc[oname,\"weight\"] == 0.0:\n                    obs.loc[oname,\"weight\"] = 1.0\n\n            #res_groups = self.res.groupby(\"name\").groups\n            res_groups = self.res.groupby(self.res.index).groups\n            #obs_groups = self.observation_data.groupby(\"obsnme\").groups\n            obs_groups = self.observation_data.groupby(self.observation_data.index).groups\n            self.__reset_weights(obs_dict, res_groups, obs_groups)", "response": "reset the weights of the observation groups to contribute a specified amount to the composite objective function"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef proportional_weights(self, fraction_stdev=1.0, wmax=100.0,\n                             leave_zero=True):\n        \"\"\"setup  weights inversely proportional to the observation value\n\n        Parameters\n        ----------\n        fraction_stdev : float\n            the fraction portion of the observation\n            val to treat as the standard deviation.  set to 1.0 for\n            inversely proportional\n        wmax : float\n            maximum weight to allow\n        leave_zero : bool\n            flag to leave existing zero weights\n\n        \"\"\"\n        new_weights = []\n        for oval, ow in zip(self.observation_data.obsval,\n                            self.observation_data.weight):\n            if leave_zero and ow == 0.0:\n                ow = 0.0\n            elif oval == 0.0:\n                ow = wmax\n            else:\n                nw = 1.0 / (np.abs(oval) * fraction_stdev)\n                ow = min(wmax, nw)\n            new_weights.append(ow)\n        self.observation_data.weight = new_weights", "response": "setups the weight inversely proportional to the observation value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef calculate_pertubations(self):\n        self.build_increments()\n        self.parameter_data.loc[:,\"pertubation\"] = \\\n            self.parameter_data.parval1 + \\\n            self.parameter_data.increment\n\n        self.parameter_data.loc[:,\"out_forward\"] = \\\n            self.parameter_data.loc[:,\"pertubation\"] > \\\n            self.parameter_data.loc[:,\"parubnd\"]\n\n        out_forward = self.parameter_data.groupby(\"out_forward\").groups\n        if True in out_forward:\n            self.parameter_data.loc[out_forward[True],\"pertubation\"] = \\\n                    self.parameter_data.loc[out_forward[True],\"parval1\"] - \\\n                    self.parameter_data.loc[out_forward[True],\"increment\"]\n\n            self.parameter_data.loc[:,\"out_back\"] = \\\n            self.parameter_data.loc[:,\"pertubation\"] < \\\n            self.parameter_data.loc[:,\"parlbnd\"]\n            out_back = self.parameter_data.groupby(\"out_back\").groups\n            if True in out_back:\n                still_out = out_back[True]\n                print(self.parameter_data.loc[still_out,:],flush=True)\n\n                raise Exception(\"Pst.calculate_pertubations(): \" +\\\n                                \"can't calc pertubations for the following \"+\\\n                                \"Parameters {0}\".format(','.join(still_out)))", "response": "Calculates the finite difference of the parameter values of the class attribute and the pertubation values of the class attribute."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef build_increments(self):\n        self.enforce_bounds()\n        self.add_transform_columns()\n        par_groups = self.parameter_data.groupby(\"pargp\").groups\n        inctype = self.parameter_groups.groupby(\"inctyp\").groups\n        for itype,inc_groups in inctype.items():\n            pnames = []\n            for group in inc_groups:\n                pnames.extend(par_groups[group])\n                derinc = self.parameter_groups.loc[group,\"derinc\"]\n                self.parameter_data.loc[par_groups[group],\"derinc\"] = derinc\n            if itype == \"absolute\":\n                self.parameter_data.loc[pnames,\"increment\"] = \\\n                    self.parameter_data.loc[pnames,\"derinc\"]\n            elif itype == \"relative\":\n                self.parameter_data.loc[pnames,\"increment\"] = \\\n                    self.parameter_data.loc[pnames,\"derinc\"] * \\\n                    self.parameter_data.loc[pnames,\"parval1\"]\n            elif itype == \"rel_to_max\":\n                mx = self.parameter_data.loc[pnames,\"parval1\"].max()\n                self.parameter_data.loc[pnames,\"increment\"] = \\\n                    self.parameter_data.loc[pnames,\"derinc\"] * mx\n            else:\n                raise Exception('Pst.get_derivative_increments(): '+\\\n                                'unrecognized increment type:{0}'.format(itype))\n\n        #account for fixed pars\n        isfixed = self.parameter_data.partrans==\"fixed\"\n        self.parameter_data.loc[isfixed,\"increment\"] = \\\n            self.parameter_data.loc[isfixed,\"parval1\"]", "response": "This method builds the parameter increments for the use of the internal and internal structures of the internal structures."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef enforce_bounds(self):\n        too_big = self.parameter_data.loc[:,\"parval1\"] > \\\n            self.parameter_data.loc[:,\"parubnd\"]\n        self.parameter_data.loc[too_big,\"parval1\"] = \\\n            self.parameter_data.loc[too_big,\"parubnd\"]\n\n        too_small = self.parameter_data.loc[:,\"parval1\"] < \\\n            self.parameter_data.loc[:,\"parlbnd\"]\n        self.parameter_data.loc[too_small,\"parval1\"] = \\\n            self.parameter_data.loc[too_small,\"parlbnd\"]", "response": "enforces bounds violation resulting from the\n            parameter pertubation calculations\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef from_io_files(cls,tpl_files,in_files,ins_files,out_files,pst_filename=None):\n        from pyemu import helpers\n        return helpers.pst_from_io_files(tpl_files=tpl_files,in_files=in_files,\n                                           ins_files=ins_files,out_files=out_files,\n                                         pst_filename=pst_filename)", "response": "create a Pst instance from a list of template and instruction files."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_parameters(self,template_file,in_file=None,pst_path=None):\n        assert os.path.exists(template_file),\"template file '{0}' not found\".format(template_file)\n        assert template_file != in_file\n        # get the parameter names in the template file\n        parnme = pst_utils.parse_tpl_file(template_file)\n\n        # find \"new\" parameters that are not already in the control file\n        new_parnme = [p for p in parnme if p not in self.parameter_data.parnme]\n\n        if len(new_parnme) == 0:\n            warnings.warn(\"no new parameters found in template file {0}\".format(template_file),PyemuWarning)\n            new_par_data = None\n        else:\n            # extend pa\n            # rameter_data\n            new_par_data = pst_utils.populate_dataframe(new_parnme,pst_utils.pst_config[\"par_fieldnames\"],\n                                                        pst_utils.pst_config[\"par_defaults\"],\n                                                        pst_utils.pst_config[\"par_dtype\"])\n            new_par_data.loc[new_parnme,\"parnme\"] = new_parnme\n            self.parameter_data = self.parameter_data.append(new_par_data)\n        if in_file is None:\n            in_file = template_file.replace(\".tpl\",'')\n        if pst_path is not None:\n            template_file = os.path.join(pst_path,os.path.split(template_file)[-1])\n            in_file = os.path.join(pst_path, os.path.split(in_file)[-1])\n        self.template_files.append(template_file)\n        self.input_files.append(in_file)\n\n        return new_par_data", "response": "add new parameters to the control file"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_observations(self,ins_file,out_file=None,pst_path=None,inschek=True):\n        assert os.path.exists(ins_file),\"{0}, {1}\".format(os.getcwd(),ins_file)\n        if out_file is None:\n            out_file = ins_file.replace(\".ins\",\"\")\n        assert ins_file != out_file, \"doh!\"\n\n        # get the parameter names in the template file\n        obsnme = pst_utils.parse_ins_file(ins_file)\n\n        sobsnme = set(obsnme)\n        sexist = set(self.obs_names)\n        sint = sobsnme.intersection(sexist)\n        if len(sint) > 0:\n            raise Exception(\"the following obs instruction file {0} are already in the control file:{1}\".\n                            format(ins_file,','.join(sint)))\n\n        # find \"new\" parameters that are not already in the control file\n        new_obsnme = [o for o in obsnme if o not in self.observation_data.obsnme]\n\n        if len(new_obsnme) == 0:\n            raise Exception(\"no new observations found in instruction file {0}\".format(ins_file))\n\n        # extend observation_data\n        new_obs_data = pst_utils.populate_dataframe(new_obsnme,pst_utils.pst_config[\"obs_fieldnames\"],\n                                                    pst_utils.pst_config[\"obs_defaults\"],\n                                                    pst_utils.pst_config[\"obs_dtype\"])\n        new_obs_data.loc[new_obsnme,\"obsnme\"] = new_obsnme\n        new_obs_data.index = new_obsnme\n        self.observation_data = self.observation_data.append(new_obs_data)\n        cwd = '.'\n        if pst_path is not None:\n            cwd = os.path.join(*os.path.split(ins_file)[:-1])\n            ins_file = os.path.join(pst_path,os.path.split(ins_file)[-1])\n            out_file = os.path.join(pst_path, os.path.split(out_file)[-1])\n        self.instruction_files.append(ins_file)\n        self.output_files.append(out_file)\n        df = None\n        if inschek:\n            df = pst_utils._try_run_inschek(ins_file,out_file,cwd=cwd)\n        if df is not None:\n            #print(self.observation_data.index,df.index)\n            self.observation_data.loc[df.index,\"obsval\"] = df.obsval\n            new_obs_data.loc[df.index,\"obsval\"] = df.obsval\n        return new_obs_data", "response": "add new parameters to a control file"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_res_stats(self,nonzero=True):\n        res = self.res.copy()\n        res.loc[:,\"obsnme\"] = res.pop(\"name\")\n        res.index = res.obsnme\n        if nonzero:\n            obs = self.observation_data.loc[self.nnz_obs_names,:]\n        #print(obs.shape,res.shape)\n        res = res.loc[obs.obsnme,:]\n        #print(obs.shape, res.shape)\n\n        #reset the res parts to current obs values and remove\n        #duplicate attributes\n        res.loc[:,\"weight\"] = obs.weight\n        res.loc[:,\"obsval\"] = obs.obsval\n        res.loc[:,\"obgnme\"] = obs.obgnme\n        res.pop(\"group\")\n        res.pop(\"measured\")\n\n        #build these attribute lists for faster lookup later\n        og_dict = {og:res.loc[res.obgnme==og,\"obsnme\"] for og in res.obgnme.unique()}\n        og_names = list(og_dict.keys())\n\n        # the list of functions and names\n        sfuncs = [self._stats_rss, self._stats_mean,self._stats_mae,\n                         self._stats_rmse,self._stats_nrmse]\n        snames = [\"rss\",\"mean\",\"mae\",\"rmse\",\"nrmse\"]\n\n        data = []\n        for sfunc,sname in zip(sfuncs,snames):\n            full = sfunc(res)\n            groups = [full]\n            for og in og_names:\n                onames = og_dict[og]\n                res_og = res.loc[onames,:]\n                groups.append(sfunc(res_og))\n            data.append(groups)\n\n        og_names.insert(0,\"all\")\n        df = pd.DataFrame(data,columns=og_names,index=snames)\n        return df", "response": "get some common residual stats from the current observation values weights and grouping in self. observation_data and the modelled values in self. res."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef write_par_summary_table(self,filename=None,group_names=None,\n                                sigma_range = 4.0):\n        \"\"\"write a stand alone parameter summary latex table\n\n\n        Parameters\n        ----------\n        filename : str\n            latex filename. If None, use <case>.par.tex. Default is None\n        group_names: dict\n            par group names : table names for example {\"w0\":\"well stress period 1\"}.\n            Default is None\n        sigma_range : float\n            number of standard deviations represented by parameter bounds.  Default\n            is 4.0, implying 95% confidence bounds\n\n        Returns\n        -------\n        None\n        \"\"\"\n\n        ffmt = lambda x: \"{0:5G}\".format(x)\n        par = self.parameter_data.copy()\n        pargp = par.groupby(par.pargp).groups\n        #cols = [\"parval1\",\"parubnd\",\"parlbnd\",\"stdev\",\"partrans\",\"pargp\"]\n        cols = [\"pargp\",\"partrans\",\"count\",\"parval1\",\"parubnd\",\"parlbnd\",\"stdev\"]\n\n        labels = {\"parval1\":\"initial value\",\"parubnd\":\"upper bound\",\n                  \"parlbnd\":\"lower bound\",\"partrans\":\"transform\",\n                  \"stdev\":\"standard deviation\",\"pargp\":\"type\",\"count\":\"count\"}\n\n        li = par.partrans == \"log\"\n        par.loc[li,\"parval1\"] = par.parval1.loc[li].apply(np.log10)\n        par.loc[li, \"parubnd\"] = par.parubnd.loc[li].apply(np.log10)\n        par.loc[li, \"parlbnd\"] = par.parlbnd.loc[li].apply(np.log10)\n        par.loc[:,\"stdev\"] = (par.parubnd - par.parlbnd) / sigma_range\n\n        data = {c:[] for c in cols}\n        for pg,pnames in pargp.items():\n            par_pg = par.loc[pnames,:]\n            data[\"pargp\"].append(pg)\n            for col in cols:\n                if col in [\"pargp\",\"partrans\"]:\n                    continue\n                if col == \"count\":\n                    data[\"count\"].append(par_pg.shape[0])\n                    continue\n                #print(col)\n                mn = par_pg.loc[:,col].min()\n                mx = par_pg.loc[:,col].max()\n                if mn == mx:\n                    data[col].append(ffmt(mn))\n                else:\n                    data[col].append(\"{0} to {1}\".format(ffmt(mn),ffmt(mx)))\n\n            pts = par_pg.partrans.unique()\n            if len(pts) == 1:\n                data[\"partrans\"].append(pts[0])\n            else:\n                data[\"partrans\"].append(\"mixed\")\n\n        pargp_df = pd.DataFrame(data=data,index=list(pargp.keys()))\n        pargp_df = pargp_df.loc[:, cols]\n        if group_names is not None:\n            pargp_df.loc[:, \"pargp\"] = pargp_df.pargp.apply(lambda x: group_names.pop(x, x))\n        pargp_df.columns = pargp_df.columns.map(lambda x: labels[x])\n\n        preamble = '\\\\documentclass{article}\\n\\\\usepackage{booktabs}\\n'+ \\\n                    '\\\\usepackage{pdflscape}\\n\\\\usepackage{longtable}\\n' + \\\n                    '\\\\usepackage{booktabs}\\n\\\\usepackage{nopageno}\\n\\\\begin{document}\\n'\n\n        if filename == \"none\":\n            return pargp_df\n        if filename is None:\n            filename = self.filename.replace(\".pst\",\".par.tex\")\n\n        with open(filename,'w') as f:\n            f.write(preamble)\n            f.write(\"\\\\begin{center}\\nParameter Summary\\n\\\\end{center}\\n\")\n            f.write(\"\\\\begin{center}\\n\\\\begin{landscape}\\n\")\n            pargp_df.to_latex(f, index=False, longtable=True)\n            f.write(\"\\\\end{landscape}\\n\")\n            f.write(\"\\\\end{center}\\n\")\n            f.write(\"\\\\end{document}\\n\")\n        return pargp_df", "response": "write a stand alone parameter summary latex table"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nwriting a stand alone observation summary latex table", "response": "def write_obs_summary_table(self,filename=None,group_names=None):\n        \"\"\"write a stand alone observation summary latex table\n\n\n                Parameters\n                ----------\n                filename : str\n                    latex filename. If None, use <case>.par.tex. Default is None\n                group_names: dict\n                    par group names : table names for example {\"w0\":\"well stress period 1\"}.\n                    Default is None\n\n                Returns\n                -------\n                None\n                \"\"\"\n\n        ffmt = lambda x: \"{0:5G}\".format(x)\n        obs = self.observation_data.copy()\n        obsgp = obs.groupby(obs.obgnme).groups\n        cols = [\"obgnme\",\"obsval\",\"nzcount\",\"zcount\",\"weight\",\"stdev\",\"pe\"]\n\n        labels = {\"obgnme\":\"group\",\"obsval\":\"value\",\"nzcount\":\"non-zero weight\",\n                  \"zcount\":\"zero weight\",\"weight\":\"weight\",\"stdev\":\"standard deviation\",\n                  \"pe\":\"percent error\"}\n\n        obs.loc[:,\"stdev\"] = 1.0 / obs.weight\n        obs.loc[:,\"pe\"] = 100.0 * (obs.stdev / obs.obsval.apply(np.abs))\n        obs = obs.replace([np.inf,-np.inf],np.NaN)\n\n        data = {c: [] for c in cols}\n        for og, onames in obsgp.items():\n            obs_g = obs.loc[onames, :]\n            data[\"obgnme\"].append(og)\n            data[\"nzcount\"].append(obs_g.loc[obs_g.weight > 0.0,:].shape[0])\n            data[\"zcount\"].append(obs_g.loc[obs_g.weight == 0.0,:].shape[0])\n            for col in cols:\n                if col in [\"obgnme\",\"nzcount\",\"zcount\"]:\n                    continue\n\n                #print(col)\n                mn = obs_g.loc[:, col].min()\n                mx = obs_g.loc[:, col].max()\n                if np.isnan(mn) or np.isnan(mx):\n                    data[col].append(\"NA\")\n                elif mn == mx:\n                    data[col].append(ffmt(mn))\n                else:\n                    data[col].append(\"{0} to {1}\".format(ffmt(mn), ffmt(mx)))\n\n\n        obsg_df = pd.DataFrame(data=data, index=list(obsgp.keys()))\n        obsg_df = obsg_df.loc[:, cols]\n        if group_names is not None:\n            obsg_df.loc[:, \"obgnme\"] = obsg_df.obgnme.apply(lambda x: group_names.pop(x, x))\n        obsg_df.sort_values(by=\"obgnme\",inplace=True,ascending=True)\n        obsg_df.columns = obsg_df.columns.map(lambda x: labels[x])\n\n        preamble = '\\\\documentclass{article}\\n\\\\usepackage{booktabs}\\n' + \\\n                   '\\\\usepackage{pdflscape}\\n\\\\usepackage{longtable}\\n' + \\\n                   '\\\\usepackage{booktabs}\\n\\\\usepackage{nopageno}\\n\\\\begin{document}\\n'\n\n\n        if filename == \"none\":\n            return obsg_df\n\n        if filename is None:\n            filename = self.filename.replace(\".pst\", \".obs.tex\")\n\n        with open(filename, 'w') as f:\n\n            f.write(preamble)\n\n            f.write(\"\\\\begin{center}\\nObservation Summary\\n\\\\end{center}\\n\")\n            f.write(\"\\\\begin{center}\\n\\\\begin{landscape}\\n\")\n            f.write(\"\\\\setlength{\\\\LTleft}{-4.0cm}\\n\")\n            obsg_df.to_latex(f, index=False, longtable=True)\n            f.write(\"\\\\end{landscape}\\n\")\n            f.write(\"\\\\end{center}\\n\")\n            f.write(\"\\\\end{document}\\n\")\n\n        return obsg_df"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef run(self,exe_name=\"pestpp\",cwd=None):\n        filename = self.filename\n        if self.new_filename is not None:\n            filename = self.new_filename\n        cmd_line = \"{0} {1}\".format(exe_name,os.path.split(filename)[-1])\n        if cwd is None:\n            cwd = os.path.join(*os.path.split(filename)[:-1])\n            if cwd == '':\n                cwd = '.'\n        print(\"executing {0} in dir {1}\".format(cmd_line, cwd))\n        pyemu.utils.os_utils.run(cmd_line,cwd=cwd)", "response": "run a command related to the pst instance"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef less_than_obs_constraints(self):\n\n\n        obs = self.observation_data\n        lt_obs = obs.loc[obs.apply(lambda x: self._is_less_const(x.obgnme) \\\n                                             and x.weight != 0.0,axis=1),\"obsnme\"]\n        return lt_obs", "response": "get the names of the observations that are non - zero weighted and less than inequality constraints. Zero - is_less_const obs are skipped"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef less_than_pi_constraints(self):\n\n        pi = self.prior_information\n        lt_pi = pi.loc[pi.apply(lambda x: self._is_less_const(x.obgnme) \\\n                                             and x.weight != 0.0, axis=1), \"pilbl\"]\n        return lt_pi", "response": "get the names of the prior information eqs that are non - zero weighted\n                        less than constraints. Zero - is_less_const \\\n                                             is skipped"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef greater_than_obs_constraints(self):\n\n\n\n        obs = self.observation_data\n        gt_obs = obs.loc[obs.apply(lambda x: self._is_greater_const(x.obgnme) \\\n                                             and x.weight != 0.0,axis=1),\"obsnme\"]\n        return gt_obs", "response": "get the names of the observations that are greater than inequality constraints. Zero - is - weighted obs are skipped"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef greater_than_pi_constraints(self):\n\n        pi = self.prior_information\n        gt_pi = pi.loc[pi.apply(lambda x: self._is_greater_const(x.obgnme) \\\n                                          and x.weight != 0.0, axis=1), \"pilbl\"]\n        return gt_pi", "response": "get the names of the prior information eqs that are non - zero weighted\n                        greater than constraints. Zero - is_greater_const is skipped"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the various parameter change limits used in the pest control file values space.", "response": "def get_par_change_limits(self):\n        \"\"\"  calculate the various parameter change limits used in pest.\n        Works in control file values space (not log transformed space).  Also\n        adds columns for effective upper and lower which account for par bounds and the\n        value of parchglim\n\n        Returns\n        -------\n            df : pandas.DataFrame\n                a copy of self.parameter_data with columns for relative and factor change limits\n        Note\n        ----\n            does not yet support absolute parameter change limits!\n\n        \"\"\"\n        par = self.parameter_data\n        fpars = par.loc[par.parchglim==\"factor\",\"parnme\"]\n        rpars = par.loc[par.parchglim == \"relative\", \"parnme\"]\n        apars = par.loc[par.parchglim == \"absolute\", \"parnme\"]\n\n        change_df = par.copy()\n\n        fpm = self.control_data.facparmax\n        rpm = self.control_data.relparmax\n        facorig = self.control_data.facorig\n        base_vals = par.parval1.copy()\n\n        # apply zero value correction\n        base_vals[base_vals==0] = par.loc[base_vals==0,\"parubnd\"] / 4.0\n\n        # apply facorig\n        replace_pars = base_vals.index.map(lambda x: par.loc[x,\"partrans\"]!=\"log\" and np.abs(base_vals.loc[x]) < facorig*np.abs(base_vals.loc[x]))\n        #print(facorig,replace_pars)\n        base_vals.loc[replace_pars] = base_vals.loc[replace_pars] * facorig\n\n        # negative fac pars\n        nfpars = par.loc[base_vals.apply(lambda x: x < 0)].index\n        change_df.loc[nfpars, \"fac_upper\"] = base_vals / fpm\n        change_df.loc[nfpars, \"fac_lower\"] = base_vals * fpm\n\n        # postive fac pars\n        pfpars = par.loc[base_vals.apply(lambda x: x > 0)].index\n        change_df.loc[pfpars, \"fac_upper\"] = base_vals * fpm\n        change_df.loc[pfpars, \"fac_lower\"] = base_vals / fpm\n\n        # relative\n\n        rdelta = base_vals.apply(np.abs) * rpm\n        change_df.loc[:,\"rel_upper\"] = base_vals + rdelta\n        change_df.loc[:,\"rel_lower\"] = base_vals - rdelta\n\n        change_df.loc[:,\"chg_upper\"] = np.NaN\n        change_df.loc[fpars,\"chg_upper\"] = change_df.fac_upper[fpars]\n        change_df.loc[rpars, \"chg_upper\"] = change_df.rel_upper[rpars]\n        change_df.loc[:, \"chg_lower\"] = np.NaN\n        change_df.loc[fpars, \"chg_lower\"] = change_df.fac_lower[fpars]\n        change_df.loc[rpars, \"chg_lower\"] = change_df.rel_lower[rpars]\n\n        # effective limits\n        change_df.loc[:,\"eff_upper\"] = change_df.loc[:,[\"parubnd\",\"chg_upper\"]].min(axis=1)\n        change_df.loc[:,\"eff_lower\"] = change_df.loc[:, [\"parlbnd\", \"chg_lower\"]].max(axis=1)\n\n        return change_df"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __load_jco(self):\n        if self.jco_arg is None:\n            return None\n            #raise Exception(\"linear_analysis.__load_jco(): jco_arg is None\")\n        if isinstance(self.jco_arg, Matrix):\n            self.__jco = self.jco_arg\n        elif isinstance(self.jco_arg, str):\n            self.__jco = self.__fromfile(self.jco_arg,astype=Jco)\n        else:\n            raise Exception(\"linear_analysis.__load_jco(): jco_arg must \" +\n                            \"be a matrix object or a file name: \" +\n                            str(self.jco_arg))", "response": "private method to set the jco attribute from a file or a matrix object"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef __load_predictions(self):\n        if self.prediction_arg is None:\n            self.__predictions = None\n            return\n        self.log(\"loading forecasts\")\n        if not isinstance(self.prediction_arg, list):\n            self.prediction_arg = [self.prediction_arg]\n\n        row_names = []\n        vecs = []\n        mat = None\n        for arg in self.prediction_arg:\n            if isinstance(arg, Matrix):\n                # a vector\n                if arg.shape[1] == 1:\n                    vecs.append(arg)\n                else:\n                    if self.jco is not None:\n                        assert arg.shape[0] == self.jco.shape[1],\\\n                        \"linear_analysis.__load_predictions(): \" +\\\n                        \"multi-prediction matrix(npar,npred) not aligned \" +\\\n                        \"with jco(nobs,npar): \" + str(arg.shape) +\\\n                        ' ' + str(self.jco.shape)\n                        #for pred_name in arg.row_names:\n                        #    vecs.append(arg.extract(row_names=pred_name).T)\n                    mat = arg\n            elif isinstance(arg, str):\n                if arg.lower() in self.jco.row_names:\n                    row_names.append(arg.lower())\n                else:\n                    try:\n                        pred_mat = self.__fromfile(arg,astype=Matrix)\n                    except Exception as e:\n                        raise Exception(\"forecast argument: \"+arg+\" not found in \" +\\\n                                        \"jco row names and could not be \" +\\\n                                        \"loaded from a file.\")\n                    # vector\n                    if pred_mat.shape[1] == 1:\n                        vecs.append(pred_mat)\n                    else:\n                        #for pred_name in pred_mat.row_names:\n                        #    vecs.append(pred_mat.get(row_names=pred_name))\n                        if mat is None:\n                            mat = pred_mat\n                        else:\n                            mat = mat.extend((pred_mat))\n            elif isinstance(arg, np.ndarray):\n                self.logger.warn(\"linear_analysis.__load_predictions(): \" +\n                                \"instantiating prediction matrix from \" +\n                                \"ndarray, can't verify alignment\")\n                self.logger.warn(\"linear_analysis.__load_predictions(): \" +\n                                 \"instantiating prediction matrix from \" +\n                                 \"ndarray, generating generic prediction names\")\n\n                pred_names = [\"pred_{0}\".format(i+1) for i in range(arg.shape[0])]\n\n                if self.jco:\n                    names = self.jco.col_names\n                elif self.parcov:\n                    names = self.parcov.col_names\n                else:\n                    raise Exception(\"linear_analysis.__load_predictions(): \" +\n                                    \"ndarray passed for predicitons \" +\n                                    \"requires jco or parcov to get \" +\n                                    \"parameter names\")\n                if mat is None:\n                    mat = Matrix(x=arg,row_names=pred_names,col_names=names).T\n                else:\n                    mat = mat.extend(Matrix(x=arg,row_names=pred_names,col_names=names).T)\n                #for pred_name in pred_names:\n                #    vecs.append(pred_matrix.get(row_names=pred_name).T)\n            else:\n                raise Exception(\"unrecognized predictions argument: \" +\n                                str(arg))\n        # turn vecs into a pyemu.Matrix\n\n        if len(vecs) > 0:\n            xs = vecs[0].x\n            for vec in vecs[1:]:\n                xs = xs.extend(vec.x)\n            names = [vec.col_names[0] for vec in vecs]\n            if mat is None:\n                mat = Matrix(x=xs,row_names=vecs[0].row_names,\n                             col_names=names)\n            else:\n                mat = mat.extend(Matrix(x = np.array(xs),\n                                        row_names=vecs[0].row_names,\n                                        col_names=names))\n\n        if len(row_names) > 0:\n            extract = self.jco.extract(row_names=row_names).T\n            if mat is None:\n                mat = extract\n            else:\n                mat = mat.extend(extract)\n            #for row_name in row_names:\n            #    vecs.append(extract.get(row_names=row_name).T)\n            # call obscov to load __obscov so that __obscov\n            # (priavte) can be manipulated\n            self.__obscov.drop(row_names, axis=0)\n        self.__predictions = mat\n        try:\n            fnames = [fname for fname in self.forecast_names if fname in self.pst.nnz_obs_names]\n        except:\n            fnames = []\n        if len(fnames) > 0:\n            self.logger.warn(\"forecasts with non-zero weight in pst: {0}...\".format(','.join(fnames)) +\n                             \"\\n -> re-setting these forecast weights to zero...\")\n            self.pst.observation_data.loc[fnames,\"weight\"] = 0.0\n        self.log(\"loading forecasts\")\n        self.logger.statement(\"forecast names: {0}\".format(','.join(mat.col_names)))\n        return self.__predictions", "response": "private method loads the prediction attribute from the prediction_arg attribute of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nwrapping around pyemu. Pst. nnz_obs_names for listing non - zerocuit - related observation names", "response": "def nnz_obs_names(self):\n        \"\"\" wrapper around pyemu.Pst.nnz_obs_names for listing non-zero\n        observation names\n\n        Returns\n        -------\n        nnz_obs_names : list\n            pyemu.Pst.nnz_obs_names\n        \n        \"\"\"\n        if self.__pst is not None:\n            return self.pst.nnz_obs_names\n        else:\n            return self.jco.obs_names"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap around pyemu. Pst. adj_par_names for list adjustable parameter AttributeNames", "response": "def adj_par_names(self):\n        \"\"\" wrapper around pyemu.Pst.adj_par_names for list adjustable parameter\n        names\n\n        Returns\n        -------\n        adj_par_names : list\n            pyemu.Pst.adj_par_names\n        \n        \"\"\"\n        if self.__pst is not None:\n            return self.pst.adj_par_names\n        else:\n            return self.jco.par_names"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget the pyemu. Pst attribute containing the current version of the attribute", "response": "def pst(self):\n        \"\"\" get the pyemu.Pst attribute\n\n        Returns\n        -------\n        pst : pyemu.Pst\n\n        Note\n        ----\n        returns a references\n        \n        If LinearAnalysis.__pst is None, then the pst attribute is\n        dynamically loaded before returning\n        \"\"\"\n        if self.__pst is None and self.pst_arg is None:\n            raise Exception(\"linear_analysis.pst: can't access self.pst:\" +\n                            \"no pest control argument passed\")\n        elif self.__pst:\n            return self.__pst\n        else:\n            self.__load_pst()\n            return self.__pst"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef qhalf(self):\n        if self.__qhalf != None:\n            return self.__qhalf\n        self.log(\"qhalf\")\n        self.__qhalf = self.obscov ** (-0.5)\n        self.log(\"qhalf\")\n        return self.__qhalf", "response": "get the square root of the cofactor matrix attribute. Create the attribute if it has not yet been created\n        is set to None."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the half normal matrix attribute. Create the attribute if it has not yet been created.", "response": "def qhalfx(self):\n        \"\"\"get the half normal matrix attribute.  Create the attribute if\n        it has not yet been created\n\n        Returns\n        -------\n        qhalfx : pyemu.Matrix\n\n        \"\"\"\n        if self.__qhalfx is None:\n            self.log(\"qhalfx\")\n            self.__qhalfx = self.qhalf * self.jco\n            self.log(\"qhalfx\")\n        return self.__qhalfx"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the normal matrix attribute. Create the attribute if it has not yet been created.", "response": "def xtqx(self):\n        \"\"\"get the normal matrix attribute. Create the attribute if\n        it has not yet been created\n\n        Returns\n        -------\n        xtqx : pyemu.Matrix\n\n        \"\"\"\n        if self.__xtqx is None:\n            self.log(\"xtqx\")\n            self.__xtqx = self.jco.T * (self.obscov ** -1) * self.jco\n            self.log(\"xtqx\")\n        return self.__xtqx"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the maximum likelihood parameter estimate.", "response": "def mle_parameter_estimate(self):\n        \"\"\" get the maximum likelihood parameter estimate.\n\n        Returns\n        -------\n         post_expt : pandas.Series\n            the maximum likelihood parameter estimates\n        \n        \"\"\"\n        res = self.pst.res\n        assert res is not None\n        # build the prior expectation parameter vector\n        prior_expt = self.pst.parameter_data.loc[:,[\"parval1\"]].copy()\n        islog = self.pst.parameter_data.partrans == \"log\"\n        prior_expt.loc[islog] = prior_expt.loc[islog].apply(np.log10)\n        prior_expt = Matrix.from_dataframe(prior_expt)\n        prior_expt.col_names = [\"prior_expt\"]\n        # build the residual vector\n        res_vec = Matrix.from_dataframe(res.loc[:,[\"residual\"]])\n\n        # calc posterior expectation\n        upgrade = self.mle_covariance * self.jco.T * res_vec\n        upgrade.col_names = [\"prior_expt\"]\n        post_expt = prior_expt + upgrade\n\n        # post processing - back log transform\n        post_expt = pd.DataFrame(data=post_expt.x,index=post_expt.row_names,\n                                 columns=[\"post_expt\"])\n        post_expt.loc[islog,:] = 10.0**post_expt.loc[islog,:]\n        return post_expt"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget a dict of prior prediction variances", "response": "def prior_prediction(self):\n        \"\"\"get a dict of prior prediction variances\n\n        Returns\n        -------\n        prior_prediction : dict\n            dictionary of prediction name, prior variance pairs\n\n        \"\"\"\n        if self.__prior_prediction is not None:\n            return self.__prior_prediction\n        else:\n            if self.predictions is not None:\n                self.log(\"propagating prior to predictions\")\n                prior_cov = self.predictions.T *\\\n                                self.parcov * self.predictions\n                self.__prior_prediction = {n:v for n,v in\n                                          zip(prior_cov.row_names,\n                                              np.diag(prior_cov.x))}\n                self.log(\"propagating prior to predictions\")\n            else:\n                self.__prior_prediction = {}\n            return self.__prior_prediction"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef apply_karhunen_loeve_scaling(self):\n        cnames = copy.deepcopy(self.jco.col_names)\n        self.__jco *= self.fehalf\n        self.__jco.col_names = cnames\n        self.__parcov = self.parcov.identity", "response": "This function applies the karhuene - loeve scaling to the jacobian matrix."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef clean(self):\n        if self.pst_arg is None:\n            self.logger.statement(\"linear_analysis.clean(): not pst object\")\n            return\n        if not self.pst.estimation and self.pst.nprior > 0:\n            self.drop_prior_information()", "response": "drop regularization and prior information observation from the jco\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nresets the LinearAnalysis. pst attribute to the given value", "response": "def reset_pst(self,arg):\n        \"\"\" reset the LinearAnalysis.pst attribute\n\n        Parameters\n        ----------\n        arg : (str or matrix)\n            the value to assign to the pst attribute\n\n        \"\"\"\n        self.logger.statement(\"resetting pst\")\n        self.__pst = None\n        self.pst_arg = arg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nresetting the parcov attribute to None", "response": "def reset_parcov(self,arg=None):\n        \"\"\"reset the parcov attribute to None\n\n        Parameters\n        ----------\n        arg : str or pyemu.Matrix\n            the value to assign to the parcov attribute.  If None,\n            the private __parcov attribute is cleared but not reset\n        \"\"\"\n        self.logger.statement(\"resetting parcov\")\n        self.__parcov = None\n        if arg is not None:\n            self.parcov_arg = arg"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the obscov attribute to None", "response": "def reset_obscov(self,arg=None):\n        \"\"\"reset the obscov attribute to None\n\n        Parameters\n        ----------\n        arg : str or pyemu.Matrix\n            the value to assign to the obscov attribute.  If None,\n            the private __obscov attribute is cleared but not reset\n        \"\"\"\n        self.logger.statement(\"resetting obscov\")\n        self.__obscov = None\n        if arg is not None:\n            self.obscov_arg = arg"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef drop_prior_information(self):\n        if self.jco is None:\n            self.logger.statement(\"can't drop prior info, LinearAnalysis.jco is None\")\n            return\n        nprior_str = str(self.pst.nprior)\n        self.log(\"removing \" + nprior_str + \" prior info from jco, pst, and \" +\n                                            \"obs cov\")\n        #pi_names = list(self.pst.prior_information.pilbl.values)\n        pi_names = list(self.pst.prior_names)\n        missing = [name for name in pi_names if name not in self.jco.obs_names]\n        if len(missing) > 0:\n            raise Exception(\"LinearAnalysis.drop_prior_information(): \"+\n                            \" prior info not found: {0}\".format(missing))\n        if self.jco is not None:\n            self.__jco.drop(pi_names, axis=0)\n        self.__pst.prior_information = self.pst.null_prior\n        self.__pst.control_data.pestmode = \"estimation\"\n        #self.__obscov.drop(pi_names,axis=0)\n        self.log(\"removing \" + nprior_str + \" prior info from jco, pst, and \" +\n                                            \"obs cov\")", "response": "drop the prior information from the jco and pst attributes\n       "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self,par_names=None,obs_names=None,astype=None):\n        # make sure we aren't fooling with unwanted prior information\n        self.clean()\n        # if there is nothing to do but copy\n        if par_names is None and obs_names is None:\n            if astype is not None:\n                self.logger.warn(\"LinearAnalysis.get(): astype is not None, \" +\n                                 \"but par_names and obs_names are None so\" +\n                                 \"\\n  ->Omitted attributes will not be \" +\n                                 \"propagated to new instance\")\n            else:\n                return copy.deepcopy(self)\n        # make sure the args are lists\n        if par_names is not None and not isinstance(par_names, list):\n            par_names = [par_names]\n        if obs_names is not None and not isinstance(obs_names, list):\n            obs_names = [obs_names]\n\n        if par_names is None:\n            par_names = self.jco.col_names\n        if obs_names is None:\n            obs_names = self.jco.row_names\n        # if possible, get a new parcov\n        if self.parcov:\n            new_parcov = self.parcov.get(col_names=[pname for pname in\\\n                                                    par_names if pname in\\\n                                                    self.parcov.col_names])\n        else:\n            new_parcov = None\n        # if possible, get a new obscov\n        if self.obscov_arg is not None:\n            new_obscov = self.obscov.get(row_names=obs_names)\n        else:\n            new_obscov = None\n        # if possible, get a new pst\n        if self.pst_arg is not None:\n            new_pst = self.pst.get(par_names=par_names,obs_names=obs_names)\n        else:\n            new_pst = None\n        new_extract = None\n        if self.predictions:\n            # new_preds = []\n            # for prediction in self.predictions:\n            #     new_preds.append(prediction.get(row_names=par_names))\n            new_preds = self.predictions.get(row_names=par_names)\n\n        else:\n            new_preds = None\n        if self.jco_arg is not None:\n            new_jco = self.jco.get(row_names=obs_names, col_names=par_names)\n        else:\n            new_jco = None\n        if astype is not None:\n            new = astype(jco=new_jco, pst=new_pst, parcov=new_parcov,\n                          obscov=new_obscov, predictions=new_preds,\n                          verbose=False)\n        else:\n            # return a new object of the same type\n            new = type(self)(jco=new_jco, pst=new_pst, parcov=new_parcov,\n                              obscov=new_obscov, predictions=new_preds,\n                              verbose=False)\n        return new", "response": "method to get a new LinearAnalysis class using a subset of parameters and observations."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef adjust_obscov_resfile(self, resfile=None):\n        self.pst.adjust_weights_resfile(resfile)\n        self.__obscov.from_observation_data(self.pst)", "response": "reset the elements of obscov based on the implied weights in res_file."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets a dataframe of composite scaled sensitivities. Includes both PEST - style and Hill - style.", "response": "def get_par_css_dataframe(self):\n        \"\"\" get a dataframe of composite scaled sensitivities.  Includes both\n        PEST-style and Hill-style.\n\n        Returns\n        -------\n        css : pandas.DataFrame\n\n        \"\"\"\n\n        assert self.jco is not None\n        assert self.pst is not None\n        jco = self.jco.to_dataframe()\n        weights = self.pst.observation_data.loc[jco.index,\"weight\"].copy().values\n        jco = (jco.T * weights).T\n\n        dss_sum = jco.apply(np.linalg.norm)\n        css = (dss_sum / float(self.pst.nnz_obs)).to_frame()\n        css.columns = [\"pest_css\"]\n        # log transform stuff\n        self.pst.add_transform_columns()\n        parval1 = self.pst.parameter_data.loc[dss_sum.index,\"parval1_trans\"].values\n        css.loc[:,\"hill_css\"] = (dss_sum * parval1) / (float(self.pst.nnz_obs)**2)\n        return css"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a dataframe of composite observation sensitivity as returned by PEST in the seo file.", "response": "def get_cso_dataframe(self):\n        \"\"\"\n        get a dataframe of composite observation sensitivity, as returned by PEST in the\n        seo file.\n\n        Note that this formulation deviates slightly from the PEST documentation in that the\n        values are divided by (npar-1) rather than by (npar).\n\n        The equation is cso_j = ((Q^1/2*J*J^T*Q^1/2)^1/2)_jj/(NPAR-1)\n        Returns:\n        cso : pandas.DataFrame\n\n        \"\"\"\n        assert self.jco is not None\n        assert self.pst is not None\n        weights = self.pst.observation_data.loc[self.jco.to_dataframe().index,\"weight\"].copy().values\n        cso = np.diag(np.sqrt((self.qhalfx.x.dot(self.qhalfx.x.T))))/(float(self.pst.npar-1))\n        cso_df = pd.DataFrame.from_dict({'obnme':self.jco.to_dataframe().index,'cso':cso})\n        cso_df.index=cso_df['obnme']\n        cso_df.drop('obnme', axis=1, inplace=True)\n        return cso_df"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef plot_summary_distributions(df,ax=None,label_post=False,label_prior=False,\n                               subplots=False,figsize=(11,8.5),pt_color='b'):\n    \"\"\" helper function to plot gaussian distrbutions from prior and posterior\n    means and standard deviations\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        a dataframe and csv file.  Must have columns named:\n        'prior_mean','prior_stdev','post_mean','post_stdev'.  If loaded\n        from a csv file, column 0 is assumed to tbe the index\n    ax: matplotlib.pyplot.axis\n        If None, and not subplots, then one is created\n        and all distributions are plotted on a single plot\n    label_post: bool\n        flag to add text labels to the peak of the posterior\n    label_prior: bool\n        flag to add text labels to the peak of the prior\n    subplots: (boolean)\n        flag to use subplots.  If True, then 6 axes per page\n        are used and a single prior and posterior is plotted on each\n    figsize: tuple\n        matplotlib figure size\n\n    Returns\n    -------\n    figs : list\n        list of figures\n    axes : list\n        list of axes\n\n    Note\n    ----\n    This is useful for demystifying FOSM results\n\n    if subplots is False, a single axis is returned\n\n    Example\n    -------\n    ``>>>import matplotlib.pyplot as plt``\n\n    ``>>>import pyemu``\n\n    ``>>>pyemu.helpers.plot_summary_distributions(\"pest.par.usum.csv\")``\n\n    ``>>>plt.show()``\n    \"\"\"\n    import matplotlib.pyplot as plt\n    if isinstance(df,str):\n        df = pd.read_csv(df,index_col=0)\n    if ax is None and not subplots:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(111)\n        ax.grid()\n\n\n    if \"post_stdev\" not in df.columns and \"post_var\" in df.columns:\n        df.loc[:,\"post_stdev\"] = df.post_var.apply(np.sqrt)\n    if \"prior_stdev\" not in df.columns and \"prior_var\" in df.columns:\n        df.loc[:,\"prior_stdev\"] = df.prior_var.apply(np.sqrt)\n    if \"prior_expt\" not in df.columns and \"prior_mean\" in df.columns:\n        df.loc[:,\"prior_expt\"] = df.prior_mean\n    if \"post_expt\" not in df.columns and \"post_mean\" in df.columns:\n        df.loc[:,\"post_expt\"] = df.post_mean\n\n    if subplots:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(2,3,1)\n        ax_per_page = 6\n        ax_count = 0\n        axes = []\n        figs = []\n    for name in df.index:\n        x,y = gaussian_distribution(df.loc[name,\"post_expt\"],\n                                    df.loc[name,\"post_stdev\"])\n        ax.fill_between(x,0,y,facecolor=pt_color,edgecolor=\"none\",alpha=0.25)\n        if label_post:\n            mx_idx = np.argmax(y)\n            xtxt,ytxt = x[mx_idx],y[mx_idx] * 1.001\n            ax.text(xtxt,ytxt,name,ha=\"center\",alpha=0.5)\n\n        x,y = gaussian_distribution(df.loc[name,\"prior_expt\"],\n                                    df.loc[name,\"prior_stdev\"])\n        ax.plot(x,y,color='0.5',lw=3.0,dashes=(2,1))\n        if label_prior:\n            mx_idx = np.argmax(y)\n            xtxt,ytxt = x[mx_idx],y[mx_idx] * 1.001\n            ax.text(xtxt,ytxt,name,ha=\"center\",alpha=0.5)\n        #ylim = list(ax.get_ylim())\n        #ylim[1] *= 1.2\n        #ylim[0] = 0.0\n        #ax.set_ylim(ylim)\n        if subplots:\n            ax.set_title(name)\n            ax_count += 1\n            ax.set_yticklabels([])\n            axes.append(ax)\n            if name == df.index[-1]:\n                break\n            if ax_count >= ax_per_page:\n                figs.append(fig)\n                fig = plt.figure(figsize=figsize)\n                ax_count = 0\n            ax = plt.subplot(2,3,ax_count+1)\n    if subplots:\n        figs.append(fig)\n        return figs, axes\n    ylim = list(ax.get_ylim())\n    ylim[1] *= 1.2\n    ylim[0] = 0.0\n    ax.set_ylim(ylim)\n    ax.set_yticklabels([])\n    return ax", "response": "helper function to plot gaussian distrbutions from prior and posterior means and standard deviations on a single page."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef gaussian_distribution(mean, stdev, num_pts=50):\n    xstart = mean - (4.0 * stdev)\n    xend = mean + (4.0 * stdev)\n    x = np.linspace(xstart,xend,num_pts)\n    y = (1.0/np.sqrt(2.0*np.pi*stdev*stdev)) * np.exp(-1.0 * ((x - mean)**2)/(2.0*stdev*stdev))\n    return x,y", "response": "get an x and y array that spans the + / - 4Gaussian distribution with a given mean and standard deviation range"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nmake plot of phi vs number of model runs", "response": "def phi_progress(pst,logger=None,filename=None,**kwargs):\n    \"\"\" make plot of phi vs number of model runs - requires\n    available pestpp .iobj file\n        Parameters\n        ----------\n        pst : pyemu.Pst\n        logger : Logger\n            if None, a generic one is created.  Default is None\n        filename : str\n            PDF filename to save figures to.  If None, figures are returned.  Default is None\n        kwargs : dict\n            optional keyword args to pass to plotting functions\n\n\n        \"\"\"\n    if logger is None:\n        logger = Logger('Default_Loggger.log', echo=False)\n    logger.log(\"plot phi_progress\")\n\n    iobj_file = pst.filename.replace(\".pst\",\".iobj\")\n    if not os.path.exists(iobj_file):\n        logger.lraise(\"couldn't find iobj file {0}\".format(iobj_file))\n    df = pd.read_csv(iobj_file)\n    if \"ax\" in kwargs:\n        ax = kwargs[\"ax\"]\n    else:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(1,1,1)\n    ax.plot(df.model_runs_completed,df.total_phi,marker='.')\n    ax.set_xlabel(\"model runs\")\n    ax.set_ylabel(\"$\\phi$\")\n    ax.grid()\n    if filename is not None:\n        plt.savefig(filename)\n    logger.log(\"plot phi_progress\")\n    return ax"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef res_1to1(pst,logger=None,filename=None,plot_hexbin=False,histogram=False,**kwargs):\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot res_1to1\")\n\n    if \"ensemble\" in kwargs:\n        try:\n            res=pst_utils.res_from_en(pst,kwargs['ensemble'])\n        except Exception as e:\n            logger.lraise(\"res_1to1: error loading ensemble file: {0}\".format( str(e)))\n    else:\n        try:\n            res = pst.res\n        except:\n            logger.lraise(\"res_phi_pie: pst.res is None, couldn't find residuals file\")\n\n    obs = pst.observation_data\n\n    if \"grouper\" in kwargs:\n        raise NotImplementedError()\n    else:\n        grouper = obs.groupby(obs.obgnme).groups\n\n    fig = plt.figure(figsize=figsize)\n    if \"fig_title\" in kwargs:\n        plt.figtext(0.5,0.5,kwargs[\"fig_title\"])\n    else:\n        plt.figtext(0.5, 0.5, \"pyemu.Pst.plot(kind='1to1')\\nfrom pest control file '{0}'\\n at {1}\"\n                    .format(pst.filename, str(datetime.now())), ha=\"center\")\n    #if plot_hexbin:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.hexbin.pdf\")\n    #else:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.pdf\")\n    figs = []\n    ax_count = 0\n    for g, names in grouper.items():\n        logger.log(\"plotting 1to1 for {0}\".format(g))\n\n        obs_g = obs.loc[names, :]\n        obs_g.loc[:, \"sim\"] = res.loc[names, \"modelled\"]\n        logger.statement(\"using control file obsvals to calculate residuals\")\n        obs_g.loc[:,'res'] = obs_g.sim - obs_g.obsval\n        if \"include_zero\" not in kwargs or kwargs[\"include_zero\"] is True:\n            obs_g = obs_g.loc[obs_g.weight > 0, :]\n        if obs_g.shape[0] == 0:\n            logger.statement(\"no non-zero obs for group '{0}'\".format(g))\n            logger.log(\"plotting 1to1 for {0}\".format(g))\n            continue\n\n        if ax_count % (nr * nc) == 0:\n            if ax_count > 0:\n                plt.tight_layout()\n            #pdf.savefig()\n            #plt.close(fig)\n            figs.append(fig)\n            fig = plt.figure(figsize=figsize)\n            axes = get_page_axes()\n            ax_count = 0\n\n        ax = axes[ax_count]\n\n        #if obs_g.shape[0] == 1:\n        #    ax.scatter(list(obs_g.sim),list(obs_g.obsval),marker='.',s=30,color='b')\n        #else:\n        mx = max(obs_g.obsval.max(), obs_g.sim.max())\n        mn = min(obs_g.obsval.min(), obs_g.sim.min())\n\n        #if obs_g.shape[0] == 1:\n        mx *= 1.1\n        mn *= 0.9\n        ax.axis('square')\n        if plot_hexbin:\n            ax.hexbin(obs_g.obsval.values, obs_g.sim.values, mincnt=1, gridsize=(75, 75),\n                      extent=(mn, mx, mn, mx), bins='log', edgecolors=None)\n#               plt.colorbar(ax=ax)\n        else:\n            ax.scatter([obs_g.obsval], [obs_g.sim], marker='.', s=10, color='b')\n\n\n\n        ax.plot([mn,mx],[mn,mx],'k--',lw=1.0)\n        xlim = (mn,mx)\n        ax.set_xlim(mn,mx)\n        ax.set_ylim(mn,mx)\n        ax.grid()\n\n        ax.set_xlabel(\"observed\",labelpad=0.1)\n        ax.set_ylabel(\"simulated\",labelpad=0.1)\n        ax.set_title(\"{0}) group:{1}, {2} observations\".\n                                 format(abet[ax_count], g, obs_g.shape[0]), loc=\"left\")\n\n        ax_count += 1\n\n        if histogram==False:\n            ax = axes[ax_count]\n            ax.scatter(obs_g.obsval, obs_g.res, marker='.', s=10, color='b')\n            ylim = ax.get_ylim()\n            mx = max(np.abs(ylim[0]), np.abs(ylim[1]))\n            if obs_g.shape[0] == 1:\n                mx *= 1.1\n            ax.set_ylim(-mx, mx)\n            #show a zero residuals line\n            ax.plot(xlim, [0,0], 'k--', lw=1.0)\n            meanres= obs_g.res.mean()\n            # show mean residuals line\n            ax.plot(xlim,[meanres,meanres], 'r-', lw=1.0)\n            ax.set_xlim(xlim)\n            ax.set_ylabel(\"residual\",labelpad=0.1)\n            ax.set_xlabel(\"observed\",labelpad=0.1)\n            ax.set_title(\"{0}) group:{1}, {2} observations\".\n                         format(abet[ax_count], g, obs_g.shape[0]), loc=\"left\")\n            ax.grid()\n            ax_count += 1\n        else:\n            ax = axes[ax_count]\n            ax.hist(obs_g.res, 50, color='b')\n            meanres= obs_g.res.mean()\n            ax.axvline(meanres, color='r', lw=1)\n            b,t = ax.get_ylim()\n            ax.text(meanres + meanres/10,\n                     t - t/10,\n                     'Mean: {:.2f}'.format(meanres))\n            ax_count += 1\n        logger.log(\"plotting 1to1 for {0}\".format(g))\n\n    for a in range(ax_count, nr * nc):\n        axes[a].set_axis_off()\n        axes[a].set_yticks([])\n        axes[a].set_xticks([])\n\n    plt.tight_layout()\n    #pdf.savefig()\n    #plt.close(fig)\n    figs.append(fig)\n    if filename is not None:\n        with PdfPages(filename) as pdf:\n            for fig in figs:\n                pdf.savefig(fig)\n                plt.close(fig)\n        logger.log(\"plot res_1to1\")\n    else:\n        logger.log(\"plot res_1to1\")\n        return figs", "response": "make 1 - to - 1 plots and also observed vs residual by observation grouper"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nplots the observation v - sim of the current state of the current state of the current state of the current state of the residual", "response": "def res_obs_v_sim(pst,logger=None, filename=None,  **kwargs):\n    \"\"\"\n    timeseries plot helper...in progress\n\n    \"\"\"\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot res_obs_v_sim\")\n\n    if \"ensemble\" in kwargs:\n        try:\n            res=pst_utils.res_from_en(pst,kwargs['ensemble'])\n        except:\n            logger.statement(\"res_1to1: could not find ensemble file {0}\".format(kwargs['ensemble']))\n    else:\n        try:\n            res = pst.res\n        except:\n            logger.lraise(\"res_phi_pie: pst.res is None, couldn't find residuals file\")\n\n    obs = pst.observation_data\n\n    if \"grouper\" in kwargs:\n        raise NotImplementedError()\n    else:\n        grouper = obs.groupby(obs.obgnme).groups\n\n    fig = plt.figure(figsize=figsize)\n    if \"fig_title\" in kwargs:\n        plt.figtext(0.5,0.5,kwargs[\"fig_title\"])\n    else:\n        plt.figtext(0.5, 0.5, \"pyemu.Pst.plot(kind='obs_v_sim')\\nfrom pest control file '{0}'\\n at {1}\"\n                    .format(pst.filename, str(datetime.now())), ha=\"center\")\n    figs = []\n    ax_count = 0\n    axes = None\n    for g, names in grouper.items():\n        logger.log(\"plotting obs_v_sim for {0}\".format(g))\n\n        obs_g = obs.loc[names, :]\n        obs_g.loc[:, \"sim\"] = res.loc[names, \"modelled\"]\n        if \"include_zero\" not in kwargs or kwargs[\"include_zero\"] is False:\n            obs_g = obs_g.loc[obs_g.weight > 0, :]\n\n        if obs_g.shape[0] == 0:\n            logger.statement(\"no non-zero obs for group '{0}'\".format(g))\n            logger.log(\"plotting obs_v_sim for {0}\".format(g))\n            continue\n\n        # parse datetimes\n        # suffix in decreasing magnitude (yearmonthday)\n        try:\n            obs_g.loc[:, \"datetime_str\"] = obs_g.obsnme.apply(lambda x: x.split('_')[-1])\n        except:\n            logger.statement(\"res_obs_v_sim error forming datetime_str\")\n            continue\n        # Default datetime\n        try:\n            obs_g.loc[:, \"datetime\"] = pd.to_datetime(obs_g.datetime_str,format=\"%Y%m%d\")\n        except:\n            logger.statement(\"res_obs_v_sim error casting datetime using default {0}\".format(g))\n\n        # abbreviated date format ALWAY 2 digit year, mabye followed by 2 digit month, maybe followed by 2 digit day\n        obs_g['datetime']=0\n        try:\n            obs_g.loc[obs_g['datetime_str'].str.len()==2,'datetime']=pd.to_datetime(obs_g['datetime_str']+'1231',format='%y%m%d')\n        except:\n            logger.statement(\"res_obs_v_sim error casting datetime using %y {0}\".format(g))\n        try:\n            obs_g.loc[obs_g['datetime_str'].str.len()==4,'datetime']=pd.to_datetime(obs_g['datetime_str'].astype(str)+'01',format='%y%m%d')+datetime.timedelta(months=1)-datetime.timedelta(days=1)\n        except:\n            logger.statement(\"res_obs_v_sim error casting datetime using %y%m {0}\".format(g))\n        try:\n            obs_g.loc[obs_g['datetime_str'].str.len()==6,'datetime']=pd.to_datetime(obs_g['datetime_str'].astype(str),format='%y%m%d')\n        except:\n            logger.statement(\"res_obs_v_sim error casting datetime using %y%m%d {0}\".format(g))\n\n\n        if ax_count % (nr * nc) == 0:\n            plt.tight_layout()\n            #pdf.savefig()\n            #plt.close(fig)\n            figs.append(fig)\n            fig = plt.figure(figsize=figsize)\n            axes = get_page_axes()\n            ax_count = 0\n\n        ax = axes[ax_count]\n        obs_g.loc[:,\"site\"] = obs_g.obsnme.apply(lambda x: x.split('_')[0])\n        for site in obs_g.site.unique():\n            obs_s = obs_g.loc[obs_g.site==site,:]\n            obs_s.sort_values(by=\"datetime\")\n            ax.plot(obs_s.datetime, obs_s.obsval, ls='-', marker='.', ms=10, color='b')\n            ax.plot(obs_s.datetime, obs_s.sim, ls='-', marker='.', ms=10, color='0.5')\n        ax.set_xlim(obs_g.datetime.min(),obs_g.datetime.max())\n        ax.grid()\n        ax.set_xlabel(\"datetime\",labelpad=0.1)\n        ax.set_title(\"{0}) group:{1}, {2} observations\".\n                     format(abet[ax_count], g, names.shape[0]), loc=\"left\")\n        ax_count += 1\n        logger.log(\"plotting obs_v_sim for {0}\".format(g))\n\n    if axes is None:\n        return\n\n    for a in range(ax_count,nr*nc):\n        axes[a].set_axis_off()\n        axes[a].set_yticks([])\n        axes[a].set_xticks([])\n\n\n\n    plt.tight_layout()\n    #pdf.savefig()\n    #plt.close(fig)\n    figs.append(fig)\n    if filename is not None:\n        with PdfPages(pst.filename.replace(\".pst\", \".obs_v_sim.pdf\")) as pdf:\n            for fig in figs:\n                pdf.savefig(fig)\n                plt.close(fig)\n                logger.log(\"plot res_obs_v_sim\")\n    else:\n        logger.log(\"plot res_obs_v_sim\")\n        return figs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef plot_id_bar(id_df, nsv=None, logger=None, **kwargs):\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot id bar\")\n\n\n    df = id_df.copy()\n\n    # drop the final `ident` column\n    if 'ident' in df.columns:\n        df.drop('ident', inplace=True, axis=1)\n\n    if nsv is None or nsv > len(df.columns):\n        nsv = len(df.columns)\n        logger.log('set number of SVs and number in the dataframe')\n\n    df = df[df.columns[:nsv]]\n\n    df['ident'] = df.sum(axis=1)\n    df.sort_values(by='ident', inplace=True, ascending=False)\n    df.drop('ident', inplace=True, axis=1)\n\n    if 'figsize' in kwargs:\n        figsize=kwargs['figsize']\n    else:\n        figsize = (8, 10.5)\n    if \"ax\" in kwargs:\n        ax = kwargs[\"ax\"]\n    else:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(1,1,1)\n\n    # plto the stacked bar chart (the easy part!)\n    df.plot.bar(stacked=True, cmap='jet_r', legend=False, ax=ax)\n\n    #\n    # horrible shenanigans to make a colorbar rather than a legend\n    #\n\n    # special case colormap just dark red if one SV\n    if nsv == 1:\n        tcm = matplotlib.colors.LinearSegmentedColormap.from_list('one_sv', [plt.get_cmap('jet_r')(0)] * 2, N=2)\n        sm = plt.cm.ScalarMappable(cmap=tcm, norm=matplotlib.colors.Normalize(vmin=0, vmax=nsv + 1))\n    # or typically just rock the jet_r colormap over the range of SVs\n    else:\n        sm = plt.cm.ScalarMappable(cmap=plt.get_cmap('jet_r'), norm=matplotlib.colors.Normalize(vmin=1, vmax=nsv))\n    sm._A = []\n\n    # now, if too many ticks for the colorbar, summarize them\n    if nsv < 20:\n        ticks = range(1, nsv + 1)\n    else:\n        ticks = np.arange(1, nsv + 1, int((nsv + 1) / 30))\n\n    cb = plt.colorbar(sm)\n    cb.set_ticks(ticks)\n\n    logger.log('plot id bar')\n\n    return ax", "response": "Plot a stacked bar chart of identifiability based on a pandas dataframe of identifiability values."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef res_phi_pie(pst,logger=None, **kwargs):\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot res_phi_pie\")\n\n    if \"ensemble\" in kwargs:\n        try:\n            res=pst_utils.res_from_en(pst,kwargs['ensemble'])\n        except:\n            logger.statement(\"res_1to1: could not find ensemble file {0}\".format(kwargs['ensemble']))\n    else:\n        try:\n            res = pst.res\n        except:\n            logger.lraise(\"res_phi_pie: pst.res is None, couldn't find residuals file\")\n\n    obs = pst.observation_data\n    phi = pst.phi\n    phi_comps = pst.phi_components\n    norm_phi_comps = pst.phi_components_normalized\n    keys = list(phi_comps.keys())\n    if \"include_zero\" not in kwargs or kwargs[\"include_zero\"] is True:\n        phi_comps = {k:phi_comps[k] for k in keys if phi_comps[k] > 0.0}\n        keys = list(phi_comps.keys())\n        norm_phi_comps = {k:norm_phi_comps[k] for k in keys}\n    if \"ax\" in kwargs:\n        ax = kwargs[\"ax\"]\n    else:\n        fig = plt.figure(figsize=figsize)\n        ax = plt.subplot(1,1,1,aspect=\"equal\")\n    labels = [\"{0}\\n{1:4G}\\n({2:3.1f}%)\".format(k,phi_comps[k],100. * (phi_comps[k] / phi)) for k in keys]\n    ax.pie([float(norm_phi_comps[k]) for k in keys],labels=labels)\n    logger.log(\"plot res_phi_pie\")\n    if \"filename\" in kwargs:\n        plt.savefig(kwargs[\"filename\"])\n    return ax", "response": "plot current phi components as a pie chart."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ensemble_helper(ensemble,bins=10,facecolor='0.5',plot_cols=None,\n                    filename=None,func_dict = None,\n                    sync_bins=True,deter_vals=None,std_window=None,\n                    deter_range=False,**kwargs):\n    \"\"\"helper function to plot ensemble histograms\n\n    Parameters\n    ----------\n    ensemble : varies\n        the ensemble argument can be a pandas.DataFrame or derived type or a str, which\n        is treated as a filename.  Optionally, ensemble can be a list of these types or\n        a dict, in which case, the keys are treated as facecolor str (e.g., 'b', 'y', etc).\n    facecolor : str\n        the histogram facecolor.  Only applies if ensemble is a single thing\n    plot_cols : enumerable\n        a collection of columns (in form of a list of parameters, or a dict with keys for\n        parsing plot axes and values of parameters) from the ensemble(s) to plot.  If None,\n        (the union of) all cols are plotted. Default is None\n    filename : str\n        the name of the pdf to create.  If None, return figs without saving.  Default is None.\n    func_dict : dict\n        a dictionary of unary functions (e.g., np.log10_ to apply to columns.  Key is\n        column name.  Default is None\n    sync_bins : bool\n        flag to use the same bin edges for all ensembles. Only applies if more than\n        one ensemble is being plotted.  Default is True\n    deter_vals : dict\n        dict of deterministic values to plot as a vertical line. key is ensemble columnn name\n    std_window : float\n        the number of standard deviations around the mean to mark as vertical lines.  If None,\n        nothing happens.  Default is None\n    deter_range : bool\n        flag to set xlims to deterministic value +/- std window.  If True, std_window must not be None.\n        Default is False\n\n    \"\"\"\n    logger = pyemu.Logger(\"ensemble_helper.log\")\n    logger.log(\"pyemu.plot_utils.ensemble_helper()\")\n    ensembles = _process_ensemble_arg(ensemble,facecolor,logger)\n\n    #apply any functions\n    if func_dict is not None:\n        logger.log(\"applying functions\")\n        for col,func in func_dict.items():\n            for fc,en in ensembles.items():\n                if col in en.columns:\n                    en.loc[:,col] = en.loc[:,col].apply(func)\n        logger.log(\"applying functions\")\n\n\n    #get a list of all cols (union)\n    all_cols = set()\n    for fc, en in ensembles.items():\n        cols = set(en.columns)\n        all_cols.update(cols)\n    if plot_cols is None:\n        plot_cols = {i: [v] for i, v in (zip(all_cols, all_cols))}\n    else:\n        if isinstance(plot_cols,list):\n            splot_cols = set(plot_cols)\n            plot_cols = {i: [v] for i, v in (zip(plot_cols, plot_cols))}\n        elif isinstance(plot_cols,dict):\n            splot_cols = []\n            for label,pcols in plot_cols.items():\n                splot_cols.extend(list(pcols))\n            splot_cols = set(splot_cols)\n        else:\n            logger.lraise(\"unrecognized plot_cols type: {0}, should be list or dict\".\n                          format(type(plot_cols)))\n\n        missing = splot_cols - all_cols\n        if len(missing) > 0:\n            logger.lraise(\"the following plot_cols are missing: {0}\".\n                          format(','.join(missing)))\n\n    logger.statement(\"plotting {0} histograms\".format(len(plot_cols)))\n\n    fig = plt.figure(figsize=figsize)\n    if \"fig_title\" in kwargs:\n        plt.figtext(0.5,0.5,kwargs[\"fig_title\"])\n    else:\n        plt.figtext(0.5, 0.5, \"pyemu.plot_utils.ensemble_helper()\\n at {0}\"\n                    .format(str(datetime.now())), ha=\"center\")\n    #plot_cols = list(plot_cols)\n    #plot_cols.sort()\n    labels = list(plot_cols.keys())\n    labels.sort()\n    logger.statement(\"saving pdf to {0}\".format(filename))\n    figs = []\n\n    ax_count = 0\n\n    #for label,plot_col in plot_cols.items():\n    for label in labels:\n        plot_col = plot_cols[label]\n        logger.log(\"plotting reals for {0}\".format(label))\n        if ax_count % (nr * nc) == 0:\n            plt.tight_layout()\n            #pdf.savefig()\n            #plt.close(fig)\n            figs.append(fig)\n            fig = plt.figure(figsize=figsize)\n            axes = get_page_axes()\n            [ax.set_yticks([]) for ax in axes]\n            ax_count = 0\n\n        ax = axes[ax_count]\n        ax.set_title(\"{0}) {1}\".format(abet[ax_count],label),loc=\"left\")\n        if sync_bins:\n            mx,mn = -1.0e+30,1.0e+30\n            for fc,en in ensembles.items():\n                # for pc in plot_col:\n                #     if pc in en.columns:\n                #         emx,emn = en.loc[:,pc].max(),en.loc[:,pc].min()\n                #         mx = max(mx,emx)\n                #         mn = min(mn,emn)\n                emn = en.loc[:,plot_col].values.min()\n                emx = en.loc[:, plot_col].values.max()\n                mx = max(mx, emx)\n                mn = min(mn,emn)\n            plot_bins = np.linspace(mn,mx,num=bins)\n            logger.statement(\"{0} min:{1:5G}, max:{2:5G}\".format(label,mn,mx))\n        else:\n            plot_bins=bins\n        for fc,en in ensembles.items():\n            #for pc in plot_col:\n            #    if pc in en.columns:\n            #        try:\n            #            en.loc[:,pc].hist(bins=plot_bins,facecolor=fc,\n            #                                    edgecolor=\"none\",alpha=0.5,\n            #                                    normed=True,ax=ax)\n            #        except Exception as e:\n            #            logger.warn(\"error plotting histogram for {0}:{1}\".\n            #                        format(pc,str(e)))\n            vals = en.loc[:,plot_col].values.flatten()\n            #print(plot_bins)\n            #print(vals)\n            ax.hist(vals,bins=plot_bins,edgecolor=\"none\",alpha=0.5,normed=True,facecolor=fc)\n            v = None\n            if deter_vals is not None:\n                for pc in plot_col:\n                    if pc in deter_vals:\n                        ylim = ax.get_ylim()\n                        v = deter_vals[pc]\n                        ax.plot([v,v],ylim,\"k--\",lw=1.5)\n                        ax.set_ylim(ylim)\n\n\n            if std_window is not None:\n                try:\n                    ylim = ax.get_ylim()\n                    mn, st = en.loc[:,pc].mean(), en.loc[:,pc].std() * (std_window / 2.0)\n\n                    ax.plot([mn - st, mn - st], ylim, color=fc, lw=1.5,ls='--')\n                    ax.plot([mn + st, mn + st], ylim, color=fc, lw=1.5,ls='--')\n                    ax.set_ylim(ylim)\n                    if deter_range and v is not None:\n                        xmn = v - st\n                        xmx = v + st\n                        ax.set_xlim(xmn,xmx)\n                except:\n                    logger.warn(\"error plotting std window for {0}\".\n                                format(pc))\n        ax.grid()\n\n        ax_count += 1\n\n    for a in range(ax_count, nr * nc):\n        axes[a].set_axis_off()\n        axes[a].set_yticks([])\n        axes[a].set_xticks([])\n\n    plt.tight_layout()\n    #pdf.savefig()\n    #plt.close(fig)\n    figs.append(fig)\n    if filename is not None:\n        plt.tight_layout()\n        with PdfPages(filename) as pdf:\n            for fig in figs:\n                pdf.savefig(fig)\n                plt.close(fig)\n    logger.log(\"pyemu.plot_utils.ensemble_helper()\")", "response": "helper function to plot a single ensemble into a single tree tree"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nfunctioning to plot first and second moment change histograms", "response": "def ensemble_change_summary(ensemble1, ensemble2, pst,bins=10, facecolor='0.5',logger=None,filename=None,**kwargs):\n    \"\"\"helper function to plot first and second moment change histograms\n\n    Parameters\n    ----------\n    ensemble1 : varies\n        str or pd.DataFrames\n    ensemble2 : varies\n        str or pd.DataFrame\n    pst : pyemu.Pst\n        pst instance\n    facecolor : str\n        the histogram facecolor.\n    filename : str\n        the name of the pdf to create. If None, return figs without saving.  Default is None.\n\n    \"\"\"\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot ensemble change\")\n\n    if isinstance(ensemble1, str):\n        ensemble1 = pd.read_csv(ensemble1,index_col=0)\n    ensemble1.columns = ensemble1.columns.str.lower()\n\n    if isinstance(ensemble2, str):\n        ensemble2 = pd.read_csv(ensemble2,index_col=0)\n    ensemble2.columns = ensemble2.columns.str.lower()\n\n    # better to ensure this is caught by pestpp-ies ensemble csvs\n    unnamed1 = [col for col in ensemble1.columns if \"unnamed:\" in col]\n    if len(unnamed1) != 0:\n        ensemble1 = ensemble1.iloc[:,:-1] # ensure unnamed col result of poor csv read only (ie last col)\n    unnamed2 = [col for col in ensemble2.columns if \"unnamed:\" in col]\n    if len(unnamed2) != 0:\n        ensemble2 = ensemble2.iloc[:,:-1] # ensure unnamed col result of poor csv read only (ie last col)\n\n    d = set(ensemble1.columns).symmetric_difference(set(ensemble2. columns))\n\n    if len(d) != 0:\n        logger.lraise(\"ensemble1 does not have the same columns as ensemble2: {0}\".\n                      format(','.join(d)))\n    if \"grouper\" in kwargs:\n        raise NotImplementedError()\n    else:\n        en_cols = set(ensemble1.columns)\n        if len(en_cols.symmetric_difference(set(pst.par_names))) == 0:\n            par = pst.parameter_data.loc[pst.adj_par_names,:]\n            grouper = par.groupby(par.pargp).groups\n            grouper[\"all\"] = pst.adj_par_names\n            li = par.loc[par.partrans == \"log\",\"parnme\"]\n            ensemble1.loc[:,li] = ensemble1.loc[:,li].apply(np.log10)\n            ensemble2.loc[:, li] = ensemble2.loc[:, li].apply(np.log10)\n        elif len(en_cols.symmetric_difference(set(pst.obs_names))) == 0:\n            obs = pst.observation_data.loc[pst.nnz_obs_names,:]\n            grouper = obs.groupby(obs.obgnme).groups\n            grouper[\"all\"] = pst.nnz_obs_names\n        else:\n            logger.lraise(\"could not match ensemble cols with par or obs...\")\n\n    en1_mn, en1_std = ensemble1.mean(axis=0), ensemble1.std(axis=0)\n    en2_mn, en2_std = ensemble2.mean(axis=0), ensemble2.std(axis=0)\n\n    # mn_diff = 100.0 * ((en1_mn - en2_mn) / en1_mn)\n    # std_diff = 100 * ((en1_std - en2_std) / en1_std)\n\n    mn_diff = -1 * (en2_mn - en1_mn)\n    std_diff = 100 * (((en1_std - en2_std) / en1_std))\n    #set en1_std==0 to nan\n    std_diff[en1_std.index[en1_std==0]] = np.nan\n\n\n\n    #diff = ensemble1 - ensemble2\n    #mn_diff = diff.mean(axis=0)\n    #std_diff = diff.std(axis=0)\n\n\n    fig = plt.figure(figsize=figsize)\n    if \"fig_title\" in kwargs:\n        plt.figtext(0.5,0.5,kwargs[\"fig_title\"])\n    else:\n        plt.figtext(0.5, 0.5, \"pyemu.Pst.plot(kind='1to1')\\nfrom pest control file '{0}'\\n at {1}\"\n                    .format(pst.filename, str(datetime.now())), ha=\"center\")\n    #if plot_hexbin:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.hexbin.pdf\")\n    #else:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.pdf\")\n    figs = []\n    ax_count = 0\n    for g, names in grouper.items():\n        logger.log(\"plotting change for {0}\".format(g))\n\n        mn_g = mn_diff.loc[names]\n        std_g = std_diff.loc[names]\n\n        if mn_g.shape[0] == 0:\n            logger.statement(\"no entries for group '{0}'\".format(g))\n            logger.log(\"plotting change for {0}\".format(g))\n            continue\n\n        if ax_count % (nr * nc) == 0:\n            if ax_count > 0:\n                plt.tight_layout()\n            #pdf.savefig()\n            #plt.close(fig)\n            figs.append(fig)\n            fig = plt.figure(figsize=figsize)\n            axes = get_page_axes()\n            ax_count = 0\n\n        ax = axes[ax_count]\n        mn_g.hist(ax=ax,facecolor=facecolor,alpha=0.5,edgecolor=None,bins=bins)\n        #mx = max(mn_g.max(), mn_g.min(),np.abs(mn_g.max()),np.abs(mn_g.min())) * 1.2\n        #ax.set_xlim(-mx,mx)\n\n        #std_g.hist(ax=ax,facecolor='b',alpha=0.5,edgecolor=None)\n\n\n\n        #ax.set_xlim(xlim)\n        ax.set_yticklabels([])\n        ax.set_xlabel(\"mean change\",labelpad=0.1)\n        ax.set_title(\"{0}) mean change group:{1}, {2} entries\\nmax:{3:10G}, min:{4:10G}\".\n                     format(abet[ax_count], g, mn_g.shape[0],mn_g.max(),mn_g.min()), loc=\"left\")\n        ax.grid()\n        ax_count += 1\n\n        ax = axes[ax_count]\n        std_g.hist(ax=ax, facecolor=facecolor, alpha=0.5, edgecolor=None, bins=bins)\n        # std_g.hist(ax=ax,facecolor='b',alpha=0.5,edgecolor=None)\n\n\n\n        # ax.set_xlim(xlim)\n        ax.set_yticklabels([])\n        ax.set_xlabel(\"sigma percent reduction\", labelpad=0.1)\n        ax.set_title(\"{0}) sigma change group:{1}, {2} entries\\nmax:{3:10G}, min:{4:10G}\".\n                     format(abet[ax_count], g, mn_g.shape[0], std_g.max(), std_g.min()), loc=\"left\")\n        ax.grid()\n        ax_count += 1\n\n        logger.log(\"plotting change for {0}\".format(g))\n\n    for a in range(ax_count, nr * nc):\n        axes[a].set_axis_off()\n        axes[a].set_yticks([])\n        axes[a].set_xticks([])\n\n    plt.tight_layout()\n    #pdf.savefig()\n    #plt.close(fig)\n    figs.append(fig)\n    if filename is not None:\n        plt.tight_layout()\n        with PdfPages(filename) as pdf:\n            for fig in figs:\n                pdf.savefig(fig)\n                plt.close(fig)\n        logger.log(\"plot ensemble change\")\n    else:\n        logger.log(\"plot ensemble change\")\n        return figs"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ensemble_res_1to1(ensemble, pst,facecolor='0.5',logger=None,filename=None,\n                      skip_groups=[],base_ensemble=None,**kwargs):\n    \"\"\"helper function to plot ensemble 1-to-1 plots sbowing the simulated range\n\n    Parameters\n    ----------\n    ensemble : varies\n        the ensemble argument can be a pandas.DataFrame or derived type or a str, which\n        is treated as a fileanme.  Optionally, ensemble can be a list of these types or\n        a dict, in which case, the keys are treated as facecolor str (e.g., 'b', 'y', etc).\n    pst : pyemu.Pst\n        pst instance\n    facecolor : str\n        the histogram facecolor.  Only applies if ensemble is a single thing\n    filename : str\n        the name of the pdf to create. If None, return figs without saving.  Default is None.\n    base_ensemble : varies\n        an optional ensemble argument for the observations + noise ensemble.\n        This will be plotted as a transparent red bar on the 1to1 plot.\n\n    \"\"\"\n    if logger is None:\n        logger=Logger('Default_Loggger.log',echo=False)\n    logger.log(\"plot res_1to1\")\n    obs = pst.observation_data\n    ensembles = _process_ensemble_arg(ensemble,facecolor,logger)\n\n    if base_ensemble is not None:\n        base_ensemble = _process_ensemble_arg(base_ensemble,\"r\",logger)\n\n    if \"grouper\" in kwargs:\n        raise NotImplementedError()\n    else:\n        grouper = obs.groupby(obs.obgnme).groups\n        for skip_group in skip_groups:\n            grouper.pop(skip_group)\n\n    fig = plt.figure(figsize=figsize)\n    if \"fig_title\" in kwargs:\n        plt.figtext(0.5,0.5,kwargs[\"fig_title\"])\n    else:\n        plt.figtext(0.5, 0.5, \"pyemu.Pst.plot(kind='1to1')\\nfrom pest control file '{0}'\\n at {1}\"\n                    .format(pst.filename, str(datetime.now())), ha=\"center\")\n    #if plot_hexbin:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.hexbin.pdf\")\n    #else:\n    #    pdfname = pst.filename.replace(\".pst\", \".1to1.pdf\")\n    figs = []\n    ax_count = 0\n    for g, names in grouper.items():\n        logger.log(\"plotting 1to1 for {0}\".format(g))\n\n        obs_g = obs.loc[names, :]\n        logger.statement(\"using control file obsvals to calculate residuals\")\n        if \"include_zero\" not in kwargs or kwargs[\"include_zero\"] is False:\n            obs_g = obs_g.loc[obs_g.weight > 0, :]\n        if obs_g.shape[0] == 0:\n            logger.statement(\"no non-zero obs for group '{0}'\".format(g))\n            logger.log(\"plotting 1to1 for {0}\".format(g))\n            continue\n\n        if ax_count % (nr * nc) == 0:\n            if ax_count > 0:\n                plt.tight_layout()\n            #pdf.savefig()\n            #plt.close(fig)\n            figs.append(fig)\n            fig = plt.figure(figsize=figsize)\n            axes = get_page_axes()\n            ax_count = 0\n\n        ax = axes[ax_count]\n        if base_ensemble is None:\n            mx = obs_g.obsval.max()\n            mn =  obs_g.obsval.min()\n        else:\n            mn = base_ensemble[\"r\"].loc[:,names].min().min()\n            mx = base_ensemble[\"r\"].loc[:, names].max().max()\n        #if obs_g.shape[0] == 1:\n        mx *= 1.1\n        mn *= 0.9\n        #ax.axis('square')\n        if base_ensemble is not None:\n            obs_gg = obs_g.sort_values(by=\"obsval\")\n\n            for c, en in base_ensemble.items():\n                en_g = en.loc[:, obs_gg.obsnme]\n                ex = en_g.max()\n                en = en_g.min()\n                #[ax.plot([ov, ov], [een, eex], color=c,alpha=0.3) for ov, een, eex in zip(obs_g.obsval.values, en.values, ex.values)]\n                ax.fill_between(obs_gg.obsval,en,ex,facecolor=c,alpha=0.2)\n        #ax.scatter([obs_g.sim], [obs_g.obsval], marker='.', s=10, color='b')\n        for c,en in ensembles.items():\n            en_g = en.loc[:,obs_g.obsnme]\n            ex = en_g.max()\n            en = en_g.min()\n            [ax.plot([ov,ov],[een,eex],color=c) for ov,een,eex in zip(obs_g.obsval.values,en.values,ex.values)]\n\n\n        ax.plot([mn,mx],[mn,mx],'k--',lw=1.0)\n        xlim = (mn,mx)\n        ax.set_xlim(mn,mx)\n        ax.set_ylim(mn,mx)\n        if mx > 1.0e5:\n            ax.xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%1.0e'))\n            ax.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%1.0e'))\n        ax.grid()\n\n        ax.set_xlabel(\"observed\",labelpad=0.1)\n        ax.set_ylabel(\"simulated\",labelpad=0.1)\n        ax.set_title(\"{0}) group:{1}, {2} observations\".\n                                 format(abet[ax_count], g, obs_g.shape[0]), loc=\"left\")\n\n        ax_count += 1\n        ax = axes[ax_count]\n        #ax.scatter(obs_g.obsval, obs_g.res, marker='.', s=10, color='b')\n\n        if base_ensemble is not None:\n            obs_gg = obs_g.sort_values(by=\"obsval\")\n\n            for c, en in base_ensemble.items():\n                en_g = en.loc[:, obs_gg.obsnme].subtract(obs_gg.obsval)\n                ex = en_g.max()\n                en = en_g.min()\n                #[ax.plot([ov, ov], [een, eex], color=c,alpha=0.3) for ov, een, eex in zip(obs_g.obsval.values, en.values, ex.values)]\n                ax.fill_between(obs_gg.obsval,en,ex,facecolor=c,alpha=0.2)\n\n        for c,en in ensembles.items():\n            en_g = en.loc[:,obs_g.obsnme].subtract(obs_g.obsval,axis=1)\n            ex = en_g.max()\n            en = en_g.min()\n            [ax.plot([ov,ov],[een,eex],color=c) for ov,een,eex in zip(obs_g.obsval.values,en.values,ex.values)]\n        # if base_ensemble is not None:\n        #     if base_ensemble is not None:\n        #         for c, en in base_ensemble.items():\n        #             en_g = en.loc[:, obs_g.obsnme].subtract(obs_g.obsval,axis=1)\n        #             ex = en_g.max()\n        #             en = en_g.min()\n        #             [ax.plot([ov, ov], [een, eex], color=c, alpha=0.3) for ov, een, eex in\n        #              zip(obs_g.obsval.values, en.values, ex.values)]\n        ylim = ax.get_ylim()\n        mx = max(np.abs(ylim[0]), np.abs(ylim[1]))\n        if obs_g.shape[0] == 1:\n            mx *= 1.1\n        ax.set_ylim(-mx, mx)\n        #show a zero residuals line\n        ax.plot(xlim, [0,0], 'k--', lw=1.0)\n\n        ax.set_xlim(xlim)\n        ax.set_ylabel(\"residual\",labelpad=0.1)\n        ax.set_xlabel(\"observed\",labelpad=0.1)\n        ax.set_title(\"{0}) group:{1}, {2} observations\".\n                     format(abet[ax_count], g, obs_g.shape[0]), loc=\"left\")\n        ax.grid()\n        if ax.get_xlim()[1] > 1.0e5:\n            ax.xaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter('%1.0e'))\n\n        ax_count += 1\n\n        logger.log(\"plotting 1to1 for {0}\".format(g))\n\n    for a in range(ax_count, nr * nc):\n        axes[a].set_axis_off()\n        axes[a].set_yticks([])\n        axes[a].set_xticks([])\n\n    plt.tight_layout()\n    #pdf.savefig()\n    #plt.close(fig)\n    figs.append(fig)\n    if filename is not None:\n        plt.tight_layout()\n        with PdfPages(filename) as pdf:\n            for fig in figs:\n                pdf.savefig(fig)\n                plt.close(fig)\n        logger.log(\"plot res_1to1\")\n    else:\n        logger.log(\"plot res_1to1\")\n        return figs", "response": "helper function to plot the simulated range of 1 - to - 1 plots"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncreates an instruction file for an smp file", "response": "def smp_to_ins(smp_filename,ins_filename=None,use_generic_names=False,\n               gwutils_compliant=False, datetime_format=None,prefix=''):\n    \"\"\" create an instruction file for an smp file\n\n    Parameters\n    ----------\n    smp_filename : str\n        existing smp file\n    ins_filename: str\n        instruction file to create.  If None, create\n        an instruction file using the smp filename\n        with the \".ins\" suffix\n    use_generic_names : bool\n        flag to force observations names to use a generic\n        int counter instead of trying to use a datetime str\n    gwutils_compliant : bool\n        flag to use instruction set that is compliant with the\n        pest gw utils (fixed format instructions).  If false,\n        use free format (with whitespace) instruction set\n    datetime_format : str\n        str to pass to datetime.strptime in the smp_to_dataframe() function\n    prefix : str\n         a prefix to add to the front of the obsnmes.  Default is ''\n\n\n    Returns\n    -------\n    df : pandas.DataFrame\n        dataframe instance of the smp file with the observation names and\n        instruction lines as additional columns\n\n    \"\"\"\n    if ins_filename is None:\n        ins_filename = smp_filename+\".ins\"\n    df = smp_to_dataframe(smp_filename,datetime_format=datetime_format)\n    df.loc[:,\"ins_strings\"] = None\n    df.loc[:,\"observation_names\"] = None\n    name_groups = df.groupby(\"name\").groups\n    for name,idxs in name_groups.items():\n        if not use_generic_names and len(name) <= 11:\n            onames = df.loc[idxs,\"datetime\"].apply(lambda x: prefix+name+'_'+x.strftime(\"%d%m%Y\")).values\n        else:\n            onames = [prefix+name+\"_{0:d}\".format(i) for i in range(len(idxs))]\n        if False in (map(lambda x :len(x) <= 20,onames)):\n            long_names = [oname for oname in onames if len(oname) > 20]\n            raise Exception(\"observation names longer than 20 chars:\\n{0}\".format(str(long_names)))\n        if gwutils_compliant:\n            ins_strs = [\"l1  ({0:s})39:46\".format(on) for on in onames]\n        else:\n            ins_strs = [\"l1 w w w  !{0:s}!\".format(on) for on in onames]\n        df.loc[idxs,\"observation_names\"] = onames\n        df.loc[idxs,\"ins_strings\"] = ins_strs\n\n    counts = df.observation_names.value_counts()\n    dup_sites = [name for name in counts.index if counts[name] > 1]\n    if len(dup_sites) > 0:\n        raise Exception(\"duplicate observation names found:{0}\"\\\n                        .format(','.join(dup_sites)))\n\n    with open(ins_filename,'w') as f:\n        f.write(\"pif ~\\n\")\n        [f.write(ins_str+\"\\n\") for ins_str in df.loc[:,\"ins_strings\"]]\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nwrite a dataframe as an smp file", "response": "def dataframe_to_smp(dataframe,smp_filename,name_col=\"name\",\n                     datetime_col=\"datetime\",value_col=\"value\",\n                     datetime_format=\"dd/mm/yyyy\",\n                     value_format=\"{0:15.6E}\",\n                     max_name_len=12):\n    \"\"\" write a dataframe as an smp file\n\n    Parameters\n    ----------\n    dataframe : pandas.DataFrame\n    smp_filename : str\n        smp file to write\n    name_col: str\n        the column in the dataframe the marks the site namne\n    datetime_col: str\n        the column in the dataframe that is a datetime instance\n    value_col: str\n        the column in the dataframe that is the values\n    datetime_format: str\n        either 'dd/mm/yyyy' or 'mm/dd/yyy'\n    value_format: str\n        a python float-compatible format\n\n    \"\"\"\n    formatters = {\"name\":lambda x:\"{0:<20s}\".format(str(x)[:max_name_len]),\n                  \"value\":lambda x:value_format.format(x)}\n    if datetime_format.lower().startswith(\"d\"):\n        dt_fmt = \"%d/%m/%Y    %H:%M:%S\"\n    elif datetime_format.lower().startswith(\"m\"):\n        dt_fmt = \"%m/%d/%Y    %H:%M:%S\"\n    else:\n        raise Exception(\"unrecognized datetime_format: \" +\\\n                        \"{0}\".format(str(datetime_format)))\n\n    for col in [name_col,datetime_col,value_col]:\n        assert col in dataframe.columns\n\n    dataframe.loc[:,\"datetime_str\"] = dataframe.loc[:,\"datetime\"].\\\n        apply(lambda x:x.strftime(dt_fmt))\n    if isinstance(smp_filename,str):\n        smp_filename = open(smp_filename,'w')\n        # need this to remove the leading space that pandas puts in front\n        s = dataframe.loc[:,[name_col,\"datetime_str\",value_col]].\\\n                to_string(col_space=0,\n                          formatters=formatters,\n                          justify=None,\n                          header=False,\n                          index=False)\n        for ss in s.split('\\n'):\n            smp_filename.write(\"{0:<s}\\n\".format(ss.strip()))\n    dataframe.pop(\"datetime_str\")"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef date_parser(items):\n    try:\n        dt = datetime.strptime(items,\"%d/%m/%Y %H:%M:%S\")\n    except Exception as e:\n        try:\n            dt = datetime.strptime(items,\"%m/%d/%Y %H:%M:%S\")\n        except Exception as ee:\n            raise Exception(\"error parsing datetime string\" +\\\n                            \" {0}: \\n{1}\\n{2}\".format(str(items),str(e),str(ee)))\n    return dt", "response": "datetime parser to help load smp files\n   "}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nloads an smp file into a pandas dataframe", "response": "def smp_to_dataframe(smp_filename,datetime_format=None):\n    \"\"\" load an smp file into a pandas dataframe (stacked in wide format)\n\n    Parameters\n    ----------\n    smp_filename : str\n        smp filename to load\n    datetime_format : str\n        should be either \"%m/%d/%Y %H:%M:%S\" or \"%d/%m/%Y %H:%M:%S\"\n        If None, then we will try to deduce the format for you, which\n        always dangerous\n\n    Returns\n    -------\n    df : pandas.DataFrame\n\n    \"\"\"\n\n    if datetime_format is not None:\n        date_func = lambda x: datetime.strptime(x,datetime_format)\n    else:\n        date_func = date_parser\n    df = pd.read_csv(smp_filename, delim_whitespace=True,\n                     parse_dates={\"datetime\":[\"date\",\"time\"]},\n                     header=None,names=[\"name\",\"date\",\"time\",\"value\"],\n                     dtype={\"name\":object,\"value\":np.float64},\n                     na_values=[\"dry\"],\n                     date_parser=date_func)\n    return df"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_nsing(self,epsilon=1.0e-4):\n        mx = self.xtqx.shape[0]\n        nsing = mx - np.searchsorted(\n                np.sort((self.xtqx.s.x / self.xtqx.s.x.max())[:,0]),epsilon)\n        if nsing == mx:\n            self.logger.warn(\"optimal nsing=npar\")\n            nsing = None\n        return nsing", "response": "get the number of solution space dimensions given a ratio between the largest and smallest singular values ratio\n           "}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_null_proj(self,nsing=None):\n        if nsing is None:\n            nsing = self.get_nsing()\n        if nsing is None:\n            raise Exception(\"nsing is None\")\n        print(\"using {0} singular components\".format(nsing))\n        self.log(\"forming null space projection matrix with \" +\\\n                 \"{0} of {1} singular components\".format(nsing,self.jco.shape[1]))\n\n        v2_proj = (self.xtqx.v[:,nsing:] * self.xtqx.v[:,nsing:].T)\n        self.log(\"forming null space projection matrix with \" +\\\n                 \"{0} of {1} singular components\".format(nsing,self.jco.shape[1]))\n\n        return v2_proj", "response": "get a null - space projection matrix of XTQX"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndraws stochastic realizations of parameters and optionally observations filling MonteCarlo. parensemble and MonteCarlo. obsensemble.", "response": "def draw(self, num_reals=1, par_file = None, obs=False,\n             enforce_bounds=None, cov=None, how=\"gaussian\"):\n        \"\"\"draw stochastic realizations of parameters and\n           optionally observations, filling MonteCarlo.parensemble and\n           optionally MonteCarlo.obsensemble.\n\n        Parameters\n        ----------\n        num_reals : int\n            number of realization to generate\n        par_file : str\n            parameter file to use as mean values. If None,\n            use MonteCarlo.pst.parameter_data.parval1.\n            Default is None\n        obs : bool\n            add a realization of measurement noise to observation values,\n            forming MonteCarlo.obsensemble.Default is False\n        enforce_bounds : str\n            enforce parameter bounds based on control file information.\n            options are 'reset', 'drop' or None.  Default is None\n        how : str\n            type of distribution to draw from. Must be in [\"gaussian\",\"uniform\"]\n            default is \"gaussian\".\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>mc = pyemu.MonteCarlo(pst=\"pest.pst\")``\n\n        ``>>>mc.draw(1000)``\n\n        \"\"\"\n        if par_file is not None:\n            self.pst.parrep(par_file)\n        how = how.lower().strip()\n        assert how in [\"gaussian\",\"uniform\"]\n\n        if cov is not None:\n            assert isinstance(cov,Cov)\n            if how == \"uniform\":\n                raise Exception(\"MonteCarlo.draw() error: 'how'='uniform',\" +\\\n                                \" 'cov' arg cannot be passed\")\n        else:\n            cov = self.parcov\n\n        self.log(\"generating {0:d} parameter realizations\".format(num_reals))\n\n        if how == \"gaussian\":\n            self.parensemble = ParameterEnsemble.from_gaussian_draw(pst=self.pst,cov=cov,\n                                                                    num_reals=num_reals,\n                                                                    use_homegrown=True,\n                                                                    enforce_bounds=False)\n\n        elif how == \"uniform\":\n            self.parensemble = ParameterEnsemble.from_uniform_draw(pst=self.pst,num_reals=num_reals)\n\n        else:\n            raise Exception(\"MonteCarlo.draw(): unrecognized 'how' arg: {0}\".format(how))\n\n        #self.parensemble = ParameterEnsemble(pst=self.pst)\n        #self.obsensemble = ObservationEnsemble(pst=self.pst)\n        #self.parensemble.draw(cov,num_reals=num_reals, how=how,\n        #                      enforce_bounds=enforce_bounds)\n        if enforce_bounds is not  None:\n            self.parensemble.enforce(enforce_bounds)\n        self.log(\"generating {0:d} parameter realizations\".format(num_reals))\n\n        if obs:\n            self.log(\"generating {0:d} observation realizations\".format(num_reals))\n            self.obsensemble = ObservationEnsemble.from_id_gaussian_draw(pst=self.pst,num_reals=num_reals)\n            self.log(\"generating {0:d} observation realizations\".format(num_reals))"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nproject the parameter ensemble with null - space projection", "response": "def project_parensemble(self,par_file=None,nsing=None,\n                            inplace=True,enforce_bounds='reset'):\n        \"\"\" perform the null-space projection operations for null-space monte carlo\n\n        Parameters\n        ----------\n        par_file: str\n            an optional file of parameter values to use\n        nsing: int\n            number of singular values to in forming null subspace matrix\n        inplace: bool\n            overwrite the existing parameter ensemble with the\n            projected values\n        enforce_bounds: str\n            how to enforce parameter bounds.  can be None, 'reset', or 'drop'.\n            Default is None\n\n        Returns\n        -------\n        par_en : pyemu.ParameterEnsemble\n            if inplace is False, otherwise None\n\n        Note\n        ----\n        to use this method, the MonteCarlo instance must have been constructed\n        with the ``jco`` argument.\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>mc = pyemu.MonteCarlo(jco=\"pest.jcb\")``\n\n        ``>>>mc.draw(1000)``\n\n        ``>>>mc.project_parensemble(par_file=\"final.par\",nsing=100)``\n\n        \"\"\"\n        assert self.jco is not None,\"MonteCarlo.project_parensemble()\" +\\\n                                    \"requires a jacobian attribute\"\n        if par_file is not None:\n            assert os.path.exists(par_file),\"monte_carlo.draw() error: par_file not found:\" +\\\n                par_file\n            self.parensemble.pst.parrep(par_file)\n\n        # project the ensemble\n        self.log(\"projecting parameter ensemble\")\n        en = self.parensemble.project(self.get_null_proj(nsing),inplace=inplace,log=self.log)\n        self.log(\"projecting parameter ensemble\")\n        return en"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrite the parameters and optionally observation realizations to a series of pest control files", "response": "def write_psts(self,prefix,existing_jco=None,noptmax=None):\n        \"\"\" write parameter and optionally observation realizations\n            to a series of pest control files\n\n        Parameters\n        ----------\n        prefix: str\n            pest control file prefix\n\n        existing_jco: str\n            filename of an existing jacobian matrix to add to the\n            pest++ options in the control file.  This is useful for\n            NSMC since this jco can be used to get the first set of\n            parameter upgrades for free!  Needs to be the path the jco\n            file as seen from the location where pest++ will be run\n\n        noptmax: int\n            value of NOPTMAX to set in new pest control files\n\n        Example\n        -------\n        ``>>>import pyemu``\n\n        ``>>>mc = pyemu.MonteCarlo(jco=\"pest.jcb\")``\n\n        ``>>>mc.draw(1000, obs=True)``\n\n        ``>>>mc.write_psts(\"mc_\", existing_jco=\"pest.jcb\", noptmax=1)``\n\n        \"\"\"\n        self.log(\"writing realized pest control files\")\n        # get a copy of the pest control file\n        pst = self.pst.get(par_names=self.pst.par_names,obs_names=self.pst.obs_names)\n\n        if noptmax is not None:\n            pst.control_data.noptmax = noptmax\n            pst.control_data.noptmax = noptmax\n\n        if existing_jco is not None:\n            pst.pestpp_options[\"BASE_JACOBIAN\"] = existing_jco\n\n        # set the indices\n        pst.parameter_data.index = pst.parameter_data.parnme\n        pst.observation_data.index = pst.observation_data.obsnme\n\n        if self.parensemble.istransformed:\n            par_en = self.parensemble._back_transform(inplace=False)\n        else:\n            par_en = self.parensemble\n\n        for i in range(self.num_reals):\n            pst_name = prefix + \"{0:d}.pst\".format(i)\n            self.log(\"writing realized pest control file \" + pst_name)\n            pst.parameter_data.loc[par_en.columns,\"parval1\"] = par_en.iloc[i, :].T\n\n            # reset the regularization\n            #if pst.control_data.pestmode == \"regularization\":\n                #pst.zero_order_tikhonov(parbounds=True)\n                #zero_order_tikhonov(pst,parbounds=True)\n            # add the obs noise realization if needed\n            if self.obsensemble.shape[0] == self.num_reals:\n                pst.observation_data.loc[self.obsensemble.columns,\"obsval\"] = \\\n                    self.obsensemble.iloc[i, :].T\n\n            # write\n            pst.write(pst_name)\n            self.log(\"writing realized pest control file \" + pst_name)\n        self.log(\"writing realized pest control files\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nidentifies which candidate solutions in obs_df are feasible with respect obs constraints", "response": "def is_feasible(self, obs_df, risk=0.5):\n        \"\"\"identify which candidate solutions in obs_df (rows)\n        are feasible with respect obs constraints (obs_df)\n\n        Parameters\n        ----------\n        obs_df : pandas.DataFrame\n            a dataframe with columns of obs names and rows of realizations\n        risk : float\n            risk value. If != 0.5, then risk shifting is used.  Otherwise, the\n            obsval in Pst is used.  Default is 0.5.\n\n\n        Returns\n        -------\n        is_feasible : pandas.Series\n            series with obs_df.index and bool values\n\n        \"\"\"\n        # todo deal with pi eqs\n\n        is_feasible = pd.Series(data=True, index=obs_df.index)\n        for lt_obs in self.pst.less_than_obs_constraints:\n            if risk != 0.5:\n                val = self.get_risk_shifted_value(risk,obs_df.loc[lt_obs])\n            else:\n                val = self.pst.observation_data.loc[lt_obs,\"obsval\"]\n            is_feasible.loc[obs_df.loc[:,lt_obs]>=val] = False\n        for gt_obs in self.pst.greater_than_obs_constraints:\n            if risk != 0.5:\n                val = self.get_risk_shifted_value(risk,obs_df.loc[gt_obs])\n            else:\n                val = self.pst.observation_data.loc[gt_obs,\"obsval\"]\n            is_feasible.loc[obs_df.loc[:,gt_obs] <= val] = False\n        return is_feasible"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nidentify which candidate solutions are pareto non - dominated - super patheically slow...", "response": "def is_nondominated_pathetic(self, obs_df):\n        \"\"\"identify which candidate solutions are pareto non-dominated -\n        super patheically slow...\n\n        Parameters\n        ----------\n        obs_df : pandas.DataFrame\n            dataframe with columns of observation names and rows of realizations\n\n        Returns\n        -------\n        is_dominated : pandas.Series\n            series with index of obs_df and bool series\n        \"\"\"\n        obj_df = obs_df.loc[:,self.obs_obj_names]\n        is_nondom = []\n        for i,iidx in enumerate(obj_df.index):\n            ind = True\n            for jidx in obj_df.index:\n                if iidx == jidx:\n                    continue\n                # if dominates(jidx,iidx):\n                #     ind = False\n                #     break\n                if self.dominates(obj_df.loc[jidx,:], obj_df.loc[iidx,:]):\n                    ind = False\n                    break\n\n            is_nondom.append(ind)\n        is_nondom = pd.Series(data=is_nondom,index=obs_df.index,dtype=bool)\n        return is_nondom"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nidentifying which candidate solutions are pareto non - dominated continuously updated but still slow", "response": "def is_nondominated_continuous(self, obs_df):\n        \"\"\"identify which candidate solutions are pareto non-dominated continuously updated,\n        but still slow\n\n        Parameters\n        ----------\n        obs_df : pandas.DataFrame\n            dataframe with columns of observation names and rows of realizations\n\n        Returns\n        -------\n        is_dominated : pandas.Series\n            series with index of obs_df and bool series\n        \"\"\"\n\n        obj_df = obs_df.loc[:,self.obs_obj_names]\n        P = list(obj_df.index)\n        PP = set()\n        PP.add(P[0])\n\n        #iidx = 1\n        #while iidx < len(P):\n        for iidx in P:\n            jidx = 0\n            drop = []\n            keep = True\n            for jidx in PP:\n                # if dominates(iidx,jidx):\n                #     drop.append(jidx)\n                # elif dominates(jidx,iidx):\n                #     keep = False\n                #     break\n                if jidx == iidx:\n                    continue\n                if self.dominates(obj_df.loc[iidx, :], obj_df.loc[jidx, :]):\n                    drop.append(jidx)\n                elif self.dominates(obj_df.loc[jidx, :], obj_df.loc[iidx, :]):\n                    keep = False\n                    break\n            for d in drop:\n                PP.remove(d)\n            if keep:\n                PP.add(iidx)\n            #iidx += 1\n\n\n\n\n        is_nondom = pd.Series(data=False,index=obs_df.index,dtype=bool)\n        is_nondom.loc[PP] = True\n        return is_nondom"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nidentify which candidate solutions are pareto non - dominated using Kungs algorithm", "response": "def is_nondominated_kung(self, obs_df):\n        \"\"\"identify which candidate solutions are pareto non-dominated using Kungs algorithm\n\n        Parameters\n        ----------\n        obs_df : pandas.DataFrame\n            dataframe with columns of observation names and rows of realizations\n\n        Returns\n        -------\n        is_dominated : pandas.Series\n            series with index of obs_df and bool series\n        \"\"\"\n\n        obj_df = obs_df.loc[:,self.obs_obj_names]\n        obj_names = self.obs_obj_names\n        ascending = False\n        if self.obs_dict[obj_names[0]] == \"min\":\n            ascending = True\n\n        obj_df.sort_values(by=obj_names[0],ascending=ascending,inplace=True)\n        P = list(obj_df.index)\n\n        def front(p):\n            if len(p) == 1:\n                return p\n            p = list(obj_df.loc[p,:].sort_values(by=obj_names[0],ascending=ascending).index)\n            half = int(len(p) / 2)\n            T = front(p[:half])\n            B = front(p[half:])\n            M = []\n            i = 0\n            while i < len(B):\n                j = 0\n                while j < len(T):\n                    #if dominates(T[j],B[i]):\n                    if self.dominates(obj_df.loc[T[j],:], obj_df.loc[B[i],:]):\n                        break\n                    j += 1\n                if (j == len(T)):\n                    M.append(B[i])\n                i += 1\n            T.extend(M)\n            return T\n\n\n        PP = front(P)\n        is_nondom = pd.Series(data=False,index=obs_df.index,dtype=bool)\n        is_nondom.loc[PP] = True\n        return is_nondom"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef crowd_distance(self,obs_df):\n\n        # initialize the distance container\n        crowd_distance = pd.Series(data=0.0,index=obs_df.index)\n\n        for name,direction in self.obs_dict.items():\n            # make a copy - wasteful, but easier\n            obj_df = obs_df.loc[:,name].copy()\n\n            # sort so that largest values are first\n            obj_df.sort_values(ascending=False,inplace=True)\n\n            # set the ends so they are always retained\n            crowd_distance.loc[obj_df.index[0]] += self.max_distance\n            crowd_distance.loc[obj_df.index[-1]] += self.max_distance\n\n            # process the vector\n            i = 1\n            for idx in obj_df.index[1:-1]:\n                crowd_distance.loc[idx] += obj_df.iloc[i-1] - obj_df.iloc[i+1]\n                i += 1\n\n        return crowd_distance", "response": "determine the crowding distance for each candidate solution in the cluster"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nassigns the primary unicode to the glyph.", "response": "def _set_unicode(self, value):\n        \"\"\"\n        Assign the primary unicode to the glyph.\n        This will be an integer or None.\n\n        Subclasses may override this method.\n        \"\"\"\n        values = list(self.unicodes)\n        if value in values:\n            values.remove(value)\n        values.insert(0, value)\n        self.unicodes = values"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the left margin of the glyph.", "response": "def _get_leftMargin(self):\n        \"\"\"\n        This must return an int or float.\n        If the glyph has no outlines, this must return `None`.\n\n        Subclasses may override this method.\n        \"\"\"\n        bounds = self.bounds\n        if bounds is None:\n            return None\n        xMin, yMin, xMax, yMax = bounds\n        return xMin"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the left margin of the log entry.", "response": "def _set_leftMargin(self, value):\n        \"\"\"\n        value will be an int or float.\n\n        Subclasses may override this method.\n        \"\"\"\n        diff = value - self.leftMargin\n        self.moveBy((diff, 0))\n        self.width += diff"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_rightMargin(self):\n        bounds = self.bounds\n        if bounds is None:\n            return None\n        xMin, yMin, xMax, yMax = bounds\n        return self.width - xMax", "response": "Returns the right margin of the glyph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the right margin of the log entry.", "response": "def _set_rightMargin(self, value):\n        \"\"\"\n        value will be an int or float.\n\n        Subclasses may override this method.\n        \"\"\"\n        bounds = self.bounds\n        if bounds is None:\n            self.width = value\n        else:\n            xMin, yMin, xMax, yMax = bounds\n            self.width = xMax + value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the bottom margin of the glyph.", "response": "def _get_bottomMargin(self):\n        \"\"\"\n        This must return an int or float.\n        If the glyph has no outlines, this must return `None`.\n\n        Subclasses may override this method.\n        \"\"\"\n        bounds = self.bounds\n        if bounds is None:\n            return None\n        xMin, yMin, xMax, yMax = bounds\n        return yMin"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_bottomMargin(self, value):\n        diff = value - self.bottomMargin\n        self.moveBy((0, diff))\n        self.height += diff", "response": "Set the bottom margin of the log entry."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the top margin of the glyph.", "response": "def _get_topMargin(self):\n        \"\"\"\n        This must return an int or float.\n        If the glyph has no outlines, this must return `None`.\n\n        Subclasses may override this method.\n        \"\"\"\n        bounds = self.bounds\n        if bounds is None:\n            return None\n        xMin, yMin, xMax, yMax = bounds\n        return self.height - yMax"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the top margin of the log entry.", "response": "def _set_topMargin(self, value):\n        \"\"\"\n        value will be an int or float.\n\n        Subclasses may override this method.\n        \"\"\"\n        bounds = self.bounds\n        if bounds is None:\n            self.height = value\n        else:\n            xMin, yMin, xMax, yMax = bounds\n            self.height = yMax + value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndraw the glyph s outline data to the given type - pen.", "response": "def draw(self, pen, contours=True, components=True):\n        \"\"\"\n        Draw the glyph's outline data (contours and components) to\n        the given :ref:`type-pen`.\n\n            >>> glyph.draw(pen)\n\n        If ``contours`` is set to ``False``, the glyph's\n        contours will not be drawn.\n\n            >>> glyph.draw(pen, contours=False)\n\n        If ``components`` is set to ``False``, the glyph's\n        components will not be drawn.\n\n            >>> glyph.draw(pen, components=False)\n        \"\"\"\n        if contours:\n            for contour in self:\n                contour.draw(pen)\n        if components:\n            for component in self.components:\n                component.draw(pen)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef drawPoints(self, pen, contours=True, components=True):\n        if contours:\n            for contour in self:\n                contour.drawPoints(pen)\n        if components:\n            for component in self.components:\n                component.drawPoints(pen)", "response": "Draw the glyph s outline data to\n        the given type - pointpen."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef clear(self, contours=True, components=True, anchors=True,\n              guidelines=True, image=True):\n        \"\"\"\n        Clear the glyph.\n\n            >>> glyph.clear()\n\n        This clears:\n\n        - contours\n        - components\n        - anchors\n        - guidelines\n        - image\n\n        It's possible to turn off the clearing of portions of\n        the glyph with the listed arguments.\n\n            >>> glyph.clear(guidelines=False)\n        \"\"\"\n        self._clear(contours=contours, components=components,\n                    anchors=anchors, guidelines=guidelines, image=image)", "response": "Clear the glyph.\n\n            >>> glyph.clear()\n\n        This clears:\n\n        - contours\n        - components\n        - anchors\n        - guidelines\n        - image\n\n        It's possible to turn off the clearing of portions of\n        the glyph with the listed arguments.\n\n            >>> glyph.clear(guidelines=False)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _clear(self, contours=True, components=True, anchors=True,\n               guidelines=True, image=True):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        if contours:\n            self.clearContours()\n        if components:\n            self.clearComponents()\n        if anchors:\n            self.clearAnchors()\n        if guidelines:\n            self.clearGuidelines()\n        if image:\n            self.clearImage()", "response": "Clear the internal cache of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nappend the data from other to this glyph.", "response": "def appendGlyph(self, other, offset=None):\n        \"\"\"\n        Append the data from ``other`` to new objects in this glyph.\n        This will append:\n\n        - contours\n        - components\n        - anchors\n        - guidelines\n\n            >>> glyph.appendGlyph(otherGlyph)\n\n        ``offset`` indicates the x and y shift values that should\n        be applied to the appended data. It must be a :ref:`type-coordinate`\n        value or ``None``. If ``None`` is given, the offset will be ``(0, 0)``.\n\n            >>> glyph.appendGlyph(otherGlyph, (100, 0))\n        \"\"\"\n        if offset is None:\n            offset = (0, 0)\n        offset = normalizers.normalizeTransformationOffset(offset)\n        self._appendGlyph(other, offset)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nappend glyph to the glyph list.", "response": "def _appendGlyph(self, other, offset=None):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        other = other.copy()\n        if offset != (0, 0):\n            other.moveBy(offset)\n        for contour in other.contours:\n            self.appendContour(contour)\n        for component in other.components:\n            self.appendComponent(component=component)\n        for anchor in other.anchors:\n            self.appendAnchor(anchor=anchor)\n        for guideline in other.guidelines:\n            self.appendGuideline(guideline=guideline)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef appendContour(self, contour, offset=None):\n        contour = normalizers.normalizeContour(contour)\n        if offset is None:\n            offset = (0, 0)\n        offset = normalizers.normalizeTransformationOffset(offset)\n        return self._appendContour(contour, offset)", "response": "Append a contour containing the same data as contour to this glyph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nappends a contour to the end of the contour.", "response": "def _appendContour(self, contour, offset=None, **kwargs):\n        \"\"\"\n        contour will be an object with a drawPoints method.\n\n        offset will be a valid offset (x, y).\n\n        This must return the new contour.\n\n        Subclasses may override this method.\n        \"\"\"\n        copy = contour.copy()\n        if offset != (0, 0):\n            copy.moveBy(offset)\n        pointPen = self.getPointPen()\n        contour.drawPoints(pointPen)\n        return self[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef removeContour(self, contour):\n        if isinstance(contour, int):\n            index = contour\n        else:\n            index = self._getContourIndex(contour)\n        index = normalizers.normalizeIndex(index)\n        if index >= len(self):\n            raise ValueError(\"No contour located at index %d.\" % index)\n        self._removeContour(index)", "response": "Remove a contour from the glyph."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a tuple of the components of the current object.", "response": "def _get_components(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        return tuple([self._getitem__components(i) for\n                     i in range(self._len__components())])"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef appendComponent(self, baseGlyph=None, offset=None, scale=None, component=None):\n        identifier = None\n        sxy = 0\n        syx = 0\n        if component is not None:\n            component = normalizers.normalizeComponent(component)\n            if baseGlyph is None:\n                baseGlyph = component.baseGlyph\n            sx, sxy, syx, sy, ox, oy = component.transformation\n            if offset is None:\n                offset = (ox, oy)\n            if scale is None:\n                scale = (sx, sy)\n            if baseGlyph is None:\n                baseGlyph = component.baseGlyph\n            if component.identifier is not None:\n                existing = set([c.identifier for c in self.components if c.identifier is not None])\n                if component.identifier not in existing:\n                    identifier = component.identifier\n        baseGlyph = normalizers.normalizeGlyphName(baseGlyph)\n        if self.name == baseGlyph:\n            raise FontPartsError((\"A glyph cannot contain a component referencing itself.\"))\n        if offset is None:\n            offset = (0, 0)\n        if scale is None:\n            scale = (1, 1)\n        offset = normalizers.normalizeTransformationOffset(offset)\n        scale = normalizers.normalizeTransformationScale(scale)\n        ox, oy = offset\n        sx, sy = scale\n        transformation = (sx, sxy, syx, sy, ox, oy)\n        identifier = normalizers.normalizeIdentifier(identifier)\n        return self._appendComponent(baseGlyph, transformation=transformation, identifier=identifier)", "response": "Append a component to this glyph."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _appendComponent(self, baseGlyph, transformation=None, identifier=None, **kwargs):\n        pointPen = self.getPointPen()\n        pointPen.addComponent(baseGlyph, transformation=transformation, identifier=identifier)\n        return self.components[-1]", "response": "Append a new component to the current component list."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef removeComponent(self, component):\n        if isinstance(component, int):\n            index = component\n        else:\n            index = self._getComponentIndex(component)\n        index = normalizers.normalizeIndex(index)\n        if index >= self._len__components():\n            raise ValueError(\"No component located at index %d.\" % index)\n        self._removeComponent(index)", "response": "Remove a component from the glyph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a tuple of the anchor names of the current object.", "response": "def _get_anchors(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        return tuple([self._getitem__anchors(i) for\n                     i in range(self._len__anchors())])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends an anchor to this glyph.", "response": "def appendAnchor(self, name=None, position=None, color=None, anchor=None):\n        \"\"\"\n        Append an anchor to this glyph.\n\n            >>> anchor = glyph.appendAnchor(\"top\", (10, 20))\n\n        This will return a :class:`BaseAnchor` object representing\n        the new anchor in the glyph. ``name`` indicated the name to\n        be assigned to the anchor. It must be a :ref:`type-string`\n        or ``None``. ``position`` indicates the x and y location\n        to be applied to the anchor. It must be a\n        :ref:`type-coordinate` value. ``color`` indicates the color\n        to be applied to the anchor. It must be a :ref:`type-color`\n        or ``None``.\n\n            >>> anchor = glyph.appendAnchor(\"top\", (10, 20), color=(1, 0, 0, 1))\n\n        ``anchor`` may be a :class:`BaseAnchor` object from which\n        attribute values will be copied. If ``name``, ``position``\n        or ``color`` are specified as arguments, those values will\n        be used instead of the values in the given anchor object.\n        \"\"\"\n        identifier = None\n        if anchor is not None:\n            anchor = normalizers.normalizeAnchor(anchor)\n            if name is None:\n                name = anchor.name\n            if position is None:\n                position = anchor.position\n            if color is None:\n                color = anchor.color\n            if anchor.identifier is not None:\n                existing = set([a.identifier for a in self.anchors if a.identifier is not None])\n                if anchor.identifier not in existing:\n                    identifier = anchor.identifier\n        name = normalizers.normalizeAnchorName(name)\n        position = normalizers.normalizeCoordinateTuple(position)\n        if color is not None:\n            color = normalizers.normalizeColor(color)\n        identifier = normalizers.normalizeIdentifier(identifier)\n        return self._appendAnchor(name, position=position, color=color, identifier=identifier)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nremoves an anchor from the glyph.", "response": "def removeAnchor(self, anchor):\n        \"\"\"\n        Remove ``anchor`` from the glyph.\n\n            >>> glyph.removeAnchor(anchor)\n\n        ``anchor`` may be an :ref:`BaseAnchor` or an\n        :ref:`type-int` representing an anchor index.\n        \"\"\"\n        if isinstance(anchor, int):\n            index = anchor\n        else:\n            index = self._getAnchorIndex(anchor)\n        index = normalizers.normalizeIndex(index)\n        if index >= self._len__anchors():\n            raise ValueError(\"No anchor located at index %d.\" % index)\n        self._removeAnchor(index)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_guidelines(self):\n        return tuple([self._getitem__guidelines(i) for\n                     i in range(self._len__guidelines())])", "response": "Return a tuple of unique identifiers."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _appendGuideline(self, position, angle, name=None, color=None, identifier=None, **kwargs):\n        self.raiseNotImplementedError()", "response": "Append a guideline to the current guideline."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove a guideline from the glyph.", "response": "def removeGuideline(self, guideline):\n        \"\"\"\n        Remove ``guideline`` from the glyph.\n\n            >>> glyph.removeGuideline(guideline)\n\n        ``guideline`` may be a :ref:`BaseGuideline` or an\n        :ref:`type-int` representing an guideline index.\n        \"\"\"\n        if isinstance(guideline, int):\n            index = guideline\n        else:\n            index = self._getGuidelineIndex(guideline)\n        index = normalizers.normalizeIndex(index)\n        if index >= self._len__guidelines():\n            raise ValueError(\"No guideline located at index %d.\" % index)\n        self._removeGuideline(index)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _round(self):\n        for contour in self.contours:\n            contour.round()\n        for component in self.components:\n            component.round()\n        for anchor in self.anchors:\n            anchor.round()\n        for guideline in self.guidelines:\n            guideline.round()\n        self.width = normalizers.normalizeRounding(self.width)\n        self.height = normalizers.normalizeRounding(self.height)", "response": "Performs round operations on the internal representation of the object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _transformBy(self, matrix, **kwargs):\n        for contour in self.contours:\n            contour.transformBy(matrix)\n        for component in self.components:\n            component.transformBy(matrix)\n        for anchor in self.anchors:\n            anchor.transformBy(matrix)\n        for guideline in self.guidelines:\n            guideline.transformBy(matrix)", "response": "This method is called by the contour components anchor and guideline functions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nscaling the glyph by the given value.", "response": "def scaleBy(self, value, origin=None, width=False, height=False):\n        \"\"\"\n        %s\n        **width** indicates if the glyph's width should be scaled.\n        **height** indicates if the glyph's height should be scaled.\n\n        The origin must not be specified when scaling the width or height.\n        \"\"\"\n        value = normalizers.normalizeTransformationScale(value)\n        if origin is None:\n            origin = (0, 0)\n        origin = normalizers.normalizeCoordinateTuple(origin)\n        if origin != (0, 0) and (width or height):\n            raise FontPartsError((\"The origin must not be set when \"\n                                  \"scaling the width or height.\"))\n        super(BaseGlyph, self).scaleBy(value, origin=origin)\n        sX, sY = value\n        if width:\n            self._scaleWidthBy(sX)\n        if height:\n            self._scaleHeightBy(sY)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a copy of the current object as a fontMath. MathGlyph.", "response": "def _toMathGlyph(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        import fontMath\n        mathGlyph = fontMath.MathGlyph(None)\n        pen = mathGlyph.getPointPen()\n        self.drawPoints(pen)\n        for anchor in self.anchors:\n            d = dict(\n                x=anchor.x,\n                y=anchor.y,\n                name=anchor.name,\n                identifier=anchor.identifier,\n                color=anchor.color\n            )\n            mathGlyph.anchors.append(d)\n        for guideline in self.guidelines:\n            d = dict(\n                x=guideline.x,\n                y=guideline.y,\n                angle=guideline.angle,\n                name=guideline.name,\n                identifier=guideline.identifier,\n                color=guideline.color\n            )\n            mathGlyph.guidelines.append(d)\n        image = self.image\n        mathGlyph.image = dict(\n            # MathGlyph works with image file names, hack\n            # around it by using the data as the file name.\n            fileName=image.data,\n            transformation=image.transformation,\n            color=image.color\n        )\n        mathGlyph.lib = deepcopy(self.lib)\n        mathGlyph.name = self.name\n        mathGlyph.unicodes = self.unicodes\n        mathGlyph.width = self.width\n        mathGlyph.height = self.height\n        mathGlyph.note = self.note\n        return mathGlyph"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninterpolate the contents of this glyph between two glyphs.", "response": "def interpolate(self, factor, minGlyph, maxGlyph,\n                    round=True, suppressError=True):\n        \"\"\"\n        Interpolate the contents of this glyph at location ``factor``\n        in a linear interpolation between ``minGlyph`` and ``maxGlyph``.\n\n            >>> glyph.interpolate(0.5, otherGlyph1, otherGlyph2)\n\n        ``factor`` may be a :ref:`type-int-float` or a tuple containing\n        two :ref:`type-int-float` values representing x and y factors.\n\n            >>> glyph.interpolate((0.5, 1.0), otherGlyph1, otherGlyph2)\n\n        ``minGlyph`` must be a :class:`BaseGlyph` and will be located at 0.0\n        in the interpolation range. ``maxGlyph`` must be a :class:`BaseGlyph`\n        and will be located at 1.0 in the interpolation range. If ``round``\n        is ``True``, the contents of the glyph will be rounded to integers\n        after the interpolation is performed.\n\n            >>> glyph.interpolate(0.5, otherGlyph1, otherGlyph2, round=True)\n\n        This method assumes that ``minGlyph`` and ``maxGlyph`` are completely\n        compatible with each other for interpolation. If not, any errors\n        encountered will raise a :class:`FontPartsError`. If ``suppressError``\n        is ``True``, no exception will be raised and errors will be silently\n        ignored.\n        \"\"\"\n        factor = normalizers.normalizeInterpolationFactor(factor)\n        if not isinstance(minGlyph, BaseGlyph):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__,\n                               minGlyph.__class__.__name__))\n        if not isinstance(maxGlyph, BaseGlyph):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__,\n                               maxGlyph.__class__.__name__))\n        round = normalizers.normalizeBoolean(round)\n        suppressError = normalizers.normalizeBoolean(suppressError)\n        self._interpolate(factor, minGlyph, maxGlyph,\n                          round=round, suppressError=suppressError)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ninterpolates the glyph between two glyphs.", "response": "def _interpolate(self, factor, minGlyph, maxGlyph,\n                     round=True, suppressError=True):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        minGlyph = minGlyph._toMathGlyph()\n        maxGlyph = maxGlyph._toMathGlyph()\n        try:\n            result = interpolate(minGlyph, maxGlyph, factor)\n        except IndexError:\n            result = None\n        if result is None and not suppressError:\n            raise FontPartsError((\"Glyphs '%s' and '%s' could not be \"\n                                  \"interpolated.\")\n                                 % (minGlyph.name, maxGlyph.name))\n        if result is not None:\n            if round:\n                result = result.round()\n            self._fromMathGlyph(result, toThisGlyph=True)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn True if point is inside the black or white of the glyph.", "response": "def pointInside(self, point):\n        \"\"\"\n        Determine if ``point`` is in the black or white of the glyph.\n\n            >>> glyph.pointInside((40, 65))\n            True\n\n        ``point`` must be a :ref:`type-coordinate`.\n        \"\"\"\n        point = normalizers.normalizeCoordinateTuple(point)\n        return self._pointInside(point)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _get_bounds(self):\n        from fontTools.pens.boundsPen import BoundsPen\n        pen = BoundsPen(self.layer)\n        self.draw(pen)\n        return pen.bounds", "response": "Returns the current bounds of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the area of the current object.", "response": "def _get_area(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        from fontTools.pens.areaPen import AreaPen\n        pen = AreaPen(self.layer)\n        self.draw(pen)\n        return abs(pen.value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget the type - glyph - layer with the given name.", "response": "def getLayer(self, name):\n        \"\"\"\n        Get the :ref:`type-glyph-layer` with ``name`` in this glyph.\n\n            >>> glyphLayer = glyph.getLayer(\"foreground\")\n        \"\"\"\n        name = normalizers.normalizeLayerName(name)\n        return self._getLayer(name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getLayer(self, name, **kwargs):\n        for glyph in self.layers:\n            if glyph.layer.name == name:\n                return glyph\n        raise ValueError(\"No layer named '%s' in glyph '%s'.\"\n                         % (name, self.name))", "response": "Returns the glyph layer with the given name."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef newLayer(self, name):\n        layerName = name\n        glyphName = self.name\n        layerName = normalizers.normalizeLayerName(layerName)\n        for glyph in self.layers:\n            if glyph.layer.name == layerName:\n                layer = glyph.layer\n                layer.removeGlyph(glyphName)\n                break\n        glyph = self._newLayer(name=layerName)\n        layer = self.font.getLayer(layerName)\n        # layer._setLayerInGlyph(glyph)\n        return glyph", "response": "Make a new layer with the given name in this glyph."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nremove a layer from this glyph.", "response": "def removeLayer(self, layer):\n        \"\"\"\n        Remove ``layer`` from this glyph.\n\n            >>> glyph.removeLayer(\"background\")\n\n        Layer can be a :ref:`type-glyph-layer` or a :ref:`type-string`\n        representing a layer name.\n        \"\"\"\n        if isinstance(layer, BaseGlyph):\n            layer = layer.layer.name\n        layerName = layer\n        layerName = normalizers.normalizeLayerName(layerName)\n        if self._getLayer(layerName).layer.name == layerName:\n            self._removeLayer(layerName)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef addImage(self, path=None, data=None, scale=None,\n                 position=None, color=None):\n        \"\"\"\n        Set the image in the glyph. This will return the\n        assigned :class:`BaseImage`. The image data can be\n        defined via ``path`` to an image file:\n\n            >>> image = glyph.addImage(path=\"/path/to/my/image.png\")\n\n        The image data can be defined with raw image data\n        via ``data``.\n\n            >>> image = glyph.addImage(data=someImageData)\n\n        If ``path`` and ``data`` are both provided, a\n        :class:`FontPartsError` will be raised. The supported\n        image formats will vary across environments. Refer\n        to :class:`BaseImage` for complete details.\n\n        ``scale`` indicates the x and y scale values that should be\n        applied to the image. It must be a :ref:`type-scale` value\n        or ``None``.\n\n            >>> image = glyph.addImage(path=\"/p/t/image.png\", scale=(0.5, 1.0))\n\n        ``position`` indicates the x and y location of the lower left\n        point of the image.\n\n            >>> image = glyph.addImage(path=\"/p/t/image.png\", position=(10, 20))\n\n        ``color`` indicates the color to be applied to the image. It must\n        be a :ref:`type-color` or ``None``.\n\n            >>> image = glyph.addImage(path=\"/p/t/image.png\", color=(1, 0, 0, 0.5))\n        \"\"\"\n        if path is not None and data is not None:\n            raise FontPartsError(\"Only path or data may be defined, not both.\")\n        if scale is None:\n            scale = (1, 1)\n        if position is None:\n            position = (0, 0)\n        scale = normalizers.normalizeTransformationScale(scale)\n        position = normalizers.normalizeTransformationOffset(position)\n        if color is not None:\n            color = normalizers.normalizeColor(color)\n        sx, sy = scale\n        ox, oy = position\n        transformation = (sx, 0, 0, sy, ox, oy)\n        if path is not None:\n            if not os.path.exists(path):\n                raise IOError(\"No image located at '%s'.\" % path)\n            f = open(path, \"rb\")\n            data = f.read()\n            f.close()\n        self._addImage(data=data, transformation=transformation, color=color)\n        return self.image", "response": "Add an image to the glyph."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ndumps the glyph to GLIF.", "response": "def dumpToGLIF(self, glyphFormatVersion=2):\n        \"\"\"\n        This will return the glyph's contents as a string in\n        `GLIF format <http://unifiedfontobject.org/versions/ufo3/glyphs/glif/>`_.\n\n            >>> xml = glyph.writeGlyphToString()\n\n        ``glyphFormatVersion`` must be a :ref:`type-int` that defines\n        the preferred GLIF format version.\n        \"\"\"\n        glyphFormatVersion = normalizers.normalizeGlyphFormatVersion(\n            glyphFormatVersion)\n        return self._dumpToGLIF(glyphFormatVersion)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_index(self):\n        glyph = self.glyph\n        if glyph is None:\n            return None\n        return glyph.anchors.index(self)", "response": "Get the anchor s index."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transformBy(self, matrix, **kwargs):\n        t = transform.Transform(*matrix)\n        x, y = t.transformPoint((self.x, self.y))\n        self.x = x\n        self.y = y", "response": "This is the environment implementation of base - anchor. transformBy."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if two base names are compatible with this one.", "response": "def _isCompatible(self, other, reporter):\n        \"\"\"\n        This is the environment implementation of\n        :meth:`BaseAnchor.isCompatible`.\n\n        Subclasses may override this method.\n        \"\"\"\n        anchor1 = self\n        anchor2 = other\n        # base names\n        if anchor1.name != anchor2.name:\n            reporter.nameDifference = True\n            reporter.warning = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the offset of the base record in the base record set.", "response": "def _get_offset(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        sx, sxy, syx, sy, ox, oy = self.transformation\n        return (ox, oy)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _set_scale(self, value):\n        sx, sxy, syx, sy, ox, oy = self.transformation\n        sx, sy = value\n        self.transformation = (sx, sxy, syx, sy, ox, oy)", "response": "Sets the scale of the log record."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _transformBy(self, matrix, **kwargs):\n        t = transform.Transform(*matrix)\n        transformation = t.transform(self.transformation)\n        self.transformation = tuple(transformation)", "response": "This method transforms the current object by the given matrix."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _round(self):\n        x, y = self.offset\n        x = normalizers.normalizeRounding(x)\n        y = normalizers.normalizeRounding(y)\n        self.offset = (x, y)", "response": "Round the offset of the current object to the nearest point in the base of the base."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef asDict(self):\n        d = {}\n        for k, v in self.items():\n            d[k] = v\n        return d", "response": "Return the Lib as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get(self, key, default=None):\n        return super(BaseLib, self).get(key, default)", "response": "Returns the contents of the named key."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef pop(self, key, default=None):\n        return super(BaseLib, self).pop(key, default)", "response": "Removes the key from the Lib and returns the list of key members. If no key is found default is returned."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef newGlyph(self, name, clear=True):\n        name = normalizers.normalizeGlyphName(name)\n        if name not in self:\n            glyph = self._newGlyph(name)\n        elif clear:\n            self.removeGlyph(name)\n            glyph = self._newGlyph(name)\n        else:\n            glyph = self._getItem(name)\n        self._setLayerInGlyph(glyph)\n        return glyph", "response": "Make a new glyph with the given name in the layer."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insertGlyph(self, glyph, name=None):\n        if name is None:\n            name = glyph.name\n        self[name] = glyph", "response": "Insert glyph into the layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the glyph names of the current set of glyph names.", "response": "def _set_selectedGlyphNames(self, value):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        select = [self[name] for name in value]\n        self.selectedGlyphs = select"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncopies data from source into this layer.", "response": "def copyData(self, source):\n        \"\"\"\n        Copy data from **source** into this layer.\n        Refer to :meth:`BaseLayer.copy` for a list\n        of values that will be copied.\n        \"\"\"\n        super(BaseLayer, self).copyData(source)\n        for name in source.keys():\n            glyph = self.newGlyph(name)\n            glyph.copyData(source[name])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef interpolate(self, factor, minLayer, maxLayer, round=True,\n                    suppressError=True):\n        \"\"\"\n        Interpolate all possible data in the layer. ::\n\n            >>> layer.interpolate(0.5, otherLayer1, otherLayer2)\n            >>> layer.interpolate((0.5, 2.0), otherLayer1, otherLayer2, round=False)\n\n        The interpolation occurs on a 0 to 1.0 range where **minLayer**\n        is located at 0 and **maxLayer** is located at 1.0. **factor**\n        is the interpolation value. It may be less than 0 and greater\n        than 1.0. It may be a :ref:`type-int-float` or a tuple of\n        two :ref:`type-int-float`. If it is a tuple, the first\n        number indicates the x factor and the second number indicates\n        the y factor. **round** indicates if the result should be\n        rounded to integers. **suppressError** indicates if incompatible\n        data should be ignored or if an error should be raised when\n        such incompatibilities are found.\n        \"\"\"\n        factor = normalizers.normalizeInterpolationFactor(factor)\n        if not isinstance(minLayer, BaseLayer):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__, minLayer.__class__.__name__))\n        if not isinstance(maxLayer, BaseLayer):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__, maxLayer.__class__.__name__))\n        round = normalizers.normalizeBoolean(round)\n        suppressError = normalizers.normalizeBoolean(suppressError)\n        self._interpolate(factor, minLayer, maxLayer,\n                          round=round, suppressError=suppressError)", "response": "Interpolate all possible data in the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _interpolate(self, factor, minLayer, maxLayer, round=True,\n                     suppressError=True):\n        \"\"\"\n        This is the environment implementation of\n        :meth:`BaseLayer.interpolate`.\n\n        Subclasses may override this method.\n        \"\"\"\n        for glyphName in self.keys():\n            del self[glyphName]\n        for glyphName in minLayer.keys():\n            if glyphName not in maxLayer:\n                continue\n            minGlyph = minLayer[glyphName]\n            maxGlyph = maxLayer[glyphName]\n            dstGlyph = self.newGlyph(glyphName)\n            dstGlyph.interpolate(factor, minGlyph, maxGlyph,\n                                 round=round, suppressError=suppressError)", "response": "This method is used to interpolate the glyph between two glyph sets."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _isCompatible(self, other, reporter):\n        layer1 = self\n        layer2 = other\n\n        # incompatible number of glyphs\n        glyphs1 = set(layer1.keys())\n        glyphs2 = set(layer2.keys())\n        if len(glyphs1) != len(glyphs2):\n            reporter.glyphCountDifference = True\n            reporter.warning = True\n        if len(glyphs1.difference(glyphs2)) != 0:\n            reporter.warning = True\n            reporter.glyphsMissingFromLayer2 = list(glyphs1.difference(glyphs2))\n        if len(glyphs2.difference(glyphs1)) != 0:\n            reporter.warning = True\n            reporter.glyphsMissingInLayer1 = list(glyphs2.difference(glyphs1))\n        # test glyphs\n        for glyphName in sorted(glyphs1.intersection(glyphs2)):\n            glyph1 = layer1[glyphName]\n            glyph2 = layer2[glyphName]\n            glyphCompatibility = glyph1.isCompatible(glyph2)[1]\n            if glyphCompatibility.fatal or glyphCompatibility.warning:\n                if glyphCompatibility.fatal:\n                    reporter.fatal = True\n                if glyphCompatibility.warning:\n                    reporter.warning = True\n                reporter.glyphs.append(glyphCompatibility)", "response": "This method checks if two BaseLayer objects are compatible."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_scale(self):\n        sx, sxy, syx, sy, ox, oy = self.transformation\n        return sx, sy", "response": "Get the scale of the current log entry."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _draw(self, pen, **kwargs):\n        from fontTools.ufoLib.pointPen import PointToSegmentPen\n        adapter = PointToSegmentPen(pen)\n        self.drawPoints(adapter)", "response": "Draw the neccesary points from the pen."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndraw points from a point pen.", "response": "def _drawPoints(self, pen, **kwargs):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        # The try: ... except TypeError: ...\n        # handles backwards compatibility with\n        # point pens that have not been upgraded\n        # to point pen protocol 2.\n        try:\n            pen.addComponent(self.baseGlyph, self.transformation,\n                             identifier=self.identifier, **kwargs)\n        except TypeError:\n            pen.addComponent(self.baseGlyph, self.transformation, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncheck if two base glyphs are compatible with this one.", "response": "def _isCompatible(self, other, reporter):\n        \"\"\"\n        This is the environment implementation of\n        :meth:`BaseComponent.isCompatible`.\n\n        Subclasses may override this method.\n        \"\"\"\n        component1 = self\n        component2 = other\n        # base glyphs\n        if component1.baseName != component2.baseName:\n            reporter.baseDifference = True\n            reporter.warning = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _pointInside(self, point):\n        from fontTools.pens.pointInsidePen import PointInsidePen\n        pen = PointInsidePen(glyphSet=self.layer, testPoint=point, evenOdd=False)\n        self.draw(pen)\n        return pen.getResult()", "response": "Returns a pen that is drawn on the current glyph set and the point is inside point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _set_anchor(self, value):\n        pX, pY = self.anchor\n        x, y = value\n        dX = x - pX\n        dY = y - pY\n        self.moveBy((dX, dY))", "response": "Set anchor of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the x y coordinates of the BCP in of the current segment.", "response": "def _get_bcpIn(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        segment = self._segment\n        offCurves = segment.offCurve\n        if offCurves:\n            bcp = offCurves[-1]\n            x, y = relativeBCPIn(self.anchor, (bcp.x, bcp.y))\n        else:\n            x = y = 0\n        return (x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the bcpIn value for the current contour.", "response": "def _set_bcpIn(self, value):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        x, y = absoluteBCPIn(self.anchor, value)\n        segment = self._segment\n        if segment.type == \"move\" and value != (0, 0):\n            raise FontPartsError((\"Cannot set the bcpIn for the first \"\n                                  \"point in an open contour.\")\n                                 )\n        else:\n            offCurves = segment.offCurve\n            if offCurves:\n                # if the two off curves are located at the anchor\n                # coordinates we can switch to a line segment type.\n                if value == (0, 0) and self.bcpOut == (0, 0):\n                    segment.type = \"line\"\n                    segment.smooth = False\n                else:\n                    offCurves[-1].x = x\n                    offCurves[-1].y = y\n            elif value != (0, 0):\n                segment.type = \"curve\"\n                offCurves = segment.offCurve\n                offCurves[-1].x = x\n                offCurves[-1].y = y"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_bcpOut(self):\n        nextSegment = self._nextSegment\n        offCurves = nextSegment.offCurve\n        if offCurves:\n            bcp = offCurves[0]\n            x, y = relativeBCPOut(self.anchor, (bcp.x, bcp.y))\n        else:\n            x = y = 0\n        return (x, y)", "response": "Get the x y coordinates of the BCP out of the current segment."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the bcpOut value for the current contour.", "response": "def _set_bcpOut(self, value):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        x, y = absoluteBCPOut(self.anchor, value)\n        segment = self._segment\n        nextSegment = self._nextSegment\n        if nextSegment.type == \"move\" and value != (0, 0):\n            raise FontPartsError((\"Cannot set the bcpOut for the last \"\n                                  \"point in an open contour.\")\n                                 )\n        else:\n            offCurves = nextSegment.offCurve\n            if offCurves:\n                # if the off curves are located at the anchor coordinates\n                # we can switch to a \"line\" segment type\n                if value == (0, 0) and self.bcpIn == (0, 0):\n                    segment.type = \"line\"\n                    segment.smooth = False\n                else:\n                    offCurves[0].x = x\n                    offCurves[0].y = y\n            elif value != (0, 0):\n                nextSegment.type = \"curve\"\n                offCurves = nextSegment.offCurve\n                offCurves[0].x = x\n                offCurves[0].y = y"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_type(self):\n        point = self._point\n        typ = point.type\n        bType = None\n        if point.smooth:\n            if typ == \"curve\":\n                bType = \"curve\"\n            elif typ == \"line\":\n                nextSegment = self._nextSegment\n                if nextSegment is not None and nextSegment.type == \"curve\":\n                    bType = \"curve\"\n                else:\n                    bType = \"corner\"\n        elif typ in (\"move\", \"line\", \"curve\"):\n            bType = \"corner\"\n\n        if bType is None:\n            raise FontPartsError(\"A %s point can not be converted to a bPoint.\"\n                                         % typ)\n        return bType", "response": "Returns the type of the current object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_type(self, value):\n        point = self._point\n        # convert corner to curve\n        if value == \"curve\" and point.type == \"line\":\n            # This needs to insert off curves without\n            # generating unnecessary points in the\n            # following segment. The segment object\n            # implements this logic, so delegate the\n            # change to the corresponding segment.\n            segment = self._segment\n            segment.type = \"curve\"\n            segment.smooth = True\n        # convert curve to corner\n        elif value == \"corner\" and point.type == \"curve\":\n            point.smooth = False", "response": "Set the type of the object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget the index of the current object in the contour.", "response": "def _get_index(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        contour = self.contour\n        value = contour.bPoints.index(self)\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _transformBy(self, matrix, **kwargs):\n        anchor = self.anchor\n        bcpIn = absoluteBCPIn(anchor, self.bcpIn)\n        bcpOut = absoluteBCPOut(anchor, self.bcpOut)\n        points = [bcpIn, anchor, bcpOut]\n        t = transform.Transform(*matrix)\n        bcpIn, anchor, bcpOut = t.transformPoints(points)\n        x, y = anchor\n        self._point.x = x\n        self._point.y = y\n        self.bcpIn = relativeBCPIn(anchor, bcpIn)\n        self.bcpOut = relativeBCPOut(anchor, bcpOut)", "response": "This method transforms the internal bcpIn and bcpOut attributes of the current object by the given matrix."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the anchor bcpIn and bcpOut attributes to the equivalent values.", "response": "def round(self):\n        \"\"\"\n        Round coordinates.\n        \"\"\"\n        x, y = self.anchor\n        self.anchor = (normalizers.normalizeRounding(x),\n                       normalizers.normalizeRounding(y))\n        x, y = self.bcpIn\n        self.bcpIn = (normalizers.normalizeRounding(x),\n                      normalizers.normalizeRounding(y))\n        x, y = self.bcpOut\n        self.bcpOut = (normalizers.normalizeRounding(x),\n                       normalizers.normalizeRounding(y))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncreating a new font.", "response": "def NewFont(familyName=None, styleName=None, showInterface=True):\n    \"\"\"\n    Create a new font. **familyName** will be assigned\n    to ``font.info.familyName`` and **styleName**\n    will be assigned to ``font.info.styleName``. These\n    are optional and default to ``None``. If **showInterface**\n    is ``False``, the font should be created without\n    graphical interface. The default for **showInterface**\n    is ``True``.\n\n    ::\n\n        from fontParts.world import *\n\n        font = NewFont()\n        font = NewFont(familyName=\"My Family\", styleName=\"My Style\")\n        font = NewFont(showInterface=False)\n    \"\"\"\n    return dispatcher[\"NewFont\"](familyName=familyName, styleName=styleName,\n                                 showInterface=showInterface)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef AllFonts(sortOptions=None):\n    fontList = FontList(dispatcher[\"AllFonts\"]())\n    if sortOptions is not None:\n        fontList.sortBy(sortOptions)\n    return fontList", "response": "Return a list of all open fonts. Optionally provide a sortOption to sort the fonts."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns 0 if the font is not italic.", "response": "def _sortValue_isItalic(font):\n    \"\"\"\n    Returns 0 if the font is italic.\n    Returns 1 if the font is not italic.\n    \"\"\"\n    info = font.info\n    styleMapStyleName = info.styleMapStyleName\n    if styleMapStyleName is not None and \"italic\" in styleMapStyleName:\n        return 0\n    if info.italicAngle not in (None, 0):\n        return 0\n    return 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns 0 if the font is monospace. Returns 1 if the font is not monospace.", "response": "def _sortValue_isMonospace(font):\n    \"\"\"\n    Returns 0 if the font is monospace.\n    Returns 1 if the font is not monospace.\n    \"\"\"\n    if font.info.postscriptIsFixedPitch:\n        return 0\n    if not len(font):\n        return 1\n    testWidth = None\n    for glyph in font:\n        if testWidth is None:\n            testWidth = glyph.width\n        else:\n            if testWidth != glyph.width:\n                return 1\n    return 0"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef sortBy(self, sortOptions, reverse=False):\n        from types import FunctionType\n        from fontTools.misc.py23 import basestring\n        valueGetters = dict(\n            familyName=_sortValue_familyName,\n            styleName=_sortValue_styleName,\n            isRoman=_sortValue_isRoman,\n            isItalic=_sortValue_isItalic,\n            widthValue=_sortValue_widthValue,\n            weightValue=_sortValue_weightValue,\n            isProportional=_sortValue_isProportional,\n            isMonospace=_sortValue_isMonospace\n        )\n        if isinstance(sortOptions, basestring) or isinstance(sortOptions, FunctionType):\n            sortOptions = [sortOptions]\n        if not isinstance(sortOptions, (list, tuple)):\n            raise ValueError(\"sortOptions must a string, list or function.\")\n        if not sortOptions:\n            raise ValueError(\"At least one sort option must be defined.\")\n        if sortOptions == [\"magic\"]:\n            sortOptions = [\n                \"familyName\",\n                \"isProportional\",\n                \"widthValue\",\n                \"weightValue\",\n                \"styleName\",\n                \"isRoman\"\n            ]\n        sorter = []\n        for originalIndex, font in enumerate(self):\n            sortable = []\n            for valueName in sortOptions:\n                if isinstance(valueName, FunctionType):\n                    value = valueName(font)\n                elif valueName in valueGetters:\n                    value = valueGetters[valueName](font)\n                elif hasattr(font.info, valueName):\n                    value = getattr(font.info, valueName)\n                else:\n                    raise ValueError(\"Unknown sort option: %s\" % repr(valueGetter))\n                sortable.append(value)\n            sortable.append(originalIndex)\n            sortable.append(font)\n            sorter.append(tuple(sortable))\n        sorter.sort()\n        fonts = [i[-1] for i in sorter]\n        del self[:]\n        self.extend(fonts)\n        if reverse:\n            self.reverse()", "response": "Sort the font list by the given sort options."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef getFontsByFontInfoAttribute(self, *attributeValuePairs):\n        found = self\n        for attr, value in attributeValuePairs:\n            found = self._matchFontInfoAttributes(found, (attr, value))\n        return found", "response": "Returns a list of fonts that match the attribute value pairs in attributeValuePairs."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the guideline s index.", "response": "def _get_index(self):\n        \"\"\"\n        Get the guideline's index.\n        This must return an ``int``.\n\n        Subclasses may override this method.\n        \"\"\"\n        glyph = self.glyph\n        if glyph is not None:\n            parent = glyph\n        else:\n            parent = self.font\n        if parent is None:\n            return None\n        return parent.guidelines.index(self)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _transformBy(self, matrix, **kwargs):\n        t = transform.Transform(*matrix)\n        # coordinates\n        x, y = t.transformPoint((self.x, self.y))\n        self.x = x\n        self.y = y\n        # angle\n        angle = math.radians(-self.angle)\n        dx = math.cos(angle)\n        dy = math.sin(angle)\n        tdx, tdy = t.transformPoint((dx, dy))\n        ta = math.atan2(tdy - t[5], tdx - t[4])\n        self.angle = -math.degrees(ta)", "response": "This is the environment implementation of base - guideline. transformBy."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nchecks if guideline names are the same.", "response": "def _isCompatible(self, other, reporter):\n        \"\"\"\n        This is the environment implementation of\n        :meth:`BaseGuideline.isCompatible`.\n\n        Subclasses may override this method.\n        \"\"\"\n        guideline1 = self\n        guideline2 = other\n        # guideline names\n        if guideline1.name != guideline2.name:\n            reporter.nameDifference = True\n            reporter.warning = True"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize a font s file format version.", "response": "def normalizeFileFormatVersion(value):\n    \"\"\"\n    Normalizes a font's file format version.\n\n    * **value** must be a :ref:`type-int`.\n    * Returned value will be a ``int``.\n    \"\"\"\n    if not isinstance(value, int):\n        raise TypeError(\"File format versions must be instances of \"\n                        \":ref:`type-int`, not %s.\"\n                        % type(value).__name__)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize layer order. ** **value** must be a ``tuple`` or ``list``. * **value** items must normalize as layer names with :func:`normalizeLayerName`. * **value** must contain layers that exist in **font**. * **value** must not contain duplicate layers. * Returned ``tuple`` will be unencoded ``unicode`` strings for each layer name.", "response": "def normalizeLayerOrder(value, font):\n    \"\"\"\n    Normalizes layer order.\n\n    ** **value** must be a ``tuple`` or ``list``.\n    * **value** items must normalize as layer names with\n      :func:`normalizeLayerName`.\n    * **value** must contain layers that exist in **font**.\n    * **value** must not contain duplicate layers.\n    * Returned ``tuple`` will be unencoded ``unicode`` strings\n      for each layer name.\n    \"\"\"\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Layer order must be a list, not %s.\"\n                        % type(value).__name__)\n    for v in value:\n        normalizeLayerName(v)\n    fontLayers = [layer.name for layer in font.layers]\n    for name in value:\n        if name not in fontLayers:\n            raise ValueError(\"Layer must exist in font. %s does not exist \"\n                             \"in font.layers.\" % name)\n    duplicates = [v for v, count in Counter(value).items() if count > 1]\n    if len(duplicates) != 0:\n        raise ValueError(\"Duplicate layers are not allowed. Layer name(s) \"\n                         \"'%s' are duplicate(s).\" % \", \".join(duplicates))\n    return tuple([unicode(v) for v in value])"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalizeDefaultLayerName(value, font):\n    value = normalizeLayerName(value)\n    if value not in font.layerOrder:\n        raise ValueError(\"No layer with the name '%s' exists.\" % value)\n    return unicode(value)", "response": "Normalizes default layer name."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes glyph order. ** **value** must be a ``tuple`` or ``list``. * **value** items must normalize as glyph names with :func:`normalizeGlyphName`. * **value** must not repeat glyph names. * Returned value will be a ``tuple`` of unencoded ``unicode`` strings.", "response": "def normalizeGlyphOrder(value):\n    \"\"\"\n    Normalizes glyph order.\n\n    ** **value** must be a ``tuple`` or ``list``.\n    * **value** items must normalize as glyph names with\n      :func:`normalizeGlyphName`.\n    * **value** must not repeat glyph names.\n    * Returned value will be a ``tuple`` of unencoded ``unicode`` strings.\n    \"\"\"\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Glyph order must be a list, not %s.\"\n                        % type(value).__name__)\n    for v in value:\n        normalizeGlyphName(v)\n    duplicates = sorted(v for v, count in Counter(value).items() if count > 1)\n    if len(duplicates) != 0:\n        raise ValueError(\"Duplicate glyph names are not allowed. Glyph \"\n                         \"name(s) '%s' are duplicate.\" % \", \".join(duplicates))\n    return tuple([unicode(v) for v in value])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nnormalizes kerning key. * **value** must be a ``tuple`` or ``list``. * **value** must contain only two members. * **value** items must be :ref:`type-string`. * **value** items must be at least one character long. * Returned value will be a two member ``tuple`` of unencoded ``unicode`` strings.", "response": "def normalizeKerningKey(value):\n    \"\"\"\n    Normalizes kerning key.\n\n    * **value** must be a ``tuple`` or ``list``.\n    * **value** must contain only two members.\n    * **value** items must be :ref:`type-string`.\n    * **value** items must be at least one character long.\n    * Returned value will be a two member ``tuple`` of unencoded\n      ``unicode`` strings.\n    \"\"\"\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Kerning key must be a tuple instance, not %s.\"\n                        % type(value).__name__)\n    if len(value) != 2:\n        raise ValueError(\"Kerning key must be a tuple containing two items, \"\n                         \"not %d.\" % len(value))\n    for v in value:\n        if not isinstance(v, basestring):\n            raise TypeError(\"Kerning key items must be strings, not %s.\"\n                            % type(v).__name__)\n        if len(v) < 1:\n            raise ValueError(\"Kerning key items must be one character long\")\n    if value[0].startswith(\"public.\") and not value[0].startswith(\n            \"public.kern1.\"):\n        raise ValueError(\"Left Kerning key group must start with \"\n                         \"public.kern1.\")\n    if value[1].startswith(\"public.\") and not value[1].startswith(\n            \"public.kern2.\"):\n        raise ValueError(\"Right Kerning key group must start with \"\n                         \"public.kern2.\")\n    return tuple([unicode(v) for v in value])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalizeKerningValue(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Kerning value must be a int or a float, not %s.\"\n                        % type(value).__name__)\n    return value", "response": "Normalizes kerning value.\n\n    * **value** must be an :ref:`type-int-float`.\n    * Returned value is the same type as input value."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalizeGroupValue(value):\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Group value must be a list, not %s.\"\n                        % type(value).__name__)\n    value = [normalizeGlyphName(v) for v in value]\n    return tuple([unicode(v) for v in value])", "response": "Normalizes group value.\n\n    * **value** must be a ``list``.\n    * **value** items must normalize as glyph names with\n      :func:`normalizeGlyphName`.\n    * Returned value will be a ``tuple`` of unencoded ``unicode`` strings."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalizeFeatureText(value):\n    if not isinstance(value, basestring):\n        raise TypeError(\"Feature text must be a string, not %s.\"\n                        % type(value).__name__)\n    return unicode(value)", "response": "Normalizes feature text.\n\n    * **value** must be a :ref:`type-string`.\n    * Returned value will be an unencoded ``unicode`` string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes lib value. * **value** must not be ``None``. * Returned value is the same type as the input value.", "response": "def normalizeLibValue(value):\n    \"\"\"\n    Normalizes lib value.\n\n    * **value** must not be ``None``.\n    * Returned value is the same type as the input value.\n    \"\"\"\n    if value is None:\n        raise ValueError(\"Lib value must not be None.\")\n    if isinstance(value, (list, tuple)):\n        for v in value:\n            normalizeLibValue(v)\n    elif isinstance(value, dict):\n        for k, v in value.items():\n            normalizeLibKey(k)\n            normalizeLibValue(v)\n    elif isinstance(value, basestring):\n        value = unicode(value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnormalizing glyph unicodes. * **value** must be a ``list``. * **value** items must normalize as glyph unicodes with :func:`normalizeGlyphUnicode`. * **value** must not repeat unicode values. * Returned value will be a ``tuple`` of ints.", "response": "def normalizeGlyphUnicodes(value):\n    \"\"\"\n    Normalizes glyph unicodes.\n\n    * **value** must be a ``list``.\n    * **value** items must normalize as glyph unicodes with\n      :func:`normalizeGlyphUnicode`.\n    * **value** must not repeat unicode values.\n    * Returned value will be a ``tuple`` of ints.\n    \"\"\"\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Glyph unicodes must be a list, not %s.\"\n                        % type(value).__name__)\n    values = [normalizeGlyphUnicode(v) for v in value]\n    duplicates = [v for v, count in Counter(value).items() if count > 1]\n    if len(duplicates) != 0:\n        raise ValueError(\"Duplicate unicode values are not allowed.\")\n    return tuple(values)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalizeGlyphUnicode(value):\n    if not isinstance(value, (int, basestring)) or isinstance(value, bool):\n        raise TypeError(\"Glyph unicode must be a int or hex string, not %s.\"\n                        % type(value).__name__)\n    if isinstance(value, basestring):\n        try:\n            value = int(value, 16)\n        except ValueError:\n            raise ValueError(\"Glyph unicode hex must be a valid hex string.\")\n    if value < 0 or value > 1114111:\n        raise ValueError(\"Glyph unicode must be in the Unicode range.\")\n    return value", "response": "Normalizes glyph unicode.\n\n    * **value** must be an int or hex (represented as a string).\n    * **value** must be in a unicode range.\n    * Returned value will be an ``int``."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef normalizeGlyphWidth(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Glyph width must be an :ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    return value", "response": "Normalizes glyph width.\n\n    * **value** must be a :ref:`type-int-float`.\n    * Returned value is the same type as the input value."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalizeGlyphLeftMargin(value):\n    if not isinstance(value, (int, float)) and value is not None:\n        raise TypeError(\"Glyph left margin must be an :ref:`type-int-float`, \"\n                        \"not %s.\" % type(value).__name__)\n    return value", "response": "Normalizes glyph left margin."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalizeGlyphRightMargin(value):\n    if not isinstance(value, (int, float)) and value is not None:\n        raise TypeError(\"Glyph right margin must be an :ref:`type-int-float`, \"\n                        \"not %s.\" % type(value).__name__)\n    return value", "response": "Normalizes glyph right margin."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalizeGlyphHeight(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Glyph height must be an :ref:`type-int-float`, not \"\n                        \"%s.\" % type(value).__name__)\n    return value", "response": "Normalizes glyph height.\n\n    * **value** must be a :ref:`type-int-float`.\n    * Returned value is the same type as the input value."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nnormalizes glyph bottom margin.", "response": "def normalizeGlyphBottomMargin(value):\n    \"\"\"\n    Normalizes glyph bottom margin.\n\n    * **value** must be a :ref:`type-int-float` or `None`.\n    * Returned value is the same type as the input value.\n    \"\"\"\n    if not isinstance(value, (int, float)) and value is not None:\n        raise TypeError(\"Glyph bottom margin must be an \"\n                        \":ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef normalizeGlyphTopMargin(value):\n    if not isinstance(value, (int, float)) and value is not None:\n        raise TypeError(\"Glyph top margin must be an :ref:`type-int-float`, \"\n                        \"not %s.\" % type(value).__name__)\n    return value", "response": "Normalizes glyph top margin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalizeGlyphFormatVersion(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Glyph Format Version must be an \"\n                        \":ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    value = int(value)\n    if value not in (1, 2):\n        raise ValueError(\"Glyph Format Version must be either 1 or 2, not %s.\"\n                         % value)\n    return value", "response": "Normalizes glyph format version for saving to XML string."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalizePointType(value):\n    allowedTypes = ['move', 'line', 'offcurve', 'curve', 'qcurve']\n    if not isinstance(value, basestring):\n        raise TypeError(\"Point type must be a string, not %s.\"\n                        % type(value).__name__)\n    if value not in allowedTypes:\n        raise ValueError(\"Point type must be '%s'; not %r.\"\n                         % (\"', '\".join(allowedTypes), value))\n    return unicode(value)", "response": "Normalizes point type.\n\n    * **value** must be an string.\n    * **value** must be one of the following:\n\n      +----------+\n      | move     |\n      +----------+\n      | line     |\n      +----------+\n      | offcurve |\n      +----------+\n      | curve    |\n      +----------+\n      | qcurve   |\n      +----------+\n\n    * Returned value will be an unencoded ``unicode`` string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalizePointName(value):\n    if not isinstance(value, basestring):\n        raise TypeError(\"Point names must be strings, not %s.\"\n                        % type(value).__name__)\n    if len(value) < 1:\n        raise ValueError(\"Point names must be at least one character long.\")\n    return unicode(value)", "response": "Normalizes point name.\n\n    * **value** must be a :ref:`type-string`.\n    * **value** must be at least one character long.\n    * Returned value will be an unencoded ``unicode`` string."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nnormalizes bPoint type. * **value** must be an string. * **value** must be one of the following: +--------+ | corner | +--------+ | curve | +--------+ * Returned value will be an unencoded ``unicode`` string.", "response": "def normalizeBPointType(value):\n    \"\"\"\n    Normalizes bPoint type.\n\n    * **value** must be an string.\n    * **value** must be one of the following:\n\n      +--------+\n      | corner |\n      +--------+\n      | curve  |\n      +--------+\n\n    * Returned value will be an unencoded ``unicode`` string.\n    \"\"\"\n    allowedTypes = ['corner', 'curve']\n    if not isinstance(value, basestring):\n        raise TypeError(\"bPoint type must be a string, not %s.\"\n                        % type(value).__name__)\n    if value not in allowedTypes:\n        raise ValueError(\"bPoint type must be 'corner' or 'curve', not %r.\"\n                         % value)\n    return unicode(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalizeInternalObjectType(value, cls, name):\n    if not isinstance(value, cls):\n        raise TypeError(\"%s must be a %s instance, not %s.\"\n                        % (name, name, type(value).__name__))\n    return value", "response": "Normalizes an internal object type."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nnormalize a boolean value.", "response": "def normalizeBoolean(value):\n    \"\"\"\n    Normalizes a boolean.\n\n    * **value** must be an ``int`` with value of 0 or 1, or a ``bool``.\n    * Returned value will be a boolean.\n    \"\"\"\n    if isinstance(value, int) and value in (0, 1):\n        value = bool(value)\n    if not isinstance(value, bool):\n        raise ValueError(\"Boolean values must be True or False, not '%s'.\"\n                         % value)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nnormalizes index. * **value** must be an ``int`` or ``None``. * Returned value is the same type as the input value.", "response": "def normalizeIndex(value):\n    \"\"\"\n    Normalizes index.\n\n    * **value** must be an ``int`` or ``None``.\n    * Returned value is the same type as the input value.\n    \"\"\"\n    if value is not None:\n        if not isinstance(value, int):\n            raise TypeError(\"Indexes must be None or integers, not %s.\"\n                            % type(value).__name__)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef normalizeIdentifier(value):\n    if value is None:\n        return value\n    if not isinstance(value, basestring):\n        raise TypeError(\"Identifiers must be strings, not %s.\"\n                        % type(value).__name__)\n    if len(value) == 0:\n        raise ValueError(\"The identifier string is empty.\")\n    if len(value) > 100:\n        raise ValueError(\"The identifier string has a length (%d) greater \"\n                         \"than the maximum allowed (100).\" % len(value))\n    for c in value:\n        v = ord(c)\n        if v < 0x20 or v > 0x7E:\n            raise ValueError(\"The identifier string ('%s') contains a \"\n                             \"character out size of the range 0x20 - 0x7E.\"\n                             % value)\n    return unicode(value)", "response": "Normalizes the identifier string."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nnormalize x coordinate. * **value** must be an :ref:`type-int-float`. * Returned value is the same type as the input value.", "response": "def normalizeX(value):\n    \"\"\"\n    Normalizes x coordinate.\n\n    * **value** must be an :ref:`type-int-float`.\n    * Returned value is the same type as the input value.\n    \"\"\"\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"X coordinates must be instances of \"\n                        \":ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nnormalizing the y coordinate.", "response": "def normalizeY(value):\n    \"\"\"\n    Normalizes y coordinate.\n\n    * **value** must be an :ref:`type-int-float`.\n    * Returned value is the same type as the input value.\n    \"\"\"\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Y coordinates must be instances of \"\n                        \":ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    return value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nnormalizing a coordinate tuple.", "response": "def normalizeCoordinateTuple(value):\n    \"\"\"\n    Normalizes coordinate tuple.\n\n    * **value** must be a ``tuple`` or ``list``.\n    * **value** must have exactly two items.\n    * **value** items must be an :ref:`type-int-float`.\n    * Returned value is a ``tuple`` of two values of the same type as\n      the input values.\n    \"\"\"\n    if not isinstance(value, (tuple, list)):\n        raise TypeError(\"Coordinates must be tuple instances, not %s.\"\n                        % type(value).__name__)\n    if len(value) != 2:\n        raise ValueError(\"Coordinates must be tuples containing two items, \"\n                         \"not %d.\" % len(value))\n    x, y = value\n    x = normalizeX(x)\n    y = normalizeY(y)\n    return (x, y)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef normalizeArea(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Area must be an instance of :ref:`type-int-float`, \"\n                        \"not %s.\" % type(value).__name__)\n    if value < 0:\n        raise ValueError(\"Area must be a positive :ref:`type-int-float`, \"\n                         \"not %s.\" % repr(value))\n    return float(value)", "response": "Normalizes area.\n\n    * **value** must be a positive :ref:`type-int-float`."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef normalizeRotationAngle(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Angle must be instances of \"\n                        \":ref:`type-int-float`, not %s.\"\n                        % type(value).__name__)\n    if abs(value) > 360:\n        raise ValueError(\"Angle must be between -360 and 360.\")\n    if value < 0:\n        value = value + 360\n    return float(value)", "response": "Normalizes an angle.\n\n    * Value must be a :ref:`type-int-float`.\n    * Value must be between -360 and 360.\n    * If the value is negative, it is normalized by adding it to 360\n    * Returned value is a ``float`` between 0 and 360."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize :ref:`type-color`. * **value** must be an ``tuple`` or ``list``. * **value** must have exactly four items. * **value** color components must be between 0 and 1. * Returned value is a ``tuple`` containing four ``float`` values.", "response": "def normalizeColor(value):\n    \"\"\"\n    Normalizes :ref:`type-color`.\n\n    * **value** must be an ``tuple`` or ``list``.\n    * **value** must have exactly four items.\n    * **value** color components must be between 0 and 1.\n    * Returned value is a ``tuple`` containing four ``float`` values.\n    \"\"\"\n    from fontParts.base.color import Color\n    if not isinstance(value, (tuple, list, Color)):\n        raise TypeError(\"Colors must be tuple instances, not %s.\"\n                        % type(value).__name__)\n    if not len(value) == 4:\n        raise ValueError(\"Colors must contain four values, not %d.\"\n                         % len(value))\n    for component, v in zip(\"rgba\", value):\n        if not isinstance(v, (int, float)):\n            raise TypeError(\"The value for the %s component (%s) is not \"\n                            \"an int or float.\" % (component, v))\n        if v < 0 or v > 1:\n            raise ValueError(\"The value for the %s component (%s) is not \"\n                             \"between 0 and 1.\" % (component, v))\n    return tuple([float(v) for v in value])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef normalizeGlyphNote(value):\n    if not isinstance(value, basestring):\n        raise TypeError(\"Note must be a string, not %s.\"\n                        % type(value).__name__)\n    return unicode(value)", "response": "Normalizes Glyph Note.\n\n    * **value** must be a :ref:`type-string`.\n    * Returned value is an unencoded ``unicode`` string"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nnormalize file path. * **value** must be a :ref:`type-string`. * Returned value is an unencoded ``unicode`` string", "response": "def normalizeFilePath(value):\n    \"\"\"\n    Normalizes file path.\n\n    * **value** must be a :ref:`type-string`.\n    * Returned value is an unencoded ``unicode`` string\n    \"\"\"\n    if not isinstance(value, basestring):\n        raise TypeError(\"File paths must be strings, not %s.\"\n                        % type(value).__name__)\n    return unicode(value)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef normalizeInterpolationFactor(value):\n    if not isinstance(value, (int, float, list, tuple)):\n        raise TypeError(\"Interpolation factor must be an int, float, or tuple \"\n                        \"instances, not %s.\" % type(value).__name__)\n    if isinstance(value, (int, float)):\n        value = (float(value), float(value))\n    else:\n        if not len(value) == 2:\n            raise ValueError(\"Interpolation factor tuple must contain two \"\n                             \"values, not %d.\" % len(value))\n        for v in value:\n            if not isinstance(v, (int, float)):\n                raise TypeError(\"Interpolation factor tuple values must be an \"\n                                \":ref:`type-int-float`, not %s.\"\n                                % type(value).__name__)\n        value = tuple([float(v) for v in value])\n    return value", "response": "Normalizes interpolation factor.\n\n    * **value** must be an :ref:`type-int-float`, ``tuple`` or ``list``.\n    * If **value** is a ``tuple`` or ``list``, it must have exactly two items.\n      These items must be instances of :ref:`type-int-float`.\n    * Returned value is a ``tuple`` of two ``float``."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef normalizeRounding(value):\n    if not isinstance(value, (int, float)):\n        raise TypeError(\"Value to round must be an int or float, not %s.\"\n                        % type(value).__name__)\n    return round3(value)", "response": "Normalizes rounding of halves."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef AskString(message, value='', title='FontParts'):\n    return dispatcher[\"AskString\"](message=message, value=value, title=title)", "response": "A dialog that asks for a string."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef AskYesNoCancel(message, title='FontParts', default=0, informativeText=\"\"):\n    return dispatcher[\"AskYesNoCancel\"](message=message, title=title,\n                                        default=default, informativeText=informativeText)", "response": "A dialog that asks for a yes no or cancel dialog."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef FindGlyph(aFont, message=\"Search for a glyph:\", title='FontParts'):\n    return dispatcher[\"FindGlyph\"](aFont=aFont, message=message, title=title)", "response": "A dialog to search a glyph for a provided font."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef GetFile(message=None, title=None, directory=None, fileName=None,\n            allowsMultipleSelection=False, fileTypes=None):\n    \"\"\"\n    An get file dialog.\n    Optionally a `message`, `title`, `directory`, `fileName` and\n    `allowsMultipleSelection` can be provided.\n\n    ::\n\n        from fontParts.ui import GetFile\n        print(GetFile())\n\n    \"\"\"\n    return dispatcher[\"GetFile\"](message=message, title=title, directory=directory,\n                                 fileName=fileName,\n                                 allowsMultipleSelection=allowsMultipleSelection,\n                                 fileTypes=fileTypes)", "response": "A get file dialog."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef SearchList(items, message=\"Select an item:\", title='FontParts'):\n    return dispatcher[\"SearchList\"](items=items, message=message, title=title)", "response": "A dialgo to search a given list."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nselects a font from all open fonts.", "response": "def SelectFont(message=\"Select a font:\", title='FontParts', allFonts=None):\n    \"\"\"\n    Select a font from all open fonts.\n    Optionally a `message`, `title` and `allFonts` can be provided.\n    If `allFonts` is `None` it will list all open fonts.\n\n    ::\n\n        from fontParts.ui import SelectFont\n        font = SelectFont()\n        print(font)\n\n    \"\"\"\n    return dispatcher[\"SelectFont\"](message=message, title=title, allFonts=allFonts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nselect a glyph for a given font.", "response": "def SelectGlyph(aFont, message=\"Select a glyph:\", title='FontParts'):\n    \"\"\"\n    Select a glyph for a given font.\n    Optionally a `message` and `title` can be provided.\n\n    ::\n\n        from fontParts.ui import SelectGlyph\n        font = CurrentFont()\n        glyph = SelectGlyph(font)\n        print(glyph)\n\n    \"\"\"\n    return dispatcher[\"SelectGlyph\"](aFont=aFont, message=message, title=title)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef ProgressBar(title=\"RoboFab...\", ticks=None, label=\"\"):\n    return dispatcher[\"ProgressBar\"](title=title, ticks=ticks, label=label)", "response": "A simple progress bar dialog."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef findGlyph(self, glyphName):\n        glyphName = normalizers.normalizeGlyphName(glyphName)\n        groupNames = self._findGlyph(glyphName)\n        groupNames = [self.keyNormalizer.__func__(\n            groupName) for groupName in groupNames]\n        return groupNames", "response": "Return a list of group names associated with glyphName."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _findGlyph(self, glyphName):\n        found = []\n        for key, groupList in self.items():\n            if glyphName in groupList:\n                found.append(key)\n        return found", "response": "This method returns a list of all the keys that contain glyphName."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_side1KerningGroups(self):\n        found = {}\n        for name, contents in self.items():\n            if name.startswith(\"public.kern1.\"):\n                found[name] = contents\n        return found", "response": "Returns a dict of all Kerning Groups."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a dict of all the KERNING groups that are part of the public. kern2.", "response": "def _get_side2KerningGroups(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        found = {}\n        for name, contents in self.items():\n            if name.startswith(\"public.kern2.\"):\n                found[name] = contents\n        return found"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get(self, groupName, default=None):\n        return super(BaseGroups, self).get(groupName, default)", "response": "Returns the contents of the named group."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nremoving the given groupName from the Groups and returns the list of group members. If no group is found default is returned.", "response": "def pop(self, groupName, default=None):\n        \"\"\"\n        Removes the **groupName** from the Groups and returns the list of\n        group members. If no group is found, **default** is returned.\n        **groupName** is a :ref:`type-string`. This must return either\n        **default** or a :ref:`type-immutable-list` of glyph names as\n        :ref:`type-string`.\n\n            >>> font.groups.pop(\"myGroup\")\n            (\"A\", \"B\", \"C\")\n        \"\"\"\n        return super(BaseGroups, self).pop(groupName, default)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_index(self):\n        contour = self.contour\n        if contour is None:\n            return None\n        return contour.points.index(self)", "response": "Get the index of the point in the contour."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef copy(self):\n        copyClass = self.copyClass\n        if copyClass is None:\n            copyClass = self.__class__\n        copied = copyClass()\n        copied.copyData(self)\n        return copied", "response": "Returns a copy of the current object."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncopy the data from another object to this one.", "response": "def copyData(self, source):\n        \"\"\"\n        Subclasses may override this method.\n        If so, they should call the super.\n        \"\"\"\n        for attr in self.copyAttributes:\n            selfValue = getattr(self, attr)\n            sourceValue = getattr(source, attr)\n            if isinstance(selfValue, BaseObject):\n                selfValue.copyData(sourceValue)\n            else:\n                setattr(self, attr, sourceValue)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove and return the object with the specified key.", "response": "def _pop(self, key, default=None):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        value = default\n        if key in self:\n            value = self[key]\n            del self[key]\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\niterates over the key - value pairs in the cache.", "response": "def _iter(self):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        keys = self.keys()\n        while keys:\n            key = keys[0]\n            yield key\n            keys = keys[1:]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _update(self, other):\n        for key, value in other.items():\n            self[key] = value", "response": "Update the internal dictionary with the contents of another object."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef transformBy(self, matrix, origin=None):\n        matrix = normalizers.normalizeTransformationMatrix(matrix)\n        if origin is None:\n            origin = (0, 0)\n        origin = normalizers.normalizeCoordinateTuple(origin)\n        if origin is not None:\n            t = transform.Transform()\n            oX, oY = origin\n            t = t.translate(oX, oY)\n            t = t.transform(matrix)\n            t = t.translate(-oX, -oY)\n            matrix = tuple(t)\n        self._transformBy(matrix)", "response": "Transform the object by a matrix."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef moveBy(self, value):\n        value = normalizers.normalizeTransformationOffset(value)\n        self._moveBy(value)", "response": "Move the object by the given value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _moveBy(self, value, **kwargs):\n        x, y = value\n        t = transform.Offset(x, y)\n        self.transformBy(tuple(t), **kwargs)", "response": "This is the environment implementation of BaseObject. moveBy. It will transform the object by the given value."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef scaleBy(self, value, origin=None):\n        value = normalizers.normalizeTransformationScale(value)\n        if origin is None:\n            origin = (0, 0)\n        origin = normalizers.normalizeCoordinateTuple(origin)\n        self._scaleBy(value, origin=origin)", "response": "Scale the object by a value."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef rotateBy(self, value, origin=None):\n        value = normalizers.normalizeRotationAngle(value)\n        if origin is None:\n            origin = (0, 0)\n        origin = normalizers.normalizeCoordinateTuple(origin)\n        self._rotateBy(value, origin=origin)", "response": "Rotate the object by a given angle."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nskews the log entry by a value.", "response": "def skewBy(self, value, origin=None):\n        \"\"\"\n        Skew the object.\n\n            >>> obj.skewBy(11)\n            >>> obj.skewBy((25, 10), origin=(500, 500))\n\n        **value** must be rone of the following:\n\n        * single :ref:`type-int-float` indicating the\n          value to skew the x direction by.\n        * iterable cointaining type :ref:`type-int-float`\n          defining the values to skew the x and y directions by.\n\n        **origin** defines the point at with the skew should\n        originate. It must be a :ref:`type-coordinate` or\n        ``None``. The default is ``(0, 0)``.\n        \"\"\"\n        value = normalizers.normalizeTransformationSkewAngle(value)\n        if origin is None:\n            origin = (0, 0)\n        origin = normalizers.normalizeCoordinateTuple(origin)\n        self._skewBy(value, origin=origin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _skewBy(self, value, origin=None, **kwargs):\n        x, y = value\n        x = math.radians(x)\n        y = math.radians(y)\n        t = transform.Identity.skew(x=x, y=y)\n        self.transformBy(tuple(t), origin=origin, **kwargs)", "response": "Skews the object by the given value."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nevaluating interpolation compatibility between self and other.", "response": "def isCompatible(self, other, cls):\n        \"\"\"\n        Evaluate interpolation compatibility with other.\n        \"\"\"\n        if not isinstance(other, cls):\n            raise TypeError(\n                \"\"\"Compatibility between an instance of %r and an \\\n                instance of %r can not be checked.\"\"\"\n                % (cls.__name__, other.__class__.__name__))\n        reporter = self.compatibilityReporterClass(self, other)\n        self._isCompatible(other, reporter)\n        return not reporter.fatal, reporter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the current position of the log entry.", "response": "def _set_position(self, value):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        pX, pY = self.position\n        x, y = value\n        dX = x - pX\n        dY = y - pY\n        self.moveBy((dX, dY))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_version():\n    with open('Lib/fontParts/__init__.py', 'r', encoding='utf-8') as f:\n        for line in f:\n            if line.startswith(u'__version__'):\n                return ast.parse(line).body[0].value.s\n        raise RuntimeError(\"No __version__ string found!\")", "response": "Fetches the version number from the package s __version__ file"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning bump2version. main with the specified arguments.", "response": "def bumpversion(self, part, **kwargs):\n        \"\"\" Run bump2version.main() with the specified arguments.\n        \"\"\"\n        import bumpversion\n\n        args = ['--verbose'] if self.verbose > 1 else []\n        for k, v in kwargs.items():\n            arg = \"--{}\".format(k.replace(\"_\", \"-\"))\n            if isinstance(v, bool):\n                if v is False:\n                    continue\n                args.append(arg)\n            else:\n                args.extend([arg, str(v)])\n        args.append(part)\n\n        log.debug(\n            \"$ bumpversion %s\" % \" \".join(a.replace(\" \", \"\\\\ \") for a in args))\n\n        bumpversion.main(args)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef edit_release_notes():\n        from tempfile import mkstemp\n        import os\n        import shlex\n        import subprocess\n\n        text_editor = shlex.split(os.environ.get('EDITOR', 'nano'))\n\n        fd, tmp = mkstemp(prefix='bumpversion-')\n        try:\n            os.close(fd)\n            with open(tmp, 'w') as f:\n                f.write(u\"\\n\\n# Write release notes.\\n\"\n                        u\"# Lines starting with '#' will be ignored.\")\n            subprocess.check_call(text_editor + [tmp])\n            with open(tmp, 'r') as f:\n                changes = \"\".join(\n                    l for l in f.readlines() if not l.startswith('#'))\n        finally:\n            os.remove(tmp)\n        return changes", "response": "Use the default text editor to edit release notes."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the value of an attribute from the object.", "response": "def _getAttr(self, attr):\n        \"\"\"\n        Subclasses may override this method.\n\n        If a subclass does not override this method,\n        it must implement '_get_attributeName' methods\n        for all Info methods.\n        \"\"\"\n        meth = \"_get_%s\" % attr\n        if not hasattr(self, meth):\n            raise AttributeError(\"No getter for attribute '%s'.\" % attr)\n        meth = getattr(self, meth)\n        value = meth()\n        return value"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _setAttr(self, attr, value):\n        meth = \"_set_%s\" % attr\n        if not hasattr(self, meth):\n            raise AttributeError(\"No setter for attribute '%s'.\" % attr)\n        meth = getattr(self, meth)\n        meth(value)", "response": "Set the value of an attribute of the object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef fromMathInfo(self, mathInfo, guidelines=True):\n        return self._fromMathInfo(mathInfo, guidelines=guidelines)", "response": "Returns a new font object from a MathInfo object."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a MathInfo object for this object.", "response": "def _toMathInfo(self, guidelines=True):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        import fontMath\n        # A little trickery is needed here because MathInfo\n        # handles font level guidelines. Those are not in this\n        # object so we temporarily fake them just enough for\n        # MathInfo and then move them back to the proper place.\n        self.guidelines = []\n        if guidelines:\n            for guideline in self.font.guidelines:\n                d = dict(\n                    x=guideline.x,\n                    y=guideline.y,\n                    angle=guideline.angle,\n                    name=guideline.name,\n                    identifier=guideline.identifier,\n                    color=guideline.color\n                )\n                self.guidelines.append(d)\n        info = fontMath.MathInfo(self)\n        del self.guidelines\n        return info"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _fromMathInfo(self, mathInfo, guidelines=True):\n        self.guidelines = []\n        mathInfo.extractInfo(self)\n        font = self.font\n        if guidelines:\n            for guideline in self.guidelines:\n                font.appendGuideline(\n                    position=(guideline[\"x\"], guideline[\"y\"]),\n                    angle=guideline[\"angle\"],\n                    name=guideline[\"name\"],\n                    color=guideline[\"color\"]\n                    # XXX identifier is lost\n                )\n        del self.guidelines", "response": "This method is used to set the attributes of the current object based on the mathInfo."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ninterpolate all pairs between minInfo and maxInfo.", "response": "def interpolate(self, factor, minInfo, maxInfo, round=True, suppressError=True):\n        \"\"\"\n        Interpolate all pairs between minInfo and maxInfo.\n        The interpolation occurs on a 0 to 1.0 range where minInfo\n        is located at 0 and maxInfo is located at 1.0.\n\n        factor is the interpolation value. It may be less than 0\n        and greater than 1.0. It may be a number (integer, float)\n        or a tuple of two numbers. If it is a tuple, the first\n        number indicates the x factor and the second number\n        indicates the y factor.\n\n        round indicates if the result should be rounded to integers.\n\n        suppressError indicates if incompatible data should be ignored\n        or if an error should be raised when such incompatibilities are found.\n        \"\"\"\n        factor = normalizers.normalizeInterpolationFactor(factor)\n        if not isinstance(minInfo, BaseInfo):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\") %\n                            (self.__class__.__name__, minInfo.__class__.__name__))\n        if not isinstance(maxInfo, BaseInfo):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\") %\n                            (self.__class__.__name__, maxInfo.__class__.__name__))\n        round = normalizers.normalizeBoolean(round)\n        suppressError = normalizers.normalizeBoolean(suppressError)\n        self._interpolate(factor, minInfo, maxInfo,\n                          round=round, suppressError=suppressError)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _interpolate(self, factor, minInfo, maxInfo, round=True, suppressError=True):\n        minInfo = minInfo._toMathInfo()\n        maxInfo = maxInfo._toMathInfo()\n        result = interpolate(minInfo, maxInfo, factor)\n        if result is None and not suppressError:\n            raise FontPartsError((\"Info from font '%s' and font '%s' could not be \"\n                                  \"interpolated.\")\n                                 % (minInfo.font.name, maxInfo.font.name))\n        if round:\n            result = result.round()\n        self._fromMathInfo(result)", "response": "Interpolate minInfo and maxInfo into a new object."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncompile a sass file into a single css file.", "response": "def compileSass(sassPath):\n    '''\n    Compile a sass file (and dependencies) into a single css file.\n\n    '''\n    cssPath = os.path.splitext(sassPath)[0] + \".css\"\n    # subprocess.call([\"sass\", sassPath, cssPath])\n    print(\"Compiling Sass\")\n\n    process = subprocess.Popen([\"sass\", sassPath, cssPath])\n    process.wait()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ntaking CSS file and automatically add browser prefixes with postCSS autoprefixer", "response": "def autoprefixCSS(sassPath):\n    '''\n    Take CSS file and automatically add browser prefixes with postCSS autoprefixer\n\n    '''\n    print(\"Autoprefixing CSS\")\n    cssPath = os.path.splitext(sassPath)[0] + \".css\"\n    command = \"postcss --use autoprefixer --autoprefixer.browsers '> 5%' -o\" + cssPath + \" \" + cssPath\n    subprocess.call(command, shell=True)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef copyData(self, source):\n        for layerName in source.layerOrder:\n            if layerName in self.layerOrder:\n                layer = self.getLayer(layerName)\n            else:\n                layer = self.newLayer(layerName)\n            layer.copyData(source.getLayer(layerName))\n        for guideline in self.guidelines:\n            self.appendGuideline(guideline)\n        super(BaseFont, self).copyData(source)", "response": "Copy data from source into this font."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsave the font to a file.", "response": "def save(self, path=None, showProgress=False, formatVersion=None):\n        \"\"\"\n        Save the font to **path**.\n\n            >>> font.save()\n            >>> font.save(\"/path/to/my/font-2.ufo\")\n\n        If **path** is None, use the font's original location.\n        The file type must be inferred from the file extension\n        of the given path. If no file extension is given, the\n        environment may fall back to the format of its choice.\n        **showProgress** indicates if a progress indicator should\n        be displayed during the operation. Environments may or may\n        not implement this behavior. **formatVersion** indicates\n        the format version that should be used for writing the given\n        file type. For example, if 2 is given for formatVersion\n        and the file type being written if UFO, the file is to\n        be written in UFO 2 format. This value is not limited\n        to UFO format versions. If no format version is given,\n        the original format version of the file should be preserved.\n        If there is no original format version it is implied that\n        the format version is the latest version for the file\n        type as supported by the environment.\n\n        .. note::\n\n           Environments may define their own rules governing when\n           a file should be saved into its original location and\n           when it should not. For example, a font opened from a\n           compiled OpenType font may not be written back into\n           the original OpenType font.\n        \"\"\"\n        if path is None and self.path is None:\n            raise IOError((\"The font cannot be saved because no file \"\n                           \"location has been given.\"))\n        if path is not None:\n            path = normalizers.normalizeFilePath(path)\n        showProgress = bool(showProgress)\n        if formatVersion is not None:\n            formatVersion = normalizers.normalizeFileFormatVersion(\n                formatVersion)\n        self._save(path=path, showProgress=showProgress,\n                   formatVersion=formatVersion)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef generateFormatToExtension(format, fallbackFormat):\n        formatToExtension = dict(\n            # mactype1=None,\n            macttf=\".ttf\",\n            macttdfont=\".dfont\",\n            otfcff=\".otf\",\n            otfttf=\".ttf\",\n            # pctype1=None,\n            # pcmm=None,\n            # pctype1ascii=None,\n            # pcmmascii=None,\n            ufo1=\".ufo\",\n            ufo2=\".ufo\",\n            ufo3=\".ufo\",\n            unixascii=\".pfa\",\n        )\n        return formatToExtension.get(format, fallbackFormat)", "response": "Generate a format to extension."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ngenerate the font to another format.", "response": "def generate(self, format, path=None, **environmentOptions):\n        \"\"\"\n        Generate the font to another format.\n\n            >>> font.generate(\"otfcff\")\n            >>> font.generate(\"otfcff\", \"/path/to/my/font.otf\")\n\n        **format** defines the file format to output.\n        Standard format identifiers can be found in :attr:`BaseFont.generateFormatToExtension`:\n\n\n        Environments are not required to support all of these\n        and environments may define their own format types.\n        **path** defines the location where the new file should\n        be created. If a file already exists at that location,\n        it will be overwritten by the new file. If **path** defines\n        a directory, the file will be output as the current\n        file name, with the appropriate suffix for the format,\n        into the given directory. If no **path** is given, the\n        file will be output into the same directory as the source\n        font with the file named with the current file name,\n        with the appropriate suffix for the format.\n\n        Environments may allow unique keyword arguments in this\n        method. For example, if a tool allows decomposing components\n        during a generate routine it may allow this:\n\n            >>> font.generate(\"otfcff\", \"/p/f.otf\", decompose=True)\n        \"\"\"\n        import warnings\n        if format is None:\n            raise ValueError(\"The format must be defined when generating.\")\n        elif not isinstance(format, basestring):\n            raise TypeError(\"The format must be defined as a string.\")\n        env = {}\n        for key, value in environmentOptions.items():\n            valid = self._isValidGenerateEnvironmentOption(key)\n            if not valid:\n                warnings.warn(\"The %s argument is not supported \"\n                              \"in this environment.\" % key, UserWarning)\n            env[key] = value\n        environmentOptions = env\n        ext = self.generateFormatToExtension(format, \".\" + format)\n        if path is None and self.path is None:\n            raise IOError((\"The file cannot be generated because an \"\n                           \"output path was not defined.\"))\n        elif path is None:\n            path = os.path.splitext(self.path)[0]\n            path += ext\n        elif os.path.isdir(path):\n            if self.path is None:\n                raise IOError((\"The file cannot be generated because \"\n                               \"the file does not have a path.\"))\n            fileName = os.path.basename(self.path)\n            fileName += ext\n            path = os.path.join(path, fileName)\n        path = normalizers.normalizeFilePath(path)\n        return self._generate(\n            format=format,\n            path=path,\n            environmentOptions=environmentOptions\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _getFlatKerning(self):\n        kernOrder = {\n            (True, True): 0,  # group group\n            (True, False): 1,  # group glyph\n            (False, True): 2,  # glyph group\n            (False, False): 3,  # glyph glyph\n        }\n\n        def kerningSortKeyFunc(pair):\n            g1, g2 = pair\n            g1grp = g1.startswith(\"public.kern1.\")\n            g2grp = g2.startswith(\"public.kern2.\")\n            return (kernOrder[g1grp, g2grp], pair)\n\n        flatKerning = dict()\n        kerning = self.kerning\n        groups = self.groups\n\n        for pair in sorted(self.kerning.keys(), key=kerningSortKeyFunc):\n            kern = kerning[pair]\n            (left, right) = pair\n            if left.startswith(\"public.kern1.\"):\n                left = groups.get(left, [])\n            else:\n                left = [left]\n\n            if right.startswith(\"public.kern2.\"):\n                right = groups.get(right, [])\n            else:\n                right = [right]\n\n            for r in right:\n                for l in left:\n                    flatKerning[(l, r)] = kern\n\n        return flatKerning", "response": "This method returns a dict of all kerning entries for the current base font."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_base_defaultLayer(self):\n        name = self.defaultLayerName\n        layer = self.getLayer(name)\n        return layer", "response": "Return the base default layer."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting the base layer with the given name.", "response": "def getLayer(self, name):\n        \"\"\"\n        Get the :class:`BaseLayer` with **name**.\n\n            >>> layer = font.getLayer(\"My Layer 2\")\n        \"\"\"\n        name = normalizers.normalizeLayerName(name)\n        if name not in self.layerOrder:\n            raise ValueError(\"No layer with the name '%s' exists.\" % name)\n        layer = self._getLayer(name)\n        self._setFontInLayer(layer)\n        return layer"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef newLayer(self, name, color=None):\n        name = normalizers.normalizeLayerName(name)\n        if name in self.layerOrder:\n            layer = self.getLayer(name)\n            if color is not None:\n                layer.color = color\n            return layer\n        if color is not None:\n            color = normalizers.normalizeColor(color)\n        layer = self._newLayer(name=name, color=color)\n        self._setFontInLayer(layer)\n        return layer", "response": "Make a new layer with the given name and color."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nremove the layer with the given name from the font.", "response": "def removeLayer(self, name):\n        \"\"\"\n        Remove the layer with **name** from the font.\n\n            >>> font.removeLayer(\"My Layer 3\")\n        \"\"\"\n        name = normalizers.normalizeLayerName(name)\n        if name not in self.layerOrder:\n            raise ValueError(\"No layer with the name '%s' exists.\" % name)\n        self._removeLayer(name)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ninserting a new layer into the font.", "response": "def insertLayer(self, layer, name=None):\n        \"\"\"\n        Insert **layer** into the font. ::\n\n            >>> layer = font.insertLayer(otherLayer, name=\"layer 2\")\n\n        This will not insert the layer directly.\n        Rather, a new layer will be created and the data from\n        **layer** will be copied to to the new layer. **name**\n        indicates the name that should be assigned to the layer\n        after insertion. If **name** is not given, the layer's\n        original name must be used. If the layer does not have\n        a name, an error must be raised. The data that will be\n        inserted from **layer** is the same data as documented\n        in :meth:`BaseLayer.copy`.\n        \"\"\"\n        if name is None:\n            name = layer.name\n        name = normalizers.normalizeLayerName(name)\n        if name in self:\n            self.removeLayer(name)\n        return self._insertLayer(layer, name=name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _insertLayer(self, layer, name, **kwargs):\n        if name != layer.name and layer.name in self.layerOrder:\n            layer = layer.copy()\n            layer.name = name\n        dest = self.newLayer(name)\n        dest.copyData(layer)\n        return dest", "response": "Internal method that inserts a new layer into the font."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nduplicate the layer with layerName assign to the new layer and insert the newLayer into the font.", "response": "def duplicateLayer(self, layerName, newLayerName):\n        \"\"\"\n        Duplicate the layer with **layerName**, assign\n        **newLayerName** to the new layer and insert the\n        new layer into the font. ::\n\n            >>> layer = font.duplicateLayer(\"layer 1\", \"layer 2\")\n        \"\"\"\n        layerOrder = self.layerOrder\n        layerName = normalizers.normalizeLayerName(layerName)\n        if layerName not in layerOrder:\n            raise ValueError(\"No layer with the name '%s' exists.\" % layerName)\n        newLayerName = normalizers.normalizeLayerName(newLayerName)\n        if newLayerName in layerOrder:\n            raise ValueError(\"A layer with the name '%s' already exists.\" % newLayerName)\n        newLayer = self._duplicateLayer(layerName, newLayerName)\n        newLayer = normalizers.normalizeLayer(newLayer)\n        return newLayer"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef swapLayerNames(self, layerName, otherLayerName):\n        layerOrder = self.layerOrder\n        layerName = normalizers.normalizeLayerName(layerName)\n        if layerName not in layerOrder:\n            raise ValueError(\"No layer with the name '%s' exists.\" % layerName)\n        otherLayerName = normalizers.normalizeLayerName(otherLayerName)\n        if otherLayerName not in layerOrder:\n            raise ValueError(\"No layer with the name '%s' exists.\" % otherLayerName)\n        self._swapLayers(layerName, otherLayerName)", "response": "Swap the names of the given layer and otherLayerName."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _swapLayers(self, layerName, otherLayerName):\n        import random\n        layer1 = self.getLayer(layerName)\n        layer2 = self.getLayer(otherLayerName)\n        # make a temporary name and assign it to\n        # the first layer to prevent two layers\n        # from having the same name at once.\n        layerOrder = self.layerOrder\n        for _ in range(50):\n            # shout out to PostScript unique IDs\n            tempLayerName = str(random.randint(4000000, 4999999))\n            if tempLayerName not in layerOrder:\n                break\n        if tempLayerName in layerOrder:\n            raise FontPartsError((\"Couldn't find a temporary layer name \"\n                                  \"after 50 tries. Sorry. Please try again.\"))\n        layer1.name = tempLayerName\n        # now swap\n        layer2.name = layerName\n        layer1.name = otherLayerName", "response": "This method is used to swap the layers in the font."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _newGlyph(self, name, **kwargs):\n        layer = self.defaultLayer\n        # clear is False here because the base newFont\n        # that has called this method will have already\n        # handled the clearing as specified by the caller.\n        return layer.newGlyph(name, clear=False)", "response": "This is the environment implementation of baseFont. newGlyph. It is the environment implementation of baseFont. newGlyph. It is the environment implementation of baseFont. newGlyph."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _round(self):\n        layer = self.defaultLayer\n        layer.round()\n        self.info.round()\n        self.kerning.round()\n        for guideline in self.guidelines:\n            guideline.round()", "response": "This is the environment implementation of\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nappending a guideline to the font.", "response": "def appendGuideline(self, position=None, angle=None, name=None, color=None, guideline=None):\n        \"\"\"\n        Append a new guideline to the font.\n\n            >>> guideline = font.appendGuideline((50, 0), 90)\n            >>> guideline = font.appendGuideline((0, 540), 0, name=\"overshoot\",\n            >>> color=(0, 0, 0, 0.2))\n\n        **position** must be a :ref:`type-coordinate`\n        indicating the position of the guideline.\n        **angle** indicates the :ref:`type-angle` of\n        the guideline. **name** indicates the name\n        for the guideline. This must be a :ref:`type-string`\n        or ``None``. **color** indicates the color for\n        the guideline. This must be a :ref:`type-color`\n        or ``None``. This will return the newly created\n        :class:`BaseGuidline` object.\n\n        ``guideline`` may be a :class:`BaseGuideline` object from which\n        attribute values will be copied. If ``position``, ``angle``, ``name``\n        or ``color`` are specified as arguments, those values will be used\n        instead of the values in the given guideline object.\n        \"\"\"\n        identifier = None\n        if guideline is not None:\n            guideline = normalizers.normalizeGuideline(guideline)\n            if position is None:\n                position = guideline.position\n            if angle is None:\n                angle = guideline.angle\n            if name is None:\n                name = guideline.name\n            if color is None:\n                color = guideline.color\n            if guideline.identifier is not None:\n                existing = set([g.identifier for g in self.guidelines if g.identifier is not None])\n                if guideline.identifier not in existing:\n                    identifier = guideline.identifier\n        position = normalizers.normalizeCoordinateTuple(position)\n        angle = normalizers.normalizeRotationAngle(angle)\n        if name is not None:\n            name = normalizers.normalizeGuidelineName(name)\n        if color is not None:\n            color = normalizers.normalizeColor(color)\n        identifier = normalizers.normalizeIdentifier(identifier)\n        guideline = self._appendGuideline(position, angle, name=name, color=color, identifier=identifier)\n        guideline.font = self\n        return guideline"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef interpolate(self, factor, minFont, maxFont,\n                    round=True, suppressError=True):\n        \"\"\"\n        Interpolate all possible data in the font.\n\n            >>> font.interpolate(0.5, otherFont1, otherFont2)\n            >>> font.interpolate((0.5, 2.0), otherFont1, otherFont2, round=False)\n\n        The interpolation occurs on a 0 to 1.0 range where **minFont**\n        is located at 0 and **maxFont** is located at 1.0. **factor**\n        is the interpolation value. It may be less than 0 and greater\n        than 1.0. It may be a :ref:`type-int-float` or a tuple of\n        two :ref:`type-int-float`. If it is a tuple, the first\n        number indicates the x factor and the second number indicates\n        the y factor. **round** indicates if the result should be\n        rounded to integers. **suppressError** indicates if incompatible\n        data should be ignored or if an error should be raised when\n        such incompatibilities are found.\n        \"\"\"\n        factor = normalizers.normalizeInterpolationFactor(factor)\n        if not isinstance(minFont, BaseFont):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__, minFont.__class__.__name__))\n        if not isinstance(maxFont, BaseFont):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\")\n                            % (self.__class__.__name__, maxFont.__class__.__name__))\n        round = normalizers.normalizeBoolean(round)\n        suppressError = normalizers.normalizeBoolean(suppressError)\n        self._interpolate(factor, minFont, maxFont,\n                          round=round, suppressError=suppressError)", "response": "Interpolate all possible data in the current font."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _interpolate(self, factor, minFont, maxFont,\n                     round=True, suppressError=True):\n        \"\"\"\n        This is the environment implementation of\n        :meth:`BaseFont.interpolate`.\n\n        Subclasses may override this method.\n        \"\"\"\n        # layers\n        for layerName in self.layerOrder:\n            self.removeLayer(layerName)\n        for layerName in minFont.layerOrder:\n            if layerName not in maxFont.layerOrder:\n                continue\n            minLayer = minFont.getLayer(layerName)\n            maxLayer = maxFont.getLayer(layerName)\n            dstLayer = self.newLayer(layerName)\n            dstLayer.interpolate(factor, minLayer, maxLayer,\n                                 round=round, suppressError=suppressError)\n        if self.layerOrder:\n            self.defaultLayer = self.getLayer(self.layerOrder[0])\n        # kerning and groups\n        self.kerning.interpolate(factor, minFont.kerning, maxFont.kerning,\n                                 round=round, suppressError=suppressError)\n        # info\n        self.info.interpolate(factor, minFont.info, maxFont.info,\n                              round=round, suppressError=suppressError)", "response": "This method is used to interpolate the kerning and info of the current base font."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _isCompatible(self, other, reporter):\n        font1 = self\n        font2 = other\n\n        # incompatible guidelines\n        guidelines1 = set(font1.guidelines)\n        guidelines2 = set(font2.guidelines)\n        if len(guidelines1) != len(guidelines2):\n            reporter.warning = True\n            reporter.guidelineCountDifference = True\n        if len(guidelines1.difference(guidelines2)) != 0:\n            reporter.warning = True\n            reporter.guidelinesMissingFromFont2 = list(\n                guidelines1.difference(guidelines2))\n        if len(guidelines2.difference(guidelines1)) != 0:\n            reporter.warning = True\n            reporter.guidelinesMissingInFont1 = list(\n                guidelines2.difference(guidelines1))\n        # incompatible layers\n        layers1 = set(font1.layerOrder)\n        layers2 = set(font2.layerOrder)\n        if len(layers1) != len(layers2):\n            reporter.warning = True\n            reporter.layerCountDifference = True\n        if len(layers1.difference(layers2)) != 0:\n            reporter.warning = True\n            reporter.layersMissingFromFont2 = list(layers1.difference(layers2))\n        if len(layers2.difference(layers1)) != 0:\n            reporter.warning = True\n            reporter.layersMissingInFont1 = list(layers2.difference(layers1))\n        # test layers\n        for layerName in sorted(layers1.intersection(layers2)):\n            layer1 = font1.getLayer(layerName)\n            layer2 = font2.getLayer(layerName)\n            layerCompatibility = layer1.isCompatible(layer2)[1]\n            if layerCompatibility.fatal or layerCompatibility.warning:\n                if layerCompatibility.fatal:\n                    reporter.fatal = True\n                if layerCompatibility.warning:\n                    reporter.warning = True\n                reporter.layers.append(layerCompatibility)", "response": "This method checks if two font objects are compatible."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _set_selectedLayerNames(self, value):\n        select = [self.layers(name) for name in value]\n        self.selectedLayers = select", "response": "Set the selected layer names."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _get_index(self):\n        contour = self.contour\n        value = contour.segments.index(self)\n        return value", "response": "Get the index of the current object in the contour segments."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nset the type of the current contour entry.", "response": "def _set_type(self, newType):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        oldType = self.type\n        if oldType == newType:\n            return\n        contour = self.contour\n        if contour is None:\n            raise FontPartsError(\"The segment does not belong to a contour.\")\n        # converting line <-> move\n        if newType in (\"move\", \"line\") and oldType in (\"move\", \"line\"):\n            pass\n        # converting to a move or line\n        elif newType not in (\"curve\", \"qcurve\"):\n            offCurves = self.offCurve\n            for point in offCurves:\n                contour.removePoint(point)\n        # converting a line/move to a curve/qcurve\n        else:\n            segments = contour.segments\n            i = segments.index(self)\n            prev = segments[i - 1].onCurve\n            on = self.onCurve\n            x = on.x\n            y = on.y\n            points = contour.points\n            i = points.index(on)\n            contour.insertPoint(i, (x, y), \"offcurve\")\n            off2 = contour.points[i]\n            contour.insertPoint(i, (prev.x, prev.y), \"offcurve\")\n            off1 = contour.points[i]\n            del self._points\n            self._setPoints((off1, off2, on))\n        self.onCurve.type = newType"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the available base - level log entries.", "response": "def _iterPoints(self, **kwargs):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        points = self.points\n        count = len(points)\n        index = 0\n        while count:\n            yield points[index]\n            count -= 1\n            index += 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _transformBy(self, matrix, **kwargs):\n        for point in self.points:\n            point.transformBy(matrix)", "response": "This method transforms the point matrix by the point s point matrix."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _isCompatible(self, other, reporter):\n        segment1 = self\n        segment2 = other\n        # type\n        if segment1.type != segment2.type:\n            # line <-> curve can be converted\n            if set((segment1.type, segment2.type)) != set((\"curve\", \"line\")):\n                reporter.typeDifference = True\n                reporter.fatal = True", "response": "Checks if two base segments are compatible with this one."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef getIdentifierForPoint(self, point):\n        point = normalizers.normalizePoint(point)\n        return self._getIdentifierforPoint(point)", "response": "Create a unique identifier for and assign it to point."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _drawPoints(self, pen, **kwargs):\n        # The try: ... except TypeError: ...\n        # handles backwards compatibility with\n        # point pens that have not been upgraded\n        # to point pen protocol 2.\n        try:\n            pen.beginPath(self.identifier)\n        except TypeError:\n            pen.beginPath()\n        for point in self.points:\n            typ = point.type\n            if typ == \"offcurve\":\n                typ = None\n            try:\n                pen.addPoint(pt=(point.x, point.y), segmentType=typ,\n                             smooth=point.smooth, name=point.name,\n                             identifier=point.identifier)\n            except TypeError:\n                pen.addPoint(pt=(point.x, point.y), segmentType=typ,\n                             smooth=point.smooth, name=point.name)\n        pen.endPath()", "response": "Draw the points in the pen."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _isCompatible(self, other, reporter):\n        contour1 = self\n        contour2 = other\n        # open/closed\n        if contour1.open != contour2.open:\n            reporter.openDifference = True\n        # direction\n        if contour1.clockwise != contour2.clockwise:\n            reporter.directionDifference = True\n        # segment count\n        if len(contour1) != len(contour2.segments):\n            reporter.segmentCountDifference = True\n            reporter.fatal = True\n        # segment pairs\n        for i in range(min(len(contour1), len(contour2))):\n            segment1 = contour1[i]\n            segment2 = contour2[i]\n            segmentCompatibility = segment1.isCompatible(segment2)[1]\n            if segmentCompatibility.fatal or segmentCompatibility.warning:\n                if segmentCompatibility.fatal:\n                    reporter.fatal = True\n                if segmentCompatibility.warning:\n                    reporter.warning = True\n                reporter.segments.append(segmentCompatibility)", "response": "This method is used to check if two contour objects are compatible."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef contourInside(self, otherContour):\n        otherContour = normalizers.normalizeContour(otherContour)\n        return self._contourInside(otherContour)", "response": "Determine if this contour is inside the other contour."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _get_segments(self):\n        points = list(self.points)\n        segments = [[]]\n        lastWasOffCurve = False\n        firstIsMove = points[0].type == \"move\"\n        for point in points:\n            segments[-1].append(point)\n            if point.type != \"offcurve\":\n                segments.append([])\n            lastWasOffCurve = point.type == \"offcurve\"\n        if len(segments[-1]) == 0:\n            del segments[-1]\n        if lastWasOffCurve and firstIsMove:\n            # ignore trailing off curves\n            del segments[-1]\n        if lastWasOffCurve and not firstIsMove:\n            segment = segments.pop(-1)\n            segment.extend(segments[0])\n            del segments[0]\n            segments.append(segment)\n        if not lastWasOffCurve and not firstIsMove:\n            segment = segments.pop(0)\n            segments.append(segment)\n        # wrap into segments\n        wrapped = []\n        for points in segments:\n            s = self.segmentClass()\n            s._setPoints(points)\n            self._setContourInSegment(s)\n            wrapped.append(s)\n        return wrapped", "response": "Returns a list of segments for this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef appendSegment(self, type=None, points=None, smooth=False, segment=None):\n        if segment is not None:\n            if type is not None:\n                type = segment.type\n            if points is None:\n                points = [(point.x, point.y) for point in segment.points]\n            smooth = segment.smooth\n        type = normalizers.normalizeSegmentType(type)\n        pts = []\n        for pt in points:\n            pt = normalizers.normalizeCoordinateTuple(pt)\n            pts.append(pt)\n        points = pts\n        smooth = normalizers.normalizeBoolean(smooth)\n        self._appendSegment(type=type, points=points, smooth=smooth)", "response": "Append a segment to the contour."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nappends a new segment to the end of the segment list.", "response": "def _appendSegment(self, type=None, points=None, smooth=False, **kwargs):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        self._insertSegment(len(self), type=type, points=points,\n                            smooth=smooth, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef insertSegment(self, index, type=None, points=None, smooth=False, segment=None):\n        if segment is not None:\n            if type is not None:\n                type = segment.type\n            if points is None:\n                points = [(point.x, point.y) for point in segment.points]\n            smooth = segment.smooth\n        index = normalizers.normalizeIndex(index)\n        type = normalizers.normalizeSegmentType(type)\n        pts = []\n        for pt in points:\n            pt = normalizers.normalizeCoordinateTuple(pt)\n            pts.append(pt)\n        points = pts\n        smooth = normalizers.normalizeBoolean(smooth)\n        self._insertSegment(index=index, type=type,\n                            points=points, smooth=smooth)", "response": "Insert a new segment into the contour."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove a segment from the contour.", "response": "def removeSegment(self, segment, preserveCurve=False):\n        \"\"\"\n        Remove segment from the contour.\n        If ``preserveCurve`` is set to ``True`` an attempt\n        will be made to preserve the shape of the curve\n        if the environment supports that functionality.\n        \"\"\"\n        if not isinstance(segment, int):\n            segment = self.segments.index(segment)\n        segment = normalizers.normalizeIndex(segment)\n        if segment >= self._len__segments():\n            raise ValueError(\"No segment located at index %d.\" % segment)\n        preserveCurve = normalizers.normalizeBoolean(preserveCurve)\n        self._removeSegment(segment, preserveCurve)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _removeSegment(self, segment, preserveCurve, **kwargs):\n        segment = self.segments[segment]\n        for point in segment.points:\n            self.removePoint(point, preserveCurve)", "response": "Remove a segment from the internal data structures."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets the first segment on the contour.", "response": "def setStartSegment(self, segment):\n        \"\"\"\n        Set the first segment on the contour.\n        segment can be a segment object or an index.\n        \"\"\"\n        segments = self.segments\n        if not isinstance(segment, int):\n            segmentIndex = segments.index(segment)\n        else:\n            segmentIndex = segment\n        if len(self.segments) < 2:\n            return\n        if segmentIndex == 0:\n            return\n        if segmentIndex >= len(segments):\n            raise ValueError((\"The contour does not contain a segment \"\n                              \"at index %d\" % segmentIndex))\n        self._setStartSegment(segmentIndex)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nappends a bPoint to the contour.", "response": "def appendBPoint(self, type=None, anchor=None, bcpIn=None, bcpOut=None, bPoint=None):\n        \"\"\"\n        Append a bPoint to the contour.\n        \"\"\"\n        if bPoint is not None:\n            if type is None:\n                type = bPoint.type\n            if anchor is None:\n                anchor = bPoint.anchor\n            if bcpIn is None:\n                bcpIn = bPoint.bcpIn\n            if bcpOut is None:\n                bcpOut = bPoint.bcpOut\n        type = normalizers.normalizeBPointType(type)\n        anchor = normalizers.normalizeCoordinateTuple(anchor)\n        if bcpIn is None:\n            bcpIn = (0, 0)\n        bcpIn = normalizers.normalizeCoordinateTuple(bcpIn)\n        if bcpOut is None:\n            bcpOut = (0, 0)\n        bcpOut = normalizers.normalizeCoordinateTuple(bcpOut)\n        self._appendBPoint(type, anchor, bcpIn=bcpIn, bcpOut=bcpOut)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _appendBPoint(self, type, anchor, bcpIn=None, bcpOut=None, **kwargs):\n        self.insertBPoint(\n            len(self.bPoints),\n            type,\n            anchor,\n            bcpIn=bcpIn,\n            bcpOut=bcpOut\n        )", "response": "Append a new bPoint to the internal list of bPoints."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef insertBPoint(self, index, type=None, anchor=None, bcpIn=None, bcpOut=None, bPoint=None):\n        if bPoint is not None:\n            if type is None:\n                type = bPoint.type\n            if anchor is None:\n                anchor = bPoint.anchor\n            if bcpIn is None:\n                bcpIn = bPoint.bcpIn\n            if bcpOut is None:\n                bcpOut = bPoint.bcpOut\n        index = normalizers.normalizeIndex(index)\n        type = normalizers.normalizeBPointType(type)\n        anchor = normalizers.normalizeCoordinateTuple(anchor)\n        if bcpIn is None:\n            bcpIn = (0, 0)\n        bcpIn = normalizers.normalizeCoordinateTuple(bcpIn)\n        if bcpOut is None:\n            bcpOut = (0, 0)\n        bcpOut = normalizers.normalizeCoordinateTuple(bcpOut)\n        self._insertBPoint(index=index, type=type, anchor=anchor,\n                           bcpIn=bcpIn, bcpOut=bcpOut)", "response": "Insert a new bPoint at the specified index in the contour."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ninsert a new bPoint at the given index.", "response": "def _insertBPoint(self, index, type, anchor, bcpIn, bcpOut, **kwargs):\n        \"\"\"\n        Subclasses may override this method.\n        \"\"\"\n        # insert a simple line segment at the given anchor\n        # look it up as a bPoint and change the bcpIn and bcpOut there\n        # this avoids code duplication\n        self._insertSegment(index=index, type=\"line\",\n                            points=[anchor], smooth=False)\n        bPoints = self.bPoints\n        index += 1\n        if index >= len(bPoints):\n            # its an append instead of an insert\n            # so take the last bPoint\n            index = -1\n        bPoint = bPoints[index]\n        bPoint.bcpIn = bcpIn\n        bPoint.bcpOut = bcpOut\n        bPoint.type = type"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nremove the bpoint from the contour.", "response": "def removeBPoint(self, bPoint):\n        \"\"\"\n        Remove the bpoint from the contour.\n        bpoint can be a point object or an index.\n        \"\"\"\n        if not isinstance(bPoint, int):\n            bPoint = bPoint.index\n        bPoint = normalizers.normalizeIndex(bPoint)\n        if bPoint >= self._len__points():\n            raise ValueError(\"No bPoint located at index %d.\" % bPoint)\n        self._removeBPoint(bPoint)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nremove the bPoint at the specified index from the internal list of bPoints.", "response": "def _removeBPoint(self, index, **kwargs):\n        \"\"\"\n        index will be a valid index.\n\n        Subclasses may override this method.\n        \"\"\"\n        bPoint = self.bPoints[index]\n\n        nextSegment = bPoint._nextSegment\n        offCurves = nextSegment.offCurve\n        if offCurves:\n            offCurve = offCurves[0]\n            self.removePoint(offCurve)\n\n        segment = bPoint._segment\n        offCurves = segment.offCurve\n        if offCurves:\n            offCurve = offCurves[-1]\n            self.removePoint(offCurve)\n\n        self.removePoint(bPoint._point)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _get_points(self):\n        return tuple([self._getitem__points(i)\n                     for i in range(self._len__points())])", "response": "Returns a tuple of the set of unique keys."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef appendPoint(self, position=None, type=\"line\", smooth=False, name=None, identifier=None, point=None):\n        if point is not None:\n            if position is None:\n                position = point.position\n            type = point.type\n            smooth = point.smooth\n            if name is None:\n                name = point.name\n            if identifier is not None:\n                identifier = point.identifier\n        self.insertPoint(\n            len(self.points),\n            position=position,\n            type=type,\n            smooth=smooth,\n            name=name,\n            identifier=identifier\n        )", "response": "Append a point to the contour."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a point into the contour.", "response": "def insertPoint(self, index, position=None, type=\"line\", smooth=False, name=None, identifier=None, point=None):\n        \"\"\"\n        Insert a point into the contour.\n        \"\"\"\n        if point is not None:\n            if position is None:\n                position = point.position\n            type = point.type\n            smooth = point.smooth\n            if name is None:\n                name = point.name\n            if identifier is not None:\n                identifier = point.identifier\n        index = normalizers.normalizeIndex(index)\n        position = normalizers.normalizeCoordinateTuple(position)\n        type = normalizers.normalizePointType(type)\n        smooth = normalizers.normalizeBoolean(smooth)\n        if name is not None:\n            name = normalizers.normalizePointName(name)\n        if identifier is not None:\n            identifier = normalizers.normalizeIdentifier(identifier)\n        self._insertPoint(\n            index,\n            position=position,\n            type=type,\n            smooth=smooth,\n            name=name,\n            identifier=identifier\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _insertPoint(self, index, position, type=\"line\",\n                     smooth=False, name=None, identifier=None, **kwargs):\n        \"\"\"\n        position will be a valid position (x, y).\n        type will be a valid type.\n        smooth will be a valid boolean.\n        name will be a valid name or None.\n        identifier will be a valid identifier or None.\n        The identifier will not have been tested for uniqueness.\n\n        Subclasses must override this method.\n        \"\"\"\n        self.raiseNotImplementedError()", "response": "Insert a new point into the tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves the point from the contour.", "response": "def removePoint(self, point, preserveCurve=False):\n        \"\"\"\n        Remove the point from the contour.\n        point can be a point object or an index.\n        If ``preserveCurve`` is set to ``True`` an attempt\n        will be made to preserve the shape of the curve\n        if the environment supports that functionality.\n        \"\"\"\n        if not isinstance(point, int):\n            point = self.points.index(point)\n        point = normalizers.normalizeIndex(point)\n        if point >= self._len__points():\n            raise ValueError(\"No point located at index %d.\" % point)\n        preserveCurve = normalizers.normalizeBoolean(preserveCurve)\n        self._removePoint(point, preserveCurve)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nscales all kerning values by a factor.", "response": "def scaleBy(self, factor):\n        \"\"\"\n        Scales all kerning values by **factor**. **factor** will be an\n        :ref:`type-int-float`, ``tuple`` or ``list``. The first value of the\n        **factor** will be used to scale the kerning values.\n\n            >>> myKerning.scaleBy(2)\n            >>> myKerning.scaleBy((2,3))\n        \"\"\"\n        factor = normalizers.normalizeTransformationScale(factor)\n        self._scale(factor)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _scale(self, factor):\n        factor = factor[0]\n        for k, v in self.items():\n            v *= factor\n            self[k] = v", "response": "This method scales the internal dictionary by a factor."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nround the kerning values to increments of multiple kerning values.", "response": "def round(self, multiple=1):\n        \"\"\"\n        Rounds the kerning values to increments of **multiple**,\n        which will be an ``int``.\n\n        The default behavior is to round to increments of 1.\n        \"\"\"\n        if not isinstance(multiple, int):\n            raise TypeError(\"The round multiple must be an int not %s.\"\n                            % multiple.__class__.__name__)\n        self._round(multiple)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef interpolate(self, factor, minKerning, maxKerning, round=True, suppressError=True):\n        factor = normalizers.normalizeInterpolationFactor(factor)\n        if not isinstance(minKerning, BaseKerning):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\") % (\n                self.__class__.__name__, minKerning.__class__.__name__))\n        if not isinstance(maxKerning, BaseKerning):\n            raise TypeError((\"Interpolation to an instance of %r can not be \"\n                             \"performed from an instance of %r.\") % (\n                self.__class__.__name__, maxKerning.__class__.__name__))\n        round = normalizers.normalizeBoolean(round)\n        suppressError = normalizers.normalizeBoolean(suppressError)\n        self._interpolate(factor, minKerning, maxKerning,\n                          round=round, suppressError=suppressError)", "response": "Interpolate all pairs between two base kerning objects and return the interpolated kerning data."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef asDict(self, returnIntegers=True):\n        d = {}\n        for k, v in self.items():\n            d[k] = v if not returnIntegers else normalizers.normalizeRounding(v)\n        return d", "response": "Return the Kerning as a dict."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get(self, pair, default=None):\n        return super(BaseKerning, self).get(pair, default)", "response": "Returns the value for the kerning pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef find(self, pair, default=None):\n        pair = normalizers.normalizeKerningKey(pair)\n        value = self._find(pair, default)\n        if value != default:\n            value = normalizers.normalizeKerningValue(value)\n        return value", "response": "Returns the value for the kerning key pair."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find(self, pair, default=None):\n        from fontTools.ufoLib.kerning import lookupKerningValue\n        font = self.font\n        groups = font.groups\n        return lookupKerningValue(pair, self, groups, fallback=default)", "response": "This is the environment implementation of baseKerning. find. This is the environment implementation of baseKerning. find. This must return an\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pop(self, pair, default=None):\n        return super(BaseKerning, self).pop(pair, default)", "response": "Removes the pair from the Kerning and returns the value as an int."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef validate_float(cls, value):\n        if not isinstance(value, (int, float)):\n            raise TypeError(\n                \"value must be a number, got %s\" % type(value)\n            )", "response": "Validate that value is a number."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert signed angle float like - 42. 42 to int 60000 per degree", "response": "def convert_to_xml(cls, value):\n        \"\"\"\n        Convert signed angle float like -42.42 to int 60000 per degree,\n        normalized to positive value.\n        \"\"\"\n        # modulo normalizes negative and >360 degree values\n        rot = int(round(value * cls.DEGREE_INCREMENTS)) % cls.THREE_SIXTY\n        return str(rot)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef convert_to_xml(cls, degrees):\n        if degrees < 0.0:\n            degrees %= -360\n            degrees += 360\n        elif degrees > 0.0:\n            degrees %= 360\n\n        return str(int(round(degrees * cls.DEGREE_INCREMENTS)))", "response": "Convert signed angle float like - 427. 42 to int 60000 per degree."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the effective value of attr_name on this placeholder shape or None if it does not have one.", "response": "def _effective_value(self, attr_name):\n        \"\"\"\n        The effective value of *attr_name* on this placeholder shape; its\n        directly-applied value if it has one, otherwise the value on the\n        layout placeholder it inherits from.\n        \"\"\"\n        directly_applied_value = getattr(\n            super(_InheritsDimensions, self), attr_name\n        )\n        if directly_applied_value is not None:\n            return directly_applied_value\n        return self._inherited_value(attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the value of an attribute that inherits from the base placeholder.", "response": "def _inherited_value(self, attr_name):\n        \"\"\"\n        Return the attribute value, e.g. 'width' of the base placeholder this\n        placeholder inherits from.\n        \"\"\"\n        base_placeholder = self._base_placeholder\n        if base_placeholder is None:\n            return None\n        inherited_value = getattr(base_placeholder, attr_name)\n        return inherited_value"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _base_placeholder(self):\n        layout, idx = self.part.slide_layout, self._element.ph_idx\n        return layout.placeholders.get(idx=idx)", "response": "Return the base placeholder this slide placeholder inherits from."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _replace_placeholder_with(self, element):\n        element._nvXxPr.nvPr._insert_ph(self._element.ph)\n        self._element.addprevious(element)\n        self._element.getparent().remove(self._element)\n        self._element = None", "response": "Replace the element with element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _base_placeholder(self):\n        base_ph_type = {\n            PP_PLACEHOLDER.BODY:         PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.CHART:        PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.BITMAP:       PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.CENTER_TITLE: PP_PLACEHOLDER.TITLE,\n            PP_PLACEHOLDER.ORG_CHART:    PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.DATE:         PP_PLACEHOLDER.DATE,\n            PP_PLACEHOLDER.FOOTER:       PP_PLACEHOLDER.FOOTER,\n            PP_PLACEHOLDER.MEDIA_CLIP:   PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.OBJECT:       PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.PICTURE:      PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.SLIDE_NUMBER: PP_PLACEHOLDER.SLIDE_NUMBER,\n            PP_PLACEHOLDER.SUBTITLE:     PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.TABLE:        PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.TITLE:        PP_PLACEHOLDER.TITLE,\n        }[self._element.ph_type]\n        slide_master = self.part.slide_master\n        return slide_master.placeholders.get(base_ph_type, None)", "response": "Return the base placeholder this layout placeholder inherits from."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the base notes master placeholder this notes slide inherits from or |None| if no base notes master placeholder is present.", "response": "def _base_placeholder(self):\n        \"\"\"\n        Return the notes master placeholder this notes slide placeholder\n        inherits from, or |None| if no placeholder of the matching type is\n        present.\n        \"\"\"\n        notes_master = self.part.notes_master\n        ph_type = self.element.ph_type\n        return notes_master.placeholders.get(ph_type=ph_type)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef insert_chart(self, chart_type, chart_data):\n        rId = self.part.add_chart_part(chart_type, chart_data)\n        graphicFrame = self._new_chart_graphicFrame(\n            rId, self.left, self.top, self.width, self.height\n        )\n        self._replace_placeholder_with(graphicFrame)\n        return PlaceholderGraphicFrame(graphicFrame, self._parent)", "response": "Insert a chart into the placeholder."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a newly created chart graphicFrame element with the specified rId position and size and containing the chart identified by rId.", "response": "def _new_chart_graphicFrame(self, rId, x, y, cx, cy):\n        \"\"\"\n        Return a newly created `p:graphicFrame` element having the specified\n        position and size and containing the chart identified by *rId*.\n        \"\"\"\n        id_, name = self.shape_id, self.name\n        return CT_GraphicalObjectFrame.new_chart_graphicFrame(\n            id_, name, rId, x, y, cx, cy\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef insert_picture(self, image_file):\n        pic = self._new_placeholder_pic(image_file)\n        self._replace_placeholder_with(pic)\n        return PlaceholderPicture(pic, self._parent)", "response": "Insert a picture into the cache."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _new_placeholder_pic(self, image_file):\n        rId, desc, image_size = self._get_or_add_image(image_file)\n        shape_id, name = self.shape_id, self.name\n        pic = CT_Picture.new_ph_pic(shape_id, name, desc, rId)\n        pic.crop_to_fit(image_size, (self.width, self.height))\n        return pic", "response": "Return a new p : pic element depicting the image in image_file suitable for use as a placeholder."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_or_add_image(self, image_file):\n        image_part, rId = self.part.get_or_add_image_part(image_file)\n        desc, image_size = image_part.desc, image_part._px_size\n        return rId, desc, image_size", "response": "Return an rId description image_size"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ninserting a new table into the current |PlaceholderGraphicFrame| object.", "response": "def insert_table(self, rows, cols):\n        \"\"\"\n        Return a |PlaceholderGraphicFrame| object containing a table of\n        *rows* rows and *cols* columns. The position and width of the table\n        are those of the placeholder and its height is proportional to the\n        number of rows. A |PlaceholderGraphicFrame| object has all the\n        properties and methods of a |GraphicFrame| shape except that the\n        value of its :attr:`~._BaseSlidePlaceholder.shape_type` property is\n        unconditionally `MSO_SHAPE_TYPE.PLACEHOLDER`. Note that the return\n        value is not the new table but rather *contains* the new table. The\n        table can be accessed using the\n        :attr:`~.PlaceholderGraphicFrame.table` property of the returned\n        |PlaceholderGraphicFrame| object.\n        \"\"\"\n        graphicFrame = self._new_placeholder_table(rows, cols)\n        self._replace_placeholder_with(graphicFrame)\n        return PlaceholderGraphicFrame(graphicFrame, self._parent)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _new_placeholder_table(self, rows, cols):\n        shape_id, name, height = self.shape_id, self.name, Emu(rows*370840)\n        return CT_GraphicalObjectFrame.new_table_graphicFrame(\n            shape_id, name, rows, cols, self.left, self.top, self.width,\n            height\n        )", "response": "Return a newly added empty ArcGIS placeholder table."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef shapes(self):\n        from pptx.shapes.shapetree import GroupShapes\n        return GroupShapes(self._element, self)", "response": "Return |GroupShapes| object for this group."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef create_tables(c):\n    # auto_shape_types ---------------------\n    c.execute(\n        'DROP TABLE IF EXISTS auto_shape_types'\n    )\n    c.execute(\n        'CREATE TABLE auto_shape_types (\\n'\n        '    id         integer,\\n'\n        '    prst       text,\\n'\n        '    const_name text,\\n'\n        '    base_name  text,\\n'\n        '    ms_name    text,\\n'\n        '    desc       text\\n'\n        ')\\n'\n    )\n    c.execute(\n        'DROP TABLE IF EXISTS adjustment_values'\n    )\n    c.execute(\n        'CREATE TABLE adjustment_values (\\n'\n        '    prst     text,\\n'\n        '    seq_nmbr integer,\\n'\n        '    name     text,\\n'\n        '    val      integer\\n'\n        ')\\n'\n    )", "response": "create the auto shape type tables"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef load_adjustment_values():\n    # parse XML --------------------------------------------\n    thisdir = os.path.split(__file__)[0]\n    prst_defs_relpath = (\n        'ISO-IEC-29500-1/schemas/dml-geometries/OfficeOpenXML-DrawingMLGeomet'\n        'ries/presetShapeDefinitions.xml'\n    )\n    prst_defs_path = os.path.join(thisdir, prst_defs_relpath)\n    presetShapeDefinitions = objectify.parse(prst_defs_path).getroot()\n    # load individual records into tuples to return --------\n    ns = 'http://schemas.openxmlformats.org/drawingml/2006/main'\n    avLst_qn = '{%s}avLst' % ns\n    adjustment_values = []\n    for shapedef in presetShapeDefinitions.iterchildren():\n        prst = shapedef.tag\n        try:\n            avLst = shapedef[avLst_qn]\n        except AttributeError:\n            continue\n        for idx, gd in enumerate(avLst.gd):\n            name = gd.get('name')\n            val = int(gd.get('fmla')[4:])  # strip off leading 'val '\n            record = (prst, idx+1, name, val)\n            adjustment_values.append(record)\n    return adjustment_values", "response": "load adjustment values and their default values from XML"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef print_mso_auto_shape_type_constants():\n    auto_shape_types = MsoAutoShapeTypeCollection.load(sort='const_name')\n    out = render_mso_auto_shape_type_constants(auto_shape_types)\n    print out", "response": "print symbolic constant definitions for msoAutoShapeType"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef print_mso_auto_shape_type_enum():\n    auto_shape_types = MsoAutoShapeTypeCollection.load(sort='const_name')\n    out = render_mso_auto_shape_type_enum(auto_shape_types)\n    print out", "response": "print symbolic constant definitions for msoAutoShapeType"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef print_mso_auto_shape_type_spec():\n    auto_shape_types = MsoAutoShapeTypeCollection.load(sort='const_name')\n    out = render_mso_auto_shape_type_spec(auto_shape_types)\n    print out", "response": "print spec dictionary for MsoAutoShapeType"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncalculate desc string wrapped if too long", "response": "def render_desc(desc):\n    \"\"\"calculate desc string, wrapped if too long\"\"\"\n    desc = desc + '.'\n    desc_lines = split_len(desc, 54)\n    if len(desc_lines) > 1:\n        join_str = \"'\\n%s'\" % (' '*21)\n        lines_str = join_str.join(desc_lines)\n        out = \"('%s')\" % lines_str\n    else:\n        out = \"'%s'\" % desc_lines[0]\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef split_len(s, length):\n    return [s[i:i+length] for i in range(0, len(s), length)]", "response": "split string s into list of strings no longer than length"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nconvert upper snake case string to mixed case e. g. MIXED_CASE becomes MixedCase", "response": "def to_mixed_case(s):\n    \"\"\"\n    convert upper snake case string to mixed case, e.g. MIXED_CASE becomes\n    MixedCase\n    \"\"\"\n    out = ''\n    last_c = ''\n    for c in s:\n        if c == '_':\n            pass\n        elif last_c in ('', '_'):\n            out += c.upper()\n        else:\n            out += c.lower()\n        last_c = c\n    return out"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef parse_args(spectypes):\n    arg_parser = argparse.ArgumentParser()\n    arg_parser.add_argument(\n        \"-c\", \"--constants\",\n        help=\"emit constants instead of spec dict\",\n        action=\"store_true\"\n    )\n    arg_parser.add_argument(\n        \"spectype\",\n        help=\"specifies the spec type to be generated\",\n        choices=spectypes\n    )\n    return arg_parser.parse_args()", "response": "Returns the arguments object formed by parsing the command line used to launch\n    the program."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nloading adjustment values for all auto shape types in self", "response": "def load_adjustment_values(self, c):\n        \"\"\"load adjustment values for auto shape types in self\"\"\"\n        # retrieve auto shape types in const_name order --------\n        for mast in self:\n            # retriev adj vals for this auto shape type --------\n            c.execute(\n                '  SELECT name, val\\n'\n                '    FROM adjustment_values\\n'\n                '   WHERE prst = ?\\n'\n                'ORDER BY seq_nmbr', (mast.prst,)\n            )\n            for name, val in c:\n                mast.adj_vals.append(AdjustmentValue(name, val))"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef to_unicode(text):\n    if not isinstance(text, str):\n        tmpl = 'expected unicode string, got %s value %s'\n        raise TypeError(tmpl % (type(text), text))\n    return text", "response": "Return text as a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns direct child of element having child_tagname or None if no such child element is present.", "response": "def _child(element, child_tagname):\n    \"\"\"\n    Return direct child of *element* having *child_tagname* or :class:`None`\n    if no such child element is present.\n    \"\"\"\n    xpath = './%s' % child_tagname\n    matching_children = element.xpath(xpath, namespaces=nsmap)\n    return matching_children[0] if len(matching_children) else None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _child_list(element, child_tagname):\n    xpath = './%s' % child_tagname\n    return element.xpath(xpath, namespaces=nsmap)", "response": "Return list containing direct children of element having child_tagname."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _required_attribute(element, name, default):\n    if element.get(name) is None:\n        element.set(name, default)", "response": "Add attribute with default value to element if it doesn t already exist."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _required_child(parent, tag):\n    if _child(parent, tag) is None:\n        parent.append(_Element(tag))", "response": "Add child element with tag to parent if it doesn t already exist."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef new_chart_graphicFrame(cls, id_, name, rId, x, y, cx, cy):\n        graphicFrame = CT_GraphicalObjectFrame.new_graphicFrame(\n            id_, name, x, y, cx, cy\n        )\n        graphicData = graphicFrame.graphic.graphicData\n        graphicData.uri = GRAPHIC_DATA_URI_CHART\n        graphicData.append(CT_Chart.new_chart(rId))\n        return graphicFrame", "response": "Return a new |GraphicalObjectFrame| populated with a chart\n        element."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new graphicFrame element tree suitable for a table or chart.", "response": "def new_graphicFrame(cls, id_, name, x, y, cx, cy):\n        \"\"\"\n        Return a new ``<p:graphicFrame>`` element tree suitable for\n        containing a table or chart. Note that a graphicFrame element is not\n        a valid shape until it contains a graphical object such as a table.\n        \"\"\"\n        xml = cls._graphicFrame_tmpl() % (id_, name, x, y, cx, cy)\n        graphicFrame = parse_xml(xml)\n        return graphicFrame"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_table_graphicFrame(cls, id_, name, rows, cols, x, y, cx, cy):\n        graphicFrame = cls.new_graphicFrame(id_, name, x, y, cx, cy)\n        graphicFrame.graphic.graphicData.uri = GRAPHIC_DATA_URI_TABLE\n        graphicFrame.graphic.graphicData.append(\n            CT_Table.new_tbl(rows, cols, cx, cy)\n        )\n        return graphicFrame", "response": "Return a new table graphicFrame element tree populated with a table\n        element."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_lumMod(self, value):\n        lumMod = self._add_lumMod()\n        lumMod.val = value\n        return lumMod", "response": "Adds a new lumMod element with the specified value."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new lumOff element to the end of the current lumOff element.", "response": "def add_lumOff(self, value):\n        \"\"\"\n        Return a newly added <a:lumOff> child element.\n        \"\"\"\n        lumOff = self._add_lumOff()\n        lumOff.val = value\n        return lumOff"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn short - form prefixed tag from fully qualified ( Clark notation )", "response": "def pfxdtag(tag):\n    \"\"\"\n    Return short-form prefixed tag from fully qualified (Clark notation)\n    tagname.\n    \"\"\"\n    uri, tagroot = tag[1:].split('}')\n    prefix = reverse_nsmap[uri]\n    return '%s:%s' % (prefix, tagroot)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns fully qualified ( Clark notation ) tagname corresponding to tag.", "response": "def qtag(tag):\n    \"\"\"\n    Return fully qualified (Clark notation) tagname corresponding to\n    short-form prefixed tagname *tag*.\n    \"\"\"\n    prefix, tagroot = tag.split(':')\n    uri = nsmap[prefix]\n    return '{%s}%s' % (uri, tagroot)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn complex type element with name *typename*", "response": "def get_complexType(self, typename):\n        \"\"\"Return complex type element with name *typename*\"\"\"\n        if typename.startswith('a:'):\n            typename = typename[2:]\n        xpath = \"./xsd:complexType[@name='%s']\" % typename\n        for xsd in self.__xsd_trees:\n            elms = xsd.xpath(xpath)\n            if len(elms):\n                return elms[0], xsd.nsprefix\n        raise KeyError(\"no complexType named '%s' found\" % typename)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns definition element with name defname * tag", "response": "def getdef(self, defname, tag='*'):\n        \"\"\"Return definition element with name *defname*\"\"\"\n        if defname.startswith('a:'):\n            defname = defname[2:]\n        for xsd in self.__xsd_trees:\n            xpath = \"./%s[@name='%s']\" % (tag, defname)\n            elements = xsd.xpath(xpath)\n            if elements:\n                return elements[0]\n        raise KeyError(\"no definition named '%s' found\" % defname)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds an element to this ComplexType and also append it to the type graph.", "response": "def add_element(self, element):\n        \"\"\"\n        Add an element to this ComplexType and also append it to element dict\n        of parent type graph.\n        \"\"\"\n        self.elements.append(element)\n        self.type_graph.add_element(element)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef element_def(self):\n        s = (\"%s = ElementDef('%s', '%s')\\n\" %\n             (self.name, self.name, self.name))\n        for element in self.elements:\n            s += (\"%s.add_child('%s', cardinality='%s')\\n\" %\n                  (self.name, element.name, element.cardinality))\n        # for attribute in self.attributes:\n        #     s += '\\n  %s' % attribute\n        return s", "response": "Return a string that represents the current element."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nclones the master placeholders.", "response": "def clone_master_placeholders(self, notes_master):\n        \"\"\"\n        Selectively add placeholder shape elements from *notes_master* to the\n        shapes collection of this notes slide. Z-order of placeholders is\n        preserved. Certain placeholders (header, date, footer) are not\n        cloned.\n        \"\"\"\n        def iter_cloneable_placeholders(notes_master):\n            \"\"\"\n            Generate a reference to each placeholder in *notes_master* that\n            should be cloned to a notes slide when the a new notes slide is\n            created.\n            \"\"\"\n            cloneable = (\n                PP_PLACEHOLDER.SLIDE_IMAGE,\n                PP_PLACEHOLDER.BODY,\n                PP_PLACEHOLDER.SLIDE_NUMBER,\n            )\n            for placeholder in notes_master.placeholders:\n                if placeholder.element.ph_type in cloneable:\n                    yield placeholder\n\n        shapes = self.shapes\n        for placeholder in iter_cloneable_placeholders(notes_master):\n            shapes.clone_placeholder(placeholder)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notes_placeholder(self):\n        for placeholder in self.placeholders:\n            if placeholder.placeholder_format.type == PP_PLACEHOLDER.BODY:\n                return placeholder\n        return None", "response": "Return the notes placeholder on this notes slide the shape that contains the actual notes text."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a slide to the book.", "response": "def add_slide(self, slide_layout):\n        \"\"\"\n        Return a newly added slide that inherits layout from *slide_layout*.\n        \"\"\"\n        rId, slide = self.part.add_slide(slide_layout)\n        slide.shapes.clone_layout_placeholders(slide_layout)\n        self._sldIdLst.add_sldId(rId)\n        return slide"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the slide identified by integer slide_id in this presentation or default if not found.", "response": "def get(self, slide_id, default=None):\n        \"\"\"\n        Return the slide identified by integer *slide_id* in this\n        presentation, or *default* if not found.\n        \"\"\"\n        slide = self.part.get_slide(slide_id)\n        if slide is None:\n            return default\n        return slide"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index(self, slide):\n        for idx, this_slide in enumerate(self):\n            if this_slide == slide:\n                return idx\n        raise ValueError('%s is not in slide collection' % slide)", "response": "Returns the index of a given entry in the collection. Raises |ValueError| on the non - present entry."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_cloneable_placeholders(self):\n        latent_ph_types = (\n            PP_PLACEHOLDER.DATE, PP_PLACEHOLDER.FOOTER,\n            PP_PLACEHOLDER.SLIDE_NUMBER\n        )\n        for ph in self.placeholders:\n            if ph.element.ph_type not in latent_ph_types:\n                yield ph", "response": "Iterate over the cloneable placeholders."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a SlideLayout object having the specified name or default if not found.", "response": "def get_by_name(self, name, default=None):\n        \"\"\"Return SlideLayout object having *name* or *default* if not found.\"\"\"\n        for slide_layout in self:\n            if slide_layout.name == name:\n                return slide_layout\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn zero - based index of slide_layout in this collection.", "response": "def index(self, slide_layout):\n        \"\"\"Return zero-based index of *slide_layout* in this collection.\n\n        Raises ValueError if *slide_layout* is not present in this collection.\n        \"\"\"\n        for idx, this_layout in enumerate(self):\n            if slide_layout == this_layout:\n                return idx\n        raise ValueError(\"layout not in this SlideLayouts collection\")"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef remove(self, slide_layout):\n        # ---raise if layout is in use---\n        if slide_layout.used_by_slides:\n            raise ValueError('cannot remove slide-layout in use by one or more slides')\n\n        # ---target layout is identified by its index in this collection---\n        target_idx = self.index(slide_layout)\n\n        # --remove layout from p:sldLayoutIds of its master\n        # --this stops layout from showing up, but doesn't remove it from package\n        target_sldLayoutId = self._sldLayoutIdLst.sldLayoutId_lst[target_idx]\n        self._sldLayoutIdLst.remove(target_sldLayoutId)\n\n        # --drop relationship from master to layout\n        # --this removes layout from package, along with everything (only) it refers to,\n        # --including images (not used elsewhere) and hyperlinks\n        slide_layout.slide_master.part.drop_rel(target_sldLayoutId.rId)", "response": "Removes a slide layout from the collection."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn |Slides| object containing the slides in this presentation.", "response": "def slides(self):\n        \"\"\"\n        |Slides| object containing the slides in this presentation.\n        \"\"\"\n        sldIdLst = self._element.get_or_add_sldIdLst()\n        self.part.rename_slide_parts([sldId.rId for sldId in sldIdLst])\n        return Slides(sldIdLst, self)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the c : tx [ c : rich ] subtree newly created if not present.", "response": "def get_or_add_tx_rich(self):\n        \"\"\"\n        Return the `c:tx[c:rich]` subtree, newly created if not present.\n        \"\"\"\n        tx = self.get_or_add_tx()\n        tx._remove_strRef()\n        tx.get_or_add_rich()\n        return tx"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef remove_tx_rich(self):\n        matches = self.xpath('c:tx[c:rich]')\n        if not matches:\n            return\n        tx = matches[0]\n        self.remove(tx)", "response": "Remove any c : tx child or do nothing."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_add_dLbl_for_point(self, idx):\n        matches = self.xpath('c:dLbl[c:idx[@val=\"%d\"]]' % idx)\n        if matches:\n            return matches[0]\n        return self._insert_dLbl_in_sequence(idx)", "response": "Get the c : dLbl element representing the label of the point at the given index. If the index is not found add it."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ninserts a new entry in the dLbl element with the specified index and return it.", "response": "def _insert_dLbl_in_sequence(self, idx):\n        \"\"\"\n        Return a newly created `c:dLbl` element having `c:idx` child of *idx*\n        and inserted in numeric sequence among the `c:dLbl` children of this\n        element.\n        \"\"\"\n        new_dLbl = self._new_dLbl()\n        new_dLbl.idx.val = idx\n\n        dLbl = None\n        for dLbl in self.dLbl_lst:\n            if dLbl.idx_val > idx:\n                dLbl.addprevious(new_dLbl)\n                return new_dLbl\n        if dLbl is not None:\n            dLbl.addnext(new_dLbl)\n        else:\n            self.insert(0, new_dLbl)\n        return new_dLbl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nsetting the value of the max child element of the current entry.", "response": "def maximum(self, value):\n        \"\"\"\n        Set the value of the ``<c:max>`` child element to the float *value*,\n        or remove the max element if *value* is |None|.\n        \"\"\"\n        self._remove_max()\n        if value is None:\n            return\n        self._add_max(val=value)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the value of the <c : min child element to the specified value.", "response": "def minimum(self, value):\n        \"\"\"\n        Set the value of the ``<c:min>`` child element to the float *value*,\n        or remove the min element if *value* is |None|.\n        \"\"\"\n        self._remove_min()\n        if value is None:\n            return\n        self._add_min(val=value)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a |FreeformBuilder| object.", "response": "def new(cls, shapes, start_x, start_y, x_scale, y_scale):\n        \"\"\"Return a new |FreeformBuilder| object.\n\n        The initial pen location is specified (in local coordinates) by\n        (*start_x*, *start_y*).\n        \"\"\"\n        return cls(\n            shapes, int(round(start_x)), int(round(start_y)),\n            x_scale, y_scale\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_line_segments(self, vertices, close=True):\n        for x, y in vertices:\n            self._add_line_segment(x, y)\n        if close:\n            self._add_close()\n        return self", "response": "Add a straight line segment to each point in vertices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a new freeform shape positioned relative to specified offset.", "response": "def convert_to_shape(self, origin_x=0, origin_y=0):\n        \"\"\"Return new freeform shape positioned relative to specified offset.\n\n        *origin_x* and *origin_y* locate the origin of the local coordinate\n        system in slide coordinates (EMU), perhaps most conveniently by use\n        of a |Length| object.\n\n        Note that this method may be called more than once to add multiple\n        shapes of the same geometry in different locations on the slide.\n        \"\"\"\n        sp = self._add_freeform_sp(origin_x, origin_y)\n        path = self._start_path(sp)\n        for drawing_operation in self:\n            drawing_operation.apply_operation_to(path)\n        return self._shapes._shape_factory(sp)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nmoves pen to ( x y ) without drawing line. Returns this FreeformBuilder object so it can be used in chained FreeformBuilder calls.", "response": "def move_to(self, x, y):\n        \"\"\"Move pen to (x, y) (local coordinates) without drawing line.\n\n        Returns this |FreeformBuilder| object so it can be used in chained\n        calls.\n        \"\"\"\n        self._drawing_operations.append(_MoveTo.new(self, x, y))\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns x distance of shape origin from local coordinate origin.", "response": "def shape_offset_x(self):\n        \"\"\"Return x distance of shape origin from local coordinate origin.\n\n        The returned integer represents the leftmost extent of the freeform\n        shape, in local coordinates. Note that the bounding box of the shape\n        need not start at the local origin.\n        \"\"\"\n        min_x = self._start_x\n        for drawing_operation in self:\n            if hasattr(drawing_operation, 'x'):\n                min_x = min(min_x, drawing_operation.x)\n        return min_x"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef shape_offset_y(self):\n        min_y = self._start_y\n        for drawing_operation in self:\n            if hasattr(drawing_operation, 'y'):\n                min_y = min(min_y, drawing_operation.y)\n        return min_y", "response": "Return y distance of shape origin from local coordinate origin."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _add_freeform_sp(self, origin_x, origin_y):\n        spTree = self._shapes._spTree\n        return spTree.add_freeform_sp(\n            origin_x + self._left,\n            origin_y + self._top,\n            self._width,\n            self._height\n        )", "response": "Add a freeform p : sp element having no drawing elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_line_segment(self, x, y):\n        self._drawing_operations.append(_LineSegment.new(self, x, y))", "response": "Add a |_LineSegment| operation to the drawing sequence."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns integer width of this shape s path in local units.", "response": "def _dx(self):\n        \"\"\"Return integer width of this shape's path in local units.\"\"\"\n        min_x = max_x = self._start_x\n        for drawing_operation in self:\n            if hasattr(drawing_operation, 'x'):\n                min_x = min(min_x, drawing_operation.x)\n                max_x = max(max_x, drawing_operation.x)\n        return max_x - min_x"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns integer height of this shape s path in local units.", "response": "def _dy(self):\n        \"\"\"Return integer height of this shape's path in local units.\"\"\"\n        min_y = max_y = self._start_y\n        for drawing_operation in self:\n            if hasattr(drawing_operation, 'y'):\n                min_y = min(min_y, drawing_operation.y)\n                max_y = max(max_y, drawing_operation.y)\n        return max_y - min_y"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _local_to_shape(self, local_x, local_y):\n        return (\n            local_x - self.shape_offset_x,\n            local_y - self.shape_offset_y\n        )", "response": "Translate local coordinates point to shape coordinates."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a newly created path element added to *sp*.", "response": "def _start_path(self, sp):\n        \"\"\"Return a newly created `a:path` element added to *sp*.\n\n        The returned `a:path` element has an `a:moveTo` element representing\n        the shape starting point as its only child.\n        \"\"\"\n        path = sp.add_path(w=self._dx, h=self._dy)\n        path.add_moveTo(\n            *self._local_to_shape(\n                self._start_x, self._start_y\n            )\n        )\n        return path"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a new _LineSegment object ending at point x and y.", "response": "def new(cls, freeform_builder, x, y):\n        \"\"\"Return a new _LineSegment object ending at point *(x, y)*.\n\n        Both *x* and *y* are rounded to the nearest integer before use.\n        \"\"\"\n        return cls(freeform_builder, int(round(x)), int(round(y)))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd a : lnTo element to the path.", "response": "def apply_operation_to(self, path):\n        \"\"\"Add `a:lnTo` element to *path* for this line segment.\n\n        Returns the `a:lnTo` element newly added to the path.\n        \"\"\"\n        return path.add_lnTo(\n            self._x - self._freeform_builder.shape_offset_x,\n            self._y - self._freeform_builder.shape_offset_y\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_fill_parent(cls, eg_fillProperties_parent):\n        fill_elm = eg_fillProperties_parent.eg_fillProperties\n        fill = _Fill(fill_elm)\n        fill_format = cls(eg_fillProperties_parent, fill)\n        return fill_format", "response": "Create a |FillFormat| instance initialized to the settings contained\n        in eg_fillProperties_parent."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef background(self):\n        noFill = self._xPr.get_or_change_to_noFill()\n        self._fill = _NoFill(noFill)", "response": "Sets the fill type to noFill i. e. transparent."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset the fill type to gradient.", "response": "def gradient(self):\n        \"\"\"Sets the fill type to gradient.\n\n        If the fill is not already a gradient, a default gradient is added.\n        The default gradient corresponds to the default in the built-in\n        PowerPoint \"White\" template. This gradient is linear at angle\n        90-degrees (upward), with two stops. The first stop is Accent-1 with\n        tint 100%, shade 100%, and satMod 130%. The second stop is Accent-1\n        with tint 50%, shade 100%, and satMod 350%.\n        \"\"\"\n        gradFill = self._xPr.get_or_change_to_gradFill()\n        self._fill = _GradFill(gradFill)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef patterned(self):\n        pattFill = self._xPr.get_or_change_to_pattFill()\n        self._fill = _PattFill(pattFill)", "response": "Selects the pattern fill type."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting the fill type to solid.", "response": "def solid(self):\n        \"\"\"\n        Sets the fill type to solid, i.e. a solid color. Note that calling\n        this method does not set a color or by itself cause the shape to\n        appear with a solid color fill; rather it enables subsequent\n        assignments to properties like fore_color to set the color.\n        \"\"\"\n        solidFill = self._xPr.get_or_change_to_solidFill()\n        self._fill = _SolidFill(solidFill)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef gradient_angle(self):\n        # ---case 1: gradient path is explicit, but not linear---\n        path = self._gradFill.path\n        if path is not None:\n            raise ValueError('not a linear gradient')\n\n        # ---case 2: gradient path is inherited (no a:lin OR a:path)---\n        lin = self._gradFill.lin\n        if lin is None:\n            return None\n\n        # ---case 3: gradient path is explicitly linear---\n        # angle is stored in XML as a clockwise angle, whereas the UI\n        # reports it as counter-clockwise from horizontal-pointing-right.\n        # Since the UI is consistent with trigonometry conventions, we\n        # respect that in the API.\n        clockwise_angle = lin.ang\n        counter_clockwise_angle = (\n            0.0 if clockwise_angle == 0.0\n            else (360.0 - clockwise_angle)\n        )\n        return counter_clockwise_angle", "response": "Return the angle in degrees of the gradient of the current weexpect entry."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef format(self):\n        dPt = self._ser.get_or_add_dPt_for_point(self._idx)\n        return ChartFormat(dPt)", "response": "Returns |ChartFormat| object providing access to the shape formatting\n        properties of this data point."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef marker(self):\n        dPt = self._ser.get_or_add_dPt_for_point(self._idx)\n        return Marker(dPt)", "response": "Returns a |Marker| instance for this point providing access to the visual\n        properties of the data point marker."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_autoshape(self, id_, name, prst, x, y, cx, cy):\n        sp = CT_Shape.new_autoshape_sp(id_, name, prst, x, y, cx, cy)\n        self.insert_element_before(sp, 'p:extLst')\n        return sp", "response": "Add a new autoshape to the group or shapetree"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_cxnSp(self, id_, name, type_member, x, y, cx, cy, flipH, flipV):\n        prst = MSO_CONNECTOR_TYPE.to_xml(type_member)\n        cxnSp = CT_Connector.new_cxnSp(\n            id_, name, prst, x, y, cx, cy, flipH, flipV\n        )\n        self.insert_element_before(cxnSp, 'p:extLst')\n        return cxnSp", "response": "Add a new CXN shape to the group or shapetree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nappends a new freeform p : sp with specified position and size.", "response": "def add_freeform_sp(self, x, y, cx, cy):\n        \"\"\"Append a new freeform `p:sp` with specified position and size.\"\"\"\n        shape_id = self._next_shape_id\n        name = 'Freeform %d' % (shape_id-1,)\n        sp = CT_Shape.new_freeform_sp(shape_id, name, x, y, cx, cy)\n        self.insert_element_before(sp, 'p:extLst')\n        return sp"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef add_grpSp(self):\n        shape_id = self._next_shape_id\n        name = 'Group %d' % (shape_id-1,)\n        grpSp = CT_GroupShape.new_grpSp(shape_id, name)\n        self.insert_element_before(grpSp, 'p:extLst')\n        return grpSp", "response": "Return a new group shape element newly appended to this shape tree."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_pic(self, id_, name, desc, rId, x, y, cx, cy):\n        pic = CT_Picture.new_pic(id_, name, desc, rId, x, y, cx, cy)\n        self.insert_element_before(pic, 'p:extLst')\n        return pic", "response": "Add a new picture to the group or shapetree."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_placeholder(self, id_, name, ph_type, orient, sz, idx):\n        sp = CT_Shape.new_placeholder_sp(\n            id_, name, ph_type, orient, sz, idx\n        )\n        self.insert_element_before(sp, 'p:extLst')\n        return sp", "response": "Append a new placeholder shape having the specified placeholder properties."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_table(self, id_, name, rows, cols, x, y, cx, cy):\n        graphicFrame = CT_GraphicalObjectFrame.new_table_graphicFrame(\n            id_, name, rows, cols, x, y, cx, cy\n        )\n        self.insert_element_before(graphicFrame, 'p:extLst')\n        return graphicFrame", "response": "Add a table to the GraphicalObjectFrame."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_textbox(self, id_, name, x, y, cx, cy):\n        sp = CT_Shape.new_textbox_sp(id_, name, x, y, cx, cy)\n        self.insert_element_before(sp, 'p:extLst')\n        return sp", "response": "Append a new textbox shape having the specified id_ name x y cx cy."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_shape_elms(self):\n        for elm in self.iterchildren():\n            if elm.tag in self._shape_tags:\n                yield elm", "response": "Iterate over the elements that are part of a shape."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef max_shape_id(self):\n        id_str_lst = self.xpath('//@id')\n        used_ids = [int(id_str) for id_str in id_str_lst if id_str.isdigit()]\n        return max(used_ids) if used_ids else 0", "response": "Maximum int value assigned as @id in this slide."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns new loose group sp element having id_ and name.", "response": "def new_grpSp(cls, id_, name):\n        \"\"\"Return new \"loose\" `p:grpSp` element having *id_* and *name*.\"\"\"\n        xml = (\n            '<p:grpSp %s>\\n'\n            '  <p:nvGrpSpPr>\\n'\n            '    <p:cNvPr id=\"%%d\" name=\"%%s\"/>\\n'\n            '    <p:cNvGrpSpPr/>\\n'\n            '    <p:nvPr/>\\n'\n            '  </p:nvGrpSpPr>\\n'\n            '  <p:grpSpPr>\\n'\n            '    <a:xfrm>\\n'\n            '      <a:off x=\"0\" y=\"0\"/>\\n'\n            '      <a:ext cx=\"0\" cy=\"0\"/>\\n'\n            '      <a:chOff x=\"0\" y=\"0\"/>\\n'\n            '      <a:chExt cx=\"0\" cy=\"0\"/>\\n'\n            '    </a:xfrm>\\n'\n            '  </p:grpSpPr>\\n'\n            '</p:grpSp>' % nsdecls('a', 'p', 'r')\n        ) % (id_, name)\n        grpSp = parse_xml(xml)\n        return grpSp"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadjust x y cx and cy to incorporate all contained shapes.", "response": "def recalculate_extents(self):\n        \"\"\"Adjust x, y, cx, and cy to incorporate all contained shapes.\n\n        This would typically be called when a contained shape is added,\n        removed, or its position or size updated.\n\n        This method is recursive \"upwards\" since a change in a group shape\n        can change the position and size of its containing group.\n        \"\"\"\n        if not self.tag == qn('p:grpSp'):\n            return\n\n        x, y, cx, cy = self._child_extents\n\n        self.chOff.x = self.x = x\n        self.chOff.y = self.y = y\n        self.chExt.cx = self.cx = cx\n        self.chExt.cy = self.cy = cy\n        self.getparent().recalculate_extents()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _child_extents(self):\n        child_shape_elms = list(self.iter_shape_elms())\n\n        if not child_shape_elms:\n            return Emu(0), Emu(0), Emu(0), Emu(0)\n\n        min_x = min([xSp.x for xSp in child_shape_elms])\n        min_y = min([xSp.y for xSp in child_shape_elms])\n        max_x = max([(xSp.x + xSp.cx) for xSp in child_shape_elms])\n        max_y = max([(xSp.y + xSp.cy) for xSp in child_shape_elms])\n\n        x = min_x\n        y = min_y\n        cx = max_x - min_x\n        cy = max_y - min_y\n\n        return x, y, cx, cy", "response": "Returns x y cx cy tuple representing net position and size."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning unique shape id suitable for use with a new shape element.", "response": "def _next_shape_id(self):\n        \"\"\"Return unique shape id suitable for use with a new shape element.\n\n        The returned id is the next available positive integer drawing object\n        id in shape tree, starting from 1 and making use of any gaps in\n        numbering. In practice, the minimum id is 2 because the spTree\n        element itself is always assigned id=\"1\".\n        \"\"\"\n        id_str_lst = self.xpath('//@id')\n        used_ids = [int(id_str) for id_str in id_str_lst if id_str.isdigit()]\n        for n in range(1, len(used_ids)+2):\n            if n not in used_ids:\n                return n"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_legend(self, bool_value):\n        if bool(bool_value) is False:\n            self._remove_legend()\n        else:\n            if self.legend is None:\n                self._add_legend()", "response": "Check if the current state of the legend element is present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef new_chart(rId):\n        xml = CT_Chart._chart_tmpl % (rId)\n        chart = parse_xml(xml)\n        return chart", "response": "Return a new chart element with the given id"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _add_externalData(self):\n        externalData = self._new_externalData()\n        externalData._add_autoUpdate(val=False)\n        self._insert_externalData(externalData)\n        return externalData", "response": "Add an external data entry to the internal data."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\niterates over the xCharts of the current object.", "response": "def iter_xCharts(self):\n        \"\"\"\n        Generate each xChart child element in document.\n        \"\"\"\n        plot_tags = (\n            qn('c:area3DChart'), qn('c:areaChart'), qn('c:bar3DChart'),\n            qn('c:barChart'), qn('c:bubbleChart'), qn('c:doughnutChart'),\n            qn('c:line3DChart'), qn('c:lineChart'), qn('c:ofPieChart'),\n            qn('c:pie3DChart'), qn('c:pieChart'), qn('c:radarChart'),\n            qn('c:scatterChart'), qn('c:stockChart'), qn('c:surface3DChart'),\n            qn('c:surfaceChart')\n        )\n\n        for child in self.iterchildren():\n            if child.tag not in plot_tags:\n                continue\n            yield child"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the last ser element in the last xChart element based on series order.", "response": "def last_ser(self):\n        \"\"\"\n        Return the last `<c:ser>` element in the last xChart element, based\n        on series order (not necessarily the same element as document order).\n        \"\"\"\n        last_xChart = self.xCharts[-1]\n        sers = last_xChart.sers\n        if not sers:\n            return None\n        return sers[-1]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef next_idx(self):\n        idx_vals = [s.idx.val for s in self.sers]\n        if not idx_vals:\n            return 0\n        return max(idx_vals)+1", "response": "Return the next available idx value within the scope of\n        this chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef next_order(self):\n        order_vals = [s.order.val for s in self.sers]\n        if not order_vals:\n            return 0\n        return max(order_vals)+1", "response": "Return the next available order value within the scope of\n        this chart"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef cell(self, row_idx, col_idx):\n        return _Cell(self._tbl.tc(row_idx, col_idx), self)", "response": "Return a |_Cell| object at the given row and column indices."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalling by a row when its height changes triggering the graphic frame to recalculate its total height.", "response": "def notify_height_changed(self):\n        \"\"\"\n        Called by a row when its height changes, triggering the graphic frame\n        to recalculate its total height (as the sum of the row heights).\n        \"\"\"\n        new_table_height = sum([row.height for row in self.rows])\n        self._graphic_frame.height = new_table_height"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef notify_width_changed(self):\n        new_table_width = sum([col.width for col in self.columns])\n        self._graphic_frame.width = new_table_width", "response": "Called by a column when its width changes triggering the graphic\n        frame to recalculate its total width."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate merged cell from this cell to other_cell.", "response": "def merge(self, other_cell):\n        \"\"\"Create merged cell from this cell to *other_cell*.\n\n        This cell and *other_cell* specify opposite corners of the merged\n        cell range. Either diagonal of the cell region may be specified in\n        either order, e.g. self=bottom-right, other_cell=top-left, etc.\n\n        Raises |ValueError| if the specified range already contains merged\n        cells anywhere within its extents or if *other_cell* is not in the\n        same table as *self*.\n        \"\"\"\n        tc_range = TcRange(self._tc, other_cell._tc)\n\n        if not tc_range.in_same_table:\n            raise ValueError('other_cell from different table')\n        if tc_range.contains_merged_cell:\n            raise ValueError('range contains one or more merged cells')\n\n        tc_range.move_content_to_origin()\n\n        row_count, col_count = tc_range.dimensions\n\n        for tc in tc_range.iter_top_row_tcs():\n            tc.rowSpan = row_count\n        for tc in tc_range.iter_left_col_tcs():\n            tc.gridSpan = col_count\n        for tc in tc_range.iter_except_left_col_tcs():\n            tc.hMerge = True\n        for tc in tc_range.iter_except_top_row_tcs():\n            tc.vMerge = True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef split(self):\n        if not self.is_merge_origin:\n            raise ValueError(\n                'not a merge-origin cell; only a merge-origin cell can be sp'\n                'lit'\n            )\n\n        tc_range = TcRange.from_merge_origin(self._tc)\n\n        for tc in tc_range.iter_tcs():\n            tc.rowSpan = tc.gridSpan = 1\n            tc.hMerge = tc.vMerge = False", "response": "Split this cell into two cells."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a new |EmbeddedXlsxPart| instance added to *package* and containing xlsx_blob*.", "response": "def new(cls, xlsx_blob, package):\n        \"\"\"\n        Return a new |EmbeddedXlsxPart| instance added to *package* and\n        containing *xlsx_blob*.\n        \"\"\"\n        partname = package.next_partname(cls.partname_template)\n        content_type = CT.SML_SHEET\n        xlsx_part = cls(partname, content_type, xlsx_blob, package)\n        return xlsx_part"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef OxmlElement(nsptag_str, nsmap=None):\n    nsptag = NamespacePrefixedTag(nsptag_str)\n    nsmap = nsmap if nsmap is not None else nsptag.nsmap\n    return oxml_parser.makeelement(nsptag.clark_name, nsmap=nsmap)", "response": "Return a loose lxml element having the specified tag specified by nsptag_str."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nremoves all child elements having tagname in tagnames*.", "response": "def remove_if_present(self, *tagnames):\n        \"\"\"\n        Remove all child elements having tagname in *tagnames*.\n        \"\"\"\n        for tagname in tagnames:\n            element = self.find(qn(tagname))\n            if element is not None:\n                self.remove(element)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\noverride of lxml. _Element. xpath method to provide standard Open XML namespace mapping in centralized location.", "response": "def xpath(self, xpath_str):\n        \"\"\"\n        Override of ``lxml`` _Element.xpath() method to provide standard Open\n        XML namespace mapping in centralized location.\n        \"\"\"\n        return super(BaseOxmlElement, self).xpath(\n            xpath_str, namespaces=_nsmap\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsetting a : srcRect child to crop according to cropping values.", "response": "def crop(self, cropping):\n        \"\"\"\n        Set `a:srcRect` child to crop according to *cropping* values.\n        \"\"\"\n        srcRect = self._add_srcRect()\n        srcRect.l, srcRect.t, srcRect.r, srcRect.b = cropping"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef color(self):\n        if self.fill.type != MSO_FILL.SOLID:\n            self.fill.solid()\n        return self.fill.fore_color", "response": "Returns |ColorFormat| instance that provides access to the color settings for this line."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn |ChartPart| object containing the chart in this graphic frame.", "response": "def chart_part(self):\n        \"\"\"\n        The |ChartPart| object containing the chart in this graphic frame.\n        \"\"\"\n        rId = self._element.chart_rId\n        chart_part = self.part.related_parts[rId]\n        return chart_part"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the type of the shape in this instance.", "response": "def shape_type(self):\n        \"\"\"\n        Unique integer identifying the type of this shape, e.g.\n        ``MSO_SHAPE_TYPE.TABLE``.\n        \"\"\"\n        if self.has_chart:\n            return MSO_SHAPE_TYPE.CHART\n        elif self.has_table:\n            return MSO_SHAPE_TYPE.TABLE\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef table(self):\n        if not self.has_table:\n            raise ValueError('shape does not contain a table')\n        tbl = self._element.graphic.graphicData.tbl\n        return Table(tbl, self)", "response": "Returns |Table| object contained in this graphic frame. Raises |ValueError| if this graphic frame does not contain a table."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _write_content_types_stream(phys_writer, parts):\n        content_types_blob = serialize_part_xml(\n            _ContentTypesItem.xml_for(parts)\n        )\n        phys_writer.write(CONTENT_TYPES_URI, content_types_blob)", "response": "Write the content types. xml part to the physical package with an appropriate content type lookup target for each part in parts."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xml_for(cls, parts):\n        cti = cls()\n        cti._defaults['rels'] = CT.OPC_RELATIONSHIPS\n        cti._defaults['xml'] = CT.XML\n        for part in parts:\n            cti._add_content_type(part.partname, part.content_type)\n        return cti._xml()", "response": "Return content types XML mapping each part in parts to the\n        appropriate content type and suitable for storage as a OPC package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a width height pair representing the size of text in English Metric Units when rendered at point_size.", "response": "def _rendered_size(text, point_size, font_file):\n    \"\"\"\n    Return a (width, height) pair representing the size of *text* in English\n    Metric Units (EMU) when rendered at *point_size* in the font defined in\n    *font_file*.\n    \"\"\"\n    emu_per_inch = 914400\n    px_per_inch = 72.0\n\n    font = _Fonts.font(font_file, point_size)\n    px_width, px_height = font.getsize(text)\n\n    emu_width = int(px_width / px_per_inch * emu_per_inch)\n    emu_height = int(px_height / px_per_inch * emu_per_inch)\n\n    return emu_width, emu_height"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the largest whole - number point size less than or equal to or equal to max_size that allows text to fit completely within extents.", "response": "def best_fit_font_size(cls, text, extents, max_size, font_file):\n        \"\"\"\n        Return the largest whole-number point size less than or equal to\n        *max_size* that allows *text* to fit completely within *extents* when\n        rendered using font defined in *font_file*.\n        \"\"\"\n        line_source = _LineSource(text)\n        text_fitter = cls(line_source, extents, font_file)\n        return text_fitter._best_fit_font_size(max_size)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _best_fit_font_size(self, max_size):\n        predicate = self._fits_inside_predicate\n        sizes = _BinarySearchTree.from_ordered_sequence(\n            range(1, int(max_size)+1)\n        )\n        return sizes.find_max(predicate)", "response": "Return the largest font size less than or equal to max_size that this fitter can fit."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nbreaking a line into two lines.", "response": "def _break_line(self, line_source, point_size):\n        \"\"\"\n        Return a (line, remainder) pair where *line* is the longest line in\n        *line_source* that will fit in this fitter's width and *remainder* is\n        a |_LineSource| object containing the text following the break point.\n        \"\"\"\n        lines = _BinarySearchTree.from_ordered_sequence(line_source)\n        predicate = self._fits_in_width_predicate(point_size)\n        return lines.find_max(predicate)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn a predicate that returns |True| if the text of a line of the given size is less than or equal to the width of the fitter.", "response": "def _fits_in_width_predicate(self, point_size):\n        \"\"\"\n        Return a function taking a text string value and returns |True| if\n        that text fits in this fitter when rendered at *point_size*. Used as\n        predicate for _break_line()\n        \"\"\"\n        def predicate(line):\n            \"\"\"\n            Return |True| if *line* fits in this fitter when rendered at\n            *point_size*.\n            \"\"\"\n            cx = _rendered_size(line.text, point_size, self._font_file)[0]\n            return cx <= self._width\n\n        return predicate"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _fits_inside_predicate(self):\n        def predicate(point_size):\n            \"\"\"\n            Return |True| if the text in *line_source* can be wrapped to fit\n            entirely within *extents* when rendered at *point_size* using the\n            font defined in *font_file*.\n            \"\"\"\n            text_lines = self._wrap_lines(self._line_source, point_size)\n            cy = _rendered_size('Ty', point_size, self._font_file)[1]\n            return (cy * len(text_lines)) <= self._height\n\n        return predicate", "response": "Returns a function that returns |True| if the text in this fitter fits entirely within its extents."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nwrap the lines in the given line_source into a sequence of str values representing the text that is rendered within this fitter when rendered at point_size.", "response": "def _wrap_lines(self, line_source, point_size):\n        \"\"\"\n        Return a sequence of str values representing the text in\n        *line_source* wrapped within this fitter when rendered at\n        *point_size*.\n        \"\"\"\n        text, remainder = self._break_line(line_source, point_size)\n        lines = [text]\n        if remainder:\n            lines.extend(self._wrap_lines(remainder, point_size))\n        return lines"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef find_max(self, predicate, max_=None):\n        if predicate(self.value):\n            max_ = self.value\n            next_node = self._greater\n        else:\n            next_node = self._lesser\n        if next_node is None:\n            return max_\n        return next_node.find_max(predicate, max_)", "response": "Find the largest item in or under this node that satisfies the predicate."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a balanced binary search tree populated with the values in iterable iseq.", "response": "def from_ordered_sequence(cls, iseq):\n        \"\"\"\n        Return the root of a balanced binary search tree populated with the\n        values in iterable *iseq*.\n        \"\"\"\n        seq = list(iseq)\n        # optimize for usually all fits by making longest first\n        bst = cls(seq.pop())\n        bst._insert_from_ordered_sequence(seq)\n        return bst"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ninsert a new node containing value into this tree.", "response": "def insert(self, value):\n        \"\"\"\n        Insert a new node containing *value* into this tree such that its\n        structure as a binary search tree is preserved.\n        \"\"\"\n        side = '_lesser' if value < self.value else '_greater'\n        child = getattr(self, side)\n        if child is None:\n            setattr(self, side, _BinarySearchTree(value))\n        else:\n            child.insert(value)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef tree(self, level=0, prefix=''):\n        text = '%s%s\\n' % (prefix, self.value.text)\n        prefix = '%s\u2514\u2500\u2500 ' % ('    ' * level)\n        if self._lesser:\n            text += self._lesser.tree(level+1, prefix)\n        if self._greater:\n            text += self._greater.tree(level+1, prefix)\n        return text", "response": "Returns a string representation of the tree rooted in this node."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the first two elements of a list of unique keys in a sequence.", "response": "def _bisect(seq):\n        \"\"\"\n        Return a (medial_value, greater_values, lesser_values) 3-tuple\n        obtained by bisecting sequence *seq*.\n        \"\"\"\n        if len(seq) == 0:\n            return [], None, []\n        mid_idx = int(len(seq)/2)\n        mid = seq[mid_idx]\n        greater = seq[mid_idx+1:]\n        lesser = seq[:mid_idx]\n        return mid, greater, lesser"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _insert_from_ordered_sequence(self, seq):\n        if len(seq) == 0:\n            return\n        mid, greater, lesser = self._bisect(seq)\n        self.insert(mid)\n        self._insert_from_ordered_sequence(greater)\n        self._insert_from_ordered_sequence(lesser)", "response": "Insert the new values contained in seq into the ordered tree."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef flattened_labels(self):\n        cat = self._xChart.cat\n        if cat is None:\n            return ()\n\n        if cat.multiLvlStrRef is None:\n            return tuple([(category.label,) for category in self])\n\n        return tuple(\n            [tuple([category.label for category in reversed(flat_cat)])\n             for flat_cat in self._iter_flattened_categories()]\n        )", "response": "Return a sequence of tuples each containing the flattened hierarchy\n        of category labels for a leaf category."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef levels(self):\n        cat = self._xChart.cat\n        if cat is None:\n            return []\n        return [CategoryLevel(lvl) for lvl in cat.lvls]", "response": "Return a sequence of |CategoryLevel| objects representing the hierarchy of this category collection."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _iter_flattened_categories(self):\n        levels = self.levels\n        if not levels:\n            return\n        leaf_level, remaining_levels = levels[0], levels[1:]\n        for category in leaf_level:\n            yield self._parentage((category,), remaining_levels)", "response": "Iterate over the categories in the current tree that are flattened."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a tuple formed by recursively concatenating categories with the next ancestor from levels.", "response": "def _parentage(self, categories, levels):\n        \"\"\"\n        Return a tuple formed by recursively concatenating *categories* with\n        its next ancestor from *levels*. The idx value of the first category\n        in *categories* determines parentage in all levels. The returned\n        sequence is in child -> parent order. A parent category is the\n        Category object in a next level having the maximum idx value not\n        exceeding that of the leaf category.\n        \"\"\"\n        # exhausting levels is the expected recursion termination condition\n        if not levels:\n            return tuple(categories)\n\n        # guard against edge case where next level is present but empty. That\n        # situation is not prohibited for some reason.\n        if not levels[0]:\n            return tuple(categories)\n\n        parent_level, remaining_levels = levels[0], levels[1:]\n        leaf_node = categories[0]\n\n        # Make the first parent the default. A possible edge case is where no\n        # parent is defined for one or more leading values, e.g. idx > 0 for\n        # the first parent.\n        parent = parent_level[0]\n        for category in parent_level:\n            if category.idx > leaf_node.idx:\n                break\n            parent = category\n\n        extended_categories = tuple(categories) + (parent,)\n        return self._parentage(extended_categories, remaining_levels)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new(cls, chart_type, chart_data, package):\n        chart_blob = chart_data.xml_bytes(chart_type)\n        partname = package.next_partname(cls.partname_template)\n        content_type = CT.DML_CHART\n        chart_part = cls.load(partname, content_type, chart_blob, package)\n        xlsx_blob = chart_data.xlsx_blob\n        chart_part.chart_workbook.update_from_xlsx_blob(xlsx_blob)\n        return chart_part", "response": "Create a new |ChartPart| instance containing the given chart data and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates the internal |EmbeddedXlsxPart| object with the contents of the Excel file in xlsx_blob.", "response": "def update_from_xlsx_blob(self, xlsx_blob):\n        \"\"\"\n        Replace the Excel spreadsheet in the related |EmbeddedXlsxPart| with\n        the Excel binary in *xlsx_blob*, adding a new |EmbeddedXlsxPart| if\n        there isn't one.\n        \"\"\"\n        xlsx_part = self.xlsx_part\n        if xlsx_part is None:\n            self.xlsx_part = EmbeddedXlsxPart.new(xlsx_blob, self._package)\n            return\n        xlsx_part.blob = xlsx_blob"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the |EmbeddedXlsxPart| object having its rId or |None| if there is no xlsxPart object having its rId or None if there is no xlsxPart object having its rId or None if there is no xlsxPart object having its rId or None if there is no xlsxPart object having its rId or None if there is no xlsxPart object with rId at .", "response": "def xlsx_part(self):\n        \"\"\"\n        Return the related |EmbeddedXlsxPart| object having its rId at\n        `c:chartSpace/c:externalData/@rId` or |None| if there is no\n        `<c:externalData>` element.\n        \"\"\"\n        xlsx_part_rId = self._chartSpace.xlsx_part_rId\n        if xlsx_part_rId is None:\n            return None\n        return self._chart_part.related_parts[xlsx_part_rId]"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the related |EmbeddedXlsxPart| to xlsx_part. Assume one does not already exist.", "response": "def xlsx_part(self, xlsx_part):\n        \"\"\"\n        Set the related |EmbeddedXlsxPart| to *xlsx_part*. Assume one does\n        not already exist.\n        \"\"\"\n        rId = self._chart_part.relate_to(xlsx_part, RT.PACKAGE)\n        externalData = self._chartSpace.get_or_add_externalData()\n        externalData.rId = rId"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\niterating over the serialized parts of the current object.", "response": "def iter_sparts(self):\n        \"\"\"\n        Generate a 3-tuple `(partname, content_type, blob)` for each of the\n        serialized parts in the package.\n        \"\"\"\n        for spart in self._sparts:\n            yield (spart.partname, spart.content_type, spart.blob)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nload the serialized parts in the phys_reader.", "response": "def _load_serialized_parts(phys_reader, pkg_srels, content_types):\n        \"\"\"\n        Return a list of |_SerializedPart| instances corresponding to the\n        parts in *phys_reader* accessible by walking the relationship graph\n        starting with *pkg_srels*.\n        \"\"\"\n        sparts = []\n        part_walker = PackageReader._walk_phys_parts(phys_reader, pkg_srels)\n        for partname, blob, srels in part_walker:\n            content_type = content_types[partname]\n            spart = _SerializedPart(partname, content_type, blob, srels)\n            sparts.append(spart)\n        return tuple(sparts)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn |_SerializedRelationshipCollection| instance populated with relationships for source identified by source_uri.", "response": "def _srels_for(phys_reader, source_uri):\n        \"\"\"\n        Return |_SerializedRelationshipCollection| instance populated with\n        relationships for source identified by *source_uri*.\n        \"\"\"\n        rels_xml = phys_reader.rels_xml_for(source_uri)\n        return _SerializedRelationshipCollection.load_from_xml(\n            source_uri.baseURI, rels_xml)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _walk_phys_parts(phys_reader, srels, visited_partnames=None):\n        if visited_partnames is None:\n            visited_partnames = []\n        for srel in srels:\n            if srel.is_external:\n                continue\n            partname = srel.target_partname\n            if partname in visited_partnames:\n                continue\n            visited_partnames.append(partname)\n            part_srels = PackageReader._srels_for(phys_reader, partname)\n            blob = phys_reader.blob_for(partname)\n            yield (partname, blob, part_srels)\n            for partname, blob, srels in PackageReader._walk_phys_parts(\n                    phys_reader, part_srels, visited_partnames):\n                yield (partname, blob, srels)", "response": "Generate a 3 - tuple for each of the parts in the hierarchy of the given phys_reader."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_xml(content_types_xml):\n        types_elm = parse_xml(content_types_xml)\n        ct_map = _ContentTypeMap()\n        for o in types_elm.override_lst:\n            ct_map._add_override(o.partName, o.contentType)\n        for d in types_elm.default_lst:\n            ct_map._add_default(d.extension, d.contentType)\n        return ct_map", "response": "Parse the contents of content types xml into a |_ContentTypeMap| instance populated with the contents of content_types_xml."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nloads a _SerializedRelationshipCollection| instance from the given XML file.", "response": "def load_from_xml(baseURI, rels_item_xml):\n        \"\"\"\n        Return |_SerializedRelationshipCollection| instance loaded with the\n        relationships contained in *rels_item_xml*. Returns an empty\n        collection if *rels_item_xml* is |None|.\n        \"\"\"\n        srels = _SerializedRelationshipCollection()\n        if rels_item_xml is not None:\n            rels_elm = parse_xml(rels_item_xml)\n            for rel_elm in rels_elm.relationship_lst:\n                srels._srels.append(_SerializedRelationship(baseURI, rel_elm))\n        return srels"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _TableFactory(tag, stream, offset, length):\n    TableClass = {\n        'head': _HeadTable,\n        'name': _NameTable,\n    }.get(tag, _BaseTable)\n    return TableClass(tag, stream, offset, length)", "response": "Returns an instance of |Table| appropriate to tag and stream starting at offset."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef find(cls, family_name, is_bold, is_italic):\n        if cls._font_files is None:\n            cls._font_files = cls._installed_fonts()\n        return cls._font_files[(family_name, is_bold, is_italic)]", "response": "Return the absolute path to the installed OpenType font having the given family name and styles is_bold and is_italic."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a dict mapping a font descriptor to its font file path and all the font files resident on the current machine.", "response": "def _installed_fonts(cls):\n        \"\"\"\n        Return a dict mapping a font descriptor to its font file path,\n        containing all the font files resident on the current machine. The\n        font descriptor is a (family_name, is_bold, is_italic) 3-tuple.\n        \"\"\"\n        fonts = {}\n        for d in cls._font_directories():\n            for key, path in cls._iter_font_files_in(d):\n                fonts[key] = path\n        return fonts"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _font_directories(cls):\n        if sys.platform.startswith('darwin'):\n            return cls._os_x_font_directories()\n        if sys.platform.startswith('win32'):\n            return cls._windows_font_directories()\n        raise OSError('unsupported operating system')", "response": "Return a sequence of directories that likely to contain fonts on the current platform."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a sequence of directories on a Mac in which fonts are likely to be located.", "response": "def _os_x_font_directories(cls):\n        \"\"\"\n        Return a sequence of directory paths on a Mac in which fonts are\n        likely to be located.\n        \"\"\"\n        os_x_font_dirs = [\n            '/Library/Fonts',\n            '/Network/Library/Fonts',\n            '/System/Library/Fonts',\n        ]\n        home = os.environ.get('HOME')\n        if home is not None:\n            os_x_font_dirs.extend([\n                os.path.join(home, 'Library', 'Fonts'),\n                os.path.join(home, '.fonts')\n            ])\n        return os_x_font_dirs"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _iter_table_records(self):\n        count = self._table_count\n        bufr = self._stream.read(offset=12, length=count*16)\n        tmpl = '>4sLLL'\n        for i in range(count):\n            offset = i * 16\n            tag, checksum, off, len_ = unpack_from(tmpl, bufr, offset)\n            yield tag.decode('utf-8'), off, len_", "response": "Iterate over the table records in the current font file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _tables(self):\n        return dict(\n            (tag, _TableFactory(tag, self._stream, off, len_))\n            for tag, off, len_ in self._iter_table_records()\n        )", "response": "A dictionary mapping of OpenType table tag to a table object containing the contents of that table."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads length bytes from this stream starting at offset.", "response": "def read(self, offset, length):\n        \"\"\"\n        Return *length* bytes from this stream starting at *offset*.\n        \"\"\"\n        self._file.seek(offset)\n        return self._file.read(length)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreading the C - struct fields in this stream at the specified offset.", "response": "def read_fields(self, template, offset=0):\n        \"\"\"\n        Return a tuple containing the C-struct fields in this stream\n        specified by *template* and starting at *offset*.\n        \"\"\"\n        self._file.seek(offset)\n        bufr = self._file.read(calcsize(template))\n        return unpack_from(template, bufr)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the name of the typeface family for this font e. g. Arial.", "response": "def family_name(self):\n        \"\"\"\n        The name of the typeface family for this font, e.g. 'Arial'.\n        \"\"\"\n        def find_first(dict_, keys, default=None):\n            for key in keys:\n                value = dict_.get(key)\n                if value is not None:\n                    return value\n            return default\n        # keys for Unicode, Mac, and Windows family name, respectively\n        return find_first(self._names, ((0, 1), (1, 1), (3, 1)))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndecodes a unicode name from the raw_name using the platform_id implied by the combination of platform_id and encoding_id.", "response": "def _decode_name(raw_name, platform_id, encoding_id):\n        \"\"\"\n        Return the unicode name decoded from *raw_name* using the encoding\n        implied by the combination of *platform_id* and *encoding_id*.\n        \"\"\"\n        if platform_id == 1:\n            # reject non-Roman Mac font names\n            if encoding_id != 0:\n                return None\n            return raw_name.decode('mac-roman')\n        elif platform_id in (0, 3):\n            return raw_name.decode('utf-16-be')\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates a key - value pair for each name in this table.", "response": "def _iter_names(self):\n        \"\"\"\n        Generate a key/value pair for each name in this table. The key is a\n        (platform_id, name_id) 2-tuple and the value is the unicode text\n        corresponding to that key.\n        \"\"\"\n        table_format, count, strings_offset = self._table_header\n        table_bytes = self._table_bytes\n\n        for idx in range(count):\n            platform_id, name_id, name = self._read_name(\n                table_bytes, idx, strings_offset\n            )\n            if name is None:\n                continue\n            yield ((platform_id, name_id), name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the raw name string in the buffer at strings_offset.", "response": "def _raw_name_string(bufr, strings_offset, str_offset, length):\n        \"\"\"\n        Return the *length* bytes comprising the encoded string in *bufr* at\n        *str_offset* in the strings area beginning at *strings_offset*.\n        \"\"\"\n        offset = strings_offset + str_offset\n        tmpl = '%ds' % length\n        return unpack_from(tmpl, bufr, offset)[0]"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreads a name from the buffer and return a 3 - tuple like 0 1 Arial 0 0", "response": "def _read_name(self, bufr, idx, strings_offset):\n        \"\"\"\n        Return a (platform_id, name_id, name) 3-tuple like (0, 1, 'Arial')\n        for the name at *idx* position in *bufr*. *strings_offset* is the\n        index into *bufr* where actual name strings begin. The returned name\n        is a unicode string.\n        \"\"\"\n        platform_id, encoding_id, lang_id, name_id, length, str_offset = (\n            self._name_header(bufr, idx)\n        )\n        name = self._read_name_text(\n            bufr, platform_id, encoding_id, strings_offset, str_offset,\n            length\n        )\n        return platform_id, name_id, name"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _read_name_text(\n            self, bufr, platform_id, encoding_id, strings_offset,\n            name_str_offset, length):\n        \"\"\"\n        Return the unicode name string at *name_str_offset* or |None| if\n        decoding its format is not supported.\n        \"\"\"\n        raw_name = self._raw_name_string(\n            bufr, strings_offset, name_str_offset, length\n        )\n        return self._decode_name(raw_name, platform_id, encoding_id)", "response": "Reads the name text from the buffer and returns it."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns a new table element tree.", "response": "def new_tbl(cls, rows, cols, width, height, tableStyleId=None):\n        \"\"\"Return a new ``<p:tbl>`` element tree.\"\"\"\n        # working hypothesis is this is the default table style GUID\n        if tableStyleId is None:\n            tableStyleId = '{5C22544A-7EE6-4342-B048-85BDC9FD1C3A}'\n\n        xml = cls._tbl_tmpl() % (tableStyleId)\n        tbl = parse_xml(xml)\n\n        # add specified number of rows and columns\n        rowheight = height//rows\n        colwidth = width//cols\n\n        for col in range(cols):\n            # adjust width of last col to absorb any div error\n            if col == cols-1:\n                colwidth = width - ((cols-1) * colwidth)\n            tbl.tblGrid.add_gridCol(width=colwidth)\n\n        for row in range(rows):\n            # adjust height of last row to absorb any div error\n            if row == rows-1:\n                rowheight = height - ((rows-1) * rowheight)\n            tr = tbl.add_tr(height=rowheight)\n            for col in range(cols):\n                tr.add_tc()\n\n        return tbl"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngeneralizing getter for the boolean properties on the <a : tblPr> element. Defaults to False.", "response": "def _get_boolean_property(self, propname):\n        \"\"\"\n        Generalized getter for the boolean properties on the ``<a:tblPr>``\n        child element. Defaults to False if *propname* attribute is missing\n        or ``<a:tblPr>`` element itself is not present.\n        \"\"\"\n        tblPr = self.tblPr\n        if tblPr is None:\n            return False\n        propval = getattr(tblPr, propname)\n        return {\n            True:  True,\n            False: False,\n            None:  False\n        }[propval]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngeneralizes setter for boolean properties on the tblPr element.", "response": "def _set_boolean_property(self, propname, value):\n        \"\"\"\n        Generalized setter for boolean properties on the ``<a:tblPr>`` child\n        element, setting *propname* attribute appropriately based on *value*.\n        If *value* is True, the attribute is set to \"1\"; a tblPr child\n        element is added if necessary. If *value* is False, the *propname*\n        attribute is removed if present, allowing its default value of False\n        to be its effective value.\n        \"\"\"\n        if value not in (True, False):\n            raise ValueError(\n                \"assigned value must be either True or False, got %s\" %\n                value\n            )\n        tblPr = self.get_or_add_tblPr()\n        setattr(tblPr, propname, value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nset value of anchor attribute on tcPr element", "response": "def anchor(self, anchor_enum_idx):\n        \"\"\"\n        Set value of anchor attribute on ``<a:tcPr>`` child element\n        \"\"\"\n        if anchor_enum_idx is None and self.tcPr is None:\n            return\n        tcPr = self.get_or_add_tcPr()\n        tcPr.anchor = anchor_enum_idx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef append_ps_from(self, spanned_tc):\n        source_txBody = spanned_tc.get_or_add_txBody()\n        target_txBody = self.get_or_add_txBody()\n\n        # ---if source is empty, there's nothing to do---\n        if source_txBody.is_empty:\n            return\n\n        # ---a single empty paragraph in target is overwritten---\n        if target_txBody.is_empty:\n            target_txBody.clear_content()\n\n        for p in source_txBody.p_lst:\n            target_txBody.append(p)\n\n        # ---neither source nor target can be left without ps---\n        source_txBody.unclear_content()\n        target_txBody.unclear_content()", "response": "Append paragraphs from a spanned cell to the text - frame of this cell."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_merge_origin(self):\n        if self.gridSpan > 1 and not self.vMerge:\n            return True\n        if self.rowSpan > 1 and not self.hMerge:\n            return True\n        return False", "response": "True if cell is top - left in merged cell range."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngeneralizes method to get margin values.", "response": "def _get_marX(self, attr_name, default):\n        \"\"\"\n        Generalized method to get margin values.\n        \"\"\"\n        if self.tcPr is None:\n            return Emu(default)\n        return Emu(int(self.tcPr.get(attr_name, default)))"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsets value of marX attribute on tcPr element.", "response": "def _set_marX(self, marX, value):\n        \"\"\"\n        Set value of marX attribute on ``<a:tcPr>`` child element. If *marX*\n        is |None|, the marX attribute is removed. *marX* is a string, one of\n        ``('marL', 'marR', 'marT', 'marB')``.\n        \"\"\"\n        if value is None and self.tcPr is None:\n            return\n        tcPr = self.get_or_add_tcPr()\n        setattr(tcPr, marX, value)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef from_merge_origin(cls, tc):\n        other_tc = tc.tbl.tc(\n            tc.row_idx + tc.rowSpan - 1,  # ---other_row_idx\n            tc.col_idx + tc.gridSpan - 1  # ---other_col_idx\n        )\n        return cls(tc, other_tc)", "response": "Return instance created from merge - origin tc element."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef contains_merged_cell(self):\n        for tc in self.iter_tcs():\n            if tc.gridSpan > 1:\n                return True\n            if tc.rowSpan > 1:\n                return True\n            if tc.hMerge:\n                return True\n            if tc.vMerge:\n                return True\n        return False", "response": "True if one or more cells in range are part of a merged cell."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning row_count col_count pair describing size of range.", "response": "def dimensions(self):\n        \"\"\"(row_count, col_count) pair describing size of range.\"\"\"\n        _, _, width, height = self._extents\n        return height, width"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef in_same_table(self):\n        if self._tc.tbl is self._other_tc.tbl:\n            return True\n        return False", "response": "True if both cells provided to constructor are in same table."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngenerating each tc element in non - first rows of range.", "response": "def iter_except_top_row_tcs(self):\n        \"\"\"Generate each `a:tc` element in non-first rows of range.\"\"\"\n        for tr in self._tbl.tr_lst[self._top + 1:self._bottom]:\n            for tc in tr.tc_lst[self._left:self._right]:\n                yield tc"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngenerates each tc element in leftmost column of range.", "response": "def iter_left_col_tcs(self):\n        \"\"\"Generate each `a:tc` element in leftmost column of range.\"\"\"\n        col_idx = self._left\n        for tr in self._tbl.tr_lst[self._top:self._bottom]:\n            yield tr.tc_lst[col_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef iter_top_row_tcs(self):\n        tr = self._tbl.tr_lst[self._top]\n        for tc in tr.tc_lst[self._left:self._right]:\n            yield tc", "response": "Generate each a : tc element in topmost row of range."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nmoves all paragraphs in range to origin cell.", "response": "def move_content_to_origin(self):\n        \"\"\"Move all paragraphs in range to origin cell.\"\"\"\n        tcs = list(self.iter_tcs())\n        origin_tc = tcs[0]\n        for spanned_tc in tcs[1:]:\n            origin_tc.append_ps_from(spanned_tc)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _bottom(self):\n        _, top, _, height = self._extents\n        return top + height", "response": "Index of row following last row of range"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _extents(self):\n        def start_and_size(idx, other_idx):\n            \"\"\"Return beginning and length of range based on two indexes.\"\"\"\n            return min(idx, other_idx), abs(idx - other_idx) + 1\n\n        tc, other_tc = self._tc, self._other_tc\n\n        left, width = start_and_size(tc.col_idx, other_tc.col_idx)\n        top, height = start_and_size(tc.row_idx, other_tc.row_idx)\n\n        return left, top, width, height", "response": "A tuple describing the extents of the current range."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _right(self):\n        left, _, width, _ = self._extents\n        return left + width", "response": "Index of the column following the last column in range"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn the action of the current object.", "response": "def action(self):\n        \"\"\"\n        A member of the :ref:`PpActionType` enumeration, such as\n        `PP_ACTION.HYPERLINK`, indicating the type of action that will result\n        when the specified shape or text is clicked or the mouse pointer is\n        positioned over the shape during a slide show.\n        \"\"\"\n        hlink = self._hlink\n\n        if hlink is None:\n            return PP_ACTION.NONE\n\n        action_verb = hlink.action_verb\n\n        if action_verb == 'hlinkshowjump':\n            relative_target = hlink.action_fields['jump']\n            return {\n                'firstslide':      PP_ACTION.FIRST_SLIDE,\n                'lastslide':       PP_ACTION.LAST_SLIDE,\n                'lastslideviewed': PP_ACTION.LAST_SLIDE_VIEWED,\n                'nextslide':       PP_ACTION.NEXT_SLIDE,\n                'previousslide':   PP_ACTION.PREVIOUS_SLIDE,\n                'endshow':         PP_ACTION.END_SHOW,\n            }[relative_target]\n\n        return {\n            None:           PP_ACTION.HYPERLINK,\n            'hlinksldjump': PP_ACTION.NAMED_SLIDE,\n            'hlinkpres':    PP_ACTION.PLAY,\n            'hlinkfile':    PP_ACTION.OPEN_FILE,\n            'customshow':   PP_ACTION.NAMED_SLIDE_SHOW,\n            'ole':          PP_ACTION.OLE_VERB,\n            'macro':        PP_ACTION.RUN_MACRO,\n            'program':      PP_ACTION.RUN_PROGRAM,\n        }[action_verb]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn |None| if no target slide is present in this presentation.", "response": "def target_slide(self):\n        \"\"\"\n        A reference to the slide in this presentation that is the target of\n        the slide jump action in this shape. Slide jump actions include\n        `PP_ACTION.FIRST_SLIDE`, `LAST_SLIDE`, `NEXT_SLIDE`,\n        `PREVIOUS_SLIDE`, and `NAMED_SLIDE`. Returns |None| for all other\n        actions. In particular, the `LAST_SLIDE_VIEWED` action and the `PLAY`\n        (start other presentation) actions are not supported.\n\n        A slide object may be assigned to this property, which makes the\n        shape an \"internal hyperlink\" to the assigened slide::\n\n            slide, target_slide = prs.slides[0], prs.slides[1]\n            shape = slide.shapes[0]\n            shape.target_slide = target_slide\n\n        Assigning |None| removes any slide jump action. Note that this is\n        accomplished by removing any action present (such as a hyperlink),\n        without first checking that it is a slide jump action.\n        \"\"\"\n        slide_jump_actions = (\n            PP_ACTION.FIRST_SLIDE,\n            PP_ACTION.LAST_SLIDE,\n            PP_ACTION.NEXT_SLIDE,\n            PP_ACTION.PREVIOUS_SLIDE,\n            PP_ACTION.NAMED_SLIDE,\n        )\n\n        if self.action not in slide_jump_actions:\n            return None\n\n        if self.action == PP_ACTION.FIRST_SLIDE:\n            return self._slides[0]\n        elif self.action == PP_ACTION.LAST_SLIDE:\n            return self._slides[-1]\n        elif self.action == PP_ACTION.NEXT_SLIDE:\n            next_slide_idx = self._slide_index + 1\n            if next_slide_idx >= len(self._slides):\n                raise ValueError('no next slide')\n            return self._slides[next_slide_idx]\n        elif self.action == PP_ACTION.PREVIOUS_SLIDE:\n            prev_slide_idx = self._slide_index - 1\n            if prev_slide_idx < 0:\n                raise ValueError('no previous slide')\n            return self._slides[prev_slide_idx]\n        elif self.action == PP_ACTION.NAMED_SLIDE:\n            rId = self._hlink.rId\n            return self.part.related_parts[rId].slide"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _hlink(self):\n        if self._hover:\n            return self._element.hlinkHover\n        return self._element.hlinkClick", "response": "Return |None| if the element is not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the address of the object.", "response": "def address(self):\n        \"\"\"\n        Read/write. The URL of the hyperlink. URL can be on http, https,\n        mailto, or file scheme; others may work. Returns |None| if no\n        hyperlink is defined, including when another action such as\n        `RUN_MACRO` is defined on the object. Assigning |None| removes any\n        action defined on the object, whether it is a hyperlink action or\n        not.\n        \"\"\"\n        hlink = self._hlink\n\n        # there's no URL if there's no click action\n        if hlink is None:\n            return None\n\n        # a click action without a relationship has no URL\n        rId = hlink.rId\n        if not rId:\n            return None\n\n        return self.part.target_ref(rId)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_or_add_hlink(self):\n        if self._hover:\n            return self._element.get_or_add_hlinkHover()\n        return self._element.get_or_add_hlinkClick()", "response": "Get the HyperlinkMacroElement object for the HyperlinkMacro object depending on the value of self. _hover. Create one if one is not present."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nremove the a : hlinkClick or a : hlinkHover element including dropping any relationship it might have.", "response": "def _remove_hlink(self):\n        \"\"\"\n        Remove the a:hlinkClick or a:hlinkHover element, including dropping\n        any relationship it might have.\n        \"\"\"\n        hlink = self._hlink\n        if hlink is None:\n            return\n        rId = hlink.rId\n        if rId:\n            self.part.drop_rel(rId)\n        self._element.remove(hlink)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning |Font| object that provides access to the text properties for these data labels.", "response": "def font(self):\n        \"\"\"\n        The |Font| object that provides access to the text properties for\n        these data labels, such as bold, italic, etc.\n        \"\"\"\n        defRPr = self._element.defRPr\n        font = Font(defRPr)\n        return font"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreads or write boolean specifying whether number formatting should be used for this object.", "response": "def number_format_is_linked(self):\n        \"\"\"\n        Read/write boolean specifying whether number formatting should be\n        taken from the source spreadsheet rather than the value of\n        :meth:`number_format`.\n        \"\"\"\n        numFmt = self._element.numFmt\n        if numFmt is None:\n            return True\n        souceLinked = numFmt.sourceLinked\n        if souceLinked is None:\n            return True\n        return numFmt.sourceLinked"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef has_text_frame(self):\n        dLbl = self._dLbl\n        if dLbl is None:\n            return False\n        if dLbl.xpath('c:tx/c:rich'):\n            return True\n        return False", "response": "Return |True| if this data label has a text frame."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef position(self):\n        dLbl = self._dLbl\n        if dLbl is None:\n            return None\n        dLblPos = dLbl.dLblPos\n        if dLblPos is None:\n            return None\n        return dLblPos.val", "response": "Returns the value of the dLblPos\n        member or |None| if no position is specified."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _get_or_add_rich(self):\n        dLbl = self._get_or_add_dLbl()\n\n        # having a c:spPr or c:txPr when a c:tx is present causes the \"can't\n        # save\" bug on bubble charts. Remove c:spPr and c:txPr when present.\n        dLbl._remove_spPr()\n        dLbl._remove_txPr()\n\n        return dLbl.get_or_add_rich()", "response": "Return the c : rich element representing the text frame for this data\n        label newly created with its ancestors if not present."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _get_or_add_tx_rich(self):\n        dLbl = self._get_or_add_dLbl()\n\n        # having a c:spPr or c:txPr when a c:tx is present causes the \"can't\n        # save\" bug on bubble charts. Remove c:spPr and c:txPr when present.\n        dLbl._remove_spPr()\n        dLbl._remove_txPr()\n\n        return dLbl.get_or_add_tx_rich()", "response": "Get the c : tx element for this data label with its c : rich child and descendants newly created if not yet present."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef include_in_layout(self):\n        overlay = self._element.overlay\n        if overlay is None:\n            return True\n        return overlay.val", "response": "|True| if the legend should be located inside the plot area."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the value of the legend position property.", "response": "def position(self):\n        \"\"\"\n        Read/write :ref:`XlLegendPosition` enumeration value specifying the\n        general region of the chart in which to place the legend.\n        \"\"\"\n        legendPos = self._element.legendPos\n        if legendPos is None:\n            return XL_LEGEND_POSITION.RIGHT\n        return legendPos.val"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a new Relationship element.", "response": "def new(cls, rId, reltype, target, target_mode=RTM.INTERNAL):\n        \"\"\"\n        Return a new ``<Relationship>`` element.\n        \"\"\"\n        xml = '<Relationship xmlns=\"%s\"/>' % nsmap['pr']\n        relationship = parse_xml(xml)\n        relationship.rId = rId\n        relationship.reltype = reltype\n        relationship.target_ref = target\n        relationship.targetMode = target_mode\n        return relationship"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_default(self, ext, content_type):\n        return self._add_default(extension=ext, contentType=content_type)", "response": "Add a child element with the specified extension and content type."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a child element with attributes set to parameter values.", "response": "def add_override(self, partname, content_type):\n        \"\"\"\n        Add a child ``<Override>`` element with attributes set to parameter\n        values.\n        \"\"\"\n        return self._add_override(\n            partName=partname, contentType=content_type\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_slide(self, slide_layout):\n        partname = self._next_slide_partname\n        slide_layout_part = slide_layout.part\n        slide_part = SlidePart.new(partname, self.package, slide_layout_part)\n        rId = self.relate_to(slide_part, RT.SLIDE)\n        return rId, slide_part.slide", "response": "Return an rId slide that inherits appearance from *slide_layout*."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns |Slide| object identified by slide_id| or |None| if not found.", "response": "def get_slide(self, slide_id):\n        \"\"\"\n        Return the |Slide| object identified by *slide_id* (in this\n        presentation), or |None| if not found.\n        \"\"\"\n        for sldId in self._element.sldIdLst:\n            if sldId.id == slide_id:\n                return self.related_parts[sldId.rId].slide\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the |NotesMasterPart| object for this presentation.", "response": "def notes_master_part(self):\n        \"\"\"\n        Return the |NotesMasterPart| object for this presentation. If the\n        presentation does not have a notes master, one is created from\n        a default template. The same single instance is returned on each\n        call.\n        \"\"\"\n        try:\n            return self.part_related_by(RT.NOTES_MASTER)\n        except KeyError:\n            notes_master_part = NotesMasterPart.create_default(self.package)\n            self.relate_to(notes_master_part, RT.NOTES_MASTER)\n            return notes_master_part"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef rename_slide_parts(self, rIds):\n        for idx, rId in enumerate(rIds):\n            slide_part = self.related_parts[rId]\n            slide_part.partname = PackURI(\n                '/ppt/slides/slide%d.xml' % (idx+1)\n            )", "response": "Assign incrementing partnames like / ppt / slides / slide9. xml to the available slide parts."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the slide identifier associated with slide_part in this presentation.", "response": "def slide_id(self, slide_part):\n        \"\"\"\n        Return the slide identifier associated with *slide_part* in this\n        presentation.\n        \"\"\"\n        for sldId in self._element.sldIdLst:\n            if self.related_parts[sldId.rId] is slide_part:\n                return sldId.id\n        raise ValueError('matching slide_part not found')"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning |PackURI| instance containing the partname for the next slide in the collection.", "response": "def _next_slide_partname(self):\n        \"\"\"\n        Return |PackURI| instance containing the partname for a slide to be\n        appended to this slide collection, e.g. ``/ppt/slides/slide9.xml``\n        for a slide collection containing 8 slides.\n        \"\"\"\n        sldIdLst = self._element.get_or_add_sldIdLst()\n        partname_str = '/ppt/slides/slide%d.xml' % (len(sldIdLst)+1)\n        return PackURI(partname_str)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn |Image| object containing poster frame for this movie.", "response": "def poster_frame(self):\n        \"\"\"Return |Image| object containing poster frame for this movie.\n\n        Returns |None| if this movie has no poster frame (uncommon).\n        \"\"\"\n        slide_part, rId = self.part, self._element.blip_rId\n        if rId is None:\n            return None\n        return slide_part.get_image(rId)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auto_shape_type(self):\n        prstGeom = self._pic.spPr.prstGeom\n        if prstGeom is None:  # ---generally means cropped with freeform---\n            return None\n        return prstGeom.prst", "response": "Member of MSO_SHAPE indicating auto - shapes."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a |PackURI| instance representing the next available partname matching tmpl.", "response": "def next_partname(self, tmpl):\n        \"\"\"\n        Return a |PackURI| instance representing the next available partname\n        matching *tmpl*, which is a printf (%)-style template string\n        containing a single replacement item, a '%d' to be used to insert the\n        integer portion of the partname. Example: '/ppt/slides/slide%d.xml'\n        \"\"\"\n        partnames = [part.partname for part in self.iter_parts()]\n        for n in range(1, len(partnames)+2):\n            candidate_partname = tmpl % n\n            if candidate_partname not in partnames:\n                return PackURI(candidate_partname)\n        raise Exception('ProgrammingError: ran out of candidate_partnames')"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef parse_from_template(template_name):\n    thisdir = os.path.split(__file__)[0]\n    filename = os.path.join(\n        thisdir, '..', 'templates', '%s.xml' % template_name\n    )\n    with open(filename, 'rb') as f:\n        xml = f.read()\n    return parse_xml(xml)", "response": "Parse an XML file from the template file identified by template_name."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nregister cls to be constructed when the oxml parser encounters an element having name nsptagname.", "response": "def register_element_cls(nsptagname, cls):\n    \"\"\"\n    Register *cls* to be constructed when the oxml parser encounters an\n    element having name *nsptag_name*. *nsptag_name* is a string of the form\n    ``nspfx:tagroot``, e.g. ``'w:document'``.\n    \"\"\"\n    nsptag = NamespacePrefixedTag(nsptagname)\n    namespace = element_class_lookup.get_namespace(nsptag.nsuri)\n    namespace[nsptag.local_part] = cls"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns an instance of the appropriate subclass of _BaseSeries based on the specified series element.", "response": "def _SeriesFactory(ser):\n    \"\"\"\n    Return an instance of the appropriate subclass of _BaseSeries based on the\n    xChart element *ser* appears in.\n    \"\"\"\n    xChart_tag = ser.getparent().tag\n\n    try:\n        SeriesCls = {\n            qn('c:areaChart'):     AreaSeries,\n            qn('c:barChart'):      BarSeries,\n            qn('c:bubbleChart'):   BubbleSeries,\n            qn('c:doughnutChart'): PieSeries,\n            qn('c:lineChart'):     LineSeries,\n            qn('c:pieChart'):      PieSeries,\n            qn('c:radarChart'):    RadarSeries,\n            qn('c:scatterChart'):  XySeries,\n        }[xChart_tag]\n    except KeyError:\n        raise NotImplementedError(\n            'series class for %s not yet implemented' % xChart_tag\n        )\n\n    return SeriesCls(ser)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef values(self):\n        def iter_values():\n            val = self._element.val\n            if val is None:\n                return\n            for idx in range(val.ptCount_val):\n                yield val.pt_v(idx)\n\n        return tuple(iter_values())", "response": "Read - only. A sequence containing the float values for this series in the order they appear on the chart."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef invert_if_negative(self):\n        invertIfNegative = self._element.invertIfNegative\n        if invertIfNegative is None:\n            return True\n        return invertIfNegative.val", "response": "|True| if the fill gradient of the bar is not the same as the fill gradient. |False| if the fill gradient of the bar is not the same as the fill gradient."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef smooth(self):\n        smooth = self._element.smooth\n        if smooth is None:\n            return True\n        return smooth.val", "response": "Read or write boolean specifying whether to use curve smoothing to connect the data points into the series of straight line segments."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef iter_values(self):\n        yVal = self._element.yVal\n        if yVal is None:\n            return\n\n        for idx in range(yVal.ptCount_val):\n            yield yVal.pt_v(idx)", "response": "Iterate over the values in this series in the order they appear."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a list of the c : pt elements under the c : cat element of this xChart element.", "response": "def cat_pts(self):\n        \"\"\"\n        Return a sequence representing the `c:pt` elements under the `c:cat`\n        element of the first series in this xChart element. A category having\n        no value will have no corresponding `c:pt` element; |None| will\n        appear in that position in such cases. Items appear in `idx` order.\n        Only those in the first ``<c:lvl>`` element are included in the case\n        of multi-level categories.\n        \"\"\"\n        cat_pts = self.xpath('./c:ser[1]/c:cat//c:lvl[1]/c:pt')\n        if not cat_pts:\n            cat_pts = self.xpath('./c:ser[1]/c:cat//c:pt')\n\n        cat_pt_dict = dict((pt.idx, pt) for pt in cat_pts)\n\n        return [cat_pt_dict.get(idx, None)\n                for idx in range(self.cat_pt_count)]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the value of the. / c : grouping attribute taking defaults into account when items are not present.", "response": "def grouping_val(self):\n        \"\"\"\n        Return the value of the ``./c:grouping{val=?}`` attribute, taking\n        defaults into account when items are not present.\n        \"\"\"\n        grouping = self.grouping\n        if grouping is None:\n            return ST_Grouping.STANDARD\n        val = grouping.val\n        if val is None:\n            return ST_Grouping.STANDARD\n        return val"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef iter_sers(self):\n        def ser_order(ser):\n            return ser.order.val\n\n        return (ser for ser in sorted(self.xpath('./c:ser'), key=ser_order))", "response": "Iterate over the ser elements in this xChart in\n        c : order. val\n\n       "}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef grouping_val(self):\n        grouping = self.grouping\n        if grouping is None:\n            return ST_Grouping.CLUSTERED\n        val = grouping.val\n        if val is None:\n            return ST_Grouping.CLUSTERED\n        return val", "response": "Return the value of the. / c : grouping { val=? } attribute taking\n        defaults into account when items are not present."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef namespaces(*prefixes):\n    namespaces = {}\n    for prefix in prefixes:\n        namespaces[prefix] = _nsmap[prefix]\n    return namespaces", "response": "Returns a dict containing the subset namespace prefixes specified by the given list of namespace prefixes."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nremoves all empty paragraphs except one empty one.", "response": "def clear(self):\n        \"\"\"\n        Remove all paragraphs except one empty one.\n        \"\"\"\n        for p in self._txBody.p_lst[1:]:\n            self._txBody.remove(p)\n        p = self.paragraphs[0]\n        p.clear()"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nfits the text in this text - frame to all the text it contains.", "response": "def fit_text(self, font_family='Calibri', max_size=18, bold=False,\n                 italic=False, font_file=None):\n        \"\"\"Fit text-frame text entirely within bounds of its shape.\n\n        Make the text in this text frame fit entirely within the bounds of\n        its shape by setting word wrap on and applying the \"best-fit\" font\n        size to all the text it contains. :attr:`TextFrame.auto_size` is set\n        to :attr:`MSO_AUTO_SIZE.NONE`. The font size will not be set larger\n        than *max_size* points. If the path to a matching TrueType font is\n        provided as *font_file*, that font file will be used for the font\n        metrics. If *font_file* is |None|, best efforts are made to locate\n        a font file with matchhing *font_family*, *bold*, and *italic*\n        installed on the current system (usually succeeds if the font is\n        installed).\n        \"\"\"\n        # ---no-op when empty as fit behavior not defined for that case---\n        if self.text == '':\n            return\n\n        font_size = self._best_fit_font_size(\n            font_family, max_size, bold, italic, font_file\n        )\n        self._apply_fit(font_family, font_size, bold, italic)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef paragraphs(self):\n        return tuple([_Paragraph(p, self) for p in self._txBody.p_lst])", "response": "Immutable sequence of |_Paragraph| instances corresponding to the\n        paragraphs in this text frame."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nread - write setting determining whether lines of text in this shape are wrapped within the shape s width.", "response": "def word_wrap(self):\n        \"\"\"\n        Read-write setting determining whether lines of text in this shape\n        are wrapped to fit within the shape's width. Valid values are True,\n        False, or None. True and False turn word wrap on and off,\n        respectively. Assigning None to word wrap causes any word wrap\n        setting to be removed from the text frame, causing it to inherit this\n        setting from its style hierarchy.\n        \"\"\"\n        return {\n            ST_TextWrappingType.SQUARE: True,\n            ST_TextWrappingType.NONE:   False,\n            None:                       None\n        }[self._txBody.bodyPr.wrap]"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _apply_fit(self, font_family, font_size, is_bold, is_italic):\n        self.auto_size = MSO_AUTO_SIZE.NONE\n        self.word_wrap = True\n        self._set_font(font_family, font_size, is_bold, is_italic)", "response": "Applies the fit to all the text in this text frame."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _best_fit_font_size(self, family, max_size, bold, italic, font_file):\n        if font_file is None:\n            font_file = FontFiles.find(family, bold, italic)\n        return TextFitter.best_fit_font_size(\n            self.text, self._extents, max_size, font_file\n        )", "response": "Return the largest integer point size not greater than max_size that allows all the text in this text frame to fit inside its extents."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _extents(self):\n        return (\n            self._parent.width - self.margin_left - self.margin_right,\n            self._parent.height - self.margin_top - self.margin_bottom\n        )", "response": "A tuple representing the extent of the text area within this text frame."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_font(self, family, size, bold, italic):\n        def iter_rPrs(txBody):\n            for p in txBody.p_lst:\n                for elm in p.content_children:\n                    yield elm.get_or_add_rPr()\n                # generate a:endParaRPr for each <a:p> element\n                yield p.get_or_add_endParaRPr()\n\n        def set_rPr_font(rPr, name, size, bold, italic):\n            f = Font(rPr)\n            f.name, f.size, f.bold, f.italic = family, Pt(size), bold, italic\n\n        txBody = self._element\n        for rPr in iter_rPrs(txBody):\n            set_rPr_font(rPr, family, size, bold, italic)", "response": "Set the font properties of all the text in this text frame to the given values."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets or set the language id of this |Font| instance.", "response": "def language_id(self):\n        \"\"\"\n        Get or set the language id of this |Font| instance. The language id\n        is a member of the :ref:`MsoLanguageId` enumeration. Assigning |None|\n        removes any language setting, the same behavior as assigning\n        `MSO_LANGUAGE_ID.NONE`.\n        \"\"\"\n        lang = self._rPr.lang\n        if lang is None:\n            return MSO_LANGUAGE_ID.NONE\n        return self._rPr.lang"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the value of the MSO_UNDERLINE attribute of the current font.", "response": "def underline(self):\n        \"\"\"\n        Read/write. |True|, |False|, |None|, or a member of the\n        :ref:`MsoTextUnderlineType` enumeration indicating the underline\n        setting for this font. |None| is the default and indicates the\n        underline setting should be inherited from the style hierarchy, such\n        as from a placeholder. |True| indicates single underline. |False|\n        indicates no underline. Other settings such as double and wavy\n        underlining are indicated with members of the\n        :ref:`MsoTextUnderlineType` enumeration.\n        \"\"\"\n        u = self._rPr.u\n        if u is MSO_UNDERLINE.NONE:\n            return False\n        if u is MSO_UNDERLINE.SINGLE_LINE:\n            return True\n        return u"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the URL of the hyperlink.", "response": "def address(self):\n        \"\"\"\n        Read/write. The URL of the hyperlink. URL can be on http, https,\n        mailto, or file scheme; others may work.\n        \"\"\"\n        if self._hlinkClick is None:\n            return None\n        return self.part.target_ref(self._hlinkClick.rId)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef clear(self):\n        for elm in self._element.content_children:\n            self._element.remove(elm)\n        return self", "response": "Remove all content from this paragraph."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the set of runs in this paragraph.", "response": "def runs(self):\n        \"\"\"\n        Immutable sequence of |_Run| objects corresponding to the runs in\n        this paragraph.\n        \"\"\"\n        return tuple(_Run(r, self) for r in self._element.r_lst)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning the major tick mark value for this axis.", "response": "def major_tick_mark(self):\n        \"\"\"\n        Read/write :ref:`XlTickMark` value specifying the type of major tick\n        mark to display on this axis.\n        \"\"\"\n        majorTickMark = self._element.majorTickMark\n        if majorTickMark is None:\n            return XL_TICK_MARK.CROSS\n        return majorTickMark.val"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef minor_tick_mark(self):\n        minorTickMark = self._element.minorTickMark\n        if minorTickMark is None:\n            return XL_TICK_MARK.CROSS\n        return minorTickMark.val", "response": "Returns the minor tick mark for this axis."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the XlTickLabelPosition value specifying where the tick labels should appear.", "response": "def tick_label_position(self):\n        \"\"\"\n        Read/write :ref:`XlTickLabelPosition` value specifying where the tick\n        labels for this axis should appear.\n        \"\"\"\n        tickLblPos = self._element.tickLblPos\n        if tickLblPos is None:\n            return XL_TICK_LABEL_POSITION.NEXT_TO_AXIS\n        if tickLblPos.val is None:\n            return XL_TICK_LABEL_POSITION.NEXT_TO_AXIS\n        return tickLblPos.val"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef crosses(self):\n        crosses = self._cross_xAx.crosses\n        if crosses is None:\n            return XL_AXIS_CROSSES.CUSTOM\n        return crosses.val", "response": "Return the value of the crosses property of the other axis."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cross_xAx(self):\n        crossAx_id = self._element.crossAx.val\n        expr = (\n            '(../c:catAx | ../c:valAx | ../c:dateAx)/c:axId[@val=\"%d\"]'\n            % crossAx_id\n        )\n        cross_axId = self._element.xpath(expr)[0]\n        return cross_axId.getparent()", "response": "The cross - axis element that crosses this axis."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_path_or_file_like(cls, movie_file, mime_type):\n        if is_string(movie_file):\n            # treat movie_file as a path\n            with open(movie_file, 'rb') as f:\n                blob = f.read()\n            filename = os.path.basename(movie_file)\n        else:\n            # assume movie_file is a file-like object\n            blob = movie_file.read()\n            filename = None\n\n        return cls.from_blob(blob, mime_type, filename)", "response": "Return a |Video| object containing video in movie_file."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef ext(self):\n        if self._filename:\n            return os.path.splitext(self._filename)[1].lstrip('.')\n        return {\n            CT.ASF:        'asf',\n            CT.AVI:        'avi',\n            CT.MOV:        'mov',\n            CT.MP4:        'mp4',\n            CT.MPG:        'mpg',\n            CT.MS_VIDEO:   'avi',\n            CT.SWF:        'swf',\n            CT.WMV:        'wmv',\n            CT.X_MS_VIDEO: 'avi',\n        }.get(self._mime_type, 'vid')", "response": "Return the file extension for this video e. g. mp4. mpg. ms. wav."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the Y value for a data point in this cache.", "response": "def pt_v(self, idx):\n        \"\"\"\n        Return the Y value for data point *idx* in this cache, or None if no\n        value is present for that data point.\n        \"\"\"\n        results = self.xpath('.//c:pt[@idx=%d]' % idx)\n        return results[0].value if results else None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_dLbl(self, idx):\n        dLbls = self.dLbls\n        if dLbls is None:\n            return None\n        return dLbls.get_dLbl_for_point(idx)", "response": "Return the c : dLbl element representing the label for the data point at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_or_add_dPt_for_point(self, idx):\n        matches = self.xpath('c:dPt[c:idx[@val=\"%d\"]]' % idx)\n        if matches:\n            return matches[0]\n        dPt = self._add_dPt()\n        dPt.idx.val = idx\n        return dPt", "response": "Return the c : dPt child representing the visual properties of the data point at the given index."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_lnTo(self, x, y):\n        lnTo = self._add_lnTo()\n        pt = lnTo._add_pt()\n        pt.x, pt.y = x, y\n        return lnTo", "response": "Return a newly created lnTo subtree with end point x y."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_moveTo(self, x, y):\n        moveTo = self._add_moveTo()\n        pt = moveTo._add_pt()\n        pt.x, pt.y = x, y\n        return moveTo", "response": "Return a newly created moveTo subtree with point x y."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef add_path(self, w, h):\n        path = self._add_path()\n        path.w, path.h = w, h\n        return path", "response": "Return a newly created a : path child element."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nrewrite the guides of the object with the ones in guides.", "response": "def rewrite_guides(self, guides):\n        \"\"\"\n        Remove any ``<a:gd>`` element children of ``<a:avLst>`` and replace\n        them with ones having (name, val) in *guides*.\n        \"\"\"\n        self._remove_avLst()\n        avLst = self._add_avLst()\n        for name, val in guides:\n            gd = avLst._add_gd()\n            gd.name = name\n            gd.fmla = 'val %d' % val"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreferences to a : custGeom descendant or |None| if not present.", "response": "def add_path(self, w, h):\n        \"\"\"Reference to `a:custGeom` descendant or |None| if not present.\"\"\"\n        custGeom = self.spPr.custGeom\n        if custGeom is None:\n            raise ValueError('shape must be freeform')\n        pathLst = custGeom.get_or_add_pathLst()\n        return pathLst.add_path(w=w, h=h)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef is_autoshape(self):\n        prstGeom = self.prstGeom\n        if prstGeom is None:\n            return False\n        if self.nvSpPr.cNvSpPr.txBox is True:\n            return False\n        return True", "response": "True if this shape is an auto shape."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn a new auto shape element tree configured as a base auto shape.", "response": "def new_autoshape_sp(id_, name, prst, left, top, width, height):\n        \"\"\"\n        Return a new ``<p:sp>`` element tree configured as a base auto shape.\n        \"\"\"\n        tmpl = CT_Shape._autoshape_sp_tmpl()\n        xml = tmpl % (id_, name, left, top, width, height, prst)\n        sp = parse_xml(xml)\n        return sp"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_freeform_sp(shape_id, name, x, y, cx, cy):\n        tmpl = CT_Shape._freeform_sp_tmpl()\n        xml = tmpl % (shape_id, name, x, y, cx, cy)\n        sp = parse_xml(xml)\n        return sp", "response": "Return a new p : sp element tree configured as freeform shape."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_placeholder_sp(id_, name, ph_type, orient, sz, idx):\n        tmpl = CT_Shape._ph_sp_tmpl()\n        xml = tmpl % (id_, name)\n        sp = parse_xml(xml)\n\n        ph = sp.nvSpPr.nvPr.get_or_add_ph()\n        ph.type = ph_type\n        ph.idx = idx\n        ph.orient = orient\n        ph.sz = sz\n\n        placeholder_types_that_have_a_text_frame = (\n            PP_PLACEHOLDER.TITLE, PP_PLACEHOLDER.CENTER_TITLE,\n            PP_PLACEHOLDER.SUBTITLE, PP_PLACEHOLDER.BODY,\n            PP_PLACEHOLDER.OBJECT\n        )\n\n        if ph_type in placeholder_types_that_have_a_text_frame:\n            sp.append(CT_TextBody.new())\n\n        return sp", "response": "Return a new empty placeholder element tree configured as a placeholder object."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_textbox_sp(id_, name, left, top, width, height):\n        tmpl = CT_Shape._textbox_sp_tmpl()\n        xml = tmpl % (id_, name, left, top, width, height)\n        sp = parse_xml(xml)\n        return sp", "response": "Return a new element tree configured as a base textbox containing the given attributes."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn appropriate XML writer object for the given chart type and chart data.", "response": "def ChartXmlWriter(chart_type, chart_data):\n    \"\"\"\n    Factory function returning appropriate XML writer object for\n    *chart_type*, loaded with *chart_type* and *chart_data*.\n    \"\"\"\n    XL_CT = XL_CHART_TYPE\n    try:\n        BuilderCls = {\n            XL_CT.AREA:                         _AreaChartXmlWriter,\n            XL_CT.AREA_STACKED:                 _AreaChartXmlWriter,\n            XL_CT.AREA_STACKED_100:             _AreaChartXmlWriter,\n            XL_CT.BAR_CLUSTERED:                _BarChartXmlWriter,\n            XL_CT.BAR_STACKED:                  _BarChartXmlWriter,\n            XL_CT.BAR_STACKED_100:              _BarChartXmlWriter,\n            XL_CT.BUBBLE:                       _BubbleChartXmlWriter,\n            XL_CT.BUBBLE_THREE_D_EFFECT:        _BubbleChartXmlWriter,\n            XL_CT.COLUMN_CLUSTERED:             _BarChartXmlWriter,\n            XL_CT.COLUMN_STACKED:               _BarChartXmlWriter,\n            XL_CT.COLUMN_STACKED_100:           _BarChartXmlWriter,\n            XL_CT.DOUGHNUT:                     _DoughnutChartXmlWriter,\n            XL_CT.DOUGHNUT_EXPLODED:            _DoughnutChartXmlWriter,\n            XL_CT.LINE:                         _LineChartXmlWriter,\n            XL_CT.LINE_MARKERS:                 _LineChartXmlWriter,\n            XL_CT.LINE_MARKERS_STACKED:         _LineChartXmlWriter,\n            XL_CT.LINE_MARKERS_STACKED_100:     _LineChartXmlWriter,\n            XL_CT.LINE_STACKED:                 _LineChartXmlWriter,\n            XL_CT.LINE_STACKED_100:             _LineChartXmlWriter,\n            XL_CT.PIE:                          _PieChartXmlWriter,\n            XL_CT.PIE_EXPLODED:                 _PieChartXmlWriter,\n            XL_CT.RADAR:                        _RadarChartXmlWriter,\n            XL_CT.RADAR_FILLED:                 _RadarChartXmlWriter,\n            XL_CT.RADAR_MARKERS:                _RadarChartXmlWriter,\n            XL_CT.XY_SCATTER:                   _XyChartXmlWriter,\n            XL_CT.XY_SCATTER_LINES:             _XyChartXmlWriter,\n            XL_CT.XY_SCATTER_LINES_NO_MARKERS:  _XyChartXmlWriter,\n            XL_CT.XY_SCATTER_SMOOTH:            _XyChartXmlWriter,\n            XL_CT.XY_SCATTER_SMOOTH_NO_MARKERS: _XyChartXmlWriter,\n        }[chart_type]\n    except KeyError:\n        raise NotImplementedError(\n            'XML writer for chart type %s not yet implemented' % chart_type\n        )\n    return BuilderCls(chart_type, chart_data)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a |_BaseSeriesXmlRewriter| subclass appropriate to *chart_type*.", "response": "def SeriesXmlRewriterFactory(chart_type, chart_data):\n    \"\"\"\n    Return a |_BaseSeriesXmlRewriter| subclass appropriate to *chart_type*.\n    \"\"\"\n    XL_CT = XL_CHART_TYPE\n\n    RewriterCls = {\n        # There are 73 distinct chart types, only specify non-category\n        # types, others default to _CategorySeriesXmlRewriter. Stock-type\n        # charts are multi-plot charts, so no guaratees on how they turn\n        # out.\n        XL_CT.BUBBLE:                       _BubbleSeriesXmlRewriter,\n        XL_CT.BUBBLE_THREE_D_EFFECT:        _BubbleSeriesXmlRewriter,\n        XL_CT.XY_SCATTER:                   _XySeriesXmlRewriter,\n        XL_CT.XY_SCATTER_LINES:             _XySeriesXmlRewriter,\n        XL_CT.XY_SCATTER_LINES_NO_MARKERS:  _XySeriesXmlRewriter,\n        XL_CT.XY_SCATTER_SMOOTH:            _XySeriesXmlRewriter,\n        XL_CT.XY_SCATTER_SMOOTH_NO_MARKERS: _XySeriesXmlRewriter,\n    }.get(chart_type, _CategorySeriesXmlRewriter)\n\n    return RewriterCls(chart_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef numRef_xml(self, wksht_ref, number_format, values):\n        pt_xml = self.pt_xml(values)\n        return (\n            '            <c:numRef>\\n'\n            '              <c:f>{wksht_ref}</c:f>\\n'\n            '              <c:numCache>\\n'\n            '                <c:formatCode>{number_format}</c:formatCode>\\n'\n            '{pt_xml}'\n            '              </c:numCache>\\n'\n            '            </c:numRef>\\n'\n        ).format(**{\n            'wksht_ref':     wksht_ref,\n            'number_format': number_format,\n            'pt_xml':        pt_xml,\n        })", "response": "Return the numberRef element specified by the parameters as\n        unicode text."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the xml representation of the data point sequence.", "response": "def pt_xml(self, values):\n        \"\"\"\n        Return the ``<c:ptCount>`` and sequence of ``<c:pt>`` elements\n        corresponding to *values* as a single unicode text string.\n        `c:ptCount` refers to the number of `c:pt` elements in this sequence.\n        The `idx` attribute value for `c:pt` elements locates the data point\n        in the overall data point sequence of the chart and is started at\n        *offset*.\n        \"\"\"\n        xml = (\n            '                <c:ptCount val=\"{pt_count}\"/>\\n'\n        ).format(\n            pt_count=len(values)\n        )\n\n        pt_tmpl = (\n            '                <c:pt idx=\"{idx}\">\\n'\n            '                  <c:v>{value}</c:v>\\n'\n            '                </c:pt>\\n'\n        )\n        for idx, value in enumerate(values):\n            if value is None:\n                continue\n            xml += pt_tmpl.format(idx=idx, value=value)\n\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a xml element for this series containing the series name.", "response": "def tx(self):\n        \"\"\"\n        Return a ``<c:tx>`` oxml element for this series, containing the\n        series name.\n        \"\"\"\n        xml = self._tx_tmpl.format(**{\n            'wksht_ref':   self._series.name_ref,\n            'series_name': self.name,\n            'nsdecls':     ' %s' % nsdecls('c'),\n        })\n        return parse_xml(xml)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the XML for this object.", "response": "def tx_xml(self):\n        \"\"\"\n        Return the ``<c:tx>`` (tx is short for 'text') element for this\n        series as unicode text. This element contains the series name.\n        \"\"\"\n        return self._tx_tmpl.format(**{\n            'wksht_ref':   self._series.name_ref,\n            'series_name': self.name,\n            'nsdecls':     '',\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef replace_series_data(self, chartSpace):\n        plotArea, date_1904 = chartSpace.plotArea, chartSpace.date_1904\n        chart_data = self._chart_data\n        self._adjust_ser_count(plotArea, len(chart_data))\n        for ser, series_data in zip(plotArea.sers, chart_data):\n            self._rewrite_ser_data(ser, series_data, date_1904)", "response": "Rewrite the series data under chartSpace with the series data in chartSpace."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nadd cloned Seses to the last xChart element in plotArea.", "response": "def _add_cloned_sers(self, plotArea, count):\n        \"\"\"\n        Add `c:ser` elements to the last xChart element in *plotArea*, cloned\n        from the last `c:ser` child of that last xChart.\n        \"\"\"\n        def clone_ser(ser):\n            new_ser = deepcopy(ser)\n            new_ser.idx.val = plotArea.next_idx\n            new_ser.order.val = plotArea.next_order\n            ser.addnext(new_ser)\n            return new_ser\n\n        last_ser = plotArea.last_ser\n        for _ in range(count):\n            last_ser = clone_ser(last_ser)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nadjust the number of ser elements in plotArea to new_ser_count.", "response": "def _adjust_ser_count(self, plotArea, new_ser_count):\n        \"\"\"\n        Adjust the number of c:ser elements in *plotArea* to *new_ser_count*.\n        Excess c:ser elements are deleted from the end, along with any xChart\n        elements that are left empty as a result. Series elements are\n        considered in xChart + series order. Any new c:ser elements required\n        are added to the last xChart element and cloned from the last c:ser\n        element in that xChart.\n        \"\"\"\n        ser_count_diff = new_ser_count - len(plotArea.sers)\n        if ser_count_diff > 0:\n            self._add_cloned_sers(plotArea, ser_count_diff)\n        elif ser_count_diff < 0:\n            self._trim_ser_count_by(plotArea, abs(ser_count_diff))"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nremoving the last count ser elements from plotArea. Any ser elements having no ser child elements after trimming are also removed.", "response": "def _trim_ser_count_by(self, plotArea, count):\n        \"\"\"\n        Remove the last *count* ser elements from *plotArea*. Any xChart\n        elements having no ser child elements after trimming are also\n        removed.\n        \"\"\"\n        extra_sers = plotArea.sers[-count:]\n        for ser in extra_sers:\n            parent = ser.getparent()\n            parent.remove(ser)\n        extra_xCharts = [\n            xChart for xChart in plotArea.iter_xCharts()\n            if len(xChart.sers) == 0\n        ]\n        for xChart in extra_xCharts:\n            parent = xChart.getparent()\n            parent.remove(xChart)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef cat(self):\n        categories = self._series.categories\n\n        if categories.are_numeric:\n            return parse_xml(\n                self._numRef_cat_tmpl.format(**{\n                    'wksht_ref':     self._series.categories_ref,\n                    'number_format': categories.number_format,\n                    'cat_count':     categories.leaf_count,\n                    'cat_pt_xml':    self._cat_num_pt_xml,\n                    'nsdecls':       ' %s' % nsdecls('c'),\n                })\n            )\n\n        if categories.depth == 1:\n            return parse_xml(\n                self._cat_tmpl.format(**{\n                    'wksht_ref':  self._series.categories_ref,\n                    'cat_count':  categories.leaf_count,\n                    'cat_pt_xml': self._cat_pt_xml,\n                    'nsdecls':    ' %s' % nsdecls('c'),\n                })\n            )\n\n        return parse_xml(\n            self._multiLvl_cat_tmpl.format(**{\n                'wksht_ref': self._series.categories_ref,\n                'cat_count': categories.leaf_count,\n                'lvl_xml':   self._lvl_xml(categories),\n                'nsdecls':   ' %s' % nsdecls('c'),\n            })\n        )", "response": "Return the XML for this series as an oxml\n        element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the unicode XML snippet for the category element for this series containing the category labels and spreadsheet reference.", "response": "def cat_xml(self):\n        \"\"\"\n        The unicode XML snippet for the ``<c:cat>`` element for this series,\n        containing the category labels and spreadsheet reference.\n        \"\"\"\n        categories = self._series.categories\n\n        if categories.are_numeric:\n            return self._numRef_cat_tmpl.format(**{\n                'wksht_ref':     self._series.categories_ref,\n                'number_format': categories.number_format,\n                'cat_count':     categories.leaf_count,\n                'cat_pt_xml':    self._cat_num_pt_xml,\n                'nsdecls':       '',\n            })\n\n        if categories.depth == 1:\n            return self._cat_tmpl.format(**{\n                'wksht_ref':  self._series.categories_ref,\n                'cat_count':  categories.leaf_count,\n                'cat_pt_xml': self._cat_pt_xml,\n                'nsdecls':    '',\n            })\n\n        return self._multiLvl_cat_tmpl.format(**{\n            'wksht_ref': self._series.categories_ref,\n            'cat_count': categories.leaf_count,\n            'lvl_xml':   self._lvl_xml(categories),\n            'nsdecls':   '',\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef val(self):\n        xml = self._val_tmpl.format(**{\n            'nsdecls':       ' %s' % nsdecls('c'),\n            'values_ref':    self._series.values_ref,\n            'number_format': self._series.number_format,\n            'val_count':     len(self._series),\n            'val_pt_xml':    self._val_pt_xml,\n        })\n        return parse_xml(xml)", "response": "Returns the XML for this series as an oxml element."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef val_xml(self):\n        return self._val_tmpl.format(**{\n            'nsdecls':       '',\n            'values_ref':    self._series.values_ref,\n            'number_format': self._series.number_format,\n            'val_count':     len(self._series),\n            'val_pt_xml':    self._val_pt_xml,\n        })", "response": "Return the unicode XML snippet for the c : val element describing the series values and their spreadsheet range\n        reference."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns unicode XML snippet for the category num_pt elements.", "response": "def _cat_num_pt_xml(self):\n        \"\"\"\n        The unicode XML snippet for the ``<c:pt>`` elements when category\n        labels are numeric (including date type).\n        \"\"\"\n        xml = ''\n        for idx, category in enumerate(self._series.categories):\n            xml += (\n                '                <c:pt idx=\"{cat_idx}\">\\n'\n                '                  <c:v>{cat_lbl_str}</c:v>\\n'\n                '                </c:pt>\\n'\n            ).format(**{\n                'cat_idx':     idx,\n                'cat_lbl_str': category.numeric_str_val(self._date_1904),\n            })\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _cat_pt_xml(self):\n        xml = ''\n        for idx, category in enumerate(self._series.categories):\n            xml += (\n                '                <c:pt idx=\"{cat_idx}\">\\n'\n                '                  <c:v>{cat_label}</c:v>\\n'\n                '                </c:pt>\\n'\n            ).format(**{\n                'cat_idx':   idx,\n                'cat_label': escape(to_unicode(category.label)),\n            })\n        return xml", "response": "Return unicode XML snippet for the the\nTaxonomy category names for this series."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns unicode XML snippet for the level elements containing multi - level category names.", "response": "def _lvl_xml(self, categories):\n        \"\"\"\n        The unicode XML snippet for the ``<c:lvl>`` elements containing\n        multi-level category names.\n        \"\"\"\n        def lvl_pt_xml(level):\n            xml = ''\n            for idx, name in level:\n                xml += (\n                    '                  <c:pt idx=\"%d\">\\n'\n                    '                    <c:v>%s</c:v>\\n'\n                    '                  </c:pt>\\n'\n                ) % (idx, escape('%s' % name))\n            return xml\n\n        xml = ''\n        for level in categories.levels:\n            xml += (\n                '                <c:lvl>\\n'\n                '{lvl_pt_xml}'\n                '                </c:lvl>\\n'\n            ).format(**{\n                'lvl_pt_xml': lvl_pt_xml(level),\n            })\n        return xml"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _val_pt_xml(self):\n        xml = ''\n        for idx, value in enumerate(self._series.values):\n            if value is None:\n                continue\n            xml += (\n                '                <c:pt idx=\"{val_idx:d}\">\\n'\n                '                  <c:v>{value}</c:v>\\n'\n                '                </c:pt>\\n'\n            ).format(**{\n                'val_idx': idx,\n                'value':   value,\n            })\n        return xml", "response": "Returns unicode XML snippet containing the values for the current series."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef xVal(self):\n        xml = self._xVal_tmpl.format(**{\n            'nsdecls':    ' %s' % nsdecls('c'),\n            'numRef_xml': self.numRef_xml(\n                self._series.x_values_ref, self._series.number_format,\n                self._series.x_values\n            ),\n        })\n        return parse_xml(xml)", "response": "Return the X values element for this series as an oxml element."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the XML representation of the This element for this series as unicode text.", "response": "def xVal_xml(self):\n        \"\"\"\n        Return the ``<c:xVal>`` element for this series as unicode text. This\n        element contains the X values for this series.\n        \"\"\"\n        return self._xVal_tmpl.format(**{\n            'nsdecls':    '',\n            'numRef_xml': self.numRef_xml(\n                self._series.x_values_ref, self._series.number_format,\n                self._series.x_values\n            ),\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef yVal(self):\n        xml = self._yVal_tmpl.format(**{\n            'nsdecls':    ' %s' % nsdecls('c'),\n            'numRef_xml': self.numRef_xml(\n                self._series.y_values_ref, self._series.number_format,\n                self._series.y_values\n            ),\n        })\n        return parse_xml(xml)", "response": "Return the Y values element for this series as an oxml element."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef yVal_xml(self):\n        return self._yVal_tmpl.format(**{\n            'nsdecls':    '',\n            'numRef_xml': self.numRef_xml(\n                self._series.y_values_ref, self._series.number_format,\n                self._series.y_values\n            ),\n        })", "response": "Return the XML representation of the Y values for this series as unicode text."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef bubbleSize(self):\n        xml = self._bubbleSize_tmpl.format(**{\n            'nsdecls':    ' %s' % nsdecls('c'),\n            'numRef_xml': self.numRef_xml(\n                self._series.bubble_sizes_ref, self._series.number_format,\n                self._series.bubble_sizes\n            ),\n        })\n        return parse_xml(xml)", "response": "Return the bubble size element for this series as an oxml\n        element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn the unicode bubble size element for this series as unicode text.", "response": "def bubbleSize_xml(self):\n        \"\"\"\n        Return the ``<c:bubbleSize>`` element for this series as unicode\n        text. This element contains the bubble size values for all the\n        data points in the chart.\n        \"\"\"\n        return self._bubbleSize_tmpl.format(**{\n            'nsdecls':    '',\n            'numRef_xml': self.numRef_xml(\n                self._series.bubble_sizes_ref, self._series.number_format,\n                self._series.bubble_sizes\n            ),\n        })"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _rewrite_ser_data(self, ser, series_data, date_1904):\n        ser._remove_tx()\n        ser._remove_xVal()\n        ser._remove_yVal()\n        ser._remove_bubbleSize()\n\n        xml_writer = _BubbleSeriesXmlWriter(series_data)\n\n        ser._insert_tx(xml_writer.tx)\n        ser._insert_xVal(xml_writer.xVal)\n        ser._insert_yVal(xml_writer.yVal)\n        ser._insert_bubbleSize(xml_writer.bubbleSize)", "response": "Rewrite the series data to include the values in the series_data."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _rewrite_ser_data(self, ser, series_data, date_1904):\n        ser._remove_tx()\n        ser._remove_cat()\n        ser._remove_val()\n\n        xml_writer = _CategorySeriesXmlWriter(series_data, date_1904)\n\n        ser._insert_tx(xml_writer.tx)\n        ser._insert_cat(xml_writer.cat)\n        ser._insert_val(xml_writer.val)", "response": "Rewrite the categories in ser based on the values in series_data."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrewrite the data in ser based on the values in series_data.", "response": "def _rewrite_ser_data(self, ser, series_data, date_1904):\n        \"\"\"\n        Rewrite the ``<c:tx>``, ``<c:xVal>`` and ``<c:yVal>`` child elements\n        of *ser* based on the values in *series_data*.\n        \"\"\"\n        ser._remove_tx()\n        ser._remove_xVal()\n        ser._remove_yVal()\n\n        xml_writer = _XySeriesXmlWriter(series_data)\n\n        ser._insert_tx(xml_writer.tx)\n        ser._insert_xVal(xml_writer.xVal)\n        ser._insert_yVal(xml_writer.yVal)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef to_unicode(text):\n    # both str and unicode inherit from basestring\n    if not isinstance(text, basestring):\n        tmpl = 'expected UTF-8 encoded string or unicode, got %s value %s'\n        raise TypeError(tmpl % (type(text), text))\n    # return unicode strings unchanged\n    if isinstance(text, unicode):\n        return text\n    # otherwise assume UTF-8 encoding, which also works for ASCII\n    return unicode(text, 'utf-8')", "response": "Return text as a unicode string."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef click_action(self):\n        cNvPr = self._element._nvXxPr.cNvPr\n        return ActionSetting(cNvPr, self)", "response": "Return an ActionSetting instance providing access to click behaviors."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef BaseShapeFactory(shape_elm, parent):\n    tag = shape_elm.tag\n\n    if tag == qn('p:pic'):\n        videoFiles = shape_elm.xpath('./p:nvPicPr/p:nvPr/a:videoFile')\n        if videoFiles:\n            return Movie(shape_elm, parent)\n        return Picture(shape_elm, parent)\n\n    shape_cls = {\n        qn('p:cxnSp'):        Connector,\n        qn('p:grpSp'):        GroupShape,\n        qn('p:sp'):           Shape,\n        qn('p:graphicFrame'): GraphicFrame,\n    }.get(tag, BaseShape)\n\n    return shape_cls(shape_elm, parent)", "response": "Returns an instance of the appropriate shape proxy class for the given shape element."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn an instance of the appropriate shape proxy class for shape_elm on a slide layout.", "response": "def _LayoutShapeFactory(shape_elm, parent):\n    \"\"\"\n    Return an instance of the appropriate shape proxy class for *shape_elm*\n    on a slide layout.\n    \"\"\"\n    tag_name = shape_elm.tag\n    if tag_name == qn('p:sp') and shape_elm.has_ph_elm:\n        return LayoutPlaceholder(shape_elm, parent)\n    return BaseShapeFactory(shape_elm, parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _MasterShapeFactory(shape_elm, parent):\n    tag_name = shape_elm.tag\n    if tag_name == qn('p:sp') and shape_elm.has_ph_elm:\n        return MasterPlaceholder(shape_elm, parent)\n    return BaseShapeFactory(shape_elm, parent)", "response": "Return an instance of the appropriate shape proxy class for the given shape element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns an instance of the appropriate shape proxy class for the given notes slide.", "response": "def _NotesSlideShapeFactory(shape_elm, parent):\n    \"\"\"\n    Return an instance of the appropriate shape proxy class for *shape_elm*\n    on a notes slide.\n    \"\"\"\n    tag_name = shape_elm.tag\n    if tag_name == qn('p:sp') and shape_elm.has_ph_elm:\n        return NotesSlidePlaceholder(shape_elm, parent)\n    return BaseShapeFactory(shape_elm, parent)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _SlidePlaceholderFactory(shape_elm, parent):\n    tag = shape_elm.tag\n    if tag == qn('p:sp'):\n        Constructor = {\n            PP_PLACEHOLDER.BITMAP:  PicturePlaceholder,\n            PP_PLACEHOLDER.CHART:   ChartPlaceholder,\n            PP_PLACEHOLDER.PICTURE: PicturePlaceholder,\n            PP_PLACEHOLDER.TABLE:   TablePlaceholder,\n        }.get(shape_elm.ph_type, SlidePlaceholder)\n    elif tag == qn('p:graphicFrame'):\n        Constructor = PlaceholderGraphicFrame\n    elif tag == qn('p:pic'):\n        Constructor = PlaceholderPicture\n    else:\n        Constructor = BaseShapeFactory\n    return Constructor(shape_elm, parent)", "response": "Returns a placeholder shape of the appropriate type for the given shape_elm."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef SlideShapeFactory(shape_elm, parent):\n    if shape_elm.has_ph_elm:\n        return _SlidePlaceholderFactory(shape_elm, parent)\n    return BaseShapeFactory(shape_elm, parent)", "response": "Returns an instance of the appropriate shape proxy class for the given shape."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef clone_placeholder(self, placeholder):\n        sp = placeholder.element\n        ph_type, orient, sz, idx = (\n            sp.ph_type, sp.ph_orient, sp.ph_sz, sp.ph_idx\n        )\n        id_ = self._next_shape_id\n        name = self._next_ph_name(ph_type, id_, orient)\n        self._spTree.add_placeholder(id_, name, ph_type, orient, sz, idx)", "response": "Add a new placeholder shape based on *placeholder*."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the base name for a placeholder of type ph_type in this shape collection.", "response": "def ph_basename(self, ph_type):\n        \"\"\"\n        Return the base name for a placeholder of *ph_type* in this shape\n        collection. There is some variance between slide types, for example\n        a notes slide uses a different name for the body placeholder, so this\n        method can be overriden by subclasses.\n        \"\"\"\n        return {\n            PP_PLACEHOLDER.BITMAP:       'ClipArt Placeholder',\n            PP_PLACEHOLDER.BODY:         'Text Placeholder',\n            PP_PLACEHOLDER.CENTER_TITLE: 'Title',\n            PP_PLACEHOLDER.CHART:        'Chart Placeholder',\n            PP_PLACEHOLDER.DATE:         'Date Placeholder',\n            PP_PLACEHOLDER.FOOTER:       'Footer Placeholder',\n            PP_PLACEHOLDER.HEADER:       'Header Placeholder',\n            PP_PLACEHOLDER.MEDIA_CLIP:   'Media Placeholder',\n            PP_PLACEHOLDER.OBJECT:       'Content Placeholder',\n            PP_PLACEHOLDER.ORG_CHART:    'SmartArt Placeholder',\n            PP_PLACEHOLDER.PICTURE:      'Picture Placeholder',\n            PP_PLACEHOLDER.SLIDE_NUMBER: 'Slide Number Placeholder',\n            PP_PLACEHOLDER.SUBTITLE:     'Subtitle',\n            PP_PLACEHOLDER.TABLE:        'Table Placeholder',\n            PP_PLACEHOLDER.TITLE:        'Title',\n        }[ph_type]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\niterate over the members of the XML tree.", "response": "def _iter_member_elms(self):\n        \"\"\"\n        Generate each child of the ``<p:spTree>`` element that corresponds to\n        a shape, in the sequence they appear in the XML.\n        \"\"\"\n        for shape_elm in self._spTree.iter_shape_elms():\n            if self._is_member_elm(shape_elm):\n                yield shape_elm"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _next_ph_name(self, ph_type, id, orient):\n        basename = self.ph_basename(ph_type)\n\n        # prefix rootname with 'Vertical ' if orient is 'vert'\n        if orient == ST_Direction.VERT:\n            basename = 'Vertical %s' % basename\n\n        # increment numpart as necessary to make name unique\n        numpart = id - 1\n        names = self._spTree.xpath('//p:cNvPr/@name')\n        while True:\n            name = '%s %d' % (basename, numpart)\n            if name not in names:\n                break\n            numpart += 1\n\n        return name", "response": "Return the next unique placeholder name for the given shape of type ph_type id and orientation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a unique shape id suitable for use with a new shape.", "response": "def _next_shape_id(self):\n        \"\"\"Return a unique shape id suitable for use with a new shape.\n\n        The returned id is 1 greater than the maximum shape id used so far.\n        In practice, the minimum id is 2 because the spTree element is always\n        assigned id=\"1\".\n        \"\"\"\n        # ---presence of cached-max-shape-id indicates turbo mode is on---\n        if self._cached_max_shape_id is not None:\n            self._cached_max_shape_id += 1\n            return self._cached_max_shape_id\n\n        return self._spTree.max_shape_id + 1"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a new chart to the slide.", "response": "def add_chart(self, chart_type, x, y, cx, cy, chart_data):\n        \"\"\"Add a new chart of *chart_type* to the slide.\n\n        The chart is positioned at (*x*, *y*), has size (*cx*, *cy*), and\n        depicts *chart_data*. *chart_type* is one of the :ref:`XlChartType`\n        enumeration values. *chart_data* is a |ChartData| object populated\n        with the categories and series values for the chart.\n\n        Note that a |GraphicFrame| shape object is returned, not the |Chart|\n        object contained in that graphic frame shape. The chart object may be\n        accessed using the :attr:`chart` property of the returned\n        |GraphicFrame| object.\n        \"\"\"\n        rId = self.part.add_chart_part(chart_type, chart_data)\n        graphicFrame = self._add_chart_graphicFrame(rId, x, y, cx, cy)\n        self._recalculate_extents()\n        return self._shape_factory(graphicFrame)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nadding a new connector shape to the end of this shape tree.", "response": "def add_connector(self, connector_type, begin_x, begin_y, end_x, end_y):\n        \"\"\"Add a newly created connector shape to the end of this shape tree.\n\n        *connector_type* is a member of the :ref:`MsoConnectorType`\n        enumeration and the end-point values are specified as EMU values. The\n        returned connector is of type *connector_type* and has begin and end\n        points as specified.\n        \"\"\"\n        cxnSp = self._add_cxnSp(\n            connector_type, begin_x, begin_y, end_x, end_y\n        )\n        self._recalculate_extents()\n        return self._shape_factory(cxnSp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_group_shape(self, shapes=[]):\n        grpSp = self._element.add_grpSp()\n        for shape in shapes:\n            grpSp.insert_element_before(shape._element, 'p:extLst')\n        if shapes:\n            grpSp.recalculate_extents()\n        return self._shape_factory(grpSp)", "response": "Return a |GroupShape| object newly appended to this shape tree."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a picture shape displaying image in image_file.", "response": "def add_picture(self, image_file, left, top, width=None, height=None):\n        \"\"\"Add picture shape displaying image in *image_file*.\n\n        *image_file* can be either a path to a file (a string) or a file-like\n        object. The picture is positioned with its top-left corner at (*top*,\n        *left*). If *width* and *height* are both |None|, the native size of\n        the image is used. If only one of *width* or *height* is used, the\n        unspecified dimension is calculated to preserve the aspect ratio of\n        the image. If both are specified, the picture is stretched to fit,\n        without regard to its native aspect ratio.\n        \"\"\"\n        image_part, rId = self.part.get_or_add_image_part(image_file)\n        pic = self._add_pic_from_image_part(\n            image_part, rId, left, top, width, height\n        )\n        self._recalculate_extents()\n        return self._shape_factory(pic)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns |Shape| object appended to this shape tree.", "response": "def add_shape(self, autoshape_type_id, left, top, width, height):\n        \"\"\"Return new |Shape| object appended to this shape tree.\n\n        *autoshape_type_id* is a member of :ref:`MsoAutoShapeType` e.g.\n        ``MSO_SHAPE.RECTANGLE`` specifying the type of shape to be added. The\n        remaining arguments specify the new shape's position and size.\n        \"\"\"\n        autoshape_type = AutoShapeType(autoshape_type_id)\n        sp = self._add_sp(autoshape_type, left, top, width, height)\n        self._recalculate_extents()\n        return self._shape_factory(sp)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef add_textbox(self, left, top, width, height):\n        sp = self._add_textbox_sp(left, top, width, height)\n        self._recalculate_extents()\n        return self._shape_factory(sp)", "response": "Returns a new shape with the specified left top width and height."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn |FreeformBuilder| object to specify a freeform shape.", "response": "def build_freeform(self, start_x=0, start_y=0, scale=1.0):\n        \"\"\"Return |FreeformBuilder| object to specify a freeform shape.\n\n        The optional *start_x* and *start_y* arguments specify the starting\n        pen position in local coordinates. They will be rounded to the\n        nearest integer before use and each default to zero.\n\n        The optional *scale* argument specifies the size of local coordinates\n        proportional to slide coordinates (EMU). If the vertical scale is\n        different than the horizontal scale (local coordinate units are\n        \"rectangular\"), a pair of numeric values can be provided as the\n        *scale* argument, e.g. `scale=(1.0, 2.0)`. In this case the first\n        number is interpreted as the horizontal (X) scale and the second as\n        the vertical (Y) scale.\n\n        A convenient method for calculating scale is to divide a |Length|\n        object by an equivalent count of local coordinate units, e.g.\n        `scale = Inches(1)/1000` for 1000 local units per inch.\n        \"\"\"\n        try:\n            x_scale, y_scale = scale\n        except TypeError:\n            x_scale = y_scale = scale\n\n        return FreeformBuilder.new(self, start_x, start_y, x_scale, y_scale)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef index(self, shape):\n        shape_elms = list(self._element.iter_shape_elms())\n        return shape_elms.index(shape.element)", "response": "Return the index of shape in this sequence. Raises |ValueError| if shape is not in this sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_chart_graphicFrame(self, rId, x, y, cx, cy):\n        shape_id = self._next_shape_id\n        name = 'Chart %d' % (shape_id-1)\n        graphicFrame = CT_GraphicalObjectFrame.new_chart_graphicFrame(\n            shape_id, name, rId, x, y, cx, cy\n        )\n        self._spTree.append(graphicFrame)\n        return graphicFrame", "response": "Return new graphicFrame element appended to this shape tree."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _add_cxnSp(self, connector_type, begin_x, begin_y, end_x, end_y):\n        id_ = self._next_shape_id\n        name = 'Connector %d' % (id_-1)\n\n        flipH, flipV = begin_x > end_x, begin_y > end_y\n        x, y = min(begin_x, end_x), min(begin_y, end_y)\n        cx, cy = abs(end_x - begin_x), abs(end_y - begin_y)\n\n        return self._element.add_cxnSp(\n            id_, name, connector_type, x, y, cx, cy, flipH, flipV\n        )", "response": "Return a newly - added cxnSp element as specified."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a newly appended p : pic element as specified.", "response": "def _add_pic_from_image_part(self, image_part, rId, x, y, cx, cy):\n        \"\"\"Return a newly appended `p:pic` element as specified.\n\n        The `p:pic` element displays the image in *image_part* with size and\n        position specified by *x*, *y*, *cx*, and *cy*. The element is\n        appended to the shape tree, causing it to be displayed first in\n        z-order on the slide.\n        \"\"\"\n        id_ = self._next_shape_id\n        scaled_cx, scaled_cy = image_part.scale(cx, cy)\n        name = 'Picture %d' % (id_-1)\n        desc = image_part.desc\n        pic = self._grpSp.add_pic(\n            id_, name, desc, rId, x, y, scaled_cx, scaled_cy\n        )\n        return pic"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nadds a new sp element to the group.", "response": "def _add_sp(self, autoshape_type, x, y, cx, cy):\n        \"\"\"Return newly-added `p:sp` element as specified.\n\n        `p:sp` element is of *autoshape_type* at position (*x*, *y*) and of\n        size (*cx*, *cy*).\n        \"\"\"\n        id_ = self._next_shape_id\n        name = '%s %d' % (autoshape_type.basename, id_-1)\n        sp = self._grpSp.add_autoshape(\n            id_, name, autoshape_type.prst, x, y, cx, cy\n        )\n        return sp"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn newly - appended textbox element.", "response": "def _add_textbox_sp(self, x, y, cx, cy):\n        \"\"\"Return newly-appended textbox `p:sp` element.\n\n        Element has position (*x*, *y*) and size (*cx*, *cy*).\n        \"\"\"\n        id_ = self._next_shape_id\n        name = 'TextBox %d' % (id_-1)\n        sp = self._spTree.add_textbox(id_, name, x, y, cx, cy)\n        return sp"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_movie(self, movie_file, left, top, width, height,\n                  poster_frame_image=None, mime_type=CT.VIDEO):\n        \"\"\"Return newly added movie shape displaying video in *movie_file*.\n\n        **EXPERIMENTAL.** This method has important limitations:\n\n        * The size must be specified; no auto-scaling such as that provided\n          by :meth:`add_picture` is performed.\n        * The MIME type of the video file should be specified, e.g.\n          'video/mp4'. The provided video file is not interrogated for its\n          type. The MIME type `video/unknown` is used by default (and works\n          fine in tests as of this writing).\n        * A poster frame image must be provided, it cannot be automatically\n          extracted from the video file. If no poster frame is provided, the\n          default \"media loudspeaker\" image will be used.\n\n        Return a newly added movie shape to the slide, positioned at (*left*,\n        *top*), having size (*width*, *height*), and containing *movie_file*.\n        Before the video is started, *poster_frame_image* is displayed as\n        a placeholder for the video.\n        \"\"\"\n        movie_pic = _MoviePicElementCreator.new_movie_pic(\n            self, self._next_shape_id, movie_file, left, top, width, height,\n            poster_frame_image, mime_type\n        )\n        self._spTree.append(movie_pic)\n        self._add_video_timing(movie_pic)\n        return self._shape_factory(movie_pic)", "response": "Add a movie to the slide."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_table(self, rows, cols, left, top, width, height):\n        graphicFrame = self._add_graphicFrame_containing_table(\n            rows, cols, left, top, width, height\n        )\n        graphic_frame = self._shape_factory(graphicFrame)\n        return graphic_frame", "response": "Add a |GraphicFrame| object containing a table with the specified number of rows and cols and the specified position and size."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the title placeholder shape on the slide or |None| if the slide has no title placeholder.", "response": "def title(self):\n        \"\"\"\n        The title placeholder shape on the slide or |None| if the slide has\n        no title placeholder.\n        \"\"\"\n        for elm in self._spTree.iter_ph_elms():\n            if elm.ph_idx == 0:\n                return self._shape_factory(elm)\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _add_graphicFrame_containing_table(self, rows, cols, x, y, cx, cy):\n        _id = self._next_shape_id\n        name = 'Table %d' % (_id-1)\n        graphicFrame = self._spTree.add_table(\n            _id, name, rows, cols, x, y, cx, cy\n        )\n        return graphicFrame", "response": "Add a new graphicFrame containing a table containing a specific region."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _add_video_timing(self, pic):\n        sld = self._spTree.xpath('/p:sld')[0]\n        childTnLst = sld.get_or_add_childTnLst()\n        childTnLst.add_video(pic.shape_id)", "response": "Add a video timing element under the sld element under p : timing."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the base name for a specific placeholder of type ph_type in this shape .", "response": "def ph_basename(self, ph_type):\n        \"\"\"\n        Return the base name for a placeholder of *ph_type* in this shape\n        collection. A notes slide uses a different name for the body\n        placeholder and has some unique placeholder types, so this\n        method overrides the default in the base class.\n        \"\"\"\n        return {\n            PP_PLACEHOLDER.BODY:         'Notes Placeholder',\n            PP_PLACEHOLDER.DATE:         'Date Placeholder',\n            PP_PLACEHOLDER.FOOTER:       'Footer Placeholder',\n            PP_PLACEHOLDER.HEADER:       'Header Placeholder',\n            PP_PLACEHOLDER.SLIDE_IMAGE:  'Slide Image Placeholder',\n            PP_PLACEHOLDER.SLIDE_NUMBER: 'Slide Number Placeholder',\n        }[ph_type]"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the first shape with matching idx value or default if not found.", "response": "def get(self, idx, default=None):\n        \"\"\"\n        Return the first placeholder shape with matching *idx* value, or\n        *default* if not found.\n        \"\"\"\n        for placeholder in self:\n            if placeholder.element.ph_idx == idx:\n                return placeholder\n        return default"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get(self, ph_type, default=None):\n        for placeholder in self:\n            if placeholder.ph_type == ph_type:\n                return placeholder\n        return default", "response": "Return the first placeholder shape with type ph_type or default if no such shape is present in the collection."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_movie_pic(cls, shapes, shape_id, movie_file, x, y, cx, cy,\n                      poster_frame_image, mime_type):\n        \"\"\"Return a new `p:pic` element containing video in *movie_file*.\n\n        If *mime_type* is None, 'video/unknown' is used. If\n        *poster_frame_file* is None, the default \"media loudspeaker\" image is\n        used.\n        \"\"\"\n        return cls(\n            shapes, shape_id, movie_file, x, y, cx, cy, poster_frame_image,\n            mime_type\n        )._pic\n        return", "response": "Return a new p : pic element containing video in movie_file."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the new p : pic element referencing the video.", "response": "def _pic(self):\n        \"\"\"Return the new `p:pic` element referencing the video.\"\"\"\n        return CT_Picture.new_video_pic(\n            self._shape_id, self._shape_name, self._video_rId,\n            self._media_rId, self._poster_frame_rId, self._x, self._y,\n            self._cx, self._cy\n        )"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the rId of relationship to poster frame image.", "response": "def _poster_frame_rId(self):\n        \"\"\"Return the rId of relationship to poster frame image.\n\n        The poster frame is the image used to represent the video before it's\n        played.\n        \"\"\"\n        _, poster_frame_rId = self._slide_part.get_or_add_image_part(\n            self._poster_frame_image_file\n        )\n        return poster_frame_rId"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the rIds for relationships to video.", "response": "def _video_part_rIds(self):\n        \"\"\"Return the rIds for relationships to media part for video.\n\n        This is where the media part and its relationships to the slide are\n        actually created.\n        \"\"\"\n        media_rId, video_rId = self._slide_part.get_or_add_video_media_part(\n            self._video\n        )\n        return media_rId, video_rId"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef effective_value(self):\n        raw_value = self.actual\n        if raw_value is None:\n            raw_value = self.def_val\n        return self._normalize(raw_value)", "response": "The value of the actual value for this\n       ."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn an initialized list of adjustment values based on the contents of prstGeom", "response": "def _initialized_adjustments(self, prstGeom):\n        \"\"\"\n        Return an initialized list of adjustment values based on the contents\n        of *prstGeom*\n        \"\"\"\n        if prstGeom is None:\n            return []\n        davs = AutoShapeType.default_adjustment_values(prstGeom.prst)\n        adjustments = [Adjustment(name, def_val) for name, def_val in davs]\n        self._update_adjustments_with_actuals(adjustments, prstGeom.gd_lst)\n        return adjustments"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _rewrite_guides(self):\n        guides = [(adj.name, adj.val) for adj in self._adjustments_]\n        self._prstGeom.rewrite_guides(guides)", "response": "Write guide elements to the XML."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _update_adjustments_with_actuals(adjustments, guides):\n        adjustments_by_name = dict((adj.name, adj) for adj in adjustments)\n        for gd in guides:\n            name = gd.name\n            actual = int(gd.fmla[4:])\n            try:\n                adjustment = adjustments_by_name[name]\n            except KeyError:\n                continue\n            adjustment.actual = actual\n        return", "response": "Update |Adjustment| instances in *adjustments* with actual values held in guides."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the type of this shape.", "response": "def shape_type(self):\n        \"\"\"\n        Unique integer identifying the type of this shape, like\n        ``MSO_SHAPE_TYPE.TEXT_BOX``.\n        \"\"\"\n        if self.is_placeholder:\n            return MSO_SHAPE_TYPE.PLACEHOLDER\n        if self._sp.has_custom_geometry:\n            return MSO_SHAPE_TYPE.FREEFORM\n        if self._sp.is_autoshape:\n            return MSO_SHAPE_TYPE.AUTO_SHAPE\n        if self._sp.is_textbox:\n            return MSO_SHAPE_TYPE.TEXT_BOX\n        msg = 'Shape instance of unrecognized shape type'\n        raise NotImplementedError(msg)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef new_cxnSp(cls, id_, name, prst, x, y, cx, cy, flipH, flipV):\n        tmpl = cls._cxnSp_tmpl()\n        flip = (\n            (' flipH=\"1\"' if flipH else '') + (' flipV=\"1\"' if flipV else '')\n        )\n        xml = tmpl.format(**{\n            'nsdecls': nsdecls('a', 'p'),\n            'id':      id_,\n            'name':    name,\n            'x':       x,\n            'y':       y,\n            'cx':      cx,\n            'cy':      cy,\n            'prst':    prst,\n            'flip':    flip,\n        })\n        return parse_xml(xml)", "response": "Return a new base cxnSp element tree configured as a base cxnSp connector."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef core_properties(self):\n        try:\n            return self.part_related_by(RT.CORE_PROPERTIES)\n        except KeyError:\n            core_props = CorePropertiesPart.default()\n            self.relate_to(core_props, RT.CORE_PROPERTIES)\n            return core_props", "response": "Return |CoreProperties| holding the read / write Dublin Core\n        document properties for this presentation."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a |PackURI| instance representing the next available image partname by sequence number.", "response": "def next_image_partname(self, ext):\n        \"\"\"\n        Return a |PackURI| instance representing the next available image\n        partname, by sequence number. *ext* is used as the extention on the\n        returned partname.\n        \"\"\"\n        def first_available_image_idx():\n            image_idxs = sorted([\n                part.partname.idx for part in self.iter_parts()\n                if part.partname.startswith('/ppt/media/image')\n                and part.partname.idx is not None\n            ])\n            for i, image_idx in enumerate(image_idxs):\n                idx = i + 1\n                if idx < image_idx:\n                    return idx\n            return len(image_idxs)+1\n\n        idx = first_available_image_idx()\n        return PackURI('/ppt/media/image%d.%s' % (idx, ext))"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef next_media_partname(self, ext):\n        def first_available_media_idx():\n            media_idxs = sorted([\n                part.partname.idx for part in self.iter_parts()\n                if part.partname.startswith('/ppt/media/media')\n            ])\n            for i, media_idx in enumerate(media_idxs):\n                idx = i + 1\n                if idx < media_idx:\n                    return idx\n            return len(media_idxs)+1\n\n        idx = first_available_media_idx()\n        return PackURI('/ppt/media/media%d.%s' % (idx, ext))", "response": "Return |PackURI| instance for next available media partname."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning an |ImagePart| object containing the image in image_file or a file - like object containing the image in image_file. If no image part with the same sha1 is found a new |ImagePart| object is returned.", "response": "def get_or_add_image_part(self, image_file):\n        \"\"\"\n        Return an |ImagePart| object containing the image in *image_file*,\n        which is either a path to an image file or a file-like object\n        containing an image. If an image part containing this same image\n        already exists, that instance is returned, otherwise a new image part\n        is created.\n        \"\"\"\n        image = Image.from_file(image_file)\n        image_part = self._find_by_sha1(image.sha1)\n        if image_part is None:\n            image_part = ImagePart.new(self._package, image)\n        return image_part"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _find_by_sha1(self, sha1):\n        for image_part in self:\n            # ---skip unknown/unsupported image types, like SVG---\n            if not hasattr(image_part, 'sha1'):\n                continue\n            if image_part.sha1 == sha1:\n                return image_part\n        return None", "response": "Find an image part by its SHA1 hash."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a |MediaPart| object containing the media in *media*. If this package already contains a media part for the same sha1 bytestream then a new |MediaPart| object is returned. Otherwise a new |MediaPart| object is returned.", "response": "def get_or_add_media_part(self, media):\n        \"\"\"Return a |MediaPart| object containing the media in *media*.\n\n        If this package already contains a media part for the same\n        bytestream, that instance is returned, otherwise a new media part is\n        created.\n        \"\"\"\n        media_part = self._find_by_sha1(media.sha1)\n        if media_part is None:\n            media_part = MediaPart.new(self._package, media)\n        return media_part"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_or_add_image_part(self, image_file):\n        image_part = self._package.get_or_add_image_part(image_file)\n        rId = self.relate_to(image_part, RT.IMAGE)\n        return image_part, rId", "response": "Get or add an image part to this slide with the key rId."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_default(cls, package):\n        notes_master_part = cls._new(package)\n        theme_part = cls._new_theme_part(package)\n        notes_master_part.relate_to(theme_part, RT.THEME)\n        return notes_master_part", "response": "Create and return a default notes master part including creating the\n        new theme it requires."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _new(cls, package):\n        partname = PackURI('/ppt/notesMasters/notesMaster1.xml')\n        content_type = CT.PML_NOTES_MASTER\n        notesMaster = CT_NotesMaster.new_default()\n        return NotesMasterPart(partname, content_type, notesMaster, package)", "response": "Create and return a standalone default notes master part based on the built - in template."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _new_theme_part(cls, package):\n        partname = package.next_partname('/ppt/theme/theme%d.xml')\n        content_type = CT.OFC_THEME\n        theme = CT_OfficeStyleSheet.new_default()\n        return XmlPart(partname, content_type, theme, package)", "response": "Create and return a default theme part suitable for use with a notes\n        master."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new(cls, package, slide_part):\n        notes_master_part = package.presentation_part.notes_master_part\n        notes_slide_part = cls._add_notes_slide_part(\n            package, slide_part, notes_master_part\n        )\n        notes_slide = notes_slide_part.notes_slide\n        notes_slide.clone_master_placeholders(notes_master_part.notes_master)\n        return notes_slide_part", "response": "Create and return a new notes slide part based on the master and slide_part."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ncreating and return a new notes slide part that is fully related to the given slide_part and the given notes master_part.", "response": "def _add_notes_slide_part(cls, package, slide_part, notes_master_part):\n        \"\"\"\n        Create and return a new notes slide part that is fully related, but\n        has no shape content (i.e. placeholders not cloned).\n        \"\"\"\n        partname = package.next_partname('/ppt/notesSlides/notesSlide%d.xml')\n        content_type = CT.PML_NOTES_SLIDE\n        notes = CT_NotesSlide.new()\n        notes_slide_part = NotesSlidePart(\n            partname, content_type, notes, package\n        )\n        notes_slide_part.relate_to(notes_master_part, RT.NOTES_MASTER)\n        notes_slide_part.relate_to(slide_part, RT.SLIDE)\n        return notes_slide_part"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a newly - created blank slide part having partname and related to slide_layout_part.", "response": "def new(cls, partname, package, slide_layout_part):\n        \"\"\"\n        Return a newly-created blank slide part having *partname* and related\n        to *slide_layout_part*.\n        \"\"\"\n        sld = CT_Slide.new()\n        slide_part = cls(partname, CT.PML_SLIDE, sld, package)\n        slide_part.relate_to(slide_layout_part, RT.SLIDE_LAYOUT)\n        return slide_part"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the rId of a new |ChartPart| object containing a chart of chart_type displaying chart_data and related to the slide contained in this part.", "response": "def add_chart_part(self, chart_type, chart_data):\n        \"\"\"\n        Return the rId of a new |ChartPart| object containing a chart of\n        *chart_type*, displaying *chart_data*, and related to the slide\n        contained in this part.\n        \"\"\"\n        chart_part = ChartPart.new(chart_type, chart_data, self.package)\n        rId = self.relate_to(chart_part, RT.CHART)\n        return rId"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning rIds for media and video relationships to media part.", "response": "def get_or_add_video_media_part(self, video):\n        \"\"\"Return rIds for media and video relationships to media part.\n\n        A new |MediaPart| object is created if it does not already exist\n        (such as would occur if the same video appeared more than once in\n         a presentation). Two relationships to the media part are created,\n        one each with MEDIA and VIDEO relationship types. The need for two\n        appears to be for legacy support for an earlier (pre-Office 2010)\n        PowerPoint media embedding strategy.\n        \"\"\"\n        media_part = self._package.get_or_add_media_part(video)\n        media_rId = self.relate_to(media_part, RT.MEDIA)\n        video_rId = self.relate_to(media_part, RT.VIDEO)\n        return media_rId, video_rId"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef notes_slide(self):\n        try:\n            notes_slide_part = self.part_related_by(RT.NOTES_SLIDE)\n        except KeyError:\n            notes_slide_part = self._add_notes_slide_part()\n        return notes_slide_part.notes_slide", "response": "Returns |NotesSlide| instance associated with this slide."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nadds a new |NotesSlidePart| object related to this slide.", "response": "def _add_notes_slide_part(self):\n        \"\"\"\n        Return a newly created |NotesSlidePart| object related to this slide\n        part. Caller is responsible for ensuring this slide doesn't already\n        have a notes slide part.\n        \"\"\"\n        notes_slide_part = NotesSlidePart.new(self.package, self)\n        self.relate_to(notes_slide_part, RT.NOTES_SLIDE)\n        return notes_slide_part"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new p : bgPr element with noFill properties.", "response": "def add_noFill_bgPr(self):\n        \"\"\"Return a new `p:bgPr` element with noFill properties.\"\"\"\n        xml = (\n            '<p:bgPr %s>\\n'\n            '  <a:noFill/>\\n'\n            '  <a:effectLst/>\\n'\n            '</p:bgPr>' % nsdecls('a', 'p')\n        )\n        bgPr = parse_xml(xml)\n        self._insert_bgPr(bgPr)\n        return bgPr"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_or_add_bgPr(self):\n        bg = self.bg\n        if bg is None or bg.bgPr is None:\n            self._change_to_noFill_bg()\n        return self.bg.bgPr", "response": "Return the grandchild s backgroundPr or add it if it does not exist."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _change_to_noFill_bg(self):\n        self._remove_bg()\n        bg = self.get_or_add_bg()\n        bg.add_noFill_bgPr()\n        return bg", "response": "Establish a new bg child with no - fill settings."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_or_add_childTnLst(self):\n        childTnLst = self._childTnLst\n        if childTnLst is None:\n            childTnLst = self._add_childTnLst()\n        return childTnLst", "response": "Return parent element for a new video child element."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nadds a child TnLst element to the set of child TNs.", "response": "def _add_childTnLst(self):\n        \"\"\"Add `./p:timing/p:tnLst/p:par/p:cTn/p:childTnLst` descendant.\n\n        Any existing `p:timing` child element is ruthlessly removed and\n        replaced.\n        \"\"\"\n        self.remove(self.get_or_add_timing())\n        timing = parse_xml(self._childTnLst_timing_xml())\n        self._insert_timing(timing)\n        return timing.xpath('./p:tnLst/p:par/p:cTn/p:childTnLst')[0]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_video(self, shape_id):\n        video_xml = (\n            '<p:video %s>\\n'\n            '  <p:cMediaNode vol=\"80000\">\\n'\n            '    <p:cTn id=\"%d\" fill=\"hold\" display=\"0\">\\n'\n            '      <p:stCondLst>\\n'\n            '        <p:cond delay=\"indefinite\"/>\\n'\n            '      </p:stCondLst>\\n'\n            '    </p:cTn>\\n'\n            '    <p:tgtEl>\\n'\n            '      <p:spTgt spid=\"%d\"/>\\n'\n            '    </p:tgtEl>\\n'\n            '  </p:cMediaNode>\\n'\n            '</p:video>\\n' % (nsdecls('p'), self._next_cTn_id, shape_id)\n        )\n        video = parse_xml(video_xml)\n        self.append(video)", "response": "Add a new video element for movie having shape_id *."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the next available unique ID for p : cTn element.", "response": "def _next_cTn_id(self):\n        \"\"\"Return the next available unique ID (int) for p:cTn element.\"\"\"\n        cTn_id_strs = self.xpath('/p:sld/p:timing//p:cTn/@id')\n        ids = [int(id_str) for id_str in cTn_id_strs]\n        return max(ids) + 1"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a byte stream of an Excel file formatted as chart data for the category chart specified in the chart data object.", "response": "def xlsx_blob(self):\n        \"\"\"\n        Return the byte stream of an Excel file formatted as chart data for\n        the category chart specified in the chart data object.\n        \"\"\"\n        xlsx_file = BytesIO()\n        with self._open_worksheet(xlsx_file) as (workbook, worksheet):\n            self._populate_worksheet(workbook, worksheet)\n        return xlsx_file.getvalue()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nopening a new XlsxWriter Worksheet object and yield it.", "response": "def _open_worksheet(self, xlsx_file):\n        \"\"\"\n        Enable XlsxWriter Worksheet object to be opened, operated on, and\n        then automatically closed within a `with` statement. A filename or\n        stream object (such as a ``BytesIO`` instance) is expected as\n        *xlsx_file*.\n        \"\"\"\n        workbook = Workbook(xlsx_file, {'in_memory': True})\n        worksheet = workbook.add_worksheet()\n        yield workbook, worksheet\n        workbook.close()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef categories_ref(self):\n        categories = self._chart_data.categories\n        if categories.depth == 0:\n            raise ValueError('chart data contains no categories')\n        right_col = chr(ord('A') + categories.depth - 1)\n        bottom_row = categories.leaf_count + 1\n        return \"Sheet1!$A$2:$%s$%d\" % (right_col, bottom_row)", "response": "A string that represents the reference to the categories for this chart."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _column_reference(column_number):\n        if column_number < 1 or column_number > 16384:\n            raise ValueError('column_number must be in range 1-16384')\n\n        # ---Work right-to-left, one order of magnitude at a time. Note there\n        #    is no zero representation in Excel address scheme, so this is\n        #    not just a conversion to base-26---\n\n        col_ref = ''\n        while column_number:\n            remainder = column_number % 26\n            if remainder == 0:\n                remainder = 26\n\n            col_letter = chr(ord('A') + remainder - 1)\n            col_ref = col_letter + col_ref\n\n            # ---Advance to next order of magnitude or terminate loop. The\n            # minus-one in this expression reflects the fact the next lower\n            # order of magnitude has a minumum value of 1 (not zero). This is\n            # essentially the complement to the \"if it's 0 make it 26' step\n            # above.---\n            column_number = (column_number - 1) // 26\n\n        return col_ref", "response": "Return str Excel column reference like BQ for column_number."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _populate_worksheet(self, workbook, worksheet):\n        self._write_categories(workbook, worksheet)\n        self._write_series(workbook, worksheet)", "response": "Populates the contents of the given worksheet with the data from the given workbook."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _series_col_letter(self, series):\n        column_number = 1 + series.categories.depth + series.index\n        return self._column_reference(column_number)", "response": "Returns the letter of the Excel worksheet column in which the data for a\n        series appears."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _write_categories(self, workbook, worksheet):\n        categories = self._chart_data.categories\n        num_format = workbook.add_format({\n            'num_format': categories.number_format,\n        })\n        depth = categories.depth\n        for idx, level in enumerate(categories.levels):\n            col = depth - idx - 1\n            self._write_cat_column(worksheet, col, level, num_format)", "response": "Write the categories column to the given worksheet."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _write_cat_column(self, worksheet, col, level, num_format):\n        worksheet.set_column(col, col, 10)  # wide enough for a date\n        for off, name in level:\n            row = off + 1\n            worksheet.write(row, col, name, num_format)", "response": "Write a category column defined by level to worksheet at col."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nwrite the series column to the given worksheet.", "response": "def _write_series(self, workbook, worksheet):\n        \"\"\"\n        Write the series column(s) to *worksheet*. Series start in the column\n        following the last categories column, placing the series title in the\n        first cell.\n        \"\"\"\n        col_offset = self._chart_data.categories.depth\n        for idx, series in enumerate(self._chart_data):\n            num_format = (\n                workbook.add_format({'num_format': series.number_format})\n            )\n            series_col = idx + col_offset\n            worksheet.write(0, series_col, series.name)\n            worksheet.write_column(1, series_col, series.values, num_format)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef series_table_row_offset(self, series):\n        title_and_spacer_rows = series.index * 2\n        data_point_rows = series.data_point_offset\n        return title_and_spacer_rows + data_point_rows", "response": "Return the number of rows preceding the data table for a series in the Excel worksheet."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the reference to the range containing the bubble sizes for the given series.", "response": "def bubble_sizes_ref(self, series):\n        \"\"\"\n        The Excel worksheet reference to the range containing the bubble\n        sizes for *series* (not including the column heading cell).\n        \"\"\"\n        top_row = self.series_table_row_offset(series) + 2\n        bottom_row = top_row + len(series) - 1\n        return \"Sheet1!$C$%d:$C$%d\" % (top_row, bottom_row)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _populate_worksheet(self, workbook, worksheet):\n        chart_num_format = workbook.add_format(\n            {'num_format': self._chart_data.number_format}\n        )\n        for series in self._chart_data:\n            series_num_format = (\n                workbook.add_format({'num_format': series.number_format})\n            )\n            offset = self.series_table_row_offset(series)\n            # write X values\n            worksheet.write_column(\n                offset+1, 0, series.x_values, chart_num_format\n            )\n            # write Y values\n            worksheet.write(offset, 1, series.name)\n            worksheet.write_column(\n                offset+1, 1, series.y_values, series_num_format\n            )\n            # write bubble sizes\n            worksheet.write(offset, 2, 'Size')\n            worksheet.write_column(\n                offset+1, 2, series.bubble_sizes, chart_num_format\n            )", "response": "Populates the given worksheet with the data from the chart data."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef PlotFactory(xChart, chart):\n    try:\n        PlotCls = {\n            qn('c:areaChart'):     AreaPlot,\n            qn('c:area3DChart'):   Area3DPlot,\n            qn('c:barChart'):      BarPlot,\n            qn('c:bubbleChart'):   BubblePlot,\n            qn('c:doughnutChart'): DoughnutPlot,\n            qn('c:lineChart'):     LinePlot,\n            qn('c:pieChart'):      PiePlot,\n            qn('c:radarChart'):    RadarPlot,\n            qn('c:scatterChart'):  XyPlot,\n        }[xChart.tag]\n    except KeyError:\n        raise ValueError('unsupported plot type %s' % xChart.tag)\n\n    return PlotCls(xChart, chart)", "response": "Returns an instance of the appropriate class based on the passed in xChart."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn |DataLabels| instance providing properties and methods on the collection of data labels associated with this plot.", "response": "def data_labels(self):\n        \"\"\"\n        |DataLabels| instance providing properties and methods on the\n        collection of data labels associated with this plot.\n        \"\"\"\n        dLbls = self._element.dLbls\n        if dLbls is None:\n            raise ValueError(\n                'plot has no data labels, set has_data_labels = True first'\n            )\n        return DataLabels(dLbls)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nchecks if the data labels of the current node are present.", "response": "def has_data_labels(self, value):\n        \"\"\"\n        Add, remove, or leave alone the ``<c:dLbls>`` child element depending\n        on current state and assigned *value*. If *value* is |True| and no\n        ``<c:dLbls>`` element is present, a new default element is added with\n        default child elements and settings. When |False|, any existing dLbls\n        element is removed.\n        \"\"\"\n        if bool(value) is False:\n            self._element._remove_dLbls()\n        else:\n            if self._element.dLbls is None:\n                dLbls = self._element._add_dLbls()\n                dLbls.showVal.val = True"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nread or write boolean value specifying whether to use a different color for each of the points in this plot. Only effective when there is at least one series in this plot.", "response": "def vary_by_categories(self):\n        \"\"\"\n        Read/write boolean value specifying whether to use a different color\n        for each of the points in this plot. Only effective when there is\n        a single series; PowerPoint automatically varies color by series when\n        more than one series is present.\n        \"\"\"\n        varyColors = self._element.varyColors\n        if varyColors is None:\n            return True\n        return varyColors.val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef overlap(self, value):\n        if value == 0:\n            self._element._remove_overlap()\n            return\n        self._element.get_or_add_overlap().val = value", "response": "Sets the value of the <c : overlap > child element to value."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef chart_type(cls, plot):\n        try:\n            chart_type_method = {\n                'AreaPlot':     cls._differentiate_area_chart_type,\n                'Area3DPlot':   cls._differentiate_area_3d_chart_type,\n                'BarPlot':      cls._differentiate_bar_chart_type,\n                'BubblePlot':   cls._differentiate_bubble_chart_type,\n                'DoughnutPlot': cls._differentiate_doughnut_chart_type,\n                'LinePlot':     cls._differentiate_line_chart_type,\n                'PiePlot':      cls._differentiate_pie_chart_type,\n                'RadarPlot':    cls._differentiate_radar_chart_type,\n                'XyPlot':       cls._differentiate_xy_chart_type,\n            }[plot.__class__.__name__]\n        except KeyError:\n            raise NotImplementedError(\n                \"chart_type() not implemented for %s\" %\n                plot.__class__.__name__\n            )\n        return chart_type_method(plot)", "response": "Returns the XlChartType member of the plot class that corresponds to the chart type of plot."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nvalue of p : blipFill. blip Returns |None| if not present.", "response": "def blip_rId(self):\n        \"\"\"Value of `p:blipFill/a:blip/@r:embed`.\n\n        Returns |None| if not present.\n        \"\"\"\n        blip = self.blipFill.blip\n        if blip is not None and blip.rEmbed is not None:\n            return blip.rEmbed\n        return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncrop the image of the species to fit the view_size.", "response": "def crop_to_fit(self, image_size, view_size):\n        \"\"\"\n        Set cropping values in `p:blipFill/a:srcRect` such that an image of\n        *image_size* will stretch to exactly fit *view_size* when its aspect\n        ratio is preserved.\n        \"\"\"\n        self.blipFill.crop(self._fill_cropping(image_size, view_size))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef new_ph_pic(cls, id_, name, desc, rId):\n        return parse_xml(\n            cls._pic_ph_tmpl() % (id_, name, desc, rId)\n        )", "response": "Return a new p : pic element populated with the supplied parameters."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nreturns a new element tree configured with the supplied parameters.", "response": "def new_pic(cls, id_, name, desc, rId, left, top, width, height):\n        \"\"\"\n        Return a new ``<p:pic>`` element tree configured with the supplied\n        parameters.\n        \"\"\"\n        xml = cls._pic_tmpl() % (\n            id_, name, desc, rId, left, top, width, height\n        )\n        pic = parse_xml(xml)\n        return pic"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef new_video_pic(cls, shape_id, shape_name, video_rId, media_rId,\n                      poster_frame_rId, x, y, cx, cy):\n        \"\"\"Return a new `p:pic` populated with the specified video.\"\"\"\n        return parse_xml(\n            cls._pic_video_tmpl() % (\n                shape_id, shape_name, video_rId, media_rId, poster_frame_rId,\n                x, y, cx, cy\n            )\n        )", "response": "Return a new p : pic populated with the specified video."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfilling the cropping tuple for the image size and view size.", "response": "def _fill_cropping(self, image_size, view_size):\n        \"\"\"\n        Return a (left, top, right, bottom) 4-tuple containing the cropping\n        values required to display an image of *image_size* in *view_size*\n        when stretched proportionately. Each value is a percentage expressed\n        as a fraction of 1.0, e.g. 0.425 represents 42.5%. *image_size* and\n        *view_size* are each (width, height) pairs.\n        \"\"\"\n        def aspect_ratio(width, height):\n            return width / height\n\n        ar_view = aspect_ratio(*view_size)\n        ar_image = aspect_ratio(*image_size)\n\n        if ar_view < ar_image:  # image too wide\n            crop = (1.0 - (ar_view/ar_image)) / 2.0\n            return (crop, 0.0, crop, 0.0)\n        if ar_view > ar_image:  # image too tall\n            crop = (1.0 - (ar_image/ar_view)) / 2.0\n            return (0.0, crop, 0.0, crop)\n        return (0.0, 0.0, 0.0, 0.0)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _srcRect_x(self, attr_name):\n        srcRect = self.blipFill.srcRect\n        if srcRect is None:\n            return 0.0\n        return getattr(srcRect, attr_name)", "response": "Get the value of the attribute attr_name in srcRect or 0. 0 if not present."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef category_axis(self):\n        catAx_lst = self._chartSpace.catAx_lst\n        if catAx_lst:\n            return CategoryAxis(catAx_lst[0])\n\n        dateAx_lst = self._chartSpace.dateAx_lst\n        if dateAx_lst:\n            return DateAxis(dateAx_lst[0])\n\n        valAx_lst = self._chartSpace.valAx_lst\n        if valAx_lst:\n            return ValueAxis(valAx_lst[0])\n\n        raise ValueError('chart has no category axis')", "response": "Returns the category axis of this chart."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef font(self):\n        defRPr = (\n            self._chartSpace\n                .get_or_add_txPr()\n                .p_lst[0]\n                .get_or_add_pPr()\n                .get_or_add_defRPr()\n        )\n        return Font(defRPr)", "response": "Return a Font object controlling text format defaults for this chart."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef has_title(self):\n        title = self._chartSpace.chart.title\n        if title is None:\n            return False\n        return True", "response": "Read / write boolean specifying whether this chart has a title."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef plots(self):\n        plotArea = self._chartSpace.chart.plotArea\n        return _Plots(plotArea, self)", "response": "A |_Plots| object containing all the plots that are in this chart. Each |_Plots| object is returned."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef replace_data(self, chart_data):\n        rewriter = SeriesXmlRewriterFactory(self.chart_type, chart_data)\n        rewriter.replace_series_data(self._chartSpace)\n        self._workbook.update_from_xlsx_blob(chart_data.xlsx_blob)", "response": "Replace the data in the chart with the data in the Excel worksheet."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn |ValueAxis| object providing access to properties of the value axis of this chart. Raises |ValueError| if the chart has no value axis.", "response": "def value_axis(self):\n        \"\"\"\n        The |ValueAxis| object providing access to properties of the value\n        axis of this chart. Raises |ValueError| if the chart has no value\n        axis.\n        \"\"\"\n        valAx_lst = self._chartSpace.valAx_lst\n        if not valAx_lst:\n            raise ValueError('chart has no value axis')\n\n        idx = 1 if len(valAx_lst) > 1 else 0\n        return ValueAxis(valAx_lst[idx])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef new(cls, package, image):\n        partname = package.next_image_partname(image.ext)\n        return cls(\n            partname, image.content_type, image.blob, package, image.filename\n        )", "response": "Return a new |ImagePart| instance containing image."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nscale the size of the internal memory area of the internal memory area of the entry in the EMU system.", "response": "def scale(self, scaled_cx, scaled_cy):\n        \"\"\"\n        Return scaled image dimensions in EMU based on the combination of\n        parameters supplied. If *scaled_cx* and *scaled_cy* are both |None|,\n        the native image size is returned. If neither *scaled_cx* nor\n        *scaled_cy* is |None|, their values are returned unchanged. If\n        a value is provided for either *scaled_cx* or *scaled_cy* and the\n        other is |None|, the missing value is calculated such that the\n        image's aspect ratio is preserved.\n        \"\"\"\n        image_cx, image_cy = self._native_size\n\n        if scaled_cx is None and scaled_cy is None:\n            scaled_cx = image_cx\n            scaled_cy = image_cy\n        elif scaled_cx is None:\n            scaling_factor = float(scaled_cy) / float(image_cy)\n            scaled_cx = int(round(image_cx * scaling_factor))\n        elif scaled_cy is None:\n            scaling_factor = float(scaled_cx) / float(image_cx)\n            scaled_cy = int(round(image_cy * scaling_factor))\n\n        return scaled_cx, scaled_cy"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _native_size(self):\n        EMU_PER_INCH = 914400\n        horz_dpi, vert_dpi = self._dpi\n        width_px, height_px = self._px_size\n\n        width = EMU_PER_INCH * width_px / horz_dpi\n        height = EMU_PER_INCH * height_px / vert_dpi\n\n        return width, height", "response": "Returns the width and height of the native image of the specified resource."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef from_file(cls, image_file):\n        if is_string(image_file):\n            # treat image_file as a path\n            with open(image_file, 'rb') as f:\n                blob = f.read()\n            filename = os.path.basename(image_file)\n        else:\n            # assume image_file is a file-like object\n            # ---reposition file cursor if it has one---\n            if callable(getattr(image_file, 'seek')):\n                image_file.seek(0)\n            blob = image_file.read()\n            filename = None\n\n        return cls.from_blob(blob, filename)", "response": "Return a |Image| object loaded from the given file."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dpi(self):\n        def int_dpi(dpi):\n            \"\"\"\n            Return an integer dots-per-inch value corresponding to *dpi*. If\n            *dpi* is |None|, a non-numeric type, less than 1 or greater than\n            2048, 72 is returned.\n            \"\"\"\n            try:\n                int_dpi = int(round(float(dpi)))\n                if int_dpi < 1 or int_dpi > 2048:\n                    int_dpi = 72\n            except (TypeError, ValueError):\n                int_dpi = 72\n            return int_dpi\n\n        def normalize_pil_dpi(pil_dpi):\n            \"\"\"\n            Return a (horz_dpi, vert_dpi) 2-tuple corresponding to *pil_dpi*,\n            the value for the 'dpi' key in the ``info`` dict of a PIL image.\n            If the 'dpi' key is not present or contains an invalid value,\n            ``(72, 72)`` is returned.\n            \"\"\"\n            if isinstance(pil_dpi, tuple):\n                return (int_dpi(pil_dpi[0]), int_dpi(pil_dpi[1]))\n            return (72, 72)\n\n        return normalize_pil_dpi(self._pil_props[2])", "response": "Return the dpi of the image file."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef ext(self):\n        ext_map = {\n            'BMP': 'bmp', 'GIF': 'gif', 'JPEG': 'jpg', 'PNG': 'png',\n            'TIFF': 'tiff', 'WMF': 'wmf'\n        }\n        format = self._format\n        if format not in ext_map:\n            tmpl = \"unsupported image format, expected one of: %s, got '%s'\"\n            raise ValueError(tmpl % (ext_map.keys(), format))\n        return ext_map[format]", "response": "Returns the canonical file extension for this image e. g. png."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef _pil_props(self):\n        stream = BytesIO(self._blob)\n        pil_image = PIL_Image.open(stream)\n        format = pil_image.format\n        width_px, height_px = pil_image.size\n        dpi = pil_image.info.get('dpi')\n        stream.close()\n        return (format, (width_px, height_px), dpi)", "response": "A tuple containing useful image properties extracted from this image\n        using Pillow."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef is_empty(self):\n        ps = self.p_lst\n        if len(ps) > 1:\n            return False\n\n        if not ps:\n            raise InvalidXmlError('p:txBody must have at least one a:p')\n\n        if ps[0].text != '':\n            return False\n        return True", "response": "True if only a single empty a : p element is present."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef autofit(self):\n        if self.noAutofit is not None:\n            return MSO_AUTO_SIZE.NONE\n        if self.normAutofit is not None:\n            return MSO_AUTO_SIZE.TEXT_TO_FIT_SHAPE\n        if self.spAutoFit is not None:\n            return MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT\n        return None", "response": "Returns the autofit setting for the text frame."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef add_hlinkClick(self, rId):\n        hlinkClick = self.get_or_add_hlinkClick()\n        hlinkClick.rId = rId\n        return hlinkClick", "response": "Add an hlinkClick child element with rId attribute set to rId."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a newly appended <a : r element.", "response": "def add_r(self, text=None):\n        \"\"\"\n        Return a newly appended <a:r> element.\n        \"\"\"\n        r = self._add_r()\n        if text:\n            r.t.text = text\n        return r"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef append_text(self, text):\n        for idx, r_str in enumerate(text.split('\\n')):\n            # ---breaks are only added *between* items, not at start---\n            if idx > 0:\n                self.add_br()\n            # ---runs that would be empty are not added---\n            if r_str:\n                self.add_r(r_str)", "response": "Append text to the internal list of items and add br and r elements."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef line_spacing(self):\n        lnSpc = self.lnSpc\n        if lnSpc is None:\n            return None\n        if lnSpc.spcPts is not None:\n            return lnSpc.spcPts.val\n        return lnSpc.spcPct.val", "response": "Returns the line spacing between successive lines in this paragraph."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef space_after(self):\n        spcAft = self.spcAft\n        if spcAft is None:\n            return None\n        spcPts = spcAft.spcPts\n        if spcPts is None:\n            return None\n        return spcPts.val", "response": "Return the space after the current one."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the value of the centipoints value in the EMU equivalent of the centipoints value in .", "response": "def space_before(self):\n        \"\"\"\n        The EMU equivalent of the centipoints value in\n        `./a:spcBef/a:spcPts/@val`.\n        \"\"\"\n        spcBef = self.spcBef\n        if spcBef is None:\n            return None\n        spcPts = spcBef.spcPts\n        if spcPts is None:\n            return None\n        return spcPts.val"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_spcPct(self, value):\n        self._remove_spcPts()\n        spcPct = self.get_or_add_spcPct()\n        spcPct.val = value", "response": "Set the spacing of the child entries to value lines."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nset the spacing points of the child entries.", "response": "def set_spcPts(self, value):\n        \"\"\"\n        Set spacing to *value* points. A ./a:spcPct child is removed if\n        present.\n        \"\"\"\n        self._remove_spcPct()\n        spcPts = self.get_or_add_spcPts()\n        spcPts.val = value"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect the given shape to the first available entry in the cluster.", "response": "def begin_connect(self, shape, cxn_pt_idx):\n        \"\"\"\n        **EXPERIMENTAL** - *The current implementation only works properly\n        with rectangular shapes, such as pictures and rectangles. Use with\n        other shape types may cause unexpected visual alignment of the\n        connected end-point and could lead to a load error if cxn_pt_idx\n        exceeds the connection point count available on the connected shape.\n        That said, a quick test should reveal what to expect when using this\n        method with other shape types.*\n\n        Connect the beginning of this connector to *shape* at the connection\n        point specified by *cxn_pt_idx*. Each shape has zero or more\n        connection points and they are identified by index, starting with 0.\n        Generally, the first connection point of a shape is at the top center\n        of its bounding box and numbering proceeds counter-clockwise from\n        there. However this is only a convention and may vary, especially\n        with non built-in shapes.\n        \"\"\"\n        self._connect_begin_to(shape, cxn_pt_idx)\n        self._move_begin_to_cxn(shape, cxn_pt_idx)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn the X - position of the begin point of this connector.", "response": "def begin_x(self):\n        \"\"\"\n        Return the X-position of the begin point of this connector, in\n        English Metric Units (as a |Length| object).\n        \"\"\"\n        cxnSp = self._element\n        x, cx, flipH = cxnSp.x, cxnSp.cx, cxnSp.flipH\n        begin_x = x+cx if flipH else x\n        return Emu(begin_x)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef begin_y(self):\n        cxnSp = self._element\n        y, cy, flipV = cxnSp.y, cxnSp.cy, cxnSp.flipV\n        begin_y = y+cy if flipV else y\n        return Emu(begin_y)", "response": "Return the Y - position of the begin point of this connector."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconnects the end of the connector to the shape at the specified connection point index.", "response": "def end_connect(self, shape, cxn_pt_idx):\n        \"\"\"\n        **EXPERIMENTAL** - *The current implementation only works properly\n        with rectangular shapes, such as pictures and rectangles. Use with\n        other shape types may cause unexpected visual alignment of the\n        connected end-point and could lead to a load error if cxn_pt_idx\n        exceeds the connection point count available on the connected shape.\n        That said, a quick test should reveal what to expect when using this\n        method with other shape types.*\n\n        Connect the ending of this connector to *shape* at the connection\n        point specified by *cxn_pt_idx*.\n        \"\"\"\n        self._connect_end_to(shape, cxn_pt_idx)\n        self._move_end_to_cxn(shape, cxn_pt_idx)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the X - position of the end point of this connector in English Metric Units.", "response": "def end_x(self):\n        \"\"\"\n        Return the X-position of the end point of this connector, in English\n        Metric Units (as a |Length| object).\n        \"\"\"\n        cxnSp = self._element\n        x, cx, flipH = cxnSp.x, cxnSp.cx, cxnSp.flipH\n        end_x = x if flipH else x+cx\n        return Emu(end_x)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn the Y - position of the end point of this connector in English Metric Units.", "response": "def end_y(self):\n        \"\"\"\n        Return the Y-position of the end point of this connector, in English\n        Metric Units (as a |Length| object).\n        \"\"\"\n        cxnSp = self._element\n        y, cy, flipV = cxnSp.y, cxnSp.cy, cxnSp.flipV\n        end_y = y if flipV else y+cy\n        return Emu(end_y)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nadds or update a stCxn element that connects its begin point to the connection point of shape specified by cxn_pt_idx.", "response": "def _connect_begin_to(self, shape, cxn_pt_idx):\n        \"\"\"\n        Add or update a stCxn element for this connector that connects its\n        begin point to the connection point of *shape* specified by\n        *cxn_pt_idx*.\n        \"\"\"\n        cNvCxnSpPr = self._element.nvCxnSpPr.cNvCxnSpPr\n        stCxn = cNvCxnSpPr.get_or_add_stCxn()\n        stCxn.id = shape.shape_id\n        stCxn.idx = cxn_pt_idx"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef _connect_end_to(self, shape, cxn_pt_idx):\n        cNvCxnSpPr = self._element.nvCxnSpPr.cNvCxnSpPr\n        endCxn = cNvCxnSpPr.get_or_add_endCxn()\n        endCxn.id = shape.shape_id\n        endCxn.idx = cxn_pt_idx", "response": "Add or update an endCxn element for this connector that connects its\n        end point to the connection point of shape specified by cxn_pt_idx."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nmoving the begin point of this connector to coordinates of the connection point specified by cxn_pt_idx.", "response": "def _move_begin_to_cxn(self, shape, cxn_pt_idx):\n        \"\"\"\n        Move the begin point of this connector to coordinates of the\n        connection point of *shape* specified by *cxn_pt_idx*.\n        \"\"\"\n        x, y, cx, cy = shape.left, shape.top, shape.width, shape.height\n        self.begin_x, self.begin_y = {\n            0: (int(x + cx/2), y),\n            1: (x, int(y + cy/2)),\n            2: (int(x + cx/2), y + cy),\n            3: (x + cx, int(y + cy/2)),\n        }[cxn_pt_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nmoving the end point of this connector to the coordinates of the connection point specified by cxn_pt_idx.", "response": "def _move_end_to_cxn(self, shape, cxn_pt_idx):\n        \"\"\"\n        Move the end point of this connector to the coordinates of the\n        connection point of *shape* specified by *cxn_pt_idx*.\n        \"\"\"\n        x, y, cx, cy = shape.left, shape.top, shape.width, shape.height\n        self.end_x, self.end_y = {\n            0: (int(x + cx/2), y),\n            1: (x, int(y + cy/2)),\n            2: (int(x + cx/2), y + cy),\n            3: (x + cx, int(y + cy/2)),\n        }[cxn_pt_idx]"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef action_fields(self):\n        url = self.action\n\n        if url is None:\n            return {}\n\n        halves = url.split('?')\n        if len(halves) == 1:\n            return {}\n\n        key_value_pairs = halves[1].split('&')\n        return dict([pair.split('=') for pair in key_value_pairs])", "response": "Returns a dictionary containing any key - value pairs present in the action attribute. For example\n        = 0&return = true. Returns an empty dictionary if the action attribute is empty."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning the host portion of the action_verb attribute. For example ppaction://customshow?id = 0&return = true. Returns |None| if no action_verb attribute is present.", "response": "def action_verb(self):\n        \"\"\"\n        The host portion of the `ppaction://` URL contained in the action\n        attribute. For example 'customshow' in\n        'ppaction://customshow?id=0&return=true'. Returns |None| if no action\n        attribute is present.\n        \"\"\"\n        url = self.action\n\n        if url is None:\n            return None\n\n        protocol_and_host = url.split('?')[0]\n        host = protocol_and_host[11:]\n\n        return host"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef data_point_offset(self, series):\n        count = 0\n        for this_series in self:\n            if series is this_series:\n                return count\n            count += len(this_series)\n        raise ValueError('series not in chart data object')", "response": "Returns the offset of the data point that is prior to the given series."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef series_index(self, series):\n        for idx, s in enumerate(self):\n            if series is s:\n                return idx\n        raise ValueError('series not in chart data object')", "response": "Return the index of a series in this sequence."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef number_format(self):\n        number_format = self._number_format\n        if number_format is None:\n            return self._chart_data.number_format\n        return number_format", "response": "Returns the number format for the current locale."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef number_format(self):\n        number_format = self._number_format\n        if number_format is None:\n            return self._series_data.number_format\n        return number_format", "response": "Returns the number format for the data point."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nadd a series to this data set entitled name and having the data points specified by values.", "response": "def add_series(self, name, values=(), number_format=None):\n        \"\"\"\n        Add a series to this data set entitled *name* and having the data\n        points specified by *values*, an iterable of numeric values.\n        *number_format* specifies how the series values will be displayed,\n        and may be a string, e.g. '#,##0' corresponding to an Excel number\n        format.\n        \"\"\"\n        series_data = CategorySeriesData(self, name, number_format)\n        self.append(series_data)\n        for value in values:\n            series_data.add_data_point(value)\n        return series_data"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef add_category(self, label):\n        category = Category(label, self)\n        self._categories.append(category)\n        return category", "response": "Add a category to the end of this category sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn |True| if the first category in this category collection has a date label.", "response": "def are_dates(self):\n        \"\"\"\n        Return |True| if the first category in this collection has a date\n        label (as opposed to str or numeric). A date label is one of type\n        datetime.date or datetime.datetime. Returns |False| otherwise,\n        including when this category collection is empty. It also returns\n        False when this category collection is hierarchical, because\n        hierarchical categories can only be written as string labels.\n        \"\"\"\n        if self.depth != 1:\n            return False\n        first_cat_label = self[0].label\n        date_types = (datetime.date, datetime.datetime)\n        if isinstance(first_cat_label, date_types):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn |True| if the first category in this category collection is numeric.", "response": "def are_numeric(self):\n        \"\"\"\n        Return |True| if the first category in this collection has a numeric\n        label (as opposed to a string label), including if that value is\n        a datetime.date or datetime.datetime object (as those are converted\n        to integers for storage in Excel). Returns |False| otherwise,\n        including when this category collection is empty. It also returns\n        False when this category collection is hierarchical, because\n        hierarchical categories can only be written as string labels.\n        \"\"\"\n        if self.depth != 1:\n            return False\n        # This method only tests the first category. The categories must\n        # be of uniform type, and if they're not, there will be problems\n        # later in the process, but it's not this method's job to validate\n        # the caller's input.\n        first_cat_label = self[0].label\n        numeric_types = (Number, datetime.date, datetime.datetime)\n        if isinstance(first_cat_label, numeric_types):\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef depth(self):\n        categories = self._categories\n        if not categories:\n            return 0\n        first_depth = categories[0].depth\n        for category in categories[1:]:\n            if category.depth != first_depth:\n                raise ValueError('category depth not uniform')\n        return first_depth", "response": "Returns the number of hierarchy levels in this category graph. Returns 0 if the category graph contains no categories. Returns 1 if the category graph contains no categories. Returns 0 if the category graph contains no categories."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef index(self, category):\n        index = 0\n        for this_category in self._categories:\n            if category is this_category:\n                return index\n            index += this_category.leaf_count\n        raise ValueError('category not in top-level categories')", "response": "Returns the index of the given category in the overall sequence of leaf categories."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef levels(self):\n        def levels(categories):\n            # yield all lower levels\n            sub_categories = [\n                sc for c in categories for sc in c.sub_categories\n            ]\n            if sub_categories:\n                for level in levels(sub_categories):\n                    yield level\n            # yield this level\n            yield [(cat.idx, cat.label) for cat in categories]\n\n        for level in levels(self):\n            yield level", "response": "A generator of tuples representing the category\n        hierarchy from the bottom up."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreading or write. Return a string representing the number format used in Excel to format these categories e. g. 0. 0 mm - dd or yyyy.", "response": "def number_format(self):\n        \"\"\"\n        Read/write. Return a string representing the number format used in\n        Excel to format these category values, e.g. '0.0' or 'mm/dd/yyyy'.\n        This string is only relevant when the categories are numeric or date\n        type, although it returns 'General' without error when the categories\n        are string labels. Assigning |None| causes the default number format\n        to be used, based on the type of the category labels.\n        \"\"\"\n        GENERAL = 'General'\n\n        # defined value takes precedence\n        if self._number_format is not None:\n            return self._number_format\n\n        # multi-level (should) always be string labels\n        # zero depth means empty in which case we can't tell anyway\n        if self.depth != 1:\n            return GENERAL\n\n        # everything except dates gets 'General'\n        first_cat_label = self[0].label\n        if isinstance(first_cat_label, (datetime.date, datetime.datetime)):\n            return 'yyyy\\-mm\\-dd'\n        return GENERAL"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a new |data. Category| object having label appended to the end of the sub - category sequence for this category.", "response": "def add_sub_category(self, label):\n        \"\"\"\n        Return a newly created |data.Category| object having *label* and\n        appended to the end of the sub-category sequence for this category.\n        \"\"\"\n        category = Category(label, self)\n        self._sub_categories.append(category)\n        return category"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns the index of the given sub_category in the overall sequence of leafCOOKIE entries.", "response": "def index(self, sub_category):\n        \"\"\"\n        The offset of *sub_category* in the overall sequence of leaf\n        categories.\n        \"\"\"\n        index = self._parent.index(self)\n        for this_sub_category in self._sub_categories:\n            if sub_category is this_sub_category:\n                return index\n            index += this_sub_category.leaf_count\n        raise ValueError('sub_category not in this category')"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef numeric_str_val(self, date_1904=False):\n        label = self._label\n        if isinstance(label, (datetime.date, datetime.datetime)):\n            return '%.1f' % self._excel_date_number(date_1904)\n        return str(self._label)", "response": "Returns a string representation of the numeric label of thisCOOKIE."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _excel_date_number(self, date_1904):\n        date, label = datetime.date, self._label\n        # -- get date from label in type-independent-ish way\n        date_ = date(label.year, label.month, label.day)\n        epoch = date(1904, 1, 1) if date_1904 else date(1899, 12, 31)\n        delta = date_ - epoch\n        excel_day_number = delta.days\n\n        # -- adjust for Excel mistaking 1900 for a leap year --\n        if not date_1904 and excel_day_number > 59:\n            excel_day_number += 1\n\n        return excel_day_number", "response": "Return an integer representing the date number of days since January 1 1900 or 1904."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a new CategoryDataPoint object to the end of the sequence.", "response": "def add_data_point(self, value, number_format=None):\n        \"\"\"\n        Return a CategoryDataPoint object newly created with value *value*,\n        an optional *number_format*, and appended to this sequence.\n        \"\"\"\n        data_point = CategoryDataPoint(self, value, number_format)\n        self.append(data_point)\n        return data_point"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef add_series(self, name, number_format=None):\n        series_data = XySeriesData(self, name, number_format)\n        self.append(series_data)\n        return series_data", "response": "Add a series to the end of the sequence identified by name and values formatted with number_format."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a |BubbleSeriesData| object newly created and added at the end of the sequence with series named name and values formatted with number_format.", "response": "def add_series(self, name, number_format=None):\n        \"\"\"\n        Return a |BubbleSeriesData| object newly created and added at the end\n        of this sequence, and having series named *name* and values formatted\n        with *number_format*.\n        \"\"\"\n        series_data = BubbleSeriesData(self, name, number_format)\n        self.append(series_data)\n        return series_data"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef add_data_point(self, x, y, number_format=None):\n        data_point = XyDataPoint(self, x, y, number_format)\n        self.append(data_point)\n        return data_point", "response": "Add a new data point to the sequence."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nadding a new BubbleDataPoint object to the series data.", "response": "def add_data_point(self, x, y, size, number_format=None):\n        \"\"\"\n        Append a new BubbleDataPoint object having the values *x*, *y*, and\n        *size*. The optional *number_format* is used to format the Y value.\n        If not provided, the number format is inherited from the series data.\n        \"\"\"\n        data_point = BubbleDataPoint(self, x, y, size, number_format)\n        self.append(data_point)\n        return data_point"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning the ASCII characters in the file specified by path and all of the paths.", "response": "def ascii_bytes_from(path, *paths):\n    \"\"\"\n    Return the ASCII characters in the file specified by *path* and *paths*.\n    The file path is determined by concatenating *path* and any members of\n    *paths* with a directory separator in between.\n    \"\"\"\n    file_path = os.path.join(path, *paths)\n    with open(file_path) as f:\n        ascii_bytes = f.read()\n    return ascii_bytes"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef add_sldId(self, rId):\n        return self._add_sldId(id=self._next_id, rId=rId)", "response": "Return a newly created <p : sldId > child element having the rId attribute set to rId."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the next available slide ID as an int. Valid slide IDs start at 256. Valid slide IDs start at 256. The next available slide ID at 256 is chosen.", "response": "def _next_id(self):\n        \"\"\"\n        Return the next available slide ID as an int. Valid slide IDs start\n        at 256. The next integer value greater than the max value in use is\n        chosen, which minimizes that chance of reusing the id of a deleted\n        slide.\n        \"\"\"\n        id_str_lst = self.xpath('./p:sldId/@id')\n        return max([255]+[int(id_str) for id_str in id_str_lst])+1"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef Presentation(pptx=None):\n    if pptx is None:\n        pptx = _default_pptx_path()\n\n    presentation_part = Package.open(pptx).main_document_part\n\n    if not _is_pptx_package(presentation_part):\n        tmpl = \"file '%s' is not a PowerPoint file, content type is '%s'\"\n        raise ValueError(tmpl % (pptx, presentation_part.content_type))\n\n    return presentation_part.presentation", "response": "Return a |Presentation| object loaded from a. pptx file or a file - like object."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _default_pptx_path():\n    _thisdir = os.path.split(__file__)[0]\n    return os.path.join(_thisdir, 'templates', 'default.pptx')", "response": "Return the path to the built - in default. pptx package."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning |True| if * prs_part* is a valid main document part.", "response": "def _is_pptx_package(prs_part):\n    \"\"\"\n    Return |True| if *prs_part* is a valid main document part, |False|\n    otherwise.\n    \"\"\"\n    valid_content_types = (\n        CT.PML_PRESENTATION_MAIN,\n        CT.PML_PRES_MACRO_MAIN,\n    )\n    return prs_part.content_type in valid_content_types"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns new |MediaPart| instance containing media*.", "response": "def new(cls, package, media):\n        \"\"\"Return new |MediaPart| instance containing *media*.\n\n        *media* must be a |Media| object.\n        \"\"\"\n        partname = package.next_media_partname(media.ext)\n        return cls(partname, media.content_type, media.blob, package)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nsetting the value of. / c : manualLayout to horz_offset.", "response": "def horz_offset(self, offset):\n        \"\"\"\n        Set the value of ./c:manualLayout/c:x@val to *offset* and\n        ./c:manualLayout/c:xMode@val to \"factor\". Remove ./c:manualLayout if\n        *offset* == 0.\n        \"\"\"\n        if offset == 0.0:\n            self._remove_manualLayout()\n            return\n        manualLayout = self.get_or_add_manualLayout()\n        manualLayout.horz_offset = offset"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef horz_offset(self):\n        x, xMode = self.x, self.xMode\n        if x is None or xMode is None or xMode.val != ST_LayoutMode.FACTOR:\n            return 0.0\n        return x.val", "response": "Returns the horz offset of the current log entry."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef horz_offset(self, offset):\n        self.get_or_add_xMode().val = ST_LayoutMode.FACTOR\n        self.get_or_add_x().val = offset", "response": "Set the value of. xMode. factor to factor."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef __get_url(self, endpoint):\n        url = self.url\n        api = \"wc-api\"\n\n        if url.endswith(\"/\") is False:\n            url = \"%s/\" % url\n\n        if self.wp_api:\n            api = \"wp-json\"\n\n        return \"%s%s/%s/%s\" % (url, api, self.version, endpoint)", "response": "Get URL for requests"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngenerating oAuth1. 0a URL", "response": "def __get_oauth_url(self, url, method, **kwargs):\n        \"\"\" Generate oAuth1.0a URL \"\"\"\n        oauth = OAuth(\n            url=url,\n            consumer_key=self.consumer_key,\n            consumer_secret=self.consumer_secret,\n            version=self.version,\n            method=method,\n            oauth_timestamp=kwargs.get(\"oauth_timestamp\", int(time()))\n        )\n\n        return oauth.get_oauth_url()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndo request to the WooCommerce API", "response": "def __request(self, method, endpoint, data, params=None, **kwargs):\n        \"\"\" Do requests \"\"\"\n        if params is None:\n            params = {}\n        url = self.__get_url(endpoint)\n        auth = None\n        headers = {\n            \"user-agent\": \"WooCommerce API Client-Python/%s\" % __version__,\n            \"accept\": \"application/json\"\n        }\n\n        if self.is_ssl is True and self.query_string_auth is False:\n            auth = (self.consumer_key, self.consumer_secret)\n        elif self.is_ssl is True and self.query_string_auth is True:\n            params.update({\n                \"consumer_key\": self.consumer_key,\n                \"consumer_secret\": self.consumer_secret\n            })\n        else:\n            encoded_params = urlencode(params)\n            url = \"%s?%s\" % (url, encoded_params)\n            url = self.__get_oauth_url(url, method, **kwargs)\n\n        if data is not None:\n            data = jsonencode(data, ensure_ascii=False).encode('utf-8')\n            headers[\"content-type\"] = \"application/json;charset=utf-8\"\n\n        return request(\n            method=method,\n            url=url,\n            verify=self.verify_ssl,\n            auth=auth,\n            params=params,\n            data=data,\n            timeout=self.timeout,\n            headers=headers,\n            **kwargs\n        )"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\npost data to the specified endpoint", "response": "def post(self, endpoint, data, **kwargs):\n        \"\"\" POST requests \"\"\"\n        return self.__request(\"POST\", endpoint, data, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_oauth_url(self):\n        params = OrderedDict()\n\n        if \"?\" in self.url:\n            url = self.url[:self.url.find(\"?\")]\n            for key, value in parse_qsl(urlparse(self.url).query):\n                params[key] = value\n        else:\n            url = self.url\n\n        params[\"oauth_consumer_key\"] = self.consumer_key\n        params[\"oauth_timestamp\"] = self.timestamp\n        params[\"oauth_nonce\"] = self.generate_nonce()\n        params[\"oauth_signature_method\"] = \"HMAC-SHA256\"\n        params[\"oauth_signature\"] = self.generate_oauth_signature(params, url)\n\n        query_string = urlencode(params)\n\n        return \"%s?%s\" % (url, query_string)", "response": "Returns the URL with OAuth params"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nnormalize the parameters of a resource.", "response": "def normalize_parameters(params):\n        \"\"\" Normalize parameters \"\"\"\n        params = params or {}\n        normalized_parameters = OrderedDict()\n\n        def get_value_like_as_php(val):\n            \"\"\" Prepare value for quote \"\"\"\n            try:\n                base = basestring\n            except NameError:\n                base = (str, bytes)\n\n            if isinstance(val, base):\n                return val\n            elif isinstance(val, bool):\n                return \"1\" if val else \"\"\n            elif isinstance(val, int):\n                return str(val)\n            elif isinstance(val, float):\n                return str(int(val)) if val % 1 == 0 else str(val)\n            else:\n                return \"\"\n\n        for key, value in params.items():\n            value = get_value_like_as_php(value)\n            key = quote(unquote(str(key))).replace(\"%\", \"%25\")\n            value = quote(unquote(str(value))).replace(\"%\", \"%25\")\n            normalized_parameters[key] = value\n\n        return normalized_parameters"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncompute several Topic Models in parallel using the LDA package.", "response": "def compute_models_parallel(data, varying_parameters=None, constant_parameters=None, n_max_processes=None):\n    \"\"\"\n    Compute several Topic Models in parallel using the \"lda\" package. Use a single or multiple document term matrices\n    `data` and optionally a list of varying parameters `varying_parameters`. Pass parameters in `constant_parameters`\n    dict to each model calculation. Use at maximum `n_max_processes` processors or use all available processors if None\n    is passed.\n    `data` can be either a Document-Term-Matrix (NumPy array/matrix, SciPy sparse matrix) or a dict with document ID ->\n    Document-Term-Matrix mapping when calculating models for multiple corpora (named multiple documents).\n\n    If `data` is a dict of named documents, this function will return a dict with document ID -> result list. Otherwise\n    it will only return a result list. A result list always is a list containing tuples `(parameter_set, model)` where\n    `parameter_set` is a dict of the used parameters.\n    \"\"\"\n    mp_models = MultiprocModelsRunner(MultiprocModelsWorkerLDA, data, varying_parameters, constant_parameters,\n                                      n_max_processes=n_max_processes)\n\n    return mp_models.run()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ncompute several Topic Models using the lda.", "response": "def evaluate_topic_models(data, varying_parameters, constant_parameters=None, n_max_processes=None, return_models=False,\n                          metric=None, **metric_kwargs):\n    \"\"\"\n    Compute several Topic Models in parallel using the \"lda\" package. Calculate the models using a list of varying\n    parameters `varying_parameters` on a single Document-Term-Matrix `data`. Pass parameters in `constant_parameters`\n    dict to each model calculation. Use at maximum `n_max_processes` processors or use all available processors if None\n    is passed.\n    `data` must be a Document-Term-Matrix (NumPy array/matrix, SciPy sparse matrix).\n    Will return a list of size `len(varying_parameters)` containing tuples `(parameter_set, eval_results)` where\n    `parameter_set` is a dict of the used parameters and `eval_results` is a dict of metric names -> metric results.\n    \"\"\"\n    mp_eval = MultiprocEvaluationRunner(MultiprocEvaluationWorkerLDA, AVAILABLE_METRICS, data,\n                                        varying_parameters, constant_parameters,\n                                        metric=metric or DEFAULT_METRICS, metric_options=metric_kwargs,\n                                        n_max_processes=n_max_processes, return_models=return_models)\n\n    return mp_eval.run()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprints n_top values from a LDA model s topic - word distributions.", "response": "def print_ldamodel_topic_words(topic_word_distrib, vocab, n_top=10, row_labels=DEFAULT_TOPIC_NAME_FMT):\n    \"\"\"Print `n_top` values from a LDA model's topic-word distributions.\"\"\"\n    print_ldamodel_distribution(topic_word_distrib, row_labels=row_labels, val_labels=vocab,\n                                top_n=n_top)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef print_ldamodel_doc_topics(doc_topic_distrib, doc_labels, n_top=3, val_labels=DEFAULT_TOPIC_NAME_FMT):\n    print_ldamodel_distribution(doc_topic_distrib, row_labels=doc_labels, val_labels=val_labels,\n                                top_n=n_top)", "response": "Print n_top values from a LDA model s document - topic distributions."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nsaving a LDA model as pickle file.", "response": "def save_ldamodel_to_pickle(picklefile, model, vocab, doc_labels, dtm=None, **kwargs):\n    \"\"\"Save a LDA model as pickle file.\"\"\"\n    pickle_data({'model': model, 'vocab': vocab, 'doc_labels': doc_labels, 'dtm': dtm}, picklefile)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nplotting a heatmap for a document - topic distribution.", "response": "def plot_doc_topic_heatmap(fig, ax, doc_topic_distrib, doc_labels, topic_labels=None,\n                           which_documents=None, which_document_indices=None,\n                           which_topics=None, which_topic_indices=None,\n                           xaxislabel=None, yaxislabel=None,\n                           **kwargs):\n    \"\"\"\n    Plot a heatmap for a document-topic distribution `doc_topic_distrib` to a matplotlib Figure `fig` and Axes `ax`\n    using `doc_labels` as document labels on the y-axis and topics from 1 to `n_topics=doc_topic_distrib.shape[1]` on\n    the x-axis.\n    Custom topic labels can be passed as `topic_labels`.\n    A subset of documents can be specified either with a sequence `which_documents` containing a subset of document\n    labels from `doc_labels` or `which_document_indices` containing a sequence of document indices.\n    A subset of topics can be specified either with a sequence `which_topics` containing sequence of numbers between\n    [1, n_topics] or `which_topic_indices` which is a number between [0, n_topics-1]\n    Additional arguments can be passed via `kwargs` to `plot_heatmap`.\n\n    Please note that it is almost always necessary to select a subset of your document-topic distribution with the\n    `which_documents` or `which_topics` parameters, as otherwise the amount of data to be plotted will be too high\n    to give a reasonable picture.\n    \"\"\"\n    if which_documents is not None and which_document_indices is not None:\n        raise ValueError('only `which_documents` or `which_document_indices` can be set, not both')\n\n    if which_topics is not None and which_topic_indices is not None:\n        raise ValueError('only `which_topics` or `which_topic_indices` can be set, not both')\n\n    if which_documents is not None:\n        which_document_indices = np.where(np.isin(doc_labels, which_documents))[0]\n\n    if which_topics is not None:\n        which_topic_indices = np.array(which_topics) - 1\n\n    select_distrib_subset = False\n\n    if topic_labels is None:\n        topic_labels = np.array(range(1, doc_topic_distrib.shape[1]+1))\n    elif not isinstance(topic_labels, np.ndarray):\n        topic_labels = np.array(topic_labels)\n\n    if which_document_indices is not None:\n        select_distrib_subset = True\n        doc_labels = np.array(doc_labels)[which_document_indices]\n\n    if which_topic_indices is not None:\n        select_distrib_subset = True\n        topic_labels = topic_labels[which_topic_indices]\n\n    if select_distrib_subset:\n        doc_topic_distrib = mat2d_window_from_indices(doc_topic_distrib, which_document_indices, which_topic_indices)\n\n    return plot_heatmap(fig, ax, doc_topic_distrib,\n                        xaxislabel=xaxislabel or 'topic',\n                        yaxislabel=yaxislabel or 'document',\n                        xticklabels=topic_labels,\n                        yticklabels=doc_labels,\n                        **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nplot a heatmap for a topic - word distribution.", "response": "def plot_topic_word_heatmap(fig, ax, topic_word_distrib, vocab,\n                            which_topics=None, which_topic_indices=None,\n                            which_words=None, which_word_indices=None,\n                            xaxislabel=None, yaxislabel=None,\n                            **kwargs):\n    \"\"\"\n    Plot a heatmap for a topic-word distribution `topic_word_distrib` to a matplotlib Figure `fig` and Axes `ax`\n    using `vocab` as vocabulary on the x-axis and topics from 1 to `n_topics=doc_topic_distrib.shape[1]` on\n    the y-axis.\n    A subset of words from `vocab` can be specified either directly with a sequence `which_words` or\n    `which_document_indices` containing a sequence of word indices in `vocab`.\n    A subset of topics can be specified either with a sequence `which_topics` containing sequence of numbers between\n    [1, n_topics] or `which_topic_indices` which is a number between [0, n_topics-1]\n    Additional arguments can be passed via `kwargs` to `plot_heatmap`.\n\n    Please note that it is almost always necessary to select a subset of your topic-word distribution with the\n    `which_words` or `which_topics` parameters, as otherwise the amount of data to be plotted will be too high\n    to give a reasonable picture.\n    \"\"\"\n    if which_topics is not None and which_topic_indices is not None:\n        raise ValueError('only `which_topics` or `which_topic_indices` can be set, not both')\n\n    if which_words is not None and which_word_indices is not None:\n        raise ValueError('only `which_words` or `which_word_indices` can be set, not both')\n\n    if which_topics is not None:\n        which_topic_indices = np.array(which_topics) - 1\n\n    if which_words is not None:\n        which_word_indices = np.where(np.isin(vocab, which_words))[0]\n\n    select_distrib_subset = False\n    topic_labels = np.array(range(1, topic_word_distrib.shape[0]+1))\n\n    if which_topic_indices is not None:\n        select_distrib_subset = True\n        topic_labels = topic_labels[which_topic_indices]\n\n    if which_word_indices is not None:\n        select_distrib_subset = True\n        vocab = np.array(vocab)[which_word_indices]\n\n    if select_distrib_subset:\n        topic_word_distrib = mat2d_window_from_indices(topic_word_distrib, which_topic_indices, which_word_indices)\n\n    return plot_heatmap(fig, ax, topic_word_distrib,\n                        xaxislabel=xaxislabel or 'vocab',\n                        yaxislabel=yaxislabel or 'topic',\n                        xticklabels=vocab,\n                        yticklabels=topic_labels,\n                        **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nplot the evaluation results from the eval_results module.", "response": "def plot_eval_results(eval_results, metric=None, xaxislabel=None, yaxislabel=None,\n                      title=None, title_fontsize='x-large', axes_title_fontsize='large',\n                      show_metric_direction=True, metric_direction_font_size='large',\n                      subplots_opts=None, subplots_adjust_opts=None, figsize='auto',\n                      **fig_kwargs):\n    \"\"\"\n    Plot the evaluation results from `eval_results`. `eval_results` must be a sequence containing `(param, values)`\n    tuples, where `param` is the parameter value to appear on the x axis and `values` can be a dict structure\n    containing the metric values. `eval_results` can be created using the `results_by_parameter` function from the\n    `topicmod.common` module.\n    Set `metric` to plot only a specific metric.\n    Set `xaxislabel` for a label on the x-axis.\n    Set `yaxislabel` for a label on the y-axis.\n    Set `title` for a plot title.\n    Options in a dict `subplots_opts` will be passed to `plt.subplots(...)`.\n    Options in a dict `subplots_adjust_opts` will be passed to `fig.subplots_adjust(...)`.\n    `figsize` can be set to a tuple `(width, height)` or to `\"auto\"` (default) which will set the size to\n    `(8, 2 * <num. of metrics>)`.\n    \"\"\"\n    if type(eval_results) not in (list, tuple) or not eval_results:\n        raise ValueError('`eval_results` must be a list or tuple with at least one element')\n\n    if type(eval_results[0]) not in (list, tuple) or len(eval_results[0]) != 2:\n        raise ValueError('`eval_results` must be a list or tuple containing a (param, values) tuple. '\n                         'Maybe `eval_results` must be converted with `results_by_parameter`.')\n\n    if metric is not None and type(metric) not in (list, tuple):\n        metric = [metric]\n    elif metric is None:\n        # remove special evaluation result 'model': the calculated model itself\n        metric = list(set(next(iter(eval_results))[1].keys()) - {'model'})\n\n    metric = sorted(metric)\n\n    metric_direction = []\n    for m in metric:\n        if m == 'perplexity':\n            metric_direction.append('minimize')\n        else:\n            m_fn_name = 'metric_%s' % (m[:16] if m.startswith('coherence_gensim') else m)\n            m_fn = getattr(evaluate, m_fn_name, None)\n            if m_fn:\n                metric_direction.append(getattr(m_fn, 'direction', 'unknown'))\n            else:\n                metric_direction.append('unknown')\n\n    n_metrics = len(metric)\n\n    assert n_metrics == len(metric_direction)\n\n    metrics_ordered = []\n    for m_dir in sorted(set(metric_direction), reverse=True):\n        metrics_ordered.extend([(m, d) for m, d in zip(metric, metric_direction) if d == m_dir])\n\n    assert n_metrics == len(metrics_ordered)\n\n    # get figure and subplots (axes)\n    if figsize == 'auto':\n        figsize = (8, 2*n_metrics)\n\n    subplots_kwargs = dict(nrows=n_metrics, ncols=1, sharex=True, constrained_layout=True, figsize=figsize)\n    subplots_kwargs.update(subplots_opts or {})\n    subplots_kwargs.update(fig_kwargs)\n\n    fig, axes = plt.subplots(**subplots_kwargs)\n\n    # set title\n    if title:\n        fig.suptitle(title, fontsize=title_fontsize)\n\n    x = list(zip(*eval_results))[0]\n\n    # set adjustments\n    if title:\n        subplots_adjust_kwargs = dict(top=0.9, hspace=0.3)\n    else:\n        subplots_adjust_kwargs = {}\n\n    subplots_adjust_kwargs.update(subplots_adjust_opts or {})\n\n    if subplots_adjust_kwargs:\n        fig.subplots_adjust(**subplots_adjust_kwargs)\n\n    # draw subplot for each metric\n    axes_pos_per_dir = defaultdict(list)\n    for i, (ax, (m, m_dir)) in enumerate(zip(axes.flatten(), metrics_ordered)):\n        if show_metric_direction:\n            axes_pos_per_dir[m_dir].append(ax.get_position())\n\n        y = [metric_res[m] for _, metric_res in eval_results]\n        ax.plot(x, y, label=m)\n\n        ax.set_title(m, fontsize=axes_title_fontsize)\n\n        # set axis labels\n        if xaxislabel and i == len(metric)-1:\n            ax.set_xlabel(xaxislabel)\n        if yaxislabel:\n            ax.set_ylabel(yaxislabel)\n\n    # show grouped metric direction on the left\n    if axes_pos_per_dir:   # = if show_metric_direction\n        left_xs = []\n        ys = []\n        for m_dir, bboxes in axes_pos_per_dir.items():\n            left_xs.append(min(bb.x0 for bb in bboxes))\n            min_y = min(bb.y0 for bb in bboxes)\n            max_y = max(bb.y1 for bb in bboxes)\n            ys.append((min_y, max_y))\n\n        left_x = min(left_xs) / 2.5\n\n        fig.lines = []\n        for (min_y, max_y), m_dir in zip(ys, axes_pos_per_dir.keys()):\n            center_y = min_y + (max_y - min_y) / 2\n\n            fig.lines.append(Line2D((left_x, left_x), (min_y, max_y), transform=fig.transFigure, linewidth=5,\n                                    color='lightgray'))\n\n            fig.text(left_x / 1.5, center_y, m_dir, fontsize=metric_direction_font_size, rotation='vertical',\n                     horizontalalignment='right', verticalalignment='center')\n\n    return fig, axes"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the number of documents that occur at least min_val times.", "response": "def get_doc_frequencies(dtm, min_val=1, proportions=False):\n    \"\"\"\n    For each word in the vocab of `dtm` (i.e. its columns), return how often it occurs at least `min_val` times.\n    If `proportions` is True, return proportions scaled to the number of documents instead of absolute numbers.\n    \"\"\"\n    if dtm.ndim != 2:\n        raise ValueError('`dtm` must be a 2D array/matrix')\n\n    doc_freq = np.sum(dtm >= min_val, axis=0)\n\n    if doc_freq.ndim != 1:\n        doc_freq = doc_freq.A.flatten()\n\n    if proportions:\n        return doc_freq / dtm.shape[0]\n    else:\n        return doc_freq"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the codoc frequency of each unique pair of words w1 and w2 in the vocab of dtm at least min_val times.", "response": "def get_codoc_frequencies(dtm, min_val=1, proportions=False):\n    \"\"\"\n    For each unique pair of words `w1, w2` in the vocab of `dtm` (i.e. its columns), return how often both occur\n    together at least `min_val` times. If `proportions` is True, return proportions scaled to the number of documents\n    instead of absolute numbers.\n    \"\"\"\n    if dtm.ndim != 2:\n        raise ValueError('`dtm` must be a 2D array/matrix')\n\n    n_docs, n_vocab = dtm.shape\n    if n_vocab < 2:\n        raise ValueError('`dtm` must have at least two columns (i.e. 2 unique words)')\n\n    word_in_doc = dtm >= min_val\n\n    codoc_freq = {}\n    for w1, w2 in itertools.combinations(range(n_vocab), 2):\n        if issparse(dtm):\n            w1_in_docs = word_in_doc[:, w1].A.flatten()\n            w2_in_docs = word_in_doc[:, w2].A.flatten()\n        else:\n            w1_in_docs = word_in_doc[:, w1]\n            w2_in_docs = word_in_doc[:, w2]\n\n        freq = np.sum(w1_in_docs & w2_in_docs)\n        if proportions:\n            freq /= n_docs\n        codoc_freq[(w1, w2)] = freq\n\n    return codoc_freq"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_term_proportions(dtm):\n    unnorm = get_term_frequencies(dtm)\n\n    if unnorm.sum() == 0:\n        raise ValueError('`dtm` does not contain any tokens (is all-zero)')\n    else:\n        return unnorm / unnorm.sum()", "response": "Returns the term proportions given the document - term matrix dtm"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ntags each token with POS.", "response": "def pos_tag(self):\n        \"\"\"\n        Apply Part-of-Speech (POS) tagging on each token.\n        Uses the default NLTK tagger if no language-specific tagger could be loaded (English is assumed then as\n        language). The default NLTK tagger uses Penn Treebank tagset\n        (https://ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html).\n        The default German tagger based on TIGER corpus uses the STTS tagset\n        (http://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/TagSets/stts-table.html).\n        \"\"\"\n        self._require_tokens()\n        self._require_no_ngrams_as_tokens()\n\n        self._invalidate_workers_tokens()\n        logger.info('POS tagging tokens')\n        self._send_task_to_workers('pos_tag')\n        self.pos_tagged = True\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nfiltering the set of tokens for a specific POS tag.", "response": "def filter_for_pos(self, required_pos, simplify_pos=True):\n        \"\"\"\n        Filter tokens for a specific POS tag (if `required_pos` is a string) or several POS tags (if `required_pos`\n        is a list/tuple/set of strings). The POS tag depends on the tagset used during tagging. If `simplify_pos` is\n        True, then the tags are matched to the following simplified forms:\n        - 'N' for nouns\n        - 'V' for verbs\n        - 'ADJ' for adjectives\n        - 'ADV' for adverbs\n        - None for all other\n        \"\"\"\n        if type(required_pos) not in (tuple, list, set) \\\n                and required_pos is not None \\\n                and not isinstance(required_pos, str):\n            raise ValueError('`required_pos` must be a string, tuple, list, set or None')\n\n        self._require_pos_tags()\n\n        self._invalidate_workers_tokens()\n\n        logger.info('filtering tokens for POS tag `%s`' % required_pos)\n        self._send_task_to_workers('filter_for_pos',\n                                   required_pos=required_pos,\n                                   pos_tagset=self.pos_tagset,\n                                   simplify_pos=simplify_pos)\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\napply a custom filter function to all tokens or ngrams.", "response": "def apply_custom_filter(self, filter_func, to_ngrams=False):\n        \"\"\"\n        Apply a custom filter function `filter_func` to all tokens or ngrams (if `to_ngrams` is True).\n        `filter_func` must accept a single parameter: a dictionary of structure `{<doc_label>: <tokens list>}`. It\n        must return a dictionary with the same structure.\n\n        This function can only be run on a single process, hence it could be slow for large corpora.\n        \"\"\"\n\n        # Because it is not possible to send a function to the workers, all tokens must be fetched from the workers\n        # first and then the custom function is called and run in a single process (the main process). After that, the\n        # filtered tokens are send back to the worker processes.\n\n        if not callable(filter_func):\n            raise ValueError('`filter_func` must be callable')\n\n        self._require_tokens()\n\n        if to_ngrams:\n            self._require_ngrams()\n            get_task = 'get_ngrams_with_worker_id'\n            set_task = 'set_ngrams'\n            set_task_param = 'ngrams'\n            self._invalidate_workers_ngrams()\n        else:\n            get_task = 'get_tokens_with_worker_id'\n            set_task = 'set_tokens'\n            set_task_param = 'tokens'\n            self._invalidate_workers_tokens()\n\n        self._send_task_to_workers(get_task)\n\n        docs_of_workers = {}\n        for _ in range(self.n_workers):\n            pair = self.results_queue.get()\n            docs_of_workers[pair[0]] = pair[1]\n\n        assert len(docs_of_workers) == self.n_workers\n\n        tok = {}\n        for docs in docs_of_workers.values():\n            tok.update(docs)\n\n        logger.info('applying custom filter function to tokens')\n        new_tok = filter_func(tok)\n        require_dictlike(new_tok)\n        if set(new_tok.keys()) != set(tok.keys()):\n            raise ValueError('the document labels and number of documents must stay unchanged during custom filtering')\n\n        logger.debug('sending task `%s` to all workers' % set_task)\n        for w_id, docs in docs_of_workers.items():\n            new_w_docs = {dl: new_tok.pop(dl) for dl in docs}\n            self.tasks_queues[w_id].put((set_task, {set_task_param: new_w_docs}))\n\n        [q.join() for q in self.tasks_queues]\n\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate worker processes and queues. Distribute the work evenly across worker processes. Optionally send initial states to each worker process.", "response": "def _setup_workers(self, initial_states=None):\n        \"\"\"\n        Create worker processes and queues. Distribute the work evenly across worker processes. Optionally\n        send initial states defined in list `initial_states` to each worker process.\n        \"\"\"\n        if initial_states is not None:\n            require_listlike(initial_states)\n\n        self.tasks_queues = []\n        self.results_queue = mp.Queue()\n        self.workers = []\n\n        common_kwargs = dict(tokenizer=self.tokenizer,\n                             stemmer=self.stemmer,\n                             lemmata_dict=self.lemmata_dict,\n                             pos_tagger=self.pos_tagger)\n\n        if initial_states is not None:\n            logger.info('setting up %d worker processes with initial states' % len(initial_states))\n\n            for i_worker, w_state in enumerate(initial_states):\n                task_q = mp.JoinableQueue()\n                w = _PreprocWorker(i_worker, w_state.pop('docs'), self.language, task_q, self.results_queue,\n                                   name='_PreprocWorker#%d' % i_worker, **common_kwargs)\n                w.start()\n\n                task_q.put(('set_state', w_state))\n\n                self.workers.append(w)\n                self.tasks_queues.append(task_q)\n\n            [q.join() for q in self.tasks_queues]\n\n        else:\n            # distribute work evenly across the worker processes\n            # we assume that the longer a document is, the longer the processing time for it is\n            # hence we distribute the work evenly by document length\n            logger.info('distributing work via greedy partitioning')\n\n            docs_and_lengths = {dl: len(dt) for dl, dt in self.docs.items()}\n            docs_per_worker = greedy_partitioning(docs_and_lengths, k=self.n_max_workers)\n\n            logger.info('setting up %d worker processes' % len(docs_per_worker))\n\n            for i_worker, doc_labels in enumerate(docs_per_worker):\n                if not doc_labels: continue\n                task_q = mp.JoinableQueue()\n                w_docs = {dl: self.docs.get(dl) for dl in doc_labels}\n\n                w = _PreprocWorker(i_worker, w_docs, self.language, task_q, self.results_queue,\n                                   name='_PreprocWorker#%d' % i_worker, **common_kwargs)\n                w.start()\n\n                self.workers.append(w)\n                self.tasks_queues.append(task_q)\n\n        self.n_workers = len(self.workers)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns marginal topic distribution p ( T ) given the document - topic distribution theta and the document lengths.", "response": "def get_marginal_topic_distrib(doc_topic_distrib, doc_lengths):\n    \"\"\"\n    Return marginal topic distribution p(T) (topic proportions) given the document-topic distribution (theta)\n    `doc_topic_distrib` and the document lengths `doc_lengths`. The latter can be calculated with `get_doc_lengths()`.\n    \"\"\"\n    unnorm = (doc_topic_distrib.T * doc_lengths).sum(axis=1)\n    return unnorm / unnorm.sum()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef _words_by_score(words, score, least_to_most, n=None):\n    if words.shape != score.shape:\n        raise ValueError('`words` and `score` must have the same shape')\n\n    if n is not None and (n <= 0 or n > len(words)):\n        raise ValueError('`n` must be in range [0, len(words)]')\n\n    indices = np.argsort(score)\n    if not least_to_most:\n        indices = indices[::-1]\n\n    ordered_words = words[indices]\n\n    if n is not None:\n        return ordered_words[:n]\n    else:\n        return ordered_words", "response": "Order a vector of words by a score. Optionally return only the top n results."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ncalculates the saliency of a word given a topic word distribution and a list of length doc_lengths", "response": "def get_word_saliency(topic_word_distrib, doc_topic_distrib, doc_lengths):\n    \"\"\"\n    Calculate word saliency according to Chuang et al. 2012.\n    saliency(w) = p(w) * distinctiveness(w)\n\n    J. Chuang, C. Manning, J. Heer 2012: \"Termite: Visualization Techniques for Assessing Textual Topic Models\"\n    \"\"\"\n    p_t = get_marginal_topic_distrib(doc_topic_distrib, doc_lengths)\n    p_w = get_marginal_word_distrib(topic_word_distrib, p_t)\n\n    return p_w * get_word_distinctiveness(topic_word_distrib, p_t)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn words in vocab ordered by saliency score.", "response": "def _words_by_salience_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None, least_to_most=False):\n    \"\"\"Return words in `vocab` ordered by saliency score.\"\"\"\n    saliency = get_word_saliency(topic_word_distrib, doc_topic_distrib, doc_lengths)\n    return _words_by_score(vocab, saliency, least_to_most=least_to_most, n=n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_most_salient_words(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None):\n    return _words_by_salience_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n)", "response": "Returns the words in the vocab that are most salient."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the words from vocab from least to most salient.", "response": "def get_least_salient_words(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None):\n    \"\"\"\n    Order the words from `vocab` by \"saliency score\" (Chuang et al. 2012) from least to most salient. Optionally only\n    return the `n` least salient words.\n\n    J. Chuang, C. Manning, J. Heer 2012: \"Termite: Visualization Techniques for Assessing Textual Topic Models\"\n    \"\"\"\n    return _words_by_salience_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n, least_to_most=True)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_word_distinctiveness(topic_word_distrib, p_t):\n    topic_given_w = topic_word_distrib / topic_word_distrib.sum(axis=0)\n    return (topic_given_w * np.log(topic_given_w.T / p_t).T).sum(axis=0)", "response": "Calculates word distinctiveness according to Chuang et al. 2012."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns words in vocab ordered by distinctiveness score.", "response": "def _words_by_distinctiveness_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None,\n                                    least_to_most=False):\n    \"\"\"Return words in `vocab` ordered by distinctiveness score.\"\"\"\n    p_t = get_marginal_topic_distrib(doc_topic_distrib, doc_lengths)\n    distinct = get_word_distinctiveness(topic_word_distrib, p_t)\n\n    return _words_by_score(vocab, distinct, least_to_most=least_to_most, n=n)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_most_distinct_words(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None):\n    return _words_by_distinctiveness_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n)", "response": "Returns the n most distinct words from the vocab."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_least_distinct_words(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n=None):\n    return _words_by_distinctiveness_score(vocab, topic_word_distrib, doc_topic_distrib, doc_lengths, n,\n                                           least_to_most=True)", "response": "Returns the n most distinct words from the vocab."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the topic - word relevance score with a lambda parameter lambda_", "response": "def get_topic_word_relevance(topic_word_distrib, doc_topic_distrib, doc_lengths, lambda_):\n    \"\"\"\n    Calculate the topic-word relevance score with a lambda parameter `lambda_` according to Sievert and Shirley 2014.\n    relevance(w,T|lambda) = lambda * log phi_{w,t} + (1-lambda) * log (phi_{w,t} / p(w))\n    with phi  .. topic-word distribution\n         p(w) .. marginal word probability\n    \"\"\"\n    p_t = get_marginal_topic_distrib(doc_topic_distrib, doc_lengths)\n    p_w = get_marginal_word_distrib(topic_word_distrib, p_t)\n\n    logtw = np.log(topic_word_distrib)\n    loglift = np.log(topic_word_distrib / p_w)\n\n    return lambda_ * logtw + (1-lambda_) * loglift"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting words from vocab for a given topic.", "response": "def get_most_relevant_words_for_topic(vocab, rel_mat, topic, n=None):\n    \"\"\"\n    Get words from `vocab` for `topic` ordered by most to least relevance (Sievert and Shirley 2014) using the relevance\n    matrix `rel_mat` obtained from `get_topic_word_relevance()`.\n    Optionally only return the `n` most relevant words.\n    \"\"\"\n    _check_relevant_words_for_topic_args(vocab, rel_mat, topic)\n    return _words_by_score(vocab, rel_mat[topic], least_to_most=False, n=n)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_least_relevant_words_for_topic(vocab, rel_mat, topic, n=None):\n    _check_relevant_words_for_topic_args(vocab, rel_mat, topic)\n    return _words_by_score(vocab, rel_mat[topic], least_to_most=True, n=n)", "response": "Get words from vocab for a given topic."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef generate_topic_labels_from_top_words(topic_word_distrib, doc_topic_distrib, doc_lengths, vocab,\n                                         n_words=None, lambda_=1, labels_glue='_', labels_format='{i1}_{topwords}'):\n    \"\"\"\n    Generate topic labels derived from the top words of each topic. The top words are determined from the\n    relevance score (Sievert and Shirley 2014) depending on `lambda_`. Specify the number of top words in the label\n    with `n_words`. If `n_words` is None, a minimum number of words will be used to create unique labels for each\n    topic. Topic labels are formed by joining the top words with `labels_glue` and formatting them with\n    `labels_format`. Placeholders in `labels_format` are `{i0}` (zero-based topic index),\n    `{i1}` (one-based topic index) and `{topwords}` (top words glued with `labels_glue`).\n    \"\"\"\n    rel_mat = get_topic_word_relevance(topic_word_distrib, doc_topic_distrib, doc_lengths, lambda_=lambda_)\n\n    if n_words is None:\n        n_words = range(1, len(vocab)+1)\n    else:\n        if not 1 <= n_words <= len(vocab):\n            raise ValueError('`n_words` must be in range [1, %d]' % len(vocab))\n\n        n_words = range(n_words, n_words+1)\n\n    most_rel_words = [tuple(get_most_relevant_words_for_topic(vocab, rel_mat, t))\n                      for t in range(topic_word_distrib.shape[0])]\n\n    n_most_rel = []\n    for n in n_words:\n        n_most_rel = [ws[:n] for ws in most_rel_words]\n        if len(n_most_rel) == len(set(n_most_rel)):   # we have a list of unique word sequences\n            break\n\n    assert n_most_rel\n\n    topic_labels = [labels_format.format(i0=i, i1=i+1, topwords=labels_glue.join(ws))\n                    for i, ws in enumerate(n_most_rel)]\n\n    if len(topic_labels) != len(set(topic_labels)):\n        raise ValueError('generated labels are not unique')\n\n    return topic_labels", "response": "Generates topic labels derived from the top words of each topic."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning a DataFrame containing the top n values from a LDA model s distribution as a DataFrame.", "response": "def top_n_from_distribution(distrib, top_n=10, row_labels=None, col_labels=None, val_labels=None):\n    \"\"\"\n    Get `top_n` values from LDA model's distribution `distrib` as DataFrame. Can be used for topic-word distributions\n    and document-topic distributions. Set `row_labels` to a format string or a list. Set `col_labels` to a format\n    string for the column names. Set `val_labels` to return value labels instead of pure values (probabilities).\n    \"\"\"\n    import pandas as pd\n\n    if len(distrib) == 0:\n        raise ValueError('`distrib` must contain values')\n\n    if top_n < 1:\n        raise ValueError('`top_n` must be at least 1')\n    elif top_n > distrib.shape[1]:\n        raise ValueError('`top_n` cannot be larger than num. of values in `distrib` rows')\n\n    if row_labels is None:\n        row_label_fixed = None\n    elif isinstance(row_labels, str):\n        row_label_fixed = row_labels\n    else:\n        row_label_fixed = None\n\n    if val_labels is not None and type(val_labels) in (list, tuple):\n        val_labels = np.array(val_labels)\n\n    if col_labels is None:\n        columns = range(top_n)\n    else:\n        columns = [col_labels.format(i0=i, i1=i+1) for i in range(top_n)]\n\n    series = []\n\n    for i, row_distrib in enumerate(distrib):\n        if row_label_fixed:\n            row_name = row_label_fixed.format(i0=i, i1=i+1)\n        else:\n            if row_labels is not None:\n                row_name = row_labels[i]\n            else:\n                row_name = None\n\n        # `sorter_arr` is an array of indices that would sort another array by `row_distrib` (from low to high!)\n        sorter_arr = np.argsort(row_distrib)\n\n        if val_labels is None:\n            sorted_vals = row_distrib[sorter_arr][:-(top_n + 1):-1]\n        else:\n            if isinstance(val_labels, str):\n                sorted_vals = [val_labels.format(i0=i, i1=i+1, val=row_distrib[i]) for i in sorter_arr[::-1]][:top_n]\n            else:\n                # first brackets: sort vocab by `sorter_arr`\n                # second brackets: slice operation that reverts ordering (:-1) and then selects only `n_top` number of\n                # elements\n                sorted_vals = val_labels[sorter_arr][:-(top_n + 1):-1]\n\n        series_kwargs = dict(index=columns)\n        if row_name is not None:\n            series_kwargs['name'] = row_name\n\n        series.append(pd.Series(sorted_vals, **series_kwargs))\n\n    return pd.DataFrame(series)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef filter_topics(w, vocab, topic_word_distrib, top_n=None, thresh=None, match='exact', cond='any', glob_method='match',\n                  return_words_and_matches=False):\n    \"\"\"\n    Filter topics defined as topic-word distribution `topic_word_distrib` across vocabulary `vocab` for a word (pass a\n    string) or multiple words/patterns `w` (pass a list of strings). Either run pattern(s) `w` against the list of\n    top words per topic (use `top_n` for number of words in top words list) or specify a minimum topic-word probability\n    `thresh`, resulting in a list of words above this threshold for each topic, which will be used for pattern matching.\n    You can also specify `top_n` *and* `thresh`.\n    Set the `match` parameter according to the options provided by `filter_tokens.token_match()` (exact matching, RE or\n    glob matching). Use `cond` to specify whether at only *one* match suffices per topic when a list of patterns `w` is\n    passed (`cond='any'`) or *all* patterns must match (`cond='all'`).\n    By default, this function returns a NumPy array containing the *indices* of topics that passed the filter criteria.\n    If `return_words_and_matches` is True, this function additonally returns a NumPy array with the top words for each\n    topic and a NumPy array with the pattern matches for each topic.\n    \"\"\"\n    if not w:\n        raise ValueError('`w` must be non empty')\n\n    if isinstance(w, str):\n        w = [w]\n    elif not isinstance(w, (list, tuple, set)):\n        raise ValueError('`w` must be either string or list, tuple or set')\n\n    if top_n is None and thresh is None:\n        raise ValueError('either `top_n` or `thresh` must be given')\n\n    if cond not in {'any', 'all'}:\n        raise ValueError(\"`cond` must be one of `'any', 'all'`\")\n\n    if thresh is None:\n        top_words = top_words_for_topics(topic_word_distrib, top_n=top_n, vocab=vocab)\n        top_probs = None\n    else:\n        top_words, top_probs = top_words_for_topics(topic_word_distrib, top_n=top_n, vocab=vocab, return_prob=True)\n\n    found_topic_indices = []\n    found_topic_words = []\n    found_topic_matches = []\n    cond_fn = np.any if cond == 'any' else np.all\n\n    for t_idx, words in enumerate(top_words):\n        token_matches = [token_match(x, words, match, glob_method=glob_method) for x in w]\n        if top_probs:\n            words_p = top_probs[t_idx]\n            probs_matches = [sum(words_p[m] >= thresh) > 0 for m in token_matches]\n        else:\n            probs_matches = [[True]]\n\n        token_matches_comb = np.any(token_matches, axis=1)\n        assert len(token_matches_comb) == len(w)\n\n        if cond_fn(token_matches_comb) and cond_fn(probs_matches):\n            found_topic_indices.append(t_idx)\n            if return_words_and_matches:\n                found_topic_words.append(words)\n                found_topic_matches.append(np.any(token_matches, axis=0))\n\n    if return_words_and_matches:\n        return np.array(found_topic_indices), np.array(found_topic_words), np.array(found_topic_matches)\n    else:\n        return np.array(found_topic_indices)", "response": "Filter a list of topics from a word or list of patterns w."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nexcludes topics with the indices excl_topic_indices from the document - topic distribution doc_topic_distrib.", "response": "def exclude_topics(excl_topic_indices, doc_topic_distrib, topic_word_distrib=None, renormalize=True,\n                   return_new_topic_mapping=False):\n    \"\"\"\n    Exclude topics with the indices `excl_topic_indices` from the document-topic distribution `doc_topic_distrib` (i.e.\n    delete the respective columns in this matrix) and optionally re-normalize the distribution so that the rows sum up\n    to 1 if `renormalize` is set to `True`.\n    Optionally also strip the topics from the topic-word distribution `topic_word_distrib` (i.e. remove the respective\n    rows).\n\n    If `topic_word_distrib` is given, return a tuple with the updated doc.-topic and topic-word distributions, else\n    return only the updated doc.-topic distribution.\n\n    *WARNING:* The topics to be excluded are specified by *zero-based indices*.\n    \"\"\"\n    new_theta = np.delete(doc_topic_distrib, excl_topic_indices, axis=1)\n    if renormalize:\n        new_theta /= new_theta.sum(axis=1)[:, None]\n\n    if topic_word_distrib is not None:\n        new_phi = np.delete(topic_word_distrib, excl_topic_indices, axis=0)\n        res_tuple = (new_theta, new_phi)\n    else:\n        res_tuple = (new_theta, )\n\n    if return_new_topic_mapping:\n        topic_ind = np.arange(doc_topic_distrib.shape[1])\n        old_topic_ind = np.delete(topic_ind, excl_topic_indices)\n        res_tuple += (dict(zip(old_topic_ind, range(len(old_topic_ind)))), )\n\n    if len(res_tuple) == 1:\n        return res_tuple[0]\n    else:\n        return res_tuple"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef paragraphs_from_lines(lines, splitchar='\\n', break_on_num_newlines=2, force_unix_linebreaks=True):\n    if splitchar:\n        if force_unix_linebreaks:\n            lines = linebreaks_win2unix(lines)\n\n        lines = lines.split(splitchar)\n    else:\n        if type(lines) not in (tuple, list):\n            raise ValueError(\"`lines` must be passed as list or tuple if `splitchar` evaluates to False\")\n\n    n_lines = len(lines)\n    paragraphs = []\n    n_emptylines = 0\n    cur_par = ''\n    # iterate through all lines\n    for i, l in enumerate(lines):\n        if not splitchar and force_unix_linebreaks:\n            l = linebreaks_win2unix(l)\n\n        if l.strip():\n            if not cur_par:\n                cur_par = l\n            else:\n                cur_par += ' ' + l\n            n_emptylines = 0\n        else:\n            n_emptylines += 1\n\n        if (n_emptylines >= break_on_num_newlines-1 or i == n_lines-1) and cur_par:\n            paragraphs.append(cur_par)\n            cur_par = ''\n            n_emptylines = 0\n\n    return paragraphs", "response": "Takes a list of lines and splits them into individual paragraphs."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_vocab_and_terms(docs):\n    vocab = set()\n    docs_terms = {}\n    sum_uniques_per_doc = 0\n\n    # go through the documents\n    for i, (doc_label, terms) in enumerate(docs.items()):\n        terms_arr = np.array(terms)\n        docs_terms[doc_label] = terms_arr\n\n        # update the vocab set\n        terms_unique = set(terms)\n        vocab |= terms_unique\n\n        # update the sum of unique values per document\n        sum_uniques_per_doc += len(terms_unique)\n\n    doc_labels = docs_terms.keys()\n\n    return np.fromiter(vocab, dtype='<U%d' % max(map(len, vocab)), count=len(vocab)), \\\n           np.fromiter(doc_labels, dtype='<U%d' % max(map(len, doc_labels)), count=len(doc_labels)),\\\n           docs_terms, sum_uniques_per_doc", "response": "Generate an array of vocabulary and terms for a given document."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef create_sparse_dtm(vocab, doc_labels, docs_terms, sum_uniques_per_doc):\n    vocab_sorter = np.argsort(vocab)  # indices that sort <vocab>\n\n    nvocab = len(vocab)\n    ndocs = len(doc_labels)\n\n    # create arrays for sparse matrix\n    data = np.empty(sum_uniques_per_doc, dtype=np.intc)  # all non-zero term frequencies at data[k]\n    cols = np.empty(sum_uniques_per_doc, dtype=np.intc)  # column index for kth data item (kth term freq.)\n    rows = np.empty(sum_uniques_per_doc, dtype=np.intc)  # row index for kth data item (kth term freq.)\n\n    ind = 0  # current index in the sparse matrix data\n    # go through all documents with their terms\n    for i, (doc_label, terms) in enumerate(docs_terms.items()):\n        if len(terms) == 0: continue   # skip empty documents\n\n        # find indices into `vocab` such that, if the corresponding elements in `terms` were\n        # inserted before the indices, the order of `vocab` would be preserved\n        # -> array of indices of `terms` in `vocab`\n        term_indices = vocab_sorter[np.searchsorted(vocab, terms, sorter=vocab_sorter)]\n\n        # count the unique terms of the document and get their vocabulary indices\n        uniq_indices, counts = np.unique(term_indices, return_counts=True)\n        n_vals = len(uniq_indices)\n        ind_end = ind + n_vals\n\n        data[ind:ind_end] = counts  # save the counts (term frequencies)\n        cols[ind:ind_end] = uniq_indices  # save the column index: index in <vocab>\n        doc_idx = np.where(doc_labels == doc_label)  # get the document index for the document name\n        assert len(doc_idx) == 1\n        rows[ind:ind_end] = np.repeat(doc_idx, n_vals)  # save it as repeated value\n\n        ind = ind_end\n\n    assert ind == len(data)\n\n    return coo_matrix((data, (rows, cols)), shape=(ndocs, nvocab), dtype=np.intc)", "response": "Create a sparse document - term - matrix from vocabulary array doc_labels dict of doc_label -> document terms docs_terms and the sum of unique terms per document sum_uniques_per_doc per document."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef feature_detector(self, tokens, index, history):\n\n        word = tokens[index]\n        if index == 0: # At the beginning of the sentence\n            prevword = prevprevword = None\n            prevtag = prevprevtag = None\n            #word = word.lower() # Lowercase at the beginning of sentence\n        elif index == 1:\n            prevword = tokens[index-1] # Note: no lowercase\n            prevprevword = None\n            prevtag = history[index-1]\n            prevprevtag = None\n        else:\n            prevword = tokens[index-1]\n            prevprevword = tokens[index-2]\n            prevtag = history[index-1]\n            prevprevtag = history[index-2]\n\n        if re.match('[0-9]+([\\.,][0-9]*)?|[0-9]*[\\.,][0-9]+$', word):\n            # Included \",\" as decimal point\n            shape = 'number'\n        elif re.compile('\\W+$', re.UNICODE).match(word):\n            # Included unicode flag\n            shape = 'punct'\n        elif re.match('([A-Z\u00c4\u00d6\u00dc]+[a-z\u00e4\u00f6\u00fc\u00df]*-?)+$', word):\n            # Included dash for dashed words and umlauts\n            shape = 'upcase'\n        elif re.match('[a-z\u00e4\u00f6\u00fc\u00df]+', word):\n            # Included umlauts\n            shape = 'downcase'\n        elif re.compile(\"\\w+\", re.UNICODE).match(word):\n            # Included unicode flag\n            shape = 'mixedcase'\n        else:\n            shape = 'other'\n\n        features = {\n            'prevtag': prevtag,\n            'prevprevtag': prevprevtag,\n            'word': word,\n            'word.lower': word.lower(),\n            'suffix3': word.lower()[-3:],\n            #'suffix2': word.lower()[-2:],\n            #'suffix1': word.lower()[-1:],\n            'preffix1': word[:1], # included\n            'prevprevword': prevprevword,\n            'prevword': prevword,\n            'prevtag+word': '%s+%s' % (prevtag, word),\n            'prevprevtag+word': '%s+%s' % (prevprevtag, word),\n            'prevword+word': '%s+%s' % (prevword, word),\n            'shape': shape\n            }\n        return features", "response": "Implement a slightly modified feature detector."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef pickle_data(data, picklefile):\n    with open(picklefile, 'wb') as f:\n        pickle.dump(data, f, protocol=2)", "response": "Helper function to pickle data in picklefile."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef unpickle_file(picklefile, **kwargs):\n    with open(picklefile, 'rb') as f:\n        return pickle.load(f, **kwargs)", "response": "Helper function to unpickle data from picklefile."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns a simplified POS tag for a full POS tag.", "response": "def simplified_pos(pos, tagset=None):\n    \"\"\"\n    Return a simplified POS tag for a full POS tag `pos` belonging to a tagset `tagset`. By default the WordNet\n    tagset is assumed.\n    Does the following conversion by default:\n    - all N... (noun) tags to 'N'\n    - all V... (verb) tags to 'V'\n    - all ADJ... (adjective) tags to 'ADJ'\n    - all ADV... (adverb) tags to 'ADV'\n    - all other to None\n    Does the following conversion by with `tagset=='penn'`:\n    - all N... (noun) tags to 'N'\n    - all V... (verb) tags to 'V'\n    - all JJ... (adjective) tags to 'ADJ'\n    - all RB... (adverb) tags to 'ADV'\n    - all other to None\n    \"\"\"\n    if tagset == 'penn':\n        if pos.startswith('N') or pos.startswith('V'):\n            return pos[0]\n        elif pos.startswith('JJ'):\n            return 'ADJ'\n        elif pos.startswith('RB'):\n            return 'ADV'\n        else:\n            return None\n    else:   # default: WordNet, STTS or unknown\n        if pos.startswith('N') or pos.startswith('V'):\n            return pos[0]\n        elif pos.startswith('ADJ') or pos.startswith('ADV'):\n            return pos[:3]\n        else:\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nselects an area / window inside of a 2D array or matrix mat specified by row_indices and col_indices.", "response": "def mat2d_window_from_indices(mat, row_indices=None, col_indices=None, copy=False):\n    \"\"\"\n    Select an area/\"window\" inside of a 2D array/matrix `mat` specified by either a sequence of\n    row indices `row_indices` and/or a sequence of column indices `col_indices`.\n    Returns the specified area as a *view* of the data if `copy` is False, else it will return a copy.\n    \"\"\"\n    if not isinstance(mat, np.ndarray) or mat.ndim != 2:\n        raise ValueError('`mat` must be a 2D NumPy array')\n\n    if mat.shape[0] == 0 or mat.shape[1] == 0:\n        raise ValueError('invalid shape for `mat`: %s' % mat.shape)\n\n    if row_indices is None:\n        row_indices = slice(None)   # a \":\" slice\n    elif len(row_indices) == 0:\n        raise ValueError('`row_indices` must be non-empty')\n\n    if col_indices is None:\n        col_indices = slice(None)   # a \":\" slice\n    elif len(col_indices) == 0:\n        raise ValueError('`col_indices` must be non-empty')\n\n    view = mat[row_indices, :][:, col_indices]\n\n    if copy:\n        return view.copy()\n    else:\n        return view"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nbring a 1D NumPy array with at least two values in values to a linearly normalized range of [ 0 1 ).", "response": "def normalize_to_unit_range(values):\n    \"\"\"Bring a 1D NumPy array with at least two values in `values` to a linearly normalized range of [0, 1].\"\"\"\n    if not isinstance(values, np.ndarray) or values.ndim != 1:\n        raise ValueError('`values` must be a 1D NumPy array')\n\n    if len(values) < 2:\n        raise ValueError('`values` must contain at least two values')\n\n    min_ = np.min(values)\n    max_ = np.max(values)\n    range_ = max_ - min_\n\n    if range_ == 0:\n        raise ValueError('range of `values` is 0 -- cannot normalize')\n\n    return (values - min_) / range_"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef greedy_partitioning(elems_dict, k, return_only_labels=False):\n    if k <= 0:\n        raise ValueError('`k` must be at least 1')\n    elif k == 1:\n        return elems_dict\n    elif k >= len(elems_dict):\n        # if k is bigger than the number of elements, return `len(elems_dict)` bins with each\n        # bin containing only a single element\n        if return_only_labels:\n            return [[k] for k in elems_dict.keys()]\n        else:\n            return [{k: v} for k, v in elems_dict.items()]\n\n    sorted_elems = sorted(elems_dict.items(), key=lambda x: x[1], reverse=True)\n    bins = [[sorted_elems.pop(0)] for _ in range(k)]\n    bin_sums = [sum(x[1] for x in b) for b in bins]\n\n    for pair in sorted_elems:\n        argmin = min(enumerate(bin_sums), key=lambda x: x[1])[0]\n        bins[argmin].append(pair)\n        bin_sums[argmin] += pair[1]\n\n    if return_only_labels:\n        return [[x[1] for x in b] for b in bins]\n    else:\n        return [dict(b) for b in bins]", "response": "Greedy partitioning algorithm for a dict of elements with label -> weight mapping."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning a NumPy array signaling matches between pattern and tokens.", "response": "def token_match(pattern, tokens, match_type='exact', ignore_case=False, glob_method='match'):\n    \"\"\"\n    Return a NumPy array signaling matches between `pattern` and `tokens`. `pattern` is a string that will be\n    compared with each element in sequence `tokens` either as exact string equality (`match_type` is 'exact') or\n    regular expression (`match_type` is 'regex') or glob pattern (`match_type` is 'glob').\n    \"\"\"\n    if match_type not in {'exact', 'regex', 'glob'}:\n        raise ValueError(\"`match_type` must be one of `'exact', 'regex', 'glob'`\")\n\n    if not isinstance(tokens, np.ndarray):\n        tokens = np.array(tokens)\n\n    if match_type == 'exact':\n        return np.char.lower(tokens) == pattern.lower() if ignore_case else tokens == pattern\n    elif match_type == 'regex':\n        if isinstance(pattern, str):\n            pattern = re.compile(pattern, flags=re.IGNORECASE)\n        vecmatch = np.vectorize(lambda x: bool(pattern.search(x)))\n        return vecmatch(tokens)\n    else:\n        if glob_method not in {'search', 'match'}:\n            raise ValueError(\"`glob_method` must be one of `'search', 'match'`\")\n\n        if isinstance(pattern, str):\n            pattern = globre.compile(pattern, flags=re.IGNORECASE)\n\n        if glob_method == 'search':\n            vecmatch = np.vectorize(lambda x: bool(pattern.search(x)))\n        else:\n            vecmatch = np.vectorize(lambda x: bool(pattern.match(x)))\n\n        return vecmatch(tokens)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef metric_held_out_documents_wallach09(dtm_test, theta_test, phi_train, alpha, n_samples=10000):\n    import gmpy2\n\n    n_test_docs, n_vocab = dtm_test.shape\n\n    if n_test_docs != theta_test.shape[0]:\n        raise ValueError('shapes of `dtm_test` and `theta_test` do not match (unequal number of documents)')\n\n    _, n_topics = theta_test.shape\n\n    if n_topics != phi_train.shape[0]:\n        raise ValueError('shapes of `theta_test` and `phi_train` do not match (unequal number of topics)')\n\n    if n_vocab != phi_train.shape[1]:\n        raise ValueError('shapes of `dtm_test` and `phi_train` do not match (unequal size of vocabulary)')\n\n    if isinstance(alpha, np.ndarray):\n        alpha_sum = np.sum(alpha)\n    else:\n        alpha_sum = alpha * n_topics\n        alpha = np.repeat(alpha, n_topics)\n\n    if alpha.shape != (n_topics, ):\n        raise ValueError('`alpha` has invalid shape (should be vector of length n_topics)')\n\n    # samples: random topic assignments for each document\n    #          shape: n_test_docs x n_samples\n    #          values in [0, n_topics) ~ theta_test\n    samples = np.array([np.random.choice(n_topics, n_samples, p=theta_test[d, :])\n                        for d in range(n_test_docs)])\n    assert samples.shape == (n_test_docs, n_samples)\n    assert 0 <= samples.min() < n_topics\n    assert 0 <= samples.max() < n_topics\n\n    # n_k: number of documents per topic and sample\n    #      shape: n_topics x n_samples\n    #      values in [0, n_test_docs]\n    n_k = np.array([np.sum(samples == t, axis=0) for t in range(n_topics)])\n    assert n_k.shape == (n_topics, n_samples)\n    assert 0 <= n_k.min() <= n_test_docs\n    assert 0 <= n_k.max() <= n_test_docs\n\n    # calculate log p(z) for each sample\n    # shape: 1 x n_samples\n    log_p_z = np.sum(gammaln(n_k + alpha[:, np.newaxis]), axis=0) + gammaln(alpha_sum) \\\n              - np.sum(gammaln(alpha)) - gammaln(n_test_docs + alpha_sum)\n\n    assert log_p_z.shape == (n_samples,)\n\n    # calculate log p(w|z) for each sample\n    # shape: 1 x n_samples\n\n    log_p_w_given_z = np.zeros(n_samples)\n\n    dtm_is_sparse = issparse(dtm_test)\n    for d in range(n_test_docs):\n        if dtm_is_sparse:\n            word_counts_d = dtm_test[d].toarray().flatten()\n        else:\n            word_counts_d = dtm_test[d]\n        words = np.repeat(np.arange(n_vocab), word_counts_d)\n        assert words.shape == (word_counts_d.sum(),)\n\n        phi_topics_d = phi_train[samples[d]]   # phi for topics in samples for document d\n        log_p_w_given_z += np.sum(np.log(phi_topics_d[:, words]), axis=1)\n\n    log_joint = log_p_z + log_p_w_given_z\n\n    # calculate log theta_test\n    # shape: 1 x n_samples\n\n    log_theta_test = np.zeros(n_samples)\n\n    for d in range(n_test_docs):\n        log_theta_test += np.log(theta_test[d, samples[d]])\n\n    # compare\n    log_weights = log_joint - log_theta_test\n\n    # calculate final log evidence\n    # requires using gmpy2 to avoid numerical underflow\n    exp_sum = gmpy2.mpfr(0)\n    for exp in (gmpy2.exp(x) for x in log_weights):\n        exp_sum += exp\n\n    return float(gmpy2.log(exp_sum)) - np.log(n_samples)", "response": "Compute the metric of held - out documents according to Wallach et al. 2009."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncalculate the harmonic mean of the loglikelihood values logliks as in Griffiths and Mark Steyvers 2004.", "response": "def metric_griffiths_2004(logliks):\n    \"\"\"\n    Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy\n    of Sciences 101, suppl 1: 5228\u20135235. http://doi.org/10.1073/pnas.0307752101\n\n    Calculates the harmonic mean of the loglikelihood values `logliks` as in Griffiths, Steyvers 2004. Burnin values\n    should already be removed from `logliks`.\n\n    Note: requires gmpy2 package for multiple-precision arithmetic to avoid numerical underflow.\n          see https://github.com/aleaxit/gmpy\n    \"\"\"\n\n    import gmpy2\n\n    # using median trick as in Martin Ponweiser's Diploma Thesis 2012, p.36\n    ll_med = np.median(logliks)\n    ps = [gmpy2.exp(ll_med - x) for x in logliks]\n    ps_mean = gmpy2.mpfr(0)\n    for p in ps:\n        ps_mean += p / len(ps)\n    return float(ll_med - gmpy2.log(ps_mean))   # after taking the log() we can use a Python float() again"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ncalculates the coherence metric according to Mimno et al. 2011.", "response": "def metric_coherence_mimno_2011(topic_word_distrib, dtm, top_n=20, eps=1e-12, normalize=True, return_mean=False):\n    \"\"\"\n    Calculate coherence metric according to Mimno et al. 2011 (a.k.a. \"U_Mass\" coherence metric). There are two\n    modifications to the originally suggested measure:\n    - uses a different epsilon by default (set `eps=1` for original)\n    - uses a normalizing constant by default (set `normalize=False` for original)\n\n    Provide a topic word distribution $\\phi$ as `topic_word_distrib` and a document-term-matrix `dtm` (can be sparse).\n    `top_n` controls how many most probable words per topic are selected.\n\n    By default, it will return a NumPy array of coherence values per topic (same ordering as in `topic_word_distrib`).\n    Set `return_mean` to True to return the mean of all topics instead.\n\n    D. Mimno, H. Wallach, E. Talley, M. Leenders, A. McCullum 2011: Optimizing semantic coherence in topic models\n    \"\"\"\n    n_topics, n_vocab = topic_word_distrib.shape\n\n    if n_vocab != dtm.shape[1]:\n        raise ValueError('shapes of provided `topic_word_distrib` and `dtm` do not match (vocab sizes differ)')\n\n    if top_n > n_vocab:\n        raise ValueError('`top_n=%d` is larger than the vocabulary size of %d words'\n                         % (top_n, topic_word_distrib.shape[1]))\n\n    top_words = top_words_for_topics(topic_word_distrib, top_n)   # V\n\n    if issparse(dtm) and dtm.format != 'csc':\n        dtm = dtm.tocsc()\n\n    coh = []\n    for t in range(n_topics):\n        c_t = 0\n\n        v = top_words[t]\n        top_dtm = dtm[:, v]\n        df = get_doc_frequencies(top_dtm)      # D(v)\n        codf = get_codoc_frequencies(top_dtm)  # D(v, v')\n\n        for m in range(1, top_n):\n            for l in range(m):\n                c_t += np.log((codf.get((m, l), codf.get((l, m))) + eps) /\n                              df[l])\n\n        coh.append(c_t)\n\n    coh = np.array(coh)\n\n    if normalize:\n        coh *= 2 / (top_n * (top_n-1))\n\n    if return_mean:\n        return coh.mean()\n    else:\n        return coh"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ncalculating the coherence of a topic word - distribution using Gensim s CoherenceModel.", "response": "def metric_coherence_gensim(measure, topic_word_distrib=None, gensim_model=None, vocab=None, dtm=None,\n                            gensim_corpus=None, texts=None, top_n=20,\n                            return_coh_model=False, return_mean=False, **kwargs):\n    \"\"\"\n    Calculate model coherence using Gensim's `CoherenceModel` [1,2]. Note: this function also supports models from\n    `lda` and `sklearn` (by passing `topic_word_distrib`, `dtm` and `vocab`)!\n\n    Define which measure to use with parameter `measure`:\n    - u_mass\n    - c_v\n    - c_uci\n    - c_npmi\n\n    Provide a topic word distribution $\\phi$ as `topic_word_distrib` OR a Gensim model `gensim_model`\n    and the corpus' vocabulary as `vocab` OR pass a gensim corpus as `gensim_corpus`.\n    `top_n` controls how many most probable words per topic are selected.\n\n    If measure is `u_mass`, a document-term-matrix `dtm` or `gensim_corpus` must be provided and `texts` can be None.\n    If any other measure than `u_mass` is used, tokenized input as `texts` must be provided as 2D list:\n    ```\n    [['some', 'text', ...],          # doc. 1\n     ['some', 'more', ...],          # doc. 2\n     ['another', 'document', ...]]   # doc. 3\n    ```\n\n    If `return_coh_model` is True, the whole `CoherenceModel` instance will be returned, otherwise:\n    - if `return_mean` is True, the mean coherence value will be returned\n    - if `return_mean` is False, a list of coherence values (for each topic) will be returned\n\n    Provided `kwargs` will be passed to `CoherenceModel()` or `CoherenceModel.get_coherence_per_topic()`.\n\n    [1]: https://radimrehurek.com/gensim/models/coherencemodel.html\n    [2]: https://rare-technologies.com/what-is-topic-coherence/\n    \"\"\"\n    try:\n        import gensim\n    except ImportError:\n        raise ValueError('package `gensim` must be installed for `coherence_gensim` metric')\n\n    if measure == 'u_mass' and dtm is None and gensim_corpus is None:\n        raise ValueError('document-term-matrix `dtm` or Gensim corpus `gensim_corpus` must be provided for measure '\n                         '`u_mass`')\n    elif measure != 'u_mass' and texts is None:\n        raise ValueError('`texts` must be provided for any other measure than `u_mass`')\n\n    if gensim_model is None:\n        if topic_word_distrib is None:\n            raise ValueError('`topic_word_distrib` must be given if `gensim_model` was not passed')\n        n_topics, n_vocab = topic_word_distrib.shape\n    else:\n        n_topics, n_vocab = None, None\n\n    if vocab is not None:\n        if len(vocab) != n_vocab:\n            raise ValueError('shape of provided `topic_word_distrib` and length of `vocab` do not match '\n                             '(vocab sizes differ)')\n        if top_n > n_vocab:\n            raise ValueError('`top_n=%d` is larger than the vocabulary size of %d words'\n                             % (top_n, topic_word_distrib.shape[1]))\n    elif gensim_corpus is None:\n        raise ValueError('a gensim corpus `gensim_corpus` must be passed if no `vocab` is given')\n\n    if measure == 'u_mass' and gensim_corpus is None and n_vocab != dtm.shape[1]:\n        raise ValueError('shapes of provided `topic_word_distrib` and `dtm` do not match (vocab sizes differ)')\n\n    if vocab is not None:\n        top_words = top_words_for_topics(topic_word_distrib, top_n, vocab=vocab)   # V\n    else:\n        top_words = None\n\n    coh_model_kwargs = {'coherence': measure}\n    if measure == 'u_mass':\n        if gensim_corpus is None:\n            gensim_corpus, gensim_dict = dtm_and_vocab_to_gensim_corpus_and_dict(dtm, vocab)\n            coh_model_kwargs.update(dict(corpus=gensim_corpus, dictionary=gensim_dict, topics=top_words))\n        else:\n            coh_model_kwargs.update(dict(model=gensim_model, corpus=gensim_corpus, topn=top_n))\n    else:\n        if gensim_corpus is None:\n            coh_model_kwargs.update(dict(texts=texts, topics=top_words, dictionary=FakedGensimDict.from_vocab(vocab)))\n        else:\n            coh_model_kwargs.update(dict(texts=texts, model=gensim_model, corpus=gensim_corpus, topn=top_n))\n\n    get_coh_kwargs = {}\n    for opt in ('segmented_topics', 'with_std', 'with_support'):\n        if opt in kwargs:\n            get_coh_kwargs[opt] = kwargs.pop(opt)\n\n    coh_model_kwargs.update(kwargs)\n\n    coh_model = gensim.models.CoherenceModel(**coh_model_kwargs)\n\n    if return_coh_model:\n        return coh_model\n    else:\n        if return_mean:\n            return coh_model.get_coherence()\n        else:\n            return coh_model.get_coherence_per_topic(**get_coh_kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef results_by_parameter(res, param, sort_by=None, sort_desc=False):\n    if len(res) == 0:\n        return []\n\n    tuples = [(p[param], r) for p, r in res]\n\n   # single validation results\n    if len(tuples[0]) != 2:\n        raise ValueError('invalid evaluation results passed')\n\n    params, metric_results = list(zip(*tuples))\n    if sort_by:\n        sorted_ind = argsort([r[sort_by] for r in metric_results])\n    else:\n        sorted_ind = argsort(params)\n\n    if sort_desc:\n        sorted_ind = reversed(sorted_ind)\n\n    measurements = tuples\n\n    return [measurements[i] for i in sorted_ind]", "response": "Takes a list of evaluation results res and returns a list with tuples with tuples with the parameter param and the result in the form param_1 param_n..."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef abstractclass(cls):\n    setattr(cls, \"_ISNEVER\", cls.__bases__[0].__name__)\n    origInit = cls.__dict__[\"__init__\"]\n\n    def wrapInit(self, *args, **kwargs):\n        # when the class is instantiated we can check for bases\n        # we don't want it to be the base class\n        try:\n            assert self.__class__.__bases__[-1].__name__ != self._ISNEVER\n            origInit(self, *args, **kwargs)\n        except AssertionError:\n            raise TypeError(\"Use of abstract base class\")\n\n    # replace the original __init__\n    setattr(wrapInit, \"__doc__\", getattr(origInit, \"__doc__\"))\n    setattr(origInit, \"__doc__\", \"\")\n    setattr(cls, \"__init__\", wrapInit)\n\n    return cls", "response": "abstractclass - class decorator."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a named granularity into seconds.", "response": "def granularity_to_time(s):\n    \"\"\"convert a named granularity into seconds.\n\n    get value in seconds for named granularities: M1, M5 ... H1 etc.\n\n    >>> print(granularity_to_time(\"M5\"))\n    300\n    \"\"\"\n    mfact = {\n        'S': 1,\n        'M': 60,\n        'H': 3600,\n        'D': 86400,\n        'W': 604800,\n    }\n    try:\n        f, n = re.match(\"(?P<f>[SMHDW])(?:(?P<n>\\d+)|)\", s).groups()\n        n = n if n else 1\n        return mfact[f] * int(n)\n\n    except Exception as e:\n        raise ValueError(e)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nreturn a list of all classes in a module", "response": "def get_classes(modName):\n    \"\"\"return a list of all classes in a module.\"\"\"\n    classNames = []\n    for name, obj in inspect.getmembers(sys.modules[modName]):\n        if inspect.isclass(obj):\n            classNames.append(name)\n\n    return classNames"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __request(self, method, url, request_args, headers=None, stream=False):\n        func = getattr(self.client, method)\n        headers = headers if headers else {}\n        response = None\n        try:\n            logger.info(\"performing request %s\", url)\n            response = func(url, stream=stream, headers=headers,\n                            **request_args)\n        except requests.RequestException as err:\n            logger.error(\"request %s failed [%s]\", url, err)\n            raise err\n\n        # Handle error responses\n        if response.status_code >= 400:\n            logger.error(\"request %s failed [%d,%s]\",\n                         url,\n                         response.status_code,\n                         response.content.decode('utf-8'))\n            raise V20Error(response.status_code,\n                           response.content.decode('utf-8'))\n        return response", "response": "This method is called by the request method in case of regular API - calls."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms a request for the APIRequest instance endpoint. Returns the response content.", "response": "def request(self, endpoint):\n        \"\"\"Perform a request for the APIRequest instance 'endpoint'.\n\n        Parameters\n        ----------\n        endpoint : APIRequest\n            The endpoint parameter contains an instance of an APIRequest\n            containing the endpoint, method and optionally other parameters\n            or body data.\n\n        Raises\n        ------\n            V20Error in case of HTTP response code >= 400\n        \"\"\"\n        method = endpoint.method\n        method = method.lower()\n        params = None\n        try:\n            params = getattr(endpoint, \"params\")\n        except AttributeError:\n            # request does not have params\n            params = {}\n\n        headers = {}\n        if hasattr(endpoint, \"HEADERS\"):\n            headers = getattr(endpoint, \"HEADERS\")\n\n        request_args = {}\n        if method == 'get':\n            request_args['params'] = params\n        elif hasattr(endpoint, \"data\") and endpoint.data:\n            request_args['json'] = endpoint.data\n\n        # if any parameter for request then merge them\n        request_args.update(self._request_params)\n\n        # which API to access ?\n        if not (hasattr(endpoint, \"STREAM\") and\n                getattr(endpoint, \"STREAM\") is True):\n            url = \"{}/{}\".format(\n                TRADING_ENVIRONMENTS[self.environment][\"api\"],\n                endpoint)\n\n            response = self.__request(method, url,\n                                      request_args, headers=headers)\n            content = response.content.decode('utf-8')\n            content = json.loads(content)\n\n            # update endpoint\n            endpoint.response = content\n            endpoint.status_code = response.status_code\n\n            return content\n\n        else:\n            url = \"{}/{}\".format(\n                TRADING_ENVIRONMENTS[self.environment][\"stream\"],\n                endpoint)\n            endpoint.response = self.__stream_request(method,\n                                                      url,\n                                                      request_args,\n                                                      headers=headers)\n            return endpoint.response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef make_definition_classes(mod):\n    rootpath = \"oandapyV20\"\n    PTH = \"{}.definitions.{}\".format(rootpath, mod)\n\n    M = import_module(PTH)\n    __ALL__ = []  # construct the __all__ variable\n    for cls, cldef in M.definitions.items():\n\n        orig, fiV = next(six.iteritems(cldef))\n        fiK = orig.replace('-', '_')\n        # create the docstring dynamically\n        clsdoc = dyndoc.format(cls=cls,\n                               PTH=PTH,\n                               mod=mod,\n                               firstItem=fiK, orig=orig,\n                               firstItemVal=fiV)\n\n        # Since we can't change the docstring afterwards (it's readonly)\n        # figure this out before and not during ...\n        for K, V in cldef.items():\n            attrName = K\n            if \"-\" in K:\n                attrName = K.replace('-', '_')\n                adoc = _doc.format(K, attrName, K)\n                clsdoc += adoc\n\n        # the class\n        dyncls = type(cls, (object,), {'__doc__': clsdoc})\n\n        definitions = dict()\n        for K, V in cldef.items():\n            attrName = K\n            if \"-\" in K:\n                attrName = K.replace('-', '_')\n            setattr(dyncls, attrName, K)  # set as class attributes\n            definitions.update({K: V})    # for mapping by __getitem__\n\n        def mkgi():\n            def __getitem__(self, definitionID):\n                \"\"\"return description for definitionID.\"\"\"\n                return self._definitions[definitionID]\n            return __getitem__\n\n        def mkinit(definitions):\n            def __init__(self):\n                self._definitions = definitions\n\n            return __init__\n\n        def mkPropDefinitions():\n            def definitions(self):\n                \"\"\"readonly property holding definition dict.\"\"\"\n                return self._definitions\n            return property(definitions)\n\n        setattr(dyncls, \"__getitem__\", mkgi())\n        setattr(dyncls, \"__init__\", mkinit(definitions))\n        setattr(dyncls, \"definitions\", mkPropDefinitions())\n        setattr(sys.modules[\"{}.definitions.{}\".format(rootpath, mod)],\n                cls, dyncls)\n        __ALL__.append(cls)\n\n    setattr(sys.modules[\"{}.definitions.{}\".format(rootpath, mod)],\n            \"__all__\", tuple(__ALL__))", "response": "Dynamically create the definition classes from the module mod."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _fix_integrity_error(f):\n\n    @wraps(f)\n    def wrapper(dialect, *args, **kwargs):\n        try:\n            return f(dialect, *args, **kwargs)\n        except dialect.dbapi.Error as exc:\n            if exc.errorcode == 301 and not isinstance(exc, dialect.dbapi.IntegrityError):\n                raise dialect.dbapi.IntegrityError(exc)\n            raise\n    return wrapper", "response": "Decorator that ensures raising of IntegrityError on unique constraint violations."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef pp_xml(body):\n    pretty = xml.dom.minidom.parseString(body)\n    return pretty.toprettyxml(indent=\"  \")", "response": "Pretty print format some XML so it s readable."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfind the value in a CIM response.", "response": "def _find_value(content, ns, key):\n    \"\"\"Find the return value in a CIM response.\n\n    The xmlns is needed because everything in CIM is a million levels\n    of namespace indirection.\n    \"\"\"\n    doc = ElementTree.fromstring(content)\n    query = './/{%(ns)s}%(item)s' % {'ns': ns, 'item': key}\n    rv = doc.find(query)\n    return rv.text"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _return_value(content, ns):\n    doc = ElementTree.fromstring(content)\n    query = './/{%(ns)s}%(item)s' % {'ns': ns, 'item': 'ReturnValue'}\n    rv = doc.find(query)\n    return int(rv.text)", "response": "Find the return value in a CIM response."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\npowering on the box.", "response": "def power_on(self):\n        \"\"\"Power on the box.\"\"\"\n        payload = amt.wsman.power_state_request(self.uri, \"on\")\n        return self.post(payload, CIM_PowerManagementService)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef set_next_boot(self, boot_device):\n        payload = amt.wsman.change_boot_order_request(self.uri, boot_device)\n        self.post(payload)\n\n        payload = amt.wsman.enable_boot_config_request(self.uri)\n        self.post(payload)", "response": "Sets the machine to boot to boot_device on its next reboot"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef loads(s, encoding=None, cls=None, object_hook=None, parse_float=None,\n          parse_int=None, parse_constant=None, object_pairs_hook=None):\n    \"\"\"Deserialize ``s`` (a ``str`` or ``unicode`` instance containing a\n    JSON5 document) to a Python object.\"\"\"\n\n    assert cls is None, 'Custom decoders are not supported'\n\n    if sys.version_info[0] < 3:\n        decodable_type = type('')\n    else:\n        decodable_type = type(b'')\n    if isinstance(s, decodable_type):\n        encoding = encoding or 'utf-8'\n        s = s.decode(encoding)\n\n    if not s:\n        raise ValueError('Empty strings are not legal JSON5')\n    parser = Parser(s, '<string>')\n    ast, err, newpos = parser.parse()\n    if err:\n        raise ValueError(err)\n\n    def _fp_constant_parser(s):\n        return float(s.replace('Infinity', 'inf').replace('NaN', 'nan'))\n\n    if object_pairs_hook:\n        dictify = object_pairs_hook\n    elif object_hook:\n        dictify = lambda pairs: object_hook(dict(pairs))\n    else:\n        dictify = dict\n\n    parse_float = parse_float or float\n    parse_int = parse_int or int\n    parse_constant = parse_constant or _fp_constant_parser\n\n    return _walk_ast(ast, dictify, parse_float, parse_int, parse_constant)", "response": "Deserialize a JSON5 string to a Python object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nserialize obj to a JSON5 - formatted str.", "response": "def dumps(obj, **kwargs):\n    \"\"\"Serialize ``obj`` to a JSON5-formatted ``str``.\"\"\"\n\n    t = type(obj)\n    if obj is True:\n        return u'true'\n    elif obj is False:\n        return u'false'\n    elif obj == None:\n        return u'null'\n    elif t == type('') or t == type(u''):\n        single = \"'\" in obj\n        double = '\"' in obj\n        if single and double:\n            return json.dumps(obj)\n        elif single:\n            return '\"' + obj + '\"'\n        else:\n            return \"'\" + obj + \"'\"\n    elif t is float or t is int:\n        return str(obj)\n    elif t is dict:\n        return u'{' + u','.join([\n            _dumpkey(k) + u':' + dumps(v) for k, v in obj.items()\n        ]) + '}'\n    elif t is list:\n        return u'[' + ','.join([dumps(el) for el in obj]) + u']'\n    else:  # pragma: no cover\n        return u''"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef dump(obj, fp, **kwargs):\n\n    s = dumps(obj, **kwargs)\n    fp.write(str(s))", "response": "Serialize obj to a JSON5 - formatted stream to fp."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef _close_received(self, error):\n        if error:\n            condition = error.condition\n            description = error.description\n            info = error.info\n        else:\n            condition = b\"amqp:unknown-error\"\n            description = None\n            info = None\n        _logger.info(\"Received Connection close event: %r\\nConnection: %r\\nDescription: %r\\nDetails: %r\",\n                     condition, self.container_id, description, info)\n        self._error = errors._process_connection_error(self.error_policy, condition, description, info)", "response": "Callback called when a connection CLOSE frame is received."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef destroy(self):\n        try:\n            self.lock()\n            _logger.debug(\"Unlocked connection %r to close.\", self.container_id)\n            self._close()\n        finally:\n            self.release()\n        uamqp._Platform.deinitialize()", "response": "Close the connection and close any associated\n            CBS authentication session."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nredirects the connection to an alternative endpoint.", "response": "def redirect(self, redirect_error, auth):\n        \"\"\"Redirect the connection to an alternative endpoint.\n        :param redirect: The Link DETACH redirect details.\n        :type redirect: ~uamqp.errors.LinkRedirect\n        :param auth: Authentication credentials to the redirected endpoint.\n        :type auth: ~uamqp.authentication.common.AMQPAuth\n        \"\"\"\n        try:\n            self.lock()\n            _logger.info(\"Redirecting connection %r.\", self.container_id)\n            if self.hostname == redirect_error.hostname:\n                return\n            if self._state != c_uamqp.ConnectionState.END:\n                _logger.info(\"Connection not closed yet - shutting down.\")\n                self._close()\n            self.hostname = redirect_error.hostname\n            self.auth = auth\n            self._conn = self._create_connection(auth)\n            for setting, value in self._settings.items():\n                setattr(self, setting, value)\n            self._error = None\n            self._closing = False\n        finally:\n            _logger.info(\"Finished redirecting connection %r.\", self.container_id)\n            self.release()"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nperforming a single Connection iteration.", "response": "def work(self):\n        \"\"\"Perform a single Connection iteration.\"\"\"\n        try:\n            raise self._error\n        except TypeError:\n            pass\n        except Exception as e:\n            _logger.warning(\"%r\", e)\n            raise\n        try:\n            self.lock()\n            self._conn.do_work()\n        except compat.TimeoutException:\n            _logger.debug(\"Connection %r timed out while waiting for lock acquisition.\", self.container_id)\n        finally:\n            self.release()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nlocking the connection for a given number of seconds.", "response": "def sleep(self, seconds):\n        \"\"\"Lock the connection for a given number of seconds.\n\n        :param seconds: Length of time to lock the connection.\n        :type seconds: int\n        \"\"\"\n        try:\n            self.lock()\n            time.sleep(seconds)\n        except compat.TimeoutException:\n            _logger.debug(\"Connection %r timed out while waiting for lock acquisition.\", self.container_id)\n        finally:\n            self.release()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef _detach_received(self, error):\n        # pylint: disable=protected-access\n        if error:\n            condition = error.condition\n            description = error.description\n            info = error.info\n        else:\n            condition = b\"amqp:unknown-error\"\n            description = None\n            info = None\n        self._error = errors._process_link_error(self.error_policy, condition, description, info)\n        _logger.info(\"Received Link detach event: %r\\nLink: %r\\nDescription: %r\"\n                     \"\\nDetails: %r\\nRetryable: %r\\nConnection: %r\",\n                     condition, self.name, description, info, self._error.action.retry,\n                     self._session._connection.container_id)", "response": "Callback called when a DETACH frame is received."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef get_state(self):\n        try:\n            raise self._error\n        except TypeError:\n            pass\n        except Exception as e:\n            _logger.warning(\"%r\", e)\n            raise\n        return self._state", "response": "Get the state of the MessageSender and its underlying Link."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef send(self, message, callback, timeout=0):\n        # pylint: disable=protected-access\n        try:\n            raise self._error\n        except TypeError:\n            pass\n        except Exception as e:\n            _logger.warning(\"%r\", e)\n            raise\n        c_message = message.get_message()\n        message._on_message_sent = callback\n        try:\n            self._session._connection.lock(timeout=-1)\n            return self._sender.send(c_message, timeout, message)\n        finally:\n            self._session._connection.release()", "response": "Send a single message to the internal pending queue."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def _redirect_async(self, redirect, auth):\n        # pylint: disable=protected-access\n        if not self._connection.cbs:\n            _logger.info(\"Closing non-CBS session.\")\n            await asyncio.shield(self._session.destroy_async())\n        self._session = None\n        self._auth = auth\n        self._hostname = self._remote_address.hostname\n        await self._connection.redirect_async(redirect, auth)\n        if not self._connection.cbs and isinstance(self._auth, authentication.CBSAsyncAuthMixin):\n            self._connection.cbs = await asyncio.shield(self._auth.create_authenticator_async(\n                self._connection,\n                debug=self._debug_trace,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach,\n                loop=self.loop))\n            self._session = self._auth._session\n        elif self._connection.cbs:\n            self._session = self._auth._session\n        else:\n            self._session = self.session_type(\n                self._connection,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach,\n                loop=self.loop)", "response": "Redirect the client endpoint using a Link DETACH redirect details."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ncloses the client asynchronously.", "response": "async def close_async(self):\n        \"\"\"Close the client asynchronously. This includes closing the Session\n        and CBS authentication layer as well as the Connection.\n        If the client was opened using an external Connection,\n        this will be left intact.\n        \"\"\"\n        if self.message_handler:\n            await self.message_handler.destroy_async()\n            self.message_handler = None\n        self._shutdown = True\n        if self._keep_alive_thread:\n            await self._keep_alive_thread\n            self._keep_alive_thread = None\n        if not self._session:\n            return  # already closed.\n        if not self._connection.cbs:\n            _logger.info(\"Closing non-CBS session.\")\n            await asyncio.shield(self._session.destroy_async())\n        else:\n            _logger.info(\"CBS session pending %r.\", self._connection.container_id)\n        self._session = None\n        if not self._ext_connection:\n            _logger.info(\"Closing exclusive connection %r.\", self._connection.container_id)\n            await asyncio.shield(self._connection.destroy_async())\n        else:\n            _logger.info(\"Shared connection remaining open.\")\n        self._connection = None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def mgmt_request_async(self, message, operation, op_type=None, node=None, callback=None, **kwargs):\n        while not await self.auth_complete_async():\n            await asyncio.sleep(0.05)\n        response = await asyncio.shield(self._session.mgmt_request_async(\n            message,\n            operation,\n            op_type=op_type,\n            node=node,\n            callback=callback,\n            encoding=self._encoding,\n            debug=self._debug_trace,\n            **kwargs))\n        return response", "response": "This method is used to send a message to a specific service. This method is used to send a message to a specific service."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreturning True if the client is ready to process messages.", "response": "async def client_ready_async(self):\n        \"\"\"\n        Whether the handler has completed all start up processes such as\n        establishing the connection, session, link and authentication, and\n        is not ready to process messages.\n\n        :rtype: bool\n        \"\"\"\n        if not await self.auth_complete_async():\n            return False\n        if not await self._client_ready_async():\n            await self._connection.work_async()\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def do_work_async(self):\n        if self._shutdown:\n            return False\n        if not await self.client_ready_async():\n            return True\n        return await self._client_run_async()", "response": "Run a single connection iteration asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _client_ready_async(self):\n        # pylint: disable=protected-access\n        if not self.message_handler:\n            self.message_handler = self.sender_type(\n                self._session, self._name, self._remote_address,\n                name='sender-link-{}'.format(uuid.uuid4()),\n                debug=self._debug_trace,\n                send_settle_mode=self._send_settle_mode,\n                max_message_size=self._max_message_size,\n                properties=self._link_properties,\n                error_policy=self._error_policy,\n                encoding=self._encoding,\n                loop=self.loop)\n            await asyncio.shield(self.message_handler.open_async())\n            return False\n        if self.message_handler.get_state() == constants.MessageSenderState.Error:\n            raise errors.MessageHandlerError(\n                \"Message Sender Client is in an error state. \"\n                \"Please confirm credentials and access permissions.\"\n                \"\\nSee debug trace for more details.\")\n        if self.message_handler.get_state() != constants.MessageSenderState.Open:\n            return False\n        return True", "response": "Determine whether the client is ready to send messages."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nperforms all pending messages and send them to the client.", "response": "async def _client_run_async(self):\n        \"\"\"MessageSender Link is now open - perform message send\n        on all pending messages.\n        Will return True if operation successful and client can remain open for\n        further work.\n\n        :rtype: bool\n        \"\"\"\n        # pylint: disable=protected-access\n        self._waiting_messages = 0\n        async with self._pending_messages_lock:\n            self._pending_messages = await self._filter_pending_async()\n        if self._backoff and not self._waiting_messages:\n            _logger.info(\"Client told to backoff - sleeping for %r seconds\", self._backoff)\n            await self._connection.sleep_async(self._backoff)\n            self._backoff = 0\n        await asyncio.shield(self._connection.work_async())\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def redirect_async(self, redirect, auth):\n        if self._ext_connection:\n            raise ValueError(\n                \"Clients with a shared connection cannot be \"\n                \"automatically redirected.\")\n        if self.message_handler:\n            await self.message_handler.destroy_async()\n            self.message_handler = None\n        async with self._pending_messages_lock:\n            self._pending_messages = []\n\n        self._remote_address = address.Target(redirect.address)\n        await self._redirect_async(redirect, auth)", "response": "Redirect the client endpoint using a Link DETACH redirect."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsends a single message or batched message asynchronously.", "response": "async def send_message_async(self, messages, close_on_done=False):\n        \"\"\"Send a single message or batched message asynchronously.\n\n        :param messages: A message to send. This can either be a single instance\n         of ~uamqp.message.Message, or multiple messages wrapped in an instance\n         of ~uamqp.message.BatchMessage.\n        :type message: ~uamqp.message.Message\n        :param close_on_done: Close the client once the message is sent. Default is `False`.\n        :type close_on_done: bool\n        :raises: ~uamqp.errors.MessageException if message fails to send after retry policy\n         is exhausted.\n        \"\"\"\n        batch = messages.gather()\n        pending_batch = []\n        for message in batch:\n            message.idle_time = self._counter.get_current_ms()\n            async with self._pending_messages_lock:\n                self._pending_messages.append(message)\n            pending_batch.append(message)\n        await self.open_async()\n        try:\n            while any([m for m in pending_batch if m.state not in constants.DONE_STATES]):\n                await self.do_work_async()\n            failed = [m for m in pending_batch if m.state == constants.MessageState.SendFailed]\n            if any(failed):\n                details = {\"total_messages\": len(pending_batch), \"number_failed\": len(failed)}\n                details['failed_messages'] = {}\n                exception = None\n                for failed_message in failed:\n                    exception = failed_message._response  # pylint: disable=protected-access\n                    details['failed_messages'][failed_message] = exception\n                raise errors.ClientMessageError(exception, info=details)\n        finally:\n            if close_on_done:\n                await self.close_async()"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\nasync def send_all_messages_async(self, close_on_done=True):\n        await self.open_async()\n        try:\n            async with self._pending_messages_lock:\n                messages = self._pending_messages[:]\n            await self.wait_async()\n            results = [m.state for m in messages]\n            return results\n        finally:\n            if close_on_done:\n                await self.close_async()", "response": "Send all pending messages in the queue asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def _client_ready_async(self):\n        # pylint: disable=protected-access\n        if not self.message_handler:\n            self.message_handler = self.receiver_type(\n                self._session, self._remote_address, self._name,\n                on_message_received=self._message_received,\n                name='receiver-link-{}'.format(uuid.uuid4()),\n                debug=self._debug_trace,\n                receive_settle_mode=self._receive_settle_mode,\n                prefetch=self._prefetch,\n                max_message_size=self._max_message_size,\n                properties=self._link_properties,\n                error_policy=self._error_policy,\n                encoding=self._encoding,\n                loop=self.loop)\n            await asyncio.shield(self.message_handler.open_async())\n            return False\n        if self.message_handler.get_state() == constants.MessageReceiverState.Error:\n            raise errors.MessageHandlerError(\n                \"Message Receiver Client is in an error state. \"\n                \"Please confirm credentials and access permissions.\"\n                \"\\nSee debug trace for more details.\")\n        if self.message_handler.get_state() != constants.MessageReceiverState.Open:\n            self._last_activity_timestamp = self._counter.get_current_ms()\n            return False\n        return True", "response": "Determine whether the client is ready to receive messages."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\nasync def _client_run_async(self):\n        await self._connection.work_async()\n        now = self._counter.get_current_ms()\n        if self._last_activity_timestamp and not self._was_message_received:\n            # If no messages are coming through, back off a little to keep CPU use low.\n            await asyncio.sleep(0.05)\n            if self._timeout > 0:\n                timespan = now - self._last_activity_timestamp\n                if timespan >= self._timeout:\n                    _logger.info(\"Timeout reached, closing receiver.\")\n                    self._shutdown = True\n        else:\n            self._last_activity_timestamp = now\n        self._was_message_received = False\n        return True", "response": "This function is called by the client when the link is now open and the client can be restarted."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\nasync def receive_messages_async(self, on_message_received):\n        await self.open_async()\n        self._message_received_callback = on_message_received\n        receiving = True\n        try:\n            while receiving:\n                receiving = await self.do_work_async()\n        except:\n            receiving = False\n            raise\n        finally:\n            if not receiving:\n                await self.close_async()", "response": "Receive messages asynchronously. This function will run indefinitely,\n        until the client closes either via timeout, error or forced\n        interruption (e.g. keyboard interrupt).\n\n        If the receive client is configured with `auto_complete=True` then the messages that\n        have not been settled on completion of the provided callback will automatically be\n        accepted provided it has not expired. If an error occurs or the message has expired\n        it will be released. Alternatively if `auto_complete=False`, each message will need\n        to be explicitly settled during the callback, otherwise it will be released.\n\n        :param on_message_received: A callback to process messages as they arrive from the\n         service. It takes a single argument, a ~uamqp.message.Message object.\n        :type on_message_received: callable[~uamqp.message.Message]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nreceiving a batch of messages asynchronously. This method will return as soon as some messages are available rather than waiting to achieve a specific batch size, and therefore the number of messages returned per call will vary up to the maximum allowed. If the receive client is configured with `auto_complete=True` then the messages received in the batch returned by this function will already be settled. Alternatively, if `auto_complete=False`, then each message will need to be explicitly settled before it expires and is released. :param max_batch_size: The maximum number of messages that can be returned in one call. This value cannot be larger than the prefetch value, and if not specified, the prefetch value will be used. :type max_batch_size: int :param on_message_received: A callback to process messages as they arrive from the service. It takes a single argument, a ~uamqp.message.Message object. :type on_message_received: callable[~uamqp.message.Message] :param timeout: I timeout in milliseconds for which to wait to receive any messages. If no messages are received in this time, an empty list will be returned. If set to 0, the client will continue to wait until at least one message is received. The default is 0. :type timeout: int", "response": "async def receive_message_batch_async(self, max_batch_size=None, on_message_received=None, timeout=0):\n        \"\"\"Receive a batch of messages asynchronously. This method will return as soon as some\n        messages are available rather than waiting to achieve a specific batch size, and\n        therefore the number of messages returned per call will vary up to the maximum allowed.\n\n        If the receive client is configured with `auto_complete=True` then the messages received\n        in the batch returned by this function will already be settled. Alternatively, if\n        `auto_complete=False`, then each message will need to be explicitly settled before\n        it expires and is released.\n\n        :param max_batch_size: The maximum number of messages that can be returned in\n         one call. This value cannot be larger than the prefetch value, and if not specified,\n         the prefetch value will be used.\n        :type max_batch_size: int\n        :param on_message_received: A callback to process messages as they arrive from the\n         service. It takes a single argument, a ~uamqp.message.Message object.\n        :type on_message_received: callable[~uamqp.message.Message]\n        :param timeout: I timeout in milliseconds for which to wait to receive any messages.\n         If no messages are received in this time, an empty list will be returned. If set to\n         0, the client will continue to wait until at least one message is received. The\n         default is 0.\n        :type timeout: int\n        \"\"\"\n        self._message_received_callback = on_message_received\n        max_batch_size = max_batch_size or self._prefetch\n        if max_batch_size > self._prefetch:\n            raise ValueError(\n                'Maximum batch size {} cannot be greater than the '\n                'connection link credit: {}'.format(max_batch_size, self._prefetch))\n        timeout = self._counter.get_current_ms() + int(timeout) if timeout else 0\n        expired = False\n        self._received_messages = self._received_messages or queue.Queue()\n        await self.open_async()\n        receiving = True\n        batch = []\n        while not self._received_messages.empty() and len(batch) < max_batch_size:\n            batch.append(self._received_messages.get())\n            self._received_messages.task_done()\n        if len(batch) >= max_batch_size:\n            return batch\n\n        while receiving and not expired and len(batch) < max_batch_size:\n            while receiving and self._received_messages.qsize() < max_batch_size:\n                if timeout and self._counter.get_current_ms() > timeout:\n                    expired = True\n                    break\n                before = self._received_messages.qsize()\n                receiving = await self.do_work_async()\n                received = self._received_messages.qsize() - before\n                if self._received_messages.qsize() > 0 and received == 0:\n                    # No new messages arrived, but we have some - so return what we have.\n                    expired = True\n                    break\n\n            while not self._received_messages.empty() and len(batch) < max_batch_size:\n                batch.append(self._received_messages.get())\n                self._received_messages.task_done()\n        return batch"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving messages by asynchronous generator.", "response": "def receive_messages_iter_async(self, on_message_received=None):\n        \"\"\"Receive messages by asynchronous generator. Messages returned in the\n        generator have already been accepted - if you wish to add logic to accept\n        or reject messages based on custom criteria, pass in a callback.\n\n        If the receive client is configured with `auto_complete=True` then the messages received\n        from the iterator returned by this function will be automatically settled when the iterator\n        is incremented. Alternatively, if `auto_complete=False`, then each message will need to\n        be explicitly settled before it expires and is released.\n\n        :param on_message_received: A callback to process messages as they arrive from the\n         service. It takes a single argument, a ~uamqp.message.Message object.\n        :type on_message_received: callable[~uamqp.message.Message]\n        :rtype: Generator[~uamqp.message.Message]\n        \"\"\"\n        self._message_received_callback = on_message_received\n        self._received_messages = queue.Queue()\n        return AsyncMessageIter(self, auto_complete=self.auto_complete)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\nasync def redirect_async(self, redirect, auth):\n        if self._ext_connection:\n            raise ValueError(\n                \"Clients with a shared connection cannot be \"\n                \"automatically redirected.\")\n        if self.message_handler:\n            await self.message_handler.destroy_async()\n            self.message_handler = None\n        self._shutdown = False\n        self._last_activity_timestamp = None\n        self._was_message_received = False\n\n        self._remote_address = address.Source(redirect.address)\n        await self._redirect_async(redirect, auth)", "response": "Redirect the client endpoint using a Link DETACH redirect."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nrun a request/response operation. These are frequently used for management tasks against a $management node, however any node name can be specified and the available options will depend on the target service. :param message: The message to send in the management request. :type message: ~uamqp.message.Message :param operation: The type of operation to be performed. This value will be service-specific, but common values include READ, CREATE and UPDATE. This value will be added as an application property on the message. :type operation: bytes :param op_type: The type on which to carry out the operation. This will be specific to the entities of the service. This value will be added as an application property on the message. :type op_type: bytes :param node: The target node. Default is `b\"$management\"`. :type node: bytes :param timeout: Provide an optional timeout in milliseconds within which a response to the management request must be received. :type timeout: int :param status_code_field: Provide an alternate name for the status code in the response body which can vary between services due to the spec still being in draft. The default is `b\"statusCode\"`. :type status_code_field: bytes :param description_fields: Provide an alternate name for the description in the response body which can vary between services due to the spec still being in draft. The default is `b\"statusDescription\"`. :type description_fields: bytes :param encoding: The encoding to use for parameters supplied as strings. Default is 'UTF-8' :type encoding: str :rtype: ~uamqp.message.Message", "response": "def mgmt_request(self, message, operation, op_type=None, node=b'$management', **kwargs):\n        \"\"\"Run a request/response operation. These are frequently used for management\n        tasks against a $management node, however any node name can be specified\n        and the available options will depend on the target service.\n\n        :param message: The message to send in the management request.\n        :type message: ~uamqp.message.Message\n        :param operation: The type of operation to be performed. This value will\n         be service-specific, but common values include READ, CREATE and UPDATE.\n         This value will be added as an application property on the message.\n        :type operation: bytes\n        :param op_type: The type on which to carry out the operation. This will\n         be specific to the entities of the service. This value will be added as\n         an application property on the message.\n        :type op_type: bytes\n        :param node: The target node. Default is `b\"$management\"`.\n        :type node: bytes\n        :param timeout: Provide an optional timeout in milliseconds within which a response\n         to the management request must be received.\n        :type timeout: int\n        :param status_code_field: Provide an alternate name for the status code in the\n         response body which can vary between services due to the spec still being in draft.\n         The default is `b\"statusCode\"`.\n        :type status_code_field: bytes\n        :param description_fields: Provide an alternate name for the description in the\n         response body which can vary between services due to the spec still being in draft.\n         The default is `b\"statusDescription\"`.\n        :type description_fields: bytes\n        :param encoding: The encoding to use for parameters supplied as strings.\n         Default is 'UTF-8'\n        :type encoding: str\n        :rtype: ~uamqp.message.Message\n        \"\"\"\n        timeout = kwargs.pop('timeout', None) or 0\n        parse_response = kwargs.pop('callback', None)\n        try:\n            mgmt_link = self._mgmt_links[node]\n        except KeyError:\n            mgmt_link = mgmt_operation.MgmtOperation(self, target=node, **kwargs)\n            self._mgmt_links[node] = mgmt_link\n            while not mgmt_link.open and not mgmt_link.mgmt_error:\n                self._connection.work()\n            if mgmt_link.mgmt_error:\n                raise mgmt_link.mgmt_error\n            if mgmt_link.open != constants.MgmtOpenStatus.Ok:\n                raise errors.AMQPConnectionError(\"Failed to open mgmt link: {}\".format(mgmt_link.open))\n        op_type = op_type or b'empty'\n        status, response, description = mgmt_link.execute(operation, op_type, message, timeout=timeout)\n        if parse_response:\n            return parse_response(status, response, description)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef parse_connection_string(connect_str):\n    connect_info = {}\n    fields = connect_str.split(';')\n    for field in fields:\n        key, value = field.split('=', 1)\n        connect_info[key] = value\n    return connect_info", "response": "Parse a connection string such as the Azure portal ID and the Azure portal ID."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef create_sas_token(key_name, shared_access_key, scope, expiry=timedelta(hours=1)):\n    shared_access_key = base64.b64encode(shared_access_key)\n    abs_expiry = int(time.time()) + expiry.seconds\n    return c_uamqp.create_sas_token(shared_access_key, scope, key_name, abs_expiry)", "response": "Create a SAS token."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a Python integer value into equivalent C object.", "response": "def _convert_py_number(value):\n    \"\"\"Convert a Python integer value into equivalent C object.\n    Will attempt to use the smallest possible conversion, starting with int, then long\n    then double.\n    \"\"\"\n    try:\n        return c_uamqp.int_value(value)\n    except OverflowError:\n        pass\n    try:\n        return c_uamqp.long_value(value)\n    except OverflowError:\n        pass\n    return c_uamqp.double_value(value)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap a Python type in the equivalent C AMQP type.", "response": "def data_factory(value, encoding='UTF-8'):\n    \"\"\"Wrap a Python type in the equivalent C AMQP type.\n    If the Python type has already been wrapped in a ~uamqp.types.AMQPType\n    object - then this will be used to select the appropriate C type.\n    - bool => c_uamqp.BoolValue\n    - int => c_uamqp.IntValue, LongValue, DoubleValue\n    - str => c_uamqp.StringValue\n    - bytes => c_uamqp.BinaryValue\n    - list/set/tuple => c_uamqp.ListValue\n    - dict => c_uamqp.DictValue (AMQP map)\n    - float => c_uamqp.DoubleValue\n    - uuid.UUID => c_uamqp.UUIDValue\n\n    :param value: The value to wrap.\n    :type value: ~uamqp.types.AMQPType\n    :rtype: uamqp.c_uamqp.AMQPValue\n    \"\"\"\n    result = None\n    if value is None:\n        result = c_uamqp.null_value()\n    elif hasattr(value, 'c_data'):\n        result = value.c_data\n    elif isinstance(value, c_uamqp.AMQPValue):\n        result = value\n    elif isinstance(value, bool):\n        result = c_uamqp.bool_value(value)\n    elif isinstance(value, six.text_type):\n        result = c_uamqp.string_value(value.encode(encoding))\n    elif isinstance(value, six.binary_type):\n        result = c_uamqp.string_value(value)\n    elif isinstance(value, uuid.UUID):\n        result = c_uamqp.uuid_value(value)\n    elif isinstance(value, bytearray):\n        result = c_uamqp.binary_value(value)\n    elif isinstance(value, six.integer_types):\n        result = _convert_py_number(value)\n    elif isinstance(value, float):\n        result = c_uamqp.double_value(value)\n    elif isinstance(value, dict):\n        wrapped_dict = c_uamqp.dict_value()\n        for key, item in value.items():\n            wrapped_dict[data_factory(key, encoding=encoding)] = data_factory(item, encoding=encoding)\n        result = wrapped_dict\n    elif isinstance(value, (list, set, tuple)):\n        wrapped_list = c_uamqp.list_value()\n        wrapped_list.size = len(value)\n        for index, item in enumerate(value):\n            wrapped_list[index] = data_factory(item, encoding=encoding)\n        result = wrapped_list\n    elif isinstance(value, datetime):\n        timestamp = int((time.mktime(value.utctimetuple()) * 1000) + (value.microsecond/1000))\n        result = c_uamqp.timestamp_value(timestamp)\n    return result"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nperforms a single Connection iteration asynchronously.", "response": "async def work_async(self):\n        \"\"\"Perform a single Connection iteration asynchronously.\"\"\"\n        try:\n            raise self._error\n        except TypeError:\n            pass\n        except Exception as e:\n            _logger.warning(\"%r\", e)\n            raise\n        try:\n            await self.lock_async()\n            if self._closing:\n                _logger.debug(\"Connection unlocked but shutting down.\")\n                return\n            await self.loop.run_in_executor(self._executor, functools.partial(self._conn.do_work))\n        except asyncio.TimeoutError:\n            _logger.debug(\"Connection %r timed out while waiting for lock acquisition.\", self.container_id)\n        finally:\n            self.release_async()"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\nasync def sleep_async(self, seconds):\n        try:\n            await self.lock_async()\n            await asyncio.sleep(seconds)\n        except asyncio.TimeoutError:\n            _logger.debug(\"Connection %r timed out while waiting for lock acquisition.\", self.container_id)\n        finally:\n            self.release_async()", "response": "Lock the connection for a given number of seconds."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nredirecting the connection to an alternative endpoint.", "response": "async def redirect_async(self, redirect_error, auth):\n        \"\"\"Redirect the connection to an alternative endpoint.\n        :param redirect: The Link DETACH redirect details.\n        :type redirect: ~uamqp.errors.LinkRedirect\n        :param auth: Authentication credentials to the redirected endpoint.\n        :type auth: ~uamqp.authentication.common.AMQPAuth\n        \"\"\"\n        _logger.info(\"Redirecting connection %r.\", self.container_id)\n        try:\n            await self.lock_async()\n            if self.hostname == redirect_error.hostname:\n                return\n            if self._state != c_uamqp.ConnectionState.END:\n                await self._close_async()\n            self.hostname = redirect_error.hostname\n            self.auth = auth\n            self._conn = self._create_connection(auth)\n            for setting, value in self._settings.items():\n                setattr(self, setting, value)\n            self._error = None\n            self._closing = False\n        except asyncio.TimeoutError:\n            _logger.debug(\"Connection %r timed out while waiting for lock acquisition.\", self.container_id)\n        finally:\n            self.release_async()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nclose the connection asynchronously and close any associated CBS authentication session.", "response": "async def destroy_async(self):\n        \"\"\"Close the connection asynchronously, and close any associated\n        CBS authentication session.\n        \"\"\"\n        try:\n            await self.lock_async()\n            _logger.debug(\"Unlocked connection %r to close.\", self.container_id)\n            await self._close_async()\n        except asyncio.TimeoutError:\n            _logger.debug(\n                \"Connection %r timed out while waiting for lock acquisition on destroy. Destroying anyway.\",\n                self.container_id)\n            await self._close_async()\n        finally:\n            self.release_async()\n        uamqp._Platform.deinitialize()"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef set_tlsio(self, hostname, port, http_proxy):\n        _default_tlsio = c_uamqp.get_default_tlsio()\n        _tlsio_config = c_uamqp.TLSIOConfig()\n        _tlsio_config.hostname = hostname\n        _tlsio_config.port = int(port)\n        if http_proxy:\n            proxy_config = self._build_proxy_config(hostname, port, http_proxy)\n            _tlsio_config.set_proxy_config(proxy_config)\n        self._underlying_xio = c_uamqp.xio_from_tlsioconfig(_default_tlsio, _tlsio_config)\n\n        cert = self.cert_file or certifi.where()\n        with open(cert, 'rb') as cert_handle:\n            cert_data = cert_handle.read()\n            try:\n                self._underlying_xio.set_certificates(cert_data)\n            except ValueError:\n                _logger.warning('Unable to set external certificates.')\n        self.sasl_client = _SASLClient(self._underlying_xio, self.sasl)\n        self.consumed = False", "response": "Setup the default TLS IO layer."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef close(self):\n        self.sasl.mechanism.destroy()\n        self.sasl_client.get_client().destroy()\n        self._underlying_xio.destroy()", "response": "Close the authentication layer and cleanup all the authentication wrapper objects."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ndecodes an AMQP message from a bytearray.", "response": "def decode_from_bytes(cls, data):\n        \"\"\"Decode an AMQP message from a bytearray.\n        The returned message will not have a delivery context and\n        therefore will be considered to be in an \"already settled\" state.\n\n        :param data: The AMQP wire-encoded bytes to decode.\n        :type data: bytes or bytearray\n        \"\"\"\n        decoded_message = c_uamqp.decode_message(len(data), data)\n        return cls(message=decoded_message)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nparsing a received message from an AMQP service.", "response": "def _parse_message(self, message):\n        \"\"\"Parse a message received from an AMQP service.\n\n        :param message: The received C message.\n        :type message: uamqp.c_uamqp.cMessage\n        \"\"\"\n        _logger.debug(\"Parsing received message %r.\", self.delivery_no)\n        self._message = message\n        body_type = message.body_type\n        if body_type == c_uamqp.MessageBodyType.NoneType:\n            self._body = None\n        elif body_type == c_uamqp.MessageBodyType.DataType:\n            self._body = DataBody(self._message)\n        elif body_type == c_uamqp.MessageBodyType.SequenceType:\n            raise TypeError(\"Message body type Sequence not supported.\")\n        else:\n            self._body = ValueBody(self._message)\n        _props = self._message.properties\n        if _props:\n            _logger.debug(\"Parsing received message properties %r.\", self.delivery_no)\n            self.properties = MessageProperties(properties=_props, encoding=self._encoding)\n        _header = self._message.header\n        if _header:\n            _logger.debug(\"Parsing received message header %r.\", self.delivery_no)\n            self.header = MessageHeader(header=_header)\n        _footer = self._message.footer\n        if _footer:\n            _logger.debug(\"Parsing received message footer %r.\", self.delivery_no)\n            self.footer = _footer.map\n        _app_props = self._message.application_properties\n        if _app_props:\n            _logger.debug(\"Parsing received message application properties %r.\", self.delivery_no)\n            self.application_properties = _app_props.map\n        _ann = self._message.message_annotations\n        if _ann:\n            _logger.debug(\"Parsing received message annotations %r.\", self.delivery_no)\n            self.annotations = _ann.map\n        _delivery_ann = self._message.delivery_annotations\n        if _delivery_ann:\n            _logger.debug(\"Parsing received message delivery annotations %r.\", self.delivery_no)\n            self.delivery_annotations = _delivery_ann.map"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets the size of the message encoded by this instance.", "response": "def get_message_encoded_size(self):\n        \"\"\"Pre-emptively get the size of the message once it has been encoded\n        to go over the wire so we can raise an error if the message will be\n        rejected for being to large.\n\n        This method is not available for messages that have been received.\n\n        :rtype: int\n        \"\"\"\n        if not self._message:\n            raise ValueError(\"No message data to encode.\")\n        cloned_data = self._message.clone()\n        self._populate_message_attributes(cloned_data)\n        encoded_data = []\n        return c_uamqp.get_encoded_message_size(cloned_data, encoded_data)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef encode_message(self):\n        if not self._message:\n            raise ValueError(\"No message data to encode.\")\n        cloned_data = self._message.clone()\n        self._populate_message_attributes(cloned_data)\n        encoded_data = []\n        c_uamqp.get_encoded_message_size(cloned_data, encoded_data)\n        return b\"\".join(encoded_data)", "response": "Encode the message to AMQP wire - encoded bytearray."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all the messages represented by this object.", "response": "def gather(self):\n        \"\"\"Return all the messages represented by this object.\n        This will always be a list of a single message.\n\n        :rtype: list[~uamqp.message.Message]\n        \"\"\"\n        if self.state in constants.RECEIVE_STATES:\n            raise TypeError(\"Only new messages can be gathered.\")\n        if not self._message:\n            raise ValueError(\"Message data already consumed.\")\n        try:\n            raise self._response\n        except TypeError:\n            pass\n        return [self]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting the underlying C message from this object.", "response": "def get_message(self):\n        \"\"\"Get the underlying C message from this object.\n\n        :rtype: uamqp.c_uamqp.cMessage\n        \"\"\"\n        if not self._message:\n            return None\n        self._populate_message_attributes(self._message)\n        return self._message"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef accept(self):\n        if self._can_settle_message():\n            self._response = errors.MessageAccepted()\n            self._settler(self._response)\n            self.state = constants.MessageState.ReceivedSettled\n            return True\n        return False", "response": "Send a response disposition to the service to indicate that the received message has been accepted. Returns True if the message was accepted False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsends a response disposition to the service to indicate that the received message has been rejected.", "response": "def reject(self, condition=None, description=None):\n        \"\"\"Send a response disposition to the service to indicate that\n        a received message has been rejected. If the client is running in PeekLock\n        mode, the service will wait on this disposition. Otherwise it will\n        be ignored. A rejected message will increment the messages delivery count.\n        Returns `True` is message was rejected, or `False` if the message\n        was already settled.\n\n        :param condition: The AMQP rejection code. By default this is `amqp:internal-error`.\n        :type condition: bytes or str\n        :param description: A description/reason to accompany the rejection.\n        :type description: bytes or str\n        :rtype: bool\n        :raises: TypeError if the message is being sent rather than received.\n        \"\"\"\n        if self._can_settle_message():\n            self._response = errors.MessageRejected(\n                condition=condition,\n                description=description,\n                encoding=self._encoding)\n            self._settler(self._response)\n            self.state = constants.MessageState.ReceivedSettled\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nsend a response disposition to the service to indicate that the received message has been released. Returns True if the message was released False otherwise.", "response": "def release(self):\n        \"\"\"Send a response disposition to the service to indicate that\n        a received message has been released. If the client is running in PeekLock\n        mode, the service will wait on this disposition. Otherwise it will\n        be ignored. A released message will not incremenet the messages\n        delivery count. Returns `True` is message was released, or `False` if the message\n        was already settled.\n\n        :rtype: bool\n        :raises: TypeError if the message is being sent rather than received.\n        \"\"\"\n        if self._can_settle_message():\n            self._response = errors.MessageReleased()\n            self._settler(self._response)\n            self.state = constants.MessageState.ReceivedSettled\n            return True\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef modify(self, failed, deliverable, annotations=None):\n        if self._can_settle_message():\n            self._response = errors.MessageModified(\n                failed,\n                deliverable,\n                annotations=annotations,\n                encoding=self._encoding)\n            self._settler(self._response)\n            self.state = constants.MessageState.ReceivedSettled\n            return True\n        return False", "response": "Send a response disposition to the service to indicate that the received message has been modified."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _create_batch_message(self):\n        return Message(body=[],\n                       properties=self.properties,\n                       annotations=self.annotations,\n                       msg_format=self.batch_format,\n                       header=self.header,\n                       encoding=self._encoding)", "response": "Create a batch message for a value supplied by the data\n        generator."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngenerates multiple ~uamqp. message. Message objects from a single data stream that in total may exceed the maximum individual message size.", "response": "def _multi_message_generator(self):\n        \"\"\"Generate multiple ~uamqp.message.Message objects from a single data\n        stream that in total may exceed the maximum individual message size.\n        Data will be continuously added to a single message until that message\n        reaches a max allowable size, at which point it will be yielded and\n        a new message will be started.\n\n        :rtype: generator[~uamqp.message.Message]\n        \"\"\"\n        unappended_message_bytes = None\n        while True:\n            new_message = self._create_batch_message()\n            message_size = new_message.get_message_encoded_size() + self.size_offset\n            body_size = 0\n            if unappended_message_bytes:\n                new_message._body.append(unappended_message_bytes)  # pylint: disable=protected-access\n                body_size += len(unappended_message_bytes)\n            try:\n                for data in self._body_gen:\n                    message_bytes = None\n                    try:\n                        if not data.application_properties:  # Message-like object\n                            data.application_properties = self.application_properties\n                        message_bytes = data.encode_message()\n                    except AttributeError:  # raw data\n                        wrap_message = Message(body=data, application_properties=self.application_properties)\n                        message_bytes = wrap_message.encode_message()\n                    body_size += len(message_bytes)\n                    if (body_size + message_size) > self.max_message_length:\n                        new_message.on_send_complete = self.on_send_complete\n                        unappended_message_bytes = message_bytes\n                        yield new_message\n                        raise StopIteration()\n                    new_message._body.append(message_bytes)  # pylint: disable=protected-access\n            except StopIteration:\n                _logger.debug(\"Sent partial message.\")\n                continue\n            else:\n                new_message.on_send_complete = self.on_send_complete\n                yield new_message\n                _logger.debug(\"Sent all batched data.\")\n                break"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn all the messages represented by this object.", "response": "def gather(self):\n        \"\"\"Return all the messages represented by this object. This will convert\n        the batch data into individual Message objects, which may be one\n        or more if multi_messages is set to `True`.\n\n        :rtype: list[~uamqp.message.Message]\n        \"\"\"\n        if self._multi_messages:\n            return self._multi_message_generator()\n\n        new_message = self._create_batch_message()\n        message_size = new_message.get_message_encoded_size() + self.size_offset\n        body_size = 0\n\n        for data in self._body_gen:\n            message_bytes = None\n            try:\n                if not data.application_properties:  # Message-like object\n                    data.application_properties = self.application_properties\n                message_bytes = data.encode_message()\n            except AttributeError:  # raw data\n                wrap_message = Message(body=data, application_properties=self.application_properties)\n                message_bytes = wrap_message.encode_message()\n            body_size += len(message_bytes)\n            if (body_size + message_size) > self.max_message_length:\n                raise ValueError(\n                    \"Data set too large for a single message.\"\n                    \"Set multi_messages to True to split data across multiple messages.\")\n            new_message._body.append(message_bytes)  # pylint: disable=protected-access\n        new_message.on_send_complete = self.on_send_complete\n        return [new_message]"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_properties_obj(self):\n        properties = c_uamqp.cProperties()\n        self._set_attr('message_id', properties)\n        self._set_attr('user_id', properties)\n        self._set_attr('to', properties)\n        self._set_attr('subject', properties)\n        self._set_attr('reply_to', properties)\n        self._set_attr('correlation_id', properties)\n        self._set_attr('content_type', properties)\n        self._set_attr('content_encoding', properties)\n        self._set_attr('absolute_expiry_time', properties)\n        self._set_attr('creation_time', properties)\n        self._set_attr('group_id', properties)\n        self._set_attr('group_sequence', properties)\n        self._set_attr('reply_to_group_id', properties)\n        return properties", "response": "Get the underlying C reference from this object."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef append(self, data):\n        if isinstance(data, six.text_type):\n            self._message.add_body_data(data.encode(self._encoding))\n        elif isinstance(data, six.binary_type):\n            self._message.add_body_data(data)", "response": "Append a section to the body."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set(self, value):\n        value = utils.data_factory(value)\n        self._message.set_body_value(value)", "response": "Set a value as the message body."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the underlying C reference from this object.", "response": "def get_header_obj(self):\n        \"\"\"Get the underlying C reference from this object.\n\n        :rtype: uamqp.c_uamqp.cHeader\n        \"\"\"\n        header = c_uamqp.create_header()\n        if self.delivery_count is not None:\n            header.delivery_count = self.delivery_count\n        if self.time_to_live is not None:\n            header.time_to_live = self.time_to_live\n        if self.first_acquirer is not None:\n            header.first_acquirer = self.first_acquirer\n        if self.durable is not None:\n            header.durable = self.durable\n        if self.priority is not None:\n            header.priority = self.priority\n        return header"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ncreate the AMQP session and the CBS channel with which the token is negotiated.", "response": "def create_authenticator(self, connection, debug=False, **kwargs):\n        \"\"\"Create the AMQP session and the CBS channel with which\n        to negotiate the token.\n\n        :param connection: The underlying AMQP connection on which\n         to create the session.\n        :type connection: ~uamqp.connection.Connection\n        :param debug: Whether to emit network trace logging events for the\n         CBS session. Default is `False`. Logging events are set at INFO level.\n        :type debug: bool\n        :rtype: uamqp.c_uamqp.CBSTokenAuth\n        \"\"\"\n        self._connection = connection\n        self._session = Session(connection, **kwargs)\n        try:\n            self._cbs_auth = c_uamqp.CBSTokenAuth(\n                self.audience,\n                self.token_type,\n                self.token,\n                int(self.expires_at),\n                self._session._session,  # pylint: disable=protected-access\n                self.timeout,\n                self._connection.container_id)\n            self._cbs_auth.set_trace(debug)\n        except ValueError:\n            self._session.destroy()\n            raise errors.AMQPConnectionError(\n                \"Unable to open authentication session on connection {}.\\n\"\n                \"Please confirm target hostname exists: {}\".format(connection.container_id, connection.hostname))\n        return self._cbs_auth"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef close_authenticator(self):\n        _logger.info(\"Shutting down CBS session on connection: %r.\", self._connection.container_id)\n        try:\n            _logger.debug(\"Unlocked CBS to close on connection: %r.\", self._connection.container_id)\n            self._cbs_auth.destroy()\n            _logger.info(\"Auth closed, destroying session on connection: %r.\", self._connection.container_id)\n            self._session.destroy()\n        finally:\n            _logger.info(\"Finished shutting down CBS session on connection: %r.\", self._connection.container_id)", "response": "Close the CBS auth channel and session."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef update_token(self):\n        if not self.username or not self.password:\n            raise errors.TokenExpired(\"Unable to refresh token - no username or password.\")\n        encoded_uri = compat.quote_plus(self.uri).encode(self._encoding)  # pylint: disable=no-member\n        encoded_key = compat.quote_plus(self.username).encode(self._encoding)  # pylint: disable=no-member\n        self.expires_at = time.time() + self.expires_in.seconds\n        self.token = utils.create_sas_token(\n            encoded_key,\n            self.password.encode(self._encoding),\n            encoded_uri,\n            self.expires_in)", "response": "Update the SAS token for the current user."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate a new CBS token session using a Shared Access Key.", "response": "def from_shared_access_key(\n            cls,\n            uri,\n            key_name,\n            shared_access_key,\n            expiry=None,\n            port=constants.DEFAULT_AMQPS_PORT,\n            timeout=10,\n            retry_policy=TokenRetryPolicy(),\n            verify=None,\n            http_proxy=None,\n            encoding='UTF-8'):\n        \"\"\"Attempt to create a CBS token session using a Shared Access Key such\n        as is used to connect to Azure services.\n\n        :param uri: The AMQP endpoint URI. This must be provided as\n         a decoded string.\n        :type uri: str\n        :param key_name: The SAS token username, also referred to as the key\n         name or policy name.\n        :type key_name: str\n        :param shared_access_key: The SAS token password, also referred to as the key.\n        :type shared_access_key: str\n        :param expiry: The lifetime in seconds for the generated token. Default is 1 hour.\n        :type expiry: int\n        :param port: The TLS port - default for AMQP is 5671.\n        :type port: int\n        :param timeout: The timeout in seconds in which to negotiate the token.\n         The default value is 10 seconds.\n        :type timeout: int\n        :param retry_policy: The retry policy for the PUT token request. The default\n         retry policy has 3 retries.\n        :type retry_policy: ~uamqp.authentication.cbs_auth.TokenRetryPolicy\n        :param verify: The path to a user-defined certificate.\n        :type verify: str\n        :param http_proxy: HTTP proxy configuration. This should be a dictionary with\n         the following keys present: 'proxy_hostname' and 'proxy_port'. Additional optional\n         keys are 'username' and 'password'.\n        :type http_proxy: dict\n        :param encoding: The encoding to use if hostname is provided as a str.\n         Default is 'UTF-8'.\n        :type encoding: str\n        \"\"\"\n        expires_in = datetime.timedelta(seconds=expiry or constants.AUTH_EXPIRATION_SECS)\n        encoded_uri = compat.quote_plus(uri).encode(encoding)  # pylint: disable=no-member\n        encoded_key = compat.quote_plus(key_name).encode(encoding)  # pylint: disable=no-member\n        expires_at = time.time() + expires_in.seconds\n        token = utils.create_sas_token(\n            encoded_key,\n            shared_access_key.encode(encoding),\n            encoded_uri,\n            expires_in)\n        return cls(\n            uri, uri, token,\n            expires_in=expires_in,\n            expires_at=expires_at,\n            username=key_name,\n            password=shared_access_key,\n            port=port,\n            timeout=timeout,\n            retry_policy=retry_policy,\n            verify=verify,\n            http_proxy=http_proxy,\n            encoding=encoding)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _settle_message(self, message_number, response):\n        if not response or isinstance(response, errors.MessageAlreadySettled):\n            return\n        if isinstance(response, errors.MessageAccepted):\n            self._receiver.settle_accepted_message(message_number)\n        elif isinstance(response, errors.MessageReleased):\n            self._receiver.settle_released_message(message_number)\n        elif isinstance(response, errors.MessageRejected):\n            self._receiver.settle_rejected_message(\n                message_number,\n                response.error_condition,\n                response.error_description)\n        elif isinstance(response, errors.MessageModified):\n            self._receiver.settle_modified_message(\n                message_number,\n                response.failed,\n                response.undeliverable,\n                response.annotations)\n        else:\n            raise ValueError(\"Invalid message response type: {}\".format(response))", "response": "Send a settle dispostition for a received message."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a single message to the internal pending queue.", "response": "async def send_async(self, message, callback, timeout=0):\n        \"\"\"Add a single message to the internal pending queue to be processed\n        by the Connection without waiting for it to be sent.\n\n        :param message: The message to send.\n        :type message: ~uamqp.message.Message\n        :param callback: The callback to be run once a disposition is received\n         in receipt of the message. The callback must take three arguments, the message,\n         the send result and the optional delivery condition (exception).\n        :type callback:\n         callable[~uamqp.message.Message, ~uamqp.constants.MessageSendResult, ~uamqp.errors.MessageException]\n        :param timeout: An expiry time for the message added to the queue. If the\n         message is not sent within this timeout it will be discarded with an error\n         state. If set to 0, the message will not expire. The default is 0.\n        \"\"\"\n        # pylint: disable=protected-access\n        try:\n            raise self._error\n        except TypeError:\n            pass\n        except Exception as e:\n            _logger.warning(\"%r\", e)\n            raise\n        c_message = message.get_message()\n        message._on_message_sent = callback\n        try:\n            await self._session._connection.lock_async(timeout=None)\n            return self._sender.send(c_message, timeout, message)\n        finally:\n            self._session._connection.release_async()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _redirect(self, redirect, auth):\n        # pylint: disable=protected-access\n        if not self._connection.cbs:\n            _logger.debug(\"Closing non-CBS session.\")\n            self._session.destroy()\n        self._session = None\n        self._auth = auth\n        self._hostname = self._remote_address.hostname\n        self._connection.redirect(redirect, auth)\n        if not self._connection.cbs and isinstance(self._auth, authentication.CBSAuthMixin):\n            self._connection.cbs = self._auth.create_authenticator(\n                self._connection,\n                debug=self._debug_trace,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach)\n            self._session = self._auth._session\n        elif self._connection.cbs:\n            self._session = self._auth._session\n        else:\n            self._session = self.session_type(\n                self._connection,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach)", "response": "Redirect the client endpoint using a Link DETACH redirect details."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef open(self, connection=None):\n        # pylint: disable=protected-access\n        if self._session:\n            return  # already open.\n        _logger.debug(\"Opening client connection.\")\n        if connection:\n            _logger.debug(\"Using existing connection.\")\n            self._auth = connection.auth\n            self._ext_connection = True\n        self._connection = connection or self.connection_type(\n            self._hostname,\n            self._auth,\n            container_id=self._name,\n            max_frame_size=self._max_frame_size,\n            channel_max=self._channel_max,\n            idle_timeout=self._idle_timeout,\n            properties=self._properties,\n            remote_idle_timeout_empty_frame_send_ratio=self._remote_idle_timeout_empty_frame_send_ratio,\n            error_policy=self._error_policy,\n            debug=self._debug_trace,\n            encoding=self._encoding)\n        if not self._connection.cbs and isinstance(self._auth, authentication.CBSAuthMixin):\n            self._connection.cbs = self._auth.create_authenticator(\n                self._connection,\n                debug=self._debug_trace,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach)\n            self._session = self._auth._session\n        elif self._connection.cbs:\n            self._session = self._auth._session\n        else:\n            self._session = self.session_type(\n                self._connection,\n                incoming_window=self._incoming_window,\n                outgoing_window=self._outgoing_window,\n                handle_max=self._handle_max,\n                on_attach=self._on_attach)\n        if self._keep_alive_interval:\n            self._keep_alive_thread = threading.Thread(target=self._keep_alive)\n            self._keep_alive_thread.start()", "response": "Open the client. The client can create a new Connection\n        or an existing Connection can be passed in. This existing Connection\n        may have an existing CBS authentication Session, which will be\n        used for this client as well. Otherwise a new Session will be\n        created.\n\n        :param connection: An existing Connection that may be shared between\n         multiple clients.\n        :type connetion: ~uamqp.connection.Connection"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef close(self):\n        if self.message_handler:\n            self.message_handler.destroy()\n            self.message_handler = None\n        self._shutdown = True\n        if self._keep_alive_thread:\n            self._keep_alive_thread.join()\n            self._keep_alive_thread = None\n        if not self._session:\n            return  # already closed.\n        if not self._connection.cbs:\n            _logger.debug(\"Closing non-CBS session.\")\n            self._session.destroy()\n        else:\n            _logger.debug(\"CBS session pending.\")\n        self._session = None\n        if not self._ext_connection:\n            _logger.debug(\"Closing exclusive connection.\")\n            self._connection.destroy()\n        else:\n            _logger.debug(\"Shared connection remaining open.\")\n        self._connection = None", "response": "Close the client. This includes closing the Session\n        and CBS authentication layer as well as the Connection.\n        If the client was opened using an external Connection,\n        this will be left intact.\n\n        No further messages can be sent or received and the client\n        cannot be re-opened.\n\n        All pending, unsent messages will remain uncleared to allow\n        them to be inspected and queued to a new client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nrun a request/response operation. These are frequently used for management tasks against a $management node, however any node name can be specified and the available options will depend on the target service. :param message: The message to send in the management request. :type message: ~uamqp.message.Message :param operation: The type of operation to be performed. This value will be service-specific, but common values include READ, CREATE and UPDATE. This value will be added as an application property on the message. :type operation: bytes :param op_type: The type on which to carry out the operation. This will be specific to the entities of the service. This value will be added as an application property on the message. :type op_type: bytes :param node: The target node. Default is `b\"$management\"`. :type node: bytes :param timeout: Provide an optional timeout in milliseconds within which a response to the management request must be received. :type timeout: int :param callback: The function to process the returned parameters of the management request including status code and a description if available. This can be used to reformat the response or raise an error based on content. The function must take 3 arguments - status code, response message and description. :type callback: ~callable[int, bytes, ~uamqp.message.Message] :param status_code_field: Provide an alternate name for the status code in the response body which can vary between services due to the spec still being in draft. The default is `b\"statusCode\"`. :type status_code_field: bytes :param description_fields: Provide an alternate name for the description in the response body which can vary between services due to the spec still being in draft. The default is `b\"statusDescription\"`. :type description_fields: bytes :rtype: ~uamqp.message.Message", "response": "def mgmt_request(self, message, operation, op_type=None, node=None, callback=None, **kwargs):\n        \"\"\"Run a request/response operation. These are frequently used for management\n        tasks against a $management node, however any node name can be specified\n        and the available options will depend on the target service.\n\n        :param message: The message to send in the management request.\n        :type message: ~uamqp.message.Message\n        :param operation: The type of operation to be performed. This value will\n         be service-specific, but common values include READ, CREATE and UPDATE.\n         This value will be added as an application property on the message.\n        :type operation: bytes\n        :param op_type: The type on which to carry out the operation. This will\n         be specific to the entities of the service. This value will be added as\n         an application property on the message.\n        :type op_type: bytes\n        :param node: The target node. Default is `b\"$management\"`.\n        :type node: bytes\n        :param timeout: Provide an optional timeout in milliseconds within which a response\n         to the management request must be received.\n        :type timeout: int\n        :param callback: The function to process the returned parameters of the management\n         request including status code and a description if available. This can be used\n         to reformat the response or raise an error based on content. The function must\n         take 3 arguments - status code, response message and description.\n        :type callback: ~callable[int, bytes, ~uamqp.message.Message]\n        :param status_code_field: Provide an alternate name for the status code in the\n         response body which can vary between services due to the spec still being in draft.\n         The default is `b\"statusCode\"`.\n        :type status_code_field: bytes\n        :param description_fields: Provide an alternate name for the description in the\n         response body which can vary between services due to the spec still being in draft.\n         The default is `b\"statusDescription\"`.\n        :type description_fields: bytes\n        :rtype: ~uamqp.message.Message\n        \"\"\"\n        while not self.auth_complete():\n            time.sleep(0.05)\n        response = self._session.mgmt_request(\n            message,\n            operation,\n            op_type=op_type,\n            node=node,\n            callback=callback,\n            encoding=self._encoding,\n            debug=self._debug_trace,\n            **kwargs)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef auth_complete(self):\n        timeout = False\n        auth_in_progress = False\n        if self._connection.cbs:\n            timeout, auth_in_progress = self._auth.handle_token()\n            if timeout is None and auth_in_progress is None:\n                _logger.debug(\"No work done.\")\n                return False\n        if timeout:\n            raise compat.TimeoutException(\"Authorization timeout.\")\n        if auth_in_progress:\n            self._connection.work()\n            return False\n        return True", "response": "Whether the authentication handshake is complete during the connection initialization."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef client_ready(self):\n        if not self.auth_complete():\n            return False\n        if not self._client_ready():\n            self._connection.work()\n            return False\n        return True", "response": "Returns True if the client is ready to process messages."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef do_work(self):\n        if self._shutdown:\n            return False\n        if not self.client_ready():\n            return True\n        return self._client_run()", "response": "Run a single connection iteration."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreturn True if the client is ready to send messages.", "response": "def _client_ready(self):\n        \"\"\"Determine whether the client is ready to start sending messages.\n        To be ready, the connection must be open and authentication complete,\n        The Session, Link and MessageSender must be open and in non-errored\n        states.\n\n        :rtype: bool\n        :raises: ~uamqp.errors.MessageHandlerError if the MessageSender\n         goes into an error state.\n        \"\"\"\n        # pylint: disable=protected-access\n        if not self.message_handler:\n            self.message_handler = self.sender_type(\n                self._session, self._name, self._remote_address,\n                name='sender-link-{}'.format(uuid.uuid4()),\n                debug=self._debug_trace,\n                send_settle_mode=self._send_settle_mode,\n                max_message_size=self._max_message_size,\n                link_credit=self._link_credit,\n                properties=self._link_properties,\n                error_policy=self._error_policy,\n                encoding=self._encoding)\n            self.message_handler.open()\n            return False\n        if self.message_handler.get_state() == constants.MessageSenderState.Error:\n            raise errors.MessageHandlerError(\n                \"Message Sender Client is in an error state. \"\n                \"Please confirm credentials and access permissions.\"\n                \"\\nSee debug trace for more details.\")\n        if self.message_handler.get_state() != constants.MessageSenderState.Open:\n            return False\n        return True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _client_run(self):\n        # pylint: disable=protected-access\n        self._waiting_messages = 0\n        self._pending_messages = self._filter_pending()\n        if self._backoff and not self._waiting_messages:\n            _logger.info(\"Client told to backoff - sleeping for %r seconds\", self._backoff)\n            self._connection.sleep(self._backoff)\n            self._backoff = 0\n        self._connection.work()\n        return True", "response": "Perform all pending messages and send them to the client."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nredirect the client endpoint using a Link DETACH redirect.", "response": "def redirect(self, redirect, auth):\n        \"\"\"Redirect the client endpoint using a Link DETACH redirect\n        response.\n\n        :param redirect: The Link DETACH redirect details.\n        :type redirect: ~uamqp.errors.LinkRedirect\n        :param auth: Authentication credentials to the redirected endpoint.\n        :type auth: ~uamqp.authentication.common.AMQPAuth\n        \"\"\"\n        if self._ext_connection:\n            raise ValueError(\n                \"Clients with a shared connection cannot be \"\n                \"automatically redirected.\")\n        if self.message_handler:\n            self.message_handler.destroy()\n            self.message_handler = None\n        self._pending_messages = []\n        self._remote_address = address.Target(redirect.address)\n        self._redirect(redirect, auth)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd one or more messages to the send queue.", "response": "def queue_message(self, *messages):\n        \"\"\"Add one or more messages to the send queue.\n        No further action will be taken until either `SendClient.wait()`\n        or `SendClient.send_all_messages()` has been called.\n        The client does not need to be open yet for messages to be added\n        to the queue. Multiple messages can be queued at once:\n            - `send_client.queue_message(my_message)`\n            - `send_client.queue_message(message_1, message_2, message_3)`\n            - `send_client.queue_message(*my_message_list)`\n\n        :param messages: A message to send. This can either be a single instance\n         of `Message`, or multiple messages wrapped in an instance of `BatchMessage`.\n        :type message: ~uamqp.message.Message\n        \"\"\"\n        for message in messages:\n            for internal_message in message.gather():\n                internal_message.idle_time = self._counter.get_current_ms()\n                internal_message.state = constants.MessageState.WaitingToBeSent\n                self._pending_messages.append(internal_message)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef send_message(self, messages, close_on_done=False):\n        batch = messages.gather()\n        pending_batch = []\n        for message in batch:\n            message.idle_time = self._counter.get_current_ms()\n            self._pending_messages.append(message)\n            pending_batch.append(message)\n        self.open()\n        running = True\n        try:\n            while running and any([m for m in pending_batch if m.state not in constants.DONE_STATES]):\n                running = self.do_work()\n            failed = [m for m in pending_batch if m.state == constants.MessageState.SendFailed]\n            if any(failed):\n                details = {\"total_messages\": len(pending_batch), \"number_failed\": len(failed)}\n                details['failed_messages'] = {}\n                exception = None\n                for failed_message in failed:\n                    exception = failed_message._response  # pylint: disable=protected-access\n                    details['failed_messages'][failed_message] = exception\n                raise errors.ClientMessageError(exception, info=details)\n        finally:\n            if close_on_done or not running:\n                self.close()", "response": "Send a single message or a batched message."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nsending all pending messages in the queue.", "response": "def send_all_messages(self, close_on_done=True):\n        \"\"\"Send all pending messages in the queue. This will return a list\n        of the send result of all the pending messages so it can be\n        determined if any messages failed to send.\n        This function will open the client if it is not already open.\n\n        :param close_on_done: Close the client once the messages are sent.\n         Default is `True`.\n        :type close_on_done: bool\n        :rtype: list[~uamqp.constants.MessageState]\n        \"\"\"\n        self.open()\n        running = True\n        try:\n            messages = self._pending_messages[:]\n            running = self.wait()\n            results = [m.state for m in messages]\n            return results\n        finally:\n            if close_on_done or not running:\n                self.close()"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\niterates over processed messages in the receive queue.", "response": "def _message_generator(self):\n        \"\"\"Iterate over processed messages in the receive queue.\n\n        :rtype: generator[~uamqp.message.Message]\n        \"\"\"\n        self.open()\n        auto_complete = self.auto_complete\n        self.auto_complete = False\n        receiving = True\n        message = None\n        try:\n            while receiving:\n                while receiving and self._received_messages.empty():\n                    receiving = self.do_work()\n                while not self._received_messages.empty():\n                    message = self._received_messages.get()\n                    self._received_messages.task_done()\n                    yield message\n                    self._complete_message(message, auto_complete)\n        finally:\n            self._complete_message(message, auto_complete)\n            self.auto_complete = auto_complete\n            self.close()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving a batch of messages from the broker.", "response": "def receive_message_batch(self, max_batch_size=None, on_message_received=None, timeout=0):\n        \"\"\"Receive a batch of messages. Messages returned in the batch have already been\n        accepted - if you wish to add logic to accept or reject messages based on custom\n        criteria, pass in a callback. This method will return as soon as some messages are\n        available rather than waiting to achieve a specific batch size, and therefore the\n        number of messages returned per call will vary up to the maximum allowed.\n\n        If the receive client is configured with `auto_complete=True` then the messages received\n        in the batch returned by this function will already be settled. Alternatively, if\n        `auto_complete=False`, then each message will need to be explicitly settled before\n        it expires and is released.\n\n        :param max_batch_size: The maximum number of messages that can be returned in\n         one call. This value cannot be larger than the prefetch value, and if not specified,\n         the prefetch value will be used.\n        :type max_batch_size: int\n        :param on_message_received: A callback to process messages as they arrive from the\n         service. It takes a single argument, a ~uamqp.message.Message object.\n        :type on_message_received: callable[~uamqp.message.Message]\n        :param timeout: I timeout in milliseconds for which to wait to receive any messages.\n         If no messages are received in this time, an empty list will be returned. If set to\n         0, the client will continue to wait until at least one message is received. The\n         default is 0.\n        :type timeout: int\n        \"\"\"\n        self._message_received_callback = on_message_received\n        max_batch_size = max_batch_size or self._prefetch\n        if max_batch_size > self._prefetch:\n            raise ValueError(\n                'Maximum batch size cannot be greater than the '\n                'connection link credit: {}'.format(self._prefetch))\n        timeout = self._counter.get_current_ms() + timeout if timeout else 0\n        expired = False\n        self._received_messages = self._received_messages or compat.queue.Queue()\n        self.open()\n        receiving = True\n        batch = []\n        while not self._received_messages.empty() and len(batch) < max_batch_size:\n            batch.append(self._received_messages.get())\n            self._received_messages.task_done()\n        if len(batch) >= max_batch_size:\n            return batch\n\n        while receiving and not expired and len(batch) < max_batch_size:\n            while receiving and self._received_messages.qsize() < max_batch_size:\n                if timeout and self._counter.get_current_ms() > timeout:\n                    expired = True\n                    break\n                before = self._received_messages.qsize()\n                receiving = self.do_work()\n                received = self._received_messages.qsize() - before\n                if self._received_messages.qsize() > 0 and received == 0:\n                    # No new messages arrived, but we have some - so return what we have.\n                    expired = True\n                    break\n            while not self._received_messages.empty() and len(batch) < max_batch_size:\n                batch.append(self._received_messages.get())\n                self._received_messages.task_done()\n        return batch"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef receive_messages(self, on_message_received):\n        self.open()\n        self._received_messages = None\n        self._message_received_callback = on_message_received\n        receiving = True\n        try:\n            while receiving:\n                receiving = self.do_work()\n        except:\n            receiving = False\n            raise\n        finally:\n            if not receiving:\n                self.close()", "response": "This function will be called by the client to process messages that arrive from the broker."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nredirecting the client endpoint using a Link DETACH redirect.", "response": "def redirect(self, redirect, auth):\n        \"\"\"Redirect the client endpoint using a Link DETACH redirect\n        response.\n\n        :param redirect: The Link DETACH redirect details.\n        :type redirect: ~uamqp.errors.LinkRedirect\n        :param auth: Authentication credentials to the redirected endpoint.\n        :type auth: ~uamqp.authentication.common.AMQPAuth\n        \"\"\"\n        if self._ext_connection:\n            raise ValueError(\n                \"Clients with a shared connection cannot be \"\n                \"automatically redirected.\")\n        if self.message_handler:\n            self.message_handler.destroy()\n            self.message_handler = None\n        self._shutdown = False\n        self._last_activity_timestamp = None\n        self._was_message_received = False\n        self._received_messages = None\n\n        self._remote_address = address.Source(redirect.address)\n        self._redirect(redirect, auth)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef send_message(target, data, auth=None, debug=False):\n    message = data if isinstance(data, Message) else Message(body=data)\n    with SendClient(target, auth=auth, debug=debug) as send_client:\n        send_client.queue_message(message)\n        return send_client.send_all_messages()", "response": "Send a single message to the specified target."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreceiving a single message from an AMQP endpoint.", "response": "def receive_message(source, auth=None, timeout=0, debug=False):\n    \"\"\"Receive a single message from an AMQP endpoint.\n\n    :param source: The AMQP source endpoint to receive from.\n    :type source: str, bytes or ~uamqp.address.Source\n    :param auth: The authentication credentials for the endpoint.\n     This should be one of the subclasses of uamqp.authentication.AMQPAuth. Currently\n     this includes:\n        - uamqp.authentication.SASLAnonymous\n        - uamqp.authentication.SASLPlain\n        - uamqp.authentication.SASTokenAuth\n     If no authentication is supplied, SASLAnnoymous will be used by default.\n    :type auth: ~uamqp.authentication.common.AMQPAuth\n    :param timeout: The timeout in milliseconds after which to return None if no messages\n     are retrieved. If set to `0` (the default), the receiver will not timeout and\n     will continue to wait for messages until interrupted.\n    :param debug: Whether to turn on network trace logs. If `True`, trace logs\n     will be logged at INFO level. Default is `False`.\n    :type debug: bool\n    :rtype: ~uamqp.message.Message or None\n    \"\"\"\n    received = receive_messages(source, auth=auth, max_batch_size=1, timeout=timeout, debug=debug)\n    if received:\n        return received[0]\n    return None"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreceive a batch of messages from an AMQP source.", "response": "def receive_messages(source, auth=None, max_batch_size=None, timeout=0, debug=False, **kwargs):\n    \"\"\"Receive a batch of messages from an AMQP endpoint.\n\n    :param source: The AMQP source endpoint to receive from.\n    :type source: str, bytes or ~uamqp.address.Source\n    :param auth: The authentication credentials for the endpoint.\n     This should be one of the subclasses of ~uamqp.authentication.AMQPAuth. Currently\n     this includes:\n        - uamqp.authentication.SASLAnonymous\n        - uamqp.authentication.SASLPlain\n        - uamqp.authentication.SASTokenAuth\n     If no authentication is supplied, SASLAnnoymous will be used by default.\n    :type auth: ~uamqp.authentication.common.AMQPAuth\n    :param max_batch_size: The maximum number of messages to return in a batch. If the\n     receiver receives a smaller number than this, it will not wait to return them so\n     the actual number returned can be anything up to this value. If the receiver reaches\n     a timeout, an empty list will be returned.\n    :param timeout: The timeout in milliseconds after which to return if no messages\n     are retrieved. If set to `0` (the default), the receiver will not timeout and\n     will continue to wait for messages until interrupted.\n    :param debug: Whether to turn on network trace logs. If `True`, trace logs\n     will be logged at INFO level. Default is `False`.\n    :type debug: bool\n    :rtype: list[~uamqp.message.Message]\n    \"\"\"\n    if max_batch_size:\n        kwargs['prefetch'] = max_batch_size\n    with ReceiveClient(source, auth=auth, debug=debug, **kwargs) as receive_client:\n        return receive_client.receive_message_batch(\n            max_batch_size=max_batch_size or receive_client._prefetch, timeout=timeout)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ninitialize the TLS or SSL platform to prepare it for AMQP requests.", "response": "def initialize(cls):\n        \"\"\"Initialize the TLS/SSL platform to prepare it for\n        making AMQP requests. This only needs to happen once.\n        \"\"\"\n        if cls.initialized:\n            _logger.debug(\"Platform already initialized.\")\n        else:\n            _logger.debug(\"Initializing platform.\")\n            c_uamqp.platform_init()\n            cls.initialized = True"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef _validate_address(self, address):\n        parsed = compat.urlparse(address)\n        if not parsed.path:\n            raise ValueError(\"Invalid {} address: {}\".format(\n                self.__class__.__name__, parsed))\n        return parsed", "response": "Confirm that the supplied address is a valid URL and\n        has an amqp or qps scheme."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\ngets the filter on the source.", "response": "def get_filter(self, name=constants.STRING_FILTER):\n        \"\"\"Get the filter on the source.\n\n        :param name: The name of the filter. This will be encoded as\n         an AMQP Symbol. By default this is set to b'apache.org:selector-filter:string'.\n        :type name: bytes\n        \"\"\"\n        try:\n            filter_key = c_uamqp.symbol_value(name)\n            return self._address.filter_set[filter_key].value\n        except (TypeError, KeyError):\n            return None"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef set_filter(self, value, name=constants.STRING_FILTER, descriptor=constants.STRING_FILTER):\n        value = value.encode(self._encoding) if isinstance(value, six.text_type) else value\n        filter_set = c_uamqp.dict_value()\n        filter_key = c_uamqp.symbol_value(name)\n        filter_value = utils.data_factory(value, encoding=self._encoding)\n        if value is not None and descriptor is not None:\n            descriptor = c_uamqp.symbol_value(descriptor)\n            filter_value = c_uamqp.described_value(descriptor, filter_value)\n\n        filter_set[filter_key] = filter_value\n        self._address.filter_set = filter_set", "response": "Set the filter on the endpoint. Only one filter can be applied to an endpoint."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ncreate the asynchronous AMQP session and the CBS channel with which the token is negotiated.", "response": "async def create_authenticator_async(self, connection, debug=False, loop=None, **kwargs):\n        \"\"\"Create the async AMQP session and the CBS channel with which\n        to negotiate the token.\n\n        :param connection: The underlying AMQP connection on which\n         to create the session.\n        :type connection: ~uamqp.async_ops.connection_async.ConnectionAsync\n        :param debug: Whether to emit network trace logging events for the\n         CBS session. Default is `False`. Logging events are set at INFO level.\n        :type debug: bool\n        :param loop: A user specified event loop.\n        :type loop: ~asycnio.AbstractEventLoop\n        :rtype: uamqp.c_uamqp.CBSTokenAuth\n        \"\"\"\n        self.loop = loop or asyncio.get_event_loop()\n        self._connection = connection\n        self._session = SessionAsync(connection, loop=self.loop, **kwargs)\n        try:\n            self._cbs_auth = c_uamqp.CBSTokenAuth(\n                self.audience,\n                self.token_type,\n                self.token,\n                int(self.expires_at),\n                self._session._session,  # pylint: disable=protected-access\n                self.timeout,\n                self._connection.container_id)\n            self._cbs_auth.set_trace(debug)\n        except ValueError:\n            await self._session.destroy_async()\n            raise errors.AMQPConnectionError(\n                \"Unable to open authentication session on connection {}.\\n\"\n                \"Please confirm target hostname exists: {}\".format(\n                    connection.container_id, connection.hostname)) from None\n        return self._cbs_auth"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def close_authenticator_async(self):\n        _logger.info(\"Shutting down CBS session on connection: %r.\", self._connection.container_id)\n        try:\n            self._cbs_auth.destroy()\n            _logger.info(\"Auth closed, destroying session on connection: %r.\", self._connection.container_id)\n            await self._session.destroy_async()\n        finally:\n            _logger.info(\"Finished shutting down CBS session on connection: %r.\", self._connection.container_id)", "response": "Close the CBS auth channel and session asynchronously."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\nasync def mgmt_request_async(self, message, operation, op_type=None, node=b'$management', **kwargs):\n        timeout = kwargs.pop('timeout', None) or 0\n        parse_response = kwargs.pop('callback', None)\n        try:\n            mgmt_link = self._mgmt_links[node]\n        except KeyError:\n            mgmt_link = MgmtOperationAsync(self, target=node, loop=self.loop, **kwargs)\n            self._mgmt_links[node] = mgmt_link\n            while not mgmt_link.open and not mgmt_link.mgmt_error:\n                await self._connection.work_async()\n            if mgmt_link.mgmt_error:\n                raise mgmt_link.mgmt_error\n            if mgmt_link.open != constants.MgmtOpenStatus.Ok:\n                raise errors.AMQPConnectionError(\"Failed to open mgmt link: {}\".format(mgmt_link.open))\n        op_type = op_type or b'empty'\n        status, response, description = await mgmt_link.execute_async(operation, op_type, message, timeout=timeout)\n        if parse_response:\n            return parse_response(status, response, description)\n        return response", "response": "Asynchronously run a request to a specific service."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\nasync def destroy_async(self):\n        for _, link in self._mgmt_links.items():\n            await link.destroy_async()\n        self._session.destroy()", "response": "Asynchronously close any open management Links and the Session."}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute a request and wait on a response asynchronously.", "response": "async def execute_async(self, operation, op_type, message, timeout=0):\n        \"\"\"Execute a request and wait on a response asynchronously.\n\n        :param operation: The type of operation to be performed. This value will\n         be service-specific, but common values include READ, CREATE and UPDATE.\n         This value will be added as an application property on the message.\n        :type operation: bytes\n        :param op_type: The type on which to carry out the operation. This will\n         be specific to the entities of the service. This value will be added as\n         an application property on the message.\n        :type op_type: bytes\n        :param message: The message to send in the management request.\n        :type message: ~uamqp.message.Message\n        :param timeout: Provide an optional timeout in milliseconds within which a response\n         to the management request must be received.\n        :type timeout: int\n        :rtype: ~uamqp.message.Message\n        \"\"\"\n        start_time = self._counter.get_current_ms()\n        operation_id = str(uuid.uuid4())\n        self._responses[operation_id] = None\n\n        def on_complete(operation_result, status_code, description, wrapped_message):\n            result = constants.MgmtExecuteResult(operation_result)\n            if result != constants.MgmtExecuteResult.Ok:\n                _logger.error(\n                    \"Failed to complete mgmt operation.\\nStatus code: %r\\nMessage: %r\",\n                    status_code, description)\n            message = Message(message=wrapped_message) if wrapped_message else None\n            self._responses[operation_id] = (status_code, message, description)\n\n        self._mgmt_op.execute(operation, op_type, None, message.get_message(), on_complete)\n        while not self._responses[operation_id] and not self.mgmt_error:\n            if timeout > 0:\n                now = self._counter.get_current_ms()\n                if (now - start_time) >= timeout:\n                    raise TimeoutException(\"Failed to receive mgmt response in {}ms\".format(timeout))\n            await self.connection.work_async()\n        if self.mgmt_error:\n            raise self.mgmt_error\n        response = self._responses.pop(operation_id)\n        return response"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef main():\n    parser = arg_parser(usage='usage: %prog [options] SUBREDDIT VIEW')\n    parser.add_option('-c', '--commenters', type='int', default=10,\n                      help='Number of top commenters to display '\n                      '[default %default]')\n    parser.add_option('-d', '--distinguished', action='store_true',\n                      help=('Include distinguished subissions and '\n                            'comments (default: False). Note that regular '\n                            'comments of distinguished submissions will still '\n                            'be included.'))\n    parser.add_option('-s', '--submitters', type='int', default=10,\n                      help='Number of top submitters to display '\n                      '[default %default]')\n\n    options, args = parser.parse_args()\n\n    if options.verbose == 1:\n        logger.setLevel(logging.INFO)\n    elif options.verbose > 1:\n        logger.setLevel(logging.DEBUG)\n    else:\n        logger.setLevel(logging.NOTSET)\n    logger.addHandler(logging.StreamHandler())\n\n    if len(args) != 2:\n        parser.error('SUBREDDIT and VIEW must be provided')\n    subreddit, view = args\n    check_for_updates(options)\n    srs = SubredditStats(subreddit, options.site, options.distinguished)\n    result = srs.run(view, options.submitters, options.commenters)\n    if result:\n        print(result.permalink)\n    return 0", "response": "Provide the entry point to the subreddit_stats command."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef basic_stats(self):\n        comment_score = sum(comment.score for comment in self.comments)\n        if self.comments:\n            comment_duration = (self.comments[-1].created_utc -\n                                self.comments[0].created_utc)\n            comment_rate = self._rate(len(self.comments), comment_duration)\n        else:\n            comment_rate = 0\n\n        submission_duration = self.max_date - self.min_date\n        submission_rate = self._rate(len(self.submissions),\n                                     submission_duration)\n        submission_score = sum(sub.score for sub in self.submissions.values())\n\n        values = [('Total', len(self.submissions), len(self.comments)),\n                  ('Rate (per day)', '{:.2f}'.format(submission_rate),\n                   '{:.2f}'.format(comment_rate)),\n                  ('Unique Redditors', len(self.submitters),\n                   len(self.commenters)),\n                  ('Combined Score', submission_score, comment_score)]\n\n        retval = 'Period: {:.2f} days\\n\\n'.format(submission_duration / 86400.)\n        retval += '||Submissions|Comments|\\n:-:|--:|--:\\n'\n        for quad in values:\n            retval += '__{}__|{}|{}\\n'.format(*quad)\n        return retval + '\\n'", "response": "Return a markdown representation of simple statistics."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nfetch recent submissions in subreddit with boundaries.", "response": "def fetch_recent_submissions(self, max_duration):\n        \"\"\"Fetch recent submissions in subreddit with boundaries.\n\n        Does not include posts within the last day as their scores may not be\n        representative.\n\n        :param max_duration: When set, specifies the number of days to include\n\n        \"\"\"\n        if max_duration:\n            self.min_date = self.max_date - SECONDS_IN_A_DAY * max_duration\n        for submission in self.subreddit.new(limit=None):\n            if submission.created_utc <= self.min_date:\n                break\n            if submission.created_utc > self.max_date:\n                continue\n            self.submissions[submission.id] = MiniSubmission(submission)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nwrap the submissions_callback function to process the submission data and update the attributes.", "response": "def fetch_submissions(self, submissions_callback, *args):\n        \"\"\"Wrap the submissions_callback function.\"\"\"\n        logger.debug('Fetching submissions')\n\n        submissions_callback(*args)\n\n        logger.info('Found {} submissions'.format(len(self.submissions)))\n        if not self.submissions:\n            return\n\n        self.min_date = min(x.created_utc for x in self.submissions.values())\n        self.max_date = max(x.created_utc for x in self.submissions.values())\n\n        self.process_submitters()\n        self.process_commenters()"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef fetch_top_submissions(self, top):\n        for submission in self.subreddit.top(limit=None, time_filter=top):\n            self.submissions[submission.id] = MiniSubmission(submission)", "response": "Fetch top submissions by some top value."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngrouping comments by author.", "response": "def process_commenters(self):\n        \"\"\"Group comments by author.\"\"\"\n        for index, submission in enumerate(self.submissions.values()):\n            if submission.num_comments == 0:\n                continue\n            real_submission = self.reddit.submission(id=submission.id)\n            real_submission.comment_sort = 'top'\n\n            for i in range(3):\n                try:\n                    real_submission.comments.replace_more(limit=0)\n                    break\n                except RequestException:\n                    if i >= 2:\n                        raise\n                    logger.debug('Failed to fetch submission {}, retrying'\n                                 .format(submission.id))\n\n            self.comments.extend(MiniComment(comment, submission)\n                                 for comment in real_submission.comments.list()\n                                 if self.distinguished\n                                 or comment.distinguished is None)\n\n            if index % 50 == 49:\n                logger.debug('Completed: {:4d}/{} submissions'\n                             .format(index + 1, len(self.submissions)))\n\n            # Clean up to reduce memory usage\n            submission = None\n            gc.collect()\n\n        self.comments.sort(key=lambda x: x.created_utc)\n        for comment in self.comments:\n            if comment.author:\n                self.commenters[comment.author].append(comment)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef process_submitters(self):\n        for submission in self.submissions.values():\n            if submission.author and (self.distinguished or\n                                      submission.distinguished is None):\n                self.submitters[submission.author].append(submission)", "response": "Add submissions to the submission list."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef publish_results(self, view, submitters, commenters):\n        def timef(timestamp, date_only=False):\n            \"\"\"Return a suitable string representaation of the timestamp.\"\"\"\n            dtime = datetime.fromtimestamp(timestamp)\n            if date_only:\n                retval = dtime.strftime('%Y-%m-%d')\n            else:\n                retval = dtime.strftime('%Y-%m-%d %H:%M PDT')\n            return retval\n\n        basic = self.basic_stats()\n        top_commenters = self.top_commenters(commenters)\n        top_comments = self.top_comments()\n        top_submissions = self.top_submissions()\n\n        # Decrease number of top submitters if body is too large.\n        body = None\n        while body is None or len(body) > 40000 and submitters > 0:\n            body = (basic + self.top_submitters(submitters) + top_commenters\n                    + top_submissions + top_comments + self.post_footer)\n            submitters -= 1\n\n        title = '{} {} {}posts from {} to {}'.format(\n            self.post_prefix, str(self.subreddit),\n            'top ' if view in TOP_VALUES else '', timef(self.min_date, True),\n            timef(self.max_date))\n\n        try:  # Attempt to make the submission\n            return self.submit_subreddit.submit(title, selftext=body)\n        except Exception:\n            logger.exception('Failed to submit to {}'\n                             .format(self.submit_subreddit))\n            self._save_report(title, body)", "response": "Publish the results to the subreddit. Has no return value ( None."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns stats and return the created Submission.", "response": "def run(self, view, submitters, commenters):\n        \"\"\"Run stats and return the created Submission.\"\"\"\n        logger.info('Analyzing subreddit: {}'.format(self.subreddit))\n\n        if view in TOP_VALUES:\n            callback = self.fetch_top_submissions\n        else:\n            callback = self.fetch_recent_submissions\n            view = int(view)\n        self.fetch_submissions(callback, view)\n\n        if not self.submissions:\n            logger.warning('No submissions were found.')\n            return\n\n        return self.publish_results(view, submitters, commenters)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nreturning a markdown representation of the top commenters.", "response": "def top_commenters(self, num):\n        \"\"\"Return a markdown representation of the top commenters.\"\"\"\n        num = min(num, len(self.commenters))\n        if num <= 0:\n            return ''\n\n        top_commenters = sorted(\n            iteritems(self.commenters),\n            key=lambda x: (-sum(y.score for y in x[1]),\n                           -len(x[1]), str(x[0])))[:num]\n\n        retval = self.post_header.format('Top Commenters')\n        for author, comments in top_commenters:\n            retval += '1. {} ({}, {} comment{})\\n'.format(\n                self._user(author),\n                self._points(sum(x.score for x in comments)),\n                len(comments), 's' if len(comments) != 1 else '')\n        return '{}\\n'.format(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns a markdown representation of the top submitters.", "response": "def top_submitters(self, num):\n        \"\"\"Return a markdown representation of the top submitters.\"\"\"\n        num = min(num, len(self.submitters))\n        if num <= 0:\n            return ''\n\n        top_submitters = sorted(\n            iteritems(self.submitters),\n            key=lambda x: (-sum(y.score for y in x[1]),\n                           -len(x[1]), str(x[0])))[:num]\n\n        retval = self.post_header.format('Top Submitters\\' Top Submissions')\n        for (author, submissions) in top_submitters:\n            retval += '1. {}, {} submission{}: {}\\n'.format(\n                self._points(sum(x.score for x in submissions)),\n                len(submissions),\n                's' if len(submissions) != 1 else '', self._user(author))\n            for sub in sorted(\n                    submissions, key=lambda x: (-x.score, x.title))[:10]:\n                title = self._safe_title(sub)\n                if sub.permalink in sub.url:\n                    retval += tt('  1. {}').format(title)\n                else:\n                    retval += tt('  1. [{}]({})').format(title, sub.url)\n                retval += ' ({}, [{} comment{}]({}))\\n'.format(\n                    self._points(sub.score), sub.num_comments,\n                    's' if sub.num_comments != 1 else '',\n                    self._permalink(sub))\n            retval += '\\n'\n        return retval"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nreturn a markdown representation of the top submissions.", "response": "def top_submissions(self):\n        \"\"\"Return a markdown representation of the top submissions.\"\"\"\n        num = min(10, len(self.submissions))\n        if num <= 0:\n            return ''\n\n        top_submissions = sorted(\n            [x for x in self.submissions.values() if self.distinguished or\n             x.distinguished is None],\n            key=lambda x: (-x.score, -x.num_comments, x.title))[:num]\n\n        if not top_submissions:\n            return ''\n\n        retval = self.post_header.format('Top Submissions')\n        for sub in top_submissions:\n            title = self._safe_title(sub)\n            if sub.permalink in sub.url:\n                retval += tt('1. {}').format(title)\n            else:\n                retval += tt('1. [{}]({})').format(title, sub.url)\n\n            retval += ' by {} ({}, [{} comment{}]({}))\\n'.format(\n                self._user(sub.author), self._points(sub.score),\n                sub.num_comments, 's' if sub.num_comments != 1 else '',\n                self._permalink(sub))\n        return tt('{}\\n').format(retval)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef top_comments(self):\n        num = min(10, len(self.comments))\n        if num <= 0:\n            return ''\n\n        top_comments = sorted(\n            self.comments, key=lambda x: (-x.score, str(x.author)))[:num]\n        retval = self.post_header.format('Top Comments')\n        for comment in top_comments:\n            title = self._safe_title(comment.submission)\n            retval += tt('1. {}: {}\\'s [comment]({}) in {}\\n').format(\n                self._points(comment.score), self._user(comment.author),\n                self._permalink(comment), title)\n        return tt('{}\\n').format(retval)", "response": "Return a markdown representation of the top comments."}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef arg_parser(*args, **kwargs):\n    msg = {\n        'site': 'The site to connect to defined in your praw.ini file.',\n        'update': 'Prevent the checking for prawtools package updates.'}\n\n    kwargs['version'] = 'BBoe\\'s PRAWtools {}'.format(__version__)\n    parser = OptionParser(*args, **kwargs)\n    parser.add_option('-v', '--verbose', action='count', default=0,\n                      help='Increase the verbosity by 1 each time')\n    parser.add_option('-U', '--disable-update-check', action='store_true',\n                      help=msg['update'])\n\n    group = OptionGroup(parser, 'Site/Authentication options')\n    group.add_option('-S', '--site', help=msg['site'])\n    parser.add_option_group(group)\n\n    return parser", "response": "Return a parser with common options used in the prawtools commands."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef main():\n    mod_choices = ('banned', 'contributor', 'moderator')\n    mod_choices_dsp = ', '.join(['`{}`'.format(x) for x in mod_choices])\n    msg = {\n        'add': ('Add users to one of the following categories: {}'\n                .format(mod_choices_dsp)),\n        'clear': 'Remove users who have no flair set.',\n        'css': 'Ignore the CSS field when synchronizing flair.',\n        'edit': 'When adding flair templates, mark them as editable.',\n        'file': 'The file containing contents for --message',\n        'flair': 'List flair for the subreddit.',\n        'flair_stats': 'Display the number of users with each flair.',\n        'json': 'Output the results as json. Applies to --flair',\n        'limit': ('The minimum number of users that must have the specified '\n                  'flair in order to add as a template. default: %default'),\n        'list': ('List the users in one of the following categories: '\n                 '{}. May be specified more than once.'\n                 .format(mod_choices_dsp)),\n        'msg': ('Send message to users of one of the following categories: '\n                '{}. Message subject provided via --subject, content provided '\n                'via --file or STDIN.').format(mod_choices_dsp),\n        'sort': ('The order to add flair templates. Available options are '\n                 '`alpha` to add alphabetically, and `size` to first add '\n                 'flair that is shared by the most number of users. '\n                 'default: %default'),\n        'static': ('Add this template when syncing flair templates. When '\n                   'syncing text and css use a comma to separate the two.'),\n        'subject': 'The subject of the message to send for --message.',\n        'sync': 'Synchronize flair templates with current user flair.',\n        'text': 'Ignore the text field when synchronizing flair.'}\n\n    usage = 'Usage: %prog [options] SUBREDDIT'\n    parser = arg_parser(usage=usage)\n    parser.add_option('-a', '--add', help=msg['add'])\n    parser.add_option('-l', '--list', action='append', help=msg['list'],\n                      choices=mod_choices, metavar='CATEGORY', default=[])\n    parser.add_option('-c', '--clear-empty', action='store_true',\n                      help=msg['clear'])\n    parser.add_option('-F', '--file', help=msg['file'])\n    parser.add_option('-f', '--flair', action='store_true', help=msg['flair'])\n    parser.add_option('', '--flair-stats', action='store_true',\n                      help=msg['flair_stats'])\n    parser.add_option('-m', '--message', choices=mod_choices, help=msg['msg'])\n    parser.add_option('', '--subject', help=msg['subject'])\n\n    group = OptionGroup(parser, 'Format options')\n    group.add_option('-j', '--json', action='store_true', help=msg['json'])\n    parser.add_option_group(group)\n\n    group = OptionGroup(parser, 'Sync options')\n    group.add_option('', '--sync', action='store_true', help=msg['sync'])\n    group.add_option('-s', '--static', action='append', help=msg['static'])\n    group.add_option('', '--editable', action='store_true', help=msg['edit'])\n    group.add_option('', '--ignore-css', action='store_true',\n                     default=False, help=msg['css'])\n    group.add_option('', '--ignore-text', action='store_true',\n                     default=False, help=msg['text'])\n    group.add_option('', '--limit', type='int', help=msg['limit'], default=2)\n    group.add_option('', '--sort', action='store', choices=('alpha', 'size'),\n                     default='alpha', help=msg['sort'])\n    parser.add_option_group(group)\n\n    options, args = parser.parse_args()\n    if len(args) == 0:\n        parser.error('Must provide subreddit name.')\n    if options.message and not options.subject:\n        parser.error('Must provide --subject when providing --message.')\n    subreddit = args[0]\n\n    check_for_updates(options)\n\n    modutils = ModUtils(subreddit, options.site, options.verbose)\n\n    if options.add:\n        modutils.add_users(options.add)\n    if options.clear_empty:\n        modutils.clear_empty()\n    for category in options.list:\n        modutils.output_list(category)\n    if options.flair:\n        modutils.output_current_flair(as_json=options.json)\n    if options.flair_stats:\n        modutils.output_flair_stats()\n    if options.sync:\n        modutils.flair_template_sync(editable=options.editable,\n                                     limit=options.limit,\n                                     static=options.static, sort=options.sort,\n                                     use_css=not options.ignore_css,\n                                     use_text=not options.ignore_text)\n    if options.message:\n        modutils.message(options.message, options.subject, options.file)", "response": "Provide the entry point in the modutils command."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nadd users to banned contributor or moderator.", "response": "def add_users(self, category):\n        \"\"\"Add users to 'banned', 'contributor', or 'moderator'.\"\"\"\n        mapping = {'banned': 'ban', 'contributor': 'make_contributor',\n                   'moderator': 'make_moderator'}\n\n        if category not in mapping:\n            print('{!r} is not a valid option for --add'.format(category))\n            return\n        func = getattr(self.sub, mapping[category])\n        print('Enter user names (any separation should suffice):')\n        data = sys.stdin.read().strip()\n        for name in re.split('[^A-Za-z0-9_]+', data):\n            func(name)\n            print('Added {!r} to {}'.format(name, category))"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nremoves all flair that is not visible or has been set to empty.", "response": "def clear_empty(self):\n        \"\"\"Remove flair that is not visible or has been set to empty.\"\"\"\n        for flair in self.current_flair():\n            if not flair['flair_text'] and not flair['flair_css_class']:\n                print(self.reddit.flair.update(flair['user']))\n                print('Removed flair for {0}'.format(flair['user']))"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef current_flair(self):\n        if self._current_flair is None:\n            self._current_flair = []\n            if self.verbose:\n                print('Fetching flair list for {}'.format(self.sub))\n            for flair in self.sub.flair:\n                self._current_flair.append(flair)\n                yield flair\n        else:\n            for item in self._current_flair:\n                yield item", "response": "Generate the flair by user for the subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsynchronizes templates with flair that already exists on the site.", "response": "def flair_template_sync(self, editable, limit,  # pylint: disable=R0912\n                            static, sort, use_css, use_text):\n        \"\"\"Synchronize templates with flair that already exists on the site.\n\n        :param editable: Indicates that all the options should be editable.\n        :param limit: The minimum number of users that must share the flair\n            before it is added as a template.\n        :param static: A list of flair templates that will always be added.\n        :param sort: The order to sort the flair templates.\n        :param use_css: Include css in the templates.\n        :param use_text: Include text in the templates.\n\n        \"\"\"\n        # Parameter verification\n        if not use_text and not use_css:\n            raise Exception('At least one of use_text or use_css must be True')\n        sorts = ('alpha', 'size')\n        if sort not in sorts:\n            raise Exception('Sort must be one of: {}'.format(', '.join(sorts)))\n\n        # Build current flair list along with static values\n        counter = {}\n        if static:\n            for key in static:\n                if use_css and use_text:\n                    parts = tuple(x.strip() for x in key.split(','))\n                    if len(parts) != 2:\n                        raise Exception('--static argument {!r} must have two '\n                                        'parts (comma separated) when using '\n                                        'both text and css.'.format(parts))\n                    key = parts\n                counter[key] = limit\n        if self.verbose:\n            sys.stdout.write('Retrieving current flair\\n')\n            sys.stdout.flush()\n        for flair in self.current_flair():\n            if self.verbose:\n                sys.stdout.write('.')\n                sys.stdout.flush()\n            if use_text and use_css:\n                key = (flair['flair_text'], flair['flair_css_class'])\n            elif use_text:\n                key = flair['flair_text']\n            else:\n                key = flair['flair_css_class']\n            if key in counter:\n                counter[key] += 1\n            else:\n                counter[key] = 1\n        if self.verbose:\n            print()\n\n        # Sort flair list items according to the specified sort\n        if sort == 'alpha':\n            items = sorted(counter.items())\n        else:\n            items = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n\n        # Clear current templates and store flair according to the sort\n        if self.verbose:\n            print('Clearing current flair templates')\n        self.sub.flair.templates.clear()\n        for key, count in items:\n            if not key or count < limit:\n                print('a')\n                continue\n            if use_text and use_css:\n                text, css = key\n            elif use_text:\n                text, css = key, ''\n            else:\n                text, css = '', key\n            if self.verbose:\n                print('Adding template: text: {!r} css: {!r}'\n                      .format(text, css))\n            self.sub.flair.templates.add(text, css, editable)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nsend a message to all users in category.", "response": "def message(self, category, subject, msg_file):\n        \"\"\"Send message to all users in `category`.\"\"\"\n        users = getattr(self.sub, category)\n        if not users:\n            print('There are no {} users on {}.'.format(category, self.sub))\n            return\n\n        if msg_file:\n            try:\n                msg = open(msg_file).read()\n            except IOError as error:\n                print(str(error))\n                return\n        else:\n            print('Enter message:')\n            msg = sys.stdin.read()\n\n        print('You are about to send the following message to the users {}:'\n              .format(', '.join([str(x) for x in users])))\n        print('---BEGIN MESSAGE---\\n{}\\n---END MESSAGE---'.format(msg))\n        if input('Are you sure? yes/[no]: ').lower() not in ['y', 'yes']:\n            print('Message sending aborted.')\n            return\n        for user in users:\n            user.send_message(subject, msg)\n            print('Sent to: {}'.format(user))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef output_current_flair(self, as_json=False):\n        flair_list = sorted(self.current_flair(), key=lambda x: x['user'].name)\n        if as_json:\n            print(json.dumps(flair_list, sort_keys=True, indent=4))\n            return\n\n        for flair in flair_list:\n            print(flair['user'])\n            print('  Text: {}\\n   CSS: {}'.format(flair['flair_text'],\n                                                  flair['flair_css_class']))", "response": "Display the current flair for all users in the subreddit."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef output_flair_stats(self):\n        css_counter = Counter()\n        text_counter = Counter()\n        for flair in self.current_flair():\n            if flair['flair_css_class']:\n                css_counter[flair['flair_css_class']] += 1\n            if flair['flair_text']:\n                text_counter[flair['flair_text']] += 1\n\n        print('Flair CSS Statistics')\n        for flair, count in sorted(css_counter.items(),\n                                   key=lambda x: (x[1], x[0])):\n            print('{0:3} {1}'.format(count, flair))\n\n        print('Flair Text Statistics')\n        for flair, count in sorted(text_counter.items(),\n                                   key=lambda x: (x[1], x[0]), reverse=True):\n            print('{0:3} {1}'.format(count, flair))", "response": "Display statistics (number of users for each unique flair item."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ndisplays the list of users in category.", "response": "def output_list(self, category):\n        \"\"\"Display the list of users in `category`.\"\"\"\n        print('{} users:'.format(category))\n        for user in getattr(self.sub, category):\n            print('  {}'.format(user))"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef quick_url(comment):\n    def to_id(fullname):\n        return fullname.split('_', 1)[1]\n    return ('http://www.reddit.com/r/{}/comments/{}/_/{}?context=3'\n            .format(comment.subreddit.display_name, to_id(comment.link_id),\n                    comment.id))", "response": "Return the URL for the comment without fetching its submission."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef main():\n    usage = 'Usage: %prog [options] KEYWORD...'\n    parser = arg_parser(usage=usage)\n    parser.add_option('-s', '--subreddit', action='append',\n                      help=('When at least one `-s` option is provided '\n                            '(multiple can be) only alert for comments in the '\n                            'indicated subreddit(s).'))\n    parser.add_option('-I', '--ignore-user', action='append', metavar='USER',\n                      help=('Ignore comments from the provided user. Can be '\n                            'supplied multiple times.'))\n    parser.add_option('-m', '--message', metavar='USER',\n                      help=('When set, send a reddit message to USER with the '\n                            'alert.'))\n    options, args = parser.parse_args()\n    if not args:\n        parser.error('At least one KEYWORD must be provided.')\n\n    session = praw.Reddit(options.site, check_for_updates=False,\n                          user_agent=AGENT)\n\n    if options.message:\n        msg_to = session.redditor(options.message)\n\n    check_for_updates(options)\n\n    # Build regex\n    args = [x.lower() for x in args]\n    reg_prefix = r'(?:^|[^a-z])'  # Any character (or start) can precede\n    reg_suffix = r'(?:$|[^a-z])'  # Any character (or end) can follow\n    regex = re.compile(r'{}({}){}'.format(reg_prefix, '|'.join(args),\n                                          reg_suffix), re.IGNORECASE)\n\n    # Determine subreddit or multireddit\n    if options.subreddit:\n        subreddit = '+'.join(sorted(options.subreddit))\n    else:\n        subreddit = 'all'\n\n    print('Alerting on:')\n    for item in sorted(args):\n        print(' * {}'.format(item))\n    print('using the comment stream: https://www.reddit.com/r/{}/comments'\n          .format(subreddit))\n\n    # Build ignore set\n    if options.ignore_user:\n        ignore_users = set(x.lower() for x in options.ignore_user)\n    else:\n        ignore_users = set()\n\n    try:\n        for comment in session.subreddit(subreddit).stream.comments():\n            if comment.author and comment.author.name.lower() in ignore_users:\n                continue\n            match = regex.search(comment.body)\n            if match:\n                keyword = match.group(1).lower()\n                url = quick_url(comment)\n                print('{}: {}'.format(keyword, url))\n                if options.message:\n                    msg_to.message(\n                        'Reddit Alert: {}'.format(keyword),\n                        '{}\\n\\nby /u/{}\\n\\n---\\n\\n{}'.format(\n                            url, comment.author, comment.body))\n    except KeyboardInterrupt:\n        sys.stderr.write('\\n')\n        print('Goodbye!\\n')", "response": "Provide the entry point into the reddit_alert program."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef get_object_executor(obj, green_mode=None):\n    # Get green mode\n    if green_mode is None:\n        green_mode = get_object_green_mode(obj)\n    # Get executor\n    executor = None\n    if hasattr(obj, '_executors'):\n        executor = obj._executors.get(green_mode, None)\n    if executor is None:\n        executor = get_executor(green_mode)\n    # Get submitter\n    return executor", "response": "Returns the proper executor for the given object."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nmake a function green. Can be used as a decorator.", "response": "def green(fn=None, consume_green_mode=True):\n    \"\"\"Make a function green. Can be used as a decorator.\"\"\"\n\n    def decorator(fn):\n        @wraps(fn)\n        def greener(obj, *args, **kwargs):\n            args = (obj,) + args\n            wait = kwargs.pop('wait', None)\n            timeout = kwargs.pop('timeout', None)\n            access = kwargs.pop if consume_green_mode else kwargs.get\n            green_mode = access('green_mode', None)\n            executor = get_object_executor(obj, green_mode)\n            return executor.run(fn, args, kwargs, wait=wait, timeout=timeout)\n\n        return greener\n\n    if fn is None:\n        return decorator\n    return decorator(fn)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef green_callback(fn, obj=None, green_mode=None):\n    executor = get_object_executor(obj, green_mode)\n\n    @wraps(fn)\n    def greener(*args, **kwargs):\n        return executor.submit(fn, *args, **kwargs)\n\n    return greener", "response": "Return a green verion of the given callback."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nexecutes an operation and return the result.", "response": "def execute(self, fn, *args, **kwargs):\n        \"\"\"Execute an operation and return the result.\"\"\"\n        if not self.asynchronous:\n            return fn(*args, **kwargs)\n        raise NotImplementedError"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __struct_params_s(obj, separator=', ', f=repr, fmt='%s = %s'):\n    s = separator.join([__single_param(obj, n, f, fmt) for n in dir(obj) if __inc_param(obj, n)])\n    return s", "response": "method wrapper for printing all elements of a struct"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __registerSeqStr():\n    _SeqStr = lambda self: (self and \"[%s]\" % (\", \".join(map(repr, self)))) or \"[]\"\n    _SeqRepr = lambda self: (self and \"[%s]\" % (\", \".join(map(repr, self)))) or \"[]\"\n\n    seqs = (StdStringVector, StdLongVector, CommandInfoList,\n            AttributeInfoList, AttributeInfoListEx, PipeInfoList,\n            DeviceDataHistoryList,\n            GroupReplyList, GroupAttrReplyList, GroupCmdReplyList,\n            DbData, DbDevInfos, DbDevExportInfos, DbDevImportInfos, DbHistoryList)\n\n    for seq in seqs:\n        seq.__str__ = _SeqStr\n        seq.__repr__ = _SeqRepr", "response": "helper function to make internal sequences printable"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nregisters str and repr methods for structures", "response": "def __registerStructStr():\n    \"\"\"helper method to register str and repr methods for structures\"\"\"\n    structs = (LockerInfo, DevCommandInfo, AttributeDimension, CommandInfo,\n               DeviceInfo, DeviceAttributeConfig, AttributeInfo, AttributeAlarmInfo,\n               ChangeEventInfo, PeriodicEventInfo, ArchiveEventInfo,\n               AttributeEventInfo, AttributeInfoEx, PipeInfo,\n               DeviceAttribute, DeviceAttributeHistory, DeviceData, DeviceDataHistory,\n               DevicePipe, DbDatum, DbDevInfo, DbDevImportInfo, DbDevExportInfo,\n               DbServerInfo, GroupReply, GroupAttrReply, GroupCmdReply,\n               DevError, EventData, AttrConfEventData, DataReadyEventData,\n               AttributeConfig, AttributeConfig_2, AttributeConfig_3,\n               AttributeConfig_5,\n               ChangeEventProp, PeriodicEventProp, ArchiveEventProp,\n               AttributeAlarm, EventProperties)\n\n    for struct in structs:\n        struct.__str__ = __str__Struct\n        struct.__repr__ = __repr__Struct\n\n    # special case for TimeVal: it already has a str representation itself\n    TimeVal.__repr__ = __repr__Struct\n\n    # special case for DevFailed: we want a better pretty print\n    # also, because it is an Exception it has the message attribute which\n    # generates a Deprecation warning in python 2.6\n    DevFailed.__str__ = __str__DevFailed\n    DevFailed.__repr__ = __repr__DevFailed\n\n    DevError.__str__ = __str__DevError"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nalias a python package properly.", "response": "def alias_package(package, alias, extra_modules={}):\n    \"\"\"Alias a python package properly.\n\n    It ensures that modules are not duplicated by trying\n    to import and alias all the submodules recursively.\n    \"\"\"\n    path = package.__path__\n    alias_prefix = alias + '.'\n    prefix = package.__name__ + '.'\n    # Alias all importable modules recursively\n    for _, name, _ in pkgutil.walk_packages(path, prefix):\n        # Skip databaseds backends\n        if name.startswith('tango.databaseds.db_access.'):\n            continue\n        try:\n            if name not in sys.modules:\n                __import__(name)\n        except ImportError:\n            continue\n        alias_name = name.replace(prefix, alias_prefix)\n        sys.modules[alias_name] = sys.modules[name]\n    # Alias extra modules\n    for key, value in extra_modules.items():\n        name = prefix + value\n        if name not in sys.modules:\n            __import__(name)\n        if not hasattr(package, key):\n            setattr(package, key, sys.modules[name])\n        sys.modules[alias_prefix + key] = sys.modules[name]\n    # Alias root module\n    sys.modules[alias] = sys.modules[package.__name__]"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nreturning the given operation as an asyncio future.", "response": "def delegate(self, fn, *args, **kwargs):\n        \"\"\"Return the given operation as an asyncio future.\"\"\"\n        callback = functools.partial(fn, *args, **kwargs)\n        coro = self.loop.run_in_executor(self.subexecutor, callback)\n        return asyncio.ensure_future(coro)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nreturning a result from an asyncio future.", "response": "def access(self, accessor, timeout=None):\n        \"\"\"Return a result from an asyncio future.\"\"\"\n        if self.loop.is_running():\n            raise RuntimeError(\"Loop is already running\")\n        coro = asyncio.wait_for(accessor, timeout, loop=self.loop)\n        return self.loop.run_until_complete(coro)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nsubmit an operation to the cache", "response": "def submit(self, fn, *args, **kwargs):\n        \"\"\"Submit an operation\"\"\"\n        corofn = asyncio.coroutine(lambda: fn(*args, **kwargs))\n        return run_coroutine_threadsafe(corofn(), self.loop)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef execute(self, fn, *args, **kwargs):\n        if self.in_executor_context():\n            corofn = asyncio.coroutine(lambda: fn(*args, **kwargs))\n            return corofn()\n        future = self.submit(fn, *args, **kwargs)\n        return future.result()", "response": "Execute an operation and return the result."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __EncodedAttribute_encode_jpeg_gray8(self, gray8, width=0, height=0, quality=100.0):\n    self._generic_encode_gray8(gray8, width=width, height=height, quality=quality, format=_ImageFormat.JpegImage)", "response": "Encode a 8 bit grayscale image as JPEG format."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef __EncodedAttribute_encode_gray8(self, gray8, width=0, height=0):\n    self._generic_encode_gray8(gray8, width=width, height=height, format=_ImageFormat.RawImage)", "response": "Encode a 8 bit grayscale image."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nencodes a 16 bit grayscale image.", "response": "def __EncodedAttribute_encode_gray16(self, gray16, width=0, height=0):\n    \"\"\"Encode a 16 bit grayscale image (no compression)\n\n           :param gray16: an object containning image information\n           :type gray16: :py:obj:`str` or :py:obj:`buffer` or :class:`numpy.ndarray` or seq< seq<element> >\n           :param width: image width. **MUST** be given if gray16 is a string or\n                         if it is a :class:`numpy.ndarray` with ndims != 2.\n                         Otherwise it is calculated internally.\n           :type width: :py:obj:`int`\n           :param height: image height. **MUST** be given if gray16 is a string\n                          or if it is a :class:`numpy.ndarray` with ndims != 2.\n                          Otherwise it is calculated internally.\n           :type height: :py:obj:`int`\n\n       .. note::\n           When :class:`numpy.ndarray` is given:\n\n               - gray16 **MUST** be CONTIGUOUS, ALIGNED\n               - if gray16.ndims != 2, width and height **MUST** be given and\n                 gray16.nbytes/2 **MUST** match width*height\n               - if gray16.ndims == 2, gray16.itemsize **MUST** be 2 (typically,\n                 gray16.dtype is one of `numpy.dtype.int16`, `numpy.dtype.uint16`,\n                 `numpy.dtype.short` or `numpy.dtype.ushort`)\n\n       Example::\n\n           def read_myattr(self, attr):\n               enc = tango.EncodedAttribute()\n               data = numpy.arange(100, dtype=numpy.int16)\n               data = numpy.array((data,data,data))\n               enc.encode_gray16(data)\n               attr.set_value(enc)\n    \"\"\"\n    if not is_seq(gray16):\n        raise TypeError(\"Expected sequence (str, numpy.ndarray, list, tuple \"\n                        \"or bytearray) as first argument\")\n\n    is_str = is_pure_str(gray16)\n    if is_str:\n        if not width or not height:\n            raise ValueError(\"When giving a string as data, you must also \"\n                             \"supply width and height\")\n\n    if np and isinstance(gray16, np.ndarray):\n        if gray16.ndim != 2:\n            if not width or not height:\n                raise ValueError(\"When giving a non 2D numpy array, width and \"\n                                 \"height must be supplied\")\n            if gray16.nbytes / 2 != width * height:\n                raise ValueError(\"numpy array size mismatch\")\n        else:\n            if gray16.itemsize != 2:\n                raise TypeError(\"Expected numpy array with itemsize == 2\")\n        if not gray16.flags.c_contiguous:\n            raise TypeError(\"Currently, only contiguous, aligned numpy arrays \"\n                            \"are supported\")\n        if not gray16.flags.aligned:\n            raise TypeError(\"Currently, only contiguous, aligned numpy arrays \"\n                            \"are supported\")\n\n    if not is_str and (not width or not height):\n        height = len(gray16)\n        if height < 1:\n            raise IndexError(\"Expected sequence with at least one row\")\n\n        row0 = gray16[0]\n        if not is_seq(row0):\n            raise IndexError(\"Expected sequence (str, numpy.ndarray, list, tuple or \"\n                             \"bytearray) inside a sequence\")\n        width = len(row0)\n        if is_pure_str(row0) or type(row0) == bytearray:\n            width /= 2\n\n    self._encode_gray16(gray16, width, height)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nencode a 24 bit rgb color image as JPEG format.", "response": "def __EncodedAttribute_encode_jpeg_rgb24(self, rgb24, width=0, height=0, quality=100.0):\n    \"\"\"Encode a 24 bit rgb color image as JPEG format.\n\n           :param rgb24: an object containning image information\n           :type rgb24: :py:obj:`str` or :class:`numpy.ndarray` or seq< seq<element> >\n           :param width: image width. **MUST** be given if rgb24 is a string or\n                         if it is a :class:`numpy.ndarray` with ndims != 3.\n                         Otherwise it is calculated internally.\n           :type width: :py:obj:`int`\n           :param height: image height. **MUST** be given if rgb24 is a string\n                          or if it is a :class:`numpy.ndarray` with ndims != 3.\n                          Otherwise it is calculated internally.\n           :type height: :py:obj:`int`\n           :param quality: Quality of JPEG (0=poor quality 100=max quality) (default is 100.0)\n           :type quality: :py:obj:`float`\n\n       .. note::\n           When :class:`numpy.ndarray` is given:\n\n               - rgb24 **MUST** be CONTIGUOUS, ALIGNED\n               - if rgb24.ndims != 3, width and height **MUST** be given and\n                 rgb24.nbytes/3 **MUST** match width*height\n               - if rgb24.ndims == 3, rgb24.itemsize **MUST** be 1 (typically,\n                 rgb24.dtype is one of `numpy.dtype.byte`, `numpy.dtype.ubyte`,\n                 `numpy.dtype.int8` or `numpy.dtype.uint8`) and shape **MUST** be\n                 (height, width, 3)\n\n       Example::\n\n           def read_myattr(self, attr):\n               enc = tango.EncodedAttribute()\n               # create an 'image' where each pixel is R=0x01, G=0x01, B=0x01\n               arr = numpy.ones((10,10,3), dtype=numpy.uint8)\n               enc.encode_jpeg_rgb24(data)\n               attr.set_value(enc)\n    \"\"\"\n    self._generic_encode_rgb24(rgb24, width=width, height=height, quality=quality, format=_ImageFormat.JpegImage)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a 24 bit color image.", "response": "def __EncodedAttribute_encode_rgb24(self, rgb24, width=0, height=0):\n    \"\"\"Encode a 24 bit color image (no compression)\n\n           :param rgb24: an object containning image information\n           :type rgb24: :py:obj:`str` or :class:`numpy.ndarray` or seq< seq<element> >\n           :param width: image width. **MUST** be given if rgb24 is a string or\n                         if it is a :class:`numpy.ndarray` with ndims != 3.\n                         Otherwise it is calculated internally.\n           :type width: :py:obj:`int`\n           :param height: image height. **MUST** be given if rgb24 is a string\n                          or if it is a :class:`numpy.ndarray` with ndims != 3.\n                          Otherwise it is calculated internally.\n           :type height: :py:obj:`int`\n\n       .. note::\n           When :class:`numpy.ndarray` is given:\n\n               - rgb24 **MUST** be CONTIGUOUS, ALIGNED\n               - if rgb24.ndims != 3, width and height **MUST** be given and\n                 rgb24.nbytes/3 **MUST** match width*height\n               - if rgb24.ndims == 3, rgb24.itemsize **MUST** be 1 (typically,\n                 rgb24.dtype is one of `numpy.dtype.byte`, `numpy.dtype.ubyte`,\n                 `numpy.dtype.int8` or `numpy.dtype.uint8`) and shape **MUST** be\n                 (height, width, 3)\n\n       Example::\n\n           def read_myattr(self, attr):\n               enc = tango.EncodedAttribute()\n               # create an 'image' where each pixel is R=0x01, G=0x01, B=0x01\n               arr = numpy.ones((10,10,3), dtype=numpy.uint8)\n               enc.encode_rgb24(data)\n               attr.set_value(enc)\n    \"\"\"\n    self._generic_encode_rgb24(rgb24, width=width, height=height, format=_ImageFormat.RawImage)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nencoding a 32 bit rgb color image as JPEG format.", "response": "def __EncodedAttribute_encode_jpeg_rgb32(self, rgb32, width=0, height=0, quality=100.0):\n    \"\"\"Encode a 32 bit rgb color image as JPEG format.\n\n           :param rgb32: an object containning image information\n           :type rgb32: :py:obj:`str` or :class:`numpy.ndarray` or seq< seq<element> >\n           :param width: image width. **MUST** be given if rgb32 is a string or\n                         if it is a :class:`numpy.ndarray` with ndims != 2.\n                         Otherwise it is calculated internally.\n           :type width: :py:obj:`int`\n           :param height: image height. **MUST** be given if rgb32 is a string\n                          or if it is a :class:`numpy.ndarray` with ndims != 2.\n                          Otherwise it is calculated internally.\n           :type height: :py:obj:`int`\n\n       .. note::\n           When :class:`numpy.ndarray` is given:\n\n               - rgb32 **MUST** be CONTIGUOUS, ALIGNED\n               - if rgb32.ndims != 2, width and height **MUST** be given and\n                 rgb32.nbytes/4 **MUST** match width*height\n               - if rgb32.ndims == 2, rgb32.itemsize **MUST** be 4 (typically,\n                 rgb32.dtype is one of `numpy.dtype.int32`, `numpy.dtype.uint32`)\n\n       Example::\n\n           def read_myattr(self, attr):\n               enc = tango.EncodedAttribute()\n               data = numpy.arange(100, dtype=numpy.int32)\n               data = numpy.array((data,data,data))\n               enc.encode_jpeg_rgb32(data)\n               attr.set_value(enc)\n    \"\"\"\n    if not is_seq(rgb32):\n        raise TypeError(\"Expected sequence (str, numpy.ndarray, list, tuple \"\n                        \"or bytearray) as first argument\")\n\n    is_str = is_pure_str(rgb32)\n    if is_str:\n        if not width or not height:\n            raise ValueError(\"When giving a string as data, you must also \"\n                             \"supply width and height\")\n\n    if np and isinstance(rgb32, np.ndarray):\n        if rgb32.ndim != 2:\n            if not width or not height:\n                raise ValueError(\"When giving a non 2D numpy array, width and \"\n                                 \"height must be supplied\")\n            if rgb32.nbytes / 4 != width * height:\n                raise ValueError(\"numpy array size mismatch\")\n        else:\n            if rgb32.itemsize != 4:\n                raise TypeError(\"Expected numpy array with itemsize == 4\")\n        if not rgb32.flags.c_contiguous:\n            raise TypeError(\"Currently, only contiguous, aligned numpy arrays \"\n                            \"are supported\")\n        if not rgb32.flags.aligned:\n            raise TypeError(\"Currently, only contiguous, aligned numpy arrays \"\n                            \"are supported\")\n\n    if not is_str and (not width or not height):\n        height = len(rgb32)\n        if height < 1:\n            raise IndexError(\"Expected sequence with at least one row\")\n\n        row0 = rgb32[0]\n        if not is_seq(row0):\n            raise IndexError(\"Expected sequence (str, numpy.ndarray, list, tuple or \"\n                             \"bytearray) inside a sequence\")\n        width = len(row0)\n        if is_pure_str(row0) or type(row0) == bytearray:\n            width /= 4\n\n    self._encode_jpeg_rgb32(rgb32, width, height, quality)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ndecoding a 8 bits grayscale image.", "response": "def __EncodedAttribute_decode_gray8(self, da, extract_as=ExtractAs.Numpy):\n    \"\"\"Decode a 8 bits grayscale image (JPEG_GRAY8 or GRAY8) and returns a 8 bits gray scale image.\n\n        :param da: :class:`DeviceAttribute` that contains the image\n        :type da: :class:`DeviceAttribute`\n        :param extract_as: defaults to ExtractAs.Numpy\n        :type extract_as: ExtractAs\n        :return: the decoded data\n\n        - In case String string is choosen as extract method, a tuple is returned:\n            width<int>, height<int>, buffer<str>\n        - In case Numpy is choosen as extract method, a :class:`numpy.ndarray` is\n          returned with ndim=2, shape=(height, width) and dtype=numpy.uint8.\n        - In case Tuple or List are choosen, a tuple<tuple<int>> or list<list<int>>\n          is returned.\n\n       .. warning::\n           The PyTango calls that return a :class:`DeviceAttribute`\n           (like :meth:`DeviceProxy.read_attribute` or :meth:`DeviceProxy.command_inout`)\n           automatically extract the contents by default. This method requires\n           that the given :class:`DeviceAttribute` is obtained from a\n           call which **DOESN'T** extract the contents. Example::\n\n               dev = tango.DeviceProxy(\"a/b/c\")\n               da = dev.read_attribute(\"my_attr\", extract_as=tango.ExtractAs.Nothing)\n               enc = tango.EncodedAttribute()\n               data = enc.decode_gray8(da)\n    \"\"\"\n    if hasattr(da, 'value'):\n        raise TypeError(\"DeviceAttribute argument must have been obtained from \"\n                        \"a call which doesn't extract the contents\")\n    if extract_as not in _allowed_extract:\n        raise TypeError(\"extract_as must be one of Numpy, String, Tuple, List\")\n    return self._decode_gray8(da, extract_as)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndecode a 16 bits grayscale image.", "response": "def __EncodedAttribute_decode_gray16(self, da, extract_as=ExtractAs.Numpy):\n    \"\"\"Decode a 16 bits grayscale image (GRAY16) and returns a 16 bits gray scale image.\n\n        :param da: :class:`DeviceAttribute` that contains the image\n        :type da: :class:`DeviceAttribute`\n        :param extract_as: defaults to ExtractAs.Numpy\n        :type extract_as: ExtractAs\n        :return: the decoded data\n\n        - In case String string is choosen as extract method, a tuple is returned:\n            width<int>, height<int>, buffer<str>\n        - In case Numpy is choosen as extract method, a :class:`numpy.ndarray` is\n          returned with ndim=2, shape=(height, width) and dtype=numpy.uint16.\n        - In case Tuple or List are choosen, a tuple<tuple<int>> or list<list<int>>\n          is returned.\n\n       .. warning::\n           The PyTango calls that return a :class:`DeviceAttribute`\n           (like :meth:`DeviceProxy.read_attribute` or :meth:`DeviceProxy.command_inout`)\n           automatically extract the contents by default. This method requires\n           that the given :class:`DeviceAttribute` is obtained from a\n           call which **DOESN'T** extract the contents. Example::\n\n               dev = tango.DeviceProxy(\"a/b/c\")\n               da = dev.read_attribute(\"my_attr\", extract_as=tango.ExtractAs.Nothing)\n               enc = tango.EncodedAttribute()\n               data = enc.decode_gray16(da)\n    \"\"\"\n    if hasattr(da, 'value'):\n        raise TypeError(\"DeviceAttribute argument must have been obtained from \"\n                        \"a call which doesn't extract the contents\")\n    if extract_as not in _allowed_extract:\n        raise TypeError(\"extract_as must be one of Numpy, String, Tuple, List\")\n    return self._decode_gray16(da, extract_as)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ndecode a color image from a device attribute.", "response": "def __EncodedAttribute_decode_rgb32(self, da, extract_as=ExtractAs.Numpy):\n    \"\"\"Decode a color image (JPEG_RGB or RGB24) and returns a 32 bits RGB image.\n\n        :param da: :class:`DeviceAttribute` that contains the image\n        :type da: :class:`DeviceAttribute`\n        :param extract_as: defaults to ExtractAs.Numpy\n        :type extract_as: ExtractAs\n        :return: the decoded data\n\n        - In case String string is choosen as extract method, a tuple is returned:\n            width<int>, height<int>, buffer<str>\n        - In case Numpy is choosen as extract method, a :class:`numpy.ndarray` is\n          returned with ndim=2, shape=(height, width) and dtype=numpy.uint32.\n        - In case Tuple or List are choosen, a tuple<tuple<int>> or list<list<int>>\n          is returned.\n\n       .. warning::\n           The PyTango calls that return a :class:`DeviceAttribute`\n           (like :meth:`DeviceProxy.read_attribute` or :meth:`DeviceProxy.command_inout`)\n           automatically extract the contents by default. This method requires\n           that the given :class:`DeviceAttribute` is obtained from a\n           call which **DOESN'T** extract the contents. Example::\n\n               dev = tango.DeviceProxy(\"a/b/c\")\n               da = dev.read_attribute(\"my_attr\", extract_as=tango.ExtractAs.Nothing)\n               enc = tango.EncodedAttribute()\n               data = enc.decode_rgb32(da)\n    \"\"\"\n    if hasattr(da, 'value'):\n        raise TypeError(\"DeviceAttribute argument must have been obtained from \"\n                        \"a call which doesn't extract the contents\")\n    if extract_as not in _allowed_extract:\n        raise TypeError(\"extract_as must be one of Numpy, String, Tuple, List\")\n    return self._decode_rgb32(da, extract_as)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __patch_read_method(tango_device_klass, attribute):\n    read_method = getattr(attribute, \"fget\", None)\n    if read_method:\n        method_name = \"__read_{0}__\".format(attribute.attr_name)\n        attribute.read_method_name = method_name\n    else:\n        method_name = attribute.read_method_name\n        read_method = getattr(tango_device_klass, method_name)\n\n    read_attr = _get_wrapped_read_method(attribute, read_method)\n    method_name = \"__read_{0}_wrapper__\".format(attribute.attr_name)\n    attribute.read_method_name = method_name\n\n    setattr(tango_device_klass, method_name, read_attr)", "response": "Patch the read method of the given device class with the correct signature."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\npatches the read or write method of the given object with the correct signature.", "response": "def __patch_write_method(tango_device_klass, attribute):\n    \"\"\"\n    Checks if method given by it's name for the given DeviceImpl\n    class has the correct signature. If a read/write method doesn't\n    have a parameter (the traditional Attribute), then the method is\n    wrapped into another method which has correct parameter definition\n    to make it work.\n\n    :param tango_device_klass: a DeviceImpl class\n    :type tango_device_klass: class\n    :param attribute: the attribute data information\n    :type attribute: AttrData\n    \"\"\"\n    write_method = getattr(attribute, \"fset\", None)\n    if write_method:\n        method_name = \"__write_{0}__\".format(attribute.attr_name)\n        attribute.write_method_name = method_name\n    else:\n        method_name = attribute.write_method_name\n        write_method = getattr(tango_device_klass, method_name)\n\n    write_attr = _get_wrapped_write_method(attribute, write_method)\n    setattr(tango_device_klass, method_name, write_attr)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\npatching read and write methods for the AttrData object.", "response": "def __patch_attr_methods(tango_device_klass, attribute):\n    \"\"\"\n    Checks if the read and write methods have the correct signature.\n    If a read/write method doesn't have a parameter (the traditional\n    Attribute), then the method is wrapped into another method to make\n    this work.\n\n    :param tango_device_klass: a DeviceImpl class\n    :type tango_device_klass: class\n    :param attribute: the attribute data information\n    :type attribute: AttrData\n    \"\"\"\n    if attribute.attr_write in (AttrWriteType.READ,\n                                AttrWriteType.READ_WRITE):\n        __patch_read_method(tango_device_klass, attribute)\n    if attribute.attr_write in (AttrWriteType.WRITE,\n                                AttrWriteType.READ_WRITE):\n        __patch_write_method(tango_device_klass, attribute)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __patch_pipe_read_method(tango_device_klass, pipe):\n    read_method = getattr(pipe, \"fget\", None)\n    if read_method:\n        method_name = \"__read_{0}__\".format(pipe.pipe_name)\n        pipe.read_method_name = method_name\n    else:\n        method_name = pipe.read_method_name\n        read_method = getattr(tango_device_klass, method_name)\n\n    read_pipe = _get_wrapped_pipe_read_method(pipe, read_method)\n    method_name = \"__read_{0}_wrapper__\".format(pipe.pipe_name)\n    pipe.read_method_name = method_name\n\n    setattr(tango_device_klass, method_name, read_pipe)", "response": "Patch the read method of a given pipe with a new method that is wrapped in another method."}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef __patch_pipe_write_method(tango_device_klass, pipe):\n    write_method = getattr(pipe, \"fset\", None)\n    if write_method:\n        method_name = \"__write_{0}__\".format(pipe.pipe_name)\n        pipe.write_method_name = method_name\n    else:\n        method_name = pipe.write_method_name\n        write_method = getattr(tango_device_klass, method_name)\n\n    write_pipe = _get_wrapped_pipe_write_method(pipe, write_method)\n    setattr(tango_device_klass, method_name, write_pipe)", "response": "Patch the method in a device class with a read or write method."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\npatch the read and write methods of a base class with the correct signature.", "response": "def __patch_pipe_methods(tango_device_klass, pipe):\n    \"\"\"\n    Checks if the read and write methods have the correct signature.\n    If a read/write method doesn't have a parameter (the traditional\n    Pipe), then the method is wrapped into another method to make\n    this work.\n\n    :param tango_device_klass: a DeviceImpl class\n    :type tango_device_klass: class\n    :param pipe: the pipe data information\n    :type pipe: PipeData\n    \"\"\"\n    __patch_pipe_read_method(tango_device_klass, pipe)\n    if pipe.pipe_write == PipeWriteType.PIPE_READ_WRITE:\n        __patch_pipe_write_method(tango_device_klass, pipe)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nreturns tango data if the argument is a tango object False otherwise.", "response": "def is_tango_object(arg):\n    \"\"\"Return tango data if the argument is a tango object,\n    False otherwise.\n    \"\"\"\n    classes = attribute, device_property\n    if isinstance(arg, classes):\n        return arg\n    try:\n        return arg.__tango_command__\n    except AttributeError:\n        return False"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef inheritance_patch(attrs):\n    for key, obj in attrs.items():\n        if isinstance(obj, attribute):\n            if getattr(obj, 'attr_write', None) == AttrWriteType.READ_WRITE:\n                if not getattr(obj, 'fset', None):\n                    method_name = obj.write_method_name or \"write_\" + key\n                    obj.fset = attrs.get(method_name)", "response": "Patch tango objects before they are processed by the metaclass."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef command(f=None, dtype_in=None, dformat_in=None, doc_in=\"\",\n            dtype_out=None, dformat_out=None, doc_out=\"\",\n            display_level=None, polling_period=None,\n            green_mode=None):\n    \"\"\"\n    Declares a new tango command in a :class:`Device`.\n    To be used like a decorator in the methods you want to declare as\n    tango commands. The following example declares commands:\n\n        * `void TurnOn(void)`\n        * `void Ramp(DevDouble current)`\n        * `DevBool Pressurize(DevDouble pressure)`\n\n    ::\n\n        class PowerSupply(Device):\n\n            @command\n            def TurnOn(self):\n                self.info_stream('Turning on the power supply')\n\n            @command(dtype_in=float)\n            def Ramp(self, current):\n                self.info_stream('Ramping on %f...' % current)\n\n            @command(dtype_in=float, doc_in='the pressure to be set',\n                     dtype_out=bool, doc_out='True if it worked, False otherwise')\n            def Pressurize(self, pressure):\n                self.info_stream('Pressurizing to %f...' % pressure)\n                return True\n\n    .. note::\n        avoid using *dformat* parameter. If you need a SPECTRUM\n        attribute of say, boolean type, use instead ``dtype=(bool,)``.\n\n    :param dtype_in:\n        a :ref:`data type <pytango-hlapi-datatypes>` describing the\n        type of parameter. Default is None meaning no parameter.\n    :param dformat_in: parameter data format. Default is None.\n    :type dformat_in: AttrDataFormat\n    :param doc_in: parameter documentation\n    :type doc_in: str\n\n    :param dtype_out:\n        a :ref:`data type <pytango-hlapi-datatypes>` describing the\n        type of return value. Default is None meaning no return value.\n    :param dformat_out: return value data format. Default is None.\n    :type dformat_out: AttrDataFormat\n    :param doc_out: return value documentation\n    :type doc_out: str\n    :param display_level: display level for the command (optional)\n    :type display_level: DispLevel\n    :param polling_period: polling period in milliseconds (optional)\n    :type polling_period: int\n    :param green_mode:\n        set green mode on this specific command. Default value is None meaning\n        use the server green mode. Set it to GreenMode.Synchronous to force\n        a non green command in a green server.\n\n    .. versionadded:: 8.1.7\n        added green_mode option\n\n    .. versionadded:: 9.2.0\n        added display_level and polling_period optional argument\n    \"\"\"\n    if f is None:\n        return functools.partial(\n            command,\n            dtype_in=dtype_in, dformat_in=dformat_in, doc_in=doc_in,\n            dtype_out=dtype_out, dformat_out=dformat_out, doc_out=doc_out,\n            display_level=display_level, polling_period=polling_period,\n            green_mode=green_mode)\n    name = f.__name__\n\n    dtype_format_in = _get_tango_type_format(dtype_in, dformat_in)\n    dtype_format_out = _get_tango_type_format(dtype_out, dformat_out)\n\n    din = [from_typeformat_to_type(*dtype_format_in), doc_in]\n    dout = [from_typeformat_to_type(*dtype_format_out), doc_out]\n\n    config_dict = {}\n    if display_level is not None:\n        config_dict['Display level'] = display_level\n    if polling_period is not None:\n        config_dict['Polling period'] = polling_period\n\n    if green_mode == GreenMode.Synchronous:\n        cmd = f\n    else:\n        @functools.wraps(f)\n        def cmd(self, *args, **kwargs):\n            return get_worker().execute(f, self, *args, **kwargs)\n\n    cmd.__tango_command__ = name, [din, dout, config_dict]\n\n    # try to create a minimalistic __doc__\n    if cmd.__doc__ is None:\n        try:\n            cmd.__doc__ = __build_command_doc(\n                f, name, dtype_in, doc_in, dtype_out, doc_out)\n        except Exception:\n            cmd.__doc__ = \"TANGO command\"\n\n    return cmd", "response": "This function creates a command in a tango module."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nprovides a simple way to run a tango server. It handles exceptions by writting a message to the msg_stream. The `classes` parameter can be either a sequence of: * :class:`~tango.server.Device` or * a sequence of two elements :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl` or * a sequence of three elements :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl`, tango class name (str) or a dictionary where: * key is the tango class name * value is either: * a :class:`~tango.server.Device` class or * a sequence of two elements :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl` or * a sequence of three elements :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl`, tango class name (str) The optional `post_init_callback` can be a callable (without arguments) or a tuple where the first element is the callable, the second is a list of arguments (optional) and the third is a dictionary of keyword arguments (also optional). .. note:: the order of registration of tango classes defines the order tango uses to initialize the corresponding devices. if using a dictionary as argument for classes be aware that the order of registration becomes arbitrary. If you need a predefined order use a sequence or an OrderedDict. Example 1: registering and running a PowerSupply inheriting from :class:`~tango.server.Device`:: from tango.server import Device, DeviceMeta, run class PowerSupply(Device): pass run((PowerSupply,)) Example 2: registering and running a MyServer defined by tango classes `MyServerClass` and `MyServer`:: from tango import Device_4Impl, DeviceClass from tango.server import run class MyServer(Device_4Impl): pass class MyServerClass(DeviceClass): pass run({'MyServer': (MyServerClass, MyServer)}) Example 3: registering and running a MyServer defined by tango classes `MyServerClass` and `MyServer`:: from tango import Device_4Impl, DeviceClass from tango.server import Device, DeviceMeta, run class PowerSupply(Device): pass class MyServer(Device_4Impl): pass class MyServerClass(DeviceClass): pass run([PowerSupply, [MyServerClass, MyServer]]) # or: run({'MyServer': (MyServerClass, MyServer)}) :param classes: a sequence of :class:`~tango.server.Device` classes or a dictionary where keyword is the tango class name and value is a sequence of Tango Device Class python class, and Tango Device python class :type classes: sequence or dict :param args: list of command line arguments [default: None, meaning use sys.argv] :type args: list :param msg_stream: stream where to put messages [default: sys.stdout] :param util: PyTango Util object [default: None meaning create a Util instance] :type util: :class:`~tango.Util` :param event_loop: event_loop callable :type event_loop: callable :param post_init_callback: an optional callback that is executed between the calls Util.server_init and Util.server_run :type post_init_callback: callable or tuple (see description above) :param raises: Disable error handling and propagate exceptions from the server :type raises: bool :return: The Util singleton object :rtype: :class:`~tango.Util` .. versionadded:: 8.1.2 .. versionchanged:: 8.1.4 when classes argument is a sequence, the items can also be a sequence <TangoClass, TangoClassClass>[, tango class name] .. versionchanged:: 9.2.2 `raises` argument has been added", "response": "def run(classes, args=None, msg_stream=sys.stdout,\n        verbose=False, util=None, event_loop=None,\n        post_init_callback=None, green_mode=None,\n        raises=False):\n    \"\"\"\n    Provides a simple way to run a tango server. It handles exceptions\n    by writting a message to the msg_stream.\n\n    The `classes` parameter can be either a sequence of:\n\n    * :class:`~tango.server.Device` or\n    * a sequence of two elements\n      :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl` or\n    * a sequence of three elements\n      :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl`,\n      tango class name (str)\n\n    or a dictionary where:\n\n    * key is the tango class name\n    * value is either:\n        * a :class:`~tango.server.Device` class or\n        * a sequence of two elements\n          :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl`\n          or\n        * a sequence of three elements\n          :class:`~tango.DeviceClass`, :class:`~tango.DeviceImpl`,\n          tango class name (str)\n\n    The optional `post_init_callback` can be a callable (without\n    arguments) or a tuple where the first element is the callable,\n    the second is a list of arguments (optional) and the third is a\n    dictionary of keyword arguments (also optional).\n\n    .. note::\n       the order of registration of tango classes defines the order\n       tango uses to initialize the corresponding devices.\n       if using a dictionary as argument for classes be aware that the\n       order of registration becomes arbitrary. If you need a\n       predefined order use a sequence or an OrderedDict.\n\n    Example 1: registering and running a PowerSupply inheriting from\n    :class:`~tango.server.Device`::\n\n        from tango.server import Device, DeviceMeta, run\n\n        class PowerSupply(Device):\n            pass\n\n        run((PowerSupply,))\n\n    Example 2: registering and running a MyServer defined by tango\n    classes `MyServerClass` and `MyServer`::\n\n        from tango import Device_4Impl, DeviceClass\n        from tango.server import run\n\n        class MyServer(Device_4Impl):\n            pass\n\n        class MyServerClass(DeviceClass):\n            pass\n\n        run({'MyServer': (MyServerClass, MyServer)})\n\n    Example 3: registering and running a MyServer defined by tango\n    classes `MyServerClass` and `MyServer`::\n\n        from tango import Device_4Impl, DeviceClass\n        from tango.server import Device, DeviceMeta, run\n\n        class PowerSupply(Device):\n            pass\n\n        class MyServer(Device_4Impl):\n            pass\n\n        class MyServerClass(DeviceClass):\n            pass\n\n        run([PowerSupply, [MyServerClass, MyServer]])\n        # or: run({'MyServer': (MyServerClass, MyServer)})\n\n    :param classes:\n        a sequence of :class:`~tango.server.Device` classes or\n        a dictionary where keyword is the tango class name and value\n        is a sequence of Tango Device Class python class, and Tango\n        Device python class\n    :type classes: sequence or dict\n\n    :param args:\n        list of command line arguments [default: None, meaning use\n        sys.argv]\n    :type args: list\n\n    :param msg_stream:\n        stream where to put messages [default: sys.stdout]\n\n    :param util:\n        PyTango Util object [default: None meaning create a Util\n        instance]\n    :type util: :class:`~tango.Util`\n\n    :param event_loop: event_loop callable\n    :type event_loop: callable\n\n    :param post_init_callback:\n        an optional callback that is executed between the calls\n        Util.server_init and Util.server_run\n    :type post_init_callback:\n        callable or tuple (see description above)\n\n    :param raises:\n        Disable error handling and propagate exceptions from the server\n    :type raises: bool\n\n    :return: The Util singleton object\n    :rtype: :class:`~tango.Util`\n\n    .. versionadded:: 8.1.2\n\n    .. versionchanged:: 8.1.4\n        when classes argument is a sequence, the items can also be\n        a sequence <TangoClass, TangoClassClass>[, tango class name]\n\n    .. versionchanged:: 9.2.2\n        `raises` argument has been added\n    \"\"\"\n    server_run = functools.partial(\n        __server_run, classes,\n        args=args, msg_stream=msg_stream,\n        util=util, event_loop=event_loop,\n        post_init_callback=post_init_callback,\n        green_mode=green_mode)\n    # Run the server without error handling\n    if raises:\n        return server_run()\n    # Run the server with error handling\n    write = msg_stream.write if msg_stream else lambda msg: None\n    try:\n        return server_run()\n    except KeyboardInterrupt:\n        write(\"Exiting: Keyboard interrupt\\n\")\n    except DevFailed as df:\n        write(\"Exiting: Server exited with tango.DevFailed:\\n\" +\n              str(df) + \"\\n\")\n        if verbose:\n            write(traceback.format_exc())\n    except Exception as e:\n        write(\"Exiting: Server exited with unforseen exception:\\n\" +\n              str(e) + \"\\n\")\n        if verbose:\n            write(traceback.format_exc())\n    write(\"\\nExited\\n\")"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef server_run(classes, args=None, msg_stream=sys.stdout,\n               verbose=False, util=None, event_loop=None,\n               post_init_callback=None, green_mode=None):\n    \"\"\"\n    Since PyTango 8.1.2 it is just an alias to\n    :func:`~tango.server.run`. Use :func:`~tango.server.run`\n    instead.\n\n    .. versionadded:: 8.0.0\n\n    .. versionchanged:: 8.0.3\n        Added `util` keyword parameter.\n        Returns util object\n\n    .. versionchanged:: 8.1.1\n        Changed default msg_stream from *stderr* to *stdout*\n        Added `event_loop` keyword parameter.\n        Returns util object\n\n    .. versionchanged:: 8.1.2\n        Added `post_init_callback` keyword parameter\n\n    .. deprecated:: 8.1.2\n        Use :func:`~tango.server.run` instead.\n\n    \"\"\"\n    return run(classes, args=args, msg_stream=msg_stream,\n               verbose=verbose, util=util, event_loop=event_loop,\n               post_init_callback=post_init_callback,\n               green_mode=green_mode)", "response": "Run a list of classes in the server."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef dyn_attr(self, dev_list):\n\n        for dev in dev_list:\n            init_dyn_attrs = getattr(dev,\n                                     \"initialize_dynamic_attributes\",\n                                     None)\n            if init_dyn_attrs and callable(init_dyn_attrs):\n                try:\n                    init_dyn_attrs()\n                except Exception:\n                    dev.warn_stream(\"Failed to initialize dynamic attributes\")\n                    dev.debug_stream(\"Details: \" + traceback.format_exc())", "response": "Invoked to create dynamic attributes for the given devices."}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nruns the class as a device server.", "response": "def run_server(cls, args=None, **kwargs):\n        \"\"\"Run the class as a device server.\n        It is based on the tango.server.run method.\n\n        The difference is that the device class\n        and server name are automatically given.\n\n        Args:\n            args (iterable): args as given in the tango.server.run method\n                             without the server name. If None, the sys.argv\n                             list is used\n            kwargs: the other keywords argument are as given\n                    in the tango.server.run method.\n        \"\"\"\n        if args is None:\n            args = sys.argv[1:]\n        args = [cls.__name__] + list(args)\n        green_mode = getattr(cls, 'green_mode', None)\n        kwargs.setdefault(\"green_mode\", green_mode)\n        return run((cls,), args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nsets the attribute setter for the object.", "response": "def setter(self, fset):\n        \"\"\"\n        To be used as a decorator. Will define the decorated method\n        as a write attribute method to be called when client writes\n        the attribute\n        \"\"\"\n        self.fset = fset\n        if self.attr_write == AttrWriteType.READ:\n            if getattr(self, 'fget', None):\n                self.attr_write = AttrWriteType.READ_WRITE\n            else:\n                self.attr_write = AttrWriteType.WRITE\n        return self"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef setter(self, fset):\n        self.fset = fset\n        self.pipe_write = PipeWriteType.PIPE_READ_WRITE\n        return self", "response": "Set the pipe method to be called when the client writes to the\n        attribute"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef __prepare(self):\n        self.log.debug(\"prepare\")\n\n        if self.__phase > 0:\n            raise RuntimeError(\"Internal error: Can only prepare in phase 0\")\n\n        server_instance = self.server_instance\n        db = Database()\n\n        # get list of server devices if server was already registered\n        server_registered = server_instance in db.get_server_list()\n\n        if server_registered:\n            dserver_name = \"dserver/{0}\".format(server_instance)\n            if db.import_device(dserver_name).exported:\n                import tango\n                dserver = tango.DeviceProxy(dserver_name)\n                try:\n                    dserver.ping()\n                    raise Exception(\"Server already running\")\n                except:\n                    self.log.info(\"Last time server was not properly \"\n                                  \"shutdown!\")\n            _, db_device_map = self.get_devices()\n        else:\n            db_device_map = {}\n\n        db_devices_add = {}\n\n        # all devices that are registered in database that are not registered\n        # as tango objects or for which the tango class changed will be removed\n        db_devices_remove = set(db_device_map) - set(self.__objects)\n\n        for local_name, local_object in self.__objects.items():\n            local_class_name = local_object.tango_class_name\n            db_class_name = db_device_map.get(local_name)\n            if db_class_name:\n                if local_class_name != db_class_name:\n                    db_devices_remove.add(local_name)\n                    db_devices_add[local_name] = local_object\n            else:\n                db_devices_add[local_name] = local_object\n\n        for device in db_devices_remove:\n            db.delete_device(device)\n            try:\n                db.delete_device_alias(db.get_alias(device))\n            except:\n                pass\n\n        # register devices in database\n\n        # add DServer\n        db_dev_info = DbDevInfo()\n        db_dev_info.server = server_instance\n        db_dev_info._class = \"DServer\"\n        db_dev_info.name = \"dserver/\" + server_instance\n\n        db_dev_infos = [db_dev_info]\n        aliases = []\n        for obj_name, obj in db_devices_add.items():\n            db_dev_info = DbDevInfo()\n            db_dev_info.server = server_instance\n            db_dev_info._class = obj.tango_class_name\n            db_dev_info.name = obj.full_name\n            db_dev_infos.append(db_dev_info)\n            if obj.alias:\n                aliases.append((obj.full_name, obj.alias))\n\n        db.add_server(server_instance, db_dev_infos)\n\n        # add aliases\n        for alias_info in aliases:\n            db.put_device_alias(*alias_info)", "response": "Update database with existing devices"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef get_devices(self):\n        if self.__util is None:\n            import tango\n            db = tango.Database()\n        else:\n            db = self.__util.get_database()\n        server = self.server_instance\n        dev_list = db.get_device_class_list(server)\n        class_map, dev_map = {}, {}\n        for class_name, dev_name in zip(dev_list[1::2], dev_list[::2]):\n            dev_names = class_map.get(class_name)\n            if dev_names is None:\n                class_map[class_name] = dev_names = []\n            dev_name = dev_name.lower()\n            dev_names.append(dev_name)\n            dev_map[dev_name] = class_name\n        return class_map, dev_map", "response": "Helper that returns a dict of devices for this server."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nregistering object with Tango", "response": "def register_object(self, obj, name, tango_class_name=None,\n                        member_filter=None):\n        \"\"\"\n        :param member_filter:\n            callable(obj, tango_class_name, member_name, member) -> bool\n        \"\"\"\n        slash_count = name.count(\"/\")\n        if slash_count == 0:\n            alias = name\n            full_name = \"{0}/{1}\".format(self.server_instance, name)\n        elif slash_count == 2:\n            alias = None\n            full_name = name\n        else:\n            raise ValueError(\"Invalid name\")\n\n        class_name = tango_class_name or obj.__class__.__name__\n        tango_class = self.get_tango_class(class_name)\n\n        if tango_class is None:\n            tango_class = create_tango_class(self, obj, class_name,\n                                             member_filter=member_filter)\n            self.register_tango_class(tango_class)\n\n        tango_object = self.TangoObjectAdapter(self, obj, full_name, alias,\n                                               tango_class_name=class_name)\n        self.__objects[full_name.lower()] = tango_object\n        if self._phase > Server.Phase1:\n            import tango\n            util = tango.Util.instance()\n            util.create_device(class_name, name)\n        return tango_object"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef _set_concurrent_future_state(concurrent, source):\n    assert source.done()\n    if source.cancelled():\n        concurrent.cancel()\n    if not concurrent.set_running_or_notify_cancel():\n        return\n    exception = source.exception()\n    if exception is not None:\n        concurrent.set_exception(exception)\n    else:\n        result = source.result()\n        concurrent.set_result(result)", "response": "Copy state from a future to a concurrent. futures. Future."}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nchains two futures so that when one completes then does the other.", "response": "def _chain_future(source, dest):\n    \"\"\"Chain two futures so that when one completes, so does the other.\n    The result (or exception) of source will be copied to destination.\n    If destination is cancelled, source gets cancelled too.\n    Compatible with both asyncio.Future and concurrent.futures.Future.\n    \"\"\"\n    if not isinstance(source, (asyncio.Future, concurrent.futures.Future)):\n        raise TypeError('A future is required for source argument')\n    if not isinstance(dest, (asyncio.Future, concurrent.futures.Future)):\n        raise TypeError('A future is required for destination argument')\n    source_loop = source._loop if isinstance(source, asyncio.Future) else None\n    dest_loop = dest._loop if isinstance(dest, asyncio.Future) else None\n\n    def _set_state(future, other):\n        if isinstance(future, asyncio.Future):\n            _copy_future_state(other, future)\n        else:\n            _set_concurrent_future_state(future, other)\n\n    def _call_check_cancel(destination):\n        if destination.cancelled():\n            if source_loop is None or source_loop is dest_loop:\n                source.cancel()\n            else:\n                source_loop.call_soon_threadsafe(source.cancel)\n\n    def _call_set_state(source):\n        if dest_loop is None or dest_loop is source_loop:\n            _set_state(dest, source)\n        else:\n            dest_loop.call_soon_threadsafe(_set_state, dest, source)\n\n    dest.add_done_callback(_call_check_cancel)\n    source.add_done_callback(_call_set_state)"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nsubmits a coroutine object to a given event loop.", "response": "def run_coroutine_threadsafe(coro, loop):\n    \"\"\"Submit a coroutine object to a given event loop.\n    Return a concurrent.futures.Future to access the result.\n    \"\"\"\n    if not asyncio.iscoroutine(coro):\n        raise TypeError('A coroutine object is required')\n    future = concurrent.futures.Future()\n\n    def callback():\n        try:\n            _chain_future(asyncio.ensure_future(coro, loop=loop), future)\n        except Exception as exc:\n            if future.set_running_or_notify_cancel():\n                future.set_exception(exc)\n            raise\n\n    loop.call_soon_threadsafe(callback)\n    return future"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef __UserDefaultAttrProp_set_enum_labels(self, enum_labels):\n    elbls = StdStringVector()\n    for enu in enum_labels:\n        elbls.append(enu)\n    return self._set_enum_labels(elbls)", "response": "Set default enumeration labels."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn the given operation as a gevent future.", "response": "def delegate(self, fn, *args, **kwargs):\n        \"\"\"Return the given operation as a gevent future.\"\"\"\n        return self.subexecutor.spawn(fn, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nexecute an operation and return the result.", "response": "def execute(self, fn, *args, **kwargs):\n        \"\"\"Execute an operation and return the result.\"\"\"\n        if self.in_executor_context():\n            return fn(*args, **kwargs)\n        task = self.submit(fn, *args, **kwargs)\n        return task.result()"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconnect a signal to a slot.", "response": "def connect(obj, signal, slot, event_type=tango.EventType.CHANGE_EVENT):\n    \"\"\"Experimental function. Not part of the official API\"\"\"\n    return obj._helper.connect(signal, slot, event_type=event_type)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef get_readme(name='README.rst'):\n    with open(name) as f:\n        return '\\n'.join(\n            line for line in f.read().splitlines()\n            if not line.startswith('|') or not line.endswith('|'))", "response": "Get the contents of a readme file without the badges."}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __create_command(self, deviceimpl_class, cmd_name, cmd_info):\n    name = self.get_name()\n\n    # check for well defined command info\n\n    # check parameter\n    if not isinstance(cmd_info, collections_abc.Sequence):\n        msg = \"Wrong data type for value for describing command %s in \" \\\n              \"class %s\\nMust be a sequence with 2 or 3 elements\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    if len(cmd_info) < 2 or len(cmd_info) > 3:\n        msg = \"Wrong number of argument for describing command %s in \" \\\n              \"class %s\\nMust be a sequence with 2 or 3 elements\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    param_info, result_info = cmd_info[0], cmd_info[1]\n\n    if not isinstance(param_info, collections_abc.Sequence):\n        msg = \"Wrong data type in command argument for command %s in \" \\\n              \"class %s\\nCommand parameter (first element) must be a sequence\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    if len(param_info) < 1 or len(param_info) > 2:\n        msg = \"Wrong data type in command argument for command %s in \" \\\n              \"class %s\\nSequence describing command parameters must contain \" \\\n              \"1 or 2 elements\"\n        __throw_create_command_exception(msg)\n\n    param_type = CmdArgType.DevVoid\n    try:\n        param_type = CmdArgType(param_info[0])\n    except:\n        msg = \"Wrong data type in command argument for command %s in \" \\\n              \"class %s\\nCommand parameter type (first element in first \" \\\n              \"sequence) must be a tango.CmdArgType\"\n        __throw_create_command_exception(msg)\n\n    param_desc = \"\"\n    if len(param_info) > 1:\n        param_desc = param_info[1]\n        if not is_pure_str(param_desc):\n            msg = \"Wrong data type in command parameter for command %s in \" \\\n                  \"class %s\\nCommand parameter description (second element \" \\\n                  \"in first sequence), when given, must be a string\"\n            __throw_create_command_exception(msg)\n\n    # Check result\n    if not isinstance(result_info, collections_abc.Sequence):\n        msg = \"Wrong data type in command result for command %s in \" \\\n              \"class %s\\nCommand result (second element) must be a sequence\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    if len(result_info) < 1 or len(result_info) > 2:\n        msg = \"Wrong data type in command result for command %s in \" \\\n              \"class %s\\nSequence describing command result must contain \" \\\n              \"1 or 2 elements\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    result_type = CmdArgType.DevVoid\n    try:\n        result_type = CmdArgType(result_info[0])\n    except:\n        msg = \"Wrong data type in command result for command %s in \" \\\n              \"class %s\\nCommand result type (first element in second \" \\\n              \"sequence) must be a tango.CmdArgType\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    result_desc = \"\"\n    if len(result_info) > 1:\n        result_desc = result_info[1]\n        if not is_pure_str(result_desc):\n            msg = \"Wrong data type in command result for command %s in \" \\\n                  \"class %s\\nCommand parameter description (second element \" \\\n                  \"in second sequence), when given, must be a string\" % (cmd_name, name)\n            __throw_create_command_exception(msg)\n\n    # If it is defined, get addictional dictionnary used for optional parameters\n    display_level, default_command, polling_period = DispLevel.OPERATOR, False, -1\n\n    if len(cmd_info) == 3:\n        extra_info = cmd_info[2]\n        if not isinstance(extra_info, collections_abc.Mapping):\n            msg = \"Wrong data type in command information for command %s in \" \\\n                  \"class %s\\nCommand information (third element in sequence), \" \\\n                  \"when given, must be a dictionary\" % (cmd_name, name)\n            __throw_create_command_exception(msg)\n\n        if len(extra_info) > 3:\n            msg = \"Wrong data type in command information for command %s in \" \\\n                  \"class %s\\nThe optional dictionary can not have more than \" \\\n                  \"three elements\" % (cmd_name, name)\n            __throw_create_command_exception(msg)\n\n        for info_name, info_value in extra_info.items():\n            info_name_lower = info_name.lower()\n            if info_name_lower == \"display level\":\n                try:\n                    display_level = DispLevel(info_value)\n                except:\n                    msg = \"Wrong data type in command information for command %s in \" \\\n                          \"class %s\\nCommand information for display level is not a \" \\\n                          \"tango.DispLevel\" % (cmd_name, name)\n                    __throw_create_command_exception(msg)\n            elif info_name_lower == \"default command\":\n                if not is_pure_str(info_value):\n                    msg = \"Wrong data type in command information for command %s in \" \\\n                          \"class %s\\nCommand information for default command is not a \" \\\n                          \"string\" % (cmd_name, name)\n                    __throw_create_command_exception(msg)\n                v = info_value.lower()\n                default_command = v == 'true'\n            elif info_name_lower == \"polling period\":\n                try:\n                    polling_period = int(info_value)\n                except:\n                    msg = \"Wrong data type in command information for command %s in \" \\\n                          \"class %s\\nCommand information for polling period is not an \" \\\n                          \"integer\" % (cmd_name, name)\n                    __throw_create_command_exception(msg)\n            else:\n                msg = \"Wrong data type in command information for command %s in \" \\\n                      \"class %s\\nCommand information has unknown key \" \\\n                      \"%s\" % (cmd_name, name, info_name)\n                __throw_create_command_exception(msg)\n\n    # check that the method to be executed exists\n    try:\n        cmd = getattr(deviceimpl_class, cmd_name)\n        if not isinstance(cmd, collections_abc.Callable):\n            msg = \"Wrong definition of command %s in \" \\\n                  \"class %s\\nThe object exists in class but is not \" \\\n                  \"a method!\" % (cmd_name, name)\n            __throw_create_command_exception(msg)\n    except AttributeError:\n        msg = \"Wrong definition of command %s in \" \\\n              \"class %s\\nThe command method does not exist!\" % (cmd_name, name)\n        __throw_create_command_exception(msg)\n\n    is_allowed_name = \"is_%s_allowed\" % cmd_name\n    try:\n        is_allowed = getattr(deviceimpl_class, is_allowed_name)\n        if not isinstance(is_allowed, collections_abc.Callable):\n            msg = \"Wrong definition of command %s in \" \\\n                  \"class %s\\nThe object '%s' exists in class but is \" \\\n                  \"not a method!\" % (cmd_name, name, is_allowed_name)\n            __throw_create_command_exception(msg)\n    except:\n        is_allowed_name = \"\"\n\n    self._create_command(cmd_name, param_type, result_type,\n                         param_desc, result_desc,\n                         display_level, default_command,\n                         polling_period, is_allowed_name)", "response": "Create a command from command info."}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nsets the default values of the properties of the class object and the device object.", "response": "def set_default_property_values(self, dev_class, class_prop, dev_prop):\n        \"\"\"\n            set_default_property_values(self, dev_class, class_prop, dev_prop) -> None\n\n                Sets the default property values\n\n            Parameters :\n                - dev_class : (DeviceClass) device class object\n                - class_prop : (dict<str,>) class properties\n                - dev_prop : (dict<str,>) device properties\n\n            Return     : None\n        \"\"\"\n        for name in class_prop:\n            type = self.get_property_type(name, class_prop)\n            val = self.get_property_values(name, class_prop)\n            val = self.values2string(val, type)\n            desc = self.get_property_description(name, class_prop)\n            dev_class.add_wiz_class_prop(name, desc, val)\n\n        for name in dev_prop:\n            type = self.get_property_type(name, dev_prop)\n            val = self.get_property_values(name, dev_prop)\n            val = self.values2string(val, type)\n            desc = self.get_property_description(name, dev_prop)\n            dev_class.add_wiz_dev_prop(name, desc, val)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef get_class_properties(self, dev_class, class_prop):\n        # initialize default values\n        if class_prop == {} or not Util._UseDb:\n            return\n\n        # call database to get properties\n        props = self.db.get_class_property(dev_class.get_name(), list(class_prop.keys()))\n\n        # if value defined in database, store it\n        for name in class_prop:\n            if props[name]:\n                type = self.get_property_type(name, class_prop)\n                values = self.stringArray2values(props[name], type)\n                self.set_property_values(name, class_prop, values)\n            else:\n                print(name + \" property NOT found in database\")", "response": "This function returns the class properties of the object that are defined in the database."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef get_device_properties(self, dev, class_prop, dev_prop):\n        #    initialize default properties\n        if dev_prop == {} or not Util._UseDb:\n            return\n\n        # Call database to get properties\n        props = self.db.get_device_property(dev.get_name(), list(dev_prop.keys()))\n        #    if value defined in database, store it\n        for name in dev_prop:\n            prop_value = props[name]\n            if len(prop_value):\n                data_type = self.get_property_type(name, dev_prop)\n                values = self.stringArray2values(prop_value, data_type)\n                if not self.is_empty_seq(values):\n                    self.set_property_values(name, dev_prop, values)\n                else:\n                    #    Try to get it from class property\n                    values = self.get_property_values(name, class_prop)\n                    if not self.is_empty_seq(values):\n                        if not self.is_seq(values):\n                            values = [values]\n                        data_type = self.get_property_type(name, class_prop)\n                        values = self.stringArray2values(values, data_type)\n                        if not self.is_empty_seq(values):\n                            self.set_property_values(name, dev_prop, values)\n            else:\n                #    Try to get it from class property\n                values = self.get_property_values(name, class_prop)\n                if not self.is_empty_seq(values):\n                    if not self.is_seq(values):\n                        values = [values]\n                    data_type = self.get_property_type(name, class_prop)\n                    values = self.stringArray2values(values, data_type)\n                    if not self.is_empty_seq(values):\n                        self.set_property_values(name, dev_prop, values)", "response": "This function returns the properties of the specified device object and class properties."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef get_property_values(self, prop_name, properties):\n        try:\n            tg_type = self.get_property_type(prop_name, properties)\n            val = properties[prop_name][2]\n        except:\n            val = []\n\n        if is_array(tg_type) or (isinstance(val, collections_abc.Sequence) and not len(val)):\n            return val\n        else:\n            if is_non_str_seq(val):\n                return val[0]\n            else:\n                return val", "response": "Gets the value of the given property name in the given properties."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DbExportDevice(self, argin):\n    self._log.debug(\"In DbExportDevice()\")\n    if len(argin) < 5:\n        self.warn_stream(\"DataBase::DbExportDevice(): insufficient export info for device \")\n        th_exc(DB_IncorrectArguments,\n               \"insufficient export info for device\",\n               \"DataBase::ExportDevice()\")\n\n    dev_name, IOR, host, pid, version = argin[:5]\n    dev_name = dev_name.lower()\n    if pid.lower() == 'null':\n        pid = \"-1\"\n    self.db.export_device(dev_name, IOR, host, pid, version)", "response": "Export a device to the database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nrunning the Database DS as a standalone database.", "response": "def __run(db_name,argv):\n    \"\"\"\n    Runs the Database DS as a standalone database. Run it with::\n\n        ./DataBaseds pydb-test -ORBendPoint giop:tcp::11000\n    \"\"\"\n    tango.Util.set_use_db(False)\n    util = tango.Util(argv)\n    __monkey_patch_util(util)\n    __monkey_patch_database_class()\n\n    dbi = DbInter()\n    util.set_interceptors(dbi)\n\n    def post_init_cb():\n        logging.debug(\"post_init_cb()\")\n        util = tango.Util.instance()\n        dserver = util.get_dserver_device()\n        dserver_name = dserver.get_name()\n        dserver_ior = util.get_dserver_ior(dserver)\n        dbase = util.get_device_by_name(db_name)\n        dbase_name = dbase.get_name()\n        dbase_ior = util.get_device_ior(dbase)\n        host = util.get_host_name()\n        pid = util.get_pid_str()\n        version = util.get_version_str()\n        DbExportDevice(dbase, [dserver_name, dserver_ior, host, pid, version])\n        DbExportDevice(dbase, [dbase_name, dbase_ior, host, pid, version])\n\n    run((DataBase,), args=argv, util=util, post_init_callback=post_init_cb,\n        green_mode=GreenMode.Gevent, verbose=True)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef __run_embedded(db_name,argv):\n    __monkey_patch_database_class()\n\n    run((DataBase,), args=argv, util=util, green_mode=GreenMode.Gevent)", "response": "Runs the Database object embeded in another TANGO Database object"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\ngets a list of device name domains matching the specified wildcard", "response": "def DbGetDeviceDomainList(self, argin):\n        \"\"\" Get list of device domain name matching the specified\n\n        :param argin: The wildcard\n        :type: tango.DevString\n        :return: Device name domain list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceDomainList()\")\n        return self.db.get_device_domain_list(replace_wildcard(argin))"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DbUnExportServer(self, argin):\n        self._log.debug(\"In DbUnExportServer()\")\n        self.db.unexport_server(argin)", "response": "Mark all devices belonging to a specified server as non exported"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes all device attribute properties for the specified device name", "response": "def DbDeleteAllDeviceAttributeProperty(self, argin):\n        \"\"\" Delete all attribute properties for the specified device attribute(s)\n\n        :param argin: str[0] = device name\n        Str[1]...str[n] = attribute name(s)\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbDeleteAllDeviceAttributeProperty()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::DbDeleteAllDeviceAttributeProperty(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to delete all device attribute(s) property\",\n                   \"DataBase::DbDeleteAllDeviceAttributeProperty()\")\n\n        dev_name = argin[0]\n\n        ret, d_name, dfm = check_device_name(dev_name)\n\n        if not ret:\n            th_exc(DB_IncorrectDeviceName,\n                  \"device name (\" + argin + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                  \"DataBase::DbDeleteAllDeviceAttributeProperty()\")\n\n        self.db.delete_all_device_attribute_property(dev_name, argin[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DbDeleteAttributeAlias(self, argin):\n        self._log.debug(\"In DbDeleteAttributeAlias()\")\n        self.db.delete_attribute_alias(argin)", "response": "Delete an attribute alias."}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DbGetClassAttributePropertyHist(self, argin):\n        self._log.debug(\"In DbGetClassAttributePropertyHist()\")\n        class_name = argin[0]\n        attribute = replace_wildcard(argin[1])\n        prop_name = replace_wildcard(argin[2])\n        return self.db.get_class_attribute_property_hist(class_name, attribute, prop_name)", "response": "Retrieve Tango class attribute property history"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbPutDeviceAttributeProperty2(self, argin):\n        self._log.debug(\"In DbPutDeviceAttributeProperty2()\")\n        device_name = argin[0]\n        nb_attributes = int(argin[1])\n        self.db.put_device_attribute_property2(device_name, nb_attributes, argin[2:])", "response": "Put device attribute property."}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nget the list of attribute aliases that match the specified filter", "response": "def DbGetAttributeAliasList(self, argin):\n        \"\"\" Get attribute alias list for a specified filter\n\n        :param argin: attribute alias filter string (eg: att*)\n        :type: tango.DevString\n        :return: attribute aliases\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetAttributeAliasList()\")\n        if not argin:\n            argin = \"%\"\n        else:\n            argin = replace_wildcard(argin)\n        return self.db.get_attribute_alias_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DbGetExportdDeviceListForClass(self, argin):\n        self._log.debug(\"In DbGetExportdDeviceListForClass()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_exported_device_list_for_class(argin)", "response": "Query the database for the list of exported devices for the specified class."}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\ndefine an alias for an attribute", "response": "def DbPutAttributeAlias(self, argin):\n        \"\"\" Define an alias for an attribute\n\n        :param argin: Str[0] = attribute name\n        Str[1] = attribute alias\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutAttributeAlias()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::DbPutAttributeAlias(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to put attribute alias\",\n                   \"DataBase::DbPutAttributeAlias()\")\n\n        attribute_name = argin[0]\n        attribute_alias = argin[1]\n        self.db.put_attribute_alias(attribute_name, attribute_alias)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DbGetServerList(self, argin):\n        self._log.debug(\"In DbGetServerList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_server_list(argin)", "response": "Get list of device server process names matching the specified filter"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbDeleteDeviceAttributeProperty(self, argin):\n        self._log.debug(\"In DbDeleteDeviceAttributeProperty()\")\n\n        if len(argin) < 3:\n            self.warn_stream(\"DataBase::db_delete_device_attribute_property(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to delete device attribute property\",\n                   \"DataBase::DeleteDeviceAttributeProperty()\")\n\n        dev_name, attr_name = argin[:2]\n\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            self.warn_stream(\"DataBase::db_delete_device_attribute_property(): device name \" + argin + \" incorrect \")\n            th_exc(DB_IncorrectDeviceName,\n                   \"failed to delete device attribute property, device name incorrect\",\n                   \"DataBase::DeleteDeviceAttributeProperty()\")\n\n        for prop_name in argin[2:]:\n            self.db.delete_device_attribute_property(dev_name, attr_name, prop_name)", "response": "delete a device attribute property from the database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting a list of device name families matching the specified wildcard", "response": "def DbGetDeviceFamilyList(self, argin):\n        \"\"\" Get a list of device name families for device name matching the\n        specified wildcard\n\n        :param argin: The wildcard\n        :type: tango.DevString\n        :return: Family list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceFamilyList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_device_family_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\ngetting a list of devices whose names satisfy the filter.", "response": "def DbGetDeviceWideList(self, argin):\n        \"\"\" Get a list of devices whose names satisfy the filter.\n\n        :param argin: filter\n        :type: tango.DevString\n        :return: list of exported devices\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceWideList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_device_wide_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\nupdating free object property", "response": "def DbPutProperty(self, argin):\n        \"\"\" Create / Update free object property(ies)\n\n        :param argin: Str[0] = Object name\n        Str[1] = Property number\n        Str[2] = Property name\n        Str[3] = Property value number\n        Str[4] = Property value 1\n        Str[n] = Property value n\n        ....\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutProperty()\")\n        object_name = argin[0]\n        nb_properties = int(argin[1])\n        self.db.put_property(object_name, properties, argin[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DbDeleteProperty(self, argin):\n        self._log.debug(\"In DbDeleteProperty()\")\n        obj_name = argin[0]\n        for prop_name in argin[1:]:\n            self.db.delete_property(obj_name, prop_name)", "response": "Delete free property from database"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting a list of exported devices whose names satisfy the filter", "response": "def DbGetDeviceExportedList(self, argin):\n        \"\"\" Get a list of exported devices whose names satisfy the filter (wildcard is\n\n        :param argin: filter\n        :type: tango.DevString\n        :return: list of exported devices\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceExportedList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_device_exported_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nget alias for a device name if found.", "response": "def DbGetDeviceAlias(self, argin):\n        \"\"\" Return alias for device name if found.\n\n        :param argin: The device name\n        :type: tango.DevString\n        :return: The alias found\n        :rtype: tango.DevString \"\"\"\n        self._log.debug(\"In DbGetDeviceAlias()\")\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            th_exc(DB_IncorrectDeviceName,\n                  \"device name (\" + argin + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                  \"DataBase::DbGetDeviceAlias()\")\n\n        return self.db.get_device_alias(dev_name)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate class attribute property in database", "response": "def DbPutClassAttributeProperty(self, argin):\n        \"\"\" Create/Update class attribute property(ies) in database\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Attribute number\n        Str[2] = Attribute name\n        Str[3] = Property number\n        Str[4] = Property name\n        Str[5] = Property value\n        .....\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutClassAttributeProperty()\")\n        class_name = argin[0]\n        nb_attributes = int(argin[1])\n        self.db.put_class_attribute_property(class_name, nb_attributes, argin[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbGetClassPropertyList(self, argin):\n        self._log.debug(\"In DbGetClassPropertyList()\")\n        if not argin:\n            argin = \"%\"\n        else:\n            argin = replace_wildcard(argin)\n        return self.db.get_class_property_list(argin)", "response": "Get property list for a Tango class with a specified filter"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DbGetDeviceAliasList(self, argin):\n        self._log.debug(\"In DbGetDeviceAliasList()\")\n        if not argin:\n            argin = \"%\"\n        else:\n            argin = replace_wildcard(argin)\n\n        return self.db.get_device_alias_list(argin)", "response": "Get the list of device alias names with a specific filter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ndeleting a class attribute and all its properties from database", "response": "def DbDeleteClassAttribute(self, argin):\n        \"\"\" delete a class attribute and all its properties from database\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Attribute name\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbDeleteClassAttribute()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::db_delete_class_attribute(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to delete class attribute\",\n                   \"DataBase::DeleteClassAttribute()\")\n\n        klass_name, attr_name = argin[:2]\n\n        self.db.delete_class_attribute(klass_name, attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nretrieves Tango class property history", "response": "def DbGetClassPropertyHist(self, argin):\n        \"\"\" Retrieve Tango class property history\n\n        :param argin: Str[0] = Tango class\n        Str[1] = Property name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Property name\n        Str[1] = date\n        Str[2] = Property value number (array case)\n        Str[3] = Property value 1\n        Str[n] = Property value n\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetClassPropertyHist()\")\n        class_name = argin[0]\n        prop_name = argin[1]\n        return self.db.get_class_property_hist(class_name, prop_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\ndelete a device attribute from database", "response": "def DbDeleteDeviceAttribute(self, argin):\n        \"\"\" Delete  device attribute properties from database\n\n        :param argin: Str[0] = Device name\n        Str[1] = Attribute name\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbDeleteDeviceAttribute()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::db_delete_device_attribute(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to delete device attribute\",\n                   \"DataBase::DeleteDeviceAttribute()\")\n\n        dev_name, attr_name = argin[:2]\n\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            self.warn_stream(\"DataBase::db_delete_device_attribute(): device name \" + argin + \" incorrect \")\n            th_exc(DB_IncorrectDeviceName,\n                   \"failed to delete device attribute, device name incorrect\",\n                   \"DataBase::DeleteDeviceAttribute()\")\n\n        self.db.delete_device_attribute(dev_name, attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbMySqlSelect(self, argin):\n        self._log.debug(\"In DbMySqlSelect()\")\n        tmp_argin = argin.lower()\n\n        #  Check if SELECT key is alread inside command\n\n        cmd = argin\n        tmp_argin = argin.lower()\n        pos = tmp_argin.find('select')\n        if pos == -1:\n            cmd = \"SELECT \" + cmd\n\n        pos = tmp_argin.find(';')\n        if pos != -1 and len(tmp_argin) > (pos + 1):\n            th_exc(DB_IncorrectArguments,\n                   \"SQL command not valid: \" + argin,\n                   \"DataBase::ExportDevice()\")\n        return self.db.my_sql_select(cmd)", "response": "This function executes a SELECT command on the specified Tango device and returns its result without filter"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nupdate the property of the specified device attribute", "response": "def DbPutDeviceAttributeProperty(self, argin):\n        \"\"\" Create/Update device attribute property(ies) in database\n\n        :param argin: Str[0] = Device name\n        Str[1] = Attribute number\n        Str[2] = Attribute name\n        Str[3] = Property number\n        Str[4] = Property name\n        Str[5] = Property value\n        .....\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutDeviceAttributeProperty()\")\n        device_name = argin[0]\n        nb_attributes = int(argin[1])\n        self.db.put_device_attribute_property(device_name, nb_attributes, argin[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets device attribute property", "response": "def DbGetDeviceAttributeProperty(self, argin):\n        \"\"\" Get device attribute property(ies) value\n\n        :param argin: Str[0] = Device name\n        Str[1] = Attribute name\n        Str[n] = Attribute name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Device name\n        Str[1] = Attribute property  number\n        Str[2] = Attribute property 1 name\n        Str[3] = Attribute property 1 value\n        Str[n + 1] = Attribute property 2 name\n        Str[n + 2] = Attribute property 2 value\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceAttributeProperty()\")\n        dev_name = argin[0]\n        return self.db.get_device_attribute_property(dev_name, argin[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget list of properties defined for a free object and matching the filter", "response": "def DbGetPropertyList(self, argin):\n        \"\"\" Get list of property defined for a free object and matching the\n        specified filter\n\n        :param argin: Str[0] = Object name\n        Str[1] = filter\n        :type: tango.DevVarStringArray\n        :return: Property name list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetPropertyList()\")\n        object_name = argin[0]\n        wildcard = replace_wildcard(argin[1])\n        return self.db.get_property_list(object_name, wildcard)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget Tango classes and device list embedded in a specific device server process", "response": "def DbGetDeviceClassList(self, argin):\n        \"\"\" Get Tango classes/device list embedded in a specific device server\n\n        :param argin: Device server process name\n        :type: tango.DevString\n        :return: Str[0] = Device name\n        Str[1] = Tango class\n        Str[n] = Device name\n        Str[n + 1] = Tango class\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceClassList()\")\n        return self.db.get_device_class_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nmark a device as non exported in database", "response": "def DbUnExportDevice(self, argin):\n        \"\"\" Mark a device as non exported in database\n\n        :param argin: Device name\n        :type: tango.DevString\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbUnExportDevice()\")\n        dev_name = argin[0].lower()\n        self.db.unexport_device(dev_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbGetAliasDevice(self, argin):\n        self._log.debug(\"In DbGetAliasDevice()\")\n        if not argin:\n            argin = \"%\"\n        else:\n            argin = replace_wildcard(argin)\n        return self.db.get_alias_device(argin)", "response": "Get alias device name from its alias"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DbDeleteDevice(self, argin):\n        self._log.debug(\"In DbDeleteDevice()\")\n\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            self.warn_stream(\"DataBase::db_delete_device(): device name \" + argin + \" incorrect \")\n            th_exc(DB_IncorrectDeviceName,\n                   \"failed to delete device, device name incorrect\",\n                   \"DataBase::DeleteDevice()\")\n        self.db.delete_device(dev_name)", "response": "Delete a device from database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting the list of attributes matching the specified wildcard", "response": "def DbGetDeviceAttributeList(self, argin):\n        \"\"\" Return list of attributes matching the wildcard\n         for the specified device\n\n        :param argin: Str[0] = Device name\n        Str[1] = Wildcard\n        :type: tango.DevVarStringArray\n        :return: attribute name list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceAttributeList()\")\n        dev_name = argin[0]\n        wildcard = argin[1]\n        if not wildcard:\n            wildcard = \"%\"\n        else:\n            wildcard = replace_wildcard(wildcard)\n        return self.db.get_device_attribute_list(dev_name, wildcard)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting info about all servers running on the specified host", "response": "def DbGetHostServersInfo(self, argin):\n        \"\"\" Get info about all servers running on specified host, name, mode and level\n\n        :param argin: Host name\n        :type: tango.DevString\n        :return: Server info for all servers running on specified host\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetHostServersInfo()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_host_servers_info(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nrenaming a device server", "response": "def DbRenameServer(self, argin):\n        \"\"\" Rename a device server process\n\n        :param argin: str[0] = old device server name (exec/instance)\n        str[1] =  new device server name (exec/instance)\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbRenameServer()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::DbRenameServer(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments (two required: old name and new name\",\n                   \"DataBase::DbRenameServer\")\n\n        old_name = argin[0]\n        new_name = argin[1]\n\n        if ('/' not in argin[0]) or ('/' not in argin[1]):\n            self.warn_stream(\"DataBase::DbRenameServer(): wrong syntax in command args \")\n            th_exc(DB_IncorrectArguments,\n                   \"Wrong syntax in command args (ds_exec_name/inst_name)\",\n                   \"DataBase::DbRenameServer\")\n\n        self.db.rename_server(old_name, new_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DbGetHostList(self, argin):\n        self._log.debug(\"In DbGetHostList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_host_list(argin)", "response": "Get the host list with name matching the specified filter"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DbGetClassInheritanceForDevice(self, argin):\n        self._log.debug(\"In DbGetClassInheritanceForDevice()\")\n        return self.db.get_class_inheritance_for_device(argin)", "response": "Get class inheritance for a device"}
{"SOURCE": "codesearchnet", "instruction": "Here you have a function in Python 3, explain what it does\ndef DbDeleteServer(self, argin):\n        self._log.debug(\"In DbDeleteServer()\")\n\n        if '*' in argin or '%' in argin or not '/' in argin:\n            self.warn_stream(\"DataBase::db_delete_server(): server name \" + argin + \" incorrect \")\n            th_exc(DB_IncorrectServerName,\n                   \"failed to delete server, server name incorrect\",\n                   \"DataBase::DeleteServer()\")\n\n        self.db.delete_server(argin)", "response": "Delete server from the database but dont delete device properties"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DbGetAttributeAlias(self, argin):\n        self._log.debug(\"In DbGetAttributeAlias()\")\n        return self.db.get_attribute_alias(argin)", "response": "Get the attribute name for the given alias"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DbGetProperty(self, argin):\n        self._log.debug(\"In DbGetProperty()\")\n        object_name = argin[0]\n        return self.db.get_property(object_name, argin[1:])", "response": "Get free object property"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nget list of Tango classes for a device server process name", "response": "def DbGetDeviceServerClassList(self, argin):\n        \"\"\" Get list of Tango classes for a device server\n\n        :param argin: device server process name\n        :type: tango.DevString\n        :return: list of classes for this device server\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceServerClassList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_server_class_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nupdates the properties of a specific device", "response": "def DbPutDeviceProperty(self, argin):\n        \"\"\" Create / Update device property(ies)\n\n        :param argin: Str[0] = Tango device name\n        Str[1] = Property number\n        Str[2] = Property name\n        Str[3] = Property value number\n        Str[4] = Property value 1\n        Str[n] = Property value n\n        ....\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutDeviceProperty()\")\n        device_name = argin[0]\n        nb_properties = int(argin[1])\n        self.db.put_device_property(device_name, nb_properties, argin[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function to\nreset the timing values for the specified resource.", "response": "def ResetTimingValues(self):\n        \"\"\" Reset the timing attribute values.\n\n        :param :\n        :type: tango.DevVoid\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In ResetTimingValues()\")\n        for tmp_timing in self.timing_maps.itervalues():\n            tmp_timing.average = 0.\n            tmp_timing.minimum = 0.\n            tmp_timing.maximum = 0.\n            tmp_timing.total_elapsed = 0.\n            tmp_timing.calls = 0."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\ncreate / Update class property(ies) :param argin: Str[0] = Tango class name Str[1] = Property number Str[2] = Property name Str[3] = Property value number Str[4] = Property value 1 Str[n] = Property value n .... :type: tango.DevVarStringArray :return: :rtype: tango.DevVoid", "response": "def DbPutClassProperty(self, argin):\n        \"\"\" Create / Update class property(ies)\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Property number\n        Str[2] = Property name\n        Str[3] = Property value number\n        Str[4] = Property value 1\n        Str[n] = Property value n\n        ....\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutClassProperty()\")\n        class_name = argin[0]\n        nb_properties = int(argin[1])\n        self.db.put_class_property(class_name, nb_properties, argin[2:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbImportDevice(self, argin):\n        self._log.debug(\"In DbImportDevice()\")\n        return self.db.import_device(argin.lower())", "response": "Import a device from the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ndeletes device property(ies) :param argin: Str[0] = Device name Str[1] = Property name Str[n] = Property name :type: tango.DevVarStringArray :return: :rtype: tango.DevVoid", "response": "def DbDeleteDeviceProperty(self, argin):\n        \"\"\" Delete device property(ies)\n\n        :param argin: Str[0] = Device name\n        Str[1] = Property name\n        Str[n] = Property name\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbDeleteDeviceProperty()\")\n        dev_name = argin[0]\n        for prop_name in argin[1:]:\n            self.db.delete_device_property(dev_name, prop_name)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\ngetting Tango class for a device.", "response": "def DbGetClassForDevice(self, argin):\n        \"\"\" Get Tango class for the specified device.\n\n        :param argin: Device name\n        :type: tango.DevString\n        :return: Device Tango class\n        :rtype: tango.DevString \"\"\"\n        self._log.debug(\"In DbGetClassForDevice()\")\n        return self.db.get_class_for_device(argin)"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nretrieve device attribute property history", "response": "def DbGetDeviceAttributePropertyHist(self, argin):\n        \"\"\" Retrieve device attribute property history\n\n        :param argin: Str[0] = Device name\n        Str[1] = Attribute name\n        Str[2] = Property name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Attribute name\n        Str[1] = Property name\n        Str[2] = date\n        Str[3] = Property value number (array case)\n        Str[4] = Property value 1\n        Str[n] = Property value n\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceAttributePropertyHist()\")\n        dev_name = argin[0]\n        attribute = replace_wildcard(argin[1])\n        prop_name = replace_wildcard(argin[2])\n        return self.db.get_device_attribute_property_hist(dev_name, attribute, prop_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbGetServerInfo(self, argin):\n        self._log.debug(\"In DbGetServerInfo()\")\n        return self.db.get_server_info(argin)", "response": "Get info about the server with the specified name"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DbPutDeviceAlias(self, argin):\n        self._log.debug(\"In DbPutDeviceAlias()\")\n\n        if len(argin) < 2:\n            self.warn_stream(\"DataBase::DbPutDeviceAlias(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to put device alias\",\n                   \"DataBase::DbPutDeviceAlias()\")\n\n        device_name = argin[0]\n        device_alias = argin[1]\n        self.db.put_device_alias(device_name, device_alias)", "response": "Define alias for a given device name"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbGetDevicePropertyList(self, argin):\n        self._log.debug(\"In DbGetDevicePropertyList()\")\n        device_name = argin[0]\n        prop_filter = argin[1]\n        prop_filter = replace_wildcard(prop_filter)\n        return self.db.get_device_property_list(device_name, prop_filter)", "response": "Get property list belonging to the specified device and with the specified filter"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget list of device server process name running on host with name matching the specified filter", "response": "def DbGetHostServerList(self, argin):\n        \"\"\" Get list of device server process name running on host with name matching\n        the specified filter\n\n        :param argin: The filter\n        :type: tango.DevString\n        :return: Device server process name list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetHostServerList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_host_server_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef DbGetObjectList(self, argin):\n        self._log.debug(\"In DbGetObjectList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_object_list(argin)", "response": "Get list of free object names matching the specified filter"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DbDeleteClassAttributeProperty(self, argin):\n        self._log.debug(\"In DbDeleteClassAttributeProperty()\")\n\n        if len(argin) < 3:\n            self.warn_stream(\"DataBase::db_delete_class_attribute_property(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient number of arguments to delete class attribute property\",\n                   \"DataBase::DeleteClassAttributeProperty()\")\n\n        klass_name, attr_name = argin[:2]\n\n        for prop_name in argin[2:]:\n            self.db.delete_class_attribute_property(klass_name, attr_name, prop_name)", "response": "delete class attribute properties from database"}
{"SOURCE": "codesearchnet", "instruction": "How would you implement a function in Python 3 that\nreturns the instance names found for the specified server.", "response": "def DbGetInstanceNameList(self, argin):\n        \"\"\" Returns the instance names found for specified server.\n\n        :param argin: Server name\n        :type: tango.DevString\n        :return: The instance names found for specified server.\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetInstanceNameList()\")\n        return self.db.get_instance_name_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\ngets the attribute alias from the attribute name", "response": "def DbGetAttributeAlias2(self, argin):\n        \"\"\" Get the attribute alias from the attribute name.\n        Returns one empty string if nothing found in database\n\n        :param argin: The attribute name (dev_name/att_name)\n        :type: tango.DevString\n        :return: The attribute alias name (or empty string)\n        :rtype: tango.DevString \"\"\"\n        self._log.debug(\"In DbGetAttributeAlias2()\")\n        attr_name = argin[0]\n        return self.db.get_attribute_alias2(attr_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbAddServer(self, argin):\n        self._log.debug(\"In DbAddServer()\")\n\n        if len(argin) < 3 or not len(argin) % 2:\n            self.warn_stream(\"DataBase::AddServer(): incorrect number of input arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"incorrect no. of input arguments, needs at least 3 (server,device,class)\",\n                   \"DataBase::AddServer()\")\n        server_name = argin[0]\n\n        for i in range((len(argin) - 1) / 2):\n            d_name, klass_name = argin[i * 2 + 1], argin[i * 2 + 2]\n            ret, dev_name, dfm = check_device_name(d_name)\n            if not ret:\n                th_exc(DB_IncorrectDeviceName,\n                      \"device name (\" + d_name + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                      \"DataBase::AddServer()\")\n            self.db.add_device(server_name, (dev_name, dfm) , klass_name)", "response": "Add a server process entry in database"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script for\ngetting event channel info from database", "response": "def DbImportEvent(self, argin):\n        \"\"\" Get event channel info from database\n\n        :param argin: name of event channel or factory\n        :type: tango.DevString\n        :return: export information e.g. IOR\n        :rtype: tango.DevVarLongStringArray \"\"\"\n        self._log.debug(\"In DbImportEvent()\")\n        argin = replace_wildcard(argin.lower())\n        return self.db.import_event(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nretrieves device property history", "response": "def DbGetDevicePropertyHist(self, argin):\n        \"\"\" Retrieve device  property history\n\n        :param argin: Str[0] = Device name\n        Str[1] = Property name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Property name\n        Str[1] = date\n        Str[2] = Property value number (array case)\n        Str[3] = Property value 1\n        Str[n] = Property value n\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDevicePropertyHist()\")\n        device_name = argin[0]\n        prop_name = argin[1]\n        return self.db.get_device_property_hist(device_name, prop_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbGetServerNameList(self, argin):\n        self._log.debug(\"In DbGetServerNameList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_server_name_list(argin)", "response": "Returns the list of server names found for the specified wildcard"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nretrieving device attribute properties.", "response": "def DbGetDeviceAttributeProperty2(self, argin):\n        \"\"\" Retrieve device attribute properties. This command has the possibility to retrieve\n        device attribute properties which are arrays. It is not possible with the old\n        DbGetDeviceAttributeProperty command. Nevertheless, the old command has not been\n        deleted for compatibility reason\n\n        :param argin: Str[0] = Device name\n        Str[1] = Attribute name\n        Str[n] = Attribute name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Device name\n        Str[1] = Attribute property  number\n        Str[2] = Attribute property 1 name\n        Str[3] = Attribute property 1 value number (array case)\n        Str[4] = Attribute property 1 value\n        Str[n] = Attribute property 1 value (array case)\n        Str[n + 1] = Attribute property 2 name\n        Str[n + 2] = Attribute property 2 value number (array case)\n        Str[n + 3] = Attribute property 2 value\n        Str[n + m] = Attribute property 2 value (array case)\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceAttributeProperty2()\")\n        dev_name = argin[0]\n        return self.db.get_device_attribute_property2(dev_name, argin[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\ndelete class properties from database", "response": "def DbDeleteClassProperty(self, argin):\n        \"\"\" Delete class properties from database\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Property name\n        Str[n] = Property name\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbDeleteClassProperty()\")\n        klass_name = argin[0]\n        for prop_name in argin[1:]:\n            self.db.delete_class_property(prop_name)"}
{"SOURCE": "codesearchnet", "instruction": "Explain what the following Python 3 code does\ndef DbUnExportEvent(self, argin):\n        self._log.debug(\"In DbUnExportEvent()\")\n        event_name = argin[0].lower()\n        self.db.unexport_event(event_name)", "response": "Mark one event channel as non exported in database"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nget Tango class property value", "response": "def DbGetClassAttributeProperty(self, argin):\n        \"\"\" Get Tango class property(ies) value\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Attribute name\n        Str[n] = Attribute name\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Tango class name\n        Str[1] = Attribute property  number\n        Str[2] = Attribute property 1 name\n        Str[3] = Attribute property 1 value\n        Str[n + 1] = Attribute property 2 name\n        Str[n + 2] = Attribute property 2 value\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetClassAttributeProperty()\")\n        class_name = argin[0]\n        return self.db.get_class_attribute_property(class_name, argin[1:])"}
{"SOURCE": "codesearchnet", "instruction": "Can you create a Python 3 function that\nupdates server info including host mode and level", "response": "def DbPutServerInfo(self, argin):\n        \"\"\" Update server info including host, mode and level\n\n        :param argin: server info\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbPutServerInfo()\")\n\n        if len(argin) < 4:\n            self.warn_stream(\"DataBase::DbPutServerInfo(): insufficient number of arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient server info\",\n                   \"DataBase::DbPutServerInfo()\")\n\n        tmp_server = argin[0].lower()\n        tmp_host = argin[1]\n        tmp_mode = argin[2]\n        tmp_level = argin[3]\n        tmp_extra = []\n        if len(argin) > 4:\n            tmp_extra = argin[4:]\n\n        tmp_len = len(argin) - 1\n        self.db.put_server_info(tmp_server, tmp_host, tmp_mode, tmp_level, tmp_extra)"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef DbDeleteDeviceAlias(self, argin):\n        self._log.debug(\"In DbDeleteDeviceAlias()\")\n        self.db.delete_device_alias(argin)", "response": "Delete a device alias."}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef DbExportEvent(self, argin):\n        self._log.debug(\"In DbExportEvent()\")\n\n        if len(argin) < 5:\n            self.warn_stream(\"DataBase::db_export_event(): insufficient export info for event \")\n            th_exc(DB_IncorrectArguments,\n                   \"insufficient export info for event\",\n                   \"DataBase::ExportEvent()\")\n\n        event, IOR, host, pid, version = argin[:5]\n        event = replace_wildcard(event.lower())\n        self.db.export_event(event, IOR, host, pid, version)", "response": "Export an event channel to the database"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DbGetDeviceInfo(self, argin):\n        self._log.debug(\"In DbGetDeviceInfo()\")\n        ret, dev_name, dfm = check_device_name(argin)\n        if not ret:\n            th_exc(DB_IncorrectDeviceName,\n                  \"device name (\" + argin + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                  \"DataBase::DbGetDeviceAlias()\")\n\n        return self.db.get_device_info(dev_name)", "response": "Get info from DbImportDevice and started or stopped dates."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef DbGetPropertyHist(self, argin):\n        self._log.debug(\"In DbGetPropertyHist()\")\n        object_name = argin[0]\n        prop_name = argin[1]\n        return self.db.get_property_hist(object_name, prop_name)", "response": "Retrieve object property history"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget a list of device name members matching the specified filter", "response": "def DbGetDeviceMemberList(self, argin):\n        \"\"\" Get a list of device name members for device name matching the\n        specified filter\n\n        :param argin: The filter\n        :type: tango.DevString\n        :return: Device names member list\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceMemberList()\")\n        argin = replace_wildcard(argin)\n        return self.db.get_device_member_list(argin)"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef DbGetClassList(self, argin):\n        self._log.debug(\"In DbGetClassList()\")\n        server = replace_wildcard(argin)\n        return self.db.get_class_list(server)", "response": "Get Tango class list with a specified filter"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ngetting the attribute name from the given alias", "response": "def DbGetAliasAttribute(self, argin):\n        \"\"\" Get the attribute name from the given alias.\n        If the given alias is not found in database, returns an empty string\n\n        :param argin: The attribute alias\n        :type: tango.DevString\n        :return: The attribute name (dev_name/att_name)\n        :rtype: tango.DevString \"\"\"\n        self._log.debug(\"In DbGetAliasAttribute()\")\n        alias_name = argin[0]\n        return self.db.get_alias_attribute(alias_name)"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef DbDeleteServerInfo(self, argin):\n        self._log.debug(\"In DbDeleteServerInfo()\")\n        self.db.delete_server_info(argin)", "response": "delete info related to a Tango devvice server"}
{"SOURCE": "codesearchnet", "instruction": "How would you code a function in Python 3 to\nget the list of attribute names for a given Tango class", "response": "def DbGetClassAttributeList(self, argin):\n        \"\"\" Get attrilute list for a given Tango class with a specified filter\n\n        :param argin: Str[0] = Tango class name\n        Str[1] = Attribute name filter (eg: att*)\n        :type: tango.DevVarStringArray\n        :return: Str[0] = Class attribute name\n        Str[n] = Class attribute name\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetClassAttributeList()\")\n        class_name = argin[0]\n        wildcard = replace_wildcard(argin[1])\n        return self.db.get_class_attribute_list(class_name, wildcard)"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nadd a Tango class device to a specific server process", "response": "def DbAddDevice(self, argin):\n        \"\"\" Add a Tango class device to a specific device server\n\n        :param argin: Str[0] = Full device server process name\n        Str[1] = Device name\n        Str[2] = Tango class name\n        :type: tango.DevVarStringArray\n        :return:\n        :rtype: tango.DevVoid \"\"\"\n        self._log.debug(\"In DbAddDevice()\")\n\n        if len(argin) < 3:\n            self.warn_stream(\"DataBase::AddDevice(): incorrect number of input arguments \")\n            th_exc(DB_IncorrectArguments,\n                   \"incorrect no. of input arguments, needs at least 3 (server,device,class)\",\n                   \"DataBase::AddDevice()\")\n\n        self.info_stream(\"DataBase::AddDevice(): insert %s server with device %s\",argin[0],argin[1])\n        server_name, d_name, klass_name = argin[:3]\n        if len(argin) > 3:\n            alias = argin[3]\n        else:\n            alias = None\n\n        ret, dev_name, dfm = check_device_name(d_name)\n        if not ret:\n            th_exc(DB_IncorrectDeviceName,\n                  \"device name (\" + d_name + \") syntax error (should be [tango:][//instance/]domain/family/member)\",\n                  \"DataBase::AddDevice()\")\n        # Lock table\n        self.db.add_device(server_name, (dev_name, dfm) , klass_name, alias=alias)"}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\ngets a list of devices for specified server and class name", "response": "def DbGetDeviceList(self, argin):\n        \"\"\" Get a list of devices for specified server and class.\n\n        :param argin: argin[0] : server name\n        argin[1] : class name\n        :type: tango.DevVarStringArray\n        :return: The list of devices for specified server and class.\n        :rtype: tango.DevVarStringArray \"\"\"\n        self._log.debug(\"In DbGetDeviceList()\")\n        server_name = replace_wildcard(argin[0])\n        class_name = replace_wildcard(argin[1])\n        return self.db.get_device_list(server_name, class_name)"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nreturns the given operation as a concurrent future.", "response": "def delegate(self, fn, *args, **kwargs):\n        \"\"\"Return the given operation as a concurrent future.\"\"\"\n        return self.subexecutor.submit(fn, *args, **kwargs)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 script to\nreturn a list of modules that require the running version of the running version of the software.", "response": "def requires_pytango(min_version=None, conflicts=(),\n                     software_name=\"Software\"):\n    \"\"\"\n    Determines if the required PyTango version for the running\n    software is present. If not an exception is thrown.\n    Example usage::\n\n        from tango import requires_pytango\n\n        requires_pytango('7.1', conflicts=['8.1.1'], software='MyDS')\n\n    :param min_version:\n        minimum PyTango version [default: None, meaning no minimum\n        required]. If a string is given, it must be in the valid\n        version number format\n        (see: :class:`~distutils.version.LooseVersion`)\n    :type min_version:\n        None, str, :class:`~distutils.version.LooseVersion`\n    :param conflics:\n        a sequence of PyTango versions which conflict with the\n        software using it\n    :type conflics:\n        seq<str|LooseVersion>\n    :param software_name:\n        software name using tango. Used in the exception message\n    :type software_name: str\n\n    :raises Exception: if the required PyTango version is not met\n\n    New in PyTango 8.1.4\n    \"\"\"\n    return __requires(\"pytango\", min_version=min_version,\n                      conflicts=conflicts, software_name=software_name)"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef requires_tango(min_version=None, conflicts=(), software_name=\"Software\"):\n    return __requires(\"Tango\", min_version=min_version,\n                      conflicts=conflicts, software_name=software_name)", "response": "Returns a list of the running items that require Tango."}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nreturn list of enumeration labels from Enum class.", "response": "def get_enum_labels(enum_cls):\n    \"\"\"\n    Return list of enumeration labels from Enum class.\n\n    The list is useful when creating an attribute, for the\n    `enum_labels` parameter.  The enumeration values are checked\n    to ensure they are unique, start at zero, and increment by one.\n\n    :param enum_cls: the Enum class to be inspected\n    :type enum_cls: :py:obj:`enum.Enum`\n\n    :return: List of label strings\n    :rtype: :py:obj:`list`\n\n    :raises EnumTypeError: in case the given class is invalid\n    \"\"\"\n    if not issubclass(enum_cls, enum.Enum):\n        raise EnumTypeError(\"Input class '%s' must be derived from enum.Enum\"\n                            % enum_cls)\n\n    # Check there are no duplicate labels\n    try:\n        enum.unique(enum_cls)\n    except ValueError as exc:\n        raise EnumTypeError(\"Input class '%s' must be unique - %s\"\n                            % (enum_cls, exc))\n\n    # Check the values start at 0, and increment by 1, since that is\n    # assumed by tango's DEV_ENUM implementation.\n    values = [member.value for member in enum_cls]\n    if not values:\n        raise EnumTypeError(\"Input class '%s' has no members!\" % enum_cls)\n    expected_value = 0\n    for value in values:\n        if value != expected_value:\n            raise EnumTypeError(\"Enum values for '%s' must start at 0 and \"\n                                \"increment by 1.  Values: %s\"\n                                % (enum_cls, values))\n        expected_value += 1\n\n    return [member.name for member in enum_cls]"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_numerical(tg_type, inc_array=False):\n    global _scalar_numerical_types, _array_numerical_types\n    if tg_type in _scalar_numerical_types:\n        return True\n    if not inc_array:\n        return False\n    return tg_type in _array_numerical_types", "response": "Tells if the given tango type is numerical or not"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate the documentation for the following Python 3 function\ndef is_int(tg_type, inc_array=False):\n    global _scalar_int_types, _array_int_types\n    if tg_type in _scalar_int_types:\n        return True\n    if not inc_array:\n        return False\n    return tg_type in _array_int_types", "response": "Tells if the given tango type is integer or not"}
{"SOURCE": "codesearchnet", "instruction": "Given the following Python 3 function, write the documentation\ndef is_float(tg_type, inc_array=False):\n    global _scalar_float_types, _array_float_types\n    if tg_type in _scalar_float_types:\n        return True\n    if not inc_array:\n        return False\n    return tg_type in _array_float_types", "response": "Tells if the given tango type is float or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_bool(tg_type, inc_array=False):\n    global _scalar_bool_types, _array_bool_types\n    if tg_type in _scalar_bool_types:\n        return True\n    if not inc_array:\n        return False\n    return tg_type in _array_bool_types", "response": "Tells if the given tango type is boolean or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef is_str(tg_type, inc_array=False):\n    global _scalar_str_types, _array_str_types\n    if tg_type in _scalar_str_types:\n        return True\n    if not inc_array:\n        return False\n    return tg_type in _array_str_types", "response": "Tells if the given tango type is string or False otherwise."}
{"SOURCE": "codesearchnet", "instruction": "Implement a Python 3 function for\nconverting a python sequence of strings into a tango. StdStringVector", "response": "def seq_2_StdStringVector(seq, vec=None):\n    \"\"\"Converts a python sequence<str> object to a :class:`tango.StdStringVector`\n\n        :param seq: the sequence of strings\n        :type seq: sequence<:py:obj:`str`>\n        :param vec: (optional, default is None) an :class:`tango.StdStringVector`\n                    to be filled. If None is given, a new :class:`tango.StdStringVector`\n                    is created\n        :return: a :class:`tango.StdStringVector` filled with the same contents as seq\n        :rtype: :class:`tango.StdStringVector`\n    \"\"\"\n    if vec is None:\n        if isinstance(seq, StdStringVector):\n            return seq\n        vec = StdStringVector()\n    if not isinstance(vec, StdStringVector):\n        raise TypeError('vec must be a tango.StdStringVector')\n    for e in seq:\n        vec.append(str(e))\n    return vec"}
{"SOURCE": "codesearchnet", "instruction": "Can you generate a brief explanation for the following Python 3 code\ndef StdStringVector_2_seq(vec, seq=None):\n    if seq is None:\n        seq = []\n    if not isinstance(vec, StdStringVector):\n        raise TypeError('vec must be a tango.StdStringVector')\n    for e in vec:\n        seq.append(str(e))\n    return seq", "response": "Converts a tango. StdStringVector to a python sequence"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\nconverting a python sequence of floats to a tango. StdDoubleVector", "response": "def seq_2_StdDoubleVector(seq, vec=None):\n    \"\"\"Converts a python sequence<float> object to a :class:`tango.StdDoubleVector`\n\n        :param seq: the sequence of floats\n        :type seq: sequence<:py:obj:`float`>\n        :param vec: (optional, default is None) an :class:`tango.StdDoubleVector`\n                    to be filled. If None is given, a new :class:`tango.StdDoubleVector`\n                    is created\n        :return: a :class:`tango.StdDoubleVector` filled with the same contents as seq\n        :rtype: :class:`tango.StdDoubleVector`\n    \"\"\"\n    if vec is None:\n        if isinstance(seq, StdDoubleVector):\n            return seq\n        vec = StdDoubleVector()\n    if not isinstance(vec, StdDoubleVector):\n        raise TypeError('vec must be a tango.StdDoubleVector')\n    for e in seq:\n        vec.append(str(e))\n    return vec"}
{"SOURCE": "codesearchnet", "instruction": "Can you write a function in Python 3 where it\nconverts a tango. StdDoubleVector to a python sequence", "response": "def StdDoubleVector_2_seq(vec, seq=None):\n    \"\"\"Converts a :class:`tango.StdDoubleVector` to a python sequence<float>\n\n        :param seq: the :class:`tango.StdDoubleVector`\n        :type seq: :class:`tango.StdDoubleVector`\n        :param vec: (optional, default is None) a python sequence to be filled.\n                     If None is given, a new list is created\n        :return: a python sequence filled with the same contents as seq\n        :rtype: sequence<float>\n    \"\"\"\n    if seq is None:\n        seq = []\n    if not isinstance(vec, StdDoubleVector):\n        raise TypeError('vec must be a tango.StdDoubleVector')\n    for e in vec:\n        seq.append(float(e))\n    return seq"}
{"SOURCE": "codesearchnet", "instruction": "Implement a function in Python 3 to\nconvert a python sequence of DbDevInfo objects to a list of tango. DbDevInfos objects.", "response": "def seq_2_DbDevInfos(seq, vec=None):\n    \"\"\"Converts a python sequence<DbDevInfo> object to a :class:`tango.DbDevInfos`\n\n        :param seq: the sequence of DbDevInfo\n        :type seq: sequence<DbDevInfo>\n        :param vec: (optional, default is None) an :class:`tango.DbDevInfos`\n                    to be filled. If None is given, a new :class:`tango.DbDevInfos`\n                    is created\n        :return: a :class:`tango.DbDevInfos` filled with the same contents as seq\n        :rtype: :class:`tango.DbDevInfos`\n    \"\"\"\n    if vec is None:\n        if isinstance(seq, DbDevInfos):\n            return seq\n        vec = DbDevInfos()\n    if not isinstance(vec, DbDevInfos):\n        raise TypeError('vec must be a tango.DbDevInfos')\n    for e in seq:\n        vec.append(e)\n    return vec"}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef seq_2_DbDevExportInfos(seq, vec=None):\n    if vec is None:\n        if isinstance(seq, DbDevExportInfos):\n            return seq\n        vec = DbDevExportInfos()\n    if not isinstance(vec, DbDevExportInfos):\n        raise TypeError('vec must be a tango.DbDevExportInfos')\n    for e in seq:\n        vec.append(e)\n    return vec", "response": "Converts a python sequence of DbDevExportInfo objects to a list of DbDevExportInfos objects."}
{"SOURCE": "codesearchnet", "instruction": "Can you implement a function in Python 3 that\nconverts a python sequence of DbDatum to a tango. DbData object", "response": "def seq_2_DbData(seq, vec=None):\n    \"\"\"Converts a python sequence<DbDatum> object to a :class:`tango.DbData`\n\n        :param seq: the sequence of DbDatum\n        :type seq: sequence<DbDatum>\n        :param vec: (optional, default is None) an :class:`tango.DbData`\n                    to be filled. If None is given, a new :class:`tango.DbData`\n                    is created\n        :return: a :class:`tango.DbData` filled with the same contents as seq\n        :rtype: :class:`tango.DbData`\n    \"\"\"\n    if vec is None:\n        if isinstance(seq, DbData):\n            return seq\n        vec = DbData()\n    if not isinstance(vec, DbData):\n        raise TypeError('vec must be a tango.DbData')\n    for e in seq:\n        vec.append(e)\n    return vec"}
{"SOURCE": "codesearchnet", "instruction": "Make a summary of the following Python 3 code\ndef seqStr_2_obj(seq, tg_type, tg_format=None):\n    if tg_format:\n        return _seqStr_2_obj_from_type_format(seq, tg_type, tg_format)\n    return _seqStr_2_obj_from_type(seq, tg_type)", "response": "Translates a sequence of strings to a sequence of objects of give type and format\n       "}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function for\nconverting a string into an object according to the given tango type .", "response": "def str_2_obj(obj_str, tg_type=None):\n    \"\"\"Converts a string into an object according to the given tango type\n\n           :param obj_str: the string to be converted\n           :type obj_str: :py:obj:`str`\n           :param tg_type: tango type\n           :type tg_type: :class:`tango.CmdArgType`\n           :return: an object calculated from the given string\n           :rtype: :py:obj:`object`\n    \"\"\"\n    if tg_type is None:\n        return obj_str\n    f = str\n    if is_scalar_type(tg_type):\n        if is_numerical_type(tg_type):\n            if obj_str in __NO_STR_VALUE:\n                return None\n        if is_int_type(tg_type):\n            f = int\n        elif is_float_type(tg_type):\n            f = float\n        elif is_bool_type(tg_type):\n            f = bool_\n    return f(obj_str)"}
{"SOURCE": "codesearchnet", "instruction": "Write a Python 3 function that can\nconvert a python object into a string according to the given tango type", "response": "def obj_2_str(obj, tg_type=None):\n    \"\"\"Converts a python object into a string according to the given tango type\n\n           :param obj: the object to be converted\n           :type obj: :py:obj:`object`\n           :param tg_type: tango type\n           :type tg_type: :class:`tango.CmdArgType`\n           :return: a string representation of the given object\n           :rtype: :py:obj:`str`\n    \"\"\"\n    if tg_type is None:\n        return obj\n    if tg_type in _scalar_types:\n        # scalar cases\n        if is_pure_str(obj):\n            return obj\n        elif is_non_str_seq(obj):\n            if not len(obj):\n                return \"\"\n            obj = obj[0]\n        return str(obj)\n    # sequence cases\n    if obj is None:\n        return ''\n    return '\\n'.join([str(i) for i in obj])"}
{"SOURCE": "codesearchnet", "instruction": "Create a Python 3 function for\ncopying documentation string of a method from the base class into the rewritten method of the given class", "response": "def copy_doc(klass, fnname):\n    \"\"\"Copies documentation string of a method from the super class into the\n    rewritten method of the given class\"\"\"\n    base_meth, base_func = __get_meth_func(klass.__base__, fnname)\n    meth, func = __get_meth_func(klass, fnname)\n    func.__doc__ = base_func.__doc__"}
{"SOURCE": "codesearchnet", "instruction": "Can you tell what is the following Python 3 function doing\ndef get_home():\n    path = ''\n    try:\n        path = os.path.expanduser(\"~\")\n    except:\n        pass\n    if not os.path.isdir(path):\n        for evar in ('HOME', 'USERPROFILE', 'TMP'):\n            try:\n                path = os.environ[evar]\n                if os.path.isdir(path):\n                    break\n            except:\n                pass\n    if path:\n        return path\n    else:\n        raise RuntimeError('please define environment variable $HOME')", "response": "Find user s home directory if possible. Otherwise raise error."}
{"SOURCE": "codesearchnet", "instruction": "How would you explain what the following Python 3 function does\ndef _get_env_var(env_var_name):\n\n    if env_var_name in os.environ:\n        return os.environ[env_var_name]\n\n    fname = os.path.join(get_home(), '.tangorc')\n    if not os.path.exists(fname):\n        if os.name == 'posix':\n            fname = \"/etc/tangorc\"\n    if not os.path.exists(fname):\n        return None\n\n    for line in open(fname):\n        strippedline = line.split('#', 1)[0].strip()\n\n        if not strippedline:\n            # empty line\n            continue\n\n        tup = strippedline.split('=', 1)\n        if len(tup) != 2:\n            # illegal line!\n            continue\n\n        key, val = map(str.strip, tup)\n        if key == env_var_name:\n            return val", "response": "Returns the value of the given environment variable name."}
